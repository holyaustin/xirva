[{"id": "1206.0051", "submitter": "Florin Rusu", "authors": "Chengjie Qin, Florin Rusu", "title": "PF-OLA: A High-Performance Framework for Parallel On-Line Aggregation", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online aggregation provides estimates to the final result of a computation\nduring the actual processing. The user can stop the computation as soon as the\nestimate is accurate enough, typically early in the execution. This allows for\nthe interactive data exploration of the largest datasets. In this paper we\nintroduce the first framework for parallel online aggregation in which the\nestimation virtually does not incur any overhead on top of the actual\nexecution. We define a generic interface to express any estimation model that\nabstracts completely the execution details. We design a novel estimator\nspecifically targeted at parallel online aggregation. When executed by the\nframework over a massive $8\\text{TB}$ TPC-H instance, the estimator provides\naccurate confidence bounds early in the execution even when the cardinality of\nthe final result is seven orders of magnitude smaller than the dataset size and\nwithout incurring overhead.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2012 23:38:36 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2013 07:10:04 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Qin", "Chengjie", ""], ["Rusu", "Florin", ""]]}, {"id": "1206.0089", "submitter": "Michel Hurfin", "authors": "Chuanyou Li, Michel Hurfin (INRIA - SUPELEC), Yun Wang", "title": "Reaching Approximate Byzantine Consensus in Partially-Connected Mobile\n  Networks", "comments": "No. RR-7985 (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of approximate consensus in mobile networks\ncontaining Byzantine nodes. We assume that each correct node can communicate\nonly with its neighbors and has no knowledge of the global topology. As all\nnodes have moving ability, the topology is dynamic. The number of Byzantine\nnodes is bounded by f and known by all correct nodes. We first introduce an\napproximate Byzantine consensus protocol which is based on the linear iteration\nmethod. As nodes are allowed to collect information during several consecutive\nrounds, moving gives them the opportunity to gather more values. We propose a\nnovel sufficient and necessary condition to guarantee the final convergence of\nthe consensus protocol. The requirement expressed by our condition is not\n\"universal\": in each phase it affects only a single correct node. More\nprecisely, at least one correct node among those that propose either the\nminimum or the maximum value which is present in the network, has to receive\nenough messages (quantity constraint) with either higher or lower values\n(quality constraint). Of course, nodes' motion should not prevent this\nrequirement to be fulfilled. Our conclusion shows that the proposed condition\ncan be satisfied if the total number of nodes is greater than 3f+1.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2012 06:14:29 GMT"}], "update_date": "2012-06-04", "authors_parsed": [["Li", "Chuanyou", "", "INRIA - SUPELEC"], ["Hurfin", "Michel", "", "INRIA - SUPELEC"], ["Wang", "Yun", ""]]}, {"id": "1206.0115", "submitter": "Olivier Coulaud", "authors": "Emmanuel Agullo (INRIA Bordeaux - Sud-Ouest, LaBRI), B\\'eranger Bramas\n  (INRIA Bordeaux - Sud-Ouest, LaBRI), Olivier Coulaud (INRIA Bordeaux -\n  Sud-Ouest, LaBRI), Eric Darve, Matthias Messner (INRIA Bordeaux - Sud-Ouest,\n  LaBRI), Takahashi Toru", "title": "Pipelining the Fast Multipole Method over a Runtime System", "comments": "No. RR-7981 (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast Multipole Methods (FMM) are a fundamental operation for the simulation\nof many physical problems. The high performance design of such methods usually\nrequires to carefully tune the algorithm for both the targeted physics and the\nhardware. In this paper, we propose a new approach that achieves high\nperformance across architectures. Our method consists of expressing the FMM\nalgorithm as a task flow and employing a state-of-the-art runtime system,\nStarPU, in order to process the tasks on the different processing units. We\ncarefully design the task flow, the mathematical operators, their Central\nProcessing Unit (CPU) and Graphics Processing Unit (GPU) implementations, as\nwell as scheduling schemes. We compute potentials and forces of 200 million\nparticles in 48.7 seconds on a homogeneous 160 cores SGI Altix UV 100 and of 38\nmillion particles in 13.34 seconds on a heterogeneous 12 cores Intel Nehalem\nprocessor enhanced with 3 Nvidia M2090 Fermi GPUs.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2012 08:05:39 GMT"}], "update_date": "2012-06-04", "authors_parsed": [["Agullo", "Emmanuel", "", "INRIA Bordeaux - Sud-Ouest, LaBRI"], ["Bramas", "B\u00e9ranger", "", "INRIA Bordeaux - Sud-Ouest, LaBRI"], ["Coulaud", "Olivier", "", "INRIA Bordeaux -\n  Sud-Ouest, LaBRI"], ["Darve", "Eric", "", "INRIA Bordeaux - Sud-Ouest,\n  LaBRI"], ["Messner", "Matthias", "", "INRIA Bordeaux - Sud-Ouest,\n  LaBRI"], ["Toru", "Takahashi", ""]]}, {"id": "1206.0150", "submitter": "Bernhard Haeupler", "authors": "Yehuda Afek and Noga Alon and Ziv Bar-Joseph and Alejandro Cornejo and\n  Bernhard Haeupler and Fabian Kuhn", "title": "Beeping a Maximal Independent Set", "comments": "arXiv admin note: substantial text overlap with arXiv:1108.1926", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing a maximal independent set (MIS) in an\nextremely harsh broadcast model that relies only on carrier sensing. The model\nconsists of an anonymous broadcast network in which nodes have no knowledge\nabout the topology of the network or even an upper bound on its size.\nFurthermore, it is assumed that an adversary chooses at which time slot each\nnode wakes up. At each time slot a node can either beep, that is, emit a\nsignal, or be silent. At a particular time slot, beeping nodes receive no\nfeedback, while silent nodes can only differentiate between none of its\nneighbors beeping, or at least one of its neighbors beeping.\n  We start by proving a lower bound that shows that in this model, it is not\npossible to locally converge to an MIS in sub-polynomial time. We then study\nfour different relaxations of the model which allow us to circumvent the lower\nbound and find an MIS in polylogarithmic time. First, we show that if a\npolynomial upper bound on the network size is known, it is possible to find an\nMIS in O(log^3 n) time. Second, if we assume sleeping nodes are awoken by\nneighboring beeps, then we can also find an MIS in O(log^3 n) time. Third, if\nin addition to this wakeup assumption we allow sender-side collision detection,\nthat is, beeping nodes can distinguish whether at least one neighboring node is\nbeeping concurrently or not, we can find an MIS in O(log^2 n) time. Finally, if\ninstead we endow nodes with synchronous clocks, it is also possible to find an\nMIS in O(log^2 n) time.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2012 11:23:30 GMT"}], "update_date": "2012-06-04", "authors_parsed": [["Afek", "Yehuda", ""], ["Alon", "Noga", ""], ["Bar-Joseph", "Ziv", ""], ["Cornejo", "Alejandro", ""], ["Haeupler", "Bernhard", ""], ["Kuhn", "Fabian", ""]]}, {"id": "1206.0154", "submitter": "Mohsen Ghaffari", "authors": "Mohsen Ghaffari and Bernhard Haeupler and Nancy Lynch and Calvin\n  Newport", "title": "Bounds on Contention Management in Radio Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The local broadcast problem assumes that processes in a wireless network are\nprovided messages, one by one, that must be delivered to their neighbors. In\nthis paper, we prove tight bounds for this problem in two well-studied wireless\nnetwork models: the classical model, in which links are reliable and collisions\nconsistent, and the more recent dual graph model, which introduces unreliable\nedges. Our results prove that the Decay strategy, commonly used for local\nbroadcast in the classical setting, is optimal. They also establish a\nseparation between the two models, proving that the dual graph setting is\nstrictly harder than the classical setting, with respect to this primitive.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2012 11:38:47 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2012 16:15:43 GMT"}], "update_date": "2012-10-04", "authors_parsed": [["Ghaffari", "Mohsen", ""], ["Haeupler", "Bernhard", ""], ["Lynch", "Nancy", ""], ["Newport", "Calvin", ""]]}, {"id": "1206.0419", "submitter": "Gopalakrishnan Tr Nair", "authors": "T. R. Gopalakrishnan Nair, P Jayarekha", "title": "Pre-allocation Strategies of Computational Resources in Cloud Computing\n  using Adaptive Resonance Theory-2", "comments": "pages 11, figures 3, International Journal on Cloud Computing:\n  Services and Architecture(IJCCSA),Vol.1, No.2, August 2011", "journal-ref": null, "doi": "10.5121/ijccsa.2011.1203", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major challenges of cloud computing is the management of\nrequest-response coupling and optimal allocation strategies of computational\nresources for the various types of service requests. In the normal situations\nthe intelligence required to classify the nature and order of the request using\nstandard methods is insufficient because the arrival of request is at a random\nfashion and it is meant for multiple resources with different priority order\nand variety. Hence, it becomes absolutely essential that we identify the trends\nof different request streams in every category by auto classifications and\norganize preallocation strategies in a predictive way. It calls for designs of\nintelligent modes of interaction between the client request and cloud computing\nresource manager. This paper discusses about the corresponding scheme using\nAdaptive Resonance Theory-2.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jun 2012 04:42:23 GMT"}], "update_date": "2012-06-05", "authors_parsed": [["Nair", "T. R. Gopalakrishnan", ""], ["Jayarekha", "P", ""]]}, {"id": "1206.0609", "submitter": "Ayad Ghany Ismaeel", "authors": "Ayad Ghany Ismaeel", "title": "New Technique for Proposing Network's Topology using GPS and GIS", "comments": "13 pages, 6 figures, 5 tables", "journal-ref": "International Journal of Distributed and Parallel Systems (IJDPS)\n  Vol.3, No.2, March 2012, Pages 53-65", "doi": "10.5121/ijdps.2012.3205", "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of proposed topology for network comes when using Prim's\nalgorithm with default distance (unrealistic distances) between network's nodes\nand don't care about the lakes, high hills, buildings, etc. This problem will\ncause incorrect estimations for cost (budget) of requirements like the media\n(optic fibre) and the number or type of Access-points, regenerator, Optic\nAmplifier, etc. This paper proposed a new technique of implementing Prim's\nalgorithm to obtain realistic topology using realistic distances between\nnetwork's nodes via Global Positioning System GPS and Geographic Information\nSystems GIS packages. Applying the new technique on academic institutes network\nof Erbil city from view of media (optic fibre) shows that there is disability\nin cost (budget) of the media which is needed (nearly) 4 times if implement\ndefault Prim's algorithm (don't using GPS & GIS) base on unrealistic distances\nbetween the nodes.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2012 13:11:14 GMT"}], "update_date": "2012-06-05", "authors_parsed": [["Ismaeel", "Ayad Ghany", ""]]}, {"id": "1206.0919", "submitter": "Jochen Gerhard", "authors": "Jochen Gerhard, Volker Lindenstruth, and Marcus Bleicher", "title": "Relativistic Hydrodynamics on Graphic Cards", "comments": "Details and discussions added, replaced with accepted version. (15\n  pages, 8 figures, 2 listings)", "journal-ref": null, "doi": "10.1016/j.cpc.2012.09.013", "report-no": null, "categories": "hep-ph cs.DC cs.PF hep-th", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to accelerate relativistic hydrodynamics simulations using\ngraphic cards (graphic processing units, GPUs). These improvements are of\nhighest relevance e.g. to the field of high-energetic nucleus-nucleus\ncollisions at RHIC and LHC where (ideal and dissipative) relativistic\nhydrodynamics is used to calculate the evolution of hot and dense QCD matter.\nThe results reported here are based on the Sharp And Smooth Transport Algorithm\n(SHASTA), which is employed in many hydrodynamical models and hybrid simulation\npackages, e.g. the Ultrarelativistic Quantum Molecular Dynamics model (UrQMD).\nWe have redesigned the SHASTA using the OpenCL computing framework to work on\naccelerators like graphic processing units (GPUs) as well as on multi-core\nprocessors. With the redesign of the algorithm the hydrodynamic calculations\nhave been accelerated by a factor 160 allowing for event-by-event calculations\nand better statistics in hybrid calculations.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 13:16:36 GMT"}, {"version": "v2", "created": "Sun, 9 Sep 2012 10:07:49 GMT"}], "update_date": "2012-09-28", "authors_parsed": [["Gerhard", "Jochen", ""], ["Lindenstruth", "Volker", ""], ["Bleicher", "Marcus", ""]]}, {"id": "1206.0988", "submitter": "Mueen Uddin", "authors": "Mueen Uddin and Azizah Abdul Rahman", "title": "Virtualization Implementation Model for Cost Effective & Efficient Data\n  Centers", "comments": "6 pages, 1 Figure, Journal Paper. arXiv admin note: substantial text\n  overlap with arXiv:1010.5037", "journal-ref": "International Journal of Advanced Computer Science and\n  Applications, (IJACSA) Vol. 2, No.1, January 2011 pg. 69-74", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data centers form a key part of the infrastructure upon which a variety of\ninformation technology services are built. They provide the capabilities of\ncentralized repository for storage, management, networking and dissemination of\ndata. With the rapid increase in the capacity and size of data centers, there\nis a continuous increase in the demand for energy consumption. These data\ncenters not only consume a tremendous amount of energy but are riddled with IT\ninefficiencies. Data center are plagued with thousands of servers as major\ncomponents. These servers consume huge energy without performing useful work.\nIn an average server environment, 30% of the servers are \"dead\" only consuming\nenergy, without being properly utilized. This paper proposes a five step model\nusing an emerging technology called virtualization to achieve energy efficient\ndata centers. The proposed model helps Data Center managers to properly\nimplement virtualization technology in their data centers to make them green\nand energy efficient so as to ensure that IT infrastructure contributes as\nlittle as possible to the emission of greenhouse gases, and helps to regain\npower and cooling capacity, recapture resilience and dramatically reducing\nenergy costs and total cost of ownership.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2012 05:19:32 GMT"}], "update_date": "2012-06-06", "authors_parsed": [["Uddin", "Mueen", ""], ["Rahman", "Azizah Abdul", ""]]}, {"id": "1206.0992", "submitter": "Guodong Shi", "authors": "Guodong Shi, Bo Li, Mikael Johansson and Karl Henrik Johansson", "title": "Finite-time Convergent Gossiping", "comments": "IEEE/ACM Transactions on Networking, In Press", "journal-ref": null, "doi": "10.1109/TNET.2015.2484345", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gossip algorithms are widely used in modern distributed systems, with\napplications ranging from sensor networks and peer-to-peer networks to mobile\nvehicle networks and social networks. A tremendous research effort has been\ndevoted to analyzing and improving the asymptotic rate of convergence for\ngossip algorithms. In this work we study finite-time convergence of\ndeterministic gossiping. We show that there exists a symmetric gossip algorithm\nthat converges in finite time if and only if the number of network nodes is a\npower of two, while there always exists an asymmetric gossip algorithm with\nfinite-time convergence, independent of the number of nodes. For $n=2^m$ nodes,\nwe prove that a fastest convergence can be reached in $nm=n\\log_2 n$ node\nupdates via symmetric gossiping. On the other hand, under asymmetric gossip\namong $n=2^m+r$ nodes with $0\\leq r<2^m$, it takes at least $mn+2r$ node\nupdates for achieving finite-time convergence. It is also shown that the\nexistence of finite-time convergent gossiping often imposes strong structural\nrequirements on the underlying interaction graph. Finally, we apply our results\nto gossip algorithms in quantum networks, where the goal is to control the\nstate of a quantum system via pairwise interactions. We show that finite-time\nconvergence is never possible for such systems.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 17:07:34 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2012 16:14:31 GMT"}, {"version": "v3", "created": "Sat, 23 Nov 2013 04:06:21 GMT"}, {"version": "v4", "created": "Sun, 11 May 2014 04:57:18 GMT"}, {"version": "v5", "created": "Fri, 3 Apr 2015 06:17:09 GMT"}, {"version": "v6", "created": "Mon, 28 Sep 2015 07:20:26 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Shi", "Guodong", ""], ["Li", "Bo", ""], ["Johansson", "Mikael", ""], ["Johansson", "Karl Henrik", ""]]}, {"id": "1206.1113", "submitter": "Guanhong Pei", "authors": "Maleq Khan, V.S. Anil Kumar, Gopal Pandurangan, Guanhong Pei", "title": "A Fast Distributed Approximation Algorithm for Minimum Spanning Trees in\n  the SINR Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem in wireless networks is the \\emph{minimum spanning\ntree} (MST) problem: given a set $V$ of wireless nodes, compute a spanning tree\n$T$, so that the total cost of $T$ is minimized. In recent years, there has\nbeen a lot of interest in the physical interference model based on SINR\nconstraints. Distributed algorithms are especially challenging in the SINR\nmodel, because of the non-locality of the model.\n  In this paper, we develop a fast distributed approximation algorithm for MST\nconstruction in an SINR based distributed computing model. For an $n$-node\nnetwork, our algorithm's running time is $O(D\\log{n}+\\mu\\log{n})$ and produces\na spanning tree whose cost is within $O(\\log n)$ times the optimal (MST cost),\nwhere $D$ denotes the diameter of the disk graph obtained by using the maximum\npossible transmission range, and $\\mu=\\log{\\frac{d_{max}}{d_{min}}}$ denotes\nthe \"distance diversity\" w.r.t. the largest and smallest distances between two\nnodes. (When $\\frac{d_{max}}{d_{min}}$ is $n$-polynomial, $\\mu = O(\\log n)$.)\nOur algorithm's running time is essentially optimal (upto a logarithmic\nfactor), since computing {\\em any} spanning tree takes $\\Omega(D)$ time; thus\nour algorithm produces a low cost spanning tree in time only a logarithmic\nfactor more than the time to compute a spanning tree. The distributed\nscheduling complexity of the spanning tree resulted from our algorithm is\n$O(\\mu \\log n)$. Our algorithmic design techniques can be useful in designing\nefficient distributed algorithms for related \"global\" problems in wireless\nnetworks in the SINR model.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2012 03:08:41 GMT"}], "update_date": "2012-06-07", "authors_parsed": [["Khan", "Maleq", ""], ["Kumar", "V. S. Anil", ""], ["Pandurangan", "Gopal", ""], ["Pei", "Guanhong", ""]]}, {"id": "1206.1118", "submitter": "Han Qi", "authors": "Han Qi, Abdullah Gani", "title": "Research On Mobile Cloud Computing: Review, Trend, And Perspectives", "comments": "8 pages, 7 figures, The Second International Conference on Digital\n  Information and Communication Technology and its Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Mobile Cloud Computing (MCC) which combines mobile computing and cloud\ncomputing, has become one of the industry buzz words and a major discussion\nthread in the IT world since 2009. As MCC is still at the early stage of\ndevelopment, it is necessary to grasp a thorough understanding of the\ntechnology in order to point out the direction of future research. With the\nlatter aim, this paper presents a review on the background and principle of\nMCC, characteristics, recent research work, and future research trends. A brief\naccount on the background of MCC: from mobile computing to cloud computing is\npresented and then followed with a discussion on characteristics and recent\nresearch work. It then analyses the features and infrastructure of mobile cloud\ncomputing. The rest of the paper analyses the challenges of mobile cloud\ncomputing, summary of some research projects related to this area, and points\nout promising future research directions.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2012 03:53:39 GMT"}], "update_date": "2012-06-07", "authors_parsed": [["Qi", "Han", ""], ["Gani", "Abdullah", ""]]}, {"id": "1206.1187", "submitter": "Gleb Beliakov", "authors": "Gleb Beliakov, Michael Johnstone, Doug Creighton, Tim Wilkin", "title": "Parallel random variates generator for GPUs based on normal numbers", "comments": "preprint, 18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.NA math.NA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pseudorandom number generators are required for many computational tasks,\nsuch as stochastic modelling and simulation. This paper investigates the serial\nCPU and parallel GPU implementation of a Linear Congruential Generator based on\nthe binary representation of the normal number $\\alpha_{2,3}$. We adapted two\nmethods of modular reduction which allowed us to perform most operations in\n64-bit integer arithmetic, improving on the original implementation based on\n106-bit double-double operations. We found that our implementation is faster\nthan existing methods in literature, and our generation rate is close to the\nlimiting rate imposed by the efficiency of writing to a GPU's global memory.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2012 11:30:42 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2012 04:42:05 GMT"}], "update_date": "2012-06-25", "authors_parsed": [["Beliakov", "Gleb", ""], ["Johnstone", "Michael", ""], ["Creighton", "Doug", ""], ["Wilkin", "Tim", ""]]}, {"id": "1206.1264", "submitter": "Siva Theja Maguluri", "authors": "Siva Theja Maguluri, R Srikant, Lei Ying", "title": "Heavy Traffic Optimal Resource Allocation Algorithms for Cloud Computing\n  Clusters", "comments": "Technical Report corresponding to the paper of same title to be\n  presented at International Teletraffic Conference 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is emerging as an important platform for business, personal\nand mobile computing applications. In this paper, we study a stochastic model\nof cloud computing, where jobs arrive according to a stochastic process and\nrequest resources like CPU, memory and storage space. We consider a model where\nthe resource allocation problem can be separated into a routing or load\nbalancing problem and a scheduling problem. We study the\njoin-the-shortest-queue routing and power-of-two-choices routing algorithms\nwith MaxWeight scheduling algorithm. It was known that these algorithms are\nthroughput optimal. In this paper, we show that these algorithms are queue\nlength optimal in the heavy traffic limit.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2012 16:07:58 GMT"}], "update_date": "2012-06-07", "authors_parsed": [["Maguluri", "Siva Theja", ""], ["Srikant", "R", ""], ["Ying", "Lei", ""]]}, {"id": "1206.1290", "submitter": "Othon Michail", "authors": "Othon Michail, Ioannis Chatzigiannakis, Paul G. Spirakis", "title": "Causality, Influence, and Computation in Possibly Disconnected Dynamic\n  Networks", "comments": "14 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the propagation of influence and computation in\ndynamic distributed systems. We focus on broadcasting models under a worst-case\ndynamicity assumption which have received much attention recently. We drop for\nthe first time in worst-case dynamic networks the common instantaneous\nconnectivity assumption and require a minimal temporal connectivity. Our\ntemporal connectivity constraint only requires that another causal influence\noccurs within every time-window of some given length. We establish that there\nare dynamic graphs with always disconnected instances with equivalent temporal\nconnectivity to those with always connected instances. We present a termination\ncriterion and also establish the computational equivalence with instantaneous\nconnectivity networks. We then consider another model of dynamic networks in\nwhich each node has an underlying communication neighborhood and the\nrequirement is that each node covers its local neighborhood within any\ntime-window of some given length. We discuss several properties and provide a\nprotocol for counting, that is for determining the number of nodes in the\nnetwork.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2012 18:10:34 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Michail", "Othon", ""], ["Chatzigiannakis", "Ioannis", ""], ["Spirakis", "Paul G.", ""]]}, {"id": "1206.1390", "submitter": "Mark Hoemmen", "authors": "Patrick G. Bridges, Kurt B. Ferreira, Michael A. Heroux, Mark Hoemmen", "title": "Fault-tolerant linear solvers via selective reliability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy increasingly constrains modern computer hardware, yet protecting\ncomputations and data against errors costs energy. This holds at all scales,\nbut especially for the largest parallel computers being built and planned\ntoday. As processor counts continue to grow, the cost of ensuring reliability\nconsistently throughout an application will become unbearable. However, many\nalgorithms only need reliability for certain data and phases of computation.\nThis suggests an algorithm and system codesign approach. We show that if the\nsystem lets applications apply reliability selectively, we can develop\nalgorithms that compute the right answer despite faults. These \"fault-tolerant\"\niterative methods either converge eventually, at a rate that degrades\ngracefully with increased fault rate, or return a clear failure indication in\nthe rare case that they cannot converge. Furthermore, they store most of their\ndata unreliably, and spend most of their time in unreliable mode.\n  We demonstrate this for the specific case of detected but uncorrectable\nmemory faults, which we argue are representative of all kinds of faults. We\ndeveloped a cross-layer application / operating system framework that\nintercepts and reports uncorrectable memory faults to the application, rather\nthan killing the application, as current operating systems do. The application\nin turn can mark memory allocations as subject to such faults. Using this\nframework, we wrote a fault-tolerant iterative linear solver using components\nfrom the Trilinos solvers library. Our solver exploits hybrid parallelism (MPI\nand threads). It performs just as well as other solvers if no faults occur, and\nconverges where other solvers do not in the presence of faults. We show\nconvergence results for representative test problems. Near-term future work\nwill include performance tests.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 03:18:42 GMT"}], "update_date": "2012-06-08", "authors_parsed": [["Bridges", "Patrick G.", ""], ["Ferreira", "Kurt B.", ""], ["Heroux", "Michael A.", ""], ["Hoemmen", "Mark", ""]]}, {"id": "1206.1430", "submitter": "Yogita Khatri", "authors": "Yogita Khatri", "title": "Distance Based Asynchronous Recovery Approach in Mobile Computing\n  Environment", "comments": "7 pages, 1figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mobile computing system is a distributed system in which at least one of\nthe processes is mobile. They are constrained by lack of stable storage, low\nnetwork bandwidth, mobility, frequent disconnection and limited battery life.\nCheckpointing is one of the commonly used techniques to provide fault tolerance\nin mobile computing environment. In order to suit the mobile environment a\ndistance based recovery scheme is proposed which is based on checkpointing and\nmessage logging. After the system recovers from failures, only the failed\nprocesses rollback and restart from their respective recent checkpoints,\nindependent of the others. The salient feature of this scheme is to reduce the\ntransfer and recovery cost. While the mobile host moves with in a specific\nrange, recovery information is not moved and thus only be transferred nearby if\nthe mobile host moves out of certain range.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 09:44:13 GMT"}], "update_date": "2012-06-08", "authors_parsed": [["Khatri", "Yogita", ""]]}, {"id": "1206.1522", "submitter": "Peter Robinson", "authors": "Gopal Pandurangan, Peter Robinson, Amitabh Trehan", "title": "DEX: Self-healing Expanders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a fully-distributed self-healing algorithm DEX, that maintains a\nconstant degree expander network in a dynamic setting. To the best of our\nknowledge, our algorithm provides the first efficient distributed construction\nof expanders --- whose expansion properties hold {\\em deterministically} ---\nthat works even under an all-powerful adaptive adversary that controls the\ndynamic changes to the network (the adversary has unlimited computational power\nand knowledge of the entire network state, can decide which nodes join and\nleave and at what time, and knows the past random choices made by the\nalgorithm). Previous distributed expander constructions typically provide only\n{\\em probabilistic} guarantees on the network expansion which {\\em rapidly\ndegrade} in a dynamic setting; in particular, the expansion properties can\ndegrade even more rapidly under {\\em adversarial} insertions and deletions.\n  Our algorithm provides efficient maintenance and incurs a low overhead per\ninsertion/deletion by an adaptive adversary: only $O(\\log n)$ rounds and\n$O(\\log n)$ messages are needed with high probability ($n$ is the number of\nnodes currently in the network). The algorithm requires only a constant number\nof topology changes. Moreover, our algorithm allows for an efficient\nimplementation and maintenance of a distributed hash table (DHT) on top of DEX,\nwith only a constant additional overhead.\n  Our results are a step towards implementing efficient self-healing networks\nthat have \\emph{guaranteed} properties (constant bounded degree and expansion)\ndespite dynamic changes.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 15:24:32 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2012 09:27:50 GMT"}, {"version": "v3", "created": "Mon, 12 Aug 2013 17:34:31 GMT"}, {"version": "v4", "created": "Mon, 21 Oct 2013 11:10:13 GMT"}], "update_date": "2013-10-22", "authors_parsed": [["Pandurangan", "Gopal", ""], ["Robinson", "Peter", ""], ["Trehan", "Amitabh", ""]]}, {"id": "1206.1653", "submitter": "Stefano Braghin", "authors": "Stefano Braghin, Jackson Tan, Rajesh Sharma and Anwitaman Datta", "title": "PriSM: A Private Social Mesh for Leveraging Social Networking at\n  Workplace", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we describe the PriSM framework for decentralized deployment of\na federation of autonomous social networks (ASN). The individual ASNs are\ncentrally managed by organizations according to their institutional needs,\nwhile cross-ASN interactions are facilitated subject to security and\nconfidentiality requirements specified by administrators and users of the ASNs.\nSuch decentralized deployment, possibly either on private or public clouds,\nprovides control and ownership of information/flow to individual organizations.\nLack of such complete control (if third party online social networking services\nwere to be used) has so far been a great barrier in taking full advantage of\nthe novel communication mechanisms at workplace that have however become\ncommonplace for personal usage with the advent of Web 2.0 platforms and online\nsocial networks. PriSM provides a practical solution for organizations to\nharness the advantages of online social networking both in\nintra/inter-organizational settings without sacrificing autonomy, security and\nconfidentiality needs.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 02:44:05 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2013 16:02:19 GMT"}], "update_date": "2013-06-06", "authors_parsed": [["Braghin", "Stefano", ""], ["Tan", "Jackson", ""], ["Sharma", "Rajesh", ""], ["Datta", "Anwitaman", ""]]}, {"id": "1206.1899", "submitter": "Rajeev  Shakya PhD Scholar", "authors": "Rajeev K. Shakya", "title": "TTMA: Traffic-adaptive Time-division Multiple Access Protocol Wireless\n  Sensor Networks", "comments": "This paper has been withdrawn by arXiv. arXiv admin note: author list\n  truncated due to disputed authorship and content. This submission repeats\n  large portions of text from\n  http://www.cse.msu.edu/~lxiao/publications/TATD_MAC.pdf by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper has been withdrawn by arXiv. arXiv admin note: author list\ntruncated due to disputed authorship and content. This submission repeats large\nportions of text from this http URL by other authors. Duty cycle mode in WSN\nimproves energy-efficiency, but also introduces packet delivery latency.\nSeveral duty-cycle based MAC schemes have been proposed to reduce latency, but\nthroughput is limited by duty-cycled scheduling performance. In this paper, a\nTraffic-adaptive Time-division Multiple Access (TTMA), a distributed TDMA-based\nMAC protocol is introduced to improves the throughput by traffic-adaptive\ntime-slot scheduling that increases the channel utilisation efficiency. The\nproposed time-slot scheduling method first avoids time-slots assigned to nodes\nwith no traffic through fast traffic notification. It then achieves better\nchannel utilisation among nodes having traffic through an ordered schedule\nnegotiation scheme. By decomposing traffic notification and data transmission\nscheduling into two phases leads each phase to be simple and efficient. The\nperformance evaluation shows that the two-phase design significantly improves\nthe throughput and outperforms the time division multiple access (TDMA) control\nwith slot stealing.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jun 2012 02:06:59 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2012 02:04:02 GMT"}, {"version": "v3", "created": "Thu, 9 Aug 2012 06:46:12 GMT"}], "update_date": "2013-04-30", "authors_parsed": [["Shakya", "Rajeev K.", ""]]}, {"id": "1206.1943", "submitter": "Rajiv Ranjan Dr.", "authors": "Dimitrios Georgakopoulos, Rajiv Ranjan, Karan Mitra, Xiangmin Zhou", "title": "MediaWise - Designing a Smart Media Cloud", "comments": "This paper appears as the invited keynote paper in the proceedings of\n  the International Conference on Advances in Cloud Computing (ACC-2012), July\n  26-28, 2012, Bangalore, India", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MM cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The MediaWise project aims to expand the scope of existing media delivery\nsystems with novel cloud, personalization and collaboration capabilities that\ncan serve the needs of more users, communities, and businesses. The project\ndevelops a MediaWise Cloud platform that supports do-it-yourself creation,\nsearch, management, and consumption of multimedia content. The MediaWise Cloud\nsupports pay-as-you-go models and elasticity that are similar to those offered\nby commercially available cloud services. However, unlike existing commercial\nCDN services providers such as Limelight Networks and Akamai the MediaWise\nCloud require no ownerships of computing infrastructure and instead rely on the\npublic Internet and public cloud services (e.g., commercial cloud storage to\nstore its content). In addition to integrating such public cloud services into\na public cloud-based Content Delivery Network, the MediaWise Cloud also\nprovides advanced Quality of Service (QoS) management as required for the\ndelivery of streamed and interactive high resolution multimedia content. In\nthis paper, we give a brief overview of MediaWise Cloud architecture and\npresent a comprehensive discussion on research objectives related to its\nservice components. Finally, we also compare the features supported by the\nexisting CDN services against the envisioned objectives of MediaWise Cloud.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jun 2012 14:07:47 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2012 03:12:37 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Georgakopoulos", "Dimitrios", ""], ["Ranjan", "Rajiv", ""], ["Mitra", "Karan", ""], ["Zhou", "Xiangmin", ""]]}, {"id": "1206.1984", "submitter": "Nasrin Jaberi", "authors": "Masnida Emami, Yashar Ghiasi, Nasrin Jaberi", "title": "Energy-Aware Scheduling using Dynamic Voltage-Frequency Scaling", "comments": "arXiv admin note: text overlap with arXiv:1203.5160", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The energy consumption issue in distributed computing systems has become\nquite critical due to environmental concerns. In response to this, many\nenergy-aware scheduling algorithms have been developed primarily by using the\ndynamic voltage-frequency scaling (DVFS) capability incorporated in recent\ncommodity processors. The majority of these algorithms involve two passes:\nschedule generation and slack reclamation. The latter is typically achieved by\nlowering processor frequency for tasks with slacks. In this article, we study\nthe latest papers in this area and develop them. This study has been evaluated\nbased on results obtained from experiments with 1,500 randomly generated task\ngraphs.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2012 00:13:47 GMT"}], "update_date": "2012-06-12", "authors_parsed": [["Emami", "Masnida", ""], ["Ghiasi", "Yashar", ""], ["Jaberi", "Nasrin", ""]]}, {"id": "1206.2016", "submitter": "Nikzad Babaii-Rizvandi", "authors": "Nikzad Babaii Rizvandi, Javid Taheri, Reza Moraveji, Albert Y. Zomaya", "title": "Network Load Analysis and Provisioning of MapReduce Applications", "comments": "6 pages-submitted to The Thirteenth International Conference on\n  Parallel and Distributed Computing, Applications and Technologies(PDCAT-12),\n  Beijing, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the dependency between configuration parameters and\nnetwork load of fixed-size MapReduce applications in shuffle phase and then\npropose an analytical method to model this dependency. Our approach consists of\nthree key phases: profiling, modeling, and prediction. In the first stage, an\napplication is run several times with different sets of MapReduce configuration\nparameters (here number of mappers and number of reducers) to profile the\nnetwork load of the application in the shuffle phase on a given cluster. Then,\nthe relation between these parameters and the network load is modeled by\nmultivariate linear regression. For evaluation, three applications (WordCount,\nExim Mainlog parsing, and TeraSort) are utilized to evaluate our technique on a\n4-node MapReduce private cluster.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2012 10:39:04 GMT"}, {"version": "v2", "created": "Fri, 27 Jul 2012 02:07:41 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Rizvandi", "Nikzad Babaii", ""], ["Taheri", "Javid", ""], ["Moraveji", "Reza", ""], ["Zomaya", "Albert Y.", ""]]}, {"id": "1206.2038", "submitter": "Tien Tuan Anh Dinh", "authors": "Dinh Tien Tuan Anh, Quach Vinh Thanh, Anwitaman Datta", "title": "CloudMine: Multi-Party Privacy-Preserving Data Analytics Service", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of businesses are replacing their data storage and\ncomputation infrastructure with cloud services. Likewise, there is an increased\nemphasis on performing analytics based on multiple datasets obtained from\ndifferent data sources. While ensuring security of data and computation\noutsourced to a third party cloud is in itself challenging, supporting\nanalytics using data distributed across multiple, independent clouds is even\nfurther from trivial. In this paper we present CloudMine, a cloud-based service\nwhich allows multiple data owners to perform privacy-preserved computation over\nthe joint data using their clouds as delegates. CloudMine protects data privacy\nwith respect to semi-honest data owners and semi-honest clouds. It furthermore\nensures the privacy of the computation outputs from the curious clouds. It\nallows data owners to reliably detect if their cloud delegates have been lazy\nwhen carrying out the delegated computation. CloudMine can run as a centralized\nservice on a single cloud, or as a distributed service over multiple,\nindependent clouds. CloudMine supports a set of basic computations that can be\nused to construct a variety of highly complex, distributed privacy-preserving\ndata analytics. We demonstrate how a simple instance of CloudMine (secure sum\nservice) is used to implement three classical data mining tasks\n(classification, association rule mining and clustering) in a cloud\nenvironment. We experiment with a prototype of the service, the results of\nwhich suggest its practicality for supporting privacy-preserving data analytics\nas a (multi) cloud-based service.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2012 16:27:48 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2013 05:14:19 GMT"}], "update_date": "2013-10-02", "authors_parsed": [["Anh", "Dinh Tien Tuan", ""], ["Thanh", "Quach Vinh", ""], ["Datta", "Anwitaman", ""]]}, {"id": "1206.2082", "submitter": "Reza Bosagh Zadeh", "authors": "Reza Bosagh Zadeh, Ashish Goel", "title": "Dimension Independent Similarity Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a suite of algorithms for Dimension Independent Similarity\nComputation (DISCO) to compute all pairwise similarities between very high\ndimensional sparse vectors. All of our results are provably independent of\ndimension, meaning apart from the initial cost of trivially reading in the\ndata, all subsequent operations are independent of the dimension, thus the\ndimension can be very large. We study Cosine, Dice, Overlap, and the Jaccard\nsimilarity measures. For Jaccard similiarity we include an improved version of\nMinHash. Our results are geared toward the MapReduce framework. We empirically\nvalidate our theorems at large scale using data from the social networking site\nTwitter. At time of writing, our algorithms are live in production at\ntwitter.com.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2012 02:19:27 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2012 04:40:52 GMT"}, {"version": "v3", "created": "Tue, 2 Apr 2013 03:54:28 GMT"}, {"version": "v4", "created": "Thu, 23 May 2013 07:56:18 GMT"}], "update_date": "2013-05-24", "authors_parsed": [["Zadeh", "Reza Bosagh", ""], ["Goel", "Ashish", ""]]}, {"id": "1206.2187", "submitter": "Lluis Pamies-Juarez", "authors": "Lluis Pamies-Juarez, Fr\\'ed\\'erique Oggier, Anwitaman Datta", "title": "An Empirical Study of the Repair Performance of Novel Coding Schemes for\n  Networked Distributed Storage Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Erasure coding techniques are getting integrated in networked distributed\nstorage systems as a way to provide fault-tolerance at the cost of less storage\noverhead than traditional replication. Redundancy is maintained over time\nthrough repair mechanisms, which may entail large network resource overheads.\nIn recent years, several novel codes tailor-made for distributed storage have\nbeen proposed to optimize storage overhead and repair, such as Regenerating\nCodes that minimize the per repair traffic, or Self-Repairing Codes which\nminimize the number of nodes contacted per repair. Existing studies of these\ncoding techniques are however predominantly theoretical, under the simplifying\nassumption that only one object is stored. They ignore many practical issues\nthat real systems must address, such as data placement, de/correlation of\nmultiple stored objects, or the competition for limited network resources when\nmultiple objects are repaired simultaneously. This paper empirically studies\nthe repair performance of these novel storage centric codes with respect to\nclassical erasure codes by simulating realistic scenarios and exploring the\ninterplay of code parameters, failure characteristics and data placement with\nrespect to the trade-offs of bandwidth usage and speed of repairs.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2012 12:55:53 GMT"}], "update_date": "2012-06-12", "authors_parsed": [["Pamies-Juarez", "Lluis", ""], ["Oggier", "Fr\u00e9d\u00e9rique", ""], ["Datta", "Anwitaman", ""]]}, {"id": "1206.2772", "submitter": "Gabriele D'Angelo", "authors": "Gabriele D'Angelo, Stefano Ferretti, Moreno Marzolla", "title": "Time Warp on the Go (Updated Version)", "comments": "Proceedings of 3nd ICST/CREATE-NET Workshop on DIstributed SImulation\n  and Online gaming (DISIO 2012). In conjunction with SIMUTools 2012.\n  Desenzano, Italy, March 2012. ISBN: 978-1-936968-47-3", "journal-ref": null, "doi": "10.4108/icst.simutools.2012.247736", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we deal with the impact of multi and many-core processor\narchitectures on simulation. Despite the fact that modern CPUs have an\nincreasingly large number of cores, most softwares are still unable to take\nadvantage of them. In the last years, many tools, programming languages and\ngeneral methodologies have been proposed to help building scalable applications\nfor multi-core architectures, but those solutions are somewhat limited.\nParallel and distributed simulation is an interesting application area in which\nefficient and scalable multi-core implementations would be desirable. In this\npaper we investigate the use of the Go Programming Language to implement\noptimistic parallel simulations based on the Time Warp mechanism. Specifically,\nwe describe the design, implementation and evaluation of a new parallel\nsimulator. The scalability of the simulator is studied when in presence of a\nmodern multi-core CPU and the effects of the Hyper-Threading technology on\noptimistic simulation are analyzed.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 11:48:48 GMT"}, {"version": "v2", "created": "Thu, 27 Dec 2012 07:07:19 GMT"}, {"version": "v3", "created": "Tue, 29 Jul 2014 10:02:52 GMT"}], "update_date": "2014-07-30", "authors_parsed": [["D'Angelo", "Gabriele", ""], ["Ferretti", "Stefano", ""], ["Marzolla", "Moreno", ""]]}, {"id": "1206.2775", "submitter": "Gabriele D'Angelo", "authors": "Luca Toscano, Gabriele D'Angelo, Moreno Marzolla", "title": "Parallel Discrete Event Simulation with Erlang", "comments": "Proceedings of ACM SIGPLAN Workshop on Functional High-Performance\n  Computing (FHPC 2012) in conjunction with ICFP 2012. ISBN: 978-1-4503-1577-7", "journal-ref": null, "doi": "10.1145/2364474.2364487", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete Event Simulation (DES) is a widely used technique in which the state\nof the simulator is updated by events happening at discrete points in time\n(hence the name). DES is used to model and analyze many kinds of systems,\nincluding computer architectures, communication networks, street traffic, and\nothers. Parallel and Distributed Simulation (PADS) aims at improving the\nefficiency of DES by partitioning the simulation model across multiple\nprocessing elements, in order to enabling larger and/or more detailed studies\nto be carried out. The interest on PADS is increasing since the widespread\navailability of multicore processors and affordable high performance computing\nclusters. However, designing parallel simulation models requires considerable\nexpertise, the result being that PADS techniques are not as widespread as they\ncould be. In this paper we describe ErlangTW, a parallel simulation middleware\nbased on the Time Warp synchronization protocol. ErlangTW is entirely written\nin Erlang, a concurrent, functional programming language specifically targeted\nat building distributed systems. We argue that writing parallel simulation\nmodels in Erlang is considerably easier than using conventional programming\nlanguages. Moreover, ErlangTW allows simulation models to be executed either on\nsingle-core, multicore and distributed computing architectures. We describe the\ndesign and prototype implementation of ErlangTW, and report some preliminary\nperformance results on multicore and distributed architectures using the well\nknown PHOLD benchmark.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 12:12:21 GMT"}, {"version": "v2", "created": "Thu, 27 Dec 2012 07:30:40 GMT"}, {"version": "v3", "created": "Thu, 24 Jul 2014 08:38:15 GMT"}], "update_date": "2014-07-25", "authors_parsed": [["Toscano", "Luca", ""], ["D'Angelo", "Gabriele", ""], ["Marzolla", "Moreno", ""]]}, {"id": "1206.3099", "submitter": "Paolo Di Lorenzo", "authors": "Paolo Di Lorenzo and Ali H. Sayed", "title": "Sparse Distributed Learning Based on Diffusion Adaptation", "comments": "to appear in IEEE Trans. on Signal Processing, 2013", "journal-ref": "IEEE Transactions on Signal Processing, Vol. 61, no. 6 , 15 March\n  2013", "doi": "10.1109/TSP.2012.2232663", "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes diffusion LMS strategies for distributed estimation\nover adaptive networks that are able to exploit sparsity in the underlying\nsystem model. The approach relies on convex regularization, common in\ncompressive sensing, to enhance the detection of sparsity via a diffusive\nprocess over the network. The resulting algorithms endow networks with learning\nabilities and allow them to learn the sparse structure from the incoming data\nin real-time, and also to track variations in the sparsity of the model. We\nprovide convergence and mean-square performance analysis of the proposed method\nand show under what conditions it outperforms the unregularized diffusion\nversion. We also show how to adaptively select the regularization parameter.\nSimulation results illustrate the advantage of the proposed filters for sparse\ndata recovery.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2012 13:10:35 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2012 23:33:32 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Di Lorenzo", "Paolo", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1206.3634", "submitter": "Ankur Sahai", "authors": "Ankur Sahai", "title": "Balls into Bins: strict Capacities and Edge Weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore a novel theoretical model for studying the performance of\ndistributed storage management systems where the data-centers have limited\ncapacities (as compared to storage space requested by the users). Prior schemes\nsuch as Balls-into-bins (used for load balancing) neither consider bin\n(consumer) capacities (multiple balls into a bin) nor the future performance of\nthe system after, balls (producer requests) are allocated to bins and restrict\nnumber of balls as a function of the number of bins. Our problem consists of\nfinding an optimal assignment of the online producer requests to consumers (via\nweighted edges) in a complete bipartite graph while ensuring that the total\nsize of request assigned on a consumer is limited by its capacity. The metric\nused to measure the performance in this model is the (minimization of) weighted\nsum of the requests assigned on the edges (loads) and their corresponding\nweights. We first explore the optimal offline algorithms followed by\ncompetitive analysis of different online techniques. Using oblivious adversary.\nLP and Primal-Dual algorithms are used for calculating the optimal offline\nsolution in O(r*n) time (where r and n are the number of requests and consumers\nrespectively) while randomized algorithms are used for the online case.\n  For the simplified model with equal consumer capacities an average-case\ncompetitive ratio of AVG(d) / MIN(d) (where d is the edge weight / distance) is\nachieved using an algorithm that has equal probability for selecting any of the\navailable edges with a running time of $O(r)$. In the extending the model to\narbitrary consumer capacities we show an average case competitive ratio of\nAVG(d*c) / (AVG(c) *MIN(d)).\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2012 07:33:30 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Sahai", "Ankur", ""]]}, {"id": "1206.3728", "submitter": "Xiaochuan Zhao", "authors": "Xiaochuan Zhao and Ali H. Sayed", "title": "Performance Limits for Distributed Estimation Over LMS Adaptive Networks", "comments": "39 pages, 7 figures, to appear in IEEE Transactions on Signal\n  Processing, 2012", "journal-ref": null, "doi": "10.1109/TSP.2012.2204985", "report-no": null, "categories": "cs.IT cs.DC cs.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we analyze the mean-square performance of different strategies\nfor distributed estimation over least-mean-squares (LMS) adaptive networks. The\nresults highlight some useful properties for distributed adaptation in\ncomparison to fusion-based centralized solutions. The analysis establishes\nthat, by optimizing over the combination weights, diffusion strategies can\ndeliver lower excess-mean-square-error than centralized solutions employing\ntraditional block or incremental LMS strategies. We first study in some detail\nthe situation involving combinations of two adaptive agents and then extend the\nresults to generic N-node ad-hoc networks. In the later case, we establish\nthat, for sufficiently small step-sizes, diffusion strategies can outperform\ncentralized block or incremental LMS strategies by optimizing over\nleft-stochastic combination weighting matrices. The results suggest more\nefficient ways for organizing and processing data at fusion centers, and\npresent useful adaptive strategies that are able to enhance performance when\nimplemented in a distributed manner.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2012 06:24:08 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Zhao", "Xiaochuan", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1206.3738", "submitter": "Georg Hager", "authors": "Jan Treibig, Georg Hager, Gerhard Wellein", "title": "Best practices for HPM-assisted performance engineering on modern\n  multicore processors", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": "10.1007/978-3-642-36949-0_50", "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many tools and libraries employ hardware performance monitoring (HPM) on\nmodern processors, and using this data for performance assessment and as a\nstarting point for code optimizations is very popular. However, such data is\nonly useful if it is interpreted with care, and if the right metrics are chosen\nfor the right purpose. We demonstrate the sensible use of hardware performance\ncounters in the context of a structured performance engineering approach for\napplications in computational science. Typical performance patterns and their\nrespective metric signatures are defined, and some of them are illustrated\nusing case studies. Although these generic concepts do not depend on specific\ntools or environments, we restrict ourselves to modern x86-based multicore\nprocessors and use the likwid-perfctr tool under the Linux OS.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2012 09:53:53 GMT"}], "update_date": "2013-02-20", "authors_parsed": [["Treibig", "Jan", ""], ["Hager", "Georg", ""], ["Wellein", "Gerhard", ""]]}, {"id": "1206.3804", "submitter": "Dimitris S. Papailiopoulos", "authors": "Dimitris S. Papailiopoulos and Alexandros G. Dimakis", "title": "Locally Repairable Codes", "comments": "presented at ISIT 2012, accepted for publication in IEEE Trans. IT,\n  2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed storage systems for large-scale applications typically use\nreplication for reliability. Recently, erasure codes were used to reduce the\nlarge storage overhead, while increasing data reliability. A main limitation of\noff-the-shelf erasure codes is their high-repair cost during single node\nfailure events. A major open problem in this area has been the design of codes\nthat {\\it i)} are repair efficient and {\\it ii)} achieve arbitrarily high data\nrates.\n  In this paper, we explore the repair metric of {\\it locality}, which\ncorresponds to the number of disk accesses required during a\n{\\color{black}single} node repair. Under this metric we characterize an\ninformation theoretic trade-off that binds together locality, code distance,\nand the storage capacity of each node. We show the existence of optimal {\\it\nlocally repairable codes} (LRCs) that achieve this trade-off. The achievability\nproof uses a locality aware flow-graph gadget which leads to a randomized code\nconstruction. Finally, we present an optimal and explicit LRC that achieves\narbitrarily high data-rates. Our locality optimal construction is based on\nsimple combinations of Reed-Solomon blocks.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2012 22:47:08 GMT"}, {"version": "v2", "created": "Sat, 3 May 2014 16:22:02 GMT"}], "update_date": "2014-05-06", "authors_parsed": [["Papailiopoulos", "Dimitris S.", ""], ["Dimakis", "Alexandros G.", ""]]}, {"id": "1206.4123", "submitter": "Mingqiang  Li", "authors": "Mingqiang Li", "title": "On the Confidentiality of Information Dispersal Algorithms and Their\n  Erasure Codes", "comments": "This version includes a correction on the example in Section IV", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \\emph{Information Dispersal Algorithms (IDAs)} have been widely applied to\nreliable and secure storage and transmission of data files in distributed\nsystems. An IDA is a method that encodes a file $F$ of size $L=|F|$ into $n$\nunrecognizable pieces $F_1$, $F_2$, ..., $F_n$, each of size $L/m$ ($m<n$), so\nthat the original file $F$ can be reconstructed from any $m$ pieces. The core\nof an IDA is the adopted non-systematic $m$-of-$n$ erasure code. This paper\nmakes a systematic study on the \\emph{confidentiality} of an IDA and its\nconnection with the adopted erasure code. Two levels of confidentiality are\ndefined: \\emph{weak confidentiality} (in the case where some parts of the\noriginal file $F$ can be reconstructed explicitly from fewer than $m$ pieces)\nand \\emph{strong confidentiality} (in the case where nothing of the original\nfile $F$ can be reconstructed explicitly from fewer than $m$ pieces). For an\nIDA that adopts an arbitrary non-systematic erasure code, its confidentiality\nmay fall into weak confidentiality. To achieve strong confidentiality, this\npaper explores a sufficient and feasible condition on the adopted erasure code.\nThen, this paper shows that Rabin's IDA has strong confidentiality. At the same\ntime, this paper presents an effective way to construct an IDA with strong\nconfidentiality from an arbitrary $m$-of-$(m+n)$ erasure code. Then, as an\nexample, this paper constructs an IDA with strong confidentiality from a\nReed-Solomon code, the computation complexity of which is comparable to or\nsometimes even lower than that of Rabin's IDA.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2012 05:01:37 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2013 03:54:30 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Li", "Mingqiang", ""]]}, {"id": "1206.4175", "submitter": "Erwan Le Merrer", "authors": "Anne-Marie Kermarrec and Erwan Le Merrer and Gilles Straub and\n  Alexandre van Kempen", "title": "Clustered Network Coding for Maintenance in Practical Storage Systems", "comments": "14 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical erasure codes, e.g. Reed-Solomon codes, have been acknowledged as\nan efficient alternative to plain replication to reduce the storage overhead in\nreliable distributed storage systems. Yet, such codes experience high overhead\nduring the maintenance process. In this paper we propose a novel erasure-coded\nframework especially tailored for networked storage systems. Our approach\nrelies on the use of random codes coupled with a clustered placement strategy,\nenabling the maintenance of a failed machine at the granularity of multiple\nfiles. Our repair protocol leverages network coding techniques to reduce by\nhalf the amount of data transferred during maintenance, as several files can be\nrepaired simultaneously. This approach, as formally proven and demonstrated by\nour evaluation on a public experimental testbed, enables to dramatically\ndecrease the bandwidth overhead during the maintenance process, as well as the\ntime to repair a failure. In addition, the implementation is made as simple as\npossible, aiming at a deployment into practical systems.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2012 11:01:42 GMT"}], "update_date": "2012-06-20", "authors_parsed": [["Kermarrec", "Anne-Marie", ""], ["Merrer", "Erwan Le", ""], ["Straub", "Gilles", ""], ["van Kempen", "Alexandre", ""]]}, {"id": "1206.4221", "submitter": "Nikolas Kantas", "authors": "Nikolas Kantas, Sumeetpal S. Singh and Arnaud Doucet", "title": "Distributed Maximum Likelihood for Simultaneous Self-localization and\n  Tracking in Sensor Networks", "comments": "shorter version is about to appear in IEEE Transactions of Signal\n  Processing; 22 pages, 15 figures", "journal-ref": null, "doi": "10.1109/TSP.2012.2205923", "report-no": null, "categories": "math.OC cs.DC cs.SY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the sensor self-localization problem can be cast as a static\nparameter estimation problem for Hidden Markov Models and we implement fully\ndecentralized versions of the Recursive Maximum Likelihood and on-line\nExpectation-Maximization algorithms to localize the sensor network\nsimultaneously with target tracking. For linear Gaussian models, our algorithms\ncan be implemented exactly using a distributed version of the Kalman filter and\na novel message passing algorithm. The latter allows each node to compute the\nlocal derivatives of the likelihood or the sufficient statistics needed for\nExpectation-Maximization. In the non-linear case, a solution based on local\nlinearization in the spirit of the Extended Kalman Filter is proposed. In\nnumerical examples we demonstrate that the developed algorithms are able to\nlearn the localization parameters.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2012 14:28:50 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Kantas", "Nikolas", ""], ["Singh", "Sumeetpal S.", ""], ["Doucet", "Arnaud", ""]]}, {"id": "1206.4377", "submitter": "Anish Das Sarma", "authors": "Foto N. Afrati, Anish Das Sarma, Semih Salihoglu, Jeffrey D. Ullman", "title": "Upper and Lower Bounds on the Cost of a Map-Reduce Computation", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the tradeoff between parallelism and communication\ncost in a map-reduce computation. For any problem that is not \"embarrassingly\nparallel,\" the finer we partition the work of the reducers so that more\nparallelism can be extracted, the greater will be the total communication\nbetween mappers and reducers. We introduce a model of problems that can be\nsolved in a single round of map-reduce computation. This model enables a\ngeneric recipe for discovering lower bounds on communication cost as a function\nof the maximum number of inputs that can be assigned to one reducer. We use the\nmodel to analyze the tradeoff for three problems: finding pairs of strings at\nHamming distance $d$, finding triangles and other patterns in a larger graph,\nand matrix multiplication. For finding strings of Hamming distance 1, we have\nupper and lower bounds that match exactly. For triangles and many other graphs,\nwe have upper and lower bounds that are the same to within a constant factor.\nFor the problem of matrix multiplication, we have matching upper and lower\nbounds for one-round map-reduce algorithms. We are also able to explore\ntwo-round map-reduce algorithms for matrix multiplication and show that these\nnever have more communication, for a given reducer size, than the best\none-round algorithm, and often have significantly less.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 02:46:27 GMT"}], "update_date": "2012-06-21", "authors_parsed": [["Afrati", "Foto N.", ""], ["Sarma", "Anish Das", ""], ["Salihoglu", "Semih", ""], ["Ullman", "Jeffrey D.", ""]]}, {"id": "1206.4675", "submitter": "Peter Haider", "authors": "Peter Haider (University of Potsdam), Tobias Scheffer (University of\n  Potsdam)", "title": "Finding Botnets Using Minimal Graph Clusterings", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of identifying botnets and the IP addresses which they\ncomprise, based on the observation of a fraction of the global email spam\ntraffic. Observed mailing campaigns constitute evidence for joint botnet\nmembership, they are represented by cliques in the graph of all messages. No\nevidence against an association of nodes is ever available. We reduce the\nproblem of identifying botnets to a problem of finding a minimal clustering of\nthe graph of messages. We directly model the distribution of clusterings given\nthe input graph; this avoids potential errors caused by distributional\nassumptions of a generative model. We report on a case study in which we\nevaluate the model by its ability to predict the spam campaign that a given IP\naddress is going to participate in.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:36:32 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Haider", "Peter", "", "University of Potsdam"], ["Scheffer", "Tobias", "", "University of\n  Potsdam"]]}, {"id": "1206.4973", "submitter": "Imen Chakroun", "authors": "Imen Chakroun (INRIA Lille - Nord Europe), Nouredine Melab (LIFL)", "title": "An Adaptative Multi-GPU based Branch-and-Bound. A Case Study: the\n  Flow-Shop Scheduling Problem", "comments": "14th IEEE International Conference on High Performance Computing and\n  Communications, HPCC 2012 (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving exactly Combinatorial Optimization Problems (COPs) using a\nBranch-and-Bound (B&B) algorithm requires a huge amount of computational\nresources. Therefore, we recently investigated designing B&B algorithms on top\nof graphics processing units (GPUs) using a parallel bounding model. The\nproposed model assumes parallelizing the evaluation of the lower bounds on\npools of sub-problems. The results demonstrated that the size of the evaluated\npool has a significant impact on the performance of B&B and that it depends\nstrongly on the problem instance being solved. In this paper, we design an\nadaptative parallel B&B algorithm for solving permutation-based combinatorial\noptimization problems such as FSP (Flow-shop Scheduling Problem) on GPU\naccelerators. To do so, we propose a dynamic heuristic for parameter\nauto-tuning at runtime. Another challenge of this work is to exploit larger\ndegrees of parallelism by using the combined computational power of multiple\nGPU devices. The approach has been applied to the permutation flow-shop\nproblem. Extensive experiments have been carried out on well-known FSP\nbenchmarks using an Nvidia Tesla S1070 Computing System equipped with two Tesla\nT10 GPUs. Compared to a CPU-based execution, accelerations up to 105 are\nachieved for large problem instances.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 18:59:34 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Chakroun", "Imen", "", "INRIA Lille - Nord Europe"], ["Melab", "Nouredine", "", "LIFL"]]}, {"id": "1206.5021", "submitter": "L\\'aszl\\'o Dobos", "authors": "L\\'aszl\\'o Dobos, Tam\\'as Budav\\'ari, Nolan Li, Alexander S. Szalay\n  and Istv\\'an Csabai", "title": "SkyQuery: An Implementation of a Parallel Probabilistic Join Engine for\n  Cross-Identification of Multiple Astronomical Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB astro-ph.IM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-wavelength astronomical studies require cross-identification of\ndetections of the same celestial objects in multiple catalogs based on\nspherical coordinates and other properties. Because of the large data volumes\nand spherical geometry, the symmetric N-way association of astronomical\ndetections is a computationally intensive problem, even when sophisticated\nindexing schemes are used to exclude obviously false candidates. Legacy\nastronomical catalogs already contain detections of more than a hundred million\nobjects while the ongoing and future surveys will produce catalogs of billions\nof objects with multiple detections of each at different times. The varying\nstatistical error of position measurements, moving and extended objects, and\nother physical properties make it necessary to perform the cross-identification\nusing a mathematically correct, proper Bayesian probabilistic algorithm,\ncapable of including various priors. One time, pair-wise cross-identification\nof these large catalogs is not sufficient for many astronomical scenarios.\nConsequently, a novel system is necessary that can cross-identify multiple\ncatalogs on-demand, efficiently and reliably. In this paper, we present our\nsolution based on a cluster of commodity servers and ordinary relational\ndatabases. The cross-identification problems are formulated in a language based\non SQL, but extended with special clauses. These special queries are\npartitioned spatially by coordinate ranges and compiled into a complex workflow\nof ordinary SQL queries. Workflows are then executed in a parallel framework\nusing a cluster of servers hosting identical mirrors of the same data sets.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 21:50:44 GMT"}], "update_date": "2012-06-25", "authors_parsed": [["Dobos", "L\u00e1szl\u00f3", ""], ["Budav\u00e1ri", "Tam\u00e1s", ""], ["Li", "Nolan", ""], ["Szalay", "Alexander S.", ""], ["Csabai", "Istv\u00e1n", ""]]}, {"id": "1206.5938", "submitter": "Zungeru Adamu Murtala", "authors": "Adamu Murtala Zungeru, Li-Minn Ang and Kah Phooi Seng", "title": "Performance Evaluation of Ant-Based Routing Protocols for Wireless\n  Sensor Networks", "comments": "10 pages, 5 figures, Journal Publication", "journal-ref": "International Journal of Computer Science Issues (IJCSI), volume\n  9, Issue 3, No 2, May 2012, pp. 388-397", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High efficient routing is an important issue in the design of limited energy\nresource Wireless Sensor Networks (WSNs). Due to the characteristic of the\nenvironment at which the sensor node is to operate, coupled with severe\nresources; on-board energy, transmission power, processing capability, and\nstorage limitations, prompt for careful resource management and new routing\nprotocol so as to counteract the differences and challenges. To this end, we\npresent an Improved Energy-Efficient Ant-Based Routing (IEEABR) Algorithm in\nwireless sensor networks. Compared to the state-of-the-art Ant-Based routing\nprotocols; Basic Ant-Based Routing (BABR) Algorithm, Sensor-driven and\nCost-aware ant routing (SC), Flooded Forward ant routing (FF), Flooded\nPiggybacked ant routing (FP), and Energy-Efficient Ant-Based Routing (EEABR),\nthe proposed IEEABR approach has advantages in terms of reduced energy usage\nwhich can effectively balance the WSN node's power consumption, and high energy\nefficiency. The performance evaluations for the algorithms on a real\napplication are conducted in a well known WSN MATLAB-based simulator (RMASE)\nusing both static and dynamic scenario.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2012 09:27:57 GMT"}], "update_date": "2012-06-27", "authors_parsed": [["Zungeru", "Adamu Murtala", ""], ["Ang", "Li-Minn", ""], ["Seng", "Kah Phooi", ""]]}, {"id": "1206.6016", "submitter": "Anasuya Threse Innocent A.", "authors": "A. Anasuya Threse Innocent", "title": "Cloud Infrastructure Service Management - A Review", "comments": "6 pages", "journal-ref": "International Journal of Computer Science Issues, Volume 9, Number\n  2, March 2012, Pg. 287 - 292", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The new era of computing called Cloud Computing allows the user to access the\ncloud services dynamically over the Internet wherever and whenever needed.\nCloud consists of data and resources; and the cloud services include the\ndelivery of software, infrastructure, applications, and storage over the\nInternet based on user demand through Internet. In short, cloud computing is a\nbusiness and economic model allowing the users to utilize high-end computing\nand storage virtually with minimal infrastructure on their end. Cloud has three\nservice models namely, Cloud Software-as-a-Service (SaaS), Cloud\nPlatform-as-a-Service (PaaS), and Cloud Infrastructure-as-a-Service (IaaS).\nThis paper talks in depth of cloud infrastructure service management.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2012 09:45:54 GMT"}], "update_date": "2012-06-27", "authors_parsed": [["Innocent", "A. Anasuya Threse", ""]]}, {"id": "1206.6207", "submitter": "Nikos Tziritas", "authors": "Nikos Tziritas, Samee Ullah Khan, Cheng-Zhong Xu, Jue Hong", "title": "An Optimal Fully Distributed Algorithm to Minimize the Resource\n  Consumption of Cloud Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to the pay-per-use model adopted in clouds, the more the resources\nconsumed by an application running in a cloud computing environment, the\ngreater the amount of money the owner of the corresponding application will be\ncharged. Therefore, applying intelligent solutions to minimize the resource\nconsumption is of great importance. Because centralized solutions are deemed\nunsuitable for large-distributed systems or large-scale applications, we\npropose a fully distributed algorithm (called DRA) to overcome the scalability\nissues. Specifically, DRA migrates the inter-communicating components of an\napplication, such as processes or virtual machines, close to each other to\nminimize the total resource consumption. The migration decisions are made in a\ndynamic way and based only on local information. We prove that DRA achieves\nconvergence and results always in the optimal solution.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 09:02:05 GMT"}], "update_date": "2012-06-28", "authors_parsed": [["Tziritas", "Nikos", ""], ["Khan", "Samee Ullah", ""], ["Xu", "Cheng-Zhong", ""], ["Hong", "Jue", ""]]}, {"id": "1206.6209", "submitter": "Saeid Abolfazli", "authors": "Saeid Abolfazli, Zohreh Sanaei, Abdullah Gani, Muhammad Shiraz", "title": "MOMCC: Market-Oriented Architecture for Mobile Cloud Computing Based on\n  Service Oriented Architecture", "comments": "6 full pages, accepted to be published in IEEE Mobicc'12; Saeid\n  Abolfazli, Zohreh Sanaei, Muhammad Shiraz, Abdullah Gani, MOMCC:\n  Market-Oriented Architecture for Mobile Cloud Computing Based on Service\n  Oriented Architecture, MobiCC'12:2012 IEEE Workshop on Mobile Cloud\n  Computing, Beijing, China", "journal-ref": "2012 1st IEEE International Conference on Communications in China\n  Workshops (2012), 8-13", "doi": "10.1109/ICCCW.2012.6316481", "report-no": null, "categories": "cs.DC cs.NI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vision of augmenting computing capabilities of mobile devices, especially\nsmartphones with least cost is likely transforming to reality leveraging cloud\ncomputing. Cloud exploitation by mobile devices breeds a new research domain\ncalled Mobile Cloud Computing (MCC). However, issues like portability and\ninteroperability should be addressed for mobile augmentation which is a\nnon-trivial task using component-based approaches. Service Oriented\nArchitecture (SOA) is a promising design philosophy embraced by mobile\ncomputing and cloud computing communities to stimulate portable, complex\napplication using prefabricated building blocks called Services. Utilizing\ndistant cloud resources to host and run Services is hampered by long WAN\nlatency. Exploiting mobile devices in vicinity alleviates long WAN latency,\nwhile creates new set of issues like Service publishing and discovery as well\nas client-server security, reliability, and Service availability. In this\npaper, we propose a market-oriented architecture based on SOA to stimulate\npublishing, discovering, and hosting Services on nearby mobiles, which reduces\nlong WAN latency and creates a business opportunity that encourages mobile\nowners to embrace Service hosting. Group of mobile phones simulate a nearby\ncloud computing platform. We create new role of \\textit{Service host} by\nenabling unskilled mobile owners/users to host Services developed by skilled\ndevelopers. Evidently, Service availability, reliability, and Service-oriented\nmobile application portability will increase towards green ubiquitous computing\nin our mobile cloud infrastructure.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 09:17:06 GMT"}], "update_date": "2013-08-20", "authors_parsed": [["Abolfazli", "Saeid", ""], ["Sanaei", "Zohreh", ""], ["Gani", "Abdullah", ""], ["Shiraz", "Muhammad", ""]]}, {"id": "1206.6219", "submitter": "Saeid Abolfazli", "authors": "Zohreh Sanaei and Saeid Abolfazli and Abdullah Gani and Muhammad\n  Shiraz", "title": "SAMI: Service-Based Arbitrated Multi-Tier Infrastructure for Mobile\n  Cloud Computing", "comments": "6 full pages, accepted for publication in IEEE MobiCC'12 conference,\n  MobiCC 2012:IEEE Workshop on Mobile Cloud Computing, Beijing, China", "journal-ref": "2012 1st IEEE International Conference on Communications in China\n  Workshops, (2012) 14-19", "doi": "10.1109/ICCCW.2012.6316466", "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile Cloud Computing (MCC) is the state-ofthe- art mobile computing\ntechnology aims to alleviate resource poverty of mobile devices. Recently,\nseveral approaches and techniques have been proposed to augment mobile devices\nby leveraging cloud computing. However, long-WAN latency and trust are still\ntwo major issues in MCC that hinder its vision. In this paper, we analyze MCC\nand discuss its issues. We leverage Service Oriented Architecture (SOA) to\npropose an arbitrated multi-tier infrastructure model named SAMI for MCC. Our\narchitecture consists of three major layers, namely SOA, arbitrator, and\ninfrastructure. The main strength of this architecture is in its multi-tier\ninfrastructure layer which leverages infrastructures from three main sources of\nClouds, Mobile Network Operators (MNOs), and MNOs' authorized dealers. On top\nof the infrastructure layer, an arbitrator layer is designed to classify\nServices and allocate them the suitable resources based on several metrics such\nas resource requirement, latency and security. Utilizing SAMI facilitate\ndevelopment and deployment of service-based platform-neutral mobile\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 09:55:16 GMT"}], "update_date": "2013-08-20", "authors_parsed": [["Sanaei", "Zohreh", ""], ["Abolfazli", "Saeid", ""], ["Gani", "Abdullah", ""], ["Shiraz", "Muhammad", ""]]}, {"id": "1206.6225", "submitter": "Saeid Abolfazli", "authors": "Muhammad Shiraz, Saeid Abolfazli, Zohreh Sanaei, Abdullah Gani", "title": "Virtual Machine Migration: A Resource Intensive Outsourcing Mechanism\n  for Mobile Cloud Computing", "comments": "This article has been withdrawn by the author due to some copyright\n  issues", "journal-ref": "Muhammad Shiraz, Saeid Abolfazli, Zohreh Sanaei, Abdullah Gani,\n  Virtual Machine Migration: A Resource Intensive Outsourcing Mechanism for\n  Mobile Cloud Computing. Archives DesSciences Journal, Vol.65, No.6, 2012.\n  ISSN: 1661-464X", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Mobile Cloud Computing (MCC), Virtual Machine (VM) migration based process\noffloading is a dominant approach to enhance Smart Mobile Devices (SMDs). A\nchallenging aspect of VM deployment is the additional computing resources usage\nin the deployment and management of VM which obliges computing resources for VM\ncreation and configuration. The management of VM comprises computing resources\nexploitation in the monitoring of VM in entire lifecycle and physical resources\nmanagement for VM on SMDs. Therefore, VM migration based application offloading\nrequires additional computing resource. Consequently computing resources demand\nand execution time of the application increases respectively. In this paper, we\nempirically review the impact of VM deployment and management on the execution\ntime of application in diverse scenarios. We investigate VM deployment and\nmanagement for application processing in simulation environment by employing\nCloudSim: a simulation toolkit that provides an extensible simulation framework\nto model VM deployment and management for application processing in cloud\ninfrastructure. The significance of this work is to ensure that VM deployment\nand management necessitates additional computing resources on SMD for\napplication offloading. We evaluate VM deployment and management in application\nprocessing by analyzing Key Performance Parameters (KPPs) in different\nscenarios; such as VM deployment, the execution time of applications, and total\nexecution time of the simulation. We use KPPs to assess deviations in the\nresults of diverse experimental scenarios. The empirical analysis concludes\nthat VM deployment and management oblige additional resources on computing host\nwhich make it a heavyweight approach for process offloading on smart mobile\ndevice.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 10:23:14 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2012 10:51:08 GMT"}, {"version": "v3", "created": "Fri, 30 Nov 2012 01:18:13 GMT"}], "update_date": "2012-12-03", "authors_parsed": [["Shiraz", "Muhammad", ""], ["Abolfazli", "Saeid", ""], ["Sanaei", "Zohreh", ""], ["Gani", "Abdullah", ""]]}, {"id": "1206.6230", "submitter": "Kian Hsiang Low", "authors": "Jie Chen, Kian Hsiang Low, Colin Keng-Yan Tan, Ali Oran, Patrick\n  Jaillet, John M. Dolan and Gaurav S. Sukhatme", "title": "Decentralized Data Fusion and Active Sensing with Mobile Sensors for\n  Modeling and Predicting Spatiotemporal Traffic Phenomena", "comments": "28th Conference on Uncertainty in Artificial Intelligence (UAI 2012),\n  Extended version with proofs, 13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of modeling and predicting spatiotemporal traffic phenomena over\nan urban road network is important to many traffic applications such as\ndetecting and forecasting congestion hotspots. This paper presents a\ndecentralized data fusion and active sensing (D2FAS) algorithm for mobile\nsensors to actively explore the road network to gather and assimilate the most\ninformative data for predicting the traffic phenomenon. We analyze the time and\ncommunication complexity of D2FAS and demonstrate that it can scale well with a\nlarge number of observations and sensors. We provide a theoretical guarantee on\nits predictive performance to be equivalent to that of a sophisticated\ncentralized sparse approximation for the Gaussian process (GP) model: The\ncomputation of such a sparse approximate GP model can thus be parallelized and\ndistributed among the mobile sensors (in a Google-like MapReduce paradigm),\nthereby achieving efficient and scalable prediction. We also theoretically\nguarantee its active sensing performance that improves under various practical\nenvironmental conditions. Empirical evaluation on real-world urban road network\ndata shows that our D2FAS algorithm is significantly more time-efficient and\nscalable than state-of-the-art centralized algorithms while achieving\ncomparable predictive performance.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 11:11:55 GMT"}, {"version": "v2", "created": "Thu, 28 Jun 2012 04:21:18 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Chen", "Jie", ""], ["Low", "Kian Hsiang", ""], ["Tan", "Colin Keng-Yan", ""], ["Oran", "Ali", ""], ["Jaillet", "Patrick", ""], ["Dolan", "John M.", ""], ["Sukhatme", "Gaurav S.", ""]]}, {"id": "1206.6293", "submitter": "Alexander Sch\\\"atzle", "authors": "Martin Przyjaciel-Zablocki, Alexander Sch\\\"atzle, Thomas Hornung,\n  Christopher Dorner, Georg Lausen", "title": "Cascading map-side joins over HBase for scalable join processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major challenges in large-scale data processing with MapReduce is\nthe smart computation of joins. Since Semantic Web datasets published in RDF\nhave increased rapidly over the last few years, scalable join techniques become\nan important issue for SPARQL query processing as well. In this paper, we\nintroduce the Map-Side Index Nested Loop Join (MAPSIN join) which combines\nscalable indexing capabilities of NoSQL storage systems like HBase, that suffer\nfrom an insufficient distributed processing layer, with MapReduce, which in\nturn does not provide appropriate storage structures for efficient large-scale\njoin processing. While retaining the flexibility of commonly used reduce-side\njoins, we leverage the effectiveness of map-side joins without any changes to\nthe underlying framework. We demonstrate the significant benefits of MAPSIN\njoins for the processing of SPARQL basic graph patterns on large RDF datasets\nby an evaluation with the LUBM and SP2Bench benchmarks. For most queries,\nMAPSIN join based query execution outperforms reduce-side join based execution\nby an order of magnitude.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 15:05:05 GMT"}], "update_date": "2012-06-28", "authors_parsed": [["Przyjaciel-Zablocki", "Martin", ""], ["Sch\u00e4tzle", "Alexander", ""], ["Hornung", "Thomas", ""], ["Dorner", "Christopher", ""], ["Lausen", "Georg", ""]]}, {"id": "1206.6409", "submitter": "Mahantesh Halappanavar", "authors": "Chad Scherrer (Pacific Northwest National Lab), Mahantesh Halappanavar\n  (Pacific Northwest National Lab), Ambuj Tewari (University of Texas), David\n  Haglin (Pacific Northwest National Lab)", "title": "Scaling Up Coordinate Descent Algorithms for Large $\\ell_1$\n  Regularization Problems", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generic framework for parallel coordinate descent (CD)\nalgorithms that includes, as special cases, the original sequential algorithms\nCyclic CD and Stochastic CD, as well as the recent parallel Shotgun algorithm.\nWe introduce two novel parallel algorithms that are also special\ncases---Thread-Greedy CD and Coloring-Based CD---and give performance\nmeasurements for an OpenMP implementation of these.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-04", "authors_parsed": [["Scherrer", "Chad", "", "Pacific Northwest National Lab"], ["Halappanavar", "Mahantesh", "", "Pacific Northwest National Lab"], ["Tewari", "Ambuj", "", "University of Texas"], ["Haglin", "David", "", "Pacific Northwest National Lab"]]}, {"id": "1206.6420", "submitter": "Qiang Liu", "authors": "Qiang Liu (UC Irvine), Alexander Ihler (UC Irvine)", "title": "Distributed Parameter Estimation via Pseudo-likelihood", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating statistical models within sensor networks requires distributed\nalgorithms, in which both data and computation are distributed across the nodes\nof the network. We propose a general approach for distributed learning based on\ncombining local estimators defined by pseudo-likelihood components,\nencompassing a number of combination methods, and provide both theoretical and\nexperimental analysis. We show that simple linear combination or max-voting\nmethods, when combined with second-order information, are statistically\ncompetitive with more advanced and costly joint optimization. Our algorithms\nhave many attractive properties including low communication and computational\ncost and \"any-time\" behavior.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Liu", "Qiang", "", "UC Irvine"], ["Ihler", "Alexander", "", "UC Irvine"]]}]