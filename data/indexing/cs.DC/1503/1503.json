[{"id": "1503.00140", "submitter": "Maria Gradinariu Potop-Butucaru", "authors": "Silvia Bonomi and Shlomi Dolev and Maria Potop-Butucaru and Michel\n  Raynal", "title": "Stabilizing Server-Based Storage in Byzantine Asynchronous\n  Message-Passing Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A stabilizing Byzantine single-writer single-reader (SWSR) regular register,\nwhich stabilizes after the first invoked write operation, is first presented.\nThen, new/old ordering inversions are eliminated by the use of a (bounded)\nsequence number for writes, obtaining a practically stabilizing SWSR atomic\nregister. A practically stabilizing Byzantine single-writer multi-reader (SWMR)\natomic register is then obtained by using several copies of SWSR atomic\nregisters. Finally, bounded time-stamps, with a time-stamp per writer, together\nwith SWMR atomic registers, are used to construct a practically stabilizing\nByzantine multi-writer multi-reader (MWMR) atomic register. In a system of $n$\nservers implementing an atomic register, and in addition to transient failures,\nthe constructions tolerate t<n/8 Byzantine servers if communication is\nasynchronous, and t<n/3 Byzantine servers if it is synchronous. The noteworthy\nfeature of the proposed algorithms is that (to our knowledge) these are the\nfirst that build an atomic read/write storage on top of asynchronous servers\nprone to transient failures, and where up to t of them can be Byzantine.\n", "versions": [{"version": "v1", "created": "Sat, 28 Feb 2015 15:27:03 GMT"}], "update_date": "2015-03-03", "authors_parsed": [["Bonomi", "Silvia", ""], ["Dolev", "Shlomi", ""], ["Potop-Butucaru", "Maria", ""], ["Raynal", "Michel", ""]]}, {"id": "1503.00321", "submitter": "Chinmoy Dutta", "authors": "Chinmoy Dutta and Jaikumar Radhakrishnan", "title": "A Sampling Technique of Proving Lower Bounds for Noisy Computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a technique of proving lower bounds for noisy computations. This\nis achieved by a theorem connecting computations on a kind of randomized\ndecision trees and sampling based algorithms. This approach is surprisingly\npowerful, and applicable to several models of computation previously studied.\n  As a first illustration we show how all the results of Evans and Pippenger\n(SIAM J. Computing, 1999) for noisy decision trees, some of which were derived\nusing Fourier analysis, follow immediately if we consider the sampling-based\nalgorithms that naturally arise from these decision trees.\n  Next, we show a tight lower bound of $\\Omega(N \\log\\log N)$ on the number of\ntransmissions required to compute several functions (including the parity\nfunction and the majority function) in a network of $N$ randomly placed\nsensors, communicating using local transmissions, and operating with power near\nthe connectivity threshold. This result considerably simplifies and strengthens\nan earlier result of Dutta, Kanoria Manjunath and Radhakrishnan (SODA 08) that\nsuch networks cannot compute the parity function reliably with significantly\nfewer than $N\\log \\log N$ transmissions. The lower bound for parity shown\nearlier made use of special properties of the parity function and is\ninapplicable, e.g., to the majority function. In this paper, we use our\napproach to develop an interesting connection between computation of boolean\nfunctions on noisy networks that make few transmissionss, and algorithms that\nwork by sampling only a part of the input. It is straightforward to verify that\nsuch sampling-based algorithms cannot compute the majority function.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2015 18:14:23 GMT"}], "update_date": "2015-03-03", "authors_parsed": [["Dutta", "Chinmoy", ""], ["Radhakrishnan", "Jaikumar", ""]]}, {"id": "1503.00576", "submitter": "Adam Polak", "authors": "Adam Polak", "title": "Counting Triangles in Large Graphs on GPU", "comments": "2016 IEEE International Parallel and Distributed Processing Symposium\n  Workshops (IPDPSW)", "journal-ref": null, "doi": "10.1109/IPDPSW.2016.108", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The clustering coefficient and the transitivity ratio are concepts often used\nin network analysis, which creates a need for fast practical algorithms for\ncounting triangles in large graphs. Previous research in this area focused on\nsequential algorithms, MapReduce parallelization, and fast approximations.\n  In this paper we propose a parallel triangle counting algorithm for CUDA GPU.\nWe describe the implementation details necessary to achieve high performance\nand present the experimental evaluation of our approach. Our algorithm achieves\n8 to 15 times speedup over the CPU implementation and is capable of finding 3.8\nbillion triangles in an 89 million edges graph in less than 10 seconds on the\nNvidia Tesla C2050 GPU.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2015 15:35:32 GMT"}, {"version": "v2", "created": "Sat, 6 Aug 2016 14:13:22 GMT"}], "update_date": "2016-08-09", "authors_parsed": [["Polak", "Adam", ""]]}, {"id": "1503.00626", "submitter": "Da Yan", "authors": "Da Yan, James Cheng, Yi Lu, Wilfred Ng", "title": "Effective Techniques for Message Reduction and Load Balancing in\n  Distributed Graph Computation", "comments": "This is a long version of the corresponding WWW 2015 paper, with all\n  proofs included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive graphs, such as online social networks and communication networks,\nhave become common today. To efficiently analyze such large graphs, many\ndistributed graph computing systems have been developed. These systems employ\nthe \"think like a vertex\" programming paradigm, where a program proceeds in\niterations and at each iteration, vertices exchange messages with each other.\nHowever, using Pregel's simple message passing mechanism, some vertices may\nsend/receive significantly more messages than others due to either the high\ndegree of these vertices or the logic of the algorithm used. This forms the\ncommunication bottleneck and leads to imbalanced workload among machines in the\ncluster. In this paper, we propose two effective message reduction techniques:\n(1)vertex mirroring with message combining, and (2)an additional\nrequest-respond API. These techniques not only reduce the total number of\nmessages exchanged through the network, but also bound the number of messages\nsent/received by any single vertex. We theoretically analyze the effectiveness\nof our techniques, and implement them on top of our open-source Pregel\nimplementation called Pregel+. Our experiments on various large real graphs\ndemonstrate that our message reduction techniques significantly improve the\nperformance of distributed graph computation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2015 17:25:57 GMT"}], "update_date": "2015-03-03", "authors_parsed": [["Yan", "Da", ""], ["Cheng", "James", ""], ["Lu", "Yi", ""], ["Ng", "Wilfred", ""]]}, {"id": "1503.00808", "submitter": "Shaoshuai Mou", "authors": "Shaoshuai Mou, Ji Liu, A. Stephen Morse", "title": "A Distributed Algorithm for Solving a Linear Algebraic Equation", "comments": "45pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A distributed algorithm is described for solving a linear algebraic equation\nof the form $Ax=b$ assuming the equation has at least one solution. The\nequation is simultaneously solved by $m$ agents assuming each agent knows only\na subset of the rows of the partitioned matrix $(A,b)$, the current estimates\nof the equation's solution generated by its neighbors, and nothing more. Each\nagent recursively updates its estimate by utilizing the current estimates\ngenerated by each of its neighbors. Neighbor relations are characterized by a\ntime-dependent directed graph $\\mathbb{N}(t)$ whose vertices correspond to\nagents and whose arcs depict neighbor relations. It is shown that for any\nmatrix $A$ for which the equation has a solution and any sequence of\n\"repeatedly jointly strongly connected graphs\" $\\mathbb{N}(t)$, $t=1,2,\\ldots$,\nthe algorithm causes all agents' estimates to converge exponentially fast to\nthe same solution to $Ax=b$. It is also shown that the neighbor graph sequence\nmust actually be repeatedly jointly strongly connected if exponential\nconvergence is to be assured. A worst case convergence rate bound is derived\nfor the case when $Ax=b$ has a unique solution. It is demonstrated that with\nminor modification, the algorithm can track the solution to $Ax = b$, even if\n$A$ and $b$ are changing with time, provided the rates of change of $A$ and $b$\nare sufficiently small. It is also shown that in the absence of communication\ndelays, exponential convergence to a solution occurs even if the times at which\neach agent updates its estimates are not synchronized with the update times of\nits neighbors. A modification of the algorithm is outlined which enables it to\nobtain a least squares solution to $Ax=b$ in a distributed manner, even if\n$Ax=b$ does not have a solution.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2015 02:31:25 GMT"}], "update_date": "2015-03-04", "authors_parsed": [["Mou", "Shaoshuai", ""], ["Liu", "Ji", ""], ["Morse", "A. Stephen", ""]]}, {"id": "1503.00855", "submitter": "Nathan Uyttendaele", "authors": "Nathan Uyttendaele", "title": "How to speed up R code: an introduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most calculations performed by the average R user are unremarkable in the\nsense that nowadays, any computer can crush the related code in a matter of\nseconds. But more and more often, heavy calculations are also performed using\nR, something especially true in some fields such as statistics. The user then\nfaces total execution times of his codes that are hard to work with: hours,\ndays, even weeks. In this paper, how to reduce the total execution time of\nvarious codes will be shown and typical bottlenecks will be discussed. As a\nlast resort, how to run your code on a cluster of computers (most workplaces\nhave one) in order to make use of a larger processing power than the one\navailable on an average computer will also be discussed through two examples.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2015 08:21:32 GMT"}], "update_date": "2015-03-04", "authors_parsed": [["Uyttendaele", "Nathan", ""]]}, {"id": "1503.01061", "submitter": "Ashkan Paya Mr.", "authors": "Dan C. Marinescu, Ashkan Paya, John P. Morrison, Philip Healy", "title": "Distributed Hierarchical Control versus an Economic Model for Cloud\n  Resource Management", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a hierarchically organized cloud infrastructure and compare\ndistributed hierarchical control based on resource monitoring with market\nmechanisms for resource management. The latter do not require a model of the\nsystem, incur a low overhead, are robust, and satisfy several other desiderates\nof autonomic computing. We introduce several performance measures and report on\nsimulation studies which show that a straightforward bidding scheme supports an\neffective admission control mechanism, while reducing the communication\ncomplexity by several orders of magnitude and also increasing the acceptance\nrate compared to hierarchical control and monitoring mechanisms. Resource\nmanagement based on market-based mechanisms can be seen as an intermediate step\ntowards cloud self-organization, an ideal alternative to current mechanisms for\ncloud resource management.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2015 19:14:01 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2015 20:28:16 GMT"}, {"version": "v3", "created": "Sun, 22 Mar 2015 21:28:05 GMT"}, {"version": "v4", "created": "Tue, 14 Apr 2015 19:06:14 GMT"}], "update_date": "2015-04-15", "authors_parsed": [["Marinescu", "Dan C.", ""], ["Paya", "Ashkan", ""], ["Morrison", "John P.", ""], ["Healy", "Philip", ""]]}, {"id": "1503.01314", "submitter": "Arka Rai Choudhuri", "authors": "Arka Rai Choudhuri, Kalyanasundaram S, Shriyak Sridhar, Annappa B", "title": "An Incentivized Approach for Fair Participation in Wireless Ad hoc\n  Networks", "comments": "6 pages, 4 figures, published in the International Journal of Recent\n  Development in Engineering and Technology", "journal-ref": "IJRDET 2, no. 3 (2014): 117-121", "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Wireless Ad hoc networks (WANETs), nodes separated by considerable\ndistance communicate with each other by relaying their messages through other\nnodes. However, it might not be in the best interests of a node to forward the\nmessage of another node due to power constraints. In addition, all nodes being\nrational, some nodes may be selfish, i.e. they might not relay data from other\nnodes so as to increase their lifetime. In this paper, we present a fair and\nincentivized approach for participation in Ad hoc networks. Given the power\nrequired for each transmission, we are able to determine the power saving\ncontributed by each intermediate hop. We propose the FAir Share incenTivizEd Ad\nhoc paRticipation protocol (FASTER), which takes a selected route from a\nrouting protocol as input, to calculate the worth of each node using the\ncooperative game theory concept of 'Shapley Value' applied on the power saved\nby each node. This value can be used for allocation of Virtual Currency to the\nnodes, which can be spent on subsequent message transmissions.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2015 14:22:25 GMT"}], "update_date": "2015-03-05", "authors_parsed": [["Choudhuri", "Arka Rai", ""], ["S", "Kalyanasundaram", ""], ["Sridhar", "Shriyak", ""], ["B", "Annappa", ""]]}, {"id": "1503.01416", "submitter": "Bulent Abali", "authors": "Bulent Abali, Richard J. Eickemeyer, Hubertus Franke, Chung-Sheng Li,\n  Marc A. Taubenblatt", "title": "Disaggregated and optically interconnected memory: when will it be cost\n  effective?", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \"Disaggregated Server\" concept has been proposed for datacenters where\nthe same type server resources are aggregated in their respective pools, for\nexample a compute pool, memory pool, network pool, and a storage pool. Each\nserver is constructed dynamically by allocating the right amount of resources\nfrom these pools according to the workload's requirements. Modularity, higher\npackaging and cooling efficiencies, and higher resource utilization are among\nthe suggested benefits. With the emergence of very large datacenters, \"clouds\"\ncontaining tens of thousands of servers, datacenter efficiency has become an\nimportant topic. Few computer chip and systems vendors are working on and\nmaking frequent announcements on silicon photonics and disaggregated memory\nsystems.\n  In this paper we study the trade-off between cost and performance of building\na disaggregated memory system where DRAM modules in the datacenter are pooled,\nfor example in memory-only chassis and racks. The compute pool and the memory\npool are interconnected by an optical interconnect to overcome the distance and\nbandwidth issues of electrical fabrics. We construct a simple cost model that\nincludes the cost of latency, cost of bandwidth and the savings expected from a\ndisaggregated memory system. We then identify the level at which a\ndisaggregated memory system becomes cost competitive with a traditional direct\nattached memory system.\n  Our analysis shows that a rack-scale disaggregated memory system will have a\nnon-trivial performance penalty, and at the datacenter scale the penalty is\nimpractically high, and the optical interconnect costs are at least a factor of\n10 more expensive than where they should be when compared to the traditional\ndirect attached memory systems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2015 18:38:33 GMT"}], "update_date": "2015-03-09", "authors_parsed": [["Abali", "Bulent", ""], ["Eickemeyer", "Richard J.", ""], ["Franke", "Hubertus", ""], ["Li", "Chung-Sheng", ""], ["Taubenblatt", "Marc A.", ""]]}, {"id": "1503.01588", "submitter": "Sunoo Park", "authors": "Shafi Goldwasser, Yael Tauman Kalai, Sunoo Park", "title": "Adaptively Secure Coin-Flipping, Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The full-information model was introduced by Ben-Or and Linial in 1985 to\nstudy collective coin-flipping: the problem of generating a common bounded-bias\nbit in a network of $n$ players with $t=t(n)$ faults. They showed that the\nmajority protocol can tolerate $t=O(\\sqrt n)$ adaptive corruptions, and\nconjectured that this is optimal in the adaptive setting. Lichtenstein, Linial,\nand Saks proved that the conjecture holds for protocols in which each player\nsends a single bit. Their result has been the main progress on the conjecture\nin the last 30 years.\n  In this work we revisit this question and ask: what about protocols involving\nlonger messages? Can increased communication allow for a larger fraction of\nfaulty players?\n  We introduce a model of strong adaptive corruptions, where in each round, the\nadversary sees all messages sent by honest parties and, based on the message\ncontent, decides whether to corrupt a party (and intercept his message) or not.\nWe prove that any one-round coin-flipping protocol, regardless of message\nlength, is secure against at most $\\tilde{O}(\\sqrt n)$ strong adaptive\ncorruptions. Thus, increased message length does not help in this setting.\n  We then shed light on the connection between adaptive and strongly adaptive\nadversaries, by proving that for any symmetric one-round coin-flipping protocol\nsecure against $t$ adaptive corruptions, there is a symmetric one-round\ncoin-flipping protocol secure against $t$ strongly adaptive corruptions.\nReturning to the standard adaptive model, we can now prove that any symmetric\none-round protocol with arbitrarily long messages can tolerate at most\n$\\tilde{O}(\\sqrt n)$ adaptive corruptions.\n  At the heart of our results lies a novel use of the Minimax Theorem and a new\ntechnique for converting any one-round secure protocol into a protocol with\nmessages of $polylog(n)$ bits. This technique may be of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2015 09:47:33 GMT"}, {"version": "v2", "created": "Mon, 4 May 2015 21:12:31 GMT"}], "update_date": "2015-05-06", "authors_parsed": [["Goldwasser", "Shafi", ""], ["Kalai", "Yael Tauman", ""], ["Park", "Sunoo", ""]]}, {"id": "1503.01913", "submitter": "Othon Michail", "authors": "Othon Michail", "title": "Terminating Distributed Construction of Shapes and Patterns in a Fair\n  Solution of Automata", "comments": "39 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a solution of automata similar to Population Protocols and\nNetwork Constructors. The automata (or nodes) move passively in a well-mixed\nsolution and can cooperate by interacting in pairs. Every such interaction may\nresult in an update of the local states of the nodes. Additionally, the nodes\nmay also choose to connect to each other in order to start forming some\nrequired structure. We may think of such nodes as the smallest possible\nprogrammable pieces of matter. The model that we introduce here is a more\napplied version of Network Constructors, imposing physical (or geometrical)\nconstraints on the connections. Each node can connect to other nodes only via a\nvery limited number of local ports, therefore at any given time it has only a\nbounded number of neighbors. Connections are always made at unit distance and\nare perpendicular to connections of neighboring ports. We show that this\nrestricted model is still capable of forming very practical 2D or 3D shapes. We\nprovide direct constructors for some basic shape construction problems. We then\ndevelop new techniques for determining the constructive capabilities of our\nmodel. One of the main novelties of our approach, concerns our attempt to\novercome the inability of such systems to detect termination. In particular, we\nexploit the assumptions that the system is well-mixed and has a unique leader,\nin order to give terminating protocols that are correct with high probability\n(w.h.p.). This allows us to develop terminating subroutines that can be\nsequentially composed to form larger modular protocols. One of our main results\nis a terminating protocol counting the size $n$ of the system w.h.p.. We then\nuse this protocol as a subroutine in order to develop our universal\nconstructors, establishing that the nodes can self-organize w.h.p. into\narbitrarily complex shapes while still detecting termination of the\nconstruction.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2015 11:04:49 GMT"}], "update_date": "2015-04-01", "authors_parsed": [["Michail", "Othon", ""]]}, {"id": "1503.02233", "submitter": "Nathaniel Stickley", "authors": "Nathaniel R. Stickley and Miguel A. Aragon-Calvo", "title": "NebulOS: A Big Data Framework for Astrophysics", "comments": "15 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce NebulOS, a Big Data platform that allows a cluster of Linux\nmachines to be treated as a single computer. With NebulOS, the process of\nwriting a massively parallel program for a datacenter is no more complicated\nthan writing a Python script for a desktop computer. The platform enables most\npre-existing data analysis software to be used, as scale, in a datacenter\nwithout modification. The shallow learning curve and compatibility with\nexisting software greatly reduces the time required to develop distributed data\nanalysis pipelines. The platform is built upon industry-standard, open-source\nBig Data technologies, from which it inherits several fault tolerance features.\nNebulOS enhances these technologies by adding an intuitive user interface,\nautomated task monitoring, and other usability features. We present a summary\nof the architecture, provide usage examples, and discuss the system's\nperformance scaling.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2015 01:14:12 GMT"}, {"version": "v2", "created": "Sat, 10 Sep 2016 00:13:20 GMT"}, {"version": "v3", "created": "Wed, 14 Sep 2016 15:42:55 GMT"}], "update_date": "2016-09-15", "authors_parsed": [["Stickley", "Nathaniel R.", ""], ["Aragon-Calvo", "Miguel A.", ""]]}, {"id": "1503.02241", "submitter": "Dan Arnon", "authors": "Dan Arnon and Navindra Sharma (EMC Corporation)", "title": "An Analysis of a Virtually Synchronous Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enterprise-scale systems such as those used for cloud computing require a\nscalable and highly available infrastructure. One crucial ingredient of such an\ninfrastructure is the ability to replicate data coherently among a group of\ncooperating processes in the presence of process failures and group membership\nchanges. The last few decades have seen prolific research into efficient\nprotocols for such data replication. One family of such protocols are the\nvirtually synchronous protocols. Virtually synchronous protocols achieve their\nefficiency by limiting their synchronicity guarantee to messages that bear a\ncausal relationship to each other. Such protocols have found wide-ranging\ncommercial uses over the years. One protocol in particular, the CBCAST protocol\ndeveloped by Birman, Schiper and Stephenson in 1991 and used in their ISIS\nplatform was particularly promising due to its unique no-wait properties, but\nhas suffered from seemingly intractable race conditions. In this paper we\ndescribe a corrected version of this protocol and prove its formal properties.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2015 02:57:49 GMT"}], "update_date": "2015-03-10", "authors_parsed": [["Arnon", "Dan", "", "EMC Corporation"], ["Sharma", "Navindra", "", "EMC Corporation"]]}, {"id": "1503.02353", "submitter": "Peter Robinson", "authors": "Gopal Pandurangan, Peter Robinson, Michele Scquizzato", "title": "Fast Distributed Algorithms for Connectivity and MST in Large Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the increasing need to understand the algorithmic foundations of\ndistributed large-scale graph computations, we study a number of fundamental\ngraph problems in a message-passing model for distributed computing where $k\n\\geq 2$ machines jointly perform computations on graphs with $n$ nodes\n(typically, $n \\gg k$). The input graph is assumed to be initially randomly\npartitioned among the $k$ machines, a common implementation in many real-world\nsystems. Communication is point-to-point, and the goal is to minimize the\nnumber of communication rounds of the computation.\n  Our main result is an (almost) optimal distributed randomized algorithm for\ngraph connectivity. Our algorithm runs in $\\tilde{O}(n/k^2)$ rounds\n($\\tilde{O}$ notation hides a $\\poly\\log(n)$ factor and an additive\n$\\poly\\log(n)$ term). This improves over the best previously known bound of\n$\\tilde{O}(n/k)$ [Klauck et al., SODA 2015], and is optimal (up to a\npolylogarithmic factor) in view of an existing lower bound of\n$\\tilde{\\Omega}(n/k^2)$. Our improved algorithm uses a bunch of techniques,\nincluding linear graph sketching, that prove useful in the design of efficient\ndistributed graph algorithms. Using the connectivity algorithm as a building\nblock, we then present fast randomized algorithms for computing minimum\nspanning trees, (approximate) min-cuts, and for many graph verification\nproblems. All these algorithms take $\\tilde{O}(n/k^2)$ rounds, and are optimal\nup to polylogarithmic factors. We also show an almost matching lower bound of\n$\\tilde{\\Omega}(n/k^2)$ rounds for many graph verification problems by\nleveraging lower bounds in random-partition communication complexity.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2015 01:16:06 GMT"}, {"version": "v2", "created": "Tue, 19 May 2015 15:54:33 GMT"}, {"version": "v3", "created": "Wed, 6 Jul 2016 18:53:05 GMT"}], "update_date": "2016-07-07", "authors_parsed": [["Pandurangan", "Gopal", ""], ["Robinson", "Peter", ""], ["Scquizzato", "Michele", ""]]}, {"id": "1503.02434", "submitter": "Marco Peressotti", "authors": "Alessio Mansutti, Marino Miculan, Marco Peressotti", "title": "Distributed execution of bigraphical reactive systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bigraph embedding problem is crucial for many results and tools about\nbigraphs and bigraphical reactive systems (BRS). Current algorithms for\ncomputing bigraphical embeddings are centralized, i.e. designed to run locally\nwith a complete view of the guest and host bigraphs. In order to deal with\nlarge bigraphs, and to parallelize reactions, we present a decentralized\nalgorithm, which distributes both state and computation over several concurrent\nprocesses. This allows for distributed, parallel simulations where\nnon-interfering reactions can be carried out concurrently; nevertheless, even\nin the worst case the complexity of this distributed algorithm is no worse than\nthat of a centralized algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2015 11:36:45 GMT"}], "update_date": "2015-03-10", "authors_parsed": [["Mansutti", "Alessio", ""], ["Miculan", "Marino", ""], ["Peressotti", "Marco", ""]]}, {"id": "1503.02464", "submitter": "Volker Weinberg", "authors": "Andrea Sgattoni, Luca Fedeli, Stefano Sinigardi, Alberto Marocchino,\n  Andrea Macchi, Volker Weinberg, Anupam Karmakar", "title": "Optimising PICCANTE - an Open Source Particle-in-Cell Code for Advanced\n  Simulations on Tier-0 Systems", "comments": "8 pages, 6 figures, PRACE Whitepaper", "journal-ref": null, "doi": null, "report-no": "WP209", "categories": "cs.DC physics.comp-ph physics.plasm-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a detailed strong and weak scaling analysis of PICCANTE, an open\nsource, massively parallel, fully-relativistic Particle-In-Cell (PIC) code. PIC\ncodes are widely used in plasma physics and astrophysics to study the cases\nwhere kinetic effects are relevant. PICCANTE is primarily developed to study\nlaser-plasma interaction. Within a PRACE Preparatory Access Project, various\nrevisions of different routines of the code have been analysed on the HPC\nsystems JUQUEEN at Juelich Supercomputing Centre (JSC), Germany, and FERMI at\nCINECA, Italy, to improve scalability and I/O performance of the application.\nThe diagnostic tool Scalasca is used to identify suboptimal routines. Different\noutput strategies are discussed. The detailed strong and weak scaling behaviour\nof the improved code are presented in comparison with the original version of\nthe code.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2015 13:05:06 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2015 13:55:41 GMT"}], "update_date": "2015-03-27", "authors_parsed": [["Sgattoni", "Andrea", ""], ["Fedeli", "Luca", ""], ["Sinigardi", "Stefano", ""], ["Marocchino", "Alberto", ""], ["Macchi", "Andrea", ""], ["Weinberg", "Volker", ""], ["Karmakar", "Anupam", ""]]}, {"id": "1503.02654", "submitter": "K. Alex Mills", "authors": "K. Alex Mills, R. Chandrasekaran, Neeraj Mittal", "title": "Algorithms for Replica Placement in High-Availability Storage", "comments": "22 pages, 7 figures, 4 algorithm listings", "journal-ref": null, "doi": "10.1007/978-3-319-26626-8_26", "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new model of causal failure is presented and used to solve a novel replica\nplacement problem in data centers. The model describes dependencies among\nsystem components as a directed graph. A replica placement is defined as a\nsubset of vertices in such a graph. A criterion for optimizing replica\nplacements is formalized and explained. In this work, the optimization goal is\nto avoid choosing placements in which a single failure event is likely to wipe\nout multiple replicas. Using this criterion, a fast algorithm is given for the\nscenario in which the dependency model is a tree. The main contribution of the\npaper is an $O(n + \\rho \\log \\rho)$ dynamic programming algorithm for placing\n$\\rho$ replicas on a tree with $n$ vertices. This algorithm exhibits the\ninteresting property that only two subproblems need to be recursively\nconsidered at each stage. An $O(n^2 \\rho)$ greedy algorithm is also briefly\nreported.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2015 19:59:17 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2015 19:32:53 GMT"}, {"version": "v3", "created": "Wed, 22 Apr 2015 16:33:41 GMT"}, {"version": "v4", "created": "Fri, 22 May 2015 15:40:48 GMT"}], "update_date": "2017-01-09", "authors_parsed": [["Mills", "K. Alex", ""], ["Chandrasekaran", "R.", ""], ["Mittal", "Neeraj", ""]]}, {"id": "1503.02735", "submitter": "Shiqiang Wang", "authors": "Shiqiang Wang, Rahul Urgaonkar, Ting He, Kevin Chan, Murtaza Zafer and\n  Kin K. Leung", "title": "Dynamic Service Placement for Mobile Micro-Clouds with Predicted Future\n  Costs", "comments": "This is the author's version of the paper accepted for publication in\n  the IEEE Transactions on Parallel and Distributed Systems", "journal-ref": null, "doi": "10.1109/TPDS.2016.2604814", "report-no": null, "categories": "cs.DC cs.NI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile micro-clouds are promising for enabling performance-critical cloud\napplications. However, one challenge therein is the dynamics at the network\nedge. In this paper, we study how to place service instances to cope with these\ndynamics, where multiple users and service instances coexist in the system. Our\ngoal is to find the optimal placement (configuration) of instances to minimize\nthe average cost over time, leveraging the ability of predicting future cost\nparameters with known accuracy. We first propose an offline algorithm that\nsolves for the optimal configuration in a specific look-ahead time-window.\nThen, we propose an online approximation algorithm with polynomial\ntime-complexity to find the placement in real-time whenever an instance\narrives. We analytically show that the online algorithm is $O(1)$-competitive\nfor a broad family of cost functions. Afterwards, the impact of prediction\nerrors is considered and a method for finding the optimal look-ahead window\nsize is proposed, which minimizes an upper bound of the average actual cost.\nThe effectiveness of the proposed approach is evaluated by simulations with\nboth synthetic and real-world (San Francisco taxi) user-mobility traces. The\ntheoretical methodology used in this paper can potentially be applied to a\nlarger class of dynamic resource allocation problems.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2015 23:52:33 GMT"}, {"version": "v2", "created": "Fri, 16 Sep 2016 15:17:53 GMT"}], "update_date": "2016-09-19", "authors_parsed": [["Wang", "Shiqiang", ""], ["Urgaonkar", "Rahul", ""], ["He", "Ting", ""], ["Chan", "Kevin", ""], ["Zafer", "Murtaza", ""], ["Leung", "Kin K.", ""]]}, {"id": "1503.02774", "submitter": "Andrea Lincoln", "authors": "Adam Hesterberg, Andrea Lincoln, Jayson Lynch", "title": "Improved Connectivity Condition for Byzantine Fault Tolerance", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a network in which some pairs of nodes can communicate freely, and some\nsubsets of the nodes could be faulty and colluding to disrupt communication,\nwhen can messages reliably be sent from one given node to another? We give a\nnew characterization of when the agreement problem can be solved and provide an\nagreement algorithm which can reach agreement when the number of Byzantine\nnodes along each minimal vertex cut is bounded. Our new bound holds for a\nstrict superset of cases than the previously known bound. We show that the new\nbound is tight. Furthermore, we show that this algorithm does not require the\nprocesses to know the graph structure, as the previously known algorithm did.\nFinally, we explore some of the situations in which we can reach agreement if\nwe assume that individual nodes or entire subgraphs are trustworthy.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2015 05:21:54 GMT"}], "update_date": "2015-03-11", "authors_parsed": [["Hesterberg", "Adam", ""], ["Lincoln", "Andrea", ""], ["Lynch", "Jayson", ""]]}, {"id": "1503.03128", "submitter": "Da Wang", "authors": "Da Wang, Gauri Joshi, Gregory Wornell", "title": "Efficient Straggler Replication in Large-scale Parallel Computing", "comments": "Submitted to ACM Transactions on Modeling and Performance Evaluation\n  of Computing Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a cloud computing job with many parallel tasks, the tasks on the slowest\nmachines (straggling tasks) become the bottleneck in the job completion.\nComputing frameworks such as MapReduce and Spark tackle this by replicating the\nstraggling tasks and waiting for any one copy to finish. Despite being adopted\nin practice, there is little analysis of how replication affects the latency\nand the cost of additional computing resources. In this paper we provide a\nframework to analyze this latency-cost trade-off and find the best replication\nstrategy by answering design questions such as: 1) when to replicate straggling\ntasks, 2) how many replicas to launch, and 3) whether to kill the original copy\nor not. Our analysis reveals that for certain execution time distributions, a\nsmall amount of task replication can drastically reduce both latency as well as\nthe cost of computing resources. We also propose an algorithm to estimate the\nlatency and cost based on the empirical distribution of task execution time.\nEvaluations using samples in the Google Cluster Trace suggest further latency\nand cost reduction compared to the existing replication strategy used in\nMapReduce.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2015 00:08:45 GMT"}, {"version": "v2", "created": "Sat, 14 Mar 2015 00:32:02 GMT"}, {"version": "v3", "created": "Wed, 13 Sep 2017 02:13:25 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Wang", "Da", ""], ["Joshi", "Gauri", ""], ["Wornell", "Gregory", ""]]}, {"id": "1503.03284", "submitter": "Patrizio Dazzi Ph.D.", "authors": "Patrizio Dazzi", "title": "Tools and Models for High Level Parallel and Grid Programming", "comments": "PhD Thesis, 2008, IMT Institute for Advanced Studies, Lucca. arXiv\n  admin note: text overlap with arXiv:1002.2722 by other authors", "journal-ref": null, "doi": "10.6092/imtlucca/e-theses/12", "report-no": null, "categories": "cs.DC cs.SE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  When algorithmic skeletons were first introduced by Cole in late 1980 the\nidea had an almost immediate success. The skeletal approach has been proved to\nbe effective when application algorithms can be expressed in terms of skeletons\ncomposition. However, despite both their effectiveness and the progress made in\nskeletal systems design and implementation, algorithmic skeletons remain absent\nfrom mainstream practice. Cole and other researchers, focused the problem. They\nrecognized the issues affecting skeletal systems and stated a set of principles\nthat have to be tackled in order to make them more effective and to take\nskeletal programming into the parallel mainstream. In this thesis we propose\ntools and models for addressing some among the skeletal programming\nenvironments issues. We describe three novel approaches aimed at enhancing\nskeletons based systems from different angles. First, we present a model we\nconceived that allows algorithmic skeletons customization exploiting the macro\ndata-flow abstraction. Then we present two results about the exploitation of\nmeta-programming techniques for the run-time generation and optimization of\nmacro data-flow graphs. In particular, we show how to generate and how to\noptimize macro data-flow graphs accordingly both to programmers provided\nnon-functional requirements and to execution platform features. The last result\nwe present are the Behavioural Skeletons, an approach aimed at addressing the\nlimitations of skeletal programming environments when used for the development\nof component-based Grid applications. We validated all the approaches\nconducting several test, performed exploiting a set of tools we developed.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2015 11:41:38 GMT"}], "update_date": "2015-03-12", "authors_parsed": [["Dazzi", "Patrizio", ""]]}, {"id": "1503.03460", "submitter": "Mohammed Radi Dr", "authors": "Mohammed Radi", "title": "Efficient Service Broker Policy For Large-Scale Cloud Environments", "comments": null, "journal-ref": "(2015). International Journal of Computer Science Issues, 12(1):\n  85-90", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms, policies, and methodologies are necessary to achieve high user\nsatisfaction and practical utilization in cloud computing by ensuring the\nefficient and fair allocation of every computing resource. Whenever a new job\narrives in cloud environments, the service broker is responsible for selecting\nthe data center that will execute that job. Selecting data centers serves an\nimportant function in enhancing the performance of a cloud environment. This\nstudy proposes a new service broker policy for large-scale cloud applications\nbased on the round-robin algorithm. The proposed policy is implemented and\nevaluated using a CloudAnalyst simulator. It is then compared with three\nexisting policies in terms of overall average response time by using different\nvirtual machine load balancing algorithms. Simulation results show that the\nproposed policy improves the overall average response time relative to that of\nthe other policies.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2015 19:36:00 GMT"}], "update_date": "2015-03-12", "authors_parsed": [["Radi", "Mohammed", ""]]}, {"id": "1503.03553", "submitter": "Teruyoshi Washizawa", "authors": "Yasuhiro Nakahara and Teruyoshi Washizawa", "title": "Accelerating DEM simulations on GPUs by reducing the impact of warp\n  divergences", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A way to accelerate DEM calculations on the GPUs is developed. We examined\nhow warp divergences take place in the contact detection and the force\ncalculations taking account of the GPU architecture. Then we showed a strategy\nto reduce the impact of the warp divergences on the runtime of the DEM force\ncalculations.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2015 01:40:58 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Nakahara", "Yasuhiro", ""], ["Washizawa", "Teruyoshi", ""]]}, {"id": "1503.03579", "submitter": "Thiruselvan Subramanian", "authors": "Thiruselvan Subramanian and Nickolas Savarimuthu", "title": "A Study on Optimized Resource Provisioning in Federated Cloud", "comments": "2013 International Conference on Computing, Cybernetics and\n  Intelligent Information Systems (CCIIS) ,VIT UNIVERSITY, VELLORE, Tamilnadu,\n  India", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing changed the way of computing as utility services offered\nthrough public network. Selecting multiple providers for various computational\nrequirements improves performance and minimizes cost of cloud services than\nchoosing a single cloud provider. Federated cloud improves scalability, cost\nminimization, performance maximization, collaboration with other providers,\nmulti-site deployment for fault tolerance and recovery, reliability and less\nenergy consumption. Both providers and consumers could benefit from federated\ncloud where providers serve the consumers by satisfying Service Level\nAgreement, minimizing overall management and infrastructure cost; consumers get\nbest services with less deployment cost and high availability. Efficient\nprovisioning of resources to consumers in federated cloud is a challenging\ntask. In this paper, the benefits of utilizing services from federated cloud,\narchitecture with various coupling levels, different optimized resource\nprovisioning methods and challenges associated with it are discussed and a\ncomparative study is carried out over these aspects.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2015 04:21:02 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Subramanian", "Thiruselvan", ""], ["Savarimuthu", "Nickolas", ""]]}, {"id": "1503.03635", "submitter": "Kiran Garimella", "authors": "Kiran Garimella, Gianmarco De Francisci Morales, Aristides Gionis,\n  Mauro Sozio", "title": "Scalable Facility Location for Massive Graphs on Pregel-like Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new scalable algorithm for facility location. Facility location\nis a classic problem, where the goal is to select a subset of facilities to\nopen, from a set of candidate facilities F , in order to serve a set of clients\nC. The objective is to minimize the total cost of opening facilities plus the\ncost of serving each client from the facility it is assigned to. In this work,\nwe are interested in the graph setting, where the cost of serving a client from\na facility is represented by the shortest-path distance on the graph. This\nsetting allows to model natural problems arising in the Web and in social media\napplications. It also allows to leverage the inherent sparsity of such graphs,\nas the input is much smaller than the full pairwise distances between all\nvertices.\n  To obtain truly scalable performance, we design a parallel algorithm that\noperates on clusters of shared-nothing machines. In particular, we target\nmodern Pregel-like architectures, and we implement our algorithm on Apache\nGiraph. Our solution makes use of a recent result to build sketches for massive\ngraphs, and of a fast parallel algorithm to find maximal independent sets, as\nbuilding blocks. In so doing, we show how these problems can be solved on a\nPregel-like architecture, and we investigate the properties of these\nalgorithms. Extensive experimental results show that our algorithm scales\ngracefully to graphs with billions of edges, while obtaining values of the\nobjective function that are competitive with a state-of-the-art sequential\nalgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2015 09:09:37 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Garimella", "Kiran", ""], ["Morales", "Gianmarco De Francisci", ""], ["Gionis", "Aristides", ""], ["Sozio", "Mauro", ""]]}, {"id": "1503.04005", "submitter": "Robert Brijder", "authors": "Robert Brijder", "title": "Dominance and Deficiency for Petri Nets and Chemical Reaction Networks", "comments": "16 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by Anderson et al. [J. R. Soc. Interface, 2014] we study the\nlong-term behavior of discrete chemical reaction networks (CRNs). In\nparticular, using techniques from both Petri net theory and CRN theory, we\nprovide a powerful sufficient condition for a structurally-bounded CRN to have\nthe property that none of the non-terminal reactions can fire for all its\nrecurrent configurations. We compare this result and its proof with a related\nresult of Anderson et al. and show its consequences for the case of CRNs with\ndeficiency one.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2015 15:07:30 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2015 09:53:27 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Brijder", "Robert", ""]]}, {"id": "1503.04347", "submitter": "Giovanni Viglietta", "authors": "G.A. Di Luna, P. Flocchini, S. Gan Chaudhuri, F. Poloni, N. Santoro,\n  G. Viglietta", "title": "Mutual Visibility by Luminous Robots Without Collisions", "comments": "60 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a finite set of identical computational entities that can move\nfreely in the Euclidean plane operating in Look-Compute-Move cycles. Let p(t)\ndenote the location of entity p at time t; entity p can see entity q at time t\nif at that time no other entity lies in the line segment p(t)q(t). We consider\nthe basic problem called Mutual Visibility: starting from arbitrary distinct\nlocations, within finite time the entities must reach, without collisions, a\nconfiguration where they all see each other. This problem must be solved by\neach entity autonomously executing the same algorithm. We study this problem in\nthe \"luminous robots\" model; in this generalization of the standard model of\noblivious robots, each entity, called \"robot\", has an externally visible\npersistent light which can assume colors from a fixed set. The case where the\nnumber of colors is c=1 corresponds to the classical model without lights.\n  In this paper we investigate under what conditions luminous robots can solve\nMutual Visibility without collisions and at what cost (i.e., with how many\ncolors). We establish a spectrum of results, depending on the power of the\nadversary, on the number c of colors, and on the a-priori knowledge the robots\nhave about the system. Among such results, we prove that Mutual Visibility can\nalways be solved without collisions in SSynch with c=2 colors and in ASynch\nwith c=3 colors. If an adversary can interrupt and stop a robot moving to its\ncomputed destination, Mutual Visibility is still always solvable without\ncollisions in SSynch with c=3 colors, and, if the robots agree on the direction\nof one axis, also in ASynch. All the results are obtained constructively by\nmeans of novel protocols.\n  As a byproduct of our solutions, we provide the first obstructed-visibility\nsolutions to two classical problems for oblivious robots: Collision-less\nConvergence to a point and Circle Formation.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2015 20:47:44 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2015 07:10:32 GMT"}], "update_date": "2015-07-02", "authors_parsed": [["Di Luna", "G. A.", ""], ["Flocchini", "P.", ""], ["Chaudhuri", "S. Gan", ""], ["Poloni", "F.", ""], ["Santoro", "N.", ""], ["Viglietta", "G.", ""]]}, {"id": "1503.04359", "submitter": "Scott Sallinen", "authors": "Scott Sallinen, Abdullah Gharaibeh, Matei Ripeanu", "title": "Accelerating Direction-Optimized Breadth First Search on Hybrid\n  Architectures", "comments": "As appeared in HeteroPar 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale-free graphs are famously difficult to process efficiently: the\nskewed vertex degree distribution makes it difficult to obtain balanced\npartitioning. Our research instead aims to turn this into an advantage by\npartitioning the workload to match the strength of the individual computing\nelements in a Hybrid, GPU-accelerated architecture. As a proof of concept we\nfocus on the direction-optimized breadth first search algorithm. We present the\nkey graph partitioning, workload allocation, and communication strategies\nrequired for massive concurrency and good overall performance. We show that\nexploiting specialization enables gains as high as 2.4x in terms of\ntime-to-solution and 2.0x in terms of energy efficiency by adding 2 GPUs to a 2\nCPU-only baseline, for synthetic graphs with up to 16 Billion undirected edges\nas well as for large real-world graphs. We also show that, for a capped energy\nenvelope, it is more efficient to add a GPU than an additional CPU. Finally,\nour performance would place us at the top of today's [Green]Graph500 challenges\nfor Scale29 graphs.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2015 22:47:53 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2015 07:16:32 GMT"}], "update_date": "2015-10-05", "authors_parsed": [["Sallinen", "Scott", ""], ["Gharaibeh", "Abdullah", ""], ["Ripeanu", "Matei", ""]]}, {"id": "1503.04422", "submitter": "Pengfei  Chen", "authors": "Pengfei Chen, Yong Qi, Peipei Wang, Li Su, Xinyi Li", "title": "Making Availability as a Service in the Clouds", "comments": "5", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing has achieved great success in modern IT industry as an\nexcellent computing paradigm due to its flexible management and elastic\nresource sharing. To date, cloud computing takes an irrepalceable position in\nour socioeconomic system and influences almost every aspect of our daily life.\nHowever, it is still in its infancy, many problems still exist.Besides the\nhotly-debated security problem, availability is also an urgent issue.With the\nlimited power of availability mechanisms provided in present cloud platform, we\ncan hardly get detailed availability information of current applications such\nas the root causes of availability problem,mean time to failure, etc. Thus a\nnew mechanism based on deep avaliability analysis is neccessary and\nbenificial.Following the prevalent terminology 'XaaS',this paper proposes a new\nwin-win concept for cloud users and providers in term of 'Availability as a\nService' (abbreviated as 'AaaS').The aim of 'AaaS' is to provide comprehensive\nand aimspecific runtime avaliabilty analysis services for cloud users by\nintegrating plent of data-driven and modeldriven approaches. To illustrate this\nconcept, we realize a prototype named 'EagleEye' with all features of 'AaaS'.\nBy subscribing corresponding services in 'EagleEye', cloud users could get\nspecific availability information of their applications deployed in cloud\nplatform. We envision this new kind of service will be merged into the cloud\nmanagement mechanism in the near future.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2015 13:06:10 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Chen", "Pengfei", ""], ["Qi", "Yong", ""], ["Wang", "Peipei", ""], ["Su", "Li", ""], ["Li", "Xinyi", ""]]}, {"id": "1503.04645", "submitter": "Guillaume Latu", "authors": "G. Latu, M. Haefele, J. Bigot, V. Grandgirard, T. Cartier-Michaud, F.\n  Rozar", "title": "Evaluating kernels on Xeon Phi to accelerate Gysela application", "comments": "submitted to ESAIM proceedings for CEMRACS 2014 summer school version\n  reviewed", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work describes the challenges presented by porting parts ofthe Gysela\ncode to the Intel Xeon Phi coprocessor, as well as techniques used for\noptimization, vectorization and tuning that can be applied to other\napplications. We evaluate the performance of somegeneric micro-benchmark on Phi\nversus Intel Sandy Bridge. Several interpolation kernels useful for the Gysela\napplication are analyzed and the performance are shown. Some memory-bound and\ncompute-bound kernels are accelerated by a factor 2 on the Phi device compared\nto Sandy architecture. Nevertheless, it is hard, if not impossible, to reach a\nlarge fraction of the peek performance on the Phi device,especially for\nreal-life applications as Gysela. A collateral benefit of this optimization and\ntuning work is that the execution time of Gysela (using 4D advections) has\ndecreased on a standard architecture such as Intel Sandy Bridge.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2015 13:43:23 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2015 16:46:01 GMT"}], "update_date": "2015-08-04", "authors_parsed": [["Latu", "G.", ""], ["Haefele", "M.", ""], ["Bigot", "J.", ""], ["Grandgirard", "V.", ""], ["Cartier-Michaud", "T.", ""], ["Rozar", "F.", ""]]}, {"id": "1503.04963", "submitter": "Janne H. Korhonen", "authors": "Keren Censor-Hillel, Petteri Kaski, Janne H. Korhonen, Christoph\n  Lenzen, Ami Paz, Jukka Suomela", "title": "Algebraic Methods in the Congested Clique", "comments": "This is work is a merger of arxiv:1412.2109 and arxiv:1412.2667", "journal-ref": null, "doi": "10.1007/s00446-016-0270-2", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we use algebraic methods for studying distance computation and\nsubgraph detection tasks in the congested clique model. Specifically, we adapt\nparallel matrix multiplication implementations to the congested clique,\nobtaining an $O(n^{1-2/\\omega})$ round matrix multiplication algorithm, where\n$\\omega < 2.3728639$ is the exponent of matrix multiplication. In conjunction\nwith known techniques from centralised algorithmics, this gives significant\nimprovements over previous best upper bounds in the congested clique model. The\nhighlight results include:\n  -- triangle and 4-cycle counting in $O(n^{0.158})$ rounds, improving upon the\n$O(n^{1/3})$ triangle detection algorithm of Dolev et al. [DISC 2012],\n  -- a $(1 + o(1))$-approximation of all-pairs shortest paths in $O(n^{0.158})$\nrounds, improving upon the $\\tilde{O} (n^{1/2})$-round $(2 +\no(1))$-approximation algorithm of Nanongkai [STOC 2014], and\n  -- computing the girth in $O(n^{0.158})$ rounds, which is the first\nnon-trivial solution in this model.\n  In addition, we present a novel constant-round combinatorial algorithm for\ndetecting 4-cycles.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 09:31:48 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Censor-Hillel", "Keren", ""], ["Kaski", "Petteri", ""], ["Korhonen", "Janne H.", ""], ["Lenzen", "Christoph", ""], ["Paz", "Ami", ""], ["Suomela", "Jukka", ""]]}, {"id": "1503.05032", "submitter": "Weifeng Liu", "authors": "Weifeng Liu, Brian Vinter", "title": "CSR5: An Efficient Storage Format for Cross-Platform Sparse\n  Matrix-Vector Multiplication", "comments": "12 pages, 10 figures, In Proceedings of the 29th ACM International\n  Conference on Supercomputing (ICS '15)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse matrix-vector multiplication (SpMV) is a fundamental building block\nfor numerous applications. In this paper, we propose CSR5 (Compressed Sparse\nRow 5), a new storage format, which offers high-throughput SpMV on various\nplatforms including CPUs, GPUs and Xeon Phi. First, the CSR5 format is\ninsensitive to the sparsity structure of the input matrix. Thus the single\nformat can support an SpMV algorithm that is efficient both for regular\nmatrices and for irregular matrices. Furthermore, we show that the overhead of\nthe format conversion from the CSR to the CSR5 can be as low as the cost of a\nfew SpMV operations. We compare the CSR5-based SpMV algorithm with 11\nstate-of-the-art formats and algorithms on four mainstream processors using 14\nregular and 10 irregular matrices as a benchmark suite. For the 14 regular\nmatrices in the suite, we achieve comparable or better performance over the\nprevious work. For the 10 irregular matrices, the CSR5 obtains average\nperformance improvement of 17.6\\%, 28.5\\%, 173.0\\% and 293.3\\% (up to 213.3\\%,\n153.6\\%, 405.1\\% and 943.3\\%) over the best existing work on dual-socket Intel\nCPUs, an nVidia GPU, an AMD GPU and an Intel Xeon Phi, respectively. For\nreal-world applications such as a solver with only tens of iterations, the CSR5\nformat can be more practical because of its low-overhead for format conversion.\nThe source code of this work is downloadable at\nhttps://github.com/bhSPARSE/Benchmark_SpMV_using_CSR5\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 13:18:49 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2015 21:28:03 GMT"}], "update_date": "2015-04-13", "authors_parsed": [["Liu", "Weifeng", ""], ["Vinter", "Brian", ""]]}, {"id": "1503.05141", "submitter": "Shiqiang Wang Mr.", "authors": "Shiqiang Wang, Rahul Urgaonkar, Ting He, Murtaza Zafer, Kevin Chan,\n  Kin K. Leung", "title": "Mobility-Induced Service Migration in Mobile Micro-Clouds", "comments": "in Proc. of IEEE MILCOM 2014, Oct. 2014", "journal-ref": null, "doi": "10.1109/MILCOM.2014.145", "report-no": null, "categories": "cs.DC cs.NI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile micro-cloud is an emerging technology in distributed computing, which\nis aimed at providing seamless computing/data access to the edge of the network\nwhen a centralized service may suffer from poor connectivity and long latency.\nDifferent from the traditional cloud, a mobile micro-cloud is smaller and\ndeployed closer to users, typically attached to a cellular basestation or\nwireless network access point. Due to the relatively small coverage area of\neach basestation or access point, when a user moves across areas covered by\ndifferent basestations or access points which are attached to different\nmicro-clouds, issues of service performance and service migration become\nimportant. In this paper, we consider such migration issues. We model the\ngeneral problem as a Markov decision process (MDP), and show that, in the\nspecial case where the mobile user follows a one-dimensional asymmetric random\nwalk mobility model, the optimal policy for service migration is a threshold\npolicy. We obtain the analytical solution for the cost resulting from arbitrary\nthresholds, and then propose an algorithm for finding the optimal thresholds.\nThe proposed algorithm is more efficient than standard mechanisms for solving\nMDPs.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 17:56:48 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Wang", "Shiqiang", ""], ["Urgaonkar", "Rahul", ""], ["He", "Ting", ""], ["Zafer", "Murtaza", ""], ["Chan", "Kevin", ""], ["Leung", "Kin K.", ""]]}, {"id": "1503.05214", "submitter": "Tarek Elgamal", "authors": "Tarek Elgamal, Mohamed Hefeeda", "title": "Analysis of PCA Algorithms in Distributed Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical machine learning algorithms often face scalability bottlenecks when\nthey are applied to large-scale data. Such algorithms were designed to work\nwith small data that is assumed to fit in the memory of one machine. In this\nreport, we analyze different methods for computing an important machine learing\nalgorithm, namely Principal Component Analysis (PCA), and we comment on its\nlimitations in supporting large datasets. The methods are analyzed and compared\nacross two important metrics: time complexity and communication complexity. We\nconsider the worst-case scenarios for both metrics, and we identify the\nsoftware libraries that implement each method. The analysis in this report\nhelps researchers and engineers in (i) understanding the main bottlenecks for\nscalability in different PCA algorithms, (ii) choosing the most appropriate\nmethod and software library for a given application and data set\ncharacteristics, and (iii) designing new scalable PCA algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 20:38:15 GMT"}, {"version": "v2", "created": "Wed, 13 May 2015 12:05:02 GMT"}], "update_date": "2015-05-14", "authors_parsed": [["Elgamal", "Tarek", ""], ["Hefeeda", "Mohamed", ""]]}, {"id": "1503.05271", "submitter": "Qinqin Chen", "authors": "Jiadi Chen, Hang Long, Qiang Zheng, Minyao Xing, Wenbo Wang", "title": "An SMDP-based Resource Management Scheme for Distributed Cloud Systems", "comments": "5 pages, 5 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the resource management problem in geographically distributed\ncloud systems is considered. The Follow Me Cloud concept which enables service\nmigration across federated data centers (DCs) is adopted. Therefore, there are\ntwo types of service requests to the DC, i.e., new requests (NRs) initiated in\nthe local service area and migration requests (MRs) generated when mobile users\nmove across service areas. A novel resource management scheme is proposed to\nhelp the resource manager decide whether to accept the service requests (NRs or\nMRs) or not and determine how much resources should be allocated to each\nservice (if accepted). The optimization objective is to maximize the average\nsystem reward and keep the rejection probability of service requests under a\ncertain threshold. Numerical results indicate that the proposed scheme can\nsignificantly improve the overall system utility as well as the user experience\ncompared with other resource management schemes.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2015 02:47:58 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Chen", "Jiadi", ""], ["Long", "Hang", ""], ["Zheng", "Qiang", ""], ["Xing", "Minyao", ""], ["Wang", "Wenbo", ""]]}, {"id": "1503.05298", "submitter": "Gemma Morral Adell", "authors": "Gemma Morral and Pascal Bianchi", "title": "Distributed on-line multidimensional scaling for self-localization in\n  wireless sensor networks", "comments": "32 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present work considers the localization problem in wireless sensor\nnetworks formed by fixed nodes. Each node seeks to estimate its own position\nbased on noisy measurements of the relative distance to other nodes. In a\ncentralized batch mode, positions can be retrieved (up to a rigid\ntransformation) by applying Principal Component Analysis (PCA) on a so-called\nsimilarity matrix built from the relative distances. In this paper, we propose\na distributed on-line algorithm allowing each node to estimate its own position\nbased on limited exchange of information in the network. Our framework\nencompasses the case of sporadic measurements and random link failures. We\nprove the consistency of our algorithm in the case of fixed sensors. Finally,\nwe provide numerical and experimental results from both simulated and real\ndata. Simulations issued to real data are conducted on a wireless sensor\nnetwork testbed.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2015 08:05:02 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Morral", "Gemma", ""], ["Bianchi", "Pascal", ""]]}, {"id": "1503.05338", "submitter": "Balajee Vamanan", "authors": "Balajee Vamanan, Hamza Bin Sohail, Jahangir Hasan, T. N. Vijaykumar", "title": "TimeTrader: Exploiting Latency Tail to Save Datacenter Energy for\n  On-line Data-Intensive Applications", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datacenters running on-line, data-intensive applications (OLDIs) consume\nsignificant amounts of energy. However, reducing their energy is challenging\ndue to their tight response time requirements. A key aspect of OLDIs is that\neach user query goes to all or many of the nodes in the cluster, so that the\noverall time budget is dictated by the tail of the replies' latency\ndistribution; replies see latency variations both in the network and compute.\nPrevious work proposes to achieve load-proportional energy by slowing down the\ncomputation at lower datacenter loads based directly on response times (i.e.,\nat lower loads, the proposal exploits the average slack in the time budget\nprovisioned for the peak load). In contrast, we propose TimeTrader to reduce\nenergy by exploiting the latency slack in the sub- critical replies which\narrive before the deadline (e.g., 80% of replies are 3-4x faster than the\ntail). This slack is present at all loads and subsumes the previous work's\nload-related slack. While the previous work shifts the leaves' response time\ndistribution to consume the slack at lower loads, TimeTrader reshapes the\ndistribution at all loads by slowing down individual sub-critical nodes without\nincreasing missed deadlines. TimeTrader exploits slack in both the network and\ncompute budgets. Further, TimeTrader leverages Earliest Deadline First\nscheduling to largely decouple critical requests from the queuing delays of\nsub- critical requests which can then be slowed down without hurting critical\nrequests. A combination of real-system measurements and at-scale simulations\nshows that without adding to missed deadlines, TimeTrader saves 15-19% and\n41-49% energy at 90% and 30% loading, respectively, in a datacenter with 512\nnodes, whereas previous work saves 0% and 31-37%.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2015 11:04:01 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Vamanan", "Balajee", ""], ["Sohail", "Hamza Bin", ""], ["Hasan", "Jahangir", ""], ["Vijaykumar", "T. N.", ""]]}, {"id": "1503.05434", "submitter": "Jagadeesh Harshan", "authors": "J. Harshan, Anwitaman Datta, Fr\\'ed\\'erique Oggier", "title": "Compressed Differential Erasure Codes for Efficient Archival of\n  Versioned Data", "comments": "16 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of storing an archive of versioned data\nin a reliable and efficient manner in distributed storage systems. We propose a\nnew storage technique called differential erasure coding (DEC) where the\ndifferences (deltas) between subsequent versions are stored rather than the\nwhole objects, akin to a typical delta encoding technique. However, unlike\ndelta encoding techniques, DEC opportunistically exploits the sparsity (i.e.,\nwhen the differences between two successive versions have few non-zero entries)\nin the updates to store the deltas using compressed sensing techniques applied\nwith erasure coding. We first show that DEC provides significant savings in the\nstorage size for versioned data whenever the update patterns are characterized\nby in-place alterations. Subsequently, we propose a practical DEC framework so\nas to reap storage size benefits against not just in-place alterations but also\nreal-world update patterns such as insertions and deletions that alter the\noverall data sizes. We conduct experiments with several synthetic workloads to\ndemonstrate that the practical variant of DEC provides significant reductions\nin storage overhead (up to 60\\% depending on the workload) compared to baseline\nstorage system which incorporates concepts from Rsync, a delta encoding\ntechnique to store and synchronize data across a network.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 09:49:50 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Harshan", "J.", ""], ["Datta", "Anwitaman", ""], ["Oggier", "Fr\u00e9d\u00e9rique", ""]]}, {"id": "1503.05743", "submitter": "Ken Miura", "authors": "Ken Miura and Tatsuya Harada", "title": "Implementation of a Practical Distributed Calculation System with\n  Browsers and JavaScript, and Application to Distributed Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.MS cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning can achieve outstanding results in various fields. However, it\nrequires so significant computational power that graphics processing units\n(GPUs) and/or numerous computers are often required for the practical\napplication. We have developed a new distributed calculation framework called\n\"Sashimi\" that allows any computer to be used as a distribution node only by\naccessing a website. We have also developed a new JavaScript neural network\nframework called \"Sukiyaki\" that uses general purpose GPUs with web browsers.\nSukiyaki performs 30 times faster than a conventional JavaScript library for\ndeep convolutional neural networks (deep CNNs) learning. The combination of\nSashimi and Sukiyaki, as well as new distribution algorithms, demonstrates the\ndistributed deep learning of deep CNNs only with web browsers on various\ndevices. The libraries that comprise the proposed methods are available under\nMIT license at http://mil-tokyo.github.io/.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2015 12:41:29 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Miura", "Ken", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1503.05829", "submitter": "Benedetta Tondi Benedetta Tondi", "authors": "Andrea Abrardo, Mauro Barni, Kassem Kallas, Benedetta Tondi", "title": "Optimum Fusion of Possibly Corrupted Reports for Distributed Detection\n  in Multi-Sensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most common approach to mitigate the impact that the presence of\nmalicious nodes has on the accuracy of decision fusion schemes consists in\nobserving the behavior of the nodes over a time interval T and then removing\nthe reports of suspect nodes from the fusion process. By assuming that some\na-priori information about the presence of malicious nodes and their behavior\nis available, we show that the information stemming from the suspect nodes can\nbe exploited to further improve the decision fusion accuracy. Specifically, we\nderive the optimum fusion rule and analyze the achievable performance for two\nspecific cases. In the first case, the states of the nodes (corrupted or\nhonest) are independent of each other and the fusion center knows only the\nprobability that a node is malicious. In the second case, the exact number of\ncorrupted nodes is fixed and known to the fusion center. We also investigate\nthe optimum corruption strategy for the malicious nodes, showing that always\nreverting the local decision does not necessarily maximize the loss of\nperformance at the fusion center.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2015 16:28:49 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Abrardo", "Andrea", ""], ["Barni", "Mauro", ""], ["Kallas", "Kassem", ""], ["Tondi", "Benedetta", ""]]}, {"id": "1503.05882", "submitter": "Qinqin Chen", "authors": "Jiadi Chen, Qiang Zheng, Hang Long, Wenbo Wang", "title": "Divisible Load Scheduling in Mobile Grid based on Stackelberg Pricing\n  Game", "comments": "5 pages, 3 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, it has become feasible to use mobile nodes as contributing entities\nin computing systems. In this paper, we consider a computational grid in which\nthe mobile devices can share their idle resources to realize parallel\nprocessing. The overall computing task can be arbitrarily partitioned into\nmultiple subtasks to be distributed to mobile resource providers (RPs). In this\nprocess, the computation load scheduling problem is highlighted. Based on the\noptimization objective, i.e., minimizing the task makespan, a buyer-seller\nmodel in which the task sponsor can inspire the SPs to share their computing\nresources by paying certain profits, is proposed. The Stackelberg Pricing Game\n(SPG) is employed to obtain the optimal price and shared resource amount of\neach SP. Finally, we evaluate the performance of the proposed algorithm by\nsystem simulation and the results indicate that the SPG-based load scheduling\nalgorithm can significantly improve the time gain in mobile grid systems.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2015 02:52:18 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Chen", "Jiadi", ""], ["Zheng", "Qiang", ""], ["Long", "Hang", ""], ["Wang", "Wenbo", ""]]}, {"id": "1503.06029", "submitter": "Pawe{\\l} Rz\\k{a}\\.zewski", "authors": "Krzysztof Kaczmarski, Pawe{\\l} Rz\\k{a}\\.zewski, Albert Wolant", "title": "Massively Parallel Construction of the Cell Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion planning is an important and well-studied field of robotics. A typical\napproach to finding a route is to construct a {\\em cell graph} representing a\nscene and then to find a path in such a graph. In this paper we present and\nanalyze parallel algorithms for constructing the cell graph on a SIMD-like GPU\nprocessor.\n  Additionally, we present a new implementation of the dictionary data type on\na GPU device. In the contrary to hash tables, which are common in GPU\nalgorithms, it uses a search tree in which all values are kept in leaves. With\nsuch a structure we can effectively perform dictionary operations on a set of\nlong vectors over a limited alphabet.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2015 10:01:20 GMT"}], "update_date": "2015-03-23", "authors_parsed": [["Kaczmarski", "Krzysztof", ""], ["Rz\u0105\u017cewski", "Pawe\u0142", ""], ["Wolant", "Albert", ""]]}, {"id": "1503.06182", "submitter": "Walter T. Giele", "authors": "John M. Campbell, R. Keith Ellis, Walter T. Giele", "title": "A Multi-Threaded Version of MCFM", "comments": "7 pages, 3 figures, MCFM-7.0 which runs under the OpenMP protocol as\n  described in this paper can be downloaded from http://mcfm.fnal.gov", "journal-ref": null, "doi": null, "report-no": "Fermilab-PUB-15-043-T", "categories": "physics.comp-ph cs.DC cs.MS hep-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on our findings modifying MCFM using OpenMP to implement\nmulti-threading. By using OpenMP, the modified MCFM will execute on any\nprocessor, automatically adjusting to the number of available threads. We\nmodified the integration routine VEGAS to distribute the event evaluation over\nthe threads, while combining all events at the end of every iteration to\noptimize the numerical integration. Special care has been taken that the\nresults of the Monte Carlo integration are independent of the number of threads\nused, to facilitate the validation of the OpenMP version of MCFM.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2015 18:02:33 GMT"}], "update_date": "2015-03-23", "authors_parsed": [["Campbell", "John M.", ""], ["Ellis", "R. Keith", ""], ["Giele", "Walter T.", ""]]}, {"id": "1503.06384", "submitter": "Matthias Boehm", "authors": "Matthias Boehm", "title": "Costing Generated Runtime Execution Plans for Large-Scale Machine\n  Learning Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Declarative large-scale machine learning (ML) aims at the specification of ML\nalgorithms in a high-level language and automatic generation of hybrid runtime\nexecution plans ranging from single node, in-memory computations to distributed\ncomputations on MapReduce (MR) or similar frameworks like Spark. The\ncompilation of large-scale ML programs exhibits many opportunities for\nautomatic optimization. Advanced cost-based optimization techniques\nrequire---as a fundamental precondition---an accurate cost model for evaluating\nthe impact of optimization decisions. In this paper, we share insights into a\nsimple and robust yet accurate technique for costing alternative runtime\nexecution plans of ML programs. Our cost model relies on generating and costing\nruntime plans in order to automatically reflect all successive optimization\nphases. Costing runtime plans also captures control flow structures such as\nloops and branches, and a variety of cost factors like IO, latency, and\ncomputation costs. Finally, we linearize all these cost factors into a single\nmeasure of expected execution time. Within SystemML, this cost model is\nleveraged by several advanced optimizers like resource optimization and global\ndata flow optimization. We share our lessons learned in order to provide\nfoundations for the optimization of ML programs.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2015 05:00:08 GMT"}], "update_date": "2015-03-24", "authors_parsed": [["Boehm", "Matthias", ""]]}, {"id": "1503.06424", "submitter": "Juan Juli\\'an Merelo-Guerv\\'os Pr.", "authors": "Juan Juli\\'an Merelo-Guerv\\'os, Pablo Garc\\'ia-S\\'anchez", "title": "Modeling browser-based distributed evolutionary computation systems", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NE cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  From the era of big science we are back to the \"do it yourself\", where you do\nnot have any money to buy clusters or subscribe to grids but still have\nalgorithms that crave many computing nodes and need them to measure\nscalability. Fortunately, this coincides with the era of big data, cloud\ncomputing, and browsers that include JavaScript virtual machines. Those are the\nreasons why this paper will focus on two different aspects of volunteer or\nfreeriding computing: first, the pragmatic: where to find those resources,\nwhich ones can be used, what kind of support you have to give them; and then,\nthe theoretical: how evolutionary algorithms can be adapted to an environment\nin which nodes come and go, have different computing capabilities and operate\nin complete asynchrony of each other. We will examine the setup needed to\ncreate a very simple distributed evolutionary algorithm using JavaScript and\nthen find a model of how users react to it by collecting data from several\nexperiments featuring different classical benchmark functions.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2015 13:20:57 GMT"}], "update_date": "2015-03-24", "authors_parsed": [["Merelo-Guerv\u00f3s", "Juan Juli\u00e1n", ""], ["Garc\u00eda-S\u00e1nchez", "Pablo", ""]]}, {"id": "1503.06479", "submitter": "Majid Khabbazian", "authors": "Majid Khabbazian", "title": "Multi-Version Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a simple lower bound for the multi-version coding problem\nformulated in [1]. We also propose simple algorithms that almost match the\nlower bound derived. Another lower bound is proven for an extended version of\nthe multi-version coding problem introduced in [2].\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2015 21:06:23 GMT"}], "update_date": "2015-03-24", "authors_parsed": [["Khabbazian", "Majid", ""]]}, {"id": "1503.06532", "submitter": "Kamran Karimi", "authors": "Kamran Karimi", "title": "The Feasibility of Using OpenCL Instead of OpenMP for Parallel CPU\n  Programming", "comments": "8 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OpenCL, along with CUDA, is one of the main tools used to program GPGPUs.\nHowever, it allows running the same code on multi-core CPUs too, making it a\nrival for the long-established OpenMP. In this paper we compare OpenCL and\nOpenMP when developing and running compute-heavy code on a CPU. Both ease of\nprogramming and performance aspects are considered. Since, unlike a GPU, no\nmemory copy operation is involved, our comparisons measure the code generation\nquality, as well as thread management efficiency of OpenCL and OpenMP. We\nevaluate the performance of these development tools under two conditions: a\nlarge number of short-running compute-heavy parallel code executions, when more\nthread management is performed, and a small number of long-running parallel\ncode executions, when less thread management is required. The results show that\nOpenCL and OpenMP each win in one of the two conditions. We argue that while\nusing OpenMP requires less setup, OpenCL can be a viable substitute for OpenMP\nfrom a performance point of view, especially when a high number of thread\ninvocations is required. We also provide a number of potential pitfalls to\nwatch for when moving from OpenMP to OpenCL.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2015 05:15:00 GMT"}], "update_date": "2015-03-24", "authors_parsed": [["Karimi", "Kamran", ""]]}, {"id": "1503.06558", "submitter": "Debajyoti Mukhopadhyay Prof.", "authors": "Manali Raje and Debajyoti Mukhopadhyay", "title": "Algorithm for Back-up and Authentication of Data Stored on Cloud", "comments": "4 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Everyday a huge amount of data is generated in Cloud Computing. The\nmaintenance of this electronic data needs some extremely efficient services.\nThere is a need to properly collect this data, check for its authenticity and\ndevelop proper backups is needed. The Objective of this paper is to provide\nResponse Server, some solution for the backup of data and its restoration,\nusing the Cloud. Thecollection of the data is to be done from the client and\nthen the data should be sent to a central location. This process is a platform\nindependent one. The data can then be used as required. The Remote Backup\nServer facilitates the collection of information from any remote location and\nprovides services to recover the data in case of loss. The authentication of\nthe user is done by using the Asymmetric key algorithm which will in turn leads\nto the authentication of the data.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2015 09:00:23 GMT"}], "update_date": "2015-03-24", "authors_parsed": [["Raje", "Manali", ""], ["Mukhopadhyay", "Debajyoti", ""]]}, {"id": "1503.06600", "submitter": "Mansaf Alam Dr", "authors": "Kashish Ara Shakil, Mansaf Alam (Member, IAENG) and Shuchi Sethi", "title": "Exploring Non-Homogeneity and Dynamicity of High Scale Cloud through\n  Hive and Pig", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing deals with heterogeneity and dynamicity at all levels and\ntherefore there is a need to manage resources in such an environment and\nproperly allocate them. Resource planning and scheduling requires a proper\nunderstanding of arrival patterns and scheduling of resources. Study of\nworkloads can aid in proper understanding of their associated environment.\nGoogle has released its latest version of cluster trace, trace version 2.1 in\nNovember 2014.The trace consists of cell information of about 29 days spanning\nacross 700k jobs. This paper deals with statistical analysis of this cluster\ntrace. Since the size of trace is very large, Hive which is a Hadoop\ndistributed file system (HDFS) based platform for querying and analysis of Big\ndata, has been used. Hive was accessed through its Beeswax interface. The data\nwas imported into HDFS through HCatalog. Apart from Hive, Pig which is a\nscripting language and provides abstraction on top of Hadoop was used. To the\nbest of our knowledge the analytical method adopted by us is novel and has\nhelped in gaining several useful insights. Clustering of jobs and arrival time\nhas been done in this paper using K-means++ clustering followed by analysis of\ndistribution of arrival time of jobs which revealed weibull distribution while\nresource usage was close to zip-f like distribution and process runtimes\nrevealed heavy tailed distribution.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2015 11:25:14 GMT"}], "update_date": "2015-03-24", "authors_parsed": [["Shakil", "Kashish Ara", "", "Member, IAENG"], ["Alam", "Mansaf", "", "Member, IAENG"], ["Sethi", "Shuchi", ""]]}, {"id": "1503.06702", "submitter": "Joel Rybicki", "authors": "Christoph Lenzen, Joel Rybicki, Jukka Suomela", "title": "Towards Optimal Synchronous Counting", "comments": "17 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a complete communication network of $n$ nodes, where the nodes\nreceive a common clock pulse. We study the synchronous $c$-counting problem:\ngiven any starting state and up to $f$ faulty nodes with arbitrary behaviour,\nthe task is to eventually have all correct nodes counting modulo $c$ in\nagreement. Thus, we are considering algorithms that are self-stabilizing\ndespite Byzantine failures. In this work, we give new algorithms for the\nsynchronous counting problem that (1) are deterministic, (2) have linear\nstabilisation time in $f$, (3) use a small number of states, and (4) achieve\nalmost-optimal resilience. Prior algorithms either resort to randomisation, use\na large number of states, or have poor resilience. In particular, we achieve an\nexponential improvement in the space complexity of deterministic algorithms,\nwhile still achieving linear stabilisation time and almost-linear resilience.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2015 16:12:32 GMT"}], "update_date": "2015-03-24", "authors_parsed": [["Lenzen", "Christoph", ""], ["Rybicki", "Joel", ""], ["Suomela", "Jukka", ""]]}, {"id": "1503.06974", "submitter": "Sabri Pllana", "authors": "Erika Abraham, Costas Bekas, Ivona Brandic, Samir Genaim, Einar Broch\n  Johnsen, Ivan Kondov, Sabri Pllana, Achim Streit", "title": "Challenges and Recommendations for Preparing HPC Applications for\n  Exascale", "comments": "18th International Conference on Network-Based Information Systems\n  (NBiS 2015). 2-4 September 2015 in Tamkang, Taiwan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the HPC community is working towards the development of the first\nExaflop computer (expected around 2020), after reaching the Petaflop milestone\nin 2008 still only few HPC applications are able to fully exploit the\ncapabilities of Petaflop systems. In this paper we argue that efforts for\npreparing HPC applications for Exascale should start before such systems become\navailable. We identify challenges that need to be addressed and recommend\nsolutions in key areas of interest, including formal modeling, static analysis\nand optimization, runtime analysis and optimization, and autonomic computing.\nFurthermore, we outline a conceptual framework for porting HPC applications to\nfuture Exascale computing systems and propose steps for its implementation.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2015 10:17:19 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2015 08:20:29 GMT"}], "update_date": "2015-06-10", "authors_parsed": [["Abraham", "Erika", ""], ["Bekas", "Costas", ""], ["Brandic", "Ivona", ""], ["Genaim", "Samir", ""], ["Johnsen", "Einar Broch", ""], ["Kondov", "Ivan", ""], ["Pllana", "Sabri", ""], ["Streit", "Achim", ""]]}, {"id": "1503.07038", "submitter": "Snehanshu Saha", "authors": "G Arun Kumar, Snehanshu Saha, Aravind Sundaresan, Bidisha Goswami", "title": "A QoS aware Novel Probabilistic strategy for Dynamic Resource Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes a two player game based strategy for resource allocation\nin service computing domain such as cloud, grid etc. The players are modeled as\ndemand/workflows for the resource and represent multiple types of qualitative\nand quantitative factors. The proposed strategy will classify them in two\nclasses. The proposed system would forecast outcome using a priori information\navailable and measure/estimate existing parameters such as utilization and\ndelay in an optimal load-balanced paradigm.\n  Keywords: Load balancing; service computing; Logistic Regression;\nprobabilistic estimation\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2015 13:52:51 GMT"}], "update_date": "2015-03-25", "authors_parsed": [["Kumar", "G Arun", ""], ["Saha", "Snehanshu", ""], ["Sundaresan", "Aravind", ""], ["Goswami", "Bidisha", ""]]}, {"id": "1503.07241", "submitter": "Narayanan Sundaram", "authors": "Narayanan Sundaram, Nadathur Rajagopalan Satish, Md Mostofa Ali\n  Patwary, Subramanya R Dulloor, Satya Gautam Vadlamudi, Dipankar Das and\n  Pradeep Dubey", "title": "GraphMat: High performance graph analytics made productive", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the growing importance of large-scale graph analytics, there is a need\nto improve the performance of graph analysis frameworks without compromising on\nproductivity. GraphMat is our solution to bridge this gap between a\nuser-friendly graph analytics framework and native, hand-optimized code.\nGraphMat functions by taking vertex programs and mapping them to high\nperformance sparse matrix operations in the backend. We get the productivity\nbenefits of a vertex programming framework without sacrificing performance.\nGraphMat is in C++, and we have been able to write a diverse set of graph\nalgorithms in this framework with the same effort compared to other vertex\nprogramming frameworks. GraphMat performs 1.2-7X faster than high performance\nframeworks such as GraphLab, CombBLAS and Galois. It achieves better multicore\nscalability (13-15X on 24 cores) than other frameworks and is 1.2X off native,\nhand-optimized code on a variety of different graph algorithms. Since GraphMat\nperformance depends mainly on a few scalable and well-understood sparse matrix\noperations, GraphMatcan naturally benefit from the trend of increasing\nparallelism on future hardware.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2015 00:10:50 GMT"}], "update_date": "2015-03-26", "authors_parsed": [["Sundaram", "Narayanan", ""], ["Satish", "Nadathur Rajagopalan", ""], ["Patwary", "Md Mostofa Ali", ""], ["Dulloor", "Subramanya R", ""], ["Vadlamudi", "Satya Gautam", ""], ["Das", "Dipankar", ""], ["Dubey", "Pradeep", ""]]}, {"id": "1503.07473", "submitter": "Debajyoti Mukhopadhyay Prof.", "authors": "Manali Raje and Debajyoti Mukhopadhyay", "title": "A Survey on Backup of Data on Remote Server", "comments": "4 pages, 3 figures in IJSR, Vol.3, Issue 12, December 2014, ISSN:\n  2319-7064", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large amount of electronic data is generated in Cloud computing every day.\nEfficient maintenance of this data requires proper services. Hence a method to\ncollect data securely, by protecting and developing backups is mentioned. The\nObjective is to provide Auto Response Server, better solutions for data backup\nand restoring using Cloud. Data can be collected and sent to a centralized\nrepository in a platform independent format without any network consideration.\nThis data can then be used according to the requirement. The purpose of this\nparticular Remote Backup Server is to collect information from any remote\nlocation even if network connectivity is not available at that point of time\nand provide proper services as well as to recover data in case of loss.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2015 17:50:31 GMT"}], "update_date": "2015-03-26", "authors_parsed": [["Raje", "Manali", ""], ["Mukhopadhyay", "Debajyoti", ""]]}, {"id": "1503.07759", "submitter": "Edvard Pedersen", "authors": "Edvard Pedersen and Lars Ailo Bongo", "title": "Large-scale Biological Meta-database Management", "comments": "10 pages, 6 figures, 4 tables", "journal-ref": null, "doi": "10.1016/j.future.2016.02.010", "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Up-to-date meta-databases are vital for the analysis of biological data.\nHowever,the current exponential increase in biological data leads to\nexponentially increasing meta-database sizes. Large-scale meta-database\nmanagement is therefore an important challenge for production platforms\nproviding services for biological data analysis. In particular, there is often\na need either to run an analysis with a particular version of a meta-database,\nor to rerun an analysis with an updated meta-database. We present our GeStore\napproach for biological meta-database management. It provides efficient storage\nand runtime generation of specific meta-database versions, and efficient\nincremental updates for biological data analysis tools. The approach is\ntransparent to the tools, and we provide a framework that makes it easy to\nintegrate GeStore with biological data analysis frameworks. We present the\nGeStore system, an evaluation of the performance characteristics of the system,\nand an evaluation of the benefits for a biological data analysis workflow.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2015 15:07:16 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2015 15:16:44 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2016 11:43:18 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Pedersen", "Edvard", ""], ["Bongo", "Lars Ailo", ""]]}, {"id": "1503.07905", "submitter": "Efrosini Sourla MSc", "authors": "Efrosini Sourla, Spyros Sioutas, Kostas Tsichlas and Christos\n  Zaroliagis", "title": "D3-Tree: A Dynamic Distributed Deterministic Load - Balancer for\n  decentralized tree structures", "comments": "32 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose D3-Tree, a dynamic distributed deterministic\nstructure for data management in decentralized networks. We present in brief\nthe theoretical algorithmic analysis, in which our proposed structure is based\non, and we describe thoroughly the key aspects of the implementation.\nConducting experiments, we verify that the implemented structure outperforms\nother well-known hierarchical tree-based structures, since it provides better\ncomplexities regarding load-balancing operations. More specifically, the\nstructure achieves a logarithmic amortized bound, using an efficient\ndeterministic load-balancing mechanism, which is general enough to be applied\nto other hierarchical tree-based structures. Moreover, we investigate the\nstructure's fault tolerance, which hasn't been sufficiently tackled in previous\nwork, both theoretically and through rigorous experimentation. We prove that\nD3-Tree is highly fault tolerant, since, even for massive node failures, it\nachieves a significant success rate in element queries. Afterwards we go one\nstep further, in order to achieve sub-logarithmic complexity and propose the\nART+ structure (Autonomous Range Tree), exploiting the excellent performance of\nD3-Tree. ART+ is a fully dynamic and fault-tolerant structure, which achieves\nsub-logarithmic performance for query and update operations and performs\nload-balancing in sub-logarithmic amortized cost.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2015 21:14:34 GMT"}], "update_date": "2015-03-30", "authors_parsed": [["Sourla", "Efrosini", ""], ["Sioutas", "Spyros", ""], ["Tsichlas", "Kostas", ""], ["Zaroliagis", "Christos", ""]]}, {"id": "1503.07994", "submitter": "Francesco Pagano", "authors": "Ernesto Damiani, Francesco Pagano, Davide Pagano", "title": "iPrivacy: a Distributed Approach to Privacy on the Cloud", "comments": "13 pages, International Journal on Advances in Security 2011 vol.4 no\n  3 & 4. arXiv admin note: substantial text overlap with arXiv:1012.0759,\n  arXiv:1109.3555", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing adoption of Cloud storage poses a number of privacy issues.\nUsers wish to preserve full control over their sensitive data and cannot accept\nthat it to be accessible by the remote storage provider. Previous research was\nmade on techniques to protect data stored on untrusted servers; however we\nargue that the cloud architecture presents a number of open issues. To handle\nthem, we present an approach where confidential data is stored in a highly\ndistributed database, partly located on the cloud and partly on the clients.\nData is shared in a secure manner using a simple grant-and-revoke permission of\nshared data and we have developed a system test implementation, using an\nin-memory RDBMS with row-level data encryption for fine-grained data access\ncontrol\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2015 09:09:38 GMT"}], "update_date": "2015-03-30", "authors_parsed": [["Damiani", "Ernesto", ""], ["Pagano", "Francesco", ""], ["Pagano", "Davide", ""]]}, {"id": "1503.08104", "submitter": "Charalampos Chalios", "authors": "Charalampos Chalios, Dimitrios S. Nikolopoulos, Enrique S.\n  Quintana-Orti", "title": "Evaluating Asymmetric Multicore Systems-on-Chip using Iso-Metrics", "comments": "Presented at HiPEAC EEHCO '15, 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The end of Dennard scaling has pushed power consumption into a first order\nconcern for current systems, on par with performance. As a result,\nnear-threshold voltage computing (NTVC) has been proposed as a potential means\nto tackle the limited cooling capacity of CMOS technology. Hardware operating\nin NTV consumes significantly less power, at the cost of lower frequency, and\nthus reduced performance, as well as increased error rates. In this paper, we\ninvestigate if a low-power systems-on-chip, consisting of ARM's asymmetric\nbig.LITTLE technology, can be an alternative to conventional high performance\nmulticore processors in terms of power/energy in an unreliable scenario. For\nour study, we use the Conjugate Gradient solver, an algorithm representative of\nthe computations performed by a large range of scientific and engineering\ncodes.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2015 15:10:43 GMT"}], "update_date": "2015-03-30", "authors_parsed": [["Chalios", "Charalampos", ""], ["Nikolopoulos", "Dimitrios S.", ""], ["Quintana-Orti", "Enrique S.", ""]]}, {"id": "1503.08169", "submitter": "Azalia Mirhoseini", "authors": "Azalia Mirhoseini, Eva L. Dyer, Ebrahim.M. Songhori, Richard G.\n  Baraniuk, Farinaz Koushanfar", "title": "RankMap: A Platform-Aware Framework for Distributed Learning from Dense\n  Datasets", "comments": "13 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces RankMap, a platform-aware end-to-end framework for\nefficient execution of a broad class of iterative learning algorithms for\nmassive and dense datasets. Our framework exploits data structure to factorize\nit into an ensemble of lower rank subspaces. The factorization creates sparse\nlow-dimensional representations of the data, a property which is leveraged to\ndevise effective mapping and scheduling of iterative learning algorithms on the\ndistributed computing machines. We provide two APIs, one matrix-based and one\ngraph-based, which facilitate automated adoption of the framework for\nperforming several contemporary learning applications. To demonstrate the\nutility of RankMap, we solve sparse recovery and power iteration problems on\nvarious real-world datasets with up to 1.8 billion non-zeros. Our evaluations\nare performed on Amazon EC2 and IBM iDataPlex servers using up to 244 cores.\nThe results demonstrate up to two orders of magnitude improvements in memory\nusage, execution speed, and bandwidth compared with the best reported prior\nwork, while achieving the same level of learning accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2015 18:02:51 GMT"}, {"version": "v2", "created": "Thu, 27 Oct 2016 14:29:44 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["Mirhoseini", "Azalia", ""], ["Dyer", "Eva L.", ""], ["Songhori", "Ebrahim. M.", ""], ["Baraniuk", "Richard G.", ""], ["Koushanfar", "Farinaz", ""]]}, {"id": "1503.08192", "submitter": "Choon Yik Tang", "authors": "Mu Yang and Choon Yik Tang", "title": "Distributed Estimation of Graph Spectrum", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a two-stage distributed algorithm that enables\nnodes in a graph to cooperatively estimate the spectrum of a matrix $W$\nassociated with the graph, which includes the adjacency and Laplacian matrices\nas special cases. In the first stage, the algorithm uses a discrete-time linear\niteration and the Cayley-Hamilton theorem to convert the problem into one of\nsolving a set of linear equations, where each equation is known to a node. In\nthe second stage, if the nodes happen to know that $W$ is cyclic, the algorithm\nuses a Lyapunov approach to asymptotically solve the equations with an\nexponential rate of convergence. If they do not know whether $W$ is cyclic, the\nalgorithm uses a random perturbation approach and a structural controllability\nresult to approximately solve the equations with an error that can be made\nsmall. Finally, we provide simulation results that illustrate the algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2015 19:30:26 GMT"}], "update_date": "2015-03-30", "authors_parsed": [["Yang", "Mu", ""], ["Tang", "Choon Yik", ""]]}, {"id": "1503.08294", "submitter": "Giacomo Parigi", "authors": "Giacomo Parigi, Angelo Stramieri, Danilo Pau, Marco Piastra", "title": "A Multi-signal Variant for the GPU-based Parallelization of Growing\n  Self-Organizing Networks", "comments": "17 pages", "journal-ref": "Informatics in Control, Automation and Robotics - 9th\n  International Conference, ICINCO 2012 Rome, Italy, July 28-31, 2012 Revised\n  Selected Papers. Part I, pp. 83-100", "doi": "10.1007/978-3-319-03500-0_6", "report-no": null, "categories": "cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the many possible approaches for the parallelization of self-organizing\nnetworks, and in particular of growing self-organizing networks, perhaps the\nmost common one is producing an optimized, parallel implementation of the\nstandard sequential algorithms reported in the literature. In this paper we\nexplore an alternative approach, based on a new algorithm variant specifically\ndesigned to match the features of the large-scale, fine-grained parallelism of\nGPUs, in which multiple input signals are processed at once. Comparative tests\nhave been performed, using both parallel and sequential implementations of the\nnew algorithm variant, in particular for a growing self-organizing network that\nreconstructs surfaces from point clouds. The experimental results show that\nthis approach allows harnessing in a more effective way the intrinsic\nparallelism that the self-organizing networks algorithms seem intuitively to\nsuggest, obtaining better performances even with networks of smaller size.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2015 10:51:55 GMT"}], "update_date": "2015-03-31", "authors_parsed": [["Parigi", "Giacomo", ""], ["Stramieri", "Angelo", ""], ["Pau", "Danilo", ""], ["Piastra", "Marco", ""]]}, {"id": "1503.08570", "submitter": "Li Ning Dr.", "authors": "Li Ning and Dongxiao Yu and Yong Zhang and Yuexuan Wang and Francis\n  C.M. Lau and Shenzhong Feng", "title": "Uniform Information Exchange in Multi-channel Wireless Ad Hoc Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the information exchange problem, k packets that are initially maintained\nby k nodes need to be disseminated to the whole network as quickly as possible.\nWe consider this problem in single-hop multi- channel networks of n nodes, and\npropose a uniform protocol that with high probability accomplishes the\ndissemination in O(k/F + F \\cdot log n) rounds, assuming F available channels\nand collision detection. This result is asymptotically optimal when k is large\n(k \\geq F^2 \\cdot log n). To our knowledge, this is the first uniform protocol\nfor information exchange in multi-channel networks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2015 07:31:15 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Ning", "Li", ""], ["Yu", "Dongxiao", ""], ["Zhang", "Yong", ""], ["Wang", "Yuexuan", ""], ["Lau", "Francis C. M.", ""], ["Feng", "Shenzhong", ""]]}, {"id": "1503.08659", "submitter": "Sophie Spirkl", "authors": "Stephan Held and Sophie Theresa Spirkl", "title": "Binary Adder Circuits of Asymptotically Minimum Depth, Linear Size, and\n  Fan-Out Two", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of constructing fast and small binary adder circuits.\nAmong widely-used adders, the Kogge-Stone adder is often considered the\nfastest, because it computes the carry bits for two $n$-bit numbers (where $n$\nis a power of two) with a depth of $2\\log_2 n$ logic gates, size $4 n\\log_2 n$,\nand all fan-outs bounded by two. Fan-outs of more than two are avoided, because\nthey lead to the insertion of repeaters for repowering the signal and\nadditional depth in the physical implementation. However, the depth bound of\nthe Kogge-Stone adder is off by a factor of two from the lower bound of $\\log_2\nn$. This bound is achieved asymptotically in two separate constructions by\nBrent and Krapchenko. Brent's construction gives neither a bound on the fan-out\nnor the size, while Krapchenko's adder has linear size, but can have up to\nlinear fan-out. With a fan-out bound of two, neither construction achieves a\ndepth of less than $2 \\log_2 n$. In a further approach, Brent and Kung proposed\nan adder with linear size and fan-out two, but twice the depth of the\nKogge-Stone adder. These results are 33-43 years old and no substantial\ntheoretical improvement for has been made since then.\n  In this paper we integrate the individual advantages of all previous adder\ncircuits into a new family of full adders, the first to improve on the depth\nbound of $2\\log_2 n$ while maintaining a fan-out bound of two. Our adders\nachieve an asymptotically optimum logic gate depth of $\\log_2 n + o(\\log_2 n)$\nand linear size $\\mathcal {O}(n)$.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2015 13:02:53 GMT"}, {"version": "v2", "created": "Sun, 17 May 2015 09:56:26 GMT"}, {"version": "v3", "created": "Tue, 17 Jan 2017 21:53:09 GMT"}], "update_date": "2017-01-19", "authors_parsed": [["Held", "Stephan", ""], ["Spirkl", "Sophie Theresa", ""]]}, {"id": "1503.08715", "submitter": "Andrey Shchurov", "authors": "Andrey A. Shchurov", "title": "Industrial Computing Systems: A Case Study of Fault Tolerance Analysis", "comments": "6 figures", "journal-ref": "International Journal of Computer Trends and Technology (IJCTT)\n  V21(1):50-55, March 2015. ISSN:2231-2803", "doi": "10.14445/22312803/IJCTT-V21P110", "report-no": null, "categories": "cs.SY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fault tolerance is a key factor of industrial computing systems design. But\nin practical terms, these systems, like every commercial product, are under\ngreat financial constraints and they have to remain in operational state as\nlong as possible due to their commercial attractiveness. This work provides an\nanalysis of the instantaneous failure rate of these systems at the end of their\nlife-time period. On the basis of this analysis, we determine the effect of a\ncritical increase in the system failure rate and the basic condition of its\nexistence. The next step determines the maintenance scheduling which can help\nto avoid this effect and to extend the system life-time in fault-tolerant mode.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2015 15:38:45 GMT"}], "update_date": "2015-03-31", "authors_parsed": [["Shchurov", "Andrey A.", ""]]}, {"id": "1503.08809", "submitter": "James Briggs Mr", "authors": "J. P. Briggs, S. J. Pennycook, J. R. Fergusson, J. J\\\"aykk\\\"a, E. P.\n  S. Shellard", "title": "Separable projection integrals for higher-order correlators of the\n  cosmic microwave sky: Acceleration by factors exceeding 100", "comments": "Accepted by Journal of Computational Physics", "journal-ref": null, "doi": "10.1016/j.jcp.2016.01.019", "report-no": null, "categories": "cs.DC astro-ph.CO cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a case study describing efforts to optimise and modernise \"Modal\",\nthe simulation and analysis pipeline used by the Planck satellite experiment\nfor constraining general non-Gaussian models of the early universe via the\nbispectrum (or three-point correlator) of the cosmic microwave background\nradiation. We focus on one particular element of the code: the projection of\nbispectra from the end of inflation to the spherical shell at decoupling, which\ndefines the CMB we observe today. This code involves a three-dimensional inner\nproduct between two functions, one of which requires an integral, on a\nnon-rectangular domain containing a sparse grid. We show that by employing\nseparable methods this calculation can be reduced to a one-dimensional\nsummation plus two integrations, reducing the overall dimensionality from four\nto three. The introduction of separable functions also solves the issue of the\nnon-rectangular sparse grid. This separable method can become unstable in\ncertain cases and so the slower non-separable integral must be calculated\ninstead. We present a discussion of the optimisation of both approaches. We\nshow significant speed-ups of ~100x, arising from a combination of algorithmic\nimprovements and architecture-aware optimisations targeted at improving thread\nand vectorisation behaviour. The resulting MPI/OpenMP hybrid code is capable of\nexecuting on clusters containing processors and/or coprocessors, with\nstrong-scaling efficiency of 98.6% on up to 16 nodes. We find that a single\ncoprocessor outperforms two processor sockets by a factor of 1.3x and that\nrunning the same code across a combination of both microarchitectures improves\nperformance-per-node by a factor of 3.38x. By making bispectrum calculations\ncompetitive with those for the power spectrum (or two-point correlator) we are\nnow able to consider joint analysis for cosmological science exploitation of\nnew data.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2015 19:31:24 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2015 12:31:14 GMT"}, {"version": "v3", "created": "Mon, 7 Sep 2015 15:53:07 GMT"}, {"version": "v4", "created": "Tue, 26 Jan 2016 13:20:01 GMT"}], "update_date": "2016-01-27", "authors_parsed": [["Briggs", "J. P.", ""], ["Pennycook", "S. J.", ""], ["Fergusson", "J. R.", ""], ["J\u00e4ykk\u00e4", "J.", ""], ["Shellard", "E. P. S.", ""]]}, {"id": "1503.08877", "submitter": "Michael Isard", "authors": "Michael Isard, Mart\\'in Abadi", "title": "Falkirk Wheel: Rollback Recovery for Dataflow Systems", "comments": "DRAFT work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new model for rollback recovery in distributed dataflow systems.\nWe explain existing rollback schemes by assigning a logical time to each event\nsuch as a message delivery. If some processors fail during an execution, the\nsystem rolls back by selecting a set of logical times for each processor. The\neffect of events at times within the set is retained or restored from saved\nstate, while the effect of other events is undone and re-executed. We show\nthat, by adopting different logical time \"domains\" at different processors, an\napplication can adopt appropriate checkpointing schemes for different parts of\nits computation. We illustrate with an example of an application that combines\nbatch processing with low-latency streaming updates. We show rules, and an\nalgorithm, to determine a globally consistent state for rollback in a system\nthat uses multiple logical time domains. We also introduce selective rollback\nat a processor, which can selectively preserve the effect of events at some\nlogical times and not others, independent of the original order of execution of\nthose events. Selective rollback permits new checkpointing policies that are\nparticularly well suited to iterative streaming algorithms. We report on an\nimplementation of our new framework in the context of the Naiad system.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2015 00:06:05 GMT"}], "update_date": "2015-04-01", "authors_parsed": [["Isard", "Michael", ""], ["Abadi", "Mart\u00edn", ""]]}, {"id": "1503.09052", "submitter": "Valter Balegas", "authors": "Valter Balegas, Diogo Serra, S\\'ergio Duarte, Carla Ferreira, Rodrigo\n  Rodrigues, Nuno Pregui\\c{c}a, Marc Shapiro, Mahsa Najafzadeh", "title": "Extending Eventually Consistent Cloud Databases for Enforcing Numeric\n  Invariants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geo-replicated databases often operate under the principle of eventual\nconsistency to offer high-availability with low latency on a simple key/value\nstore abstraction. Recently, some have adopted commutative data types to\nprovide seamless reconciliation for special purpose data types, such as\ncounters. Despite this, the inability to enforce numeric invariants across all\nreplicas still remains a key shortcoming of relying on the limited guarantees\nof eventual consistency storage. We present a new replicated data type, called\nbounded counter, which adds support for numeric invariants to eventually\nconsistent geo-replicated databases. We describe how this can be implemented on\ntop of existing cloud stores without modifying them, using Riak as an example.\nOur approach adapts ideas from escrow transactions to devise a solution that is\ndecentralized, fault-tolerant and fast. Our evaluation shows much lower latency\nand better scalability than the traditional approach of using strong\nconsistency to enforce numeric invariants, thus alleviating the tension between\nconsistency and availability.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2015 14:17:42 GMT"}], "update_date": "2015-04-01", "authors_parsed": [["Balegas", "Valter", ""], ["Serra", "Diogo", ""], ["Duarte", "S\u00e9rgio", ""], ["Ferreira", "Carla", ""], ["Rodrigues", "Rodrigo", ""], ["Pregui\u00e7a", "Nuno", ""], ["Shapiro", "Marc", ""], ["Najafzadeh", "Mahsa", ""]]}, {"id": "1503.09062", "submitter": "Emilio Coppa", "authors": "Emilio Coppa, Irene Finocchi", "title": "On data skewness, stragglers, and MapReduce progress indicators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of predicting the performance of MapReduce\napplications, designing accurate progress indicators that keep programmers\ninformed on the percentage of completed computation time during the execution\nof a job. Through extensive experiments, we show that state-of-the-art progress\nindicators (including the one provided by Hadoop) can be seriously harmed by\ndata skewness, load unbalancing, and straggling tasks. This is mainly due to\ntheir implicit assumption that the running time depends linearly on the input\nsize. We thus design a novel profile-guided progress indicator, called\nNearestFit, that operates without the linear hypothesis assumption and exploits\na careful combination of nearest neighbor regression and statistical curve\nfitting techniques. Our theoretical progress model requires fine-grained\nprofile data, that can be very difficult to manage in practice. To overcome\nthis issue, we resort to computing accurate approximations for some of the\nquantities used in our model through space- and time-efficient data streaming\nalgorithms. We implemented NearestFit on top of Hadoop 2.6.0. An extensive\nempirical assessment over the Amazon EC2 platform on a variety of real-world\nbenchmarks shows that NearestFit is practical w.r.t. space and time overheads\nand that its accuracy is generally very good, even in scenarios where\ncompetitors incur non-negligible errors and wide prediction fluctuations.\nOverall, NearestFit significantly improves the current state-of-art on progress\nanalysis for MapReduce.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2015 14:29:13 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2015 15:55:15 GMT"}], "update_date": "2015-04-03", "authors_parsed": [["Coppa", "Emilio", ""], ["Finocchi", "Irene", ""]]}]