[{"id": "1405.0354", "submitter": "Umang Vipul", "authors": "Umang Vipul", "title": "Map-Reduce Parallelization of Motif Discovery", "comments": "4 pages, 1 figure, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motif discovery is one of the most challenging problems in bioinformatics\ntoday. DNA sequence motifs are becoming increasingly important in analysis of\ngene regulation. Motifs are short, recurring patterns in DNA that have a\nbiological function. For example, they indicate binding sites for Transcription\nFactors (TFs) and nucleases. There are a number of Motif Discovery algorithms\nthat run sequentially. The sequential nature stops these algorithms from being\nparallelized. HOMER is one such Motif discovery tool, that we have decided to\nuse to overcome this limitation. To overcome this limitation, we propose a new\nmethodology for Motif Discovery, using HOMER, that parallelizes the task.\nParallelized version can potentially yield better scalability and performance.\nTo achieve this, we have decided to use sub-sampling and the Map Reduce model.\nAt each Map node, a sub-sampled version of the input DNA sequences is used as\ninput to HOMER. Subsampling at each map node is performed with different\nparameters to ensure that no two HOMER instances receive identical inputs. The\noutput of the map phase and the input of the reduce phase is a list of Motifs\ndiscovered using the sub-sampled sequences. The reduce phase calculates the\nmode, most frequent Motifs, and outputs them as the final discovered Motifs. We\nfound marginal speed gains with this model of execution and substantial amount\nof quality loss in discovered Motifs.\n", "versions": [{"version": "v1", "created": "Fri, 2 May 2014 07:30:45 GMT"}], "update_date": "2014-05-05", "authors_parsed": [["Vipul", "Umang", ""]]}, {"id": "1405.0637", "submitter": "Bryan Ford", "authors": "Cristina Basescu, Michael F. Nowlan, Kirill Nikitin, Jose M. Faleiro,\n  and Bryan Ford", "title": "Crux: Locality-Preserving Distributed Services", "comments": "11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed systems achieve scalability by distributing load across many\nmachines, but wide-area deployments can introduce worst-case response latencies\nproportional to the network's diameter. Crux is a general framework to build\nlocality-preserving distributed systems, by transforming an existing scalable\ndistributed algorithm A into a new locality-preserving algorithm ALP, which\nguarantees for any two clients u and v interacting via ALP that their\ninteractions exhibit worst-case response latencies proportional to the network\nlatency between u and v. Crux builds on compact-routing theory, but generalizes\nthese techniques beyond routing applications. Crux provides weak and strong\nconsistency flavors, and shows latency improvements for localized interactions\nin both cases, specifically up to several orders of magnitude for\nweakly-consistent Crux (from roughly 900ms to 1ms). We deployed on PlanetLab\nlocality-preserving versions of a Memcached distributed cache, a Bamboo\ndistributed hash table, and a Redis publish/subscribe. Our results indicate\nthat Crux is effective and applicable to a variety of existing distributed\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sun, 4 May 2014 00:35:25 GMT"}, {"version": "v2", "created": "Sat, 12 May 2018 09:21:09 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Basescu", "Cristina", ""], ["Nowlan", "Michael F.", ""], ["Nikitin", "Kirill", ""], ["Faleiro", "Jose M.", ""], ["Ford", "Bryan", ""]]}, {"id": "1405.1020", "submitter": "Siddhartha Mukherjee", "authors": "Siddhartha Mukherjee", "title": "Study on performance improvement of oil paint image filter algorithm\n  using parallel pattern library", "comments": "12 pages, 4 figures, 4 code snippets, 4 tables, 2 graphs, 2 images of\n  experimental result, Conference: CCSEA 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives a detailed study on the performance of oil paint image\nfilter algorithm with various parameters applied on an image of RGB model. Oil\nPaint image processing, being very performance hungry, current research tries\nto find improvement using parallel pattern library. With increasing\nkernel-size, the processing time of oil paint image filter algorithm increases\nexponentially.\n", "versions": [{"version": "v1", "created": "Wed, 19 Mar 2014 07:32:37 GMT"}], "update_date": "2014-05-06", "authors_parsed": [["Mukherjee", "Siddhartha", ""]]}, {"id": "1405.1133", "submitter": "Ioana O. Bercea", "authors": "Ioana O. Bercea, Navin Goyal, David G. Harris, Aravind Srinivasan", "title": "On Computing Maximal Independent Sets of Hypergraphs in Parallel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whether or not the problem of finding maximal independent sets (MIS) in\nhypergraphs is in (R)NC is one of the fundamental problems in the theory of\nparallel computing. Unlike the well-understood case of MIS in graphs, for the\nhypergraph problem, our knowledge is quite limited despite considerable work.\nIt is known that the problem is in \\emph{RNC} when the edges of the hypergraph\nhave constant size. For general hypergraphs with $n$ vertices and $m$ edges,\nthe fastest previously known algorithm works in time $O(\\sqrt{n})$ with\n$\\text{poly}(m,n)$ processors. In this paper we give an EREW PRAM algorithm\nthat works in time $n^{o(1)}$ with $\\text{poly}(m,n)$ processors on general\nhypergraphs satisfying $m \\leq n^{\\frac{\\log^{(2)}n}{8(\\log^{(3)}n)^2}}$, where\n$\\log^{(2)}n = \\log\\log n$ and $\\log^{(3)}n = \\log\\log\\log n$. Our algorithm is\nbased on a sampling idea that reduces the dimension of the hypergraph and\nemploys the algorithm for constant dimension hypergraphs as a subroutine.\n", "versions": [{"version": "v1", "created": "Tue, 6 May 2014 02:55:50 GMT"}, {"version": "v2", "created": "Tue, 12 Aug 2014 23:24:26 GMT"}], "update_date": "2014-08-14", "authors_parsed": [["Bercea", "Ioana O.", ""], ["Goyal", "Navin", ""], ["Harris", "David G.", ""], ["Srinivasan", "Aravind", ""]]}, {"id": "1405.1167", "submitter": "George Saad", "authors": "George Saad and Jared Saia", "title": "Self-Healing Computation", "comments": "17 pages and 1 figure. It is submitted to SSS'14", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the problem of reliable multiparty computation (RC), there are $n$\nparties, each with an individual input, and the parties want to jointly compute\na function $f$ over $n$ inputs. The problem is complicated by the fact that an\nomniscient adversary controls a hidden fraction of the parties.\n  We describe a self-healing algorithm for this problem. In particular, for a\nfixed function $f$, with $n$ parties and $m$ gates, we describe how to perform\nRC repeatedly as the inputs to $f$ change. Our algorithm maintains the\nfollowing properties, even when an adversary controls up to $t \\leq\n(\\frac{1}{4} - \\epsilon) n$ parties, for any constant $\\epsilon >0$. First, our\nalgorithm performs each reliable computation with the following amortized\nresource costs: $O(m + n \\log n)$ messages, $O(m + n \\log n)$ computational\noperations, and $O(\\ell)$ latency, where $\\ell$ is the depth of the circuit\nthat computes $f$. Second, the expected total number of corruptions is $O(t\n(\\log^{*} m)^2)$, after which the adversarially controlled parties are\neffectively quarantined so that they cause no more corruptions.\n", "versions": [{"version": "v1", "created": "Tue, 6 May 2014 06:44:46 GMT"}, {"version": "v2", "created": "Mon, 27 Oct 2014 15:17:02 GMT"}], "update_date": "2014-10-28", "authors_parsed": [["Saad", "George", ""], ["Saia", "Jared", ""]]}, {"id": "1405.1382", "submitter": "Calvin Newport", "authors": "Calvin Newport", "title": "Consensus with an Abstract MAC Layer", "comments": "Appeared in PODC 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study distributed consensus in the radio network setting.\nWe produce new upper and lower bounds for this problem in an abstract MAC layer\nmodel that captures the key guarantees provided by most wireless MAC layers. In\nmore detail, we first generalize the well-known impossibility of deterministic\nconsensus with a single crash failure [FLP 1895] from the asynchronous message\npassing model to our wireless setting. Proceeding under the assumption of no\nfaults, we then investigate the amount of network knowledge required to solve\nconsensus in our model---an important question given that these networks are\noften deployed in an ad hoc manner. We prove consensus is impossible without\nunique ids or without knowledge of network size (in multihop topologies). We\nalso prove a lower bound on optimal time complexity. We then match these lower\nbounds with a pair of new deterministic consensus algorithms---one for single\nhop topologies and one for multihop topologies---providing a comprehensive\ncharacterization of the consensus problem in the wireless setting. From a\ntheoretical perspective, our results shed new insight into the role of network\ninformation and the power of MAC layer abstractions in solving distributed\nconsensus. From a practical perspective, given the level of abstraction used by\nour model, our upper bounds can be easily implemented in real wireless devices\non existing MAC layers while preserving their correctness\nguarantees---facilitating the development of wireless distributed systems.\n", "versions": [{"version": "v1", "created": "Tue, 6 May 2014 17:48:03 GMT"}], "update_date": "2014-05-07", "authors_parsed": [["Newport", "Calvin", ""]]}, {"id": "1405.1649", "submitter": "Danupon Nanongkai", "authors": "Shay Kutten, Danupon Nanongkai, Gopal Pandurangan, Peter Robinson", "title": "Distributed Symmetry Breaking in Hypergraphs", "comments": "Changes from the previous version: More references added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fundamental local symmetry breaking problems such as Maximal Independent Set\n(MIS) and coloring have been recognized as important by the community, and\nstudied extensively in (standard) graphs. In particular, fast (i.e.,\nlogarithmic run time) randomized algorithms are well-established for MIS and\n$\\Delta +1$-coloring in both the LOCAL and CONGEST distributed computing\nmodels. On the other hand, comparatively much less is known on the complexity\nof distributed symmetry breaking in {\\em hypergraphs}. In particular, a key\nquestion is whether a fast (randomized) algorithm for MIS exists for\nhypergraphs.\n  In this paper, we study the distributed complexity of symmetry breaking in\nhypergraphs by presenting distributed randomized algorithms for a variety of\nfundamental problems under a natural distributed computing model for\nhypergraphs. We first show that MIS in hypergraphs (of arbitrary dimension) can\nbe solved in $O(\\log^2 n)$ rounds ($n$ is the number of nodes of the\nhypergraph) in the LOCAL model. We then present a key result of this paper ---\nan $O(\\Delta^{\\epsilon}\\text{polylog}(n))$-round hypergraph MIS algorithm in\nthe CONGEST model where $\\Delta$ is the maximum node degree of the hypergraph\nand $\\epsilon > 0$ is any arbitrarily small constant.\n  To demonstrate the usefulness of hypergraph MIS, we present applications of\nour hypergraph algorithm to solving problems in (standard) graphs. In\nparticular, the hypergraph MIS yields fast distributed algorithms for the {\\em\nbalanced minimal dominating set} problem (left open in Harris et al. [ICALP\n2013]) and the {\\em minimal connected dominating set problem}. We also present\ndistributed algorithms for coloring, maximal matching, and maximal clique in\nhypergraphs.\n", "versions": [{"version": "v1", "created": "Wed, 7 May 2014 15:48:36 GMT"}, {"version": "v2", "created": "Tue, 20 May 2014 14:22:05 GMT"}, {"version": "v3", "created": "Sun, 24 Aug 2014 16:03:50 GMT"}, {"version": "v4", "created": "Tue, 30 Sep 2014 08:30:10 GMT"}], "update_date": "2014-10-01", "authors_parsed": [["Kutten", "Shay", ""], ["Nanongkai", "Danupon", ""], ["Pandurangan", "Gopal", ""], ["Robinson", "Peter", ""]]}, {"id": "1405.1671", "submitter": "Erez Kantor", "authors": "Mohsen Ghaffari and Erez Kantor and Nancy Lynch and Calvin Newport", "title": "Multi-Message Broadcast with Abstract MAC Layers and Unreliable Links", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the multi-message broadcast problem using abstract MAC layer models\nof wireless networks. These models capture the key guarantees of existing MAC\nlayers while abstracting away low-level details such as signal propagation and\ncontention. We begin by studying upper and lower bounds for this problem in a\n{\\em standard abstract MAC layer model}---identifying an interesting dependence\nbetween the structure of unreliable links and achievable time complexity. In\nmore detail, given a restriction that devices connected directly by an\nunreliable link are not too far from each other in the reliable link topology,\nwe can (almost) match the efficiency of the reliable case. For the related\nrestriction, however, that two devices connected by an unreliable link are not\ntoo far from each other in geographic distance, we prove a new lower bound that\nshows that this efficiency is impossible. We then investigate how much extra\npower must be added to the model to enable a new order of magnitude of\nefficiency. In more detail, we consider an {\\em enhanced abstract MAC layer\nmodel} and present a new multi-message broadcast algorithm that (under certain\nnatural assumptions) solves the problem in this model faster than any known\nsolutions in an abstract MAC layer setting.\n", "versions": [{"version": "v1", "created": "Wed, 7 May 2014 17:20:13 GMT"}], "update_date": "2014-05-08", "authors_parsed": [["Ghaffari", "Mohsen", ""], ["Kantor", "Erez", ""], ["Lynch", "Nancy", ""], ["Newport", "Calvin", ""]]}, {"id": "1405.1688", "submitter": "Tsvetomira Radeva", "authors": "Christoph Lenzen, Nancy Lynch, Calvin Newport, Tsvetomira Radeva", "title": "Trade-offs between Selection Complexity and Performance when Searching\n  the Plane without Communication", "comments": "appears in PODC 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the ANTS problem [Feinerman et al.] in which a group of agents\ncollaboratively search for a target in a two-dimensional plane. Because this\nproblem is inspired by the behavior of biological species, we argue that in\naddition to studying the {\\em time complexity} of solutions it is also\nimportant to study the {\\em selection complexity}, a measure of how likely a\ngiven algorithmic strategy is to arise in nature due to selective pressures. In\nmore detail, we propose a new selection complexity metric $\\chi$, defined for\nalgorithm ${\\cal A}$ such that $\\chi({\\cal A}) = b + \\log \\ell$, where $b$ is\nthe number of memory bits used by each agent and $\\ell$ bounds the fineness of\navailable probabilities (agents use probabilities of at least $1/2^\\ell$). In\nthis paper, we study the trade-off between the standard performance metric of\nspeed-up, which measures how the expected time to find the target improves with\n$n$, and our new selection metric.\n  In particular, consider $n$ agents searching for a treasure located at\n(unknown) distance $D$ from the origin (where $n$ is sub-exponential in $D$).\nFor this problem, we identify $\\log \\log D$ as a crucial threshold for our\nselection complexity metric. We first prove a new upper bound that achieves a\nnear-optimal speed-up of $(D^2/n +D) \\cdot 2^{O(\\ell)}$ for $\\chi({\\cal A})\n\\leq 3 \\log \\log D + O(1)$. In particular, for $\\ell \\in O(1)$, the speed-up is\nasymptotically optimal. By comparison, the existing results for this problem\n[Feinerman et al.] that achieve similar speed-up require $\\chi({\\cal A}) =\n\\Omega(\\log D)$. We then show that this threshold is tight by describing a\nlower bound showing that if $\\chi({\\cal A}) < \\log \\log D - \\omega(1)$, then\nwith high probability the target is not found within $D^{2-o(1)}$ moves per\nagent. Hence, there is a sizable gap to the straightforward $\\Omega(D^2/n + D)$\nlower bound in this setting.\n", "versions": [{"version": "v1", "created": "Wed, 7 May 2014 18:27:20 GMT"}], "update_date": "2014-05-08", "authors_parsed": [["Lenzen", "Christoph", ""], ["Lynch", "Nancy", ""], ["Newport", "Calvin", ""], ["Radeva", "Tsvetomira", ""]]}, {"id": "1405.1811", "submitter": "Hamed Haddadi", "authors": "Hamed Haddadi, Georgios Smaragdakis, K. K. Ramakrishnan", "title": "Opportunities in a Federated Cloud Marketplace", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent measurement studies show that there are massively distributed hosting\nand computing infrastructures deployed in the Internet. Such infrastructures\ninclude large data centers and organizations' computing clusters. When idle,\nthese resources can readily serve local users. Such users can be smartphone or\ntablet users wishing to access services such as remote desktop or CPU/bandwidth\nintensive activities. Particularly, when they are likely to have high latency\nto access, or may have no access at all to, centralized cloud providers. Today,\nhowever, there is no global marketplace where sellers and buyers of available\nresources can trade. The recently introduced marketplaces of Amazon and other\ncloud infrastructures are limited by the network footprint of their own\ninfrastructures and availability of such services in the target country and\nregion. In this article we discuss the potentials for a federated cloud\nmarketplace where sellers and buyers of a number of resources, including\nstorage, computing, and network bandwidth, can freely trade. This ecosystem can\nbe regulated through brokers who act as service level monitors and auctioneers.\nWe conclude by discussing the challenges and opportunities in this space.\n", "versions": [{"version": "v1", "created": "Thu, 8 May 2014 06:32:06 GMT"}], "update_date": "2014-05-09", "authors_parsed": [["Haddadi", "Hamed", ""], ["Smaragdakis", "Georgios", ""], ["Ramakrishnan", "K. K.", ""]]}, {"id": "1405.1932", "submitter": "Kimia Ghaffari", "authors": "Kimia Ghaffari, Mohammad Soltani Delgosha and Neda Abdolvand", "title": "Towards Cloud Computing: A SWOT Analysis on its Adoption in SMEs", "comments": null, "journal-ref": null, "doi": "10.5121/ijitcs.2014.4202", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, emergence of cloud computing has notably made an\nevolution in the IT industry by putting forward an \"everything as a service\"\nidea .Cloud Computing is of growing interest to companies throughout the world,\nbut there are many barriers associated with its adoption which should be\neliminated. This paper aims to investigate Cloud Computing and discusses the\ndrivers and inhibitors of its adoption. Moreover, an attempt has been made to\nidentify the key stakeholders of Cloud Computing and outline the current\nsecurity challenges. A SWOT analysis which consists of strengths, weaknesses,\nopportunities and threats has also carried out in which Cloud Computing\nadoption for SMEs (Small and Medium-sized Enterprises) is evaluated. Finally,\nthe paper concludes with some further research areas in the field of Cloud\nComputing.\n", "versions": [{"version": "v1", "created": "Thu, 8 May 2014 14:04:43 GMT"}], "update_date": "2014-05-09", "authors_parsed": [["Ghaffari", "Kimia", ""], ["Delgosha", "Mohammad Soltani", ""], ["Abdolvand", "Neda", ""]]}, {"id": "1405.1964", "submitter": "Antimo Barbato", "authors": "Antimo Barbato, Antonio Capone, Lin Chen, Fabio Martignon and Stefano\n  Paris", "title": "A Distributed Demand-Side Management Framework for the Smart Grid", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a fully distributed Demand-Side Management system for\nSmart Grid infrastructures, especially tailored to reduce the peak demand of\nresidential users. In particular, we use a dynamic pricing strategy, where\nenergy tariffs are function of the overall power demand of customers. We\nconsider two practical cases: (1) a fully distributed approach, where each\nappliance decides autonomously its own scheduling, and (2) a hybrid approach,\nwhere each user must schedule all his appliances. We analyze numerically these\ntwo approaches, showing that they are characterized practically by the same\nperformance level in all the considered grid scenarios. We model the proposed\nsystem using a non-cooperative game theoretical approach, and demonstrate that\nour game is a generalized ordinal potential one under general conditions.\nFurthermore, we propose a simple yet effective best response strategy that is\nproved to converge in a few steps to a pure Nash Equilibrium, thus\ndemonstrating the robustness of the power scheduling plan obtained without any\ncentral coordination of the operator or the customers. Numerical results,\nobtained using real load profiles and appliance models, show that the\nsystem-wide peak absorption achieved in a completely distributed fashion can be\nreduced up to 55%, thus decreasing the capital expenditure (CAPEX) necessary to\nmeet the growing energy demand.\n", "versions": [{"version": "v1", "created": "Thu, 8 May 2014 15:23:43 GMT"}], "update_date": "2014-05-09", "authors_parsed": [["Barbato", "Antimo", ""], ["Capone", "Antonio", ""], ["Chen", "Lin", ""], ["Martignon", "Fabio", ""], ["Paris", "Stefano", ""]]}, {"id": "1405.2011", "submitter": "Boaz Patt-Shamir", "authors": "Christoph Lenzen and Boaz Patt-Shamir", "title": "Improved Distributed Steiner Forest Construction", "comments": "title page + 11 pages + 30 page appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new distributed algorithms for constructing a Steiner Forest in\nthe CONGEST model. Our deterministic algorithm finds, for any given constant\n$\\epsilon>0$, a $(2+\\epsilon)$-approximation in\n$\\tilde{O}(sk+\\sqrt{\\min(st,n)})$ rounds, where $s$ is the shortest path\ndiameter, $t$ is the number of terminals, $k$ is the number of terminal\ncomponents in the input, and $n$ is the number of nodes. Our randomized\nalgorithm finds, with high probability, an $O(\\log n)$- approximation in time\n$\\tilde{O}(k+\\min(s,\\sqrt n)+D)$, where $D$ is the unweighted diameter of the\nnetwork. We also prove a matching lower bound of\n$\\tilde{\\Omega}(k+\\min(s,\\sqrt{n})+D)$ on the running time of any distributed\napproximation algorithm for the Steiner Forest problem. Previous algorithms\nwere randomized, and obtained either an $O(\\log n)$-approximation in\n$\\tilde{O}(sk)$ time, or an $O(1/\\epsilon)$-approximation in\n$\\tilde{O}((\\sqrt{n}+t)^{1+\\epsilon}+D)$ time.\n", "versions": [{"version": "v1", "created": "Thu, 8 May 2014 16:42:29 GMT"}], "update_date": "2014-05-09", "authors_parsed": [["Lenzen", "Christoph", ""], ["Patt-Shamir", "Boaz", ""]]}, {"id": "1405.2281", "submitter": "Frank Hannig", "authors": "Frank Hannig and J\\\"urgen Teich", "title": "Proceedings of the First Workshop on Resource Awareness and Adaptivity\n  in Multi-Core Computing (Racing 2014)", "comments": "Website of the workshop: http://www12.cs.fau.de/racing2014/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.OS cs.RO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the papers accepted at the 1st Workshop on Resource\nAwareness and Adaptivity in Multi-Core Computing (Racing 2014), held in\nPaderborn, Germany, May 29-30, 2014. Racing 2014 was co-located with the IEEE\nEuropean Test Symposium (ETS).\n", "versions": [{"version": "v1", "created": "Thu, 8 May 2014 07:09:55 GMT"}], "update_date": "2014-05-12", "authors_parsed": [["Hannig", "Frank", ""], ["Teich", "J\u00fcrgen", ""]]}, {"id": "1405.2430", "submitter": "Giuseppe Antonio Di Luna", "authors": "G. A. Di Luna, P. Flocchini, S. Gan Chaudhuri, N. Santoro, G.\n  Viglietta", "title": "Robots with Lights: Overcoming Obstructed Visibility Without Colliding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots with lights is a model of autonomous mobile computational entities\noperating in the plane in Look-Compute-Move cycles: each agent has an\nexternally visible light which can assume colors from a fixed set; the lights\nare persistent (i.e., the color is not erased at the end of a cycle), but\notherwise the agents are oblivious. The investigation of computability in this\nmodel, initially suggested by Peleg, is under way, and several results have\nbeen recently established. In these investigations, however, an agent is\nassumed to be capable to see through another agent. In this paper we start the\nstudy of computing when visibility is obstructable, and investigate the most\nbasic problem for this setting, Complete Visibility: The agents must reach\nwithin finite time a configuration where they can all see each other and\nterminate. We do not make any assumption on a-priori knowledge of the number of\nagents, on rigidity of movements nor on chirality. The local coordinate system\nof an agent may change at each activation. Also, by definition of lights, an\nagent can communicate and remember only a constant number of bits in each\ncycle. In spite of these weak conditions, we prove that Complete Visibility is\nalways solvable, even in the asynchronous setting, without collisions and using\na small constant number of colors. The proof is constructive. We also show how\nto extend our protocol for Complete Visibility so that, with the same number of\ncolors, the agents solve the (non-uniform) Circle Formation problem with\nobstructed visibility.\n", "versions": [{"version": "v1", "created": "Sat, 10 May 2014 13:05:25 GMT"}], "update_date": "2014-05-13", "authors_parsed": [["Di Luna", "G. A.", ""], ["Flocchini", "P.", ""], ["Chaudhuri", "S. Gan", ""], ["Santoro", "N.", ""], ["Viglietta", "G.", ""]]}, {"id": "1405.2523", "submitter": "Nikzad Babaii-Rizvandi", "authors": "Nikzad Babaii Rizvandi", "title": "Performance Provisioning and Energy Efficiency in Cloud and Distributed\n  Computing Systems", "comments": "PhD thesis with 139 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the issue of energy consumption in high performance\ncomputing (HPC) systems has attracted a great deal of attention. In response to\nthis, many energy-aware algorithms have been developed in different layers of\nHPC systems, including the hardware layer, service layer and system layer.\nThese algorithms are of two types: first, algorithms which directly try to\nimprove the energy by tweaking frequency operation or scheduling algorithms;\nand second, algorithms which focus on improving the performance of the system,\nwith the assumption that efficient running of a system may indirectly save more\nenergy.\n  In this thesis, we develop algorithms in both layers. First, we introduce\nthree algorithms to directly improve the energy of scheduled tasks at the\nhardware level by using Dynamic Voltage Frequency Scaling (DVFS). Second, we\npropose two algorithms for modelling and resource provisioning of MapReduce\napplications (a well-known parametric distributed framework currently used by\nGoogle, Yahoo, Facebook and LinkedIn) based on its configuration parameters.\nCertainly, estimating the performance (e.g., execution time or CPU clock ticks)\nof a MapReduce application can be later used for smart scheduling of such\napplications in clouds or clusters.\n  To evaluate the algorithms, we have conducted extensive simulation and real\nexperiments on a 5-node physical cluster with up to 25 virtual nodes, using\nboth synthetic and real world applications. Also, the proposed new algorithms\nare compared with existing algorithms by experimentation, and the experimental\nresults reveal new information on the performance of these algorithms, as well\nas on the properties of MapReduce and DVFS. In the end, three open problems are\nrevealed by the experimental observations, and their importance is explained.\n", "versions": [{"version": "v1", "created": "Sun, 11 May 2014 11:40:36 GMT"}], "update_date": "2014-05-13", "authors_parsed": [["Rizvandi", "Nikzad Babaii", ""]]}, {"id": "1405.2636", "submitter": "Mathieu Faverge", "authors": "Xavier Lacoste (INRIA Bordeaux - Sud-Ouest), Mathieu Faverge (INRIA\n  Bordeaux - Sud-Ouest, LaBRI), George Bosilca (ICL), Pierre Ramet (INRIA\n  Bordeaux - Sud-Ouest, LaBRI), Samuel Thibault (LaBRI, INRIA Bordeaux -\n  Sud-Ouest)", "title": "Taking advantage of hybrid systems for sparse direct solvers via\n  task-based runtimes", "comments": "Heterogeneity in Computing Workshop (2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ongoing hardware evolution exhibits an escalation in the number, as well\nas in the heterogeneity, of computing resources. The pressure to maintain\nreasonable levels of performance and portability forces application developers\nto leave the traditional programming paradigms and explore alternative\nsolutions. PaStiX is a parallel sparse direct solver, based on a dynamic\nscheduler for modern hierarchical manycore architectures. In this paper, we\nstudy the benefits and limits of replacing the highly specialized internal\nscheduler of the PaStiX solver with two generic runtime systems: PaRSEC and\nStarPU. The tasks graph of the factorization step is made available to the two\nruntimes, providing them the opportunity to process and optimize its traversal\nin order to maximize the algorithm efficiency for the targeted hardware\nplatform. A comparative study of the performance of the PaStiX solver on top of\nits native internal scheduler, PaRSEC, and StarPU frameworks, on different\nexecution environments, is performed. The analysis highlights that these\ngeneric task-based runtimes achieve comparable results to the\napplication-optimized embedded scheduler on homogeneous platforms. Furthermore,\nthey are able to significantly speed up the solver on heterogeneous\nenvironments by taking advantage of the accelerators while hiding the\ncomplexity of their efficient manipulation from the programmer.\n", "versions": [{"version": "v1", "created": "Mon, 12 May 2014 06:28:03 GMT"}], "update_date": "2014-05-13", "authors_parsed": [["Lacoste", "Xavier", "", "INRIA Bordeaux - Sud-Ouest"], ["Faverge", "Mathieu", "", "INRIA\n  Bordeaux - Sud-Ouest, LaBRI"], ["Bosilca", "George", "", "ICL"], ["Ramet", "Pierre", "", "INRIA\n  Bordeaux - Sud-Ouest, LaBRI"], ["Thibault", "Samuel", "", "LaBRI, INRIA Bordeaux -\n  Sud-Ouest"]]}, {"id": "1405.2833", "submitter": "Akshay Kumar", "authors": "Akshay Kumar, Ravi Tandon, T. Charles Clancy", "title": "On the Latency and Energy Efficiency of Erasure-Coded Cloud Storage\n  Systems", "comments": "Submitted to IEEE Transactions on Cloud Computing. Contains 24 pages,\n  13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increase in data storage and power consumption at data-centers has made\nit imperative to design energy efficient Distributed Storage Systems (DSS). The\nenergy efficiency of DSS is strongly influenced not only by the volume of data,\nfrequency of data access and redundancy in data storage, but also by the\nheterogeneity exhibited by the DSS in these dimensions. To this end, we propose\nand analyze the energy efficiency of a heterogeneous distributed storage system\nin which $n$ storage servers (disks) store the data of $R$ distinct classes.\nData of class $i$ is encoded using a $(n,k_{i})$ erasure code and the (random)\ndata retrieval requests can also vary across classes. We show that the energy\nefficiency of such systems is closely related to the average latency and hence\nmotivates us to study the energy efficiency via the lens of average latency.\nThrough this connection, we show that erasure coding serves the dual purpose of\nreducing latency and increasing energy efficiency. We present a queuing\ntheoretic analysis of the proposed model and establish upper and lower bounds\non the average latency for each data class under various scheduling policies.\nThrough extensive simulations, we present qualitative insights which reveal the\nimpact of coding rate, number of servers, service distribution and number of\nredundant requests on the average latency and energy efficiency of the DSS.\n", "versions": [{"version": "v1", "created": "Mon, 12 May 2014 16:51:53 GMT"}, {"version": "v2", "created": "Fri, 22 May 2015 03:10:24 GMT"}], "update_date": "2015-05-25", "authors_parsed": [["Kumar", "Akshay", ""], ["Tandon", "Ravi", ""], ["Clancy", "T. Charles", ""]]}, {"id": "1405.2907", "submitter": "Vahid Lari", "authors": "Vahid Lari, Alexandru Tanase, Frank Hannig, J\\\"urgen Teich", "title": "Massively Parallel Processor Architectures for Resource-aware Computing", "comments": "Presented at 1st Workshop on Resource Awareness and Adaptivity in\n  Multi-Core Computing (Racing 2014) (arXiv:1405.2281)", "journal-ref": null, "doi": null, "report-no": "Racing/2014/01", "categories": "cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a class of massively parallel processor architectures called\ninvasive tightly coupled processor arrays (TCPAs). The presented processor\nclass is a highly parameterizable template, which can be tailored before\nruntime to fulfill costumers' requirements such as performance, area cost, and\nenergy efficiency. These programmable accelerators are well suited for\ndomain-specific computing from the areas of signal, image, and video processing\nas well as other streaming processing applications. To overcome future scaling\nissues (e.g., power consumption, reliability, resource management, as well as\napplication parallelization and mapping), TCPAs are inherently designed in a\nway to support self-adaptivity and resource awareness at hardware level. Here,\nwe follow a recently introduced resource-aware parallel computing paradigm\ncalled invasive computing where an application can dynamically claim, execute,\nand release resources. Furthermore, we show how invasive computing can be used\nas an enabler for power management. Finally, we will introduce ideas on how to\nrealize fault-tolerant loop execution on such massively parallel architectures\nthrough employing on-demand spatial redundancies at the processor array level.\n", "versions": [{"version": "v1", "created": "Mon, 12 May 2014 16:39:44 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["Lari", "Vahid", ""], ["Tanase", "Alexandru", ""], ["Hannig", "Frank", ""], ["Teich", "J\u00fcrgen", ""]]}, {"id": "1405.2908", "submitter": "Johny Paul", "authors": "Johny Paul, Walter Stechele, Manfred Kr\\\"ohnert, Tamim Asfour", "title": "Resource-Aware Programming for Robotic Vision", "comments": "Presented at 1st Workshop on Resource Awareness and Adaptivity in\n  Multi-Core Computing (Racing 2014) (arXiv:1405.2281)", "journal-ref": null, "doi": null, "report-no": "Racing/2014/02", "categories": "cs.CV cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humanoid robots are designed to operate in human centered environments. They\nface changing, dynamic environments in which they need to fulfill a multitude\nof challenging tasks. Such tasks differ in complexity, resource requirements,\nand execution time. Latest computer architectures of humanoid robots consist of\nseveral industrial PCs containing single- or dual-core processors. According to\nthe SIA roadmap for semiconductors, many-core chips with hundreds to thousands\nof cores are expected to be available in the next decade. Utilizing the full\npower of a chip with huge amounts of resources requires new computing paradigms\nand methodologies.\n  In this paper, we analyze a resource-aware computing methodology named\nInvasive Computing, to address these challenges. The benefits and limitations\nof the new programming model is analyzed using two widely used computer vision\nalgorithms, the Harris Corner detector and SIFT (Scale Invariant Feature\nTransform) feature matching. The result indicate that the new programming model\ntogether with the extensions within the application layer, makes them highly\nadaptable; leading to better quality in the results obtained.\n", "versions": [{"version": "v1", "created": "Mon, 12 May 2014 16:40:04 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["Paul", "Johny", ""], ["Stechele", "Walter", ""], ["Kr\u00f6hnert", "Manfred", ""], ["Asfour", "Tamim", ""]]}, {"id": "1405.2910", "submitter": "Oliver Mattes", "authors": "Oliver Mattes, Wolfgang Karl", "title": "Evaluating the Self-Optimization Process of the Adaptive Memory\n  Management Architecture Self-aware Memory", "comments": "Presented at 1st Workshop on Resource Awareness and Adaptivity in\n  Multi-Core Computing (Racing 2014) (arXiv:1405.2281)", "journal-ref": null, "doi": null, "report-no": "Racing/2014/04", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the continuously increasing integration level, manycore processor\nsystems are likely to be the coming system structure not only in HPC but also\nfor desktop or mobile systems. Nowadays manycore processors like Tilera TILE,\nKALRAY MPPA or Intel SCC combine a rising number of cores in a tiled\narchitecture and are mainly designed for high performance applications with\nfocus on direct inter-core communication. The current architectures have\nlimitations by central or sparse components like memory controllers, memory I/O\nor inflexible memory management.\n  In the future highly dynamic workloads with multiple concurrently running\napplications, changing I/O characteristics and a not predictable memory usage\nhave to be utilized on these manycore systems. Consequently the memory\nmanagement has to become more flexible and distributed in nature and adaptive\nmechanisms and system structures are needed. With Self-aware Memory (SaM), a\ndecentralized, scalable and autonomous self-optimizing memory architecture is\ndeveloped. This adaptive memory management can achieve higher flexibility and\nan easy usage of memory.\n  In this paper the concept of an ongoing decentralized self-optimization is\nintroduced and the evaluation of its various parameters is presented. The\nresults show that the overhead of the decentralized optimization process is\namortized by the optimized runtime using the appropriate parameter settings.\n", "versions": [{"version": "v1", "created": "Mon, 12 May 2014 16:40:42 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["Mattes", "Oliver", ""], ["Karl", "Wolfgang", ""]]}, {"id": "1405.2913", "submitter": "Bj\\\"orn D\\\"obel", "authors": "Bj\\\"orn D\\\"obel, Robert Muschner, Hermann H\\\"artig", "title": "Resource-Aware Replication on Heterogeneous Multicores: Challenges and\n  Opportunities", "comments": "Presented at 1st Workshop on Resource Awareness and Adaptivity in\n  Multi-Core Computing (Racing 2014) (arXiv:1405.2281)", "journal-ref": null, "doi": null, "report-no": "Racing/2014/07", "categories": "cs.DC cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decreasing hardware feature sizes and increasing heterogeneity in multicore\nhardware require software that can adapt to these platforms' properties. We\nimplemented ROMAIN, an OS service providing redundant multithreading on top of\nthe FIASCO.OC microkernel to address the increasing unreliability of hardware.\nIn this paper we review challenges and opportunities for ROMAIN to adapt to\nsuch multicore platforms in order to decrease execution overhead, resource\nrequirements, and vulnerability against faults.\n", "versions": [{"version": "v1", "created": "Mon, 12 May 2014 16:41:49 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["D\u00f6bel", "Bj\u00f6rn", ""], ["Muschner", "Robert", ""], ["H\u00e4rtig", "Hermann", ""]]}, {"id": "1405.2914", "submitter": "Hananeh Aliee", "authors": "Hananeh Aliee, Liang Chen, Mojtaba Ebrahimi, Michael Gla{\\ss},\n  Faramarz Khosravi, Mehdi B. Tahoori", "title": "Towards Cross-layer Reliability Analysis of Transient and Permanent\n  Faults", "comments": "Presented at 1st Workshop on Resource Awareness and Adaptivity in\n  Multi-Core Computing (Racing 2014) (arXiv:1405.2281)", "journal-ref": null, "doi": null, "report-no": "Racing/2014/08", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the increasing complexity of Multi-Processor Systems on Chip (MPSoCs),\nsystem-level design methodologies have got a lot of attention in recent years.\nHowever, the significant gap between the system-level reliability analysis and\nthe level where the actual faults occur necessitates a cross-layer approach in\nwhich the sufficient data about the effects of faults at low levels are passed\nto the system level. So far, the cross-layer reliability analysis techniques\nfocus on a specific type of faults, e.g., either permanent or transient faults.\nIn this work, we aim at proposing a cross-layer reliability analysis which\nconsiders different fault types concurrently and connects reliability analysis\ntechniques at different levels of abstraction using adapters.\n", "versions": [{"version": "v1", "created": "Mon, 12 May 2014 16:42:09 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["Aliee", "Hananeh", ""], ["Chen", "Liang", ""], ["Ebrahimi", "Mojtaba", ""], ["Gla\u00df", "Michael", ""], ["Khosravi", "Faramarz", ""], ["Tahoori", "Mehdi B.", ""]]}, {"id": "1405.2915", "submitter": "Christoph Kessler", "authors": "Christoph Kessler, Usman Dastgeer, Lu Li", "title": "Optimized Composition: Generating Efficient Code for Heterogeneous\n  Systems from Multi-Variant Components, Skeletons and Containers", "comments": "Presented at 1st Workshop on Resource Awareness and Adaptivity in\n  Multi-Core Computing (Racing 2014) (arXiv:1405.2281)", "journal-ref": null, "doi": null, "report-no": "Racing/2014/09", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this survey paper, we review recent work on frameworks for the high-level,\nportable programming of heterogeneous multi-/manycore systems (especially,\nGPU-based systems) using high-level constructs such as annotated user-level\nsoftware components, skeletons (i.e., predefined generic components) and\ncontainers, and discuss the optimization problems that need to be considered in\nselecting among multiple implementation variants, generating code and providing\nruntime support for efficient execution on such systems.\n", "versions": [{"version": "v1", "created": "Mon, 12 May 2014 16:42:26 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["Kessler", "Christoph", ""], ["Dastgeer", "Usman", ""], ["Li", "Lu", ""]]}, {"id": "1405.2916", "submitter": "Andi Drebes", "authors": "Andi Drebes, Karine Heydemann, Antoniu Pop, Albert Cohen, Nathalie\n  Drach", "title": "Automatic Detection of Performance Anomalies in Task-Parallel Programs", "comments": "Presented at 1st Workshop on Resource Awareness and Adaptivity in\n  Multi-Core Computing (Racing 2014) (arXiv:1405.2281)", "journal-ref": null, "doi": null, "report-no": "Racing/2014/10", "categories": "cs.DC cs.PF cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To efficiently exploit the resources of new many-core architectures,\nintegrating dozens or even hundreds of cores per chip, parallel programming\nmodels have evolved to expose massive amounts of parallelism, often in the form\nof fine-grained tasks. Task-parallel languages, such as OpenStream, X10,\nHabanero Java and C or StarSs, simplify the development of applications for new\narchitectures, but tuning task-parallel applications remains a major challenge.\nPerformance bottlenecks can occur at any level of the implementation, from the\nalgorithmic level (e.g., lack of parallelism or over-synchronization), to\ninteractions with the operating and runtime systems (e.g., data placement on\nNUMA architectures), to inefficient use of the hardware (e.g., frequent cache\nmisses or misaligned memory accesses); detecting such issues and determining\nthe exact cause is a difficult task.\n  In previous work, we developed Aftermath, an interactive tool for trace-based\nperformance analysis and debugging of task-parallel programs and run-time\nsystems. In contrast to other trace-based analysis tools, such as Paraver or\nVampir, Aftermath offers native support for tasks, i.e., visualization,\nstatistics and analysis tools adapted for performance debugging at task\ngranularity. However, the tool currently does not provide support for the\nautomatic detection of performance bottlenecks and it is up to the user to\ninvestigate the relevant aspects of program execution by focusing the\ninspection on specific slices of a trace file. In this paper, we present\nongoing work on two extensions that guide the user through this process.\n", "versions": [{"version": "v1", "created": "Mon, 12 May 2014 16:42:48 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["Drebes", "Andi", ""], ["Heydemann", "Karine", ""], ["Pop", "Antoniu", ""], ["Cohen", "Albert", ""], ["Drach", "Nathalie", ""]]}, {"id": "1405.3223", "submitter": "Eric Badouel", "authors": "Eric Badouel (INRIA - IRISA, LIRIMA), Lo\\\"ic H\\'elou\\\"et (INRIA -\n  IRISA), Georges-Edouard Kouamou (LIRIMA), Christophe Morvan (INRIA - IRISA)", "title": "A Grammatical Approach to Data-centric Case Management in a Distributed\n  Collaborative Environment", "comments": null, "journal-ref": "N&deg; RR-8528 (2014)", "doi": null, "report-no": "RR-8528", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a purely declarative approach to artifact-centric case\nmanagement systems, and a decentralization scheme for this model. Each case is\npresented as a tree-like structure; nodes bear information that combines data\nand computations. Each node belongs to a given stakeholder, and semantic rules\ngovern the evolution of the tree structure, as well as how data values derive\nfrom information stemming from the context of the node. Stakeholders\ncommunicate through asynchronous message passing without shared memory,\nenabling convenient distribution.\n", "versions": [{"version": "v1", "created": "Tue, 13 May 2014 16:43:49 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["Badouel", "Eric", "", "INRIA - IRISA, LIRIMA"], ["H\u00e9lou\u00ebt", "Lo\u00efc", "", "INRIA -\n  IRISA"], ["Kouamou", "Georges-Edouard", "", "LIRIMA"], ["Morvan", "Christophe", "", "INRIA - IRISA"]]}, {"id": "1405.3411", "submitter": "Aftab Ahmed Chandio", "authors": "Aftab Ahmed Chandio, Zhibin Yu, Feroz Shah Syed, Imtiaz Ali Korejo", "title": "A Case Study on Job Scheduling Policy for Workload Characterization and\n  Power Efficiency", "comments": "6 pages, 4 figures", "journal-ref": "Sindh University Research Journal (Science Series) Vol. 45(A-1)\n  23- 28 (2013)", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing popularity of cloud computing, datacenters are becoming\nmore important than ever before. A typical datacenter typically consists of a\nlarge number of homogeneous or heterogeneous servers connected by networks.\nUnfortunately, these servers and network equipment are often under-utilized and\npower hungry. To improve the utilization of hardware resources and make them\npower efficiency in datacenters, workload characterization and analysis is at\nthe foundation. In this paper, we characterize and analyze the job arriving\nrate, arriving time, job length, power consumption, and temperature dissipation\nin a real world datacenter by using statistical methods. From the\ncharacterization, we find unique features in the workload can be used to\noptimize the resource utilization and power consumption of datacenters\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2014 08:47:48 GMT"}], "update_date": "2014-05-15", "authors_parsed": [["Chandio", "Aftab Ahmed", ""], ["Yu", "Zhibin", ""], ["Syed", "Feroz Shah", ""], ["Korejo", "Imtiaz Ali", ""]]}, {"id": "1405.3726", "submitter": "Xi Qiu", "authors": "Xi Qiu and Christopher Stewart", "title": "Topic words analysis based on LDA model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DC cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social network analysis (SNA), which is a research field describing and\nmodeling the social connection of a certain group of people, is popular among\nnetwork services. Our topic words analysis project is a SNA method to visualize\nthe topic words among emails from Obama.com to accounts registered in Columbus,\nOhio. Based on Latent Dirichlet Allocation (LDA) model, a popular topic model\nof SNA, our project characterizes the preference of senders for target group of\nreceptors. Gibbs sampling is used to estimate topic and word distribution. Our\ntraining and testing data are emails from the carbon-free server\nDatagreening.com. We use parallel computing tool BashReduce for word processing\nand generate related words under each latent topic to discovers typical\ninformation of political news sending specially to local Columbus receptors.\nRunning on two instances using paralleling tool BashReduce, our project\ncontributes almost 30% speedup processing the raw contents, comparing with\nprocessing contents on one instance locally. Also, the experimental result\nshows that the LDA model applied in our project provides precision rate 53.96%\nhigher than TF-IDF model finding target words, on the condition that\nappropriate size of topic words list is selected.\n", "versions": [{"version": "v1", "created": "Thu, 15 May 2014 02:15:01 GMT"}], "update_date": "2014-05-16", "authors_parsed": [["Qiu", "Xi", ""], ["Stewart", "Christopher", ""]]}, {"id": "1405.3805", "submitter": "{\\AA}smund Ervik", "authors": "{\\AA}smund Ervik, Svend Tollak Munkejord and Bernhard M\\\"uller", "title": "Extending a serial 3D two-phase CFD code to parallel execution over MPI\n  by using the PETSc library for domain decomposition", "comments": "8 pages, 6 figures, final version for to the CFD 2014 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.DC physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To leverage the last two decades' transition in High-Performance Computing\n(HPC) towards clusters of compute nodes bound together with fast interconnects,\na modern scalable CFD code must be able to efficiently distribute work amongst\nseveral nodes using the Message Passing Interface (MPI). MPI can enable very\nlarge simulations running on very large clusters, but it is necessary that the\nbulk of the CFD code be written with MPI in mind, an obstacle to parallelizing\nan existing serial code.\n  In this work we present the results of extending an existing two-phase 3D\nNavier-Stokes solver, which was completely serial, to a parallel execution\nmodel using MPI. The 3D Navier-Stokes equations for two immiscible\nincompressible fluids are solved by the continuum surface force method, while\nthe location of the interface is determined by the level-set method.\n  We employ the Portable Extensible Toolkit for Scientific Computing (PETSc)\nfor domain decomposition (DD) in a framework where only a fraction of the code\nneeds to be altered. We study the strong and weak scaling of the resulting\ncode. Cases are studied that are relevant to the fundamental understanding of\noil/water separation in electrocoalescers.\n", "versions": [{"version": "v1", "created": "Thu, 15 May 2014 11:41:27 GMT"}], "update_date": "2014-05-16", "authors_parsed": [["Ervik", "\u00c5smund", ""], ["Munkejord", "Svend Tollak", ""], ["M\u00fcller", "Bernhard", ""]]}, {"id": "1405.4027", "submitter": "Alex Thomo", "authors": "Ben Kimmett, Alex Thomo, S. Venkatesh", "title": "Three-Way Joins on MapReduce: An Experimental Study", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study three-way joins on MapReduce. Joins are very useful in a multitude\nof applications from data integration and traversing social networks, to mining\ngraphs and automata-based constructions. However, joins are expensive, even for\nmoderate data sets; we need efficient algorithms to perform distributed\ncomputation of joins using clusters of many machines. MapReduce has become an\nincreasingly popular distributed computing system and programming paradigm. We\nconsider a state-of-the-art MapReduce multi-way join algorithm by Afrati and\nUllman and show when it is appropriate for use on very large data sets. By\nproviding a detailed experimental study, we demonstrate that this algorithm\nscales much better than what is suggested by the original paper. However, if\nthe join result needs to be summarized or aggregated, as opposed to being only\nenumerated, then the aggregation step can be integrated into a cascade of\ntwo-way joins, making it more efficient than the other algorithm, and thus\nbecomes the preferred solution.\n", "versions": [{"version": "v1", "created": "Thu, 15 May 2014 22:25:09 GMT"}], "update_date": "2014-05-19", "authors_parsed": [["Kimmett", "Ben", ""], ["Thomo", "Alex", ""], ["Venkatesh", "S.", ""]]}, {"id": "1405.4085", "submitter": "Stefano Ferretti Stefano Ferretti", "authors": "Stefano Ferretti", "title": "On the Topology Maintenance of Dynamic P2P Overlays through Self-Healing\n  Local Interactions", "comments": "A revised version of the paper appears in Proc. of the IFIP\n  Networking 2014 Conference, IEEE, Trondheim, (Norway), June 2014", "journal-ref": null, "doi": "10.1109/IFIPNetworking.2014.6857126", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the use of self-organizing protocols to improve the\nreliability of dynamic Peer-to-Peer (P2P) overlay networks. We present two\napproaches, that employ local knowledge of the 2nd neighborhood of nodes. The\nfirst scheme is a simple protocol requiring interactions among nodes and their\ndirect neighbors. The second scheme extends this approach by resorting to the\nEdge Clustering Coefficient (ECC), a local measure that allows to identify\nthose edges that connect different clusters in an overlay. A simulation\nassessment is presented, which evaluates these protocols over uniform networks,\nclustered networks and scale-free networks. Different failure modes are\nconsidered. Results demonstrate the viability of the proposal.\n", "versions": [{"version": "v1", "created": "Fri, 16 May 2014 08:06:04 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Ferretti", "Stefano", ""]]}, {"id": "1405.4256", "submitter": "Pedro Lopez-Garcia", "authors": "Alejandro Serrano, Pedro Lopez-Garcia and Manuel V. Hermenegildo", "title": "Resource Usage Analysis of Logic Programs via Abstract Interpretation\n  Using Sized Types", "comments": "To appear in Theory and Practice of Logic Programming (TPLP),\n  improved version of arXiv:1308.3940 (which was conference version)", "journal-ref": "Theory and Practice of Logic Programming 14 (2014) 739-754", "doi": "10.1017/S147106841400057X", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel general resource analysis for logic programs based on\nsized types. Sized types are representations that incorporate structural\n(shape) information and allow expressing both lower and upper bounds on the\nsize of a set of terms and their subterms at any position and depth. They also\nallow relating the sizes of terms and subterms occurring at different argument\npositions in logic predicates. Using these sized types, the resource analysis\ncan infer both lower and upper bounds on the resources used by all the\nprocedures in a program as functions on input term (and subterm) sizes,\novercoming limitations of existing resource analyses and enhancing their\nprecision. Our new resource analysis has been developed within the abstract\ninterpretation framework, as an extension of the sized types abstract domain,\nand has been integrated into the Ciao preprocessor, CiaoPP. The abstract domain\noperations are integrated with the setting up and solving of recurrence\nequations for inferring both size and resource usage functions. We show that\nthe analysis is an improvement over the previous resource analysis present in\nCiaoPP and compares well in power to state of the art systems.\n", "versions": [{"version": "v1", "created": "Fri, 16 May 2014 17:59:17 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Serrano", "Alejandro", ""], ["Lopez-Garcia", "Pedro", ""], ["Hermenegildo", "Manuel V.", ""]]}, {"id": "1405.4356", "submitter": "Sriram Pemmaraju", "authors": "James W. Hegeman, Sriram V. Pemmaraju", "title": "Lessons from the Congested Clique Applied to MapReduce", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main results of this paper are (I) a simulation algorithm which, under\nquite general constraints, transforms algorithms running on the Congested\nClique into algorithms running in the MapReduce model, and (II) a distributed\n$O(\\Delta)$-coloring algorithm running on the Congested Clique which has an\nexpected running time of (i) $O(1)$ rounds, if $\\Delta \\geq \\Theta(\\log^4 n)$;\nand (ii) $O(\\log \\log n)$ rounds otherwise. Applying the simulation theorem to\nthe Congested-Clique $O(\\Delta)$-coloring algorithm yields an $O(1)$-round\n$O(\\Delta)$-coloring algorithm in the MapReduce model.\n  Our simulation algorithm illustrates a natural correspondence between\nper-node bandwidth in the Congested Clique model and memory per machine in the\nMapReduce model. In the Congested Clique (and more generally, any network in\nthe $\\mathcal{CONGEST}$ model), the major impediment to constructing fast\nalgorithms is the $O(\\log n)$ restriction on message sizes. Similarly, in the\nMapReduce model, the combined restrictions on memory per machine and total\nsystem memory have a dominant effect on algorithm design. In showing a fairly\ngeneral simulation algorithm, we highlight the similarities and differences\nbetween these models.\n", "versions": [{"version": "v1", "created": "Sat, 17 May 2014 06:31:32 GMT"}, {"version": "v2", "created": "Thu, 19 Jun 2014 21:28:47 GMT"}], "update_date": "2014-06-23", "authors_parsed": [["Hegeman", "James W.", ""], ["Pemmaraju", "Sriram V.", ""]]}, {"id": "1405.4402", "submitter": "Jia Zeng", "authors": "Yi Wang, Xuemin Zhao, Zhenlong Sun, Hao Yan, Lifeng Wang, Zhihui Jin,\n  Liubin Wang, Yang Gao, Ching Law and Jia Zeng", "title": "Peacock: Learning Long-Tail Topic Features for Industrial Applications", "comments": "23 pages, 11 figures, ACM Transactions on Intelligent Systems and\n  Technology, 2015", "journal-ref": "ACM Transactions on Intelligent Systems and Technology, Vol. 6,\n  No. 4, Article 47, 2015", "doi": null, "report-no": null, "categories": "cs.IR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent Dirichlet allocation (LDA) is a popular topic modeling technique in\nacademia but less so in industry, especially in large-scale applications\ninvolving search engine and online advertising systems. A main underlying\nreason is that the topic models used have been too small in scale to be useful;\nfor example, some of the largest LDA models reported in literature have up to\n$10^3$ topics, which cover difficultly the long-tail semantic word sets. In\nthis paper, we show that the number of topics is a key factor that can\nsignificantly boost the utility of topic-modeling systems. In particular, we\nshow that a \"big\" LDA model with at least $10^5$ topics inferred from $10^9$\nsearch queries can achieve a significant improvement on industrial search\nengine and online advertising systems, both of which serving hundreds of\nmillions of users. We develop a novel distributed system called Peacock to\nlearn big LDA models from big data. The main features of Peacock include\nhierarchical distributed architecture, real-time prediction and topic\nde-duplication. We empirically demonstrate that the Peacock system is capable\nof providing significant benefits via highly scalable LDA topic models for\nseveral industrial applications.\n", "versions": [{"version": "v1", "created": "Sat, 17 May 2014 14:36:52 GMT"}, {"version": "v2", "created": "Wed, 3 Dec 2014 09:56:44 GMT"}, {"version": "v3", "created": "Sat, 6 Dec 2014 09:54:43 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Wang", "Yi", ""], ["Zhao", "Xuemin", ""], ["Sun", "Zhenlong", ""], ["Yan", "Hao", ""], ["Wang", "Lifeng", ""], ["Jin", "Zhihui", ""], ["Wang", "Liubin", ""], ["Gao", "Yang", ""], ["Law", "Ching", ""], ["Zeng", "Jia", ""]]}, {"id": "1405.4464", "submitter": "Justin Shi", "authors": "Justin Shi", "title": "Seeking the Principles of Sustainable Software Engineering", "comments": "WSSSPE 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Like other engineering disciplines, software engineering should also have\nprinciples to guide the construction of sustainable computer applications.\nTangible properties include a) unlimited scalability, b) maximal\nreproducibility, and c) optimizable energy efficiency. In practice, we expect a\nsustainable scientific application should be written once and execute many\ntimes on multiple different processing platforms of different scales with\noptimized performance and energy efficiency. For more than two decades,\nexplicit parallel programming/processing paradigms only focused on performance.\nPractices showed that the rigid program-data binding prohibited dynamic runtime\nresource optimization and fault isolation, making it difficult to reproduce\napplications in scale. This paper reports our practice and experiences in\nsearch of the first principles of sustainable software engineering for compute\nand data intensive applications. Specifically, we report our practice and\nexperiences using implicit parallel programming/processing paradigms.\n", "versions": [{"version": "v1", "created": "Sun, 18 May 2014 06:29:02 GMT"}, {"version": "v2", "created": "Mon, 21 Jul 2014 17:58:52 GMT"}, {"version": "v3", "created": "Tue, 22 Jul 2014 03:32:48 GMT"}], "update_date": "2014-07-23", "authors_parsed": [["Shi", "Justin", ""]]}, {"id": "1405.4618", "submitter": "Yunji Wang", "authors": "Wanneng Shu, Wei Wang, Yunji Wang", "title": "A novel energy-efficient resource allocation algorithm based on immune\n  clonal optimization for green cloud computing", "comments": "arXiv admin note: text overlap with arXiv:1006.0308 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Cloud computing is a style of computing in which dynamically scalable and\nother virtualized resources are provided as a service over the Internet. The\nenergy consumption and makespan associated with the resources allocated should\nbe taken into account. This paper proposes an improved clonal selection\nalgorithm based on time cost and energy consumption models in cloud computing\nenvironment. We have analyzed the performance of our approach using the\nCloudSim toolkit. The experimental results show that our approach has immense\npotential as it offers significant improvement in the aspects of response time\nand makespan, demonstrates high potential for the improvement in energy\nefficiency of the data center, and can effectively meet the service level\nagreement requested by the users.\n", "versions": [{"version": "v1", "created": "Mon, 19 May 2014 06:52:59 GMT"}], "update_date": "2014-05-20", "authors_parsed": [["Shu", "Wanneng", ""], ["Wang", "Wei", ""], ["Wang", "Yunji", ""]]}, {"id": "1405.4699", "submitter": "Thanasis Naskos", "authors": "Athanasios Naskos, Emmanouela Stachtiari, Anastasios Gounaris,\n  Panagiotis Katsaros, Dimitrios Tsoumakos, Ioannis Konstantinou, Spyros\n  Sioutas", "title": "Cloud elasticity using probabilistic model checking", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing has become the leading paradigm for deploying large-scale\ninfrastructures and running big data applications, due to its capacity of\nachieving economies of scale. In this work, we focus on one of the most\nprominent advantages of cloud computing, namely the on-demand resource\nprovisioning, which is commonly referred to as elasticity. Although a lot of\neffort has been invested in developing systems and mechanisms that enable\nelasticity, the elasticity decision policies tend to be designed without\nguaranteeing or quantifying the quality of their operation. This work aims to\nmake the development of elasticity policies more formalized and dependable. We\nmake two distinct contributions. First, we propose an extensible approach to\nenforcing elasticity through the dynamic instantiation and online quantitative\nverification of Markov Decision Processes (MDP) using probabilistic model\nchecking. Second, we propose concrete elasticity models and related elasticity\npolicies. We evaluate our decision policies using both real and synthetic\ndatasets in clusters of NoSQL databases. According to the experimental results,\nour approach improves upon the state-of-the-art in significantly increasing\nuser-defined utility values and decreasing user-defined threshold violations.\n", "versions": [{"version": "v1", "created": "Mon, 19 May 2014 12:47:16 GMT"}], "update_date": "2014-05-20", "authors_parsed": [["Naskos", "Athanasios", ""], ["Stachtiari", "Emmanouela", ""], ["Gounaris", "Anastasios", ""], ["Katsaros", "Panagiotis", ""], ["Tsoumakos", "Dimitrios", ""], ["Konstantinou", "Ioannis", ""], ["Sioutas", "Spyros", ""]]}, {"id": "1405.5145", "submitter": "Eli Gafni professor", "authors": "Eli Gafni", "title": "Set Consensus: Captured by a Set of Runs with Ramifications", "comments": "Submited to DISC 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Are (set)-consensus objects necessary? This paper answer is negative.\n  We show that the availability of consensus objects can be replaced by\nrestricting the set of runs we consider. In particular we concentrate of the\nset of runs of the Immediate-Snapshot-Model (IIS), and given the object we\nidentify this restricted subset of IIS runs.\n  We further show that given an $(m,k)$-set consensus, an object that provides\n$k$-set consensus among $m$ processors, in a system of $n$, $n>m$ processors,\nwe do not need to use the precise power of the objects but rather their\neffective cumulative set consensus power. E.g. when $n=3, m=2,$ and $k=1$ and\nall the 3 processors are active then we only use 2-set consensus among the 3\nprocessors, as if 2-processors consensus is not available. We do this until at\nleast one of the 3 processors obtains an output. We show that this suggests a\nnew direction in the design of algorithms when consensus objects are involved.\n", "versions": [{"version": "v1", "created": "Tue, 20 May 2014 16:22:02 GMT"}], "update_date": "2014-05-21", "authors_parsed": [["Gafni", "Eli", ""]]}, {"id": "1405.5200", "submitter": "Narzu Tarannum", "authors": "Narzu Tarannum and Nova Ahmed", "title": "Efficient and Reliable Hybrid Cloud Architechture for Big Data", "comments": "13 pages, 9 figures, International Journal on Cloud Computing:\n  Services and Architecture (IJCCSA), Vol.3, No.6, December 2013", "journal-ref": null, "doi": "10.5121/ijccsa.2013.3602", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of our paper is to propose a Cloud computing framework which is\nfeasible and necessary for handling huge data. In our prototype system we\nconsidered national ID database structure of Bangladesh which is prepared by\nelection commission of Bangladesh. Using this database we propose an\ninteractive graphical user interface for Bangladeshi People Search (BDPS) that\nuse a hybrid structure of cloud computing handled by apache Hadoop where\ndatabase is implemented by HiveQL. The infrastructure divides into two parts:\nlocally hosted cloud which is based on Eucalyptus and the remote cloud which is\nimplemented on well-known Amazon Web Service (AWS). Some common problems of\nBangladesh aspect which includes data traffic congestion, server time out and\nserver down issue is also discussed.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 12:46:41 GMT"}], "update_date": "2014-05-21", "authors_parsed": [["Tarannum", "Narzu", ""], ["Ahmed", "Nova", ""]]}, {"id": "1405.5326", "submitter": "Mahdi Zamani", "authors": "Mahnush Movahedi and Jared Saia and Mahdi Zamani", "title": "Secure Anonymous Broadcast", "comments": "18 Pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In anonymous broadcast, one or more parties want to anonymously send messages\nto all parties. This problem is increasingly important as a black-box in many\nprivacy-preserving applications such as anonymous communication, distributed\nauctions, and multi-party computation. In this paper, we design decentralized\nprotocols for anonymous broadcast that require each party to send (and compute)\na polylogarithmic number of bits (and operations) per anonymous bit delivered\nwith $O(\\log n)$ rounds of communication. Our protocol is provably secure\nagainst traffic analysis, does not require any trusted party, and is completely\nload-balanced. The protocol tolerates up to $n/6$ statically-scheduled\nByzantine parties that are controlled by a computationally unbounded adversary.\nOur main strategy for achieving scalability is to perform local communications\n(and computations) among a logarithmic number of parties. We provide simulation\nresults to show that our protocol improves significantly over previous work. We\nfinally show that using a common cryptographic tool in our protocol one can\nachieve practical results for anonymous broadcast.\n", "versions": [{"version": "v1", "created": "Wed, 21 May 2014 08:12:59 GMT"}], "update_date": "2014-05-22", "authors_parsed": [["Movahedi", "Mahnush", ""], ["Saia", "Jared", ""], ["Zamani", "Mahdi", ""]]}, {"id": "1405.5461", "submitter": "Justin Kopinsky", "authors": "Dan Alistarh, Justin Kopinsky, Alexander Matveev, Nir Shavit", "title": "The LevelArray: A Fast, Practical Long-Lived Renaming Algorithm", "comments": "ICDCS 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The long-lived renaming problem appears in shared-memory systems where a set\nof threads need to register and deregister frequently from the computation,\nwhile concurrent operations scan the set of currently registered threads.\nInstances of this problem show up in concurrent implementations of\ntransactional memory, flat combining, thread barriers, and memory reclamation\nschemes for lock-free data structures. In this paper, we analyze a randomized\nsolution for long-lived renaming. The algorithmic technique we consider, called\nthe LevelArray, has previously been used for hashing and one-shot (single-use)\nrenaming. Our main contribu- tion is to prove that, in long-lived executions,\nwhere processes may register and deregister polynomially many times, the\ntechnique guarantees constant steps on average and O(log log n) steps with high\nprobability for registering, unit cost for deregistering, and O(n) steps for\ncollect queries, where n is an upper bound on the number of processes that may\nbe active at any point in time. We also show that the algorithm has the\nsurprising property that it is self-healing: under reasonable assumptions on\nthe schedule, operations running while the data structure is in a degraded\nstate implicitly help the data structure re-balance itself. This subtle\nmechanism obviates the need for expensive periodic rebuilding procedures. Our\nbenchmarks validate this approach, showing that, for typical use parameters,\nthe average number of steps a process takes to register is less than two and\nthe worst-case number of steps is bounded by six, even in executions with\nbillions of operations. We contrast this with other randomized implementations,\nwhose worst-case behavior we show to be unreliable, and with deterministic\nimplementations, whose cost is linear in n.\n", "versions": [{"version": "v1", "created": "Wed, 21 May 2014 15:57:58 GMT"}], "update_date": "2014-05-22", "authors_parsed": [["Alistarh", "Dan", ""], ["Kopinsky", "Justin", ""], ["Matveev", "Alexander", ""], ["Shavit", "Nir", ""]]}, {"id": "1405.5661", "submitter": "Yan Kit Li", "authors": "Yan Kit Li, Min Xu, Chun Ho Ng, Patrick P. C. Lee", "title": "Efficient Hybrid Inline and Out-of-line Deduplication for Backup Storage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backup storage systems often remove redundancy across backups via inline\ndeduplication, which works by referring duplicate chunks of the latest backup\nto those of existing backups. However, inline deduplication degrades restore\nperformance of the latest backup due to fragmentation, and complicates deletion\nof ex- pired backups due to the sharing of data chunks. While out-of-line\ndeduplication addresses the problems by forward-pointing existing duplicate\nchunks to those of the latest backup, it introduces additional I/Os of writing\nand removing duplicate chunks. We design and implement RevDedup, an efficient\nhybrid inline and out-of-line deduplication system for backup storage. It\napplies coarse-grained inline deduplication to remove duplicates of the latest\nbackup, and then fine-grained out-of-line reverse deduplication to remove\nduplicates from older backups. Our reverse deduplication design limits the I/O\noverhead and prepares for efficient deletion of expired backups. Through\nextensive testbed experiments using synthetic and real-world datasets, we show\nthat RevDedup can bring high performance to the backup, restore, and deletion\noperations, while maintaining high storage efficiency comparable to\nconventional inline deduplication.\n", "versions": [{"version": "v1", "created": "Thu, 22 May 2014 08:13:18 GMT"}], "update_date": "2014-05-23", "authors_parsed": [["Li", "Yan Kit", ""], ["Xu", "Min", ""], ["Ng", "Chun Ho", ""], ["Lee", "Patrick P. C.", ""]]}, {"id": "1405.5689", "submitter": "Srivatsan Ravi Mr", "authors": "Dan Alistarh, Justin Kopinsky, Petr Kuznetsov, Srivatsan Ravi, Nir\n  Shavit", "title": "Inherent Limitations of Hybrid Transactional Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several Hybrid Transactional Memory (HyTM) schemes have recently been\nproposed to complement the fast, but best-effort, nature of Hardware\nTransactional Memory (HTM) with a slow, reliable software backup. However, the\nfundamental limitations of building a HyTM with nontrivial concurrency between\nhardware and software transactions are still not well understood.\n  In this paper, we propose a general model for HyTM implementations, which\ncaptures the ability of hardware transactions to buffer memory accesses, and\nallows us to formally quantify and analyze the amount of overhead\n(instrumentation) of a HyTM scheme. We prove the following: (1) it is\nimpossible to build a strictly serializable HyTM implementation that has both\nuninstrumented reads and writes, even for weak progress guarantees, and (2)\nunder reasonable assumptions, in any opaque progressive HyTM, a hardware\ntransaction must incur instrumentation costs linear in the size of its data\nset. We further provide two upper bound implementations whose instrumentation\ncosts are optimal with respect to their progress guarantees. In sum, this paper\ncaptures for the first time an inherent trade-off between the degree of\nconcurrency a HyTM provides between hardware and software transactions, and the\namount of instrumentation overhead the implementation must incur.\n", "versions": [{"version": "v1", "created": "Thu, 22 May 2014 09:43:07 GMT"}, {"version": "v2", "created": "Thu, 10 Jul 2014 13:05:47 GMT"}, {"version": "v3", "created": "Tue, 17 Feb 2015 11:09:55 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Alistarh", "Dan", ""], ["Kopinsky", "Justin", ""], ["Kuznetsov", "Petr", ""], ["Ravi", "Srivatsan", ""], ["Shavit", "Nir", ""]]}, {"id": "1405.5902", "submitter": "Xavier Urbain", "authors": "Pierre Courtieu (CEDRIC), Lionel Rieg (CEDRIC, ENSIIE), Xavier Urbain\n  (CEDRIC, ENSIIE, LRI), S\\'ebastien Tixeuil (LIP6, LINCS, IUF)", "title": "Impossibility of Gathering, a Certification", "comments": "10p", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Distributed Computing highlight models and algorithms for\nautonomous swarms of mobile robots that self-organise and cooperate to solve\nglobal objectives. The overwhelming majority of works so far considers handmade\nalgorithms and proofs of correctness. This paper builds upon a previously\nproposed formal framework to certify the correctness of impossibility results\nregarding distributed algorithms that are dedicated to autonomous mobile robots\nevolving in a continuous space. As a case study, we consider the problem of\ngathering all robots at a particular location, not known beforehand. A\nfundamental (but not yet formally certified) result, due to Suzuki and\nYamashita, states that this simple task is impossible for two robots executing\ndeterministic code and initially located at distinct positions. Not only do we\nobtain a certified proof of the original impossibility result, we also get the\nmore general impossibility of gathering with an even number of robots, when any\ntwo robots are possibly initially at the same exact location.\n", "versions": [{"version": "v1", "created": "Thu, 22 May 2014 20:34:03 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Courtieu", "Pierre", "", "CEDRIC"], ["Rieg", "Lionel", "", "CEDRIC, ENSIIE"], ["Urbain", "Xavier", "", "CEDRIC, ENSIIE, LRI"], ["Tixeuil", "S\u00e9bastien", "", "LIP6, LINCS, IUF"]]}, {"id": "1405.6162", "submitter": "Alan Gray", "authors": "Alan Gray and Kevin Stratford", "title": "targetDP: an Abstraction of Lattice Based Parallelism with Portable\n  Performance", "comments": "4 pages, 1 figure, to appear in proceedings of HPCC 2014 conference", "journal-ref": "2014 IEEE Intl Conf on High Performance Computing and\n  Communications, 2014", "doi": "10.1109/HPCC.2014.212", "report-no": null, "categories": "cs.DC hep-lat physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To achieve high performance on modern computers, it is vital to map\nalgorithmic parallelism to that inherent in the hardware. From an application\ndeveloper's perspective, it is also important that code can be maintained in a\nportable manner across a range of hardware. Here we present targetDP (target\nData Parallel), a lightweight programming layer that allows the abstraction of\ndata parallelism for applications that employ structured grids. A single source\ncode may be used to target both thread level parallelism (TLP) and instruction\nlevel parallelism (ILP) on either SIMD multi-core CPUs or GPU-accelerated\nplatforms. targetDP is implemented via standard C preprocessor macros and\nlibrary functions, can be added to existing applications incrementally, and can\nbe combined with higher-level paradigms such as MPI. We present CPU and GPU\nperformance results for a benchmark taken from the lattice Boltzmann\napplication that motivated this work. These demonstrate not only performance\nportability, but also the optimisation resulting from the intelligent exposure\nof ILP.\n", "versions": [{"version": "v1", "created": "Tue, 29 Apr 2014 07:51:59 GMT"}, {"version": "v2", "created": "Thu, 31 Jul 2014 13:45:44 GMT"}], "update_date": "2016-06-20", "authors_parsed": [["Gray", "Alan", ""], ["Stratford", "Kevin", ""]]}, {"id": "1405.6169", "submitter": "Takeshi Takahashi", "authors": "Takeshi Takahashi and Youki Kadobayashi and Hiroyuki Fujiwara", "title": "Ontological Approach toward Cybersecurity in Cloud Computing", "comments": "This is a preprint version of our paper presented in SIN'10, Sept.\n  7-11, 2010, Taganrog, Rostov Oblast, Russia, International Conference on\n  Security of Information and Networks, 2010", "journal-ref": null, "doi": "10.1145/1854099.1854121", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Widespread deployment of the Internet enabled building of an emerging IT\ndelivery model, i.e., cloud computing. Albeit cloud computing-based services\nhave rapidly developed, their security aspects are still at the initial stage\nof development. In order to preserve cybersecurity in cloud computing,\ncybersecurity information that will be exchanged within it needs to be\nidentified and discussed. For this purpose, we propose an ontological approach\nto cybersecurity in cloud computing. We build an ontology for cybersecurity\noperational information based on actual cybersecurity operations mainly focused\non non-cloud computing. In order to discuss necessary cybersecurity information\nin cloud computing, we apply the ontology to cloud computing. Through the\ndiscussion, we identify essential changes in cloud computing such as data-asset\ndecoupling and clarify the cybersecurity information required by the changes\nsuch as data provenance and resource dependency information.\n", "versions": [{"version": "v1", "created": "Tue, 1 Apr 2014 08:10:42 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Takahashi", "Takeshi", ""], ["Kadobayashi", "Youki", ""], ["Fujiwara", "Hiroyuki", ""]]}, {"id": "1405.6178", "submitter": "Mehdi Bahrami", "authors": "Mehdi Bahrami, Peyman arebi, Hosseyn Bakhshizadeh, Hamed Barangi", "title": "A Novel Self-Recognition Method for Autonomic Grid Networks Case Study:\n  Advisor Labor Law Software Application", "comments": null, "journal-ref": "Advanced in Information Sciences and Service Sciences. Volume 3,\n  Number 5, pp.262-269, June 2011", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Recently, Grid Computing Systems have provided wide integrated use of\nresources. Grid computing systems provide the ability to share, select and\naggregate distributed resources as computers, storage systems or other devices\nin an integrated way. Grid computing systems have solved many problems in\nscience, engineering and commerce fields. In this paper we introduce a\nself-recognition algorithm for grid network and introduced this algorithm to\nhave exclusive management control on the autonomic grid networks. This\nalgorithm is base on binomial heap to allocate and recognition any node in the\ngrid. We try to using this algorithm in advisor labor law software application\nas case study and shown in this application how to use this method for any\nadvisor application on the network. By this implementation model shown this\nmethod can get better answer to any question as a best labor law advisor.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 01:28:22 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Bahrami", "Mehdi", ""], ["arebi", "Peyman", ""], ["Bakhshizadeh", "Hosseyn", ""], ["Barangi", "Hamed", ""]]}, {"id": "1405.6200", "submitter": "He Li", "authors": "Mianxiong Dong, He Li, Kaoru Ota, Haojin Zhu", "title": "HVSTO: Efficient Privacy Preserving Hybrid Storage in Cloud Data Center", "comments": "7 pages, 8 figures, in proceeding of The Second International\n  Workshop on Security and Privacy in Big Data (BigSecurity 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cloud data center, shared storage with good management is a main structure\nused for the storage of virtual machines (VM). In this paper, we proposed\nHybrid VM storage (HVSTO), a privacy preserving shared storage system designed\nfor the virtual machine storage in large-scale cloud data center. Unlike\ntraditional shared storage, HVSTO adopts a distributed structure to preserve\nprivacy of virtual machines, which are a threat in traditional centralized\nstructure. To improve the performance of I/O latency in this distributed\nstructure, we use a hybrid system to combine solid state disk and distributed\nstorage. From the evaluation of our demonstration system, HVSTO provides a\nscalable and sufficient throughput for the platform as a service\ninfrastructure.\n", "versions": [{"version": "v1", "created": "Fri, 23 May 2014 07:07:59 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Dong", "Mianxiong", ""], ["Li", "He", ""], ["Ota", "Kaoru", ""], ["Zhu", "Haojin", ""]]}, {"id": "1405.6215", "submitter": "Shafi'i Muhammad Abdulhamid Mr", "authors": "Mohammed Bakri Bashir, Muhammad Shafie Abd Latiff, Shafii Muhammad\n  Abdulhamid and Cheah Tek Loon", "title": "Grid-based Search Technique for Massive Academic Publications", "comments": "4 pages, 5 figures, conference. The 2014 Third ICT International\n  Student Project Conference (ICT-ISPC2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The numerical size of academic publications that are being published in\nrecent years had grown rapidly. Accessing and searching massive academic\npublications that are distributed over several locations need large amount of\ncomputing resources to increase the system performance. Therefore, many\ngrid-based search techniques were proposed to provide flexible methods for\nsearching the distributed extensive data. This paper proposes search technique\nthat is capable of searching the extensive publications by utilizing grid\ncomputing technology. The search technique is implemented as interconnected\ngrid services to offer a mechanism to access different data locations. The\nexperimental result shows that the grid-based search technique has enhanced the\nperformance of the search.\n", "versions": [{"version": "v1", "created": "Sun, 30 Mar 2014 13:38:15 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Bashir", "Mohammed Bakri", ""], ["Latiff", "Muhammad Shafie Abd", ""], ["Abdulhamid", "Shafii Muhammad", ""], ["Loon", "Cheah Tek", ""]]}, {"id": "1405.6263", "submitter": "Hemalata  Gosavi A", "authors": "Hemalata A. Gosavi and Manish R. Umale", "title": "Public Auditing and Data Dynamics for Storage Security in Cloud\n  Computing", "comments": "04 pages, 8 figures, \"Published with International Journal of\n  Engineering Trends and Technology (IJETT)\". arXiv admin note: text overlap\n  with arXiv:1211.1457 by other authors", "journal-ref": "IJETT, V11(4), 174-177 May 2014. ISSN:2231-5381", "doi": "10.14445/22315381/IJETT-V11P235", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing has been envisioned as the next generation architecture of IT\nEnterprise. Using Cloud Storage,users can remotely store their data and enjoy\nthe on demand high quality applications and services from a shared pool of\nconfigurable computing resources, without the burden local copy data storage\nand maintenance. It moves the application of software data stored to the\ncentralized large data centers, where the management of the data stored\nservices may not be completely trusted. There are many new security challenges\nand the problems taken into account for ensuring the integrity of data storage\nin Cloud Computing. In particular, we consider the task of allowing a third\nparty auditor (TPA) to perform verifies the integrity of the dynamic data\nstored in the cloud.\n", "versions": [{"version": "v1", "created": "Sat, 24 May 2014 03:46:01 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Gosavi", "Hemalata A.", ""], ["Umale", "Manish R.", ""]]}, {"id": "1405.6362", "submitter": "Rio Yokota Dr.", "authors": "Huda Ibeid, Rio Yokota, David Keyes", "title": "A Performance Model for the Communication in Fast Multipole Methods on\n  HPC Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exascale systems are predicted to have approximately one billion cores,\nassuming Gigahertz cores. Limitations on affordable network topologies for\ndistributed memory systems of such massive scale bring new challenges to the\ncurrent parallel programing model. Currently, there are many efforts to\nevaluate the hardware and software bottlenecks of exascale designs. There is\ntherefore an urgent need to model application performance and to understand\nwhat changes need to be made to ensure extrapolated scalability. The fast\nmultipole method (FMM) was originally developed for accelerating N-body\nproblems in astrophysics and molecular dynamics, but has recently been extended\nto a wider range of problems, including preconditioners for sparse linear\nsolvers. It's high arithmetic intensity combined with its linear complexity and\nasynchronous communication patterns makes it a promising algorithm for exascale\nsystems. In this paper, we discuss the challenges for FMM on current parallel\ncomputers and future exascale architectures, with a focus on inter-node\ncommunication. We develop a performance model that considers the communication\npatterns of the FMM, and observe a good match between our model and the actual\ncommunication time, when latency, bandwidth, network topology, and multi-core\npenalties are all taken into account. To our knowledge, this is the first\nformal characterization of inter-node communication in FMM, which validates the\nmodel against actual measurements of communication time.\n", "versions": [{"version": "v1", "created": "Sun, 25 May 2014 07:28:33 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Ibeid", "Huda", ""], ["Yokota", "Rio", ""], ["Keyes", "David", ""]]}, {"id": "1405.6477", "submitter": "Enrique Mallada", "authors": "Enrique Mallada, Xiaoqiao Meng, Michel Hack, Li Zhang, and Ao Tang", "title": "Skewless Network Clock Synchronization Without Discontinuity:\n  Convergence and Performance", "comments": "to appear in ToN. arXiv admin note: substantial text overlap with\n  arXiv:1208.5703", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines synchronization of computer clocks connected via a data\nnetwork and proposes a skewless algorithm to synchronize them. Unlike existing\nsolutions, which either estimate and compensate the frequency difference (skew)\namong clocks or introduce offset corrections that can generate jitter and\npossibly even backward jumps, our solution achieves synchronization without\nthese problems. We first analyze the convergence property of the algorithm and\nprovide explicit necessary and sufficient conditions on the parameters to\nguarantee synchronization. We then study the effect of noisy measurements\n(jitter) and frequency drift (wander) on the offsets and synchronization\nfrequency, and further optimize the parameter values to minimize their\nvariance. Our study reveals a few insights, for example, we show that our\nalgorithm can converge even in the presence of timing loops and noise, provided\nthat there is a well defined leader. This marks a clear contrast with current\nstandards such as NTP and PTP, where timing loops are specifically avoided.\nFurthermore, timing loops can even be beneficial in our scheme as it is\ndemonstrated that highly connected subnetworks can collectively outperform\nindividual clients when the time source has large jitter. The results are\nsupported by experiments running on a cluster of IBM BladeCenter servers with\nLinux.\n", "versions": [{"version": "v1", "created": "Mon, 26 May 2014 07:01:33 GMT"}, {"version": "v2", "created": "Mon, 28 Jul 2014 16:10:57 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Mallada", "Enrique", ""], ["Meng", "Xiaoqiao", ""], ["Hack", "Michel", ""], ["Zhang", "Li", ""], ["Tang", "Ao", ""]]}, {"id": "1405.6490", "submitter": "Bohar Singh Singh", "authors": "Bohar Singh, Pawan Luthra", "title": "Review of Linpack and Cloudsim on VMM", "comments": "5 Pages", "journal-ref": null, "doi": "10.14445/22315381/IJETT-V11P251", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtualization is a framework of dividing the resources of a computer into\nmultiple execution environments which offers a lot of benefits including\nflexibility, security, ease to configuration and reduction of cost but at the\nsame time it also brings a certain degree of performance overhead. Furthermore,\nVirtual Machine Monitor (VMM) is the core component of virtual machine (VM)\nsystem and its effectiveness greatly impacts the performance of the whole\nsystem. This review paper will try to describe the basic knowledge about\nvarious virtual machine monitors such as VMware and VirtualBox. It also\ndiscussed and explores the benchmark LINPACK and CloudSim available for cloud\ncomputing. This benchmark and CloudSim can be used to measure the performance\nof two different virtual machine monitors in terms of processing speed, time,\nbandwidth, quality and response of the cloud computing network.\n", "versions": [{"version": "v1", "created": "Mon, 26 May 2014 07:50:16 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Singh", "Bohar", ""], ["Luthra", "Pawan", ""]]}, {"id": "1405.7153", "submitter": "Sebastian Nanz", "authors": "Scott West and Sebastian Nanz and Bertrand Meyer", "title": "Efficient and Reasonable Object-Oriented Concurrency", "comments": "Proceedings of the 10th Joint Meeting of the European Software\n  Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of\n  Software Engineering (ESEC/FSE '15). ACM, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making threaded programs safe and easy to reason about is one of the chief\ndifficulties in modern programming. This work provides an efficient execution\nmodel for SCOOP, a concurrency approach that provides not only data race\nfreedom but also pre/postcondition reasoning guarantees between threads. The\nextensions we propose influence both the underlying semantics to increase the\namount of concurrent execution that is possible, exclude certain classes of\ndeadlocks, and enable greater performance. These extensions are used as the\nbasis an efficient runtime and optimization pass that improve performance 15x\nover a baseline implementation. This new implementation of SCOOP is also 2x\nfaster than other well-known safe concurrent languages. The measurements are\nbased on both coordination-intensive and data-manipulation-intensive benchmarks\ndesigned to offer a mixture of workloads.\n", "versions": [{"version": "v1", "created": "Wed, 28 May 2014 08:30:43 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2015 07:59:46 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["West", "Scott", ""], ["Nanz", "Sebastian", ""], ["Meyer", "Bertrand", ""]]}, {"id": "1405.7300", "submitter": "Calvin Newport", "authors": "Calvin Newport", "title": "Radio Network Lower Bounds Made Easy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theoreticians have studied distributed algorithms in the radio network model\nfor close to three decades. A significant fraction of this work focuses on\nlower bounds for basic communication problems such as wake-up (symmetry\nbreaking among an unknown set of nodes) and broadcast (message dissemination\nthrough an unknown network topology). In this paper, we introduce a new\ntechnique for proving this type of bound, based on reduction from a\nprobabilistic hitting game, that simplifies and strengthens much of this\nexisting work. In more detail, in this single paper we prove new expected time\nand high probability lower bounds for wake-up and global broadcast in single\nand multichannel versions of the radio network model both with and without\ncollision detection. In doing so, we are able to reproduce results that\npreviously spanned a half-dozen papers published over a period of twenty-five\nyears. In addition to simplifying these existing results, our technique, in\nmany places, also improves the state of the art: of the eight bounds we prove,\nfour strictly strengthen the best known previous result (in terms of time\ncomplexity and/or generality of the algorithm class for which it holds), and\nthree provide the first known non-trivial bound for the case in question. The\nfact that the same technique can easily generate this diverse collection of\nlower bounds indicates a surprising unity underlying communication tasks in the\nradio network model---revealing that deep down, below the specifics of the\nproblem definition and model assumptions, communication in this setting reduces\nto finding efficient strategies for a simple game.\n", "versions": [{"version": "v1", "created": "Wed, 28 May 2014 16:33:13 GMT"}], "update_date": "2014-05-29", "authors_parsed": [["Newport", "Calvin", ""]]}, {"id": "1405.7461", "submitter": "Michael Gowanlock", "authors": "Michael G. Gowanlock and Henri Casanova", "title": "Technical Report: Parallel Distance Threshold Query Processing for\n  Spatiotemporal Trajectory Databases on the GPU", "comments": "35 pages, 16 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Processing moving object trajectories arises in many application domains and\nhas been addressed by practitioners in the spatiotemporal database and\nGeographical Information System communities. In this work, we focus on a\ntrajectory similarity search, the distance threshold query, which finds all\ntrajectories within a given distance d of a search trajectory over a time\ninterval. We demonstrate the performance of a multithreaded implementation\nwhich features the use of an R-tree index and which has high parallel\nefficiency (78%-90%). We introduce a GPGPU implementation which avoids the use\nof index-trees, and instead features a GPU-friendly indexing method. We compare\nthe performance of the multithreaded and GPU implementations, and show that a\nspeedup can be obtained using the latter. We propose two classes of algorithms,\nSetSplit and GreedySetSplit, to create efficient query batches that reduce\nmemory pressure and computational cost on the GPU. However, we find that using\nfixed-size batches is sufficiently efficient in practice. We develop an\nempirical performance model for our GPGPU implementation that can be used to\npredict the response time of the distance threshold query. This model can be\nused to pick a good query batch size.\n", "versions": [{"version": "v1", "created": "Thu, 29 May 2014 04:44:35 GMT"}, {"version": "v2", "created": "Sat, 13 Sep 2014 03:21:48 GMT"}], "update_date": "2014-09-16", "authors_parsed": [["Gowanlock", "Michael G.", ""], ["Casanova", "Henri", ""]]}, {"id": "1405.7487", "submitter": "Rio Yokota Dr.", "authors": "Mustafa AbdulJabbar, Rio Yokota, David Keyes", "title": "Asynchronous Execution of the Fast Multipole Method Using Charm++", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast multipole methods (FMM) on distributed mem- ory have traditionally used\na bulk-synchronous model of com- municating the local essential tree (LET) and\noverlapping it with computation of the local data. This could be perceived as\nan extreme case of data aggregation, where the whole LET is communicated at\nonce. Charm++ allows a much finer control over the granularity of\ncommunication, and has a asynchronous execution model that fits well with the\nstructure of our FMM code. Unlike previous work on asynchronous fast N-body\nmethods such as ChaNGa and PEPC, the present work performs a direct comparison\nagainst the traditional bulk-synchronous approach and the asynchronous approach\nusing Charm++. Furthermore, the serial performance of our FMM code is over an\norder of magnitude better than these previous codes, so it is much more\nchallenging to hide the overhead of Charm++.\n", "versions": [{"version": "v1", "created": "Thu, 29 May 2014 08:09:35 GMT"}], "update_date": "2014-05-30", "authors_parsed": [["AbdulJabbar", "Mustafa", ""], ["Yokota", "Rio", ""], ["Keyes", "David", ""]]}, {"id": "1405.7958", "submitter": "George Teodoro", "authors": "George Teodoro, Tony Pan, Tahsin Kurc, Jun Kong, Lee Cooper, Scott\n  Klasky, Joel Saltz", "title": "Region Templates: Data Representation and Management for Large-Scale\n  Image Analysis", "comments": "43 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed memory machines equipped with CPUs and GPUs (hybrid computing\nnodes) are hard to program because of the multiple layers of memory and\nheterogeneous computing configurations. In this paper, we introduce a region\ntemplate abstraction for the efficient management of common data types used in\nanalysis of large datasets of high resolution images on clusters of hybrid\ncomputing nodes. The region template provides a generic container template for\ncommon data structures, such as points, arrays, regions, and object sets,\nwithin a spatial and temporal bounding box. The region template abstraction\nenables different data management strategies and data I/O implementations,\nwhile providing a homogeneous, unified interface to the application for data\nstorage and retrieval. The execution of region templates applications is\ncoordinated by a runtime system that supports efficient execution in hybrid\nmachines. Region templates applications are represented as hierarchical\ndataflow in which each computing stage may be represented as another dataflow\nof finer-grain tasks. A number of optimizations for hybrid machines are\navailable in our runtime system, including performance-aware scheduling for\nmaximizing utilization of computing devices and techniques to reduce impact of\ndata transfers between CPUs and GPUs. An experimental evaluation on a\nstate-of-the-art hybrid cluster using a microscopy imaging study shows that\nthis abstraction adds negligible overhead (about 3%) and achieves good\nscalability.\n", "versions": [{"version": "v1", "created": "Fri, 30 May 2014 19:22:46 GMT"}], "update_date": "2014-06-02", "authors_parsed": [["Teodoro", "George", ""], ["Pan", "Tony", ""], ["Kurc", "Tahsin", ""], ["Kong", "Jun", ""], ["Cooper", "Lee", ""], ["Klasky", "Scott", ""], ["Saltz", "Joel", ""]]}]