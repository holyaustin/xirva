[{"id": "1707.00424", "submitter": "Pratik Chaudhari", "authors": "Pratik Chaudhari, Carlo Baldassi, Riccardo Zecchina, Stefano Soatto,\n  Ameet Talwalkar, Adam Oberman", "title": "Parle: parallelizing stochastic gradient descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new algorithm called Parle for parallel training of deep\nnetworks that converges 2-4x faster than a data-parallel implementation of SGD,\nwhile achieving significantly improved error rates that are nearly\nstate-of-the-art on several benchmarks including CIFAR-10 and CIFAR-100,\nwithout introducing any additional hyper-parameters. We exploit the phenomenon\nof flat minima that has been shown to lead to improved generalization error for\ndeep networks. Parle requires very infrequent communication with the parameter\nserver and instead performs more computation on each client, which makes it\nwell-suited to both single-machine, multi-GPU settings and distributed\nimplementations.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jul 2017 07:14:56 GMT"}, {"version": "v2", "created": "Sun, 10 Sep 2017 04:22:49 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Chaudhari", "Pratik", ""], ["Baldassi", "Carlo", ""], ["Zecchina", "Riccardo", ""], ["Soatto", "Stefano", ""], ["Talwalkar", "Ameet", ""], ["Oberman", "Adam", ""]]}, {"id": "1707.00629", "submitter": "Wiktor Daszczuk", "authors": "Jerzy Mie\\'scicki, Wiktor B. Daszczuk, Waldemar Grabski, Artur\n  Krystosik", "title": "Practical Approach to Distributed Systems' Design", "comments": null, "journal-ref": "Scientific Journal of Silesian University of Technology. Series\n  Computer Science. Vol. 34, Proc. V Seminar \"Computer Networks\", 18-19 March\n  1998, Gliwice, Poland, pp. 205-214", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper, based on authors' experience from several distributed systems\nintegration projects, summarizes briefly practical designer's view on\nmethodological requirements and overall system organization, including clues as\nto the organization of the application layer, use of operating system and\npreferred communication protocols.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 19:11:30 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Mie\u015bcicki", "Jerzy", ""], ["Daszczuk", "Wiktor B.", ""], ["Grabski", "Waldemar", ""], ["Krystosik", "Artur", ""]]}, {"id": "1707.00788", "submitter": "Jon Currey", "authors": "Armon Dadgar, James Phillips and Jon Currey", "title": "Lifeguard: Local Health Awareness for More Accurate Failure Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SWIM is a peer-to-peer group membership protocol with attractive scaling and\nrobustness properties. However, slow message processing can cause SWIM to mark\nhealthy members as failed (so called false positive failure detection), despite\ninclusion of a mechanism to avoid this.\n  We identify the properties of SWIM that lead to the problem, and propose\nLifeguard, a set of extensions to SWIM which consider that the local failure\ndetector module may be at fault, via the concept of local health. We evaluate\nthis approach in a precisely controlled environment and validate it in a\nreal-world scenario, showing that it drastically reduces the rate of false\npositives. The false positive rate and detection time for true failures can be\nreduced simultaneously, compared to the baseline levels of SWIM.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 00:35:37 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 07:50:59 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Dadgar", "Armon", ""], ["Phillips", "James", ""], ["Currey", "Jon", ""]]}, {"id": "1707.00832", "submitter": "Gabriele D'Angelo", "authors": "Gabriele D'Angelo, Stefano Ferretti, Vittorio Ghini", "title": "Modeling the Internet of Things: a simulation perspective", "comments": "Proceedings of the IEEE 2017 International Conference on High\n  Performance Computing and Simulation (HPCS 2017)", "journal-ref": null, "doi": "10.1109/HPCS.2017.13", "report-no": null, "categories": "cs.DC cs.MA cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the problem of properly simulating the Internet of\nThings (IoT). Simulating an IoT allows evaluating strategies that can be\nemployed to deploy smart services over different kinds of territories. However,\nthe heterogeneity of scenarios seriously complicates this task. This imposes\nthe use of sophisticated modeling and simulation techniques. We discuss novel\napproaches for the provision of scalable simulation scenarios, that enable the\nreal-time execution of massively populated IoT environments. Attention is given\nto novel hybrid and multi-level simulation techniques that, when combined with\nagent-based, adaptive Parallel and Distributed Simulation (PADS) approaches,\ncan provide means to perform highly detailed simulations on demand. To support\nthis claim, we detail a use case concerned with the simulation of vehicular\ntransportation systems.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 07:16:02 GMT"}, {"version": "v2", "created": "Wed, 20 Sep 2017 13:06:53 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["D'Angelo", "Gabriele", ""], ["Ferretti", "Stefano", ""], ["Ghini", "Vittorio", ""]]}, {"id": "1707.00889", "submitter": "Pushkara Ravindra", "authors": "Pushkara Ravindra, Aakash Khochare, Siva Prakash Reddy, Sarthak\n  Sharma, Prateeksha Varshney and Yogesh Simmhan", "title": "ECHO: An Adaptive Orchestration Platform for Hybrid Dataflows across\n  Cloud and Edge", "comments": "17 pages, 5 figures, 2 tables, submitted to ICSOC-2017", "journal-ref": "Proceedings of the International Conference on Service-Oriented\n  Computing, ICSOC, 2017. Lecture Notes in Computer Science, vol 10601", "doi": "10.1007/978-3-319-69035-3_28", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) is offering unprecedented observational data\nthat are used for managing Smart City utilities. Edge and Fog gateway devices\nare an integral part of IoT deployments to acquire real-time data and enact\ncontrols. Recently, Edge-computing is emerging as first-class paradigm to\ncomplement Cloud-centric analytics. But a key limitation is the lack of a\nplatform-as-a-service for applications spanning Edge and Cloud. Here, we\npropose ECHO, an orchestration platform for dataflows across distributed\nresources. ECHO's hybrid dataflow composition can operate on diverse data\nmodels -- streams, micro-batches and files, and interface with native runtime\nengines like TensorFlow and Storm to execute them. It manages the application's\nlifecycle, including container-based deployment and a registry for state\nmanagement. ECHO can schedule the dataflow on different Edge, Fog and Cloud\nresources, and also perform dynamic task migration between resources. We\nvalidate the ECHO platform for executing video analytics and sensor streams for\nSmart Traffic and Smart Utility applications on Raspberry Pi, NVidia TX1, ARM64\nand Azure Cloud VM resources, and present our results.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 10:09:40 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Ravindra", "Pushkara", ""], ["Khochare", "Aakash", ""], ["Reddy", "Siva Prakash", ""], ["Sharma", "Sarthak", ""], ["Varshney", "Prateeksha", ""], ["Simmhan", "Yogesh", ""]]}, {"id": "1707.00904", "submitter": "Ken-ichiro Ishikawa", "authors": "Ken-ichiro Ishikawa", "title": "Sequential Checking: Reallocation-Free Data-Distribution Algorithm for\n  Scale-out Storage", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using tape or optical devices for scale-out storage is one option for storing\na vast amount of data. However, it is impossible or almost impossible to\nrewrite data with such devices. Thus, scale-out storage using such devices\ncannot use standard data-distribution algorithms because they rewrite data for\nmoving between servers constituting the scale-out storage when the server\nconfiguration is changed. Although using rewritable devices for scale-out\nstorage, when server capacity is huge, rewriting data is very hard when server\nconstitution is changed. In this paper, a data-distribution algorithm called\nSequential Checking is proposed, which can be used for scale-out storage\ncomposed of devices that are hardly able to rewrite data. Sequential Checking\n1) does not need to move data between servers when the server configuration is\nchanged, 2) distribute data, the amount of which depends on the server's\nvolume, 3) select a unique server when datum is written, and 4) select servers\nwhen datum is read (there are few such server(s) in most cases) and find out a\nunique server that stores the newest datum from them. These basic\ncharacteristics were confirmed through proofs and simulations. Data can be read\nby accessing 1.98 servers on average from a storage comprising 256 servers\nunder a realistic condition. And it is confirmed by evaluations in real\nenvironment that access time is acceptable. Sequential Checking makes selecting\nscale-out storage using tape or optical devices or using huge capacity servers\nrealistic.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 10:52:39 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Ishikawa", "Ken-ichiro", ""]]}, {"id": "1707.01428", "submitter": "Jeffery Kinnison", "authors": "Jeff Kinnison, Nathaniel Kremer-Herman, Douglas Thain and Walter\n  Scheirer", "title": "SHADHO: Massively Scalable Hardware-Aware Distributed Hyperparameter\n  Optimization", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer vision is experiencing an AI renaissance, in which machine learning\nmodels are expediting important breakthroughs in academic research and\ncommercial applications. Effectively training these models, however, is not\ntrivial due in part to hyperparameters: user-configured values that control a\nmodel's ability to learn from data. Existing hyperparameter optimization\nmethods are highly parallel but make no effort to balance the search across\nheterogeneous hardware or to prioritize searching high-impact spaces. In this\npaper, we introduce a framework for massively Scalable Hardware-Aware\nDistributed Hyperparameter Optimization (SHADHO). Our framework calculates the\nrelative complexity of each search space and monitors performance on the\nlearning task over all trials. These metrics are then used as heuristics to\nassign hyperparameters to distributed workers based on their hardware. We first\ndemonstrate that our framework achieves double the throughput of a standard\ndistributed hyperparameter optimization framework by optimizing SVM for MNIST\nusing 150 distributed workers. We then conduct model search with SHADHO over\nthe course of one week using 74 GPUs across two compute clusters to optimize\nU-Net for a cell segmentation task, discovering 515 models that achieve a lower\nvalidation loss than standard U-Net.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 15:16:27 GMT"}, {"version": "v2", "created": "Mon, 22 Jan 2018 16:26:17 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Kinnison", "Jeff", ""], ["Kremer-Herman", "Nathaniel", ""], ["Thain", "Douglas", ""], ["Scheirer", "Walter", ""]]}, {"id": "1707.01655", "submitter": "Huanle Xu Mr", "authors": "Huanle Xu, Gustavo de Veciana, Wing Cheong Lau, Kunxiao Zhou", "title": "Online Job Scheduling with Redundancy and Opportunistic Checkpointing: A\n  Speedup-Function-Based Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a large-scale computing cluster, the job completions can be substantially\ndelayed due to two sources of variability, namely, variability in the job size\nand that in the machine service capacity. To tackle this issue, existing works\nhave proposed various scheduling algorithms which exploit redundancy wherein a\njob runs on multiple servers until the first completes. In this paper, we\nexplore the impact of variability in the machine service capacity and adopt a\nrigorous analytical approach to design scheduling algorithms using redundancy\nand checkpointing. We design several online scheduling algorithms which can\ndynamically vary the number of redundant copies for jobs. We also provide new\ntheoretical performance bounds for these algorithms in terms of the overall job\nflowtime by introducing the notion of a speedup function, based on which a\nnovel potential function can be defined to enable the corresponding competitive\nratio analysis. In particular, by adopting the online primal-dual fitting\napproach, we prove that our SRPT+R Algorithm in a non-multitasking cluster is\n$(1+\\epsilon)$-speed, $\\ O(\\frac{1}{\\epsilon})$-competitive. We also show that\nour proposed Fair+R and LAPS+R($\\beta$) Algorithms for a multitasking cluster\nare $(4+\\epsilon)$-speed, $\\ O(\\frac{1}{\\epsilon})$-competitive and {($2 +\n2\\beta + 2\\epsilon)$-speed $O(\\frac{1}{\\beta \\epsilon})$-competitive}\nrespectively. We demonstrate via extensive simulations that our proposed\nalgorithms can significantly reduce job flowtime under both the\nnon-multitasking and multitasking modes.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 06:50:47 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Xu", "Huanle", ""], ["de Veciana", "Gustavo", ""], ["Lau", "Wing Cheong", ""], ["Zhou", "Kunxiao", ""]]}, {"id": "1707.01747", "submitter": "Martin Kleppmann", "authors": "Victor B. F. Gomes, Martin Kleppmann, Dominic P. Mulligan, Alastair R.\n  Beresford", "title": "Verifying Strong Eventual Consistency in Distributed Systems", "comments": null, "journal-ref": "Proceedings of the ACM on Programming Languages (PACMPL), Vol. 1,\n  No. OOPSLA, Article 109, October 2017", "doi": "10.1145/3133933", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data replication is used in distributed systems to maintain up-to-date copies\nof shared data across multiple computers in a network. However, despite decades\nof research, algorithms for achieving consistency in replicated systems are\nstill poorly understood. Indeed, many published algorithms have later been\nshown to be incorrect, even some that were accompanied by supposed mechanised\nproofs of correctness. In this work, we focus on the correctness of\nConflict-free Replicated Data Types (CRDTs), a class of algorithm that provides\nstrong eventual consistency guarantees for replicated data. We develop a\nmodular and reusable framework in the Isabelle/HOL interactive proof assistant\nfor verifying the correctness of CRDT algorithms. We avoid correctness issues\nthat have dogged previous mechanised proofs in this area by including a network\nmodel in our formalisation, and proving that our theorems hold in all possible\nnetwork behaviours. Our axiomatic network model is a standard abstraction that\naccurately reflects the behaviour of real-world computer networks. Moreover, we\nidentify an abstract convergence theorem, a property of order relations, which\nprovides a formal definition of strong eventual consistency. We then obtain the\nfirst machine-checked correctness theorems for three concrete CRDTs: the\nReplicated Growable Array, the Observed-Remove Set, and an Increment-Decrement\nCounter. We find that our framework is highly reusable, developing proofs of\ncorrectness for the latter two CRDTs in a few hours and with relatively little\nCRDT-specific code.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 12:35:08 GMT"}, {"version": "v2", "created": "Fri, 14 Jul 2017 16:37:27 GMT"}, {"version": "v3", "created": "Tue, 29 Aug 2017 07:01:43 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Gomes", "Victor B. F.", ""], ["Kleppmann", "Martin", ""], ["Mulligan", "Dominic P.", ""], ["Beresford", "Alastair R.", ""]]}, {"id": "1707.01869", "submitter": "Shantanu Sharma", "authors": "Shlomi Dolev, Patricia Florissi, Ehud Gudes, Shantanu Sharma, Ido\n  Singer", "title": "A Survey on Geographically Distributed Big-Data Processing using\n  MapReduce", "comments": "IEEE Transactions on Big Data; Accepted June 2017. 20 pages", "journal-ref": null, "doi": "10.1109/TBDATA.2017.2723473", "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hadoop and Spark are widely used distributed processing frameworks for\nlarge-scale data processing in an efficient and fault-tolerant manner on\nprivate or public clouds. These big-data processing systems are extensively\nused by many industries, e.g., Google, Facebook, and Amazon, for solving a\nlarge class of problems, e.g., search, clustering, log analysis, different\ntypes of join operations, matrix multiplication, pattern matching, and social\nnetwork analysis. However, all these popular systems have a major drawback in\nterms of locally distributed computations, which prevent them in implementing\ngeographically distributed data processing. The increasing amount of\ngeographically distributed massive data is pushing industries and academia to\nrethink the current big-data processing systems. The novel frameworks, which\nwill be beyond state-of-the-art architectures and technologies involved in the\ncurrent system, are expected to process geographically distributed data at\ntheir locations without moving entire raw datasets to a single location. In\nthis paper, we investigate and discuss challenges and requirements in designing\ngeographically distributed data processing frameworks and protocols. We\nclassify and study batch processing (MapReduce-based systems), stream\nprocessing (Spark-based systems), and SQL-style processing geo-distributed\nframeworks, models, and algorithms with their overhead issues.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 17:04:46 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Dolev", "Shlomi", ""], ["Florissi", "Patricia", ""], ["Gudes", "Ehud", ""], ["Sharma", "Shantanu", ""], ["Singer", "Ido", ""]]}, {"id": "1707.01873", "submitter": "Christian Cachin", "authors": "Christian Cachin, Marko Vukoli\\'c", "title": "Blockchain Consensus Protocols in the Wild", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A blockchain is a distributed ledger for recording transactions, maintained\nby many nodes without central authority through a distributed cryptographic\nprotocol. All nodes validate the information to be appended to the blockchain,\nand a consensus protocol ensures that the nodes agree on a unique order in\nwhich entries are appended. Consensus protocols for tolerating Byzantine faults\nhave received renewed attention because they also address blockchain systems.\nThis work discusses the process of assessing and gaining confidence in the\nresilience of a consensus protocols exposed to faults and adversarial nodes. We\nadvocate to follow the established practice in cryptography and computer\nsecurity, relying on public reviews, detailed models, and formal proofs; the\ndesigners of several practical systems appear to be unaware of this. Moreover,\nwe review the consensus protocols in some prominent permissioned blockchain\nplatforms with respect to their fault models and resilience against attacks.\nThe protocol comparison covers Hyperledger Fabric, Tendermint, Symbiont,\nR3~Corda, Iroha, Kadena, Chain, Quorum, MultiChain, Sawtooth Lake, Ripple,\nStellar, and IOTA.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 17:21:03 GMT"}, {"version": "v2", "created": "Fri, 7 Jul 2017 05:46:05 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Cachin", "Christian", ""], ["Vukoli\u0107", "Marko", ""]]}, {"id": "1707.01952", "submitter": "Randy Katz", "authors": "Jayanta Basak, Randy H. Katz", "title": "Significance of Disk Failure Prediction in Datacenters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern datacenters assemble a very large number of disk drives under a single\nroof. Even if economic and technical factors where to make individual drives\nmore reliable (which is not at all clear, given the commoditization of the\ntechnology), their sheer numbers combined with their ever increasing\nutilization in a well-balanced design makes achieving storage reliability a\nmajor challenge. In this paper, we assess the challenge of storage system\nreliability in the modern datacenter, and demonstrate how good disk failure\nprediction models can significantly improve the reliability of such systems.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 20:03:17 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Basak", "Jayanta", ""], ["Katz", "Randy H.", ""]]}, {"id": "1707.02000", "submitter": "Kamesh Madduri", "authors": "Humayun Kabir, Kamesh Madduri", "title": "Shared-memory Graph Truss Decomposition", "comments": "10 pages, conference submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present PKT, a new shared-memory parallel algorithm and OpenMP\nimplementation for the truss decomposition of large sparse graphs. A k-truss is\na dense subgraph definition that can be considered a relaxation of a clique.\nTruss decomposition refers to a partitioning of all the edges in the graph\nbased on their k-truss membership. The truss decomposition of a graph has many\napplications. We show that our new approach PKT consistently outperforms other\ntruss decomposition approaches for a collection of large sparse graphs and on a\n24-core shared-memory server. PKT is based on a recently proposed algorithm for\nk-core decomposition.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 00:09:09 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Kabir", "Humayun", ""], ["Madduri", "Kamesh", ""]]}, {"id": "1707.02096", "submitter": "Mohammad Noormohammadpour", "authors": "Mohammad Noormohammadpour, Cauligi S. Raghavendra, Sriram Rao,\n  Srikanth Kandula", "title": "DCCast: Efficient Point to Multipoint Transfers Across Datacenters", "comments": "9th USENIX Workshop on Hot Topics in Cloud Computing,\n  https://www.usenix.org/conference/hotcloud17/program/presentation/noormohammadpour", "journal-ref": "HotCloud (2017) 1-8", "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.PF cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using multiple datacenters allows for higher availability, load balancing and\nreduced latency to customers of cloud services. To distribute multiple copies\nof data, cloud providers depend on inter-datacenter WANs that ought to be used\nefficiently considering their limited capacity and the ever-increasing data\ndemands. In this paper, we focus on applications that transfer objects from one\ndatacenter to several datacenters over dedicated inter-datacenter networks. We\npresent DCCast, a centralized Point to Multi-Point (P2MP) algorithm that uses\nforwarding trees to efficiently deliver an object from a source datacenter to\nrequired destination datacenters. With low computational overhead, DCCast\nselects forwarding trees that minimize bandwidth usage and balance load across\nall links. With simulation experiments on Google's GScale network, we show that\nDCCast can reduce total bandwidth usage and tail Transfer Completion Times\n(TCT) by up to $50\\%$ compared to delivering the same objects via independent\npoint-to-point (P2P) transfers.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 09:25:01 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Noormohammadpour", "Mohammad", ""], ["Raghavendra", "Cauligi S.", ""], ["Rao", "Sriram", ""], ["Kandula", "Srikanth", ""]]}, {"id": "1707.02229", "submitter": "Michele Scquizzato", "authors": "Gianfranco Bilardi, Michele Scquizzato, Francesco Silvestri", "title": "A Lower Bound Technique for Communication in BSP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication is a major factor determining the performance of algorithms on\ncurrent computing systems; it is therefore valuable to provide tight lower\nbounds on the communication complexity of computations. This paper presents a\nlower bound technique for the communication complexity in the bulk-synchronous\nparallel (BSP) model of a given class of DAG computations. The derived bound is\nexpressed in terms of the switching potential of a DAG, that is, the number of\npermutations that the DAG can realize when viewed as a switching network. The\nproposed technique yields tight lower bounds for the fast Fourier transform\n(FFT), and for any sorting and permutation network. A stronger bound is also\nderived for the periodic balanced sorting network, by applying this technique\nto suitable subnetworks. Finally, we demonstrate that the switching potential\ncaptures communication requirements even in computational models different from\nBSP, such as the I/O model and the LPRAM.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 15:31:16 GMT"}, {"version": "v2", "created": "Sat, 25 Nov 2017 16:27:57 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Bilardi", "Gianfranco", ""], ["Scquizzato", "Michele", ""], ["Silvestri", "Francesco", ""]]}, {"id": "1707.02244", "submitter": "Sophie Fosson", "authors": "Attilio Fiandrotti, Sophie M. Fosson, Chiara Ravazzi, and Enrico Magli", "title": "GPU-Accelerated Algorithms for Compressed Signals Recovery with\n  Application to Astronomical Imagery Deblurring", "comments": null, "journal-ref": null, "doi": "10.1080/01431161.2017.1356489", "report-no": null, "categories": "cs.DC astro-ph.IM cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Compressive sensing promises to enable bandwidth-efficient on-board\ncompression of astronomical data by lifting the encoding complexity from the\nsource to the receiver. The signal is recovered off-line, exploiting GPUs\nparallel computation capabilities to speedup the reconstruction process.\nHowever, inherent GPU hardware constraints limit the size of the recoverable\nsignal and the speedup practically achievable. In this work, we design parallel\nalgorithms that exploit the properties of circulant matrices for efficient\nGPU-accelerated sparse signals recovery. Our approach reduces the memory\nrequirements, allowing us to recover very large signals with limited memory. In\naddition, it achieves a tenfold signal recovery speedup thanks to ad-hoc\nparallelization of matrix-vector multiplications and matrix inversions.\nFinally, we practically demonstrate our algorithms in a typical application of\ncirculant matrices: deblurring a sparse astronomical image in the compressed\ndomain.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 15:55:28 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Fiandrotti", "Attilio", ""], ["Fosson", "Sophie M.", ""], ["Ravazzi", "Chiara", ""], ["Magli", "Enrico", ""]]}, {"id": "1707.02423", "submitter": "Robert Lim", "authors": "Robert Lim, Boyana Norris and Allen Malony", "title": "A Similarity Measure for GPU Kernel Subgraph Matching", "comments": null, "journal-ref": "31st International Workshop on Languages and Compilers for\n  Parallel Computing (LCPC), 2018", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accelerator architectures specialize in executing SIMD (single instruction,\nmultiple data) in lockstep. Because the majority of CUDA applications are\nparallelized loops, control flow information can provide an in-depth\ncharacterization of a kernel. CUDAflow is a tool that statically separates CUDA\nbinaries into basic block regions and dynamically measures instruction and\nbasic block frequencies. CUDAflow captures this information in a control flow\ngraph (CFG) and performs subgraph matching across various kernel's CFGs to gain\ninsights to an application's resource requirements, based on the shape and\ntraversal of the graph, instruction operations executed and registers\nallocated, among other information. The utility of CUDAflow is demonstrated\nwith SHOC and Rodinia application case studies on a variety of GPU\narchitectures, revealing novel thread divergence characteristics that\nfacilitates end users, autotuners and compilers in generating high performing\ncode.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jul 2017 09:58:48 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 02:13:06 GMT"}, {"version": "v3", "created": "Thu, 21 Mar 2019 18:57:11 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Lim", "Robert", ""], ["Norris", "Boyana", ""], ["Malony", "Allen", ""]]}, {"id": "1707.02557", "submitter": "Peng Sun", "authors": "Peng Sun, Yonggang Wen, Ta Nguyen Binh Duong, Xiaokui Xiao", "title": "GraphMP: An Efficient Semi-External-Memory Big Graph Processing System\n  on a Single Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies showed that single-machine graph processing systems can be as\nhighly competitive as cluster-based approaches on large-scale problems. While\nseveral out-of-core graph processing systems and computation models have been\nproposed, the high disk I/O overhead could significantly reduce performance in\nmany practical cases. In this paper, we propose GraphMP to tackle big graph\nanalytics on a single machine. GraphMP achieves low disk I/O overhead with\nthree techniques. First, we design a vertex-centric sliding window (VSW)\ncomputation model to avoid reading and writing vertices on disk. Second, we\npropose a selective scheduling method to skip loading and processing\nunnecessary edge shards on disk. Third, we use a compressed edge cache\nmechanism to fully utilize the available memory of a machine to reduce the\namount of disk accesses for edges. Extensive evaluations have shown that\nGraphMP could outperform state-of-the-art systems such as GraphChi, X-Stream\nand GridGraph by 31.6x, 54.5x and 23.1x respectively, when running popular\ngraph applications on a billion-vertex graph.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jul 2017 10:35:26 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Sun", "Peng", ""], ["Wen", "Yonggang", ""], ["Duong", "Ta Nguyen Binh", ""], ["Xiao", "Xiaokui", ""]]}, {"id": "1707.02589", "submitter": "Omer Khan", "authors": "Qingchuan Shi, Hamza Omar, Omer Khan", "title": "Exploiting the Tradeoff between Program Accuracy and Soft-error\n  Resiliency Overhead for Machine Learning Workloads", "comments": "Presented in 2017 IEEE Workshop on Silicon Errors in Logic - System\n  Effects", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To protect multicores from soft-error perturbations, resiliency schemes have\nbeen developed with high coverage but high power and performance overheads.\nEmerging safety-critical machine learning applications are increasingly being\ndeployed on these platforms. Moreover, these systems are exposed to harsh\nenvironments, such as unmanned aerial vehicles (UAVs) and self-driving cars.\nDue to the unique structure and computational behavior of such applications,\nresearch has been done on relaxing their accuracy for performance benefits. We\nobserve that not all transient errors affect program correctness, some errors\nonly affect program accuracy, i.e., the program completes with certain\nacceptable deviations from error free outcome. This paper illustrates the idea\nof cross-layer soft-error resilience using machine learning workloads, where\nprogram accuracy is introduced as a tradeoff to deliver resilient yet efficient\nexecution on futuristic large-scale multicores.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jul 2017 14:50:02 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Shi", "Qingchuan", ""], ["Omar", "Hamza", ""], ["Khan", "Omer", ""]]}, {"id": "1707.02600", "submitter": "Sylvain Hall\\'e", "authors": "Sylvain Hall\\'e and Rapha\\\"el Khoury and S\\'ebastien Gaboury", "title": "Event Stream Processing with Multiple Threads", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current runtime verification tools seldom make use of multi-threading to\nspeed up the evaluation of a property on a large event trace. In this paper, we\npresent an extension to the BeepBeep 3 event stream engine that allows the use\nof multiple threads during the evaluation of a query. Various parallelization\nstrategies are presented and described on simple examples. The implementation\nof these strategies is then evaluated empirically on a sample of problems.\nCompared to the previous, single-threaded version of the BeepBeep engine, the\nallocation of just a few threads to specific portions of a query provides\ndramatic improvement in terms of running time.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jul 2017 16:45:18 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Hall\u00e9", "Sylvain", ""], ["Khoury", "Rapha\u00ebl", ""], ["Gaboury", "S\u00e9bastien", ""]]}, {"id": "1707.02639", "submitter": "Ole Weidner", "authors": "Ole Weidner, Malcolm Atkinson, Adam Barker", "title": "Towards a Comprehensive Framework for Telemetry Data in HPC Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current HPC platforms do not provide the infrastructure, interfaces and\nconceptual models to collect, store, analyze, and access such data. Today,\napplications depend on application and platform specific techniques for\ncollecting telemetry data; introducing significant development overheads that\ninhibit portability and mobility. The development and adoption of adaptive,\ncontext-aware strategies is thereby impaired. To facilitate 2nd generation\napplications, more efficient application development, and swift adoption of\nadaptive applications in production, a comprehensive framework for telemetry\ndata management must be provided by future HPC systems and services. We\nintroduce a conceptual model and a software framework to collect, store,\nanalyze, and exploit streams of telemetry data generated by HPC systems and\ntheir applications. We show how this framework can be integrated with HPC\nplatform architectures and how it enables common application execution\nstrategies.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jul 2017 21:21:20 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Weidner", "Ole", ""], ["Atkinson", "Malcolm", ""], ["Barker", "Adam", ""]]}, {"id": "1707.02647", "submitter": "Mohammad Motamedi", "authors": "Mohammad Motamedi, Daniel Fong, and Soheil Ghiasi", "title": "Cappuccino: Efficient Inference Software Synthesis for Mobile\n  System-on-Chips", "comments": "4 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) exhibit remarkable performance in\nvarious machine learning tasks. As sensor-equipped Internet of Things (IoT)\ndevices permeate into every aspect of modern life, the ability to execute CNN\ninference, a computationally intensive application, on resource constrained\ndevices has become increasingly important. In this context, we present\nCappuccino, a framework for synthesis of efficient inference software targeting\nmobile System-on-Chips (SoCs). We propose techniques for efficient\nparallelization of CNN inference targeting mobile SoCs, and explore the\nunderlying tradeoffs. Experiments with different CNNs on three mobile devices\ndemonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jul 2017 22:03:05 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Motamedi", "Mohammad", ""], ["Fong", "Daniel", ""], ["Ghiasi", "Soheil", ""]]}, {"id": "1707.02789", "submitter": "Anna Engelmann", "authors": "Anna Engelmann, Wolfgang Bziuk, Admela Jukan and Muriel Medard", "title": "Exploiting Parallelism in Optical Network Systems: A Case Study of\n  Random Linear Network Coding (RLNC) in Ethernet-over-Optical Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As parallelism becomes critically important in the semiconductor technology,\nhigh-performance computing, and cloud applications, parallel network systems\nwill increasingly follow suit. Today, parallelism is an essential architectural\nfeature of 40/100/400 Gigabit Ethernet standards, whereby high speed Ethernet\nsystems are equipped with multiple parallel network interfaces. This creates\nnew network topology abstractions and new technology requirements: instead of a\nsingle high capacity network link, multiple Ethernet end-points and interfaces\nneed to be considered together with multiple links in form of discrete parallel\npaths. This new paradigm is enabling implementations of various new features to\nimprove overall system performance. In this paper, we analyze the performance\nof parallel network systems with network coding. In particular, by using random\nLNC (RLNC), - a code without the need for decoding, we can make use of the fact\nthat we have codes that are both distributed (removing the need for\ncoordination or optimization of resources) and composable (without the need to\nexchange code information), leading to a fully stateless operation. We propose\na novel theoretical modeling framework, including derivation of the upper and\nlower bounds as well as an expected value of the differential delay of parallel\npaths, and the resulting queue size at the receiver. The results show a great\npromise of network system parallelism in combination with RLNC: with a proper\nset of design parameters, the differential delay and the buffer size at the\nEthernet receiver can be reduced significantly, while the cross-layer design\nand routing can be greatly simplified.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jul 2017 10:33:07 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Engelmann", "Anna", ""], ["Bziuk", "Wolfgang", ""], ["Jukan", "Admela", ""], ["Medard", "Muriel", ""]]}, {"id": "1707.02895", "submitter": "Michele Amoretti", "authors": "Michele Amoretti and Stefano Carretta", "title": "Entanglement Verification in Quantum Networks with Tampered Nodes", "comments": "14 pages, 7 figures", "journal-ref": "IEEE Journal on Selected Areas in Communications, vol. 38, no. 3,\n  pp. 598-604, 2020", "doi": "10.1109/JSAC.2020.2967955", "report-no": null, "categories": "quant-ph cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of entanglement verification across\nthe quantum memories of any two nodes of a quantum network. Its solution can be\na means for detecting (albeit not preventing) the presence of intruders that\nhave taken full control of a node, either to make a denial-of-service attack or\nto reprogram the node. Looking for strategies that only require local\noperations and classical communication (LOCC), we propose two entanglement\nverification protocols characterized by increasing robustness and efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jul 2017 15:02:39 GMT"}, {"version": "v2", "created": "Sat, 20 Jan 2018 15:43:42 GMT"}, {"version": "v3", "created": "Thu, 16 Apr 2020 15:21:21 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Amoretti", "Michele", ""], ["Carretta", "Stefano", ""]]}, {"id": "1707.03198", "submitter": "Fred Stober", "authors": "F. Stober, M. Fischer, P. Schleper, H. Stadie, C. Garbers, J. Lange,\n  N. Kovalchuk", "title": "The swiss army knife of job submission tools: grid-control", "comments": "8 pages, 7 figures, Proceedings for the 22nd International Conference\n  on Computing in High Energy and Nuclear Physics", "journal-ref": null, "doi": "10.1088/1742-6596/898/9/092052", "report-no": null, "categories": "cs.DC hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grid-control is a lightweight and highly portable open source submission tool\nthat supports virtually all workflows in high energy physics (HEP). Since 2007\nit has been used by a sizeable number of HEP analyses to process tasks that\nsometimes consist of up 100k jobs. grid-control is built around a powerful\nplugin and configuration system, that allows users to easily specify all\naspects of the desired workflow. Job submission to a wide range of local or\nremote batch systems or grid middleware is supported. Tasks can be conveniently\nspecified through the parameter space that will be processed, which can consist\nof any number of variables and data sources with complex dependencies on each\nother. Dataset information is processed through a configurable pipeline of\ndataset filters, partition plugins and partition filters. The partition plugins\ncan take the number of files, size of the work units, metadata or combinations\nthereof into account. All changes to the input datasets or variables are\npropagated through the processing pipeline and can transparently trigger\nadjustments to the parameter space and the job submission. While the core\nfunctionality is completely experiment independent, integration with the CMS\ncomputing environment is provided by a small set of plugins.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 09:46:58 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Stober", "F.", ""], ["Fischer", "M.", ""], ["Schleper", "P.", ""], ["Stadie", "H.", ""], ["Garbers", "C.", ""], ["Lange", "J.", ""], ["Kovalchuk", "N.", ""]]}, {"id": "1707.03350", "submitter": "Kiumars Soltani", "authors": "Kiumars Soltani, Anand Padmanabhan, Shaowen Wang", "title": "MovePattern: Interactive Framework to Provide Scalable Visualization of\n  Movement Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of movement data sources such as GPS traces, traffic\nnetworks and social media have provided analysts with the opportunity to\nexplore collective patterns of geographical movements in a nearly real-time\nfashion. A fast and interactive visualization framework can help analysts to\nunderstand these massive and dynamically changing datasets. However, previous\nstudies on movement visualization either ignore the unique properties of\ngeographical movement or are unable to handle today's massive data. In this\npaper, we develop MovePattern, a novel framework to 1) efficiently construct a\nconcise multi-level view of movements using a scalable and spatially-aware\nMapReduce-based approach and 2) present a fast and highly interactive webbased\nenvironment which engages vector-based visualization to include on-the-fly\ncustomization and the ability to enhance analytical functions by storing\nmetadata for both places and movements. We evaluate the framework using the\nmovements of Twitter users captured from geo-tagged tweets. The experiments\nconfirmed that our framework is able to aggregate close to 180 million\nmovements in a few minutes. In addition, we run series of stress tests on the\nfront-end of the framework to ensure that simultaneous user queries do not lead\nto long latency in the user response.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 03:57:32 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Soltani", "Kiumars", ""], ["Padmanabhan", "Anand", ""], ["Wang", "Shaowen", ""]]}, {"id": "1707.03478", "submitter": "Slobodan Mitrovi\\'c", "authors": "Artur Czumaj, Jakub {\\L}\\k{a}cki, Aleksander M\\k{a}dry, Slobodan\n  Mitrovi\\'c, Krzysztof Onak, Piotr Sankowski", "title": "Round Compression for Parallel Matching Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For over a decade now we have been witnessing the success of {\\em massive\nparallel computation} (MPC) frameworks, such as MapReduce, Hadoop, Dryad, or\nSpark. One of the reasons for their success is the fact that these frameworks\nare able to accurately capture the nature of large-scale computation. In\nparticular, compared to the classic distributed algorithms or PRAM models,\nthese frameworks allow for much more local computation. The fundamental\nquestion that arises in this context is though: can we leverage this additional\npower to obtain even faster parallel algorithms?\n  A prominent example here is the {\\em maximum matching} problem---one of the\nmost classic graph problems. It is well known that in the PRAM model one can\ncompute a 2-approximate maximum matching in $O(\\log{n})$ rounds. However, the\nexact complexity of this problem in the MPC framework is still far from\nunderstood. Lattanzi et al. showed that if each machine has $n^{1+\\Omega(1)}$\nmemory, this problem can also be solved $2$-approximately in a constant number\nof rounds. These techniques, as well as the approaches developed in the follow\nup work, seem though to get stuck in a fundamental way at roughly $O(\\log{n})$\nrounds once we enter the near-linear memory regime. It is thus entirely\npossible that in this regime, which captures in particular the case of sparse\ngraph computations, the best MPC round complexity matches what one can already\nget in the PRAM model, without the need to take advantage of the extra local\ncomputation power.\n  In this paper, we finally refute that perplexing possibility. That is, we\nbreak the above $O(\\log n)$ round complexity bound even in the case of {\\em\nslightly sublinear} memory per machine. In fact, our improvement here is {\\em\nalmost exponential}: we are able to deliver a $(2+\\epsilon)$-approximation to\nmaximum matching, for any fixed constant $\\epsilon>0$, in $O((\\log \\log n)^2)$\nrounds.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 22:10:43 GMT"}, {"version": "v2", "created": "Thu, 1 Feb 2018 18:13:10 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Czumaj", "Artur", ""], ["\u0141\u0105cki", "Jakub", ""], ["M\u0105dry", "Aleksander", ""], ["Mitrovi\u0107", "Slobodan", ""], ["Onak", "Krzysztof", ""], ["Sankowski", "Piotr", ""]]}, {"id": "1707.03492", "submitter": "Paola Flocchini", "authors": "Jean-Lou De Carufel, Paola Flocchini", "title": "Fault-Induced Dynamics of Oblivious Robots on a Line", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of computing in presence of faulty robots in the Look-Compute-Move\nmodel has been the object of extensive investigation, typically with the goal\nof designing algorithms tolerant to as many faults as possible. In this paper,\nwe initiate a new line of investigation on the presence of faults, focusing on\na rather different issue. We are interested in understanding the dynamics of a\ngroup of robots when they execute an algorithm designed for a fault-free\nenvironment, in presence of some undetectable crashed robots. We start this\ninvestigation focusing on the classic point-convergence algorithm by Ando et\nal. for robots with limited visibility, in a simple setting (which already\npresents serious challenges): the robots operate fully synchronously on a line,\nand at most two of them are faulty. Interestingly, and perhaps surprisingly,\nthe presence of faults induces the robots to perform some form of scattering,\nrather than point-convergence. In fact, we discover that they arrange\nthemselves inside the segment delimited by the two faults in interleaved\nsequences of equidistant robots. The structure that they form has a\nhierarchical nature: robots organize themselves in groups where a group of some\nlevel converges to an equidistant distribution only after all groups of lower\nlevels have converged. This is the first study on the unintended dynamics of\noblivious robots induced by the presence of faults.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 23:25:39 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["De Carufel", "Jean-Lou", ""], ["Flocchini", "Paola", ""]]}, {"id": "1707.03515", "submitter": "Jeremy Kepner", "authors": "Chansup Byun, Jeremy Kepner, William Arcand, David Bestor, Bill\n  Bergeron, Vijay Gadepally, Michael Houle, Matthew Hubbell, Michael Jones,\n  Anna Klein, Peter Michaleas, Lauren Milechin, Julie Mullen, Andrew Prout,\n  Antonio Rosa, Siddharth Samsi, Charles Yee, Albert Reuther", "title": "Benchmarking Data Analysis and Machine Learning Applications on the\n  Intel KNL Many-Core Processor", "comments": "6 pages; 9 figures; accepted to IEEE HPEC 2017", "journal-ref": null, "doi": "10.1109/HPEC.2017.8091067", "report-no": null, "categories": "cs.PF astro-ph.IM cs.DC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knights Landing (KNL) is the code name for the second-generation Intel Xeon\nPhi product family. KNL has generated significant interest in the data analysis\nand machine learning communities because its new many-core architecture targets\nboth of these workloads. The KNL many-core vector processor design enables it\nto exploit much higher levels of parallelism. At the Lincoln Laboratory\nSupercomputing Center (LLSC), the majority of users are running data analysis\napplications such as MATLAB and Octave. More recently, machine learning\napplications, such as the UC Berkeley Caffe deep learning framework, have\nbecome increasingly important to LLSC users. Thus, the performance of these\napplications on KNL systems is of high interest to LLSC users and the broader\ndata analysis and machine learning communities. Our data analysis benchmarks of\nthese application on the Intel KNL processor indicate that single-core\ndouble-precision generalized matrix multiply (DGEMM) performance on KNL systems\nhas improved by ~3.5x compared to prior Intel Xeon technologies. Our data\nanalysis applications also achieved ~60% of the theoretical peak performance.\nAlso a performance comparison of a machine learning application, Caffe, between\nthe two different Intel CPUs, Xeon E5 v3 and Xeon Phi 7210, demonstrated a 2.7x\nimprovement on a KNL node.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 02:04:58 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Byun", "Chansup", ""], ["Kepner", "Jeremy", ""], ["Arcand", "William", ""], ["Bestor", "David", ""], ["Bergeron", "Bill", ""], ["Gadepally", "Vijay", ""], ["Houle", "Michael", ""], ["Hubbell", "Matthew", ""], ["Jones", "Michael", ""], ["Klein", "Anna", ""], ["Michaleas", "Peter", ""], ["Milechin", "Lauren", ""], ["Mullen", "Julie", ""], ["Prout", "Andrew", ""], ["Rosa", "Antonio", ""], ["Samsi", "Siddharth", ""], ["Yee", "Charles", ""], ["Reuther", "Albert", ""]]}, {"id": "1707.03527", "submitter": "Rui Wang", "authors": "Rui Wang and Jun Wang", "title": "Oseba: Optimization for Selective Bulk Analysis in Big Data Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selective bulk analyses, such as statistical learning on temporal/spatial\ndata, are fundamental to a wide range of contemporary data analysis. However,\nwith the increasingly larger data-sets, such as weather data and marketing\ntransactions, the data organization/access becomes more challenging in\nselective bulk data processing with the use of current big data processing\nframeworks such as Spark or keyvalue stores. In this paper, we propose a method\nto optimize selective bulk analysis in big data processing and referred to as\nOseba. Oseba maintains a super index for the data organization in memory to\nsupport fast lookup through targeting the data involved with each selective\nanalysis program. Oseba is able to save memory as well as computation in\ncomparison to the default data processing frameworks.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 03:42:21 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["Wang", "Rui", ""], ["Wang", "Jun", ""]]}, {"id": "1707.03682", "submitter": "Yuzhi Wang", "authors": "Yuzhi Wang and Anqi Yang and Xiaoming Chen and Pengjun Wang and Yu\n  Wang and Huazhong Yang", "title": "A Deep Learning Approach for Blind Drift Calibration of Sensor Networks", "comments": null, "journal-ref": "IEEE Sensors Journal, 17 (2017), 4158-4171", "doi": "10.1109/JSEN.2017.2703885", "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal drift of sensory data is a severe problem impacting the data quality\nof wireless sensor networks (WSNs). With the proliferation of large-scale and\nlong-term WSNs, it is becoming more important to calibrate sensors when the\nground truth is unavailable. This problem is called \"blind calibration\". In\nthis paper, we propose a novel deep learning method named projection-recovery\nnetwork (PRNet) to blindly calibrate sensor measurements online. The PRNet\nfirst projects the drifted data to a feature space, and uses a powerful deep\nconvolutional neural network to recover the estimated drift-free measurements.\nWe deploy a 24-sensor testbed and provide comprehensive empirical evidence\nshowing that the proposed method significantly improves the sensing accuracy\nand drifted sensor detection. Compared with previous methods, PRNet can\ncalibrate 2x of drifted sensors at the recovery rate of 80% under the same\nlevel of accuracy requirement. We also provide helpful insights for designing\ndeep neural networks for sensor calibration. We hope our proposed simple and\neffective approach will serve as a solid baseline in blind drift calibration of\nsensor networks.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 17:10:13 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["Wang", "Yuzhi", ""], ["Yang", "Anqi", ""], ["Chen", "Xiaoming", ""], ["Wang", "Pengjun", ""], ["Wang", "Yu", ""], ["Yang", "Huazhong", ""]]}, {"id": "1707.03856", "submitter": "Avery Miller", "authors": "Avery Miller, Boaz Patt-Shamir", "title": "Buffer Size for Routing Limited-Rate Adversarial Traffic", "comments": "19 pages, 2 figures. Corrected version of a paper originally\n  presented at DISC 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the slight variation of the adversarial queuing theory model, in\nwhich an adversary injects packets with routes into the network subject to the\nfollowing constraint: For any link $e$, the total number of packets injected in\nany time window $[t,t')$ and whose route contains $e$, is at most\n$\\rho(t'-t)+\\sigma$, where $\\rho$ and $\\sigma$ are non-negative parameters.\nInformally, $\\rho$ bounds the long-term rate of injections and $\\sigma$ bounds\nthe \"burstiness\" of injection: $\\sigma=0$ means that the injection is as smooth\nas it can be.\n  It is known that greedy scheduling of the packets (under which a link is not\nidle if there is any packet ready to be sent over it) may result in $\\Omega(n)$\nbuffer size even on an $n$-line network and very smooth injections\n($\\sigma=0$). In this paper we propose a simple non-greedy scheduling policy\nand show that, in a tree where all packets are destined at the root, no buffer\nneeds to be larger than $\\sigma+2\\rho$ to ensure that no overflows occur, which\nis optimal in our model. The rule of our algorithm is to forward a packet only\nif its next buffer is completely empty. The policy is centralized: in a single\nstep, a long \"train\" of packets may progress together. We show that in some\nsense central coordination is required, by presenting an injection pattern with\n$\\sigma=0$ for the $n$-node line that results in $\\Omega(n)$ packets in a\nbuffer if local control is used, even for the more sophisticated \"downhill\"\nalgorithm, which forwards a packet only if its next buffer is less occupied\nthan its current one.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 18:31:52 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Miller", "Avery", ""], ["Patt-Shamir", "Boaz", ""]]}, {"id": "1707.04011", "submitter": "Mohammad Noormohammadpour", "authors": "Mohammad Noormohammadpour, Cauligi S. Raghavendra, Sriram Rao", "title": "DCRoute: Speeding up Inter-Datacenter Traffic Allocation while\n  Guaranteeing Deadlines", "comments": "23rd IEEE International Conference on High Performance Computing\n  (HiPC)", "journal-ref": null, "doi": "10.1109/HiPC.2016.019", "report-no": null, "categories": "cs.NI cs.DC cs.PF cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datacenters provide the infrastructure for cloud computing services used by\nmillions of users everyday. Many such services are distributed over multiple\ndatacenters at geographically distant locations possibly in different\ncontinents. These datacenters are then connected through high speed WAN links\nover private or public networks. To perform data backups or data\nsynchronization operations, many transfers take place over these networks that\nhave to be completed before a deadline in order to provide necessary service\nguarantees to end users. Upon arrival of a transfer request, we would like the\nsystem to be able to decide whether such a request can be guaranteed successful\ndelivery. If yes, it should provide us with transmission schedule in the\nshortest time possible. In addition, we would like to avoid packet reordering\nat the destination as it affects TCP performance. Previous work in this area\neither cannot guarantee that admitted transfers actually finish before the\nspecified deadlines or use techniques that can result in packet reordering. In\nthis paper, we propose DCRoute, a fast and efficient routing and traffic\nallocation technique that guarantees transfer completion before deadlines for\nadmitted requests. It assigns each transfer a single path to avoid packet\nreordering. Through simulations, we show that DCRoute is at least 200 times\nfaster than other traffic allocation techniques based on linear programming\n(LP) while admitting almost the same amount of traffic to the system.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 07:47:20 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Noormohammadpour", "Mohammad", ""], ["Raghavendra", "Cauligi S.", ""], ["Rao", "Sriram", ""]]}, {"id": "1707.04282", "submitter": "Miguel Mosteiro", "authors": "Dariusz R. Kowalski and Miguel A. Mosteiro", "title": "Polynomial Counting in Anonymous Dynamic Networks with Applications to\n  Anonymous Dynamic Algebraic Computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Starting with Michail, Chatzigiannakis, and Spirakis work, the problem of\nCounting the number of nodes in Anonymous Dynamic Networks has attracted a lot\nof attention. The problem is challenging because nodes are indistinguishable\n(they lack identifiers and execute the same program) and the topology may\nchange arbitrarily from round to round of communication, as long as the network\nis connected in each round. The problem is central in distributed computing as\nthe number of participants is frequently needed to make important decisions,\nsuch as termination, agreement, synchronization, and many others. A variety of\nalgorithms built on top of mass-distribution techniques have been presented,\nanalyzed, and also experimentally evaluated; some of them assumed additional\nknowledge of network characteristics, such as bounded degree or given upper\nbound on the network size. However, the question of whether Counting can be\nsolved deterministically in sub-exponential time remained open. In this work,\nwe answer this question positively by presenting Methodical Counting, which\nruns in polynomial time and requires no knowledge of network characteristics.\nMoreover, we also show how to extend Methodical Counting to compute the sum of\ninput values and more complex functions without extra cost. Our analysis\nleverages previous work on random walks in evolving graphs, combined with\ncarefully chosen alarms in the algorithm that control the process and its\nparameters. To the best of our knowledge, our Counting algorithm and its\nextensions to other algebraic and Boolean functions are the first that can be\nimplemented in practice with worst-case guarantees.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 18:54:49 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Kowalski", "Dariusz R.", ""], ["Mosteiro", "Miguel A.", ""]]}, {"id": "1707.04338", "submitter": "Chunlei Zhang", "authors": "Chunlei Zhang and Muaz Ahmad and Yongqiang Wang", "title": "ADMM Based Privacy-preserving Decentralized Optimization", "comments": "accepted to IEEE Transactions on Information Forensics and Security", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy preservation is addressed for decentralized optimization, where $N$\nagents cooperatively minimize the sum of $N$ convex functions private to these\nindividual agents. In most existing decentralized optimization approaches,\nparticipating agents exchange and disclose states explicitly, which may not be\ndesirable when the states contain sensitive information of individual agents.\nThe problem is more acute when adversaries exist which try to steal information\nfrom other participating agents. To address this issue, we propose a\nprivacy-preserving decentralized optimization approach based on ADMM and\npartially homomorphic cryptography. To our knowledge, this is the first time\nthat cryptographic techniques are incorporated in a fully decentralized setting\nto enable privacy preservation in decentralized optimization in the absence of\nany third party or aggregator. To facilitate the incorporation of encryption in\na fully decentralized manner, we introduce a new ADMM which allows time-varying\npenalty matrices and rigorously prove that it has a convergence rate of\n$O(1/t)$. Numerical and experimental results confirm the effectiveness and low\ncomputational complexity of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 21:57:47 GMT"}, {"version": "v2", "created": "Sun, 1 Jul 2018 17:18:36 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Zhang", "Chunlei", ""], ["Ahmad", "Muaz", ""], ["Wang", "Yongqiang", ""]]}, {"id": "1707.04449", "submitter": "Yoshiaki Katayama", "authors": "Takashi Okumura, Koichi Wada, Yoshiaki Katayama", "title": "Optimal Asynchronous Rendezvous for Mobile Robots with Lights", "comments": "15 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a Rendezvous problem for 2 autonomous mobile robots in asynchronous\nsettings with persistent memory called light. It is well known that Rendezvous\nis impossible when robots have no lights in basic common models, even if the\nsystem is semi-synchronous. On the other hand, Rendezvous is possible if robots\nhave lights with a constant number of colors in several types lights. In\nasynchronous settings, Rendezvous can be solved by robots with 4 colors of\nlights in non-rigid movement, if robots can use not only own light but also\nother robot's light (full-light), where non-rigid movement means robots may be\nstopped before reaching the computed destination but can move a minimum\ndistance \\delta > 0 and rigid movement means robots can reach the computed\ndestination. In semi-synchronous settings, Rendezvous can be solved with 2\ncolors of full-lights in non-rigid movement.\n  In this paper, we show that in asynchronous settings, Rendezvous can be\nsolved with 2 colors of full-lights in rigid movement and in non-rigid movement\nif robots know the value of the minimum distance \\delta. We also show that\nRendezvous can be solved with 2 colors of full-lights in general non-rigid\nmovement if we consider some reasonable restricted class of asynchronous\nsettings.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 10:37:09 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Okumura", "Takashi", ""], ["Wada", "Koichi", ""], ["Katayama", "Yoshiaki", ""]]}, {"id": "1707.04618", "submitter": "Edgar Solomonik", "authors": "Edgar Solomonik, James Demmel, Torsten Hoefler", "title": "Communication Lower Bounds of Bilinear Algorithms for Symmetric Tensor\n  Contractions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new theoretical framework for deriving lower bounds on data\nmovement in bilinear algorithms. Bilinear algorithms are a general\nrepresentation of fast algorithms for bilinear functions, which include\ncomputation of matrix multiplication, convolution, and symmetric tensor\ncontractions. A bilinear algorithm is described by three matrices. Our\ncommunication lower bounds are based on quantifying the minimal matrix ranks of\nmatching subsets of columns of these matrices. This infrastructure yields new\ncommunication lower bounds for symmetric tensor contraction algorithms, which\nprovide qualitative new insights. Tensor symmetry (invariance under permutation\nof modes) is common to many applications of tensor computations (e.g., tensor\nrepresentation of hypergraphs, analysis of high order moments in data, as well\nas tensors modelling interactions of electrons in computational chemistry).\nTensor symmetry enables reduction in representation size as well as arithmetic\ncost of contractions by factors that scale with the number of equivalent\npermutations. However, we derive lower bounds showing that these arithmetic\ncost and memory reductions can necessitate increases in data movement by\nfactors that scale with the size of the tensors.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 19:46:13 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 22:05:41 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Solomonik", "Edgar", ""], ["Demmel", "James", ""], ["Hoefler", "Torsten", ""]]}, {"id": "1707.04788", "submitter": "Brandon Morris", "authors": "Brandon L. Morris, Anthony Skjellum", "title": "MPIgnite: An MPI-Like Language and Prototype Implementation for Apache\n  Spark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scale-out parallel processing based on MPI is a 25-year-old standard with at\nleast another decade of preceding history of enabling technologies in the High\nPerformance Computing community. Newer frameworks such as MapReduce, Hadoop,\nand Spark represent industrial scalable computing solutions that have received\nbroad adoption because of their comparative simplicity of use, applicability to\nrelevant problems, and ability to harness scalable, distributed resources.\nWhile MPI provides performance and portability, it lacks in productivity and\nfault tolerance. Likewise, Spark is a specific example of a current-generation\nMapReduce and data-parallel computing infrastructure that addresses those goals\nbut in turn lacks peer communication support to allow featherweight, highly\nscalable peer-to-peer data-parallel code sections. The key contribution of this\npaper is to demonstrate how to introduce the collective and point-to-point peer\ncommunication concepts of MPI into a Spark environment. This is done in order\nto produce performance-portable, peer-oriented and group-oriented communication\nservices while retaining the essential, desirable properties of Spark.\nAdditional concepts of fault tolerance and productivity are considered. This\napproach is offered in contrast to adding MapReduce framework as\nupper-middleware based on a traditional MPI implementation as baseline\ninfrastructure.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jul 2017 21:28:03 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Morris", "Brandon L.", ""], ["Skjellum", "Anthony", ""]]}, {"id": "1707.04835", "submitter": "Marc Mosko", "authors": "Marc Mosko", "title": "Process Migration over CCNx", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process migration involves moving the running state of a process from one\nphysical system to another, as is commonly done for virtual machines. In this\npaper, we describe how Content Centric Networking (CCNx) facilitates process\nmigration through an intuitive naming ontology and version checkpointing.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jul 2017 07:12:50 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Mosko", "Marc", ""]]}, {"id": "1707.04939", "submitter": "Yuri G. Gordienko", "authors": "Vladyslav Taran, Oleg Alienin, Sergii Stirenko, A.Rojbi, and Yuri\n  Gordienko", "title": "Performance Evaluation of Distributed Computing Environments with Hadoop\n  and Spark Frameworks", "comments": "5 pages, 1 table, 2017 IEEE International Young Scientists Forum on\n  Applied Physics and Engineering (YSF-2017) (Lviv, Ukraine)", "journal-ref": null, "doi": "10.1109/YSF.2017.8126655", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, due to rapid development of information and communication\ntechnologies, the data are created and consumed in the avalanche way.\nDistributed computing create preconditions for analyzing and processing such\nBig Data by distributing the computations among a number of compute nodes. In\nthis work, performance of distributed computing environments on the basis of\nHadoop and Spark frameworks is estimated for real and virtual versions of\nclusters. As a test task, we chose the classic use case of word counting in\ntexts of various sizes. It was found that the running times grow very fast with\nthe dataset size and faster than a power function even. As to the real and\nvirtual versions of cluster implementations, this tendency is the similar for\nboth Hadoop and Spark frameworks. Moreover, speedup values decrease\nsignificantly with the growth of dataset size, especially for virtual version\nof cluster configuration. The problem of growing data generated by IoT and\nmultimodal (visual, sound, tactile, neuro and brain-computing, muscle and eye\ntracking, etc.) interaction channels is presented. In the context of this\nproblem, the current observations as to the running times and speedup on Hadoop\nand Spark frameworks in real and virtual cluster configurations can be very\nuseful for the proper scaling-up and efficient job management, especially for\nmachine learning and Deep Learning applications, where Big Data are widely\npresent.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jul 2017 19:47:17 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Taran", "Vladyslav", ""], ["Alienin", "Oleg", ""], ["Stirenko", "Sergii", ""], ["Rojbi", "A.", ""], ["Gordienko", "Yuri", ""]]}, {"id": "1707.05014", "submitter": "Caesar Ordonez", "authors": "Caesar E. Ordo\\~nez, Nicholas Karonis, Kirk Duffin, George Coutrakon,\n  Reinhard Schulte, Robert Johnson, Mark Pankuch", "title": "A Real-time Image Reconstruction System for Particle Treatment Planning\n  Using Proton Computed Tomography (pCT)", "comments": "Paper presented at Conference on the Application of Accelerators in\n  Research and Industry, CAARI 2016, 30 October to 4 November 2016, Ft. Worth,\n  TX, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proton computed tomography (pCT) is a novel medical imaging modality for\nmapping the distribution of proton relative stopping power (RSP) in medical\nobjects of interest. Compared to conventional X-ray computed tomography, where\nrange uncertainty margins are around 3.5%, pCT has the potential to provide\nmore accurate measurements to within 1%. This improved efficiency will be\nbeneficial to proton-therapy planning and pre-treatment verification. A\nprototype pCT imaging device has recently been developed capable of rapidly\nacquiring low-dose proton radiographs of head-sized objects. We have also\ndeveloped an advanced, fast image reconstruction software based on distributed\ncomputing that utilizes parallel processors and graphical processing units. The\ncombination of fast data acquisition and fast image reconstruction will enable\nthe availability of RSP images within minutes for use in clinical settings. The\nperformance of our image reconstruction software has been evaluated using data\ncollected by the prototype pCT scanner from several phantoms.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 06:55:22 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Ordo\u00f1ez", "Caesar E.", ""], ["Karonis", "Nicholas", ""], ["Duffin", "Kirk", ""], ["Coutrakon", "George", ""], ["Schulte", "Reinhard", ""], ["Johnson", "Robert", ""], ["Pankuch", "Mark", ""]]}, {"id": "1707.05041", "submitter": "Giuseppe Antonio Di Luna", "authors": "Giuseppe Di Luna, Paola Flocchini, Giuseppe Prencipe, Nicola Santoro,\n  Giovanni Viglietta", "title": "Line-Recovery by Programmable Particles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shape formation has been recently studied in distributed systems of\nprogrammable particles. In this paper we consider the shape recovery problem of\nrestoring the shape when $f$ of the $n$ particles have crashed. We focus on the\nbasic line shape, used as a tool for the construction of more complex\nconfigurations.\n  We present a solution to the line recovery problem by the non-faulty\nanonymous particles; the solution works regardless of the initial distribution\nand number $f<n-4$ of faults, of the local orientations of the non-faulty\nentities, and of the number of non-faulty entities activated in each round\n(i.e., semi-synchronous adversarial scheduler).\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 08:41:43 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Di Luna", "Giuseppe", ""], ["Flocchini", "Paola", ""], ["Prencipe", "Giuseppe", ""], ["Santoro", "Nicola", ""], ["Viglietta", "Giovanni", ""]]}, {"id": "1707.05062", "submitter": "Guillaume Noyel", "authors": "Guillaume Noyel (IPRI, SIGPH@iPRI)", "title": "Speeding up the K\\\"ohler's method of contrast thresholding", "comments": "IEEE CopyrightProceedings of the IEEE International Conference on\n  Image Processing ICIP 2017", "journal-ref": "IEEE. IEEE International Conference on Image Processing ICIP 2017,\n  Sep 2017, Beijing, China. IEEE, 2017, http://2017.ieeeicip.org", "doi": "10.1109/ICIP.2017.8296295", "report-no": null, "categories": "cs.CV cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  K{\\\"o}hler's method is a useful multi-thresholding technique based on\nboundary contrast. However, the direct algorithm has a too high complexity-O(N\n2) i.e. quadratic with the pixel numbers N-to process images at a sufficient\nspeed for practical applications. In this paper, a new algorithm to speed up\nK{\\\"o}hler's method is introduced with a complexity in O(N M), M is the number\nof grey levels. The proposed algorithm is designed for parallelisation and\nvector processing , which are available in current processors, using OpenMP\n(Open Multi-Processing) and SIMD instructions (Single Instruction on Multiple\nData). A fast implementation allows a gain factor of 405 in an image of 18\nmillion pixels and a video processing in real time (gain factor of 96).\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 09:41:04 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 10:43:48 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Noyel", "Guillaume", "", "IPRI, SIGPH@iPRI"]]}, {"id": "1707.05063", "submitter": "Antonella Del", "authors": "Silvia Bonomi, Antonella Del Pozzo (Sorbonne University), Maria\n  Potop-Butucaru (Sorbonne University), S\\'ebastien Tixeuil (Sorbonne\n  University)", "title": "Optimal Storage under Unsynchrononized Mobile Byzantine Faults", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we prove lower and matching upper bounds for the number of\nservers required to implement a regular shared register that tolerates\nunsynchronized Mobile Byzantine failures. We consider the strongest model of\nMobile Byzantine failures to date: agents are moved arbitrarily by an\nomniscient adversary from a server to another in order to deviate their\ncomputation in an unforeseen manner. When a server is infected by an Byzantine\nagent, it behaves arbitrarily until the adversary decides to move the agent to\nanother server. Previous approaches considered asynchronous servers with\nsynchronous mobile Byzantine agents (yielding impossibility results), and\nsynchronous servers with synchronous mobile Byzantine agents (yielding optimal\nsolutions for regular register implementation, even in the case where servers\nand agents periods are decoupled). We consider the remaining open case of\nsynchronous servers with unsynchronized agents, that can move at their own\npace, and change their pace during the execution of the protocol. Most of our\nfindings relate to lower bounds, and characterizing the model parameters that\nmake the problem solvable. It turns out that unsynchronized mobile Byzantine\nagent movements requires completely new proof arguments, that can be of\nindependent interest when studying other problems in this model. Additionally,\nwe propose a generic server-based algorithm that emulates a regular register in\nthis model, that is tight with respect to the number of mobile Byzantine agents\nthat can be tolerated. Our emulation spans two awareness models: servers with\nand without self-diagnose mechanisms. In the first case servers are aware that\nthe mobile Byzantine agent has left and hence they can stop running the\nprotocol until they recover a correct state while in the second case, servers\nare not aware of their faulty state and continue to run the protocol using an\nincorrect local state.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 09:44:55 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Bonomi", "Silvia", "", "Sorbonne University"], ["Del Pozzo", "Antonella", "", "Sorbonne University"], ["Potop-Butucaru", "Maria", "", "Sorbonne University"], ["Tixeuil", "S\u00e9bastien", "", "Sorbonne\n  University"]]}, {"id": "1707.05077", "submitter": "Andrey Kupavskii", "authors": "Andrey Kupavskii, Emo Welzl", "title": "Lower Bounds for Searching Robots, some Faulty", "comments": "Appears in the proceedings of PODC'18. Compared to the previous\n  version, a generalization to m rays is added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.DC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose we are sending out $k$ robots from $0$ to search the real line at\nconstant speed (with turns) to find a target at an unknown location; $f$ of the\nrobots are faulty, meaning that they fail to report the target although\nvisiting its location (called crash type). The goal is to find the target in\ntime at most $\\lambda |d|$, if the target is located at $d$, $|d| \\ge 1$, for\n$\\lambda$ as small as possible. We show that this cannot be achieved for\n$$\\lambda < 2\\frac{\\rho^\\rho}{(\\rho-1)^{\\rho-1}}+1,~~ \\rho :=\n\\frac{2(f+1)}{k}~, $$ which is tight due to earlier work (see J. Czyzowitz, E.\nKranakis, D. Krizanc, L. Narayanan, J. Opatrny, PODC'16, where this problem was\nintroduced). This also gives some better than previously known lower bounds for\nso-called Byzantine-type faulty robots that may actually wrongly report a\ntarget.\n  In the second part of the paper, we deal with the $m$-rays generalization of\nthe problem, where the hidden target is to be detected on $m$ rays all\nemanating at the same point. Using a generalization of our methods, along with\na useful relaxation of the original problem, we establish a tight lower for\nthis setting as well (as above, with $\\rho := m(f+1)/k$). When specialized to\nthe case $f=0$, this resolves the question on parallel search on $m$ rays,\nposed by three groups of scientists some 15 to 30 years ago: by Baeza-Yates,\nCulberson, and Rawlins; by Kao, Ma, Sipser, and Yin; and by Bernstein,\nFinkelstein, and Zilberstein. The $m$-rays generalization is known to have\nconnections to other, seemingly unrelated, problems, including hybrid\nalgorithms for on-line problems, and so-called contract algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 10:23:20 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 16:50:20 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Kupavskii", "Andrey", ""], ["Welzl", "Emo", ""]]}, {"id": "1707.05354", "submitter": "Saman Ashkiani", "authors": "Saman Ashkiani, Shengren Li, Martin Farach-Colton, Nina Amenta, John\n  D. Owens", "title": "GPU LSM: A Dynamic Dictionary Data Structure for the GPU", "comments": "11 pages, accepted to appear on the Proceedings of IEEE International\n  Parallel and Distributed Processing Symposium (IPDPS'18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We develop a dynamic dictionary data structure for the GPU, supporting fast\ninsertions and deletions, based on the Log Structured Merge tree (LSM). Our\nimplementation on an NVIDIA K40c GPU has an average update (insertion or\ndeletion) rate of 225 M elements/s, 13.5x faster than merging items into a\nsorted array. The GPU LSM supports the retrieval operations of lookup, count,\nand range query operations with an average rate of 75 M, 32 M and 23 M\nqueries/s respectively. The trade-off for the dynamic updates is that the\nsorted array is almost twice as fast on retrievals. We believe that our GPU LSM\nis the first dynamic general-purpose dictionary data structure for the GPU.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 18:30:43 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 00:29:56 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Ashkiani", "Saman", ""], ["Li", "Shengren", ""], ["Farach-Colton", "Martin", ""], ["Amenta", "Nina", ""], ["Owens", "John D.", ""]]}, {"id": "1707.05364", "submitter": "Shahzad Ahmed Mr.", "authors": "Shahzad Ahmed, M. Usman Ali, Javed Ferzund, Muhammad Atif Sarwar,\n  Abbas Rehman and Atif Mehmood", "title": "Modern Data Formats for Big Bioinformatics Data Analytics", "comments": "12 Pages, 20 figures and 2 Tables", "journal-ref": "International Journal of Advanced Computer Science and\n  Applications, Issue 8, No. 4, page 366-377 (1 May 2017)", "doi": "10.14569/IJACSA.2017.080450", "report-no": null, "categories": "cs.DB cs.CY cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Next Generation Sequencing (NGS) technology has resulted in massive amounts\nof proteomics and genomics data. This data is of no use if it is not properly\nanalyzed. ETL (Extraction, Transformation, Loading) is an important step in\ndesigning data analytics applications. ETL requires proper understanding of\nfeatures of data. Data format plays a key role in understanding of data,\nrepresentation of data, space required to store data, data I/O during\nprocessing of data, intermediate results of processing, in-memory analysis of\ndata and overall time required to process data. Different data mining and\nmachine learning algorithms require input data in specific types and formats.\nThis paper explores the data formats used by different tools and algorithms and\nalso presents modern data formats that are used on Big Data Platform. It will\nhelp researchers and developers in choosing appropriate data format to be used\nfor a particular tool or algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 5 May 2017 11:35:53 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Ahmed", "Shahzad", ""], ["Ali", "M. Usman", ""], ["Ferzund", "Javed", ""], ["Sarwar", "Muhammad Atif", ""], ["Rehman", "Abbas", ""], ["Mehmood", "Atif", ""]]}, {"id": "1707.05594", "submitter": "Venkatesan Chakaravarthy", "authors": "Venkatesan T Chakaravarthy, Jee W Choi, Douglas J Joseph, Xing Liu,\n  Prakash Murali, Yogish Sabharwal, Dheeraj Sreedhar", "title": "On Optimizing Distributed Tucker Decomposition for Dense Tensors", "comments": "Preliminary version of the paper appears in the proceedings of\n  IPDPS'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Tucker decomposition expresses a given tensor as the product of a small\ncore tensor and a set of factor matrices. Apart from providing data\ncompression, the construction is useful in performing analysis such as\nprincipal component analysis (PCA)and finds applications in diverse domains\nsuch as signal processing, computer vision and text analytics. Our objective is\nto develop an efficient distributed implementation for the case of dense\ntensors. The implementation is based on the HOOI (Higher Order Orthogonal\nIterator) procedure, wherein the tensor-times-matrix product forms the core\nroutine. Prior work have proposed heuristics for reducing the computational\nload and communication volume incurred by the routine. We study the two metrics\nin a formal and systematic manner, and design strategies that are optimal under\nthe two fundamental metrics. Our experimental evaluation on a large benchmark\nof tensors shows that the optimal strategies provide significant reduction in\nload and volume compared to prior heuristics, and provide up to 7x speed-up in\nthe overall running time.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 12:57:22 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Chakaravarthy", "Venkatesan T", ""], ["Choi", "Jee W", ""], ["Joseph", "Douglas J", ""], ["Liu", "Xing", ""], ["Murali", "Prakash", ""], ["Sabharwal", "Yogish", ""], ["Sreedhar", "Dheeraj", ""]]}, {"id": "1707.05629", "submitter": "William Moses Jr.", "authors": "John Augustine, William K. Moses Jr", "title": "Dispersion of Mobile Robots: A Study of Memory-Time Trade-offs", "comments": "18 pages, conference version appeared in ICDCN 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new problem in the domain of mobile robots, which we term\ndispersion. In this problem, $n$ robots are placed in an $n$ node graph\narbitrarily and must coordinate with each other to reach a final configuration\nsuch that exactly one robot is at each node. We study this problem through the\nlenses of minimizing the memory required by each robot and of minimizing the\nnumber of rounds required to achieve dispersion.\n  Dispersion is of interest due to its relationship to the problems of\nscattering on a graph, exploration using mobile robots, and load balancing on a\ngraph. Additionally, dispersion has an immediate real world application due to\nits relationship to the problem of recharging electric cars, as each car can be\nconsidered a robot and recharging stations and the roads connecting them nodes\nand edges of a graph respectively. Since recharging is a costly affair relative\nto traveling, we want to distribute these cars amongst the various available\nrecharge points where communication should be limited to car-to-car\ninteractions.\n  We provide lower bounds on both the memory required for robots to achieve\ndispersion and the minimum running time to achieve dispersion on any type of\ngraph. We then analyze the trade-offs between time and memory for various types\nof graphs. We provide time optimal and memory optimal algorithms for several\ntypes of graphs and show the power of a little memory in terms of running time.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 14:11:02 GMT"}, {"version": "v2", "created": "Mon, 31 Jul 2017 15:56:36 GMT"}, {"version": "v3", "created": "Mon, 16 Oct 2017 13:56:47 GMT"}, {"version": "v4", "created": "Tue, 17 Jul 2018 10:49:01 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Augustine", "John", ""], ["Moses", "William K.", "Jr"]]}, {"id": "1707.05867", "submitter": "Tom Morgan", "authors": "Michael Mitzenmacher and Tom Morgan", "title": "Reconciling Graphs and Sets of Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore a generalization of set reconciliation, where the goal is to\nreconcile sets of sets. Alice and Bob each have a parent set consisting of $s$\nchild sets, each containing at most $h$ elements from a universe of size $u$.\nThey want to reconcile their sets of sets in a scenario where the total number\nof differences between all of their child sets (under the minimum difference\nmatching between their child sets) is $d$. We give several algorithms for this\nproblem, and discuss applications to reconciliation problems on graphs,\ndatabases, and collections of documents. We specifically focus on graph\nreconciliation, providing protocols based on set of sets reconciliation for\nrandom graphs from $G(n,p)$ and for forests of rooted trees.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 21:32:11 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 15:40:48 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Mitzenmacher", "Michael", ""], ["Morgan", "Tom", ""]]}, {"id": "1707.05900", "submitter": "Jeremy Kepner", "authors": "Andrew Prout, William Arcand, David Bestor, Bill Bergeron, Chansup\n  Byun, Vijay Gadepally, Matthew Hubbell, Michael Houle, Michael Jones, Peter\n  Michaleas, Lauren Milechin, Julie Mullen, Antonio Rosa, Siddharth Samsi,\n  Albert Reuther, Jeremy Kepner", "title": "MIT SuperCloud Portal Workspace: Enabling HPC Web Application Deployment", "comments": "6 pages, 3 figures, to appear in IEEE HPEC 2017", "journal-ref": null, "doi": "10.1109/HPEC.2017.8091097", "report-no": null, "categories": "cs.DC cs.HC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The MIT SuperCloud Portal Workspace enables the secure exposure of web\nservices running on high performance computing (HPC) systems. The portal allows\nusers to run any web application as an HPC job and access it from their\nworkstation while providing authentication, encryption, and access control at\nthe system level to prevent unintended access. This capability permits users to\nseamlessly utilize existing and emerging tools that present their user\ninterface as a website on an HPC system creating a portal workspace.\nPerformance measurements indicate that the MIT SuperCloud Portal Workspace\nincurs marginal overhead when compared to a direct connection of the same\nservice.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 00:04:21 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Prout", "Andrew", ""], ["Arcand", "William", ""], ["Bestor", "David", ""], ["Bergeron", "Bill", ""], ["Byun", "Chansup", ""], ["Gadepally", "Vijay", ""], ["Hubbell", "Matthew", ""], ["Houle", "Michael", ""], ["Jones", "Michael", ""], ["Michaleas", "Peter", ""], ["Milechin", "Lauren", ""], ["Mullen", "Julie", ""], ["Rosa", "Antonio", ""], ["Samsi", "Siddharth", ""], ["Reuther", "Albert", ""], ["Kepner", "Jeremy", ""]]}, {"id": "1707.06140", "submitter": "Mikhail Egorov", "authors": "Michael Egorov, MacLane Wilkison and David Nunez", "title": "NuCypher KMS: Decentralized key management system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NuCypher KMS is a decentralized Key Management System (KMS) that addresses\nthe limitations of using consensus networks to securely store and manipulate\nprivate, encrypted data. It provides encryption and cryptographic access\ncontrols, performed by a decentralized network, leveraging proxy re-encryption.\nUnlike centralized KMS as a service solutions, it doesn't require trusting a\nservice provider. NuCypher KMS enables sharing of sensitive data for both\ndecentralized and centralized applications, providing security infrastructure\nfor applications from healthcare to identity management to decentralized\ncontent marketplaces. NuCypher KMS will be an essential part of decentralized\napplications, just as SSL/TLS is an essential part of every secure web\napplication.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 15:10:12 GMT"}, {"version": "v2", "created": "Thu, 20 Jul 2017 22:38:06 GMT"}, {"version": "v3", "created": "Tue, 8 Aug 2017 21:06:26 GMT"}, {"version": "v4", "created": "Sun, 3 Sep 2017 02:03:34 GMT"}, {"version": "v5", "created": "Sun, 12 Nov 2017 21:12:38 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Egorov", "Michael", ""], ["Wilkison", "MacLane", ""], ["Nunez", "David", ""]]}, {"id": "1707.06391", "submitter": "William Moses Jr.", "authors": "Ankush Agarwalla, John Augustine, William K. Moses Jr., Madhav Sankar\n  K., Arvind Krishna Sridhar", "title": "Deterministic Dispersion of Mobile Robots in Dynamic Rings", "comments": "21 pages, 10 figures, concise version of paper to appear in ICDCN\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the problem of dispersion of mobile robots on dynamic\nrings. The problem of dispersion of $n$ robots on an $n$ node graph, introduced\nby Augustine and Moses Jr. [1], requires robots to coordinate with each other\nand reach a configuration where exactly one robot is present on each node. This\nproblem has real world applications and applies whenever we want to minimize\nthe total cost of $n$ agents sharing $n$ resources, located at various places,\nsubject to the constraint that the cost of an agent moving to a different\nresource is comparatively much smaller than the cost of multiple agents sharing\na resource (e.g. smart electric cars sharing recharge stations). The study of\nthis problem also provides indirect benefits to the study of scattering on\ngraphs, the study of exploration by mobile robots, and the study of load\nbalancing on graphs.\n  We solve the problem of dispersion in the presence of two types of dynamism\nin the underlying graph: (i) vertex permutation and (ii) 1-interval\nconnectivity. We introduce the notion of vertex permutation dynamism and have\nit mean that for a given set of nodes, in every round, the adversary ensures a\nring structure is maintained, but the connections between the nodes may change.\nWe use the idea of 1-interval connectivity from Di Luna et al. [10], where for\na given ring, in each round, the adversary chooses at most one edge to remove.\n  We assume robots have full visibility and present asymptotically time optimal\nalgorithms to achieve dispersion in the presence of both types of dynamism when\nrobots have chirality. When robots do not have chirality, we present\nasymptotically time optimal algorithms to achieve dispersion subject to certain\nconstraints. Finally, we provide impossibility results for dispersion when\nrobots have no visibility.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 06:46:15 GMT"}, {"version": "v2", "created": "Wed, 4 Oct 2017 03:29:44 GMT"}, {"version": "v3", "created": "Mon, 16 Oct 2017 13:50:46 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Agarwalla", "Ankush", ""], ["Augustine", "John", ""], ["Moses", "William K.", "Jr."], ["K.", "Madhav Sankar", ""], ["Sridhar", "Arvind Krishna", ""]]}, {"id": "1707.06398", "submitter": "Shuji Kijima", "authors": "Akihiro Monde, Yukiko Yamauchi, Shuji Kijima, Masafumi Yamashita", "title": "Can Walker Localize The Middle Point of A Line-segment?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper poses a question about a simple localization problem. The question\nis if an {\\em oblivious} walker on a line-segment can localize the middle point\nof the line-segment in {\\em finite} steps observing the direction (i.e., Left\nor Right) and the distance to the nearest end point. This problem is arisen\nfrom {\\em self-stabilizing} location problems by {\\em autonomous mobile robots}\nwith {\\em limited visibility}, that is a widely interested abstract model in\ndistributed computing. Contrary to appearances, it is far from trivial if this\nsimple problem is solvable or not, and unsettled yet. This paper is concerned\nwith three variants of the problem with a minimal relaxation, and presents\nself-stabilizing algorithms for them. We also show an easy impossibility\ntheorem for bilaterally symmetric algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 07:13:16 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2019 04:49:57 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Monde", "Akihiro", ""], ["Yamauchi", "Yukiko", ""], ["Kijima", "Shuji", ""], ["Yamashita", "Masafumi", ""]]}, {"id": "1707.06403", "submitter": "\\'Alvaro L\\'opez Garc\\'ia", "authors": "Alvaro Lopez Garcia, Lisa Zangrando, Massimo Sgaravatto, Vincent\n  Llorens, Sara Vallero, Valentina Zaccolo, Stefano Bagnasco, Sonia Taneja,\n  Stefano Dal Pra, Davide Salomoni, Giacinto Donvito", "title": "Improved Cloud resource allocation: how INDIGO-DataCloud is overcoming\n  the current limitations in Cloud schedulers", "comments": null, "journal-ref": "2017 J. Phys.: Conf. Ser. 898 092010", "doi": "10.1088/1742-6596/898/9/092010", "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Performing efficient resource provisioning is a fundamental aspect for any\nresource provider. Local Resource Management Systems (LRMS) have been used in\ndata centers for decades in order to obtain the best usage of the resources,\nproviding their fair usage and partitioning for the users. In contrast, current\ncloud schedulers are normally based on the immediate allocation of resources on\na first-come, first-served basis, meaning that a request will fail if there are\nno resources (e.g. OpenStack) or it will be trivially queued ordered by entry\ntime (e.g. OpenNebula). Moreover, these scheduling strategies are based on a\nstatic partitioning of the resources, meaning that existing quotas cannot be\nexceeded, even if there are idle resources allocated to other projects. This is\na consequence of the fact that cloud instances are not associated with a\nmaximum execution time and leads to a situation where the resources are\nunder-utilized. These facts have been identified by the INDIGO-DataCloud\nproject as being too simplistic for accommodating scientific workloads in an\nefficient way, leading to an underutilization of the resources, a non desirable\nsituation in scientific data centers. In this work, we will present the work\ndone in the scheduling area during the first year of the INDIGO project and the\nforeseen evolutions.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 07:45:59 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Garcia", "Alvaro Lopez", ""], ["Zangrando", "Lisa", ""], ["Sgaravatto", "Massimo", ""], ["Llorens", "Vincent", ""], ["Vallero", "Sara", ""], ["Zaccolo", "Valentina", ""], ["Bagnasco", "Stefano", ""], ["Taneja", "Sonia", ""], ["Pra", "Stefano Dal", ""], ["Salomoni", "Davide", ""], ["Donvito", "Giacinto", ""]]}, {"id": "1707.06420", "submitter": "Matej Arta\\v{c}", "authors": "Craig Sheridan, Darren Whigham, Matej Arta\\v{c}", "title": "DICE Fault Injection Tool", "comments": "QUDOS 2016 submission", "journal-ref": null, "doi": "10.1145/2945408.2945415", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe the motivation, innovation, design, running\nexample and future development of a Fault Inject Tool (FIT). This tool enables\ncontrolled causing of cloud platform issues such as resource stress and service\nor VM outages, the purpose being to observe the subsequent effect on deployed\napplications. It is being designed for use in a DevOps workflow for tighter\ncorrelation between application design and cloud operation, although not\nlimited to this usage, and helps improve resiliency for data intensive\napplications by bringing together fault tolerance, stress testing and\nbenchmarking in a single tool.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 09:16:53 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Sheridan", "Craig", ""], ["Whigham", "Darren", ""], ["Arta\u010d", "Matej", ""]]}, {"id": "1707.06470", "submitter": "Josef Mich\\'alek", "authors": "Jan Vanek, Josef Michalek, Josef Psutka", "title": "A Comparison of Support Vector Machines Training GPU-Accelerated Open\n  Source Implementations", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Last several years, GPUs are used to accelerate computations in many computer\nscience domains. We focused on GPU accelerated Support Vector Machines (SVM)\ntraining with non-linear kernel functions. We had searched for all available\nGPU accelerated C++ open-source implementations and created an open-source C++\nbenchmark project. We modifed all the implementations to run on actual hardware\nand software and in both Windows and Linux operating systems. The benchmark\nproject offers making a fair and direct comparison of the individual\nimplementations under the same conditions, datasets, and hardware. In addition,\nwe selected the most popular datasets in the community and tested them.\nFinally, based on the evaluation, we recommended the best-performing\nimplementations for dense and sparse datasets.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 12:20:52 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Vanek", "Jan", ""], ["Michalek", "Josef", ""], ["Psutka", "Josef", ""]]}, {"id": "1707.06560", "submitter": "Alessandro Bianchi PhD", "authors": "Alessandro Bianchi, Sebastiano Pizzutilo, Gennaro Vessio", "title": "An ASM-based Characterization of Starvation-free Systems", "comments": "This is an Accepted Manuscript of an article published by Taylor &\n  Francis Group in the International Journal of Parallel, Emergent &\n  Distributed Systems on 14/02/2017, available online:\n  http://www.tandfonline.com/10.1080/17445760.2017.1288808", "journal-ref": "International Journal of Parallel, Emergent & Distributed Systems\n  (2017)", "doi": "10.1080/17445760.2017.1288808", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract State Machines (ASMs) have been successfully applied for modeling\ncritical and complex systems in a wide range of application domains. However,\nunlike other well-known formalisms, e.g. Petri nets, ASMs lack inherent,\ndomain-independent characterisations of computationally important properties.\nHere, we provide an ASM-based characterisation of the starvation-free property.\nThe classic, informal notion of starvation, usually provided in literature, is\nanalysed and expressed as a necessary condition in terms of ASMs. Thus, we\nenrich the ASM framework with the notion of vulnerable rule as a practical tool\nfor analysing starvation issues in an operational fashion\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 15:06:30 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Bianchi", "Alessandro", ""], ["Pizzutilo", "Sebastiano", ""], ["Vessio", "Gennaro", ""]]}, {"id": "1707.06665", "submitter": "Sergey Pupyrev", "authors": "Igor Kabiljo and Brian Karrer and Mayank Pundir and Sergey Pupyrev and\n  Alon Shalita and Alessandro Presta and Yaroslav Akhremtsev", "title": "Social Hash Partitioner: A Scalable Distributed Hypergraph Partitioner", "comments": "Proceedings of the VLDB Endowment 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design and implement a distributed algorithm for balanced $k$-way\nhypergraph partitioning that minimizes fanout, a fundamental hypergraph\nquantity also known as the communication volume and ($k-1$)-cut metric, by\noptimizing a novel objective called probabilistic fanout. This choice allows a\nsimple local search heuristic to achieve comparable solution quality to the\nbest existing hypergraph partitioners.\n  Our algorithm is arbitrarily scalable due to a careful design that controls\ncomputational complexity, space complexity, and communication. In practice, we\ncommonly process hypergraphs with billions of vertices and hyperedges in a few\nhours. We explain how the algorithm's scalability, both in terms of hypergraph\nsize and bucket count, is limited only by the number of machines available. We\nperform an extensive comparison to existing distributed hypergraph partitioners\nand find that our approach is able to optimize hypergraphs roughly $100$ times\nbigger on the same set of machines.\n  We call the resulting tool Social Hash Partitioner (SHP), and accompanying\nthis paper, we open-source the most scalable version based on recursive\nbisection.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 18:17:36 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Kabiljo", "Igor", ""], ["Karrer", "Brian", ""], ["Pundir", "Mayank", ""], ["Pupyrev", "Sergey", ""], ["Shalita", "Alon", ""], ["Presta", "Alessandro", ""], ["Akhremtsev", "Yaroslav", ""]]}, {"id": "1707.06776", "submitter": "Huda Chuangpishit", "authors": "Huda Chuangpishit, Jurek Czyzowicz, Evangelos Kranakis, Danny Krizanc", "title": "Rendezvous on a Line by Location-Aware Robots Despite the Presence of\n  Byzantine Faults", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A set of mobile robots is placed at points of an infinite line. The robots\nare equipped with GPS devices and they may communicate their positions on the\nline to a central authority. The collection contains an unknown subset of\n\"spies\", i.e., byzantine robots, which are indistinguishable from the\nnon-faulty ones. The set of the non-faulty robots need to rendezvous in the\nshortest possible time in order to perform some task, while the byzantine\nrobots may try to delay their rendezvous for as long as possible. The problem\nfacing a central authority is to determine trajectories for all robots so as to\nminimize the time until the non-faulty robots have rendezvoused. The\ntrajectories must be determined without knowledge of which robots are faulty.\nOur goal is to minimize the competitive ratio between the time required to\nachieve the first rendezvous of the non-faulty robots and the time required for\nsuch a rendezvous to occur under the assumption that the faulty robots are\nknown at the start. We provide a bounded competitive ratio algorithm, where the\ncentral authority is informed only of the set of initial robot positions,\nwithout knowing which ones or how many of them are faulty. When an upper bound\non the number of byzantine robots is known to the central authority, we provide\nalgorithms with better competitive ratios. In some instances we are able to\nshow these algorithms are optimal.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 07:10:20 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Chuangpishit", "Huda", ""], ["Czyzowicz", "Jurek", ""], ["Kranakis", "Evangelos", ""], ["Krizanc", "Danny", ""]]}, {"id": "1707.07137", "submitter": "Gal Oren", "authors": "Gal Oren, Yehuda Ganan, Guy Malamud", "title": "AutOMP: An Automatic OpenMP Parallelization Generator for\n  Variable-Oriented High-Performance Scientific Codes", "comments": "The 7th International Supercomputing Conference in Mexico 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OpenMP is a cross-platform API that extends C, C++ and Fortran and provides\nshared-memory parallelism platform for those languages. The use of many cores\nand HPC technologies for scientific computing has been spread since the 1990s,\nand now takes part in many fields of research. The relative ease of\nimplementing OpenMP, along with the development of multi-core shared memory\nprocessors (such as Intel Xeon Phi) makes OpenMP a favorable method for\nparallelization in the process of modernizing a legacy codes. Legacy scientific\ncodes are usually holding large number of physical arrays which being used and\nupdated by the code routines. In most of the cases the parallelization of such\ncode focuses on loop parallelization. A key step in this parallelization is\ndeciding which of the variables in the parallelized scope should be private (so\neach thread will hold a copy of them), and which variables should be shared\nacross the threads. Other important step is finding which variables should be\nsynchronized after the loop execution. In this work we present an automatic\npre-processor that preforms these stages - AutOMP (Automatic OpenMP). AutOMP\nrecognize all the variables assignments inside a loop. These variables will be\nprivate unless the assignment is of an array element which depend on the loop\nindex variable. Afterwards, AutOMP finds the places where threads\nsynchronization is needed, and which reduction operator is to be used. At last,\nthe program provides the parallelization command to be used for parallelizing\nthe loop.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jul 2017 11:02:51 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Oren", "Gal", ""], ["Ganan", "Yehuda", ""], ["Malamud", "Guy", ""]]}, {"id": "1707.07263", "submitter": "Fan Zhang", "authors": "Fan Zhang, Chen Hu, Qiang Yin and Wei Hu", "title": "A GPU Based Memory Optimized Parallel Method For FFT Implementation", "comments": "15 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FFT (fast Fourier transform) plays a very important role in many fields, such\nas digital signal processing, digital image processing and so on. However, in\napplication, FFT becomes a factor of affecting the processing efficiency,\nespecially in remote sensing, which large amounts of data need to be processed\nwith FFT. So shortening the FFT computation time is particularly important. GPU\n(Graphics Processing Unit) has been used in many common areas and its\nacceleration effect is very obvious compared with CPU (Central Processing Unit)\nplatform. In this paper, we present a new parallel method to execute FFT on\nGPU. Based on GPU storage system and hardware processing pipeline, we improve\nthe way of data storage. We divided the data into parts reasonably according\nthe size of data to make full use of the characteristics of the GPU. We propose\nthe memory optimized method based on share memory and texture memory to reduce\nthe number of global memory access to achieve better efficiency. The results\nshow that the GPU-based memory optimized FFT implementation not only can\nincrease over 100% than FFTW library in CPU platform, but also can improve over\n30% than CUFFT library in GPU platform.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jul 2017 07:57:37 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Zhang", "Fan", ""], ["Hu", "Chen", ""], ["Yin", "Qiang", ""], ["Hu", "Wei", ""]]}, {"id": "1707.07426", "submitter": "Naama Kraus", "authors": "Naama Kraus, David Carmel, Idit Keidar", "title": "Tail-Tolerant Distributed Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's search engines process billions of online user queries a day over\nhuge collections of data. In order to scale, they distribute query processing\namong many nodes, where each node holds and searches over a subset of the index\ncalled shard. Responses from some nodes occasionally fail to arrive within a\nreasonable time-interval due to various reasons, such as high server load and\nnetwork congestion. Search engines typically need to respond in a timely\nmanner, and therefore skip such tail latency responses, which causes\ndegradation in search quality. In this paper, we tackle response misses due to\nhigh tail latencies with the goal of maximizing search quality.\n  Search providers today use redundancy in the form of Replication for\nmitigating response misses, by constructing multiple copies of each shard and\nsearching all replicas. This approach is not ideal, as it wastes resources on\nsearching duplicate data. We propose two strategies to reduce this waste.\nFirst, we propose rSmartRed, an optimal shard selection scheme for replicated\nindexes. Second, when feasible, we propose to replace Replication with\nRepartition, which constructs independent index instances instead of exact\ncopies. We analytically prove that rSmartRed's selection is optimal for\nReplication, and that Repartition achieves better search quality compared to\nReplication. We confirm our results with an empirical study using two\nreal-world datasets, showing that rSmartRed improves recall compared to\ncurrently used approaches. We additionally show that Repartition improves over\nReplication in typical scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 07:32:06 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Kraus", "Naama", ""], ["Carmel", "David", ""], ["Keidar", "Idit", ""]]}, {"id": "1707.07452", "submitter": "Blesson Varghese", "authors": "Blesson Varghese and Rajkumar Buyya", "title": "Next Generation Cloud Computing: New Trends and Research Directions", "comments": "Accepted to Future Generation Computer Systems, 07 September 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The landscape of cloud computing has significantly changed over the last\ndecade. Not only have more providers and service offerings crowded the space,\nbut also cloud infrastructure that was traditionally limited to single provider\ndata centers is now evolving. In this paper, we firstly discuss the changing\ncloud infrastructure and consider the use of infrastructure from multiple\nproviders and the benefit of decentralising computing away from data centers.\nThese trends have resulted in the need for a variety of new computing\narchitectures that will be offered by future cloud infrastructure. These\narchitectures are anticipated to impact areas, such as connecting people and\ndevices, data-intensive computing, the service space and self-learning systems.\nFinally, we lay out a roadmap of challenges that will need to be addressed for\nrealising the potential of next generation cloud systems.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 09:42:58 GMT"}, {"version": "v2", "created": "Thu, 7 Sep 2017 15:33:30 GMT"}, {"version": "v3", "created": "Fri, 8 Sep 2017 06:52:30 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Varghese", "Blesson", ""], ["Buyya", "Rajkumar", ""]]}, {"id": "1707.07478", "submitter": "Francesco Quaglia Prof.", "authors": "Mauro Ianni, Alessandro Pellegrini, Francesco Quaglia", "title": "A Wait-free Multi-word Atomic (1,N) Register for Large-scale Data\n  Sharing on Multi-core Machines", "comments": "none", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a multi-word atomic (1,N) register for multi-core machines\nexploiting Read-Modify-Write (RMW) instructions to coordinate the writer and\nthe readers in a wait-free manner. Our proposal, called Anonymous Readers\nCounting (ARC), enables large-scale data sharing by admitting up to $2^{32}-2$\nconcurrent readers on off-the-shelf 64-bits machines, as opposed to the most\nadvanced RMW-based approach which is limited to 58 readers. Further, ARC avoids\nmultiple copies of the register content when accessing it---this affects\nclassical register's algorithms based on atomic read/write operations on single\nwords. Thus it allows for higher scalability with respect to the register size.\nMoreover, ARC explicitly reduces improves performance via a proper limitation\nof RMW instructions in case of read operations, and by supporting constant time\nfor read operations and amortized constant time for write operations. A proof\nof correctness of our register algorithm is also provided, together with\nexperimental data for a comparison with literature proposals. Beyond assessing\nARC on physical platforms, we carry out as well an experimentation on\nvirtualized infrastructures, which shows the resilience of wait-free\nsynchronization as provided by ARC with respect to CPU-steal times, proper of\nmore modern paradigms such as cloud computing.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 11:01:30 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Ianni", "Mauro", ""], ["Pellegrini", "Alessandro", ""], ["Quaglia", "Francesco", ""]]}, {"id": "1707.07659", "submitter": "Lewis Tseng", "authors": "Lewis Tseng", "title": "An Improved Approximate Consensus Algorithm in the Presence of Mobile\n  Faults", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the problem of reaching approximate consensus in\nsynchronous point-to-point networks, where each pair of nodes is able to\ncommunicate with each other directly and reliably. We consider the mobile\nByzantine fault model proposed by Garay '94 -- in the model, an omniscient\nadversary can corrupt up to $f$ nodes in each round, and at the beginning of\neach round, faults may \"move\" in the system (i.e., different sets of nodes may\nbecome faulty in different rounds). Recent work by Bonomi et al. '16 proposed a\nsimple iterative approximate consensus algorithm which requires at least $4f+1$\nnodes. This paper proposes a novel technique of using \"confession\" (a mechanism\nto allow others to ignore past behavior) and a variant of reliable broadcast to\nimprove the fault-tolerance level. In particular, we present an approximate\nconsensus algorithm that requires only $\\lceil 7f/2\\rceil + 1$ nodes, an\n$\\lfloor f/2 \\rfloor$ improvement over the state-of-the-art algorithms.\nMoreover, we also show that the proposed algorithm is optimal within a family\nof round-based algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 17:36:25 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Tseng", "Lewis", ""]]}, {"id": "1707.07699", "submitter": "Vidhya Tekken Valapil", "authors": "Vidhya Tekken Valapil, Sorrachai Yingchareonthawornchai, Sandeep\n  Kulkarni, Eric Torng and Murat Demirbas", "title": "Monitoring Partially Synchronous Distributed Systems using SMT Solvers", "comments": "Technical Report corresponding to the paper accepted at Runtime\n  Verification (RV) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss the feasibility of monitoring partially synchronous\ndistributed systems to detect latent bugs, i.e., errors caused by concurrency\nand race conditions among concurrent processes. We present a monitoring\nframework where we model both system constraints and latent bugs as\nSatisfiability Modulo Theories (SMT) formulas, and we detect the presence of\nlatent bugs using an SMT solver. We demonstrate the feasibility of our\nframework using both synthetic applications where latent bugs occur at any time\nwith random probability and an application involving exclusive access to a\nshared resource with a subtle timing bug. We illustrate how the time required\nfor verification is affected by parameters such as communication frequency,\nlatency, and clock skew. Our results show that our framework can be used for\nreal-life applications, and because our framework uses SMT solvers, the range\nof appropriate applications will increase as these solvers become more\nefficient over time.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 18:13:13 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Valapil", "Vidhya Tekken", ""], ["Yingchareonthawornchai", "Sorrachai", ""], ["Kulkarni", "Sandeep", ""], ["Torng", "Eric", ""], ["Demirbas", "Murat", ""]]}, {"id": "1707.07788", "submitter": "Himanshu Chauhan", "authors": "Himanshu Chauhan and Vijay Garg", "title": "Space Efficient Breadth-First and Level Traversals of Consistent Global\n  States of Parallel Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enumerating consistent global states of a computation is a fundamental\nproblem in parallel computing with applications to debug- ging, testing and\nruntime verification of parallel programs. Breadth-first search (BFS)\nenumeration is especially useful for these applications as it finds an\nerroneous consistent global state with the least number of events possible. The\ntotal number of executed events in a global state is called its rank. BFS also\nallows enumeration of all global states of a given rank or within a range of\nranks. If a computation on n processes has m events per process on average,\nthen the traditional BFS (Cooper-Marzullo and its variants) requires\n$\\mathcal{O}(\\frac{m^{n-1}}{n})$ space in the worst case, whereas ou r\nalgorithm performs the BFS requires $\\mathcal{O}(m^2n^2)$ space. Thus, we\nreduce the space complexity for BFS enumeration of consistent global states\nexponentially. and give the first polynomial space algorithm for this task. In\nour experimental evaluation of seven benchmarks, traditional BFS fails in many\ncases by exhausting the 2 GB heap space allowed to the JVM. In contrast, our\nimplementation uses less than 60 MB memory and is also faster in many cases.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 01:56:59 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Chauhan", "Himanshu", ""], ["Garg", "Vijay", ""]]}, {"id": "1707.08167", "submitter": "El Mahdi El Mhamdi", "authors": "El Mahdi El Mhamdi, Rachid Guerraoui, Sebastien Rouault", "title": "On The Robustness of a Neural Network", "comments": "36th IEEE International Symposium on Reliable Distributed Systems 26\n  - 29 September 2017. Hong Kong, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of neural networks based machine learning and their\nusage in mission critical applications, voices are rising against the\n\\textit{black box} aspect of neural networks as it becomes crucial to\nunderstand their limits and capabilities. With the rise of neuromorphic\nhardware, it is even more critical to understand how a neural network, as a\ndistributed system, tolerates the failures of its computing nodes, neurons, and\nits communication channels, synapses. Experimentally assessing the robustness\nof neural networks involves the quixotic venture of testing all the possible\nfailures, on all the possible inputs, which ultimately hits a combinatorial\nexplosion for the first, and the impossibility to gather all the possible\ninputs for the second.\n  In this paper, we prove an upper bound on the expected error of the output\nwhen a subset of neurons crashes. This bound involves dependencies on the\nnetwork parameters that can be seen as being too pessimistic in the average\ncase. It involves a polynomial dependency on the Lipschitz coefficient of the\nneurons activation function, and an exponential dependency on the depth of the\nlayer where a failure occurs. We back up our theoretical results with\nexperiments illustrating the extent to which our prediction matches the\ndependencies between the network parameters and robustness. Our results show\nthat the robustness of neural networks to the average crash can be estimated\nwithout the need to neither test the network on all failure configurations, nor\naccess the training set used to train the network, both of which are\npractically impossible requirements.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 19:22:55 GMT"}, {"version": "v2", "created": "Mon, 7 Aug 2017 16:18:24 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Mhamdi", "El Mahdi El", ""], ["Guerraoui", "Rachid", ""], ["Rouault", "Sebastien", ""]]}, {"id": "1707.08216", "submitter": "Imtiaz Parvez", "authors": "Imtiaz Parvez, Arif I. Sarwat, Jonathan Pinto, Zakaria Parvez,\n  Mohammad Aqib Khandaker", "title": "A Gossip Algorithm based Clock Synchronization Scheme for Smart Grid\n  Applications", "comments": null, "journal-ref": "2017 North American Power Symposium (NAPS), Morgantown, WV, 2017,\n  pp. 1-6", "doi": "10.1109/NAPS.2017.8107405", "report-no": null, "categories": "cs.SY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The uprising interest in multi-agent based networked system, and the numerous\nnumber of applications in the distributed control of the smart grid leads us to\naddress the problem of time synchronization in the smart grid. Utility\ncompanies look for new packet based time synchronization solutions with Global\nPositioning System (GPS) level accuracies beyond traditional packet methods\nsuch as Network Time Proto- col (NTP). However GPS based solutions have poor\nreception in indoor environments and dense urban canyons as well as GPS antenna\ninstallation might be costly. Some smart grid nodes such as Phasor Measurement\nUnits (PMUs), fault detection, Wide Area Measurement Systems (WAMS) etc.,\nrequires synchronous accuracy as low as 1 ms. On the other hand, 1 sec accuracy\nis acceptable in management information domain. Acknowledging this, in this\nstudy, we introduce gossip algorithm based clock synchronization method among\nnetwork entities from the decision control and communication point of view. Our\nmethod synchronizes clock within dense network with a bandwidth limited\nenvironment. Our technique has been tested in different kinds of network\ntopologies- complete, star and random geometric network and demonstrated\nsatisfactory performance.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 20:57:21 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Parvez", "Imtiaz", ""], ["Sarwat", "Arif I.", ""], ["Pinto", "Jonathan", ""], ["Parvez", "Zakaria", ""], ["Khandaker", "Mohammad Aqib", ""]]}, {"id": "1707.08357", "submitter": "Ajay Singh", "authors": "Ajay Singh, Sathya Peri, G Monika and Anila Kumari", "title": "Performance Comparison of Various STM Concurrency Control Protocols\n  Using Synchrobench", "comments": "7 pages, 10 figures, This work was selected and presented at\n  PARCOMPTECH 2017 : National Conference on Parallel Computing Technologies\n  PARCOMPTECH 17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Writing concurrent programs for shared memory multiprocessor systems is a\nnightmare. This hinders users to exploit the full potential of multiprocessors.\nSTM (Software Transactional Memory) is a promising concurrent programming\nparadigm which addresses woes of programming for multiprocessor systems.\n  In this paper, we implement BTO (Basic Timestamp Ordering), SGT\n(Serialization Graph Testing) and MVTO(Multi-Version Time-Stamp Ordering)\nconcurrency control protocols and build an STM(Software Transactional Memory)\nlibrary to evaluate the performance of these protocols. The deferred write\napproach is followed to implement the STM. A SET data structure is implemented\nusing the transactions of our STM library. And this transactional SET is used\nas a test application to evaluate the STM. The performance of the protocols is\nrigorously compared against the linked-list module of the Synchrobench\nbenchmark. Linked list module implements SET data structure using lazy-list,\nlock-free list, lock-coupling list and ESTM (Elastic Software Transactional\nMemory).\n  Our analysis shows that for a number of threads greater than 60 and update\nrate 70%, BTO takes (17% to 29%) and (6% to 24%) less CPU time per thread when\ncompared against lazy-list and lock-coupling list respectively. MVTO takes (13%\nto 24%) and (3% to 24%) less CPU time per thread when compared against\nlazy-list and lock-coupling list respectively. BTO and MVTO have similar per\nthread CPU time. BTO and MVTO outperform SGT by 9% to 36%.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 10:24:36 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Singh", "Ajay", ""], ["Peri", "Sathya", ""], ["Monika", "G", ""], ["Kumari", "Anila", ""]]}, {"id": "1707.08484", "submitter": "Tomasz Jurdzinski", "authors": "Tomasz Jurdzinski and Krzysztof Nowicki", "title": "MST in O(1) Rounds of the Congested Clique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a distributed randomized algorithm finding Minimum Spanning Tree\n(MST) of a given graph in O(1) rounds, with high probability, in the Congested\nClique model. The input graph in the Congested Clique model is a graph of n\nnodes, where each node initially knows only its incident edges. The\ncommunication graph is a clique with limited edge bandwidth: each two nodes\n(not necessarily neighbours in the input graph) can exchange $O(\\log n)$ bits.\n  As in previous works, the key part of the MST algorithm is an efficient\nConnected Components (CC) algorithm. However, unlike the former approaches, we\ndo not aim at simulating the standard Boruvka algorithm, at least at initial\nstages of the CC algorithm. Instead, we develop a new technique which combines\nconnected components of sample sparse subgraphs of the input graph in order to\naccelerate the process of uncovering connected components of the original input\ngraph. More specifically, we develop a sparsification technique which reduces\nan initial CC problem in $O(1)$ rounds to its two restricted instances. The\nformer instance has a graph with maximal degree $O(\\log \\log n)$ as the input\n-- here our sample-combining technique helps. In the latter instance, a\npartition of the input graph into $O(n/\\log \\log n)$ connected components is\nknown. This gives an opportunity to apply previous algorithms to determine\nconnected components in $O(1)$ rounds.\n  Our result addresses the problem from and the $O(\\log \\log n)$ algorithm of\nLotker et al. [SPAA 2003; SICOMP 2005], improves over previous $O(\\log* n)$\nalgorithm of Ghaffari et al. [PODC 2016] and $O(\\log \\log \\log n)$ algorithm of\nHegeman et al. [PODC 2015] . It also determines $\\Theta(1)$ round complexity in\nthe congested clique for MST, as well as other graph problems, including\nbipartiteness, cut verification, s-t connectivity and cycle containment.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 15:04:22 GMT"}, {"version": "v2", "created": "Thu, 27 Jul 2017 12:54:35 GMT"}, {"version": "v3", "created": "Tue, 31 Oct 2017 16:33:48 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Jurdzinski", "Tomasz", ""], ["Nowicki", "Krzysztof", ""]]}, {"id": "1707.08496", "submitter": "Keren Censor-Hillel", "authors": "Keren Censor-Hillel, Rina Levy and Hadas Shachnai", "title": "Fast Distributed Approximation for Max-Cut", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding a maximum cut is a fundamental task in many computational settings.\nSurprisingly, it has been insufficiently studied in the classic distributed\nsettings, where vertices communicate by synchronously sending messages to their\nneighbors according to the underlying graph, known as the $\\mathcal{LOCAL}$ or\n$\\mathcal{CONGEST}$ models. We amend this by obtaining almost optimal\nalgorithms for Max-Cut on a wide class of graphs in these models. In\nparticular, for any $\\epsilon > 0$, we develop randomized approximation\nalgorithms achieving a ratio of $(1-\\epsilon)$ to the optimum for Max-Cut on\nbipartite graphs in the $\\mathcal{CONGEST}$ model, and on general graphs in the\n$\\mathcal{LOCAL}$ model.\n  We further present efficient deterministic algorithms, including a\n$1/3$-approximation for Max-Dicut in our models, thus improving the best known\n(randomized) ratio of $1/4$. Our algorithms make non-trivial use of the greedy\napproach of Buchbinder et al. (SIAM Journal on Computing, 2015) for maximizing\nan unconstrained (non-monotone) submodular function, which may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 15:29:24 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Censor-Hillel", "Keren", ""], ["Levy", "Rina", ""], ["Shachnai", "Hadas", ""]]}, {"id": "1707.08551", "submitter": "Hao Dong", "authors": "Hao Dong, Akara Supratak, Luo Mai, Fangde Liu, Axel Oehmichen, Simiao\n  Yu, Yike Guo", "title": "TensorLayer: A Versatile Library for Efficient Deep Learning Development", "comments": "ACM Multimedia 2017", "journal-ref": null, "doi": "10.1145/3123266.3129391", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has enabled major advances in the fields of computer vision,\nnatural language processing, and multimedia among many others. Developing a\ndeep learning system is arduous and complex, as it involves constructing neural\nnetwork architectures, managing training/trained models, tuning optimization\nprocess, preprocessing and organizing data, etc. TensorLayer is a versatile\nPython library that aims at helping researchers and engineers efficiently\ndevelop deep learning systems. It offers rich abstractions for neural networks,\nmodel and data management, and parallel workflow mechanism. While boosting\nefficiency, TensorLayer maintains both performance and scalability. TensorLayer\nwas released in September 2016 on GitHub, and has helped people from academia\nand industry develop real-world applications of deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 17:29:49 GMT"}, {"version": "v2", "created": "Wed, 2 Aug 2017 10:26:34 GMT"}, {"version": "v3", "created": "Thu, 3 Aug 2017 14:48:16 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Dong", "Hao", ""], ["Supratak", "Akara", ""], ["Mai", "Luo", ""], ["Liu", "Fangde", ""], ["Oehmichen", "Axel", ""], ["Yu", "Simiao", ""], ["Guo", "Yike", ""]]}, {"id": "1707.08691", "submitter": "Muhammad Junaid Farooq", "authors": "Muhammad Junaid Farooq and Quanyan Zhu", "title": "Adaptive and Resilient Revenue Maximizing Dynamic Resource Allocation\n  and Pricing for Cloud-Enabled IoT Systems", "comments": "American Control Conference (ACC 2018)", "journal-ref": "Annual American Control Conference (ACC 2018)", "doi": "10.23919/ACC.2018.8430776", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is becoming an essential component of modern computer and\ncommunication systems. The available resources at the cloud such as computing\nnodes, storage, databases, etc. are often packaged in the form of virtual\nmachines (VMs) to be used by remotely located client applications for\ncomputational tasks. However, the cloud has a limited number of VMs available,\nwhich have to be efficiently utilized to generate higher productivity and\nsubsequently generate maximum revenue. Client applications generate requests\nwith computational tasks at random times with random complexity to be processed\nby the cloud. The cloud service provider (CSP) has to decide whether to\nallocate a VM to a task at hand or to wait for a higher complexity task in the\nfuture. We propose a threshold-based mechanism to optimally decide the\nallocation and pricing of VMs to sequentially arriving requests in order to\nmaximize the revenue of the CSP over a finite time horizon. Moreover, we\ndevelop an adaptive and resilient framework based that can counter the effect\nof realtime changes in the number of available VMs at the cloud server, the\nfrequency and nature of arriving tasks on the revenue of the CSP.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 03:03:12 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 23:13:26 GMT"}, {"version": "v3", "created": "Sat, 3 Mar 2018 01:38:48 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Farooq", "Muhammad Junaid", ""], ["Zhu", "Quanyan", ""]]}, {"id": "1707.08751", "submitter": "EPTCS", "authors": "Joseph Y. Halpern (Cornell University), Rafael Pass (Cornell\n  University)", "title": "A Knowledge-Based Analysis of the Blockchain Protocol", "comments": "In Proceedings TARK 2017, arXiv:1707.08250", "journal-ref": "EPTCS 251, 2017, pp. 324-335", "doi": "10.4204/EPTCS.251.22", "report-no": null, "categories": "cs.CR cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the heart of the Bitcoin is a blockchain protocol, a protocol for\nachieving consensus on a public ledger that records bitcoin transactions. To\nthe extent that a blockchain protocol is used for applications such as contract\nsigning and making certain transactions (such as house sales) public, we need\nto understand what guarantees the protocol gives us in terms of agents'\nknowledge. Here, we provide a complete characterization of agent's knowledge\nwhen running a blockchain protocol using a variant of common knowledge that\ntakes into account the fact that agents can enter and leave the system, it is\nnot known which agents are in fact following the protocol (some agents may want\nto deviate if they can gain by doing so), and the fact that the guarantees\nprovided by blockchain protocols are probabilistic. We then consider some\nscenarios involving contracts and show that this level of knowledge suffices\nfor some scenarios, but not others.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 07:50:56 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Halpern", "Joseph Y.", "", "Cornell University"], ["Pass", "Rafael", "", "Cornell\n  University"]]}, {"id": "1707.08860", "submitter": "Huajin Wang", "authors": "Huajin Wang, Jianhui Li, Zhihong Shen and Yuanchun Zhou", "title": "Approximations and Bounds for (n, k) Fork-Join Queues: A Linear\n  Transformation Approach", "comments": "10 pages", "journal-ref": "2018 18th IEEE/ACM International Symposium on Cluster, Cloud and\n  Grid Computing (CCGRID)", "doi": "10.1109/CCGRID.2018.00069", "report-no": null, "categories": "cs.PF cs.DC cs.NI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared to basic fork-join queues, a job in (n, k) fork-join queues only\nneeds its k out of all n sub-tasks to be finished. Since (n, k) fork-join\nqueues are prevalent in popular distributed systems, erasure coding based cloud\nstorages, and modern network protocols like multipath routing, estimating the\nsojourn time of such queues is thus critical for the performance measurement\nand resource plan of computer clusters. However, the estimating keeps to be a\nwell-known open challenge for years, and only rough bounds for a limited range\nof load factors have been given. In this paper, we developed a closed-form\nlinear transformation technique for jointly-identical random variables: An\norder statistic can be represented by a linear combination of maxima. This\nbrand-new technique is then used to transform the sojourn time of non-purging\n(n, k) fork-join queues into a linear combination of the sojourn times of basic\n(k, k), (k+1, k+1), ..., (n, n) fork-join queues. Consequently, existing\napproximations for basic fork-join queues can be bridged to the approximations\nfor non-purging (n, k) fork-join queues. The uncovered approximations are then\nused to improve the upper bounds for purging (n, k) fork-join queues.\nSimulation experiments show that this linear transformation approach is\npracticed well for moderate n and relatively large k.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 13:35:13 GMT"}, {"version": "v2", "created": "Mon, 31 Jul 2017 09:02:36 GMT"}, {"version": "v3", "created": "Tue, 1 Aug 2017 03:02:27 GMT"}, {"version": "v4", "created": "Sat, 5 Aug 2017 05:44:25 GMT"}, {"version": "v5", "created": "Fri, 8 Sep 2017 04:40:18 GMT"}, {"version": "v6", "created": "Sun, 3 Dec 2017 10:57:40 GMT"}, {"version": "v7", "created": "Mon, 11 Dec 2017 00:59:00 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Wang", "Huajin", ""], ["Li", "Jianhui", ""], ["Shen", "Zhihong", ""], ["Zhou", "Yuanchun", ""]]}, {"id": "1707.08900", "submitter": "Maarit K\\\"apyl\\\"a", "authors": "Johannes Pekkil\\\"a (1), Miikka S. V\\\"ais\\\"al\\\"a (2), Maarit J.\n  K\\\"apyl\\\"a (3,1), Petri J. K\\\"apyl\\\"a (4,1,3) and Omer Anjum (5,1) ((1)\n  ReSoLVE Center of Excellence, Aalto, (2) Department of Physics, University of\n  Helsinki, (3) Max-Planck-Institut f\\\"ur Sonnensystemforschung, (4) AIP, (5)\n  Nokia Solutions and Networks, Finland)", "title": "Methods for compressible fluid simulation on GPUs using high-order\n  finite differences", "comments": "14 pages, 7 figures", "journal-ref": "Computer Physics Communications, Volume 217, August 2017, Pages\n  11-22", "doi": "10.1016/j.cpc.2017.03.011", "report-no": null, "categories": "physics.comp-ph astro-ph.IM cs.DC physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on implementing and optimizing a sixth-order finite-difference\nsolver for simulating compressible fluids on a GPU using third-order\nRunge-Kutta integration. Since graphics processing units perform well in\ndata-parallel tasks, this makes them an attractive platform for fluid\nsimulation. However, high-order stencil computation is memory-intensive with\nrespect to both main memory and the caches of the GPU. We present two\napproaches for simulating compressible fluids using 55-point and 19-point\nstencils. We seek to reduce the requirements for memory bandwidth and cache\nsize in our methods by using cache blocking and decomposing a latency-bound\nkernel into several bandwidth-bound kernels. Our fastest implementation is\nbandwidth-bound and integrates $343$ million grid points per second on a Tesla\nK40t GPU, achieving a $3.6 \\times$ speedup over a comparable hydrodynamics\nsolver benchmarked on two Intel Xeon E5-2690v3 processors. Our alternative GPU\nimplementation is latency-bound and achieves the rate of $168$ million updates\nper second.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 15:05:10 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Pekkil\u00e4", "Johannes", ""], ["V\u00e4is\u00e4l\u00e4", "Miikka S.", ""], ["K\u00e4pyl\u00e4", "Maarit J.", ""], ["K\u00e4pyl\u00e4", "Petri J.", ""], ["Anjum", "Omer", ""]]}, {"id": "1707.09242", "submitter": "Alexey Gotsman", "authors": "Alexey Gotsman and Sebastian Burckhardt", "title": "Consistency models with global operation sequencing and their\n  composition (extended version)", "comments": "Extended version of the paper from DISC'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern distributed systems often achieve availability and scalability by\nproviding consistency guarantees about the data they manage weaker than\nlinearizability. We consider a class of such consistency models that, despite\nthis weakening, guarantee that clients eventually agree on a global sequence of\noperations, while seeing a subsequence of this final sequence at any given\npoint of time. Examples of such models include the classical Total Store Order\n(TSO) and recently proposed dual TSO, Global Sequence Protocol (GSP) and\nOrdered Sequential Consistency.\n  We define a unified model, called Global Sequence Consistency (GSC), that has\nthe above models as its special cases, and investigate its key properties.\nFirst, we propose a condition under which multiple objects each satisfying GSC\ncan be composed so that the whole set of objects satisfies GSC. Second, we\nprove an interesting relationship between special cases of GSC---GSP, TSO and\ndual TSO: we show that clients that do not communicate out-of-band cannot tell\nthe difference between these models. To obtain these results, we propose a\nnovel axiomatic specification of GSC and prove its equivalence to the\noperational definition of the model.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 14:09:01 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Gotsman", "Alexey", ""], ["Burckhardt", "Sebastian", ""]]}, {"id": "1707.09315", "submitter": "Poonam Yadav Dr", "authors": "Poonam Yadav and Julie A. McCann and Tiago Pereira", "title": "Self-Synchronization in Duty-cycled Internet of Things (IoT)\n  Applications", "comments": "12 Pages, 11 Figures, Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the networks of low-power devices have gained popularity.\nTypically these devices are wireless and interact to form large networks such\nas the Machine to Machine (M2M) networks, Internet of Things (IoT), Wearable\nComputing, and Wireless Sensor Networks. The collaboration among these devices\nis a key to achieving the full potential of these networks. A major problem in\nthis field is to guarantee robust communication between elements while keeping\nthe whole network energy efficient. In this paper, we introduce an extended and\nimproved emergent broadcast slot (EBS) scheme, which facilitates collaboration\nfor robust communication and is energy efficient. In the EBS, nodes\ncommunication unit remains in sleeping mode and are awake just to communicate.\nThe EBS scheme is fully decentralized, that is, nodes coordinate their wake-up\nwindow in partially overlapped manner within each duty-cycle to avoid message\ncollisions. We show the theoretical convergence behavior of the scheme, which\nis confirmed through real test-bed experimentation.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 16:37:20 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Yadav", "Poonam", ""], ["McCann", "Julie A.", ""], ["Pereira", "Tiago", ""]]}, {"id": "1707.09317", "submitter": "Frederick Nwanganga", "authors": "Frederick Nwanganga, Mandana Saebi, Gregory Madey and Nitesh Chawla", "title": "A Minimum-Cost Flow Model for Workload Optimization on Cloud\n  Infrastructure", "comments": "2017 IEEE 10th International Conference on Cloud Computing", "journal-ref": null, "doi": "10.1109/CLOUD.2017.68", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent technology advancements in the areas of compute, storage and\nnetworking, along with the increased demand for organizations to cut costs\nwhile remaining responsive to increasing service demands have led to the growth\nin the adoption of cloud computing services. Cloud services provide the promise\nof improved agility, resiliency, scalability and a lowered Total Cost of\nOwnership (TCO). This research introduces a framework for minimizing cost and\nmaximizing resource utilization by using an Integer Linear Programming (ILP)\napproach to optimize the assignment of workloads to servers on Amazon Web\nServices (AWS) cloud infrastructure. The model is based on the classical\nminimum-cost flow model, known as the assignment model.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 16:39:17 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Nwanganga", "Frederick", ""], ["Saebi", "Mandana", ""], ["Madey", "Gregory", ""], ["Chawla", "Nitesh", ""]]}, {"id": "1707.09323", "submitter": "Ahsan Javed Awan", "authors": "Ahsan Javed Awan, Mats Brorsson, Vladimir Vlassov and Eduard Ayguade", "title": "Identifying the potential of Near Data Computing for Apache Spark", "comments": "position paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While cluster computing frameworks are continuously evolving to provide\nreal-time data analysis capabilities, Apache Spark has managed to be at the\nforefront of big data analytics for being a unified framework for both, batch\nand stream data processing. There is also a renewed interest is Near Data\nComputing (NDC) due to technological advancement in the last decade. However,\nit is not known if NDC architectures can improve the performance of big data\nprocessing frameworks such as Apache Spark. In this position paper, we\nhypothesize in favour of NDC architecture comprising programmable logic based\nhybrid 2D integrated processing-in-memory and in-storage processing for Apache\nSpark, by extensive profiling of Apache Spark based workloads on Ivy Bridge\nServer.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 03:56:36 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Awan", "Ahsan Javed", ""], ["Brorsson", "Mats", ""], ["Vlassov", "Vladimir", ""], ["Ayguade", "Eduard", ""]]}, {"id": "1707.09414", "submitter": "Ammar Ahmad Awan", "authors": "Ammar Ahmad Awan, Ching-Hsiang Chu, Hari Subramoni, and Dhabaleswar K.\n  Panda", "title": "Optimized Broadcast for Deep Learning Workloads on Dense-GPU InfiniBand\n  Clusters: MPI or NCCL?", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense Multi-GPU systems have recently gained a lot of attention in the HPC\narena. Traditionally, MPI runtimes have been primarily designed for clusters\nwith a large number of nodes. However, with the advent of MPI+CUDA applications\nand CUDA-Aware MPI runtimes like MVAPICH2 and OpenMPI, it has become important\nto address efficient communication schemes for such dense Multi-GPU nodes. This\ncoupled with new application workloads brought forward by Deep Learning\nframeworks like Caffe and Microsoft CNTK pose additional design constraints due\nto very large message communication of GPU buffers during the training phase.\nIn this context, special-purpose libraries like NVIDIA NCCL have been proposed\nfor GPU-based collective communication on dense GPU systems. In this paper, we\npropose a pipelined chain (ring) design for the MPI_Bcast collective operation\nalong with an enhanced collective tuning framework in MVAPICH2-GDR that enables\nefficient intra-/inter-node multi-GPU communication. We present an in-depth\nperformance landscape for the proposed MPI_Bcast schemes along with a\ncomparative analysis of NVIDIA NCCL Broadcast and NCCL-based MPI_Bcast. The\nproposed designs for MVAPICH2-GDR enable up to 14X and 16.6X improvement,\ncompared to NCCL-based solutions, for intra- and inter-node broadcast latency,\nrespectively. In addition, the proposed designs provide up to 7% improvement\nover NCCL-based solutions for data parallel training of the VGG network on 128\nGPUs using Microsoft CNTK.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 20:54:06 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Awan", "Ammar Ahmad", ""], ["Chu", "Ching-Hsiang", ""], ["Subramoni", "Hari", ""], ["Panda", "Dhabaleswar K.", ""]]}, {"id": "1707.09455", "submitter": "Tevfik Kosar", "authors": "MD S Q Zulkar Nine, Kemal Guner, Ziyun Huang, Xiangyu Wang, Jinhui Xu,\n  and Tevfik Kosar", "title": "Data Transfer Optimization Based on Offline Knowledge Discovery and\n  Adaptive Real-time Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The amount of data moved over dedicated and non-dedicated network links\nincreases much faster than the increase in the network capacity, but the\ncurrent solutions fail to guarantee even the promised achievable transfer\nthroughputs. In this paper, we propose a novel dynamic throughput optimization\nmodel based on mathematical modeling with offline knowledge discovery/analysis\nand adaptive online decision making. In offline analysis, we mine historical\ntransfer logs to perform knowledge discovery about the transfer\ncharacteristics. Online phase uses the discovered knowledge from the offline\nanalysis along with real-time investigation of the network condition to\noptimize the protocol parameters. As real-time investigation is expensive and\nprovides partial knowledge about the current network status, our model uses\nhistorical knowledge about the network and data to reduce the real-time\ninvestigation overhead while ensuring near optimal throughput for each\ntransfer. Our network and data agnostic solution is tested over different\nnetworks and achieved up to 93% accuracy compared with the optimal achievable\nthroughput possible on those networks.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jul 2017 03:34:22 GMT"}, {"version": "v2", "created": "Mon, 27 Nov 2017 14:03:17 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Nine", "MD S Q Zulkar", ""], ["Guner", "Kemal", ""], ["Huang", "Ziyun", ""], ["Wang", "Xiangyu", ""], ["Xu", "Jinhui", ""], ["Kosar", "Tevfik", ""]]}, {"id": "1707.09488", "submitter": "Jaydip Sen", "authors": "Jaydip Sen, Shanrong Zhao, Xiaoying Wang, Guojing Zhang, Mengqin Yang,\n  Jian Wang, Yun Long, Sergey Andreev, Roman Florea, Aleksandr Ometov, Adam\n  Surak, Yevgeni Koucheryavy, Muhammad Ahmad Ashraf, Waleed Tariq Sethi,\n  Abdullah Alfakhri, Saleh Alshebeili, Amr Alasaad", "title": "Cloud Computing - Architecture and Applications", "comments": "Edited Volume published by Intech Publishers, Croatia, June 2017. 138\n  pages. ISBN 978-953-51-3244-8, Print ISBN 978-953-51-3243-1. Link:\n  https://www.intechopen.com/books/cloud-computing-architecture-and-applications", "journal-ref": null, "doi": "10.5772/62794", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of Internet of Things and with the explosive worldwide growth of\nelectronic data volume, and associated need of processing, analysis, and\nstorage of such humongous volume of data, it has now become mandatory to\nexploit the power of massively parallel architecture for fast computation.\nCloud computing provides a cheap source of such computing framework for large\nvolume of data for real-time applications. It is, therefore, not surprising to\nsee that cloud computing has become a buzzword in the computing fraternity over\nthe last decade. This book presents some critical applications in cloud\nframeworks along with some innovation design of algorithms and architecture for\ndeployment in cloud environment. It is a valuable source of knowledge for\nresearchers, engineers, practitioners, and graduate and doctoral students\nworking in the field of cloud computing. It will also be useful for faculty\nmembers of graduate schools and universities.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jul 2017 09:45:08 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Sen", "Jaydip", ""], ["Zhao", "Shanrong", ""], ["Wang", "Xiaoying", ""], ["Zhang", "Guojing", ""], ["Yang", "Mengqin", ""], ["Wang", "Jian", ""], ["Long", "Yun", ""], ["Andreev", "Sergey", ""], ["Florea", "Roman", ""], ["Ometov", "Aleksandr", ""], ["Surak", "Adam", ""], ["Koucheryavy", "Yevgeni", ""], ["Ashraf", "Muhammad Ahmad", ""], ["Sethi", "Waleed Tariq", ""], ["Alfakhri", "Abdullah", ""], ["Alshebeili", "Saleh", ""], ["Alasaad", "Amr", ""]]}, {"id": "1707.09562", "submitter": "Hantian Zhang", "authors": "Yu Liu, Hantian Zhang, Luyuan Zeng, Wentao Wu, Ce Zhang", "title": "MLBench: How Good Are Machine Learning Clouds for Binary Classification\n  Tasks on Structured Data?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct an empirical study of machine learning functionalities provided by\nmajor cloud service providers, which we call machine learning clouds. Machine\nlearning clouds hold the promise of hiding all the sophistication of running\nlarge-scale machine learning: Instead of specifying how to run a machine\nlearning task, users only specify what machine learning task to run and the\ncloud figures out the rest. Raising the level of abstraction, however, rarely\ncomes free - a performance penalty is possible. How good, then, are current\nmachine learning clouds on real-world machine learning workloads?\n  We study this question with a focus on binary classication problems. We\npresent mlbench, a novel benchmark constructed by harvesting datasets from\nKaggle competitions. We then compare the performance of the top winning code\navailable from Kaggle with that of running machine learning clouds from both\nAzure and Amazon on mlbench. Our comparative study reveals the strength and\nweakness of existing machine learning clouds and points out potential future\ndirections for improvement.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jul 2017 21:59:18 GMT"}, {"version": "v2", "created": "Wed, 2 Aug 2017 16:36:55 GMT"}, {"version": "v3", "created": "Mon, 16 Oct 2017 11:13:32 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Liu", "Yu", ""], ["Zhang", "Hantian", ""], ["Zeng", "Luyuan", ""], ["Wu", "Wentao", ""], ["Zhang", "Ce", ""]]}, {"id": "1707.09616", "submitter": "Liang Wang", "authors": "Liang Wang", "title": "Owl: A General-Purpose Numerical Library in OCaml", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owl is a new numerical library developed in the OCaml language. It focuses on\nproviding a comprehensive set of high-level numerical functions so that\ndevelopers can quickly build up data analytical applications. In this abstract,\nwe will present Owl's design, core components, and its key functionality.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jul 2017 13:18:06 GMT"}, {"version": "v2", "created": "Fri, 22 Sep 2017 16:44:26 GMT"}, {"version": "v3", "created": "Tue, 28 Aug 2018 06:42:48 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Wang", "Liang", ""]]}, {"id": "1707.09668", "submitter": "Michelle Strout", "authors": "Benjamin James Gaska, Neha Jothi, Mahdi Soltan Mohammadi, Kat Volk,\n  and Michelle Mills Strout", "title": "Handling Nested Parallelism and Extreme Load Imbalance in an Orbital\n  Analysis Code", "comments": "11 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nested parallelism exists in scientific codes that are searching\nmulti-dimensional spaces. However, implementations of nested parallelism often\nhave overhead and load balance issues. The Orbital Analysis code we present\nexhibits a sparse search space, significant load imbalances, and stopping when\nthe first solution is reached. All these aspects of the algorithm exacerbate\nthe problem of using nested parallelism effectively. In this paper, we present\nan inspector/executor strategy for chunking such computations into parallel\nwavefronts. The presented shared memory parallelization is no longer nested and\nexhibits significantly less load imbalance. We evaluate this approach on an\nOrbital analysis code, and we improve the execution time from the original\nimplementation by an order of magnitude. As part of a Graduate Computer Science\ncourse in Parallel Programming models, we show how the approach can be\nimplemented in parallel Perl, Python, Chapel, Pthreads, and OpenMP. Future work\nincludes investigating how to automate and generalize the parallelization\napproach.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jul 2017 20:51:26 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Gaska", "Benjamin James", ""], ["Jothi", "Neha", ""], ["Mohammadi", "Mahdi Soltan", ""], ["Volk", "Kat", ""], ["Strout", "Michelle Mills", ""]]}, {"id": "1707.09850", "submitter": "Bruce Becker", "authors": "Bruce Becker and Sean Murray", "title": "CODE-RADE - Community Infrastructure for the Delivery of Physics\n  Applications", "comments": "Article submitted to SAIP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Scientific computing can in some sense be distilled to the execution of an\napplication - or rather sets of applications which are combined into complex\nworkflows. Due to the complexity and number both of scientific packages as well\nas computing platforms, delivering these applications to end users has always\nbeen a significant challenge through the grid era, and remains so in the cloud\nera. In this contribution we describe a platform for user-driven, continuous\nintegration and delivery of research applications in a distributed environment\n- project CODE-RADE. Starting with 6 hypotheses describing the problem at hand,\nwe put forward technical and social solutions to these. Combining widely-used\nand thoroughly-tested tools, we show how it is possible to manage the\ndependencies and configurations of a wide range of scientific applications, in\nan almost fully-automated way. The CODE-RADE platform is a means for developing\ntrust between public computing and data infrastructures on the one hand and\nvarious developer and scientific communities on the other hand. Predefined\nintegration tests are specified for any new application, allowing the system to\nbe user-driven. This greatly accelerates time-to-production for scientific\napplications, while reducing the workload for administrators of HPC, grid and\ncloud installations. Finally, we will give some insight into how this platform\ncould be extended to address issues of reproducibility and collaboration in\nscientific research in Africa.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 14:02:15 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Becker", "Bruce", ""], ["Murray", "Sean", ""]]}, {"id": "1707.09865", "submitter": "Hamid Hamraz", "authors": "Hamid Hamraz and Marco A. Contreras", "title": "Remote sensing of forests using discrete return airborne LiDAR", "comments": "This manuscript is a book chapter that has provisionally been\n  accepted to be published in \"Recent Advances and Applications in Remote\n  Sensing\", ISBN 978-953-51-5564-5. Ed.: Hung, Ming Cheh. InTechOpen. The\n  chapter summarizes novel methods from four recently published journal ppapers\n  by the authors in a concise and cohesive manner", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CE cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Airborne discrete return light detection and ranging (LiDAR) point clouds\ncovering forested areas can be processed to segment individual trees and\nretrieve their morphological attributes. Segmenting individual trees in natural\ndeciduous forests however remained a challenge because of the complex and\nmulti-layered canopy. In this chapter, we present (i) a robust segmentation\nmethod that avoids a priori assumptions about the canopy structure, (ii) a\nvertical canopy stratification procedure that improves segmentation of\nunderstory trees, (iii) an occlusion model for estimating the point density of\neach canopy stratum, and (iv) a distributed computing approach for efficient\nprocessing at the forest level. When applied to the University of Kentucky\nRobinson Forest, the segmentation method detected about 90% of overstory and\n47% of understory trees with over-segmentation rates of 14% and 2%. Stratifying\nthe canopy improved the detection rate of understory trees to 68% at the cost\nof increasing their over-segmentations to 16%. According to our occlusion\nmodel, a point density of ~170 pt/m-sqr is needed to segment understory trees\nas accurately as overstory trees. Lastly, using the distributed approach, we\nsegmented about two million trees in the 7,440-ha forest in 2.5 hours using 192\nprocessors, which is 167 times faster than using a single processor. Keywords:\nindividual tree segmentation, multi-layered stand, vertical canopy\nstratification, segmentation evaluation, point density, canopy occlusion\neffect, big data, distributed computing.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 19:06:18 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Hamraz", "Hamid", ""], ["Contreras", "Marco A.", ""]]}, {"id": "1707.09965", "submitter": "Sascha Hunold", "authors": "Sascha Hunold and Alexandra Carpen-Amarie", "title": "Tuning MPI Collectives by Verifying Performance Guidelines", "comments": "16 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MPI collective operations provide a standardized interface for performing\ndata movements within a group of processes. The efficiency of collective\ncommunication operations depends on the actual algorithm, its implementation,\nand the specific communication problem (type of communication, message size,\nnumber of processes). Many MPI libraries provide numerous algorithms for\nspecific collective operations. The strategy for selecting an efficient\nalgorithm is often times predefined (hard-coded) in MPI libraries, but some of\nthem, such as Open MPI, allow users to change the algorithm manually. Finding\nthe best algorithm for each case is a hard problem, and several approaches to\ntune these algorithmic parameters have been proposed. We use an orthogonal\napproach to the parameter-tuning of MPI collectives, that is, instead of\ntesting individual algorithmic choices provided by an MPI library, we compare\nthe latency of a specific MPI collective operation to the latency of\nsemantically equivalent functions, which we call the mock-up implementations.\nThe structure of the mock-up implementations is defined by self-consistent\nperformance guidelines. The advantage of this approach is that tuning using\nmock-up implementations is always possible, whether or not an MPI library\nallows users to select a specific algorithm at run-time. We implement this\nconcept in a library called PGMPITuneLib, which is layered between the user\ncode and the actual MPI implementation. This library selects the\nbest-performing algorithmic pattern of an MPI collective by intercepting MPI\ncalls and redirecting them to our mock-up implementations. Experimental results\nshow that PGMPITuneLib can significantly reduce the latency of MPI collectives,\nand also equally important, that it can help identifying the tuning potential\nof MPI libraries.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 17:19:09 GMT"}, {"version": "v2", "created": "Thu, 10 Aug 2017 14:08:30 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Hunold", "Sascha", ""], ["Carpen-Amarie", "Alexandra", ""]]}]