[{"id": "1507.00073", "submitter": "Armando Casta\\~neda", "authors": "Armando Castaneda, Michel Raynal and Sergio Rajsbaum", "title": "Specifying Concurrent Problems: Beyond Linearizability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tasks and objects are two predominant ways of specifying distributed\nproblems. A task is specified by an input/output relation, defining for each\nset of processes that may run concurrently, and each assignment of inputs to\nthe processes in the set, the valid outputs of the processes. An object is\nspecified by an automaton describing the outputs the object may produce when it\nis accessed sequentially. Thus, tasks explicitly state what may happen only\nwhen sets of processes run concurrently, while objects only specify what\nhappens when processes access the object sequentially. Each one requires its\nown implementation notion, to tell when an execution satisfies the\nspecification. For objects linearizability is commonly used, a very elegant and\nuseful consistency condition. For tasks implementation notions are less\nexplored.\n  The paper introduces the notion of interval-sequential object. The\ncorresponding implementation notion of interval-linearizability generalizes\nlinearizability, and allows to associate states along the interval of execution\nof an operation. Interval-linearizability allows to specify any task, however,\nthere are sequential one-shot objects that cannot be expressed as tasks, under\nthe simplest interpretation of a task. It also shows that a natural extension\nof the notion of a task is expressive enough to specify any interval-sequential\nobject.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2015 00:12:35 GMT"}], "update_date": "2015-07-02", "authors_parsed": [["Castaneda", "Armando", ""], ["Raynal", "Michel", ""], ["Rajsbaum", "Sergio", ""]]}, {"id": "1507.00090", "submitter": "Fabio Lopez-Pires", "authors": "Jammily Ortigoza and Fabio L\\'opez-Pires and Benjam\\'in Bar\\'an", "title": "Workload Trace Generation for Dynamic Environments in Cloud Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing datacenters provide millions of virtual machines in actual\ncloud markets. In this context, Virtual Machine Placement (VMP) is one of the\nmost challenging problems in cloud infrastructure management, considering the\nlarge number of possible optimization criteria and different formulations that\ncould be studied. Considering the on-demand model of cloud computing, the VMP\nproblem should be optimized dynamically to efficiently attend typical workload\nof modern applications. This work proposes several dynamic environments for\nsolving the VMP from the providers' perspective based on the most relevant\ndynamic parameters studied so far in the VMP literature. A complete set of\nenvironments and workload traces examples are presented in this work.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2015 01:55:11 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2015 18:00:18 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Ortigoza", "Jammily", ""], ["L\u00f3pez-Pires", "Fabio", ""], ["Bar\u00e1n", "Benjam\u00edn", ""]]}, {"id": "1507.00245", "submitter": "Quinten Stokkink", "authors": "Quinten Stokkink, Harmjan Treep, Johan Pouwelse", "title": "Performance analysis of a Tor-like onion routing implementation", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current onion routing implementation of Tribler works as expected but\nthrottles the overall throughput of the Tribler system. This article discusses\na measuring procedure to reproducibly profile the tunnel implementation so\nfurther optimizations of the tunnel community can be made. Our work has been\nintegrated into the Tribler eco-system.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2015 14:39:29 GMT"}], "update_date": "2015-07-02", "authors_parsed": [["Stokkink", "Quinten", ""], ["Treep", "Harmjan", ""], ["Pouwelse", "Johan", ""]]}, {"id": "1507.00365", "submitter": "Evgeny Nikulchev", "authors": "E. Nikulchev, E. Pluzhnik, D. Biryukov, O. Lukyanchikov, S. Payain", "title": "Experimental Study of the Cloud Architecture Selection for Effective Big\n  Data Processing", "comments": null, "journal-ref": "IJACSA 6 (2015) 22-26", "doi": "10.14569/IJACSA.2015.060603", "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Big data dictate their requirements to the hardware and software. Simple\nmigration to the cloud data processing, while solving the problem of increasing\ncomputational capabilities, however creates some issues: the need to ensure the\nsafety, the need to control the quality during data transmission, the need to\noptimize requests. Computational cloud does not simply provide scalable\nresources but also requires network infrastructure, unknown routes and the\nnumber of user requests. In addition, during functioning situation can occur,\nin which you need to change the architecture of the application - part of the\ndata needs to be placed in a private cloud, part in a public cloud, part stays\non the client.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2015 20:34:30 GMT"}], "update_date": "2015-07-03", "authors_parsed": [["Nikulchev", "E.", ""], ["Pluzhnik", "E.", ""], ["Biryukov", "D.", ""], ["Lukyanchikov", "O.", ""], ["Payain", "S.", ""]]}, {"id": "1507.00391", "submitter": "Bernardo Huberman", "authors": "Bernardo A. Huberman and Freddy C. Chua", "title": "Partitioning Uncertain Workflows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is common practice to partition complex workflows into separate channels\nin order to speed up their completion times. When this is done within a\ndistributed environment, unavoidable fluctuations make individual realizations\ndepart from the expected average gains. We present a method for breaking any\ncomplex workflow into several workloads in such a way that once their outputs\nare joined, their full completion takes less time and exhibit smaller variance\nthan when running in only one channel. We demonstrate the effectiveness of this\nmethod in two different scenarios; the optimization of a convex function and\nthe transmission of a large computer file over the Internet.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2015 23:39:36 GMT"}], "update_date": "2015-07-03", "authors_parsed": [["Huberman", "Bernardo A.", ""], ["Chua", "Freddy C.", ""]]}, {"id": "1507.00474", "submitter": "Michel Raynal", "authors": "Zohir Bouzid (NPA), Michel Raynal (ASAP), Pierre Sutra", "title": "Anonymous Obstruction-free $(n,k)$-Set Agreement with $n-k+1$ Atomic\n  Read/Write Registers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k$-set agreement problem is a generalization of the consensus problem.\nNamely, assuming each process proposes a value, each non-faulty process has to\ndecide a value such that each decided value was proposed, and no more than $k$\ndifferent values are decided. This is a hard problem in the sense that it\ncannot be solved in asynchronous systems as soon as $k$ or more processes may\ncrash. One way to circumvent this impossibility consists in weakening its\ntermination property, requiring that a process terminates (decides) only if it\nexecutes alone during a long enough period. This is the well-known\nobstruction-freedom progress condition. Considering a system of $n$ {\\it\nanonymous asynchronous} processes, which communicate through atomic {\\it\nread/write registers only}, and where {\\it any number of processes may crash},\nthis paper addresses and solves the challenging open problem of designing an\nobstruction-free $k$-set agreement algorithm with $(n-k+1)$ atomic registers\nonly. From a shared memory cost point of view, this algorithm is the best\nalgorithm known so far, thereby establishing a new upper bound on the number of\nregisters needed to solve the problem (its gain is $(n-k)$ with respect to the\nprevious upper bound). The algorithm is then extended to address the repeated\nversion of $(n,k)$-set agreement. As it is optimal in the number of atomic\nread/write registers, this algorithm closes the gap on previously established\nlower/upper bounds for both the anonymous and non-anonymous versions of the\nrepeated $(n,k)$-set agreement problem. Finally, for $1 \\leq x\\leq k\n\\textless{} n$, a generalization suited to $x$-obstruction-freedom is also\ndescribed, which requires $(n-k+x)$ atomic registers only.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2015 08:49:51 GMT"}], "update_date": "2015-07-03", "authors_parsed": [["Bouzid", "Zohir", "", "NPA"], ["Raynal", "Michel", "", "ASAP"], ["Sutra", "Pierre", ""]]}, {"id": "1507.00567", "submitter": "Pooyan Jamshidi", "authors": "Pooyan Jamshidi, Amir Sharifloo, Claus Pahl, Andreas Metzger, Giovani\n  Estrada", "title": "Self-Learning Cloud Controllers: Fuzzy Q-Learning for Knowledge\n  Evolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.DC cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud controllers aim at responding to application demands by automatically\nscaling the compute resources at runtime to meet performance guarantees and\nminimize resource costs. Existing cloud controllers often resort to scaling\nstrategies that are codified as a set of adaptation rules. However, for a cloud\nprovider, applications running on top of the cloud infrastructure are more or\nless black-boxes, making it difficult at design time to define optimal or\npre-emptive adaptation rules. Thus, the burden of taking adaptation decisions\noften is delegated to the cloud application. Yet, in most cases, application\ndevelopers in turn have limited knowledge of the cloud infrastructure. In this\npaper, we propose learning adaptation rules during runtime. To this end, we\nintroduce FQL4KE, a self-learning fuzzy cloud controller. In particular, FQL4KE\nlearns and modifies fuzzy rules at runtime. The benefit is that for designing\ncloud controllers, we do not have to rely solely on precise design-time\nknowledge, which may be difficult to acquire. FQL4KE empowers users to specify\ncloud controllers by simply adjusting weights representing priorities in system\ngoals instead of specifying complex adaptation rules. The applicability of\nFQL4KE has been experimentally assessed as part of the cloud application\nframework ElasticBench. The experimental results indicate that FQL4KE\noutperforms our previously developed fuzzy controller without learning\nmechanisms and the native Azure auto-scaling.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2015 13:11:22 GMT"}], "update_date": "2015-07-03", "authors_parsed": [["Jamshidi", "Pooyan", ""], ["Sharifloo", "Amir", ""], ["Pahl", "Claus", ""], ["Metzger", "Andreas", ""], ["Estrada", "Giovani", ""]]}, {"id": "1507.00772", "submitter": "Roman Kecher", "authors": "Yehuda Afek, Roman Kecher, Moshe Sulamy", "title": "Optimal and Resilient Pheromone Utilization in Ant Foraging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pheromones are a chemical substance produced and released by ants as means of\ncommunication. In this work we present the minimum amount of pheromones\nnecessary and sufficient for a colony of ants (identical mobile agents) to\ndeterministically find a food source (treasure), assuming that each ant has the\ncomputational capabilities of either a Finite State Machine (FSM) or a Turing\nMachine (TM). In addition, we provide pheromone-based foraging algorithms\ncapable of handling fail-stop faults.\n  In more detail, we consider the case where $k$ identical ants, initially\nlocated at the center (nest) of an infinite two-dimensional grid and\ncommunicate only through pheromones, perform a collaborative search for an\nadversarially hidden treasure placed at an unknown distance $D$. We begin by\nproving a tight lower bound of $\\Omega(D)$ on the amount of pheromones required\nby any number of FSM based ants to complete the search, and continue to reduce\nthe lower bound to $\\Omega(k)$ for the stronger ants modeled as TM. We provide\nalgorithms which match the aforementioned lower bounds, and still terminate in\noptimal $\\mathcal{O}(D + D^2 / k)$ time, under both the synchronous and\nasynchronous models. Furthermore, we consider a more realistic setting, where\nan unknown number $f < k$ of ants may fail-stop at any time; we provide\nfault-tolerant FSM algorithms (synchronous and asynchronous), that terminate in\n$\\mathcal{O}(D + D^2/(k-f) + Df)$ rounds and emit no more than the same\nasymptotic minimum number of $\\mathcal{O}(D)$ pheromones overall.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2015 21:34:58 GMT"}], "update_date": "2015-07-06", "authors_parsed": [["Afek", "Yehuda", ""], ["Kecher", "Roman", ""], ["Sulamy", "Moshe", ""]]}, {"id": "1507.00898", "submitter": "Carsten Kutzner", "authors": "Carsten Kutzner, Szil\\'ard P\\'all, Martin Fechner, Ansgar Esztermann,\n  Bert L. de Groot, Helmut Grubm\\\"uller", "title": "Best bang for your buck: GPU nodes for GROMACS biomolecular simulations", "comments": null, "journal-ref": "Journal of Computational Chemistry, 2015, 36, 1990-2008", "doi": "10.1002/jcc.24030", "report-no": null, "categories": "cs.DC cs.PF physics.bio-ph physics.comp-ph q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The molecular dynamics simulation package GROMACS runs efficiently on a wide\nvariety of hardware from commodity workstations to high performance computing\nclusters. Hardware features are well exploited with a combination of SIMD,\nmulti-threading, and MPI-based SPMD/MPMD parallelism, while GPUs can be used as\naccelerators to compute interactions offloaded from the CPU. Here we evaluate\nwhich hardware produces trajectories with GROMACS 4.6 or 5.0 in the most\neconomical way. We have assembled and benchmarked compute nodes with various\nCPU/GPU combinations to identify optimal compositions in terms of raw\ntrajectory production rate, performance-to-price ratio, energy efficiency, and\nseveral other criteria. Though hardware prices are naturally subject to trends\nand fluctuations, general tendencies are clearly visible. Adding any type of\nGPU significantly boosts a node's simulation performance. For inexpensive\nconsumer-class GPUs this improvement equally reflects in the\nperformance-to-price ratio. Although memory issues in consumer-class GPUs could\npass unnoticed since these cards do not support ECC memory, unreliable GPUs can\nbe sorted out with memory checking tools. Apart from the obvious determinants\nfor cost-efficiency like hardware expenses and raw performance, the energy\nconsumption of a node is a major cost factor. Over the typical hardware\nlifetime until replacement of a few years, the costs for electrical power and\ncooling can become larger than the costs of the hardware itself. Taking that\ninto account, nodes with a well-balanced ratio of CPU and consumer-class GPU\nresources produce the maximum amount of GROMACS trajectory over their lifetime.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2015 13:04:54 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Kutzner", "Carsten", ""], ["P\u00e1ll", "Szil\u00e1rd", ""], ["Fechner", "Martin", ""], ["Esztermann", "Ansgar", ""], ["de Groot", "Bert L.", ""], ["Grubm\u00fcller", "Helmut", ""]]}, {"id": "1507.00909", "submitter": "Juho Hirvonen", "authors": "Pierre Fraigniaud, Juho Hirvonen, Jukka Suomela", "title": "Node Labels in Local Decision", "comments": "Conference version to appear in the proceedings of SIROCCO 2015", "journal-ref": null, "doi": "10.1016/j.tcs.2017.01.011", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The role of unique node identifiers in network computing is well understood\nas far as symmetry breaking is concerned. However, the unique identifiers also\nleak information about the computing environment - in particular, they provide\nsome nodes with information related to the size of the network. It was recently\nproved that in the context of local decision, there are some decision problems\nsuch that (1) they cannot be solved without unique identifiers, and (2) unique\nnode identifiers leak a sufficient amount of information such that the problem\nbecomes solvable (PODC 2013).\n  In this work we give study what is the minimal amount of information that we\nneed to leak from the environment to the nodes in order to solve local decision\nproblems. Our key results are related to scalar oracles $f$ that, for any given\n$n$, provide a multiset $f(n)$ of $n$ labels; then the adversary assigns the\nlabels to the $n$ nodes in the network. This is a direct generalisation of the\nusual assumption of unique node identifiers. We give a complete\ncharacterisation of the weakest oracle that leaks at least as much information\nas the unique identifiers.\n  Our main result is the following dichotomy: we classify scalar oracles as\nlarge and small, depending on their asymptotic behaviour, and show that (1) any\nlarge oracle is at least as powerful as the unique identifiers in the context\nof local decision problems, while (2) for any small oracle there are local\ndecision problems that still benefit from unique identifiers.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2015 13:35:09 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Fraigniaud", "Pierre", ""], ["Hirvonen", "Juho", ""], ["Suomela", "Jukka", ""]]}, {"id": "1507.00939", "submitter": "Sugam Sharma", "authors": "Sugam Sharma", "title": "Evolution of as-a-Service Era in Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, a paradigm shift is being observed in science, where the focus is\ngradually shifting toward the cloud environments to obtain appropriate, robust\nand affordable services to deal with Big Data challenges (Sharma et al. 2014,\n2015a, 2015b). Cloud computing avoids any need to locally maintain the overly\nscaled computing infrastructure that include not only dedicated space, but the\nexpensive hardware and software also. In this paper, we study the evolution of\nas-a-Service modalities, stimulated by cloud computing, and explore the most\ncomplete inventory of new members beyond traditional cloud computing stack.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2015 17:39:39 GMT"}], "update_date": "2015-07-06", "authors_parsed": [["Sharma", "Sugam", ""]]}, {"id": "1507.01066", "submitter": "Dylan Hutchison", "authors": "Dylan Hutchison and Jeremy Kepner and Vijay Gadepally and Adam Fuchs", "title": "Graphulo Implementation of Server-Side Sparse Matrix Multiply in the\n  Accumulo Database", "comments": "To be presented at IEEE HPEC 2015: http://www.ieee-hpec.org/", "journal-ref": null, "doi": "10.1109/HPEC.2015.7322448", "report-no": null, "categories": "cs.DB cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Apache Accumulo database excels at distributed storage and indexing and\nis ideally suited for storing graph data. Many big data analytics compute on\ngraph data and persist their results back to the database. These graph\ncalculations are often best performed inside the database server. The GraphBLAS\nstandard provides a compact and efficient basis for a wide range of graph\napplications through a small number of sparse matrix operations. In this\narticle, we implement GraphBLAS sparse matrix multiplication server-side by\nleveraging Accumulo's native, high-performance iterators. We compare the\nmathematics and performance of inner and outer product implementations, and\nshow how an outer product implementation achieves optimal performance near\nAccumulo's peak write rate. We offer our work as a core component to the\nGraphulo library that will deliver matrix math primitives for graph analytics\nwithin Accumulo.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2015 05:20:22 GMT"}, {"version": "v2", "created": "Sun, 30 Aug 2015 05:47:18 GMT"}], "update_date": "2016-08-12", "authors_parsed": [["Hutchison", "Dylan", ""], ["Kepner", "Jeremy", ""], ["Gadepally", "Vijay", ""], ["Fuchs", "Adam", ""]]}, {"id": "1507.01067", "submitter": "Jaderick Pabico", "authors": "Marie Yvette B. de Robles, Zenith O. Arnejo, Jaderick P. Pabico", "title": "On Web-grid Implementation Using Single System Image", "comments": "10 pages, 6 figures, appeared in H.N. Adorna and A.L. Sioson (eds.)\n  Proceedings of the 6th National Symposium on Mathematical Aspects of Computer\n  Science (SMACS 2012), La Carmela de Boracay Convention Center, Boracay\n  Island, Malay, Aklan, Philippines, 04-08 December 2012, pp. 135-143", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the latest innovations and trend towards personalizing users' web\nbrowsing experience, the web has been increasingly dominated by dynamic\ncontents. However, delivering dynamic content remains a challenge due to the\nmany dependencies involved in compiling the content, specifically personalized\nones. This paper presents the use of Single System Image (SSI) clustering\nsystems for a cheap, off-the-shelf, local lightweight distributed web-grid\ncomposed of desktop PCs. The three clustering systems considered in the study\nare Kerrighed, OpenSSI and openMosix. Through an online simulation technique,\nthe performance savings achieved by the clustering systems were measured.\nResults showed that Kerrighed has the least number of missed requests while the\nresponse time is comparable with the rest.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2015 05:20:52 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["de Robles", "Marie Yvette B.", ""], ["Arnejo", "Zenith O.", ""], ["Pabico", "Jaderick P.", ""]]}, {"id": "1507.01101", "submitter": "Pan Lai", "authors": "Pan Lai, Rui Fan, Xiao Zhang, Wei Zhang, Fang Liu, Joey Tianyi Zhou", "title": "Utility Optimal Thread Assignment and Resource Allocation in\n  Multi-Server Systems", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving high performance in many multi-server systems requires finding a\ngood assignment of worker threads to servers and also effectively allocating\neach server's resources to its assigned threads. The assignment and allocation\ncomponents of this problem have been studied extensively but largely separately\nin the literature. In this paper, we introduce the assign and allocate (AA)\nproblem, which seeks to simultaneously find an assignment and allocation that\nmaximizes the total utility of the threads. Assigning and allocating the\nthreads together can result in substantially better overall utility than\nperforming the steps separately, as is traditionally done. We model each thread\nby a utility function giving its performance as a function of its assigned\nresources. We first prove that the AA problem is NP-hard. We then present a $2\n(\\sqrt{2}-1) > 0.828$ factor approximation algorithm for concave utility\nfunctions, which runs in $O(mn^2 + n (\\log mC)^2)$ time for $n$ threads and $m$\nservers with $C$ amount of resources each. We also give a faster algorithm with\nthe same approximation ratio and $O(n (\\log mC)^2)$ time complexity. We then\nextend the problem to two more general settings. First, we consider threads\nwith nonconcave utility functions, and give a 1/2 factor approximation\nalgorithm. Next, we give an algorithm for threads using multiple types of\nresources, and show the algorithm achieves good empirical performance. We\nconduct extensive experiments to test the performance of our algorithms on\nthreads with both synthetic and realistic utility functions, and find that they\nachieve over 92\\% of the optimal utility on average. We also compare our\nalgorithms with a number of practical heuristics, and find that our algorithms\nachieve up to 9 times higher total utility.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2015 12:29:20 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2015 11:44:21 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 14:04:41 GMT"}, {"version": "v4", "created": "Wed, 9 Jun 2021 17:23:16 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Lai", "Pan", ""], ["Fan", "Rui", ""], ["Zhang", "Xiao", ""], ["Zhang", "Wei", ""], ["Liu", "Fang", ""], ["Zhou", "Joey Tianyi", ""]]}, {"id": "1507.01138", "submitter": "Simon Portegies Zwart", "authors": "Derek Groen (University College London) and Simon Portegies Zwart\n  (Sterrewacht Leiden)", "title": "From Thread to Transcontinental Computer: Disturbing Lessons in\n  Distributed Supercomputing", "comments": "Accepted for publication in IEEE conference on ERRORs", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the political and technical complications encountered during the\nastronomical CosmoGrid project. CosmoGrid is a numerical study on the formation\nof large scale structure in the universe. The simulations are challenging due\nto the enormous dynamic range in spatial and temporal coordinates, as well as\nthe enormous computer resources required. In CosmoGrid we dealt with the\ncomputational requirements by connecting up to four supercomputers via an\noptical network and make them operate as a single machine. This was\nchallenging, if only for the fact that the supercomputers of our choice are\nseparated by half the planet, as three of them are located scattered across\nEurope and fourth one is in Tokyo. The co-scheduling of multiple computers and\nthe 'gridification' of the code enabled us to achieve an efficiency of up to\n$93\\%$ for this distributed intercontinental supercomputer. In this work, we\nfind that high-performance computing on a grid can be done much more\neffectively if the sites involved are willing to be flexible about their user\npolicies, and that having facilities to provide such flexibility could be key\nto strengthening the position of the HPC community in an increasingly\nCloud-dominated computing landscape. Given that smaller computer clusters owned\nby research groups or university departments usually have flexible user\npolicies, we argue that it could be easier to instead realize distributed\nsupercomputing by combining tens, hundreds or even thousands of these\nresources.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2015 20:01:25 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Groen", "Derek", "", "University College London"], ["Zwart", "Simon Portegies", "", "Sterrewacht Leiden"]]}, {"id": "1507.01181", "submitter": "Tariq Toukan", "authors": "Keren Censor-Hillel and Tariq Toukan", "title": "On Fast and Robust Information Spreading in the Vertex-Congest Model", "comments": "Appears in SIROCCO 2015 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper initiates the study of the impact of failures on the fundamental\nproblem of \\emph{information spreading} in the Vertex-Congest model, in which\nin every round, each of the $n$ nodes sends the same $O(\\log{n})$-bit message\nto all of its neighbors.\n  Our contribution to coping with failures is twofold. First, we prove that the\nrandomized algorithm which chooses uniformly at random the next message to\nforward is slow, requiring $\\Omega(n/\\sqrt{k})$ rounds on some graphs, which we\ndenote by $G_{n,k}$, where $k$ is the vertex-connectivity.\n  Second, we design a randomized algorithm that makes dynamic message choices,\nwith probabilities that change over the execution. We prove that for $G_{n,k}$\nit requires only a near-optimal number of $O(n\\log^3{n}/k)$ rounds, despite a\nrate of $q=O(k/n\\log^3{n})$ failures per round. Our technique of choosing\nprobabilities that change according to the execution is of independent\ninterest.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2015 08:54:59 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Censor-Hillel", "Keren", ""], ["Toukan", "Tariq", ""]]}, {"id": "1507.01265", "submitter": "Alexey Lastovetsky", "authors": "Alexey Lastovetsky, Lukasz Szustak, Roman Wyrzykowski", "title": "Model-based optimization of MPDATA on Intel Xeon Phi through load\n  imbalancing", "comments": "10 pages, 9 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Load balancing is a widely accepted technique for performance optimization of\nscientific applications on parallel architectures. Indeed, balanced\napplications do not waste processor cycles on waiting at points of\nsynchronization and data exchange, maximizing this way the utilization of\nprocessors. In this paper, we challenge the universality of the load-balancing\napproach to optimization of the performance of parallel applications. First, we\nformulate conditions that should be satisfied by the performance profile of an\napplication in order for the application to achieve its best performance via\nload balancing. Then we use a real-life scientific application, MPDATA, to\ndemonstrate that its performance profile on a modern parallel architecture,\nIntel Xeon Phi, significantly deviates from these conditions. Based on this\nobservation, we propose a method of performance optimization of scientific\napplications through load imbalancing. We also propose an algorithm that finds\nthe optimal, possibly imbalanced, configuration of a data parallel application\non a set of homogeneous processors. This algorithm uses functional performance\nmodels of the application to find the partitioning that minimizes its\ncomputation time but not necessarily balances the load of the processors. We\nshow how to apply this algorithm to optimization of MPDATA on Intel Xeon Phi.\nExperimental results demonstrate that the performance of this carefully\noptimized load-balanced application can be further improved by 15\\% using the\nproposed load-imbalancing optimization.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2015 20:06:43 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Lastovetsky", "Alexey", ""], ["Szustak", "Lukasz", ""], ["Wyrzykowski", "Roman", ""]]}, {"id": "1507.01321", "submitter": "Maria Spichkova", "authors": "Iman I. Yusuf and Ian E. Thomas and Maria Spichkova and Steve\n  Androulakis and Grischa R. Meyer and Daniel W. Drumm and George Opletal and\n  Salvy P. Russo and Ashley M. Buckle and Heinz W. Schmidt", "title": "Chiminey: Reliable Computing and Data Management Platform in the Cloud", "comments": "Preprint, ICSE 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The enabling of scientific experiments that are embarrassingly parallel, long\nrunning and data-intensive into a cloud-based execution environment is a\ndesirable, though complex undertaking for many researchers. The management of\nsuch virtual environments is cumbersome and not necessarily within the core\nskill set for scientists and engineers. We present here Chiminey, a software\nplatform that enables researchers to (i) run applications on both traditional\nhigh-performance computing and cloud-based computing infrastructures, (ii)\nhandle failure during execution, (iii) curate and visualise execution outputs,\n(iv) share such data with collaborators or the public, and (v) search for\npublicly available data.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2015 02:51:20 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Yusuf", "Iman I.", ""], ["Thomas", "Ian E.", ""], ["Spichkova", "Maria", ""], ["Androulakis", "Steve", ""], ["Meyer", "Grischa R.", ""], ["Drumm", "Daniel W.", ""], ["Opletal", "George", ""], ["Russo", "Salvy P.", ""], ["Buckle", "Ashley M.", ""], ["Schmidt", "Heinz W.", ""]]}, {"id": "1507.01391", "submitter": "Nodari Sitchinava", "authors": "Peyman Afshani and Nodari Sitchinava", "title": "Sorting and Permuting without Bank Conflicts on GPUs", "comments": "12 pages, 2 figures, 23rd European Symposium on Algorithms (ESA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we look at the complexity of designing algorithms without any\nbank conflicts in the shared memory of Graphical Processing Units (GPUs). Given\ninput of size $n$, $w$ processors and $w$ memory banks, we study three\nfundamental problems: sorting, permuting and $w$-way partitioning (defined as\nsorting an input containing exactly $n/w$ copies of every integer in $[w]$).\n  We solve sorting in optimal $O(\\frac{n}{w} \\log n)$ time. When $n \\ge w^2$,\nwe solve the partitioning problem optimally in $O(n/w)$ time. We also present a\ngeneral solution for the partitioning problem which takes $O(\\frac{n}{w}\n\\log^3_{n/w} w)$ time. Finally, we solve the permutation problem using a\nrandomized algorithm in $O(\\frac{n}{w} \\log\\log\\log_{n/w} n)$ time. Our results\nshow evidence that when working with banked memory architectures, there is a\nseparation between these problems and the permutation and partitioning problems\nare not as easy as simple parallel scanning.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2015 11:20:34 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Afshani", "Peyman", ""], ["Sitchinava", "Nodari", ""]]}, {"id": "1507.01456", "submitter": "Radu Cristian Ionescu", "authors": "Radu Cristian Ionescu", "title": "A scalable system for primal-dual optimization", "comments": "This has been withdrawn by the author due since it is not fully\n  complete to reach a publication on arxiv.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present some of the most widely used architectures for Big Data,\n\\textit{Hadoop} and \\textit{Spark}, and develop several implementations\nexploiting, the advantages of each. We implement a simplified version of the\nprimal-dual optimization algorithm, described briefly in this paper, by\nchoosing the smoothing functions to be $\\Vert \\cdot \\Vert^2$ with a zero center\npoint. Under the assumption that data is provided as a sparse matrix, we assess\nthe scalability of the designed systems empirically by running them on sample\ntests.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2015 13:42:56 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2015 14:47:56 GMT"}], "update_date": "2015-08-10", "authors_parsed": [["Ionescu", "Radu Cristian", ""]]}, {"id": "1507.01461", "submitter": "Radu Cristian Ionescu", "authors": "Radu Cristian Ionescu", "title": "Revisiting Large Scale Distributed Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, with the widespread of smartphones and other portable gadgets\nequipped with a variety of sensors, data is ubiquitous available and the focus\nof machine learning has shifted from being able to infer from small training\nsamples to dealing with large scale high-dimensional data. In domains such as\npersonal healthcare applications, which motivates this survey, distributed\nmachine learning is a promising line of research, both for scaling up learning\nalgorithms, but mostly for dealing with data which is inherently produced at\ndifferent locations. This report offers a thorough overview of and\nstate-of-the-art algorithms for distributed machine learning, for both\nsupervised and unsupervised learning, ranging from simple linear logistic\nregression to graphical models and clustering. We propose future directions for\nmost categories, specific to the potential personal healthcare applications.\nWith this in mind, the report focuses on how security and low communication\noverhead can be assured in the specific case of a strictly client-server\narchitectural model. As particular directions we provides an exhaustive\npresentation of an empirical clustering algorithm, k-windows, and proposed an\nasynchronous distributed machine learning algorithm that would scale well and\nalso would be computationally cheap and easy to implement.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2015 13:50:26 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Ionescu", "Radu Cristian", ""]]}, {"id": "1507.01546", "submitter": "Sukhpal  Singh Gill", "authors": "Sukhpal Singh Gill", "title": "Autonomic Cloud Computing: Research Perspective", "comments": "Author's Viewpoint on Autonomic Cloud Computing and Uploaded on\n  Research Gate [https://www.researchgate.net/profile/Sukhpal_Gill]", "journal-ref": null, "doi": "10.13140/RG.2.1.4453.4881", "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Cloud computing is an evolving utility computing mechanism in which cloud\nconsumer can detect, choose and utilize the resources (infrastructure, software\nand platform) and provide service to user based on pay per use model as\ncomputing utilities. Current computing mechanism is effective, particular for\nmedium and small cloud based companies, in which it permits easy and reliable\naccess to cloud services like infrastructure, software and platform. Present\ncloud computing is almost similar to the existing models: cluster computing and\ngrid computing. The important key technical features of cloud computing which\nincludes autonomic service, rapid elasticity, end-to-end virtualization\nsupport, on-demand resource pooling and transparency in cloud billing. Further,\nnon-technical features of cloud computing includes environment friendliness,\nlittle maintenance overhead, lower upfront costs, faster time to deployments,\nService Level Agreement (SLA) and pay-as-you-go-model. In distributed computing\nenvironment, unpredictability of service is a fact, so same possible in cloud\nalso. The success of next-generation Cloud Computing infrastructures will\ndepend on how capably these infrastructures will discover and dynamically\ntolerate computing platforms, which meet randomly varying resource and service\nrequirements of Cloud costumer applications.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2015 17:27:04 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2015 13:40:07 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Gill", "Sukhpal Singh", ""]]}, {"id": "1507.01663", "submitter": "Hengfeng Wei", "authors": "Hengfeng Wei, Yu Huang, Jiannong Cao, Jian Lu", "title": "Almost Strong Consistency: \"Good Enough\" in Distributed Storage Systems", "comments": "17 pages, including 5 pages for appendix; 7 figures; 5 tables; to be\n  submitted to VLDB'2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A consistency/latency tradeoff arises as soon as a distributed storage system\nreplicates data. For low latency, modern storage systems often settle for weak\nconsistency conditions, which provide little, or even worse, no guarantee for\ndata consistency. In this paper we propose the notion of almost strong\nconsistency as a better balance option for the consistency/latency tradeoff. It\nprovides both deterministically bounded staleness of data versions for each\nread and probabilistic quantification on the rate of \"reading stale values\",\nwhile achieving low latency. In the context of distributed storage systems, we\ninvestigate almost strong consistency in terms of 2-atomicity. Our 2AM\n(2-Atomicity Maintenance) algorithm completes both reads and writes in one\ncommunication round-trip, and guarantees that each read obtains the value of\nwithin the latest 2 versions. To quantify the rate of \"reading stale values\",\nwe decompose the so-called \"old-new inversion\" phenomenon into concurrency\npatterns and read-write patterns, and propose a stochastic queueing model and a\n\"timed balls-into-bins model\" to analyze them, respectively. The theoretical\nanalysis not only demonstrates that \"old-new inversions\" rarely occur as\nexpected, but also reveals that the read-write pattern dominates in\nguaranteeing such rare data inconsistencies. These are further confirmed by the\nexperimental results, showing that 2-atomicity is \"good enough\" in distributed\nstorage systems by achieving low latency, bounded staleness, and rare data\ninconsistencies.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2015 03:22:32 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2015 03:21:05 GMT"}], "update_date": "2015-07-16", "authors_parsed": [["Wei", "Hengfeng", ""], ["Huang", "Yu", ""], ["Cao", "Jiannong", ""], ["Lu", "Jian", ""]]}, {"id": "1507.01773", "submitter": "Jose Gracia", "authors": "Huan Zhou, Yousri Mhedheb, Kamran Idrees, Colin W. Glass, Jos\\'e\n  Gracia, Karl F\\\"urlinger, Jie Tao", "title": "DART-MPI: An MPI-based Implementation of a PGAS Runtime System", "comments": "11 pages, International Conference on Partitioned Global Address\n  Space Programming Models (PGAS14)", "journal-ref": null, "doi": "10.1145/2676870.2676875", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Partitioned Global Address Space (PGAS) approach treats a distributed\nsystem as if the memory were shared on a global level. Given such a global view\non memory, the user may program applications very much like shared memory\nsystems. This greatly simplifies the tasks of developing parallel applications,\nbecause no explicit communication has to be specified in the program for data\nexchange between different computing nodes. In this paper we present DART, a\nruntime environment, which implements the PGAS paradigm on large-scale\nhigh-performance computing clusters. A specific feature of our implementation\nis the use of one-sided communication of the Message Passing Interface (MPI)\nversion 3 (i.e. MPI-3) as the underlying communication substrate. We evaluated\nthe performance of the implementation with several low-level kernels in order\nto determine overheads and limitations in comparison to the underlying MPI-3.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2015 12:13:23 GMT"}], "update_date": "2015-07-08", "authors_parsed": [["Zhou", "Huan", ""], ["Mhedheb", "Yousri", ""], ["Idrees", "Kamran", ""], ["Glass", "Colin W.", ""], ["Gracia", "Jos\u00e9", ""], ["F\u00fcrlinger", "Karl", ""], ["Tao", "Jie", ""]]}, {"id": "1507.01845", "submitter": "Lili Su", "authors": "Lili Su, Nitin Vaidya", "title": "Byzantine Multi-Agent Optimization: Part II", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Part I of this report, we introduced a Byzantine fault-tolerant\ndistributed optimization problem whose goal is to optimize a sum of convex\n(cost) functions with real-valued scalar input/ouput. In this second part, we\nintroduce a condition-based variant of the original problem over arbitrary\ndirected graphs. Specifically, for a given collection of $k$ input functions\n$h_1(x), \\ldots, h_k(x)$, we consider the scenario when the local cost function\nstored at agent $j$, denoted by $g_j(x)$, is formed as a convex combination of\nthe $k$ input functions $h_1(x), \\ldots, h_k(x)$. The goal of this\ncondition-based problem is to generate an output that is an optimum of\n$\\frac{1}{k}\\sum_{i=1}^k h_i(x)$. Depending on the availability of side\ninformation at each agent, two slightly different variants are considered. We\nshow that for a given graph, the problem can indeed be solved despite the\npresence of faulty agents. In particular, even in the absence of side\ninformation at each agent, when adequate redundancy is available in the optima\nof input functions, a distributed algorithm is proposed in which each agent\ncarries minimal state across iterations.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2015 15:30:13 GMT"}], "update_date": "2015-07-08", "authors_parsed": [["Su", "Lili", ""], ["Vaidya", "Nitin", ""]]}, {"id": "1507.01926", "submitter": "Niklas Baumstark", "authors": "Niklas Baumstark, Guy Blelloch, Julian Shun", "title": "Efficient Implementation of a Synchronous Parallel Push-Relabel\n  Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the observation that FIFO-based push-relabel algorithms are able\nto outperform highest label-based variants on modern, large maximum flow\nproblem instances, we introduce an efficient implementation of the algorithm\nthat uses coarse-grained parallelism to avoid the problems of existing parallel\napproaches. We demonstrate good relative and absolute speedups of our algorithm\non a set of large graph instances taken from real-world applications. On a\nmodern 40-core machine, our parallel implementation outperforms existing\nsequential implementations by up to a factor of 12 and other parallel\nimplementations by factors of up to 3.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2015 19:11:12 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2015 20:02:31 GMT"}], "update_date": "2015-07-27", "authors_parsed": [["Baumstark", "Niklas", ""], ["Blelloch", "Guy", ""], ["Shun", "Julian", ""]]}, {"id": "1507.02259", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu, Yin Tat Lee, Lorenzo Orecchia", "title": "Using Optimization to Obtain a Width-Independent, Parallel, Simpler, and\n  Faster Positive SDP Solver", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC math.NA math.OC math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the design of polylogarithmic depth algorithms for approximately\nsolving packing and covering semidefinite programs (or positive SDPs for\nshort). This is a natural SDP generalization of the well-studied positive LP\nproblem.\n  Although positive LPs can be solved in polylogarithmic depth while using only\n$\\tilde{O}(\\log^{2} n/\\varepsilon^2)$ parallelizable iterations, the best known\npositive SDP solvers due to Jain and Yao require $O(\\log^{14} n\n/\\varepsilon^{13})$ parallelizable iterations. Several alternative solvers have\nbeen proposed to reduce the exponents in the number of iterations. However, the\ncorrectness of the convergence analyses in these works has been called into\nquestion, as they both rely on algebraic monotonicity properties that do not\ngeneralize to matrix algebra.\n  In this paper, we propose a very simple algorithm based on the optimization\nframework proposed for LP solvers. Our algorithm only needs $\\tilde{O}(\\log^2 n\n/ \\varepsilon^2)$ iterations, matching that of the best LP solver. To surmount\nthe obstacles encountered by previous approaches, our analysis requires a new\nmatrix inequality that extends Lieb-Thirring's inequality, and a\nsign-consistent, randomized variant of the gradient truncation technique\nproposed in.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2015 19:09:33 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2016 20:34:43 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Lee", "Yin Tat", ""], ["Orecchia", "Lorenzo", ""]]}, {"id": "1507.02272", "submitter": "Bogdan Chlebus", "authors": "Bogdan S. Chlebus and Gianluca De Marco and Muhammed Talo", "title": "Anonymous Processors with Synchronous Shared Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider synchronous distributed systems in which anonymous processors\ncommunicate by shared read-write variables. The goal is to have all the\nprocessors assign unique names to themselves. We consider the instances of this\nproblem determined by whether the number $n$ is known or not, and whether\nconcurrently attempting to write distinct values into the same memory cell is\nallowed or not, and whether the number of shared variables is a constant\nindependent of $n$ or it is unbounded. For known $n$, we give Las Vegas\nalgorithms that operate in the optimum expected time, as determined by the\namount of available shared memory, and use the optimum $O(n\\log n)$ expected\nnumber of random bits. For unknown $n$, we give Monte Carlo algorithms that\nproduce correct output upon termination with probabilities that are\n$1-n^{-\\Omega(1)}$, which is best possible when terminating almost surely and\nusing $O(n\\log n)$ random bits.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2015 19:59:35 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2015 23:20:23 GMT"}, {"version": "v3", "created": "Thu, 1 Sep 2016 02:29:18 GMT"}], "update_date": "2016-09-02", "authors_parsed": [["Chlebus", "Bogdan S.", ""], ["De Marco", "Gianluca", ""], ["Talo", "Muhammed", ""]]}, {"id": "1507.02357", "submitter": "Jeremy Kepner", "authors": "Jeremy Kepner, William Arcand, David Bestor, Bill Bergeron, Chansup\n  Byun, Lauren Edwards, Vijay Gadepally, Matthew Hubbell, Peter Michaleas,\n  Julie Mullen, Andrew Prout, Antonio Rosa, Charles Yee, Albert Reuther", "title": "Lustre, Hadoop, Accumulo", "comments": "6 pages; accepted to IEEE High Performance Extreme Computing\n  conference, Waltham, MA, 2015", "journal-ref": null, "doi": "10.1109/HPEC.2015.7322476", "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data processing systems impose multiple views on data as it is processed by\nthe system. These views include spreadsheets, databases, matrices, and graphs.\nThere are a wide variety of technologies that can be used to store and process\ndata through these different steps. The Lustre parallel file system, the Hadoop\ndistributed file system, and the Accumulo database are all designed to address\nthe largest and the most challenging data storage problems. There have been\nmany ad-hoc comparisons of these technologies. This paper describes the\nfoundational principles of each technology, provides simple models for\nassessing their capabilities, and compares the various technologies on a\nhypothetical common cluster. These comparisons indicate that Lustre provides 2x\nmore storage capacity, is less likely to loose data during 3 simultaneous drive\nfailures, and provides higher bandwidth on general purpose workloads. Hadoop\ncan provide 4x greater read bandwidth on special purpose workloads. Accumulo\nprovides 10,000x lower latency on random lookups than either Lustre or Hadoop\nbut Accumulo's bulk bandwidth is 10x less. Significant recent work has been\ndone to enable mix-and-match solutions that allow Lustre, Hadoop, and Accumulo\nto be combined in different ways.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2015 03:00:06 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Kepner", "Jeremy", ""], ["Arcand", "William", ""], ["Bestor", "David", ""], ["Bergeron", "Bill", ""], ["Byun", "Chansup", ""], ["Edwards", "Lauren", ""], ["Gadepally", "Vijay", ""], ["Hubbell", "Matthew", ""], ["Michaleas", "Peter", ""], ["Mullen", "Julie", ""], ["Prout", "Andrew", ""], ["Rosa", "Antonio", ""], ["Yee", "Charles", ""], ["Reuther", "Albert", ""]]}, {"id": "1507.02372", "submitter": "Min Sang Yoon", "authors": "Min Sang Yoon, Ahmed E. Kamal, Zhengyuan Zhu", "title": "Request Prediction in Cloud with a Cyclic Window Learning Algorithm", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic resource scaling is one advantage of Cloud systems. Cloud systems\nare able to scale the number of physical machines depending on user requests.\nTherefore, accurate request prediction brings a great improvement in Cloud\nsystems' performance. If we can make accurate requests prediction, the\nappropriate number of physical machines that can accommodate predicted amount\nof requests can be activated and Cloud systems will save more energy by\npreventing excessive activation of physical machines. Also, Cloud systems can\nimplement advanced load distribution with accurate requests prediction. We\npropose an algorithm that predicts a probability distribution parameters of\nrequests for each time interval. Maximum Likelihood Estimation (MLE) and Local\nLinear Regression (LLR) are used to implement this algorithm. An evaluation of\nthe proposed algorithm is performed with the Google cluster-trace data. The\nprediction is implemented about the number of task arrivals, CPU requests, and\nmemory requests. Then the accuracy of prediction is measured with Mean Absolute\nPercentage Error (MAPE).\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2015 04:43:57 GMT"}], "update_date": "2015-07-10", "authors_parsed": [["Yoon", "Min Sang", ""], ["Kamal", "Ahmed E.", ""], ["Zhu", "Zhengyuan", ""]]}, {"id": "1507.02545", "submitter": "Gourav Saha Mr", "authors": "Gourav Saha and Ramkrishna Pasumarthy", "title": "Maximizing Profit of Cloud Brokers under Quantized Billing Cycles: a\n  Dynamic Pricing Strategy based on Ski-Rental Problem", "comments": "11 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cloud computing, users scale their resources (computational) based on\ntheir need. There is massive literature dealing with such resource scaling\nalgorithms. These works ignore a fundamental constrain imposed by all Cloud\nService Providers (CSP), i.e. one has to pay for a fixed minimum duration\nirrespective of their usage. Such quantization in billing cycles poses problem\nfor users with sporadic workload. In recent literature, Cloud Broker (CB) has\nbeen introduced for the benefit of such users. A CB rents resources from CSP\nand in turn provides service to users to generate profit. Contract between CB\nand user is that of pay-what-you-use/pay-per-use. However CB faces the\nchallenge of Quantized Billing Cycles as it negotiates with CSP. We design two\nalgorithms, one fully online and the other partially online, which maximizes\nthe profit of the CB. The key idea is to regulate users demand using dynamic\npricing. Our algorithm is inspired by the Ski-Rental problem. We derive\ncompetitive ratio of these algorithms and also conduct simulations using real\nworld traces to prove the efficiency of our algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2015 15:09:53 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2015 12:54:55 GMT"}], "update_date": "2015-09-01", "authors_parsed": [["Saha", "Gourav", ""], ["Pasumarthy", "Ramkrishna", ""]]}, {"id": "1507.02721", "submitter": "Akka Zemmari", "authors": "Y. M\\'etivier and J.M. Robson and A. Zemmari", "title": "On Distributed Computing with Beeps", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider networks of processes which interact with beeps. Various beeping\nmodels are used. The basic one, defined by Cornejo and Kuhn [CK10], assumes\nthat a process can choose either to beep or to listen; if it listens it can\ndistinguish between silence or the presence of at least one beep. The aim of\nthis paper is the study of the resolution of paradigms such as collision\ndetection, computation of the degree of a vertex, colouring, or 2-hop-colouring\nin the framework of beeping models. For each of these problems we present Las\nVegas or Monte Carlo algorithms and we analyse their complexities expressed in\nterms of the number of slots. We present also efficient randomised emulations\nof more powerful beeping models on the basic one. We illustrate emulation\nprocedures with an efficient degree computation algorithm in the basic beeping\nmodel; this algorithm was given initially in a more powerful model.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2015 21:44:45 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2015 07:58:23 GMT"}], "update_date": "2015-07-24", "authors_parsed": [["M\u00e9tivier", "Y.", ""], ["Robson", "J. M.", ""], ["Zemmari", "A.", ""]]}, {"id": "1507.02722", "submitter": "Zahra Aghazadeh", "authors": "Zahra Aghazadeh, Philipp Woelfel", "title": "On the Time and Space Complexity of ABA Prevention and Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the time and space complexity of detecting and preventing ABAs\nin shared memory algorithms for systems with n processes and bounded base\nobjects. To that end, we define ABA-detecting registers, which are similar to\nnormal read/write registers, except that they allow a process q to detect with\na read operation, whether some process wrote the register since q's last read.\nABA-detecting registers can be implemented trivially from a single unbounded\nregister, but we show that they have a high complexity if base objects are\nbounded: An obstruction-free implementation of an ABA-detecting single bit\nregister cannot be implemented from fewer than n-1 bounded registers. Moreover,\nbounded CAS objects (or more generally, conditional read-modify-write\nprimitives) offer little help to implement ABA-detecting single bit registers:\nWe prove a linear time-space tradeoff for such implementations. We show that\nthe same time-space tradeoff holds for implementations of single bit LL/SC\nprimitives from bounded writable CAS objects. This proves that the\nimplementations of LL/SC/VL by Anderson and Moir (1995) as well as Jayanti and\nPetrovic (2003) are optimal. We complement our lower bounds with tight upper\nbounds: We give an implementation of ABA-detecting registers from n+1 bounded\nregisters, which has step complexity O(1). We also show that (bounded) LL/SC/VL\ncan be implemented from a single bounded CAS object and with O(n) step\ncomplexity. Both upper bounds are asymptotically optimal with respect to their\ntime-space product. These results give formal evidence that the ABA problem is\ninherently difficult, that even writable CAS objects do not provide significant\nbenefits over registers for dealing with the ABA problem itself, and that there\nis no hope of finding a more efficient implementation of LL/SC/VL from bounded\nCAS objects and registers than the ones mentioned.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2015 21:53:23 GMT"}], "update_date": "2015-07-13", "authors_parsed": [["Aghazadeh", "Zahra", ""], ["Woelfel", "Philipp", ""]]}, {"id": "1507.02798", "submitter": "Marek Szuba", "authors": "Ahmad Maatouki, Marek Szuba, J\\\"org Meyer, Achim Streit", "title": "A horizontally-scalable multiprocessing platform based on Node.js", "comments": "8 pages, 7 figures. Accepted for publication as a conference paper\n  for the 13th IEEE International Symposium on Parallel and Distributed\n  Processing with Applications (IEEE ISPA-15)", "journal-ref": "CoRR abs/1507.02798 (2015). ISBN: 978-1-4673-7952-6/15", "doi": "10.1109/Trustcom-BigDataSe-ISPA.2015.618", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a scalable web-based platform called Node Scala which\nallows to split and handle requests on a parallel distributed system according\nto pre-defined use cases. We applied this platform to a client application that\nvisualizes climate data stored in a NoSQL database MongoDB. The design of Node\nScala leads to efficient usage of available computing resources in addition to\nallowing the system to scale simply by adding new workers. Performance\nevaluation of Node Scala demonstrated a gain of up to 74 % compared to the\nstate-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2015 08:06:22 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["Maatouki", "Ahmad", ""], ["Szuba", "Marek", ""], ["Meyer", "J\u00f6rg", ""], ["Streit", "Achim", ""]]}, {"id": "1507.02987", "submitter": "Felipe Fernandes Albrecht", "authors": "Felipe Albrecht", "title": "Genoogle: an indexed and parallelized search engine for similar DNA\n  sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE cs.IR q-bio.GN", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The search for similar genetic sequences is one of the main bioinformatics\ntasks. The genetic sequences data banks are growing exponentially and the\nsearching techniques that use linear time are not capable to do the search in\nthe required time anymore. Another problem is that the clock speed of the\nmodern processors are not growing as it did before, instead, the processing\ncapacity is growing with the addiction of more processing cores and the\ntechniques which does not use parallel computing does not have benefits from\nthese extra cores. This work aims to use data indexing techniques to reduce the\nsearching process computation cost united with the parallelization of the\nsearching techniques to use the computational capacity of the multi core\nprocessors. To verify the viability of using these two techniques\nsimultaneously, a software which uses parallelization techniques with inverted\nindexes was developed.\n  Experiments were executed to analyze the performance gain when parallelism is\nutilized, the search time gain, and also the quality of the results when it\ncompared with others searching tools. The results of these experiments were\npromising, the parallelism gain overcame the expected speedup, the searching\ntime was 20 times faster than the parallelized NCBI BLAST, and the searching\nresults showed a good quality when compared with this tool.\n  The software source code is available at\nhttps://github.com/felipealbrecht/Genoogle .\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2015 18:50:31 GMT"}], "update_date": "2015-07-13", "authors_parsed": [["Albrecht", "Felipe", ""]]}, {"id": "1507.03162", "submitter": "Wojciech Golab", "authors": "Marlon McKenzie, Hua Fan, Wojciech Golab", "title": "Continuous Partial Quorums for Consistency-Latency Tuning in Distributed\n  NoSQL Storage Systems", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NoSQL storage systems are used extensively by web applications and provide an\nattractive alternative to conventional databases when the need for scalability\noutweighs the need for transactions. Several of these systems provide\nquorum-based replication and present the application developer with a choice of\nmultiple client-side \"consistency levels\" that determine the number of replicas\naccessed by reads and writes, which in turn affects both latency and the\nconsistency observed by the client application. Since using a fixed combination\nof read and write consistency levels for a given application provides only a\nlimited number of discrete options, we investigate techniques that allow more\nfine-grained tuning of the consistency-latency trade-off, as may be required to\nsupport consistency-based service level agreements (SLAs). We propose a novel\ntechnique called \\emph{continuous partial quorums} (CPQ) that assigns the\nconsistency level on a per-operation basis by choosing randomly between two\noptions, such as eventual and strong consistency, with a tunable probability.\nWe evaluate our technique experimentally using Apache Cassandra and demonstrate\nthat it outperforms an alternative tuning technique that delays operations\nartificially.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2015 22:14:31 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2015 12:08:27 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2015 12:45:50 GMT"}], "update_date": "2015-10-02", "authors_parsed": [["McKenzie", "Marlon", ""], ["Fan", "Hua", ""], ["Golab", "Wojciech", ""]]}, {"id": "1507.03274", "submitter": "Yeounoh Chung", "authors": "Yeounoh Chung and Erfan Zamanian", "title": "Using RDMA for Lock Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we aim to evaluate different Distributed Lock Management\nservice designs with Remote Direct Memory Access (RDMA). In specific, we\nimplement and evaluate the centralized and the RDMA-enabled lock manager\ndesigns for fast network settings. Experimental results confirms a couple of\nhypotheses. First, in the traditional centralized lock manager design, CPU is\nthe bottleneck and bypassing CPU on client-to-server communication using RDMA\nresults in better lock service perofrmance. Second, different lock manager\ndesigns with RDMA in consideration result in even better performance; we need\nto re-design lock management system for RDMA and fast networks.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2015 21:28:34 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2015 19:02:31 GMT"}], "update_date": "2015-07-21", "authors_parsed": [["Chung", "Yeounoh", ""], ["Zamanian", "Erfan", ""]]}, {"id": "1507.03325", "submitter": "Zhao Zhang", "authors": "Zhao Zhang, Kyle Barbary, Frank Austin Nothaft, Evan Sparks, Oliver\n  Zahn, Michael J. Franklin, David A. Patterson, Saul Perlmutter", "title": "Scientific Computing Meets Big Data Technology: An Astronomy Use Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific analyses commonly compose multiple single-process programs into a\ndataflow. An end-to-end dataflow of single-process programs is known as a\nmany-task application. Typically, tools from the HPC software stack are used to\nparallelize these analyses. In this work, we investigate an alternate approach\nthat uses Apache Spark -- a modern big data platform -- to parallelize\nmany-task applications. We present Kira, a flexible and distributed astronomy\nimage processing toolkit using Apache Spark. We then use the Kira toolkit to\nimplement a Source Extractor application for astronomy images, called Kira SE.\nWith Kira SE as the use case, we study the programming flexibility, dataflow\nrichness, scheduling capacity and performance of Apache Spark running on the\nEC2 cloud. By exploiting data locality, Kira SE achieves a 2.5x speedup over an\nequivalent C program when analyzing a 1TB dataset using 512 cores on the Amazon\nEC2 cloud. Furthermore, we show that by leveraging software originally designed\nfor big data infrastructure, Kira SE achieves competitive performance to the C\nimplementation running on the NERSC Edison supercomputer. Our experience with\nKira indicates that emerging Big Data platforms such as Apache Spark are a\nperformant alternative for many-task scientific applications.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2015 04:47:04 GMT"}, {"version": "v2", "created": "Mon, 14 Mar 2016 19:04:09 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Zhang", "Zhao", ""], ["Barbary", "Kyle", ""], ["Nothaft", "Frank Austin", ""], ["Sparks", "Evan", ""], ["Zahn", "Oliver", ""], ["Franklin", "Michael J.", ""], ["Patterson", "David A.", ""], ["Perlmutter", "Saul", ""]]}, {"id": "1507.03376", "submitter": "Akka Zemmari", "authors": "Y. M\\'etivier, J.M. Robson, and A. Zemmari", "title": "A Distributed Enumeration Algorithm and Applications to All Pairs\n  Shortest Paths, Diameter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the standard message passing model; we assume the system is fully\nsynchronous: all processes start at the same time and time proceeds in\nsynchronised rounds. In each round each vertex can transmit a different message\nof size $O(1)$ to each of its neighbours. This paper proposes and analyses a\ndistributed enumeration algorithm of vertices of a graph having a distinguished\nvertex which satisfies that two vertices with consecutive numbers are at\ndistance at most $3$. We prove that its time complexity is $O(n)$ where $n$ is\nthe number of vertices of the graph. Furthermore, the size of each message is\n$O(1)$ thus its bit complexity is also $O(n).$ We provide some links between\nthis enumeration and Hamiltonian graphs from which we deduce that this\nenumeration is optimal in the sense that there does not exist an enumeration\nwhich satisfies that two vertices with consecutive numbers are at distance at\nmost $2$.\n  We deduce from this enumeration algorithms which compute all pairs shortest\npaths and the diameter with a time complexity and a bit complexity equal to\n$O(n)$. This improves the best known distributed algorithms (under the same\nhypotheses) for computing all pairs shortest paths or the diameter presented in\n\\cite{PRT12,HW12} having a time complexity equal to $O(n)$ and which use\nmessages of size $O(\\log n)$ bits.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2015 09:58:11 GMT"}], "update_date": "2015-07-14", "authors_parsed": [["M\u00e9tivier", "Y.", ""], ["Robson", "J. M.", ""], ["Zemmari", "A.", ""]]}, {"id": "1507.03562", "submitter": "Mbarka Soualhia", "authors": "Mbarka Soualhia, Foutse Khomh and Sofiene Tahar", "title": "Predicting Scheduling Failures in the Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud Computing has emerged as a key technology to deliver and manage\ncomputing, platform, and software services over the Internet. Task scheduling\nalgorithms play an important role in the efficiency of cloud computing services\nas they aim to reduce the turnaround time of tasks and improve resource\nutilization. Several task scheduling algorithms have been proposed in the\nliterature for cloud computing systems, the majority relying on the\ncomputational complexity of tasks and the distribution of resources. However,\nseveral tasks scheduled following these algorithms still fail because of\nunforeseen changes in the cloud environments. In this paper, using tasks\nexecution and resource utilization data extracted from the execution traces of\nreal world applications at Google, we explore the possibility of predicting the\nscheduling outcome of a task using statistical models. If we can successfully\npredict tasks failures, we may be able to reduce the execution time of jobs by\nrescheduling failed tasks earlier (i.e., before their actual failing time). Our\nresults show that statistical models can predict task failures with a precision\nup to 97.4%, and a recall up to 96.2%. We simulate the potential benefits of\nsuch predictions using the tool kit GloudSim and found that they can improve\nthe number of finished tasks by up to 40%. We also perform a case study using\nthe Hadoop framework of Amazon Elastic MapReduce (EMR) and the jobs of a gene\nexpression correlations analysis study from breast cancer research. We find\nthat when extending the scheduler of Hadoop with our predictive models, the\npercentage of failed jobs can be reduced by up to 45%, with an overhead of less\nthan 5 minutes.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2015 19:31:23 GMT"}], "update_date": "2015-07-14", "authors_parsed": [["Soualhia", "Mbarka", ""], ["Khomh", "Foutse", ""], ["Tahar", "Sofiene", ""]]}, {"id": "1507.03648", "submitter": "Cengis Hasan", "authors": "Cengis Hasan and Zygmunt J. Haas", "title": "Deadline-aware Power Management in Data Centers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the dynamic power optimization problem in data centers. We formulate\nand solve the following offline problem: in which slot which server has to be\nassigned to which job; and in which slot which server has to be switched ON or\nOFF so that the total power is optimal for some time horizon. We show that the\noffline problem is a new version of generalized assignment problem including\nnew constraints issuing from deadline characteristics of jobs and difference of\nactivation energy of servers. We propose an online algorithm that solves the\nproblem heuristically and compare it to randomized routing.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2015 22:54:20 GMT"}], "update_date": "2015-07-19", "authors_parsed": [["Hasan", "Cengis", ""], ["Haas", "Zygmunt J.", ""]]}, {"id": "1507.03719", "submitter": "Huy Nguyen", "authors": "Rafael da Ponte Barbosa, Alina Ene, Huy L. Nguyen, Justin Ward", "title": "A New Framework for Distributed Submodular Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide variety of problems in machine learning, including exemplar\nclustering, document summarization, and sensor placement, can be cast as\nconstrained submodular maximization problems. A lot of recent effort has been\ndevoted to developing distributed algorithms for these problems. However, these\nresults suffer from high number of rounds, suboptimal approximation ratios, or\nboth. We develop a framework for bringing existing algorithms in the sequential\nsetting to the distributed setting, achieving near optimal approximation ratios\nfor many settings in only a constant number of MapReduce rounds. Our techniques\nalso give a fast sequential algorithm for non-monotone maximization subject to\na matroid constraint.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2015 04:46:01 GMT"}, {"version": "v2", "created": "Thu, 11 Aug 2016 21:20:02 GMT"}], "update_date": "2016-08-15", "authors_parsed": [["Barbosa", "Rafael da Ponte", ""], ["Ene", "Alina", ""], ["Nguyen", "Huy L.", ""], ["Ward", "Justin", ""]]}, {"id": "1507.03927", "submitter": "Houwu Chen", "authors": "Houwu Chen, Jiwu Shu", "title": "SkyHash: a Hash Opinion Dynamics Model", "comments": "This paper has been withdrawn by the author due to a crucial\n  theoretic defect", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the first hash opinion dynamics model, named SkyHash,\nthat can help a P2P network quickly reach consensus on hash opinion. The model\nconsists of a bit layer and a hash layer, each time when a node shapes its new\nopinion, the bit layer is to determine each bit of a pseudo hash, and the hash\nlayer is to choose a hash opinion with minimum Hamming distance to the pseudo\nhash. With simulations, we conducted a comprehensive study on the convergence\nspeed of the model by taking into account impacts of various configurations\nsuch as network size, node degree, hash size, and initial hash density.\nEvaluation demonstrates that using our model, consensus can be quickly reached\neven in large networks. We also developed a denial-of-service (DoS) proof\nextension for our model. Experiments on the SNAP dataset of the Wikipedia\nwho-votes-on-whom network demonstrate that besides the ability to refuse known\nill-behaved nodes, the DoS-proof extended model also outperforms Bitcoin by\nproducing consensus in 45 seconds, and tolerating DoS attack committed by up to\n0.9% top influential nodes.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2015 17:03:56 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2015 10:25:24 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2015 07:44:57 GMT"}, {"version": "v4", "created": "Sat, 17 Oct 2015 11:15:55 GMT"}, {"version": "v5", "created": "Tue, 17 Nov 2015 15:47:38 GMT"}, {"version": "v6", "created": "Sun, 26 Feb 2017 23:22:50 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Chen", "Houwu", ""], ["Shu", "Jiwu", ""]]}, {"id": "1507.04039", "submitter": "Pascal Potvin", "authors": "Pascal Potvin, Hanen Garcia Gamardo, Kim-Khoa Nguyen and Mohamed\n  Cheriet", "title": "Hyper Heterogeneous Cloud-based IMS Software Architecture: A\n  Proof-of-Concept and Empirical Analysis", "comments": "12 pages, 9 figures, 1 table. Accepted for oral presentation at S2CT\n  2015 in Toronto. Latest Version is Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The IP Multimedia Subsystem (IMS) defined by the 3GPP has been mainly\ndeveloped and deployed by telephony vendors on vendor-specific hardware. Recent\nadvances in Network Function Virtualisation (NFV) technology paved the way for\nvirtualized hardware and telephony function elasticity. As such, Telecom\nvendors have started to embrace the cloud as a deployment platform, usually\nselecting a privileged virtualization platform. Operators would like to deploy\ntelecom functionality on their already existing IT cloud platforms. Achieving\nsuch flexibility would require the telecom vendors to adopt a software\narchitecture allowing deployment on many cloud platforms or even heterogeneous\ncloud platforms. We propose a distributed software architecture enabling the\ndeployment of a single software version on multiple cloud platforms thus\nallowing for a solution-based deployment. We also present a prototype we\ndeveloped to study the characteristics of this architecture.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2015 22:27:16 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2015 15:34:21 GMT"}], "update_date": "2015-09-21", "authors_parsed": [["Potvin", "Pascal", ""], ["Gamardo", "Hanen Garcia", ""], ["Nguyen", "Kim-Khoa", ""], ["Cheriet", "Mohamed", ""]]}, {"id": "1507.04047", "submitter": "Nuno Fachada", "authors": "Nuno Fachada, Vitor V. Lopes, Rui C. Martins, Agostinho C. Rosa", "title": "Parallelization Strategies for Spatial Agent-Based Models", "comments": "The peer-reviewed version of this paper is published in the\n  International Journal of Parallel Programming at\n  http://dx.doi.org/10.1007/s10766-015-0399-9 . This version is typeset by the\n  authors and differs only in pagination and typographical detail", "journal-ref": "International Journal of Parallel Programming, 45(3), pp. 449-481,\n  2017", "doi": "10.1007/s10766-015-0399-9", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agent-based modeling (ABM) is a bottom-up modeling approach, where each\nentity of the system being modeled is uniquely represented as an independent\ndecision-making agent. Large scale emergent behavior in ABMs is population\nsensitive. As such, the number of agents in a simulation should be able to\nreflect the reality of the system being modeled, which can be in the order of\nmillions or billions of individuals in certain domains. A natural solution to\nreach acceptable scalability in commodity multi-core processors consists of\ndecomposing models such that each component can be independently processed by a\ndifferent thread in a concurrent manner. In this paper we present a\nmultithreaded Java implementation of the PPHPC ABM, with two goals in mind: 1)\ncompare the performance of this implementation with an existing NetLogo\nimplementation; and, 2) study how different parallelization strategies impact\nsimulation performance on a shared memory architecture. Results show that: 1)\nmodel parallelization can yield considerable performance gains; 2) distinct\nparallelization strategies offer specific trade-offs in terms of performance\nand simulation reproducibility; and, 3) PPHPC is a valid reference model for\ncomparing distinct implementations or parallelization strategies, from both\nperformance and statistical accuracy perspectives.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2015 23:20:54 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2015 19:39:18 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2015 20:33:10 GMT"}, {"version": "v4", "created": "Thu, 24 Dec 2015 01:12:42 GMT"}, {"version": "v5", "created": "Mon, 10 Apr 2017 19:33:23 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Fachada", "Nuno", ""], ["Lopes", "Vitor V.", ""], ["Martins", "Rui C.", ""], ["Rosa", "Agostinho C.", ""]]}, {"id": "1507.04086", "submitter": "Vinit Kumar", "authors": "Vinit Kumar and Ajay Agarwal", "title": "HT-Ring Paxos: Theory of High Throughput State-Machine Replication for\n  Clustered Data Centers", "comments": "18 pages. arXiv admin note: substantial text overlap with\n  arXiv:1407.1237", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implementations of state-machine replication (SMR) prevalently use the\nvariants of Paxos. Some of the recent variants of Paxos like, Ring Paxos,\nMulti-Ring Paxos, S-Paxos and HT-Paxos achieve significantly high throughput.\nHowever, to meet the growing demand of high throughput, we are proposing\nHT-Ring Paxos, a variant of Paxos that is basically derived from the classical\nPaxos. Moreover, it also adopts some fundamental concepts of Ring Paxos,\nS-Paxos and HT-Paxos for increasing throughput. Furthermore, HT-Ring Paxos is\nbest suitable for clustered data centers and achieves comparatively high\nthroughput among all variants of Paxos. However, similar to Ring Paxos, latency\nof the HT-Ring Paxos is quite high as compared with other variants of Paxos.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2015 05:17:50 GMT"}], "update_date": "2015-07-16", "authors_parsed": [["Kumar", "Vinit", ""], ["Agarwal", "Ajay", ""]]}, {"id": "1507.04234", "submitter": "Pooja Vyavahare", "authors": "Pooja Vyavahare and Nutan Limaye Ajit A. Diwan and D. Manjunath", "title": "On the Maximum Rate of Networked Computation in a Capacitated Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a capacitated communication network $\\mathcal{N}$ and a function f that\nneeds to be computed on $\\mathcal{N},$ we study the problem of generating a\ncomputation and communication schedule in $\\mathcal{N}$ to maximize the rate of\ncomputation of f. Shah et. al.[IEEE Journal of Selected Areas in Communication,\n2013] studied this problem when the computation schema $\\mathcal{G}$ for f is a\ntree. We define the notion of a schedule when $\\mathcal{G}$ is a general DAG\nand show that finding an optimal schedule is equivalent to finding the solution\nof a packing LP. We prove that approximating the maximum rate is MAX SNP-hard\nby looking at the packing LP. For this packing LP we prove that solving the\nseparation oracle of its dual is equivalent to solving the LP. The separation\noracle of the dual reduces to the problem of finding minimum cost embedding\ngiven $\\mathcal{N},\\mathcal{G},$ which we prove to be MAX SNP-hard even when\n$\\mathcal{G}$ has bounded degree and bounded edge weights and $\\mathcal{N}$ has\njust three vertices. We present a polynomial time algorithm to compute the\nmaximum rate of function computation when $\\mathcal{N}$ has two vertices by\nreducing the problem to a version of submodular function minimization problem.\nFor the general $\\mathcal{N}$ we study restricted class of schedules and its\nequivalent packing LP. We observe that for this packing LP also the separation\noracle of its dual reduces to finding minimum cost embedding. A version of this\nminimum cost embedding problem has been studied in literature. We present a\nquadratic integer program for the minimum cost embedding problem and its linear\nprogramming relaxation based on earthmover metric. We also present some\napproximate algorithms for special classes of $\\mathcal{G}.$\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2015 14:34:17 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2015 03:58:10 GMT"}, {"version": "v3", "created": "Thu, 21 Jan 2016 05:43:41 GMT"}], "update_date": "2016-01-22", "authors_parsed": [["Vyavahare", "Pooja", ""], ["Diwan", "Nutan Limaye Ajit A.", ""], ["Manjunath", "D.", ""]]}, {"id": "1507.04296", "submitter": "Arun Nair", "authors": "Arun Nair, Praveen Srinivasan, Sam Blackwell, Cagdas Alcicek, Rory\n  Fearon, Alessandro De Maria, Vedavyas Panneershelvam, Mustafa Suleyman,\n  Charles Beattie, Stig Petersen, Shane Legg, Volodymyr Mnih, Koray\n  Kavukcuoglu, David Silver", "title": "Massively Parallel Methods for Deep Reinforcement Learning", "comments": "Presented at the Deep Learning Workshop, International Conference on\n  Machine Learning, Lille, France, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first massively distributed architecture for deep\nreinforcement learning. This architecture uses four main components: parallel\nactors that generate new behaviour; parallel learners that are trained from\nstored experience; a distributed neural network to represent the value function\nor behaviour policy; and a distributed store of experience. We used our\narchitecture to implement the Deep Q-Network algorithm (DQN). Our distributed\nalgorithm was applied to 49 games from Atari 2600 games from the Arcade\nLearning Environment, using identical hyperparameters. Our performance\nsurpassed non-distributed DQN in 41 of the 49 games and also reduced the\nwall-time required to achieve these results by an order of magnitude on most\ngames.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2015 16:56:56 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2015 09:27:06 GMT"}], "update_date": "2015-07-17", "authors_parsed": [["Nair", "Arun", ""], ["Srinivasan", "Praveen", ""], ["Blackwell", "Sam", ""], ["Alcicek", "Cagdas", ""], ["Fearon", "Rory", ""], ["De Maria", "Alessandro", ""], ["Panneershelvam", "Vedavyas", ""], ["Suleyman", "Mustafa", ""], ["Beattie", "Charles", ""], ["Petersen", "Stig", ""], ["Legg", "Shane", ""], ["Mnih", "Volodymyr", ""], ["Kavukcuoglu", "Koray", ""], ["Silver", "David", ""]]}, {"id": "1507.04330", "submitter": "Zohar Karnin", "authors": "Keren Censor-Hillel, Elad Haramaty, Zohar Karnin", "title": "Optimal Dynamic Distributed MIS", "comments": "19 pages including appendix and references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding a maximal independent set (MIS) in a graph is a cornerstone task in\ndistributed computing. The local nature of an MIS allows for fast solutions in\na static distributed setting, which are logarithmic in the number of nodes or\nin their degrees. The result trivially applies for the dynamic distributed\nmodel, in which edges or nodes may be inserted or deleted. In this paper, we\ntake a different approach which exploits locality to the extreme, and show how\nto update an MIS in a dynamic distributed setting, either \\emph{synchronous} or\n\\emph{asynchronous}, with only \\emph{a single adjustment} and in a single\nround, in expectation. These strong guarantees hold for the \\emph{complete\nfully dynamic} setting: Insertions and deletions, of edges as well as nodes,\ngracefully and abruptly. This strongly separates the static and dynamic\ndistributed models, as super-constant lower bounds exist for computing an MIS\nin the former.\n  Our results are obtained by a novel analysis of the surprisingly simple\nsolution of carefully simulating the greedy \\emph{sequential} MIS algorithm\nwith a random ordering of the nodes. As such, our algorithm has a direct\napplication as a $3$-approximation algorithm for correlation clustering. This\nadds to the important toolbox of distributed graph decompositions, which are\nwidely used as crucial building blocks in distributed computing.\n  Finally, our algorithm enjoys a useful \\emph{history-independence} property,\nmeaning the output is independent of the history of topology changes that\nconstructed that graph. This means the output cannot be chosen, or even biased,\nby the adversary in case its goal is to prevent us from optimizing some\nobjective function.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2015 19:09:35 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2015 10:39:24 GMT"}], "update_date": "2015-07-17", "authors_parsed": [["Censor-Hillel", "Keren", ""], ["Haramaty", "Elad", ""], ["Karnin", "Zohar", ""]]}, {"id": "1507.04383", "submitter": "Sayyed Ali Mirsoleimani", "authors": "S. Ali Mirsoleimani, Aske Plaat, Jaap van den Herik, Jos Vermaseren", "title": "Scaling Monte Carlo Tree Search on Intel Xeon Phi", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many algorithms have been parallelized successfully on the Intel Xeon Phi\ncoprocessor, especially those with regular, balanced, and predictable data\naccess patterns and instruction flows. Irregular and unbalanced algorithms are\nharder to parallelize efficiently. They are, for instance, present in\nartificial intelligence search algorithms such as Monte Carlo Tree Search\n(MCTS). In this paper we study the scaling behavior of MCTS, on a highly\noptimized real-world application, on real hardware. The Intel Xeon Phi allows\nshared memory scaling studies up to 61 cores and 244 hardware threads. We\ncompare work-stealing (Cilk Plus and TBB) and work-sharing (FIFO scheduling)\napproaches. Interestingly, we find that a straightforward thread pool with a\nwork-sharing FIFO queue shows the best performance. A crucial element for this\nhigh performance is the controlling of the grain size, an approach that we call\nGrain Size Controlled Parallel MCTS. Our subsequent comparing with the Xeon\nCPUs shows an even more comprehensible distinction in performance between\ndifferent threading libraries. We achieve, to the best of our knowledge, the\nfastest implementation of a parallel MCTS on the 61 core Intel Xeon Phi using a\nreal application (47 relative to a sequential run).\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2015 20:28:18 GMT"}], "update_date": "2015-07-17", "authors_parsed": [["Mirsoleimani", "S. Ali", ""], ["Plaat", "Aske", ""], ["Herik", "Jaap van den", ""], ["Vermaseren", "Jos", ""]]}, {"id": "1507.04405", "submitter": "Ryan McCune", "authors": "Robert Ryan McCune, Tim Weninger, Gregory Madey", "title": "Thinking Like a Vertex: a Survey of Vertex-Centric Frameworks for\n  Distributed Graph Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vertex-centric programming model is an established computational paradigm\nrecently incorporated into distributed processing frameworks to address\nchallenges in large-scale graph processing. Billion-node graphs that exceed the\nmemory capacity of standard machines are not well-supported by popular Big Data\ntools like MapReduce, which are notoriously poor-performing for iterative graph\nalgorithms such as PageRank. In response, a new type of framework challenges\none to Think Like A Vertex (TLAV) and implements user-defined programs from the\nperspective of a vertex rather than a graph. Such an approach improves\nlocality, demonstrates linear scalability, and provides a natural way to\nexpress and compute many iterative graph algorithms. These frameworks are\nsimple to program and widely applicable, but, like an operating system, are\ncomposed of several intricate, interdependent components, of which a thorough\nunderstanding is necessary in order to elicit top performance at scale. To this\nend, the first comprehensive survey of TLAV frameworks is presented. In this\nsurvey, the vertex-centric approach to graph processing is overviewed, TLAV\nframeworks are deconstructed into four main components and respectively\nanalyzed, and TLAV implementations are reviewed and categorized.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2015 22:14:23 GMT"}], "update_date": "2015-07-17", "authors_parsed": [["McCune", "Robert Ryan", ""], ["Weninger", "Tim", ""], ["Madey", "Gregory", ""]]}, {"id": "1507.04461", "submitter": "Shantanu Sharma", "authors": "Foto Afrati, Shlomi Dolev, Ephraim Korach, Shantanu Sharma, Jeffrey D.\n  Ullman", "title": "Assignment Problems of Different-Sized Inputs in MapReduce", "comments": "This paper is accepted in ACM Transactions on Knowledge Discovery\n  from Data (TKDD), August 2016. Preliminary versions of this paper have\n  appeared in the proceeding of DISC 2014 and BeyondMR 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A MapReduce algorithm can be described by a mapping schema, which assigns\ninputs to a set of reducers, such that for each required output there exists a\nreducer that receives all the inputs that participate in the computation of\nthis output. Reducers have a capacity, which limits the sets of inputs that\nthey can be assigned. However, individual inputs may vary in terms of size. We\nconsider, for the first time, mapping schemas where input sizes are part of the\nconsiderations and restrictions. One of the significant parameters to optimize\nin any MapReduce job is communication cost between the map and reduce phases.\nThe communication cost can be optimized by minimizing the number of copies of\ninputs sent to the reducers. The communication cost is closely related to the\nnumber of reducers of constrained capacity that are used to accommodate\nappropriately the inputs, so that the requirement of how the inputs must meet\nin a reducer is satisfied. In this work, we consider a family of problems where\nit is required that each input meets with each other input in at least one\nreducer. We also consider a slightly different family of problems in which,\neach input of a list, X, is required to meet each input of another list, Y, in\nat least one reducer. We prove that finding an optimal mapping schema for these\nfamilies of problems is NP-hard, and present a bin-packing-based approximation\nalgorithm for finding a near optimal mapping schema.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2015 06:46:19 GMT"}, {"version": "v2", "created": "Thu, 20 Oct 2016 19:07:51 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Afrati", "Foto", ""], ["Dolev", "Shlomi", ""], ["Korach", "Ephraim", ""], ["Sharma", "Shantanu", ""], ["Ullman", "Jeffrey D.", ""]]}, {"id": "1507.04462", "submitter": "Shantanu Sharma", "authors": "Shantanu Sharma, Awadhesh Kumar Singh", "title": "On Detecting Termination in Cognitive Radio Networks", "comments": "Accepted in Wiley International Journal of Network Management\n  (Wiley-IJNM) 2014, 12 figures", "journal-ref": "International Journal of Network Management 24.6 (2014): 499-527", "doi": "10.1002/nem.1870", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cognitive radio networks are an emerging wireless communication and\ncomputing paradigm. The cognitive radio nodes execute computations on multiple\nheterogeneous channels in the absence of licensed users (a.k.a. primary users)\nof those bands. Termination detection is a fundamental and non-trivial problem\nin distributed systems. In this paper, we propose a termination detection\nprotocol for multi-hop cognitive radio networks where the cognitive radio nodes\nare allowed to tune to channels that are not currently occupied by primary\nusers and to move to different locations during the protocol execution. The\nproposed protocol applies credit distribution and aggregation approach and\nmaintains a new kind of logical structure, called the virtual tree-like\nstructure. The virtual tree-like structure helps in decreasing the latency\ninvolved in announcing termination. Unlike conventional tree structures, the\nvirtual tree-like structure does not require a specific node to act as the root\nnode that has to stay involved in the computation until termination\nannouncement; hence, the root node may become idle soon after finishing its\ncomputation. Also, the protocol is able to detect the presence of licensed\nusers and announce strong or weak termination, whichever is possible.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2015 06:53:19 GMT"}], "update_date": "2015-07-17", "authors_parsed": [["Sharma", "Shantanu", ""], ["Singh", "Awadhesh Kumar", ""]]}, {"id": "1507.04909", "submitter": "Akka Zemmari", "authors": "Jean-Fran\\c{c}ois Marckert, Nasser Saheb-Djahromi, Akka Zemmari", "title": "Election algorithms with random delays in trees", "comments": null, "journal-ref": "Discrete Mathematics and Theoretical Computer Science (DMTCS),\n  611-622, 2009", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The election is a classical problem in distributed algorithmic. It aims to\ndesign and to analyze a distributed algorithm choosing a node in a graph, here,\nin a tree. In this paper, a class of randomized algorithms for the election is\nstudied. The election amounts to removing leaves one by one until the tree is\nreduced to a unique node which is then elected. The algorithm assigns to each\nleaf a probability distribution (that may depends on the information\ntransmitted by the eliminated nodes) used by the leaf to generate its remaining\nrandom lifetime. In the general case, the probability of each node to be\nelected is given. For two categories of algorithms, close formulas are\nprovided.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2015 10:35:52 GMT"}], "update_date": "2015-07-20", "authors_parsed": [["Marckert", "Jean-Fran\u00e7ois", ""], ["Saheb-Djahromi", "Nasser", ""], ["Zemmari", "Akka", ""]]}, {"id": "1507.05086", "submitter": "Dimitris S. Papailiopoulos", "authors": "Xinghao Pan, Dimitris Papailiopoulos, Samet Oymak, Benjamin Recht,\n  Kannan Ramchandran, Michael I. Jordan", "title": "Parallel Correlation Clustering on Big Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a similarity graph between items, correlation clustering (CC) groups\nsimilar items together and dissimilar ones apart. One of the most popular CC\nalgorithms is KwikCluster: an algorithm that serially clusters neighborhoods of\nvertices, and obtains a 3-approximation ratio. Unfortunately, KwikCluster in\npractice requires a large number of clustering rounds, a potential bottleneck\nfor large graphs.\n  We present C4 and ClusterWild!, two algorithms for parallel correlation\nclustering that run in a polylogarithmic number of rounds and achieve nearly\nlinear speedups, provably. C4 uses concurrency control to enforce\nserializability of a parallel clustering process, and guarantees a\n3-approximation ratio. ClusterWild! is a coordination free algorithm that\nabandons consistency for the benefit of better scaling; this leads to a\nprovably small loss in the 3-approximation ratio.\n  We provide extensive experimental results for both algorithms, where we\noutperform the state of the art, both in terms of clustering accuracy and\nrunning time. We show that our algorithms can cluster billion-edge graphs in\nunder 5 seconds on 32 cores, while achieving a 15x speedup.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2015 19:48:32 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2015 18:36:02 GMT"}], "update_date": "2015-07-21", "authors_parsed": [["Pan", "Xinghao", ""], ["Papailiopoulos", "Dimitris", ""], ["Oymak", "Samet", ""], ["Recht", "Benjamin", ""], ["Ramchandran", "Kannan", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1507.05129", "submitter": "Francisco Igual", "authors": "Sandra Catal\\'an and Francisco D. Igual and Rafael Mayo and Luis\n  Pi\\~nuel and Enrique S. Quintana-Ort\\'i and Rafael Rodr\\'iguez-S\\'anchez", "title": "Performance and Energy Optimization of Matrix Multiplication on\n  Asymmetric big.LITTLE Processors", "comments": "Presented at HiPEAC 2015, Amsterdam. Foundation of the Asymmetric\n  BLIS implementation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asymmetric processors have emerged as an appealing technology for severely\nenergy-constrained environments, especially in the mobile market where\nheterogeneity in applications is mainstream. In addition, given the growing\ninterest on ultra low-power architectures for high performance computing, this\ntype of platforms are also being investigated in the road towards the\nimplementation of energy- efficient high-performance scientific applications.\nIn this paper, we propose a first step towards a complete implementation of the\nBLAS interface adapted to asymmetric ARM big.LITTLE processors, analyzing the\ntrade-offs between performance and energy efficiency when compared to existing\nhomogeneous (symmetric) multi-threaded BLAS implementations. Our experimental\nresults reveal important gains in performance while maintaining the energy\nefficiency of homogeneous solutions by efficiently exploiting all the resources\nof the asymmetric processor.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2015 22:56:12 GMT"}], "update_date": "2015-07-21", "authors_parsed": [["Catal\u00e1n", "Sandra", ""], ["Igual", "Francisco D.", ""], ["Mayo", "Rafael", ""], ["Pi\u00f1uel", "Luis", ""], ["Quintana-Ort\u00ed", "Enrique S.", ""], ["Rodr\u00edguez-S\u00e1nchez", "Rafael", ""]]}, {"id": "1507.05169", "submitter": "Alexander Spiegelman", "authors": "Alexander Spiegelman, Yuval Cassuto, Gregory Chockler, and Idit Keidar", "title": "Space Bounds for Reliable Storage: Fundamental Limits of Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the inherent space requirements of shared storage algorithms in\nasynchronous fault-prone systems. Previous works use codes to achieve a better\nstorage cost than the well-known replication approach. However, a closer look\nreveals that they incur extra costs somewhere else: Some use unbounded storage\nin communication links, while others assume bounded concurrency or synchronous\nperiods. We prove here that this is inherent, and indeed, if there is no bound\non the concurrency level, then the storage cost of any reliable storage\nalgorithm is at least f+1 times the data size, where f is the number of\ntolerated failures. We further present a technique for combining erasure-codes\nwith full replication so as to obtain the best of both. We present a storage\nalgorithm whose storage cost is close to the lower bound in the worst case, and\nadapts to the concurrency level.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2015 10:25:18 GMT"}], "update_date": "2015-07-21", "authors_parsed": [["Spiegelman", "Alexander", ""], ["Cassuto", "Yuval", ""], ["Chockler", "Gregory", ""], ["Keidar", "Idit", ""]]}, {"id": "1507.05228", "submitter": "Reza Abdolee", "authors": "Reza Abdolee, Benoit Champagne, Ali H. Sayed", "title": "Diffusion Adaptation over Multi-Agent Networks with Wireless Link\n  Impairments", "comments": "IEEE Transaction on Mobile Computing, July 2015", "journal-ref": null, "doi": "10.1109/TMC.2015.2460251", "report-no": null, "categories": "cs.SY cs.DC cs.IT math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the performance of diffusion least-mean-square algorithms for\ndistributed parameter estimation in multi-agent networks when nodes exchange\ninformation over wireless communication links. Wireless channel impairments,\nsuch as fading and path-loss, adversely affect the exchanged data and cause\ninstability and performance degradation if left unattended. To mitigate these\neffects, we incorporate equalization coefficients into the diffusion\ncombination step and update the combination weights dynamically in the face of\nrandomly changing neighborhoods due to fading conditions. When channel state\ninformation (CSI) is unavailable, we determine the equalization factors from\npilot-aided channel coefficient estimates. The analysis reveals that by\nproperly monitoring the CSI over the network and choosing sufficiently small\nadaptation step-sizes, the diffusion strategies are able to deliver\nsatisfactory performance in the presence of fading and path loss.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2015 22:34:21 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Abdolee", "Reza", ""], ["Champagne", "Benoit", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1507.05398", "submitter": "Manish Gupta", "authors": "Srajan Paliwal, Saurabh Tiwary, Bhaskar Chaudhury and Manish K. Gupta", "title": "Generating Binary Optimal Codes Using Heterogeneous Parallel Computing", "comments": "8 pages, draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generation of optimal codes is a well known problem in coding theory. Many\ncomputational approaches exist in the literature for finding record breaking\ncodes. However generating codes with long lengths $n$ using serial algorithms\nis computationally very expensive, for example the worst case time complexity\nof a Greedy algorithm is $\\mathcal{O}(n\\; 4^n)$. In order to improve the\nefficiency of generating codes with long lengths, we propose and investigate\nsome parallel algorithms using General Purpose Graphic Processing Units\n(GPGPU). This paper considers the implementation of parallel Greedy algorithm\nusing GPGPU-CUDA (Computed Unified Device Architecture) framework and discusses\nvarious optimization techniques to accelerate the GPU code. The performance\nachieved for optimized parallel implementations is more than two to three\norders of magnitude faster than that of serial implementation and shows a great\npotential of GPGPU in the field of coding theory applications.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2015 07:12:12 GMT"}], "update_date": "2015-07-21", "authors_parsed": [["Paliwal", "Srajan", ""], ["Tiwary", "Saurabh", ""], ["Chaudhury", "Bhaskar", ""], ["Gupta", "Manish K.", ""]]}, {"id": "1507.05467", "submitter": "Long Thai MSc", "authors": "Long Thai, Blesson Varghese, Adam Barker", "title": "Budget Constrained Execution of Multiple Bag-of-Tasks Applications on\n  the Cloud", "comments": "8th IEEE International Conference on Cloud Computing (CLOUD 2015)", "journal-ref": null, "doi": "10.1109/CLOUD.2015.131", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimising the execution of Bag-of-Tasks (BoT) applications on the cloud is a\nhard problem due to the trade- offs between performance and monetary cost. The\nproblem can be further complicated when multiple BoT applications need to be\nexecuted. In this paper, we propose and implement a heuristic algorithm that\nschedules tasks of multiple applications onto different cloud virtual machines\nin order to maximise performance while satisfying a given budget constraint.\nCurrent approaches are limited in task scheduling since they place a limit on\nthe number of cloud resources that can be employed by the applications.\nHowever, in the proposed algorithm there are no such limits, and in comparison\nwith other approaches, the algorithm on average achieves an improved\nperformance of 10%. The experimental results also highlight that the algorithm\nyields consistent performance even with low budget constraints which cannot be\nachieved by competing approaches.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2015 12:25:54 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Thai", "Long", ""], ["Varghese", "Blesson", ""], ["Barker", "Adam", ""]]}, {"id": "1507.05470", "submitter": "Long Thai MSc", "authors": "Long Thai, Blesson Varghese, Adam Barker", "title": "Task Scheduling on the Cloud with Hard Constraints", "comments": "Visionary Track of the IEEE 11th World Congress on Services (IEEE\n  SERVICES 2015)", "journal-ref": null, "doi": "10.1109/SERVICES.2015.22", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scheduling Bag-of-Tasks (BoT) applications on the cloud can be more\nchallenging than grid and cluster environ- ments. This is because a user may\nhave a budgetary constraint or a deadline for executing the BoT application in\norder to keep the overall execution costs low. The research in this paper is\nmotivated to investigate task scheduling on the cloud, given two hard\nconstraints based on a user-defined budget and a deadline. A heuristic\nalgorithm is proposed and implemented to satisfy the hard constraints for\nexecuting the BoT application in a cost effective manner. The proposed\nalgorithm is evaluated using four scenarios that are based on the trade-off\nbetween performance and the cost of using different cloud resource types. The\nexperimental evaluation confirms the feasibility of the algorithm in satisfying\nthe constraints. The key observation is that multiple resource types can be a\nbetter alternative to using a single type of resource.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2015 12:31:23 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Thai", "Long", ""], ["Varghese", "Blesson", ""], ["Barker", "Adam", ""]]}, {"id": "1507.05472", "submitter": "Marco Netto", "authors": "Kiran Mantripragada, Leonardo P. Tizzei, Alecio P. D. Binotto, Marco\n  A. S. Netto", "title": "An SLA-based Advisor for Placement of HPC Jobs on Hybrid Clouds", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several scientific and industry applications require High Performance\nComputing (HPC) resources to process and/or simulate complex models. Not long\nago, companies, research institutes, and universities used to acquire and\nmaintain on-premise computer clusters; but, recently, cloud computing has\nemerged as an alternative for a subset of HPC applications. This poses a\nchallenge to end-users, who have to decide where to run their jobs: on local\nclusters or burst to a remote cloud service provider. While current research on\nHPC cloud has focused on comparing performance of on-premise clusters against\ncloud resources, we build on top of existing efforts and introduce an advisory\nservice to help users make this decision considering the trade-offs of resource\ncosts, performance, and availability on hybrid clouds. We evaluated our service\nusing a real test-bed with a seismic processing application based on Full\nWaveform Inversion; a technique used by geophysicists in the oil & gas industry\nand earthquake prediction. We also discuss how the advisor can be used for\nother applications and highlight the main lessons learned constructing this\nservice to reduce costs and turnaround times.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2015 12:41:32 GMT"}], "update_date": "2015-07-21", "authors_parsed": [["Mantripragada", "Kiran", ""], ["Tizzei", "Leonardo P.", ""], ["Binotto", "Alecio P. D.", ""], ["Netto", "Marco A. S.", ""]]}, {"id": "1507.05501", "submitter": "Ewout Bongers", "authors": "Ewout Bongers, Johan Pouwelse", "title": "A survey of P2P multidimensional indexing structures", "comments": "Course IN4306 - Literature Survey", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Traditional databases have long since reaped the benefits of multidimensional\nindexes. Numerous proposals in the literature describe multidimensional index\ndesigns for P2P systems. However, none of these designs have had real world\nimplementations. Several proposals for P2P multidimensional indexes are\nreviewed and analyzed. Znet and VBI-tree are the most promising from a\ntechnical standpoint. All of the proposed designs assume honest nodes and are\nthus open to abuse. This is a critical flaw that must be solved before any of\nthe proposed systems can be used.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2015 14:04:35 GMT"}], "update_date": "2015-07-21", "authors_parsed": [["Bongers", "Ewout", ""], ["Pouwelse", "Johan", ""]]}, {"id": "1507.05720", "submitter": "David Budden", "authors": "David M. Budden and Edmund J. Crampin", "title": "Gene expression modelling across multiple cell-lines with MapReduce", "comments": "10 pages, 3 figures", "journal-ref": "BMC Bioinformatics 2016 17:446", "doi": "10.1186/s12859-016-1313-1", "report-no": null, "categories": "q-bio.QM cs.DC q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the wealth of high-throughput sequencing data generated by recent\nlarge-scale consortia, predictive gene expression modelling has become an\nimportant tool for integrative analysis of transcriptomic and epigenetic data.\nHowever, sequencing data-sets are characteristically large, and previously\nmodelling frameworks are typically inefficient and unable to leverage\nmulti-core or distributed processing architectures. In this study, we detail an\nefficient and parallelised MapReduce implementation of gene expression\nmodelling. We leverage the computational efficiency of this framework to\nprovide an integrative analysis of over fifty histone modification data-sets\nacross a variety of cancerous and non-cancerous cell-lines. Our results\ndemonstrate that the genome-wide relationships between histone modifications\nand mRNA transcription are lineage, tissue and karyotype-invariant, and that\nmodels trained on matched epigenetic/transcriptomic data from non-cancerous\ncell-lines are able to predict cancerous expression with equivalent genome-wide\nfidelity.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2015 06:37:35 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Budden", "David M.", ""], ["Crampin", "Edmund J.", ""]]}, {"id": "1507.05796", "submitter": "Emanuele Natale", "authors": "Pierre Fraigniaud and Emanuele Natale", "title": "Noisy Rumor Spreading and Plurality Consensus", "comments": "Minor revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Error-correcting codes are efficient methods for handling \\emph{noisy}\ncommunication channels in the context of technological networks. However, such\nelaborate methods differ a lot from the unsophisticated way biological entities\nare supposed to communicate. Yet, it has been recently shown by Feinerman,\nHaeupler, and Korman {[}PODC 2014{]} that complex coordination tasks such as\n\\emph{rumor spreading} and \\emph{majority consensus} can plausibly be achieved\nin biological systems subject to noisy communication channels, where every\nmessage transferred through a channel remains intact with small probability\n$\\frac{1}{2}+\\epsilon$, without using coding techniques. This result is a\nconsiderable step towards a better understanding of the way biological entities\nmay cooperate. It has been nevertheless be established only in the case of\n2-valued \\emph{opinions}: rumor spreading aims at broadcasting a single-bit\nopinion to all nodes, and majority consensus aims at leading all nodes to adopt\nthe single-bit opinion that was initially present in the system with (relative)\nmajority. In this paper, we extend this previous work to $k$-valued opinions,\nfor any $k\\geq2$.\n  Our extension requires to address a series of important issues, some\nconceptual, others technical. We had to entirely revisit the notion of noise,\nfor handling channels carrying $k$-\\emph{valued} messages. In fact, we\nprecisely characterize the type of noise patterns for which plurality consensus\nis solvable. Also, a key result employed in the bivalued case by Feinerman et\nal. is an estimate of the probability of observing the most frequent opinion\nfrom observing the mode of a small sample. We generalize this result to the\nmultivalued case by providing a new analytical proof for the bivalued case that\nis amenable to be extended, by induction, and that is of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2015 12:02:36 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2015 00:59:08 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2015 12:20:07 GMT"}, {"version": "v4", "created": "Sun, 14 Feb 2016 03:21:06 GMT"}, {"version": "v5", "created": "Sun, 22 May 2016 10:28:06 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Fraigniaud", "Pierre", ""], ["Natale", "Emanuele", ""]]}, {"id": "1507.05875", "submitter": "Tarek Richard Besold", "authors": "Arne Recknagel and Tarek R. Besold", "title": "Efficient Dodgson-Score Calculation Using Heuristics and Parallel\n  Computing", "comments": "Additional references; partially rewritten text for improved\n  readability; minor corrections of typos/language issues etc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conflict of interest is the permanent companion of any population of agents\n(computational or biological). For that reason, the ability to compromise is of\nparamount importance, making voting a key element of societal mechanisms. One\nof the voting procedures most often discussed in the literature and, due to its\nintuitiveness, also conceptually quite appealing is Charles Dodgson's scoring\nrule, basically using the respective closeness to being a Condorcet winner for\nevaluating competing alternatives. In this paper, we offer insights on the\npractical limits of algorithms computing the exact Dodgson scores from a number\nof votes. While the problem itself is theoretically intractable, this work\nproposes and analyses five different solutions which try distinct approaches to\npractically solve the issue in an effective manner. Additionally, three of the\ndiscussed procedures can be run in parallel which has the potential of\ndrastically reducing the problem size.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2015 15:29:28 GMT"}, {"version": "v2", "created": "Tue, 9 Aug 2016 14:44:41 GMT"}], "update_date": "2016-08-10", "authors_parsed": [["Recknagel", "Arne", ""], ["Besold", "Tarek R.", ""]]}, {"id": "1507.05995", "submitter": "Yuchao Tang", "authors": "Yuchao Tang, Zhenggang Wu, Chuanxi Zhu", "title": "A Warm Restart Strategy for Solving Sudoku by Sparse Optimization\n  Methods", "comments": "11 pages,5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the popular Sudoku problem. We proposed a warm\nrestart strategy for solving Sudoku puzzles, based on the sparse optimization\ntechnique. Furthermore, we defined a new difficulty level for Sudoku puzzles.\nThe efficiency of the proposed method is tested using a dataset of Sudoku\npuzzles, and the numerical results show that the accurate recovery rate can be\nenhanced from 84%+ to 99%+ using the L1 sparse optimization method.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2015 04:39:26 GMT"}, {"version": "v2", "created": "Thu, 26 May 2016 07:20:51 GMT"}, {"version": "v3", "created": "Thu, 15 Mar 2018 04:29:35 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Tang", "Yuchao", ""], ["Wu", "Zhenggang", ""], ["Zhu", "Chuanxi", ""]]}, {"id": "1507.06165", "submitter": "Cheng Wang", "authors": "Cheng Wang", "title": "Asynchronous Byzantine Agreement with Optimal Resilience and Linear\n  Complexity", "comments": "Previous title: Fast Almost-Surely Terminating Byzantine Agreement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given a system with $n > 3t + 1$ processes, where $t$ is the tolerated number\nof faulty ones, we present a fast asynchronous Byzantine agreement protocol\nthat can reach agreement in $O(t)$ expected running time. This improves the\n$O(n^2)$ expected running time of Abraham, Dolev, and Halpern [PODC 2008].\nFurthermore, if $n = (3 + \\varepsilon) t$ for any $\\varepsilon > 0$, our\nprotocol can reach agreement in $O (1 / \\varepsilon)$ expected running time.\nThis improves the result of Feldman and Micali [STOC 1988] (with constant\nexpected running time when $n > 4 t$).\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2015 12:56:55 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2015 00:21:37 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2015 21:31:11 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Wang", "Cheng", ""]]}, {"id": "1507.06702", "submitter": "Jesun Sahariar Firoz", "authors": "Jesun Sahariar Firoz, Thejaka Amila Kanewala, Marcin Zalewski, Martina\n  Barnas, Andrew Lumsdaine", "title": "The Anatomy of Large-Scale Distributed Graph Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.PF cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing complexity of the software/hardware stack of modern\nsupercomputers results in explosion of parameters. The performance analysis\nbecomes a truly experimental science, even more challenging in the presence of\nmassive irregularity and data dependency. We analyze how the existing body of\nresearch handles the experimental aspect in the context of distributed graph\nalgorithms (DGAs). We distinguish algorithm-level contributions, often\nprioritized by authors, from runtime-level concerns that are harder to place.\nWe show that the runtime is such an integral part of DGAs that experimental\nresults are difficult to interpret and extrapolate without understanding the\nproperties of the runtime used. We argue that in order to gain understanding\nabout the impact of runtimes, more information needs to be gathered. To begin\nthis process, we provide an initial set of recommendations for describing DGA\nresults based on our analysis of the current state of the field.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2015 23:42:34 GMT"}], "update_date": "2015-07-27", "authors_parsed": [["Firoz", "Jesun Sahariar", ""], ["Kanewala", "Thejaka Amila", ""], ["Zalewski", "Marcin", ""], ["Barnas", "Martina", ""], ["Lumsdaine", "Andrew", ""]]}, {"id": "1507.06707", "submitter": "Emanuele Natale", "authors": "Luca Becchetti, Andrea Clementi, Emanuele Natale, Francesco Pasquale", "title": "Probabilistic Self-Stabilization", "comments": "arXiv admin note: text overlap with arXiv:1501.04822", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By using concrete scenarios, we present and discuss a new concept of\nprobabilistic Self-Stabilization in Distributed Systems.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2015 00:14:33 GMT"}], "update_date": "2015-07-27", "authors_parsed": [["Becchetti", "Luca", ""], ["Clementi", "Andrea", ""], ["Natale", "Emanuele", ""], ["Pasquale", "Francesco", ""]]}, {"id": "1507.06812", "submitter": "Stathis Maneas", "authors": "Nikos Chondros, Bingsheng Zhang, Thomas Zacharias, Panos\n  Diamantopoulos, Stathis Maneas, Christos Patsonakis, Alex Delis, Aggelos\n  Kiayias, Mema Roussopoulos", "title": "D-DEMOS: A distributed, end-to-end verifiable, internet voting system", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  E-voting systems have emerged as a powerful technology for improving\ndemocracy by reducing election cost, increasing voter participation, and even\nallowing voters to directly verify the entire election procedure. Prior\ninternet voting systems have single points of failure, which may result in the\ncompromise of availability, voter secrecy, or integrity of the election\nresults. In this paper, we present the design, implementation, security\nanalysis, and evaluation of D-DEMOS, a complete e-voting system that is\ndistributed, privacy-preserving and end-to-end verifiable. Our system includes\na fully asynchronous vote collection subsystem that provides immediate\nassurance to the voter her vote was recorded as cast, without requiring\ncryptographic operations on behalf of the voter. We also include a distributed,\nreplicated and fault-tolerant Bulletin Board component, that stores all\nnecessary election-related information, and allows any party to read and verify\nthe complete election process. Finally, we also incorporate trustees, i.e.,\nindividuals who control election result production while guaranteeing privacy\nand end-to-end-verifiability as long as their strong majority is honest. Our\nsystem is the first e-voting system whose voting operation is human verifiable,\ni.e., a voter can vote over the web, even when her web client stack is\npotentially unsafe, without sacrificing her privacy, and still be assured her\nvote was recorded as cast. Additionally, a voter can outsource election\nauditing to third parties, still without sacrificing privacy. Finally, as the\nnumber of auditors increases, the probability of election fraud going\nundetected is diminished exponentially. We provide a model and security\nanalysis of the system. We implement a prototype of the complete system, we\nmeasure its performance experimentally, and we demonstrate its ability to\nhandle large-scale elections.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2015 11:29:12 GMT"}, {"version": "v2", "created": "Sat, 19 Dec 2015 01:35:10 GMT"}], "update_date": "2015-12-22", "authors_parsed": [["Chondros", "Nikos", ""], ["Zhang", "Bingsheng", ""], ["Zacharias", "Thomas", ""], ["Diamantopoulos", "Panos", ""], ["Maneas", "Stathis", ""], ["Patsonakis", "Christos", ""], ["Delis", "Alex", ""], ["Kiayias", "Aggelos", ""], ["Roussopoulos", "Mema", ""]]}, {"id": "1507.06858", "submitter": "Mahdy Nabaee Ph.D.", "authors": "Pascal Potvin, Mahdy Nabaee, Fabrice Labeau, Kim-Khoa Nguyen, Mohamed\n  Cheriet", "title": "Micro Service Cloud Computing Pattern for Next Generation Networks", "comments": "12 pages, submitted for EAI International Conference on Smart\n  Sustainable City Technologies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The falling trend in the revenue of traditional telephony services has\nattracted attention to new IP based services. The IP Multimedia System (IMS) is\na key architecture which provides the necessary platform for delivery of new\nmultimedia services. However, current implementations of IMS do not offer\nautomatic scalability or elastisity for the growing number of customers.\nAlthough the cloud computing paradigm has shown many promising characteristics\nfor web applications, it is still failing to meet the requirements for\ntelecommunication applications. In this paper, we present some related cloud\ncomputing patterns and discuss their adaptations for implementation of IMS or\nother telecommunication systems.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2015 14:28:32 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2015 02:46:06 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Potvin", "Pascal", ""], ["Nabaee", "Mahdy", ""], ["Labeau", "Fabrice", ""], ["Nguyen", "Kim-Khoa", ""], ["Cheriet", "Mohamed", ""]]}, {"id": "1507.06970", "submitter": "Horia Mania", "authors": "Horia Mania, Xinghao Pan, Dimitris Papailiopoulos, Benjamin Recht,\n  Kannan Ramchandran, Michael I. Jordan", "title": "Perturbed Iterate Analysis for Asynchronous Stochastic Optimization", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.DS cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and analyze stochastic optimization methods where the input to\neach gradient update is perturbed by bounded noise. We show that this framework\nforms the basis of a unified approach to analyze asynchronous implementations\nof stochastic optimization algorithms.In this framework, asynchronous\nstochastic optimization algorithms can be thought of as serial methods\noperating on noisy inputs. Using our perturbed iterate framework, we provide\nnew analyses of the Hogwild! algorithm and asynchronous stochastic coordinate\ndescent, that are simpler than earlier analyses, remove many assumptions of\nprevious models, and in some cases yield improved upper bounds on the\nconvergence rates. We proceed to apply our framework to develop and analyze\nKroMagnon: a novel, parallel, sparse stochastic variance-reduced gradient\n(SVRG) algorithm. We demonstrate experimentally on a 16-core machine that the\nsparse and parallel version of SVRG is in some cases more than four orders of\nmagnitude faster than the standard SVRG algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2015 19:36:13 GMT"}, {"version": "v2", "created": "Fri, 25 Mar 2016 20:00:45 GMT"}], "update_date": "2016-03-29", "authors_parsed": [["Mania", "Horia", ""], ["Pan", "Xinghao", ""], ["Papailiopoulos", "Dimitris", ""], ["Recht", "Benjamin", ""], ["Ramchandran", "Kannan", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1507.07068", "submitter": "Baidurya Bhattacharya", "authors": "Anirban Pal, Abhishek Agarwala, Soumyendu Raha, Baidurya Bhattacharya", "title": "Performance metrics in a hybrid MPI-OpenMP based molecular dynamics\n  simulation with short-range interactions", "comments": null, "journal-ref": "Journal of Parallel and Distributed Computing, Elsevier, vol. 74,\n  no. 3, pp. 2203-2214, 2014", "doi": "10.1016/j.jpdc.2013.12.008", "report-no": null, "categories": "physics.comp-ph cond-mat.mtrl-sci cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the computational bottlenecks in molecular dynamics (MD) and\ndescribe the challenges in parallelizing the computation intensive tasks. We\npresent a hybrid algorithm using MPI (Message Passing Interface) with OpenMP\nthreads for parallelizing a generalized MD computation scheme for systems with\nshort range interatomic interactions. The algorithm is discussed in the context\nof nanoindentation of Chromium films with carbon indenters using the Embedded\nAtom Method potential for Cr Cr interaction and the Morse potential for Cr C\ninteractions. We study the performance of our algorithm for a range of\nMPIthread combinations and find the performance to depend strongly on the\ncomputational task and load sharing in the multicore processor. The algorithm\nscaled poorly with MPI and our hybrid schemes were observed to outperform the\npure message passing scheme, despite utilizing the same number of processors or\ncores in the cluster. Speed-up achieved by our algorithm compared favourably\nwith that achieved by standard MD packages.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2015 05:28:27 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Pal", "Anirban", ""], ["Agarwala", "Abhishek", ""], ["Raha", "Soumyendu", ""], ["Bhattacharya", "Baidurya", ""]]}, {"id": "1507.07086", "submitter": "Alexander Spiegelman", "authors": "Alexander Spiegelman and Idit Keidar", "title": "On Liveness of Dynamic Storage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic distributed storage algorithms such as DynaStore, Reconfigurable\nPaxos, RAMBO, and RDS, do not ensure liveness (wait-freedom) in asynchronous\nruns with infinitely many reconfigurations. We prove that this is inherent for\nasynchronous dynamic storage algorithms, including ones that use $\\Omega$ or\n$\\diamond S$ oracles. Our result holds even if only one process may fail,\nprovided that machines that were successfully removed from the system's\nconfiguration may be switched off by an administrator. Intuitively, the\nimpossibility relies on the fact that a correct process can be suspected to\nhave failed at any time, i.e., its failure is indistinguishable to other\nprocesses from slow delivery of its messages, and so the system should be able\nto reconfigure without waiting for this process to complete its pending\noperations.\n  To circumvent this result, we define a dynamic eventually perfect failure\ndetector, and present an algorithm that uses it to emulate wait-free dynamic\natomic storage (with no restrictions on reconfiguration rate). Together, our\nresults thus draw a sharp line between oracles like $\\Omega$ and $\\diamond S$,\nwhich allow some correct process to continue to be suspected forever, and a\ndynamic eventually perfect one, which does not.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2015 09:54:16 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Spiegelman", "Alexander", ""], ["Keidar", "Idit", ""]]}, {"id": "1507.07204", "submitter": "Yasir Shoaib", "authors": "Yasir Shoaib, Olivia Das", "title": "Modeling Website Workload Using Neural Networks", "comments": "25 pages, 13 figures, 21 references, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, artificial neural networks (ANN) are used for modeling the\nnumber of requests received by 1998 FIFA World Cup website. Modeling is done by\nmeans of time-series forecasting. The log traces of the website, available\nthrough the Internet Traffic Archive (ITA), are processed to obtain two\ntime-series data sets that are used for finding the following measurements:\nrequests/day and requests/second. These are modeled by training and simulating\nANN. The method followed to collect and process the data, and perform the\nexperiments have been detailed in this article. In total, 13 cases have been\ntried and their results have been presented, discussed, compared and\nsummarized. Lastly, future works have also been mentioned.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2015 14:42:56 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Shoaib", "Yasir", ""], ["Das", "Olivia", ""]]}, {"id": "1507.07429", "submitter": "Peter Elmer", "authors": "David Abdurachmanov, Alessandro Degano, Peter Elmer, Giulio Eulisse,\n  David Mendez, Shahzad Muzaffar", "title": "Optimizing CMS build infrastructure via Apache Mesos", "comments": "Submitted to proceedings of the 21st International Conference on\n  Computing in High Energy and Nuclear Physics (CHEP2015), Okinawa, Japan", "journal-ref": null, "doi": "10.1088/1742-6596/664/6/062013", "report-no": null, "categories": "cs.DC hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Offline Software of the CMS Experiment at the Large Hadron Collider (LHC)\nat CERN consists of 6M lines of in-house code, developed over a decade by\nnearly 1000 physicists, as well as a comparable amount of general use\nopen-source code. A critical ingredient to the success of the construction and\nearly operation of the WLCG was the convergence, around the year 2000, on the\nuse of a homogeneous environment of commodity x86-64 processors and Linux.\nApache Mesos is a cluster manager that provides efficient resource isolation\nand sharing across distributed applications, or frameworks. It can run Hadoop,\nJenkins, Spark, Aurora, and other applications on a dynamically shared pool of\nnodes. We present how we migrated our continuos integration system to schedule\njobs on a relatively small Apache Mesos enabled cluster and how this resulted\nin better resource usage, higher peak performance and lower latency thanks to\nthe dynamic scheduling capabilities of Mesos.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2015 13:07:34 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2015 10:02:50 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["Abdurachmanov", "David", ""], ["Degano", "Alessandro", ""], ["Elmer", "Peter", ""], ["Eulisse", "Giulio", ""], ["Mendez", "David", ""], ["Muzaffar", "Shahzad", ""]]}, {"id": "1507.07430", "submitter": "Peter Elmer", "authors": "Lothar Bauerdick, Brian Bockelman, Peter Elmer, Stephen Gowdy, Matevz\n  Tadel, Frank Wuerthwein", "title": "Designing Computing System Architecture and Models for the HL-LHC era", "comments": "Submitted to proceedings of the 21st International Conference on\n  Computing in High Energy and Nuclear Physics (CHEP2015), Okinawa, Japan", "journal-ref": null, "doi": "10.1088/1742-6596/664/3/032010", "report-no": null, "categories": "cs.DC hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a programme to study the computing model in CMS after\nthe next long shutdown near the end of the decade.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2015 14:22:28 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["Bauerdick", "Lothar", ""], ["Bockelman", "Brian", ""], ["Elmer", "Peter", ""], ["Gowdy", "Stephen", ""], ["Tadel", "Matevz", ""], ["Wuerthwein", "Frank", ""]]}, {"id": "1507.08101", "submitter": "Moritz Kreutzer", "authors": "Moritz Kreutzer, Jonas Thies, Melven R\\\"ohrig-Z\\\"ollner, Andreas\n  Pieper, Faisal Shahzad, Martin Galgon, Achim Basermann, Holger Fehske, Georg\n  Hager, and Gerhard Wellein", "title": "GHOST: Building blocks for high performance sparse linear algebra on\n  heterogeneous systems", "comments": "32 pages, 11 figures", "journal-ref": null, "doi": "10.1007/s10766-016-0464-z", "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While many of the architectural details of future exascale-class high\nperformance computer systems are still a matter of intense research, there\nappears to be a general consensus that they will be strongly heterogeneous,\nfeaturing \"standard\" as well as \"accelerated\" resources. Today, such resources\nare available as multicore processors, graphics processing units (GPUs), and\nother accelerators such as the Intel Xeon Phi. Any software infrastructure that\nclaims usefulness for such environments must be able to meet their inherent\nchallenges: massive multi-level parallelism, topology, asynchronicity, and\nabstraction. The \"General, Hybrid, and Optimized Sparse Toolkit\" (GHOST) is a\ncollection of building blocks that targets algorithms dealing with sparse\nmatrix representations on current and future large-scale systems. It implements\nthe \"MPI+X\" paradigm, has a pure C interface, and provides hybrid-parallel\nnumerical kernels, intelligent resource management, and truly heterogeneous\nparallelism for multicore CPUs, Nvidia GPUs, and the Intel Xeon Phi. We\ndescribe the details of its design with respect to the challenges posed by\nmodern heterogeneous supercomputers and recent algorithmic developments.\nImplementation details which are indispensable for achieving high efficiency\nare pointed out and their necessity is justified by performance measurements or\npredictions based on performance models. The library code and several\napplications are available as open source. We also provide instructions on how\nto make use of GHOST in existing software packages, together with a case study\nwhich demonstrates the applicability and performance of GHOST as a component\nwithin a larger software stack.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2015 11:08:57 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2015 16:08:56 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2016 12:28:41 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Kreutzer", "Moritz", ""], ["Thies", "Jonas", ""], ["R\u00f6hrig-Z\u00f6llner", "Melven", ""], ["Pieper", "Andreas", ""], ["Shahzad", "Faisal", ""], ["Galgon", "Martin", ""], ["Basermann", "Achim", ""], ["Fehske", "Holger", ""], ["Hager", "Georg", ""], ["Wellein", "Gerhard", ""]]}, {"id": "1507.08217", "submitter": "Armin Balalaie", "authors": "Armin Balalaie (1), Abbas Heydarnoori (1), Pooyan Jamshidi (2) ((1)\n  Sharif University of Technology, (2) Imperial College London)", "title": "Migrating to Cloud-Native Architectures Using Microservices: An\n  Experience Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Migration to the cloud has been a popular topic in industry and academia in\nrecent years. Despite many benefits that the cloud presents, such as high\navailability and scalability, most of the on-premise application architectures\nare not ready to fully exploit the benefits of this environment, and adapting\nthem to this environment is a non-trivial task. Microservices have appeared\nrecently as novel architectural styles that are native to the cloud. These\ncloud-native architectures can facilitate migrating on-premise architectures to\nfully benefit from the cloud environments because non-functional attributes,\nlike scalability, are inherent in this style. The existing approaches on cloud\nmigration does not mostly consider cloud-native architectures as their\nfirst-class citizens. As a result, the final product may not meet its primary\ndrivers for migration. In this paper, we intend to report our experience and\nlessons learned in an ongoing project on migrating a monolithic on-premise\nsoftware architecture to microservices. We concluded that microservices is not\na one-fit-all solution as it introduces new complexities to the system, and\nmany factors, such as distribution complexities, should be considered before\nadopting this style. However, if adopted in a context that needs high\nflexibility in terms of scalability and availability, it can deliver its\npromised benefits.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2015 16:52:39 GMT"}], "update_date": "2015-07-30", "authors_parsed": [["Balalaie", "Armin", ""], ["Heydarnoori", "Abbas", ""], ["Jamshidi", "Pooyan", ""]]}, {"id": "1507.08340", "submitter": "Ahsan Javed Awan", "authors": "Ahsan Javed Awan, Mats Brorsson, Vladimir Vlassov and Eduard Ayguade", "title": "How Data Volume Affects Spark Based Data Analytics on a Scale-up Server", "comments": "accepted to 6th International Workshop on Big Data Benchmarks,\n  Performance Optimization and Emerging Hardware (BpoE-6) held in conjunction\n  with VLDB 2015. arXiv admin note: text overlap with arXiv:1506.07742", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sheer increase in volume of data over the last decade has triggered research\nin cluster computing frameworks that enable web enterprises to extract big\ninsights from big data. While Apache Spark is gaining popularity for exhibiting\nsuperior scale-out performance on the commodity machines, the impact of data\nvolume on the performance of Spark based data analytics in scale-up\nconfiguration is not well understood. We present a deep-dive analysis of Spark\nbased applications on a large scale-up server machine. Our analysis reveals\nthat Spark based data analytics are DRAM bound and do not benefit by using more\nthan 12 cores for an executor. By enlarging input data size, application\nperformance degrades significantly due to substantial increase in wait time\nduring I/O operations and garbage collection, despite 10\\% better instruction\nretirement rate (due to lower L1 cache misses and higher core utilization). We\nmatch memory behaviour with the garbage collector to improve performance of\napplications between 1.6x to 3x.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2015 22:59:49 GMT"}], "update_date": "2015-08-03", "authors_parsed": [["Awan", "Ahsan Javed", ""], ["Brorsson", "Mats", ""], ["Vlassov", "Vladimir", ""], ["Ayguade", "Eduard", ""]]}, {"id": "1507.08492", "submitter": "Georgia Kougka", "authors": "Georgia Kougka and Anastasios Gounaris", "title": "Cost optimization of data flows based on task re-ordering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing big data in a highly dynamic environment becomes more and more\ncritical because of the increasingly need for end-to-end processing of this\ndata. Modern data flows are quite complex and there are not efficient,\ncost-based, fully-automated, scalable optimization solutions that can\nfacilitate flow designers. The state-of-the-art proposals fail to provide near\noptimal solutions even for simple data flows. To tackle this problem, we\nintroduce a set of approximate algorithms for defining the execution order of\nthe constituent tasks, in order to minimize the total execution cost of a data\nflow. We also present the advantages of the parallel execution of data flows.\nWe validated our proposals in both a real tool and synthetic flows and the\nresults show that we can achieve significant speed-ups, moving much closer to\noptimal solutions.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2015 13:25:40 GMT"}], "update_date": "2015-07-31", "authors_parsed": [["Kougka", "Georgia", ""], ["Gounaris", "Anastasios", ""]]}, {"id": "1507.08566", "submitter": "Vinay Chakravarthi Gogineni", "authors": "Vinay Chakravarthi Gogineni and Mrityunjoy Chakraborty", "title": "Diffusion Adaptation Over Clustered Multitask Networks Based on the\n  Affine Projection Algorithm", "comments": "Under Communication. arXiv admin note: substantial text overlap with\n  arXiv:1311.4894 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SY math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed adaptive networks achieve better estimation performance by\nexploiting temporal and as well spatial diversity while consuming few\nresources. Recent works have studied the single task distributed estimation\nproblem, in which the nodes estimate a single optimum parameter vector\ncollaboratively. However, there are many important applications where the\nmultiple vectors have to estimated simultaneously, in a collaborative manner.\nThis paper presents multi-task diffusion strategies based on the Affine\nProjection Algorithm (APA), usage of APA makes the algorithm robust against the\ncorrelated input. The performance analysis of the proposed multi-task diffusion\nAPA algorithm is studied in mean and mean square sense. And also a modified\nmulti-task diffusion strategy is proposed that improves the performance in\nterms of convergence rate and steady state EMSE as well. Simulations are\nconducted to verify the analytical results.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2015 09:27:38 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2015 13:33:33 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2015 15:12:47 GMT"}, {"version": "v4", "created": "Thu, 1 Oct 2015 09:23:55 GMT"}], "update_date": "2015-10-02", "authors_parsed": [["Gogineni", "Vinay Chakravarthi", ""], ["Chakraborty", "Mrityunjoy", ""]]}, {"id": "1507.08834", "submitter": "Matthias Keller", "authors": "Matthias Keller, Holger Karl", "title": "Response-Time-Optimised Service Deployment: MILP Formulations of\n  Piece-wise Linear Functions Approximating Non-linear Bivariate Mixed-integer\n  Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A current trend in networking and cloud computing is to provide compute\nresources at widely dispersed places; this is exemplified by developments such\nas Network Function Virtualisation. This paves the way for wide-area service\ndeployments with improved service quality: e.g, a nearby server can reduce the\nuser-perceived response times. But always using the nearest server can be a bad\ndecision if that server is already highly utilised. This paper formalises the\ntwo related problems of allocating resources at different locations and\nassigning users to them with the goal of minimising the response times for a\ngiven number of resources to use -- a non-linear capacitated facility location\nproblem with integrated queuing systems. To efficiently handle the\nnon-linearity, we introduce five linear problem approximations and adapt the\ncurrently best heuristic for a similar problem to our scenario. All six\napproaches are compared in experiments for solution quality and solving time.\nSurprisingly, our best optimisation formulation outperforms the heuristic in\nboth time and quality. Additionally, we evaluate the influence ot resource\ndistributions in the network on the response time: Cut by half for some\nconfigurations. The presented formulations are applicable to a broader\noptimisation domain.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2015 11:26:34 GMT"}, {"version": "v2", "created": "Mon, 30 May 2016 19:22:57 GMT"}, {"version": "v3", "created": "Tue, 30 Aug 2016 05:47:10 GMT"}], "update_date": "2016-08-31", "authors_parsed": [["Keller", "Matthias", ""], ["Karl", "Holger", ""]]}, {"id": "1507.08967", "submitter": "Olivia Simpson", "authors": "Fan Chung and Olivia Simpson", "title": "Distributed Algorithms for Finding Local Clusters Using Heat Kernel\n  Pagerank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A distributed algorithm performs local computations on pieces of input and\ncommunicates the results through given communication links. When processing a\nmassive graph in a distributed algorithm, local outputs must be configured as a\nsolution to a graph problem without shared memory and with few rounds of\ncommunication. In this paper we consider the problem of computing a local\ncluster in a massive graph in the distributed setting. Computing local clusters\nare of certain application-specific interests, such as detecting communities in\nsocial networks or groups of interacting proteins in biological networks. When\nthe graph models the computer network itself, detecting local clusters can help\nto prevent communication bottlenecks. We give a distributed algorithm that\ncomputes a local cluster in time that depends only logarithmically on the size\nof the graph in the CONGEST model. In particular, when the value of the optimal\nlocal cluster is known, the algorithm runs in time entirely independent of the\nsize of the graph and depends only on error bounds for approximation. We also\nshow that the local cluster problem can be computed in the k-machine\ndistributed model in sublinear time. The speedup of our local cluster\nalgorithms is mainly due to the use of our distributed algorithm for heat\nkernel pagerank.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2015 18:12:27 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2015 19:35:41 GMT"}, {"version": "v3", "created": "Fri, 2 Dec 2016 22:39:20 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Chung", "Fan", ""], ["Simpson", "Olivia", ""]]}]