[{"id": "0712.1167", "submitter": "Felipe Fran\\c{c}a", "authors": "Leandro A. J. Marzulo, Felipe M. G. Fran\\c{c}a and V\\'itor Santos\n  Costa", "title": "Transactional WaveCache: Towards Speculative and Out-of-Order DataFlow\n  Execution of Memory Operations", "comments": "Submitted to ACM International Conference on Computing Frontiers\n  2008, http://www.computingfrontiers.org/, 20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC", "license": null, "abstract": "  The WaveScalar is the first DataFlow Architecture that can efficiently\nprovide the sequential memory semantics required by imperative languages. This\nwork presents an alternative memory ordering mechanism for this architecture,\nthe Transaction WaveCache. Our mechanism maintains the execution order of\nmemory operations within blocks of code, called Waves, but adds the ability to\nspeculatively execute, out-of-order, operations from different waves. This\nordering mechanism is inspired by progress in supporting Transactional\nMemories. Waves are considered as atomic regions and executed as nested\ntransactions. If a wave has finished the execution of all its memory\noperations, as soon as the previous waves are committed, it can be committed.\nIf a hazard is detected in a speculative Wave, all the following Waves\n(children) are aborted and re-executed. We evaluate the WaveCache on a set\nartificial benchmarks. If the benchmark does not access memory often, we could\nachieve speedups of around 90%. Speedups of 33.1% and 24% were observed on more\nmemory intensive applications, and slowdowns up to 16% arise if memory\nbandwidth is a bottleneck. For an application full of WAW, WAR and RAW hazards,\na speedup of 139.7% was verified.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2007 15:59:37 GMT"}], "update_date": "2007-12-10", "authors_parsed": [["Marzulo", "Leandro A. J.", ""], ["Fran\u00e7a", "Felipe M. G.", ""], ["Costa", "V\u00edtor Santos", ""]]}, {"id": "0712.2255", "submitter": "Ian T Foster", "authors": "Ian Foster", "title": "Human-Machine Symbiosis, 50 Years On", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE cs.HC", "license": null, "abstract": "  Licklider advocated in 1960 the construction of computers capable of working\nsymbiotically with humans to address problems not easily addressed by humans\nworking alone. Since that time, many of the advances that he envisioned have\nbeen achieved, yet the time spent by human problem solvers in mundane\nactivities remains large. I propose here four areas in which improved tools can\nfurther advance the goal of enhancing human intellect: services, provenance,\nknowledge communities, and automation of problem-solving protocols.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2007 23:00:37 GMT"}], "update_date": "2007-12-17", "authors_parsed": [["Foster", "Ian", ""]]}, {"id": "0712.2262", "submitter": "Ian T Foster", "authors": "David Bernholdt, Shishir Bharathi, David Brown, Kasidit Chanchio,\n  Meili Chen, Ann Chervenak, Luca Cinquini, Bob Drach, Ian Foster, Peter Fox,\n  Jose Garcia, Carl Kesselman, Rob Markel, Don Middleton, Veronika Nefedova,\n  Line Pouchard, Arie Shoshani, Alex Sim, Gary Strand, Dean Williams", "title": "The Earth System Grid: Supporting the Next Generation of Climate\n  Modeling Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC cs.NI", "license": null, "abstract": "  Understanding the earth's climate system and how it might be changing is a\npreeminent scientific challenge. Global climate models are used to simulate\npast, present, and future climates, and experiments are executed continuously\non an array of distributed supercomputers. The resulting data archive, spread\nover several sites, currently contains upwards of 100 TB of simulation data and\nis growing rapidly. Looking toward mid-decade and beyond, we must anticipate\nand prepare for distributed climate research data holdings of many petabytes.\nThe Earth System Grid (ESG) is a collaborative interdisciplinary project aimed\nat addressing the challenge of enabling management, discovery, access, and\nanalysis of these critically important datasets in a distributed and\nheterogeneous computational environment. The problem is fundamentally a Grid\nproblem. Building upon the Globus toolkit and a variety of other technologies,\nESG is developing an environment that addresses authentication, authorization\nfor data access, large-scale data transport and management, services and\nabstractions for high-performance remote data access, mechanisms for scalable\ndata replication, cataloging with rich semantic and syntactic information, data\ndiscovery, distributed monitoring, and Web-based portals for using the system.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2007 23:39:04 GMT"}], "update_date": "2007-12-17", "authors_parsed": [["Bernholdt", "David", ""], ["Bharathi", "Shishir", ""], ["Brown", "David", ""], ["Chanchio", "Kasidit", ""], ["Chen", "Meili", ""], ["Chervenak", "Ann", ""], ["Cinquini", "Luca", ""], ["Drach", "Bob", ""], ["Foster", "Ian", ""], ["Fox", "Peter", ""], ["Garcia", "Jose", ""], ["Kesselman", "Carl", ""], ["Markel", "Rob", ""], ["Middleton", "Don", ""], ["Nefedova", "Veronika", ""], ["Pouchard", "Line", ""], ["Shoshani", "Arie", ""], ["Sim", "Alex", ""], ["Strand", "Gary", ""], ["Williams", "Dean", ""]]}, {"id": "0712.2302", "submitter": "Georg Hager", "authors": "Georg Hager, Thomas Zeiser, Gerhard Wellein", "title": "Data access optimizations for highly threaded multi-core CPUs with\n  multiple memory controllers", "comments": "12 pages, 7 figures. Accepted for Workshop on Large-Scale Parallel\n  Processing 2008. Revised and extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": null, "abstract": "  Processor and system architectures that feature multiple memory controllers\nare prone to show bottlenecks and erratic performance numbers on codes with\nregular access patterns. Although such effects are well known in the form of\ncache thrashing and aliasing conflicts, they become more severe when memory\naccess is involved. Using the new Sun UltraSPARC T2 processor as a prototypical\nmulti-core design, we analyze performance patterns in low-level and application\nbenchmarks and show ways to circumvent bottlenecks by careful data layout and\npadding.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2007 08:14:20 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2008 16:18:50 GMT"}], "update_date": "2008-01-28", "authors_parsed": [["Hager", "Georg", ""], ["Zeiser", "Thomas", ""], ["Wellein", "Gerhard", ""]]}, {"id": "0712.2773", "submitter": "Emmanuel Cecchet", "authors": "Emmanuel Cecchet, George Candea, Anastasia Ailamaki", "title": "Middleware-based Database Replication: The Gaps between Theory and\n  Practice", "comments": "14 pages. Appears in Proc. ACM SIGMOD International Conference on\n  Management of Data, Vancouver, Canada, June 2008", "journal-ref": null, "doi": null, "report-no": "EPFL technical report DSLAB-REPORT-2007-001", "categories": "cs.DB cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for high availability and performance in data management systems has\nbeen fueling a long running interest in database replication from both academia\nand industry. However, academic groups often attack replication problems in\nisolation, overlooking the need for completeness in their solutions, while\ncommercial teams take a holistic approach that often misses opportunities for\nfundamental innovation. This has created over time a gap between academic\nresearch and industrial practice.\n  This paper aims to characterize the gap along three axes: performance,\navailability, and administration. We build on our own experience developing and\ndeploying replication systems in commercial and academic settings, as well as\non a large body of prior related work. We sift through representative examples\nfrom the last decade of open-source, academic, and commercial database\nreplication systems and combine this material with case studies from real\nsystems deployed at Fortune 500 customers. We propose two agendas, one for\nacademic research and one for industrial R&D, which we believe can bridge the\ngap within 5-10 years. This way, we hope to both motivate and help researchers\nin making the theory and practice of middleware-based database replication more\nrelevant to each other.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2007 18:42:15 GMT"}, {"version": "v2", "created": "Wed, 5 Nov 2008 20:53:51 GMT"}], "update_date": "2008-11-05", "authors_parsed": [["Cecchet", "Emmanuel", ""], ["Candea", "George", ""], ["Ailamaki", "Anastasia", ""]]}, {"id": "0712.3389", "submitter": "Georg Hager", "authors": "Georg Hager, Holger Stengel, Thomas Zeiser, Gerhard Wellein", "title": "RZBENCH: Performance evaluation of current HPC architectures using\n  low-level and application benchmarks", "comments": "Contribution to the HLRB/KONWIHR results and review workshop, Dec\n  3rd/4th 2007, LRZ Munich, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": null, "abstract": "  RZBENCH is a benchmark suite that was specifically developed to reflect the\nrequirements of scientific supercomputer users at the University of\nErlangen-Nuremberg (FAU). It comprises a number of application and low-level\ncodes under a common build infrastructure that fosters maintainability and\nexpandability. This paper reviews the structure of the suite and briefly\nintroduces the most relevant benchmarks. In addition, some widely known\nstandard benchmark codes are reviewed in order to emphasize the need for a\ncritical review of often-cited performance results. Benchmark data is presented\nfor the HLRB-II at LRZ Munich and a local InfiniBand Woodcrest cluster as well\nas two uncommon system architectures: A bandwidth-optimized InfiniBand cluster\nbased on single socket nodes (\"Port Townsend\") and an early version of Sun's\nhighly threaded T2 architecture (\"Niagara 2\").\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2007 12:15:26 GMT"}], "update_date": "2007-12-21", "authors_parsed": [["Hager", "Georg", ""], ["Stengel", "Holger", ""], ["Zeiser", "Thomas", ""], ["Wellein", "Gerhard", ""]]}, {"id": "0712.3980", "submitter": "Vincent Gramoli", "authors": "Antonio Fernandez (LADyR), Vincent Gramoli (INRIA Futurs, IRISA),\n  Ernesto Jimenez (EUI), Anne-Marie Kermarrec (IRISA), Michel Raynal (IRISA)", "title": "Distributed Slicing in Dynamic Systems", "comments": null, "journal-ref": "Dans The 27th International Conference on Distributed Computing\n  Systems (ICDCS'07) (2007) 66", "doi": null, "report-no": "ICDCS07", "categories": "cs.DC", "license": null, "abstract": "  Peer to peer (P2P) systems are moving from application specific architectures\nto a generic service oriented design philosophy. This raises interesting\nproblems in connection with providing useful P2P middleware services capable of\ndealing with resource assignment and management in a large-scale, heterogeneous\nand unreliable environment. The slicing service, has been proposed to allow for\nan automatic partitioning of P2P networks into groups (slices) that represent a\ncontrollable amount of some resource and that are also relatively homogeneous\nwith respect to that resource. In this paper we propose two gossip-based\nalgorithms to solve the distributed slicing problem. The first algorithm speeds\nup an existing algorithm sorting a set of uniform random numbers. The second\nalgorithm statistically approximates the rank of nodes in the ordering. The\nscalability, efficiency and resilience to dynamics of both algorithms rely on\ntheir gossip-based models. These algorithms are proved viable theoretically and\nexperimentally.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2007 13:55:47 GMT"}], "update_date": "2007-12-27", "authors_parsed": [["Fernandez", "Antonio", "", "LADyR"], ["Gramoli", "Vincent", "", "INRIA Futurs, IRISA"], ["Jimenez", "Ernesto", "", "EUI"], ["Kermarrec", "Anne-Marie", "", "IRISA"], ["Raynal", "Michel", "", "IRISA"]]}, {"id": "0712.4213", "submitter": "Seiichiro Tani", "authors": "Seiichiro Tani, Hirotada Kobayashi, Keiji Matsumoto", "title": "Exact Quantum Algorithms for the Leader Election Problem", "comments": "47 pages, preliminary version in Proceedings of STACS 2005", "journal-ref": "ACM TOCT 4 (2012): Article 1; IEEE TPDS 23 (2012): 255 - 262", "doi": null, "report-no": null, "categories": "quant-ph cs.DC cs.DS", "license": null, "abstract": "  This paper gives the first separation of quantum and classical pure (i.e.,\nnon-cryptographic) computing abilities with no restriction on the amount of\navailable computing resources, by considering the exact solvability of a\ncelebrated unsolvable problem in classical distributed computing, the ``leader\nelection problem'' on anonymous networks. The goal of the leader election\nproblem is to elect a unique leader from among distributed parties. The paper\nconsiders this problem for anonymous networks, in which each party has the same\nidentifier. It is well-known that no classical algorithm can solve exactly\n(i.e., in bounded time without error) the leader election problem in anonymous\nnetworks, even if it is given the number of parties. This paper gives two\nquantum algorithms that, given the number of parties, can exactly solve the\nproblem for any network topology in polynomial rounds and polynomial\ncommunication/time complexity with respect to the number of parties, when the\nparties are connected by quantum communication links.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2007 10:52:52 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Tani", "Seiichiro", ""], ["Kobayashi", "Hirotada", ""], ["Matsumoto", "Keiji", ""]]}]