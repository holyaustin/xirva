[{"id": "1106.0113", "submitter": "Taisuke Izumi", "authors": "Taisuke Izumi, Zohir Bouzid, S\\'ebastien Tixeuil, Koichi Wada", "title": "The BG-simulation for Byzantine Mobile Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the task solvability of mobile robot systems subject\nto Byzantine faults. We first consider the gathering problem, which requires\nall robots to meet in finite time at a non-predefined location. It is known\nthat the solvability of Byzantine gathering strongly depends on a number of\nsystem attributes, such as synchrony, the number of Byzantine robots,\nscheduling strategy, obliviousness, orientation of local coordinate systems and\nso on. However, the complete characterization of the attributes making\nByzantine gathering solvable still remains open.\n  In this paper, we show strong impossibility results of Byzantine gathering.\nNamely, we prove that Byzantine gathering is impossible even if we assume one\nByzantine fault, an atomic execution system, the n-bounded centralized\nscheduler, non-oblivious robots, instantaneous movements and a common\norientation of local coordinate systems (where n denote the number of correct\nrobots). Those hypotheses are much weaker than used in previous work, inducing\na much stronger impossibility result.\n  At the core of our impossibility result is a reduction from the distributed\nconsensus problem in asynchronous shared-memory systems. In more details, we\nnewly construct a generic reduction scheme based on the distributed\nBG-simulation. Interestingly, because of its versatility, we can easily extend\nour impossibility result for general pattern formation problems.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2011 08:02:13 GMT"}], "update_date": "2011-06-02", "authors_parsed": [["Izumi", "Taisuke", ""], ["Bouzid", "Zohir", ""], ["Tixeuil", "S\u00e9bastien", ""], ["Wada", "Koichi", ""]]}, {"id": "1106.0118", "submitter": "Juan Juli\\'an Merelo-Guerv\\'os Pr.", "authors": "Juan-J. Merelo, Maribel Garc\\'ia-Arenas, Juan-Luis J. Laredo,\n  Francisco Fern\\'andez de la Vega (editors)", "title": "1st International Workshop on Distributed Evolutionary Computation in\n  Informal Environments", "comments": "Five papers, workshop took place together with CEC 2011 in New\n  Orleans (LA, USA). http://geneura.ugr.es/~iwdecie", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC cs.ET cs.NI", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  Online conference proceedings for the IWDECIE workshop, taking place in New\nOrleans on June 5th, 2011. The workshop focuses on non-conventional\nimplementations of bioinspired algorithms and its conceptual implications.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2011 08:29:28 GMT"}, {"version": "v2", "created": "Thu, 2 Jun 2011 08:23:54 GMT"}], "update_date": "2011-06-03", "authors_parsed": [["Merelo", "Juan-J.", "", "editors"], ["Garc\u00eda-Arenas", "Maribel", "", "editors"], ["Laredo", "Juan-Luis J.", "", "editors"], ["de la Vega", "Francisco Fern\u00e1ndez", "", "editors"]]}, {"id": "1106.0159", "submitter": "Mikolaj Szydlarski", "authors": "Mikolaj Szydlarski (INRIA Saclay - Ile de France), Pierre Esterie\n  (LRI), Joel Falcou (LRI), Laura Grigori (INRIA Saclay - Ile de France), R.\n  Stompor (APC)", "title": "Parallel Spherical Harmonic Transforms on heterogeneous architectures\n  (GPUs/multi-core CPUs)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC astro-ph.CO physics.ao-ph physics.comp-ph physics.geo-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spherical Harmonic Transforms (SHT) are at the heart of many scientific and\npractical applications ranging from climate modelling to cosmological\nobservations. In many of these areas new, cutting-edge science goals have been\nrecently proposed requiring simulations and analyses of experimental or\nobservational data at very high resolutions and of unprecedented volumes. Both\nthese aspects pose formidable challenge for the currently existing\nimplementations of the transforms.\n  This paper describes parallel algorithms for computing SHT with two variants\nof intra-node parallelism appropriate for novel supercomputer architectures,\nmulti-core processors and Graphic Processing Units (GPU). It also discusses\ntheir performance, alone and embedded within a top-level, MPI-based\nparallelisation layer ported from the S2HAT library, in terms of their\naccuracy, overall efficiency and scalability. We show that our inverse SHT run\non GeForce 400 Series GPUs equipped with latest CUDA architecture (\"Fermi\")\noutperforms the state of the art implementation for a multi-core processor\nexecuted on a current Intel Core i7-2600K. Furthermore, we show that an\nMPI/CUDA version of the inverse transform run on a cluster of 128 Nvidia Tesla\nS1070 is as much as 3 times faster than the hybrid MPI/OpenMP version executed\non the same number of quad-core processors Intel Nahalem for problem sizes\nmotivated by our target applications. Performance of the direct transforms is\nhowever found to be at the best comparable in these cases. We discuss in detail\nthe algorithmic solutions devised for major steps involved in the transforms\ncalculation, emphasising those with a major impact on their overall\nperformance, and elucidates the sources of the dichotomy between the direct and\nthe inverse operations.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2011 12:42:58 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2012 18:11:31 GMT"}, {"version": "v3", "created": "Fri, 15 Feb 2013 16:36:50 GMT"}, {"version": "v4", "created": "Mon, 1 Apr 2013 21:25:11 GMT"}], "update_date": "2013-04-03", "authors_parsed": [["Szydlarski", "Mikolaj", "", "INRIA Saclay - Ile de France"], ["Esterie", "Pierre", "", "LRI"], ["Falcou", "Joel", "", "LRI"], ["Grigori", "Laura", "", "INRIA Saclay - Ile de France"], ["Stompor", "R.", "", "APC"]]}, {"id": "1106.0736", "submitter": "Lei Yang", "authors": "Lei Yang, Yalin E. Sagduyu, Junshan Zhang, Jason H. Li", "title": "Distributed Stochastic Power Control in Ad-hoc Networks: A Nonconvex\n  Case", "comments": "Contains 12 pages, 10 figures, and 2 tables; work submitted to IEEE\n  Transactions on Mobile Computing", "journal-ref": null, "doi": "10.1186/1687-1499-2012-231", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Utility-based power allocation in wireless ad-hoc networks is inherently\nnonconvex because of the global coupling induced by the co-channel\ninterference. To tackle this challenge, we first show that the globally optimal\npoint lies on the boundary of the feasible region, which is utilized as a basis\nto transform the utility maximization problem into an equivalent max-min\nproblem with more structure. By using extended duality theory, penalty\nmultipliers are introduced for penalizing the constraint violations, and the\nminimum weighted utility maximization problem is then decomposed into\nsubproblems for individual users to devise a distributed stochastic power\ncontrol algorithm, where each user stochastically adjusts its target utility to\nimprove the total utility by simulated annealing. The proposed distributed\npower control algorithm can guarantee global optimality at the cost of slow\nconvergence due to simulated annealing involved in the global optimization. The\ngeometric cooling scheme and suitable penalty parameters are used to improve\nthe convergence rate. Next, by integrating the stochastic power control\napproach with the back-pressure algorithm, we develop a joint scheduling and\npower allocation policy to stabilize the queueing systems. Finally, we\ngeneralize the above distributed power control algorithms to multicast\ncommunications, and show their global optimality for multicast traffic.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2011 19:50:22 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Yang", "Lei", ""], ["Sagduyu", "Yalin E.", ""], ["Zhang", "Junshan", ""], ["Li", "Jason H.", ""]]}, {"id": "1106.0940", "submitter": "Herodotos Herodotou", "authors": "Herodotos Herodotou", "title": "Hadoop Performance Models", "comments": "16 pages, 0 figures, Duke University Technical Report", "journal-ref": null, "doi": null, "report-no": "CS-2011-05", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hadoop MapReduce is now a popular choice for performing large-scale data\nanalytics. This technical report describes a detailed set of mathematical\nperformance models for describing the execution of a MapReduce job on Hadoop.\nThe models describe dataflow and cost information at the fine granularity of\nphases within the map and reduce tasks of a job execution. The models can be\nused to estimate the performance of MapReduce jobs as well as to find the\noptimal configuration settings to use when running the jobs.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2011 00:02:32 GMT"}], "update_date": "2011-06-07", "authors_parsed": [["Herodotou", "Herodotos", ""]]}, {"id": "1106.1286", "submitter": "Rajeswari Seethapathy Ms.", "authors": "S. Rajeswari, Y. Venkataramani", "title": "Traffic Performance Analysis of Manet Routing Protocol", "comments": "12 pages,12 figures", "journal-ref": "International Journal of Distributed and Parallel Systems (IJDPS)\n  Vol.2, No.3, May 2011", "doi": "10.5121/ijdps.2011.2306", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The primary objective of this research work is to study and investigate the\nperformance measures of Gossip Routing protocol and Energy Efficient and\nReliable Adaptive Gossip routing protocols. We use TCP and CBR based traffic\nmodels to analyze the performance of above mentioned protocols based on the\nparameters of Packet Delivery Ratio, Average End-to-End Delay and Throughput.\nWe will investigate the effect of change in the simulation time and Number of\nnodes for the MANET routing protocols. For Simulation, we have used ns-2\nsimulator.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2011 09:09:17 GMT"}], "update_date": "2011-06-08", "authors_parsed": [["Rajeswari", "S.", ""], ["Venkataramani", "Y.", ""]]}, {"id": "1106.1287", "submitter": "Arunmozhi Annamalai Ms.", "authors": "S.A.Arunmozhi, Y.Venkataramani", "title": "DDoS Attack and Defense Scheme in Wireless Ad hoc Networks", "comments": "6 pages, 5 figures", "journal-ref": "Arunmozhi S.A., Venkataramani Y.,DDoS Attack and Defense Scheme in\n  Wireless Ad hoc Networks,International Journal of Network Security & Its\n  Applications (IJNSA), Vol.3, No.3, May 2011", "doi": "10.5121/ijnsa.2011.3312", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wireless ad hoc networks are highly vulnerable to distributed denial of\nservice(DDoS) attacks because of its unique characteristics such as open\nnetwork architecture, shared wireless medium and stringent resource\nconstraints. These attacks throttle the tcp throughput heavily and reduce the\nquality of service(QoS) to end systems gradually rather than refusing the\nclients from the services completely. In this paper, we discussed the DDoS\nattacks and proposed a defense scheme to improve the performance of the ad hoc\nnetworks. Our proposed defense mechanism uses the medium access control (MAC)\nlayer information to detect the attackers. The status values from MAC layer\nthat can be used for detection are Frequency of receiving RTS/CTS packets,\nFrequency of sensing a busy channel and the number of RTS/DATA retransmissions.\nOnce the attackers are identified, all the packets from those nodes will be\nblocked. The network resources are made available to the legitimate users. We\nperform the simulation with Network Simulator NS2 and we proved that our\nproposed system improves the network performance.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2011 09:09:18 GMT"}], "update_date": "2011-06-08", "authors_parsed": [["Arunmozhi", "S. A.", ""], ["Venkataramani", "Y.", ""]]}, {"id": "1106.1516", "submitter": "Francesco De Pellegrini Dr.", "authors": "Francesco De Pellegrini, Karina Gomez, Daniele Miorandi and Imrich\n  Chlamtac", "title": "Distributed Wake-Up Scheduling for Energy Saving in Wireless Networks", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A customary solution to reduce the energy consumption of wireless\ncommunication devices is to periodically put the radio into low-power sleep\nmode. A relevant problem is to schedule the wake-up of nodes in such a way as\nto ensure proper coordination among devices, respecting delay constraints while\nstill saving energy. In this paper, we introduce a simple algebraic\ncharacterization of the problem of periodic wake-up scheduling under both\nenergy consumption and delay constraints. We demonstrate that the general\nproblem of wake-up times coordination is equivalent to integer factorization\nand discuss the implications on the design of efficient scheduling algorithms.\nWe then propose simple polynomial time heuristic algorithms that can be\nimplemented in a distributed fashion and present a message complexity of the\norder of the number of links in the network. Numerical results are provided in\norder to assess the performance of the proposed techniques when applied to\nwireless sensor networks.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2011 08:12:19 GMT"}], "update_date": "2011-06-09", "authors_parsed": [["De Pellegrini", "Francesco", ""], ["Gomez", "Karina", ""], ["Miorandi", "Daniele", ""], ["Chlamtac", "Imrich", ""]]}, {"id": "1106.1634", "submitter": "Dimitris S. Papailiopoulos", "authors": "Dimitris S. Papailiopoulos, Alexandros G. Dimakis, and Viveck R.\n  Cadambe", "title": "Repair Optimal Erasure Codes through Hadamard Designs", "comments": "19 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In distributed storage systems that employ erasure coding, the issue of\nminimizing the total {\\it communication} required to exactly rebuild a storage\nnode after a failure arises. This repair bandwidth depends on the structure of\nthe storage code and the repair strategies used to restore the lost data.\nDesigning high-rate maximum-distance separable (MDS) codes that achieve the\noptimum repair communication has been a well-known open problem. In this work,\nwe use Hadamard matrices to construct the first explicit 2-parity MDS storage\ncode with optimal repair properties for all single node failures, including the\nparities. Our construction relies on a novel method of achieving perfect\ninterference alignment over finite fields with a finite file size, or number of\nextensions. We generalize this construction to design $m$-parity MDS codes that\nachieve the optimum repair communication for single systematic node failures\nand show that there is an interesting connection between our $m$-parity codes\nand the systematic-repair optimal permutation-matrix based codes of Tamo {\\it\net al.} \\cite{Tamo} and Cadambe {\\it et al.} \\cite{PermCodes_ISIT, PermCodes}.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2011 19:46:16 GMT"}], "update_date": "2011-06-09", "authors_parsed": [["Papailiopoulos", "Dimitris S.", ""], ["Dimakis", "Alexandros G.", ""], ["Cadambe", "Viveck R.", ""]]}, {"id": "1106.1652", "submitter": "Dimitris S. Papailiopoulos", "authors": "Dimitris S. Papailiopoulos and Alexandros G. Dimakis", "title": "Distributed Storage Codes through Hadamard Designs", "comments": "5 pages, 3 figures, to be presented at ISIT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In distributed storage systems that employ erasure coding, the issue of\nminimizing the total {\\it repair bandwidth} required to exactly regenerate a\nstorage node after a failure arises. This repair bandwidth depends on the\nstructure of the storage code and the repair strategies used to restore the\nlost data. Minimizing it requires that undesired data during a repair align in\nthe smallest possible spaces, using the concept of interference alignment (IA).\nHere, a points-on-a-lattice representation of the symbol extension IA of\nCadambe {\\it et al.} provides cues to perfect IA instances which we combine\nwith fundamental properties of Hadamard matrices to construct a new storage\ncode with favorable repair properties. Specifically, we build an explicit\n$(k+2,k)$ storage code over $\\mathbb{GF}(3)$, whose single systematic node\nfailures can be repaired with bandwidth that matches exactly the theoretical\nminimum. Moreover, the repair of single parity node failures generates at most\nthe same repair bandwidth as any systematic node failure. Our code can tolerate\nany single node failure and any pair of failures that involves at most one\nsystematic failure.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2011 20:02:19 GMT"}], "update_date": "2011-06-10", "authors_parsed": [["Papailiopoulos", "Dimitris S.", ""], ["Dimakis", "Alexandros G.", ""]]}, {"id": "1106.1845", "submitter": "Guanfeng Liang", "authors": "Guanfeng Liang and Nitin Vaidya", "title": "Byzantine Broadcast in Point-to-Point Networks using Local Linear Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of Byzantine Broadcast (BB) is to allow a set of fault-free nodes to\nagree on information that a source node wants to broadcast to them, in the\npresence of Byzantine faulty nodes. We consider design of efficient algorithms\nfor BB in {\\em synchronous} point-to-point networks, where the rate of\ntransmission over each communication link is limited by its \"link capacity\".\nThe throughput of a particular BB algorithm is defined as the average number of\nbits that can be reliably broadcast to all fault-free nodes per unit time using\nthe algorithm without violating the link capacity constraints. The {\\em\ncapacity} of BB in a given network is then defined as the supremum of all\nachievable BB throughputs in the given network, over all possible BB\nalgorithms.\n  We develop NAB -- a Network-Aware Byzantine broadcast algorithm -- for\narbitrary point-to-point networks consisting of $n$ nodes, wherein the number\nof faulty nodes is at most $f$, $f<n/3$, and the network connectivity is at\nleast $2f+1$. We also prove an upper bound on the capacity of Byzantine\nbroadcast, and conclude that NAB can achieve throughput at least 1/3 of the\ncapacity. When the network satisfies an additional condition, NAB can achieve\nthroughput at least 1/2 of the capacity.\n  To the best of our knowledge, NAB is the first algorithm that can achieve a\nconstant fraction of capacity of Byzantine Broadcast (BB) in arbitrary\npoint-to-point networks.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2011 16:07:57 GMT"}, {"version": "v2", "created": "Thu, 3 Nov 2011 13:17:52 GMT"}, {"version": "v3", "created": "Wed, 2 May 2012 00:48:52 GMT"}], "update_date": "2012-05-03", "authors_parsed": [["Liang", "Guanfeng", ""], ["Vaidya", "Nitin", ""]]}, {"id": "1106.1846", "submitter": "Guanfeng Liang", "authors": "Guanfeng Liang and Nitin Vaidya", "title": "New Efficient Error-Free Multi-Valued Consensus with Byzantine Failures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we investigate the multi-valued Byzantine consensus problem.\nWe introduce two algorithms: the first one achieves traditional validity\nrequirement for consensus, and the second one achieves a stronger \"q-validity\"\nrequirement. Both algorithms are more efficient than the ones introduces in our\nrecent PODC 2011 paper titled \"Error-Free Multi-Valued Consensus with Byzantine\nFailures\".\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2011 16:13:54 GMT"}], "update_date": "2011-06-10", "authors_parsed": [["Liang", "Guanfeng", ""], ["Vaidya", "Nitin", ""]]}, {"id": "1106.1900", "submitter": "Jeroen B\\'edorf", "authors": "Jeroen B\\'edorf and Evghenii Gaburov and Simon Portegies Zwart", "title": "A sparse octree gravitational N-body code that runs entirely on the GPU\n  processor", "comments": "Accepted version. Published in Journal of Computational Physics. 35\n  pages, 12 figures, single column", "journal-ref": "Journal of Computational Physics. Volume 231, Issue 7, 1 April\n  2012, Pages 2825-2839", "doi": "10.1016/j.jcp.2011.12.024", "report-no": null, "categories": "astro-ph.IM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present parallel algorithms for constructing and traversing sparse octrees\non graphics processing units (GPUs). The algorithms are based on parallel-scan\nand sort methods. To test the performance and feasibility, we implemented them\nin CUDA in the form of a gravitational tree-code which completely runs on the\nGPU.(The code is publicly available at:\nhttp://castle.strw.leidenuniv.nl/software.html) The tree construction and\ntraverse algorithms are portable to many-core devices which have support for\nCUDA or OpenCL programming languages. The gravitational tree-code outperforms\ntuned CPU code during the tree-construction and shows a performance improvement\nof more than a factor 20 overall, resulting in a processing rate of more than\n2.8 million particles per second.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2011 20:00:07 GMT"}, {"version": "v2", "created": "Tue, 10 Apr 2012 13:20:03 GMT"}], "update_date": "2012-04-11", "authors_parsed": [["B\u00e9dorf", "Jeroen", ""], ["Gaburov", "Evghenii", ""], ["Zwart", "Simon Portegies", ""]]}, {"id": "1106.2065", "submitter": "Yehuda Afek", "authors": "Yehuda Afek, Yakov Babichenko, Uriel Feige, Eli Gafni, Nati Linial,\n  and Benny Sudakov", "title": "Oblivious Collaboration", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication is a crucial ingredient in every kind of collaborative work.\nBut what is the least possible amount of communication required for a given\ntask? We formalize this question by introducing a new framework for distributed\ncomputation, called {\\em oblivious protocols}.\n  We investigate the power of this model by considering two concrete examples,\nthe {\\em musical chairs} task $MC(n,m)$ and the well-known {\\em Renaming}\nproblem. The $MC(n,m)$ game is played by $n$ players (processors) with $m$\nchairs. Players can {\\em occupy} chairs, and the game terminates as soon as\neach player occupies a unique chair. Thus we say that player $P$ is {\\em in\nconflict} if some other player $Q$ is occupying the same chair, i.e.,\ntermination means there are no conflicts. By known results from distributed\ncomputing, if $m \\le 2n-2$, no strategy of the players can guarantee\ntermination. However, there is a protocol with $m = 2n-1$ chairs that always\nterminates. Here we consider an oblivious protocol where in every time step the\nonly communication is this: an adversarial {\\em scheduler} chooses an arbitrary\nnonempty set of players, and for each of them provides only one bit of\ninformation, specifying whether the player is currently in conflict or not. A\nplayer notified not to be in conflict halts and never changes its chair,\nwhereas a player notified to be in conflict changes its chair according to its\ndeterministic program. Remarkably, even with this minimal communication\ntermination can be guaranteed with only $m=2n-1$ chairs. Likewise, we obtain an\noblivious protocol for the Renaming problem whose name-space is small as that\nof the optimal nonoblivious distributed protocol.\n  Other aspects suggest themselves, such as the efficiency (program length) of\nour protocols. We make substantial progress here as well, though many\ninteresting questions remain open.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2011 14:11:33 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Afek", "Yehuda", ""], ["Babichenko", "Yakov", ""], ["Feige", "Uriel", ""], ["Gafni", "Eli", ""], ["Linial", "Nati", ""], ["Sudakov", "Benny", ""]]}, {"id": "1106.2126", "submitter": "Yehuda Afek", "authors": "Yehuda Afek, Noga Alon, Ziv Bar-Joseph", "title": "MIS on the fly", "comments": "have been submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are very good at optimizing solutions for specific problems.\nBiological processes, on the other hand, have evolved to handle multiple\nconstrained distributed environments and so they are robust and adaptable.\nInspired by observations made in a biological system we have recently presented\na simple new randomized distributed MIS algorithm \\cite{ZScience}. Here we\nextend these results by removing a number of strong assumptions that we made,\nmaking the algorithms more practical. Specifically we present an $O(\\log^2 n)$\nrounds synchronous randomized MIS algorithm which uses only 1 bit unary\nmessages (a beeping signal with collision detection), allows for asynchronous\nwake up, does not assume any knowledge of the network topology, and assumes\nonly a loose bound on the network size. We also present an extension with no\ncollision detection in which the round complexity increases to $(\\log^3 n)$.\nFinally, we show that our algorithm is optimal under some restriction, by\npresenting a tight lower bound of $\\Omega(\\log^2 n)$ on the number of rounds\nrequired to construct a MIS for a restricted model.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2011 17:28:35 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Afek", "Yehuda", ""], ["Alon", "Noga", ""], ["Bar-Joseph", "Ziv", ""]]}, {"id": "1106.2275", "submitter": "Anwitaman Datta", "authors": "Fr\\'ed\\'erique Oggier and Anwitaman Datta", "title": "Byzantine Fault Tolerance of Regenerating Codes", "comments": "In The 11th IEEE International Conference on Peer-to-Peer Computing\n  (P2P 2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed a slew of coding techniques custom designed for\nnetworked storage systems. Network coding inspired regenerating codes are the\nmost prolifically studied among these new age storage centric codes. A lot of\neffort has been invested in understanding the fundamental achievable trade-offs\nof storage and bandwidth usage to maintain redundancy in presence of different\nmodels of failures, showcasing the efficacy of regenerating codes with respect\nto traditional erasure coding techniques. For practical usability in open and\nadversarial environments, as is typical in peer-to-peer systems, we need\nhowever not only resilience against erasures, but also from (adversarial)\nerrors. In this paper, we study the resilience of generalized regenerating\ncodes (supporting multi-repairs, using collaboration among newcomers) in the\npresence of two classes of Byzantine nodes, relatively benign selfish\n(non-cooperating) nodes, as well as under more active, malicious polluting\nnodes. We give upper bounds on the resilience capacity of regenerating codes,\nand show that the advantages of collaborative repair can turn to be detrimental\nin the presence of Byzantine nodes. We further exhibit that system mechanisms\ncan be combined with regenerating codes to mitigate the effect of rogue nodes.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jun 2011 04:13:57 GMT"}], "update_date": "2011-06-14", "authors_parsed": [["Oggier", "Fr\u00e9d\u00e9rique", ""], ["Datta", "Anwitaman", ""]]}, {"id": "1106.2593", "submitter": "Oleg Mazonka", "authors": "Oleg Mazonka and Alex Kolodin", "title": "A Simple Multi-Processor Computer Based on Subleq", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subleq (Subtract and Branch on result Less than or Equal to zero) is both an\ninstruction set and a programming language for One Instruction Set Computer\n(OISC). We describe a hardware implementation of an array of 28 one-instruction\nSubleq processors on a low-cost FPGA board. Our test results demonstrate that\ncomputational power of our Subleq OISC multi-processor is comparable to that of\nCPU of a modern personal computer. Additionally, we provide implementation\ndetails of our complier from a C-style language to Subleq.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2011 01:26:41 GMT"}], "update_date": "2011-06-15", "authors_parsed": [["Mazonka", "Oleg", ""], ["Kolodin", "Alex", ""]]}, {"id": "1106.2673", "submitter": "Joseph Y. Halpern", "authors": "Danny Dolev, Dror G. Feitelson, Joseph Y. Halpern, Raz Kupferman, and\n  Nati Linial", "title": "No justified complaints: On fair sharing of multiple resources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fair allocation has been studied intensively in both economics and computer\nscience, and fair sharing of resources has aroused renewed interest with the\nadvent of virtualization and cloud computing. Prior work has typically focused\non mechanisms for fair sharing of a single resource. We provide a new\ndefinition for the simultaneous fair allocation of multiple\ncontinuously-divisible resources. Roughly speaking, we define fairness as the\nsituation where every user either gets all the resources he wishes for, or else\ngets at least his entitlement on some bottleneck resource, and therefore cannot\ncomplain about not getting more. This definition has the same desirable\nproperties as the recently suggested dominant resource fairness, and also\nhandles the case of multiple bottlenecks. We then prove that a fair allocation\naccording to this definition is guaranteed to exist for any combination of user\nrequests and entitlements (where a user's relative use of the different\nresources is fixed). The proof, which uses tools from the theory of ordinary\ndifferential equations, is constructive and provides a method to compute the\nallocations numerically.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2011 11:20:26 GMT"}], "update_date": "2011-06-15", "authors_parsed": [["Dolev", "Danny", ""], ["Feitelson", "Dror G.", ""], ["Halpern", "Joseph Y.", ""], ["Kupferman", "Raz", ""], ["Linial", "Nati", ""]]}, {"id": "1106.2677", "submitter": "Mark McLaughlin", "authors": "Mark Anthony McLaughlin", "title": "A Framework for Enabling Distributed Applications on the Internet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The last five years have seen the rapid rise in popularity of what we term\ninternet distributed applications (IDAs). These are internet applications with\nwhich many users interact simultaneously. IDAs range from P2P file-sharing\napplications, to collaborative distributed computing projects, to massively\nmultiplayer online games (MMOGs). Currently, there is no framework that\ncombines IDAs collectively within a single context. We provide a basis for such\na framework here.\n  In considering IDAs collectively, we found that there was no generic\ndescription that had been applied to them as a group. We have therefore put\nforward such a description here. In our description, IDAs are functionality\nseparated into three logic layers, which are designed and built individually.\nEach layer is represented by functionality on the software client running on\neach participating computer, which together comprise the overall IDA.\n  The core contribution of this work is a framework, called the Internet\nDistributed Application Framework (IDAF), which outlines how IDAs can be\ndesigned, built and run. The IDAF outlines a set of constraints that each\nimplementing software system must abide by. To verify the IDAF, we have built a\nsystem prototype implementation called the Internet Distributed Application\nSystem (IDAS). The IDAS includes an implementation of the IDAF layer model,\nwhich specifies IDAs are built. The IDAS also includes a generic software\nclient that is capable of simultaneously running and managing arbitrary IDAs.\nWe provide sample IDAs and demonstrations to verify both that the IDAF is\nimplementable and that the IDAS is a workable usable system.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2011 11:32:22 GMT"}], "update_date": "2011-06-15", "authors_parsed": [["McLaughlin", "Mark Anthony", ""]]}, {"id": "1106.2766", "submitter": "Luis Nogueira PhD", "authors": "Lu\\'is Nogueira, Lu\\'is Miguel Pinho", "title": "Supporting Parallelism in Server-based Multiprocessor Systems", "comments": "WiP Session of the 31st IEEE Real-Time Systems Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing an efficient server-based real-time scheduling solution that\nsupports dynamic task-level parallelism is now relevant to even the desktop and\nembedded domains and no longer only to the high performance computing market\nniche. This paper proposes a novel approach that combines the constant\nbandwidth server abstraction with a work-stealing load balancing scheme which,\nwhile ensuring isolation among tasks, enables a task to be executed on more\nthan one processor at a given time instant.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2011 17:26:21 GMT"}], "update_date": "2011-06-15", "authors_parsed": [["Nogueira", "Lu\u00eds", ""], ["Pinho", "Lu\u00eds Miguel", ""]]}, {"id": "1106.2992", "submitter": "Michiel W. van Tol", "authors": "Michiel W. van Tol", "title": "A Characterization of the SPARC T3-4 System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report covers a set of experiments on the 64-core SPARC T3-4\nsystem, comparing it to two similar AMD and Intel systems. Key characteristics\nas maximum integer and floating point arithmetic throughput are measured as\nwell as memory throughput, showing the scalability of the SPARC T3-4 system.\nThe performance of POSIX threads primitives is characterized and compared in\ndetail, such as thread creation and mutex synchronization. Scalability tests\nwith a fine grained multithreaded runtime are performed, showing problems with\natomic CAS operations on such physically highly parallel systems.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2011 15:18:27 GMT"}], "update_date": "2011-06-17", "authors_parsed": [["van Tol", "Michiel W.", ""]]}, {"id": "1106.3172", "submitter": "Patrizio Dazzi", "authors": "Ranieri Baraglia, Patrizio Dazzi, Matteo Mordacchini, Laura Ricci,\n  Luca Alessi", "title": "On Democracy in Peer-to-Peer systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The information flow inside a P2P network is highly dependent on the network\nstructure. In order to ease the diffusion of relevant data toward interested\npeers, many P2P protocols gather similar nodes by putting them in direct\ncontact. With this approach the similarity between nodes is computed in a\npoint-to-point fashion: each peer individually identifies the nodes that share\nsimilar interests with it. This leads to the creation of a sort of \"private\"\ncommunities, limited to each peer neighbors list. This \"private\" knowledge do\nnot allow to identify the features needed to discover and characterize the\ncorrelations that collect similar peers in broader groups. In order to let\nthese correlations to emerge, the collective knowledge of peers must be\nexploited. One common problem to overcome in order to avoid the \"private\"\nvision of the network, is related to how distributively determine the\nrepresentation of a community and how nodes may decide to belong to it. We\npropose to use a gossip-like approach in order to let peers elect and identify\nleaders of interest communities. Once leaders are elected, their profiles are\nused as community representatives. Peers decide to adhere to a community or\nanother by choosing the most similar representative they know about.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2011 08:59:13 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Baraglia", "Ranieri", ""], ["Dazzi", "Patrizio", ""], ["Mordacchini", "Matteo", ""], ["Ricci", "Laura", ""], ["Alessi", "Luca", ""]]}, {"id": "1106.3314", "submitter": "Roman Gitlin", "authors": "Roman Gitlin", "title": "Reducing Interpolation on Multi-Grid to Quantizing Grid's Data-Base as a\n  Recursion", "comments": "75 pages, 2 code snippets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In his article \"Powerlist: A Structure for Parallel Recursion\" Jayadev Misra\nwrote:\n  \"Many data parallel algorithms Fast Fourier Transform, Batcher's sorting\nschemes and prefix sum -exhibit recursive structure. We propose a data\nstructure, powerlist, that permits succinct descriptions of such algorithms,\nhighlighting the roles of both parallelism and recursion. Simple algebraic\nproperties of this data structure can be exploited to derive properties of\nthese algorithms and establish equivalence of different algorithms that solve\nthe same problem.\"\n  The quote above illustrates a widely shared assumption about recursion\nimplementations: either they are done in purely structural terms or they cannot\nbe done at all.\n  Multi-dimensional interpolation on a grid is one of hosts of semi-recursive\nschemes that, while often referred to as recursive and routinely described in\nvaguely recursive terms, cannot be implemented as a recursion in their\nstructural entirety.\n  This article describes a computer-implemented scheme for isolating the\nrecursive core of interpolation on a multi-grid, an arrangement that both stems\nfrom and provides a structural framework to a number of multi-dimensional\ninterpolation optimization techniques that, once implemented, provide gains in\nmulti-dimensional interpolation speed that, compared to some known benchmarks,\nmeasure in multiple orders of magnitude.\n  Categories and Subject Descriptors: Multi-dimensional Programming; Concurrent\nProgramming; Recursion\n  General terms: Parallel Processing, Prioritized Processing, Interpolation,\nRecursion, Multi-Cube\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2011 19:28:07 GMT"}, {"version": "v10", "created": "Thu, 1 Sep 2011 17:33:33 GMT"}, {"version": "v11", "created": "Mon, 5 Sep 2011 19:29:36 GMT"}, {"version": "v12", "created": "Tue, 6 Sep 2011 19:59:01 GMT"}, {"version": "v13", "created": "Wed, 7 Sep 2011 19:47:38 GMT"}, {"version": "v14", "created": "Fri, 9 Sep 2011 12:42:29 GMT"}, {"version": "v15", "created": "Mon, 12 Sep 2011 18:08:15 GMT"}, {"version": "v16", "created": "Sat, 17 Sep 2011 10:13:56 GMT"}, {"version": "v17", "created": "Wed, 21 Sep 2011 19:56:38 GMT"}, {"version": "v18", "created": "Thu, 22 Sep 2011 19:59:32 GMT"}, {"version": "v19", "created": "Mon, 26 Sep 2011 14:42:40 GMT"}, {"version": "v2", "created": "Tue, 19 Jul 2011 14:58:49 GMT"}, {"version": "v20", "created": "Wed, 28 Sep 2011 08:14:17 GMT"}, {"version": "v21", "created": "Thu, 29 Sep 2011 14:42:50 GMT"}, {"version": "v3", "created": "Fri, 22 Jul 2011 09:51:21 GMT"}, {"version": "v4", "created": "Tue, 26 Jul 2011 15:53:05 GMT"}, {"version": "v5", "created": "Thu, 28 Jul 2011 13:11:17 GMT"}, {"version": "v6", "created": "Sun, 31 Jul 2011 13:13:08 GMT"}, {"version": "v7", "created": "Tue, 9 Aug 2011 14:22:35 GMT"}, {"version": "v8", "created": "Mon, 29 Aug 2011 19:31:03 GMT"}, {"version": "v9", "created": "Wed, 31 Aug 2011 12:34:16 GMT"}], "update_date": "2011-09-30", "authors_parsed": [["Gitlin", "Roman", ""]]}, {"id": "1106.3325", "submitter": "Daniel Wilkerson", "authors": "Daniel Shawcross Wilkerson, Simon Fredrick Vicente Goldsmith, Ryan\n  Barrett, Erick Armbrust, Robert Johnson, Alfred Fuller", "title": "Distributed Transactions for Google App Engine: Optimistic Distributed\n  Transactions built upon Local Multi-Version Concurrency Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.DS cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massively scalable web applications encounter a fundamental tension in\ncomputing between \"performance\" and \"correctness\": performance is often\naddressed by using a large and therefore distributed machine where programs are\nmulti-threaded and interruptible, whereas correctness requires data invariants\nto be maintained with certainty. A solution to this problem is \"transactions\"\n[Gray-Reuter].\n  Some distributed systems such as Google App Engine\n[http://code.google.com/appengine/docs/] provide transaction semantics but only\nfor functions that access one of a set of predefined local regions of the\ndatabase: a \"Local Transaction\" (LT)\n[http://code.google.com/appengine/docs/python/datastore/transactions.html]. To\naddress this problem we give a \"Distributed Transaction\" (DT) algorithm which\nprovides transaction semantics for functions that operate on any set of objects\ndistributed across the machine. Our algorithm is in an \"optimistic\"\n[http://en.wikipedia.org/wiki/Optimistic_concurrency_control] style. We assume\nSequential [Time-]Consistency\n[http://en.wikipedia.org/wiki/Sequential_consistency] for Local Transactions.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2011 00:00:22 GMT"}], "update_date": "2011-06-17", "authors_parsed": [["Wilkerson", "Daniel Shawcross", ""], ["Goldsmith", "Simon Fredrick Vicente", ""], ["Barrett", "Ryan", ""], ["Armbrust", "Erick", ""], ["Johnson", "Robert", ""], ["Fuller", "Alfred", ""]]}, {"id": "1106.3579", "submitter": "Emmanuel Godard", "authors": "Emmanuel Godard and Joseph Peters", "title": "Consensus vs Broadcast in Communication Networks with Arbitrary Mobile\n  Omission Faults", "comments": "Erratum for Def. 4.8 and 4.9", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare the solvability of the Consensus and Broadcast problems in\nsynchronous communication networks in which the delivery of messages is not\nreliable. The failure model is the mobile omission faults model. During each\nround, some messages can be lost and the set of possible simultaneous losses is\nthe same for each round. We investigate these problems for the first time for\narbitrary sets of possible failures. Previously, these sets were defined by\nbounding the numbers of failures.\n  In this setting, we present a new necessary condition for the solvability of\nConsensus that unifies previous impossibility results in this area. This\ncondition is expressed using Broadcastability properties. As a very important\napplication, we show that when the sets of omissions that can occur are defined\nby bounding the numbers of failures, counted in any way (locally, globally,\netc.), then the Consensus problem is actually equivalent to the Broadcast\nproblem.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2011 21:16:51 GMT"}, {"version": "v2", "created": "Thu, 31 May 2012 17:42:02 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Godard", "Emmanuel", ""], ["Peters", "Joseph", ""]]}, {"id": "1106.3634", "submitter": "Vladimir Berezovsky", "authors": "Vladimir Berezovsky and Alexander Popov", "title": "Strategies for Development of a Distributed Framework for Computational\n  Sciences", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses some generic approach for developing grid-based\nframework for enabling establishment of workflows comprising existing software\nin computational sciences areas. We highlight the main requirements addressed\nthe developing of such framework. Some strategies for enabling interoperability\nbetween convenient computation software in the grid environment has been shown.\nThe UML based instruments of graphical description of workflows for the\ndeveloping system has been suggested.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jun 2011 10:26:39 GMT"}], "update_date": "2011-06-21", "authors_parsed": [["Berezovsky", "Vladimir", ""], ["Popov", "Alexander", ""]]}, {"id": "1106.3693", "submitter": "Sunil K.  Narang", "authors": "Sunil K. Narang and Antonio Ortega", "title": "Perfect Reconstruction Two-Channel Wavelet Filter-Banks for Graph\n  Structured Data", "comments": "32 pages double spaced 12 Figures, to appear in IEEE Transactions of\n  Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2012.2188718", "report-no": null, "categories": "cs.DC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose the construction of two-channel wavelet filterbanks\nfor analyzing functions defined on the vertices of any arbitrary finite\nweighted undirected graph. These graph based functions are referred to as\ngraph-signals as we build a framework in which many concepts from the classical\nsignal processing domain, such as Fourier decomposition, signal filtering and\ndownsampling can be extended to graph domain. Especially, we observe a spectral\nfolding phenomenon in bipartite graphs which occurs during downsampling of\nthese graphs and produces aliasing in graph signals. This property of bipartite\ngraphs, allows us to design critically sampled two-channel filterbanks, and we\npropose quadrature mirror filters (referred to as graph-QMF) for bipartite\ngraph which cancel aliasing and lead to perfect reconstruction. For arbitrary\ngraphs we present a bipartite subgraph decomposition which produces an\nedge-disjoint collection of bipartite subgraphs. Graph-QMFs are then\nconstructed on each bipartite subgraph leading to \"multi-dimensional\" separable\nwavelet filterbanks on graphs. Our proposed filterbanks are critically sampled\nand we state necessary and sufficient conditions for orthogonality, aliasing\ncancellation and perfect reconstruction. The filterbanks are realized by\nChebychev polynomial approximations.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jun 2011 21:37:02 GMT"}, {"version": "v2", "created": "Thu, 30 Jun 2011 07:18:40 GMT"}, {"version": "v3", "created": "Thu, 1 Dec 2011 23:15:13 GMT"}], "update_date": "2015-10-28", "authors_parsed": [["Narang", "Sunil K.", ""], ["Ortega", "Antonio", ""]]}, {"id": "1106.4100", "submitter": "EPTCS", "authors": "Pontus Bostr\\\"om, Fredrik Degerlund, Kaisa Sere, Marina Wald\\'en", "title": "Concurrent Scheduling of Event-B Models", "comments": "In Proceedings Refine 2011, arXiv:1106.3488", "journal-ref": "EPTCS 55, 2011, pp. 166-182", "doi": "10.4204/EPTCS.55.11", "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event-B is a refinement-based formal method that has been shown to be useful\nin developing concurrent and distributed programs. Large models can be\ndecomposed into sub-models that can be refined semi-independently and executed\nin parallel. In this paper, we show how to introduce explicit control flow for\nthe concurrent sub-models in the form of event schedules. We explore how\nschedules can be designed so that their application results in a\ncorrectness-preserving refinement step. For practical application, two patterns\nfor schedule introduction are provided, together with their associated proof\nobligations. We demonstrate our method by applying it on the dining\nphilosophers problem.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2011 05:25:34 GMT"}], "update_date": "2011-06-22", "authors_parsed": [["Bostr\u00f6m", "Pontus", ""], ["Degerlund", "Fredrik", ""], ["Sere", "Kaisa", ""], ["Wald\u00e9n", "Marina", ""]]}, {"id": "1106.4213", "submitter": "Erlin Yao", "authors": "Erlin Yao, Mingyu Chen, Rui Wang, Wenli Zhang, Guangming Tan", "title": "A New and Efficient Algorithm-Based Fault Tolerance Scheme for A Million\n  Way Parallelism", "comments": "11 pages, 8 figures, 1 table, submitted to conference SC 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Fault tolerance overhead of high performance computing (HPC) applications is\nbecoming critical to the efficient utilization of HPC systems at large scale.\nHPC applications typically tolerate fail-stop failures by checkpointing.\nAnother promising method is in the algorithm level, called algorithmic\nrecovery. These two methods can achieve high efficiency when the system scale\nis not very large, but will both lose their effectiveness when systems approach\nthe scale of Exaflops, where the number of processors including in system is\nexpected to achieve one million. This paper develops a new and efficient\nalgorithm-based fault tolerance scheme for HPC applications. When failure\noccurs during the execution, we do not stop to wait for the recovery of\ncorrupted data, but replace them with the corresponding redundant data and\ncontinue the execution. A background accelerated recovery method is also\nproposed to rebuild redundancy to tolerate multiple times of failures during\nthe execution. To demonstrate the feasibility of our new scheme, we have\nincorporated it to the High Performance Linpack. Theoretical analysis\ndemonstrates that our new fault tolerance scheme can still be effective even\nwhen the system scale achieves the Exaflops. Experiment using SiCortex SC5832\nverifies the feasibility of the scheme, and indicates that the advantage of our\nscheme can be observable even in a small scale.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2011 14:24:43 GMT"}], "update_date": "2011-06-22", "authors_parsed": [["Yao", "Erlin", ""], ["Chen", "Mingyu", ""], ["Wang", "Rui", ""], ["Zhang", "Wenli", ""], ["Tan", "Guangming", ""]]}, {"id": "1106.4346", "submitter": "Kevin Topley", "authors": "Kevin Topley, Vikram Krishnamurthy", "title": "Average-Consensus Algorithms in a Deterministic Framework", "comments": "53 pages, 2 figures, 1 table. Short version submitted to IEEE Trans.\n  Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the average-consensus problem in a multi-node network of finite\nsize. Communication between nodes is modeled by a sequence of directed signals\nwith arbitrary communication delays. Four distributed algorithms that achieve\naverage-consensus are proposed. Necessary and sufficient communication\nconditions are given for each algorithm to achieve average-consensus. Resource\ncosts for each algorithm are derived based on the number of scalar values that\nare required for communication and storage at each node. Numerical examples are\nprovided to illustrate the empirical convergence rate of the four algorithms in\ncomparison with a well-known \"gossip\" algorithm as well as a randomized\ninformation spreading algorithm when assuming a fully connected random graph\nwith instantaneous communication.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2011 18:53:04 GMT"}], "update_date": "2011-06-23", "authors_parsed": [["Topley", "Kevin", ""], ["Krishnamurthy", "Vikram", ""]]}, {"id": "1106.4582", "submitter": "Maury Bramson", "authors": "Maury Bramson, Yi Lu, Balaji Prabhakar", "title": "Decay of tails at equilibrium for FIFO join the shortest queue networks", "comments": "Published in at http://dx.doi.org/10.1214/12-AAP888 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Probability 2013, Vol. 23, No. 5, 1841-1878", "doi": "10.1214/12-AAP888", "report-no": "IMS-AAP-AAP888", "categories": "math.PR cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In join the shortest queue networks, incoming jobs are assigned to the\nshortest queue from among a randomly chosen subset of $D$ queues, in a system\nof $N$ queues; after completion of service at its queue, a job leaves the\nnetwork. We also assume that jobs arrive into the system according to a\nrate-$\\alpha N$ Poisson process, $\\alpha<1$, with rate-1 service at each queue.\nWhen the service at queues is exponentially distributed, it was shown in\nVvedenskaya et al. [Probl. Inf. Transm. 32 (1996) 15-29] that the tail of the\nequilibrium queue size decays doubly exponentially in the limit as\n$N\\rightarrow\\infty$. This is a substantial improvement over the case D=1,\nwhere the queue size decays exponentially. The reasoning in [Probl. Inf.\nTransm. 32 (1996) 15-29] does not easily generalize to jobs with nonexponential\nservice time distributions. A modularized program for treating general service\ntime distributions was introduced in Bramson et al. [In Proc. ACM SIGMETRICS\n(2010) 275-286]. The program relies on an ansatz that asserts, in equilibrium,\nany fixed number of queues become independent of one another as\n$N\\rightarrow\\infty$. This ansatz was demonstrated in several settings in\nBramson et al. [Queueing Syst. 71 (2012) 247-292], including for networks where\nthe service discipline is FIFO and the service time distribution has a\ndecreasing hazard rate. In this article, we investigate the limiting behavior,\nas $N\\rightarrow \\infty$, of the equilibrium at a queue when the service\ndiscipline is FIFO and the service time distribution has a power law with a\ngiven exponent $-\\beta$, for $\\beta>1$. We show under the above ansatz that, as\n$N\\rightarrow\\infty$, the tail of the equilibrium queue size exhibits a wide\nrange of behavior depending on the relationship between $\\beta$ and $D$. In\nparticular, if $\\beta>D/(D-1)$, the tail is doubly exponential and, if\n$\\beta<D/(D-1)$, the tail has a power law. When $\\beta=D/(D-1)$, the tail is\nexponentially distributed.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2011 21:11:49 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2013 06:56:36 GMT"}], "update_date": "2013-09-10", "authors_parsed": [["Bramson", "Maury", ""], ["Lu", "Yi", ""], ["Prabhakar", "Balaji", ""]]}, {"id": "1106.4985", "submitter": "Mark Stillwell", "authors": "Henri Casanova (CoRG), Mark Stillwell (LIP, INRIA Grenoble\n  Rh\\^one-Alpes / LIP Laboratoire de l'Informatique du Parall\\'elisme),\n  Fr\\'ed\\'eric Vivien (LIP, INRIA Grenoble Rh\\^one-Alpes / LIP Laboratoire de\n  l'Informatique du Parall\\'elisme)", "title": "Dynamic Fractional Resource Scheduling vs. Batch Scheduling", "comments": "N&deg; RR-7659 (2011)", "journal-ref": null, "doi": null, "report-no": "RR-7659", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel job scheduling approach for homogeneous cluster computing\nplatforms. Its key feature is the use of virtual machine technology to share\nfractional node resources in a precise and controlled manner. Other VM-based\nscheduling approaches have focused primarily on technical issues or on\nextensions to existing batch scheduling systems, while we take a more\naggressive approach and seek to find heuristics that maximize an objective\nmetric correlated with job performance. We derive absolute performance bounds\nand develop algorithms for the online, non-clairvoyant version of our\nscheduling problem. We further evaluate these algorithms in simulation against\nboth synthetic and real-world HPC workloads and compare our algorithms to\nstandard batch scheduling approaches. We find that our approach improves over\nbatch scheduling by orders of magnitude in terms of job stretch, while leading\nto comparable or better resource utilization. Our results demonstrate that\nvirtualization technology coupled with lightweight online scheduling strategies\ncan afford dramatic improvements in performance for executing HPC workloads.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2011 14:54:51 GMT"}], "update_date": "2011-06-27", "authors_parsed": [["Casanova", "Henri", "", "CoRG"], ["Stillwell", "Mark", "", "LIP, INRIA Grenoble\n  Rh\u00f4ne-Alpes / LIP Laboratoire de l'Informatique du Parall\u00e9lisme"], ["Vivien", "Fr\u00e9d\u00e9ric", "", "LIP, INRIA Grenoble Rh\u00f4ne-Alpes / LIP Laboratoire de\n  l'Informatique du Parall\u00e9lisme"]]}, {"id": "1106.5113", "submitter": "Tamir Tassa", "authors": "Tamir Tassa", "title": "Secure Mining of Association Rules in Horizontally Distributed Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a protocol for secure mining of association rules in horizontally\ndistributed databases. The current leading protocol is that of Kantarcioglu and\nClifton (TKDE 2004). Our protocol, like theirs, is based on the Fast\nDistributed Mining (FDM) algorithm of Cheung et al. (PDIS 1996), which is an\nunsecured distributed version of the Apriori algorithm. The main ingredients in\nour protocol are two novel secure multi-party algorithms --- one that computes\nthe union of private subsets that each of the interacting players hold, and\nanother that tests the inclusion of an element held by one player in a subset\nheld by another. Our protocol offers enhanced privacy with respect to the\nprotocol of Kantarcioglu and Clifton. In addition, it is simpler and is\nsignificantly more efficient in terms of communication rounds, communication\ncost and computational cost.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jun 2011 08:51:05 GMT"}], "update_date": "2011-06-28", "authors_parsed": [["Tassa", "Tamir", ""]]}, {"id": "1106.5158", "submitter": "Ciprian Dobre", "authors": "Ciprian Dobre, Corina Stratan", "title": "MONARC Simulation Framework", "comments": "Buletinul Stiintific al Universitatii \"Politehnica\" din Timisoara,\n  Romania, Seria Automatica si Calculatoare, Periodica Politechnica,\n  Transactions on Automatic Control and Computer Science Vol.49 (63), 2004,\n  ISSN 1224-600X Special issue on 3rd Edition of RoEduNet International\n  Conference, Timisoara, Romania, 2004", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the latest generation of the MONARC (MOdels of Networked\nAnalysis at Regional Centers) simulation framework, as a design and modelling\ntool for large scale distributed systems applied to HEP experiments. A\nprocess-oriented approach for discrete event simulation is well-suited for\ndescribing concurrent running programs, as well as the stochastic arrival\npatterns that characterize how such systems are used. The simulation engine is\nbased on Threaded Objects (or Active Objects), which offer great flexibility in\nsimulating the complex behavior of distributed data processing programs. The\nengine provides an appropriate scheduling mechanism for the Active objects with\nsupport for interrupts. This approach offers a natural way of describing\ncomplex running programs that are data dependent and which concurrently compete\nfor shared resources as well as large numbers of concurrent data transfers on\nshared resources. The framework provides a complete set of basic components\n(processing nodes, data servers, network components) together with dynamically\nloadable decision units (scheduling or data replication modules) for easily\nbuilding complex Computing Model simulations. Examples of simulating complex\ndata processing systems are presented, and the way the framework is used to\ncompare different decision making algorithms or to optimize the overall Grid\narchitecture and/or the policies that govern the Grid's use.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jun 2011 19:40:21 GMT"}], "update_date": "2011-06-28", "authors_parsed": [["Dobre", "Ciprian", ""], ["Stratan", "Corina", ""]]}, {"id": "1106.5161", "submitter": "Ciprian Dobre", "authors": "Iosif Legrand, Ciprian Dobre, Ramiro Voicu, Corina Stratan, Catalin\n  Cirstoiu, Lucian Musat", "title": "A Simulation Study for T0/T1 Data Replication and Production Activities", "comments": "in Proc. of 15th International Conference on Control Systems and\n  Computer Science (CSCS-15), pp. 131-135, 2005, Bucharest, Romania, Ed.\n  Politehnica Press, ISBN: 973-8449-89-8", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the latest generation of the MONARC (MOdels of Networked\nAnalysis at Regional Centers) simulation framework, as a design and modeling\ntool for large scale distributed systems applied to HEP experiments. The\nsimulation of Grid architectures has a vital importance in the future\ndeployment of Grid systems for providing the users an appropriate feed-back. We\npresent here an example of simulating complex data processing systems and the\nway the framework is used to optimize the overall Grid architecture and/or the\npolicies that govern the Grid's use.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jun 2011 19:46:36 GMT"}], "update_date": "2011-06-28", "authors_parsed": [["Legrand", "Iosif", ""], ["Dobre", "Ciprian", ""], ["Voicu", "Ramiro", ""], ["Stratan", "Corina", ""], ["Cirstoiu", "Catalin", ""], ["Musat", "Lucian", ""]]}, {"id": "1106.5168", "submitter": "Ciprian Dobre", "authors": "Iosif C. Legrand, Ciprian Dobre, Ramiro Voicu, Corina Stratan, Catalin\n  Cirstoiu, Lucian Musat", "title": "LISA (Localhost Information Service Agent)", "comments": "Proc. of the 15th International Conference on Control Systems and\n  Computer Science (CSCS-15), Bucharest, Romania, 2005, pp. 127-130, ISBN:\n  973-8449-89-8", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grid computing has gained an increasing importance in the last years,\nespecially in the academic environments, offering the possibility to rapidly\nsolve complex scientific problems. The monitoring of the Grid jobs has a vital\nimportance for analyzing the system's performance, for providing the users an\nappropriate feed-back, and for obtaining historical data which may be used for\nperformance prediction. Several monitoring systems have been developed, with\ndifferent strategies to collect and store the information. We shall present\nhere a solution based on MonALISA, a distributed service for monitoring,\ncontrol and global optimization of complex systems, and LISA, a component\napplication of MonALISA which can help in optimizing other applications by\nmeans of monitoring services. The advantages of this system are, among others,\nflexibility, dynamic configuration, high communication performance.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jun 2011 20:49:17 GMT"}], "update_date": "2011-06-28", "authors_parsed": [["Legrand", "Iosif C.", ""], ["Dobre", "Ciprian", ""], ["Voicu", "Ramiro", ""], ["Stratan", "Corina", ""], ["Cirstoiu", "Catalin", ""], ["Musat", "Lucian", ""]]}, {"id": "1106.5170", "submitter": "Allison Lewko", "authors": "Allison Lewko", "title": "The Contest Between Simplicity and Efficiency in Asynchronous Byzantine\n  Agreement", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the wake of the decisive impossibility result of Fischer, Lynch, and\nPaterson for deterministic consensus protocols in the aynchronous model with\njust one failure, Ben-Or and Bracha demonstrated that the problem could be\nsolved with randomness, even for Byzantine failures. Both protocols are natural\nand intuitive to verify, and Bracha's achieves optimal resilience. However, the\nexpected running time of these protocols is exponential in general. Recently,\nKapron, Kempe, King, Saia, and Sanwalani presented the first efficient\nByzantine agreement algorithm in the asynchronous, full information model,\nrunning in polylogarithmic time. Their algorithm is Monte Carlo and drastically\ndeparts from the simple structure of Ben-Or and Bracha's Las Vegas algorithms.\n  In this paper, we begin an investigation of the question: to what extent is\nthis departure necessary? Might there be a much simpler and intuitive Las Vegas\nprotocol that runs in expected polynomial time? We will show that the\nexponential running time of Ben-Or and Bracha's algorithms is no mere accident\nof their specific details, but rather an unavoidable consequence of their\ngeneral symmetry and round structure. We define a natural class of \"fully\nsymmetric round protocols\" for solving Byzantine agreement in an asynchronous\nsetting and show that any such protocol can be forced to run in expected\nexponential time by an adversary in the full information model. We assume the\nadversary controls $t$ Byzantine processors for $t = cn$, where $c$ is an\narbitrary positive constant $< 1/3$. We view our result as a step toward\nidentifying the level of complexity required for a polynomial-time algorithm in\nthis setting, and also as a guide in the search for new efficient algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jun 2011 20:53:20 GMT"}, {"version": "v2", "created": "Thu, 7 Jul 2011 01:08:56 GMT"}], "update_date": "2011-07-08", "authors_parsed": [["Lewko", "Allison", ""]]}, {"id": "1106.5171", "submitter": "Ciprian Dobre", "authors": "Ciprian Dobre, Ramiro Voicu, Adrian Muraru, Iosif C. Legrand", "title": "A Distributed Agent Based System to Control and Coordinate Large Scale\n  Data Transfers", "comments": "Proc. of 16th International Conference on Control Systems and\n  Computer Science (CSCS-16), pp. 64-68, Bucharest, Romania, ISBN:\n  978-973-718-741-3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a distributed agent based system used to monitor, configure and\ncontrol complex, large scale data transfers in the Wide Area Network. The\nLocalhost Information Service Agent (LISA) is a lightweight dynamic service\nthat provides complete system and applications monitoring, is capable to\ndynamically configure system parameters and can help in optimizing distributed\napplications.\n  As part of the MonALISA (Monitoring Agents in A Large Integrated Services\nArchitecture) system, LISA is an end host agent capable to collect any type of\nmonitoring information, to distribute them, and to take actions based on local\nor global decision units. The system has been used for the Bandwidth Challenge\nat Supercomputing 2006 to coordinate global large scale data transfers using\nFast Data Transfer (FDT) application between hundreds of servers distributed on\nmajor Grid sites involved in processing High Energy Physics data for the future\nLarge Hadron Collider experiments.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jun 2011 20:54:12 GMT"}], "update_date": "2011-06-28", "authors_parsed": [["Dobre", "Ciprian", ""], ["Voicu", "Ramiro", ""], ["Muraru", "Adrian", ""], ["Legrand", "Iosif C.", ""]]}, {"id": "1106.5299", "submitter": "Ciprian Dobre", "authors": "Ciprian Dobre, Florin Pop, Valentin Cristea", "title": "DistHash: A robust P2P DHT-based system for replicated objects", "comments": "Proceedings of 17th International Conference on Control Systems and\n  Computer Science (CSCS 17), Bucharest, Romania, May 26-29, 2009. Vol. 1, pp.\n  453-460, ISSN: 2066-4451", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the Internet today, computing and communications environments are\nsignificantly more complex and chaotic than classical distributed systems,\nlacking any centralized organization or hierarchical control. There has been\nmuch interest in emerging Peer-to-Peer (P2P) network overlays because they\nprovide a good substrate for creating large-scale data sharing, content\ndistribution and application-level multicast applications. In this paper we\npresent DistHash, a P2P overlay network designed to share large sets of\nreplicated distributed objects in the context of large-scale highly dynamic\ninfrastructures. We present original solutions to achieve optimal message\nrouting in hop-count and throughput, provide an adequate consistency approach\namong replicas, as well as provide a fault-tolerant substrate.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2011 05:49:21 GMT"}], "update_date": "2011-06-28", "authors_parsed": [["Dobre", "Ciprian", ""], ["Pop", "Florin", ""], ["Cristea", "Valentin", ""]]}, {"id": "1106.5302", "submitter": "Florin Pop Mr.", "authors": "Dacian Tudor, Florin Pop, Valentin Cristea, Vladimir Cretu", "title": "Towards an IO intensive Grid application instrumentation in MedioGRID", "comments": null, "journal-ref": "Proceedings of the 16th International Conference on Control\n  Systems and Computer Science (CSCS16'07), pp. 130-135, May 22-25, Bucharest,\n  Romania, 2007", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining high performance in IO intensive applications requires systems that\nsupport reliable fast transfer, data replication, and caching. In this paper we\npresent an architecture designed for supporting IO intensive applications in\nMedioGRID, a system for real-time processing of satellite images, operating in\na Grid environment. The solution ensures that applications which are processing\ngeographical data have uniform access to data and is based on continuous\nmonitoring of the data transfers using MonALISA and its extensions. The\nMedioGRID architecture is also built on Globus, Condor and PBS and based on\nthis middleware we aim to extract information about the running systems. The\nresults obtained in testing MedioGRID system for large data transfers show that\nmonitoring system provides a very good view of system evolution.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2011 06:03:28 GMT"}], "update_date": "2011-06-28", "authors_parsed": [["Tudor", "Dacian", ""], ["Pop", "Florin", ""], ["Cristea", "Valentin", ""], ["Cretu", "Vladimir", ""]]}, {"id": "1106.5303", "submitter": "Florin Pop Mr.", "authors": "Florin Pop, Valentin Cristea", "title": "Intelligent strategies for DAG scheduling optimization in Grid\n  environments", "comments": "Printech, ISBN 978-973-718-743-7", "journal-ref": "Proceedings of the 16th International Conference on Control\n  Systems and Computer Science (CSCS16'07), pp. 98-103, May 22-25, Bucharest,\n  Romania, 2007", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a solution to the dynamic DAG scheduling problem in Grid\nenvironments. It presents a distributed, scalable, efficient and fault-tolerant\nalgorithm for optimizing tasks assignment. The scheduler algorithm for tasks\nwith dependencies uses a heuristic model to optimize the total cost of tasks\nexecution. Also, a method based on genetic algorithms is proposed to optimize\nthe procedure of resources assignment. The experiments used the MonALISA\nmonitoring environment and its extensions. The results demonstrate very good\nbehavior in comparison with other scheduling approaches for this kind of DAG\nscheduling algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2011 06:03:42 GMT"}], "update_date": "2011-06-28", "authors_parsed": [["Pop", "Florin", ""], ["Cristea", "Valentin", ""]]}, {"id": "1106.5309", "submitter": "Florin Pop Mr.", "authors": "Diana Moise, Eliza Moise, Florin Pop, Valentin Cristea", "title": "Resource CoAllocation for Scheduling Tasks with Dependencies, in Grid", "comments": "ISSN: 2065-0701", "journal-ref": "Proceedings of The Second International Workshop on High\n  Performance in Grid Middleware (HiPerGRID 2008), Bucharest, Romania,\n  Published by IEEE Romania, 2008, pages: 41-48", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scheduling applications on wide-area distributed systems is useful for\nobtaining quick and reliable results in an efficient manner. Optimized\nscheduling algorithms are fundamentally important in order to achieve optimized\nresources utilization. The existing and potential applications include many\nfields of activity like satellite image processing and medicine. The paper\nproposes a scheduling algorithm for tasks with dependencies in Grid\nenvironments. CoAllocation represents a strategy that provides a schedule for\ntask with dependencies, having as main purpose the efficiency of the schedule,\nin terms of load balancing and minimum time for the execution of the tasks.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2011 06:24:40 GMT"}], "update_date": "2011-06-28", "authors_parsed": [["Moise", "Diana", ""], ["Moise", "Eliza", ""], ["Pop", "Florin", ""], ["Cristea", "Valentin", ""]]}, {"id": "1106.5310", "submitter": "Florin Pop Mr.", "authors": "Eliza Moise, Diana Moise, Florin Pop, Valentin Cristea", "title": "Advance Reservation of Resources for Task Execution in Grid Environments", "comments": "ISSN: 2065-0701", "journal-ref": "Proceedings of The Second International Workshop on High\n  Performance in Grid Middleware (HiPerGRID 2008), Bucharest, Romania,\n  Published by IEEE Romania, 2008, pages: 57-64", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes a solution for the Grid scheduling problem, addressing in\nparticular the requirement of high performance an efficient algorithm must\nfulfill. Advance Reservation engages a distributed, dynamic, fault-tolerant and\nefficient strategy which reserves resources for future task execution. The\npaper presents the main features of the strategy, the functioning mechanism the\nstrategy is based on and the methods used for evaluating the algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2011 06:24:50 GMT"}], "update_date": "2011-06-28", "authors_parsed": [["Moise", "Eliza", ""], ["Moise", "Diana", ""], ["Pop", "Florin", ""], ["Cristea", "Valentin", ""]]}, {"id": "1106.5451", "submitter": "Ilango Sriram", "authors": "Ilango Sriram and Dave Cliff", "title": "Hybrid complex network topologies are preferred for\n  component-subscription in large-scale data-centres", "comments": null, "journal-ref": "CompleNet 2010, CCIS vol. 116, pp. 130-137, Springer Heidelberg,\n  2011", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on experiments exploring the interplay between the topology of the\ncomplex network of dependent components in a large-scale data-centre, and the\nrobustness and scaling properties of that data-centre. In a previous paper [1]\nwe used the SPECI large-scale data-centre simulator [2] to compare the\nrobustness and scaling characteristics of data-centres whose dependent\ncomponents are connected via Strogatz-Watts small-world (SW) networks [3],\nversus those organized as Barabasi-Albert scale-free (SF) networks [4], and\nfound significant differences. In this paper, we present results from using the\nKlemm-Eguiliz (KE) construction method [5] to generate complex network\ntopologies for data-centre component dependencies. The KE model has a control\nparameter {\\mu}\\in[0,1]\\inR that determines whether the networks generated are\nSW (0<{\\mu}<<1) or SF ({\\mu}=1) or a \"hybrid\" network topology part-way between\nSW and SF (0<{\\mu}<1). We find that the best scores for system-level\nperformance metrics of the simulated data-centres are given by \"hybrid\" values\nof {\\mu} significantly different from pure-SW or pure-SF.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2011 17:16:41 GMT"}], "update_date": "2011-06-28", "authors_parsed": [["Sriram", "Ilango", ""], ["Cliff", "Dave", ""]]}, {"id": "1106.5457", "submitter": "Ilango Sriram", "authors": "John Cartlidge and Ilango Sriram", "title": "Modelling Resilience in Cloud-Scale Data Centres", "comments": "To appear in: Proceedings of the 23rd European Modeling & Simulation\n  Symposium (Simulation in Industry) 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The trend for cloud computing has initiated a race towards data centres (DC)\nof an ever-increasing size. The largest DCs now contain many hundreds of\nthousands of virtual machine (VM) services. Given the finite lifespan of\nhardware, such large DCs are subject to frequent hardware failure events that\ncan lead to disruption of service. To counter this, multiple redundant copies\nof task threads may be distributed around a DC to ensure that individual\nhardware failures do not cause entire jobs to fail. Here, we present results\ndemonstrating the resilience of different job scheduling algorithms in a\nsimulated DC with hardware failure. We use a simple model of jobs distributed\nacross a hardware network to demonstrate the relationship between resilience\nand additional communication costs of different scheduling methods.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2011 17:31:49 GMT"}], "update_date": "2011-06-28", "authors_parsed": [["Cartlidge", "John", ""], ["Sriram", "Ilango", ""]]}, {"id": "1106.5465", "submitter": "Ilango Sriram", "authors": "Ilango Leonardo Sriram, Dave Cliff", "title": "SPECI-2: An open-source framework for predictive simulation of\n  cloud-scale data-centres", "comments": "To appear in Proceedings of SIMULTECH 2011, see also speci.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Version 2 of SPECI, a system for predictive simulation modeling\nof large-scale data-centres, i.e. warehouse-sized facilities containing\nhundreds of thousands of servers, as used to provide cloud services.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2011 18:01:03 GMT"}], "update_date": "2011-06-28", "authors_parsed": [["Sriram", "Ilango Leonardo", ""], ["Cliff", "Dave", ""]]}, {"id": "1106.5570", "submitter": "Ciprian Dobre", "authors": "Ramiro Voicu, Iosif Legrand, Harvey Newman, Nicolae Tapus, Ciprian\n  Dobre", "title": "A distributed service for on demand end to end optical circuits", "comments": "17th International Conference on Control Systems and Computer Science\n  (CSCS 17), Bucharest, Romania, May 26-29, 2009. Vol. 1, pp. 155-161, ISSN:\n  2066-4451", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a system for monitoring and controlling dynamic\nnetwork circuits inside the USLHCNet network. This distributed service system\nprovides in near real-time complete topological information for all the\ncircuits, resource allocation and usage, accounting, detects automatically\nfailures in the links and network equipment, generate alarms and has the\nfunctionality to take automatic actions. The system is developed based on the\nMonALISA framework, which provides a robust monitoring and controlling service\noriented architecture, with no single points of failure.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2011 06:01:49 GMT"}], "update_date": "2011-06-29", "authors_parsed": [["Voicu", "Ramiro", ""], ["Legrand", "Iosif", ""], ["Newman", "Harvey", ""], ["Tapus", "Nicolae", ""], ["Dobre", "Ciprian", ""]]}, {"id": "1106.5576", "submitter": "Ciprian Dobre", "authors": "Valentin Cristea, Ciprian Dobre, Florin Pop, Corina Stratan, Alexandru\n  Costan, Catalin Leordeanu", "title": "Models and Techniques for Ensuring Reliability, Safety, Availability and\n  Security of Large Scale Distributed Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  17th International Conference on Control Systems and Computer Science (CSCS\n17), Bucharest, Romania, May 26-29, 2009. Vol. 1, pp. 401-406, ISSN: 2066-4451.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2011 06:53:59 GMT"}], "update_date": "2011-06-29", "authors_parsed": [["Cristea", "Valentin", ""], ["Dobre", "Ciprian", ""], ["Pop", "Florin", ""], ["Stratan", "Corina", ""], ["Costan", "Alexandru", ""], ["Leordeanu", "Catalin", ""]]}, {"id": "1106.5694", "submitter": "Roberto Roverso", "authors": "Roberto Roverso, Amgad Naiem, Mohammed El-Beltagy and Sameh El-Ansary", "title": "GPU-Based Heuristic Solver for Linear Sum Assignment Problems Under\n  Real-time Constraints", "comments": "White Paper, Peerialism Inc. (www.peerialism.com)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS cs.PF math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we modify a fast heuristic solver for the Linear Sum Assignment\nProblem (LSAP) for use on Graphical Processing Units (GPUs). The motivating\nscenario is an industrial application for P2P live streaming that is moderated\nby a central node which is periodically solving LSAP instances for assigning\npeers to one another. The central node needs to handle LSAP instances involving\nthousands of peers in as near to real-time as possible. Our findings are\ngeneric enough to be applied in other contexts. Our main result is a parallel\nversion of a heuristic algorithm called Deep Greedy Switching (DGS) on GPUs\nusing the CUDA programming language. DGS sacrifices absolute optimality in\nfavor of low computation time and was designed as an alternative to classical\nLSAP solvers such as the Hungarian and auctioning methods. The contribution of\nthe paper is threefold: First, we present the process of trial and error we\nwent through, in the hope that our experience will be beneficial to adopters of\nGPU programming for similar problems. Second, we show the modifications needed\nto parallelize the DGS algorithm. Third, we show the performance gains of our\napproach compared to both a sequential CPU-based implementation of DGS and a\nparallel GPU-based implementation of the auctioning algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2011 14:53:58 GMT"}, {"version": "v2", "created": "Thu, 30 Jun 2011 13:41:49 GMT"}], "update_date": "2011-07-01", "authors_parsed": [["Roverso", "Roberto", ""], ["Naiem", "Amgad", ""], ["El-Beltagy", "Mohammed", ""], ["El-Ansary", "Sameh", ""]]}, {"id": "1106.5846", "submitter": "Ciprian Dobre", "authors": "Alexandru Costan, Florin Pop, Corina Stratan, Ciprian Dobre, Catalin\n  Leordeanu, Valentin Cristea", "title": "An Architectural Model for a Grid based Workflow Management Platform in\n  Scientific Applications", "comments": "17th International Conference on Control Systems and Computer Science\n  (CSCS 17), Bucharest, Romania, May 26-29, 2009. Vol. 1, pp. 407-414, ISSN:\n  2066-4451", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With recent increasing computational and data requirements of scientific\napplications, the use of large clustered systems as well as distributed\nresources is inevitable. Although executing large applications in these\nenvironments brings increased performance, the automation of the process\nbecomes more and more challenging. While the use of complex workflow management\nsystems has been a viable solution for this automation process in business\noriented environments, the open source engines available for scientific\napplications lack some functionalities or are too difficult to use for\nnon-specialists. In this work we propose an architectural model for a grid\nbased workflow management platform providing features like an intuitive way to\ndescribe workflows, efficient data handling mechanisms and flexible fault\ntolerance support. Our integrated solution introduces a workflow engine\ncomponent based on ActiveBPEL extended with additional functionalities and a\nscheduling component providing efficient mapping between tasks and available\nresources.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2011 06:03:11 GMT"}], "update_date": "2011-06-30", "authors_parsed": [["Costan", "Alexandru", ""], ["Pop", "Florin", ""], ["Stratan", "Corina", ""], ["Dobre", "Ciprian", ""], ["Leordeanu", "Catalin", ""], ["Cristea", "Valentin", ""]]}, {"id": "1106.5908", "submitter": "Georg Hager", "authors": "Gerald Schubert, Holger Fehske, Georg Hager, Gerhard Wellein", "title": "Hybrid-parallel sparse matrix-vector multiplication with explicit\n  communication overlap on current multicore-based systems", "comments": "16 pages, 10 figures", "journal-ref": "Parallel Processing Letters 21(3), 339-358 (2011)", "doi": "10.1142/S0129626411000254", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate optimized parallel sparse matrix-vector operations for several\nrepresentative application areas on widespread multicore-based cluster\nconfigurations. First the single-socket baseline performance is analyzed and\nmodeled with respect to basic architectural properties of standard multicore\nchips. Beyond the single node, the performance of parallel sparse matrix-vector\noperations is often limited by communication overhead. Starting from the\nobservation that nonblocking MPI is not able to hide communication cost using\nstandard MPI implementations, we demonstrate that explicit overlap of\ncommunication and computation can be achieved by using a dedicated\ncommunication thread, which may run on a virtual core. Moreover we identify\nperformance benefits of hybrid MPI/OpenMP programming due to improved load\nbalancing even without explicit communication overlap. We compare performance\nresults for pure MPI, the widely used \"vector-like\" hybrid programming\nstrategies, and explicit overlap on a modern multicore-based cluster and a Cray\nXE6 system.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2011 11:25:50 GMT"}], "update_date": "2012-03-01", "authors_parsed": [["Schubert", "Gerald", ""], ["Fehske", "Holger", ""], ["Hager", "Georg", ""], ["Wellein", "Gerhard", ""]]}, {"id": "1106.6069", "submitter": "Harish Chintakunta", "authors": "Harish Chintakunta and Hamid Krim", "title": "Topological Fidelity in Sensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensor Networks are inherently complex networks, and many of their associated\nproblems require analysis of some of their global characteristics. These are\nprimarily affected by the topology of the network. We present in this paper, a\ngeneral framework for a topological analysis of a network, and develop\ndistributed algorithms in a generalized combinatorial setting in order to solve\ntwo seemingly unrelated problems, 1) Coverage hole detection and Localization\nand 2) Worm hole attack detection and Localization. We also note these\nsolutions remain coordinate free as no priori localization information of the\nnodes is assumed. For the coverage hole problem, we follow a \"divide and\nconquer approach\", by strategically dissecting the network so that the overall\ntopology is preserved, while efficiently pursuing the detection and\nlocalization of failures. The detection of holes, is enabled by first\nattributing a combinatorial object called a \"Rips Complex\" to each network\nsegment, and by subsequently checking the existence/non-existence of holes by\nway of triviality of the first homology class of this complex. Our estimate\nexponentially approaches the location of potential holes with each iteration,\nyielding a very fast convergence coupled with optimal usage of valuable\nresources such as power and memory. We then show a simple extension of the\nabove problem to address a well known problem in networks, namely the\nlocalization of a worm hole attack. We demonstrate the effectiveness of the\npresented algorithm with several substantiating examples.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2011 22:15:25 GMT"}], "update_date": "2011-07-01", "authors_parsed": [["Chintakunta", "Harish", ""], ["Krim", "Hamid", ""]]}, {"id": "1106.6122", "submitter": "Ciprian Dobre", "authors": "Dobre Ciprian, Cristea Valentin, Iosif C. Legrand", "title": "Simulation Framework for Modeling Large-Scale Distributed Systems", "comments": "International Conference on Control Systems and Computer Science\n  (CSCS-14), Ed. Politehnica Press, Bucharest, Romania, pp. 145-149", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation has become the evaluation method of choice for many areas of\ndistributing computing research. However, most existing simulation packages\nhave several limitations on the size and complexity of the system being\nmodeled. Fine grained simulation of complex systems such as Grids requires high\ncomputational effort which can only be obtained by using an underlying\ndistributed architecture. We are proposing a new distributed simulation system\nthat has the advantage of being able to model very complex distributed systems\nwhile hiding the computational effort from the end-user.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2011 06:37:34 GMT"}], "update_date": "2011-07-01", "authors_parsed": [["Ciprian", "Dobre", ""], ["Valentin", "Cristea", ""], ["Legrand", "Iosif C.", ""]]}, {"id": "1106.6196", "submitter": "Kees Middelburg", "authors": "J. A. Bergstra, C. A. Middelburg", "title": "On the behaviours produced by instruction sequences under execution", "comments": "36 pages, consolidates material from arXiv:0811.0436 [cs.PL],\n  arXiv:0902.2859 [cs.PL], and arXiv:0905.2257 [cs.PL]; abstract and\n  introduction rewritten, examples and proofs added", "journal-ref": "Fundamenta Informaticae, 120(2):111--144, 2012", "doi": "10.3233/FI-2012-753", "report-no": null, "categories": "cs.PL cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study several aspects of the behaviours produced by instruction sequences\nunder execution in the setting of the algebraic theory of processes known as\nACP. We use ACP to describe the behaviours produced by instruction sequences\nunder execution and to describe two protocols implementing these behaviours in\nthe case where the processing of instructions takes place remotely. We also\nshow that all finite-state behaviours considered in ACP can be produced by\ninstruction sequences under execution.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2011 11:51:25 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2012 07:11:09 GMT"}], "update_date": "2012-12-05", "authors_parsed": [["Bergstra", "J. A.", ""], ["Middelburg", "C. A.", ""]]}, {"id": "1106.6217", "submitter": "Mihai Niculescu", "authors": "Mihai Niculescu, Sorin-Ion Zgura", "title": "Computing trends using graphic processor in high energy physics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC hep-ex physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main challenges in Heavy Energy Physics is to make fast analysis\nof high amount of experimental and simulated data. At LHC-CERN one p-p event is\napproximate 1 Mb in size. The time taken to analyze the data and obtain fast\nresults depends on high computational power. The main advantage of using\nGPU(Graphic Processor Unit) programming over traditional CPU one is that\ngraphical cards bring a lot of computing power at a very low price. Today a\nhuge number of application(scientific, financial etc) began to be ported or\ndeveloped for GPU, including Monte Carlo tools or data analysis tools for High\nEnergy Physics. In this paper, we'll present current status and trends in HEP\nusing GPU.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2011 13:08:28 GMT"}], "update_date": "2011-07-01", "authors_parsed": [["Niculescu", "Mihai", ""], ["Zgura", "Sorin-Ion", ""]]}, {"id": "1106.6304", "submitter": "Danny  Hendler", "authors": "Gal Bar-Nissan, Danny Hendler and Adi Suissa", "title": "A Dynamic Elimination-Combining Stack Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two key synchronization paradigms for the construction of scalable concurrent\ndata-structures are software combining and elimination. Elimination-based\nconcurrent data-structures allow operations with reverse semantics (such as\npush and pop stack operations) to \"collide\" and exchange values without having\nto access a central location. Software combining, on the other hand, is\neffective when colliding operations have identical semantics: when a pair of\nthreads performing operations with identical semantics collide, the task of\nperforming the combined set of operations is delegated to one of the threads\nand the other thread waits for its operation(s) to be performed. Applying this\nmechanism iteratively can reduce memory contention and increase throughput. The\nmost highly scalable prior concurrent stack algorithm is the\nelimination-backoff stack. The elimination-backoff stack provides high\nparallelism for symmetric workloads in which the numbers of push and pop\noperations are roughly equal, but its performance deteriorates when workloads\nare asymmetric. We present DECS, a novel Dynamic Elimination-Combining Stack\nalgorithm, that scales well for all workload types. While maintaining the\nsimplicity and low-overhead of the elimination-bakcoff stack, DECS manages to\nbenefit from collisions of both identical- and reverse-semantics operations.\nOur empirical evaluation shows that DECS scales significantly better than both\nblocking and non-blocking best prior stack algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2011 17:12:14 GMT"}], "update_date": "2011-07-01", "authors_parsed": [["Bar-Nissan", "Gal", ""], ["Hendler", "Danny", ""], ["Suissa", "Adi", ""]]}]