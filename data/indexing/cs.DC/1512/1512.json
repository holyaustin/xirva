[{"id": "1512.00061", "submitter": "Syed (Shawon) Rahman", "authors": "Kathleen Jungck and Shawon Rahman", "title": "Cloud Computing Avoids Downfall of Application Service Providers", "comments": null, "journal-ref": null, "doi": "10.5121/ijitcs.2011.1301", "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Businesses have become dependent on ever increasing amounts of electronic\ninformation and rapid transaction speeds. Experts such as Diffie speculate that\nthe end of isolated computing is at hand, and that within the next decade most\nbusinesses will have made the shift to utility computing. In order to cut costs\nwhile still implementing increasingly complex Information Technology services,\nmany companies turned to Application Service Providers (ASPs). Due to poor\nbusiness models, over competition, and poor internet availability and\nbandwidth, many ASPs failed with the dot com crash. Other ASPs, however, who\nembraced web services architecture and true internet delivery were well placed\nas early cloud adopters. With the expanded penetration and bandwidth of\ninternet services today, better business plans, and a wide divergence of\noffering, cloud computing is avoiding the ASP downfall, and is positioned to\nemerge as an enduring paradigm in computing\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2015 21:54:58 GMT"}], "update_date": "2015-12-02", "authors_parsed": [["Jungck", "Kathleen", ""], ["Rahman", "Shawon", ""]]}, {"id": "1512.00168", "submitter": "Paolo Viotti", "authors": "Paolo Viotti and Marko Vukoli\\'c", "title": "Consistency in Non-Transactional Distributed Storage Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the years, different meanings have been associated to the word\nconsistency in the distributed systems community. While in the '80s\n\"consistency\" typically meant strong consistency, later defined also as\nlinearizability, in recent years, with the advent of highly available and\nscalable systems, the notion of \"consistency\" has been at the same time both\nweakened and blurred.\n  In this paper we aim to fill the void in literature, by providing a\nstructured and comprehensive overview of different consistency notions that\nappeared in distributed systems, and in particular storage systems research, in\nthe last four decades. We overview more than 50 different consistency notions,\nranging from linearizability to eventual and weak consistency, defining\nprecisely many of these, in particular where the previous definitions were\nambiguous. We further provide a partial order among different consistency\npredicates, ordering them by their semantic \"strength\", which we believe will\nreveal useful in future research. Finally, we map the consistency semantics to\ndifferent practical systems and research prototypes.\n  The scope of this paper is restricted to non-transactional semantics, i.e.,\nthose that apply to single storage object operations. As such, our paper\ncomplements the existing surveys done in the context of transactional, database\nconsistency semantics.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2015 07:50:37 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2015 10:03:53 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2015 16:16:17 GMT"}, {"version": "v4", "created": "Tue, 12 Apr 2016 11:40:31 GMT"}], "update_date": "2016-04-13", "authors_parsed": [["Viotti", "Paolo", ""], ["Vukoli\u0107", "Marko", ""]]}, {"id": "1512.00272", "submitter": "Samuel Skipsey", "authors": "Samuel Cadellin Skipsey, Shaun De Witt, Alastair Dewhurst, David\n  Britton, Gareth Roy, David Crooks", "title": "Enabling Object Storage via shims for Grid Middleware", "comments": "21st International Conference on Computing in High Energy and Nuclear\n  Physics (CHEP2015)", "journal-ref": null, "doi": "10.1088/1742-6596/664/4/042052", "report-no": null, "categories": "physics.comp-ph cs.DC hep-ex", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The Object Store model has quickly become the basis of most commercially\nsuccessful mass storage infrastructure, backing so-called \"Cloud\" storage such\nas Amazon S3, but also underlying the implementation of most parallel\ndistributed storage systems. Many of the assumptions in Object Store design are\nsimilar, but not identical, to concepts in the design of Grid Storage Elements,\nalthough the requirement for \"POSIX-like\" filesystem structures on top of SEs\nmakes the disjunction seem larger. As modern Object Stores provide many\nfeatures that most Grid SEs do not (block level striping, parallel access,\nautomatic file repair, etc.), it is of interest to see how easily we can\nprovide interfaces to typical Object Stores via plugins and shims for Grid\ntools, and how well experiments can adapt their data models to them. We present\nevaluation of, and first-deployment experiences with, (for example) Xrootd-Ceph\ninterfaces for direct object-store access, as part of an initiative within\nGridPP\\cite{GridPP} hosted at RAL. Additionally, we discuss the tradeoffs and\nexperience of developing plugins for the currently-popular {\\it Ceph} parallel\ndistributed filesystem for the GFAL2 access layer, at Glasgow.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2015 15:05:59 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["Skipsey", "Samuel Cadellin", ""], ["De Witt", "Shaun", ""], ["Dewhurst", "Alastair", ""], ["Britton", "David", ""], ["Roy", "Gareth", ""], ["Crooks", "David", ""]]}, {"id": "1512.00313", "submitter": "Luiz Capretz Dr.", "authors": "Hany F. El Yamany, Miriam Capretz, Luiz Fernando Capretz", "title": "A Multi-Agent Framework for Testing Distributed Systems", "comments": null, "journal-ref": "30th IEEE International Computer Software and Applications\n  Conference (COMPSAC), Chicago, USA, Volume II, pp. 151-156, 2006", "doi": "10.1109/COMPSAC.2006.98", "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software testing is a very expensive and time consuming process. It can\naccount for up to 50% of the total cost of the software development.\nDistributed systems make software testing a daunting task. The research\ndescribed in this paper investigates a novel multi-agent framework for testing\n3-tier distributed systems. This paper describes the framework architecture as\nwell as the communication mechanism among agents in the architecture. Web-based\napplication is examined as a case study to validate the proposed framework. The\nframework is considered as a step forward to automate testing for distributed\nsystems in order to enhance their reliability within an acceptable range of\ncost and time.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2015 15:55:05 GMT"}], "update_date": "2015-12-02", "authors_parsed": [["Yamany", "Hany F. El", ""], ["Capretz", "Miriam", ""], ["Capretz", "Luiz Fernando", ""]]}, {"id": "1512.00540", "submitter": "Miguel Mosteiro", "authors": "Dariusz R. Kowalski, Miguel A. Mosteiro, and Kevin Zaki", "title": "Dynamic Multiple-Message Broadcast: Bounding Throughput in the\n  Affectance Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a dynamic version of the Multiple-Message Broadcast problem, where\npackets are continuously injected in network nodes for dissemination throughout\nthe network. Our performance metric is the ratio of the throughput of such\nprotocol against the optimal one, for any sufficiently long period of time\nsince startup. We present and analyze a dynamic Multiple-Message Broadcast\nprotocol that works under an affectance model, which parameterizes the\ninterference that other nodes introduce in the communication between a given\npair of nodes. As an algorithmic tool, we develop an efficient algorithm to\nschedule a broadcast along a BFS tree under the affectance model. To provide a\nrigorous and accurate analysis, we define two novel network characteristics\nbased on the network topology and the affectance function. The combination of\nthese characteristics influence the performance of broadcasting with affectance\n(modulo a logarithmic function). We also carry out simulations of our protocol\nunder affectance. To the best of our knowledge, this is the first dynamic\nMultiple-Message Broadcast protocol that provides throughput guarantees for\ncontinuous injection of messages and works under the affectance model.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2015 01:36:10 GMT"}], "update_date": "2015-12-03", "authors_parsed": [["Kowalski", "Dariusz R.", ""], ["Mosteiro", "Miguel A.", ""], ["Zaki", "Kevin", ""]]}, {"id": "1512.00664", "submitter": "Sanjay Sahay", "authors": "Aruna Govada, Bhavul Gauri and S.K. Sahay", "title": "Distributed Multi Class SVM for Large Data Sets", "comments": "Presente in the WCI, Kochi, India, 2015", "journal-ref": "ACM Digital Library, Proceeding WCI '15 Proceedings of the Third\n  International Symposium on Women in Computing and Informatics, PP. 54-58,\n  2015", "doi": "10.1145/2791405.2791534", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data mining algorithms are originally designed by assuming the data is\navailable at one centralized site.These algorithms also assume that the whole\ndata is fit into main memory while running the algorithm. But in today's\nscenario the data has to be handled is distributed even geographically.\nBringing the data into a centralized site is a bottleneck in terms of the\nbandwidth when compared with the size of the data. In this paper for multiclass\nSVM we propose an algorithm which builds a global SVM model by merging the\nlocal SVMs using a distributed approach(DSVM). And the global SVM will be\ncommunicated to each site and made it available for further classification. The\nexperimental analysis has shown promising results with better accuracy when\ncompared with both the centralized and ensemble method. The time complexity is\nalso reduced drastically because of the parallel construction of local SVMs.\nThe experiments are conducted by considering the data sets of size 100s to\nhundred of 100s which also addresses the issue of scalability.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2015 12:14:19 GMT"}], "update_date": "2015-12-03", "authors_parsed": [["Govada", "Aruna", ""], ["Gauri", "Bhavul", ""], ["Sahay", "S. K.", ""]]}, {"id": "1512.00665", "submitter": "Weidong Wang", "authors": "Weidong Wang, Chunhua Liao, Liqiang Wang, Daniel J. Quinlan, Wei Lu", "title": "HBTM: A Heartbeat-based Behavior Detection Mechanism for POSIX Threads\n  and OpenMP Applications", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme-scale computing involves hundreds of millions of threads with\nmulti-level parallelism running on large-scale hierarchical and heterogeneous\nhardware. In POSIX threads and OpenMP applications, some key behaviors\noccurring in runtime such as thread failure, busy waiting, and exit need to be\naccurately and timely detected. However, for the most of these applications,\nthere are lack of unified and efficient detection mechanisms to do this. In\nthis paper, a heartbeat-based behavior detection mechanism for POSIX threads\n(Pthreads) and OpenMP applications (HBTM) is proposed. In the design, two types\nof implementations are conducted, centralized and decentralized respectively.\nIn both implementations, unified API has been designed to guarantee the\ngenerality of the mechanism. Meanwhile, a ring-based detection algorithm is\ndesigned to ease the burden of the centra thread at runtime. To evaluate the\nmechanism, the NAS Parallel Benchmarks (NPB) are used to test the performance\nof the HBTM. The experimental results show that the HBTM supports detection of\nbehaviors of POSIX threads and OpenMP applications while acquiring a short\nlatency and near 1% overhead.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2015 12:24:06 GMT"}], "update_date": "2015-12-03", "authors_parsed": [["Wang", "Weidong", ""], ["Liao", "Chunhua", ""], ["Wang", "Liqiang", ""], ["Quinlan", "Daniel J.", ""], ["Lu", "Wei", ""]]}, {"id": "1512.01129", "submitter": "Jose  Luis Garcia Dorado", "authors": "Jose Luis Garcia-Dorado", "title": "Bandwidth in the Cloud", "comments": null, "journal-ref": "Bandwidth Measurements within the Cloud: Characterizing Regular\n  Behaviors and Correlating Downtimes. ACM Transactions on Internet Technology,\n  Vol.17, No. 4, Article No. 39, 2017", "doi": "10.1145/3093893", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The seek for the best quality of service has led Cloud infrastructure clients\nto disseminate their services, contents and data over multiple cloud\ndata-centers often involving several Cloud Service Providers (CSPs). The\nconsequence of this is that a large amount of bytes must be transmitted across\nthe public Cloud. However, very little is known about its bandwidth dynamics.\nTo address this, we have conducted a measurement campaign for bandwidth between\neighteen data-centers of four major CSPs. Such extensive campaign allowed us to\ncharacterize the resulting time series of bandwidth as the addition of a\nstationary component and some infrequent excursions (typically, downtimes).\nWhile the former provides a description of the bandwidth users can expect in\nthe Cloud, the latter is closely related to the robustness of the Cloud (i.e.,\nthe occurrence of downtimes is correlated). Both components have been studied\nfurther by applying a factor analysis, specifically ANOVA, as a mechanism to\nformally compare data-centers' behaviors and extract generalities. The results\nshow that the stationary process is closely related to data-center locations\nand CSPs involved in transfers, which fortunately makes both the Cloud more\npredictable and the set of reported measurements extrapolate. On the other\nhand, although the correlation in the Cloud is low, i.e., only 10% of the\nmeasured pair of paths showed some correlation, we have found evidence that\nsuch correlation depends on the particular relationships between pairs of\ndata-centers with little link to more general factors. Positively, this implies\nthat data-centers either at the same area or CSP do not show qualitatively more\ncorrelation than others data-centers, which eases the deployment of robust\ninfrastructures. On the downside, this metric is barely generalizable and,\nconsequently, calls for exhaustive monitoring.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2015 15:57:16 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Garcia-Dorado", "Jose Luis", ""]]}, {"id": "1512.01274", "submitter": "Mu Li", "authors": "Tianqi Chen, Mu Li, Yutian Li, Min Lin, Naiyan Wang, Minjie Wang,\n  Tianjun Xiao, Bing Xu, Chiyuan Zhang and Zheng Zhang", "title": "MXNet: A Flexible and Efficient Machine Learning Library for\n  Heterogeneous Distributed Systems", "comments": "In Neural Information Processing Systems, Workshop on Machine\n  Learning Systems, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.MS cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  MXNet is a multi-language machine learning (ML) library to ease the\ndevelopment of ML algorithms, especially for deep neural networks. Embedded in\nthe host language, it blends declarative symbolic expression with imperative\ntensor computation. It offers auto differentiation to derive gradients. MXNet\nis computation and memory efficient and runs on various heterogeneous systems,\nranging from mobile devices to distributed GPU clusters.\n  This paper describes both the API design and the system implementation of\nMXNet, and explains how embedding of both symbolic expression and tensor\noperation is handled in a unified fashion. Our preliminary experiments reveal\npromising results on large scale deep neural network applications using\nmultiple GPU machines.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2015 22:49:21 GMT"}], "update_date": "2015-12-07", "authors_parsed": [["Chen", "Tianqi", ""], ["Li", "Mu", ""], ["Li", "Yutian", ""], ["Lin", "Min", ""], ["Wang", "Naiyan", ""], ["Wang", "Minjie", ""], ["Xiao", "Tianjun", ""], ["Xu", "Bing", ""], ["Zhang", "Chiyuan", ""], ["Zhang", "Zheng", ""]]}, {"id": "1512.01568", "submitter": "Sanjay Sahay", "authors": "Aruna Govada, Pravin Joshi, Sahil Mittal and Sanjay K Sahay", "title": "Hybrid Approach for Inductive Semi Supervised Learning using Label\n  Propagation and Support Vector Machine", "comments": "Presented in the 11th International Conference, MLDM, Germany, July\n  20 - 21, 2015. Springer, Machine Learning and Data Mining in Pattern\n  Recognition, LNAI Vol. 9166, p. 199-213, 2015", "journal-ref": null, "doi": "10.1007/978-3-319-21024-7_14", "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi supervised learning methods have gained importance in today's world\nbecause of large expenses and time involved in labeling the unlabeled data by\nhuman experts. The proposed hybrid approach uses SVM and Label Propagation to\nlabel the unlabeled data. In the process, at each step SVM is trained to\nminimize the error and thus improve the prediction quality. Experiments are\nconducted by using SVM and logistic regression(Logreg). Results prove that SVM\nperforms tremendously better than Logreg. The approach is tested using 12\ndatasets of different sizes ranging from the order of 1000s to the order of\n10000s. Results show that the proposed approach outperforms Label Propagation\nby a large margin with F-measure of almost twice on average. The parallel\nversion of the proposed approach is also designed and implemented, the analysis\nshows that the training time decreases significantly when parallel version is\nused.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2015 12:04:30 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Govada", "Aruna", ""], ["Joshi", "Pravin", ""], ["Mittal", "Sahil", ""], ["Sahay", "Sanjay K", ""]]}, {"id": "1512.01609", "submitter": "Xiaohan Wei", "authors": "Xiaohan Wei and Michael J. Neely", "title": "Data Center Server Provision: Distributed Asynchronous Control for\n  Coupled Renewal Systems", "comments": "This is a revised version for IEEE Transactions on Networking", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a cost minimization problem for data centers with N\nservers and randomly arriving service requests. A central router decides which\nserver to use for each new request. Each server has three types of states\n(active, idle, setup) with different costs and time durations. The servers\noperate asynchronously over their own states and can choose one of multiple\nsleep modes when idle. We develop an online distributed control algorithm so\nthat each server makes its own decisions, the request queues are bounded and\nthe overall time average cost is near optimal with probability 1. The algorithm\ndoes not need probability information for the arrival rate or job sizes. Next,\nan improved algorithm that uses a single queue is developed via a\n\"virtualization\" technique which is shown to provide the same (near optimal)\ncosts. Simulation experiments on a real data center traffic trace demonstrate\nthe efficiency of our algorithm compared to other existing algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2015 01:20:24 GMT"}, {"version": "v2", "created": "Sat, 17 Dec 2016 17:47:21 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Wei", "Xiaohan", ""], ["Neely", "Michael J.", ""]]}, {"id": "1512.01625", "submitter": "Songze Li", "authors": "Songze Li and Mohammad Ali Maddah-Ali and A. Salman Avestimehr", "title": "Coded MapReduce", "comments": "16 pages, 6 figures. Parts of this work were presented in 53rd\n  Allerton Conference, Sept. 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MapReduce is a commonly used framework for executing data-intensive jobs on\ndistributed server clusters. We introduce a variant implementation of\nMapReduce, namely \"Coded MapReduce\", to substantially reduce the inter-server\ncommunication load for the shuffling phase of MapReduce, and thus accelerating\nits execution. The proposed Coded MapReduce exploits the repetitive mapping of\ndata blocks at different servers to create coding opportunities in the\nshuffling phase to exchange (key,value) pairs among servers much more\nefficiently. We demonstrate that Coded MapReduce can cut down the total\ninter-server communication load by a multiplicative factor that grows linearly\nwith the number of servers in the system and it achieves the minimum\ncommunication load within a constant multiplicative factor. We also analyze the\ntradeoff between the \"computation load\" and the \"communication load\" of Coded\nMapReduce.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2015 05:47:03 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Li", "Songze", ""], ["Maddah-Ali", "Mohammad Ali", ""], ["Avestimehr", "A. Salman", ""]]}, {"id": "1512.01668", "submitter": "Zhaoyu Dong", "authors": "Zhao Yu Dong", "title": "A Framework for Computing on Large Dynamic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This proposal presents a graph computing framework intending to support both\nonline and offline computing on large dynamic graphs efficiently. The framework\nproposes a new data model to support rich evolving vertex and edge data types.\nIt employs a replica-coherence protocol to improve data locality thus can adapt\nto data access patterns of different algorithms. A new computing model called\nprotocol dataflow is proposed to implement and integrate various programming\nmodels for both online and offline computing on large dynamic graphs. A central\ntopic of the proposal is also the analysis of large real dynamic graphs using\nour proposed framework. Our goal is to calculate the temporal patterns and\nproperties which emerge when the large graphs keep evolving. Thus we can\nevaluate the capability of the proposed framework. Key words: Large dynamic\ngraph, programming model, distributed computing.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2015 14:03:23 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Dong", "Zhao Yu", ""]]}, {"id": "1512.01708", "submitter": "Soham De", "authors": "Soham De, Gavin Taylor, Tom Goldstein", "title": "Variance Reduction for Distributed Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variance reduction (VR) methods boost the performance of stochastic gradient\ndescent (SGD) by enabling the use of larger, constant stepsizes and preserving\nlinear convergence rates. However, current variance reduced SGD methods require\neither high memory usage or an exact gradient computation (using the entire\ndataset) at the end of each epoch. This limits the use of VR methods in\npractical distributed settings. In this paper, we propose a variance reduction\nmethod, called VR-lite, that does not require full gradient computations or\nextra storage. We explore distributed synchronous and asynchronous variants\nthat are scalable and remain stable with low communication frequency. We\nempirically compare both the sequential and distributed algorithms to\nstate-of-the-art stochastic optimization methods, and find that our proposed\nalgorithms perform favorably to other stochastic methods.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2015 22:48:40 GMT"}, {"version": "v2", "created": "Fri, 7 Apr 2017 04:07:29 GMT"}], "update_date": "2017-04-10", "authors_parsed": [["De", "Soham", ""], ["Taylor", "Gavin", ""], ["Goldstein", "Tom", ""]]}, {"id": "1512.01795", "submitter": "Michael Vyalyi", "authors": "I. M. Khuziev, M. N. Vyalyi", "title": "Distributed protocols for spanning tree construction and leader election", "comments": "There are a lot of changes in the second version. Exposition was made\n  more detailed. Protocols are changed to make formal proofs easier and to get\n  a better time bounds. Submitted to Problems of Information Transmission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present fast deterministic distributed protocols in synchronous networks\nfor leader election and spanning tree construction. The protocols are designed\nunder the assumption that nodes in a network have identifiers but the size of\nan identifier is unlimited. So time bounds of protocols depend on the sizes of\nidentifiers. We present fast protocols running in time $O(D\\log L+L)$, where\n$L$ is the size of the minimal identifier and $D$ is the diameter of a network.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2015 14:30:06 GMT"}, {"version": "v2", "created": "Tue, 3 May 2016 15:26:14 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Khuziev", "I. M.", ""], ["Vyalyi", "M. N.", ""]]}, {"id": "1512.01841", "submitter": "Evgeny Nikulchev", "authors": "Evgeny Nikulchev, Evgeniy Pluzhnik, Dmitry Biryukov, Oleg Lukyanchikov", "title": "Designing Applications in a Hybrid Cloud", "comments": "8 pages", "journal-ref": "Contemporary Engineering Sciences 8 (2015) 963-970", "doi": "10.12988/ces.2015.57214", "report-no": null, "categories": "cs.DC cs.DS cs.SE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Designing applications for hybrid cloud has many features, including dynamic\nvirtualization management and route switching. This makes it impossible to\nevaluate the query and hence the optimal distribution of data. In this paper,\nwe formulate the main challenges of designing and simulation, offer\ninstallation for processing.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2015 21:53:30 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Nikulchev", "Evgeny", ""], ["Pluzhnik", "Evgeniy", ""], ["Biryukov", "Dmitry", ""], ["Lukyanchikov", "Oleg", ""]]}, {"id": "1512.01993", "submitter": "Sanjay Sahay", "authors": "Aruna Govada, Shree Ranjani, Aditi Viswanathan and S.K.Sahay", "title": "A Novel Approach to Distributed Multi-Class SVM", "comments": "8 Pages", "journal-ref": "Transactions on Machine Learning and Artificial Intelligence, Vol.\n  2, No. 5, p. 72, 2014", "doi": "10.14738/tmlai.25.562", "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With data sizes constantly expanding, and with classical machine learning\nalgorithms that analyze such data requiring larger and larger amounts of\ncomputation time and storage space, the need to distribute computation and\nmemory requirements among several computers has become apparent. Although\nsubstantial work has been done in developing distributed binary SVM algorithms\nand multi-class SVM algorithms individually, the field of multi-class\ndistributed SVMs remains largely unexplored. This research proposes a novel\nalgorithm that implements the Support Vector Machine over a multi-class dataset\nand is efficient in a distributed environment (here, Hadoop). The idea is to\ndivide the dataset into half recursively and thus compute the optimal Support\nVector Machine for this half during the training phase, much like a divide and\nconquer approach. While testing, this structure has been effectively exploited\nto significantly reduce the prediction time. Our algorithm has shown better\ncomputation time during the prediction phase than the traditional sequential\nSVM methods (One vs. One, One vs. Rest) and out-performs them as the size of\nthe dataset grows. This approach also classifies the data with higher accuracy\nthan the traditional multi-class algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2015 11:44:35 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Govada", "Aruna", ""], ["Ranjani", "Shree", ""], ["Viswanathan", "Aditi", ""], ["Sahay", "S. K.", ""]]}, {"id": "1512.02194", "submitter": "Derek Groen", "authors": "Derek Groen, Agastya Bhati, James Suter, James Hetherington, Stefan\n  Zasada, Peter Coveney", "title": "FabSim: facilitating computational research through automation on\n  large-scale and distributed e-infrastructures", "comments": "29 pages, 8 figures, 2 tables, submitted", "journal-ref": null, "doi": "10.1016/j.cpc.2016.05.020", "report-no": null, "categories": "cs.DC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present FabSim, a toolkit developed to simplify a range of computational\ntasks for researchers in diverse disciplines. FabSim is flexible, adaptable,\nand allows users to perform a wide range of tasks with ease. It also provides a\nsystematic way to automate the use of resourcess, including HPC and distributed\nresources, and to make tasks easier to repeat by recording contextual\ninformation. To demonstrate this, we present three use cases where FabSim has\nenhanced our research productivity. These include simulating cerebrovascular\nbloodflow, modelling clay-polymer nanocomposites across multiple scales, and\ncalculating ligand-protein binding affinities.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2015 20:31:51 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Groen", "Derek", ""], ["Bhati", "Agastya", ""], ["Suter", "James", ""], ["Hetherington", "James", ""], ["Zasada", "Stefan", ""], ["Coveney", "Peter", ""]]}, {"id": "1512.02673", "submitter": "Kangwook Lee", "authors": "Kangwook Lee, Maximilian Lam, Ramtin Pedarsani, Dimitris\n  Papailiopoulos, Kannan Ramchandran", "title": "Speeding Up Distributed Machine Learning Using Codes", "comments": "This work is published in IEEE Transactions on Information Theory and\n  presented in part at the NIPS 2015 Workshop on Machine Learning Systems and\n  the IEEE ISIT 2016", "journal-ref": null, "doi": "10.1109/TIT.2017.2736066", "report-no": null, "categories": "cs.DC cs.IT cs.LG cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Codes are widely used in many engineering applications to offer robustness\nagainst noise. In large-scale systems there are several types of noise that can\naffect the performance of distributed machine learning algorithms -- straggler\nnodes, system failures, or communication bottlenecks -- but there has been\nlittle interaction cutting across codes, machine learning, and distributed\nsystems. In this work, we provide theoretical insights on how coded solutions\ncan achieve significant gains compared to uncoded ones. We focus on two of the\nmost basic building blocks of distributed learning algorithms: matrix\nmultiplication and data shuffling. For matrix multiplication, we use codes to\nalleviate the effect of stragglers, and show that if the number of homogeneous\nworkers is $n$, and the runtime of each subtask has an exponential tail, coded\ncomputation can speed up distributed matrix multiplication by a factor of $\\log\nn$. For data shuffling, we use codes to reduce communication bottlenecks,\nexploiting the excess in storage. We show that when a constant fraction\n$\\alpha$ of the data matrix can be cached at each worker, and $n$ is the number\nof workers, \\emph{coded shuffling} reduces the communication cost by a factor\nof $(\\alpha + \\frac{1}{n})\\gamma(n)$ compared to uncoded shuffling, where\n$\\gamma(n)$ is the ratio of the cost of unicasting $n$ messages to $n$ users to\nmulticasting a common message (of the same size) to $n$ users. For instance,\n$\\gamma(n) \\simeq n$ if multicasting a message to $n$ users is as cheap as\nunicasting a message to one user. We also provide experiment results,\ncorroborating our theoretical gains of the coded algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2015 21:54:04 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2015 19:34:37 GMT"}, {"version": "v3", "created": "Mon, 29 Jan 2018 03:04:14 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Lee", "Kangwook", ""], ["Lam", "Maximilian", ""], ["Pedarsani", "Ramtin", ""], ["Papailiopoulos", "Dimitris", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "1512.02726", "submitter": "Lingxiang Mao", "authors": "Lingxiang Mao", "title": "Information Resources Management Framework for Virtual Enterprise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Virtual enterprise is a new form of organization in recent years which adapt\nto the IT environment. Information resources management implemented in the\nvirtual enterprise is determined by the form of business organization and\ninformation exchange mechanisms. According to the present characteristics of\nvirtual enterprise management, it puts forward the strategies and measures of\ninformation resources management framework for virtual enterprise.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2015 02:31:45 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2015 09:04:30 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Mao", "Lingxiang", ""]]}, {"id": "1512.02727", "submitter": "MohammadHossein Bateni", "authors": "Kevin Aydin and MohammadHossein Bateni and Vahab Mirrokni", "title": "Distributed Balanced Partitioning via Linear Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Balanced partitioning is often a crucial first step in solving large-scale\ngraph optimization problems, e.g., in some cases, a big graph can be chopped\ninto pieces that fit on one machine to be processed independently before\nstitching the results together. In other cases, links between different parts\nmay show up in the running time and/or network communications cost. We study a\ndistributed balanced partitioning problem where the goal is to partition the\nvertices of a given graph into k pieces so as to minimize the total cut size.\nOur algorithm is composed of a few steps that are easily implementable in\ndistributed computation frameworks. The algorithm first embeds nodes of the\ngraph onto a line, and then processes nodes in a distributed manner guided by\nthe linear embedding order. We examine various ways to find the first\nembedding, e.g., via a hierarchical clustering or Hilbert curves. Then we apply\nfour different techniques including local swaps, minimum cuts on the boundaries\nof partitions, as well as contraction and dynamic programming. As our empirical\nstudy, we compare the above techniques with each other, and also to previous\nwork in distributed graph algorithms, e.g., a label propagation method, FENNEL\nand Spinner. We report our results both on a private map graph and several\npublic social networks, and show that our results beat previous distributed\nalgorithms: e.g., compared to the label propagation algorithm, we report an\nimprovement of 15-25% in the cut value. We also observe that our algorithms\nallow for scalable distributed implementation for any number of partitions.\nFinally, we apply our techniques for the Google Maps Driving Directions to\nminimize the number of multi-shard queries with the goal of saving in CPU\nusage. During live experiments, we observe an ~40% drop in the number of\nmulti-shard queries when comparing our method with a standard geography-based\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2015 02:44:51 GMT"}], "update_date": "2015-12-10", "authors_parsed": [["Aydin", "Kevin", ""], ["Bateni", "MohammadHossein", ""], ["Mirrokni", "Vahab", ""]]}, {"id": "1512.02737", "submitter": "Harsha Vardhan  Simhadri", "authors": "Harsha Vardhan Simhadri", "title": "Using Symmetry to Schedule Classical Matrix Multiplication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Presented with a new machine with a specific interconnect topology, algorithm\ndesigners use intuition about the symmetry of the algorithm to design time and\ncommunication-efficient schedules that map the algorithm to the machine. Is\nthere a systematic procedure for designing schedules? We present a new\ntechnique to design schedules for algorithms with no non-trivial dependencies,\nfocusing on the classical matrix multiplication algorithm.\n  We model the symmetry of algorithm with the set of instructions $X$ as the\naction of the group formed by the compositions of bijections from the set $X$\nto itself. We model the machine as the action of the group $N\\times \\Delta$,\nwhere $N$ and $\\Delta$ represent the interconnect topology and time increments\nrespectively, on the set $P\\times T$ of processors iterated over time steps. We\nmodel schedules as symmetry-preserving equivariant maps between the set $X$ and\na subgroup of its symmetry and the set $P\\times T$ with the symmetry\n$N\\times\\Delta$. Such equivariant maps are the solutions of a set of algebraic\nequations involving group homomorphisms. We associate time and communication\ncosts with the solutions to these equations.\n  We solve these equations for the classical matrix multiplication algorithm\nand show that equivariant maps correspond to time- and communication-efficient\nschedules for many topologies. We recover well known variants including the\nCannon's algorithm and the communication-avoiding \"2.5D\" algorithm for toroidal\ninterconnects, systolic computation for planar hexagonal VLSI arrays, recursive\nalgorithms for fat-trees, the cache-oblivious algorithm for the ideal cache\nmodel, and the space-bounded schedule for the parallel memory hierarchy model.\nThis suggests that the design of a schedule for a new class of machines can be\nmotivated by solutions to algebraic equations.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2015 03:34:55 GMT"}], "update_date": "2015-12-10", "authors_parsed": [["Simhadri", "Harsha Vardhan", ""]]}, {"id": "1512.02769", "submitter": "Difrawi Samouriq", "authors": "Samouriq Difrawi", "title": "Scheduling on Grid with communication Delay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel processing, the core of High Performance Computing (HPC), was and\nstill the most effective way in improving the speed of computer systems. For\nthe past few years, the substantial developments in the computing power of\nprocessors and the network speed have strikingly changed the landscape of HPC.\nGeography distributed heterogeneous systems can now cooperate and share\nresources to execute one application. This computing infrastructure is known as\ncomputational Grid or Grid Computing. Grid can be viewed as a distributed\nlarge-scale cluster computing. From other perspective, it constitutes the major\npart of Cloud Computing Systems in addition to thin clients and utility\ncomputing [1,2, 3]. Hence, Grid computing has attracted many researchers [4].\nThe interest in Grid computing has gone beyond the paradigm of traditional Grid\ncomputing to a Wireless Grid computing [5,6].\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2015 07:06:43 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Difrawi", "Samouriq", ""]]}, {"id": "1512.02831", "submitter": "Fabian Gieseke", "authors": "Fabian Gieseke and Cosmin Eugen Oancea and Ashish Mahabal and\n  Christian Igel and Tom Heskes", "title": "Bigger Buffer k-d Trees on Multi-Many-Core Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A buffer k-d tree is a k-d tree variant for massively-parallel nearest\nneighbor search. While providing valuable speed-ups on modern many-core devices\nin case both a large number of reference and query points are given, buffer k-d\ntrees are limited by the amount of points that can fit on a single device. In\nthis work, we show how to modify the original data structure and the associated\nworkflow to make the overall approach capable of dealing with massive data\nsets. We further provide a simple yet efficient way of using multiple devices\ngiven in a single workstation. The applicability of the modified framework is\ndemonstrated in the context of astronomy, a field that is faced with huge\namounts of data.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2015 12:28:12 GMT"}], "update_date": "2015-12-10", "authors_parsed": [["Gieseke", "Fabian", ""], ["Oancea", "Cosmin Eugen", ""], ["Mahabal", "Ashish", ""], ["Igel", "Christian", ""], ["Heskes", "Tom", ""]]}, {"id": "1512.02832", "submitter": "Othon Michail", "authors": "Othon Michail, Paul G. Spirakis", "title": "Connectivity Preserving Network Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Population Protocol model is a distributed model that concerns systems of\nvery weak computational entities that cannot control the way they interact. The\nmodel of Network Constructors is a variant of Population Protocols capable of\n(algorithmically) constructing abstract networks. Both models are characterized\nby a fundamental inability to terminate. In this work, we investigate the\nminimal strengthenings of the latter that could overcome this inability. Our\nmain conclusion is that initial connectivity of the communication topology\ncombined with the ability of the protocol to transform the communication\ntopology plus a few other local and realistic assumptions are sufficient to\nguarantee not only termination but also the maximum computational power that\none can hope for in this family of models. The technique is to transform any\ninitial connected topology to a less symmetric and detectable topology without\never breaking its connectivity during the transformation. The target topology\nof all of our transformers is the spanning line and we call Terminating Line\nTransformation the corresponding problem. We first study the case in which\nthere is a pre-elected unique leader and give a time-optimal protocol for\nTerminating Line Transformation. We then prove that dropping the leader without\nadditional assumptions leads to a strong impossibility result. In an attempt to\novercome this, we equip the nodes with the ability to tell, during their\npairwise interactions, whether they have at least one neighbor in common.\nInterestingly, it turns out that this local and realistic mechanism is\nsufficient to make the problem solvable. In particular, we give a very\nefficient protocol that solves Terminating Line Transformation when all nodes\nare initially identical. The latter implies that the model computes with\ntermination any symmetric predicate computable by a Turing Machine of space\n$\\Theta(n^2)$.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2015 12:28:17 GMT"}], "update_date": "2015-12-10", "authors_parsed": [["Michail", "Othon", ""], ["Spirakis", "Paul G.", ""]]}, {"id": "1512.02970", "submitter": "Soham De", "authors": "Soham De and Tom Goldstein", "title": "Efficient Distributed SGD with Variance Reduction", "comments": "In Proceedings of 2016 IEEE International Conference on Data Mining\n  (ICDM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent (SGD) has become one of the most popular\noptimization methods for training machine learning models on massive datasets.\nHowever, SGD suffers from two main drawbacks: (i) The noisy gradient updates\nhave high variance, which slows down convergence as the iterates approach the\noptimum, and (ii) SGD scales poorly in distributed settings, typically\nexperiencing rapidly decreasing marginal benefits as the number of workers\nincreases. In this paper, we propose a highly parallel method, CentralVR, that\nuses error corrections to reduce the variance of SGD gradient updates, and\nscales linearly with the number of worker nodes. CentralVR enjoys low iteration\ncomplexity, provably linear convergence rates, and exhibits linear performance\ngains up to hundreds of cores for massive datasets. We compare CentralVR to\nstate-of-the-art parallel stochastic optimization methods on a variety of\nmodels and datasets, and find that our proposed methods exhibit stronger\nscaling than other SGD variants.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2015 17:57:31 GMT"}, {"version": "v2", "created": "Tue, 4 Oct 2016 16:03:51 GMT"}, {"version": "v3", "created": "Fri, 7 Apr 2017 02:54:14 GMT"}], "update_date": "2017-04-10", "authors_parsed": [["De", "Soham", ""], ["Goldstein", "Tom", ""]]}, {"id": "1512.02972", "submitter": "Jorge Ortiz", "authors": "Jorge Ortiz (IBM Reserch) and Chien-Chin Huang (NYU Computer Science)\n  and Supriyo Chakraborty (IBM Research)", "title": "Get More With Less: Near Real-Time Image Clustering on Mobile Phones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms, in conjunction with user data, hold the promise\nof revolutionizing the way we interact with our phones, and indeed their\nwidespread adoption in the design of apps bear testimony to this promise.\nHowever, currently, the computationally expensive segments of the learning\npipeline, such as feature extraction and model training, are offloaded to the\ncloud, resulting in an over-reliance on the network and under-utilization of\ncomputing resources available on mobile platforms. In this paper, we show that\nby combining the computing power distributed over a number of phones, judicious\noptimization choices, and contextual information it is possible to execute the\nend-to-end pipeline entirely on the phones at the edge of the network,\nefficiently. We also show that by harnessing the power of this combination, it\nis possible to execute a computationally expensive pipeline at near real-time.\n  To demonstrate our approach, we implement an end-to-end image-processing\npipeline -- that includes feature extraction, vocabulary learning,\nvectorization, and image clustering -- on a set of mobile phones. Our results\nshow a 75% improvement over the standard, full pipeline implementation running\non the phones without modification -- reducing the time to one minute under\ncertain conditions. We believe that this result is a promising indication that\nfully distributed, infrastructure-less computing is possible on networks of\nmobile phones; enabling a new class of mobile applications that are less\nreliant on the cloud.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2015 18:08:59 GMT"}], "update_date": "2015-12-10", "authors_parsed": [["Ortiz", "Jorge", "", "IBM Reserch"], ["Huang", "Chien-Chin", "", "NYU Computer Science"], ["Chakraborty", "Supriyo", "", "IBM Research"]]}, {"id": "1512.02977", "submitter": "Kasim Sinan Yildirim", "authors": "Kasim Sinan Yildirim", "title": "Gradient Descent Algorithm Inspired Adaptive Time Synchronization in\n  Wireless Sensor Networks", "comments": "Submitted for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our motivation in this paper is to take another step forward from complex and\nheavyweight synchronization protocols to the easy-to-implement and lightweight\nsynchronization protocols in WSNs. To this end, we present GraDeS, a novel\nmulti-hop time synchronization protocol based upon gradient descent algorithm.\nWe give details about our implementation of GraDeS and present its experimental\nevaluation in our testbed of MICAz sensor nodes. Our observations indicate that\nGraDeS is scalable, it has identical memory and processing overhead, better\nconvergence time and comparable synchronization performance as compared to\nexisting lightweight solutions.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2015 18:20:45 GMT"}], "update_date": "2015-12-10", "authors_parsed": [["Yildirim", "Kasim Sinan", ""]]}, {"id": "1512.03126", "submitter": "Iain Hepburn", "authors": "I. Hepburn, W. Chen, E. De Schutter", "title": "Accurate Reaction-Diffusion Operator Splitting on Tetrahedral Meshes for\n  Parallel Stochastic Molecular Simulations", "comments": "33 pages, 10 figures", "journal-ref": null, "doi": "10.1063/1.4960034", "report-no": null, "categories": "q-bio.QM cs.DC physics.bio-ph physics.chem-ph q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial stochastic molecular simulations in biology are limited by the\nintense computation required to track molecules in space either in a discrete\ntime or discrete space framework, meaning that the serial limit has already\nbeen reached in sub-cellular models. This calls for parallel simulations that\ncan take advantage of the power of modern supercomputers; however exact methods\nare known to be inherently serial. We introduce an operator splitting\nimplementation for irregular grids with a novel method to improve accuracy, and\ndemonstrate potential for scalable parallel simulations in an initial MPI\nversion. We foresee that this groundwork will enable larger scale, whole-cell\nstochastic simulations in the near future.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2015 02:21:19 GMT"}], "update_date": "2016-08-24", "authors_parsed": [["Hepburn", "I.", ""], ["Chen", "W.", ""], ["De Schutter", "E.", ""]]}, {"id": "1512.03306", "submitter": "Amos Korman", "authors": "Amos Korman (GANG, LIAFA), Jean-S\\'ebastien Sereni (MASCOTTE), Laurent\n  Viennot (GANG, LIAFA, LINCS)", "title": "Toward more localized local algorithms: removing assumptions concerning\n  global knowledge", "comments": null, "journal-ref": "Distributed Computing, Springer Verlag, 2013, 26 (5-6)", "doi": "10.1007/s00446-012-0174-8", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous sophisticated local algorithm were suggested in the literature for\nvarious fundamental problems. Notable examples are the MIS and\n$(\\Delta+1)$-coloring algorithms by Barenboim and Elkin [6], by Kuhn [22], and\nby Panconesi and Srinivasan [34], as well as the $O(\\Delta 2)$-coloring\nalgorithm by Linial [28]. Unfortunately, most known local algorithms\n(including, in particular, the aforementioned algorithms) are non-uniform, that\nis, local algorithms generally use good estimations of one or more global\nparameters of the network, e.g., the maximum degree $\\Delta$ or the number of\nnodes n. This paper provides a method for transforming a non-uniform local\nalgorithm into a uniform one. Furthermore , the resulting algorithm enjoys the\nsame asymp-totic running time as the original non-uniform algorithm. Our method\napplies to a wide family of both deterministic and randomized algorithms.\nSpecifically, it applies to almost all state of the art non-uniform algorithms\nfor MIS and Maximal Matching, as well as to many results concerning the\ncoloring problem. (In particular, it applies to all aforementioned algorithms.)\nTo obtain our transformations we introduce a new distributed tool called\npruning algorithms, which we believe may be of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2015 16:14:59 GMT"}], "update_date": "2015-12-12", "authors_parsed": [["Korman", "Amos", "", "GANG, LIAFA"], ["Sereni", "Jean-S\u00e9bastien", "", "MASCOTTE"], ["Viennot", "Laurent", "", "GANG, LIAFA, LINCS"]]}, {"id": "1512.03487", "submitter": "Peter Boyle", "authors": "Peter Boyle, Azusa Yamaguchi, Guido Cossu, Antonin Portelli", "title": "Grid: A next generation data parallel C++ QCD library", "comments": "14 pages, Lattice 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-lat cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this proceedings we discuss the motivation, implementation details, and\nperformance of a new physics code base called Grid. It is intended to be more\nperformant, more general, but similar in spirit to QDP++\\cite{QDP}. Our\napproach is to engineer the basic type system to be consistently fast, rather\nthan bolt on a few optimised routines, and we are attempt to write all our\noptimised routines directly in the Grid framework. It is hoped this will\ndeliver best known practice performance across the next generation of\nsupercomputers, which will provide programming challenges to traditional scalar\ncodes.\n  We illustrate the programming patterns used to implement our goals, and\nadvances in productivity that have been enabled by using new features in C++11.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2015 23:51:19 GMT"}], "update_date": "2015-12-14", "authors_parsed": [["Boyle", "Peter", ""], ["Yamaguchi", "Azusa", ""], ["Cossu", "Guido", ""], ["Portelli", "Antonin", ""]]}, {"id": "1512.04222", "submitter": "Thomas Nowak", "authors": "Bernadette Charron-Bost and Matthias F\\\"ugger and Thomas Nowak", "title": "Amortized Averaging Algorithms for Approximate Consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new class of distributed algorithms for the approximate\nconsensus problem in dynamic rooted networks, which we call amortized averaging\nalgorithms. They are deduced from ordinary averaging algorithms by adding a\nvalue-gathering phase before each value update. This allows their decision time\nto drop from being exponential in the number $n$ of processes to being linear\nunder the assumption that each process knows $n$. In particular, the amortized\nmidpoint algorithm, which achieves a linear decision time, works in completely\nanonymous dynamic rooted networks where processes can exchange and store\ncontinuous values, and under the assumption that the number of processes is\nknown to all processes. We then study the way amortized averaging algorithms\ndegrade when communication graphs are from time to time non rooted, or with a\nwrong estimate of the number of processes. Finally, we analyze the amortized\nmidpoint algorithm under the additional constraint that processes can only\nstore and send quantized values, and get as a corollary that the 2-set\nconsensus problem is solvable in linear time in any rooted dynamic network\nmodel when allowing all decision values to be in the range of initial values.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2015 09:16:18 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Charron-Bost", "Bernadette", ""], ["F\u00fcgger", "Matthias", ""], ["Nowak", "Thomas", ""]]}, {"id": "1512.04343", "submitter": "Stefan Zasada", "authors": "Stefan J. Zasada and Peter V. Coveney", "title": "A Distributed Multi-agent Market Place for HPC Compute Cycle Resource\n  Trading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer simulation is finding a role in an increasing number of scientific\ndisciplines, concomitant with the rise in available computing power. Realizing\nthis inevitably requires access to computational power beyond the desktop,\nmaking use of clusters, supercomputers, data repositories, networks and\ndistributed aggregations of these resources. Accessing one such resource\nentails a number of usability and security problems; when multiple\ngeographically distributed resources are involved, the difficulty is\ncompounded.\n  This presents the user with the problem of how to gain access to suitable\nresources to run their workloads as they need them. In this paper we present\nour solutions to this problem, a resource trading platform that allows users to\npurchase access to resources within a distributed e-infrastructure. We present\nthe implementation of this Resource Allocation Market Place as a distributed\nmulti-agent system, and show how it provides a highly flexible, efficient tool\nto schedule workflows across high performance computing resources.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2015 14:48:10 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Zasada", "Stefan J.", ""], ["Coveney", "Peter V.", ""]]}, {"id": "1512.04629", "submitter": "Luke Olson", "authors": "Amanda Bienz, Robert D. Falgout William Gropp, Luke N. Olson, Jacob B.\n  Schroder", "title": "Reducing Parallel Communication in Algebraic Multigrid through\n  Sparsification", "comments": "27 pages, 19 figures, submitted to SISC, multigrid, algebraic\n  multigrid, non-Galerkin multigrid, high performance computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algebraic multigrid (AMG) is an $\\mathcal{O}(n)$ solution process for many\nlarge sparse linear systems. A hierarchy of progressively coarser grids is\nconstructed that utilize complementary relaxation and interpolation operators.\nHigh-energy error is reduced by relaxation, while low-energy error is mapped to\ncoarse-grids and reduced there. However, large parallel communication costs\noften limit parallel scalability. As the multigrid hierarchy is formed, each\ncoarse matrix is formed through a triple matrix product. The resulting\ncoarse-grids often have significantly more nonzeros per row than the original\nfine-grid operator, thereby generating high parallel communication costs on\ncoarse-levels. In this paper, we introduce a method that systematically removes\nentries in coarse-grid matrices after the hierarchy is formed, leading to an\nimproved communication costs. We sparsify by removing weakly connected or\nunimportant entries in the matrix, leading to improved solve time. The main\ntrade-off is that if the heuristic identifying unimportant entries is used too\naggressively, then AMG convergence can suffer. To counteract this, the original\nhierarchy is retained, allowing entries to be reintroduced into the solver\nhierarchy if convergence is too slow. This enables a balance between\ncommunication cost and convergence, as necessary. In this paper we present new\nalgorithms for reducing communication and present a number of computational\nexperiments in support.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2015 02:39:00 GMT"}], "update_date": "2015-12-16", "authors_parsed": [["Bienz", "Amanda", ""], ["Gropp", "Robert D. Falgout William", ""], ["Olson", "Luke N.", ""], ["Schroder", "Jacob B.", ""]]}, {"id": "1512.04832", "submitter": "Amos Korman", "authors": "Liah Kor, Amos Korman (GANG, LIAFA), David Peleg", "title": "Tight Bounds for Distributed Minimum-Weight Spanning Tree Verification", "comments": null, "journal-ref": "Theory of Computing Systems, Springer Verlag, 2013,\n  \\&lt;10.1007/s00224-013-9479-7\\&gt;", "doi": "10.1007/s00224-013-9479-7", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the notion of distributed verification without\npreprocessing. It focuses on the Minimum-weight Spanning Tree (MST)\nverification problem and establishes tight upper and lower bounds for the time\nand message complexities of this problem. Specifically, we provide an MST\nverification algorithm that achieves simultaneously O(m) messages and O($\\sqrt$\nn+D) time, where m is the number of edges in the given graph G, n is the number\nof nodes, and D is G's diameter. On the other hand, we show that any MST\nverification algorithm must send {\\Omega}(m) messages and incur\n{\\Omega}($\\sqrt$ n + D) time in worst case. Our upper bound result appears to\nindicate that the verification of an MST may be easier than its construction,\nsince for MST construction, both lower bounds of {\\Omega}(m) messages and\n{\\Omega}($\\sqrt$ n+D time hold, but at the moment there is no known distributed\nalgorithm that constructs an MST and achieves simultaneously O(m) messages and\nO($\\sqrt$ n + D) time. Specifically, the best known time-optimal algorithm\n(using O($\\sqrt$ n + D) time) requires O(m + n 3/2) messages, and the best\nknown message-optimal algorithm (using O(m) messages) requires O(n) time. On\nthe other hand, our lower bound results indicate that the verification of an\nMST is not significantly easier than its construction.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2015 16:01:53 GMT"}], "update_date": "2015-12-16", "authors_parsed": [["Kor", "Liah", "", "GANG, LIAFA"], ["Korman", "Amos", "", "GANG, LIAFA"], ["Peleg", "David", ""]]}, {"id": "1512.04898", "submitter": "Christopher Meiklejohn", "authors": "Christopher Meiklejohn", "title": "Declarative, Secure, Convergent Edge Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eventual consistency is a more natural model than strong consistency for a\ndistributed system, since it is closer to the underlying physical reality.\nTherefore, we propose that it is important to find a programming model that is\nboth congenial to developers and supports eventual consistency. In particular,\nwe consider that a crucial test for such a model is that it should support edge\ncomputation in a both natural and secure way. We present a preliminary work\nreport with an initial solution, called Lasp, which resembles a concurrent\nfunctional language while naturally supporting an eventually consistent\ncoordination-free distribution model.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2015 19:00:39 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2015 02:06:19 GMT"}], "update_date": "2015-12-17", "authors_parsed": [["Meiklejohn", "Christopher", ""]]}, {"id": "1512.05172", "submitter": "Steven Weber", "authors": "Ni An and Steven Weber", "title": "On the performance overhead tradeoff of distributed principal component\n  analysis via data partitioning", "comments": "6 pages, 6 figures, submitted to CISS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is not only a fundamental dimension\nreduction method, but is also a widely used network anomaly detection\ntechnique. Traditionally, PCA is performed in a centralized manner, which has\npoor scalability for large distributed systems, on account of the large network\nbandwidth cost required to gather the distributed state at a fusion center.\nConsequently, several recent works have proposed various distributed PCA\nalgorithms aiming to reduce the communication overhead incurred by PCA without\nlosing its inferential power. This paper evaluates the tradeoff between\ncommunication cost and solution quality of two distributed PCA algorithms on a\nreal domain name system (DNS) query dataset from a large network. We also apply\nthe distributed PCA algorithm in the area of network anomaly detection and\ndemonstrate that the detection accuracy of both distributed PCA-based methods\nhas little degradation in quality, yet achieves significant savings in\ncommunication bandwidth.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2015 13:35:47 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2015 14:07:29 GMT"}, {"version": "v3", "created": "Mon, 21 Dec 2015 13:01:59 GMT"}], "update_date": "2015-12-22", "authors_parsed": [["An", "Ni", ""], ["Weber", "Steven", ""]]}, {"id": "1512.05264", "submitter": "Pier Stanislao Paolucci", "authors": "Elena Pastorelli, Pier Stanislao Paolucci, Roberto Ammendola, Andrea\n  Biagioni, Ottorino Frezza, Francesca Lo Cicero, Alessandro Lonardo, Michele\n  Martinelli, Francesco Simula, Piero Vicini", "title": "Impact of exponential long range and Gaussian short range lateral\n  connectivity on the distributed simulation of neural networks including up to\n  30 billion synapses", "comments": "6 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent experimental neuroscience studies are pointing out the role of\nlong-range intra-areal connectivity that can be modeled by a distance dependent\nexponential decay of the synaptic probability distribution. This short report\nprovides a preliminary measure of the impact of exponentially decaying lateral\nconnectivity compared to that of shorter-range Gaussian decays on the scaling\nbehaviour and memory occupation of a distributed spiking neural network\nsimulator (DPSNN). Two-dimensional grids of cortical columns composed by\npoint-like spiking neurons have been connected by up to 30 billion synapses\nusing exponential and Gaussian connectivity models. Up to 1024 hardware cores,\nhosted on a 64 nodes server platform, executed the MPI processes composing the\ndistributed simulator. The hardware platform was a cluster of IBM NX360 M5\n16-core compute nodes, each one containing two Intel Xeon Haswell 8-core\nE5-2630 v3 processors, with a clock of 2.40GHz, interconnected through an\nInfiniBand network. This study is conducted in the framework of the CORTICONIC\nFET project, also in view of the next -to-start activities foreseen as part of\nthe Human Brain Project (HBP), SubProject 3 Cognitive and Systems Neuroscience,\nWaveScalES work-package.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2015 18:03:20 GMT"}], "update_date": "2015-12-17", "authors_parsed": [["Pastorelli", "Elena", ""], ["Paolucci", "Pier Stanislao", ""], ["Ammendola", "Roberto", ""], ["Biagioni", "Andrea", ""], ["Frezza", "Ottorino", ""], ["Cicero", "Francesca Lo", ""], ["Lonardo", "Alessandro", ""], ["Martinelli", "Michele", ""], ["Simula", "Francesco", ""], ["Vicini", "Piero", ""]]}, {"id": "1512.05306", "submitter": "Giuseppe Antonio Di Luna", "authors": "Giuseppe Antonio Di Luna, Stefan Dobrev, Paola Flocchini, Nicola\n  Santoro", "title": "Live Exploration of Dynamic Rings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the graph exploration problem, a team of mobile computational entities,\ncalled agents, arbitrarily positioned at some nodes of a graph, must cooperate\nso that each node is eventually visited by at least one agent. In the\nliterature, the main focus has been on graphs that are static; that is, the\ntopology is either invariant in time or subject to localized changes. The few\nstudies on exploration of dynamic graphs have been almost all limited to the\ncentralized case (i.e., assuming complete a priori knowledge of the changes and\nthe times of their occurrence). We investigate the decentralized exploration of\ndynamic graphs (i.e., when the agents are unaware of the location and timing of\nthe changes) focusing, in this paper, on dynamic systems whose underlying graph\nis a ring. We first consider the fully-synchronous systems traditionally\nassumed in the literature; i.e., all agents are active at each time step. We\nthen introduce the notion of semi-synchronous systems, where only a subset of\nagents might be active at each time step (the choice of the subset is made by\nan adversary); this model is common in the context of mobile agents in\ncontinuous spaces but has never been studied before for agents moving in\ngraphs. Our main focus is on the impact that the level of synchrony as well as\nother factors such as anonymity, knowledge of the size of the ring, and\nchirality (i.e., common orientation) have on the solvability of the problem,\nfocusing on the minimum number of agents necessary. We draw an extensive map of\nfeasibility, and of complexity in terms of minimum number of agent movements.\nAll our sufficiency proofs are constructive, and almost all our solution\nprotocols are asymptotically optimal.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2015 19:58:32 GMT"}, {"version": "v2", "created": "Wed, 30 Mar 2016 21:14:57 GMT"}, {"version": "v3", "created": "Mon, 27 Jun 2016 07:06:11 GMT"}, {"version": "v4", "created": "Fri, 18 May 2018 07:53:34 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Di Luna", "Giuseppe Antonio", ""], ["Dobrev", "Stefan", ""], ["Flocchini", "Paola", ""], ["Santoro", "Nicola", ""]]}, {"id": "1512.05427", "submitter": "Sergio Rajsbaum", "authors": "Fernando Benavides and Sergio Rajsbaum", "title": "The read/write protocol complex is collapsible", "comments": "Full version of Springer LNCS Proceedings of LATIN 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The celebrated \\emph{asynchronous computability theorem} provides a\ncharacterization of the class of decision tasks that can be solved in a\nwait-free manner by asynchronous processes that communicate by writing and\ntaking atomic snapshots of a shared memory. Several variations of the model\nhave been proposed (immediate snapshots and iterated immediate snapshots), all\nequivalent for wait-free solution of decision tasks, in spite of the fact that\nthe protocol complexes that arise from the different models are structurally\ndistinct. The topological and combinatorial properties of these snapshot\nprotocol complexes have been studied in detail, providing explanations for why\nthe asynchronous computability theorem holds in all the models.\n  In reality concurrent systems do not provide processes with snapshot\noperations. Instead, snapshots are implemented (by a wait-free protocol) using\noperations that write and read individual shared memory locations. Thus,\nread/write protocols are also computationally equivalent to snapshot protocols.\nHowever, the structure of the read/write protocol complex has not been studied.\nIn this paper we show that the read/write iterated protocol complex is\ncollapsible (and hence contractible). Furthermore, we show that a distributed\nprotocol that wait-free implements atomic snapshots in effect is performing the\ncollapses.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2015 01:06:36 GMT"}], "update_date": "2015-12-18", "authors_parsed": [["Benavides", "Fernando", ""], ["Rajsbaum", "Sergio", ""]]}, {"id": "1512.05578", "submitter": "Aare M\\\"allo PhD", "authors": "Peter Brauer, Martin Lundqvist, Aare M\\\"allo (Ericsson AB, G\\\"oteborg,\n  Sweden)", "title": "Improving Latency in a Signal Processing System on the Epiphany\n  Architecture", "comments": "Draft paper submitted to and accepted by PDP 2016, 24th Euromicro\n  International Conference on Parallel, Distributed and Network-Based\n  Processing. Heraklion Crete, Greece, 17th-19th February 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we use the Adapteva Epiphany manycore chip to demonstrate how\nthe throughput and the latency of a baseband signal processing chain, typically\nfound in LTE or WiFi, can be optimized by a combination of task- and data\nparallelization, and data pipelining. The parallelization and data pipelining\nare facilitated by the shared memory architecture of the Epiphany, and the fact\nthat a processor on one core can write directly into the memory of any other\ncore on the chip.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2015 13:46:07 GMT"}], "update_date": "2015-12-18", "authors_parsed": [["Brauer", "Peter", "", "Ericsson AB, G\u00f6teborg,\n  Sweden"], ["Lundqvist", "Martin", "", "Ericsson AB, G\u00f6teborg,\n  Sweden"], ["M\u00e4llo", "Aare", "", "Ericsson AB, G\u00f6teborg,\n  Sweden"]]}, {"id": "1512.05827", "submitter": "Matthew Swisher", "authors": "Matthew Swisher", "title": "HALO: Report and Predicted Response Times", "comments": "3 pages, 2 charts, Report on HALO: Heterogeneity-Aware Load Balancing\n  for independent study at O.S.U", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HALO: Heterogeneity-Aware Load Balancing is a paper that proposes a class of\nheterogeneity-aware Load Balancers (LBs) for cluster systems. LBs that are\nheterogeneity-aware are able to detect when servers differ in speeds and in\nnumber of cores. Response times for heterogeneous systems are calculated and\npresented.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2015 23:46:12 GMT"}], "update_date": "2015-12-21", "authors_parsed": [["Swisher", "Matthew", ""]]}, {"id": "1512.05864", "submitter": "K\\'evin Atighehchi", "authors": "Kevin Atighehchi and Robert Rolland", "title": "Optimization of Tree Modes for Parallel Hash Functions: A Case Study", "comments": "Preprint version. Added citations, IEEE Transactions on Computers,\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on parallel hash functions based on tree modes of\noperation for an inner Variable-Input-Length function. This inner function can\nbe either a single-block-length (SBL) and prefix-free MD hash function, or a\nsponge-based hash function. We discuss the various forms of optimality that can\nbe obtained when designing parallel hash functions based on trees where all\nleaves have the same depth. The first result is a scheme which optimizes the\ntree topology in order to decrease the running time. Then, without affecting\nthe optimal running time we show that we can slightly change the corresponding\ntree topology so as to minimize the number of required processors as well.\nConsequently, the resulting scheme decreases in the first place the running\ntime and in the second place the number of required processors.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2015 07:29:03 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2016 19:11:33 GMT"}, {"version": "v3", "created": "Fri, 11 Mar 2016 08:51:24 GMT"}, {"version": "v4", "created": "Thu, 31 Mar 2016 16:58:27 GMT"}, {"version": "v5", "created": "Sat, 18 Jun 2016 15:09:55 GMT"}, {"version": "v6", "created": "Fri, 13 Jan 2017 17:27:26 GMT"}, {"version": "v7", "created": "Sun, 11 Jun 2017 10:25:50 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Atighehchi", "Kevin", ""], ["Rolland", "Robert", ""]]}, {"id": "1512.06168", "submitter": "Jose Faleiro", "authors": "Kun Ren, Jose M. Faleiro, Daniel J. Abadi", "title": "Design Principles for Scaling Multi-core OLTP Under High Contention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although significant recent progress has been made in improving the\nmulti-core scalability of high throughput transactional database systems,\nmodern systems still fail to achieve scalable throughput for workloads\ninvolving frequent access to highly contended data. Most of this inability to\nachieve high throughput is explained by the fundamental constraints involved in\nguaranteeing ACID --- the addition of cores results in more concurrent\ntransactions accessing the same contended data for which access must be\nserialized in order to guarantee isolation. Thus, linear scalability for\ncontended workloads is impossible. However, there exist flaws in many modern\narchitectures that exacerbate their poor scalability, and result in throughput\nthat is much worse than fundamentally required by the workload.\n  In this paper we identify two prevalent design principles that limit the\nmulti-core scalability of many (but not all) transactional database systems on\ncontended workloads: the multi-purpose nature of execution threads in these\nsystems, and the lack of advanced planning of data access. We demonstrate the\ndeleterious results of these design principles by implementing a prototype\nsystem, ORTHRUS, that is motivated by the principles of separation of database\ncomponent functionality and advanced planning of transactions. We find that\nthese two principles alone result in significantly improved scalability on\nhigh-contention workloads, and an order of magnitude increase in throughput for\na non-trivial subset of these contended workloads.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2015 00:24:59 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2016 19:00:15 GMT"}, {"version": "v3", "created": "Tue, 5 Jan 2016 16:41:08 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Ren", "Kun", ""], ["Faleiro", "Jose M.", ""], ["Abadi", "Daniel J.", ""]]}, {"id": "1512.06216", "submitter": "Hao Zhang", "authors": "Hao Zhang, Zhiting Hu, Jinliang Wei, Pengtao Xie, Gunhee Kim, Qirong\n  Ho and Eric Xing", "title": "Poseidon: A System Architecture for Efficient GPU-based Deep Learning on\n  Multiple Machines", "comments": "14 pages, 8 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) has achieved notable successes in many machine learning\ntasks. A number of frameworks have been developed to expedite the process of\ndesigning and training deep neural networks (DNNs), such as Caffe, Torch and\nTheano. Currently they can harness multiple GPUs on a single machine, but are\nunable to use GPUs that are distributed across multiple machines; as even\naverage-sized DNNs can take days to train on a single GPU with 100s of GBs to\nTBs of data, distributed GPUs present a prime opportunity for scaling up DL.\nHowever, the limited bandwidth available on commodity Ethernet networks\npresents a bottleneck to distributed GPU training, and prevents its trivial\nrealization.\n  To investigate how to adapt existing frameworks to efficiently support\ndistributed GPUs, we propose Poseidon, a scalable system architecture for\ndistributed inter-machine communication in existing DL frameworks. We integrate\nPoseidon with Caffe and evaluate its performance at training DNNs for object\nrecognition. Poseidon features three key contributions that accelerate DNN\ntraining on clusters: (1) a three-level hybrid architecture that allows\nPoseidon to support both CPU-only and GPU-equipped clusters, (2) a distributed\nwait-free backpropagation (DWBP) algorithm to improve GPU utilization and to\nbalance communication, and (3) a structure-aware communication protocol (SACP)\nto minimize communication overheads. We empirically show that Poseidon\nconverges to same objectives as a single machine, and achieves state-of-art\ntraining speedup across multiple models and well-established datasets using a\ncommodity GPU cluster of 8 nodes (e.g. 4.5x speedup on AlexNet, 4x on\nGoogLeNet, 4x on CIFAR-10). On the much larger ImageNet22K dataset, Poseidon\nwith 8 nodes achieves better speedup and competitive accuracy to recent\nCPU-based distributed systems such as Adam and Le et al., which use 10s to\n1000s of nodes.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2015 09:55:37 GMT"}], "update_date": "2015-12-22", "authors_parsed": [["Zhang", "Hao", ""], ["Hu", "Zhiting", ""], ["Wei", "Jinliang", ""], ["Xie", "Pengtao", ""], ["Kim", "Gunhee", ""], ["Ho", "Qirong", ""], ["Xing", "Eric", ""]]}, {"id": "1512.06227", "submitter": "Damien Imbs", "authors": "Zohir Bouzid, Damien Imbs, Michel Raynal", "title": "A Necessary Condition for Byzantine $k$-Set Agreement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short paper presents a necessary condition for Byzantine $k$-set\nagreement in (synchronous or asynchronous) message-passing systems and\nasynchronous shared memory systems where the processes communicate through\natomic single-writer multi-reader registers. It gives a proof, which is\nparticularly simple, that $k$-set agreement cannot be solved $t$-resiliently in\nan $n$-process system when $n \\leq 2t + \\frac{t}{k}$. This bound is tight for\nthe case $k=1$ (Byzantine consensus) in synchronous message-passing systems.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2015 11:39:23 GMT"}], "update_date": "2015-12-22", "authors_parsed": [["Bouzid", "Zohir", ""], ["Imbs", "Damien", ""], ["Raynal", "Michel", ""]]}, {"id": "1512.06257", "submitter": "Lina Yao", "authors": "Lina Yao, Quan Z. Sheng, Boualem Benatallah, Schahram Dustdar, Xianzhi\n  Wang, Ali Shemshadi, and Anne H.H. Ngu", "title": "Up in the Air: When Homes Meet the Web of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging Internet of Things (IoT) will comprise billions of Web-enabled\nobjects (or \"things\") where such objects can sense, communicate, compute and\npotentially actuate. WoT is essentially the embodiment of the evolution from\nsystems linking digital documents to systems relating digital information to\nreal-world physical items. It is widely understood that significant technical\nchallenges exist in developing applications in the WoT environment. In this\npaper, we report our practical experience in the design and development of a\nsmart home system in a WoT environment. Our system provides a layered framework\nfor managing and sharing the information produced by physical things as well as\nthe residents. We particularly focus on a research prototype named WITS, that\nhelps the elderly live independently and safely in their own homes, with\nminimal support from the decreasing number of individuals in the working-age\npopulation. WITS enables an unobtrusive monitoring of elderly people in a\nreal-world, inhabituated home environment, by leveraging WoT technologies in\nbuilding context-aware, personalized services.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2015 14:56:55 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2015 10:29:50 GMT"}, {"version": "v3", "created": "Tue, 18 Jul 2017 05:12:49 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Yao", "Lina", ""], ["Sheng", "Quan Z.", ""], ["Benatallah", "Boualem", ""], ["Dustdar", "Schahram", ""], ["Wang", "Xianzhi", ""], ["Shemshadi", "Ali", ""], ["Ngu", "Anne H. H.", ""]]}, {"id": "1512.06425", "submitter": "Muhammad Shafique", "authors": "Muhammad Shafique", "title": "Content-based Dynaic Routing in Structured Overlays Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acyclic overlays used for broker-based publish/subscribe systems provide\nunique paths for content-based routing from a publisher to interested\nsubscribers. Cyclic overlays may provide multiple paths, however, the\nsubscription broadcast process generates one content-based routing path per\nsubscription. This poses serious challenges in offering dynamic routing of\nnotifications when congestion is detected because instantaneous updates in\nrouting tables are required to generate alternative routing paths. This paper\nintroduces the first subscription-based publish/subscribe system, OctopiS,\nwhich offers inter-cluster dynamic routing when congestion in the output queues\nis detected. OctopiS is based on a formally defined Structured Cyclic Overlay\nTopology (SCOT). SCOT is divided into homogeneous clusters where each cluster\nhas equal number of brokers and connects to other clusters through multiple\ninter-cluster overlay links. These links are used to provide parallel routing\npaths between publishers and subscribers connected to brokers in different\nclusters. While aiming at deployment at data center networks, OctopiS generates\nsubscription-trees of shortest lengths used by Static Notification Routing\n(SNR) algorithm. Dynamic Notification Routing (DNR) algorithm uses a bit-vector\nmechanism to exploit the structuredness of a clustered SCOT to offer\ninter-cluster dynamic routing without making updates in routing tables and\nminimizing load on overwhelmed brokers and congested links. Experiments on a\ncluster testbed with real world data show that OctopiS is scalable and reduces\nthe number of inter-broker messages in subscription delivery by 89%,\nsubscription delay by 77%, end-to-end notification delay in static and dynamic\nrouting by 47% and 58% respectively, and the lengths of output queues of\nbrokers in dynamic routing paths by 59%.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2015 20:03:03 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 18:24:11 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Shafique", "Muhammad", ""]]}, {"id": "1512.06432", "submitter": "Ioannis Papapanagiotou", "authors": "Zhihao Yao and Ioannis Papapanagiotou and Rean Griffith", "title": "Serifos: Workload Consolidation and Load Balancing for SSD Based Cloud\n  Storage Systems", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving high performance in virtualized data centers requires both\ndeploying high throughput storage clusters, i.e. based on Solid State Disks\n(SSDs), as well as optimally consolidating the workloads across storage nodes.\nNowadays, the only practical solution for cloud storage providers to offer\nguaranteed performance is to grossly over-provision the storage nodes. The\ncurrent workload scheduling mechanisms used in production do not have the\nintelligence to optimally allocate block storage volumes based on the\nperformance of SSDs. In this paper, we introduce Serifos, an autonomous\nperformance modeling and load balancing system designed for SSD-based cloud\nstorage. Serifos takes into account the characteristics of the SSD storage\nunits and constructs hardware dependent workload consolidation models. Thus\nSerifos is able to predict the latency caused by workload interference and the\naverage latency of concurrent workloads. Furthermore, Serifos leverages an I/O\nload balancing algorithm to dynamically balance the volumes across the cluster.\nExperimental results indicate that Serifos consolidation model is able to\nmaintain the mean prediction error of around 10% for heterogeneous hardware. As\na result of Serifos load balancing, we found that the variance and the maximum\naverage latency are reduced by 82% and 52%, respectively. The supported Service\nLevel Objectives (SLOs) on the testbed improve 43% on average latency, 32% on\nthe maximum read and 63% on the maximum write latency.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2015 20:53:55 GMT"}, {"version": "v2", "created": "Fri, 25 Dec 2015 18:24:14 GMT"}], "update_date": "2015-12-29", "authors_parsed": [["Yao", "Zhihao", ""], ["Papapanagiotou", "Ioannis", ""], ["Griffith", "Rean", ""]]}, {"id": "1512.06593", "submitter": "Alexander Setzer", "authors": "Christian Scheideler, Alexander Setzer, Thim Strothmann", "title": "Towards Establishing Monotonic Searchability in Self-Stabilizing Data\n  Structures (full version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed applications are commonly based on overlay networks\ninterconnecting their sites so that they can exchange information. For these\noverlay networks to preserve their functionality, they should be able to\nrecover from various problems like membership changes or faults. Various\nself-stabilizing overlay networks have already been proposed in recent years,\nwhich have the advantage of being able to recover from any illegal state, but\nnone of these networks can give any guarantees on its functionality while the\nrecovery process is going on. We initiate research on overlay networks that are\nnot only self-stabilizing but that also ensure that searchability is maintained\nwhile the recovery process is going on, as long as there are no corrupted\nmessages in the system. More precisely, once a search message from node $u$ to\nanother node $v$ is successfully delivered, all future search messages from $u$\nto $v$ succeed as well. We call this property monotonic searchability. We show\nthat in general it is impossible to provide monotonic searchability if\ncorrupted messages are present in the system, which justifies the restriction\nto system states without corrupted messages. Furthermore, we provide a\nself-stabilizing protocol for the line for which we can also show monotonic\nsearchability. It turns out that even for the line it is non-trivial to achieve\nthis property. Additionally, we extend our protocol to deal with node\ndepartures in terms of the Finite Departure Problem of Foreback et. al (SSS\n2014). This makes our protocol even capable of handling node dynamics.\n  This is the full version of a correspondent paper published at OPODIS'15.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2015 12:05:10 GMT"}], "update_date": "2015-12-22", "authors_parsed": [["Scheideler", "Christian", ""], ["Setzer", "Alexander", ""], ["Strothmann", "Thim", ""]]}, {"id": "1512.06637", "submitter": "G\\'abor B\\'ir\\'o", "authors": "G\\'abor B\\'ir\\'o and Gergely G\\'abor Barnaf\\\"oldi and Endre Fut\\'o\n  (for the GeantV Collaboration)", "title": "On the Way to Future's High Energy Particle Physics Transport Code", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High Energy Physics (HEP) needs a huge amount of computing resources. In\naddition data acquisition, transfer, and analysis require a well developed\ninfrastructure too. In order to prove new physics disciplines it is required to\nhigher the luminosity of the accelerator facilities, which produce\nmore-and-more data in the experimental detectors. Both testing new theories and\ndetector R&D are based on complex simulations. Today have already reach that\nlevel, the Monte Carlo detector simulation takes much more time than real data\ncollection. This is why speed up of the calculations and simulations became\nimportant in the HEP community. The Geant Vector Prototype (GeantV) project\naims to optimize the most-used particle transport code applying parallel\ncomputing and to exploit the capabilities of the modern CPU and GPU\narchitectures as well. With the maximized concurrency at multiple levels the\nGeantV is intended to be the successor of the Geant4 particle transport code\nthat has been used since two decades successfully. Here we present our latest\nresult on the GeantV tests performances, comparing CPU/GPU based vectorized\nGeantV geometrical code to the Geant4 version.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2015 14:21:41 GMT"}, {"version": "v2", "created": "Thu, 26 May 2016 16:18:42 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["B\u00edr\u00f3", "G\u00e1bor", "", "for the GeantV Collaboration"], ["Barnaf\u00f6ldi", "Gergely G\u00e1bor", "", "for the GeantV Collaboration"], ["Fut\u00f3", "Endre", "", "for the GeantV Collaboration"]]}, {"id": "1512.06947", "submitter": "EPTCS", "authors": "Jos\\'e Proen\\c{c}a, Massimo Tivoli", "title": "Proceedings 14th International Workshop on Foundations of Coordination\n  Languages and Self-Adaptive Systems", "comments": null, "journal-ref": "EPTCS 201, 2015", "doi": "10.4204/EPTCS.201", "report-no": null, "categories": "cs.DC cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of FOCLASA 2015, the 14th International\nWorkshop on the Foundations of Coordination Languages and Self-Adaptive\nSystems. FOCLASA 2015 was held in Madrid, Spain, on September 5, 2015 as a\nsatellite event of CONCUR 2015, the 26th International Conference on\nConcurrency Theory.\n  Modern software systems are distributed, concurrent, mobile, and often\ninvolve composition of heterogeneous components and stand-alone services.\nService coordination and self-adaptation constitute the core characteristics of\ndistributed and service-oriented systems. Coordination languages and formal\napproaches to modelling and reasoning about self-adaptive behaviour help to\nsimplify the development of complex distributed service-based systems, enable\nfunctional correctness proofs, automated synthesis of correct-by-construction\nsystems, and improve reusability and maintainability of such systems. The goal\nof the FOCLASA workshop is to put together researchers and practitioners of the\naforementioned fields, to share and identify common problems, and to devise\ngeneral solutions in the context of coordination languages and self-adaptive\nsystems.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 03:30:13 GMT"}], "update_date": "2015-12-23", "authors_parsed": [["Proen\u00e7a", "Jos\u00e9", ""], ["Tivoli", "Massimo", ""]]}, {"id": "1512.06989", "submitter": "Amos Korman", "authors": "Pierre Fraigniaud (LIAFA, GANG), Magn\\'us Halld\\'orsson, Amos Korman\n  (LIAFA, GANG)", "title": "On the Impact of Identifiers on Local Decision", "comments": "Principles of Distributed Systems, 16th International Conference, Dec\n  2012, Rome, Italy", "journal-ref": null, "doi": "10.1007/978-3-642-35476-2_16", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The issue of identifiers is crucial in distributed computing. Informally,\nidentities are used for tackling two of the fundamental difficulties that\nareinherent to deterministic distributed computing, namely: (1) symmetry\nbreaking, and (2) topological information gathering. In the context of local\ncomputation, i.e., when nodes can gather information only from nodes at bounded\ndistances, some insight regarding the role of identities has been established.\nFor instance, it was shown that, for large classes of construction problems,\nthe role of the identities can be rather small. However, for theidentities to\nplay no role, some other kinds of mechanisms for breaking symmetry must be\nemployed, such as edge-labeling or sense of direction. When it comes to local\ndistributed decision problems, the specification of the decision task does not\nseem to involve symmetry breaking. Therefore, it is expected that, assuming\nnodes can gather sufficient information about their neighborhood, one could get\nrid of the identities, without employing extra mechanisms for breaking\nsymmetry. We tackle this question in the framework of the $\\local$ model. Let\n$\\LD$ be the class of all problems that can be decided in a constant number of\nrounds in the $\\local$ model. Similarly, let $\\LD^*$ be the class of all\nproblems that can be decided at constant cost in the anonymous variant of the\n$\\local$ model, in which nodes have no identities, but each node can get access\nto the (anonymous) ball of radius $t$ around it, for any $t$, at a cost of $t$.\nIt is clear that $\\LD^*\\subseteq \\LD$. We conjecture that $\\LD^*=\\LD$. In this\npaper, we give several evidences supporting this conjecture. In particular, we\nshow that it holds for hereditary problems, as well as when the nodes know an\narbitrary upper bound on the total number of nodes. Moreover, we prove that the\nconjecture holds in the context of non-deterministic local decision, where\nnodes are given certificates (independent of the identities, if they exist),\nand the decision consists in verifying these certificates. In short, we prove\nthat $\\NLD^*=\\NLD$.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 09:21:52 GMT"}], "update_date": "2015-12-23", "authors_parsed": [["Fraigniaud", "Pierre", "", "LIAFA, GANG"], ["Halld\u00f3rsson", "Magn\u00fas", "", "LIAFA, GANG"], ["Korman", "Amos", "", "LIAFA, GANG"]]}, {"id": "1512.07021", "submitter": "Alexander Sch\\\"atzle", "authors": "Alexander Sch\\\"atzle, Martin Przyjaciel-Zablocki, Simon Skilevic,\n  Georg Lausen", "title": "S2RDF: RDF Querying with SPARQL on Spark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RDF has become very popular for semantic data publishing due to its flexible\nand universal graph-like data model. Yet, the ever-increasing size of RDF data\ncollections makes it more and more infeasible to store and process them on a\nsingle machine, raising the need for distributed approaches. Instead of\nbuilding a standalone but closed distributed RDF store, we endorse the usage of\nexisting infrastructures for Big Data processing, e.g. Hadoop. However, SPARQL\nquery performance is a major challenge as these platforms are not designed for\nRDF processing from ground. Thus, existing Hadoop-based approaches often favor\ncertain query pattern shape while performance drops significantly for other\nshapes. In this paper, we describe a novel relational partitioning schema for\nRDF data called ExtVP that uses a semi-join based preprocessing, akin to the\nconcept of Join Indices in relational databases, to efficiently minimize query\ninput size regardless of its pattern shape and diameter. Our prototype system\nS2RDF is built on top of Spark and uses its relational interface to execute\nSPARQL queries over ExtVP. We demonstrate its superior performance in\ncomparison to state of the art SPARQL-on-Hadoop approaches using the recent\nWatDiv test suite. S2RDF achieves sub-second runtimes for majority of queries\non a billion triples RDF graph.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 10:42:31 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2016 08:20:04 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2016 14:58:43 GMT"}], "update_date": "2016-01-28", "authors_parsed": [["Sch\u00e4tzle", "Alexander", ""], ["Przyjaciel-Zablocki", "Martin", ""], ["Skilevic", "Simon", ""], ["Lausen", "Georg", ""]]}, {"id": "1512.07067", "submitter": "Brodu Etienne", "authors": "Etienne Brodu (DICE), St\\'ephane Fr\\'enot (DICE), Fr\\'ed\\'eric Obl\\'e", "title": "Transforming Javascript Event-Loop Into a Pipeline", "comments": null, "journal-ref": "Symposium on Applied Computing, Apr 2016, Pisa, Italy. 2016,\n  http://www.acm.org/conferences/sac/sac2016/", "doi": "10.1145/2851613.2851745", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of a real-time web application often starts with a\nfeature-driven approach allowing to quickly react to users feedbacks. However,\nthis approach poorly scales in performance. Yet, the user-base can increase by\nan order of magnitude in a matter of hours. This first approach is unable to\ndeal with the highest connections spikes. It leads the development team to\nshift to a scalable approach often linked to new development paradigm such as\ndataflow programming. This shift of technology is disruptive and\ncontinuity-threatening. To avoid it, we propose to abstract the feature-driven\ndevelopment into a more scalable high-level language. Indeed, reasoning on this\nhigh-level language allows to dynamically cope with user-base size evolutions.\nWe propose a compilation approach that transforms a Javascript, single-threaded\nreal-time web application into a network of small independent parts\ncommunicating by message streams. We named these parts fluxions, by contraction\nbetween a flow (flux in french) and a function. The independence of these parts\nallows their execution to be parallel, and to organize an application on\nseveral processors to cope with its load, in a similar way network routers do\nwith IP traffic. We test this approach by applying the compiler to a real web\napplication. We transform this application to parallelize the execution of an\nindependent part and present the result.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 13:01:48 GMT"}], "update_date": "2015-12-23", "authors_parsed": [["Brodu", "Etienne", "", "DICE"], ["Fr\u00e9not", "St\u00e9phane", "", "DICE"], ["Obl\u00e9", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1512.07305", "submitter": "Sri Raj Paul", "authors": "Sri Raj Paul, Karthik Murthy, Kuldeep S. Meel, John Mellor-Crummey", "title": "Distributed Phasers", "comments": "2 page extended abstract presented at The International Conference on\n  Parallel Architectures and Compilation Techniques (PACT) 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A phaser is an expressive synchronization construct that unifies collective\nand point-to-point coordination with dynamic task parallelism. Each task can\nparticipate in a phaser as a signaler, a waiter, or both. The participants in a\nphaser may change over time as dynamic tasks are added and deleted. In this\nposter, we present a highly concurrent and scalable design of phasers for a\ndistributed memory environment that is suitable for use with asynchronous\npartitioned global address space programming models. Our design for a\ndistributed phaser employs a pair of skip lists augmented with the ability to\ncollect and propagate synchronization signals. To enable a high degree of\nconcurrency, addition and deletion of participant tasks are performed in two\nphases: a \"fast single-link-modify\" step followed by multiple hand-overhand\n\"lazy multi-link-modify\" steps. We show that the cost of synchronization and\nstructural operations on a distributed phaser scales logarithmically, even in\nthe presence of concurrent structural modifications. To verify the correctness\nof our design for distributed phasers, we employ the SPIN model checker. To\naddress this issue of state space explosion, we describe how we decompose the\nstate space to separately verify correct handling for different kinds of\nmessages, which enables complete model checking of our phaser design.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 23:55:38 GMT"}, {"version": "v2", "created": "Sat, 12 Mar 2016 22:39:14 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Paul", "Sri Raj", ""], ["Murthy", "Karthik", ""], ["Meel", "Kuldeep S.", ""], ["Mellor-Crummey", "John", ""]]}, {"id": "1512.07437", "submitter": "Adam Gudy\\'s", "authors": "Adam Gudys and Sebastian Deorowicz", "title": "QuickProbs 2: towards rapid construction of high-quality alignments of\n  large protein families", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": "10.1038/srep41553", "report-no": null, "categories": "q-bio.QM cs.CE cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing size of sequence databases caused by the development of high\nthroughput sequencing, poses multiple alignment algorithms to face one of the\ngreatest challenges yet. As we show, well-established techniques employed for\nincreasing alignment quality, i.e., refinement and consistency, are ineffective\nwhen large protein families are of interest. We present QuickProbs 2, an\nalgorithm for multiple sequence alignment. Based on probabilistic models,\nequipped with novel column-oriented refinement and selective consistency, it\noffers outstanding accuracy. When analysing hundreds of sequences, QuickProbs 2\nis significantly better than Clustal Omega, the previous leader for processing\nnumerous protein families. In the case of smaller sets, for which\nconsistency-based methods are the best performing, QuickProbs 2 is also\nsuperior to the competitors. Due to computational scalability of selective\nconsistency and utilisation of massively parallel architectures, presented\nalgorithm is comparable to Clustal Omega in terms of execution time, and orders\nof magnitude faster than full consistency approaches, like MSAProbs or PicXAA.\nAll these make QuickProbs 2 a useful tool for aligning families ranging from\nfew, to hundreds of proteins. QuickProbs 2 is available at\nhttps://github.com/refresh-bio/QuickProbs.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2015 11:29:18 GMT"}, {"version": "v2", "created": "Tue, 30 Aug 2016 18:02:10 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Gudys", "Adam", ""], ["Deorowicz", "Sebastian", ""]]}, {"id": "1512.07574", "submitter": "Crist\\'obal Camarero", "authors": "Crist\\'obal Camarero, Carmen Mart\\'inez, Enrique Vallejo and Ram\\'on\n  Beivide", "title": "Projective Networks: Topologies for Large Parallel Computer Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interconnection network comprises a significant portion of the cost of\nlarge parallel computers, both in economic terms and power consumption. Several\nprevious proposals exploit large-radix routers to build scalable low-distance\ntopologies with the aim of minimizing these costs. However, they fail to\nconsider potential unbalance in the network utilization, which in some cases\nresults in suboptimal designs. Based on an appropriate cost model, this paper\nadvocates the use of networks based on incidence graphs of projective planes,\nbroadly denoted as Projective Networks. Projective Networks rely on highly\nsymmetric generalized Moore graphs and encompass several proposed direct (PN\nand demi-PN) and indirect (OFT) topologies under a common mathematical\nframework. Compared to other proposals with average distance between 2 and 3\nhops, these networks provide very high scalability while preserving a balanced\nnetwork utilization, resulting in low network costs. Overall, Projective\nNetworks constitute a competitive alternative for exascale-level\ninterconnection network design.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2015 18:26:49 GMT"}], "update_date": "2015-12-24", "authors_parsed": [["Camarero", "Crist\u00f3bal", ""], ["Mart\u00ednez", "Carmen", ""], ["Vallejo", "Enrique", ""], ["Beivide", "Ram\u00f3n", ""]]}, {"id": "1512.07684", "submitter": "EPTCS", "authors": "Asma Cherif (Umm al-Qura University, Saudi Arabia), Abdessamad Imine\n  (Lorraine University and Inria Nancy Grand-Est, France)", "title": "A Constraint-based Approach for Generating Transformation Patterns", "comments": "In Proceedings FOCLASA 2015, arXiv:1512.06947", "journal-ref": "EPTCS 201, 2015, pp. 48-62", "doi": "10.4204/EPTCS.201.4", "report-no": null, "categories": "cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Undoing operations is an indispensable feature for many collaborative\napplications, mainly collaborative editors. It provides the ability to restore\na correct state of shared data after erroneous operations. In particular,\nselective undo allows to undo any operation and is based on rearranging\noperations in the history thanks to the Operational Transformation (OT)\napproach. OT is an optimistic replication technique allowing for updating the\nshared data concurrently while maintaining convergence. It is a challenging\ntask how to meaningfully combine OT and undo approaches. Indeed, undoing\noperations that are received and executed out-of-order at different sites leads\nto divergence cases. Even though various undo solutions have been proposed over\nthe recent years, they are either limited or erroneous.\n  In this paper, we propose a constraint-based approach to address the undo\nproblem. We use Constraint Satisfaction Problem (CSP) theory to devise correct\nand undoable transformation patterns (w.r.t OT and undo properties) which\nconsiderably simplifies the design of collaborative objects.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2015 01:40:09 GMT"}], "update_date": "2016-01-04", "authors_parsed": [["Cherif", "Asma", "", "Umm al-Qura University, Saudi Arabia"], ["Imine", "Abdessamad", "", "Lorraine University and Inria Nancy Grand-Est, France"]]}, {"id": "1512.07800", "submitter": "Amos Korman", "authors": "Amos Korman (LIAFA, GANG), Shay Kutten, Toshimitsu Masuzawa\n  (Department of Information and Computer sciences Osaka University)", "title": "Fast and compact self-stabilizing verification, computation, and fault\n  detection of an MST", "comments": null, "journal-ref": "Distributed Computing, Springer Verlag, 2015, 28 (4)", "doi": "10.1007/s00446-015-0242-y", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates the usefulness of distributed local verification of\nproofs, as a tool for the design of self-stabilizing algorithms.In particular,\nit introduces a somewhat generalized notion of distributed local proofs, and\nutilizes it for improving the time complexity significantly, while maintaining\nspace optimality. As a result, we show that optimizing the memory size carries\nat most a small cost in terms of time, in the context of Minimum Spanning Tree\n(MST). That is, we present algorithms that are both time and space efficient\nfor both constructing an MST and for verifying it.This involves several parts\nthat may be considered contributions in themselves.First, we generalize the\nnotion of local proofs, trading off the time complexity for memory efficiency.\nThis adds a dimension to the study of distributed local proofs, which has been\ngaining attention recently. Specifically, we design a (self-stabilizing) proof\nlabeling scheme which is memory optimal (i.e., $O(\\log n)$ bits per node), and\nwhose time complexity is $O(\\log ^2 n)$ in synchronous networks, or $O(\\Delta\n\\log ^3 n)$ time in asynchronous ones, where $\\Delta$ is the maximum degree of\nnodes. This answers an open problem posed by Awerbuch and Varghese (FOCS 1991).\nWe also show that $\\Omega(\\log n)$ time is necessary, even in synchronous\nnetworks. Another property is that if $f$ faults occurred, then, within the\nrequireddetection time above, they are detected by some node in the $O(f\\log\nn)$ locality of each of the faults.Second, we show how to enhance a known\ntransformer that makes input/output algorithms self-stabilizing. It now takes\nas input an efficient construction algorithm and an efficient self-stabilizing\nproof labeling scheme, and produces an efficient self-stabilizing algorithm.\nWhen used for MST, the transformer produces a memory optimal self-stabilizing\nalgorithm, whose time complexity, namely, $O(n)$, is significantly better even\nthan that of previous algorithms. (The time complexity of previous MST\nalgorithms that used $\\Omega(\\log^2 n)$ memory bits per node was $O(n^2)$, and\nthe time for optimal space algorithms was $O(n|E|)$.) Inherited from our proof\nlabelling scheme, our self-stabilising MST construction algorithm also has the\nfollowing two properties: (1) if faults occur after the construction ended,\nthen they are detected by some nodes within $O(\\log ^2 n)$ time in synchronous\nnetworks, or within $O(\\Delta \\log ^3 n)$ time in asynchronous ones, and (2) if\n$f$ faults occurred, then, within the required detection time above, they are\ndetected within the $O(f\\log n)$ locality of each of the faults. We also show\nhow to improve the above two properties, at the expense of some increase in the\nmemory.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2015 12:06:18 GMT"}], "update_date": "2015-12-25", "authors_parsed": [["Korman", "Amos", "", "LIAFA, GANG"], ["Kutten", "Shay", "", "Department of Information and Computer sciences Osaka University"], ["Masuzawa", "Toshimitsu", "", "Department of Information and Computer sciences Osaka University"]]}, {"id": "1512.07805", "submitter": "Maomeng Su", "authors": "Maomeng Su, Mingxing Zhang, Kang Chen, Yongwei Wu, and Guoliang Li", "title": "RFP: A Remote Fetching Paradigm for RDMA-Accelerated Systems", "comments": "11 pages, 10 figures; Key Words: RDMA and InfiniBand, Remote Fetching\n  Paradigm, IOPS, and Small Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remote Direct Memory Access (RDMA) is an efficient way to improve the\nperformance of traditional client-server systems. Currently, there are two main\ndesign paradigms for RDMA-accelerated systems. The first allows the clients to\ndirectly operate the server's memory and totally bypasses the CPUs at server\nside. The second follows the traditional server-reply paradigm, which asks the\nserver to write results back to the clients. However, the first method has to\nexpose server's memory and needs tremendous re-design of upper-layer software,\nwhich is complex, unsafe, error-prone, and inefficient. The second cannot\nachieve high input/output operations per second (IOPS), because it employs\nout-bound RDMA-write at server side which is not efficient.\n  We find that the performance of out-bound RDMA-write and in-bound RDMA-read\nis asymmetric and the latter is 5 times faster than the former. Based on this\nobservation, we propose a novel design paradigm named Remote Fetching Paradigm\n(RFP). In RFP, the server is still responsible for processing requests from the\nclients. However, counter-intuitively, instead of sending results back to the\nclients through out-bound RDMA-write, the server only writes the results in\nlocal memory buffers, and the clients use in-bound RDMA-read to remotely fetch\nthese results. Since in-bound RDMA-read achieves much higher IOPS than\nout-bound RDMA-write, our model is able to bring higher performance than the\ntraditional models.\n  In order to prove the effectiveness of RFP, we design and implement an\nRDMA-accelerated in-memory key-value store following the RFP model. To further\nimprove the IOPS, we propose an optimization mechanism that combines status\nchecking and result fetching. Experiment results show that RFP can improve the\nIOPS by 160%~310% against state-of-the-art models for in-memory key-value\nstores.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2015 12:49:43 GMT"}], "update_date": "2015-12-25", "authors_parsed": [["Su", "Maomeng", ""], ["Zhang", "Mingxing", ""], ["Chen", "Kang", ""], ["Wu", "Yongwei", ""], ["Li", "Guoliang", ""]]}, {"id": "1512.08017", "submitter": "Poorna Dasgupta", "authors": "Poorna Banerjee Dasgupta", "title": "An Analytical Evaluation of Matricizing Least-Square-Errors Curve\n  Fitting to Support High Performance Computation on Large Datasets", "comments": "3 pages, Published with International Journal of Computer Trends and\n  Technology (IJCTT), Volume-30 Number-2, December-2015", "journal-ref": "International Journal of Computer Trends and Technology (IJCTT)\n  V30(2):113-115, December 2015", "doi": "10.14445/22312803/IJCTT-V30P120", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The procedure of Least Square-Errors curve fitting is extensively used in\nmany computer applications for fitting a polynomial curve of a given degree to\napproximate a set of data. Although various methodologies exist to carry out\ncurve fitting on data, most of them have shortcomings with respect to\nefficiency especially where huge datasets are involved. This paper proposes and\nanalyzes a matricized approach to the Least Square-Errors curve fitting with\nthe primary objective of parallelizing the whole algorithm so that high\nperformance efficiency can be achieved when algorithmic execution takes place\non colossal datasets.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2015 16:53:57 GMT"}], "update_date": "2015-12-29", "authors_parsed": [["Dasgupta", "Poorna Banerjee", ""]]}, {"id": "1512.08150", "submitter": "Faisal Orakzai Faisal Orakzai", "authors": "Faisal Orakzai, Thomas Devogele, Toon Calders", "title": "Towards Distributed Convoy Pattern Mining", "comments": "SIGSPATIAL'15 November 03-06, 2015, Bellevue, WA, USA", "journal-ref": null, "doi": "10.1145/2820783.2820840", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining movement data to reveal interesting behavioral patterns has gained\nattention in recent years. One such pattern is the convoy pattern which\nconsists of at least m objects moving together for at least k consecutive time\ninstants where m and k are user-defined parameters. Existing algorithms for\ndetecting convoy patterns, however do not scale to real-life dataset sizes.\nTherefore a distributed algorithm for convoy mining is inevitable. In this\npaper, we discuss the problem of convoy mining and analyze different data\npartitioning strategies to pave the way for a generic distributed convoy\npattern mining algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2015 22:10:05 GMT"}], "update_date": "2015-12-29", "authors_parsed": [["Orakzai", "Faisal", ""], ["Devogele", "Thomas", ""], ["Calders", "Toon", ""]]}, {"id": "1512.08194", "submitter": "Matteo Turilli", "authors": "Andre Merzky and Matteo Turilli and Manuel Maldonado and Mark\n  Santcroos and Shantenu Jha", "title": "Using Pilot Systems to Execute Many Task Workloads on Supercomputers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High performance computing systems have historically been designed to support\napplications comprised of mostly monolithic, single-job workloads. Pilot\nsystems decouple workload specification, resource selection, and task execution\nvia job placeholders and late-binding. Pilot systems help to satisfy the\nresource requirements of workloads comprised of multiple tasks. RADICAL-Pilot\n(RP) is a modular and extensible Python-based pilot system. In this paper we\ndescribe RP's design, architecture and implementation, and characterize its\nperformance. RP is capable of spawning more than 100 tasks/second and supports\nthe steady-state execution of up to 16K concurrent tasks. RP can be used\nstand-alone, as well as integrated with other application-level tools as a\nruntime system.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2015 09:59:12 GMT"}, {"version": "v2", "created": "Tue, 12 Apr 2016 23:43:41 GMT"}, {"version": "v3", "created": "Mon, 26 Mar 2018 17:01:18 GMT"}, {"version": "v4", "created": "Mon, 30 Jul 2018 11:21:04 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Merzky", "Andre", ""], ["Turilli", "Matteo", ""], ["Maldonado", "Manuel", ""], ["Santcroos", "Mark", ""], ["Jha", "Shantenu", ""]]}, {"id": "1512.08258", "submitter": "Tong Che", "authors": "Tong Che", "title": "Eventual Wait-Free Synchronization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Eventually linearizable objects are novel shared memory programming\nconstructs introduced as an analogy to eventual consistency in message-passing\nsystems. However, their behaviors in shared memory systems are so mysterious\nthat very little general theoretical properties of them is known.\n  In this paper, we lay the theoretical foundation of the study of eventually\nlinearizable objects. We prove that the n-process eventually linearizable\nfetch-and-cons (n-FAC) object is universal and can be used to classify the\neventually linearizable objects. In particular, we define the concept of\neventual consensus number of an abstract data type and prove that the eventual\nconsensus number can be used as a good characterization of the synchronization\npower of eventual objects. Thus we got a complete hierarchy of eventually\nlinearizable objects, as a perfect analogy of the consensus hierarchy. In this\nway, the synchronization power of eventual linearizability become much more\nwell understood.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2015 18:28:06 GMT"}], "update_date": "2015-12-29", "authors_parsed": [["Che", "Tong", ""]]}, {"id": "1512.08314", "submitter": "Lan Wang", "authors": "Olivier Brun, Lan Wang and Erol Gelenbe", "title": "Data Driven SMART Intercontinental Overlay Networks", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the use of Big Data and machine learning based analytics\nto the real-time management of Internet scale Quality-of-Service Route\nOptimisation with the help of an overlay network. Based on the collection of\nlarge amounts of data sampled each $2$ minutes over a large number of\nsource-destinations pairs, we show that intercontinental Internet Protocol (IP)\npaths are far from optimal with respect to Quality of Service (QoS) metrics\nsuch as end-to-end round-trip delay. We therefore develop a machine learning\nbased scheme that exploits large scale data collected from communicating node\npairs in a multi-hop overlay network that uses IP between the overlay nodes\nthemselves, to select paths that provide substantially better QoS than IP. The\napproach inspired from Cognitive Packet Network protocol, uses Random Neural\nNetworks with Reinforcement Learning based on the massive data that is\ncollected, to select intermediate overlay hops resulting in significantly\nbetter QoS than IP itself. The routing scheme is illustrated on a $20$-node\nintercontinental overlay network that collects close to $2\\times 10^6$\nmeasurements per week, and makes scalable distributed routing decisions.\nExperimental results show that this approach improves QoS significantly and\nefficiently in a scalable manner.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2015 03:43:04 GMT"}], "update_date": "2015-12-29", "authors_parsed": [["Brun", "Olivier", ""], ["Wang", "Lan", ""], ["Gelenbe", "Erol", ""]]}, {"id": "1512.08383", "submitter": "Ismail Hababeh", "authors": "Ismail Hababeh", "title": "Data Migration among Different Clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing services are becoming more and more popular. However, the\nhigh concentration of data and services on the clouds make them attractive\ntargets for various security attacks, including DoS, data theft, and privacy\nattacks. Additionally, cloud providers may fail to comply with service level\nagreement in terms of performance, availability, and security guarantees.\nMoreover, users may choose to utilize public cloud services from multiple\nvendors for various reasons including fault tolerance and availability.\nTherefore, it is of paramount importance to have secure and efficient\nmechanisms that enable users to transparently copy and move their data from one\nprovider to another. In this paper, we explore the state of the art inter cloud\nmigration techniques and identify the potential security threats in the scope\nof Hadoop Distributed File System HDFS. We propose an inter cloud data\nmigration mechanism that offers better security guarantees and faster response\ntime for migrating large scale data files in cloud database management systems.\nThe proposed approach enhances the data security processes used to achieve\nsecure data migration between cloud nodes thus improves applications response\ntime and throughput. The performance of the proposed approach is validated by\nmeasuring its impact on response time and throughput, and comparing the\nperformance to that of other techniques in the literature.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2015 12:11:36 GMT"}], "update_date": "2015-12-29", "authors_parsed": [["Hababeh", "Ismail", ""]]}, {"id": "1512.08417", "submitter": "Todor Ivanov", "authors": "Todor Ivanov and Max-Georg Beer", "title": "Evaluating Hive and Spark SQL with BigBench", "comments": "50 pages, 20 Tables", "journal-ref": null, "doi": null, "report-no": "Technical Report No. 2015-2", "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this work was to utilize BigBench [1] as a Big Data\nbenchmark and evaluate and compare two processing engines: MapReduce [2] and\nSpark [3]. MapReduce is the established engine for processing data on Hadoop.\nSpark is a popular alternative engine that promises faster processing times\nthan the established MapReduce engine. BigBench was chosen for this comparison\nbecause it is the first end-to-end analytics Big Data benchmark and it is\ncurrently under public review as TPCx-BB [4]. One of our goals was to evaluate\nthe benchmark by performing various scalability tests and validate that it is\nable to stress test the processing engines. First, we analyzed the steps\nnecessary to execute the available MapReduce implementation of BigBench [1] on\nSpark. Then, all the 30 BigBench queries were executed on MapReduce/Hive with\ndifferent scale factors in order to see how the performance changes with the\nincrease of the data size. Next, the group of HiveQL queries were executed on\nSpark SQL and compared with their respective Hive runtimes. This report gives a\ndetailed overview on how to setup an experimental Hadoop cluster and execute\nBigBench on both Hive and Spark SQL. It provides the absolute times for all\nexperiments preformed for different scale factors as well as query results\nwhich can be used to validate correct benchmark execution. Additionally,\nmultiple issues and workarounds were encountered and solved during our work. An\nevaluation of the resource utilization (CPU, memory, disk and network usage) of\na subset of representative BigBench queries is presented to illustrate the\nbehavior of the different query groups on both processing engines. Last but not\nleast it is important to mention that larger parts of this report are taken\nfrom the master thesis of Max-Georg Beer, entitled \"Evaluation of BigBench on\nApache Spark Compared to MapReduce\" [5].\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2015 14:12:16 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2016 17:49:24 GMT"}], "update_date": "2016-01-14", "authors_parsed": [["Ivanov", "Todor", ""], ["Beer", "Max-Georg", ""]]}, {"id": "1512.08493", "submitter": "Lina Yao", "authors": "Lina Yao, Quan Z. Sheng, Anne H.H. Ngu, Xue Li, Boualem Benatallah", "title": "Unveiling Contextual Similarity of Things via Mining Human-Thing\n  Interactions in the Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With recent advances in radio-frequency identification (RFID), wireless\nsensor networks, and Web services, physical things are becoming an integral\npart of the emerging ubiquitous Web. Finding correlations of ubiquitous things\nis a crucial prerequisite for many important applications such as things\nsearch, discovery, classification, recommendation, and composition. This\narticle presents DisCor-T, a novel graph-based method for discovering\nunderlying connections of things via mining the rich content embodied in\nhuman-thing interactions in terms of user, temporal and spatial information. We\nmodel these various information using two graphs, namely spatio-temporal graph\nand social graph. Then, random walk with restart (RWR) is applied to find\nproximities among things, and a relational graph of things (RGT) indicating\nimplicit correlations of things is learned. The correlation analysis lays a\nsolid foundation contributing to improved effectiveness in things management.\nTo demonstrate the utility, we develop a flexible feature-based classification\nframework on top of RGT and perform a systematic case study. Our evaluation\nexhibits the strength and feasibility of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2015 13:47:27 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2015 10:36:47 GMT"}, {"version": "v3", "created": "Tue, 18 Jul 2017 03:10:57 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Yao", "Lina", ""], ["Sheng", "Quan Z.", ""], ["Ngu", "Anne H. H.", ""], ["Li", "Xue", ""], ["Benatallah", "Boualem", ""]]}, {"id": "1512.08646", "submitter": "Luis Veiga", "authors": "Pradeeban Kathiravelu and Lu\\'is Veiga", "title": "Not Every Flow is Equal: SMART Discrimination in Redundancy", "comments": "INESC-ID Tec. Rep. 17/2015, October 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software-Defined Data Centers (SDDC) extend virtualization, software-defined\nnetworking and systems, and middleboxes to provide a better quality of service\n(QoS). While many network flow routing algorithms exist, most of them fail to\nadapt to the dynamic nature of the data center and cloud networks and their\nusers' and enterprise requirements. This paper presents SMART, a\nSoftware-Defined Networking (SDN) middlebox architecture for reliable\ntransfers. As an architectural enhancement for network flows allocation,\nrouting, and control, SMART ensures timely delivery of flows by diverting them\nto a less congested path dynamically in the software-defined data center\nnetworks. SMART also clones packets of higher priority flows to route in an\nalternative path, along with the original flow. Hence SMART offers a\ndifferentiated QoS through varying levels of redundancy in the flows.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2015 10:29:44 GMT"}], "update_date": "2015-12-31", "authors_parsed": [["Kathiravelu", "Pradeeban", ""], ["Veiga", "Lu\u00eds", ""]]}, {"id": "1512.08822", "submitter": "Youcheng Lou", "authors": "Youcheng Lou, Lean Yu and Shouyang Wang", "title": "Privacy Preservation in Distributed Subgradient Optimization Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy preservation is becoming an increasingly important issue in data\nmining and machine learning. In this paper, we consider the privacy preserving\nfeatures of distributed subgradient optimization algorithms. We first show that\na well-known distributed subgradient synchronous optimization algorithm, in\nwhich all agents make their optimization updates simultaneously at all times,\nis not privacy preserving in the sense that the malicious agent can learn other\nagents' subgradients asymptotically. Then we propose a distributed subgradient\nprojection asynchronous optimization algorithm without relying on any existing\nprivacy preservation technique, where agents can exchange data between\nneighbors directly. In contrast to synchronous algorithms, in the new\nasynchronous algorithm agents make their optimization updates asynchronously.\nThe introduced projection operation and asynchronous optimization mechanism can\nguarantee that the proposed asynchronous optimization algorithm is privacy\npreserving. Moreover, we also establish the optimal convergence of the newly\nproposed algorithm. The proposed privacy preservation techniques shed light on\ndeveloping other privacy preserving distributed optimization algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2015 01:13:06 GMT"}], "update_date": "2015-12-31", "authors_parsed": [["Lou", "Youcheng", ""], ["Yu", "Lean", ""], ["Wang", "Shouyang", ""]]}, {"id": "1512.08943", "submitter": "Gregory Chockler", "authors": "Vita Bortnikov, Gregory Chockler, Dmitri Perelman, Alexey Roytman,\n  Shlomit Shachor, and Ilya Shnayderman", "title": "Reconfigurable State Machine Replication from Non-Reconfigurable\n  Building Blocks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconfigurable state machine replication is an important enabler of\nelasticity for replicated cloud services, which must be able to dynamically\nadjust their size as a function of changing load and resource availability. We\nintroduce a new generic framework to allow the reconfigurable state machine\nimplementation to be derived from a collection of arbitrary non-reconfigurable\nstate machines. Our reduction framework follows the black box approach, and\ndoes not make any assumptions with respect to its execution environment apart\nfrom reliable channels. It allows higher-level services to leverage speculative\ncommand execution to ensure uninterrupted progress during the reconfiguration\nperiods as well as in situations where failures prevent the reconfiguration\nagreement from being reached in a timely fashion. We apply our framework to\nobtain a reconfigurable speculative state machine from the non-reconfigurable\nPaxos implementation, and analyze its performance on a realistic distributed\ntestbed. Our results show that our framework incurs negligible overheads in the\nabsence of reconfiguration, and allows steady throughput to be maintained\nthroughout the reconfiguration periods.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2015 13:47:32 GMT"}], "update_date": "2015-12-31", "authors_parsed": [["Bortnikov", "Vita", ""], ["Chockler", "Gregory", ""], ["Perelman", "Dmitri", ""], ["Roytman", "Alexey", ""], ["Shachor", "Shlomit", ""], ["Shnayderman", "Ilya", ""]]}, {"id": "1512.09228", "submitter": "Minyoung Jung", "authors": "Minyoung Jung and Bernd Burgstaller and Johann Blieberger", "title": "Efficient Construction of Simultaneous Deterministic Finite Automata on\n  Multicores Using Rabin Fingerprints", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose several optimizations for the SFA construction\nalgorithm, which greatly reduce the in-memory footprint and the processing\nsteps required to construct an SFA. We introduce fingerprints as a space- and\ntime-efficient way to represent SFA states. To compute fingerprints, we apply\nthe Barrett reduction algorithm and accelerate it using recent additions to the\nx86 instruction set architecture. We exploit fingerprints to introduce hashing\nfor further optimizations. Our parallel SFA construction algorithm is\nnonblocking and utilizes instruction-level, data-level, and task-level\nparallelism of coarse-, medium- and fine-grained granularity. We adapt static\nworkload distributions and align the SFA data-structures with the constraints\nof multicore memory hierarchies, to increase the locality of memory accesses\nand facilitate HW prefetching. We conduct experiments on the PROSITE protein\ndatabase for FAs of up to 702 FA states to evaluate performance and\neffectiveness of our proposed optimizations. Evaluations have been conducted on\na 4 CPU (64 cores) AMD Opteron 6378 system and a 2 CPU (28 cores, 2\nhyperthreads per core) Intel Xeon E5-2697 v3 system. The observed speedups over\nthe sequential baseline algorithm are up to 118541x on the AMD system and\n2113968x on the Intel system.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2015 06:41:17 GMT"}, {"version": "v2", "created": "Tue, 26 Sep 2017 02:02:22 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Jung", "Minyoung", ""], ["Burgstaller", "Bernd", ""], ["Blieberger", "Johann", ""]]}, {"id": "1512.09295", "submitter": "Qirong Ho", "authors": "Eric P. Xing, Qirong Ho, Pengtao Xie, Wei Dai", "title": "Strategies and Principles of Distributed Machine Learning on Big Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of Big Data has led to new demands for Machine Learning (ML) systems\nto learn complex models with millions to billions of parameters, that promise\nadequate capacity to digest massive datasets and offer powerful predictive\nanalytics thereupon. In order to run ML algorithms at such scales, on a\ndistributed cluster with 10s to 1000s of machines, it is often the case that\nsignificant engineering efforts are required --- and one might fairly ask if\nsuch engineering truly falls within the domain of ML research or not. Taking\nthe view that Big ML systems can benefit greatly from ML-rooted statistical and\nalgorithmic insights --- and that ML researchers should therefore not shy away\nfrom such systems design --- we discuss a series of principles and strategies\ndistilled from our recent efforts on industrial-scale ML solutions. These\nprinciples and strategies span a continuum from application, to engineering,\nand to theoretical research and development of Big ML systems and\narchitectures, with the goal of understanding how to make them efficient,\ngenerally-applicable, and supported with convergence and scaling guarantees.\nThey concern four key questions which traditionally receive little attention in\nML research: How to distribute an ML program over a cluster? How to bridge ML\ncomputation with inter-machine communication? How to perform such\ncommunication? What should be communicated between machines? By exposing\nunderlying statistical and algorithmic characteristics unique to ML programs\nbut not typically seen in traditional computer programs, and by dissecting\nsuccessful cases to reveal how we have harnessed these principles to design and\ndevelop both high-performance distributed ML software as well as\ngeneral-purpose ML frameworks, we present opportunities for ML researchers and\npractitioners to further shape and grow the area that lies between ML and\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2015 14:33:53 GMT"}], "update_date": "2016-01-01", "authors_parsed": [["Xing", "Eric P.", ""], ["Ho", "Qirong", ""], ["Xie", "Pengtao", ""], ["Dai", "Wei", ""]]}, {"id": "1512.09314", "submitter": "Bogdan Chlebus", "authors": "Bogdan S. Chlebus and Dariusz R. Kowalski", "title": "Asynchronous Exclusive Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An asynchronous system of $n$ processes prone to crashes, along with a number\nof shared read-write registers, is the distributed setting. We consider\nassigning integer numbers to processes in an exclusive manner, in the sense\nthat no integer is assigned to two distinct processes. In the problem called\nRenaming, any $k\\le n$ processes, which hold original names from a range\n$[N]=\\{1,\\ldots,N\\}$, contend to acquire unique integers in a smaller range\n$[M]$ as new names using some $r$ auxiliary shared registers. We develop a\nwait-free $(k,N)$-renaming solution operating in $O(\\log k (\\log N + \\log\nk\\log\\log N))$ local steps, for $M=O(k)$, and with $r=O(k\\log(N/k))$ auxiliary\nregisters. We develop a wait-free $k$-renaming algorithm operating in $O(k)$\ntime, with $M=2k-1$ and with $r=O(k^2)$ registers. We develop an almost\nadaptive wait-free $N$-renaming algorithm, with $N$ known, operating in\n$O(\\log^2 k (\\log N + \\log k\\log\\log N))$ time, with $M=O(k)$ and with\n$r=O(n\\log(N/n))$ registers. We give a fully adaptive solution of Renaming,\nwith neither $k$ nor $N$ known, having $M=8k-\\lg k-1$ as the bound on new\nnames, operating in $O(k)$ steps and using $O(n^2)$ registers. As regards lower\nbounds, we show that a wait-free solution of Renaming requires\n$1+\\min\\{k-2,\\log_{2r} \\frac{N}{2M}\\}$ steps in the worst case. We apply\nrenaming algorithms to obtain solutions to a problem called Store-and-Collect,\nwhich is about operations of storing and collecting under additional\nrequirements. We consider the problem called Unbounded-Naming in which\nprocesses may repeatedly request new names, while no name can be reused once\nassigned, so that infinitely many integers need to be exclusively assigned as\nnames in an execution.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2015 15:55:08 GMT"}], "update_date": "2016-01-01", "authors_parsed": [["Chlebus", "Bogdan S.", ""], ["Kowalski", "Dariusz R.", ""]]}, {"id": "1512.09369", "submitter": "Pedro Lopez-Garcia", "authors": "Pedro Lopez-Garcia and Remy Haemmerle and Maximiliano Klemen and Umer\n  Liqat and Manuel V. Hermenegildo", "title": "Towards Energy Consumption Verification via Static Analysis", "comments": "Presented at HIP3ES, 2015 (arXiv: 1501.03064)", "journal-ref": null, "doi": null, "report-no": "HIP3ES/2015/04", "categories": "cs.PL cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we leverage an existing general framework for resource usage\nverification and specialize it for verifying energy consumption specifications\nof embedded programs. Such specifications can include both lower and upper\nbounds on energy usage, and they can express intervals within which energy\nusage is to be certified to be within such bounds. The bounds of the intervals\ncan be given in general as functions on input data sizes. Our verification\nsystem can prove whether such energy usage specifications are met or not. It\ncan also infer the particular conditions under which the specifications hold.\nTo this end, these conditions are also expressed as intervals of functions of\ninput data sizes, such that a given specification can be proved for some\nintervals but disproved for others. The specifications themselves can also\ninclude preconditions expressing intervals for input data sizes. We report on a\nprototype implementation of our approach within the CiaoPP system for the XC\nlanguage and XS1-L architecture, and illustrate with an example how embedded\nsoftware developers can use this tool, and in particular for determining values\nfor program parameters that ensure meeting a given energy budget while\nminimizing the loss in quality of service.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2015 20:57:50 GMT"}], "update_date": "2016-01-01", "authors_parsed": [["Lopez-Garcia", "Pedro", ""], ["Haemmerle", "Remy", ""], ["Klemen", "Maximiliano", ""], ["Liqat", "Umer", ""], ["Hermenegildo", "Manuel V.", ""]]}]