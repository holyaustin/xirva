[{"id": "1905.00331", "submitter": "Tao Wang", "authors": "Taiping He, Tao Wang, Ralph Abbey, and Joshua Griffin", "title": "High-Performance Support Vector Machines and Its Applications", "comments": "ICDATA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The support vector machines (SVM) algorithm is a popular classification\ntechnique in data mining and machine learning. In this paper, we propose a\ndistributed SVM algorithm and demonstrate its use in a number of applications.\nThe algorithm is named high-performance support vector machines (HPSVM). The\nmajor contribution of HPSVM is two-fold. First, HPSVM provides a new way to\ndistribute computations to the machines in the cloud without shuffling the\ndata. Second, HPSVM minimizes the inter-machine communications in order to\nmaximize the performance. We apply HPSVM to some real-world classification\nproblems and compare it with the state-of-the-art SVM technique implemented in\nR on several public data sets. HPSVM achieves similar or better results.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 14:43:03 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["He", "Taiping", ""], ["Wang", "Tao", ""], ["Abbey", "Ralph", ""], ["Griffin", "Joshua", ""]]}, {"id": "1905.00342", "submitter": "Frederik Mallmann-Trenn", "authors": "Alberto Ancona, Ayesha Bajwa, Nancy Lynch, and Frederik Mallmann-Trenn", "title": "How to Color a French Flag--Biologically Inspired Algorithms for\n  Scale-Invariant Patterning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the French flag problem, initially uncolored cells on a grid must\ndifferentiate to become blue, white or red. The goal is for the cells to color\nthe grid as a French flag, i.e., a three-colored triband, in a distributed\nmanner. To solve a generalized version of the problem in a distributed\ncomputational setting, we consider two models: a biologically-inspired version\nthat relies on morphogens (diffusing proteins acting as chemical signals) and a\nmore abstract version based on reliable message passing between cellular\nagents.\n  Much of developmental biology research has focused on concentration-based\napproaches using morphogens, since morphogen gradients are thought to be an\nunderlying mechanism in tissue patterning. We show that both our model types\neasily achieve a French ribbon - a French flag in the 1D case. However,\nextending the ribbon to the 2D flag in the concentration model is somewhat\ndifficult unless each agent has additional positional information. Assuming\nthat cells are are identical, it is impossible to achieve a French flag or even\na close approximation. In contrast, using a message-based approach in the 2D\ncase only requires assuming that agents can be represented as constant size\nstate machines.\n  We hope that our insights may lay some groundwork for what kind of message\npassing abstractions or guarantees, if any, may be useful in analogy to cells\ncommunicating at long and short distances to solve patterning problems. In\naddition, we hope that our models and findings may be of interest in the design\nof nano-robots.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 15:02:13 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Ancona", "Alberto", ""], ["Bajwa", "Ayesha", ""], ["Lynch", "Nancy", ""], ["Mallmann-Trenn", "Frederik", ""]]}, {"id": "1905.00565", "submitter": "Bo Pu", "authors": "Bo Pu, Lujie Duan, Nathaniel Osgood", "title": "Parallelizing Convergent Cross Mapping Using Apache Spark", "comments": "11 pages, 5 figures, SBP conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying the causal relationships between subjects or variables remains an\nimportant problem across various scientific fields. This is particularly\nimportant but challenging in complex systems, such as those involving human\nbehavior, sociotechnical contexts, and natural ecosystems. By exploiting state\nspace reconstruction via lagged embedding of time series, convergent cross\nmapping (CCM) serves as an important method for addressing this problem. While\npowerful, CCM is computationally costly; moreover, CCM results are highly\nsensitive to several parameter values. While best practice entails exploring a\nrange of parameter settings when assessing casual relationships, the resulting\ncomputational burden can raise barriers to practical use, especially for long\ntime series exhibiting weak causal linkages. We demonstrate here several means\nof accelerating CCM by harnessing the distributed Apache Spark platform. We\ncharacterize and report on results of several experiments with parallelized\nsolutions that demonstrate high scalability and a capacity for over an order of\nmagnitude performance improvement for the baseline configuration. Such\neconomies in computation time can speed learning and robust identification of\ncausal drivers in complex systems.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 03:41:10 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Pu", "Bo", ""], ["Duan", "Lujie", ""], ["Osgood", "Nathaniel", ""]]}, {"id": "1905.00580", "submitter": "William Moses Jr.", "authors": "Yuval Emek, Shay Kutten, Ron Lavi, and William K. Moses Jr", "title": "Deterministic Leader Election in Programmable Matter", "comments": "33 pages, 16 figures, to appear in the proceedings of ICALP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Addressing a fundamental problem in programmable matter, we present the first\ndeterministic algorithm to elect a unique leader in a system of connected\namoebots assuming only that amoebots are initially contracted. Previous\nalgorithms either used randomization, made various assumptions (shapes with no\nholes, or known shared chirality), or elected several co-leaders in some cases.\n  Some of the building blocks we introduce in constructing the algorithm are of\ninterest by themselves, especially the procedure we present for reaching common\nchirality among the amoebots. Given the leader election and the chirality\nagreement building block, it is known that various tasks in programmable matter\ncan be performed or improved.\n  The main idea of the new algorithm is the usage of the ability of the\namoebots to move, which previous leader election algorithms have not used.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 05:56:08 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Emek", "Yuval", ""], ["Kutten", "Shay", ""], ["Lavi", "Ron", ""], ["Moses", "William K.", "Jr"]]}, {"id": "1905.00661", "submitter": "Daniel Castro", "authors": "Daniel Castro, Paolo Romano, Aleksandar Ilic and Amin M. Khan", "title": "HeTM: Transactional Memory for Heterogeneous Systems", "comments": "The current work was accepted in the 28th International Conference on\n  Parallel Architectures and Compilation Techniques (PACT'19)", "journal-ref": null, "doi": "10.1109/PACT.2019.00026", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern heterogeneous computing architectures, which couple multi-core CPUs\nwith discrete many-core GPUs (or other specialized hardware accelerators),\nenable unprecedented peak performance and energy efficiency levels.\nUnfortunately, though, developing applications that can take full advantage of\nthe potential of heterogeneous systems is a notoriously hard task. This work\ntakes a step towards reducing the complexity of programming heterogeneous\nsystems by introducing the abstraction of Heterogeneous Transactional Memory\n(HeTM). HeTM provides programmers with the illusion of a single memory region,\nshared among the CPUs and the (discrete) GPU(s) of a heterogeneous system, with\nsupport for atomic transactions. Besides introducing the abstract semantics and\nprogramming model of HeTM, we present the design and evaluation of a concrete\nimplementation of the proposed abstraction, which we named Speculative HeTM\n(SHeTM). SHeTM makes use of a novel design that leverages on speculative\ntechniques and aims at hiding the inherently large communication latency\nbetween CPUs and discrete GPUs and at minimizing inter-device synchronization\noverhead. SHeTM is based on a modular and extensible design that allows for\neasily integrating alternative TM implementations on the CPU's and GPU's sides,\nwhich allows the flexibility to adopt, on either side, the TM implementation\n(e.g., in hardware or software) that best fits the applications' workload and\nthe architectural characteristics of the processing unit. We demonstrate the\nefficiency of the SHeTM via an extensive quantitative study based both on\nsynthetic benchmarks and on a porting of a popular object caching system.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 10:52:21 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 10:25:24 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Castro", "Daniel", ""], ["Romano", "Paolo", ""], ["Ilic", "Aleksandar", ""], ["Khan", "Amin M.", ""]]}, {"id": "1905.00673", "submitter": "Mustafa Abduljabbar", "authors": "Jing Chen, Pirah Noor Soomro, Mustafa Abduljabbar, Miquel Peric\\`as", "title": "An Adaptive Performance-oriented Scheduler for Static and Dynamic\n  Heterogeneity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emergence of heterogeneous hardware paving the way for the\npost-Moore era, it is of high importance to adapt the runtime scheduling to the\nplatform's heterogeneity. To enhance adaptive and responsive scheduling, we\nintroduce a Performance Trace Table (PTT) into XiTAO, a framework for elastic\nscheduling of mixed-mode parallelism. The PTT is an extensible and dynamic\nlightweight manifest of the per-core latency that can be used to guide the\nscheduling of both critical and non-critical tasks. By understanding the\nper-task latency, the PTT can infer task performance, intra-application\ninterference as well as inter-application interference. We run random Direct\nAcyclic Graphs (DAGs) of different workload categories as a benchmark on NVIDIA\nJetson TX2 chip, achieving up to 3.25x speedup over a standard work-stealing\nscheduler. To exemplify scheduling adaption to interference, we run DAGs with\nhigh parallelism and analyze the scheduler's response to interference from a\nbackground process on an Intel Haswell (2650v3) multicore workstation. We also\nshowcase the XiTAO's scheduling performance by porting the VGG-16 image\nclassification framework based on Convolutional Neural Networks (CNN).\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 11:38:02 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 10:16:22 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Chen", "Jing", ""], ["Soomro", "Pirah Noor", ""], ["Abduljabbar", "Mustafa", ""], ["Peric\u00e0s", "Miquel", ""]]}, {"id": "1905.00850", "submitter": "Peilin Zhong", "authors": "Alexandr Andoni, Clifford Stein and Peilin Zhong", "title": "Log Diameter Rounds Algorithms for $2$-Vertex and $2$-Edge Connectivity", "comments": "ICALP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern parallel systems, such as MapReduce, Hadoop and Spark, can be\nmodeled well by the MPC model. The MPC model captures well coarse-grained\ncomputation on large data --- data is distributed to processors, each of which\nhas a sublinear (in the input data) amount of memory and we alternate between\nrounds of computation and rounds of communication, where each machine can\ncommunicate an amount of data as large as the size of its memory. This model is\nstronger than the classical PRAM model, and it is an intriguing question to\ndesign algorithms whose running time is smaller than in the PRAM model.\n  In this paper, we study two fundamental problems, $2$-edge connectivity and\n$2$-vertex connectivity (biconnectivity). PRAM algorithms which run in $O(\\log\nn)$ time have been known for many years. We give algorithms using roughly log\ndiameter rounds in the MPC model. Our main results are, for an $n$-vertex,\n$m$-edge graph of diameter $D$ and bi-diameter $D'$, 1) a $O(\\log\nD\\log\\log_{m/n} n)$ parallel time $2$-edge connectivity algorithm, 2) a $O(\\log\nD\\log^2\\log_{m/n}n+\\log D'\\log\\log_{m/n}n)$ parallel time biconnectivity\nalgorithm, where the bi-diameter $D'$ is the largest cycle length over all the\nvertex pairs in the same biconnected component. Our results are fully scalable,\nmeaning that the memory per processor can be $O(n^{\\delta})$ for arbitrary\nconstant $\\delta>0$, and the total memory used is linear in the problem size.\nOur $2$-edge connectivity algorithm achieves the same parallel time as the\nconnectivity algorithm of Andoni et al. (FOCS 2018). We also show an\n$\\Omega(\\log D')$ conditional lower bound for the biconnectivity problem.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 16:53:55 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Andoni", "Alexandr", ""], ["Stein", "Clifford", ""], ["Zhong", "Peilin", ""]]}, {"id": "1905.00863", "submitter": "Jack Kosaian", "authors": "Jack Kosaian, K.V. Rashmi, Shivaram Venkataraman", "title": "Parity Models: A General Framework for Coding-Based Resilience in ML\n  Inference", "comments": "This paper is superseded by the ACM SOSP 2019 paper \"Parity Models:\n  Erasure-Coded Resilience for Prediction Serving Systems\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are becoming the primary workhorses for many\napplications. Production services deploy models through prediction serving\nsystems that take in queries and return predictions by performing inference on\nmachine learning models. In order to scale to high query rates, prediction\nserving systems are run on many machines in cluster settings, and thus are\nprone to slowdowns and failures that inflate tail latency and cause violations\nof strict latency targets. Current approaches to reducing tail latency are\ninadequate for the latency targets of prediction serving, incur high resource\noverhead, or are inapplicable to the computations performed during inference.\n  We present ParM, a novel, general framework for making use of ideas from\nerasure coding and machine learning to achieve low-latency, resource-efficient\nresilience to slowdowns and failures in prediction serving systems. ParM\nencodes multiple queries together into a single parity query and performs\ninference on the parity query using a parity model. A decoder uses the output\nof a parity model to reconstruct approximations of unavailable predictions.\nParM uses neural networks to learn parity models that enable simple, fast\nencoders and decoders to reconstruct unavailable predictions for a variety of\ninference tasks such as image classification, speech recognition, and object\nlocalization. We build ParM atop an open-source prediction serving system and\nthrough extensive evaluation show that ParM improves overall accuracy in the\nface of unavailability with low latency while using 2-4$\\times$ less additional\nresources than replication-based approaches. ParM reduces the gap between\n99.9th percentile and median latency by up to $3.5\\times$ compared to\napproaches that use an equal amount of resources, while maintaining the same\nmedian.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 17:22:13 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 11:36:10 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Kosaian", "Jack", ""], ["Rashmi", "K. V.", ""], ["Venkataraman", "Shivaram", ""]]}, {"id": "1905.00968", "submitter": "Christina Delimitrou", "authors": "Yu Gan, Yanqi Zhang, Kelvin Hu, Dailun Cheng, Yuan He, Meghna\n  Pancholi, and Christina Delimitrou", "title": "Leveraging Deep Learning to Improve the Performance Predictability of\n  Cloud Microservices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance unpredictability is a major roadblock towards cloud adoption, and\nhas performance, cost, and revenue ramifications. Predictable performance is\neven more critical as cloud services transition from monolithic designs to\nmicroservices. Detecting QoS violations after they occur in systems with\nmicroservices results in long recovery times, as hotspots propagate and amplify\nacross dependent services. We present Seer, an online cloud performance\ndebugging system that leverages deep learning and the massive amount of tracing\ndata cloud systems collect to learn spatial and temporal patterns that\ntranslate to QoS violations. Seer combines lightweight distributed RPC-level\ntracing, with detailed low-level hardware monitoring to signal an upcoming QoS\nviolation, and diagnose the source of unpredictable performance. Once an\nimminent QoS violation is detected, Seer notifies the cluster manager to take\naction to avoid performance degradation altogether. We evaluate Seer both in\nlocal clusters, and in large-scale deployments of end-to-end applications built\nwith microservices with hundreds of users. We show that Seer correctly\nanticipates QoS violations 91% of the time, and avoids the QoS violation to\nbegin with in 84% of cases. Finally, we show that Seer can identify\napplication-level design bugs, and provide insights on how to better architect\nmicroservices to achieve predictable performance.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 21:25:56 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Gan", "Yu", ""], ["Zhang", "Yanqi", ""], ["Hu", "Kelvin", ""], ["Cheng", "Dailun", ""], ["He", "Yuan", ""], ["Pancholi", "Meghna", ""], ["Delimitrou", "Christina", ""]]}, {"id": "1905.01200", "submitter": "Archit Somani", "authors": "Chirag Juyal, Sandeep Kulkarni, Sweta Kumari, Sathya Peri and Archit\n  Somani", "title": "An Efficient Approach to Achieve Compositionality using Optimized\n  Multi-Version Object Based Transactional Systems", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the modern era of multi-core systems, the main aim is to utilize the cores\nproperly. This utilization can be done by concurrent programming. But\ndeveloping a flawless and well-organized concurrent program is difficult.\nSoftware Transactional Memory Systems (STMs) are a convenient programming\ninterface which assist the programmer to access the shared memory concurrently\nwithout worrying about consistency issues such as priority-inversion, deadlock,\nlivelock, etc. Another important feature that STMs facilitate is\ncompositionality of concurrent programs with great ease. It composes different\nconcurrent operations in a single atomic unit by encapsulating them in a\ntransaction. Many STMs available in the literature execute read/write primitive\noperations on memory buffers. We represent them as Read-Write STMs or RWSTMs.\nWhereas, there exist some STMs (transactional boosting and its variants) which\nwork on higher level operations such as insert, delete, lookup, etc. on a\nhash-table. We refer these STMs as Object Based STMs or OSTMs. The literature\nof databases and RWSTMs say that maintaining multiple versions ensures greater\nconcurrency. This motivates us to maintain multiple version at higher level\nwith object semantics and achieves greater concurrency. So, this paper\npro-poses the notion of Optimized Multi-version Object Based STMs or\nOPT-MVOSTMs which encapsulates the idea of multiple versions in OSTMs to\nharness the greater concurrency efficiently.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 14:23:29 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Juyal", "Chirag", ""], ["Kulkarni", "Sandeep", ""], ["Kumari", "Sweta", ""], ["Peri", "Sathya", ""], ["Somani", "Archit", ""]]}, {"id": "1905.01219", "submitter": "Vibhatha Abeykoon", "authors": "Vibhatha Abeykoon, Geoffrey Fox, Minje Kim", "title": "Performance Optimization on Model Synchronization in Parallel Stochastic\n  Gradient Descent Based SVM", "comments": "Paper Accepted in HPML 2019 Held in conjunction with IEEE/ACM CCGRID\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the bottlenecks in implementing stochastic gradient descent\n(SGD)-based distributed support vector machines (SVM) algorithm is important in\ntraining larger data sets. The communication time to do the model\nsynchronization across the parallel processes is the main bottleneck that\ncauses inefficiency in the training process. The model synchronization is\ndirectly affected by the mini-batch size of data processed before the global\nsynchronization. In producing an efficient distributed model, the communication\ntime in training model synchronization has to be as minimum as possible while\nretaining a high testing accuracy. The effect from model synchronization\nfrequency over the convergence of the algorithm and accuracy of the generated\nmodel must be well understood to design an efficient distributed model. In this\nresearch, we identify the bottlenecks in model synchronization in parallel\nstochastic gradient descent (PSGD)-based SVM algorithm with respect to the\ntraining model synchronization frequency (MSF). Our research shows that by\noptimizing the MSF in the data sets that we used, a reduction of 98\\% in\ncommunication time can be gained (16x - 24x speed up) with respect to\nhigh-frequency model synchronization. The training model optimization discussed\nin this paper guarantees a higher accuracy than the sequential algorithm along\nwith faster convergence.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 15:16:02 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Abeykoon", "Vibhatha", ""], ["Fox", "Geoffrey", ""], ["Kim", "Minje", ""]]}, {"id": "1905.01234", "submitter": "Alex Furtunato", "authors": "Alex F. A. Furtunato, Kyriakos Georgiou, Kerstin Eder, Samuel\n  Xavier-de-Souza", "title": "When parallel speedups hit the memory wall", "comments": "24 pages", "journal-ref": null, "doi": "10.1109/ACCESS.2020.2990418", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After Amdahl's trailblazing work, many other authors proposed analytical\nspeedup models but none have considered the limiting effect of the memory wall.\nThese models exploited aspects such as problem-size variation, memory size,\ncommunication overhead, and synchronization overhead, but data-access delays\nare assumed to be constant. Nevertheless, such delays can vary, for example,\naccording to the number of cores used and the ratio between processor and\nmemory frequencies. Given the large number of possible configurations of\noperating frequency and number of cores that current architectures can offer,\nsuitable speedup models to describe such variations among these configurations\nare quite desirable for off-line or on-line scheduling decisions. This work\nproposes new parallel speedup models that account for variations of the average\ndata-access delay to describe the limiting effect of the memory wall on\nparallel speedups. Analytical results indicate that the proposed modeling can\ncapture the desired behavior while experimental hardware results validate the\nformer. Additionally, we show that when accounting for parameters that reflect\nthe intrinsic characteristics of the applications, such as degree of\nparallelism and susceptibility to the memory wall, our proposal has significant\nadvantages over machine-learning-based modeling. Moreover, besides being\nblack-box modeling, our experiments show that conventional machine-learning\nmodeling needs about one order of magnitude more measurements to reach the same\nlevel of accuracy achieved in our modeling.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 15:43:28 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 22:41:47 GMT"}, {"version": "v3", "created": "Wed, 18 Mar 2020 00:33:18 GMT"}, {"version": "v4", "created": "Thu, 23 Apr 2020 17:51:30 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Furtunato", "Alex F. A.", ""], ["Georgiou", "Kyriakos", ""], ["Eder", "Kerstin", ""], ["Xavier-de-Souza", "Samuel", ""]]}, {"id": "1905.01302", "submitter": "Chengzheng Sun", "authors": "David Sun, Chengzheng Sun, Agustina Ng, Weiwei Cai", "title": "Real Differences between OT and CRDT in Correctness and Complexity for\n  Consistency Maintenance in Co-Editors", "comments": "30 pages. arXiv admin note: substantial text overlap with\n  arXiv:1810.02137", "journal-ref": "PACMHCI Vol. 4, CSCW1, Article 21, May 2020", "doi": "10.1145/3392825", "report-no": null, "categories": "cs.DC cs.HC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OT (Operational Transformation) was invented for supporting real-time\nco-editors in the late 1980s and has evolved to become core techniques widely\nused in today's working co-editors and adopted in industrial products. CRDT\n(Commutative Replicated Data Type) for co-editors was first proposed around\n2006, under the name of WOOT (WithOut Operational Transformation). Follow-up\nCRDT variations are commonly labeled as \"post-OT\" techniques capable of making\nconcurrent operations natively commutative in co-editors. On top of that, CRDT\nsolutions have made broad claims of superiority over OT solutions, and often\nportrayed OT as an incorrect and inefficient technique. Over one decade later,\nhowever, CRDT is rarely found in working co-editors; OT remains the choice for\nbuilding the vast majority of today's co-editors. Contradictions between the\nreality and CRDT's purported advantages have been the source of much confusion\nand debate among co-editing researcher sand developers. To seek truth from\nfacts, we set out to conduct a comprehensive and critical review on\nrepresentative OT and CRDT solutions and co-editors based on them. From this\nwork, we have made important discoveries about OT and CRDT, and revealed facts\nand evidences that refute CRDT claims over OT on all accounts. These\ndiscoveries help explain the underlying reasons for the choice between OT and\nCRDT in the real world. We report these results in a series of three articles.\n  In the second article of this series, we reveal the differences between OT\nand CRDT in their basic approaches to realizing the same general transformation\nand how such differences had resulted in different challenges and consequential\ncorrectness and complexity issues. Moreover, we reveal hidden complexity and\nalgorithmic flaws with representative CRDT solutions, and discuss common myths\nand facts related to correctness and complexity of OT and CRDT.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 07:45:28 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 14:41:17 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Sun", "David", ""], ["Sun", "Chengzheng", ""], ["Ng", "Agustina", ""], ["Cai", "Weiwei", ""]]}, {"id": "1905.01306", "submitter": "Nataliya Shakhovska Prof", "authors": "Nataliya Shakhovska, Uyrii Bolubash, Oleh Veres", "title": "Big Data Model \"Entity and Features\"", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article deals with the problem which led to Big Data. Big Data\ninformation technology is the set of methods and means of processing different\ntypes of structured and unstructured dynamic large amounts of data for their\nanalysis and use of decision support. Features of NoSQL databases and\ncategories are described. The developed Big Data Model \"Entity and Features\"\nallows determining the distance between the sources of data on the availability\nof information about a particular entity. The information structure of Big Data\nhas been devised. It became a basis for further research and for concentrating\non a problem of development of diverse data without their preliminary\nintegration.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 16:13:52 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Shakhovska", "Nataliya", ""], ["Bolubash", "Uyrii", ""], ["Veres", "Oleh", ""]]}, {"id": "1905.01307", "submitter": "Nataliya Shakhovska Prof", "authors": "Nataliya Shakhovska, Yurii Bolubash", "title": "Dataspace architecture and manage its components class projection", "comments": "10 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big Data technology is described. Big data is a popular term used to describe\nthe exponential growth and availability of data, both structured and\nunstructured. There is constructed dataspace architecture. Dataspace has\nfocused solely - and passionately - on providing unparalleled expertise in\nbusiness intelligence and data warehousing strategy and implementation.\nDataspaces are an abstraction in data management that aims to overcome some of\nthe problems encountered in data integration system. In our case it is block\nvector for heterogeneous data representation. Traditionally, data integration\nand data exchange systems have aimed to offer many of the purported services of\ndataspace systems. Dataspaces can be viewed as a next step in the evolution of\ndata integration architectures, but are distinct from current data integration\nsystems in the following way. Data integration systems require semantic\nintegration before any services can be provided. Hence, although there is not a\nsingle schema to which all the data conforms and the data resides in a\nmultitude of host systems, the data integration system knows the precise\nrelationships between the terms used in each schema. As a result, significant\nup-front effort is required in order to set up a data integration system. For\nrealization of data integration from different sources we used SQL Server\nIntegration Services, SSIS. For developing the portal as an architectural\npattern there is used pattern Model-View-Controller (MVC). There is specifics\ndebug operation data space as a complex system. The query translator in\nBackus/Naur Form is give.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 16:18:19 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Shakhovska", "Nataliya", ""], ["Bolubash", "Yurii", ""]]}, {"id": "1905.01349", "submitter": "Anastasios Gounaris", "authors": "Nikodimos Nikolaidis and Anastasios Gounaris", "title": "Adaptive filter ordering in Spark", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report describes a technical methodology to render the Apache Spark\nexecution engine adaptive. It presents the engineering solutions, which\nspecifically target to adaptively reorder predicates in data streams with\nevolving statistics. The system extension developed is available as an\nopen-source prototype. Indicative experimental results show its overhead and\nsensitivity to tuning parameters.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 19:36:55 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Nikolaidis", "Nikodimos", ""], ["Gounaris", "Anastasios", ""]]}, {"id": "1905.01403", "submitter": "Yu Huang", "authors": "Yuqi Zhang, Yu Huang, Hengfeng Wei, Jian Lu", "title": "Remove-Win: a Design Framework for Conflict-free Replicated Data\n  Collections", "comments": "revised after submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet-scale distributed systems often replicate data within and across\ndata centers to provide low latency and high availability despite node and\nnetwork failures. Replicas are required to accept updates without coordination\nwith each other, and the updates are then propagated asynchronously. This\nbrings the issue of conflict resolution among concurrent updates, which is\noften challenging and error-prone. The Conflict-free Replicated Data Type\n(CRDT) framework provides a principled approach to address this challenge.\n  This work focuses on a special type of CRDT, namely the Conflict-free\nReplicated Data Collection (CRDC), e.g. list and queue. The CRDC can have\ncomplex and compound data items, which are organized in structures of rich\nsemantics. Complex CRDCs can greatly ease the development of upper-layer\napplications, but also makes the conflict resolution notoriously difficult.\nThis explains why existing CRDC designs are tricky, and hard to be generalized\nto other data types. A design framework is in great need to guide the\nsystematic design of new CRDCs.\n  To address the challenges above, we propose the Remove-Win Design Framework.\nThe remove-win strategy for conflict resolution is simple but powerful. The\nremove operation just wipes out the data item, no matter how complex the value\nis. The user of the CRDC only needs to specify conflict resolution for\nnon-remove operations. This resolution is destructed to three basic cases and\nare left as open terms in the CRDC design skeleton. Stubs containing\nuser-specified conflict resolution logics are plugged into the skeleton to\nobtain concrete CRDC designs. We demonstrate the effectiveness of our design\nframework via a case study of designing a conflict-free replicated priority\nqueue. Performance measurements also show the efficiency of the design derived\nfrom our design framework.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 01:21:33 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 07:21:42 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Zhang", "Yuqi", ""], ["Huang", "Yu", ""], ["Wei", "Hengfeng", ""], ["Lu", "Jian", ""]]}, {"id": "1905.01443", "submitter": "Rupei Xu", "authors": "Rupei Xu, Andr\\'as Farag\\'o and Jason P. Jue", "title": "Job Edge-Fog Interconnection Network Creation Game in Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.GT cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the first paper to address the topology structure of Job Edge-Fog\ninterconnection network in the perspective of network creation game. A two\nlevel network creation game model is given, in which the first level is similar\nto the traditional network creation game with total length objective to other\nnodes. The second level adopts two types of cost functions, one is created\nbased on the Jackson-Wolinsky type of distance based utility, another is\ncreated based on the Network-Only Cost in the IoT literature. We show the\nperformance of this two level game (Price of Anarchy). This work discloses how\nthe selfish strategies of each individual device can influence the global\ntopology structure of the job edge-fog interconnection network and provides\ntheoretical foundations of the IoT infrastructure construction. A significant\nadvantage of this framework is that it can avoid solving the traditional\nexpensive and impractical quadratic assignment problem, which was the typical\nframework to study this task. Furthermore, it can control the systematic\nperformance based only on one or two cost parameters of the job edge-fog\nnetworks, independently and in a distributed way.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 06:35:26 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 08:12:48 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Xu", "Rupei", ""], ["Farag\u00f3", "Andr\u00e1s", ""], ["Jue", "Jason P.", ""]]}, {"id": "1905.01517", "submitter": "Chengzheng Sun", "authors": "David Sun, Chengzheng Sun, Agustina Ng, Weiwei Cai", "title": "Real Differences between OT and CRDT in Building Co-Editing Systems and\n  Real World Applications", "comments": "16 pages. This article has been revised in accordance to the other\n  two companion articles, which have been recently published at PACMHCI\n  (https://doi.org/10.1145/3375186; and https://doi.org/10.1145/3392825,\n  respectively). arXiv admin note: substantial text overlap with\n  arXiv:1810.02137, arXiv:1905.01302", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.HC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OT (Operational Transformation) was invented for supporting real-time\nco-editors in the late 1980s and has evolved to become a core technique used in\ntoday's working co-editors and adopted in major industrial products. CRDT\n(Commutative Replicated Data Type) for co-editors was first proposed around\n2006, under the name of WOOT (WithOut Operational Transformation). Follow-up\nCRDT variations are commonly labeled as \"post-OT\" techniques and have made\nbroad claims of superiority over OT solutions, in terms of correctness, time\nand space complexity, simplicity, etc. Over one decade later, however, OT\nremains the choice for building the vast majority of co-editors, whereas CRDT\nis rarely found in working co-editors. Why? To seek truth from facts, we set\nout to conduct a comprehensive and critical review of representative OT and\nCRDT solutions and working co-editors based on them. From this work, we have\nmade important discoveries about OT and CRDT, and revealed facts and evidences\nthat refute CRDT claims over OT on all accounts. We present our discoveries in\nthree related and complementary articles.\n  In prior two articles, we have revealed the similarities of OT and CRDT in\nfollowing the same general transformation approach in co-editors, and their\nreal differences in correctness and complexity. In this article, we examine the\nrole of building working co-editors in shaping OT and CRDT research and\nsolutions, and consequential differences in the choice between OT and CRDT in\nreal world co-editors and industry products. In particular, we review the\nevolution of co-editors from research vehicles to real world applications, and\ndiscuss representative OT-based co-editors and alternative approaches in\nindustry products and open source projects. Moreover, we evaluate CRDT-based\nco-editors in relation to published CRDT solutions, and clarify some myths\nsurrounding \"peer-to-peer\" co-editing.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 10:10:28 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 15:15:23 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Sun", "David", ""], ["Sun", "Chengzheng", ""], ["Ng", "Agustina", ""], ["Cai", "Weiwei", ""]]}, {"id": "1905.01518", "submitter": "Chengzheng Sun", "authors": "Chengzheng Sun, David Sun, Agustina, Weiwei Cai", "title": "Real Differences between OT and CRDT under a General Transformation\n  Framework for Consistency Maintenance in Co-Editors", "comments": "25 pages. This is the author's version of the revised and published\n  article at PACMHCI, Vol.4. GROUP, Article 6, January 2020:\n  https://doi.org/10.1145/3375186. arXiv admin note: substantial text overlap\n  with arXiv:1810.02137, arXiv:1905.01302, arXiv:1905.01517", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.HC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OT (Operational Transformation) was invented for supporting real-time\nco-editors in the late 1980s and has evolved to become a core technique used in\ntoday's working co-editors and adopted in major industrial products. CRDT\n(Commutative Replicated Data Type) for co-editors was first proposed around\n2006, under the name of WOOT (WithOut Operational Transformation). Follow-up\nCRDT variations are commonly labeled as \"post-OT\" techniques capable of making\nconcurrent operations natively commutative in co-editors. On top of that, CRDT\nsolutions have made broad claims of superiority over OT solutions, and\nroutinely portrayed OT as an incorrect, complex and inefficient technique. Over\none decade later, however, OT remains the choice for building the vast majority\nof co-editors, whereas CRDT is rarely found in working co-editors.\nContradictions between the reality and CRDT's purported advantages have been\nthe source of much confusion and debate in co-editing communities. Have the\nvast majority of co-editors been unfortunate in choosing the faulty and\ninferior OT, or those CRDT claims are false? What are the real differences\nbetween OT and CRDT for co-editors? What are the key factors and underlying\nreasons behind the choices between OT and CRDT in the real world? To seek truth\nfrom facts, we set out to conduct a comprehensive and critical review on\nrepresentative OT and CRDT solutions and working co-editors based on them. From\nthis work, we have made important discoveries about OT and CRDT, and revealed\nfacts and evidences that refute CRDT claims over OT on all accounts. We report\nour discoveries in a series of three articles and the current article is the\nfirst one in this series. We hope the discoveries from this work help clear up\ncommon misconceptions and confusions surrounding OT and CRDT, and accelerate\nprogress in co-editing technology for real world applications.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 07:22:33 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 15:03:41 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Sun", "Chengzheng", ""], ["Sun", "David", ""], ["Agustina", "", ""], ["Cai", "Weiwei", ""]]}, {"id": "1905.01596", "submitter": "Donghui Yan", "authors": "Donghui Yan, Yingjie Wang, Jin Wang, Guodong Wu, Honggang Wang", "title": "Fast communication-efficient spectral clustering over distributed data", "comments": "27 pages, 7 figures", "journal-ref": "IEEE Transactions on Big Data, 2019", "doi": "10.1109/TBDATA.2019.2907985", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decades have seen a surge of interests in distributed computing\nthanks to advances in clustered computing and big data technology. Existing\ndistributed algorithms typically assume {\\it all the data are already in one\nplace}, and divide the data and conquer on multiple machines. However, it is\nincreasingly often that the data are located at a number of distributed sites,\nand one wishes to compute over all the data with low communication overhead.\nFor spectral clustering, we propose a novel framework that enables its\ncomputation over such distributed data, with \"minimal\" communications while a\nmajor speedup in computation. The loss in accuracy is negligible compared to\nthe non-distributed setting. Our approach allows local parallel computing at\nwhere the data are located, thus turns the distributed nature of the data into\na blessing; the speedup is most substantial when the data are evenly\ndistributed across sites. Experiments on synthetic and large UC Irvine datasets\nshow almost no loss in accuracy with our approach while about 2x speedup under\nvarious settings with two distributed sites. As the transmitted data need not\nbe in their original form, our framework readily addresses the privacy concern\nfor data sharing in distributed computing.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 04:02:28 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Yan", "Donghui", ""], ["Wang", "Yingjie", ""], ["Wang", "Jin", ""], ["Wu", "Guodong", ""], ["Wang", "Honggang", ""]]}, {"id": "1905.01656", "submitter": "Umair Mohammad", "authors": "Umair Mohammad and Sameh Sorour", "title": "Adaptive Task Allocation for Asynchronous Federated and Parallelized\n  Mobile Edge Learning", "comments": "7 pages, 3 figures, submitted to IEEE TVT as a correspondence paper\n  (conference paper), 3 Appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a scheme to efficiently execute distributed learning\ntasks in an asynchronous manner while minimizing the gradient staleness on\nwireless edge nodes with heterogeneous computing and communication capacities.\nThe approach considered in this paper ensures that all devices work for a\ncertain duration that covers the time for data/model distribution, learning\niterations, model collection and global aggregation. The resulting problem is\nan integer non-convex program with quadratic equality constraints as well as\nlinear equality and inequality constraints. Because the problem is NP-hard, we\nrelax the integer constraints in order to solve it efficiently with available\nsolvers. Analytical bounds are derived using the KKT conditions and Lagrangian\nanalysis in conjunction with the suggest-and-improve approach. Results show\nthat our approach reduces the gradient staleness and can offer better accuracy\nthan the synchronous scheme and the asynchronous scheme with equal task\nallocation.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 11:22:14 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 15:42:24 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 01:37:24 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Mohammad", "Umair", ""], ["Sorour", "Sameh", ""]]}, {"id": "1905.01663", "submitter": "Shuo Wan", "authors": "Shuo Wan, Jiaxun Lu, Pingyi Fan, and Khaled B. Letaief", "title": "Towards Big data processing in IoT: network management for online edge\n  data processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.DC cs.IT eess.IV math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heavy data load and wide cover range have always been crucial problems for\ninternet of things (IoT). However, in mobile-edge computing (MEC) network, the\nhuge data can be partly processed at the edge. In this paper, a MEC-based big\ndata analysis network is discussed. The raw data generated by distributed\nnetwork terminals are collected and processed by edge servers. The edge servers\nsplit out a large sum of redundant data and transmit extracted information to\nthe center cloud for further analysis. However, for consideration of limited\nedge computation ability, part of the raw data in huge data sources may be\ndirectly transmitted to the cloud. To manage limited resources online, we\npropose an algorithm based on Lyapunov optimization to jointly optimize the\npolicy of edge processor frequency, transmission power and bandwidth\nallocation. The algorithm aims at stabilizing data processing delay and saving\nenergy without knowing probability distributions of data sources. The proposed\nnetwork management algorithm may contribute to big data processing in future\nIoT.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 11:42:38 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Wan", "Shuo", ""], ["Lu", "Jiaxun", ""], ["Fan", "Pingyi", ""], ["Letaief", "Khaled B.", ""]]}, {"id": "1905.01749", "submitter": "Max Noormohammadpour", "authors": "Mohammad Noormohammadpour, Srikanth Kandula, Cauligi S. Raghavendra,\n  Sriram Rao", "title": "Efficient Inter-Datacenter Bulk Transfers with Mixed Completion Time\n  Objectives", "comments": "Accepted to Elsevier Computer Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bulk transfers from one to multiple datacenters can have many different\ncompletion time objectives ranging from quickly replicating some $k$ copies to\nminimizing the time by which the last destination receives a full replica. We\ndesign an SDN-style wide-area traffic scheduler that optimizes different\ncompletion time objectives for various requests. The scheduler builds, for each\nbulk transfer, one or more multicast forwarding trees which preferentially use\nlightly loaded network links. Multiple multicast trees are used per bulk\ntransfer to insulate destinations that have higher available bandwidth and can\nhence finish quickly from congested destinations. These decisions--how many\ntrees to construct and which receivers to serve using a given tree--result from\nan optimization problem that minimizes a weighted sum of transfers' completion\ntime objectives and their bandwidth consumption. Results from simulations and\nemulations on Mininet show that our scheduler, Iris, can improve different\ncompletion time objectives by about $2.5\\times$.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 21:22:44 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 06:02:51 GMT"}, {"version": "v3", "created": "Sun, 15 Sep 2019 16:14:54 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Noormohammadpour", "Mohammad", ""], ["Kandula", "Srikanth", ""], ["Raghavendra", "Cauligi S.", ""], ["Rao", "Sriram", ""]]}, {"id": "1905.01848", "submitter": "Xi Zheng", "authors": "Xi Zheng", "title": "Real-Time Simulation in Real-Time Systems: Current Status, Research\n  Challenges and A Way Forward", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation especially real-time simulation have been widely used for the\ndesign and testing of real-time systems. The advancement of simulation tools\nhas largely attributed to the evolution of computing technologies. With the\nreduced cost and dramatically improved performance, researchers and industry\nengineers are able to access variety of effective and highly performing\nsimulation tools. This chapter describes the definition and importance of\nreal-time simulation for real-time systems. Moreover, the chapter also points\nout the challenges met in real-time simulation and walks through some promising\nresearch progress in addressing some of the challenges.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 07:20:24 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Zheng", "Xi", ""]]}, {"id": "1905.02113", "submitter": "Daniel Riley", "authors": "Daniel Riley, Christopher Jones", "title": "Multi-threaded Output in CMS using ROOT", "comments": "Submitted to CHEP 2018 - 23rd International Conference on Computing\n  in High Energy and Nuclear Physics; 6 pages, 4 figures, uses webofc class", "journal-ref": null, "doi": "10.1051/epjconf/201921402016", "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  CMS has worked aggressively to make use of multi-core architectures,\nroutinely running 4- to 8-core production jobs in 2017. The primary impediment\nto efficiently scaling beyond 8 cores has been our ROOT-based output module,\nwhich has been necessarily single threaded. In this paper we explore the\nchanges made to the CMS framework and our ROOT output module to overcome the\nprevious scaling limits, using two new ROOT features: the\n\\texttt{TBufferMerger} asynchronous file merger, and Implicit Multi-Threading.\nWe examine the architecture of the new parallel output module, the specific\naccommodations and modifications that were made to ensure compatibility with\nthe CMS framework scheduler, and the performance characteristics of the new\noutput module.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 15:52:25 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Riley", "Daniel", ""], ["Jones", "Christopher", ""]]}, {"id": "1905.02119", "submitter": "Maria Casimiro", "authors": "Maria Casimiro and Diego Didona and Paolo Romano and Lu\\'is Rodrigues\n  and Willy Zwanepoel and David Garlan", "title": "Lynceus: Cost-efficient Tuning and Provisioning of Data Analytic Jobs", "comments": "This updated version features a novel extension of our approach: the\n  time out mechanism. Additionally, we improved the write-up of the paper,\n  fruit of the collaboration with professor David Garlan and Carnegie Mellon\n  Univeristy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern data analytic and machine learning jobs find in the cloud a natural\ndeployment platform to satisfy their notoriously large resource requirements.\nYet, to achieve cost efficiency, it is crucial to identify a deployment\nconfiguration that satisfies user-defined QoS constraints (e.g., on execution\ntime), while avoiding unnecessary over-provisioning. This paper introduces\nLynceus, a new approach for the optimization of cloud based data analytic jobs\nthat improves overstate-of-the-art approaches by enabling significant cost\nsavings both in terms of the final recommended configuration and of the\noptimization process used to recommend configurations. Unlike existing\nsolutions, Lynceus optimizes in a joint fashion both the cloud-related and the\napplication-level parameters. This allows for a reduction of the cost of\nrecommended configurations by up to 3.7x at the 90-th percentile with respect\nto existing approaches, which treat the optimization of cloud-related and\napplication-level parameters as two independent problems. Further, Lynceus\nreduces the cost of the optimization process (i.e., the cloud cost incurred for\ntesting configurations) by up to 11x. Such an improvement is achieved thanks to\ntwo mechanisms: i) a timeout approach which allows to abort the exploration of\nconfigurations that are deemed suboptimal, while still extracting useful\ninformation to guide future explorations and to improve its predictive model -\ndifferently from recent works, which either incur the full cost for testing\nsuboptimal configurations or are unable to extract any knowledge from aborted\nruns; ii) a long-sighted and budget-aware technique that determines which\nconfigurations to test by predicting the long-term impact of each exploration -\nunlike state-of-the-art approaches for the optimization of cloud jobs, which\nadopt greedy optimization methods.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 16:10:39 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 15:59:38 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Casimiro", "Maria", ""], ["Didona", "Diego", ""], ["Romano", "Paolo", ""], ["Rodrigues", "Lu\u00eds", ""], ["Zwanepoel", "Willy", ""], ["Garlan", "David", ""]]}, {"id": "1905.02158", "submitter": "Zhuozhao Li", "authors": "Yadu Babuji, Anna Woodard, Zhuozhao Li, Daniel S. Katz, Ben Clifford,\n  Rohan Kumar, Lukasz Lacinski, Ryan Chard, Justin M. Wozniak, Ian Foster,\n  Michael Wilde, Kyle Chard", "title": "Parsl: Pervasive Parallel Programming in Python", "comments": null, "journal-ref": null, "doi": "10.1145/3307681.3325400", "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-level programming languages such as Python are increasingly used to\nprovide intuitive interfaces to libraries written in lower-level languages and\nfor assembling applications from various components. This migration towards\norchestration rather than implementation, coupled with the growing need for\nparallel computing (e.g., due to big data and the end of Moore's law),\nnecessitates rethinking how parallelism is expressed in programs. Here, we\npresent Parsl, a parallel scripting library that augments Python with simple,\nscalable, and flexible constructs for encoding parallelism. These constructs\nallow Parsl to construct a dynamic dependency graph of components that it can\nthen execute efficiently on one or many processors. Parsl is designed for\nscalability, with an extensible set of executors tailored to different use\ncases, such as low-latency, high-throughput, or extreme-scale execution. We\nshow, via experiments on the Blue Waters supercomputer, that Parsl executors\ncan allow Python scripts to execute components with as little as 5 ms of\noverhead, scale to more than 250 000 workers across more than 8000 nodes, and\nprocess upward of 1200 tasks per second. Other Parsl features simplify the\nconstruction and execution of composite programs by supporting elastic\nprovisioning and scaling of infrastructure, fault-tolerant execution, and\nintegrated wide-area data management. We show that these capabilities satisfy\nthe needs of many-task, interactive, online, and machine learning applications\nin fields such as biology, cosmology, and materials science.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 17:19:10 GMT"}, {"version": "v2", "created": "Sat, 18 May 2019 02:56:23 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Babuji", "Yadu", ""], ["Woodard", "Anna", ""], ["Li", "Zhuozhao", ""], ["Katz", "Daniel S.", ""], ["Clifford", "Ben", ""], ["Kumar", "Rohan", ""], ["Lacinski", "Lukasz", ""], ["Chard", "Ryan", ""], ["Wozniak", "Justin M.", ""], ["Foster", "Ian", ""], ["Wilde", "Michael", ""], ["Chard", "Kyle", ""]]}, {"id": "1905.02381", "submitter": "Sumit Tetarave", "authors": "Sumit Kumar Tetarave, Somanath Tripathy, R. K. Ghosh", "title": "Enhancing Quality of Experience using DHT Overlay on Device-to-Device\n  Communications in LTE-A Networks", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": "e4546", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In [1], we proposed a two-tier model for creating and maintaining a\ndistributed hash table (DHT) overlay of smartphones. The purpose was to reduce\nInternet usage and increase D2D content sharing over LTE-A/5G network. However,\nthe real challenge is not in creating a two-tier model, but to evolve an\nefficient overlay that offers enhanced opportunities for device-to-device (D2D)\ncontent sharing over the existing model. In this paper, we formulated the\nselection of tier-1 devices as finding P-medians in a distribution network and\nsolved it using Lagrangian relaxation method. Tier-2 devices become clients\nseeking content sharing services from tier-1 devices. A strong motivation in\nthis work is to raise a user's perception of the grade of service known as\nQuality of Experience (QoE). We analyzed the QoE assessment challenge for\nresource-constrained smartphones under the proposed model of enhanced D2D\ncommunication. Our focus is to establish a framework to assess QoE for apps and\nservices over LTE-A/5G networks with an improved level of D2D communication.\nThe simulation and the experimental results validate the claim that substantial\nimprovements in QoE are indeed possible with the proposed mathematical model\nfor selection and placement of tier-1 mobile devices and maintaining a DHT for\nD2D communication.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 06:53:56 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Tetarave", "Sumit Kumar", ""], ["Tripathy", "Somanath", ""], ["Ghosh", "R. K.", ""]]}, {"id": "1905.02448", "submitter": "Yehia Elkhatib PhD", "authors": "Faiza Samreen, Gordon S Blair, Yehia Elkhatib", "title": "Transferable Knowledge for Low-cost Decision Making in Cloud\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users of cloud computing are increasingly overwhelmed with the wide range of\nproviders and services offered by each provider. As such, many users select\ncloud services based on description alone. An emerging alternative is to use a\ndecision support system (DSS), which typically relies on gaining insights from\nobservational data in order to assist a customer in making decisions regarding\noptimal deployment or redeployment of cloud applications. The primary activity\nof such systems is the generation of a prediction model (e.g. using machine\nlearning), which requires a significantly large amount of training data.\nHowever, considering the varying architectures of applications, cloud\nproviders, and cloud offerings, this activity is not sustainable as it incurs\nadditional time and cost to collect training data and subsequently train the\nmodels. We overcome this through developing a Transfer Learning (TL) approach\nwhere the knowledge (in the form of the prediction model and associated data\nset) gained from running an application on a particular cloud infrastructure is\ntransferred in order to substantially reduce the overhead of building new\nmodels for the performance of new applications and/or cloud infrastructures. In\nthis paper, we present our approach and evaluate it through extensive\nexperimentation involving three real world applications over two major public\ncloud providers, namely Amazon and Google. Our evaluation shows that our novel\ntwo-mode TL scheme increases overall efficiency with a factor of 60\\% reduction\nin the time and cost of generating a new prediction model. We test this under a\nnumber of cross-application and cross-cloud scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 10:08:19 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Samreen", "Faiza", ""], ["Blair", "Gordon S", ""], ["Elkhatib", "Yehia", ""]]}, {"id": "1905.02637", "submitter": "Amir Daneshmand", "authors": "Ying Sun, Amir Daneshmand, Gesualdo Scutari", "title": "Distributed Optimization Based on Gradient-tracking Revisited: Enhancing\n  Convergence Rate via Surrogation", "comments": "This revised version contains explicit expression of the convergence\n  rates. Furthermore, new rates are provided in the case data among the agents\n  are statistically similar", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study distributed multiagent optimization over (directed, time-varying)\ngraphs. We consider the minimization of $F+G$ subject to convex constraints,\nwhere $F$ is the smooth strongly convex sum of the agent's losses and $G$ is a\nnonsmooth convex function. We build on the SONATA algorithm: the algorithm\nemploys the use of surrogate objective functions in the agents' subproblems\n(going thus beyond linearization, such as proximal-gradient) coupled with a\nperturbed (push-sum) consensus mechanism that aims to track locally the\ngradient of $F$. SONATA achieves precision $\\epsilon>0$ on the objective value\nin $\\mathcal{O}(\\kappa_g \\log(1/\\epsilon))$ gradient computations at each node\nand $\\tilde{\\mathcal{O}}\\big(\\kappa_g (1-\\rho)^{-1/2} \\log(1/\\epsilon)\\big)$\ncommunication steps, where $\\kappa_g$ is the condition number of $F$ and $\\rho$\ncharacterizes the connectivity of the network. This is the first linear rate\nresult for distributed composite optimization; it also improves on existing\n(non-accelerated) schemes just minimizing $F$, whose rate depends on much\nlarger quantities than $\\kappa_g$ (e.g., the worst-case condition number among\nthe agents). When considering in particular empirical risk minimization\nproblems with statistically similar data across the agents, SONATA employing\nhigh-order surrogates achieves precision $\\epsilon>0$ in\n$\\mathcal{O}\\big((\\beta/\\mu) \\log(1/\\epsilon)\\big)$ iterations and\n$\\tilde{\\mathcal{O}}\\big((\\beta/\\mu) (1-\\rho)^{-1/2} \\log(1/\\epsilon)\\big)$\ncommunication steps, where $\\beta$ measures the degree of similarity of the\nagents' losses and $\\mu$ is the strong convexity constant of $F$. Therefore,\nwhen $\\beta/\\mu < \\kappa_g$, the use of high-order surrogates yields provably\nfaster rates than what achievable by first-order models; this is without\nexchanging any Hessian matrix over the network.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 15:22:35 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 02:37:00 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Sun", "Ying", ""], ["Daneshmand", "Amir", ""], ["Scutari", "Gesualdo", ""]]}, {"id": "1905.02803", "submitter": "Dmitry Pekurovsky", "authors": "Dmitry Pekurovsky", "title": "P3DFFT: a framework for parallel computations of Fourier transforms in\n  three dimensions", "comments": null, "journal-ref": "SIAM Journal on Scientific Computing, 34(4), C192-C209 (2012)", "doi": "10.1137/11082748X", "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fourier and related transforms is a family of algorithms widely employed in\ndiverse areas of computational science, notoriously difficult to scale on\nhigh-performance parallel computers with large number of processing elements\n(cores). This paper introduces a popular software package called P3DFFT\nimplementing Fast Fourier Transforms (FFT) in three dimensions (3D) in a highly\nefficient and scalable way. It overcomes a well-known scalability bottleneck of\n3D FFT implementations by using two-dimensional domain decomposition. Designed\nfor portable performance, P3DFFT achieves excellent timings for a number of\nsystems and problem sizes. On Cray XT5 system P3DFFT attains 45% efficiency in\nweak scaling from 128 to 65,536 computational cores. Library features include\nFourier and Chebyshev transforms, Fortran and C interfaces, in- and\nout-of-place transforms, uneven data grids, single and double precision. P3DFFT\nis available as open source at http://code.google.com/p/p3dfft/. This paper\ndiscusses P3DFFT implementation and performance in a way that helps guide the\nuser in making optimal choices for parameters of their runs.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 20:47:58 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Pekurovsky", "Dmitry", ""]]}, {"id": "1905.02847", "submitter": "Victor Zakhary", "authors": "Victor Zakhary, Divyakant Agrawal, Amr El Abbadi", "title": "Atomic Commitment Across Blockchains", "comments": null, "journal-ref": null, "doi": "10.14778/3397230.3397231", "report-no": null, "categories": "cs.DB cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent adoption of blockchain technologies and open permissionless\nnetworks suggest the importance of peer-to-peer atomic cross-chain transaction\nprotocols. Users should be able to atomically exchange tokens and assets\nwithout depending on centralized intermediaries such as exchanges. Recent\npeer-to-peer atomic cross-chain swap protocols use hashlocks and timelocks to\nensure that participants comply to the protocol. However, an expired timelock\ncould lead to a violation of the all-or-nothing atomicity property. An honest\nparticipant who fails to execute a smart contract on time due to a crash\nfailure or network delays at her site might end up losing her assets. Although\na crashed participant is the only participant who ends up worse off, current\nproposals are unsuitable for atomic cross-chain transactions in asynchronous\nenvironments where crash failures and network delays are the norm. In this\npaper, we present AC3WN, the first decentralized all-or-nothing atomic\ncross-chain commitment protocol. The redeem and refund events of the smart\ncontracts that exchange assets are modeled as conflicting events. An open\npermissionless network of witnesses is used to guarantee that conflicting\nevents could never simultaneously occur and either all smart contracts in an\natomic cross-chain transaction are redeemed or all of them are refunded.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 00:02:12 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 18:53:12 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Zakhary", "Victor", ""], ["Agrawal", "Divyakant", ""], ["Abbadi", "Amr El", ""]]}, {"id": "1905.03012", "submitter": "Janne H. Korhonen", "authors": "Klaus-Tycho Foerster and Janne H. Korhonen and Joel Rybicki and Stefan\n  Schmid", "title": "Brief Announcement: Does Preprocessing Help under Congestion?", "comments": "Appears in PODC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the power of preprocessing in the CONGEST model.\nSchmid and Suomela (ACM HotSDN 2013) introduced the SUPPORTED CONGEST model to\nstudy the application of distributed algorithms in Software-Defined Networks\n(SDNs). In this paper, we show that a large class of lower bounds in the\nCONGEST model still hold in the SUPPORTED model, highlighting the robustness of\nthese bounds. This also raises the question how much does preprocessing help in\nthe CONGEST model.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 11:38:20 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Foerster", "Klaus-Tycho", ""], ["Korhonen", "Janne H.", ""], ["Rybicki", "Joel", ""], ["Schmid", "Stefan", ""]]}, {"id": "1905.03061", "submitter": "Nataliya Shakhovska Prof", "authors": "Shakhovska Nataliya, Veres Oleh, Hirnyak Mariia", "title": "Generalized formal model of big data", "comments": null, "journal-ref": "ECONTECHMOD. AN INTERNATIONAL QUARTERLY JOURNAL - 2016, Vol. 05,\n  No. 2, 33-38", "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article dwells on the basic characteristic features of the Big Data\ntechnologies. It is analyzed the existing definition of the \"big data\" term.\nThe article proposes and describes the elements of the generalized formal model\nof big data. It is analyzed the peculiarities of the application of the\nproposed model components. It described the fundamental differences between Big\nData technology and business analytics. Big Data is supported by the\ndistributed file system Google File System technology, Cassandra, HBase, Lustre\nand ZFS, by the MapReduce and Hadoop programming constructs and many other\nsolutions. According to the experts, such as McKinsey Institute, the\nmanufacturing, healthcare, trade, administration and control of individual\nmovements undergo the transformations under the influence of the Big Data.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 03:01:20 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Nataliya", "Shakhovska", ""], ["Oleh", "Veres", ""], ["Mariia", "Hirnyak", ""]]}, {"id": "1905.03111", "submitter": "Xiong Zheng", "authors": "Xiong Zheng, Vijay Garg", "title": "Parallel and Distributed Algorithms for the housing allocation Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give parallel and distributed algorithms for the housing allocation\nproblem. In this problem, there is a set of agents and a set of houses. Each\nagent has a strict preference list for a subset of houses. We need to find a\nmatching such that some criterion is optimized. One such criterion is Pareto\nOptimality. A matching is Pareto optimal if no coalition of agents can be\nstrictly better off by exchanging houses among themselves. We also study the\nhousing market problem, a variant of the housing allocation problem, where each\nagent initially owns a house. In addition to Pareto optimality, we are also\ninterested in finding the core of a housing market. A matching is in the core\nif there is no coalition of agents that can be better off by breaking away from\nother agents and switching houses only among themselves.\n  In the first part of this work, we show that computing a Pareto optimal\nmatching of a house allocation is in {\\bf CC} and computing the core of a\nhousing market is {\\bf CC}-hard. Given a matching, we also show that verifying\nwhether it is in the core can be done in {\\bf NC}. We then give an algorithm to\nshow that computing a maximum Pareto optimal matching for the housing\nallocation problem is in {\\bf RNC}^2 and quasi-{\\bf NC}^2. In the second part\nof this work, we present a distributed version of the top trading cycle\nalgorithm for finding the core of a housing market. To that end, we first\npresent two algorithms for finding all the disjoint cycles in a functional\ngraph: a Las Vegas algorithm which terminates in $O(\\log l)$ rounds with high\nprobability, where $l$ is the length of the longest cycle, and a deterministic\nalgorithm which terminates in $O(\\log^* n \\log l)$ rounds, where $n$ is the\nnumber of nodes in the graph. Both algorithms work in the synchronous\ndistributed model and use messages of size $O(\\log n)$.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 14:46:32 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Zheng", "Xiong", ""], ["Garg", "Vijay", ""]]}, {"id": "1905.03113", "submitter": "Yongquan Fu", "authors": "Yongquan Fu, Dongsheng Li, Siqi Shen, Yiming Zhang, Kai Chen", "title": "Locality-Sensitive Sketching for Resilient Network Flow Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network monitoring is vital in modern clouds and data center networks for\ntraffic engineering, network diagnosis, network intrusion detection, which need\ndiverse traffic statistics ranging from flow size distributions to heavy\nhitters. To cope with increasing network rates and massive traffic volumes,\nsketch based approximate measurement has been extensively studied to trade the\naccuracy for memory and computation cost, which unfortunately, is sensitive to\nhash collisions. In addition, deploying the sketch involves fine-grained\nperformance control and instrumentation.\n  This paper presents a locality-sensitive sketch (LSS) to be resilient to hash\ncollisions. LSS proactively minimizes the estimation error due to hash\ncollisions with an autoencoder based optimization model, and reduces the\nestimation variance by keeping similar network flows to the same bucket array.\nTo illustrate the feasibility of the sketch, we develop a disaggregated\nmonitoring application that supports non-intrusive sketching deployment and\nnative network-wide analysis. Testbed shows that the framework adapts to line\nrates and provides accurate query results. Real-world trace-driven simulations\nshow that LSS remains stable performance under wide ranges of parameters and\ndramatically outperforms state-of-the-art sketching structures, with over\n$10^3$ to $10^5$ times reduction in relative errors for per-flow queries as the\nratio of the number of buckets to the number of network flows reduces from 10\\%\nto 0.1\\%.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 14:47:04 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Fu", "Yongquan", ""], ["Li", "Dongsheng", ""], ["Shen", "Siqi", ""], ["Zhang", "Yiming", ""], ["Chen", "Kai", ""]]}, {"id": "1905.03135", "submitter": "Patrick Rebeschini", "authors": "Dominic Richards and Patrick Rebeschini", "title": "Optimal Statistical Rates for Decentralised Non-Parametric Regression\n  with Linear Speed-Up", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse the learning performance of Distributed Gradient Descent in the\ncontext of multi-agent decentralised non-parametric regression with the square\nloss function when i.i.d. samples are assigned to agents. We show that if\nagents hold sufficiently many samples with respect to the network size, then\nDistributed Gradient Descent achieves optimal statistical rates with a number\nof iterations that scales, up to a threshold, with the inverse of the spectral\ngap of the gossip matrix divided by the number of samples owned by each agent\nraised to a problem-dependent power. The presence of the threshold comes from\nstatistics. It encodes the existence of a \"big data\" regime where the number of\nrequired iterations does not depend on the network topology. In this regime,\nDistributed Gradient Descent achieves optimal statistical rates with the same\norder of iterations as gradient descent run with all the samples in the\nnetwork. Provided the communication delay is sufficiently small, the\ndistributed protocol yields a linear speed-up in runtime compared to the\nsingle-machine protocol. This is in contrast to decentralised optimisation\nalgorithms that do not exploit statistics and only yield a linear speed-up in\ngraphs where the spectral gap is bounded away from zero. Our results exploit\nthe statistical concentration of quantities held by agents and shed new light\non the interplay between statistics and communication in decentralised methods.\nBounds are given in the standard non-parametric setting with source/capacity\nassumptions.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 15:08:28 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 11:29:35 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Richards", "Dominic", ""], ["Rebeschini", "Patrick", ""]]}, {"id": "1905.03184", "submitter": "Kiril Dichev", "authors": "Kiril Dichev, Dimitrios S. Nikolopoulos", "title": "Implementing Efficient Message Logging Protocols as MPI Application\n  Extensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Message logging protocols are enablers of local rollback, a more efficient\nalternative to global rollback, for fault tolerant MPI applications. Until now,\nmessage logging MPI implementations have incurred the overheads of a redesign\nand redeployment of an MPI library, as well as continued performance penalties\nacross various kernels. Successful research efforts for message logging\nimplementations do exist, but not a single one of them can be easily deployed\ntoday by more than a few experts. In contrast, in this work we build efficient\nmessage logging capabilities on top of an MPI library with no message logging\ncapabilities; we do so for two different HPC kernels, one with a global\nexchange pattern (CG), and one with a neighbourhood exchange pattern (LULESH).\nWhile our library of choice ULFM detects failure and recovers MPI\ncommunicators, we build on that to then restore the intra- and inter-process\ndata consistency of both applications. This task turns out to be challenging,\nand we present the methodology for doing so in this work. In the end, we\nachieve message logging capabilities for each kernel, without the need for an\nactual message logging runtime underneath. On the performance side, we match\nstate-of-the-art solutions and (a) eliminate event logging and the event logger\ncomponent altogether, and (b) design a hybrid protocol, which gracefully shifts\nbetween global and local rollback, depending on the available payload logging\nmemory. Such a hybrid protocol between local and global rollback has not been\npreviously proposed to our knowledge. Our extensions span a few hundred lines\nof code for each kernel, are open-sourced, and enable local and global rollback\nafter process failure.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 16:11:26 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Dichev", "Kiril", ""], ["Nikolopoulos", "Dimitrios S.", ""]]}, {"id": "1905.03448", "submitter": "Eviatar Bach", "authors": "Eviatar Bach", "title": "parasweep: A template-based utility for generating, dispatching, and\n  post-processing of parameter sweeps", "comments": null, "journal-ref": "SoftwareX 13 (Jan. 2021) 100631", "doi": "10.1016/j.softx.2020.100631", "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce parasweep, a free and open-source utility for facilitating\nparallel parameter sweeps with computational models. Instead of requiring\nparameters to be passed by command-line, which can be error-prone and\ntime-consuming, parasweep leverages the model's existing configuration files\nusing a template system, requiring minimal code changes. parasweep supports a\nvariety different sweep types, generating parameter sets accordingly and\ndispatching a parallel job for each set, with support for common\nhigh-performance computing (HPC) job schedulers. Post-processing is facilitated\nby providing a mapping between the parameter sets and the simulations. We\ndemonstrate the usage of parasweep with an example.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 05:44:10 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Bach", "Eviatar", ""]]}, {"id": "1905.03525", "submitter": "Peter Sanders", "authors": "Lorenz H\\\"ubschle-Schneider, Peter Sanders", "title": "Linear Work Generation of R-MAT Graphs", "comments": null, "journal-ref": "Net Sci 8 (2020) 543-550", "doi": "10.1017/nws.2020.21", "report-no": null, "categories": "cs.DS cs.DC cs.DM cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  R-MAT is a simple, widely used recursive model for generating `complex\nnetwork' graphs with a power law degree distribution and community structure.\nWe make R-MAT even more useful by reducing the required work per edge from\nlogarithmic to constant. The algorithm works in an embarrassingly parallel way.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 10:46:34 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["H\u00fcbschle-Schneider", "Lorenz", ""], ["Sanders", "Peter", ""]]}, {"id": "1905.03748", "submitter": "Ander Biguri", "authors": "Ander Biguri, Reuben Lindroos, Robert Bryll, Hossein Towsyfyan, Hans\n  Deyhle, Richard Boardman, Mark Mavrogordato, Manjit Dosanjh, Steven Hancock,\n  Thomas Blumensath", "title": "Arbitrarily large iterative tomographic reconstruction on multiple GPUs\n  using the TIGRE toolbox", "comments": "18 pages, 11 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tomographic image sizes keep increasing over time and while the GPUs that\ncompute the tomographic reconstruction are also increasing in memory size, they\nare not doing so fast enough to reconstruct the largest datasets. This problem\nis often solved by reconstructing data in large clusters of GPUs with enough\ndevices to fit the measured X-ray projections and reconstructed volume. Often\nthis requires tens of GPUs, which is a very economically expensive solution.\nAccess to single-node machines designed to reconstruct using just one or a few\nGPUs is more common in the field, but current software does not allow iterative\nreconstruction of volumes that do not fit in those GPUs. In this work, we\npropose a strategy to execute efficiently the required operations for iterative\nreconstruction for arbitrarily large images with any number of GPUs with\narbitrarily small memories in a single node. Strategies for both the forward\nand backprojection operators are presented, along with two regularization\napproaches that are easily generalized to other projection types or\nregularizers. The proposed improvement also accelerates reconstruction of\nsmaller images on single or multiple GPUs, providing faster code for\ntime-critical medical applications. The resulting algorithm has been added to\nthe TIGRE toolbox, a repository for iterative reconstruction algorithms for\ngeneral CT, but this memory-saving and problem-splitting strategy can be easily\nadapted for any other GPU-based CT code.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 14:51:16 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Biguri", "Ander", ""], ["Lindroos", "Reuben", ""], ["Bryll", "Robert", ""], ["Towsyfyan", "Hossein", ""], ["Deyhle", "Hans", ""], ["Boardman", "Richard", ""], ["Mavrogordato", "Mark", ""], ["Dosanjh", "Manjit", ""], ["Hancock", "Steven", ""], ["Blumensath", "Thomas", ""]]}, {"id": "1905.03852", "submitter": "Jieru Zhao", "authors": "Jieru Zhao, Tingyuan Liang, Sharad Sinha and Wei Zhang", "title": "Machine Learning Based Routing Congestion Prediction in FPGA High-Level\n  Synthesis", "comments": "Preprint: to appear in Proceedings of Design, Automation and Test in\n  Europe (DATE 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-level synthesis (HLS) shortens the development time of hardware designs\nand enables faster design space exploration at a higher abstraction level.\nOptimization of complex applications in HLS is challenging due to the effects\nof implementation issues such as routing congestion. Routing congestion\nestimation is absent or inaccurate in existing HLS design methods and tools.\nEarly and accurate congestion estimation is of great benefit to guide the\noptimization in HLS and improve the efficiency of implementation. However,\nroutability, a serious concern in FPGA designs, has been difficult to evaluate\nin HLS without analyzing post-implementation details after Place and Route. To\nthis end, we propose a novel method to predict routing congestion in HLS using\nmachine learning and map the expected congested regions in the design to the\nrelevant high-level source code. This is greatly beneficial in early\nidentification of routability oriented bottlenecks in the high-level source\ncode without running time-consuming register-transfer level (RTL)\nimplementation flow. Experiments demonstrate that our approach accurately\nestimates vertical and horizontal routing congestion with errors of 6.71% and\n10.05% respectively. By presenting Face Detection application as a case study,\nwe show that by discovering the bottlenecks in high-level source code, routing\ncongestion can be easily and quickly resolved compared to the efforts involved\nin RTL implementation and design feedback.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 06:33:22 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Zhao", "Jieru", ""], ["Liang", "Tingyuan", ""], ["Sinha", "Sharad", ""], ["Zhang", "Wei", ""]]}, {"id": "1905.03853", "submitter": "S\\'ebastien Rouault", "authors": "El-Mahdi El-Mhamdi and Rachid Guerraoui and Arsany Guirguis and L\\^e\n  Nguy\\^en Hoang and S\\'ebastien Rouault", "title": "Genuinely Distributed Byzantine Machine Learning", "comments": "This is a merge of arXiv:1905.03853 and arXiv:1911.07537;\n  arXiv:1911.07537 will be retracted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine Learning (ML) solutions are nowadays distributed, according to the\nso-called server/worker architecture. One server holds the model parameters\nwhile several workers train the model. Clearly, such architecture is prone to\nvarious types of component failures, which can be all encompassed within the\nspectrum of a Byzantine behavior. Several approaches have been proposed\nrecently to tolerate Byzantine workers. Yet all require trusting a central\nparameter server. We initiate in this paper the study of the ``general''\nByzantine-resilient distributed machine learning problem where no individual\ncomponent is trusted.\n  We show that this problem can be solved in an asynchronous system, despite\nthe presence of $\\frac{1}{3}$ Byzantine parameter servers and $\\frac{1}{3}$\nByzantine workers (which is optimal). We present a new algorithm, ByzSGD, which\nsolves the general Byzantine-resilient distributed machine learning problem by\nrelying on three major schemes. The first, Scatter/Gather, is a communication\nscheme whose goal is to bound the maximum drift among models on correct\nservers. The second, Distributed Median Contraction (DMC), leverages the\ngeometric properties of the median in high dimensional spaces to bring\nparameters within the correct servers back close to each other, ensuring\nlearning convergence. The third, Minimum-Diameter Averaging (MDA), is a\nstatistically-robust gradient aggregation rule whose goal is to tolerate\nByzantine workers. MDA requires loose bound on the variance of non-Byzantine\ngradient estimates, compared to existing alternatives (e.g., Krum).\nInterestingly, ByzSGD ensures Byzantine resilience without adding communication\nrounds (on a normal path), compared to vanilla non-Byzantine alternatives.\nByzSGD requires, however, a larger number of messages which, we show, can be\nreduced if we assume synchrony.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 16:14:30 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 08:57:00 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["El-Mhamdi", "El-Mahdi", ""], ["Guerraoui", "Rachid", ""], ["Guirguis", "Arsany", ""], ["Hoang", "L\u00ea Nguy\u00ean", ""], ["Rouault", "S\u00e9bastien", ""]]}, {"id": "1905.03854", "submitter": "Bashima Islam", "authors": "Bashima Islam and Shahriar Nirjon", "title": "Zygarde: Time-Sensitive On-Device Deep Inference and Adaptation on\n  Intermittently-Powered Systems", "comments": "Accepted in Proceedings of the ACM on Interactive, Mobile, Wearable\n  and Ubiquitous Technologies, September 2020, Vol 4, No 3", "journal-ref": "Proceedings of the ACM on Interactive, Mobile, Wearable and\n  Ubiquitous Technologies. September 2020 Article No.: 82", "doi": "10.1145/3411808", "report-no": null, "categories": "cs.DC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Zygarde -- which is an energy -- and accuracy-aware soft real-time\ntask scheduling framework for batteryless systems that flexibly execute deep\nlearning tasks1 that are suitable for running on microcontrollers. The sporadic\nnature of harvested energy, resource constraints of the embedded platform, and\nthe computational demand of deep neural networks (DNNs) pose a unique and\nchallenging real-time scheduling problem for which no solutions have been\nproposed in the literature. We empirically study the problem and model the\nenergy harvesting pattern as well as the trade-off between the accuracy and\nexecution of a DNN. We develop an imprecise computing-based scheduling\nalgorithm that improves the timeliness of DNN tasks on intermittently powered\nsystems. We evaluate Zygarde using four standard datasets as well as by\ndeploying it in six real-life applications involving audio and camera sensor\nsystems. Results show that Zygarde decreases the execution time by up to 26%\nand schedules 9%-34% more tasks with up to 21% higher inference accuracy,\ncompared to traditional schedulers such as the earliest deadline first (EDF).\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 01:06:48 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 15:55:40 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Islam", "Bashima", ""], ["Nirjon", "Shahriar", ""]]}, {"id": "1905.03857", "submitter": "Songyuan Li", "authors": "Songyuan Li, Jiwei Huang, Bo Cheng, Lizhen Cui, Yuliang Shi", "title": "FASS: A Fairness-Aware Approach for Concurrent Service Selection with\n  Constraints", "comments": "IEEE International Conference on Web Services (IEEE ICWS 2019), 9\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing momentum of service-oriented architecture has led to the\nemergence of divergent delivered services, where service selection is meritedly\nrequired to obtain the target service fulfilling the requirements from both\nusers and service providers. Despite many existing works have extensively\nhandled the issue of service selection, it remains an open question in the case\nwhere requests from multiple users are performed simultaneously by a certain\nset of shared candidate services. Meanwhile, there exist some constraints\nenforced on the context of service selection, e.g. service placement location\nand contracts between users and service providers. In this paper, we focus on\nthe QoS-aware service selection with constraints from a fairness aspect, with\nthe objective of achieving max-min fairness across multiple service requests\nsharing candidate service sets. To be more specific, we study the problem of\nfairly selecting services from shared candidate sets while service providers\nare self-motivated to offer better services with higher QoS values. We\nformulate this problem as a lexicographical maximization problem, which is far\nfrom trivial to deal with practically due to its inherently multi-objective and\ndiscrete nature. A fairness-aware algorithm for concurrent service selection\n(FASS) is proposed, whose basic idea is to iteratively solve the\nsingle-objective subproblems by transforming them into linear programming\nproblems. Experimental results based on real-world datasets also validate the\neffectiveness and practicality of our proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 18:03:38 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Li", "Songyuan", ""], ["Huang", "Jiwei", ""], ["Cheng", "Bo", ""], ["Cui", "Lizhen", ""], ["Shi", "Yuliang", ""]]}, {"id": "1905.03888", "submitter": "Isaac Sheff", "authors": "Isaac Sheff, Xinwen Wang, Haobin Ni, Robbert van Renesse, Andrew C.\n  Myers", "title": "Charlotte: Composable Authenticated Distributed Data Structures,\n  Technical Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Charlotte, a framework for composable, authenticated distributed\ndata structures. Charlotte data is stored in blocks that reference each other\nby hash. Together, all Charlotte blocks form a directed acyclic graph, the\nblockweb; all observers and applications use subgraphs of the blockweb for\ntheir own data structures. Unlike prior systems, Charlotte data structures are\ncomposable: applications and data structures can operate fully independently\nwhen possible, and share blocks when desired. To support this composability, we\ndefine a language-independent format for Charlotte blocks and a network API for\nCharlotte servers.\n  An authenticated distributed data structure guarantees that data is immutable\nand self-authenticating: data referenced will be unchanged when it is\nretrieved. Charlotte extends these guarantees by allowing applications to plug\nin their own mechanisms for ensuring availability and integrity of data\nstructures. Unlike most traditional distributed systems, including distributed\ndatabases, blockchains, and distributed hash tables, Charlotte supports\nheterogeneous trust: different observers may have their own beliefs about who\nmight fail, and how. Despite heterogeneity of trust, Charlotte presents each\nobserver with a consistent, available view of data.\n  We demonstrate the flexibility of Charlotte by implementing a variety of\nintegrity mechanisms, including consensus and proof of work. We study the power\nof disentangling availability and integrity mechanisms by building a variety of\napplications. The results from these examples suggest that developers can use\nCharlotte to build flexible, fast, composable applications with strong\nguarantees.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 23:25:35 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Sheff", "Isaac", ""], ["Wang", "Xinwen", ""], ["Ni", "Haobin", ""], ["van Renesse", "Robbert", ""], ["Myers", "Andrew C.", ""]]}, {"id": "1905.03957", "submitter": "Sanjana Singh", "authors": "Sanjana Singh, Divyanjali Sharma and Subodh Sharma", "title": "Dynamic Verification with Observational Equivalence of C/C++ Concurrency", "comments": "Paper has some issues with certain claims that needs to be rectified", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Program executions under relaxed memory model (rmm) semantics are\nsignificantly more difficult to analyze; the rmm semantics result in out of\norder execution of program events leading to an explosion of state-space.\nDynamic partial order reduction (DPOR) is a powerful technique to address such\na state-space explosion and has been used to verify programs under rmm such as\nTSO, PSO, and POWER. Central to such DPOR techniques is the notion of\ntrace-equivalence, which is computed based on the independence relation among\nprogram events. We propose a coarser notion of rmm-aware trace equivalence\ncalled observational equivalence (OE). Two program behaviors are\nobservationally equivalent if every read event reads the same value in both the\nbehaviors. We propose a notion of observational independence (OI) and provide\nan algorithmic construction to compute trace equivalence (modulo OI)\nefficiently. We also demonstrate the effectiveness of DPOR with OE on threaded\nC/C++ programs by first providing an elaborate happensbefore (hb) relation for\ncapturing the C/C++ concurrency semantics. We implement the presented technique\nin a runtime model checker called Drista. Our experiments reflect that (i) when\ncompared to existing nonOE techniques, we achieve significant savings in the\nnumber of traces explored under OE, and (ii) our treatment of C/C++ concurrency\nis more extensive than the existing state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 06:08:47 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 13:43:53 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Singh", "Sanjana", ""], ["Sharma", "Divyanjali", ""], ["Sharma", "Subodh", ""]]}, {"id": "1905.03960", "submitter": "Anand Jayarajan", "authors": "Anand Jayarajan, Jinliang Wei, Garth Gibson, Alexandra Fedorova,\n  Gennady Pekhimenko", "title": "Priority-based Parameter Propagation for Distributed DNN Training", "comments": "In proceedings of the 2nd SysML Conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data parallel training is widely used for scaling distributed deep neural\nnetwork (DNN) training. However, the performance benefits are often limited by\nthe communication-heavy parameter synchronization step. In this paper, we take\nadvantage of the domain specific knowledge of DNN training and overlap\nparameter synchronization with computation in order to improve the training\nperformance. We make two key observations: (1) the optimal data representation\ngranularity for the communication may differ from that used by the underlying\nDNN model implementation and (2) different parameters can afford different\nsynchronization delays. Based on these observations, we propose a new\nsynchronization mechanism called Priority-based Parameter Propagation (P3). P3\nsynchronizes parameters at a finer granularity and schedules data transmission\nin such a way that the training process incurs minimal communication delay. We\nshow that P3 can improve the training throughput of ResNet-50, Sockeye and\nVGG-19 by as much as 25%, 38% and 66% respectively on clusters with realistic\nnetwork bandwidth\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 06:22:35 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Jayarajan", "Anand", ""], ["Wei", "Jinliang", ""], ["Gibson", "Garth", ""], ["Fedorova", "Alexandra", ""], ["Pekhimenko", "Gennady", ""]]}, {"id": "1905.04035", "submitter": "Valeriu Codreanu", "authors": "Derya Cavdar, Valeriu Codreanu, Can Karakus, John A. Lockman III,\n  Damian Podareanu, Vikram Saletore, Alexander Sergeev, Don D. Smith II, Victor\n  Suthichai, Quy Ta, Srinivas Varadharajan, Lucas A. Wilson, Rengan Xu, Pei\n  Yang", "title": "Densifying Assumed-sparse Tensors: Improving Memory Efficiency and MPI\n  Collective Performance during Tensor Accumulation for Parallelized Training\n  of Neural Machine Translation Models", "comments": "18 pages, 10 figures, accepted at the 2019 International\n  Supercomputing Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation - using neural networks to translate human\nlanguage - is an area of active research exploring new neuron types and network\ntopologies with the goal of dramatically improving machine translation\nperformance. Current state-of-the-art approaches, such as the multi-head\nattention-based transformer, require very large translation corpuses and many\nepochs to produce models of reasonable quality. Recent attempts to parallelize\nthe official TensorFlow \"Transformer\" model across multiple nodes have hit\nroadblocks due to excessive memory use and resulting out of memory errors when\nperforming MPI collectives. This paper describes modifications made to the\nHorovod MPI-based distributed training framework to reduce memory usage for\ntransformer models by converting assumed-sparse tensors to dense tensors, and\nsubsequently replacing sparse gradient gather with dense gradient reduction.\nThe result is a dramatic increase in scale-out capability, with CPU-only\nscaling tests achieving 91% weak scaling efficiency up to 1200 MPI processes\n(300 nodes), and up to 65% strong scaling efficiency up to 400 MPI processes\n(200 nodes) using the Stampede2 supercomputer.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 09:44:35 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Cavdar", "Derya", ""], ["Codreanu", "Valeriu", ""], ["Karakus", "Can", ""], ["Lockman", "John A.", "III"], ["Podareanu", "Damian", ""], ["Saletore", "Vikram", ""], ["Sergeev", "Alexander", ""], ["Smith", "Don D.", "II"], ["Suthichai", "Victor", ""], ["Ta", "Quy", ""], ["Varadharajan", "Srinivas", ""], ["Wilson", "Lucas A.", ""], ["Xu", "Rengan", ""], ["Yang", "Pei", ""]]}, {"id": "1905.04064", "submitter": "Ermin Sakic", "authors": "Ermin Sakic, Nemanja Deric, Endri Goshi, Wolfgang Kellerer", "title": "P4BFT: Hardware-Accelerated Byzantine-Resilient Network Control Plane", "comments": "Accepted for publication at IEEE Globecom 2019 CQRM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Byzantine Fault Tolerance (BFT) enables correct operation of distributed,\ni.e., replicated applications in the face of malicious take-over and\nfaulty/buggy individual instances. Recently, BFT designs have gained traction\nin the context of Software Defined Networking (SDN). In SDN, controller\nreplicas are distributed and their state replicated for high availability\npurposes. Malicious controller replicas, however, may destabilize the control\nplane and manipulate the data plane, thus motivating the BFT requirement.\nNonetheless, deploying BFT in practice comes at a disadvantage of increased\ntraffic load stemming from replicated controllers, as well as a requirement for\nproprietary switch functionalities, thus putting strain on switches' control\nplane where particular BFT actions must be executed in software.\n  P4BFT leverages an optimal strategy to decrease the total amount of messages\ntransmitted to switches that are the configuration targets of SDN controllers.\nIt does so by means of message comparison and deduction of correct messages in\nthe determined optimal locations in the data plane. In terms of the incurred\ncontrol plane load, our P4-based data plane extensions outperform the existing\nsolutions by ~33.2% and ~40.2% on average, in random 128-switch and\nFat-Tree/Internet2 topologies, respectively. To validate the correctness and\nperformance gains of P4BFT, we deploy bmv2 and Netronome Agilio SmartNIC-based\ntopologies. The advantages of P4BFT can thus be reproduced both with software\nswitches and \"commodity\" P4-enabled hardware. A hardware-accelerated controller\npacket comparison procedure results in an average 96.4% decrease in processing\ndelay per request compared to existing software approaches.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 10:46:28 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 09:36:55 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Sakic", "Ermin", ""], ["Deric", "Nemanja", ""], ["Goshi", "Endri", ""], ["Kellerer", "Wolfgang", ""]]}, {"id": "1905.04065", "submitter": "Eike Hermann M\\\"uller", "authors": "William Robert Saunders, James Grant, Eike Hermann M\\\"uller, Ian\n  Thompson", "title": "Fast electrostatic solvers for kinetic Monte Carlo simulations", "comments": "26 pages, 19 figures, 7 tables; accepted for publication in Computer\n  Physics Communications", "journal-ref": null, "doi": "10.1016/j.jcp.2020.109379", "report-no": null, "categories": "physics.comp-ph cond-mat.mtrl-sci cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kinetic Monte Carlo (KMC) is an important computational tool in physics and\nchemistry. In contrast to standard Monte Carlo, KMC permits the description of\ntime dependent dynamical processes and is not restricted to systems in\nequilibrium. Recently KMC has been applied successfully in modelling of novel\nenergy materials such as Lithium-ion batteries and solar cells. We consider\ngeneral solid state systems which contain free, interacting particles which can\nhop between localised sites in the material. The KMC transition rates for those\nhops depend on the change in total potential energy of the system. For charged\nparticles this requires the frequent calculation of electrostatic interactions,\nwhich is usually the bottleneck of the simulation. To avoid this issue and\nobtain results in reasonable times, many studies replace the long-range\npotential by a short range approximation. This, however, leads to systematic\nerrors and unphysical results. On the other hand standard electrostatic solvers\nsuch as Ewald summation or fast Poisson solvers are highly inefficient or\nintroduce uncontrollable systematic errors at high resolution. In this paper we\ndescribe how the Fast Multipole Method by Greengard and Rokhlin can be adapted\nto overcome this issue by dramatically reducing computational costs. We exploit\nthe fact that each update in the transition rate calculation corresponds to a\nsingle particle move and changes the configuration only by a small amount. This\nallows us to construct an algorithm which scales linearly in the number of\ncharges for each KMC step, something which had not been deemed to be possible\nbefore. We demonstrate the performance and parallel scalability of the method\nby implementing it in a performance portable software library. We describe the\nhigh-level Python interface of the code which makes it easy to adapt to\nspecific cases.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 10:47:59 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 17:52:47 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Saunders", "William Robert", ""], ["Grant", "James", ""], ["M\u00fcller", "Eike Hermann", ""], ["Thompson", "Ian", ""]]}, {"id": "1905.04106", "submitter": "Arnaud Casteigts", "authors": "Arnaud Casteigts, Swan Dubois, Franck Petit, John M. Robson", "title": "Robustness: a New Form of Heredity Motivated by Dynamic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a special case of hereditary property in graphs, referred to\nas {\\em robustness}. A property (or structure) is called robust in a graph $G$\nif it is inherited by all the connected spanning subgraphs of $G$. We motivate\nthis definition using two different settings of dynamic networks. The first\ncorresponds to networks of low dynamicity, where some links may be permanently\nremoved so long as the network remains connected. The second corresponds to\nhighly-dynamic networks, where communication links appear and disappear\narbitrarily often, subject only to the requirement that the entities are\ntemporally connected in a recurrent fashion ({\\it i.e.} they can always reach\neach other through temporal paths). Each context induces a different\ninterpretation of the notion of robustness.\n  We start by motivating the definition and discussing the two interpretations,\nafter what we consider the notion independently from its interpretation, taking\nas our focus the robustness of {\\em maximal independent sets} (MIS). A graph\nmay or may not admit a robust MIS. We characterize the set of graphs \\forallMIS\nin which {\\em all} MISs are robust. Then, we turn our attention to the graphs\nthat {\\em admit} a robust MIS (\\existsMIS). This class has a more complex\nstructure; we give a partial characterization in terms of elementary graph\nproperties, then a complete characterization by means of a (polynomial time)\ndecision algorithm that accepts if and only if a robust MIS exists. This\nalgorithm can be adapted to construct such a solution if one exists.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 12:18:48 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Casteigts", "Arnaud", ""], ["Dubois", "Swan", ""], ["Petit", "Franck", ""], ["Robson", "John M.", ""]]}, {"id": "1905.04211", "submitter": "Yang Yang", "authors": "Yang Yang, Marius Pesavento, Zhi-Quan Luo, Bj\\\"orn Ottersten", "title": "Inexact Block Coordinate Descent Algorithms for Nonsmooth Nonconvex\n  Optimization", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2019.2959240", "report-no": null, "categories": "math.OC cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an inexact block coordinate descent algorithm for\nlarge-scale nonsmooth nonconvex optimization problems. At each iteration, a\nparticular block variable is selected and updated by inexactly solving the\noriginal optimization problem with respect to that block variable. More\nprecisely, a local approximation of the original optimization problem is\nsolved. The proposed algorithm has several attractive features, namely, i) high\nflexibility, as the approximation function only needs to be strictly convex and\nit does not have to be a global upper bound of the original function; ii) fast\nconvergence, as the approximation function can be designed to exploit the\nproblem structure at hand and the stepsize is calculated by the line search;\niii) low complexity, as the approximation subproblems are much easier to solve\nand the line search scheme is carried out over a properly constructed\ndifferentiable function; iv) guaranteed convergence of a subsequence to a\nstationary point, even when the objective function does not have a Lipschitz\ncontinuous gradient. Interestingly, when the approximation subproblem is solved\nby a descent algorithm, convergence of a subsequence to a stationary point is\nstill guaranteed even if the approximation subproblem is solved inexactly by\nterminating the descent algorithm after a finite number of iterations. These\nfeatures make the proposed algorithm suitable for large-scale problems where\nthe dimension exceeds the memory and/or the processing capability of the\nexisting hardware. These features are also illustrated by several applications\nin signal processing and machine learning, for instance, network anomaly\ndetection and phase retrieval.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 15:16:24 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 21:06:15 GMT"}, {"version": "v3", "created": "Thu, 25 Jul 2019 13:30:15 GMT"}, {"version": "v4", "created": "Fri, 6 Dec 2019 11:47:05 GMT"}, {"version": "v5", "created": "Wed, 11 Dec 2019 08:35:36 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Yang", "Yang", ""], ["Pesavento", "Marius", ""], ["Luo", "Zhi-Quan", ""], ["Ottersten", "Bj\u00f6rn", ""]]}, {"id": "1905.04264", "submitter": "Kiran Matam", "authors": "Kiran Kumar Matam, Hanieh Hashemi, Murali Annavaram", "title": "PartitionedVC: Partitioned External Memory Graph Analytics Framework for\n  SSDs", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph analytics are at the heart of a broad range of applications such as\ndrug discovery, page ranking, and recommendation systems. When graph size\nexceeds memory size, out-of-core graph processing is needed. For the widely\nused external memory graph processing systems, accessing storage becomes the\nbottleneck. We make the observation that nearly all graph algorithms have a\ndynamically varying number of active vertices that must be processed in each\niteration. However, existing graph processing frameworks, such as GraphChi,\nload the entire graph in each iteration even if a small fraction of the graph\nis active. This limitation is due to the structure of the data storage used by\nthese systems. In this work, we propose to use a compressed sparse row (CSR)\nbased graph storage that is more amenable for selectively loading only a few\nactive vertices in each iteration. But CSR based systems suffers from random\nupdate propagation to many target vertices. To solve this challenge, we propose\nto use a multi-log update mechanism that logs updates separately, rather than\ndirectly update the active edges in a graph. Our proposed multi-log system\nmaintains a separate log per each vertex interval. This separation enables us\nto efficiently process each vertex interval by just loading the corresponding\nlog. Further, while accessing SSD pages with fewer active vertex data, we\nreduce the read amplification due to the page granular accesses in SSD by\nlogging the active vertex data in the current iteration and efficiently reading\nthe log in the next iteration. Over the current state of the art out-of-core\ngraph processing framework, our PartitionedVC improves performance by up to\n$17.84\\times$, $1.19\\times$, $1.65\\times$, $1.38\\times$, $3.15\\times$, and\n$6.00\\times$ for the widely used bfs, pagerank, community detection, graph\ncoloring, maximal independent set, and random-walk applications, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 17:08:31 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 08:13:26 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Matam", "Kiran Kumar", ""], ["Hashemi", "Hanieh", ""], ["Annavaram", "Murali", ""]]}, {"id": "1905.04341", "submitter": "Philipp Grete", "authors": "Philipp Grete, Forrest W. Glines, Brian W. O'Shea", "title": "K-Athena: a performance portable structured grid finite volume\n  magnetohydrodynamics code", "comments": "13 pages, 6 figures, 2 tables; accepted for publication in IEEE\n  Transactions on Parallel and Distributed Systems (TPDS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC astro-ph.IM cs.PF physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale simulations are a key pillar of modern research and require\never-increasing computational resources. Different novel manycore architectures\nhave emerged in recent years on the way towards the exascale era. Performance\nportability is required to prevent repeated non-trivial refactoring of a code\nfor different architectures. We combine Athena++, an existing\nmagnetohydrodynamics (MHD) CPU code, with Kokkos, a performance portable\non-node parallel programming paradigm, into K-Athena to allow efficient\nsimulations on multiple architectures using a single codebase. We present\nprofiling and scaling results for different platforms including Intel Skylake\nCPUs, Intel Xeon Phis, and NVIDIA GPUs. K-Athena achieves $>10^8$\ncell-updates/s on a single V100 GPU for second-order double precision MHD\ncalculations, and a speedup of 30 on up to 24,576 GPUs on Summit (compared to\n172,032 CPU cores), reaching $1.94\\times10^{12}$ total cell-updates/s at 76%\nparallel efficiency. Using a roofline analysis we demonstrate that the overall\nperformance is currently limited by DRAM bandwidth and calculate a performance\nportability metric of 62.8%. Finally, we present the implementation strategies\nused and the challenges encountered in maximizing performance. This will\nprovide other research groups with a straightforward approach to prepare their\nown codes for the exascale era. K-Athena is available at\nhttps://gitlab.com/pgrete/kathena .\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 18:47:25 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 18:06:16 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Grete", "Philipp", ""], ["Glines", "Forrest W.", ""], ["O'Shea", "Brian W.", ""]]}, {"id": "1905.04374", "submitter": "S\\'ebastien Rouault", "authors": "El-Mahdi El-Mhamdi and Rachid Guerraoui and S\\'ebastien Rouault", "title": "Fast and Robust Distributed Learning in High Dimension", "comments": "preliminary theoretical draft, complements the SysML 2019 practical\n  paper of which the code is provided at\n  https://github.com/LPD-EPFL/AggregaThor. arXiv admin note: text overlap with\n  arXiv:1703.02757", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Could a gradient aggregation rule (GAR) for distributed machine learning be\nboth robust and fast? This paper answers by the affirmative through\nmulti-Bulyan. Given $n$ workers, $f$ of which are arbitrary malicious\n(Byzantine) and $m=n-f$ are not, we prove that multi-Bulyan can ensure a strong\nform of Byzantine resilience, as well as an ${\\frac{m}{n}}$ slowdown, compared\nto averaging, the fastest (but non Byzantine resilient) rule for distributed\nmachine learning. When $m \\approx n$ (almost all workers are correct),\nmulti-Bulyan reaches the speed of averaging. We also prove that multi-Bulyan's\ncost in local computation is $O(d)$ (like averaging), an important feature for\nML where $d$ commonly reaches $10^9$, while robust alternatives have at least\nquadratic cost in $d$.\n  Our theoretical findings are complemented with an experimental evaluation\nwhich, in addition to supporting the linear $O(d)$ complexity argument, conveys\nthe fact that multi-Bulyan's parallelisability further adds to its efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 16:41:25 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 16:44:25 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["El-Mhamdi", "El-Mahdi", ""], ["Guerraoui", "Rachid", ""], ["Rouault", "S\u00e9bastien", ""]]}, {"id": "1905.04376", "submitter": "Juan Gomez Luna", "authors": "Onur Mutlu, Saugata Ghose, Juan G\\'omez-Luna, Rachata Ausavarungnirun", "title": "Enabling Practical Processing in and near Memory for Data-Intensive\n  Computing", "comments": "A version of this work is to appear in a DAC 2019 Special Session as\n  an Invited Paper in June 2019. arXiv admin note: substantial text overlap\n  with arXiv:1903.03988", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern computing systems suffer from the dichotomy between computation on one\nside, which is performed only in the processor (and accelerators), and data\nstorage/movement on the other, which all other parts of the system are\ndedicated to. Due to this dichotomy, data moves a lot in order for the system\nto perform computation on it. Unfortunately, data movement is extremely\nexpensive in terms of energy and latency, much more so than computation. As a\nresult, a large fraction of system energy is spent and performance is lost\nsolely on moving data in a modern computing system.\n  In this work, we re-examine the idea of reducing data movement by performing\nProcessing in Memory (PIM). PIM places computation mechanisms in or near where\nthe data is stored (i.e., inside the memory chips, in the logic layer of\n3D-stacked logic and DRAM, or in the memory controllers), so that data movement\nbetween the computation units and memory is reduced or eliminated. While the\nidea of PIM is not new, we examine two new approaches to enabling PIM: 1)\nexploiting analog properties of DRAM to perform massively-parallel operations\nin memory, and 2) exploiting 3D-stacked memory technology design to provide\nhigh bandwidth to in-memory logic. We conclude by discussing work on solving\nkey challenges to the practical adoption of PIM.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 14:29:03 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Mutlu", "Onur", ""], ["Ghose", "Saugata", ""], ["G\u00f3mez-Luna", "Juan", ""], ["Ausavarungnirun", "Rachata", ""]]}, {"id": "1905.04391", "submitter": "Amirhossein Esmaili", "authors": "Amirhossein Esmaili, Mahdi Nazemi, Massoud Pedram", "title": "Energy-Aware Scheduling of Task Graphs with Imprecise Computations and\n  End-to-End Deadlines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imprecise computations provide an avenue for scheduling algorithms developed\nfor energy-constrained computing devices by trading off output quality with the\nutilization of system resources. This work proposes a method for scheduling\ntask graphs with potentially imprecise computations, with the goal of\nmaximizing the quality of service subject to a hard deadline and an energy\nbound. Furthermore, for evaluating the efficacy of the proposed method, a mixed\ninteger linear program formulation of the problem, which provides the optimal\nreference scheduling solutions, is also presented. The effect of potentially\nimprecise inputs of tasks on their output quality is taken into account in the\nproposed method. Both the proposed method and MILP formulation target\nmultiprocessor platforms. Experiments are run on 10 randomly generated task\ngraphs. Based on the obtained results, for some cases, a feasible schedule of a\ntask graph can be achieved with the energy consumption less than 50% of the\nminimum energy required for scheduling all tasks in that task graph completely\nprecisely.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 22:12:57 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Esmaili", "Amirhossein", ""], ["Nazemi", "Mahdi", ""], ["Pedram", "Massoud", ""]]}, {"id": "1905.04456", "submitter": "Mohsen Amini Salehi", "authors": "Chavit Denninnart, James Gentry, Mohsen Amini Salehi", "title": "Improving Robustness of Heterogeneous Serverless Computing Systems Via\n  Probabilistic Task Pruning", "comments": "IPDPSW '19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud-based serverless computing is an increasingly popular computing\nparadigm. In this paradigm, different services have diverse computing\nrequirements that justify deploying an inconsistently Heterogeneous Computing\n(HC) system to efficiently process them. In an inconsistently HC system, each\ntask needed for a given service, potentially exhibits different execution times\non each type of machine. An ideal resource allocation system must be aware of\nsuch uncertainties in execution times and be robust against them, so that\nQuality of Service (QoS) requirements of users are met. This research aims to\nmaximize the robustness of an HC system utilized to offer a serverless\ncomputing system, particularly when the system is oversubscribed. Our strategy\nto maximize robustness is to develop a task pruning mechanism that can be added\nto existing task-mapping heuristics without altering them. Pruning tasks with a\nlow probability of meeting their deadlines improves the likelihood of other\ntasks meeting their deadlines, thereby increasing system robustness and overall\nQoS. To evaluate the impact of the pruning mechanism, we examine it on various\nconfigurations of heterogeneous and homogeneous computing systems. Evaluation\nresults indicate a considerable improvement (up to 35%) in the system\nrobustness.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 06:20:16 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Denninnart", "Chavit", ""], ["Gentry", "James", ""], ["Salehi", "Mohsen Amini", ""]]}, {"id": "1905.04458", "submitter": "Mohsen Amini Salehi", "authors": "Anna Kovalenko, Razin Farhan Hussain, Omid Semiari, Mohsen Amini\n  Salehi", "title": "Robust Resource Allocation Using Edge Computing for Vehicle to\n  Infrastructure (V2I) Networks", "comments": null, "journal-ref": "3rd IEEE International Conference on Fog and Edge Computing (ICFEC\n  2019)", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development of autonomous and self-driving vehicles requires agile and\nreliable services to manage hazardous road situations. Vehicular Network is the\nmedium that can provide high-quality services for self-driving vehicles. The\nmajority of service requests in Vehicular Networks are delay intolerant (e.g.,\nhazard alerts, lane change warning) and require immediate service. Therefore,\nVehicular Networks, and particularly, Vehicle-to-Infrastructure (V2I) systems\nmust provide a consistent real-time response to autonomous vehicles. During\npeak hours or disasters, when a surge of requests arrives at a Base Station, it\nis challenging for the V2I system to maintain its performance, which can lead\nto hazardous consequences. Hence, the goal of this research is to develop a V2I\nsystem that is robust against uncertain request arrivals. To achieve this goal,\nwe propose to dynamically allocate service requests among Base Stations. We\ndevelop an uncertainty-aware resource allocation method for the federated\nenvironment that assigns arriving requests to a Base Station so that the\nlikelihood of completing it on-time is maximized. We evaluate the system under\nvarious workload conditions and oversubscription levels. Simulation results\nshow that edge federation can improve robustness of the V2I system by reducing\nthe overall service miss rate by up to 45%.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 06:28:32 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Kovalenko", "Anna", ""], ["Hussain", "Razin Farhan", ""], ["Semiari", "Omid", ""], ["Salehi", "Mohsen Amini", ""]]}, {"id": "1905.04459", "submitter": "Mohsen Amini Salehi", "authors": "Vaughan Veillon, Chavit Denninnart, Mohsen Amini Salehi", "title": "F-FDN: Federation of Fog Computing Systems for Low Latency Video\n  Streaming", "comments": "3rd IEEE International Conference on Fog and Edge Computing (ICFEC\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video streaming is growing in popularity and has become the most\nbandwidth-consuming Internet service. As such, robust streaming in terms of low\nlatency and uninterrupted streaming experience, particularly for viewers in\ndistant areas, has become a challenge. The common practice to reduce latency is\nto pre-process multiple versions of each video and use Content Delivery\nNetworks (CDN) to cache videos that are popular in a geographical area.\nHowever, with the fast-growing video repository sizes, caching video contents\nin multiple versions on each CDN is becoming inefficient. Accordingly, in this\npaper, we propose the architecture for Fog Delivery Networks (FDN) and provide\nmethods to federate them (called F-FDN) to reduce video streaming latency. In\naddition to caching, FDNs have the ability to process videos in an on-demand\nmanner. F-FDN leverages cached contents on the neighboring FDNs to further\nreduce latency. In particular, F-FDN is equipped with methods that aim at\nreducing latency through probabilistically evaluating the cost benefit of\nfetching video segments either from neighboring FDNs or by processing them.\nExperimental results against alternative streaming methods show that both\non-demand processing and leveraging cached video segments on neighboring FDNs\ncan remarkably reduce streaming latency (on average 52%).\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 06:43:10 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Veillon", "Vaughan", ""], ["Denninnart", "Chavit", ""], ["Salehi", "Mohsen Amini", ""]]}, {"id": "1905.04460", "submitter": "Mohsen Amini Salehi", "authors": "Razin Farhan Hussain, Mohsen Amini Salehi, Omid Semiari", "title": "Serverless Edge Computing for Green Oil and Gas Industry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development of autonomous and self-driving vehicles requires agile and\nreliable services to manage hazardous road situations. Vehicular Network is the\nmedium that can provide high-quality services for self-driving vehicles. The\nmajority of service requests in Vehicular Networks are delay intolerant (e.g.,\nhazard alerts, lane change warning) and require immediate service. Therefore,\nVehicular Networks, and particularly, Vehicle-to-Infrastructure (V2I) systems\nmust provide a consistent real-time response to autonomous vehicles. During\npeak hours or disasters, when a surge of requests arrives at a Base Station, it\nis challenging for the V2I system to maintain its performance, which can lead\nto hazardous consequences. Hence, the goal of this research is to develop a V2I\nsystem that is robust against uncertain request arrivals. To achieve this goal,\nwe propose to dynamically allocate service requests among Base Stations. We\ndevelop an uncertainty-aware resource allocation method for the federated\nenvironment that assigns arriving requests to a Base Station so that the\nlikelihood of completing it on-time is maximized. We evaluate the system under\nvarious workload conditions and oversubscription levels. Simulation results\nshow that edge federation can improve robustness of the V2I system by reducing\nthe overall service miss rate by up to 45%.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 06:49:14 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Hussain", "Razin Farhan", ""], ["Salehi", "Mohsen Amini", ""], ["Semiari", "Omid", ""]]}, {"id": "1905.04501", "submitter": "Shangqi Lai", "authors": "Shangqi Lai ((1) and (2)), Xingliang Yuan (1) and Shi-Feng Sun ((1)\n  and (2)) and Joseph K. Liu (1) and Yuhong Liu (3) and Dongxi Liu (2) ((1)\n  Monash University, (2) Data61, CSIRO (3) Santa Clara University)", "title": "GraphSE$^2$: An Encrypted Graph Database for Privacy-Preserving Social\n  Search", "comments": "This is the full version of our AsiaCCS paper \"GraphSE$^2$: An\n  Encrypted Graph Database for Privacy-Preserving Social Search\". It includes\n  the security proof of the proposed scheme. If you want to cite our work,\n  please cite the conference version of it", "journal-ref": null, "doi": "10.1145/3321705.3329803", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose GraphSE$^2$, an encrypted graph database for online\nsocial network services to address massive data breaches. GraphSE$^2$ preserves\nthe functionality of social search, a key enabler for quality social network\nservices, where social search queries are conducted on a large-scale social\ngraph and meanwhile perform set and computational operations on user-generated\ncontents. To enable efficient privacy-preserving social search, GraphSE$^2$\nprovides an encrypted structural data model to facilitate parallel and\nencrypted graph data access. It is also designed to decompose complex social\nsearch queries into atomic operations and realise them via interchangeable\nprotocols in a fast and scalable manner. We build GraphSE$^2$ with various\nqueries supported in the Facebook graph search engine and implement a\nfull-fledged prototype. Extensive evaluations on Azure Cloud demonstrate that\nGraphSE$^2$ is practical for querying a social graph with a million of users.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 11:16:23 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 23:12:43 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Lai", "Shangqi", ""], ["Yuan", "Xingliang", ""], ["Sun", "Shi-Feng", ""], ["Liu", "Joseph K.", ""], ["Liu", "Yuhong", ""], ["Liu", "Dongxi", ""]]}, {"id": "1905.04634", "submitter": "Saber Salehkaleybar", "authors": "Saber Salehkaleybar, Arsalan Sharifnassab, S. Jamaloddin Golestani", "title": "One-Shot Federated Learning: Theoretical Limits and Algorithms to\n  Achieve Them", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider distributed statistical optimization in one-shot setting, where\nthere are $m$ machines each observing $n$ i.i.d. samples. Based on its observed\nsamples, each machine sends a $B$-bit-long message to a server. The server then\ncollects messages from all machines, and estimates a parameter that minimizes\nan expected convex loss function. We investigate the impact of communication\nconstraint, $B$, on the expected error and derive a tight lower bound on the\nerror achievable by any algorithm. We then propose an estimator, which we call\nMulti-Resolution Estimator (MRE), whose expected error (when $B\\ge\\log mn$)\nmeets the aforementioned lower bound up to poly-logarithmic factors, and is\nthereby order optimal. We also address the problem of learning under tiny\ncommunication budget, and present lower and upper error bounds when $B$ is a\nconstant. The expected error of MRE, unlike existing algorithms, tends to zero\nas the number of machines ($m$) goes to infinity, even when the number of\nsamples per machine ($n$) remains upper bounded by a constant. This property of\nthe MRE algorithm makes it applicable in new machine learning paradigms where\n$m$ is much larger than $n$.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 02:52:08 GMT"}, {"version": "v2", "created": "Sun, 4 Aug 2019 05:07:38 GMT"}, {"version": "v3", "created": "Tue, 12 Nov 2019 08:14:52 GMT"}, {"version": "v4", "created": "Thu, 12 Dec 2019 11:20:03 GMT"}, {"version": "v5", "created": "Mon, 30 Dec 2019 10:20:19 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Salehkaleybar", "Saber", ""], ["Sharifnassab", "Arsalan", ""], ["Golestani", "S. Jamaloddin", ""]]}, {"id": "1905.04648", "submitter": "Lorin Hochstein", "authors": "Ali Basiri, Lorin Hochstein, Nora Jones, Haley Tucker", "title": "Automating chaos experiments in production", "comments": "International Conference on Software Engineering (ICSE), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed systems often face transient errors and localized component\ndegradation and failure. Verifying that the overall system remains healthy in\nthe face of such failures is challenging. At Netflix, we have built a platform\nfor automatically generating and executing chaos experiments, which check how\nwell the production system can handle component failures and slowdowns. This\npaper describes the platform and our experiences operating it.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 05:51:41 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Basiri", "Ali", ""], ["Hochstein", "Lorin", ""], ["Jones", "Nora", ""], ["Tucker", "Haley", ""]]}, {"id": "1905.04795", "submitter": "Mustafa Bal", "authors": "Mustafa Bal and Caitlin Ner", "title": "NFTracer: A Non-Fungible Token Tracking Proof-of-Concept Using\n  Hyperledger Fabric", "comments": "9 pages, 3 figures, 5 algorithms, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various start-up developers and academic researchers have investigated the\nusage of blockchain as a data storage medium due to the advantages offered by\nits tamper-proof and decentralized nature. However, there have not been many\nattempts to provide a standard platform for virtually storing the states of\nunique tangible entities and their subsequent modifications. In this paper, we\npropose NFTracer, a non-fungible token tracking proof-of-concept based on\nHyperledger Composer and Hyperledger Fabric Blockchain. To achieve the\ncapabilities of our platform, we use NFTracer to build an artwork auction and a\nreal estate auction, which vary in technical complexity and demonstrate the\nadvantages of being able to track entities and their resulting modifications in\na decentralized manner. We also present its accompanying modular architecture\nand system components, and discuss possible future works on NFTracer.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 21:39:03 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Bal", "Mustafa", ""], ["Ner", "Caitlin", ""]]}, {"id": "1905.04800", "submitter": "Josef Spillner", "authors": "Josef Spillner", "title": "Quantitative Analysis of Cloud Function Evolution in the AWS Serverless\n  Application Repository", "comments": "26 pages, 13 figures, 4 tables, live updates, unreviewed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The serverless computing ecosystem is growing due to interest by software\nengineers. Beside Function-as-a-Service (FaaS) and Backend-as-a-Service (BaaS)\nsystems, developer-oriented tools such as deployment and debugging frameworks\nas well as cloud function repositories enable the rapid creation of wholly or\npartially serverless applications. This study presents first insights into how\ncloud functions (Lambda functions) and composite serverless applications\noffered through the AWS Serverless Application Repository have evolved over the\ncourse of one year. Specifically, it outlines information on cloud function and\nfunction-based application offering models and descriptions, high-level\nimplementation statistics, and evolution including change patterns over time.\nSeveral results are presented in live paper style, offering hyperlinks to\ncontinuously updated figures to follow the evolution after publication date.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 22:26:08 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Spillner", "Josef", ""]]}, {"id": "1905.04855", "submitter": "Chia-Ling Huang", "authors": "Chia-Ling Huang and Wei-Chang Yeh", "title": "A new SSO-based Algorithm for the Bi-Objective Time-constrained task\n  Scheduling Problem in Cloud Computing Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing distributes computing tasks across numerous distributed\nresources for large-scale calculation. The task scheduling problem is a\nlong-standing problem in cloud-computing services with the purpose of\ndetermining the quality, availability, reliability, and ability of the cloud\ncomputing. This paper is an extension and a correction to our previous\nconference paper entitled Multi Objective Scheduling in Cloud Computing Using\nMOSSO published in 2018 IEEE Congress on Evolutionary Computation. More new\nalgorithms, testing, and comparisons have been implemented to solve the\nbi-objective time-constrained task scheduling problem in a more efficient\nmanner. Furthermore, this paper developed a new SSO-based algorithm called the\nbi-objective simplified swarm optimization to fix the error in previous\nSSO-based algorithm to address the task-scheduling problem. From the results\nobtained from the new experiments conducted, the proposed BSSO outperforms\nexisting famous algorithms, e.g., NSGA-II, MOPSO, and MOSSO in the convergence,\ndiversity, number of obtained temporary nondominated solutions, and the number\nof obtained real nondominated solutions. The results propound that the proposed\nBSSO can successfully achieve the aim of this work.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 04:20:18 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Huang", "Chia-Ling", ""], ["Yeh", "Wei-Chang", ""]]}, {"id": "1905.04867", "submitter": "Quan Nguyen Hoang", "authors": "Quan Nguyen, Andre Cronje", "title": "ONLAY: Online Layering for scalable asynchronous BFT system", "comments": "arXiv admin note: substantial text overlap with arXiv:1810.10360", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new framework, namely \\emph{\\onlay}, for scalable\nasynchronous distributed systems. In this framework, we propose a consensus\nprotocol $L_{\\phi}$, which is based on the Lachesis protocol~\\cite{lachesis01}.\nAt the core of $L_{\\phi}$ protocol, it introduces to use layering algorithm to\nachieve practical Byzantine fault tolerance (pBFT) in leaderless asynchronous\nDirected Acyclic Graph (DAG). Further, we present new online layering\nalgorithms for the evolutionary DAGs across the nodes. Our new protocol\nachieves determistic scalable consensus in asynchronous pBFT by using assigned\nlayers and asynchronous partially ordered sets with logical time ordering\ninstead of blockchains. The partial ordering produced by $L_{\\phi}$ is flexible\nbut consistent across the distributed system of nodes. We then present the\nformal model of our layering-based consensus. The model is generalized that can\nbe applied to abstract asynchronous DAG-based distributed systems.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 05:30:29 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Nguyen", "Quan", ""], ["Cronje", "Andre", ""]]}, {"id": "1905.04975", "submitter": "Mirko Myllykoski", "authors": "Mirko Myllykoski and Carl Christian Kjelgaard Mikkelsen", "title": "Introduction to StarNEig -- A Task-based Library for Solving\n  Nonsymmetric Eigenvalue Problems", "comments": "10 pages, 4 figures (10 when counting sub-figures), 2 tex-files.\n  Submitted to PPAM 2019, 13th international conference on parallel processing\n  and applied mathematics, September 8-11, 2019. Proceedings will be published\n  after the conference by Springer in the LNCS series. Second author's first\n  name is \"Carl Christian\" and last name \"Kjelgaard Mikkelsen\"", "journal-ref": "LNCS 12043 (2020) 70-81", "doi": "10.1007/978-3-030-43229-4_7", "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the StarNEig library for solving dense\nnon-symmetric (generalized) eigenvalue problems. The library is built on top of\nthe StarPU runtime system and targets both shared and distributed memory\nmachines. Some components of the library support GPUs. The library is currently\nin an early beta state and only real arithmetic is supported. Support for\ncomplex data types is planned for a future release. This paper is aimed for\npotential users of the library. We describe the design choices and capabilities\nof the library, and contrast them to existing software such as ScaLAPACK.\nStarNEig implements a ScaLAPACK compatibility layer that should make it easy\nfor a new user to transition to StarNEig. We demonstrate the performance of the\nlibrary with a small set of computational experiments.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 11:20:09 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Myllykoski", "Mirko", ""], ["Mikkelsen", "Carl Christian Kjelgaard", ""]]}, {"id": "1905.04989", "submitter": "Iqra Altaf Gillani", "authors": "Iqra Altaf Gillani and Amitabha Bagchi", "title": "A Distributed Laplacian Solver and its Applications to Electrical Flow\n  and Random Spanning Tree Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use queueing networks to present a new approach to solving Laplacian\nsystems. This marks a significant departure from the existing techniques,\nmostly based on graph-theoretic constructions and sampling. Our distributed\nsolver works for a large and important class of Laplacian systems that we call\n\"one-sink\" Laplacian systems. Specifically, our solver can produce solutions\nfor systems of the form $Lx = b$ where exactly one of the coordinates of $b$ is\nnegative. Our solver is a distributed algorithm that takes\n$\\widetilde{O}(t_{hit} d_{\\max})$ time (where $\\widetilde{O}$ hides\n$\\text{poly}\\log n$ factors) to produce an approximate solution where $t_{hit}$\nis the worst-case hitting time of the random walk on the graph, which is\n$\\Theta(n)$ for a large set of important graphs, and $d_{\\max}$ is the\ngeneralized maximum degree of the graph. The class of one-sink Laplacians\nincludes the important voltage computation problem and allows us to compute the\neffective resistance between nodes in a distributed setting. As a result, our\nLaplacian solver can be used to adapt the approach by Kelner and M\\k{a}dry\n(2009) to give the first distributed algorithm to compute approximate random\nspanning trees efficiently.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 12:06:13 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 03:30:39 GMT"}, {"version": "v3", "created": "Sun, 13 Oct 2019 16:55:56 GMT"}, {"version": "v4", "created": "Thu, 10 Sep 2020 11:28:08 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Gillani", "Iqra Altaf", ""], ["Bagchi", "Amitabha", ""]]}, {"id": "1905.05011", "submitter": "Susmita Dey Manasi", "authors": "Susmita Dey Manasi, Farhana Sharmin Snigdha, and Sachin S. Sapatnekar", "title": "NeuPart: Using Analytical Models to Drive Energy-Efficient Partitioning\n  of CNN Computations on Cloud-Connected Mobile Clients", "comments": "Published in IEEE Transactions on Very Large Scale Integration (VLSI)\n  Systems, April 2020", "journal-ref": "IEEE Transactions on Very Large Scale Integration Systems (TVLSI),\n  vol. 28, no. 8, pp. 1844-1857, Aug. 2020", "doi": "10.1109/TVLSI.2020.2995135", "report-no": null, "categories": "cs.DC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data processing on convolutional neural networks (CNNs) places a heavy burden\non energy-constrained mobile platforms. This work optimizes energy on a mobile\nclient by partitioning CNN computations between in situ processing on the\nclient and offloaded computations in the cloud. A new analytical CNN energy\nmodel is formulated, capturing all major components of the in situ computation,\nfor ASIC-based deep learning accelerators. The model is benchmarked against\nmeasured silicon data. The analytical framework is used to determine the\noptimal energy partition point between the client and the cloud at runtime. On\nstandard CNN topologies, partitioned computation is demonstrated to provide\nsignificant energy savings on the client over fully cloud-based or fully in\nsitu computation. For example, at 80 Mbps effective bit rate and 0.78 W\ntransmission power, the optimal partition for AlexNet [SqueezeNet] saves up to\n52.4% [73.4%] energy over a fully cloud-based computation, and 27.3% [28.8%]\nenergy over a fully in situ computation.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 17:35:32 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 07:22:11 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Manasi", "Susmita Dey", ""], ["Snigdha", "Farhana Sharmin", ""], ["Sapatnekar", "Sachin S.", ""]]}, {"id": "1905.05042", "submitter": "Igor Ostanin A", "authors": "Igor Ostanin, Traian Dumitric\\u{a}, Sebastian Eibl, Ulrich R\\\"ude", "title": "Computational Study of Ultrathin CNT Films with the Scalable Mesoscopic\n  Distinct Element Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mes-hall cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a computational study of the small strain mechanics\nof freestanding ultrathin CNT films under in-plane loading. The numerical\nmodeling of the mechanics of representatively large specimens with realistic\nmicro- and nanostructure is presented. Our simulations utilize the scalable\nimplementation of the mesoscopic distinct element method of the waLBerla\nmulti-physics framework. Within our modeling approach, CNTs are represented as\nchains of interacting rigid segments. Neighboring segments in the chain are\nconnected with elastic bonds, resolving tension, bending, shear and torsional\ndeformations. These bonds represent a covalent bonding within CNT surface and\nutilize Enhanced Vector Model (EVM) formalism. Segments of the neighboring CNTs\ninteract with realistic coarse-grained anisotropic vdW potential, enabling\nrelative slip of CNTs in contact. The advanced simulation technique allowed us\nto gain useful insights on the behavior of CNT materials. In particular, it was\nestablished that the energy dissipation during CNT sliding leads to extended\nload transfer that conditions material-like mechanical response of the weakly\nbonded assemblies of CNTs.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 14:00:01 GMT"}, {"version": "v2", "created": "Sat, 19 Oct 2019 21:50:56 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Ostanin", "Igor", ""], ["Dumitric\u0103", "Traian", ""], ["Eibl", "Sebastian", ""], ["R\u00fcde", "Ulrich", ""]]}, {"id": "1905.05079", "submitter": "Shiyu Cai", "authors": "Shiyu Cai", "title": "Analysis of Committee Selection Mechanism in Blockchain", "comments": "This version is rough and e-mail me if there are mistakes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Committee Selection Mechanism can select multiple users of blockchain\nnetwork to execute a consensus algorithm, such as PBFT. In order to guarantee\ntwo properties, the mathematical form of the mechanism is relatively limited.\nFurther, if the mechanism is used in open network, it will bring about an\nincrease in efficiency, but it will reduce the security and practicability of\nthe blockchain network.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 12:23:54 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Cai", "Shiyu", ""]]}, {"id": "1905.05119", "submitter": "Son Dinh", "authors": "Son Dinh, Christopher Gill, Kunal Agrawal", "title": "Analysis of Global Fixed-Priority Scheduling for Generalized Sporadic\n  DAG Tasks", "comments": "real-time systems, parallel DAG tasks, G-FP scheduling", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider global fixed-priority (G-FP) scheduling of parallel tasks, in\nwhich each task is represented as a directed acyclic graph (DAG). We summarize\nand highlight limitations of the state-of-the-art analyses for G-FP and propose\na novel technique for bounding interfering workload, which can be applied\ndirectly to generalized DAG tasks. Our technique works by constructing\noptimization problems for which the optimal solution values serve as safe and\ntight upper bounds for interfering workloads. Using the proposed workload\nbounding technique, we derive a response-time analysis and show that it\nimproves upon state-of-the-art analysis techniques for G-FP scheduling.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 16:15:03 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Dinh", "Son", ""], ["Gill", "Christopher", ""], ["Agrawal", "Kunal", ""]]}, {"id": "1905.05175", "submitter": "Gaurav Khanna", "authors": "Connor Kenyon, Glenn Volkema and Gaurav Khanna", "title": "Overcoming Limitations of GPGPU-Computing in Scientific Applications", "comments": "9 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of discrete general purpose graphics processing units\n(GPGPUs) has been improving at a rapid pace. The PCIe interconnect that\ncontrols the communication of data between the system host memory and the GPU\nhas not improved as quickly, leaving a gap in performance due to GPU downtime\nwhile waiting for PCIe data transfer. In this article, we explore two\nalternatives to the limited PCIe bandwidth, NVIDIA NVLink interconnect, and\nzero-copy algorithms for shared memory Heterogeneous System Architecture (HSA)\ndevices. The OpenCL SHOC benchmark suite is used to measure the performance of\neach device on various scientific application kernels.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 11:51:28 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Kenyon", "Connor", ""], ["Volkema", "Glenn", ""], ["Khanna", "Gaurav", ""]]}, {"id": "1905.05177", "submitter": "Jun Li", "authors": "Jun Li and Xun Lin and Xiaoguang Rui and Yong Rui and Dacheng Tao", "title": "A Distributed Approach towards Discriminative Distance Metric Learning", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2014.2377211", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distance metric learning is successful in discovering intrinsic relations in\ndata. However, most algorithms are computationally demanding when the problem\nsize becomes large. In this paper, we propose a discriminative metric learning\nalgorithm, and develop a distributed scheme learning metrics on moderate-sized\nsubsets of data, and aggregating the results into a global solution. The\ntechnique leverages the power of parallel computation. The algorithm of the\naggregated distance metric learning (ADML) scales well with the data size and\ncan be controlled by the partition. We theoretically analyse and provide bounds\nfor the error induced by the distributed treatment. We have conducted\nexperimental evaluation of ADML, both on specially designed tests and on\npractical image annotation tasks. Those tests have shown that ADML achieves the\nstate-of-the-art performance at only a fraction of the cost incurred by most\nexisting methods.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 11:56:33 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Li", "Jun", ""], ["Lin", "Xun", ""], ["Rui", "Xiaoguang", ""], ["Rui", "Yong", ""], ["Tao", "Dacheng", ""]]}, {"id": "1905.05254", "submitter": "Wei Quan Lim", "authors": "Wei Quan Lim", "title": "Optimal Multithreaded Batch-Parallel 2-3 Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a batch-parallel 2-3 tree T in an asynchronous dynamic\nmultithreading model that supports searches, insertions and deletions in sorted\nbatches and has essentially optimal parallelism, even under the restrictive\nQRMW (queued read-modify-write) memory contention model where concurrent\naccesses to the same memory location are queued and serviced one by one.\n  Specifically, if T has n items, then performing an item-sorted batch (given\nas a leaf-based balanced binary tree) of b operations on T takes O( b *\nlog(n/b+1) + b ) work and O( log b + log n ) span (in the worst case as b,n ->\ninf). This is information-theoretically work-optimal for b <= n, and also\nspan-optimal for pointer-based structures. Moreover, it is easy to support\noptimal intersection, union and difference of instances of T with sizes m <= n,\nnamely within O( m * log(n/m+1) ) work and O( log m + log n ) span.\nFurthermore, T supports other batch operations that make it a very useful\nbuilding block for parallel data structures.\n  To the author's knowledge, T is the first parallel sorted-set data structure\nthat can be used in an asynchronous multi-processor machine under a memory\nmodel with queued contention and yet have asymptotically optimal work and span.\nIn fact, T is designed to have bounded contention and satisfy the claimed work\nand span bounds regardless of the execution schedule.\n  Since all data structures and algorithms in this paper fit into the dynamic\nmultithreading paradigm, all their performance bounds are directly composable\nwith those of other data structures and algorithms in the same model. Finally,\nthe pipelining techniques in this paper are also likely to be very useful in\nasynchronous parallelization of other recursive data structures.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 19:23:36 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 08:27:48 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Lim", "Wei Quan", ""]]}, {"id": "1905.05359", "submitter": "Tong Geng", "authors": "Chen Yang, Tong Geng, Tianqi Wang, Rushi Patel, Qingqing Xiong, Ahmed\n  Sanaullah, Jiayi Sheng, Charles Lin, Vipin Sachdeva, Woody Sherman, Martin C.\n  Herbordt", "title": "Fully Integrated On-FPGA Molecular Dynamics Simulations", "comments": "13 pages, 17 figures;", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The implementation of Molecular Dynamics (MD) on FPGAs has received\nsubstantial attention. Previous work, however, has consisted of either\nproof-of-concept implementations of components, usually the range-limited\nforce; full systems, but with much of the work shared by the host CPU; or\nprototype demonstrations, e.g., using OpenCL, that neither implement a whole\nsystem nor have competitive performance. In this paper, we present what we\nbelieve to be the first full-scale FPGA-based simulation engine, and show that\nits performance is competitive with a GPU (running Amber in an industrial\nproduction environment). The system features on-chip particle data storage and\nmanagement, short- and long-range force evaluation, as well as bonded forces,\nmotion update, and particle migration. Other contributions of this work include\nexploring numerous architectural trade-offs and analysis on various mappings\nschemes among particles/cells and the various on-chip compute units. The\npotential impact is that this system promises to be the basis for long\ntimescale Molecular Dynamics with a commodity cluster.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 02:29:27 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Yang", "Chen", ""], ["Geng", "Tong", ""], ["Wang", "Tianqi", ""], ["Patel", "Rushi", ""], ["Xiong", "Qingqing", ""], ["Sanaullah", "Ahmed", ""], ["Sheng", "Jiayi", ""], ["Lin", "Charles", ""], ["Sachdeva", "Vipin", ""], ["Sherman", "Woody", ""], ["Herbordt", "Martin C.", ""]]}, {"id": "1905.05388", "submitter": "Sumit Tetarave", "authors": "Sumit Kumar Tetarave, Somanath Tripathy", "title": "Robust Node ID Assignment for Mobile P2P Networks", "comments": "13 pages", "journal-ref": null, "doi": "10.1007/s42486-020-00047-x", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advancement of portable mobile wireless devices such as smart-phones,\nPDA, etc., brought mobile peer-to-peer (P2P) as an extension of traditional P2P\nnetworks to provide efficient, low-cost communication among them in a cellular\nnetwork. It is challenging to assign a unique identifier to each user, as an\nadversary can target to disrupt the P2P system, by carefully selecting user IDs\nor obtaining many pseudo-IDs. This work proposes a robust node-ID assignment\nmechanism for secure peer joining in mobile P2P system called PJ-Sec. PJ-Sec\nfacilitates to generate nodeID for a joining peer by a collaborative effort of\nan existing peer (within the vicinity) and pre-selected vicinity head. PJ-Sec\nis formally analyzed using AVISPA model checker and found to be attack\nresistant.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 04:32:37 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Tetarave", "Sumit Kumar", ""], ["Tripathy", "Somanath", ""]]}, {"id": "1905.05411", "submitter": "Nicolas Holliman Professor", "authors": "Richard Cloete, Nick Holliman", "title": "Measuring and simulating latency in interactive remote rendering systems", "comments": "Minor update to typos and acknowledgements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.GR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background: The computationally intensive task of real-time rendering can be\noffloaded to remote cloud systems. However, due to network latency, interactive\nremote rendering (IRR) introduces the challenge of interaction latency (IL),\nwhich is the time between an action and response to that action. Objectives: to\nmodel sources of latency, measure it in a real-world network and to use this\nunderstanding to simulate latency so that we have a controlled platform for\nexperimental work in latency management. Method: we present a seven-parameter\nmodel of latency for a typical IRR system; we describe new, minimally intrusive\nsoftware methods for measuring latency in a 3D graphics environment and create\na novel latency simulator tool in software. Results: We demonstrate our latency\nsimulator is comparable to real-world behavior and confirm that real-world\nlatency exceeds the interactive limit of 70ms over long distance connections.\nWe also find that current approaches to measuring IL are not general enough for\nmost situations and therefore propose a novel general-purpose solution.\nConclusion: to ameliorate latency in IRR systems we need controllable\nsimulation tools for experimentation. In addition to a new measurement\ntechnique, we propose a new approach that will be of interest to IRR\nresearchers and developers when designing IL compensation techniques.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 06:38:36 GMT"}, {"version": "v2", "created": "Sat, 18 May 2019 19:58:34 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Cloete", "Richard", ""], ["Holliman", "Nick", ""]]}, {"id": "1905.05478", "submitter": "Ivan Yanchin", "authors": "Ivan Yanchin and Oleg Petrov", "title": "Parallel genetic algorithm for planning safe and optimal route for ship", "comments": "26 pages, 13 figures, 15 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper represents an algorithm for planning safe and optimal routes for\ntransport facilities with unrestricted movement direction that travel within\nareas with obstacles. Paper explains the algorithm using a ship as an example\nof such a transport facility. This paper also provides a survey of several\nexisting solutions for the problem. The method employs an evolutionary\nalgorithm to plan several locally optimal routes and a parallel genetic\nalgorithm to create the final route by optimising the abovementioned set of\nroutes. The routes are optimized against the arrival time, assuming that the\noptimal route is the route with the lowermost arrival time. It is also possible\nto apply additional restriction to the routes.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 09:24:16 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Yanchin", "Ivan", ""], ["Petrov", "Oleg", ""]]}, {"id": "1905.05568", "submitter": "Michael Orr", "authors": "Michael Orr, Oliver Sinnen", "title": "Parallel and Memory-limited Algorithms for Optimal Task Scheduling Using\n  a Duplicate-Free State-Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of task scheduling with communication delays is strongly NP-hard.\nState-space search algorithms such as A* have been shown to be a promising\napproach to solving small to medium sized instances optimally. A recently\nproposed state-space model for task scheduling, known as Allocation-Ordering\n(AO), allows state-space search methods to be applied without the need for\npreviously necessary duplicate avoidance mechanisms, and resulted in\nsignificantly improved A* performance. The property of a duplicate-free state\nspace also holds particular promise for memory limited search algorithms, such\nas depth-first branch-and-bound (DFBnB), and parallel search algorithms. This\npaper investigates and proposes such algorithms for the AO model and, for\ncomparison, the older Exhaustive List Scheduling (ELS) state-space model. Our\nextensive evaluation shows that AO gives a clear advantage to DFBnB and allows\ngreater scalability for parallel search algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 12:52:53 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Orr", "Michael", ""], ["Sinnen", "Oliver", ""]]}, {"id": "1905.05574", "submitter": "Albin Severinson", "authors": "Albin Severinson, Eirik Rosnes and Alexandre Graell i Amat", "title": "Coded Distributed Tracking", "comments": "Accepted for publication at IEEE GLOBECOM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.PF cs.RO cs.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of tracking the state of a process that evolves over\ntime in a distributed setting, with multiple observers each observing parts of\nthe state, which is a fundamental information processing problem with a wide\nrange of applications. We propose a cloud-assisted scheme where the tracking is\nperformed over the cloud. In particular, to provide timely and accurate\nupdates, and alleviate the straggler problem of cloud computing, we propose a\ncoded distributed computing approach where coded observations are distributed\nover multiple workers. The proposed scheme is based on a coded version of the\nKalman filter that operates on data encoded with an erasure correcting code,\nsuch that the state can be estimated from partial updates computed by a subset\nof the workers. We apply the proposed scheme to the problem of tracking\nmultiple vehicles. We show that replication achieves significantly higher\naccuracy than the corresponding uncoded scheme. The use of maximum distance\nseparable (MDS) codes further improves accuracy for larger update intervals. In\nboth cases, the proposed scheme approaches the accuracy of an ideal centralized\nscheme when the update interval is large enough. Finally, we observe a\ntrade-off between age-of-information and estimation accuracy for MDS codes.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 13:02:44 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 14:16:02 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Severinson", "Albin", ""], ["Rosnes", "Eirik", ""], ["Amat", "Alexandre Graell i", ""]]}, {"id": "1905.05957", "submitter": "Hanlin Tang", "authors": "Hanlin Tang, Xiangru Lian, Chen Yu, Tong Zhang, Ji Liu", "title": "DoubleSqueeze: Parallel Stochastic Gradient Descent with Double-Pass\n  Error-Compensated Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A standard approach in large scale machine learning is distributed stochastic\ngradient training, which requires the computation of aggregated stochastic\ngradients over multiple nodes on a network. Communication is a major bottleneck\nin such applications, and in recent years, compressed stochastic gradient\nmethods such as QSGD (quantized SGD) and sparse SGD have been proposed to\nreduce communication. It was also shown that error compensation can be combined\nwith compression to achieve better convergence in a scheme that each node\ncompresses its local stochastic gradient and broadcast the result to all other\nnodes over the network in a single pass. However, such a single pass broadcast\napproach is not realistic in many practical implementations. For example, under\nthe popular parameter server model for distributed learning, the worker nodes\nneed to send the compressed local gradients to the parameter server, which\nperforms the aggregation. The parameter server has to compress the aggregated\nstochastic gradient again before sending it back to the worker nodes. In this\nwork, we provide a detailed analysis on this two-pass communication model and\nits asynchronous parallel variant, with error-compensated compression both on\nthe worker nodes and on the parameter server. We show that the\nerror-compensated stochastic gradient algorithm admits three very nice\nproperties: 1) it is compatible with an \\emph{arbitrary} compression technique;\n2) it admits an improved convergence rate than the non error-compensated\nstochastic gradient methods such as QSGD and sparse SGD; 3) it admits linear\nspeedup with respect to the number of workers. The empirical study is also\nconducted to validate our theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 06:07:55 GMT"}, {"version": "v2", "created": "Sun, 23 Jun 2019 00:44:41 GMT"}, {"version": "v3", "created": "Sat, 21 Mar 2020 19:45:13 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Tang", "Hanlin", ""], ["Lian", "Xiangru", ""], ["Yu", "Chen", ""], ["Zhang", "Tong", ""], ["Liu", "Ji", ""]]}, {"id": "1905.06022", "submitter": "Yixin Li", "authors": "Bin Cao, Yixin Li, Lei Zhang, Long Zhang, Shahid Mumtaz, Zhenyu Zhou\n  and Mugen Peng", "title": "When Internet of Things Meets Blockchain: Challenges in Distributed\n  Consensus", "comments": null, "journal-ref": "IEEE Network, 2019", "doi": "10.1109/MNET.2019.1900002", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain has been regarded as a promising technology for Internet of Things\n(IoT), since it provides significant solutions for decentralized network which\ncan address trust and security concerns, high maintenance cost problem, etc.\nThe decentralization provided by blockchain can be largely attributed to the\nuse of consensus mechanism, which enables peer-to-peer trading in a distributed\nmanner without the involvement of any third party. This article starts from\nintroducing the basic concept of blockchain and illustrating why consensus\nmechanism plays an indispensable role in a blockchain enabled IoT system. Then,\nwe discuss the main ideas of two famous consensus mechanisms including Proof of\nWork (PoW) and Proof of Stake (PoS), and list their limitations in IoT. Next,\ntwo mainstream Direct Acyclic Graph (DAG) based consensus mechanisms, i.e., the\nTangle and Hashgraph, are reviewed to show why DAG consensus is more suitable\nfor IoT system than PoW and PoS. Potential issues and challenges of DAG based\nconsensus mechanism to be addressed in the future are discussed in the last.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 08:21:03 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Cao", "Bin", ""], ["Li", "Yixin", ""], ["Zhang", "Lei", ""], ["Zhang", "Long", ""], ["Mumtaz", "Shahid", ""], ["Zhou", "Zhenyu", ""], ["Peng", "Mugen", ""]]}, {"id": "1905.06087", "submitter": "Guy Goren", "authors": "Guy Goren and Yoram Moses", "title": "Byzantine Consensus in the Common Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modular methods to transform Byzantine consensus protocols into ones that are\nfast and communication efficient in the common cases are presented. Small and\nshort protocol segments called layers are custom designed to optimize\nperformance in the common case. When composed with a Byzantine consensus\nprotocol of choice, they allow considerable control over the tradeoff in the\ncombined protocol's behavior in the presence of failures and its performance in\ntheir absence. When runs are failure free in the common case, the resulting\nprotocols decide in two rounds and require $2nt$ bits of communication. For the\ncommon case assumption that all processors propose 1 and no failures occur, we\nshow a transformation in which decisions are made in one round, and no bits of\ncommunication are exchanged. The resulting protocols achieve better common-case\ncomplexity than all existing Byzantine consensus protocols. Finally, in the\nrare instances in which the common case does not occur, a small cost is added\nto the complexity of the original consensus protocol being transformed. The key\ningredient of these layers that allows both time and communication efficiency\nin the common case is the use of {\\it silent confirmation rounds}, which are\nrounds where considerable relevant information can be obtained in the absence\nof any communication whatsoever.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 11:00:40 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Goren", "Guy", ""], ["Moses", "Yoram", ""]]}, {"id": "1905.06186", "submitter": "John Collomosse", "authors": "Yifan Yang, Daniel Cooper, John Collomosse, Constantin C. Dr\\u{a}gan,\n  Mark Manulis, Jamie Steane, Arthi Manohar, Jo Briggs, Helen Jones, Wendy\n  Moncur", "title": "TAPESTRY: A Blockchain based Service for Trusted Interaction Online", "comments": "Submitted to IEEE TSC Special Issue on Blockchain Services, May 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel blockchain based service for proving the provenance of\nonline digital identity, exposed as an assistive tool to help non-expert users\nmake better decisions about whom to trust online. Our service harnesses the\ndigital personhood (DP); the longitudinal and multi-modal signals created\nthrough users' lifelong digital interactions, as a basis for evidencing the\nprovenance of identity. We describe how users may exchange trust evidence\nderived from their DP, in a granular and privacy-preserving manner, with other\nusers in order to demonstrate coherence and longevity in their behaviour\nonline. This is enabled through a novel secure infrastructure combining hybrid\non- and off-chain storage combined with deep learning for DP analytics and\nvisualization. We show how our tools enable users to make more effective\ndecisions on whether to trust unknown third parties online, and also to spot\nbehavioural deviations in their own social media footprints indicative of\naccount hijacking.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 13:49:23 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Yang", "Yifan", ""], ["Cooper", "Daniel", ""], ["Collomosse", "John", ""], ["Dr\u0103gan", "Constantin C.", ""], ["Manulis", "Mark", ""], ["Steane", "Jamie", ""], ["Manohar", "Arthi", ""], ["Briggs", "Jo", ""], ["Jones", "Helen", ""], ["Moncur", "Wendy", ""]]}, {"id": "1905.06204", "submitter": "Stefan Schulte", "authors": "Michael Borkowski and Marten Sigwart and Philipp Frauenthaler and\n  Taneli Hukkinen and Stefan Schulte", "title": "DeXTT: Deterministic Cross-Blockchain Token Transfers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current blockchain technologies provide very limited interoperability.\nRestrictions with regards to asset transfers and data exchange between\ndifferent blockchains reduce usability and comfort for users, and hinder novel\ndevelopments within the blockchain space.\n  As a first step towards cross-blockchain interoperability, we propose the\nDeXTT cross-blockchain transfer protocol, which can be used to transfer a token\non any number of blockchains simultaneously in a decentralized manner. We\nprovide a reference implementation using Solidity, and evaluate its\nperformance. We show logarithmic scalability of DeXTT with respect to the\nnumber of participating nodes, and analyze cost requirements of the transferred\ntokens.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 14:19:21 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Borkowski", "Michael", ""], ["Sigwart", "Marten", ""], ["Frauenthaler", "Philipp", ""], ["Hukkinen", "Taneli", ""], ["Schulte", "Stefan", ""]]}, {"id": "1905.06234", "submitter": "Karan Aggarwal", "authors": "Karan Aggarwal, Uday Bondhugula", "title": "Optimizing the Linear Fascicle Evaluation Algorithm for Multi-Core and\n  Many-Core Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse matrix-vector multiplication (SpMV) operations are commonly used in\nvarious scientific applications. The performance of the SpMV operation often\ndepends on exploiting regularity patterns in the matrix. Various\nrepresentations have been proposed to minimize the memory bandwidth bottleneck\narising from the irregular memory access pattern involved. Among recent\nrepresentation techniques, tensor decomposition is a popular one used for very\nlarge but sparse matrices. Post sparse-tensor decomposition, the new\nrepresentation involves indirect accesses, making it challenging to optimize\nfor multi-cores and GPUs.\n  Computational neuroscience algorithms often involve sparse datasets while\nstill performing long-running computations on them. The LiFE application is a\npopular neuroscience algorithm used for pruning brain connectivity graphs. The\ndatasets employed herein involve the Sparse Tucker Decomposition (STD), a\nwidely used tensor decomposition method. Using this decomposition leads to\nirregular array references, making it very difficult to optimize for both CPUs\nand GPUs. Recent codes of the LiFE algorithm show that its SpMV operations are\nthe key bottleneck for performance and scaling. In this work, we first propose\ntarget-independent optimizations to optimize these SpMV operations, followed by\ntarget-dependent optimizations for CPU and GPU systems. The target-independent\ntechniques include: (1) standard compiler optimizations, (2) data restructuring\nmethods, and (3) methods to partition computations among threads. Then we\npresent the optimizations for CPUs and GPUs to exploit platform-specific speed.\nOur highly optimized CPU code obtain a speedup of 27.12x over the original\nsequential CPU code running on 16-core Intel Xeon (Skylake-based) system, and\nour optimized GPU code achieves a speedup of 5.2x over a reference optimized\nGPU code version on NVIDIA's GeForce RTX 2080 Ti GPU.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 11:09:11 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 06:29:42 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Aggarwal", "Karan", ""], ["Bondhugula", "Uday", ""]]}, {"id": "1905.06235", "submitter": "Issam Damaj", "authors": "Palwasha Shaikh (1), Issam Damaj (1) ((1) American University of\n  Kuwait)", "title": "Analysis of Pipelined KATAN Ciphers under Handle-C for FPGAs", "comments": "6 pages, 3 figures, 6 tables", "journal-ref": "13th International Conference on Innovations in Information\n  Technology, IEEE, Al Ain, UAE (2018) 163-168", "doi": "10.1109/INNOVATIONS.2018.8606012", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedded Systems are everywhere from the smartphones we hold in our hands to\nthe satellites that hover around the earth. These embedded systems are being\nincreasingly integrated into our personal and commercial infrastructures. More\nthan 98% of all processors are implanted and used in embedded systems rather\nthan traditional computers. As a result, security in embedded systems now more\nthan ever has become a major concern. Since embedded systems are designed to be\nlow-cost, fast and real-time, it would be appropriate to use tiny, lightweight\nand highly secure cryptographic algorithms. KATAN and KATANTAN family of\nlight-weight block ciphers are promising cryptographic options. In this paper,\na sequential hardware design is developed under Handel-C. Taking a step\nfurther, Handel-C's parallel construct is taken advantage of to develop a\nparallel-pipelined hybrid implementation. Both sequential and\nparallel-pipelined implementations are tested under Altera Quartus to implement\nand analyze hardware designs in conjunction with DK Design Suite's Handel-C\ncompiler. The developed designs are mapped to Altera's Stratix II that is one\nof the industry's highest bandwidth and density FPGAs. The results confirm that\nusing Handel-C can provide faster implementations. The obtained results are\npromising and show better performance when compared with similar\nimplementations-specifically the developed parallel-pipelined processor.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 12:52:28 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Shaikh", "Palwasha", ""], ["Damaj", "Issam", ""]]}, {"id": "1905.06236", "submitter": "Wushi Dong", "authors": "Wushi Dong, Murat Keceli, Rafael Vescovi, Hanyu Li, Corey Adams, Elise\n  Jennings, Samuel Flender, Tom Uram, Venkatram Vishwanath, Nicola Ferrier,\n  Narayanan Kasthuri, Peter Littlewood", "title": "Scaling Distributed Training of Flood-Filling Networks on HPC\n  Infrastructure for Brain Mapping", "comments": "9 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mapping all the neurons in the brain requires automatic reconstruction of\nentire cells from volume electron microscopy data. The flood-filling network\n(FFN) architecture has demonstrated leading performance for segmenting\nstructures from this data. However, the training of the network is\ncomputationally expensive. In order to reduce the training time, we implemented\nsynchronous and data-parallel distributed training using the Horovod library,\nwhich is different from the asynchronous training scheme used in the published\nFFN code. We demonstrated that our distributed training scaled well up to 2048\nIntel Knights Landing (KNL) nodes on the Theta supercomputer. Our trained\nmodels achieved similar level of inference performance, but took less training\ntime compared to previous methods. Our study on the effects of different batch\nsizes on FFN training suggests ways to further improve training efficiency. Our\nfindings on optimal learning rate and batch sizes agree with previous works.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 16:00:52 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 03:27:23 GMT"}, {"version": "v3", "created": "Sat, 21 Sep 2019 17:37:37 GMT"}, {"version": "v4", "created": "Mon, 9 Dec 2019 22:29:23 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Dong", "Wushi", ""], ["Keceli", "Murat", ""], ["Vescovi", "Rafael", ""], ["Li", "Hanyu", ""], ["Adams", "Corey", ""], ["Jennings", "Elise", ""], ["Flender", "Samuel", ""], ["Uram", "Tom", ""], ["Vishwanath", "Venkatram", ""], ["Ferrier", "Nicola", ""], ["Kasthuri", "Narayanan", ""], ["Littlewood", "Peter", ""]]}, {"id": "1905.06237", "submitter": "Antonios Makris", "authors": "Antonios Makris", "title": "Implementation of functions in R tool in parallel environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug promiscuity and polypharmacology are much discussed topics in\npharmaceutical research. Drug repositioning applies established drugs to new\ndisease indications with increasing success. As polypharmacology, defined a\ndrug's ability to bind to several targets but due to possible side effects,\nthis feature is not taken into consideration. Thus, the pharmaceutical industry\nfocused on the development of highly selective single-target drugs. Nowadays\nafter lot of researches, it is clear that polypharmacology is important for the\nefficacy of drugs. There are side effects but on the other hand, this gives the\nopportunity to uncover new uses for already known drugs and especially for\ncomplex diseases. Thus, it is clear that there are two sides of the same coin.\nThere are several approaches to discover new drugs targets, as analysis of\ngenome wide association, gene expression data and networks, structural\napproaches with alignment methods etc. Computational drug discovery and design\nhas experienced a rapid increase in development which is mainly due to the\nincreasing cost for discovering new compounds. Since drug development is a very\ncostly venture, the pharmaceutical industry puts effort in the repositioning of\nwithdrawn or already approved drugs. The costs for bringing such a drug to\nmarket are 60% lower than the development of a novel drug, which costs roughly\none billion US dollars. Thus, target prediction, drug repositioning approaches,\nprotein-ligand docking and scoring algorithms, virtual screening and other\ncomputational techniques have gained the interest of researchers and\npharmaceutical companies.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 11:12:37 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Makris", "Antonios", ""]]}, {"id": "1905.06238", "submitter": "Jian Weng", "authors": "Jian Weng, Vidushi Dadu, Tony Nowatzki", "title": "Exploiting Fine-Grain Ordered Parallelism in Dense Matrix Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense linear algebra kernels are critical for wireless applications, and the\noncoming proliferation of 5G only amplifies their importance. Many such matrix\nalgorithms are inductive, and exhibit ample amounts of fine-grain ordered\nparallelism -- when multiple computations flow with fine-grain\nproducer/consumer dependences, and where the iteration domain is not easily\ntileable. Synchronization overheads make multi-core parallelism ineffective and\nthe non-tileable iterations make the vector-VLIW approach less effective,\nespecially for the typically modest-sized matrices. Because CPUs and DSPs lose\norder-of-magnitude performance/hardware utilization, costly and inflexible\nASICs are often employed in signal processing pipelines. A programmable\naccelerator with similar performance/power/area would be highly desirable. We\nfind that fine-grain ordered parallelism can be exploited by supporting: 1.\nfine-grain stream-based communication/synchronization; 2. inductive data-reuse\nand memory access patterns; 3. implicit vector-masking for partial vectors; 4.\nhardware specialization of dataflow criticality. In this work, we propose,\nREVEL, as a next-generation DSP architecture. It supports the above features in\nits ISA and microarchitecture, and further uses a novel vector-stream control\nparadigm to reduce control overheads. Across a suite of linear algebra kernels,\nREVEL outperforms equally provisioned DSPs by 4.6x-37x in latency and achieves\na performance per mm 2 of 8.3x. It is only 2.2x higher power to achieve the\nsame performance as ideal ASICs, at about 55% of the combined area.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 20:28:30 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Weng", "Jian", ""], ["Dadu", "Vidushi", ""], ["Nowatzki", "Tony", ""]]}, {"id": "1905.06421", "submitter": "Christina Peterson", "authors": "Victor Cook, Christina Peterson, Zachary Painter, Damian Dechev", "title": "Quantifiability: Concurrent Correctness from First Principles", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Architectural imperatives due to the slowing of Moore's Law, the broad\nacceptance of relaxed semantics and the O(n!) worst case verification\ncomplexity of generating sequential histories motivate a new approach to\nconcurrent correctness. Desiderata for a new correctness condition are that it\nbe independent of sequential histories, compositional, flexible as to timing,\nmodular as to semantics and free of inherent locking or waiting. We propose\nQuantifiability, a novel correctness condition based on intuitive first\nprinciples. Quantifiability models a system in vector space to launch a new\nmathematical analysis of concurrency. The vector space model is suitable for a\nwide range of concurrent systems and their associated data structures. This\npaper formally defines quantifiability and demonstrates useful properties such\nas compositionality. Analysis is facilitated with linear algebra, better\nsupported and of much more efficient time complexity than traditional\ncombinatorial methods. We present results showing that quantifiable data\nstructures are highly scalable due to the usage of relaxed semantics and\npropose entropy to evaluate the implementation trade-offs permitted by\nquantifiability.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 20:15:52 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2019 19:11:53 GMT"}, {"version": "v3", "created": "Tue, 16 Jul 2019 13:49:04 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Cook", "Victor", ""], ["Peterson", "Christina", ""], ["Painter", "Zachary", ""], ["Dechev", "Damian", ""]]}, {"id": "1905.06460", "submitter": "Hung Dang", "authors": "Hung Dang, Ee-Chien Chang", "title": "Autonomous Membership Service for Enclave Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trusted Execution Environment, or enclave, promises to protect data\nconfidentiality and execution integrity of an outsourced computation on an\nuntrusted host. Extending the protection to distributed applications that run\non physically separated hosts, however, remains non-trivial. For instance, the\ncurrent enclave provisioning model hinders elasticity of cloud applications.\nFurthermore, it remains unclear how an enclave process could verify if there\nexists another concurrently running enclave process instantiated using the same\ncodebase, or count a number of such processes. In this paper, we seek an\nautonomous membership service for enclave applications. The application owner\nonly needs to partake in instantiating the very first process of the\napplication, whereas all subsequent process commission and decommission will be\nadministered by existing and active processes of that very application. To\nachieve both safety and liveness, our protocol design admits unjust\nexcommunication of a non-faulty process from the membership group. We implement\nthe proposed membership service in a system called AMES. Our experimental study\nshows that AMES incurs an overhead of 5% - 16% compared to vanilla enclave\nexecution.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 22:33:42 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Dang", "Hung", ""], ["Chang", "Ee-Chien", ""]]}, {"id": "1905.06462", "submitter": "Praneeth Vepakomma", "authors": "Ramesh Raskar, Praneeth Vepakomma, Tristan Swedish, Aalekh Sharan", "title": "Data Markets to support AI for All: Pricing, Valuation and Governance", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss a data market technique based on intrinsic (relevance and\nuniqueness) as well as extrinsic value (influenced by supply and demand) of\ndata. For intrinsic value, we explain how to perform valuation of data in\nabsolute terms (i.e just by itself), or relatively (i.e in comparison to\nmultiple datasets) or in conditional terms (i.e valuating new data given\ncurrently existing data).\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 04:41:11 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Raskar", "Ramesh", ""], ["Vepakomma", "Praneeth", ""], ["Swedish", "Tristan", ""], ["Sharan", "Aalekh", ""]]}, {"id": "1905.06520", "submitter": "Dumitrel Loghin", "authors": "Dumitrel Loghin, Gang Chen, Tien Tuan Anh Dinh, Beng Chin Ooi, Yong\n  Meng Teo", "title": "Blockchain Goes Green? An Analysis of Blockchain on Low-Power Nodes", "comments": "17 pages, 13 pages paper, 4 pages appendix, 20 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.ET cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by the massive energy usage of blockchain, on the one hand, and by\nsignificant performance improvements in low-power, wimpy systems, on the other\nhand, we perform an in-depth time-energy analysis of blockchain systems on\nlow-power nodes in comparison to high-performance nodes. We use three low-power\nsystems to represent a wide range of the performance-power spectrum, while\ncovering both x86/64 and ARM architectures. We show that low-end wimpy nodes\nare struggling to run full-fledged blockchains mainly due to their small and\nlow-bandwidth memory. On the other hand, wimpy systems with balanced\nperformance-to-power ratio achieve reasonable performance while saving\nsignificant amounts of energy. For example, Jetson TX2 nodes achieve around 80%\nand 30% of the throughput of Parity and Hyperledger, respectively, while using\n18x and 23x less energy compared to traditional brawny servers with Intel Xeon\nCPU.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 04:21:04 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 06:21:18 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Loghin", "Dumitrel", ""], ["Chen", "Gang", ""], ["Dinh", "Tien Tuan Anh", ""], ["Ooi", "Beng Chin", ""], ["Teo", "Yong Meng", ""]]}, {"id": "1905.06625", "submitter": "Hai Dinh-Tuan", "authors": "Hai Dinh-Tuan, Felix Beierle, Sandro Rodriguez Garzon", "title": "MAIA: A Microservices-based Architecture for Industrial Data Analytics", "comments": "Accepted to be published at the IEEE International Conference on\n  Industrial Cyber-Physical Systems 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent decades, it has become a significant tendency for industrial\nmanufacturers to adopt decentralization as a new manufacturing paradigm. This\nenables more efficient operations and facilitates the shift from mass to\ncustomized production. At the same time, advances in data analytics give more\ninsights into the production lines, thus improving its overall productivity.\nThe primary objective of this paper is to apply a decentralized architecture to\naddress new challenges in industrial analytics. The main contributions of this\nwork are therefore two-fold: (1) an assessment of the microservices'\nfeasibility in industrial environments, and (2) a microservices-based\narchitecture for industrial data analytics. Also, a prototype has been\ndeveloped, analyzed, and evaluated, to provide further practical insights.\nInitial evaluation results of this prototype underpin the adoption of\nmicroservices in industrial analytics with less than 20ms end-to-end processing\nlatency for predicting movement paths for 100 autonomous robots on a commodity\nhardware server. However, it also identifies several drawbacks of the approach,\nwhich is, among others, the complexity in structure, leading to higher resource\nconsumption.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 09:53:11 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Dinh-Tuan", "Hai", ""], ["Beierle", "Felix", ""], ["Garzon", "Sandro Rodriguez", ""]]}, {"id": "1905.06802", "submitter": "Mohsen Annabestani", "authors": "Mohsen Annabestani, Mahshid Nasserian, Fatemeh Hasanzadeh, Mohammad\n  Taherzadeh-Sani, Alireza Hassanzadeh", "title": "An Algebraic Approach to Fast Estimation of the Threshold Voltage of\n  Junctionless Double Gate MOSFETs Using the Gram Schmidt Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effect of decreasing Drain-Induced Barrier Lowering (DIBL) is one of the\nnon-desirable short-channel effects in the MOSFETs family, which causes the\nthreshold voltage of the transistor to be reduced by increasing the voltage of\nthe drain. This effect makes it impossible for circuit designers to consider VT\nas a constant value, and hence, it is necessary to calculate VT as a function\nof the drain voltage. Therefore, to consider the effect of DIBL in the design\nof integrated circuits, a large computational burden is imposed on the system,\nwhich slows down the simulation process in circuit-level simulators,\nparticularly when a large number of transistors are to be simulated.\nAccordingly, in this paper, a multiple input single output (MISO) Nonlinear\nAutoregressive (N-AR) model using the Gram-Schmidt orthogonalization approach\nis proposed, that calculates the threshold voltage of the new generation of\nMOSFETs, i.e., Junctionless Double-Gate MOSFETs (JL-DG-MOSFETs), with a high\nprecision and a significant speed-up in the computational procedure of the\nmodel. It is shown that, on average, the proposed numerical method is 313 times\nfaster than the state-of-the-art analytical model. The calculated percentage of\nnormalized mean square error between the proposed model and analytical one is\n0.435% on average, showing that the proposed approach can be a fast and\naccurate candidate for replacing the analytical modeling.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 23:09:44 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Annabestani", "Mohsen", ""], ["Nasserian", "Mahshid", ""], ["Hasanzadeh", "Fatemeh", ""], ["Taherzadeh-Sani", "Mohammad", ""], ["Hassanzadeh", "Alireza", ""]]}, {"id": "1905.06844", "submitter": "Issam Damaj", "authors": "Safaa Kasbah (1), Ramzi Haraty (1), Issam Damaj (2) ((1) Lebanese\n  American University, (2) Dhofar University)", "title": "Reconfigurable Hardware Implementation of the Successive Overrelaxation\n  Method", "comments": "15 pages, 5 figures, 4 tables. arXiv admin note: substantial text\n  overlap with arXiv:1904.00629", "journal-ref": "Lec. Notes. in. Elec. Eng. Springer. 5(2008) 453-466", "doi": "10.1007/978-0-387-74905-1_32", "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter, we study the feasibility of implementing SOR in\nreconfigurable hardware. We use Handel-C, a higher level design tool, to code\nour design, which is analyzed, synthesized, and placed and routed using the\nFPGAs proprietary software (DK Design Suite, Xilinx ISE 8.1i, and Quartus II\n5.1). We target Virtex II Pro, Altera Stratix, and Spartan3L, which is embedded\nin the RC10 FPGA-based system from Celoxica. We report our timing results when\ntargeting Virtex II Pro and compare them to software version results written in\nC++ and running on a general purpose processor (GPP).\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 12:18:34 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Kasbah", "Safaa", ""], ["Haraty", "Ramzi", ""], ["Damaj", "Issam", ""]]}, {"id": "1905.06850", "submitter": "Siegfried Cools", "authors": "Siegfried Cools, Jeffrey Cornelis, Pieter Ghysels, Wim Vanroose", "title": "Improving strong scaling of the Conjugate Gradient method for solving\n  large linear systems using global reduction pipelining", "comments": "EuroMPI 2019, 10 - 13 September 2019, ETH Zurich, Switzerland, 11\n  pages, 4 figures, 1 table. arXiv admin note: substantial text overlap with\n  arXiv:1902.03100", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents performance results comparing MPI-based implementations\nof the popular Conjugate Gradient (CG) method and several of its communication\nhiding (or 'pipelined') variants. Pipelined CG methods are designed to\nefficiently solve SPD linear systems on massively parallel distributed memory\nhardware, and typically display significantly improved strong scaling compared\nto classic CG. This increase in parallel performance is achieved by overlapping\nthe global reduction phase (MPI_Iallreduce) required to compute the inner\nproducts in each iteration by (chiefly local) computational work such as the\nmatrix-vector product as well as other global communication. This work includes\na brief introduction to the deep pipelined CG method for readers that may be\nunfamiliar with the specifics of the method. A brief overview of implementation\ndetails provides the practical tools required for implementation of the\nalgorithm. Subsequently, easily reproducible strong scaling results on the US\nDepartment of Energy (DoE) NERSC machine 'Cori' (Phase I - Haswell nodes) on up\nto 1024 nodes with 16 MPI ranks per node are presented using an implementation\nof p(l)-CG that is available in the open source PETSc library. Observations on\nthe staggering and overlap of the asynchronous, non-blocking global\ncommunication phases with communication and computational kernels are drawn\nfrom the experiments.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 15:44:36 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Cools", "Siegfried", ""], ["Cornelis", "Jeffrey", ""], ["Ghysels", "Pieter", ""], ["Vanroose", "Wim", ""]]}, {"id": "1905.06911", "submitter": "Derek Weitzel", "authors": "Derek Weitzel, Marian Zvada, Ilija Vukotic, Rob Gardner, Brian\n  Bockelman, Mats Rynge, Edgar Fajardo Hernandez, Brian Lin, and Matyas Selmeci", "title": "StashCache: A Distributed Caching Federation for the Open Science Grid", "comments": "In Practice and Experience in Advanced Research Computing (PEARC 19),\n  July 28-August 1, 2019, Chicago, IL, USA. ACM, New York, NY, USA, 7 pages", "journal-ref": null, "doi": "10.1145/3332186.3332212", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data distribution for opportunistic users is challenging as they neither own\nthe computing resources they are using or any nearby storage. Users are\nmotivated to use opportunistic computing to expand their data processing\ncapacity, but they require storage and fast networking to distribute data to\nthat processing. Since it requires significant management overhead, it is rare\nfor resource providers to allow opportunistic access to storage. Additionally,\nin order to use opportunistic storage at several distributed sites, users\nassume the responsibility to maintain their data. In this paper we present\nStashCache, a distributed caching federation that enables opportunistic users\nto utilize nearby opportunistic storage. StashCache is comprised of four\ncomponents: data origins, redirectors, caches, and clients. StashCache has been\ndeployed in the Open Science Grid for several years and has been used by many\nprojects. Caches are deployed in geographically distributed locations across\nthe U.S. and Europe. We will present the architecture of StashCache, as well as\nutilization information of the infrastructure. We will also present performance\nanalysis comparing distributed HTTP Proxies vs StashCache.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 17:14:44 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Weitzel", "Derek", ""], ["Zvada", "Marian", ""], ["Vukotic", "Ilija", ""], ["Gardner", "Rob", ""], ["Bockelman", "Brian", ""], ["Rynge", "Mats", ""], ["Hernandez", "Edgar Fajardo", ""], ["Lin", "Brian", ""], ["Selmeci", "Matyas", ""]]}, {"id": "1905.06975", "submitter": "\\'Italo Assis", "authors": "\\'Italo A. S. Assis, Jo\\~ao B. Fernandes, Tiago Barros, Samuel\n  Xavier-de-Souza", "title": "Auto-tuning of dynamic scheduling applied to 3D reverse time migration\n  on multicore systems", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2020.3015045", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reverse time migration (RTM) is an algorithm widely used in the oil and gas\nindustry to process seismic data. It is a computationally intensive task that\nsuits well in parallel computers. Methods such as RTM can be parallelized in\nshared memory systems through scheduling iterations of parallel loops to\nthreads. However, several aspects, such as memory size and hierarchy, number of\ncores, and input size, make optimal scheduling very challenging. In this paper,\nwe introduce a run-time strategy to automatically tune the dynamic scheduling\nof parallel loops iterations in iterative applications, such as the RTM, in\nmulticore systems. The proposed method aims to reduce the execution time of\nsuch applications. To find the optimal granularity, we propose a coupled\nsimulated annealing (CSA) based auto-tuning strategy that adjusts the chunk\nsize of work that OpenMP parallel loops assign dynamically to worker threads\nduring the initialization of a 3D RTM application. Experiments performed with\ndifferent computational systems and input sizes show that the proposed method\nis consistently better than the default OpenMP schedulers, static, auto, and\nguided, causing the application to be up to 33% faster. We show that the\npossible reason for this performance is the reduction of cache misses, mainly\nlevel L3, and low overhead, inferior to 2%. Having shown to be robust and\nscalable for the 3D RTM, the proposed method could also improve the performance\nof similar wave-based algorithms, such as full-waveform inversion (FWI) and\nother iterative applications.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 18:04:05 GMT"}, {"version": "v2", "created": "Sun, 5 Jul 2020 20:23:45 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Assis", "\u00cdtalo A. S.", ""], ["Fernandes", "Jo\u00e3o B.", ""], ["Barros", "Tiago", ""], ["Xavier-de-Souza", "Samuel", ""]]}, {"id": "1905.07063", "submitter": "Jaros{\\l}aw Mirek", "authors": "Dariusz R. Kowalski, Jaroslaw Mirek", "title": "On the complexity of fault-tolerant consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper studies the problem of reaching agreement in a distributed\nmessage-passing system prone to crash failures. Crashes are generated by\n\\constrained\\ adversaries - a \\wadapt\\ adversary, who has to fix in advance the\nset of $f$ crash-prone processes, or a \\chainadapt\\ adversary, who orders all\nthe processes into $k$ disjoint chains and has to follow this pattern when\ncrashing them. Apart from these constraints, both of them may crash processes\nin an adaptive way at any time. While commonly used \\sadapt\\ adversaries model\nattacks and \\noadapt\\ ones -- pre-defined faults, the constrained adversaries\nmodel more realistic scenarios when there are fault-prone dependent processes,\ne.g., in hierarchical or dependable software/hardware systems. We propose\ntime-efficient consensus algorithms against such adversaries and also show how\nto improve the message complexity of proposed solutions. Finally, we show how\nto reach consensus against a \\kthick\\ adversary, limited by an arbitrary\npartial order \\dk{with a maximal anti-chain of length $k$}. We complement our\nalgorithmic results with (almost) tight lower bounds, and extend the one for\n\\wadapt\\ adversaries to hold also for (syntactically) weaker \\noadapt\\\nadversaries. Together with the consensus algorithm against \\wadapt\\ adversaries\n(which automatically translates to \\noadapt\\ adversaries), these results extend\nthe state-of-the-art of the popular class of \\noadapt\\ adversaries, in\nparticular the result of Chor, Meritt and Shmoys~\\cite{CMS}, and prove general\nseparation between \\sadapt\\ and the constrained adversaries (including\n\\noadapt) analyzed by Bar-Joseph and Ben-Or~\\cite{BB} and others.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 23:36:13 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Kowalski", "Dariusz R.", ""], ["Mirek", "Jaroslaw", ""]]}, {"id": "1905.07169", "submitter": "Shuaifeng Pang", "authors": "Shuaifeng Pang, Xiaodong Qi, Zhao Zhang, Cheqing Jin, Aoying Zhou", "title": "Concurrency Protocol Aiming at High Performance of Execution and Replay\n  for Smart Contracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the emergence of the programmable smart contract makes blockchain\nsystems easily embrace a wider range of industrial areas, how to execute smart\ncontracts efficiently becomes a big challenge nowadays. Due to the existence of\nByzantine nodes, the mechanism of executing smart contracts is quite different\nfrom that in database systems, so that existing successful concurrency control\nprotocols in database systems cannot be employed directly. Moreover, even\nthough smart contract execution follows a two-phase style, i.e, the miner node\nexecutes a batch of smart contracts in the first phase and the validators\nreplay them in the second phase, existing parallel solutions only focus on the\noptimization in the first phase, but not including the second phase.\n  In this paper, we propose a novel efficient concurrency control scheme which\nis the first one to do optimization in both phases. Specifically, (i) in the\nfirst phase, we give a variant of OCC (Optimistic Concurrency Control) protocol\nbased on {\\em batching} feature to improve the concurrent execution efficiency\nfor the miner and produce a schedule log with high parallelism for validators.\nAlso, a graph partition algorithm is devised to divide the original schedule\nlog into small pieces and further reduce the communication cost; and (ii) in\nthe second phase, we give a deterministic OCC protocol to replay all smart\ncontracts efficiently on multi-core validators where all cores can replay smart\ncontracts independently. Theoretical analysis and extensive experimental\nresults illustrate that the proposed scheme outperforms state-of-art solutions\nsignificantly.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 08:58:57 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Pang", "Shuaifeng", ""], ["Qi", "Xiaodong", ""], ["Zhang", "Zhao", ""], ["Jin", "Cheqing", ""], ["Zhou", "Aoying", ""]]}, {"id": "1905.07210", "submitter": "Naoya Yoshida", "authors": "Naoya Yoshida, Takayuki Nishio, Masahiro Morikura, Koji Yamamoto, and\n  Ryo Yonetani", "title": "Hybrid-FL for Wireless Networks: Cooperative Learning Mechanism Using\n  Non-IID Data", "comments": null, "journal-ref": "Proc. IEEE ICC 2019, Dublin, Ireland, June 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a cooperative mechanism for mitigating the performance\ndegradation due to non-independent-and-identically-distributed (non-IID) data\nin collaborative machine learning (ML), namely federated learning (FL), which\ntrains an ML model using the rich data and computational resources of mobile\nclients without gathering their data to central systems. The data of mobile\nclients is typically non-IID owing to diversity among mobile clients' interests\nand usage, and FL with non-IID data could degrade the model performance.\nTherefore, to mitigate the degradation induced by non-IID data, we assume that\na limited number (e.g., less than 1%) of clients allow their data to be\nuploaded to a server, and we propose a hybrid learning mechanism referred to as\nHybrid-FL, wherein the server updates the model using the data gathered from\nthe clients and aggregates the model with the models trained by clients. The\nHybrid-FL solves both client- and data-selection problems via heuristic\nalgorithms, which try to select the optimal sets of clients who train models\nwith their own data, clients who upload their data to the server, and data\nuploaded to the server. The algorithms increase the number of clients\nparticipating in FL and make more data gather in the server IID, thereby\nimproving the prediction accuracy of the aggregated model. Evaluations, which\nconsist of network simulations and ML experiments, demonstrate that the\nproposed scheme achieves a 13.5% higher classification accuracy than those of\nthe previously proposed schemes for the non-IID case.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 11:34:23 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 09:45:15 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2020 07:17:13 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Yoshida", "Naoya", ""], ["Nishio", "Takayuki", ""], ["Morikura", "Masahiro", ""], ["Yamamoto", "Koji", ""], ["Yonetani", "Ryo", ""]]}, {"id": "1905.07224", "submitter": "Rayan Chikhi", "authors": "Ma\\\"el Kerbiriou and Rayan Chikhi", "title": "Parallel decompression of gzip-compressed files and random access to DNA\n  sequences", "comments": "HiCOMB'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decompressing a file made by the gzip program at an arbitrary location is in\nprinciple impossible, due to the nature of the DEFLATE compression algorithm.\nConsequently, no existing program can take advantage of parallelism to rapidly\ndecompress large gzip-compressed files. This is an unsatisfactory bottleneck,\nespecially for the analysis of large sequencing data experiments. Here we\npropose a parallel algorithm and an implementation, pugz, that performs fast\nand exact decompression of any text file. We show that pugz is an order of\nmagnitude faster than gunzip, and 5x faster than a highly-optimized sequential\nimplementation (libdeflate). We also study the related problem of random access\nto compressed data. We give simple models and experimental results that shed\nlight on the structure of gzip-compressed files containing DNA sequences.\nPreliminary results show that random access to sequences within a\ngzip-compressed FASTQ file is almost always feasible at low compression levels,\nyet is approximate at higher compression levels.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 12:24:17 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Kerbiriou", "Ma\u00ebl", ""], ["Chikhi", "Rayan", ""]]}, {"id": "1905.07511", "submitter": "Kyle Kuan", "authors": "Kyle Kuan and Tosiron Adegbija", "title": "HALLS: An Energy-Efficient Highly Adaptable Last Level STT-RAM Cache for\n  Multicore Systems", "comments": "To Appear on IEEE Transactions on Computers (TC)", "journal-ref": null, "doi": "10.1109/TC.2019.2918153", "report-no": null, "categories": "cs.AR cs.DC cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spin-Transfer Torque RAM (STT-RAM) is widely considered a promising\nalternative to SRAM in the memory hierarchy due to STT-RAM's non-volatility,\nlow leakage power, high density, and fast read speed. The STT-RAM's small\nfeature size is particularly desirable for the last-level cache (LLC), which\ntypically consumes a large area of silicon die. However, long write latency and\nhigh write energy still remain challenges of implementing STT-RAMs in the CPU\ncache. An increasingly popular method for addressing this challenge involves\ntrading off the non-volatility for reduced write speed and write energy by\nrelaxing the STT-RAM's data retention time. However, in order to maximize\nenergy saving potential, the cache configurations, including STT-RAM's\nretention time, must be dynamically adapted to executing applications' variable\nmemory needs. In this paper, we propose a highly adaptable last level STT-RAM\ncache (HALLS) that allows the LLC configurations and retention time to be\nadapted to applications' runtime execution requirements. We also propose\nlow-overhead runtime tuning algorithms to dynamically determine the best\n(lowest energy) cache configurations and retention times for executing\napplications. Compared to prior work, HALLS reduced the average energy\nconsumption by 60.57% in a quad-core system, while introducing marginal latency\noverhead.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 00:42:54 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Kuan", "Kyle", ""], ["Adegbija", "Tosiron", ""]]}, {"id": "1905.07533", "submitter": "Soheil Behnezhad", "authors": "Soheil Behnezhad and Laxman Dhulipala and Hossein Esfandiari and Jakub\n  {\\L}\\k{a}cki and Warren Schudy and Vahab Mirrokni", "title": "Massively Parallel Computation via Remote Memory Access", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Adaptive Massively Parallel Computation (AMPC) model, which\nis an extension of the Massively Parallel Computation (MPC) model. At a high\nlevel, the AMPC model strengthens the MPC model by storing all messages sent\nwithin a round in a distributed data store. In the following round, all\nmachines are provided with random read access to the data store, subject to the\nsame constraints on the total amount of communication as in the MPC model. Our\nmodel is inspired by the previous empirical studies of distributed graph\nalgorithms using MapReduce and a distributed hash table service.\n  This extension allows us to give new graph algorithms with much lower round\ncomplexities compared to the best known solutions in the MPC model. In\nparticular, in the AMPC model we show how to solve maximal independent set in\n$O(1)$ rounds and connectivity/minimum spanning tree in $O(\\log\\log_{m/n} n)$\nrounds both using $O(n^\\delta)$ space per machine for constant $\\delta < 1$. In\nthe same memory regime for MPC, the best known algorithms for these problems\nrequire polylog $n$ rounds. Our results imply that the 2-Cycle conjecture,\nwhich is widely believed to hold in the MPC model, does not hold in the AMPC\nmodel.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 04:06:43 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Behnezhad", "Soheil", ""], ["Dhulipala", "Laxman", ""], ["Esfandiari", "Hossein", ""], ["\u0141\u0105cki", "Jakub", ""], ["Schudy", "Warren", ""], ["Mirrokni", "Vahab", ""]]}, {"id": "1905.07598", "submitter": "Yufan Huang", "authors": "Richeng Jin, Yufan Huang, and Huaiyu Dai", "title": "On the Privacy Guarantees of Gossip Protocols in General Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the privacy guarantees of information dissemination protocols have\nattracted increasing research interests, among which the gossip protocols\nassume vital importance in various information exchange applications. In this\nwork, we study the privacy guarantees of gossip protocols in general networks\nin terms of differential privacy and prediction uncertainty. First, lower\nbounds of the differential privacy guarantees are derived for gossip protocols\nin general networks in both synchronous and asynchronous settings. The\nprediction uncertainty of the source node given a uniform prior is also\ndetermined. For the private gossip algorithm, the differential privacy and\nprediction uncertainty guarantees are derived in closed form. Moreover,\nconsidering that these two metrics may be restrictive in some scenarios, the\nrelaxed variants are proposed. It is found that source anonymity is closely\nrelated to some key network structure parameters in the general network\nsetting. Then, we investigate information spreading in wireless networks with\nunreliable communications, and quantify the tradeoff between differential\nprivacy guarantees and information spreading efficiency. Finally, considering\nthat the attacker may not be present at the beginning of the information\ndissemination process, the scenario of delayed monitoring is studied and the\ncorresponding differential privacy guarantees are evaluated.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 14:47:10 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 05:45:06 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Jin", "Richeng", ""], ["Huang", "Yufan", ""], ["Dai", "Huaiyu", ""]]}, {"id": "1905.07607", "submitter": "Ali Kashif Bashir", "authors": "Rajakumar Arul, Gunasekaran Raja, Ali Kashif Bashir, Junaid Chaudry,\n  and Amjad Ali", "title": "A Console GRID LA Console GRID Leveraged Authentication and Key\n  Agreement Mechanism for LTE/SAE", "comments": "12 pages, 11 figures,", "journal-ref": "IEEE Transactions on Industrial Informatics, 2017", "doi": "10.1109/TII.2018.2817028", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing popularity of multimedia applications, pervasive connectivity,\nhigher bandwidth, and euphoric technology penetration among the bulk of the\nhuman race that happens to be cellular technology users, has fueled the\nadaptation to Long Term Evolution (LTE)/ System Architecture Evolution (SAE).\nThe LTE fulfills the resource demands of the next generation applications for\nnow. We identify security issues in the authentication mechanism used in LTE\nthat without countermeasures might give superuser rights to unauthorized users.\nThe LTE uses static LTE Key (LTE-K) to derive the entire key hierarchy such as\nLTE follows Evolved Packet System-Authentication and Key Agreement (EPS-AKA)\nbased authentication which discloses user identity, location, and other\nPersonally Identifiable Information (PII). To counter this, we propose a public\nkey cryptosystem named International mobile subscriber identity Protected\nConsole Grid-based Authentication and Key Agreement (IPG-AKA) protocol to\naddress the vulnerabilities related to weak key management. From the data\nobtained from threat modeling and simulation results, we claim that the IPG-AKA\nscheme not only improves the security of authentication procedures, it also\nshows improvements in authentication loads and reduction in key generation\ntime. The empirical results and qualitative analysis presented in this paper\nproves that IPG-AKA improves security in authentication procedure and\nperformance in the LTE.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 15:58:25 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Arul", "Rajakumar", ""], ["Raja", "Gunasekaran", ""], ["Bashir", "Ali Kashif", ""], ["Chaudry", "Junaid", ""], ["Ali", "Amjad", ""]]}, {"id": "1905.07699", "submitter": "Sikder Huq", "authors": "Sikder Huq and Sukumar Ghosh", "title": "Locally Self-Adjusting Hypercubic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a prior work (ICDCS 2017), we presented a distributed self-adjusting\nalgorithm DSG for skip graphs. DSG performs topological adaption to\ncommunication pattern to minimize the average routing costs between\ncommunicating nodes. In this work, we present a distributed self-adjusting\nalgorithm (referred to as DyHypes) for topological adaption in hypercubic\nnetworks. One of the major differences between hypercubes and skip graphs is\nthat hypercubes are more rigid in structure compared skip graphs. This property\nmakes self-adjustment significantly different in hypercubic networks than skip\ngraphs. Upon a communication between an arbitrary pair of nodes, DyHypes\ntransforms the network to place frequently communicating nodes closer to each\nother to maximize communication efficiency, and uses randomization in the\ntransformation process to speed up the transformation and reduce message\ncomplexity. We show that, as compared to DSG, DyHypes reduces the\ntransformation cost by a factor of $O(\\log n)$, where $n$ is the number of\nnodes involved in the transformation. Moreover, despite achieving faster\ntransformation with lower message complexity, the combined cost (routing and\ntransformation) of DyHypes is at most a $\\log \\log n$ factor more than that of\nany algorithm that conforms to the computational model adopted for this work.\nSimilar to DSG, DyHypes is fully decentralized, conforms to the\n$\\mathcal{CONGEST}$ model, and requires $O(\\log n)$ bits of memory for each\nnode, where $n$ is the total number of nodes.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 07:34:35 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Huq", "Sikder", ""], ["Ghosh", "Sukumar", ""]]}, {"id": "1905.07780", "submitter": "Lijie Chen", "authors": "Lijie Chen, Ofer Grossman", "title": "Broadcast Congested Clique: Planted Cliques and Pseudorandom Generators", "comments": "abstract shortened to meet the constraint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop techniques to prove lower bounds for the BCAST(log n) Broadcast\nCongested Clique model (a distributed message passing model where in each\nround, each processor can broadcast an O(log n)-sized message to all other\nprocessors). Our techniques are built to prove bounds for natural input\ndistributions. So far, all lower bounds for problems in the model relied on\nconstructing specifically tailored graph families for the specific problem at\nhand, resulting in lower bounds for artificially constructed inputs, instead of\nnatural input distributions.\n  One of our results is a lower bound for the directed planted clique problem.\nIn this problem, an input graph is either a random directed graph (each\ndirected edge is included with probability 1/2), or a random graph with a\nplanted clique of size k. That is, k randomly chosen vertices have all of the\nedges between them included, and all other edges in the graph appear with\nprobability 1/2. The goal is to determine whether a clique exists. We show that\nwhen k = n^(1/4 - eps), this problem requires a number of rounds polynomial in\nn.\n  Additionally, we construct a pseudo-random generator which fools the\nBroadcast Congested Clique. This allows us to show that every k round\nrandomized algorithm in which each processor uses up to n random bits can be\nefficiently transformed into an O(k)-round randomized algorithm in which each\nprocessor uses only up to O(k log n) random bits, while maintaining a high\nsuccess probability. The pseudo-random generator is simple to describe,\ncomputationally very cheap, and its seed size is optimal up to constant\nfactors. However, the analysis is quite involved, and is based on the new\ntechnique for proving lower bounds in the model.\n  The technique also allows us to prove the first average case lower bound for\nthe Broadcast Congested Clique, as well as an average-case time hierarchy.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 17:32:04 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Chen", "Lijie", ""], ["Grossman", "Ofer", ""]]}, {"id": "1905.07805", "submitter": "Idan Berkovits", "authors": "Idan Berkovits, Marijana Lazic, Giuliano Losa, Oded Padon, Sharon\n  Shoham", "title": "Verification of Threshold-Based Distributed Algorithms by Decomposition\n  to Decidable Logics", "comments": "23 pages, extended version of the paper with the same title presented\n  in CAV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verification of fault-tolerant distributed protocols is an immensely\ndifficult task. Often, in these protocols, thresholds on set cardinalities are\nused both in the process code and in its correctness proof, e.g., a process can\nperform an action only if it has received an acknowledgment from at least half\nof its peers. Verification of threshold-based protocols is extremely\nchallenging as it involves two kinds of reasoning: first-order reasoning about\nthe unbounded state of the protocol, together with reasoning about sets and\ncardinalities. In this work, we develop a new methodology for decomposing the\nverification task of such protocols into two decidable logics: EPR and BAPA.\nOur key insight is that such protocols use thresholds in a restricted way as a\nmeans to obtain certain properties of \"intersection\" between sets. We define a\nlanguage for expressing such properties, and present two translations: to EPR\nand BAPA. The EPR translation allows verifying the protocol while assuming\nthese properties, and the BAPA translation allows verifying the correctness of\nthe properties. We further develop an algorithm for automatically generating\nthe properties needed for verifying a given protocol, facilitating fully\nautomated deductive verification. Using this technique we have verified several\nchallenging protocols, including Byzantine one-step consensus, hybrid reliable\nbroadcast and fast Byzantine Paxos.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 20:40:05 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Berkovits", "Idan", ""], ["Lazic", "Marijana", ""], ["Losa", "Giuliano", ""], ["Padon", "Oded", ""], ["Shoham", "Sharon", ""]]}, {"id": "1905.07903", "submitter": "Ruslan Nikolaev", "authors": "Ruslan Nikolaev and Binoy Ravindran", "title": "Snapshot-Free, Transparent, and Robust Memory Reclamation for Lock-Free\n  Data Structures", "comments": "An extended version of the PLDI'21 paper (with Appendix)", "journal-ref": "42nd ACM SIGPLAN International Conference on Programming Language\n  Design and Implementation (PLDI 2021)", "doi": "10.1145/3453483.3454090", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a family of safe memory reclamation schemes, Hyaline, which are\nfast, scalable, and transparent to the underlying lock-free data structures.\nHyaline is based on reference counting - considered impractical for memory\nreclamation in the past due to high overheads. Hyaline uses reference counters\nonly during reclamation, but not while accessing individual objects, which\nreduces overheads for object accesses. Since with reference counters, an\narbitrary thread ends up freeing memory, Hyaline's reclamation workload is\n(almost) balanced across all threads, unlike most prior reclamation schemes\nsuch as epoch-based reclamation (EBR) or hazard pointers (HP). Hyaline often\nyields (excellent) EBR-grade performance with (good) HP-grade memory\nefficiency, which is a challenging tradeoff with all existing schemes.\n  Hyaline schemes offer: (i) high performance; (ii) good memory efficiency;\n(iii) robustness: bounding memory usage even in the presence of stalled\nthreads, a well-known problem with EBR; (iv) transparency: supporting virtually\nunbounded number of threads (or concurrent entities) that can be created and\ndeleted dynamically, and effortlessly join existent workload; (v) autonomy:\navoiding special OS mechanisms and being non-intrusive to runtime or compiler\nenvironments; (vi) simplicity: enabling easy integration into unmanaged C/C++\ncode; and (vii) generality: supporting many data structures. All existing\nschemes lack one or more properties.\n  We have implemented and tested Hyaline on x86(-64), ARM32/64, PowerPC, and\nMIPS. The general approach requires LL/SC or double-width CAS, while a\nspecialized version also works with single-width CAS. Our evaluation reveals\nthat Hyaline's throughput is very high - it steadily outperforms EBR by 10% in\none test and yields 2x gains in oversubscribed scenarios. Hyaline's superior\nmemory efficiency is especially evident in read-dominated workloads\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 06:34:15 GMT"}, {"version": "v2", "created": "Sat, 1 May 2021 13:38:45 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Nikolaev", "Ruslan", ""], ["Ravindran", "Binoy", ""]]}, {"id": "1905.07940", "submitter": "Alain Brenzikofer", "authors": "Alain Brenzikofer, Noa Melchior", "title": "Privacy-Preserving P2P Energy Market on the Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Quartierstrom creates a peer-to-peer marketplace for locally generated solar\npower. The marketplace is implemented as a smart contract on a permissioned\nblockchain governed by all prosumers. Two privacy-by-design concepts are\npresented which guarantee that the users individual load profile is not leaked\nto any third party despite using a blockchain. The first approach leverages\nUTXO based coin mixing protocols in combination with an account-based on-chain\nsmart contract. The second approach relies on an off-chain smart contract\nrunning in trusted execution environments.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 08:26:00 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Brenzikofer", "Alain", ""], ["Melchior", "Noa", ""]]}, {"id": "1905.07996", "submitter": "Sulaiman Alghunaim Mr.", "authors": "Sulaiman A. Alghunaim, Kun Yuan, Ali H. Sayed", "title": "A Linearly Convergent Proximal Gradient Algorithm for Decentralized\n  Optimization", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized optimization is a powerful paradigm that finds applications in\nengineering and learning design. This work studies decentralized composite\noptimization problems with non-smooth regularization terms. Most existing\ngradient-based proximal decentralized methods are known to converge to the\noptimal solution with sublinear rates, and it remains unclear whether this\nfamily of methods can achieve global linear convergence. To tackle this\nproblem, this work assumes the non-smooth regularization term is common across\nall networked agents, which is the case for many machine learning problems.\nUnder this condition, we design a proximal gradient decentralized algorithm\nwhose fixed point coincides with the desired minimizer. We then provide a\nconcise proof that establishes its linear convergence. In the absence of the\nnon-smooth term, our analysis technique covers the well known EXTRA algorithm\nand provides useful bounds on the convergence rate and step-size.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 11:12:08 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 19:49:13 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Alghunaim", "Sulaiman A.", ""], ["Yuan", "Kun", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1905.08051", "submitter": "Diptanshu Kakwani", "authors": "Diptanshu Kakwani and Yogesh Simmhan", "title": "Distributed Algorithms for Subgraph-Centric Graph Platforms", "comments": null, "journal-ref": "HiPC 2016 SRS", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph analytics for large scale graphs has gained interest in recent years.\nMany graph algorithms have been designed for vertex-centric distributed graph\nprocessing frameworks to operate on large graphs with 100 M vertices and edges,\nusing commodity clusters and Clouds. Subgraph-centric programming models have\nshown additional performance benefits than vertex-centric models. But direct\nmapping of vertex-centric and shared-memory algorithms to subgraph-centric\nframeworks are either not possible, or lead to inefficient algorithms. In this\npaper, we present three subgraph-centric distributed graph algorithms for\ntriangle counting, clustering and minimum spanning forest, using variations of\nshared and vertex-centric models. These augment existing subgraph-centric\nalgorithms that exist in literature, and allow a broader evaluation of these\nthree classes of graph processing algorithms and platforms.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 12:44:48 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Kakwani", "Diptanshu", ""], ["Simmhan", "Yogesh", ""]]}, {"id": "1905.08073", "submitter": "Ali Mohammed", "authors": "Ali Mohammed, Aurelien Cavelan, and Florina M. Ciorba", "title": "rDLB: A Novel Approach for Robust Dynamic Load Balancing of Scientific\n  Applications with Parallel Independent Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific applications often contain large and computationally intensive\nparallel loops. Dynamic loop self scheduling (DLS) is used to achieve a\nbalanced load execution of such applications on high performance computing\n(HPC) systems. Large HPC systems are vulnerable to processors or node failures\nand perturbations in the availability of resources. Most self-scheduling\napproaches do not consider fault-tolerant scheduling or depend on failure or\nperturbation detection and react by rescheduling failed tasks. In this work, a\nrobust dynamic load balancing (rDLB) approach is proposed for the robust self\nscheduling of independent tasks. The proposed approach is proactive and does\nnot depend on failure or perturbation detection. The theoretical analysis of\nthe proposed approach shows that it is linearly scalable and its cost decrease\nquadratically by increasing the system size. rDLB is integrated into an MPI DLS\nlibrary to evaluate its performance experimentally with two computationally\nintensive scientific applications. Results show that rDLB enables the tolerance\nof up to (P minus one) processor failures, where P is the number of processors\nexecuting an application. In the presence of perturbations, rDLB boosted the\nrobustness of DLS techniques up to 30 times and decreased application execution\ntime up to 7 times compared to their counterparts without rDLB.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 13:01:09 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 10:37:12 GMT"}, {"version": "v3", "created": "Fri, 4 Oct 2019 15:30:44 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Mohammed", "Ali", ""], ["Cavelan", "Aurelien", ""], ["Ciorba", "Florina M.", ""]]}, {"id": "1905.08204", "submitter": "Duncan Brown", "authors": "Karan Vahi, Mats Rynge, George Papadimitriou, Duncan A. Brown, Rajiv\n  Mayani, Rafael Ferreira da Silva, Ewa Deelman, Anirban Mandal, Eric Lyons,\n  Michael Zink", "title": "Custom Execution Environments with Containers in Pegasus-enabled\n  Scientific Workflows", "comments": "10 pages, 7 figures, submitted to eScience 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Science reproducibility is a cornerstone feature in scientific workflows. In\nmost cases, this has been implemented as a way to exactly reproduce the\ncomputational steps taken to reach the final results. While these steps are\noften completely described, including the input parameters, datasets, and\ncodes, the environment in which these steps are executed is only described at a\nhigher level with endpoints and operating system name and versions. Though this\nmay be sufficient for reproducibility in the short term, systems evolve and are\nreplaced over time, breaking the underlying workflow reproducibility. A natural\nsolution to this problem is containers, as they are well defined, have a\nlifetime independent of the underlying system, and can be user-controlled so\nthat they can provide custom environments if needed. This paper highlights some\nunique challenges that may arise when using containers in distributed\nscientific workflows. Further, this paper explores how the Pegasus Workflow\nManagement System implements container support to address such challenges.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 16:41:20 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Vahi", "Karan", ""], ["Rynge", "Mats", ""], ["Papadimitriou", "George", ""], ["Brown", "Duncan A.", ""], ["Mayani", "Rajiv", ""], ["da Silva", "Rafael Ferreira", ""], ["Deelman", "Ewa", ""], ["Mandal", "Anirban", ""], ["Lyons", "Eric", ""], ["Zink", "Michael", ""]]}, {"id": "1905.08217", "submitter": "Iosif Meyerov", "authors": "Iosif Meyerov, Sergei Bastrakov, Aleksei Bashinov, Evgeny Efimenko,\n  Alexander Panov, Elena Panova, Igor Surmin, Valentin Volokitin, and Arkady\n  Gonoskov", "title": "Exploiting Parallelism on Shared Memory in the QED Particle-in-Cell Code\n  PICADOR with Greedy Load Balancing", "comments": "11 pages, 5 figures. Submitted to PPAM-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art numerical simulations of laser plasma by means of the\nParticle-in-Cell method are often extremely computationally intensive.\nTherefore there is a growing need for development of approaches for efficient\nutilization of resources of modern supercomputers. In this paper, we address\nthe problem of a substantially non-uniform and dynamically varying distribution\nof macroparticles in a computational area in simulating quantum electrodynamic\n(QED) cascades. We propose and evaluate a load balancing scheme for shared\nmemory systems, which allows subdividing individual cells of the computational\ndomain into work portions with subsequent dynamic distribution of these\nportions between OpenMP threads. Computational experiments on 1D, 2D, and 3D\nQED simulations show that the proposed scheme outperforms the previously\ndeveloped standard and custom schemes in the PICADOR code by 2.1 to 10 times\nwhen employing several Intel Cascade Lake CPUs.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 17:08:25 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Meyerov", "Iosif", ""], ["Bastrakov", "Sergei", ""], ["Bashinov", "Aleksei", ""], ["Efimenko", "Evgeny", ""], ["Panov", "Alexander", ""], ["Panova", "Elena", ""], ["Surmin", "Igor", ""], ["Volokitin", "Valentin", ""], ["Gonoskov", "Arkady", ""]]}, {"id": "1905.08386", "submitter": "Angel Beltre", "authors": "Pankaj Saha, Angel Beltre, Madhusudhan Govindaraju", "title": "Scylla: A Mesos Framework for Container Based MPI Jobs", "comments": null, "journal-ref": "MTAGS 2017: 10th Workshop on Many-Task Computing on Clouds, Grids,\n  and Supercomputers", "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open source cloud technologies provide a wide range of support for creating\ncustomized compute node clusters to schedule tasks and managing resources. In\ncloud infrastructures such as Jetstream and Chameleon, which are used for\nscientific research, users receive complete control of the Virtual Machines\n(VM) that are allocated to them. Importantly, users get root access to the VMs.\nThis provides an opportunity for HPC users to experiment with new resource\nmanagement technologies such as Apache Mesos that have proven scalability,\nflexibility, and fault tolerance. To ease the development and deployment of HPC\ntools on the cloud, the containerization technology has matured and is gaining\ninterest in the scientific community. In particular, several well known\nscientific code bases now have publicly available Docker containers. While\nMesos provides support for Docker containers to execute individually, it does\nnot provide support for container inter-communication or orchestration of the\ncontainers for a parallel or distributed application. In this paper, we present\nthe design, implementation, and performance analysis of a Mesos framework,\nScylla, which integrates Mesos with Docker Swarm to enable orchestration of MPI\njobs on a cluster of VMs acquired from the Chameleon cloud [1]. Scylla uses\nDocker Swarm for communication between containerized tasks (MPI processes) and\nApache Mesos for resource pooling and allocation. Scylla allows a policy-driven\napproach to determine how the containers should be distributed across the nodes\ndepending on the CPU, memory, and network throughput requirement for each\napplication.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 23:59:52 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Saha", "Pankaj", ""], ["Beltre", "Angel", ""], ["Govindaraju", "Madhusudhan", ""]]}, {"id": "1905.08387", "submitter": "Angel Beltre", "authors": "Pankaj Saha, Angel Beltre, Madhusudhan Govindaraju", "title": "Tromino: Demand and DRF Aware Multi-Tenant Queue Manager for Apache\n  Mesos Cluster", "comments": null, "journal-ref": "2018 IEEE/ACM 11th International Conference on Utility and Cloud\n  Computing (UCC) 63-72", "doi": "10.1109/UCC.2018.00015", "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Apache Mesos, a two-level resource scheduler, provides resource sharing\nacross multiple users in a multi-tenant cluster environment. Computational\nresources (i.e., CPU, memory, disk, etc. ) are distributed according to the\nDominant Resource Fairness (DRF) policy. Mesos frameworks (users) receive\nresources based on their current usage and are responsible for scheduling their\ntasks within the allocation. We have observed that multiple frameworks can\ncause fairness imbalance in a multiuser environment. For example, a greedy\nframework consuming more than its fair share of resources can deny resource\nfairness to others. The user with the least Dominant Share is considered first\nby the DRF module to get its resource allocation. However, the default DRF\nimplementation, in Apache Mesos' Master allocation module, does not consider\nthe overall resource demands of the tasks in the queue for each user/framework.\nThis lack of awareness can result in users without any pending task receiving\nmore resource offers while users with a queue of pending tasks starve due to\ntheir high dominant shares. We have developed a policy-driven queue manager,\nTromino, for an Apache Mesos cluster where tasks for individual frameworks can\nbe scheduled based on each framework's overall resource demands and current\nresource consumption. Dominant Share and demand awareness of Tromino and\nscheduling based on these attributes can reduce (1) the impact of unfairness\ndue to a framework specific configuration, and (2) unfair waiting time due to\nhigher resource demand in a pending task queue. In the best case, Tromino can\nsignificantly reduce the average waiting time of a framework by using the\nproposed Demand-DRF aware policy.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 00:00:04 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Saha", "Pankaj", ""], ["Beltre", "Angel", ""], ["Govindaraju", "Madhusudhan", ""]]}, {"id": "1905.08388", "submitter": "Angel Beltre", "authors": "Pankaj Saha, Angel Beltre, Madhusudhan Govindaraju", "title": "Exploring the Fairness and Resource Distribution in an Apache Mesos\n  Environment", "comments": null, "journal-ref": "2018 IEEE 11th International Conference on Cloud Computing (CLOUD)", "doi": "10.1109/CLOUD.2018.00061", "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Apache Mesos, a cluster-wide resource manager, is widely deployed in massive\nscale at several Clouds and Data Centers. Mesos aims to provide high cluster\nutilization via fine grained resource co-scheduling and resource fairness among\nmultiple users through Dominant Resource Fairness (DRF) based allocation. DRF\ntakes into account different resource types (CPU, Memory, Disk I/O) requested\nby each application and determines the share of each cluster resource that\ncould be allocated to the applications. Mesos has adopted a two-level\nscheduling policy: (1) DRF to allocate resources to competing frameworks and\n(2) task level scheduling by each framework for the resources allocated during\nthe previous step. We have conducted experiments in a local Mesos cluster when\nused with frameworks such as Apache Aurora, Marathon, and our own framework\nScylla, to study resource fairness and cluster utilization. Experimental\nresults show how informed decision regarding second level scheduling policy of\nframeworks and attributes like offer holding period, offer refusal cycle and\ntask arrival rate can reduce unfair resource distribution. Bin-Packing\nscheduling policy on Scylla with Marathon can reduce unfair allocation from\n38\\% to 3\\%. By reducing unused free resources in offers we bring down the\nunfairness from to 90\\% to 28\\%. We also show the effect of task arrival rate\nto reduce the unfairness from 23\\% to 7\\%.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 00:00:07 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Saha", "Pankaj", ""], ["Beltre", "Angel", ""], ["Govindaraju", "Madhusudhan", ""]]}, {"id": "1905.08415", "submitter": "Angel Beltre", "authors": "Pankaj Saha, Angel Beltre, Piotr Uminski, Madhusudhan Govindaraju", "title": "Evaluation of Docker Containers for Scientific Workloads in the Cloud", "comments": null, "journal-ref": "PEARC 2018 Proceedings of the Practice and Experience on Advanced\n  Research Computing", "doi": "10.1145/3219104.3229280", "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The HPC community is actively researching and evaluating tools to support\nexecution of scientific applications in cloud-based environments. Among the\nvarious technologies, containers have recently gained importance as they have\nsignificantly better performance compared to full-scale virtualization, support\nfor microservices and DevOps, and work seamlessly with workflow and\norchestration tools. Docker is currently the leader in containerization\ntechnology because it offers low overhead, flexibility, portability of\napplications, and reproducibility. Singularity is another container solution\nthat is of interest as it is designed specifically for scientific applications.\nIt is important to conduct performance and feature analysis of the container\ntechnologies to understand their applicability for each application and target\nexecution environment. This paper presents a (1) performance evaluation of\nDocker and Singularity on bare metal nodes in the Chameleon cloud (2) mechanism\nby which Docker containers can be mapped with InfiniBand hardware with RDMA\ncommunication and (3) analysis of mapping elements of parallel workloads to the\ncontainers for optimal resource management with container-ready orchestration\ntools. Our experiments are targeted toward application developers so that they\ncan make informed decisions on choosing the container technologies and\napproaches that are suitable for their HPC workloads on cloud infrastructure.\nOur performance analysis shows that scientific workloads for both Docker and\nSingularity based containers can achieve near-native performance. Singularity\nis designed specifically for HPC workloads. However, Docker still has\nadvantages over Singularity for use in clouds as it provides overlay networking\nand an intuitive way to run MPI applications with one container per rank for\nfine-grained resources allocation.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 03:03:37 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Saha", "Pankaj", ""], ["Beltre", "Angel", ""], ["Uminski", "Piotr", ""], ["Govindaraju", "Madhusudhan", ""]]}, {"id": "1905.08423", "submitter": "Fande Kong", "authors": "Fande Kong", "title": "Parallel memory-efficient all-at-once algorithms for the sparse matrix\n  triple products in multigrid methods", "comments": "14 pages, 10 figures. Submitted to The International Journal of High\n  Performance Computing Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilevel/multigrid methods is one of the most popular approaches for\nsolving a large sparse linear system of equations, typically, arising from the\ndiscretization of partial differential equations. One critical step in the\nmultilevel/multigrid methods is to form coarse matrices through a sequence of\nsparse matrix triple products. A commonly used approach for the triple products\nexplicitly involves two steps, and during each step a sparse matrix-matrix\nmultiplication is employed. This approach works well for many applications with\na good computational efficiency, but it has a high memory overhead since some\nauxiliary matrices need to be temporarily stored for accomplishing the\ncalculations. In this work, we propose two new algorithms that construct a\ncoarse matrix with taking one pass through the input matrices without involving\nany auxiliary matrices for saving memory. The new approaches are referred to as\n\"all-at-once\" and \"merged all-at-once\", and the traditional method is denoted\nas \"two-step\". The all-at-once and the merged all-at-once algorithms are\nimplemented based on hash tables in PETSc as part of this work with a careful\nconsideration on the performance in terms of the compute time and the memory\nusage. We numerically show that the proposed algorithms and their\nimplementations are perfectly scalable in both the compute time and the memory\nusage with up to 32,768 processor cores for a model problem with 27 billions of\nunknowns. The scalability is also demonstrated for a realistic neutron\ntransport problem with over 2 billion unknowns on a supercomputer with 10,000\nprocessor cores. Compared with the traditional two-step method, the all-at-once\nand the merged all-at-once algorithms consume much less memory for both the\nmodel problem and the realistic neutron transport problem meanwhile they are\nable to maintain the computational efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 03:20:38 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Kong", "Fande", ""]]}, {"id": "1905.08526", "submitter": "Yukiko Yamauchi", "authors": "Yukiko Yamauchi and Masafumi Yamashita", "title": "Coding theory for noiseless channels realized by anonymous oblivious\n  mobile robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an information transmission scheme by a swarm of anonymous\noblivious mobile robots on a graph. The swarm of robots travel from a sender\nvertex to a receiver vertex to transmit a symbol generated at the sender. The\ncodeword for a symbol is a pair of an initial configuration at the sender and a\nset of terminal configurations at the receiver. The set of such codewords forms\na code. We analyze the performance of the proposed scheme in terms of its code\nsize and transmission delay. We first demonstrate that a lower bound of the\ntransmission delay depends on the size of the swarm, and the code size is upper\nbounded by an exponent of the size of the swarm. We then give two algorithms\nfor a swarm of a fixed size. The first algorithm realizes a near optimal code\nsize with a large transmission delay. The second algorithm realizes an optimal\ntransmission delay with a smaller code size. We then consider information\ntransmission by swarms of different sizes and present upper bounds of the\nexpected swarm size by the two algorithms. We also present lower bounds by\nShannon's lemma and noiseless coding theorem.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 10:02:49 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Yamauchi", "Yukiko", ""], ["Yamashita", "Masafumi", ""]]}, {"id": "1905.08563", "submitter": "Laurent Feuilloley", "authors": "L\\'elia Blin, Laurent Feuilloley, Gabriel Le Bouder", "title": "Memory lower bounds for deterministic self-stabilization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of self-stabilization, a \\emph{silent} algorithm guarantees\nthat the register of every node does not change once the algorithm has\nstabilized. At the end of the 90's, Dolev et al. [Acta Inf. '99] showed that,\nfor finding the centers of a graph, for electing a leader, or for constructing\na spanning tree, every silent algorithm must use a memory of $\\Omega(\\log n)$\nbits per register in $n$-node networks. Similarly, Korman et al. [Dist. Comp.\n'07] proved, using the notion of proof-labeling-scheme, that, for constructing\na minimum-weight spanning trees (MST), every silent algorithm must use a memory\nof $\\Omega(\\log^2n)$ bits per register. It follows that requiring the algorithm\nto be silent has a cost in terms of memory space, while, in the context of\nself-stabilization, where every node constantly checks the states of its\nneighbors, the silence property can be of limited practical interest. In fact,\nit is known that relaxing this requirement results in algorithms with smaller\nspace-complexity.\n  In this paper, we are aiming at measuring how much gain in terms of memory\ncan be expected by using arbitrary self-stabilizing algorithms, not necessarily\nsilent. To our knowledge, the only known lower bound on the memory requirement\nfor general algorithms, also established at the end of the 90's, is due to\nBeauquier et al.~[PODC '99] who proved that registers of constant size are not\nsufficient for leader election algorithms. We improve this result by\nestablishing a tight lower bound of $\\Theta(\\log \\Delta+\\log \\log n)$ bits per\nregister for self-stabilizing algorithms solving $(\\Delta+1)$-coloring or\nconstructing a spanning tree in networks of maximum degree~$\\Delta$. The lower\nbound $\\Omega(\\log \\log n)$ bits per register also holds for leader election.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 11:44:49 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 17:22:17 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Blin", "L\u00e9lia", ""], ["Feuilloley", "Laurent", ""], ["Bouder", "Gabriel Le", ""]]}, {"id": "1905.08565", "submitter": "Laurent Feuilloley", "authors": "L\\'elia Blin, Swan Dubois, Laurent Feuilloley", "title": "Silent MST approximation for tiny memory", "comments": "To appear at SSS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show that approximation can help reduce the space used for\nself-stabilization. In the classic \\emph{state model}, where the nodes of a\nnetwork communicate by reading the states of their neighbors, an important\nmeasure of efficiency is the space: the number of bits used at each node to\nencode the state. In this model, a classic requirement is that the algorithm\nhas to be \\emph{silent}, that is, after stabilization the states should not\nchange anymore. We design a silent self-stabilizing algorithm for the problem\nof minimum spanning tree, that has a trade-off between the quality of the\nsolution and the space needed to compute it.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 11:45:13 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 17:14:29 GMT"}, {"version": "v3", "created": "Mon, 27 Jan 2020 21:07:11 GMT"}, {"version": "v4", "created": "Wed, 21 Oct 2020 13:01:54 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Blin", "L\u00e9lia", ""], ["Dubois", "Swan", ""], ["Feuilloley", "Laurent", ""]]}, {"id": "1905.08637", "submitter": "Vinicius V. Cogo", "authors": "Vinicius V. Cogo, Alysson Bessani", "title": "Auditable Register Emulations", "comments": "16 pages, 2 figures, 1 algorithm. Improved the model definition,\n  simplified the configuration figures, and added a section about signed reads", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread prevalence of data breaches amplifies the importance of\nauditing storage systems. In this work, we initiate the study of auditable\nstorage emulations, which provide the capability for an auditor to report the\npreviously executed reads in a register. We precisely define the notion of\nauditable register and its properties, and establish tight bounds and\nimpossibility results for auditable storage emulations in the presence of\nfaulty storage objects. Our formulation considers loggable read-write registers\nthat securely store data using information dispersal and support fast reads. In\nsuch a scenario, given a maximum number~$f$ of faulty storage objects and a\nminimum number~$\\tau$ of data blocks required to recover a stored value, we\nprove that (1) auditability is impossible if $\\tau \\leq 2f $; (2) implementing\na weak form of auditability requires $\\tau \\geq 3f+1$; and (3) a stronger form\nof auditability is impossible. We also show that signing read requests\novercomes the lower bound of weak auditability, while totally ordering\noperations or using non-fast reads enables strong auditability.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 13:44:22 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 11:59:35 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Cogo", "Vinicius V.", ""], ["Bessani", "Alysson", ""]]}, {"id": "1905.08645", "submitter": "Nicolas Loizou", "authors": "Nicolas Loizou and Peter Richt\\'arik", "title": "Revisiting Randomized Gossip Algorithms: General Framework, Convergence\n  Rates and Novel Block and Accelerated Protocols", "comments": "44 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a new framework for the analysis and design of\nrandomized gossip algorithms for solving the average consensus problem. We show\nhow classical randomized iterative methods for solving linear systems can be\ninterpreted as gossip algorithms when applied to special systems encoding the\nunderlying network and explain in detail their decentralized nature. Our\ngeneral framework recovers a comprehensive array of well-known gossip\nalgorithms as special cases, including the pairwise randomized gossip algorithm\nand path averaging gossip, and allows for the development of provably faster\nvariants. The flexibility of the new approach enables the design of a number of\nnew specific gossip methods. For instance, we propose and analyze novel block\nand the first provably accelerated randomized gossip protocols, and dual\nrandomized gossip algorithms.\n  From a numerical analysis viewpoint, our work is the first that explores in\ndepth the decentralized nature of randomized iterative methods for linear\nsystems and proposes them as methods for solving the average consensus problem.\n  We evaluate the performance of the proposed gossip protocols by performing\nextensive experimental testing on typical wireless network topologies.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 14:36:59 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 16:41:08 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Loizou", "Nicolas", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1905.08733", "submitter": "Jan Skrzypczak", "authors": "Jan Skrzypczak, Florian Schintke, Thorsten Sch\\\"utt", "title": "Linearizable State Machine Replication of State-Based CRDTs without Logs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General solutions of state machine replication have to ensure that all\nreplicas apply the same commands in the same order, even in the presence of\nfailures. Such strict ordering incurs high synchronization costs caused by\ndistributed consensus or by the use of a leader.\n  This paper presents a protocol for linearizable state machine replication of\nconflict-free replicated data types (CRDTs) that neither requires consensus nor\na leader. By leveraging the properties of state-based CRDTs - in particular,\nthe monotonic growth of a join semilattice - synchronization overhead is\ngreatly reduced. As a result, updates only need a single round trip and modify\nthe state 'in-place' without the need for a log. Furthermore, the message size\noverhead for coordination consists of a single counter per message. For\nqueries, we guarantee finite writes termination. We show in an experimental\nevaluation that more than 99 % of queries can be handled in one to three round\ntrips under highly concurrent accesses.\n  Our protocol achieves high throughput without auxiliary processes such as\ncommand log management or leader election. Thus, it is well suited for\npractical scenarios that need linearizable access to CRDT data on a\nfine-granular scale.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 16:24:13 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 11:05:52 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Skrzypczak", "Jan", ""], ["Schintke", "Florian", ""], ["Sch\u00fctt", "Thorsten", ""]]}, {"id": "1905.08764", "submitter": "Yihui Ren", "authors": "Yihui Ren, Shinjae Yoo and Adolfy Hoisie", "title": "Performance Analysis of Deep Learning Workloads on Leading-edge Systems", "comments": "11 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work examines the performance of leading-edge systems designed for\nmachine learning computing, including the NVIDIA DGX-2, Amazon Web Services\n(AWS) P3, IBM Power System Accelerated Compute Server AC922, and a\nconsumer-grade Exxact TensorEX TS4 GPU server. Representative deep learning\nworkloads from the fields of computer vision and natural language processing\nare the focus of the analysis. Performance analysis is performed along with a\nnumber of important dimensions. Performance of the communication interconnects\nand large and high-throughput deep learning models are considered. Different\npotential use models for the systems as standalone and in the cloud also are\nexamined. The effect of various optimization of the deep learning models and\nsystem configurations is included in the analysis.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 17:33:19 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 20:59:22 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Ren", "Yihui", ""], ["Yoo", "Shinjae", ""], ["Hoisie", "Adolfy", ""]]}, {"id": "1905.08778", "submitter": "Yehia Arafa", "authors": "Yehia Arafa, Abdel-Hameed Badawy, Gopinath Chennupati, Nandakishore\n  Santhi, and Stephan Eidenbenz", "title": "Low Overhead Instruction Latency Characterization for NVIDIA GPGPUs", "comments": "Several typos in addition to paper tittle are updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade has seen a shift in the computer systems industry where\nheterogeneous computing has become prevalent. Graphics Processing Units (GPUs)\nare now present in supercomputers to mobile phones and tablets. GPUs are used\nfor graphics operations as well as general-purpose computing (GPGPUs) to boost\nthe performance of compute-intensive applications. However, the percentage of\nundisclosed characteristics beyond what vendors provide is not small. In this\npaper, we introduce a very low overhead and portable analysis for exposing the\nlatency of each instruction executing in the GPU pipeline(s) and the access\noverhead of the various memory hierarchies found in GPUs at the\nmicro-architecture level. Furthermore, we show the impact of the various\noptimizations the CUDA compiler can perform over the various latencies. We\nperform our evaluation on seven different high-end NVIDIA GPUs from five\ndifferent generations/architectures: Kepler, Maxwell, Pascal, Volta, and\nTuring. The results in this paper can help architects to have an accurate\ncharacterization of the latencies of these GPUs, which will help in modeling\nthe hardware accurately. Also, software developers can perform informed\noptimizations to their applications.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 17:48:35 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 23:55:02 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Arafa", "Yehia", ""], ["Badawy", "Abdel-Hameed", ""], ["Chennupati", "Gopinath", ""], ["Santhi", "Nandakishore", ""], ["Eidenbenz", "Stephan", ""]]}, {"id": "1905.08856", "submitter": "Jaroslav Opatrny", "authors": "Anne-Laure Ehresmann, Manuel Lafond, Lata Narayanan, Jaroslav Opatrny", "title": "Distributed Pattern Formation in a Ring", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.SI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Motivated by concerns about diversity in social networks, we consider the\nfollowing pattern formation problems in rings. Assume $n$ mobile agents are\nlocated at the nodes of an $n$-node ring network. Each agent is assigned a\ncolour from the set $\\{c_1, c_2, \\ldots, c_q \\}$. The ring is divided into $k$\ncontiguous {\\em blocks} or neighbourhoods of length $p$. The agents are\nrequired to rearrange themselves in a distributed manner to satisfy given\ndiversity requirements: in each block $j$ and for each colour $c_i$, there must\nbe exactly $n_i(j) >0$ agents of colour $c_i$ in block $j$. Agents are assumed\nto be able to see agents in adjacent blocks, and move to any position in\nadjacent blocks in one time step. When the number of colours $q=2$, we give an\nalgorithm that terminates in time $N_1/n^*_1 + k + 4$ where $N_1$ is the total\nnumber of agents of colour $c_1$ and $n^*_1$ is the minimum number of agents of\ncolour $c_1$ required in any block. When the diversity requirements are the\nsame in every block, our algorithm requires $3k+4$ steps, and is asymptotically\noptimal. Our algorithm generalizes for an arbitrary number of colours, and\nterminates in $O(nk)$ steps. We also show how to extend it to achieve arbitrary\nspecific final patterns, provided there is at least one agent of every colour\nin every pattern.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 20:21:31 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Ehresmann", "Anne-Laure", ""], ["Lafond", "Manuel", ""], ["Narayanan", "Lata", ""], ["Opatrny", "Jaroslav", ""]]}, {"id": "1905.08932", "submitter": "Sheshadri K R", "authors": "Sumit Kumar Monga, Sheshadri K R and Yogesh Simmhan", "title": "ElfStore: A Resilient Data Storage Service for Federated Edge and Fog\n  Resources", "comments": "24 pages, 14 figures, To appear in IEEE International Conference on\n  Web Services (ICWS), Milan, Italy, 2019", "journal-ref": "Proceedings of the 2019 IEEE International Conference on Web\n  Services (ICWS) Conference", "doi": "10.1109/ICWS.2019.00062", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge and fog computing have grown popular as IoT deployments become\nwide-spread. While application composition and scheduling on such resources are\nbeing explored, there exists a gap in a distributed data storage service on the\nedge and fog layer, instead depending solely on the cloud for data persistence.\nSuch a service should reliably store and manage data on fog and edge devices,\neven in the presence of failures, and offer transparent discovery and access to\ndata for use by edge computing applications. Here, we present Elfstore, a\nfirst-of-its-kind edge-local federated store for streams of data blocks. It\nuses reliable fog devices as a super-peer overlay to monitor the edge\nresources, offers federated metadata indexing using Bloom filters, locates data\nwithin 2-hops, and maintains approximate global statistics about the\nreliability and storage capacity of edges. Edges host the actual data blocks,\nand we use a unique differential replication scheme to select edges on which to\nreplicate blocks, to guarantee a minimum reliability and to balance storage\nutilization. Our experiments on two IoT virtual deployments with 20 and 272\ndevices show that ElfStore has low overheads, is bound only by the network\nbandwidth, has scalable performance, and offers tunable resilience.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 02:56:05 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Monga", "Sumit Kumar", ""], ["R", "Sheshadri K", ""], ["Simmhan", "Yogesh", ""]]}, {"id": "1905.09016", "submitter": "Shreyas Pai", "authors": "Shreyas Pai, Sriram V. Pemmaraju", "title": "Connectivity Lower Bounds in Broadcast Congested Clique", "comments": "19 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We prove three new lower bounds for graph connectivity in the $1$-bit\nbroadcast congested clique model, BCC$(1)$. First, in the KT-$0$ version of\nBCC$(1)$, in which nodes are aware of neighbors only through port numbers, we\nshow an $\\Omega(\\log n)$ round lower bound for CONNECTIVITY even for\nconstant-error randomized Monte Carlo algorithms. The deterministic version of\nthis result can be obtained via the well-known \"edge-crossing\" argument, but,\nthe randomized version of this result requires establishing new combinatorial\nresults regarding the indistinguishability graph induced by inputs. In our\nsecond result, we show that the $\\Omega(\\log n)$ lower bound result extends to\nthe KT-$1$ version of the BCC$(1)$ model, in which nodes are aware of IDs of\nall neighbors, though our proof works only for deterministic algorithms. Since\nnodes know IDs of their neighbors in the KT-$1$ model, it is no longer possible\nto play \"edge-crossing\" tricks; instead we present a reduction from the 2-party\ncommunication complexity problem PARTITION in which Alice and Bob are give two\nset partitions on $[n]$ and are required to determine if the join of these two\nset partitions equals the trivial one-part set partition. While our KT-$1$\nCONNECTIVITY lower bound holds only for deterministic algorithms, in our third\nresult we extend this $\\Omega(\\log n)$ KT-1 lower bound to constant-error Monte\nCarlo algorithms for the closely related CONNECTED COMPONENTS problem. We use\ninformation-theoretic techniques to obtain this result. All our results hold\nfor the seemingly easy special case of CONNECTIVITY in which an algorithm has\nto distinguish an instance with one cycle from an instance with multiple\ncycles. Our results showcase three rather different lower bound techniques and\nlay the groundwork for further improvements in lower bounds for CONNECTIVITY in\nthe BCC$(1)$ model.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 08:35:09 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Pai", "Shreyas", ""], ["Pemmaraju", "Sriram V.", ""]]}, {"id": "1905.09034", "submitter": "Petar Zecevic", "authors": "Petar Ze\\v{c}evi\\'c, Colin T. Slater, Mario Juri\\'c, Andrew J.\n  Connolly, Sven Lon\\v{c}ari\\'c, Eric C. Bellm, V. Zach Golkhou, Krzysztof\n  Suberlak", "title": "AXS: A framework for fast astronomical data processing based on Apache\n  Spark", "comments": null, "journal-ref": null, "doi": "10.3847/1538-3881/ab2384", "report-no": null, "categories": "astro-ph.IM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce AXS (Astronomy eXtensions for Spark), a scalable open-source\nastronomical data analysis framework built on Apache Spark, a widely used\nindustry-standard engine for big data processing. Building on capabilities\npresent in Spark, AXS aims to enable querying and analyzing almost arbitrarily\nlarge astronomical catalogs using familiar Python/AstroPy concepts, DataFrame\nAPIs, and SQL statements. We achieve this by i) adding support to Spark for\nefficient on-line positional cross-matching and ii) supplying a Python library\nsupporting commonly-used operations for astronomical data analysis. To support\nscalable cross-matching, we developed a variant of the ZONES algorithm (Gray et\nal. 2004) capable of operating in distributed, shared-nothing architecture. We\ncouple this to a data partitioning scheme that enables fast catalog\ncross-matching and handles the data skew often present in deep all-sky data\nsets. The cross-match and other often-used functionalities are exposed to the\nend users through an easy-to-use Python API. We demonstrate AXS' technical and\nscientific performance on SDSS, ZTF, Gaia DR2, and AllWise catalogs. Using AXS\nwe were able to perform on-the-fly cross-match of Gaia DR2 (1.8 billion rows)\nand AllWise (900 million rows) data sets in ~ 30 seconds. We discuss how\ncloud-ready distributed systems like AXS provide a natural way to enable\ncomprehensive end-user analyses of large datasets such as LSST.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 09:25:01 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 18:42:13 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Ze\u010devi\u0107", "Petar", ""], ["Slater", "Colin T.", ""], ["Juri\u0107", "Mario", ""], ["Connolly", "Andrew J.", ""], ["Lon\u010dari\u0107", "Sven", ""], ["Bellm", "Eric C.", ""], ["Golkhou", "V. Zach", ""], ["Suberlak", "Krzysztof", ""]]}, {"id": "1905.09166", "submitter": "Gourav Rattihalli", "authors": "Gourav Rattihalli, Pankaj Saha, Madhusudhan Govindaraju, Devesh Tiwari", "title": "Two stage cluster for resource optimization with Apache Mesos", "comments": "MTAGS17:10th Workshop on Many-Task Computing on Clouds, Grids, and\n  Supercomputers", "journal-ref": "MTAGS 2017: 10th Workshop on Many-Task Computing on Clouds, Grids,\n  and Supercomputers", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As resource estimation for jobs is difficult, users often overestimate their\nrequirements. Both commercial clouds and academic campus clusters suffer from\nlow resource utilization and long wait times as the resource estimates for\njobs, provided by users, is inaccurate. We present an approach to statistically\nestimate the actual resource requirement of a job in a Little cluster before\nthe run in a Big cluster. The initial estimation on the little cluster gives us\na view of how much actual resources a job requires. This initial estimate\nallows us to accurately allocate resources for the pending jobs in the queue\nand thereby improve throughput and resource utilization. In our experiments, we\ndetermined resource utilization estimates with an average accuracy of 90% for\nmemory and 94% for CPU, while we make better utilization of memory by an\naverage of 22% and CPU by 53%, compared to the default job submission methods\non Apache Aurora and Apache Mesos.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 14:26:53 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Rattihalli", "Gourav", ""], ["Saha", "Pankaj", ""], ["Govindaraju", "Madhusudhan", ""], ["Tiwari", "Devesh", ""]]}, {"id": "1905.09175", "submitter": "Nikos Parotsidis", "authors": "Giuseppe F. Italiano, Silvio Lattanzi, Vahab S. Mirrokni and Nikos\n  Parotsidis", "title": "Dynamic Algorithms for the Massively Parallel Computation Model", "comments": "Accepted to the 31st ACM Symposium on Parallelism in Algorithms and\n  Architectures (SPAA 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Massive Parallel Computing (MPC) model gained popularity during the last\ndecade and it is now seen as the standard model for processing large scale\ndata. One significant shortcoming of the model is that it assumes to work on\nstatic datasets while, in practice, real-world datasets evolve continuously. To\novercome this issue, in this paper we initiate the study of dynamic algorithms\nin the MPC model.\n  We first discuss the main requirements for a dynamic parallel model and we\nshow how to adapt the classic MPC model to capture them. Then we analyze the\nconnection between classic dynamic algorithms and dynamic algorithms in the MPC\nmodel. Finally, we provide new efficient dynamic MPC algorithms for a variety\nof fundamental graph problems, including connectivity, minimum spanning tree\nand matching.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 14:44:37 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Italiano", "Giuseppe F.", ""], ["Lattanzi", "Silvio", ""], ["Mirrokni", "Vahab S.", ""], ["Parotsidis", "Nikos", ""]]}, {"id": "1905.09177", "submitter": "Ulysse L\\'echine", "authors": "Ulysse L\\'echine and S\\'ebastien Tixeuil", "title": "Asynchronous Scattering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of scattering a swarm of mobile\noblivious robots in a continuous space. We consider the fully asynchronous\nsetting where robots may base their computation on past observations, or may be\nobserved by other robots while moving.\n  It turns out that asynchronous scattering is solvable in the most general\ncase when both vision (the ability to see others robots positions) and weak\nlocal multiplicity detection are available. In the case of a bidimensional\nEuclidean space, ASYNC scattering is also solvable with blind robots if moves\nare rigid. Our approach is constructive and modular, as we present a proof\ntechnique for probabilistic robot protocols that is of independent interest and\ncan be reused for other purposes.\n  On the negative side, we show that when robots are both blind and have no\nmultiplicity detection, the problem is unsolvable, and when only one of those\nis available, the problem remains unsolvable on the line.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 14:53:39 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["L\u00e9chine", "Ulysse", ""], ["Tixeuil", "S\u00e9bastien", ""]]}, {"id": "1905.09219", "submitter": "Shiqiang Wang", "authors": "Tiffany Tuor, Shiqiang Wang, Kin K. Leung, Bong Jun Ko", "title": "Online Collection and Forecasting of Resource Utilization in Large-Scale\n  Distributed Systems", "comments": "Accepted at IEEE International Conference on Distributed Computing\n  Systems (ICDCS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale distributed computing systems often contain thousands of\ndistributed nodes (machines). Monitoring the conditions of these nodes is\nimportant for system management purposes, which, however, can be extremely\nresource demanding as this requires collecting local measurements of each\nindividual node and constantly sending those measurements to a central\ncontroller. Meanwhile, it is often useful to forecast the future system\nconditions for various purposes such as resource planning/allocation and\nanomaly detection, but it is usually too resource-consuming to have one\nforecasting model running for each node, which may also neglect correlations in\nobserved metrics across different nodes. In this paper, we propose a mechanism\nfor collecting and forecasting the resource utilization of machines in a\ndistributed computing system in a scalable manner. We present an algorithm that\nallows each local node to decide when to transmit its most recent measurement\nto the central node, so that the transmission frequency is kept below a given\nconstraint value. Based on the measurements received from local nodes, the\ncentral node summarizes the received data into a small number of clusters.\nSince the cluster partitioning can change over time, we also present a method\nto capture the evolution of clusters and their centroids. As an effective way\nto reduce the amount of computation, time-series forecasting models are trained\non the time-varying centroids of each cluster, to forecast the future resource\nutilizations of a group of local nodes. The effectiveness of our proposed\napproach is confirmed by extensive experiments using multiple real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 16:14:14 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Tuor", "Tiffany", ""], ["Wang", "Shiqiang", ""], ["Leung", "Kin K.", ""], ["Ko", "Bong Jun", ""]]}, {"id": "1905.09271", "submitter": "St\u00e9phane Devismes", "authors": "Quentin Bramas, Stephane Devismes, Pascal Lafourcade", "title": "Infinite Grid Exploration by Disoriented Robots", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We deal with a set of autonomous robots moving on an infinite grid. Those\nrobots are opaque, have limited visibility capabilities, and run using\nsynchronous Look-Compute-Move cycles. They all agree on a common chirality, but\nhave no global compass. Finally, they may use lights of different colors, but\nexcept from that, robots have neither persistent memories, nor communication\nmean. We consider the infinite grid exploration (IGE) problem. For this problem\nwe give two impossibility results and three algorithms, including one which is\noptimal in terms of number of robots. In more detail, we first show that two\nrobots are not sufficient in our settings to solve the problem, even when\nrobots have a common coordinate system. We then show that if the robots'\ncoordinate systems are not self-consistent, three or four robots are not\nsufficient to solve the problem. Finally, we present three algorithms that\nsolve the IGE problem in various settings. The first algorithm uses six robots\nwith constant colors and a visibility range of one. The second one uses the\nminimum number of robots, i.e., five, as well as five modifiable colors, still\nunder visibility one. The last algorithm requires seven oblivious anonymous\nrobots, yet assuming visibility two. Notice that the two last algorithms also\nsatisfy achieve exclusiveness.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 17:57:34 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 09:25:12 GMT"}, {"version": "v3", "created": "Fri, 7 Jun 2019 07:10:15 GMT"}, {"version": "v4", "created": "Tue, 2 Jul 2019 13:39:57 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Bramas", "Quentin", ""], ["Devismes", "Stephane", ""], ["Lafourcade", "Pascal", ""]]}, {"id": "1905.09345", "submitter": "Yuke Wang", "authors": "Yuke Wang, Zhaorui Zeng, Boyuan Feng, Lei Deng, Yufei Ding", "title": "KPynq: A Work-Efficient Triangle-Inequality based K-means on FPGA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  K-means is a popular but computation-intensive algorithm for unsupervised\nlearning. To address this issue, we present KPynq, a work-efficient\ntriangle-inequality based K-means on FPGA for handling large-size,\nhigh-dimension datasets. KPynq leverages an algorithm-level optimization to\nbalance the performance and computation irregularity, and a hardware\narchitecture design to fully exploit the pipeline and parallel processing\ncapability of various FPGAs. In the experiment, KPynq consistently outperforms\nthe CPU-based standard K-means in terms of its speedup (up to 4.2x) and\nsignificant energy-efficiency (up to 218x).\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 19:41:17 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Wang", "Yuke", ""], ["Zeng", "Zhaorui", ""], ["Feng", "Boyuan", ""], ["Deng", "Lei", ""], ["Ding", "Yufei", ""]]}, {"id": "1905.09359", "submitter": "Mohammad Javad Amiri", "authors": "Victor Zakhary, Mohammad Javad Amiri, Sujaya Maiyya, Divyakant\n  Agrawal, Amr El Abbadi", "title": "Towards Global Asset Management in Blockchain Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Permissionless blockchains (e.g., Bitcoin, Ethereum, etc) have shown a wide\nsuccess in implementing global scale peer-to-peer cryptocurrency systems. In\nsuch blockchains, new currency units are generated through the mining process\nand are used in addition to transaction fees to incentivize miners to maintain\nthe blockchain. Although it is clear how currency units are generated and\ntransacted on, it is unclear how to use the infrastructure of permissionless\nblockchains to manage other assets than the blockchain's currency units (e.g.,\ncars, houses, etc). In this paper, we propose a global asset management system\nby unifying permissioned and permissionless blockchains. A governmental\npermissioned blockchain authenticates the registration of end-user assets\nthrough smart contract deployments on a permissionless blockchain. Afterwards,\nend-users can transact on their assets through smart contract function calls\n(e.g., sell a car, rent a room in a house, etc). In return, end-users get paid\nin currency units of the same blockchain or other blockchains through atomic\ncross-chain transactions and governmental offices receive taxes on these\ntransactions in cryptocurrency units.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 20:44:36 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Zakhary", "Victor", ""], ["Amiri", "Mohammad Javad", ""], ["Maiyya", "Sujaya", ""], ["Agrawal", "Divyakant", ""], ["Abbadi", "Amr El", ""]]}, {"id": "1905.09395", "submitter": "Dirk Van Essendelft", "authors": "Kyle Buchheit, Opeoluwa Owoyele, Terry Jordan, Dirk Van Essendelft", "title": "The Stabilized Explicit Variable-Load Solver with Machine Learning\n  Acceleration for the Rapid Solution of Stiff Chemical Kinetics", "comments": "25 pages, 14 Figures, 2 Tables, 56 Equations, Original research into\n  accelerating CFD with ML/AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.DC cs.GR cs.LG cs.PF", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this study, a fast and stable machine-learned hybrid algorithm implemented\nin TensorFlow for the integration of stiff chemical kinetics is introduced.\nNumerical solutions to differential equations are at the core of computational\nfluid dynamics calculations. As the size and complexity of the simulations\ngrow, so does the need for computational power and time. Many efforts have been\nmade to implement stiff chemistry solvers on GPUs but have not been highly\nsuccessful because of the logical divergence in traditional stiff solver\nalgorithms. Because of these constrains, a novel Explicit Stabilized\nVariable-load (STEV) solver has been developed. Overstepping due to the\nrelatively large time steps is prevented by introducing limits to the maximum\nchanges of chemical species per time step. To prevent oscillations, a discrete\nFourier transform is introduced to dampen ringing. In contrast to conventional\nexplicit approaches, a variable-load approach is used where each cell in the\ncomputational domain is advanced with its unique time step. This approach\nallows cells to be integrated simultaneously while maintaining warp convergence\nbut finish at different iterations and be removed from the workload. To improve\nthe computational performance of the introduced solver, specific thermodynamic\nquantities of interest were estimated using shallow neural networks in place of\npolynomial fits, leading to an additional 10% savings in clock time with\nminimal training and implementation requirements. However ML specific hardware\ncould increase the time savings to as much as 28%. While the complexity of\nthese particular machine learning models is not high by modern standards, the\nimpact on computational efficiency should not be ignored. The results show a\ndramatic decrease in total chemistry solution time (over 200 times) while\nmaintaining a similar degree of accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 15:10:35 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 12:26:27 GMT"}, {"version": "v3", "created": "Fri, 21 Jun 2019 21:14:31 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Buchheit", "Kyle", ""], ["Owoyele", "Opeoluwa", ""], ["Jordan", "Terry", ""], ["Van Essendelft", "Dirk", ""]]}, {"id": "1905.09572", "submitter": "Cheng Zhao", "authors": "Cheng Zhao, Zhibin Zhang, Peng Xu, Tianqi Zheng, Xueqi Cheng", "title": "Kaleido: An Efficient Out-of-core Graph Mining System on A Single\n  Machine", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Graph mining is one of the most important categories of graph algorithms.\n  However, exploring the subgraphs of an input graph produces a huge amount of\nintermediate data.\n  The 'think like a vertex' programming paradigm, pioneered by Pregel, cannot\nreadily formulate mining problems, which is designed to produce graph\ncomputation problems like PageRank.\n  Existing mining systems like Arabesque and RStream need large amounts of\ncomputing and memory resources.\n  In this paper, we present Kaleido, an efficient single machine, out-of-core\ngraph mining system which treats disks as an extension of memory.\n  Kaleido treats intermediate data in graph mining tasks as a tensor and adopts\na succinct data structure for the intermediate data.\n  Kaleido utilizes the eigenvalue of the adjacency matrix of a subgraph to\nefficiently solve the subgraph isomorphism problems with an acceptable\nconstraint that the vertex number of a subgraph is less than 9.\n  Kaleido implements half-memory-half-disk storage for storing large\nintermediate data, which treats the disk as an extension of the memory.\n  Comparing with two state-of-the-art mining systems, Arabesque and RStream,\nKaleido outperforms them by a GeoMean 12.3$\\times$ and 40.0$\\times$\nrespectively.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 10:26:40 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Zhao", "Cheng", ""], ["Zhang", "Zhibin", ""], ["Xu", "Peng", ""], ["Zheng", "Tianqi", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1905.09590", "submitter": "Kyrill Winkler", "authors": "Thomas Nowak, Ulrich Schmid, Kyrill Winkler", "title": "Topological Characterization of Consensus under General Message\n  Adversaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide a rigorous characterization of consensus\nsolvability in synchronous directed dynamic networks controlled by an arbitrary\nmessage adversary using point-set topology: We extend the approach introduced\nby Alpern and Schneider in 1985 by introducing two novel topologies on the\nspace of infinite executions: the process-view topology, induced by a distance\nfunction that relies on the local view of a given process in an execution, and\nthe minimum topology, which is induced by a distance function that focuses on\nthe local view of the process that is the last to distinguish two executions.\nWe establish some simple but powerful topological results, which not only lead\nto a topological explanation of bivalence arguments, but also provide necessary\nand sufficient topological conditions on the admissible graph sequences of a\nmessage adversary for solving consensus. In particular, we characterize\nconsensus solvability in terms of connectivity of the set of admissible graph\nsequences. For non-compact message adversaries, which are not limit-closed in\nthe sense that there is a convergent sequence of graph sequences whose limit is\nnot permitted, this requires the exclusion of all \"fair\" and \"unfair\" limit\nsequences that coincide with the forever bivalent runs constructed in bivalence\nproofs. For both compact and non-compact message adversaries, we also provide\ntailored characterizations of consensus solvability, i.e., tight conditions for\nimpossibility and existence of algorithms, based on the broadcastability of the\nconnected components of the set of admissible graph sequences.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 11:26:11 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Nowak", "Thomas", ""], ["Schmid", "Ulrich", ""], ["Winkler", "Kyrill", ""]]}, {"id": "1905.09655", "submitter": "Pawel Szalachowski", "authors": "Pawel Szalachowski, Daniel Reijsbergen, Ivan Homoliak, Siwei Sun", "title": "StrongChain: Transparent and Collaborative Proof-of-Work Consensus", "comments": "USENIX Security '19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin is the most successful cryptocurrency so far. This is mainly due to\nits novel consensus algorithm, which is based on proof-of-work combined with a\ncryptographically-protected data structure and a rewarding scheme that\nincentivizes nodes to participate. However, despite its unprecedented success\nBitcoin suffers from many inefficiencies. For instance, Bitcoin's consensus\nmechanism has been proved to be incentive-incompatible, its high reward\nvariance causes centralization, and its hardcoded deflation raises questions\nabout its long-term sustainability.\n  In this work, we revise the Bitcoin consensus mechanism by proposing\nStrongChain, a scheme that introduces transparency and incentivizes\nparticipants to collaborate rather than to compete. The core design of our\nprotocol is to reflect and utilize the computing power aggregated on the\nblockchain which is invisible and \"wasted\" in Bitcoin today. Introducing\nrelatively easy, although important changes to Bitcoin's design enables us to\nimprove many crucial aspects of Bitcoin-like cryptocurrencies making it more\nsecure, efficient, and profitable for participants. We thoroughly analyze our\napproach and we present an implementation of StrongChain. The obtained results\nconfirm its efficiency, security, and deployability.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 13:50:31 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Szalachowski", "Pawel", ""], ["Reijsbergen", "Daniel", ""], ["Homoliak", "Ivan", ""], ["Sun", "Siwei", ""]]}, {"id": "1905.09680", "submitter": "Hyunghun Cho", "authors": "Hyunghun Cho, Yongjin Kim, Eunjung Lee, Daeyoung Choi, Yongjae Lee,\n  Wonjong Rhee", "title": "DEEP-BO for Hyperparameter Optimization of Deep Networks", "comments": "26 pages, NeurIPS19 under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of deep neural networks (DNN) is very sensitive to the\nparticular choice of hyper-parameters. To make it worse, the shape of the\nlearning curve can be significantly affected when a technique like batchnorm is\nused. As a result, hyperparameter optimization of deep networks can be much\nmore challenging than traditional machine learning models. In this work, we\nstart from well known Bayesian Optimization solutions and provide enhancement\nstrategies specifically designed for hyperparameter optimization of deep\nnetworks. The resulting algorithm is named as DEEP-BO (Diversified,\nEarly-termination-Enabled, and Parallel Bayesian Optimization). When evaluated\nover six DNN benchmarks, DEEP-BO easily outperforms or shows comparable\nperformance with some of the well-known solutions including GP-Hedge,\nHyperband, BOHB, Median Stopping Rule, and Learning Curve Extrapolation. The\ncode used is made publicly available at https://github.com/snu-adsl/DEEP-BO.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 14:25:33 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Cho", "Hyunghun", ""], ["Kim", "Yongjin", ""], ["Lee", "Eunjung", ""], ["Choi", "Daeyoung", ""], ["Lee", "Yongjae", ""], ["Rhee", "Wonjong", ""]]}, {"id": "1905.09726", "submitter": "Ali Ebnenasir", "authors": "Ali Ebnenasir", "title": "Verification and Synthesis of Symmetric Uni-Rings for Leads-To\n  Properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper investigates the verification and synthesis of parameterized\nprotocols that satisfy leadsto properties $R \\leadsto Q$ on symmetric\nunidirectional rings (a.k.a. uni-rings) of deterministic and constant-space\nprocesses under no fairness and interleaving semantics, where $R$ and $Q$ are\nglobal state predicates. First, we show that verifying $R \\leadsto Q$ for\nparameterized protocols on symmetric uni-rings is undecidable, even for\ndeterministic and constant-space processes, and conjunctive state predicates.\nThen, we show that surprisingly synthesizing symmetric uni-ring protocols that\nsatisfy $R \\leadsto Q$ is actually decidable. We identify necessary and\nsufficient conditions for the decidability of synthesis based on which we\ndevise a sound and complete polynomial-time algorithm that takes the predicates\n$R$ and $Q$, and automatically generates a parameterized protocol that\nsatisfies $R \\leadsto Q$ for unbounded (but finite) ring sizes. Moreover, we\npresent some decidability results for cases where leadsto is required from\nmultiple distinct $R$ predicates to different $Q$ predicates. To demonstrate\nthe practicality of our synthesis method, we synthesize some parameterized\nprotocols, including agreement and parity protocols.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 16:03:04 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Ebnenasir", "Ali", ""]]}, {"id": "1905.09743", "submitter": "Maurice Herlihy", "authors": "Maurice Herlihy and Barbara Liskov and Liuba Shrira", "title": "Cross-chain Deals and Adversarial Commerce", "comments": "To appear in VLDB 2020", "journal-ref": null, "doi": "10.14778/3364324.3364326", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern distributed data management systems face a new challenge: how can\nautonomous, mutually-distrusting parties cooperate safely and effectively?\nAddressing this challenge brings up questions familiar from classical\ndistributed systems: how to combine multiple steps into a single atomic action,\nhow to recover from failures, and how to synchronize concurrent access to data.\nNevertheless, each of these issues requires rethinking when participants are\nautonomous and potentially adversarial.\n  We propose the notion of a *cross-chain deal*, a new way to structure complex\ndistributed computations that manage assets in an adversarial setting. Deals\nare inspired by classical atomic transactions, but are necessarily different,\nin important ways, to accommodate the decentralized and untrusting nature of\nthe exchange. We describe novel safety and liveness properties, along with two\nalternative protocols for implementing cross-chain deals in a system of\nindependent blockchain ledgers. One protocol, based on synchronous\ncommunication, is fully decentralized, while the other, based on\nsemi-synchronous communication, requires a globally shared ledger.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 16:06:25 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 13:16:34 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 17:58:02 GMT"}, {"version": "v4", "created": "Sat, 5 Oct 2019 00:59:25 GMT"}, {"version": "v5", "created": "Tue, 15 Oct 2019 17:39:08 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Herlihy", "Maurice", ""], ["Liskov", "Barbara", ""], ["Shrira", "Liuba", ""]]}, {"id": "1905.09766", "submitter": "Ioannis Paraskevakos", "authors": "Ioannis Paraskevakos, Matteo Turilli, Bento Collares Gon\\c{c}alves,\n  Heather J. Lynch, and Shantenu Jha", "title": "Workflow Design Analysis for High Resolution Satellite Image Analysis", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ecological sciences are using imagery from a variety of sources to monitor\nand survey populations and ecosystems. Very High Resolution (VHR) satellite\nimagery provide an effective dataset for large scale surveys. Convolutional\nNeural Networks have successfully been employed to analyze such imagery and\ndetect large animals. As the datasets increase in volume, O(TB), and number of\nimages, O(1k), utilizing High Performance Computing (HPC) resources becomes\nnecessary. In this paper, we investigate a task-parallel data-driven workflows\ndesign to support imagery analysis pipelines with heterogeneous tasks on HPC.\nWe analyze the capabilities of each design when processing a dataset of 3,000\nVHR satellite images for a total of 4~TB. We experimentally model the execution\ntime of the tasks of the image processing pipeline. We perform experiments to\ncharacterize the resource utilization, total time to completion, and overheads\nof each design. Based on the model, overhead and utilization analysis, we show\nwhich design approach to is best suited in scientific pipelines with similar\ncharacteristics.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 16:41:15 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 15:33:18 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Paraskevakos", "Ioannis", ""], ["Turilli", "Matteo", ""], ["Gon\u00e7alves", "Bento Collares", ""], ["Lynch", "Heather J.", ""], ["Jha", "Shantenu", ""]]}, {"id": "1905.09786", "submitter": "Kaustav Bose", "authors": "Kaustav Bose, Ranendu Adhikary, Manash Kumar Kundu and Buddhadeb Sau", "title": "Positional Encoding by Robots with Non-Rigid Movements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a set of autonomous computational entities, called \\emph{robots},\noperating inside a polygonal enclosure (possibly with holes), that have to\nperform some collaborative tasks. The boundary of the polygon obstructs both\nvisibility and mobility of a robot. Since the polygon is initially unknown to\nthe robots, the natural approach is to first explore and construct a map of the\npolygon. For this, the robots need an unlimited amount of persistent memory to\nstore the snapshots taken from different points inside the polygon. However, it\nhas been shown by Di Luna et al. [DISC 2017] that map construction can be done\neven by oblivious robots by employing a positional encoding strategy where a\nrobot carefully positions itself inside the polygon to encode information in\nthe binary representation of its distance from the closest polygon vertex. Of\ncourse, to execute this strategy, it is crucial for the robots to make accurate\nmovements. In this paper, we address the question whether this technique can be\nimplemented even when the movements of the robots are unpredictable in the\nsense that the robot can be stopped by the adversary during its movement before\nreaching its destination. However, there exists a constant $\\delta > 0$,\nunknown to the robot, such that the robot can always reach its destination if\nit has to move by no more than $\\delta$ amount. This model is known in\nliterature as \\emph{non-rigid} movement. We give a partial answer to the\nquestion in the affirmative by presenting a map construction algorithm for\nrobots with non-rigid movement, but having $O(1)$ bits of persistent memory and\nability to make circular moves.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 17:17:28 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Bose", "Kaustav", ""], ["Adhikary", "Ranendu", ""], ["Kundu", "Manash Kumar", ""], ["Sau", "Buddhadeb", ""]]}, {"id": "1905.09816", "submitter": "Jim Basney", "authors": "Alex Withers (NCSA), Brian Bockelman (Morgridge Institute for\n  Research), Derek Weitzel (University of Nebraska-Lincoln), Duncan Brown\n  (Syracuse University), Jason Patton (University of Wisconsin-Madison), Jeff\n  Gaynor (NCSA), Jim Basney (NCSA), Todd Tannenbaum (University of\n  Wisconsin-Madison), You Alex Gao (University of Illinois), Zach Miller\n  (University of Wisconsin-Madison)", "title": "SciTokens: Demonstrating Capability-Based Access to Remote Scientific\n  Data using HTCondor", "comments": "8 pages, 3 figures, PEARC '19: Practice and Experience in Advanced\n  Research Computing, July 28-August 1, 2019, Chicago, IL, USA. arXiv admin\n  note: substantial text overlap with arXiv:1807.04728", "journal-ref": null, "doi": "10.1145/3332186.3333258", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The management of security credentials (e.g., passwords, secret keys) for\ncomputational science workflows is a burden for scientists and information\nsecurity officers. Problems with credentials (e.g., expiration, privilege\nmismatch) cause workflows to fail to fetch needed input data or store valuable\nscientific results, distracting scientists from their research by requiring\nthem to diagnose the problems, re-run their computations, and wait longer for\ntheir results. SciTokens introduces a capabilities-based authorization\ninfrastructure for distributed scientific computing, to help scientists manage\ntheir security credentials more reliably and securely. SciTokens uses\nIETF-standard OAuth JSON Web Tokens for capability-based secure access to\nremote scientific data. These access tokens convey the specific authorizations\nneeded by the workflows, rather than general-purpose authentication\nimpersonation credentials, to address the risks of scientific workflows running\non distributed infrastructure including NSF resources (e.g., LIGO Data Grid,\nOpen Science Grid, XSEDE) and public clouds (e.g., Amazon Web Services, Google\nCloud, Microsoft Azure). By improving the interoperability and security of\nscientific workflows, SciTokens 1) enables use of distributed computing for\nscientific domains that require greater data protection and 2) enables use of\nmore widely distributed computing resources by reducing the risk of credential\nabuse on remote systems.\n  In this extended abstract, we present the results over the past year of our\nopen source implementation of the SciTokens model and its deployment in the\nOpen Science Grid, including new OAuth support added in the HTCondor 8.8\nrelease series.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 18:55:11 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Withers", "Alex", "", "NCSA"], ["Bockelman", "Brian", "", "Morgridge Institute for\n  Research"], ["Weitzel", "Derek", "", "University of Nebraska-Lincoln"], ["Brown", "Duncan", "", "Syracuse University"], ["Patton", "Jason", "", "University of Wisconsin-Madison"], ["Gaynor", "Jeff", "", "NCSA"], ["Basney", "Jim", "", "NCSA"], ["Tannenbaum", "Todd", "", "University of\n  Wisconsin-Madison"], ["Gao", "You Alex", "", "University of Illinois"], ["Miller", "Zach", "", "University of Wisconsin-Madison"]]}, {"id": "1905.09985", "submitter": "Soichiro Imoto", "authors": "Soichiro Imoto, Yuichi Sudo, Hirotsugu Kakugawa, Toshimitsu Masuzawa", "title": "Atomic Cross-Chain Swaps with Improved Space and Local Time Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An effective atomic cross-chain swap protocol is introduced by Herlihy\n[Herlihy, 2018] as a distributed coordination protocol in order to exchange\nassets across multiple blockchains among multiple parties. An atomic\ncross-chain swap protocol guarantees; (1) if all parties conform to the\nprotocol, then all assets are exchanged among parties, (2) even if some parties\nor coalitions of parties deviate from the protocol, no party conforming to the\nprotocol suffers a loss, and (3) no coalition has an incentive to deviate from\nthe protocol. Herlihy [Herlihy, 2018] invented this protocol by using hashed\ntimelock contracts. A cross-chain swap is modeled as a directed graph D =\n(V,A). Vertex set V denotes a set of parties and arc set A denotes a set of\nproposed asset transfers. Herlihy's protocol uses the graph topology and\nsignature information to set appropriate hashed timelock contracts. The space\ncomplexity of the protocol (i.e., the total number of bits written in the\nblockchains in a swap) is O(|A|^2). The local time complexity of the protocol\n(i.e., the maximum execution time of a contract in a swap to transfer the\ncorresponding asset) is O(|V||L|), where L is a feedback vertex set computed by\nthe protocol. We propose a new atomic cross-chain swap protocol which uses only\nsignature information and improves the space complexity to O(|A||V|) and the\nlocal time complexity to O(|V|).\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 01:05:58 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 05:27:58 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Imoto", "Soichiro", ""], ["Sudo", "Yuichi", ""], ["Kakugawa", "Hirotsugu", ""], ["Masuzawa", "Toshimitsu", ""]]}, {"id": "1905.10083", "submitter": "Zhi Zhou", "authors": "Zhi Zhou, Xu Chen, En Li, Liekang Zeng, Ke Luo, Junshan Zhang", "title": "Edge Intelligence: Paving the Last Mile of Artificial Intelligence with\n  Edge Computing", "comments": "Zhi Zhou, Xu Chen, En Li, Liekang Zeng, Ke Luo, and Junshan Zhang,\n  \"Edge Intelligence: Paving the Last Mile of Artificial Intelligence with Edge\n  Computing,\" Proceedings of the IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the breakthroughs in deep learning, the recent years have witnessed a\nbooming of artificial intelligence (AI) applications and services, spanning\nfrom personal assistant to recommendation systems to video/audio surveillance.\nMore recently, with the proliferation of mobile computing and\nInternet-of-Things (IoT), billions of mobile and IoT devices are connected to\nthe Internet, generating zillions Bytes of data at the network edge. Driving by\nthis trend, there is an urgent need to push the AI frontiers to the network\nedge so as to fully unleash the potential of the edge big data. To meet this\ndemand, edge computing, an emerging paradigm that pushes computing tasks and\nservices from the network core to the network edge, has been widely recognized\nas a promising solution. The resulted new inter-discipline, edge AI or edge\nintelligence, is beginning to receive a tremendous amount of interest. However,\nresearch on edge intelligence is still in its infancy stage, and a dedicated\nvenue for exchanging the recent advances of edge intelligence is highly desired\nby both the computer system and artificial intelligence communities. To this\nend, we conduct a comprehensive survey of the recent research efforts on edge\nintelligence. Specifically, we first review the background and motivation for\nartificial intelligence running at the network edge. We then provide an\noverview of the overarching architectures, frameworks and emerging key\ntechnologies for deep learning model towards training/inference at the network\nedge. Finally, we discuss future research opportunities on edge intelligence.\nWe believe that this survey will elicit escalating attentions, stimulate\nfruitful discussions and inspire further research ideas on edge intelligence.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 08:19:05 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Zhou", "Zhi", ""], ["Chen", "Xu", ""], ["Li", "En", ""], ["Zeng", "Liekang", ""], ["Luo", "Ke", ""], ["Zhang", "Junshan", ""]]}, {"id": "1905.10090", "submitter": "Fabio Baruffa", "authors": "David Brayford, Sofia Vallecorsa, Atanas Atanasov, Fabio Baruffa,\n  Walter Riviera", "title": "Deploying AI Frameworks on Secure HPC Systems with Containers", "comments": "6 pages, 2 figures, 2019 IEEE High Performance Extreme Computing\n  Conference", "journal-ref": null, "doi": "10.1109/HPEC.2019.8916576", "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing interest in the usage of Artificial Intelligence techniques\n(AI) from the research community and industry to tackle \"real world\" problems,\nrequires High Performance Computing (HPC) resources to efficiently compute and\nscale complex algorithms across thousands of nodes. Unfortunately, typical data\nscientists are not familiar with the unique requirements and characteristics of\nHPC environments. They usually develop their applications with high-level\nscripting languages or frameworks such as TensorFlow and the installation\nprocess often requires connection to external systems to download open source\nsoftware during the build. HPC environments, on the other hand, are often based\non closed source applications that incorporate parallel and distributed\ncomputing API's such as MPI and OpenMP, while users have restricted\nadministrator privileges, and face security restrictions such as not allowing\naccess to external systems. In this paper we discuss the issues associated with\nthe deployment of AI frameworks in a secure HPC environment and how we\nsuccessfully deploy AI frameworks on SuperMUC-NG with Charliecloud.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 08:45:56 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Brayford", "David", ""], ["Vallecorsa", "Sofia", ""], ["Atanasov", "Atanas", ""], ["Baruffa", "Fabio", ""], ["Riviera", "Walter", ""]]}, {"id": "1905.10149", "submitter": "Keisuke Okumura", "authors": "Keisuke Okumura, Yasumasa Tamura, Xavier D\\'efago", "title": "winPIBT: Extended Prioritized Algorithm for Iterative Multi-agent Path\n  Finding", "comments": "9 pages, 7 figures, preprint, to be presented at IJCAI-20 MAPF\n  workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of Multi-agent Path Finding (MAPF) consists in providing agents\nwith efficient paths while preventing collisions. Numerous solvers have been\ndeveloped so far since MAPF is critical for practical applications such as\nautomated warehouses. The recently-proposed Priority Inheritance with\nBacktracking (PIBT) is a promising decoupled method that solves MAPF\niteratively with flexible priorities. The method is aimed to be decentralized\nand has a very low computational cost, but it is shortsighted in the sense that\nit plans only one step ahead, thus occasionally resulting in inefficient\nplannings. This work proposes a generalization of PIBT, called windowed PIBT\n(winPIBT), that introduces a configurable time window. winPIBT allows agents to\nplan paths anticipating multiple steps ahead. We prove that, similarly to PIBT,\nall agents reach their own destinations in finite time as long as the\nenvironment is a graph with adequate properties, e.g., biconnected.\nExperimental results over various scenarios confirm that winPIBT mitigates\nlivelock situations occurring in PIBT, and usually plans more efficient paths\ngiven adequate window size.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 11:12:25 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 01:25:00 GMT"}, {"version": "v3", "created": "Sat, 7 Sep 2019 04:49:36 GMT"}, {"version": "v4", "created": "Sat, 26 Sep 2020 09:38:54 GMT"}, {"version": "v5", "created": "Mon, 14 Dec 2020 05:19:36 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Okumura", "Keisuke", ""], ["Tamura", "Yasumasa", ""], ["D\u00e9fago", "Xavier", ""]]}, {"id": "1905.10252", "submitter": "Alessandro Varsi", "authors": "Alessandro Varsi, Lykourgos Kekempanos, Jeyarajan Thiyagalingam, Simon\n  Maskell", "title": "A Single SMC Sampler on MPI that Outperforms a Single MCMC Sampler", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov Chain Monte Carlo (MCMC) is a well-established family of algorithms\nwhich are primarily used in Bayesian statistics to sample from a target\ndistribution when direct sampling is challenging. Single instances of MCMC\nmethods are widely considered hard to parallelise in a problem-agnostic fashion\nand hence, unsuitable to meet both constraints of high accuracy and high\nthroughput. Sequential Monte Carlo (SMC) Samplers can address the same problem,\nbut are parallelisable: they share with Particle Filters the same key tasks and\nbottleneck. Although a rich literature already exists on MCMC methods, SMC\nSamplers are relatively underexplored, such that no parallel implementation is\ncurrently available. In this paper, we first propose a parallel MPI version of\nthe SMC Sampler, including an optimised implementation of the bottleneck, and\nthen compare it with single-core Metropolis-Hastings. The goal is to show that\nSMC Samplers may be a promising alternative to MCMC methods with high potential\nfor future improvements. We demonstrate that a basic SMC Sampler with 512 cores\nis up to 85 times faster or up to 8 times more accurate than\nMetropolis-Hastings.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 14:25:37 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Varsi", "Alessandro", ""], ["Kekempanos", "Lykourgos", ""], ["Thiyagalingam", "Jeyarajan", ""], ["Maskell", "Simon", ""]]}, {"id": "1905.10270", "submitter": "Alexey Ilyushkin", "authors": "Alexey Ilyushkin, Andr\\'e Bauer, Alessandro V. Papadopoulos, Ewa\n  Deelman, Alexandru Iosup", "title": "Performance-Feedback Autoscaling with Budget Constraints for Cloud-based\n  Workloads of Workflows", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing popularity of workflows in the cloud domain promoted the\ndevelopment of sophisticated autoscaling policies that allow automatic\nallocation and deallocation of resources. However, many state-of-the-art\nautoscaling policies for workflows are mostly plan-based or designed for\nbatches (ensembles) of workflows. This reduces their flexibility when dealing\nwith workloads of workflows, as the workloads are often subject to\nunpredictable resource demand fluctuations. Moreover, autoscaling in clouds\nalmost always imposes budget constraints that should be satisfied. The\nbudget-aware autoscalers for workflows usually require task runtime estimates\nto be provided beforehand, which is not always possible when dealing with\nworkloads due to their dynamic nature. To address these issues, we propose a\nnovel Performance-Feedback Autoscaler (PFA) that is budget-aware and does not\nrequire task runtime estimates for its operation. Instead, it uses the\nperformance-feedback loop that monitors the average throughput on each resource\ntype. We implement PFA in the popular Apache Airflow workflow management\nsystem, and compare the performance of our autoscaler with other two\nstate-of-the-art autoscalers, and with the optimal solution obtained with the\nMixed Integer Programming approach. Our results show that PFA outperforms other\nconsidered online autoscalers, as it effectively minimizes the average job\nslowdown by up to 47% while still satisfying the budget constraints. Moreover,\nPFA shows by up to 76% lower average runtime than the competitors.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 15:02:57 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 15:30:07 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Ilyushkin", "Alexey", ""], ["Bauer", "Andr\u00e9", ""], ["Papadopoulos", "Alessandro V.", ""], ["Deelman", "Ewa", ""], ["Iosup", "Alexandru", ""]]}, {"id": "1905.10284", "submitter": "Michal Dory", "authors": "Nir Bachrach, Keren Censor-Hillel, Michal Dory, Yuval Efron, Dean\n  Leitersdorf, Ami Paz", "title": "Hardness of Distributed Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies lower bounds for fundamental optimization problems in the\nCONGEST model. We show that solving problems exactly in this model can be a\nhard task, by providing $\\tilde{\\Omega}(n^2)$ lower bounds for cornerstone\nproblems, such as minimum dominating set (MDS), Hamiltonian path, Steiner tree\nand max-cut. These are almost tight, since all of these problems can be solved\noptimally in $O(n^2)$ rounds. Moreover, we show that even in bounded-degree\ngraphs and even in simple graphs with maximum degree 5 and logarithmic\ndiameter, it holds that various tasks, such as finding a maximum independent\nset (MaxIS) or a minimum vertex cover, are still difficult, requiring a\nnear-tight number of $\\tilde{\\Omega}(n)$ rounds.\n  Furthermore, we show that in some cases even approximations are difficult, by\nproviding an $\\tilde{\\Omega}(n^2)$ lower bound for a\n$(7/8+\\epsilon)$-approximation for MaxIS, and a nearly-linear lower bound for\nan $O(\\log{n})$-approximation for the $k$-MDS problem for any constant $k \\geq\n2$, as well as for several variants of the Steiner tree problem.\n  Our lower bounds are based on a rich variety of constructions that leverage\nnovel observations, and reductions among problems that are specialized for the\nCONGEST model. However, for several additional approximation problems, as well\nas for exact computation of some central problems in $P$, such as maximum\nmatching and max flow, we show that such constructions cannot be designed, by\nwhich we exemplify some limitations of this framework.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 15:24:23 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Bachrach", "Nir", ""], ["Censor-Hillel", "Keren", ""], ["Dory", "Michal", ""], ["Efron", "Yuval", ""], ["Leitersdorf", "Dean", ""], ["Paz", "Ami", ""]]}, {"id": "1905.10336", "submitter": "Rekha Singhal Dr.", "authors": "Rekha Singhal, Nathan Zhang, Luigi Nardi, Muhammad Shahbaz, Kunle\n  Olukotun", "title": "Polystore++: Accelerated Polystore System for Heterogeneous Workloads", "comments": "11 pages, Accepted in ICDCS 2019", "journal-ref": "ICDCS 2019", "doi": null, "report-no": null, "categories": "cs.AR cs.DB cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern real-time business analytic consist of heterogeneous workloads (e.g,\ndatabase queries, graph processing, and machine learning). These analytic\napplications need programming environments that can capture all aspects of the\nconstituent workloads (including data models they work on and movement of data\nacross processing engines). Polystore systems suit such applications; however,\nthese systems currently execute on CPUs and the slowdown of Moore's Law means\nthey cannot meet the performance and efficiency requirements of modern\nworkloads. We envision Polystore++, an architecture to accelerate existing\npolystore systems using hardware accelerators (e.g, FPGAs, CGRAs, and GPUs).\nPolystore++ systems can achieve high performance at low power by identifying\nand offloading components of a polystore system that are amenable to\nacceleration using specialized hardware. Building a Polystore++ system is\nchallenging and introduces new research problems motivated by the use of\nhardware accelerators (e.g, optimizing and mapping query plans across\nheterogeneous computing units and exploiting hardware pipelining and\nparallelism to improve performance). In this paper, we discuss these challenges\nin detail and list possible approaches to address these problems.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 17:01:36 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Singhal", "Rekha", ""], ["Zhang", "Nathan", ""], ["Nardi", "Luigi", ""], ["Shahbaz", "Muhammad", ""], ["Olukotun", "Kunle", ""]]}, {"id": "1905.10395", "submitter": "Wenbo Gao", "authors": "Yunfei Teng, Wenbo Gao, Francois Chalus, Anna Choromanska, Donald\n  Goldfarb, Adrian Weller", "title": "Leader Stochastic Gradient Descent for Distributed Training of Deep\n  Learning Models", "comments": "NeurIPS 2019. 25 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider distributed optimization under communication constraints for\ntraining deep learning models. We propose a new algorithm, whose parameter\nupdates rely on two forces: a regular gradient step, and a corrective direction\ndictated by the currently best-performing worker (leader). Our method differs\nfrom the parameter-averaging scheme EASGD in a number of ways: (i) our\nobjective formulation does not change the location of stationary points\ncompared to the original optimization problem; (ii) we avoid convergence\ndecelerations caused by pulling local workers descending to different local\nminima to each other (i.e. to the average of their parameters); (iii) our\nupdate by design breaks the curse of symmetry (the phenomenon of being trapped\nin poorly generalizing sub-optimal solutions in symmetric non-convex\nlandscapes); and (iv) our approach is more communication efficient since it\nbroadcasts only parameters of the leader rather than all workers. We provide\ntheoretical analysis of the batch version of the proposed algorithm, which we\ncall Leader Gradient Descent (LGD), and its stochastic variant (LSGD). Finally,\nwe implement an asynchronous version of our algorithm and extend it to the\nmulti-leader setting, where we form groups of workers, each represented by its\nown local leader (the best performer in a group), and update each worker with a\ncorrective direction comprised of two attractive forces: one to the local, and\none to the global leader (the best performer among all workers). The\nmulti-leader setting is well-aligned with current hardware architecture, where\nlocal workers forming a group lie within a single computational node and\ndifferent groups correspond to different nodes. For training convolutional\nneural networks, we empirically demonstrate that our approach compares\nfavorably to state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 18:12:06 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 19:14:51 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Teng", "Yunfei", ""], ["Gao", "Wenbo", ""], ["Chalus", "Francois", ""], ["Choromanska", "Anna", ""], ["Goldfarb", "Donald", ""], ["Weller", "Adrian", ""]]}, {"id": "1905.10456", "submitter": "Meng Ma", "authors": "Meng Ma, Bingcong Li, Georgios B. Giannakis", "title": "Tight Linear Convergence Rate of ADMM for Decentralized Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper considers leveraging network topology information to\nimprove the convergence rate of ADMM for decentralized optimization, where\nnetworked nodes work collaboratively to minimize the objective. Such problems\ncan be solved efficiently using ADMM via decomposing the objective into easier\nsubproblems. Properly exploiting network topology can significantly improve the\nalgorithm performance. Hybrid ADMM explores the direction of exploiting node\ninformation by taking into account node centrality but fails to utilize edge\ninformation. This paper fills the gap by incorporating both node and edge\ninformation and provides a novel convergence rate bound for decentralized ADMM\nthat explicitly depends on network topology. Such a novel bound is attainable\nfor certain class of problems, thus tight. The explicit dependence further\nsuggests possible directions to optimal design of edge weights to achieve the\nbest performance. Numerical experiments show that simple heuristic methods\ncould achieve better performance, and also exhibits robustness to topology\nchanges.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 21:36:42 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Ma", "Meng", ""], ["Li", "Bingcong", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1905.10458", "submitter": "Suayb Arslan", "authors": "Suayb S. Arslan and Turguy Goker", "title": "Compress-Store on Blockchain: A Decentralized Data Processing and\n  Immutable Storage for Multimedia Streaming", "comments": "7 pages, 3 figures, 1 table, submitted to IEEE Transactions on\n  services computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralization for data storage is a challenging problem for\nblockchain-based solutions as the blocksize plays the key role for scalability.\nIn addition, specific requirements of multimedia data calls for various changes\nin the blockchain technology internals.Considering one of the most popular\napplications of secure multimedia streaming, i.e., video surveillance, it is\nnot clear how to judiciously encode incentivisation, immutability and\ncompression into a viable ecosystem. In this study, we provide a genuine scheme\nthat achieves this encoding for a video surveillance application. The proposed\nscheme provides a novel integration of data compression, immutable off-chain\ndata storage using a new consensus protocol namely, proof of work storage\n(PoWS) in order to enable fully useful work to be performed by the miner nodes\nof the network. The proposed idea is the first step towards achieving greener\napplication of blockchain-based environment to the video storage business that\nutilizes system resources efficiently.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 21:53:35 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Arslan", "Suayb S.", ""], ["Goker", "Turguy", ""]]}, {"id": "1905.10775", "submitter": "Yannic Maus", "authors": "Janosch Deurer, Fabian Kuhn, Yannic Maus", "title": "Deterministic Distributed Dominating Set Approximation in the CONGEST\n  Model", "comments": "added better reasoning in the proof of Lemma 3.12", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop deterministic approximation algorithms for the minimum dominating\nset problem in the CONGEST model with an almost optimal approximation\nguarantee. For $\\epsilon>1/{\\text{{poly}}}\\log \\Delta$ we obtain two algorithms\nwith approximation factor $(1+\\epsilon)(1+\\ln (\\Delta+1))$ and with runtimes\n$2^{O(\\sqrt{\\log n \\log\\log n})}$ and $O(\\Delta\\cdot\\text{poly}\\log \\Delta\n+\\text{poly}\\log \\Delta \\log^{*} n)$, respectively. Further we show how\ndominating set approximations can be deterministically transformed into a\nconnected dominating set in the \\CONGEST model while only increasing the\napproximation guarantee by a constant factor. This results in a deterministic\n$O(\\log \\Delta)$-approximation algorithm for the minimum connected dominating\nset with time complexity\n  $2^{O(\\sqrt{\\log n \\log\\log n})}$.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 10:02:35 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 08:58:36 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Deurer", "Janosch", ""], ["Kuhn", "Fabian", ""], ["Maus", "Yannic", ""]]}, {"id": "1905.10786", "submitter": "Zhaoguo Wang", "authors": "Zhaoguo Wang, Changgeng Zhao, Shuai Mu, Haibo Chen and Jinyang Li", "title": "On the parallels between Paxos and Raft, and how to port optimizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Raft has overtaken Paxos as the consensus algorithm of\nchoice. [53] While many have pointed out similarities between the two\nprotocols, no one has formally mapped out their relationships. In this paper,\nwe show how Raft and Paxos are formally related despite their surface\ndifferences. Based on the formal mapping between the two protocols, we show how\nto automatically port a certain class of optimizations from Paxos to Raft with\nguaranteed correctness. As case studies, we port and evaluate two\noptimizations, Mencius and Paxos Quorum Lease to Raft.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 11:06:25 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Wang", "Zhaoguo", ""], ["Zhao", "Changgeng", ""], ["Mu", "Shuai", ""], ["Chen", "Haibo", ""], ["Li", "Jinyang", ""]]}, {"id": "1905.10833", "submitter": "Michal Dory", "authors": "Michal Dory, Mohsen Ghaffari", "title": "Improved Distributed Approximations for Minimum-Weight\n  Two-Edge-Connected Spanning Subgraph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minimum-weight $2$-edge-connected spanning subgraph (2-ECSS) problem is a\nnatural generalization of the well-studied minimum-weight spanning tree (MST)\nproblem, and it has received considerable attention in the area of network\ndesign. The latter problem asks for a minimum-weight subgraph with an edge\nconnectivity of $1$ between each pair of vertices while the former strengthens\nthis edge-connectivity requirement to $2$. Despite this resemblance, the 2-ECSS\nproblem is considerably more complex than MST. While MST admits a linear-time\ncentralized exact algorithm, 2-ECSS is NP-hard and the best known centralized\napproximation algorithm for it (that runs in polynomial time) gives a\n$2$-approximation.\n  In this paper, we give a deterministic distributed algorithm with round\ncomplexity of $\\widetilde{O}(D+\\sqrt{n})$ that computes a\n$(5+\\epsilon)$-approximation of 2-ECSS, for any constant $\\epsilon>0$. Up to\nlogarithmic factors, this complexity matches the\n$\\widetilde{\\Omega}(D+\\sqrt{n})$ lower bound that can be derived from Das Sarma\net al. [STOC'11], as shown by Censor-Hillel and Dory [OPODIS'17]. Our result is\nthe first distributed constant approximation for 2-ECSS in the nearly optimal\ntime and it improves on a recent randomized algorithm of Dory [PODC'18], which\nachieved an $O(\\log n)$-approximation in $\\widetilde{O}(D+\\sqrt{n})$ rounds.\n  We also present an alternative algorithm for $O(\\log n)$-approximation, whose\nround complexity is linear in the low-congestion shortcut parameter of the\nnetwork, following a framework introduced by Ghaffari and Haeupler [SODA'16].\nThis algorithm has round complexity $\\widetilde{O}(D+\\sqrt{n})$ in worst-case\nnetworks but it provably runs much faster in many well-behaved graph families\nof interest. For instance, it runs in $\\widetilde{O}(D)$ time in planar\nnetworks and those with bounded genus, bounded path-width or bounded\ntree-width.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 16:37:22 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 11:49:00 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Dory", "Michal", ""], ["Ghaffari", "Mohsen", ""]]}, {"id": "1905.10895", "submitter": "Serguei Popov", "authors": "Serguei Popov and William J Buchanan", "title": "FPC-BI: Fast Probabilistic Consensus within Byzantine Infrastructures", "comments": "30 pages, 4 figures; final version", "journal-ref": "Journal of Parallel and Distributed Computing, Volume 147, January\n  2021, pages 77-86", "doi": "10.1016/j.jpdc.2020.09.002", "report-no": null, "categories": "cs.DC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel leaderless protocol (FPC-BI: Fast Probabilistic\nConsensus within Byzantine Infrastructures) with a low communicational\ncomplexity and which allows a set of nodes to come to a consensus on a value of\na single bit. The paper makes the assumption that part of the nodes are\nByzantine, and are thus controlled by an adversary who intends to either delay\nthe consensus, or break it (this defines that at least a couple of honest nodes\ncome to different conclusions). We prove that, nevertheless, the protocol works\nwith high probability when its parameters are suitably chosen. Along this the\npaper also provides explicit estimates on the probability that the protocol\nfinalizes in the consensus state in a given time. This protocol could be\napplied to reaching consensus in decentralized cryptocurrency systems. A\nspecial feature of it is that it makes use of a sequence of random numbers\nwhich are either provided by a trusted source or generated by the nodes\nthemselves using some decentralized random number generating protocol. This\nincreases the overall trustworthiness of the infrastructure. A core\ncontribution of the paper is that it uses a very weak consensus to obtain a\nstrong consensus on the value of a bit, and which can relate to the validity of\na transaction.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 22:14:10 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 20:10:38 GMT"}, {"version": "v3", "created": "Sun, 13 Sep 2020 08:22:53 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Popov", "Serguei", ""], ["Buchanan", "William J", ""]]}, {"id": "1905.10925", "submitter": "Yixin Li", "authors": "Yixin Li, Bin Cao, Mugen Peng, Long Zhang, Lei Zhang, Daquan Feng and\n  Jihong Yu", "title": "Direct Acyclic Graph based Ledger for Internet of Things: Performance\n  and Security Analysis", "comments": "accepted by IEEE Transactions on Networking", "journal-ref": null, "doi": "10.1109/TNET.2020.2991994", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct Acyclic Graph (DAG)-based ledger and the corresponding consensus\nalgorithm has been identified as a promising technology for Internet of Things\n(IoT). Compared with Proof-of-Work (PoW) and Proof-of-Stake (PoS) that have\nbeen widely used in blockchain, the consensus mechanism designed on DAG\nstructure (simply called as DAG consensus) can overcome some shortcomings such\nas high resource consumption, high transaction fee, low transaction throughput\nand long confirmation delay. However, the theoretic analysis on the DAG\nconsensus is an untapped venue to be explored. To this end, based on one of the\nmost typical DAG consensuses, Tangle, we investigate the impact of network load\non the performance and security of the DAG-based ledger. Considering unsteady\nnetwork load, we first propose a Markov chain model to capture the behavior of\nDAG consensus process under dynamic load conditions. The key performance\nmetrics, i.e., cumulative weight and confirmation delay are analysed based on\nthe proposed model. Then, we leverage a stochastic model to analyse the\nprobability of a successful double-spending attack in different network load\nregimes. The results can provide an insightful understanding of DAG consensus\nprocess, e.g., how the network load affects the confirmation delay and the\nprobability of a successful attack. Meanwhile, we also demonstrate the\ntrade-off between security level and confirmation delay, which can act as a\nguidance for practical deployment of DAG-based ledgers.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 01:30:16 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 14:01:38 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Li", "Yixin", ""], ["Cao", "Bin", ""], ["Peng", "Mugen", ""], ["Zhang", "Long", ""], ["Zhang", "Lei", ""], ["Feng", "Daquan", ""], ["Yu", "Jihong", ""]]}, {"id": "1905.10936", "submitter": "Shuai Zheng", "authors": "Shuai Zheng and Ziyue Huang and James T. Kwok", "title": "Communication-Efficient Distributed Blockwise Momentum SGD with\n  Error-Feedback", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication overhead is a major bottleneck hampering the scalability of\ndistributed machine learning systems. Recently, there has been a surge of\ninterest in using gradient compression to improve the communication efficiency\nof distributed neural network training. Using 1-bit quantization, signSGD with\nmajority vote achieves a 32x reduction on communication cost. However, its\nconvergence is based on unrealistic assumptions and can diverge in practice. In\nthis paper, we propose a general distributed compressed SGD with Nesterov's\nmomentum. We consider two-way compression, which compresses the gradients both\nto and from workers. Convergence analysis on nonconvex problems for general\ngradient compressors is provided. By partitioning the gradient into blocks, a\nblockwise compressor is introduced such that each gradient block is compressed\nand transmitted in 1-bit format with a scaling factor, leading to a nearly 32x\nreduction on communication. Experimental results show that the proposed method\nconverges as fast as full-precision distributed momentum SGD and achieves the\nsame testing accuracy. In particular, on distributed ResNet training with 7\nworkers on the ImageNet, the proposed algorithm achieves the same testing\naccuracy as momentum SGD using full-precision gradients, but with $46\\%$ less\nwall clock time.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 02:16:42 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 06:53:56 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Zheng", "Shuai", ""], ["Huang", "Ziyue", ""], ["Kwok", "James T.", ""]]}, {"id": "1905.11055", "submitter": "Christina Delimitrou", "authors": "Yu Gan, Yanqi Zhang, Dailun Cheng, Ankitha Shetty, Priyal Rathi, Nayan\n  Katarki, Ariana Bruno, Justin Hu, Brian Ritchken, Brendon Jackson, Kelvin Hu,\n  Meghna Pancholi, Yuan He, Brett Clancy, Chris Colen, Fukang Wen, Catherine\n  Leung, Siyuan Wang, Leon Zaruvinsky, Mateo Espinosa, Rick Lin, Zhongling Liu,\n  Jake Padilla, and Christina Delimitrou", "title": "An Open-Source Benchmark Suite for Cloud and IoT Microservices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud services have recently started undergoing a major shift from monolithic\napplications, to graphs of hundreds of loosely-coupled microservices.\nMicroservices fundamentally change a lot of assumptions current cloud systems\nare designed with, and present both opportunities and challenges when\noptimizing for quality of service (QoS) and utilization. In this paper we\nexplore the implications microservices have across the cloud system stack. We\nfirst present DeathStarBench, a novel, open-source benchmark suite built with\nmicroservices that is representative of large end-to-end services, modular and\nextensible. DeathStarBench includes a social network, a media service, an\ne-commerce site, a banking system, and IoT applications for coordination\ncontrol of UAV swarms. We then use DeathStarBench to study the architectural\ncharacteristics of microservices, their implications in networking and\noperating systems, their challenges with respect to cluster management, and\ntheir trade-offs in terms of application design and programming frameworks.\nFinally, we explore the tail at scale effects of microservices in real\ndeployments with hundreds of users, and highlight the increased pressure they\nput on performance predictability.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 09:03:18 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Gan", "Yu", ""], ["Zhang", "Yanqi", ""], ["Cheng", "Dailun", ""], ["Shetty", "Ankitha", ""], ["Rathi", "Priyal", ""], ["Katarki", "Nayan", ""], ["Bruno", "Ariana", ""], ["Hu", "Justin", ""], ["Ritchken", "Brian", ""], ["Jackson", "Brendon", ""], ["Hu", "Kelvin", ""], ["Pancholi", "Meghna", ""], ["He", "Yuan", ""], ["Clancy", "Brett", ""], ["Colen", "Chris", ""], ["Wen", "Fukang", ""], ["Leung", "Catherine", ""], ["Wang", "Siyuan", ""], ["Zaruvinsky", "Leon", ""], ["Espinosa", "Mateo", ""], ["Lin", "Rick", ""], ["Liu", "Zhongling", ""], ["Padilla", "Jake", ""], ["Delimitrou", "Christina", ""]]}, {"id": "1905.11360", "submitter": "Zeta Avarikioti", "authors": "Georgia Avarikioti, Eleftherios Kokoris Kogias, Roger Wattenhofer,\n  Dionysis Zindros", "title": "Brick: Asynchronous Payment Channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-chain protocols (channels) are a promising solution to the scalability\nand privacy challenges of blockchain payments. Current proposals, however,\nrequire synchrony assumptions to preserve the safety of a channel, leaking to\nan adversary the exact amount of time needed to control the network for a\nsuccessful attack. In this paper, we introduce Brick, the first payment channel\nthat remains secure under network asynchrony and concurrently provides correct\nincentives. The core idea is to incorporate the conflict resolution process\nwithin the channel by introducing a rational committee of external parties,\ncalled Wardens. Hence, if a party wants to close a channel unilaterally, it can\nonly get the committee's approval for the last valid state. Brick provides\nsub-second latency because it does not employ heavy-weight consensus. Instead,\nBrick uses consistent broadcast to announce updates and close the channel, a\nlight-weight abstraction that is powerful enough to preserve safety and\nliveness to any rational parties. Furthermore, we consider permissioned\nblockchains, where the additional property of auditability might be desired for\nregulatory purposes. We introduce Brick+, an off-chain construction that\nprovides auditability on top of Brick without conflicting with its privacy\nguarantees. We formally define the properties our payment channel construction\nshould fulfill, and prove that both Brick and Brick+ satisfy them. We also\ndesign incentives for Brick such that honest and rational behavior aligns.\nFinally, we provide a reference implementation of the smart contracts in\nSolidity.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 17:45:49 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 14:14:22 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 13:36:46 GMT"}, {"version": "v4", "created": "Fri, 19 Jun 2020 15:12:09 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Avarikioti", "Georgia", ""], ["Kogias", "Eleftherios Kokoris", ""], ["Wattenhofer", "Roger", ""], ["Zindros", "Dionysis", ""]]}, {"id": "1905.11394", "submitter": "Hadrien Hendrikx", "authors": "Hadrien Hendrikx, Francis Bach and Laurent Massoulie", "title": "An Accelerated Decentralized Stochastic Proximal Algorithm for Finite\n  Sums", "comments": "Code available in source files. arXiv admin note: substantial text\n  overlap with arXiv:1901.09865", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern large-scale finite-sum optimization relies on two key aspects:\ndistribution and stochastic updates. For smooth and strongly convex problems,\nexisting decentralized algorithms are slower than modern accelerated\nvariance-reduced stochastic algorithms when run on a single machine, and are\ntherefore not efficient. Centralized algorithms are fast, but their scaling is\nlimited by global aggregation steps that result in communication bottlenecks.\nIn this work, we propose an efficient \\textbf{A}ccelerated\n\\textbf{D}ecentralized stochastic algorithm for \\textbf{F}inite \\textbf{S}ums\nnamed ADFS, which uses local stochastic proximal updates and randomized\npairwise communications between nodes. On $n$ machines, ADFS learns from $nm$\nsamples in the same time it takes optimal algorithms to learn from $m$ samples\non one machine. This scaling holds until a critical network size is reached,\nwhich depends on communication delays, on the number of samples $m$, and on the\nnetwork topology. We provide a theoretical analysis based on a novel augmented\ngraph approach combined with a precise evaluation of synchronization times and\nan extension of the accelerated proximal coordinate gradient algorithm to\narbitrary sampling. We illustrate the improvement of ADFS over state-of-the-art\ndecentralized approaches with experiments.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 11:16:01 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 06:16:24 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Hendrikx", "Hadrien", ""], ["Bach", "Francis", ""], ["Massoulie", "Laurent", ""]]}, {"id": "1905.11549", "submitter": "Xin Zhang", "authors": "Xin Zhang, Jia Liu, Zhengyuan Zhu", "title": "Distributed Linear Model Clustering over Networks: A Tree-Based\n  Fused-Lasso ADMM Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG cs.NI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider to improve the model estimation efficiency by\naggregating the neighbors' information as well as identify the subgroup\nmembership for each node in the network. A tree-based $l_1$ penalty is proposed\nto save the computation and communication cost. We design a decentralized\ngeneralized alternating direction method of multiplier algorithm for solving\nthe objective function in parallel. The theoretical properties are derived to\nguarantee both the model consistency and the algorithm convergence. Thorough\nnumerical experiments are also conducted to back up our theory, which also show\nthat our approach outperforms in the aspects of the estimation accuracy,\ncomputation speed and communication cost.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 00:40:01 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Zhang", "Xin", ""], ["Liu", "Jia", ""], ["Zhu", "Zhengyuan", ""]]}, {"id": "1905.11573", "submitter": "Philipp Bamberger", "authors": "Philipp Bamberger, Mohsen Ghaffari, Fabian Kuhn, Yannic Maus, Jara\n  Uitto", "title": "On the Complexity of Distributed Splitting Problems", "comments": null, "journal-ref": null, "doi": "10.1145/3293611.3331630", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the fundamental open problems in the area of distributed graph\nalgorithms is the question of whether randomization is needed for efficient\nsymmetry breaking. While there are fast, $\\text{poly}\\log n$-time randomized\ndistributed algorithms for all of the classic symmetry breaking problems, for\nmany of them, the best deterministic algorithms are almost exponentially\nslower. The following basic local splitting problem, which is known as the\n\\emph{weak splitting} problem takes a central role in this context: Each node\nof a graph $G=(V,E)$ has to be colored red or blue such that each node of\nsufficiently large degree has at least one node of each color among its\nneighbors. Ghaffari, Kuhn, and Maus [STOC '17] showed that this seemingly\nsimple problem is complete w.r.t. the above fundamental open question in the\nfollowing sense: If there is an efficient $\\text{poly}\\log n$-time determinstic\ndistributed algorithm for weak splitting, then there is such an algorithm for\nall locally checkable graph problems for which an efficient randomized\nalgorithm exists. In this paper, we investigate the distributed complexity of\nweak splitting and some closely related problems. E.g., we obtain efficient\nalgorithms for special cases of weak splitting, where the graph is nearly\nregular. In particular, we show that if $\\delta$ and $\\Delta$ are the minimum\nand maximum degrees of $G$ and if $\\delta=\\Omega(\\log n)$, weak splitting can\nbe solved deterministically in time\n$O\\big(\\frac{\\Delta}{\\delta}\\cdot\\text{poly}(\\log n)\\big)$. Further, if $\\delta\n= \\Omega(\\log\\log n)$ and $\\Delta\\leq 2^{\\varepsilon\\delta}$, there is a\nrandomized algorithm with time complexity\n$O\\big(\\frac{\\Delta}{\\delta}\\cdot\\text{poly}(\\log\\log n)\\big)$.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 02:18:53 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Bamberger", "Philipp", ""], ["Ghaffari", "Mohsen", ""], ["Kuhn", "Fabian", ""], ["Maus", "Yannic", ""], ["Uitto", "Jara", ""]]}, {"id": "1905.11607", "submitter": "Rida Bazzi", "authors": "Rida Bazzi and Maurice Herlihy", "title": "Clairvoyant State Machine Replication", "comments": "21 pages including 6 figures. An earlier version appeared in SSS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new protocol for the generalized consensus problem in\nasynchronous systems subject to Byzantine server failures. The protocol solves\nthe consensus problem in a setting in which information about conflict between\ntransactions is available (such information can be in the form of transaction\nread and write sets). Unlike most prior proposals (for generalized or classical\nconsensus), which use a leader to order transactions, this protocol is\nleaderless, and relies on non-skipping timestamps for transaction ordering.\nBeing leaderless, the protocol does not need to pause for leader elections. The\nuse of non-skipping timestamps permits servers to commit transactions as soon\nas they know that no conflicting transaction can be ordered earlier. For n\nservers of which f may be faulty, this protocol requires n > 4f.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 04:46:21 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Bazzi", "Rida", ""], ["Herlihy", "Maurice", ""]]}, {"id": "1905.11707", "submitter": "Igor Ivkic", "authors": "Roland Pellegrini, Igor Ivkic and Markus Tauber", "title": "Function-as-a-Service Benchmarking Framework", "comments": "https://www.scitepress.org/PublicationsDetail.aspx?ID=Df3810DssWw=&t=1", "journal-ref": null, "doi": "10.5220/0007757304790487", "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud Service Providers deliver their products in form of 'as-a-Service',\nwhich are typically categorized by the level of abstraction. This approach\nhides the implementation details and shows only functionality to the user.\nHowever, the problem is that it is hard to measure the performance of Cloud\nservices, because they behave like black boxes. Especially with\nFunction-as-a-Service it is even more difficult because it completely hides\nserver and infrastructure management from users by design. Cloud Service\nProdivers usually restrict the maximum size of code, memory and runtime of\nCloud Functions. Nevertheless, users need clarification if more ressources are\nneeded to deliver services in high quality. In this regard, we present the\narchitectural design of a new Function-as-a-Service benchmarking tool, which\nallows users to evaluate the performance of Cloud Functions. Furthermore, the\ncapabilities of the framework are tested on an isolated platform with a\nspecific workload. The results show that users are able to get insights into\nFunction-as-a-Service environments. This, in turn, allows users to identify\nfactors which may slow down or speed up the performance of Cloud Functions.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 09:41:17 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Pellegrini", "Roland", ""], ["Ivkic", "Igor", ""], ["Tauber", "Markus", ""]]}, {"id": "1905.11762", "submitter": "Tadeusz Kobus", "authors": "Maciej Kokoci\\'nski, Tadeusz Kobus, Pawe{\\l} T. Wojciechowski", "title": "On Mixing Eventual and Strong Consistency: Acute Cloud Types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we study the properties of distributed systems that mix\neventual and strong consistency. We formalize such systems through acute cloud\ntypes (ACTs), abstractions similar to conflict-free replicated data types\n(CRDTs), which by default work in a highly available, eventually consistent\nfashion, but which also feature strongly consistent operations for tasks which\nrequire global agreement. Unlike other mixed-consistency solutions, ACTs can\nrely on efficient quorum-based protocols, such as Paxos. Hence, ACTs gracefully\ntolerate machine and network failures also for the strongly consistent\noperations. We formally study ACTs and demonstrate phenomena which are neither\npresent in purely eventually consistent nor strongly consistent systems. In\nparticular, we identify temporary operation reordering, which implies interim\ndisagreement between replicas on the relative order in which the client\nrequests were executed. When not handled carefully, this phenomenon may lead to\nundesired anomalies, including circular causality. We prove an impossibility\nresult which states that temporary operation reordering is unavoidable in\nmixed-consistency systems with sufficiently complex semantics. Our result is\nstartling, because it shows that apparent strengthening of the semantics of a\nsystem (by introducing strongly consistent operations to an eventually\nconsistent system) results in the weakening of the guarantees on the eventually\nconsistent operations.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 12:09:25 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 11:37:54 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Kokoci\u0144ski", "Maciej", ""], ["Kobus", "Tadeusz", ""], ["Wojciechowski", "Pawe\u0142 T.", ""]]}, {"id": "1905.11962", "submitter": "Dominik Kaaser", "authors": "Petra Berenbrink and Dominik Kaaser and Tomasz Radzik", "title": "On Counting the Population Size", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of counting the population size in the population\nmodel. In this model, we are given a distributed system of $n$ identical agents\nwhich interact in pairs with the goal to solve a common task. In each time\nstep, the two interacting agents are selected uniformly at random. In this\npaper, we consider so-called uniform protocols, where the actions of two agents\nupon an interaction may not depend on the population size $n$. We present two\npopulation protocols to count the size of the population: protocol Approximate,\nwhich computes with high probability either $\\lfloor\\log n\\rfloor$ or\n$\\lceil\\log n\\rceil$, and protocol CountExact, which computes the exact\npopulation size in optimal $\\operatorname{O}({n\\log{n}})$ interactions, using\n$\\tilde{\\operatorname{O}}({n})$ states. Both protocols can also be converted to\nstable protocols that give a correct result with probability $1$ by using an\nadditional multiplicative factor of $\\operatorname{O}({\\log{n}})$ states.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 17:35:18 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Berenbrink", "Petra", ""], ["Kaaser", "Dominik", ""], ["Radzik", "Tomasz", ""]]}, {"id": "1905.12063", "submitter": "Constantin Enea", "authors": "Hagit Attiya and Constantin Enea", "title": "Putting Strong Linearizability in Context: Preserving Hyperproperties in\n  Programs that Use Concurrent Objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been observed that linearizability, the prevalent consistency\ncondition for implementing concurrent objects, does not preserve some\nprobability distributions. A stronger condition, called strong linearizability\nhas been proposed, but its study has been somewhat ad-hoc. This paper\ninvestigates strong linearizability by casting it in the context of\nobservational refinement of objects. We present a strengthening of\nobservational refinement, which generalizes strong linearizability, obtaining\nseveral important implications.\n  When a concrete concurrent object refining another, more abstract object -\noften sequential - the correctness of a program employing the concrete object\ncan be verified by considering its behaviors when using the more abstract\nobject. This means that trace properties of a program using the concrete object\ncan be proved by considering the program with the abstract object. This,\nhowever, does not hold for hyperproperties, including many security properties\nand probability distributions of events.\n  We define strong observational refinement, a strengthening of refinement that\npreserves hyperproperties, and prove that it is equivalent to the existence of\nforward simulations. We show that strong observational refinement generalizes\nstrong linearizability. This implies that strong linearizability is also\nequivalent to forward simulation, and shows that strongly linearizable\nimplementations can be composed both horizontally (i.e., locality) and\nvertically (i.e., with instantiation).\n  For situations where strongly linearizable implementations do not exist (or\nare less efficient), we argue that reasoning about hyperproperties of programs\ncan be simplified by strong observational refinement of abstract objects that\nare not necessarily sequential.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 20:10:41 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Attiya", "Hagit", ""], ["Enea", "Constantin", ""]]}, {"id": "1905.12143", "submitter": "Naama Ben-David", "authors": "Marcos K. Aguilera, Naama Ben-David, Rachid Guerraoui, Virendra\n  Marathe, Igor Zablotchi", "title": "The Impact of RDMA on Agreement", "comments": "Full version of PODC'19 paper, strengthened broadcast algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remote Direct Memory Access (RDMA) is becoming widely available in data\ncenters. This technology allows a process to directly read and write the memory\nof a remote host, with a mechanism to control access permissions. In this\npaper, we study the fundamental power of these capabilities. We consider the\nwell-known problem of achieving consensus despite failures, and find that RDMA\ncan improve the inherent trade-off in distributed computing between failure\nresilience and performance. Specifically, we show that RDMA allows algorithms\nthat simultaneously achieve high resilience and high performance, while\ntraditional algorithms had to choose one or another. With Byzantine failures,\nwe give an algorithm that only requires $n \\geq 2f_P + 1$ processes (where\n$f_P$ is the maximum number of faulty processes) and decides in two (network)\ndelays in common executions. With crash failures, we give an algorithm that\nonly requires $n \\geq f_P + 1$ processes and also decides in two delays. Both\nalgorithms tolerate a minority of memory failures inherent to RDMA, and they\nprovide safety in asynchronous systems and liveness with standard additional\nassumptions.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 00:26:25 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 18:50:01 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Aguilera", "Marcos K.", ""], ["Ben-David", "Naama", ""], ["Guerraoui", "Rachid", ""], ["Marathe", "Virendra", ""], ["Zablotchi", "Igor", ""]]}, {"id": "1905.12351", "submitter": "Victor Cook", "authors": "Victor Cook, Zachary Painter, Christina Peterson, Damian Dechev", "title": "Read-Uncommitted Transactions for Smart Contract Performance", "comments": "Accepted to ICDCS 2019, Dallas, Texas.\n  https://theory.utdallas.edu/ICDCS2019/program.html#Session%202F 10 pages, 3\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart contract transactions demonstrate issues of performance and correctness\nthat application programmers must work around. Although the blockchain\nconsensus mechanism approaches ACID compliance, use cases that rely on frequent\nstate changes are impractical due to the block publishing interval of $O(10^1)$\nseconds. The effective isolation level is Read-Committed, only revealing state\ntransitions at the end of the block interval. Values read may be stale and not\nmatch program order, causing many transactions to fail when a block is\ncommitted. This paper perceives the blockchain as a transactional data\nstructure, using this analogy in the development of a new algorithm,\nHash-Mark-Set (HMS), that improves transaction throughput by providing a\nRead-Uncommitted view of state variables. HMS creates a directed acyclic graph\n(DAG) from the pending transaction pool. The transaction order derived from the\nDAG is used to provide a Read-Uncommitted view of the data for new\ntransactions, which enter the DAG as they are received. An implementation of\nHMS is provided, interoperable with Ethereum and ready for use in smart\ncontracts. Over a wide range of transaction mixes, HMS is demonstrated to\nimprove throughput. A side product of the implementation is a new technique,\nRuntime Argument Augmentation (RAA), that allows smart contracts to communicate\nwith external data services before submitting a transaction. RAA has use cases\nbeyond HMS and can serve as a lightweight replacement for blockchain oracles.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 12:00:14 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Cook", "Victor", ""], ["Painter", "Zachary", ""], ["Peterson", "Christina", ""], ["Dechev", "Damian", ""]]}, {"id": "1905.12465", "submitter": "Dave McEwan", "authors": "Dave McEwan and Jose Nunez-Yanez", "title": "Relationship Estimation Metrics for Binary SoC Data", "comments": "11 pages, 9 figures, LOD2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  System-on-Chip (SoC) designs are used in every aspect of computing and their\noptimization is a difficult but essential task in today's competitive market.\nData taken from SoCs to achieve this is often characterised by very long\nconcurrent bit vectors which have unknown relationships to each other. This\npaper explains and empirically compares the accuracy of several methods used to\ndetect the existence of these relationships in a wide range of systems. A\nprobabilistic model is used to construct and test a large number of SoC-like\nsystems with known relationships which are compared with the estimated\nrelationships to give accuracy scores. The metrics \\.Cov and \\.Dep based on\ncovariance and independence are demonstrated to be the most useful, whereas\nmetrics based on the Hamming distance and geometric approaches are shown to be\nless useful for detecting the presence of relationships between SoC data.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 14:47:03 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 10:48:48 GMT"}, {"version": "v3", "created": "Tue, 24 Sep 2019 10:58:03 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["McEwan", "Dave", ""], ["Nunez-Yanez", "Jose", ""]]}, {"id": "1905.12468", "submitter": "Robert Sch\\\"one", "authors": "Robert Sch\\\"one, Thomas Ilsche, Mario Bielert, Andreas Gocht, Daniel\n  Hackenberg", "title": "Energy Efficiency Features of the Intel Skylake-SP Processor and Their\n  Impact on Performance", "comments": "8 pages, HPCS2019, HPBench, READEX, HAEC, Horizon2020, H2020 grant\n  agreement number 671657, DFG, CRC 912", "journal-ref": null, "doi": "10.1109/HPCS48598.2019.9188239", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overwhelming majority of High Performance Computing (HPC) systems and\nserver infrastructure uses Intel x86 processors. This makes an architectural\nanalysis of these processors relevant for a wide audience of administrators and\nperformance engineers. In this paper, we describe the effects of hardware\ncontrolled energy efficiency features for the Intel Skylake-SP processor. Due\nto the prolonged micro-architecture cycles, which extend the previous Tick-Tock\nscheme by Intel, our findings will also be relevant for succeeding\narchitectures. The findings of this paper include the following: C-state\nlatencies increased significantly over the Haswell-EP processor generation. The\nmechanism that controls the uncore frequency has a latency of approximately 10\nms and it is not possible to truly fix the uncore frequency to a specific\nlevel. The out-of-order throttling for workloads using 512 bit wide vectors\nalso occurs at low processor frequencies. Data has a significant impact on\nprocessor power consumption which causes a large error in energy models relying\nonly on instructions.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 12:08:50 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 08:40:54 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Sch\u00f6ne", "Robert", ""], ["Ilsche", "Thomas", ""], ["Bielert", "Mario", ""], ["Gocht", "Andreas", ""], ["Hackenberg", "Daniel", ""]]}, {"id": "1905.12652", "submitter": "Joerg Evermann", "authors": "Joerg Evermann and Henry Kim", "title": "Workflow Management on BFT Blockchains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Blockchain technology has been proposed as a new infrastructure technology\nfor a wide variety of novel applications. Blockchains provide an immutable\nrecord of transactions, making them useful when business actors do not trust\neach other. Their distributed nature makes them suitable for\ninter-organizational applications. However, proof-of-work based blockchains are\ncomputationally inefficient and do not provide final consensus, although they\nscale well to large networks. In contrast, blockchains built around Byzantine\nFault Tolerance (BFT) algorithms are more efficient and provide immediate and\nfinal consensus, but do not scale well to large networks. We argue that this\nmakes them well-suited for workflow management applications that typically\ninclude no more than a few dozen participants but require final consensus. In\nthis paper, we discuss architectural options and present a prototype\nimplementation of a BFT-blockchain-based workflow management system (WfMS).\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 18:03:36 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 14:24:27 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Evermann", "Joerg", ""], ["Kim", "Henry", ""]]}, {"id": "1905.12720", "submitter": "Val\\'erie Hayot-Sasson", "authors": "Valerie Hayot-Sasson and Tristan Glatard", "title": "Evaluation of pilot jobs for Apache Spark applications on HPC clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Big Data has become prominent throughout many scientific fields and, as a\nresult, scientific communities have sought out Big Data frameworks to\naccelerate the processing of their increasingly data-intensive pipelines.\nHowever, while scientific communities typically rely on High-Performance\nComputing (HPC) clusters for the parallelization of their pipelines, many\npopular Big Data frameworks such as Hadoop and Apache Spark were primarily\ndesigned to be executed on dedicated commodity infrastructures. This paper\nevaluates the benefits of pilot jobs over traditional batch submission for\nApache Spark on HPC clusters. Surprisingly, our results show that the speed-up\nprovided by pilot jobs over batch scheduling is moderate to inexistent (0.98 on\naverage) despite the presence of long queuing times. In addition, pilot jobs\nprovide an extra layer of scheduling that complexifies debugging and\ndeployment. We conclude that traditional batch scheduling should remain the\ndefault strategy to deploy Apache Spark applications on HPC clusters.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 20:55:50 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Hayot-Sasson", "Valerie", ""], ["Glatard", "Tristan", ""]]}, {"id": "1905.12755", "submitter": "Aniket Shivam", "authors": "Aniket Shivam, Alexandru Nicolau, Alexander V. Veidenbaum", "title": "MCompiler: A Synergistic Compilation Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a meta-compilation framework, the MCompiler. The main\nidea is that different segments of a program can be compiled with different\ncompilers/optimizers and combined into a single executable. The MCompiler can\nbe used in a number of ways. It can generate an executable with higher\nperformance than any individual compiler, because each compiler uses a\nspecific, ordered set of optimization techniques and different profitability\nmodels and can, therefore, generate code significantly different from other\ncompilers. Alternatively, the MCompiler can be used by researchers and compiler\ndevelopers to evaluate their compiler implementation and compare it to results\nfrom other available compilers/optimizers.\n  A code segment in this work is a loop nest, but other choices are possible.\nThis work also investigates the use of Machine Learning to learn inherent\ncharacteristics of loop nests and then predict during compilation the most\nsuited code optimizer for each loop nest in an application. This reduces the\nneed for profiling applications as well as the compilation time.\n  The results show that our framework improves the overall performance for\napplications over state-of-the-art compilers by a geometric mean of 1.96x for\nauto-vectorized code and 2.62x for auto-parallelized code. Parallel\napplications with OpenMP directives are also improved by the MCompiler, with a\ngeometric mean performance improvement of 1.04x (up to 1.74x). The use of\nMachine Learning prediction achieves performance very close to the\nprofiling-based search for choosing the most suited code optimizer: within 4%\nfor auto-vectorized code and within 8% for auto-parallelized code. Finally, the\nMCompiler can be expanded to collect metrics other than performance to be used\nin optimization process. The example presented is collecting energy data.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 22:24:18 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Shivam", "Aniket", ""], ["Nicolau", "Alexandru", ""], ["Veidenbaum", "Alexander V.", ""]]}, {"id": "1905.12795", "submitter": "Navjot Kukreja", "authors": "Oscar F. Mojica, Navjot Kukreja", "title": "Towards automatically building starting models for full-waveform\n  inversion using global optimization methods: A PSO approach via DEAP + Devito", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.DC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this work, we illustrate an example of estimating the macro-model of\nvelocities in the subsurface through the use of global optimization methods\n(GOMs). The optimization problem is solved using DEAP (Distributed Evolutionary\nAlgorithms in Python) and Devito, python frameworks for evolutionary and\nautomated finite difference computations, respectively. We implement a Particle\nswarm optimization (PSO) with an \"elitism strategy\" on top of DEAP, leveraging\nits transparent, simple and coherent environment for implementing of\nevolutionary algorithms (EAs). The high computational effort, due to the huge\nnumber of cost function evaluations (each one demanding a forward modeling\nstep) required by PSO, is alleviated through the use of Devito as well as\nthrough parallelization with Dask. The combined use of these frameworks yields\nnot only an efficient way of providing acoustic macro models of the P-wave\nvelocity field (Vp), but also significantly reduces the amount of human effort\nin fulfilling this task.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 00:19:15 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Mojica", "Oscar F.", ""], ["Kukreja", "Navjot", ""]]}, {"id": "1905.12800", "submitter": "Juan Galvis", "authors": "Juan Galvis", "title": "On condition numbers of symmetric and nonsymmetric domain decomposition\n  methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using oblique projections and angles between subspaces we write condition\nnumber estimates for abstract nonsymmetric domain decomposition methods. In\nparticular, we consider a restricted additive method for the Poisson equation\nand write a bound for the condition number of the preconditioned operator. We\nalso obtain the non-negativity of the preconditioned operator. Condition number\nestimates are not enough for the convergence of iterative methods such as GMRES\nbut these bounds may lead to further understanding of nonsymmetric domain\ndecomposition methods.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 00:38:14 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 03:36:40 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Galvis", "Juan", ""]]}, {"id": "1905.13002", "submitter": "Simo S\\\"arkk\\\"a", "authors": "Simo S\\\"arkk\\\"a and \\'Angel F. Garc\\'ia-Fern\\'andez", "title": "Temporal Parallelization of Bayesian Smoothers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.DC math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents algorithms for temporal parallelization of Bayesian\nsmoothers. We define the elements and the operators to pose these problems as\nthe solutions to all-prefix-sums operations for which efficient parallel\nscan-algorithms are available. We present the temporal parallelization of the\ngeneral Bayesian filtering and smoothing equations and specialize them to\nlinear/Gaussian models. The advantage of the proposed algorithms is that they\nreduce the linear complexity of standard smoothing algorithms with respect to\ntime to logarithmic.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 12:42:26 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 07:40:55 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["S\u00e4rkk\u00e4", "Simo", ""], ["Garc\u00eda-Fern\u00e1ndez", "\u00c1ngel F.", ""]]}, {"id": "1905.13064", "submitter": "Lum Ramabaja", "authors": "Lum Ramabaja", "title": "The Bloom Clock", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bloom clock is a space-efficient, probabilistic data structure designed\nto determine the partial order of events in highly distributed systems. The\nbloom clock, like the vector clock, can autonomously detect causality\nviolations by comparing its logical timestamps. Unlike the vector clock, the\nspace complexity of the bloom clock does not depend on the number of nodes in a\nsystem. Instead it depends on a set of chosen parameters that determine its\nconfidence interval, i.e. false positive rate. To reduce the space complexity\nfrom which the vector clock suffers, the bloom clock uses a 'moving window' in\nwhich the partial order of events can be inferred with high confidence. If two\nclocks are not comparable, the bloom clock can always deduce it, i.e. false\nnegatives are not possible. If two clocks are comparable, the bloom clock can\ncalculate the confidence of that statement, i.e. it can compute the false\npositive rate between comparable pairs of clocks. By choosing an acceptable\nthreshold for the false positive rate, the bloom clock can properly compare the\norder of its timestamps, with that of other nodes in a highly accurate and\nspace efficient way.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 14:12:03 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 15:24:04 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 20:28:45 GMT"}, {"version": "v4", "created": "Sun, 9 Jun 2019 19:51:19 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Ramabaja", "Lum", ""]]}, {"id": "1905.13135", "submitter": "Katy Williams", "authors": "Katy Williams, Alex Bigelow, Katherine E. Isaacs", "title": "Visualizing a Moving Target: A Design Study on Task Parallel Programs in\n  the Presence of Evolving Data and Concerns", "comments": "IEEE VIS InfoVis 2019", "journal-ref": null, "doi": "10.1109/TVCG.2019.2934285", "report-no": null, "categories": "cs.HC cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common pitfalls in visualization projects include lack of data availability\nand the domain users' needs and focus changing too rapidly for the design\nprocess to complete. While it is often prudent to avoid such projects, we argue\nit can be beneficial to engage them in some cases as the visualization process\ncan help refine data collection, solving a \"chicken and egg\" problem of having\nthe data and tools to analyze it. We found this to be the case in the domain of\ntask parallel computing where such data and tooling is an open area of\nresearch. Despite these hurdles, we conducted a design study. Through a\ntightly-coupled iterative design process, we built Atria, a multi-view\nexecution graph visualization to support performance analysis. Atria simplifies\nthe initial representation of the execution graph by aggregating nodes as\nrelated to their line of code. We deployed Atria on multiple platforms, some\nrequiring design alteration. We describe how we adapted the design study\nmethodology to the \"moving target\" of both the data and the domain experts'\nconcerns and how this movement kept both the visualization and programming\nproject healthy. We reflect on our process and discuss what factors allow the\nproject to be successful in the presence of changing data and user needs.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 16:01:13 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 18:26:05 GMT"}, {"version": "v3", "created": "Mon, 7 Oct 2019 18:29:54 GMT"}, {"version": "v4", "created": "Tue, 15 Oct 2019 17:34:03 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Williams", "Katy", ""], ["Bigelow", "Alex", ""], ["Isaacs", "Katherine E.", ""]]}, {"id": "1905.13348", "submitter": "Qian Li", "authors": "Francisco Romero, Qian Li, Neeraja J. Yadwadkar, Christos Kozyrakis", "title": "INFaaS: A Model-less and Managed Inference Serving System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite existing work in machine learning inference serving, ease-of-use and\ncost efficiency remain challenges at large scales. Developers must manually\nsearch through thousands of model-variants -- versions of already-trained\nmodels that differ in hardware, resource footprints, latencies, costs, and\naccuracies -- to meet the diverse application requirements. Since requirements,\nquery load, and applications themselves evolve over time, these decisions need\nto be made dynamically for each inference query to avoid excessive costs\nthrough naive autoscaling. To avoid navigating through the large and complex\ntrade-off space of model-variants, developers often fix a variant across\nqueries, and replicate it when load increases. However, given the diversity\nacross variants and hardware platforms in the cloud, a lack of understanding of\nthe trade-off space can incur significant costs to developers.\n  This paper introduces INFaaS, a managed and model-less system for distributed\ninference serving, where developers simply specify the performance and accuracy\nrequirements for their applications without needing to specify a specific\nmodel-variant for each query. INFaaS generates model-variants, and efficiently\nnavigates the large trade-off space of model-variants on behalf of developers\nto meet application-specific objectives: (a) for each query, it selects a\nmodel, hardware architecture, and model optimizations, (b) it combines VM-level\nhorizontal autoscaling with model-level autoscaling, where multiple, different\nmodel-variants are used to serve queries within each machine. By leveraging\ndiverse variants and sharing hardware resources across models, INFaaS achieves\n1.3x higher throughput, violates latency objectives 1.6x less often, and saves\nup to 21.6x in cost (8.5x on average) compared to state-of-the-art inference\nserving systems on AWS EC2.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 23:08:29 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 15:56:30 GMT"}, {"version": "v3", "created": "Thu, 27 Jun 2019 04:41:59 GMT"}, {"version": "v4", "created": "Tue, 24 Sep 2019 17:32:22 GMT"}, {"version": "v5", "created": "Wed, 25 Sep 2019 22:14:38 GMT"}, {"version": "v6", "created": "Tue, 15 Dec 2020 21:04:54 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Romero", "Francisco", ""], ["Li", "Qian", ""], ["Yadwadkar", "Neeraja J.", ""], ["Kozyrakis", "Christos", ""]]}, {"id": "1905.13352", "submitter": "Hafiz Muhammad Mohsin Bashir", "authors": "Hafiz Mohsin Bashir, Abdullah Bin Faisal, Muhammad Asim Jamshed, Peter\n  Vondras, Ali Musa Iftikhar, Ihsan Ayyub Qazi, Fahad R. Dogar", "title": "Reducing Tail Latency via Safe and Simple Duplication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Duplication can be a powerful strategy for overcoming stragglers in cloud\nservices, but is often used conservatively because of the risk of overloading\nthe system. We present duplicate-aware scheduling or DAS, which makes\nduplication safe and easy to use, by leveraging the two well-known primitives\nof prioritization and purging. To support DAS across diverse layers of a cloud\nsystem (e.g., network, storage, etc), we propose the D-Stage abstraction, which\ndecouples the duplication policy from the mechanism, and facilitates working\nwith legacy layers of a system. Using this abstraction, we evaluate the\nbenefits of DAS for two data parallel applications (HDFS, an in-memory workload\ngenerator) and a network function (snort-based IDS cluster). Our experiments on\nthe public cloud and Emulab show that DAS is safe to use, and the tail latency\nimprovement holds across a wide range of workloads\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 23:30:56 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Bashir", "Hafiz Mohsin", ""], ["Faisal", "Abdullah Bin", ""], ["Jamshed", "Muhammad Asim", ""], ["Vondras", "Peter", ""], ["Iftikhar", "Ali Musa", ""], ["Qazi", "Ihsan Ayyub", ""], ["Dogar", "Fahad R.", ""]]}, {"id": "1905.13368", "submitter": "Rekha Singhal Dr.", "authors": "Rekha Singhal, Gautam Shroff, Mukund Kumar, Sharod Roy, Sanket\n  Kadarkar, Rupinder virk, Siddharth Verma and Vartika Tiwari", "title": "Fast Online \"Next Best Offers\" using Deep Learning", "comments": "7 Pages, Accepted in COMAD-CODS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present iPrescribe, a scalable low-latency architecture for\nrecommending 'next-best-offers' in an online setting. The paper presents the\ndesign of iPrescribe and compares its performance for implementations using\ndifferent real-time streaming technology stacks. iPrescribe uses an ensemble of\ndeep learning and machine learning algorithms for prediction. We describe the\nscalable real-time streaming technology stack and optimized machine-learning\nimplementations to achieve a 90th percentile recommendation latency of 38\nmilliseconds. Optimizations include a novel mechanism to deploy recurrent Long\nShort Term Memory (LSTM) deep learning networks efficiently.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 01:03:04 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Singhal", "Rekha", ""], ["Shroff", "Gautam", ""], ["Kumar", "Mukund", ""], ["Roy", "Sharod", ""], ["Kadarkar", "Sanket", ""], ["virk", "Rupinder", ""], ["Verma", "Siddharth", ""], ["Tiwari", "Vartika", ""]]}, {"id": "1905.13376", "submitter": "Rekha Singhal Dr.", "authors": "Kunle Olukotun, Raghu Prabhakar, Rekha Singhal, Jeffrey D.Ullman, and\n  Yaqi Zhang", "title": "Efficient Multiway Hash Join on Reconfigurable Hardware", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the algorithms for performing multiway joins using a new type of\ncoarse grain reconfigurable hardware accelerator~-- ``Plasticine''~-- that,\ncompared with other accelerators, emphasizes high compute capability and high\non-chip communication bandwidth. Joining three or more relations in a single\nstep, i.e. multiway join, is efficient when the join of any two relations\nyields too large an intermediate relation. We show at least 200X speedup for a\nsequence of binary hash joins execution on Plasticine over CPU. We further show\nthat in some realistic cases, a Plasticine-like accelerator can make 3-way\njoins more efficient than a cascade of binary hash joins on the same hardware,\nby a factor of up to 45X.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 01:48:58 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Olukotun", "Kunle", ""], ["Prabhakar", "Raghu", ""], ["Singhal", "Rekha", ""], ["Ullman", "Jeffrey D.", ""], ["Zhang", "Yaqi", ""]]}, {"id": "1905.13415", "submitter": "Elias Stehle", "authors": "Elias Stehle and Hans-Arno Jacobsen", "title": "ParPaRaw: Massively Parallel Parsing of Delimiter-Separated Raw Data", "comments": null, "journal-ref": "PVLDB, 13(5): 616-628, 2020", "doi": "10.14778/3377369.3377372", "report-no": null, "categories": "cs.DB cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parsing is essential for a wide range of use cases, such as stream\nprocessing, bulk loading, and in-situ querying of raw data. Yet, the\ncompute-intense step often constitutes a major bottleneck in the data ingestion\npipeline, since parsing of inputs that require more involved parsing rules is\nchallenging to parallelise. This work proposes a massively parallel algorithm\nfor parsing delimiter-separated data formats on GPUs. Other than the\nstate-of-the-art, the proposed approach does not require an initial sequential\npass over the input to determine a thread's parsing context. That is, how a\nthread, beginning somewhere in the middle of the input, should interpret a\ncertain symbol (e.g., whether to interpret a comma as a delimiter or as part of\na larger string enclosed in double-quotes). Instead of tailoring the approach\nto a single format, we are able to perform a massively parallel FSM simulation,\nwhich is more flexible and powerful, supporting more expressive parsing rules\nwith general applicability. Achieving a parsing rate of as much as 14.2 GB/s,\nour experimental evaluation on a GPU with 3584 cores shows that the presented\napproach is able to scale to thousands of cores and beyond. With an end-to-end\nstreaming approach, we are able to exploit the full-duplex capabilities of the\nPCIe bus and hide latency from data transfers. Considering the end-to-end\nperformance, the algorithm parses 4.8 GB in as little as 0.44 seconds,\nincluding data transfers.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 05:04:39 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 04:52:33 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Stehle", "Elias", ""], ["Jacobsen", "Hans-Arno", ""]]}, {"id": "1905.13503", "submitter": "Behnaz Pourmohseni", "authors": "Behnaz Pourmohseni, Fedor Smirnov, Stefan Wildermann, J\\\"urgen Teich", "title": "Isolation-Aware Timing Analysis and Design Space Exploration for\n  Predictable and Composable Many-Core Systems", "comments": "Final version published at the 31st Euromicro Conference on Real-Time\n  Systems (ECRTS 2019)", "journal-ref": null, "doi": "10.4230/LIPIcs.ECRTS.2019.12", "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Composable many-core systems enable the independent development and analysis\nof applications which will be executed on a shared platform where the mix of\nconcurrently executed applications may change dynamically at run time. For each\nindividual application, an off-line Design Space Exploration (DSE) is performed\nto compute several mapping alternatives on the platform, offering\nPareto-optimal trade-offs in terms of real-time guarantees, resource usage,\netc. At run time, one mapping is then chosen to launch the application on\ndemand. In this context, to enable an independent analysis of each individual\napplication at design time, so-called inter-application isolation schemes are\napplied which specify temporal or spatial isolation policies between\napplications. S.o.t.a. composable many-core systems are developed based on a\nfixed isolation scheme that is exclusively applied to every resource in every\nmapping of every application and use a timing analysis tailored to that\nisolation scheme to derive timing guarantees for each mapping. A fixed\nisolation scheme, however, heavily restricts the explored space of solutions\nand can, therefore, lead to suboptimality. Lifting this restriction\nnecessitates a timing analysis that is applicable to mappings with an arbitrary\nmix of isolation schemes on different resources. To address this issue, we\npresent an isolation-aware timing analysis that unlike existing analyses can\nhandle multiple isolation schemes in combination within one mapping and\ndelivers safe yet tight timing bounds by identifying and excluding interference\nscenarios that can never happen under the given combination of isolation\nschemes. Based on the timing analysis, we present a DSE which explores the\nchoices of isolation scheme per resource within each mapping. Experimental\nresults demonstrate the advantage of the proposed approach over approaches\nbased on a fixed isolation scheme.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 10:43:21 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 12:07:28 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2019 08:43:05 GMT"}, {"version": "v4", "created": "Mon, 10 Feb 2020 10:48:06 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Pourmohseni", "Behnaz", ""], ["Smirnov", "Fedor", ""], ["Wildermann", "Stefan", ""], ["Teich", "J\u00fcrgen", ""]]}, {"id": "1905.13529", "submitter": "Yli\\`es Falcone", "authors": "Mohamad Jaber, Yli\\`es Falcone, Paul Attie, Al-Abbass Khalil, Rayan\n  Hallal", "title": "From Global Choreographies to Provably Correct and Efficient Distributed\n  Implementations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a method to automatically synthesize provably-correct efficient\ndistributed implementations from high-level global choreographies. A global\nchoreography describes the execution and communication logic between a set of\nprovided processes which are described by their interfaces. The operations at\nthe level of choreographies include multiparty communications, choice, loop,\nand branching. Choreographies are master-triggered, that is each choreography\nhas one master to trigger its execution. This allows to automatically generate\nconflict free distributed implementations without controllers. The behavior of\nthe synthesized implementations follows the behavior of choreographies. In\naddition, the absence of controllers ensures the efficiency of the\nimplementation and reduces the communication needed at runtime. Moreover, we\ndefine a translation of the distributed implementations to equivalent Promela\nversions. The translation allows verifying the distributed system against\nbehavioral properties. We implemented a Java prototype to validate the approach\nand applied it to automatically synthesize micro-services architectures. We\nillustrate our method on the automatic synthesis of a verified distributed\nbuying system.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 12:05:42 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Jaber", "Mohamad", ""], ["Falcone", "Yli\u00e8s", ""], ["Attie", "Paul", ""], ["Khalil", "Al-Abbass", ""], ["Hallal", "Rayan", ""]]}, {"id": "1905.13600", "submitter": "Ohad Ben-Baruch", "authors": "Hagit Attiya, Ohad Ben-Baruch, Panagiota Fatourou, Danny Hendler,\n  Eleftherios Kosmas", "title": "Tracking in Order to Recover: Detectable Recovery of Lock-Free Data\n  Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the tracking approach for deriving detectably recoverable\n(and thus also durable) implementations of many widely-used concurrent data\nstructures. Such data structures, satisfying detectable recovery, are appealing\nfor emerging systems featuring byte-addressable non-volatile main memory\n(NVRAM), whose persistence allows to efficiently resurrect failed processes\nafter crashes. Detectable recovery ensures that after a crash, every executed\noperation is able to recover and return a correct response, and that the state\nof the data structure is not corrupted. Info-Structure Based (ISB)-tracking\namends descriptor objects used in existing lock-free helping schemes with\nadditional fields that track an operation's progress towards completion and\npersists these fields to memory in order to ensure detectable recovery.\nISB-tracking avoids full-fledged logging and tracks the progress of concurrent\noperations in a per-process manner, thus reducing the cost of ensuring\ndetectable recovery. We have applied ISB-tracking to derive detectably\nrecoverable implementations of a queue, a linked list, a binary search tree,\nand an exchanger. Experimental results show the feasibility of the technique.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 13:12:12 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 19:12:33 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Attiya", "Hagit", ""], ["Ben-Baruch", "Ohad", ""], ["Fatourou", "Panagiota", ""], ["Hendler", "Danny", ""], ["Kosmas", "Eleftherios", ""]]}, {"id": "1905.13685", "submitter": "Adarsh Subramaniam", "authors": "Adarsh M. Subramaniam, Anoosheh Heiderzadeh, Krishna R. Narayanan", "title": "Collaborative Decoding of Polynomial Codes for Distributed Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that polynomial codes (and some related codes) used for distributed\nmatrix multiplication are interleaved Reed-Solomon codes and, hence, can be\ncollaboratively decoded. We consider a fault tolerant setup where $t$ worker\nnodes return erroneous values. For an additive random Gaussian error model, we\nshow that for all $t < N-K$, errors can be corrected with probability 1.\nFurther, numerical results show that in the presence of additive errors, when\n$L$ Reed-Solomon codes are collaboratively decoded, the numerical stability in\nrecovering the error locator polynomial improves with increasing $L$.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 15:47:58 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Subramaniam", "Adarsh M.", ""], ["Heiderzadeh", "Anoosheh", ""], ["Narayanan", "Krishna R.", ""]]}, {"id": "1905.13727", "submitter": "Thijs Vogels", "authors": "Thijs Vogels and Sai Praneeth Karimireddy and Martin Jaggi", "title": "PowerSGD: Practical Low-Rank Gradient Compression for Distributed\n  Optimization", "comments": "Presented at NeurIPS 2019", "journal-ref": "NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study gradient compression methods to alleviate the communication\nbottleneck in data-parallel distributed optimization. Despite the significant\nattention received, current compression schemes either do not scale well or\nfail to achieve the target test accuracy. We propose a new low-rank gradient\ncompressor based on power iteration that can i) compress gradients rapidly, ii)\nefficiently aggregate the compressed gradients using all-reduce, and iii)\nachieve test performance on par with SGD. The proposed algorithm is the only\nmethod evaluated that achieves consistent wall-clock speedups when benchmarked\nagainst regular SGD with an optimized communication backend. We demonstrate\nreduced training times for convolutional networks as well as LSTMs on common\ndatasets. Our code is available at https://github.com/epfml/powersgd.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 17:25:13 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 13:19:34 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 14:13:56 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Vogels", "Thijs", ""], ["Karimireddy", "Sai Praneeth", ""], ["Jaggi", "Martin", ""]]}]