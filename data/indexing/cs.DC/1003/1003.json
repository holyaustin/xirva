[{"id": "1003.0951", "submitter": "Jianfeng Zhan", "authors": "Rui Ren, Xiaoyu Fu, Jianfeng Zhan, Wei Zhou", "title": "LogMaster: Mining Event Correlations in Logs of Large scale Cluster\n  Systems", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a methodology and a system, named LogMaster, for mining\ncorrelations of events that have multiple attributions, i.e., node ID,\napplication ID, event type, and event severity, in logs of large-scale cluster\nsystems. Different from traditional transactional data, e.g., supermarket\npurchases, system logs have their unique characteristic, and hence we propose\nseveral innovative approaches to mine their correlations. We present a simple\nmetrics to measure correlations of events that may happen interleavedly. On the\nbasis of the measurement of correlations, we propose two approaches to mine\nevent correlations; meanwhile, we propose an innovative abstraction: event\ncorrelation graphs (ECGs) to represent event correlations, and present an ECGs\nbased algorithm for predicting events. For two system logs of a production\nHadoop-based cloud computing system at Research Institution of China Mobile and\na production HPC cluster system at Los Alamos National Lab (LANL), we evaluate\nour approaches in three scenarios: (a) predicting all events on the basis of\nboth failure and non-failure events; (b) predicting only failure events on the\nbasis of both failure and non-failure events; (c) predicting failure events\nafter removing non-failure events.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2010 02:47:07 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2013 05:48:43 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Ren", "Rui", ""], ["Fu", "Xiaoyu", ""], ["Zhan", "Jianfeng", ""], ["Zhou", "Wei", ""]]}, {"id": "1003.0952", "submitter": "Vicente H. F. Batista", "authors": "Vicente H. F. Batista, George O. Ainsworth Jr. and Fernando L. B.\n  Ribeiro", "title": "Parallel structurally-symmetric sparse matrix-vector products on\n  multi-core processors", "comments": "17 pages, 17 figures, reviewed related work section, fixed typos", "journal-ref": null, "doi": "10.4203/ccp.101.22", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of developing an efficient multi-threaded\nimplementation of the matrix-vector multiplication algorithm for sparse\nmatrices with structural symmetry. Matrices are stored using the compressed\nsparse row-column format (CSRC), designed for profiting from the symmetric\nnon-zero pattern observed in global finite element matrices. Unlike classical\ncompressed storage formats, performing the sparse matrix-vector product using\nthe CSRC requires thread-safe access to the destination vector. To avoid race\nconditions, we have implemented two partitioning strategies. In the first one,\neach thread allocates an array for storing its contributions, which are later\ncombined in an accumulation step. We analyze how to perform this accumulation\nin four different ways. The second strategy employs a coloring algorithm for\ngrouping rows that can be concurrently processed by threads. Our results\nindicate that, although incurring an increase in the working set size, the\nformer approach leads to the best performance improvements for most matrices.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2010 03:25:41 GMT"}, {"version": "v2", "created": "Sat, 6 Mar 2010 04:24:34 GMT"}, {"version": "v3", "created": "Fri, 28 May 2010 22:57:02 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Batista", "Vicente H. F.", ""], ["Ainsworth", "George O.", "Jr."], ["Ribeiro", "Fernando L. B.", ""]]}, {"id": "1003.0955", "submitter": "Jianfeng Zhan", "authors": "Zhihong Zhang, Jianfeng Zhan, Yong Li, Lei Wang, Dan Meng, Bo Sang", "title": "Precise Request Tracing and Performance Debugging for Multi-tier\n  Services of Black Boxes", "comments": null, "journal-ref": "Proceeding of IEEE/IFIP 39th Dependable System and Network (DSN\n  2009)", "doi": "10.1109/DSN.2009.5270321", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As more and more multi-tier services are developed from commercial components\nor heterogeneous middleware without the source code available, both developers\nand administrators need a precise request tracing tool to help understand and\ndebug performance problems of large concurrent services of black boxes.\nPrevious work fails to resolve this issue in several ways: they either accept\nthe imprecision of probabilistic correlation methods, or rely on knowledge of\nprotocols to isolate requests in pursuit of tracing accuracy. This paper\nintroduces a tool named PreciseTracer to help debug performance problems of\nmulti-tier services of black boxes. Our contributions are two-fold: first, we\npropose a precise request tracing algorithm for multi-tier services of black\nboxes, which only uses application-independent knowledge; secondly, we present\na component activity graph abstraction to represent causal paths of requests\nand facilitate end-to-end performance debugging. The low overhead and tolerance\nof noise make PreciseTracer a promising tracing tool for using on production\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2010 06:51:51 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Zhang", "Zhihong", ""], ["Zhan", "Jianfeng", ""], ["Li", "Yong", ""], ["Wang", "Lei", ""], ["Meng", "Dan", ""], ["Sang", "Bo", ""]]}, {"id": "1003.0958", "submitter": "Jianfeng Zhan", "authors": "Jianfeng Zhan, Lei Wang, Weisong Shi, Shimin Gong and Xiutao Zang", "title": "PhoenixCloud: Provisioning Resources for Heterogeneous Cloud Workloads", "comments": "Submitted to IEEE Transaction on Service Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As more and more service providers choose Cloud platforms, a resource\nprovider needs to provision resources and supporting runtime environments (REs)\nfor heterogeneous workloads in different scenarios. Previous work fails to\nresolve this issue in several ways: (1) it fails to pay attention to diverse RE\nrequirements, and does not enable creating coordinated REs on demand; (2) few\nwork investigates coordinated resource provisioning for heterogeneous\nworkloads. In this paper, our contributions are three-fold: (1) we present an\nRE agreement that expresses diverse RE requirements, and build an innovative\nsystem PhoenixCloud that enables a resource provider to create REs on demand\naccording to RE agreements; (2) we propose two coordinated resource\nprovisioning solutions for heterogeneous workloads in two typical Cloud\nscenarios: first, a large organization operates a private Cloud for two\nheterogeneous workloads; second, a large organization or two service providers\nrunning heterogeneous workloads revert to a public Cloud; and (3) A\ncomprehensive evaluation has been performed in experiments. For typical\nworkload traces of parallel batch jobs and Web services, our experiments show\nthat: a) In the first Cloud scenario, when the throughput is almost same like\nthat of a dedicated cluster system, our solution decreases the configuration\nsize of cluster by about 40%; b) in the second scenario, our solution decreases\nnot only the total resource consumption, but also the peak resource consumption\nmaximally to 31% with respect to that of EC2 + RightScale solution.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2010 03:26:26 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2010 06:24:32 GMT"}, {"version": "v3", "created": "Tue, 30 Mar 2010 02:55:49 GMT"}, {"version": "v4", "created": "Wed, 31 Mar 2010 00:40:42 GMT"}], "update_date": "2010-04-01", "authors_parsed": [["Zhan", "Jianfeng", ""], ["Wang", "Lei", ""], ["Shi", "Weisong", ""], ["Gong", "Shimin", ""], ["Zang", "Xiutao", ""]]}, {"id": "1003.0959", "submitter": "Jianfeng Zhan", "authors": "Bo Sang, Jianfeng Zhan, Guanhua Tian", "title": "Decreasing log data of multi-tier services for effective request tracing", "comments": null, "journal-ref": "Proceeding of IEEE/IFIP 39th Dependable System and Network (DSN\n  2009), Fast Abstract", "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work shows request tracing systems help understand and debug the\nperformance problems of multi-tier services. However, for large-scale data\ncenters, more than hundreds of thousands of service instances provide online\nservice at the same time. Previous work such as white-box or black box tracing\nsystems will produce large amount of log data, which would be correlated into\nlarge quantities of causal paths for performance debugging. In this paper, we\npropose an innovative algorithm to eliminate valueless logs of multitiers\nservices. Our experiment shows our method filters 84% valueless causal paths\nand is promising to be used in large-scale data centers.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2010 06:54:26 GMT"}], "update_date": "2010-03-05", "authors_parsed": [["Sang", "Bo", ""], ["Zhan", "Jianfeng", ""], ["Tian", "Guanhua", ""]]}, {"id": "1003.1058", "submitter": "Carole Delporte-Gallet", "authors": "Carole Delporte-Gallet (LIAFA), St\\'ephane Devismes (VERIMAG - IMAG),\n  Hugues Fauconnier (LIAFA), Mikel Larrea", "title": "Algorithms For Extracting Timeliness Graphs", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-642-13284-1_11", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider asynchronous message-passing systems in which some links are\ntimely and processes may crash. Each run defines a timeliness graph among\ncorrect processes: (p; q) is an edge of the timeliness graph if the link from p\nto q is timely (that is, there is bound on communication delays from p to q).\nThe main goal of this paper is to approximate this timeliness graph by graphs\nhaving some properties (such as being trees, rings, ...). Given a family S of\ngraphs, for runs such that the timeliness graph contains at least one graph in\nS then using an extraction algorithm, each correct process has to converge to\nthe same graph in S that is, in a precise sense, an approximation of the\ntimeliness graph of the run. For example, if the timeliness graph contains a\nring, then using an extraction algorithm, all correct processes eventually\nconverge to the same ring and in this ring all nodes will be correct processes\nand all links will be timely. We first present a general extraction algorithm\nand then a more specific extraction algorithm that is communication efficient\n(i.e., eventually all the messages of the extraction algorithm use only links\nof the extracted graph).\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2010 14:47:17 GMT"}, {"version": "v2", "created": "Mon, 31 May 2010 09:17:24 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Delporte-Gallet", "Carole", "", "LIAFA"], ["Devismes", "St\u00e9phane", "", "VERIMAG - IMAG"], ["Fauconnier", "Hugues", "", "LIAFA"], ["Larrea", "Mikel", ""]]}, {"id": "1003.1168", "submitter": "Jianfeng Zhan", "authors": "Lei Wang, Jianfeng Zhan, Weisong Shi, Yi Liang, Lin Yuan", "title": "In Cloud, Do MTC or HTC Service Providers Benefit from the Economies of\n  Scale?", "comments": null, "journal-ref": "Proceedings of 2nd Workshop on Many-Task Computing on Grids and\n  Supercomputers, Co-located with ACM/IEEE SC 2009", "doi": "10.1145/1646468.1646475", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we intend to answer one key question to the success of cloud\ncomputing: in cloud, do many task computing (MTC) or high throughput computing\n(HTC) service providers, which offer the corresponding computing service to end\nusers, benefit from the economies of scale? Our research contributions are\nthree-fold: first, we propose an innovative usage model, called dynamic service\nprovision (DSP) model, for MTC or HTC service providers. In the DSP model, the\nresource provider provides the service of creating and managing runtime\nenvironments for MTC or HTC service providers, and consolidates heterogeneous\nMTC or HTC workloads on the cloud platform; second, according to the DSP model,\nwe design and implement DawningCloud, which provides automatic management for\nheterogeneous workloads; third, a comprehensive evaluation of DawningCloud has\nbeen performed in an emulatation experiment. We found that for typical\nworkloads, in comparison with the previous two cloud solutions, DawningCloud\nsaves the resource consumption maximally by 46.4% (HTC) and 74.9% (MTC) for the\nservice providers, and saves the total resource consumption maximally by 29.7%\nfor the resource provider. At the same time, comparing with the traditional\nsolution that provides MTC or HTC services with dedicated systems, DawningCloud\nis more cost-effective. To this end, we conclude that for typical MTC and HTC\nworkloads, on the cloud platform, MTC and HTC service providers and the\nresource provider can benefit from the economies of scale.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2010 00:10:19 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2010 08:09:42 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2010 05:50:25 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Wang", "Lei", ""], ["Zhan", "Jianfeng", ""], ["Shi", "Weisong", ""], ["Liang", "Yi", ""], ["Yuan", "Lin", ""]]}, {"id": "1003.1291", "submitter": "Alejandro Lorca", "authors": "Alejandro Lorca, Eduardo Huedo, Ignacio M. Llorente", "title": "The Grid[Way] Job Template Manager, a tool for parameter sweeping", "comments": "26 pages, 1 figure,", "journal-ref": null, "doi": "10.1016/j.cpc.2010.12.041", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter sweeping is a widely used algorithmic technique in computational\nscience. It is specially suited for high-throughput computing since the jobs\nevaluating the parameter space are loosely coupled or independent.\n  A tool that integrates the modeling of a parameter study with the control of\njobs in a distributed architecture is presented. The main task is to facilitate\nthe creation and deletion of job templates, which are the elements describing\nthe jobs to be run. Extra functionality relies upon the GridWay Metascheduler,\nacting as the middleware layer for job submission and control. It supports\ninteresting features like multi-dimensional sweeping space, wildcarding of\nparameters, functional evaluation of ranges, value-skipping and job template\nautomatic indexation.\n  The use of this tool increases the reliability of the parameter sweep study\nthanks to the systematic bookkeping of job templates and respective job\nstatuses. Furthermore, it simplifies the porting of the target application to\nthe grid reducing the required amount of time and effort.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2010 15:34:09 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Lorca", "Alejandro", ""], ["Huedo", "Eduardo", ""], ["Llorente", "Ignacio M.", ""]]}, {"id": "1003.1395", "submitter": "Zolt\\'an K\\'asa", "authors": "Peter Burcsi, Attila Kov\\'acs, Antal T\\'atrai", "title": "Start-phase control of distributed systems written in Erlang/OTP", "comments": null, "journal-ref": "Acta Univ. Sapientiae, Informatica, 2, 1 (2010) 10-27", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a realization for the reliable and fast startup of\ndistributed systems written in Erlang. The traditional startup provided by the\nErlang/OTP library is sequential, parallelization usually requires unsafe and\nad-hoc solutions. The proposed method calls only for slight modifications in\nthe Erlang/OTP stdlib by applying a system dependency graph. It makes the\nstartup safe, quick, and it is equally easy to use in newly developed and\nlegacy systems.\n", "versions": [{"version": "v1", "created": "Sat, 6 Mar 2010 15:47:21 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2010 13:12:36 GMT"}], "update_date": "2010-03-13", "authors_parsed": [["Burcsi", "Peter", ""], ["Kov\u00e1cs", "Attila", ""], ["T\u00e1trai", "Antal", ""]]}, {"id": "1003.1397", "submitter": "Zolt\\'an K\\'asa", "authors": "Stefan Korecko, Branislav Sobota", "title": "Using Coloured Petri Nets for design of parallel raytracing environment", "comments": null, "journal-ref": "Acta Univ. Sapientiae, Informatica, 2,1 (2010) 28-39", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the parallel raytracing part of virtual-reality system\nPROLAND, developed at the home institution of authors. It describes an actual\nimplementation of the raytracing part and introduces a Coloured Petri Nets\nmodel of the implementation. The model is used for an evaluation of the\nimplementation by means of simulation-based performance analysis and also forms\nthe basis for future improvements of its parallelization strategy.\n", "versions": [{"version": "v1", "created": "Sat, 6 Mar 2010 16:24:29 GMT"}], "update_date": "2010-03-13", "authors_parsed": [["Korecko", "Stefan", ""], ["Sobota", "Branislav", ""]]}, {"id": "1003.1608", "submitter": "Leonid Barenboim", "authors": "Leonid Barenboim and Michael Elkin", "title": "Deterministic Distributed Vertex Coloring in Polylogarithmic Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider an n-vertex graph G = (V,E) of maximum degree Delta, and suppose\nthat each vertex v \\in V hosts a processor. The processors are allowed to\ncommunicate only with their neighbors in G. The communication is synchronous,\ni.e., it proceeds in discrete rounds. In the distributed vertex coloring\nproblem the objective is to color G with Delta + 1, or slightly more than Delta\n+ 1, colors using as few rounds of communication as possible. (The number of\nrounds of communication will be henceforth referred to as running time.)\nEfficient randomized algorithms for this problem are known for more than twenty\nyears \\cite{L86, ABI86}. Specifically, these algorithms produce a (Delta +\n1)-coloring within O(log n) time, with high probability. On the other hand, the\nbest known deterministic algorithm that requires polylogarithmic time employs\nO(Delta^2) colors. This algorithm was devised in a seminal FOCS'87 paper by\nLinial \\cite{L87}. Its running time is O(log^* n). In the same paper Linial\nasked whether one can color with significantly less than Delta^2 colors in\ndeterministic polylogarithmic time. By now this question of Linial became one\nof the most central long-standing open questions in this area. In this paper we\nanswer this question in the affirmative, and devise a deterministic algorithm\nthat employs \\Delta^{1 +o(1)} colors, and runs in polylogarithmic time.\nSpecifically, the running time of our algorithm is O(f(Delta) log Delta log n),\nfor an arbitrarily slow-growing function f(Delta) = \\omega(1). We can also\nproduce O(Delta^{1 + \\eta})-coloring in O(log Delta log n)-time, for an\narbitrarily small constant \\eta > 0, and O(Delta)-coloring in\nO(Delta^{\\epsilon} log n) time, for an arbitrarily small constant \\epsilon > 0.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2010 12:00:09 GMT"}], "update_date": "2010-03-09", "authors_parsed": [["Barenboim", "Leonid", ""], ["Elkin", "Michael", ""]]}, {"id": "1003.1833", "submitter": "Feng Xia", "authors": "Da Zhang, Feng Xia, Zhuo Yang, Lin Yao, Wenhong Zhao", "title": "Localization Technologies for Indoor Human Tracking", "comments": "To appear in The 5th International Conference on Future Information\n  Technology (FutureTech), May 2010, Busan, Korea.", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of wireless localization technologies provides a promising\nfuture for serving human beings in indoor scenarios. Their applications include\nreal-time tracking, activity recognition, health care, navigation, emergence\ndetection, and target-of-interest monitoring, among others. Additionally,\nindoor localization technologies address the inefficiency of GPS (Global\nPositioning System) inside buildings. Since people spend most of their time in\nindoor environments, indoor tracking service is in great public demand. Based\non this observation, this paper aims to provide a better understanding of\nstate-of-the-art technologies and stimulate new research efforts in this field.\nFor these purposes, existing localization technologies that can be used for\ntracking individuals in indoor environments are reviewed, along with some\nfurther discussions.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2010 09:08:06 GMT"}], "update_date": "2010-03-10", "authors_parsed": [["Zhang", "Da", ""], ["Xia", "Feng", ""], ["Yang", "Zhuo", ""], ["Yao", "Lin", ""], ["Zhao", "Wenhong", ""]]}, {"id": "1003.1940", "submitter": "Vamsi Kundeti", "authors": "Vamsi Kundeti, Sanguthevar Rajasekaran, Hieu Dinh", "title": "Efficient Parallel and Out of Core Algorithms for Constructing Large\n  Bi-directed de Bruijn Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assembling genomic sequences from a set of overlapping reads is one of the\nmost fundamental problems in computational biology. Algorithms addressing the\nassembly problem fall into two broad categories -- based on the data structures\nwhich they employ. The first class uses an overlap/string graph and the second\ntype uses a de Bruijn graph. However with the recent advances in short read\nsequencing technology, de Bruijn graph based algorithms seem to play a vital\nrole in practice.\n  Efficient algorithms for building these massive de Bruijn graphs are very\nessential in large sequencing projects based on short reads. In Jackson et. al.\nICPP-2008, an $O(n/p)$ time parallel algorithm has been given for this problem.\nHere $n$ is the size of the input and $p$ is the number of processors. This\nalgorithm enumerates all possible bi-directed edges which can overlap with a\nnode and ends up generating $\\Theta(n\\Sigma)$ messages.\n  In this paper we present a $\\Theta(n/p)$ time parallel algorithm with a\ncommunication complexity equal to that of parallel sorting and is not sensitive\nto $\\Sigma$. The generality of our algorithm makes it very easy to extend it\neven to the out-of-core model and in this case it has an optimal I/O complexity\nof $\\Theta(\\frac{n\\log(n/B)}{B\\log(M/B)})$. We demonstrate the scalability of\nour parallel algorithm on a SGI/Altix computer. A comparison of our algorithm\nwith that of Jackson et. al. ICPP-2008 reveals that our algorithm is faster. We\nalso provide efficient algorithms for the bi-directed chain compaction problem.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2010 17:54:01 GMT"}], "update_date": "2010-03-10", "authors_parsed": [["Kundeti", "Vamsi", ""], ["Rajasekaran", "Sanguthevar", ""], ["Dinh", "Hieu", ""]]}, {"id": "1003.2084", "submitter": "Rena Bakhshi", "authors": "Rena Bakhshi and J\\\"org Endrullis and Wan Fokkink and Jun Pang", "title": "Asynchronous Bounded Expected Delay Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The commonly used asynchronous bounded delay (ABD) network models assume a\nfixed bound on message delay. We propose a probabilistic network model, called\nasynchronous bounded expected delay (ABE) model. Instead of a strict bound, the\nABE model requires only a bound on the expected message delay. While the\nconditions of ABD networks restrict the set of possible executions, in ABE\nnetworks all asynchronous executions are possible, but executions with\nextremely long delays are less probable. In contrast to ABD networks, ABE\nnetworks cannot be synchronised efficiently. At the example of an election\nalgorithm, we show that the minimal assumptions of ABE networks are sufficient\nfor the development of efficient algorithms. For anonymous, unidirectional ABE\nrings of known size N we devise a probabilistic leader election algorithm\nhaving average message and time complexity O(N).\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2010 11:39:08 GMT"}, {"version": "v2", "created": "Mon, 30 May 2011 17:10:44 GMT"}, {"version": "v3", "created": "Tue, 7 Jun 2011 09:05:23 GMT"}], "update_date": "2011-06-08", "authors_parsed": [["Bakhshi", "Rena", ""], ["Endrullis", "J\u00f6rg", ""], ["Fokkink", "Wan", ""], ["Pang", "Jun", ""]]}, {"id": "1003.3305", "submitter": "Secretary Aircc Journal", "authors": "Maher Khemakhem (1) and Abdelfettah Belghith (2) ((1) Sousse\n  University, Tunisia, (2) Manouba University, Tunisia)", "title": "Towards trusted volunteer grid environments", "comments": "9 Pages, IJCNC Journal 2010", "journal-ref": null, "doi": "10.5121/ijcnc.2010.2207", "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Intensive experiences show and confirm that grid environments can be\nconsidered as the most promising way to solve several kinds of problems\nrelating either to cooperative work especially where involved collaborators are\ndispersed geographically or to some very greedy applications which require\nenough power of computing or/and storage. Such environments can be classified\ninto two categories; first, dedicated grids where the federated computers are\nsolely devoted to a specific work through its end. Second, Volunteer grids\nwhere federated computers are not completely devoted to a specific work but\ninstead they can be randomly and intermittently used, at the same time, for any\nother purpose or they can be connected or disconnected at will by their owners\nwithout any prior notification. Each category of grids includes surely several\nadvantages and disadvantages; nevertheless, we think that volunteer grids are\nvery promising and more convenient especially to build a general multipurpose\ndistributed scalable environment. Unfortunately, the big challenge of such\nenvironments is, however, security and trust. Indeed, owing to the fact that\nevery federated computer in such an environment can randomly be used at the\nsame time by several users or can be disconnected suddenly, several security\nproblems will automatically arise. In this paper, we propose a novel solution\nbased on identity federation, agent technology and the dynamic enforcement of\naccess control policies that lead to the design and implementation of trusted\nvolunteer grid environments.\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2010 06:28:40 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Khemakhem", "Maher", ""], ["Belghith", "Abdelfettah", ""]]}, {"id": "1003.3325", "submitter": "Secretary Aircc Journal", "authors": "K. Abdelkader (1), J. Broeckhove (1) and K. Vanmechelen (1) ((1)\n  University of Antwerp, Belgium)", "title": "Resource Pricing In A Dynamic Multi-Commodity Market For Computational\n  Resources", "comments": "14 Pages, IJCNC Journal", "journal-ref": "International Journal of Computer Networks & Communications 2.2\n  (2010) 74-87", "doi": "10.5121/ijcnc.2010.2205", "report-no": null, "categories": "cs.GT cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The adoption of market-based principles in resource management systems for\ncomputational infrastructures such as grids and clusters allows for matching\ndemand and supply for resources in a utility maximizing manner. As such, they\noffer a promise of producing more efficient resource allocations, compared to\ntraditional system-centric approaches that do not allow consumers and providers\nto express their valuations for computational resources. In this paper, we\ninvestigate the pricing of resources in grids through the use of a\ncomputational commodity market of CPU resources, where resource prices are\ndetermined through the computation of a supply-and-demand equilibrium. In\nparticular, we introduce several categories of CPUs characterized by their\nexecution speed. These differ in cost and performance but may be used\ninterchangeably in executing jobs and thus represent so-called substitutable\nresources. We investigate the performance of the algorithms for computing the\nsupply-and-demand equilibrium in this multi-commodity setting under dynamically\nvarying consumer and provider populations.\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2010 08:48:43 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Abdelkader", "K.", ""], ["Broeckhove", "J.", ""], ["Vanmechelen", "K.", ""]]}, {"id": "1003.3543", "submitter": "Saber Jafarizadeh", "authors": "Saber Jafarizadeh", "title": "Fastest Distributed Consensus Problem on Fusion of Two Star Networks", "comments": "26 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding optimal weights for the problem of Fastest Distributed Consensus on\nnetworks with different topologies has been an active area of research for a\nnumber of years. Here in this work we present an analytical solution for the\nproblem of Fastest Distributed Consensus for a network formed from fusion of\ntwo different symmetric star networks or in other words a network consists of\ntwo different symmetric star networks which share the same central node. The\nsolution procedure consists of stratification of associated connectivity graph\nof network and Semidefinite Programming (SDP), particularly solving the\nslackness conditions, where the optimal weights are obtained by inductive\ncomparing of the characteristic polynomials initiated by slackness conditions.\nSome numerical simulations are carried out to investigate the trade-off between\nthe parameters of two fused star networks, namely the length and number of\nbranches.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2010 10:25:51 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2010 16:57:59 GMT"}], "update_date": "2010-03-29", "authors_parsed": [["Jafarizadeh", "Saber", ""]]}, {"id": "1003.3684", "submitter": "Andy Yoo", "authors": "Andy Yoo and Keith Henderson", "title": "Parallel Generation of Massive Scale-Free Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  One of the biggest huddles faced by researchers studying algorithms for\nmassive graphs is the lack of large input graphs that are essential for the\ndevelopment and test of the graph algorithms. This paper proposes two efficient\nand highly scalable parallel graph generation algorithms that can produce\nmassive realistic graphs to address this issue. The algorithms, designed to\nachieve high degree of parallelism by minimizing inter-processor\ncommunications, are two of the fastest graph generators which are capable of\ngenerating scale-free graphs with billions of vertices and edges. The synthetic\ngraphs generated by the proposed methods possess the most common properties of\nreal complex networks such as power-law degree distribution, small-worldness,\nand communities-within-communities. Scalability was tested on a large cluster\nat Lawrence Livermore National Laboratory. In the experiment, we were able to\ngenerate a graph with 1 billion vertices and 5 billion edges in less than 13\nseconds. To the best of our knowledge, this is the largest synthetic scale-free\ngraph reported in the literature.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2010 22:11:14 GMT"}], "update_date": "2010-03-22", "authors_parsed": [["Yoo", "Andy", ""], ["Henderson", "Keith", ""]]}, {"id": "1003.3866", "submitter": "Ali Khajeh-Hosseini", "authors": "Ali Khajeh-Hosseini, David Greenwood, James W. Smith, Ian Sommerville", "title": "The Cloud Adoption Toolkit: Addressing the Challenges of Cloud Adoption\n  in Enterprise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing promises a radical shift in the provisioning of computing\nresource within the enterprise. This paper: i) describes the challenges that\ndecision makers face when attempting to determine the feasibility of the\nadoption of cloud computing in their organisations; ii) illustrates a lack of\nexisting work to address the feasibility challenges of cloud adoption in the\nenterprise; iii) introduces the Cloud Adoption Toolkit that provides a\nframework to support decision makers in identifying their concerns, and\nmatching these concerns to appropriate tools/techniques that can be used to\naddress them. The paper adopts a position paper methodology such that case\nstudy evidence is provided, where available, to support claims. We conclude\nthat the Cloud Adoption Toolkit, whilst still under development, shows signs\nthat it is a useful tool for decision makers as it helps address the\nfeasibility challenges of cloud adoption in the enterprise.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2010 19:40:41 GMT"}, {"version": "v2", "created": "Thu, 13 May 2010 14:54:25 GMT"}], "update_date": "2010-05-14", "authors_parsed": [["Khajeh-Hosseini", "Ali", ""], ["Greenwood", "David", ""], ["Smith", "James W.", ""], ["Sommerville", "Ian", ""]]}, {"id": "1003.3920", "submitter": "Rajkumar Buyya", "authors": "Rajkumar Buyya, Rajiv Ranjan, Rodrigo N. Calheiros", "title": "InterCloud: Utility-Oriented Federation of Cloud Computing Environments\n  for Scaling of Application Services", "comments": "20 pages, 4 figures, 3 tables, conference paper", "journal-ref": "Proceedings of the 10th International Conference on Algorithms and\n  Architectures for Parallel Processing (ICA3PP 2010, Busan, South Korea, May\n  21-23, 2010), LNCS, Springer, Germany, 2010.", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing providers have setup several data centers at different\ngeographical locations over the Internet in order to optimally serve needs of\ntheir customers around the world. However, existing systems do not support\nmechanisms and policies for dynamically coordinating load distribution among\ndifferent Cloud-based data centers in order to determine optimal location for\nhosting application services to achieve reasonable QoS levels. Further, the\nCloud computing providers are unable to predict geographic distribution of\nusers consuming their services, hence the load coordination must happen\nautomatically, and distribution of services must change in response to changes\nin the load. To counter this problem, we advocate creation of federated Cloud\ncomputing environment (InterCloud) that facilitates just-in-time,\nopportunistic, and scalable provisioning of application services, consistently\nachieving QoS targets under variable workload, resource and network conditions.\nThe overall goal is to create a computing environment that supports dynamic\nexpansion or contraction of capabilities (VMs, services, storage, and database)\nfor handling sudden variations in service demands.\n  This paper presents vision, challenges, and architectural elements of\nInterCloud for utility-oriented federation of Cloud computing environments. The\nproposed InterCloud environment supports scaling of applications across\nmultiple vendor clouds. We have validated our approach by conducting a set of\nrigorous performance evaluation study using the CloudSim toolkit. The results\ndemonstrate that federated Cloud computing model has immense potential as it\noffers significant performance gains as regards to response time and cost\nsaving under dynamic workload scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 20 Mar 2010 10:54:43 GMT"}], "update_date": "2010-03-23", "authors_parsed": [["Buyya", "Rajkumar", ""], ["Ranjan", "Rajiv", ""], ["Calheiros", "Rodrigo N.", ""]]}, {"id": "1003.4066", "submitter": "William Jackson", "authors": "S. Vidhya, S. Karthikeyan", "title": "A Security Based Data Mining Approach in Data Grid", "comments": null, "journal-ref": "Journal of Computing, Volume 2, Issue 3, March 2010,\n  https://sites.google.com/site/journalofcomputing/", "doi": null, "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grid computing is the next logical step to distributed computing. Main\nobjective of grid computing is an innovative approach to share resources such\nas CPU usage; memory sharing and software sharing. Data Grids provide\ntransparent access to semantically related data resources in a heterogeneous\nsystem. The system incorporates both data mining and grid computing techniques\nwhere Grid application reduces the time for sending results to several clients\nat the same time and Data mining application on computational grids gives fast\nand sophisticated results to users. In this work, grid based data mining\ntechnique is used to do automatic allocation based on probabilistic mining\nfrequent sequence algorithm. It finds frequent sequences for many users at a\ntime with accurate result. It also includes the trust management architecture\nfor trust enhanced security.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2010 05:30:53 GMT"}], "update_date": "2010-03-23", "authors_parsed": [["Vidhya", "S.", ""], ["Karthikeyan", "S.", ""]]}, {"id": "1003.4074", "submitter": "William Jackson", "authors": "Shivaji P. Mirashe, N. V. Kalyankar", "title": "Cloud Computing", "comments": null, "journal-ref": "Journal of Computing, Volume 2, Issue 3, March 2010", "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing as you know it is about to change, your applications and documents\nare going to move from the desktop into the cloud. I'm talking about cloud\ncomputing, where applications and files are hosted on a \"cloud\" consisting of\nthousands of computers and servers, all linked together and accessible via the\nInternet. With cloud computing, everything you do is now web based instead of\nbeing desktop based. You can access all your programs and documents from any\ncomputer that's connected to the Internet. How will cloud computing change the\nway you work? For one thing, you're no longer tied to a single computer. You\ncan take your work anywhere because it's always accessible via the web. In\naddition, cloud computing facilitates group collaboration, as all group members\ncan access the same programs and documents from wherever they happen to be\nlocated. Cloud computing might sound far-fetched, but chances are you're\nalready using some cloud applications. If you're using a web-based email\nprogram, such as Gmail or Hotmail, you're computing in the cloud. If you're\nusing a web-based application such as Google Calendar or Apple Mobile Me,\nyou're computing in the cloud. If you're using a file- or photo-sharing site,\nsuch as Flickr or Picasa Web Albums, you're computing in the cloud. It's the\ntechnology of the future, available to use today.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2010 06:16:48 GMT"}], "update_date": "2010-03-23", "authors_parsed": [["Mirashe", "Shivaji P.", ""], ["Kalyankar", "N. V.", ""]]}, {"id": "1003.5238", "submitter": "Tuhin Sahai", "authors": "Stefan Klus, Tuhin Sahai, Cong Liu and Michael Dellnitz", "title": "An efficient algorithm for the parallel solution of high-dimensional\n  differential equations", "comments": null, "journal-ref": null, "doi": "10.1016/j.cam.2010.12.026", "report-no": null, "categories": "cs.DC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of high-dimensional differential equations is challenging and\ndifficult due to the analytical and computational intractability. Here, we\nimprove the speed of waveform relaxation (WR), a method to simulate\nhigh-dimensional differential-algebraic equations. This new method termed\nadaptive waveform relaxation (AWR) is tested on a communication network\nexample. Further we propose different heuristics for computing graph partitions\ntailored to adaptive waveform relaxation. We find that AWR coupled with\nappropriate graph partitioning methods provides a speedup by a factor between 3\nand 16.\n", "versions": [{"version": "v1", "created": "Fri, 26 Mar 2010 21:30:08 GMT"}, {"version": "v2", "created": "Tue, 24 Aug 2010 18:42:48 GMT"}, {"version": "v3", "created": "Tue, 26 Oct 2010 19:56:42 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Klus", "Stefan", ""], ["Sahai", "Tuhin", ""], ["Liu", "Cong", ""], ["Dellnitz", "Michael", ""]]}, {"id": "1003.5309", "submitter": "Michael Rabbat", "authors": "Alexandros G. Dimakis, Soummya Kar, Jose M.F. Moura, Michael G.\n  Rabbat, Anna Scaglione", "title": "Gossip Algorithms for Distributed Signal Processing", "comments": "Submitted to Proceedings of the IEEE, 29 pages", "journal-ref": null, "doi": "10.1109/JPROC.2010.2052531", "report-no": null, "categories": "cs.DC cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gossip algorithms are attractive for in-network processing in sensor networks\nbecause they do not require any specialized routing, there is no bottleneck or\nsingle point of failure, and they are robust to unreliable wireless network\nconditions. Recently, there has been a surge of activity in the computer\nscience, control, signal processing, and information theory communities,\ndeveloping faster and more robust gossip algorithms and deriving theoretical\nperformance guarantees. This article presents an overview of recent work in the\narea. We describe convergence rate results, which are related to the number of\ntransmitted messages and thus the amount of energy consumed in the network for\ngossiping. We discuss issues related to gossiping over wireless links,\nincluding the effects of quantization and noise, and we illustrate the use of\ngossip algorithms for canonical signal processing tasks including distributed\nestimation, source localization, and compression.\n", "versions": [{"version": "v1", "created": "Sat, 27 Mar 2010 16:20:14 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Dimakis", "Alexandros G.", ""], ["Kar", "Soummya", ""], ["Moura", "Jose M. F.", ""], ["Rabbat", "Michael G.", ""], ["Scaglione", "Anna", ""]]}, {"id": "1003.5342", "submitter": "Samih Mohammed Mostafa", "authors": "Samih Mohemmed Mostafa", "title": "Improving Waiting Time of Tasks Scheduled Under Preemptive Round Robin\n  Using Changeable Time Quantum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimizing waiting time for tasks waiting in the queue for execution is one\nof the important scheduling cri-teria which took a wide area in scheduling\npreemptive tasks. In this paper we present Changeable Time Quan-tum (CTQ)\napproach combined with the round-robin algorithm, we try to adjust the time\nquantum according to the burst times of the tasks in the ready queue. There are\ntwo important benefits of using (CTQ) approach: minimizing the average waiting\ntime of the tasks, consequently minimizing the average turnaround time, and\nkeeping the number of context switches as low as possible, consequently\nminimizing the scheduling overhead. In this paper, we consider the scheduling\nproblem for preemptive tasks, where the time costs of these tasks are known a\npriori. Our experimental results demonstrate that CTQ can provide much lower\nscheduling overhead and better scheduling criteria.\n", "versions": [{"version": "v1", "created": "Sun, 28 Mar 2010 06:34:20 GMT"}], "update_date": "2010-03-30", "authors_parsed": [["Mostafa", "Samih Mohemmed", ""]]}, {"id": "1003.5794", "submitter": "Jianfeng Zhan", "authors": "Wei Zhou, Lei Wang, Dan Meng, Lin Yuan, Jianfeng Zhan", "title": "Scalable Group Management in Large-Scale Virtualized Clusters", "comments": "9 pages", "journal-ref": "The Journal of High Technology Letters, January, 2011", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To save cost, recently more and more users choose to provision virtual\nmachine resources in cluster systems, especially in data centres. Maintaining a\nconsistent member view is the foundation of reliable cluster managements, and\nit also raises several challenge issues for large scale cluster systems\ndeployed with virtual machines (which we call virtualized clusters). In this\npaper, we introduce our experiences in design and implementation of scalable\nmember view management on large-scale virtual clusters. Our research\ncontributions are three-fold: 1) we propose a scalable and reliable management\ninfrastructure that combines a peer-to-peer structure and a hierarchy structure\nto maintain a consistent member view in virtual clusters; 2) we present a\nlight-weighted group membership algorithm that can reach the consistent member\nview within a single round of message exchange; and 3) we design and implement\na scalable membership service that can provision virtual machines and maintain\na consistent member view in virtual clusters. Our work is verified on Dawning\n5000A, which ranked No.10 of Top 500 super computers in November, 2008.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2010 11:22:55 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2010 00:52:51 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2010 08:35:50 GMT"}], "update_date": "2010-04-13", "authors_parsed": [["Zhou", "Wei", ""], ["Wang", "Lei", ""], ["Meng", "Dan", ""], ["Yuan", "Lin", ""], ["Zhan", "Jianfeng", ""]]}]