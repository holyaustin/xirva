[{"id": "1709.00105", "submitter": "Prasanna Kansakar", "authors": "Prasanna Kansakar and Arslan Munir and Neda Shabani", "title": "Technology in Hospitality Industry: Prospects and Challenges", "comments": "Accepted for publication in IEEE Consumer Electronics Magazine, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The leisure and hospitality industry is one of the driving forces of the\nglobal economy. The widespread adoption of new technologies in this industry\nover recent years has fundamentally reshaped the way in which services are\nprovided and received. In this paper, we explore some of the state-of-the-art\ntechnologies currently employed in the hospitality industry and how they are\nimproving guest experiences and changing the hospitality service platform. We\nalso envision some potential future hospitality services we can expect as the\nInternet of things (IoT) technology keeps growing. We recognize that the\ntechnological backbone of many hospitality establishments needs to be\noverhauled in order to facilitate the changing landscape of technology in the\nmodern world. We discuss some fundamental challenges that need to be overcome\nto institute a lasting future-proof solution for the hospitality industry. We\nalso touch upon the problems these challenges pose for guests and hospitality\nservice providers (HSP).\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 23:15:06 GMT"}, {"version": "v2", "created": "Tue, 6 Feb 2018 22:43:31 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Kansakar", "Prasanna", ""], ["Munir", "Arslan", ""], ["Shabani", "Neda", ""]]}, {"id": "1709.00196", "submitter": "Mehrdad Kiamari", "authors": "Mehrdad Kiamari, Chenwei Wang, and A. Salman Avestimehr", "title": "On Heterogeneous Coded Distributed Computing", "comments": "To appear in IEEE GLOBECOM 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the recently proposed Coded Distributed Computing (CDC) framework\nthat leverages carefully designed redundant computations to enable coding\nopportunities that substantially reduce the communication load of distributed\ncomputing. We generalize this framework to heterogeneous systems where\ndifferent nodes in the computing cluster can have different storage (or\nprocessing) capabilities. We provide the information-theoretically optimal data\nset placement and coded data shuffling scheme that minimizes the communication\nload in a cluster with 3 nodes. For clusters with $K>3$ nodes, we provide an\nalgorithm description to generalize our coding ideas to larger networks.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 08:26:41 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Kiamari", "Mehrdad", ""], ["Wang", "Chenwei", ""], ["Avestimehr", "A. Salman", ""]]}, {"id": "1709.00198", "submitter": "Miguel Matos", "authors": "Hugues Mercier, Laurent Hayez, Miguel Matos", "title": "Optimal epidemic dissemination", "comments": "A brief announcement of this work was presented at PODC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of reliable epidemic dissemination of a rumor in a\nfully connected network of~$n$ processes using push and pull operations. We\nrevisit the random phone call model and show that it is possible to disseminate\na rumor to all processes with high probability using $\\Theta(\\ln n)$ rounds of\ncommunication and only $n+o(n)$ messages of size $b$, all of which are\nasymptotically optimal and achievable with pull and push-then-pull algorithms.\nThis contradicts two highly-cited lower bounds of Karp et al. stating that any\nalgorithm in the random phone call model running in $\\mathcal{O}(\\ln n)$ rounds\nwith communication peers chosen uniformly at random requires at least\n$\\omega(n)$ messages to disseminate a rumor with high probability, and that any\naddress-oblivious algorithm needs $\\Omega(n \\ln \\ln n)$ messages regardless of\nthe number of communication rounds. The reason for this contradiction is that\nin the original work, processes do not have to share the rumor once the\ncommunication is established. However, it is implicitly assumed that they\nalways do so in the proofs of their lower bounds, which, it turns out, is not\noptimal. Our algorithms are strikingly simple, address-oblivious, and robust\nagainst $\\epsilon n$ adversarial failures and stochastic failures occurring\nwith probability $\\delta$ for any $0 \\leq \\{\\epsilon,\\delta\\} < 1$.\nFurthermore, they can handle multiple rumors of size $b \\in \\omega(\\ln n \\ln\n\\ln n)$ with $nb + o(nb)$ bits of communication per rumor.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 08:44:41 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Mercier", "Hugues", ""], ["Hayez", "Laurent", ""], ["Matos", "Miguel", ""]]}, {"id": "1709.00302", "submitter": "Rafael Rodriguez-Sanchez", "authors": "Rafael Rodr\\'iguez-S\\'anchez, Sandra Catal\\'an, Jos\\'e R. Herrero,\n  Enrique S. Quintana-Ort\\'i, Andr\\'es E. Tom\\'as", "title": "Look-Ahead in the Two-Sided Reduction to Compact Band Forms for\n  Symmetric Eigenvalue Problems and the SVD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the reduction to compact band forms, via unitary similarity\ntransformations, for the solution of symmetric eigenvalue problems and the\ncomputation of the singular value decomposition (SVD). Concretely, in the first\ncase we revisit the reduction to symmetric band form while, for the second\ncase, we propose a similar alternative, which transforms the original matrix to\n(unsymmetric) band form, replacing the conventional reduction method that\nproduces a triangular--band output. In both cases, we describe algorithmic\nvariants of the standard Level-3 BLAS-based procedures, enhanced with\nlook-ahead, to overcome the performance bottleneck imposed by the panel\nfactorization. Furthermore, our solutions employ an algorithmic block size that\ndiffers from the target bandwidth, illustrating the important performance\nbenefits of this decision. Finally, we show that our alternative compact band\nform for the SVD is key to introduce an effective look-ahead strategy into the\ncorresponding reduction procedure.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 13:34:32 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 12:52:00 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Rodr\u00edguez-S\u00e1nchez", "Rafael", ""], ["Catal\u00e1n", "Sandra", ""], ["Herrero", "Jos\u00e9 R.", ""], ["Quintana-Ort\u00ed", "Enrique S.", ""], ["Tom\u00e1s", "Andr\u00e9s E.", ""]]}, {"id": "1709.00333", "submitter": "Kyumars Sheykh Esmaili", "authors": "Philippe Dobbelaere and Kyumars Sheykh Esmaili", "title": "Kafka versus RabbitMQ", "comments": "25 single-column pages, 7 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Publish/subscribe is a distributed interaction paradigm well adapted to the\ndeployment of scalable and loosely coupled systems.\n  Apache Kafka and RabbitMQ are two popular open-source and\ncommercially-supported pub/sub systems that have been around for almost a\ndecade and have seen wide adoption. Given the popularity of these two systems\nand the fact that both are branded as pub/sub systems, two frequently asked\nquestions in the relevant online forums are: how do they compare against each\nother and which one to use?\n  In this paper, we frame the arguments in a holistic approach by establishing\na common comparison framework based on the core functionalities of pub/sub\nsystems. Using this framework, we then venture into a qualitative and\nquantitative (i.e. empirical) comparison of the common features of the two\nsystems. Additionally, we also highlight the distinct features that each of\nthese systems has. After enumerating a set of use cases that are best suited\nfor RabbitMQ or Kafka, we try to guide the reader through a determination table\nto choose the best architecture given his/her particular set of requirements.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 14:27:19 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Dobbelaere", "Philippe", ""], ["Esmaili", "Kyumars Sheykh", ""]]}, {"id": "1709.00411", "submitter": "Amir Varastehhajipour", "authors": "Amir Varasteh, Farzad Tashtarian, Maziar Goudarzi", "title": "On Reliability-Aware Server Consolidation in Cloud Datacenters", "comments": "International Symposium on Parallel and Distributed Computing\n  (ISPDC), Innsbruck, Austria, 2017", "journal-ref": null, "doi": "10.1109/ISPDC.2017.26", "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, datacenter (DC) energy consumption has become an\nimportant issue in technology world. Server consolidation using virtualization\nand virtual machine (VM) live migration allows cloud DCs to improve resource\nutilization and hence energy efficiency. In order to save energy, consolidation\ntechniques try to turn off the idle servers, while because of workload\nfluctuations, these offline servers should be turned on to support the\nincreased resource demands. These repeated on-off cycles could affect the\nhardware reliability and wear-and-tear of servers and as a result, increase the\nmaintenance and replacement costs. In this paper we propose a holistic\nmathematical model for reliability-aware server consolidation with the\nobjective of minimizing total DC costs including energy and reliability costs.\nIn fact, we try to minimize the number of active PMs and racks, in a\nreliability-aware manner. We formulate the problem as a Mixed Integer Linear\nProgramming (MILP) model which is in form of NP-complete. Finally, we evaluate\nthe performance of our approach in different scenarios using extensive\nnumerical MATLAB simulations.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 13:13:47 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Varasteh", "Amir", ""], ["Tashtarian", "Farzad", ""], ["Goudarzi", "Maziar", ""]]}, {"id": "1709.00412", "submitter": "Gregory Tsipenyuk", "authors": "Gregory Tsipenyuk, Jon Crowcroft", "title": "My Home is My Post-Office: Evaluation of a decentralized email\n  architecture on Internet-of-Things low-end device", "comments": "9 pages, 15 figures, 1 table, ICC'17, Cambridge, UK", "journal-ref": null, "doi": "10.1145/3018896.3018918", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users predominantly access their email via mobile devices. This presents a\ntwo-fold challenge to the email applications. First, email's update from\nmultiple devices has to be eventually reconciled with the server.\nPrioritization of updates is difficult and maybe undesirable. Solving this\nproblem requires a data store with the complete history of email changes.\nSecond, legacy email protocols don't provide an optimal email synchronization\nand access in mobile environment. In this paper we are proposing to take\nadvantage of the Internet of Things (IoT) phenomena. In IoT environment a user\nmay have multiple interconnected in-home low-end devices with publicly\naccessible address. In this architecture we move the email application from the\ncentral service into user's in-home and mobile devices, store complete email\nhistory on each device, and replace legacy IMAP and SMTP protocols with a\nsynchronization protocol found in Distributed Version Control Systems(DVCS).\nThis addresses the email reconciliation issue, optimizes the bandwidth usage,\nand intrinsically puts the user in control of her data. We analyze a number of\nstores and synchronization implementations and compare them with the open\nsource Dovecot email server.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 16:03:54 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Tsipenyuk", "Gregory", ""], ["Crowcroft", "Jon", ""]]}, {"id": "1709.00462", "submitter": "Xiang Sun", "authors": "Nirwan Ansari and Xiang Sun", "title": "Mobile Edge Computing Empowers Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a Mobile Edge Internet of Things (MEIoT)\narchitecture by leveraging the fiber-wireless access technology, the cloudlet\nconcept, and the software defined networking framework. The MEIoT architecture\nbrings computing and storage resources close to Internet of Things (IoT)\ndevices in order to speed up IoT data sharing and analytics. Specifically, the\nIoT devices (belonging to the same user) are associated to a specific proxy\nVirtual Machine (VM) in the nearby cloudlet. The proxy VM stores and analyzes\nthe IoT data (generated by its IoT devices) in real-time. Moreover, we\nintroduce the semantic and social IoT technology in the context of MEIoT to\nsolve the interoperability and inefficient access control problem in the IoT\nsystem. In addition, we propose two dynamic proxy VM migration methods to\nminimize the end-to-end delay between proxy VMs and their IoT devices and to\nminimize the total on-grid energy consumption of the cloudlets, respectively.\nPerformance of the proposed methods are validated via extensive simulations.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 20:10:58 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 16:55:27 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Ansari", "Nirwan", ""], ["Sun", "Xiang", ""]]}, {"id": "1709.00681", "submitter": "Archit Somani", "authors": "Sathya Peri, Ajay Singh and Archit Somani", "title": "Efficient means of Achieving Composability using Object based Conflicts\n  on Transactional Memory", "comments": "67 pages, 37 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Composing together the individual atomic methods of concurrent\ndata-structures (cds) pose multiple design and consistency challenges. In this\ncontext composition provided by transactions in software transaction memory\n(STM) can be handy. However, most of the STMs offer read/write primitives to\naccess shared cds. These read/write primitives result in unnecessary aborts.\nInstead, semantically rich higher-level methods of the underlying cds like\nlookup, insert or delete (in case of hash-table or lists) aid in ignoring\nunimportant lower level read/write conflicts and allow better concurrency. In\nthis paper, we adapt transaction tree model in databases to propose OSTM which\nenables efficient composition in cds. We extend the traditional notion of\nconflicts and legality to higher level methods of cds using STMs and lay down\ndetailed correctness proof to show that it is co-opaque. We implement OSTM with\nconcurrent closed addressed hash-table(HT-OSTM)and list (list-OSTM) which\nexports the higher-level operations as transaction interface. In our\nexperiments with varying workloads and randomly generated transaction\noperations, HT-OSTM shows speedup of 3 to 6 times and w.r.t aborts HT-OSTMis 3\nto 7 times better than ESTM and read/write based STM, respectively. Where\nas,list-OSTM outperforms state of the art lock-free transactional list, NOrec\nSTM list and boosted list by 30% to 80% across all workloads and scenarios.\nFurther,list-OSTM incurred negligible aborts in comparison to other techniques\nconsidered in the paper.\n", "versions": [{"version": "v1", "created": "Sun, 3 Sep 2017 08:22:44 GMT"}, {"version": "v2", "created": "Sun, 4 Mar 2018 14:38:12 GMT"}, {"version": "v3", "created": "Wed, 14 Mar 2018 07:44:54 GMT"}, {"version": "v4", "created": "Thu, 15 Mar 2018 12:42:29 GMT"}, {"version": "v5", "created": "Sat, 26 May 2018 07:17:34 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Peri", "Sathya", ""], ["Singh", "Ajay", ""], ["Somani", "Archit", ""]]}, {"id": "1709.00700", "submitter": "Sebastian Bre{\\ss}", "authors": "Sebastian Bre{\\ss} and Bastian K\\\"ocher and Henning Funke and Tilmann\n  Rabl and Volker Markl", "title": "Generating Custom Code for Efficient Query Execution on Heterogeneous\n  Processors", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Processor manufacturers build increasingly specialized processors to mitigate\nthe effects of the power wall to deliver improved performance. Currently,\ndatabase engines are manually optimized for each processor: A costly and error\nprone process.\n  In this paper, we propose concepts to enable the database engine to perform\nper-processor optimization automatically. Our core idea is to create variants\nof generated code and to learn a fast variant for each processor. We create\nvariants by modifying parallelization strategies, specializing data structures,\nand applying different code transformations.\n  Our experimental results show that the performance of variants may diverge up\nto two orders of magnitude. Therefore, we need to generate custom code for each\nprocessor to achieve peak performance. We show that our approach finds a fast\ncustom variant for multi-core CPUs, GPUs, and MICs.\n", "versions": [{"version": "v1", "created": "Sun, 3 Sep 2017 11:16:31 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Bre\u00df", "Sebastian", ""], ["K\u00f6cher", "Bastian", ""], ["Funke", "Henning", ""], ["Rabl", "Tilmann", ""], ["Markl", "Volker", ""]]}, {"id": "1709.00722", "submitter": "Kjell Winblad", "authors": "Kjell Winblad", "title": "Faster Concurrent Range Queries with Contention Adapting Search Trees\n  Using Immutable Data", "comments": "12 pages, 21 figures, To be published in 2017 Imperial College\n  Computing Student Workshop (ICCSW 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The need for scalable concurrent ordered set data structures with\nlinearizable range query support is increasing due to the rise of multicore\ncomputers, data processing platforms and in-memory databases. This paper\npresents a new concurrent ordered set with linearizable range query support.\nThe new data structure is based on the contention adapting search tree and an\nimmutable data structure. Experimental results show that the new data structure\nis as much as three times faster compared to related data structures. The data\nstructure scales well due to its ability to adapt the sizes of its immutable\nparts to the contention level and the sizes of the range queries.\n", "versions": [{"version": "v1", "created": "Sun, 3 Sep 2017 14:25:24 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Winblad", "Kjell", ""]]}, {"id": "1709.00821", "submitter": "Ximin Wang", "authors": "Lang-lang Xiong, Xi-min Wang, Song Liu, Zhi-yun Peng, and Shuang-ying\n  Zhong", "title": "The electromagnetic waves propagation in unmagnetized plasma media using\n  parallelized finite-difference time-domain method", "comments": "12 pages,3 figures", "journal-ref": "Lang-lang Xiong, Xi-min Wang, Song Liu, Zhi-yun Peng, Shuang-ying\n  Zhong, The electromagnetic waves propagation in unmagnetized plasma media\n  using parallelized finite-difference time-domain method, Optik, Volume 166,\n  August 2018, Pages 8-14", "doi": "10.1016/j.ijleo.2018.03.136", "report-no": null, "categories": "physics.comp-ph cs.CE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The finite-difference time-domain (FDTD) method has been commonly utilized to\nsimulate the electromagnetic (EM) waves propagation in the plasma media.\nHowever, the FDTD method may bring about extra run-time on concerning\ncomputationally large and complicated EM problems. Fortunately, the FDTD method\nis easy to parallelize. Besides, GPU has been widely used for parallel\ncomputing due to its unique SPMD (Single Program Multiple Data) architecture.\nIn this paper, we represent the parallel Runge-Kutta exponential time\ndifferencing scheme FDTD (RKETD) method for the unmagnetized plasma implemented\non GPU. The detailed flowchart of parallel RKETD-FDTD method is described. The\naccuracy and acceleration performance of the proposed parallel RKETD-FDTD\nmethod implemented on GPU are substantiated by calculating the reflection and\ntransmission coefficients for one-dimensional unmagnetized plasma slab. The\nresults indicate that the numerical precision of the parallel RKETD-FDTD scheme\nis consistent with that of the code implemented on CPU. The computation\nefficiency is greatly improved compared with merely CPU-based serial RKETD-FDTD\nmethod. Moreover, the comparisons of the performance of CUDA-based GPU parallel\nprogram, OpenMP (Open Multi-Processing)-based CPU parallel program, and\nsingle-CPU serial program on the same host computer are done. Compared with the\nserial program, both parallel programs get good results, while GPU-based\nparallel program gains better result.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 06:01:46 GMT"}, {"version": "v2", "created": "Wed, 6 Sep 2017 08:53:31 GMT"}, {"version": "v3", "created": "Thu, 12 Apr 2018 04:28:15 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Xiong", "Lang-lang", ""], ["Wang", "Xi-min", ""], ["Liu", "Song", ""], ["Peng", "Zhi-yun", ""], ["Zhong", "Shuang-ying", ""]]}, {"id": "1709.00877", "submitter": "Kaustav Bose", "authors": "Kaustav Bose, Ranendu Adhikary, Sruti Gan Chaudhuri, Buddhadeb Sau", "title": "Crash tolerant gathering on grid by asynchronous oblivious robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a system of autonomous mobile robots initially randomly deployed on\nthe nodes of an anonymous finite grid. A gathering algorithm is a sequence of\nmoves to be executed independently by each robot so that all robots meet at a\nsingle node after finite time. The robots operate in Look-Compute-Move cycles.\nIn each cycle, a robot takes a snapshot of the current configuration of the\ngrid in terms of occupied nodes (\\emph{Look}), then based on the perceived\nconfiguration, decides whether to stay put or to move to an adjacent node\n(\\emph{Compute}), and in the later case makes an instantaneous move accordingly\n(\\emph{Move}). The robots have \\emph{weak multiplicity detection} capability,\nwhich enables them to detect if a node is empty or occupied by a single robot\nor by multiple robots. The robots are \\emph{asynchronous}, \\emph{oblivious},\n\\emph{anonymous}, can not communicate with each other and execute the same\ndistributed algorithm. In a faulty system, however, any robot can \\emph{crash},\nwhich means that it becomes completely inactive and does not take part in the\nprocess any further. In that case a fault-tolerant gathering algorithm is an\nalgorithm that gathers all the non-faulty robots at a single node. This paper\nconsiders a faulty system that can have at most one crash fault. With these\nassumptions deterministic fault-tolerant gathering algorithms are presented\nthat gather all initial configurations that are gatherable in a non-faulty\nsystem, except for one specific configuration called the \\emph{2S2\nconfiguration}.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 09:44:47 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Bose", "Kaustav", ""], ["Adhikary", "Ranendu", ""], ["Chaudhuri", "Sruti Gan", ""], ["Sau", "Buddhadeb", ""]]}, {"id": "1709.00901", "submitter": "Christopher Purcell", "authors": "Jukka Kohonen, Janne H. Korhonen, Christopher Purcell, Jukka Suomela,\n  Przemys{\\l}aw Uzna\\'nski", "title": "Distributed Colour Reduction Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new, simple distributed algorithm for graph colouring in paths and\ncycles. Our algorithm is fast and self-contained, it does not need any globally\nconsistent orientation, and it reduces the number of colours from $10^{100}$ to\n$3$ in three iterations.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 11:17:46 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Kohonen", "Jukka", ""], ["Korhonen", "Janne H.", ""], ["Purcell", "Christopher", ""], ["Suomela", "Jukka", ""], ["Uzna\u0144ski", "Przemys\u0142aw", ""]]}, {"id": "1709.00953", "submitter": "Yushan Gao", "authors": "Yushan Gao, Thomas Blumensath", "title": "Distributed Computation of Linear Inverse Problems with Application to\n  Computed Tomography", "comments": "13 pages, 17 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inversion of linear systems is a fundamental step in many inverse\nproblems. Computational challenges exist when trying to invert large linear\nsystems, where limited computing resources mean that only part of the system\ncan be kept in computer memory at any one time. We are here motivated by\ntomographic inversion problems that often lead to linear inverse problems. In\nstate of the art x-ray systems, even a standard scan can produce 4 million\nindividual measurements and the reconstruction of x-ray attenuation profiles\ntypically requires the estimation of a million attenuation coefficients. To\ndeal with the large data sets encountered in real applications and to utilise\nmodern graphics processing unit (GPU) based computing architectures,\ncombinations of iterative reconstruction algorithms and parallel computing\nschemes are increasingly applied. Although both row and column action methods\nhave been proposed to utilise parallel computing architectures, individual\ncomputations in current methods need to know either the entire set of\nobservations or the entire set of estimated x-ray absorptions, which can be\nprohibitive in many realistic big data applications. We present a fully\nparallelizable computed tomography (CT) image reconstruction algorithm that\nworks with arbitrary partial subsets of the data and the reconstructed volume.\nWe further develop a non-homogeneously randomised selection criteria which\nguarantees that sub-matrices of the system matrix are selected more frequently\nif they are dense, thus maximising information flow through the algorithm. A\ngrouped version of the algorithm is also proposed to further improve\nconvergence speed and performance. Algorithm performance is verified\nexperimentally.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 13:38:06 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Gao", "Yushan", ""], ["Blumensath", "Thomas", ""]]}, {"id": "1709.01033", "submitter": "Sweta Kumari", "authors": "Ved Prakash Chaudhary, Chirag Juyal, Sandeep Kulkarni, Sweta Kumari,\n  Sathya Peri", "title": "Achieving Starvation-Freedom in Multi-Version Transactional Memory\n  Systems", "comments": "53 Pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software Transactional Memory systems (STMs) have garnered significant\ninterest as an elegant alternative for addressing synchronization and\nconcurrency issues with multi-threaded programming in multi-core systems.\nClient programs use STMs by issuing transactions. STM ensures that transaction\neither commits or aborts. A transaction aborted due to conflicts is typically\nre-issued with the expectation that it will complete successfully in a\nsubsequent incarnation. However, many existing STMs fail to provide starvation\nfreedom, i.e., in these systems, it is possible that concurrency conflicts may\nprevent an incarnated transaction from committing. To overcome this limitation,\nwe systematically derive a novel starvation free algorithm for multi-version\nSTM. Our algorithm can be used either with the case where the number of\nversions is unbounded and garbage collection is used or where only the latest K\nversions are maintained, KSFTM. We have demonstrated that our proposed\nalgorithm performs better than existing state-of-the-art STMs.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 16:35:27 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 09:30:07 GMT"}, {"version": "v3", "created": "Sun, 3 Jun 2018 10:11:43 GMT"}, {"version": "v4", "created": "Fri, 17 Aug 2018 11:46:27 GMT"}, {"version": "v5", "created": "Fri, 22 Mar 2019 12:00:58 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Chaudhary", "Ved Prakash", ""], ["Juyal", "Chirag", ""], ["Kulkarni", "Sandeep", ""], ["Kumari", "Sweta", ""], ["Peri", "Sathya", ""]]}, {"id": "1709.01054", "submitter": "Dylan Hutchison", "authors": "Dylan Hutchison", "title": "Distributed Triangle Counting in the Graphulo Matrix Math Library", "comments": "Honorable mention in the 2017 IEEE HPEC's Graph Challenge", "journal-ref": null, "doi": "10.1109/HPEC.2017.8091041", "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Triangle counting is a key algorithm for large graph analysis. The Graphulo\nlibrary provides a framework for implementing graph algorithms on the Apache\nAccumulo distributed database. In this work we adapt two algorithms for\ncounting triangles, one that uses the adjacency matrix and another that also\nuses the incidence matrix, to the Graphulo library for server-side processing\ninside Accumulo. Cloud-based experiments show a similar performance profile for\nthese different approaches on the family of power law Graph500 graphs, for\nwhich data skew increasingly bottlenecks. These results motivate the design of\nskew-aware hybrid algorithms that we propose for future work.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 06:03:31 GMT"}, {"version": "v2", "created": "Tue, 5 Sep 2017 04:37:43 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Hutchison", "Dylan", ""]]}, {"id": "1709.01142", "submitter": "Sebastian Neef", "authors": "Sebastian Neef", "title": "Implementation and Evaluation of a Framework to calculate Impact\n  Measures for Wikipedia Authors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.DB cs.DC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wikipedia, an open collaborative website, can be edited by anyone, even\nanonymously, thus becoming victim to ill-intentioned changes. Therefore,\nranking Wikipedia authors by calculating impact measures based on the edit\nhistory can help to identify reputational users or harmful activity such as\nvandalism \\cite{Adler:2008:MAC:1822258.1822279}. However, processing millions\nof edits on one system can take a long time. The author implements an open\nsource framework to calculate such rankings in a distributed way (MapReduce)\nand evaluates its performance on various sized datasets. A reimplementation of\nthe contribution measures by \\citeauthor{Adler:2008:MAC:1822258.1822279}\ndemonstrates its extensibility and usability, as well as problems of handling\nhuge datasets and their possible resolutions. The results put different\nperformance optimizations into perspective and show that horizontal scaling can\ndecrease the total processing time.\n", "versions": [{"version": "v1", "created": "Sat, 26 Aug 2017 21:33:02 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Neef", "Sebastian", ""]]}, {"id": "1709.01190", "submitter": "Yiqiu Wang", "authors": "Yiqiu Wang, Anshumali Shrivastava, Jonathan Wang, Junghee Ryu", "title": "FLASH: Randomized Algorithms Accelerated over CPU-GPU for Ultra-High\n  Dimensional Similarity Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.DC cs.IR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present FLASH (\\textbf{F}ast \\textbf{L}SH \\textbf{A}lgorithm for\n\\textbf{S}imilarity search accelerated with \\textbf{H}PC), a similarity search\nsystem for ultra-high dimensional datasets on a single machine, that does not\nrequire similarity computations and is tailored for high-performance computing\nplatforms. By leveraging a LSH style randomized indexing procedure and\ncombining it with several principled techniques, such as reservoir sampling,\nrecent advances in one-pass minwise hashing, and count based estimations, we\nreduce the computational and parallelization costs of similarity search, while\nretaining sound theoretical guarantees.\n  We evaluate FLASH on several real, high-dimensional datasets from different\ndomains, including text, malicious URL, click-through prediction, social\nnetworks, etc. Our experiments shed new light on the difficulties associated\nwith datasets having several million dimensions. Current state-of-the-art\nimplementations either fail on the presented scale or are orders of magnitude\nslower than FLASH. FLASH is capable of computing an approximate k-NN graph,\nfrom scratch, over the full webspam dataset (1.3 billion nonzeros) in less than\n10 seconds. Computing a full k-NN graph in less than 10 seconds on the webspam\ndataset, using brute-force ($n^2D$), will require at least 20 teraflops. We\nprovide CPU and GPU implementations of FLASH for replicability of our results.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 23:09:19 GMT"}, {"version": "v2", "created": "Tue, 3 Jul 2018 07:09:23 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Wang", "Yiqiu", ""], ["Shrivastava", "Anshumali", ""], ["Wang", "Jonathan", ""], ["Ryu", "Junghee", ""]]}, {"id": "1709.01363", "submitter": "Marcos Assuncao", "authors": "Marcos Dias de Assuncao, Alexandre da Silva Veith and Rajkumar Buyya", "title": "Distributed Data Stream Processing and Edge Computing: A Survey on\n  Resource Elasticity and Future Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under several emerging application scenarios, such as in smart cities,\noperational monitoring of large infrastructure, wearable assistance, and\nInternet of Things, continuous data streams must be processed under very short\ndelays. Several solutions, including multiple software engines, have been\ndeveloped for processing unbounded data streams in a scalable and efficient\nmanner. More recently, architecture has been proposed to use edge computing for\ndata stream processing. This paper surveys state of the art on stream\nprocessing engines and mechanisms for exploiting resource elasticity features\nof cloud computing in stream processing. Resource elasticity allows for an\napplication or service to scale out/in according to fluctuating demands.\nAlthough such features have been extensively investigated for enterprise\napplications, stream processing poses challenges on achieving elastic systems\nthat can make efficient resource management decisions based on current load.\nElasticity becomes even more challenging in highly distributed environments\ncomprising edge and cloud computing resources. This work examines some of these\nchallenges and discusses solutions proposed in the literature to address them.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 13:00:11 GMT"}, {"version": "v2", "created": "Sat, 2 Dec 2017 05:59:51 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["de Assuncao", "Marcos Dias", ""], ["Veith", "Alexandre da Silva", ""], ["Buyya", "Rajkumar", ""]]}, {"id": "1709.01384", "submitter": "Krzysztof Rzadca", "authors": "Pawel Janus and Krzysztof Rzadca", "title": "SLO-aware Colocation of Data Center Tasks Based on Instantaneous\n  Processor Requirements", "comments": "Author's version of a paper published in ACM SoCC'17", "journal-ref": "ACM SoCC'17, September 24-27, 2017, Santa Clara, CA, USA", "doi": "10.1145/3127479.3132244", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a cloud data center, a single physical machine simultaneously executes\ndozens of highly heterogeneous tasks. Such colocation results in more efficient\nutilization of machines, but, when tasks' requirements exceed available\nresources, some of the tasks might be throttled down or preempted. We analyze\nversion 2.1 of the Google cluster trace that shows short-term (1 second) task\nCPU usage. Contrary to the assumptions taken by many theoretical studies, we\ndemonstrate that the empirical distributions do not follow any single\ndistribution. However, high percentiles of the total processor usage (summed\nover at least 10 tasks) can be reasonably estimated by the Gaussian\ndistribution. We use this result for a probabilistic fit test, called the\nGaussian Percentile Approximation (GPA), for standard bin-packing algorithms.\nTo check whether a new task will fit into a machine, GPA checks whether the\nresulting distribution's percentile corresponding to the requested service\nlevel objective, SLO is still below the machine's capacity. In our simulation\nexperiments, GPA resulted in colocations exceeding the machines' capacity with\na frequency similar to the requested SLO.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 13:53:32 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Janus", "Pawel", ""], ["Rzadca", "Krzysztof", ""]]}, {"id": "1709.01440", "submitter": "V Lalitha", "authors": "Sneh Gupta and V. Lalitha", "title": "Locality-Aware Hybrid Coded MapReduce for Server-Rack Architecture", "comments": "5 pages, accepted to IEEE Information Theory Workshop (ITW) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MapReduce is a widely used framework for distributed computing. Data\nshuffling between the Map phase and Reduce phase of a job involves a large\namount of data transfer across servers, which in turn accounts for increase in\njob completion time. Recently, Coded MapReduce has been proposed to offer\nsavings with respect to the communication cost incurred in data shuffling. This\nis achieved by creating coded multicast opportunities for shuffling through\nrepeating Map tasks at multiple servers. We consider a server-rack architecture\nfor MapReduce and in this architecture, propose to divide the total\ncommunication cost into two: intra-rack communication cost and cross-rack\ncommunication cost. Having noted that cross-rack data transfer operates at\nlower speed as compared to intra-rack data transfer, we present a scheme termed\nas Hybrid Coded MapReduce which results in lower cross-rack communication than\nCoded MapReduce at the cost of increase in intra-rack communication. In\naddition, we pose the problem of assigning Map tasks to servers to maximize\ndata locality in the framework of Hybrid Coded MapReduce as a constrained\ninteger optimization problem. We show through simulations that data locality\ncan be improved considerably by using the solution of optimization to assign\nMap tasks to servers.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 13:10:35 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Gupta", "Sneh", ""], ["Lalitha", "V.", ""]]}, {"id": "1709.01494", "submitter": "Qin Xin", "authors": "Qin Xin and Yan Xia", "title": "Latency Optimal Broadcasting in Noisy Wireless Mesh Networks", "comments": "arXiv admin note: text overlap with arXiv:1705.07369 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we adopt a new noisy wireless network model introduced very\nrecently by Censor-Hillel et al. in [ACM PODC 2017, CHHZ17]. More specifically,\nfor a given noise parameter $p\\in [0,1],$ any sender has a probability of $p$\nof transmitting noise or any receiver of a single transmission in its\nneighborhood has a probability $p$ of receiving noise.\n  In this paper, we first propose a new asymptotically latency-optimal\napproximation algorithm (under faultless model) that can complete\nsingle-message broadcasting task in $D+O(\\log^2 n)$ time units/rounds in any\nWMN of size $n,$ and diameter $D$. We then show this diameter-linear\nbroadcasting algorithm remains robust under the noisy wireless network model\nand also improves the currently best known result in CHHZ17 by a\n$\\Theta(\\log\\log n)$ factor.\n  In this paper, we also further extend our robust single-message broadcasting\nalgorithm to $k$ multi-message broadcasting scenario and show it can broadcast\n$k$ messages in $O(D+k\\log n+\\log^2 n)$ time rounds. This new robust\nmulti-message broadcasting scheme is not only asymptotically optimal but also\nanswers affirmatively the problem left open in CHHZ17 on the existence of an\nalgorithm that is robust to sender and receiver faults and can broadcast $k$\nmessages in $O(D+k\\log n + polylog(n))$ time rounds.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 15:54:26 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Xin", "Qin", ""], ["Xia", "Yan", ""]]}, {"id": "1709.01619", "submitter": "Jonathan Regele", "authors": "Ben J. Zimmerman, Jonathan D. Regele, Bong Wie", "title": "A Comparative Study of 2D Numerical Methods with GPU Computing", "comments": "24 pages, 8 figures, 4 tables, 11 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphics Processing Unit (GPU) computing is becoming an alternate computing\nplatform for numerical simulations. However, it is not clear which numerical\nscheme will provide the highest computational efficiency for different types of\nproblems. To this end, numerical accuracies and computational work of several\nnumerical methods are compared using a GPU computing implementation. The\nCorrection Procedure via Reconstruction (CPR), Discontinuous Galerkin (DG),\nNodal Discontinuous Galerkin (NDG), Spectral Difference (SD), and Finite Volume\n(FV) methods are investigated using various reconstruction orders. Both smooth\nand discontinuous cases are considered for two-dimensional simulations. For\ndiscontinuous problems, MUSCL schemes are employed with FV, while CPR, DG, NDG,\nand SD use slope limiting. The computation time to reach a set error criteria\nand total time to complete solutions are compared across the methods. It is\nshown that while FV methods can produce solutions with low computational times,\nthey produce larger errors than high-order methods for smooth problems at the\nsame order of accuracy. For discontinuous problems, the methods show good\nagreement with one another in terms of solution profiles, and the total\ncomputational times between FV, CPR, and SD are comparable.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 22:58:36 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Zimmerman", "Ben J.", ""], ["Regele", "Jonathan D.", ""], ["Wie", "Bong", ""]]}, {"id": "1709.01812", "submitter": "Gil Vernik", "authors": "Gil Vernik, Michael Factor, Elliot K. Kolodner, Pietro Michiardi, Effi\n  Ofer, Francesco Pace", "title": "Stocator: A High Performance Object Store Connector for Spark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Stocator, a high performance object store connector for Apache\nSpark, that takes advantage of object store semantics. Previous connectors have\nassumed file system semantics, in particular, achieving fault tolerance and\nallowing speculative execution by creating temporary files to avoid\ninterference between worker threads executing the same task and then renaming\nthese files. Rename is not a native object store operation; not only is it not\natomic, but it is implemented using a costly copy operation and a delete.\nInstead our connector leverages the inherent atomicity of object creation, and\nby avoiding the rename paradigm it greatly decreases the number of operations\non the object store as well as enabling a much simpler approach to dealing with\nthe eventually consistent semantics typical of object stores. We have\nimplemented Stocator and shared it in open source. Performance testing shows\nthat it is as much as 18 times faster for write intensive workloads and\nperforms as much as 30 times fewer operations on the object store than the\nlegacy Hadoop connectors, reducing costs both for the client and the object\nstorage service provider.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 06:02:03 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Vernik", "Gil", ""], ["Factor", "Michael", ""], ["Kolodner", "Elliot K.", ""], ["Michiardi", "Pietro", ""], ["Ofer", "Effi", ""], ["Pace", "Francesco", ""]]}, {"id": "1709.01821", "submitter": "Ruben Mayer", "authors": "Ruben Mayer, Ahmad Slo, Muhammad Adnan Tariq, Kurt Rothermel, Manuel\n  Gr\\\"aber, Umakishore Ramachandran", "title": "SPECTRE: Supporting Consumption Policies in Window-Based Parallel\n  Complex Event Processing", "comments": "To be published in ACM/IFIP/USENIX Middleware 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Complex Event Processing (DCEP) is a paradigm to infer the\noccurrence of complex situations in the surrounding world from basic events\nlike sensor readings. In doing so, DCEP operators detect event patterns on\ntheir incoming event streams. To yield high operator throughput, data\nparallelization frameworks divide the incoming event streams of an operator\ninto overlapping windows that are processed in parallel by a number of operator\ninstances. In doing so, the basic assumption is that the different windows can\nbe processed independently from each other. However, consumption policies\nenforce that events can only be part of one pattern instance; then, they are\nconsumed, i.e., removed from further pattern detection. That implies that the\nconstituent events of a pattern instance detected in one window are excluded\nfrom all other windows as well, which breaks the data parallelism between\ndifferent windows. In this paper, we tackle this problem by means of\nspeculation: Based on the likelihood of an event's consumption in a window,\nsubsequent windows may speculatively suppress that event. We propose the\nSPECTRE framework for speculative processing of multiple dependent windows in\nparallel. Our evaluations show an up to linear scalability of SPECTRE with the\nnumber of CPU cores.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 13:46:20 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Mayer", "Ruben", ""], ["Slo", "Ahmad", ""], ["Tariq", "Muhammad Adnan", ""], ["Rothermel", "Kurt", ""], ["Gr\u00e4ber", "Manuel", ""], ["Ramachandran", "Umakishore", ""]]}, {"id": "1709.01879", "submitter": "Thibault Rieutord", "authors": "Damien Imbs, Petr Kuznetsov and Thibault Rieutord", "title": "Progress-Space Tradeoffs in Single-Writer Memory Implementations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most algorithms designed for shared-memory distributed systems assume the\nsingle-writer multi-reader (SWMR) setting where each process is provided with a\nunique register readable by all. In a system where computation is performed by\na bounded number n of processes coming from a very large (possibly unbounded)\nset of potential participants, the assumption of a SWMR memory is no longer\nreasonable. If only a bounded number of multi-writer multi-reader (MWMR)\nregisters are provided, we cannot rely on an a priori assignment of processes\nto registers. In this setting, simulating SWMR memory, or equivalently,\nensuring stable writing (i.e., every written value persists in the memory), is\ndesirable.\n  In this paper, we propose a SWMR simulation that adapts the number of MWMR\nregisters used to the desired progress condition. For any given k from 1 to n,\nwe present an algorithm that uses only n+k-1 registers to simulate a\nk-lock-free SWMR memory. We also give a matching lower bound of n+1 registers\nrequired for the case of 2-lock-freedom, which supports our conjectures that\nthe algorithm is space-optimal. Our lower bound holds for the strictly weaker\nprogress condition of 2-obstruction-freedom, which suggests that the space\ncomplexity for k-obstruction-free and k-lock-free SWMR simulations might\ncoincide.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 16:25:50 GMT"}, {"version": "v2", "created": "Mon, 27 Nov 2017 09:10:51 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Imbs", "Damien", ""], ["Kuznetsov", "Petr", ""], ["Rieutord", "Thibault", ""]]}, {"id": "1709.01921", "submitter": "Surat Teerapittayanon", "authors": "Surat Teerapittayanon, Bradley McDanel and H.T. Kung", "title": "Distributed Deep Neural Networks over the Cloud, the Edge and End\n  Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose distributed deep neural networks (DDNNs) over distributed\ncomputing hierarchies, consisting of the cloud, the edge (fog) and end devices.\nWhile being able to accommodate inference of a deep neural network (DNN) in the\ncloud, a DDNN also allows fast and localized inference using shallow portions\nof the neural network at the edge and end devices. When supported by a scalable\ndistributed computing hierarchy, a DDNN can scale up in neural network size and\nscale out in geographical span. Due to its distributed nature, DDNNs enhance\nsensor fusion, system fault tolerance and data privacy for DNN applications. In\nimplementing a DDNN, we map sections of a DNN onto a distributed computing\nhierarchy. By jointly training these sections, we minimize communication and\nresource usage for devices and maximize usefulness of extracted features which\nare utilized in the cloud. The resulting system has built-in support for\nautomatic sensor fusion and fault tolerance. As a proof of concept, we show a\nDDNN can exploit geographical diversity of sensors to improve object\nrecognition accuracy and reduce communication cost. In our experiment, compared\nwith the traditional method of offloading raw sensor data to be processed in\nthe cloud, DDNN locally processes most sensor data on end devices while\nachieving high accuracy and is able to reduce the communication cost by a\nfactor of over 20x.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 04:00:18 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Teerapittayanon", "Surat", ""], ["McDanel", "Bradley", ""], ["Kung", "H. T.", ""]]}, {"id": "1709.02091", "submitter": "Daning Cheng", "authors": "Daning Cheng, Shigang Li and Yunquan Zhang", "title": "Asynchronous COMID: the theoretic basis for transmitted data\n  sparsification tricks on Parameter Server", "comments": "asynchronous COMID, parameter server, FTRL, $L2$ norm regularization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asynchronous FTRL-proximal and L2 norm done at server are two widely used\ntricks in Parameters Server which is an implement of delayed SGD. Their\ncommonness is leaving parts of updating computation on server which reduces the\nburden of network via making transmitted data sparse. But above tricks'\nconvergences are not well-proved. In this paper, based on above commonness, we\npropose a more general algorithm named as asynchronous COMID and prove its\nconvergence. We prove that asynchronous FTRL-proximal and L2 norm done at\nserver are applications of asynchronous COMID, which demonstrates the\nconvergences of above two tricks. Then, we conduct experiments to verify\ntheoretical results. Experimental results show that compared with delayed SGD\non Parameters Server, asynchronous COMID reduces the burden of the network\nwithout any harm on the mathematical convergence speed and final output.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 06:48:29 GMT"}, {"version": "v2", "created": "Mon, 11 Sep 2017 12:41:55 GMT"}, {"version": "v3", "created": "Tue, 12 Sep 2017 14:02:46 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Cheng", "Daning", ""], ["Li", "Shigang", ""], ["Zhang", "Yunquan", ""]]}, {"id": "1709.02108", "submitter": "EPTCS", "authors": "Andrei Sandler (University of Hertfordshire), Olga Tveretina\n  (University of Hertfordshire)", "title": "ParaPlan: A Tool for Parallel Reachability Analysis of Planar Polygonal\n  Differential Inclusion Systems", "comments": "In Proceedings GandALF 2017, arXiv:1709.01761", "journal-ref": "EPTCS 256, 2017, pp. 283-296", "doi": "10.4204/EPTCS.256.20", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the ParaPlan tool which provides the reachability analysis of\nplanar hybrid systems defined by differential inclusions (SPDI). It uses the\nparallelized and optimized version of the algorithm underlying the SPeeDI tool.\nThe performance comparison demonstrates the speed-up of up to 83 times with\nrespect to the sequential implementation on various benchmarks. Some of the\nbenchmarks we used are randomly generated with the novel approach based on the\npartitioning of the plane with Voronoi diagrams.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 07:00:38 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Sandler", "Andrei", "", "University of Hertfordshire"], ["Tveretina", "Olga", "", "University of Hertfordshire"]]}, {"id": "1709.02125", "submitter": "Istv\\'an Z Reguly", "authors": "Istvan Z Reguly, Gihan R Mudalige, Michael B Giles", "title": "Beyond 16GB: Out-of-Core Stencil Computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stencil computations are a key class of applications, widely used in the\nscientific computing community, and a class that has particularly benefited\nfrom performance improvements on architectures with high memory bandwidth.\nUnfortunately, such architectures come with a limited amount of fast memory,\nwhich is limiting the size of the problems that can be efficiently solved. In\nthis paper, we address this challenge by applying the well-known cache-blocking\ntiling technique to large scale stencil codes implemented using the OPS domain\nspecific language, such as CloverLeaf 2D, CloverLeaf 3D, and OpenSBLI. We\nintroduce a number of techniques and optimisations to help manage data resident\nin fast memory, and minimise data movement. Evaluating our work on Intel's\nKnights Landing Platform as well as NVIDIA P100 GPUs, we demonstrate that it is\npossible to solve 3 times larger problems than the on-chip memory size with at\nmost 15\\% loss in efficiency\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 07:58:39 GMT"}, {"version": "v2", "created": "Thu, 26 Oct 2017 12:16:00 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Reguly", "Istvan Z", ""], ["Mudalige", "Gihan R", ""], ["Giles", "Michael B", ""]]}, {"id": "1709.02225", "submitter": "Niv Gabso", "authors": "Assaf Yifrach, Niv Gabso", "title": "Enhancing KiWi - Scalable Concurrent Key-Value Map", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We take a relatively fresh wait-free, concurrent sorted map called KiWi, fix\nand enhance it. First, we test its linearizability by fuzzing and applying\nWing&Gong [2] linearizability test. After fixing a few bugs in the algorithm\ndesign and its implementation, we enhance it. We design, implement and test two\nnew linearizable operations sizeLowerBound() and sizeUpperBound(). We further\ncompose these operations to create more useful operations. Last, we evaluate\nthe map performance because previous evaluations became obsolete due to our bug\ncorrections.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 13:23:27 GMT"}, {"version": "v2", "created": "Fri, 13 Oct 2017 06:02:36 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["Yifrach", "Assaf", ""], ["Gabso", "Niv", ""]]}, {"id": "1709.02287", "submitter": "Patricia Binder", "authors": "Patricia Binder, Michael Muma, Abdelhak M. Zoubir", "title": "Gravitational Clustering: A Simple, Robust and Adaptive Approach for\n  Distributed Networks", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed signal processing for wireless sensor networks enables that\ndifferent devices cooperate to solve different signal processing tasks. A\ncrucial first step is to answer the question: who observes what? Recently,\nseveral distributed algorithms have been proposed, which frame the\nsignal/object labelling problem in terms of cluster analysis after extracting\nsource-specific features, however, the number of clusters is assumed to be\nknown. We propose a new method called Gravitational Clustering (GC) to\nadaptively estimate the time-varying number of clusters based on a set of\nfeature vectors. The key idea is to exploit the physical principle of\ngravitational force between mass units: streaming-in feature vectors are\nconsidered as mass units of fixed position in the feature space, around which\nmobile mass units are injected at each time instant. The cluster enumeration\nexploits the fact that the highest attraction on the mobile mass units is\nexerted by regions with a high density of feature vectors, i.e., gravitational\nclusters. By sharing estimates among neighboring nodes via a\ndiffusion-adaptation scheme, cooperative and distributed cluster enumeration is\nachieved. Numerical experiments concerning robustness against outliers,\nconvergence and computational complexity are conducted. The application in a\ndistributed cooperative multi-view camera network illustrates the applicability\nto real-world problems.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 12:05:17 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Binder", "Patricia", ""], ["Muma", "Michael", ""], ["Zoubir", "Abdelhak M.", ""]]}, {"id": "1709.02327", "submitter": "Claudio Reggiani", "authors": "Claudio Reggiani, Yann-A\\\"el Le Borgne, Gianluca Bontempi", "title": "Feature selection in high-dimensional dataset using MapReduce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a distributed MapReduce implementation of the minimum\nRedundancy Maximum Relevance algorithm, a popular feature selection method in\nbioinformatics and network inference problems. The proposed approach handles\nboth tall/narrow and wide/short datasets. We further provide an open source\nimplementation based on Hadoop/Spark, and illustrate its scalability on\ndatasets involving millions of observations or features.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 16:05:51 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Reggiani", "Claudio", ""], ["Borgne", "Yann-A\u00ebl Le", ""], ["Bontempi", "Gianluca", ""]]}, {"id": "1709.02381", "submitter": "S. Karen Khatamifard", "authors": "S. Karen Khatamifard, Zamshed Chowdhury, Nakul Pande, Meisam\n  Razaviyayn, Chris Kim, Ulya R. Karpuzcu", "title": "Read Mapping Near Non-Volatile Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DNA sequencing is the physical/biochemical process of identifying the\nlocation of the four bases (Adenine, Guanine, Cytosine, Thymine) in a DNA\nstrand. As semiconductor technology revolutionized computing, modern DNA\nsequencing technology (termed Next Generation Sequencing, NGS)revolutionized\ngenomic research. As a result, modern NGS platforms can sequence hundreds of\nmillions of short DNA fragments in parallel. The sequenced DNA fragments,\nrepresenting the output of NGS platforms, are termed reads. Besides genomic\nvariations, NGS imperfections induce noise in reads. Mapping each read to (the\nmost similar portion of) a reference genome of the same species, i.e., read\nmapping, is a common critical first step in a diverse set of emerging\nbioinformatics applications. Mapping represents a search-heavy memory-intensive\nsimilarity matching problem, therefore, can greatly benefit from near-memory\nprocessing. Intuition suggests using fast associative search enabled by Ternary\nContent Addressable Memory (TCAM) by construction. However, the excessive\nenergy consumption and lack of support for similarity matching (under NGS and\ngenomic variation induced noise) renders direct application of TCAM infeasible,\nirrespective of volatility, where only non-volatile TCAM can accommodate the\nlarge memory footprint in an area-efficient way. This paper introduces GeNVoM,\na scalable, energy-efficient and high-throughput solution. Instead of\noptimizing an algorithm developed for general-purpose computers or GPUs, GeNVoM\nrethinks the algorithm and non-volatile TCAM-based accelerator design together\nfrom the ground up. Thereby GeNVoM can improve the throughput by up to 113.5\ntimes (3.6); the energy consumption, by up to 210.9 times (1.36), when compared\nto a GPU (accelerator) baseline, which represents one of the highest-throughput\nimplementations known.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 03:51:51 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2018 23:54:43 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 15:20:47 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Khatamifard", "S. Karen", ""], ["Chowdhury", "Zamshed", ""], ["Pande", "Nakul", ""], ["Razaviyayn", "Meisam", ""], ["Kim", "Chris", ""], ["Karpuzcu", "Ulya R.", ""]]}, {"id": "1709.02425", "submitter": "Joshua Daymude", "authors": "Marta Andr\\'es Arroyo, Sarah Cannon, Joshua J. Daymude, Dana Randall,\n  Andr\\'ea W. Richa", "title": "A Stochastic Approach to Shortcut Bridging in Programmable Matter", "comments": "Published in Proc. of DNA23: DNA Computing and Molecular Programming\n  - 23rd International Conference, 2017. An updated journal version will appear\n  in the DNA23 Special Issue of Natural Computing", "journal-ref": "Natural Computing 17:4 (2018) 723-741", "doi": "10.1007/s11047-018-9714-x", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a self-organizing particle system, an abstraction of programmable matter,\nsimple computational elements called particles with limited memory and\ncommunication self-organize to solve system-wide problems of movement,\ncoordination, and configuration. In this paper, we consider a stochastic,\ndistributed, local, asynchronous algorithm for \"shortcut bridging\", in which\nparticles self-assemble bridges over gaps that simultaneously balance\nminimizing the length and cost of the bridge. Army ants of the genus Eciton\nhave been observed exhibiting a similar behavior in their foraging trails,\ndynamically adjusting their bridges to satisfy an efficiency trade-off using\nlocal interactions. Using techniques from Markov chain analysis, we rigorously\nanalyze our algorithm, show it achieves a near-optimal balance between the\ncompeting factors of path length and bridge cost, and prove that it exhibits a\ndependence on the angle of the gap being \"shortcut\" similar to that of the ant\nbridges. We also present simulation results that qualitatively compare our\nalgorithm with the army ant bridging behavior. Our work gives a plausible\nexplanation of how convergence to globally optimal configurations can be\nachieved via local interactions by simple organisms (e.g., ants) with some\nlimited computational power and access to random bits. The proposed algorithm\nalso demonstrates the robustness of the stochastic approach to algorithms for\nprogrammable matter, as it is a surprisingly simple extension of our previous\nstochastic algorithm for compression.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 19:50:01 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 22:23:34 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Arroyo", "Marta Andr\u00e9s", ""], ["Cannon", "Sarah", ""], ["Daymude", "Joshua J.", ""], ["Randall", "Dana", ""], ["Richa", "Andr\u00e9a W.", ""]]}, {"id": "1709.02500", "submitter": "Mark Amo-Boateng PhD.", "authors": "Mark Amo-Boateng", "title": "Super-speeds with Zero-RAM: Next Generation Large-Scale Optimization in\n  Your Laptop!", "comments": "7 pages, 4 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.DS cs.PF math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents the novel breakthrough general purpose algorithm for\nlarge scale optimization problems. The novel algorithm is capable of achieving\nbreakthrough speeds for very large-scale optimization on general purpose\nlaptops and embedded systems. Application of the algorithm to the Griewank\nfunction was possible in up to 1 billion decision variables in double precision\ntook only 64485 seconds (~18 hours) to solve, while consuming 7,630 MB (7.6 GB)\nor RAM on a single threaded laptop CPU. It shows that the algorithm is\ncomputationally and memory (space) linearly efficient, and can find the optimal\nor near-optimal solution in a fraction of the time and memory that many\nconventional algorithms require. It is envisaged that this will open up new\npossibilities of real-time large-scale problems on personal laptops and\nembedded systems.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 01:47:56 GMT"}, {"version": "v2", "created": "Mon, 11 Sep 2017 01:14:46 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Amo-Boateng", "Mark", ""]]}, {"id": "1709.02520", "submitter": "Dmitri Arkhipov", "authors": "Dmitri I. Arkhipov, Di Wu, Keqin Li, Amelia C. Regan", "title": "Sorting with GPUs: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sorting is a fundamental operation in computer science and is a bottleneck in\nmany important fields. Sorting is critical to database applications, online\nsearch and indexing,biomedical computing, and many other applications. The\nexplosive growth in computational power and availability of GPU coprocessors\nhas allowed sort operations on GPUs to be done much faster than any\nequivalently priced CPU. Current trends in GPU computing shows that this\nexplosive growth in GPU capabilities is likely to continue for some time. As\nsuch, there is a need to develop algorithms to effectively harness the power of\nGPUs for crucial applications such as sorting.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 03:32:57 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Arkhipov", "Dmitri I.", ""], ["Wu", "Di", ""], ["Li", "Keqin", ""], ["Regan", "Amelia C.", ""]]}, {"id": "1709.02533", "submitter": "Ahmed Mahmood", "authors": "Ahmed R. Mahmood, Anas Daghistani, Ahmed M. Aly, Walid G. Aref,\n  Mingjie Tang, Saleh Basalamah, Sunil Prabhakar", "title": "Adaptive Processing of Spatial-Keyword Data Over a Distributed Streaming\n  Cluster", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread use of GPS-enabled smartphones along with the popularity of\nmicro-blogging and social networking applications, e.g., Twitter and Facebook,\nhas resulted in the generation of huge streams of geo-tagged textual data. Many\napplications require real-time processing of these streams. For example,\nlocation-based e-coupon and ad-targeting systems enable advertisers to register\nmillions of ads to millions of users. The number of users is typically very\nhigh and they are continuously moving, and the ads change frequently as well.\nHence sending the right ad to the matching users is very challenging. Existing\nstreaming systems are either centralized or are not spatial-keyword aware, and\ncannot efficiently support the processing of rapidly arriving spatial-keyword\ndata streams. This paper presents Tornado, a distributed spatial-keyword stream\nprocessing system. Tornado features routing units to fairly distribute the\nworkload, and furthermore, co-locate the data objects and the corresponding\nqueries at the same processing units. The routing units use the Augmented-Grid,\na novel structure that is equipped with an efficient search algorithm for\ndistributing the data objects and queries. Tornado uses evaluators to process\nthe data objects against the queries. The routing units minimize the redundant\ncommunication by not sending data updates for processing when these updates do\nnot match any query. By applying dynamically evaluated cost formulae that\ncontinuously represent the processing overhead at each evaluator, Tornado is\nadaptive to changes in the workload. Extensive experimental evaluation using\nspatio-textual range queries over real Twitter data indicates that Tornado\noutperforms the non-spatio-textually aware approaches by up to two orders of\nmagnitude in terms of the overall system throughput.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 04:37:44 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Mahmood", "Ahmed R.", ""], ["Daghistani", "Anas", ""], ["Aly", "Ahmed M.", ""], ["Aref", "Walid G.", ""], ["Tang", "Mingjie", ""], ["Basalamah", "Saleh", ""], ["Prabhakar", "Sunil", ""]]}, {"id": "1709.02599", "submitter": "Stepan Kochemazov", "authors": "Stepan Kochemazov, Eduard Vatutin, Oleg Zaikin", "title": "Fast Algorithm for Enumerating Diagonal Latin Squares of Small Order", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose an algorithm for enumerating diagonal Latin squares\nof small order. It relies on specific properties of diagonal Latin squares to\nemploy symmetry breaking techniques, and on several heuristic optimizations and\nbit arithmetic techniques to make use of computational power of\nstate-of-the-art CPUs. Using this approach we enumerated diagonal Latin squares\nof order at most 9, and vertically symmetric diagonal Latin squares of order at\nmost 10.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 09:07:14 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Kochemazov", "Stepan", ""], ["Vatutin", "Eduard", ""], ["Zaikin", "Oleg", ""]]}, {"id": "1709.02610", "submitter": "Nachshon Cohen", "authors": "Nachshon Cohen, Michal Friedman, James R. Larus", "title": "Efficient Logging in Non-Volatile Memory by Exploiting Coherency\n  Protocols", "comments": null, "journal-ref": null, "doi": "10.1145/3133891", "report-no": null, "categories": "cs.DC cs.DB cs.PL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Non-volatile memory (NVM) technologies such as PCM, ReRAM and STT-RAM allow\nprocessors to directly write values to persistent storage at speeds that are\nsignificantly faster than previous durable media such as hard drives or SSDs.\nMany applications of NVM are constructed on a logging subsystem, which enables\noperations to appear to execute atomically and facilitates recovery from\nfailures. Writes to NVM, however, pass through a processor's memory system,\nwhich can delay and reorder them and can impair the correctness and cost of\nlogging algorithms.\n  Reordering arises because of out-of-order execution in a CPU and the\ninter-processor cache coherence protocol. By carefully considering the\nproperties of these reorderings, this paper develops a logging protocol that\nrequires only one round trip to non-volatile memory while avoiding expensive\ncomputations. We show how to extend the logging protocol to building a\npersistent set (hash map) that also requires only a single round trip to\nnon-volatile memory for insertion, updating, or deletion.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 09:35:29 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Cohen", "Nachshon", ""], ["Friedman", "Michal", ""], ["Larus", "James R.", ""]]}, {"id": "1709.02718", "submitter": "Mayank Mishra", "authors": "Mayank Mishra and Arun K. Somani", "title": "On-Disk Data Processing: Issues and Future Directions", "comments": "24 pages, 17 Figures, 3 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a survey of \"on-disk\" data processing (ODDP). ODDP,\nwhich is a form of near-data processing, refers to the computing arrangement\nwhere the secondary storage drives have the data processing capability.\nProposed ODDP schemes vary widely in terms of the data processing capability,\ntarget applications, architecture and the kind of storage drive employed. Some\nODDP schemes provide only a specific but heavily used operation like sort\nwhereas some provide a full range of operations. Recently, with the advent of\nSolid State Drives, powerful and extensive ODDP solutions have been proposed.\nIn this paper, we present a thorough review of architectures developed for\ndifferent on-disk processing approaches along with current and future\nchallenges and also identify the future directions which ODDP can take.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 14:28:12 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Mishra", "Mayank", ""], ["Somani", "Arun K.", ""]]}, {"id": "1709.02877", "submitter": "Vincent Cicirello", "authors": "Vincent A. Cicirello", "title": "Variable Annealing Length and Parallelism in Simulated Annealing", "comments": "Tenth International Symposium on Combinatorial Search, pages 2-10.\n  June 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose: (a) a restart schedule for an adaptive simulated\nannealer, and (b) parallel simulated annealing, with an adaptive and\nparameter-free annealing schedule. The foundation of our approach is the\nModified Lam annealing schedule, which adaptively controls the temperature\nparameter to track a theoretically ideal rate of acceptance of neighboring\nstates. A sequential implementation of Modified Lam simulated annealing is\nalmost parameter-free. However, it requires prior knowledge of the annealing\nlength. We eliminate this parameter using restarts, with an exponentially\nincreasing schedule of annealing lengths. We then extend this restart schedule\nto parallel implementation, executing several Modified Lam simulated annealers\nin parallel, with varying initial annealing lengths, and our proposed parallel\nannealing length schedule. To validate our approach, we conduct experiments on\nan NP-Hard scheduling problem with sequence-dependent setup constraints. We\ncompare our approach to fixed length restarts, both sequentially and in\nparallel. Our results show that our approach can achieve substantial\nperformance gains, throughout the course of the run, demonstrating our approach\nto be an effective anytime algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 23:05:55 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Cicirello", "Vincent A.", ""]]}, {"id": "1709.02946", "submitter": "Do Le Quoc", "authors": "Do Le Quoc, Ruichuan Chen, Pramod Bhatotia, Christof Fetze, Volker\n  Hilt, Thorsten Strufe", "title": "Approximate Stream Analytics in Apache Flink and Apache Spark Streaming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate computing aims for efficient execution of workflows where an\napproximate output is sufficient instead of the exact output. The idea behind\napproximate computing is to compute over a representative sample instead of the\nentire input dataset. Thus, approximate computing - based on the chosen sample\nsize - can make a systematic trade-off between the output accuracy and\ncomputation efficiency.\n  Unfortunately, the state-of-the-art systems for approximate computing\nprimarily target batch analytics, where the input data remains unchanged during\nthe course of sampling. Thus, they are not well-suited for stream analytics.\nThis motivated the design of StreamApprox - a stream analytics system for\napproximate computing. To realize this idea, we designed an online stratified\nreservoir sampling algorithm to produce approximate output with rigorous error\nbounds. Importantly, our proposed algorithm is generic and can be applied to\ntwo prominent types of stream processing systems: (1) batched stream processing\nsuch as Apache Spark Streaming, and (2) pipelined stream processing such as\nApache Flink.\n  We evaluated StreamApprox using a set of microbenchmarks and real-world case\nstudies. Our results show that Spark- and Flink-based StreamApprox systems\nachieve a speedup of $1.15\\times$-$3\\times$ compared to the respective native\nSpark Streaming and Flink executions, with varying sampling fraction of $80\\%$\nto $10\\%$. Furthermore, we have also implemented an improved baseline in\naddition to the native execution baseline - a Spark-based approximate computing\nsystem leveraging the existing sampling modules in Apache Spark. Compared to\nthe improved baseline, our results show that StreamApprox achieves a speedup\n$1.1\\times$-$2.4\\times$ while maintaining the same accuracy level.\n", "versions": [{"version": "v1", "created": "Sat, 9 Sep 2017 11:59:44 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Quoc", "Do Le", ""], ["Chen", "Ruichuan", ""], ["Bhatotia", "Pramod", ""], ["Fetze", "Christof", ""], ["Hilt", "Volker", ""], ["Strufe", "Thorsten", ""]]}, {"id": "1709.03110", "submitter": "Da Yan", "authors": "Da Yan, Hongzhi Chen, James Cheng, M.Tamer \\\"Ozsu, Qizhen Zhang, John\n  C.S. Lui", "title": "G-thinker: Big Graph Mining Made Easier and Faster", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a general system for compute-intensive graph mining tasks\nthat find from a big graph all subgraphs that satisfy certain requirements\n(e.g., graph matching and community detection). Due to the broad range of\napplications of such tasks, many single-threaded algorithms have been proposed.\nHowever, graphs such as online social networks and knowledge graphs often have\nbillions of vertices and edges, which require distributed processing in order\nto scale. Unfortunately, existing distributed graph processing systems such as\nPregel and GraphLab are designed for data-intensive analytics, and are\ninefficient for compute-intensive graph mining tasks since computation over any\ndata is coupled with the data's access that involves network transmission. We\npropose a distributed graph mining framework, called G-thinker, which is\ndesigned for compute-intensive graph mining workloads. G-thinker provides an\nintuitive graph-exploration API for the convenient implementation of various\ngraph mining algorithms, and the runtime engine provides efficient execution\nwith bounded memory consumption, light network communication, and parallelism\nbetween computation and communication. Extensive experiments were conducted,\nwhich demonstrate that G-thinker is orders of magnitude faster than existing\nsolution, and can scale to graphs that are two orders of magnitude larger given\nthe same hardware resources.\n", "versions": [{"version": "v1", "created": "Sun, 10 Sep 2017 15:05:52 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Yan", "Da", ""], ["Chen", "Hongzhi", ""], ["Cheng", "James", ""], ["\u00d6zsu", "M. Tamer", ""], ["Zhang", "Qizhen", ""], ["Lui", "John C. S.", ""]]}, {"id": "1709.03133", "submitter": "Shiqiang Wang", "authors": "Ting He, Ertugrul N. Ciftcioglu, Shiqiang Wang, Kevin S. Chan", "title": "Location Privacy in Mobile Edge Clouds: A Chaff-based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider user location privacy in mobile edge clouds\n(MECs). MECs are small clouds deployed at the network edge to offer cloud\nservices close to mobile users, and many solutions have been proposed to\nmaximize service locality by migrating services to follow their users.\nCo-location of a user and his service, however, implies that a cyber\neavesdropper observing service migrations between MECs can localize the user up\nto one MEC coverage area, which can be fairly small (e.g., a femtocell). We\nconsider using chaff services to defend against such an eavesdropper, with\nfocus on strategies to control the chaffs. Assuming the eavesdropper performs\nmaximum likelihood (ML) detection, we consider both heuristic strategies that\nmimic the user's mobility and optimized strategies designed to minimize the\ndetection or tracking accuracy. We show that a single chaff controlled by the\noptimal strategy or its online variation can drive the eavesdropper's tracking\naccuracy to zero when the user's mobility is sufficiently random. We further\npropose extended strategies that utilize randomization to defend against an\nadvanced eavesdropper aware of the strategy. The efficacy of our solutions is\nverified through both synthetic and trace-driven simulations.\n", "versions": [{"version": "v1", "created": "Sun, 10 Sep 2017 16:52:58 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["He", "Ting", ""], ["Ciftcioglu", "Ertugrul N.", ""], ["Wang", "Shiqiang", ""], ["Chan", "Kevin S.", ""]]}, {"id": "1709.03264", "submitter": "Miguel Cardenas Montes", "authors": "Miguel C\\'ardenas-Montes, Iv\\'an M\\'endez-Jim\\'enez, Juan Jos\\'e\n  Rodr\\'iguez-V\\'azquez, and Jos\\'e Mar\\'ia Hern\\'andez Calama", "title": "Report: Performance comparison between C2075 and P100 GPU cards using\n  cosmological correlation functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF astro-ph.IM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, some cosmological correlation functions are used to evaluate\nthe differential performance between C2075 and P100 GPU cards. In the past, the\ncorrelation functions used in this work have been widely studied and exploited\non some previous GPU architectures. The analysis of the performance indicates\nthat a speedup in the range from 13 to 15 is achieved without any additional\noptimization process for the P100 card.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 07:03:23 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["C\u00e1rdenas-Montes", "Miguel", ""], ["M\u00e9ndez-Jim\u00e9nez", "Iv\u00e1n", ""], ["Rodr\u00edguez-V\u00e1zquez", "Juan Jos\u00e9", ""], ["Calama", "Jos\u00e9 Mar\u00eda Hern\u00e1ndez", ""]]}, {"id": "1709.03265", "submitter": "Robert Riemann", "authors": "St\\'ephane Grumbach (DICE), Robert Riemann (DICE)", "title": "Secure and Trustable Distributed Aggregation based on Kademlia", "comments": null, "journal-ref": "ICT Systems Security and Privacy Protection: 32nd IFIP TC 11\n  International Conference, May 2017, Rome, Italy. pp.171-185, 2017", "doi": "10.1007/978-3-319-58469-0_12", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aggregation of values that need to be kept confidential while guaranteeing\nthe robustness of the process and the correctness of the result is required in\nan increasing number of applications. We propose an aggregation algorithm,\nwhich supports a large spectrum of potential applications including complex\nvoting protocols. It relies on the distributed hash table Kademlia, used in\nBitTorrent, for pseudonymous communication between randomly predetermined peers\nto ensure a high degree of confidentiality which does not solely relies on\ncryptography. The distribution of data and computation limits the potential for\ndata breaches, and reduces the need for institutional trust. Experimental\nresults confirm the complexity of O(n) for n peers allowing for large-scale\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 07:05:26 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Grumbach", "St\u00e9phane", "", "DICE"], ["Riemann", "Robert", "", "DICE"]]}, {"id": "1709.03316", "submitter": "Vinay Amatya", "authors": "Vinay Amatya, Abhinav Vishnu, Charles Siegel, Jeff Daily", "title": "What does fault tolerant Deep Learning need from MPI?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) algorithms have become the de facto Machine Learning (ML)\nalgorithm for large scale data analysis. DL algorithms are computationally\nexpensive - even distributed DL implementations which use MPI require days of\ntraining (model learning) time on commonly studied datasets. Long running DL\napplications become susceptible to faults - requiring development of a fault\ntolerant system infrastructure, in addition to fault tolerant DL algorithms.\nThis raises an important question: What is needed from MPI for de- signing\nfault tolerant DL implementations? In this paper, we address this problem for\npermanent faults. We motivate the need for a fault tolerant MPI specification\nby an in-depth consideration of recent innovations in DL algorithms and their\nproperties, which drive the need for specific fault tolerance features. We\npresent an in-depth discussion on the suitability of different parallelism\ntypes (model, data and hybrid); a need (or lack thereof) for check-pointing of\nany critical data structures; and most importantly, consideration for several\nfault tolerance proposals (user-level fault mitigation (ULFM), Reinit) in MPI\nand their applicability to fault tolerant DL implementations. We leverage a\ndistributed memory implementation of Caffe, currently available under the\nMachine Learning Toolkit for Extreme Scale (MaTEx). We implement our approaches\nby ex- tending MaTEx-Caffe for using ULFM-based implementation. Our evaluation\nusing the ImageNet dataset and AlexNet, and GoogLeNet neural network topologies\ndemonstrates the effectiveness of the proposed fault tolerant DL implementation\nusing OpenMPI based ULFM.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 10:08:24 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Amatya", "Vinay", ""], ["Vishnu", "Abhinav", ""], ["Siegel", "Charles", ""], ["Daily", "Jeff", ""]]}, {"id": "1709.03332", "submitter": "Shilpa Chaturvedi", "authors": "Shilpa Chaturvedi, Sahil Tyagi and Yogesh Simmhan", "title": "Collaborative Reuse of Streaming Dataflows in IoT Applications", "comments": "To appear in IEEE eScience Conference 2017", "journal-ref": "Proceedings of the 13th IEEE International Conference on e-Science\n  (e-Science), Auckland, New Zealand, 2017", "doi": "10.1109/eScience.2017.54", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Stream Processing Systems (DSPS) like Apache Storm and Spark\nStreaming enable composition of continuous dataflows that execute persistently\nover data streams. They are used by Internet of Things (IoT) applications to\nanalyze sensor data from Smart City cyber-infrastructure, and make active\nutility management decisions. As the ecosystem of such IoT applications that\nleverage shared urban sensor streams continue to grow, applications will\nperform duplicate pre-processing and analytics tasks. This offers the\nopportunity to collaboratively reuse the outputs of overlapping dataflows,\nthereby improving the resource efficiency. In this paper, we propose\n\\emph{dataflow reuse algorithms} that given a submitted dataflow, identifies\nthe intersection of reusable tasks and streams from a collection of running\ndataflows to form a \\emph{merged dataflow}. Similar algorithms to unmerge\ndataflows when they are removed are also proposed. We implement these\nalgorithms for the popular Apache Storm DSPS, and validate their performance\nand resource savings for 35 synthetic dataflows based on public OPMW workflows\nwith diverse arrival and departure distributions, and on 21 real IoT dataflows\nfrom RIoTBench.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 11:15:09 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Chaturvedi", "Shilpa", ""], ["Tyagi", "Sahil", ""], ["Simmhan", "Yogesh", ""]]}, {"id": "1709.03404", "submitter": "Oskar Schirmer", "authors": "Felix Winkelmann, Oskar Schirmer", "title": "A Domain-specific Language for High-reliability Software used in the\n  JUICE SWI Instrument - The hO Language Manual", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  hO is a custom restricted dialect of Oberon, developed at the Max-Planck\nInstitute for Solar System Research in G\\\"ottingen and used in the SWI flight\nsoftware for the JUICE mission. hO is applied to reduce the possibility of\nsyntactically valid but incorrect code, provide better means of statically\nanalyzing source code, is more readable than C and gives syntactic support for\nthe software architecture used in the SWI instrument software. By using a\nhigher-level, application-specific notation a whole range of possible errors is\neliminated and source code size is reduced, while making the code itself easier\nto understand, review and analyze.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 14:27:33 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Winkelmann", "Felix", ""], ["Schirmer", "Oskar", ""]]}, {"id": "1709.03528", "submitter": "Shusen Wang", "authors": "Shusen Wang, Farbod Roosta-Khorasani, Peng Xu and Michael W. Mahoney", "title": "GIANT: Globally Improved Approximate Newton Method for Distributed\n  Optimization", "comments": "Fixed some typos. Improved writing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For distributed computing environment, we consider the empirical risk\nminimization problem and propose a distributed and communication-efficient\nNewton-type optimization method. At every iteration, each worker locally finds\nan Approximate NewTon (ANT) direction, which is sent to the main driver. The\nmain driver, then, averages all the ANT directions received from workers to\nform a {\\it Globally Improved ANT} (GIANT) direction. GIANT is highly\ncommunication efficient and naturally exploits the trade-offs between local\ncomputations and global communications in that more local computations result\nin fewer overall rounds of communications. Theoretically, we show that GIANT\nenjoys an improved convergence rate as compared with first-order methods and\nexisting distributed Newton-type methods. Further, and in sharp contrast with\nmany existing distributed Newton-type methods, as well as popular first-order\nmethods, a highly advantageous practical feature of GIANT is that it only\ninvolves one tuning parameter. We conduct large-scale experiments on a computer\ncluster and, empirically, demonstrate the superior performance of GIANT.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 18:17:18 GMT"}, {"version": "v2", "created": "Wed, 27 Sep 2017 17:47:15 GMT"}, {"version": "v3", "created": "Wed, 9 May 2018 21:45:02 GMT"}, {"version": "v4", "created": "Fri, 18 May 2018 21:05:37 GMT"}, {"version": "v5", "created": "Tue, 11 Sep 2018 15:12:01 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Wang", "Shusen", ""], ["Roosta-Khorasani", "Farbod", ""], ["Xu", "Peng", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1709.03715", "submitter": "Stefano Bagnasco", "authors": "Marco Aldinucci, Stefano Bagnasco, Stefano Lusso, Paolo Pasteris,\n  Sergio Rabellino and Sara Vallero", "title": "OCCAM: a flexible, multi-purpose and extendable HPC cluster", "comments": "Accepted for publication in the Proceedings of CHEP2016, San\n  Francisco, USA", "journal-ref": null, "doi": "10.1088/1742-6596/898/8/082039", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Open Computing Cluster for Advanced data Manipulation (OCCAM) is a\nmulti-purpose flexible HPC cluster designed and operated by a collaboration\nbetween the University of Torino and the Sezione di Torino of the Istituto\nNazionale di Fisica Nucleare. It is aimed at providing a flexible,\nreconfigurable and extendable infrastructure to cater to a wide range of\ndifferent scientific computing use cases, including ones from solid-state\nchemistry, high-energy physics, computer science, big data analytics,\ncomputational biology, genomics and many others. Furthermore, it will serve as\na platform for R&D activities on computational technologies themselves, with\ntopics ranging from GPU acceleration to Cloud Computing technologies. A\nheterogeneous and reconfigurable system like this poses a number of challenges\nrelated to the frequency at which heterogeneous hardware resources might change\ntheir availability and shareability status, which in turn affect methods and\nmeans to allocate, manage, optimize, bill, monitor VMs, containers, virtual\nfarms, jobs, interactive bare-metal sessions, etc. This work describes some of\nthe use cases that prompted the design and construction of the HPC cluster, its\narchitecture and resource provisioning model, along with a first\ncharacterization of its performance by some synthetic benchmark tools and a few\nrealistic use-case tests.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 07:40:51 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Aldinucci", "Marco", ""], ["Bagnasco", "Stefano", ""], ["Lusso", "Stefano", ""], ["Pasteris", "Paolo", ""], ["Rabellino", "Sergio", ""], ["Vallero", "Sara", ""]]}, {"id": "1709.03767", "submitter": "Mike Rainey", "authors": "Umut A. Acar, Arthur Chargu\\'eraud, Mike Rainey", "title": "Parallel Work Inflation, Memory Effects, and their Empirical Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an empirical method for evaluating the performance\nof parallel code. Our method is based on a simple idea that is surprisingly\neffective in helping to identify causes of poor performance, such as high\nparallelization overheads, lack of adequate parallelism, and memory effects.\nOur method relies on only the measurement of the run time of a baseline\nsequential program, the run time of the parallel program, the single-processor\nrun time of the parallel program, and the total amount of time processors spend\nidle, waiting for work.\n  In our proposed approach, we establish an equality between the observed\nparallel speedups and three terms that we call parallel work, idle time, and\nwork-inflation, where all terms except work inflation can be measured\nempirically, with precision. We then use the equality to calculate the\ndifficult-to-measure work-inflation term, which includes increased\ncommunication costs and memory effects due to parallel execution. By isolating\nthe main factors of poor performance, our method enables the programmer to\nassign blame to certain properties of the code, such as parallel grain size,\namount of parallelism, and memory usage.\n  We present a mathematical model, inspired by the work-span model, that\nenables us to justify the interpretation of our measurements. We also introduce\na method to help the programmer to visualize both the relative impact of the\nvarious causes of poor performance and the scaling trends in the causes of poor\nperformance. Our method fits in a sweet spot in between state-of-the-art\nprofiling and visualization tools. We illustrate our method by several\nempirical studies and we describe a few experiments that emphasize the care\nthat is required to accurately interpret speedup plots.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 09:59:40 GMT"}, {"version": "v2", "created": "Wed, 13 Sep 2017 20:09:54 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Acar", "Umut A.", ""], ["Chargu\u00e9raud", "Arthur", ""], ["Rainey", "Mike", ""]]}, {"id": "1709.04061", "submitter": "Blesson Varghese", "authors": "Nan Wang, Blesson Varghese, Michail Matthaiou and Dimitrios S.\n  Nikolopoulos", "title": "ENORM: A Framework For Edge NOde Resource Management", "comments": "14 pages; accepted to IEEE Transactions on Services Computing on 12\n  September 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current computing techniques using the cloud as a centralised server will\nbecome untenable as billions of devices get connected to the Internet. This\nraises the need for fog computing, which leverages computing at the edge of the\nnetwork on nodes, such as routers, base stations and switches, along with the\ncloud. However, to realise fog computing the challenge of managing edge nodes\nwill need to be addressed. This paper is motivated to address the resource\nmanagement challenge. We develop the first framework to manage edge nodes,\nnamely the Edge NOde Resource Management (ENORM) framework. Mechanisms for\nprovisioning and auto-scaling edge node resources are proposed. The feasibility\nof the framework is demonstrated on a PokeMon Go-like online game use-case. The\nbenefits of using ENORM are observed by reduced application latency between 20%\n- 80% and reduced data transfer and communication frequency between the edge\nnode and the cloud by up to 95\\%. These results highlight the potential of fog\ncomputing for improving the quality of service and experience.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 21:16:28 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Wang", "Nan", ""], ["Varghese", "Blesson", ""], ["Matthaiou", "Michail", ""], ["Nikolopoulos", "Dimitrios S.", ""]]}, {"id": "1709.04137", "submitter": "Vahid Behzadan", "authors": "Vahid Behzadan and Arslan Munir", "title": "Models and Framework for Adversarial Attacks on Complex Adaptive Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CR cs.DC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the paradigm of adversarial attacks that target the dynamics of\nComplex Adaptive Systems (CAS). To facilitate the analysis of such attacks, we\npresent multiple approaches to the modeling of CAS as dynamical, data-driven,\nand game-theoretic systems, and develop quantitative definitions of attack,\nvulnerability, and resilience in the context of CAS security. Furthermore, we\npropose a comprehensive set of schemes for classification of attacks and attack\nsurfaces in CAS, complemented with examples of practical attacks. Building on\nthis foundation, we propose a framework based on reinforcement learning for\nsimulation and analysis of attacks on CAS, and demonstrate its performance\nthrough three real-world case studies of targeting power grids, destabilization\nof terrorist organizations, and manipulation of machine learning agents. We\nalso discuss potential mitigation techniques, and remark on future research\ndirections in analysis and design of secure complex adaptive systems.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 05:14:48 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Behzadan", "Vahid", ""], ["Munir", "Arslan", ""]]}, {"id": "1709.04255", "submitter": "Miguel Isabel", "authors": "Elvira Albert, Miguel G\\'omez-Zamalloa and Miguel Isabel", "title": "On the Generation of Initial Contexts for Effective Deadlock Detection", "comments": "Pre-proceedings paper presented at the 27th International Symposium\n  on Logic-Based Program Synthesis and Transformation (LOPSTR 2017), Namur,\n  Belgium, 10-12 October 2017 (arXiv:1708.07854)", "journal-ref": null, "doi": null, "report-no": "LOPSTR/2017/15", "categories": "cs.PL cs.DC cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been recently proposed that testing based on symbolic execution can be\nused in conjunction with static deadlock analysis to define a deadlock\ndetection framework that: (i) can show deadlock presence, in that case a\nconcrete test-case and trace are obtained, and (ii) can also prove deadlock\nfreedom. Such symbolic execution starts from an initial distributed context,\ni.e., a set of locations and their initial tasks. Considering all possibilities\nresults in a combinatorial explosion on the different distributed contexts that\nmust be considered. This paper proposes a technique to effectively generate\ninitial contexts that can lead to deadlock, using the possible conflicting task\ninteractions identified by static analysis, discarding other distributed\ncontexts that cannot lead to deadlock. The proposed technique has been\nintegrated in the above-mentioned deadlock detection framework hence enabling\nit to analyze systems without the need of any user supplied initial context.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 11:16:10 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Albert", "Elvira", ""], ["G\u00f3mez-Zamalloa", "Miguel", ""], ["Isabel", "Miguel", ""]]}, {"id": "1709.04305", "submitter": "Tim Oates", "authors": "Zhiguang Wang, Chul Gwon, Tim Oates, Adam Iezzi", "title": "Automated Cloud Provisioning on AWS using Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the use of cloud computing continues to rise, controlling cost becomes\nincreasingly important. Yet there is evidence that 30\\% - 45\\% of cloud spend\nis wasted. Existing tools for cloud provisioning typically rely on highly\ntrained human experts to specify what to monitor, thresholds for triggering\naction, and actions. In this paper we explore the use of reinforcement learning\n(RL) to acquire policies to balance performance and spend, allowing humans to\nspecify what they want as opposed to how to do it, minimizing the need for\ncloud expertise. Empirical results with tabular, deep, and dueling double deep\nQ-learning with the CloudSim simulator show the utility of RL and the relative\nmerits of the approaches. We also demonstrate effective policy transfer\nlearning from an extremely simple simulator to CloudSim, with the next step\nbeing transfer from CloudSim to an Amazon Web Services physical environment.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 13:06:43 GMT"}, {"version": "v2", "created": "Tue, 19 Sep 2017 14:45:59 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Wang", "Zhiguang", ""], ["Gwon", "Chul", ""], ["Oates", "Tim", ""], ["Iezzi", "Adam", ""]]}, {"id": "1709.04385", "submitter": "Paul Gainer", "authors": "Paul Gainer, Sven Linker, Clare Dixon, Ullrich Hustadt and Michael\n  Fisher", "title": "The Power of Synchronisation: Formal Analysis of Power Consumption in\n  Networks of Pulse-Coupled Oscillators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We assess the power consumption of network synchronisation protocols,\nparticularly the energy required to synchronise all nodes across a network. We\nuse the widely adopted approach of bio-inspired, pulse-coupled oscillators to\nachieve network-wide synchronisation and provide an extended formal model of\njust such a protocol, enhanced with structures for recording energy usage.\nExhaustive analysis is then carried out through formal verification, utilising\nthe PRISM model checker to calculate the resources consumed on each possible\nsystem execution. This allows us to assess a range of parameter instantiations\nand to explore trade-offs between power consumption and time to synchronise.\nThis provides a principled basis for the formal analysis of a much broader\nrange of large-scale network protocols.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 15:33:30 GMT"}, {"version": "v2", "created": "Thu, 14 Sep 2017 10:23:00 GMT"}, {"version": "v3", "created": "Tue, 24 Oct 2017 08:47:23 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Gainer", "Paul", ""], ["Linker", "Sven", ""], ["Dixon", "Clare", ""], ["Hustadt", "Ullrich", ""], ["Fisher", "Michael", ""]]}, {"id": "1709.04551", "submitter": "Simone Atzeni", "authors": "Simone Atzeni, Ganesh Gopalakrishnan", "title": "An Operational Semantic Basis for OpenMP Race Analysis", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OpenMP is the de facto standard to exploit the on-node parallelism in new\ngeneration supercomputers.Despite its overall ease of use, even expert users\nare known to create OpenMP programs that harbor concurrency errors, of which\none of the most insidious of errors are {\\em data races}.OpenMP is also a\nrapidly evolving standard, which means that future data races may be introduced\nwithin unfamiliar contexts.A simple and rigorous operational semantics for\nOpenMP can help build reliable race checkers and ward off future errors through\nprogrammer education and better tooling.This paper's key contribution is a\nsimple operational semantics for OpenMP, with primitive events matching those\ngenerated by today's popular OpenMP runtimes and tracing methods such as\nOMPT.This makes our operational semantics more than a theoretical document for\nintellectual edification; it can serve as a blueprint for OpenMP event capture\nand tool building.We back this statement by summarizing the workings of a new\ndata race checker for OpenMP being built based on this semantics.The larger\npurpose served by our semantics is to serve the needs of the OpenMP community\nwith regard to their contemplated extensions to OpenMP, as well as future\ntooling efforts.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 22:00:17 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Atzeni", "Simone", ""], ["Gopalakrishnan", "Ganesh", ""]]}, {"id": "1709.04569", "submitter": "Abhinav Aggarwal", "authors": "Abhinav Aggarwal, Mahdi Zamani, Mihai Christodorescu", "title": "REMOTEGATE: Incentive-Compatible Remote Configuration of Security\n  Gateways", "comments": "Working manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imagine that a malicious hacker is trying to attack a server over the\nInternet and the server wants to block the attack packets as close to their\npoint of origin as possible. However, the security gateway ahead of the source\nof attack is untrusted. How can the server block the attack packets through\nthis gateway? In this paper, we introduce REMOTEGATE, a trustworthy mechanism\nfor allowing any party (server) on the Internet to configure a security gateway\nowned by a second party, at a certain agreed upon reward that the former pays\nto the latter for its service. We take an interactive incentive-compatible\napproach, for the case when both the server and the gateway are rational, to\ndevise a protocol that will allow the server to help the security gateway\ngenerate and deploy a policy rule that filters the attack packets before they\nreach the server. The server will reward the gateway only when the latter can\nsuccessfully verify that it has generated and deployed the correct rule for the\nissue. This mechanism will enable an Internet-scale approach to improving\nsecurity and privacy, backed by digital payment incentives.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 00:12:15 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Aggarwal", "Abhinav", ""], ["Zamani", "Mahdi", ""], ["Christodorescu", "Mihai", ""]]}, {"id": "1709.04599", "submitter": "Sepehr Assadi", "authors": "Sepehr Assadi", "title": "Simple Round Compression for Parallel Vertex Cover", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Czumaj et.al. (arXiv 2017) presented a parallel (almost)\n$2$-approximation algorithm for the maximum matching problem in only\n$O({(\\log\\log{n})^2})$ rounds of the massive parallel computation (MPC)\nframework, when the memory per machine is $O(n)$. The main approach in their\nwork is a way of compressing $O(\\log{n})$ rounds of a distributed algorithm for\nmaximum matching into only $O({(\\log\\log{n})^2})$ MPC rounds.\n  In this note, we present a similar algorithm for the closely related problem\nof approximating the minimum vertex cover in the MPC framework. We show that\none can achieve an $O(\\log{n})$ approximation to minimum vertex cover in only\n$O(\\log\\log{n})$ MPC rounds when the memory per machine is $O(n)$. Our\nalgorithm for vertex cover is similar to the maximum matching algorithm of\nCzumaj et.al. but avoids many of the intricacies in their approach and as a\nresult admits a considerably simpler analysis (at a cost of a worse\napproximation guarantee). We obtain this result by modifying a previous\nparallel algorithm by Khanna and the author (SPAA 2017) for vertex cover that\nallowed for compressing $O(\\log{n})$ rounds of a distributed algorithm into\nconstant MPC rounds when the memory allowed per machine is $O(n\\sqrt{n})$.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 02:49:01 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Assadi", "Sepehr", ""]]}, {"id": "1709.04640", "submitter": "Leonid Sokolinsky", "authors": "Irina Sokolinskaya and Leonid B. Sokolinsky", "title": "Scalability Evaluation of NSLP Algorithm for Solving Non-Stationary\n  Linear Programming Problems on Cluster Computing Systems", "comments": "Submitted to \"Russian Supercomputing Days 2017\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper is devoted to a scalability study of the NSLP algorithm for solving\nnon-stationary high-dimension linear programming problem on the cluster\ncomputing systems. The analysis is based on the BSF model of parallel\ncomputations. The BSF model is a new parallel computation model designed on the\nbasis of BSP and SPMD models. The brief descriptions of the NSLP algorithm and\nthe BSF model are given. The NSLP algorithm implementation in the form of a BSF\nprogram is considered. On the basis of the BSF cost metric, the upper bound of\nthe NSLP algorithm scalability is derived and its parallel efficiency is\nestimated. NSLP algorithm implementation using BSF skeleton is described. A\ncomparison of scalability estimations obtained analytically and experimentally\nis provided.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 07:35:56 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Sokolinskaya", "Irina", ""], ["Sokolinsky", "Leonid B.", ""]]}, {"id": "1709.04708", "submitter": "Dezhai Yuan", "authors": "De-zhai Yuan, Xing-yi Peng, Ting Liu, Zhe Cui", "title": "A Randomly Expandable Method for Data Layout of RAID Storage Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increase of huge amounts of data in volume, velocity, and variety,\nthe need for capacity of Redundant Arrays of Inexpensive Disks (RAID) storage\nsystems is dramatically growing. However, the probability of disk failures in\nRAID storage systems is sharply high with the increase of program/erase cycles,\nread cycles, and retention time. Furthermore, they are faced with more\nchallenges in fault tolerance, storage efficiency, computational complexity,\nand expandability. This article presents a novel data layout scheme for RAID\nstorage System using Random Binary Extensive Code (RBEC), which are designed to\nensure random expandability, high reliability, and availability of data in RAID\nstorage systems. RBEC is a family of systematic code, in which the generator\nmatrix consists of two submatrices with entries over GF(2), an identity matrix\non the top, and another submatrix on the bottom. Compared with the existed\napproaches, the attractive advantages of our schemes include 1) they are\ncompletely implemented based on only simple eXclusive OR (XOR) operations and\nhave systematic code property, 2) they can provide arbitrary fault tolerance,\n3) their storage efficiency is quasi-optimal, and 4) data and parity disks of\nRAID storage systems can be randomly expanded according to practical\nrequirements. Thus, our scheme is particularly suitable for RAID storage\nsystems that need higher reliability, availability, and expandability.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 11:27:03 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Yuan", "De-zhai", ""], ["Peng", "Xing-yi", ""], ["Liu", "Ting", ""], ["Cui", "Zhe", ""]]}, {"id": "1709.04714", "submitter": "EPTCS", "authors": "Bashar Igried (Dept. of Computer Science, Swansea University), Anton\n  Setzer (Dept. of Computer Science, Swansea University)", "title": "Trace and Stable Failures Semantics for CSP-Agda", "comments": "In Proceedings CoALP-Ty'16, arXiv:1709.04199", "journal-ref": "EPTCS 258, 2017, pp. 36-51", "doi": "10.4204/EPTCS.258.3", "report-no": null, "categories": "cs.PL cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CSP-Agda is a library, which formalises the process algebra CSP in the\ninteractive theorem prover Agda using coinductive data types. In CSP-Agda, CSP\nprocesses are in monadic form, which sup- ports a modular development of\nprocesses. In this paper, we implement two main models of CSP, trace and stable\nfailures semantics, in CSP-Agda, and define the corresponding refinement and\nequal- ity relations. Because of the monadic setting, some adjustments need to\nbe made. As an example, we prove commutativity of the external choice operator\nw.r.t. the trace semantics in CSP-Agda, and that refinement w.r.t. stable\nfailures semantics is a partial order. All proofs and definitions have been\ntype checked in Agda. Further proofs of algebraic laws will be available in the\nCSP-Agda repository.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 11:35:47 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Igried", "Bashar", "", "Dept. of Computer Science, Swansea University"], ["Setzer", "Anton", "", "Dept. of Computer Science, Swansea University"]]}, {"id": "1709.04806", "submitter": "Myoungsoo Jung", "authors": "Miryeong Kwon, Jie Zhang, Gyuyoung Park, Wonil Choi, David Donofrio,\n  John Shalf, Mahmut Kandemir, and Myoungsoo Jung", "title": "TraceTracker: Hardware/Software Co-Evaluation for Large-Scale I/O\n  Workload Reconstruction", "comments": "This paper is accepted by and will be published at 2017 IEEE\n  International Symposium on Workload Characterization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Block traces are widely used for system studies, model verifications, and\ndesign analyses in both industry and academia. While such traces include\ndetailed block access patterns, existing trace-driven research unfortunately\noften fails to find true-north due to a lack of runtime contexts such as user\nidle periods and system delays, which are fundamentally linked to the\ncharacteristics of target storage hardware. In this work, we propose\nTraceTracker, a novel hardware/software co-evaluation method that allows users\nto reuse a broad range of the existing block traces by keeping most their\nexecution contexts and user scenarios while adjusting them with new system\ninformation. Specifically, our TraceTracker's software evaluation model can\ninfer CPU burst times and user idle periods from old storage traces, whereas\nits hardware evaluation method remasters the storage traces by interoperating\nthe inferred time information, and updates all inter-arrival times by making\nthem aware of the target storage system. We apply the proposed co-evaluation\nmodel to 577 traces, which were collected by servers from different\ninstitutions and locations a decade ago, and revive the traces on a\nhigh-performance flash-based storage array. The evaluation results reveal that\nthe accuracy of the execution contexts reconstructed by TraceTracker is on\naverage 99% and 96% with regard to the frequency of idle operations and the\ntotal idle periods, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 14:14:03 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Kwon", "Miryeong", ""], ["Zhang", "Jie", ""], ["Park", "Gyuyoung", ""], ["Choi", "Wonil", ""], ["Donofrio", "David", ""], ["Shalf", "John", ""], ["Kandemir", "Mahmut", ""], ["Jung", "Myoungsoo", ""]]}, {"id": "1709.04811", "submitter": "Johanne Cohen", "authors": "Johanne Cohen, Georges Manoussakis, Laurence Pilard, Devan Sohier", "title": "A self-stabilizing algorithm for maximal matching in link-register model\n  in $O(n\\Delta^3)$ moves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the matching problem, each node maintains a pointer to one of its neighbor\nor to $null$, and a maximal matching is computed when each node points either\nto a neighbor that itself points to it (they are then called married), or to\n$null$, in which case no neighbor can also point to $null$. This paper presents\na self-stabilizing distributed algorithm to compute a maximal matching in the\nlink-register model under read/write atomicity, with complexity\n{$O(n\\Delta^3)$} moves under the adversarial distributed daemon, where $\\Delta$\nis the maximum degree of the graph.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 14:27:08 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Cohen", "Johanne", ""], ["Manoussakis", "Georges", ""], ["Pilard", "Laurence", ""], ["Sohier", "Devan", ""]]}, {"id": "1709.04859", "submitter": "Yorai Wardi", "authors": "X. Chen, Y. Wardi, and S. Yalamanchili", "title": "Power Regulation in High Performance Multicore Processors", "comments": "A reduced version will be submitted as the final version to the\n  Proceedings of the 56th IEEE Conference on Decision and Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents, implements, and evaluates a power-regulation technique\nfor multicore processors, based on an integral controller with adjustable gain.\nThe gain is designed for wide stability margins, and computed in real time as\npart of the control law. The tracking performance of the control system is\nrobust with respect to modeling uncertainties and computational errors in the\nloop. The main challenge of designing such a controller is that the power\ndissipation of program-workloads varies widely and often cannot be measured\naccurately; hence extant controllers are either ad hoc or based on a-priori\nmodeling characterizations of the processor and workloads. Our approach is\ndifferent. Leveraging the aforementioned robustness it uses a simple textbook\nmodeling framework, and adjusts its parameters in real time by a\nsystem-identification module. In this it trades modeling precision for fast\ncomputations in the loop making it suitable for on-line implementation in\ncommodity data-center processors. Consequently, the proposed controller is\nagnostic in the sense that it does not require any a-priori system\ncharacterizations. We present an implementation of the controller on Intel's\nfourth-generation microarchitecture, Haswell, and test it on a number of\nindustry benchmark programs which are used in scientific computing and\ndatacenter applications. Results of these experiments are presented in detail\nexposing the practical challenges of implementing provably-convergent power\nregulation solutions in commodity multicore processors.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 16:24:46 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Chen", "X.", ""], ["Wardi", "Y.", ""], ["Yalamanchili", "S.", ""]]}, {"id": "1709.04885", "submitter": "Ori Gurel-Gurevich", "authors": "Yoel Grinshpon, Ori Gurel-Gurevich", "title": "Optimal broadcasting in networks with faulty nodes", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large computer networks are an essential part of modern technology, and quite\noften information needs to be broadcast to all the computers in the network. If\nall computers work perfectly all the time, this is simple. Suppose, however,\nthat some of the computers fail occasionally. What is the fastest way to ensure\nthat with high probability all working computers get the information?\n  In this paper, we analyze three algorithms to do so. All algorithms terminate\nin logarithmic time, assuming computers fail with probability $1-p$\nindependently of each other. We prove that the third algorithm, which runs in\ntime $(1+o(1))(\\frac{\\log N}{\\log(1+p)})$, is asymptotically optimal.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 17:18:53 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Grinshpon", "Yoel", ""], ["Gurel-Gurevich", "Ori", ""]]}, {"id": "1709.05061", "submitter": "Mo Sha", "authors": "Mo Sha, Yuchen Li, Bingsheng He and Kian-Lee Tan", "title": "Technical Report: Accelerating Dynamic Graph Analytics on GPUs", "comments": "34 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As graph analytics often involves compute-intensive operations, GPUs have\nbeen extensively used to accelerate the processing. However, in many\napplications such as social networks, cyber security, and fraud detection,\ntheir representative graphs evolve frequently and one has to perform a rebuild\nof the graph structure on GPUs to incorporate the updates. Hence, rebuilding\nthe graphs becomes the bottleneck of processing high-speed graph streams. In\nthis paper, we propose a GPU-based dynamic graph storage scheme to support\nexisting graph algorithms easily. Furthermore, we propose parallel update\nalgorithms to support efficient stream updates so that the maintained graph is\nimmediately available for high-speed analytic processing on GPUs. Our extensive\nexperiments with three streaming applications on large-scale real and synthetic\ndatasets demonstrate the superior performance of our proposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 05:08:58 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2018 06:13:41 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Sha", "Mo", ""], ["Li", "Yuchen", ""], ["He", "Bingsheng", ""], ["Tan", "Kian-Lee", ""]]}, {"id": "1709.05122", "submitter": "Robert Riemann", "authors": "St\\'ephane Grumbach (1), Robert Riemann (1) ((1) DICE, DATASPHERE)", "title": "Distributed Random Process for a Large-Scale Peer-to-Peer Lottery", "comments": null, "journal-ref": "Lydia Y. Chen; Hans P. Reiser. Proc. of 17th IFIP Distributed\n  Applications and Interoperable Systems, Jun 2017, Neuch{\\^a}tel, Switzerland.\n  Springer, 10320, pp.34-48, 2017, LNCS - Lecture Notes in Computer Science", "doi": "10.1007/978-3-319-59665-5_3", "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most online lotteries today fail to ensure the verifiability of the random\nprocess and rely on a trusted third party. This issue has received little\nattention since the emergence of distributed protocols like Bitcoin that\ndemonstrated the potential of protocols with no trusted third party. We argue\nthat the security requirements of online lotteries are similar to those of\nonline voting, and propose a novel distributed online lottery protocol that\napplies techniques developed for voting applications to an existing lottery\nprotocol. As a result, the protocol is scalable, provides efficient\nverification of the random process and does not rely on a trusted third party\nnor on assumptions of bounded computational resources. An early prototype\nconfirms the feasibility of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 09:23:34 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Grumbach", "St\u00e9phane", "", "DICE, DATASPHERE"], ["Riemann", "Robert", "", "DICE, DATASPHERE"]]}, {"id": "1709.05183", "submitter": "Demian Hespe", "authors": "Demian Hespe, Martin Weidner, Jonathan Dees, Peter Sanders", "title": "Fast OLAP Query Execution in Main Memory on Large Data in a Cluster", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Main memory column-stores have proven to be efficient for processing\nanalytical queries. Still, there has been much less work in the context of\nclusters. Using only a single machine poses several restrictions: Processing\npower and data volume are bounded to the number of cores and main memory\nfitting on one tightly coupled system. To enable the processing of larger data\nsets, switching to a cluster becomes necessary. In this work, we explore\ntechniques for efficient execution of analytical SQL queries on large amounts\nof data in a parallel database cluster while making maximal use of the\navailable hardware. This includes precompiled query plans for efficient CPU\nutilization, full parallelization on single nodes and across the cluster, and\nefficient inter-node communication. We implement all features in a prototype\nfor running a subset of TPC-H benchmark queries. We evaluate our implementation\nusing a 128 node cluster running TPC-H queries with 30 000 gigabyte of\nuncompressed data.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 13:08:07 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Hespe", "Demian", ""], ["Weidner", "Martin", ""], ["Dees", "Jonathan", ""], ["Sanders", "Peter", ""]]}, {"id": "1709.05197", "submitter": "Philipp Grulich", "authors": "Philipp M. Grulich", "title": "Scalable real-time processing with Spark Streaming: implementation and\n  design of a Car Information System", "comments": "Hamburg University of Applied Sciences, Bachelor Thesis, 2016, in\n  German, 113 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Streaming data processing is a hot topic in big data these days, because it\nmade it possible to process a huge amount of events within a low latency. One\nof the most common used open-source stream processing platforms is Spark\nStreaming, which is demonstrated and discussed based on a real-world use-case\nin this paper. The use-case is about a Car Information System, which is an\nexample for a classic stream processing system. First the System is de- signed\nand engineered, whereby the application architecture is created carefully,\nbecause it should be adaptable for similar use-cases. At the end of this paper\nthe CIS and Spark Streaming is evaluated by the use of the Goal Question Metric\nmodel. The evaluation proves that Spark Streaming is capable to create stream\nprocessing in a scalable and fault tolerant manner. But it also shows that\nSpark is a very fast moving project, which could cause problems during the\ndevelopment and maintenance of a software project.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 11:13:17 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Grulich", "Philipp M.", ""]]}, {"id": "1709.05365", "submitter": "Myoungsoo Jung", "authors": "Sungjoon Koh, Jie Zhang, Miryeong Kwon, Jungyeon Yoon, David Donofrio,\n  Namsung Kim and Myoungsoo Jung", "title": "Understanding System Characteristics of Online Erasure Coding on\n  Scalable, Distributed and Large-Scale SSD Array Systems", "comments": "This paper is accepted by and will be published at 2017 IEEE\n  International Symposium on Workload Characterization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale systems with arrays of solid state disks (SSDs) have become\nincreasingly common in many computing segments. To make such systems resilient,\nwe can adopt erasure coding such as Reed-Solomon (RS) code as an alternative to\nreplication because erasure coding can offer a significantly lower storage cost\nthan replication. To understand the impact of using erasure coding on system\nperformance and other system aspects such as CPU utilization and network\ntraffic, we build a storage cluster consisting of approximately one hundred\nprocessor cores with more than fifty high-performance SSDs, and evaluate the\ncluster with a popular open-source distributed parallel file system, Ceph. Then\nwe analyze behaviors of systems adopting erasure coding from the following five\nviewpoints, compared with those of systems using replication: (1) storage\nsystem I/O performance; (2) computing and software overheads; (3) I/O\namplification; (4) network traffic among storage nodes; (5) the impact of\nphysical data layout on performance of RS-coded SSD arrays. For all these\nanalyses, we examine two representative RS configurations, which are used by\nGoogle and Facebook file systems, and compare them with triple replication that\na typical parallel file system employs as a default fault tolerance mechanism.\nLastly, we collect 54 block-level traces from the cluster and make them\navailable for other researchers.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 14:14:10 GMT"}, {"version": "v2", "created": "Tue, 19 Sep 2017 04:14:56 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Koh", "Sungjoon", ""], ["Zhang", "Jie", ""], ["Kwon", "Miryeong", ""], ["Yoon", "Jungyeon", ""], ["Donofrio", "David", ""], ["Kim", "Namsung", ""], ["Jung", "Myoungsoo", ""]]}, {"id": "1709.05483", "submitter": "Salvatore Di Girolamo", "authors": "Torsten Hoefler, Salvatore Di Girolamo, Konstantin Taranov, Ryan E.\n  Grant, Ron Brightwell", "title": "sPIN: High-performance streaming Processing in the Network", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing communication performance is imperative for large-scale computing\nbecause communication overheads limit the strong scalability of parallel\napplications. Today's network cards contain rather powerful processors\noptimized for data movement. However, these devices are limited to fixed\nfunctions, such as remote direct memory access. We develop sPIN, a portable\nprogramming model to offload simple packet processing functions to the network\ncard. To demonstrate the potential of the model, we design a cycle-accurate\nsimulation environment by combining the network simulator LogGOPSim and the CPU\nsimulator gem5.\n  We implement offloaded message matching, datatype processing, and collective\ncommunications and demonstrate transparent full-application speedups.\nFurthermore, we show how sPIN can be used to accelerate redundant in-memory\nfilesystems and several other use cases.\n  Our work investigates a portable packet-processing network acceleration model\nsimilar to compute acceleration with CUDA or OpenCL. We show how such network\nacceleration enables an eco-system that can significantly speed up applications\nand system services.\n", "versions": [{"version": "v1", "created": "Sat, 16 Sep 2017 08:57:46 GMT"}, {"version": "v2", "created": "Thu, 19 Oct 2017 13:40:13 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Hoefler", "Torsten", ""], ["Di Girolamo", "Salvatore", ""], ["Taranov", "Konstantin", ""], ["Grant", "Ryan E.", ""], ["Brightwell", "Ron", ""]]}, {"id": "1709.05586", "submitter": "Qiang Zhu Professor", "authors": "Qiang Zhu", "title": "Generalized PMC model for the hybrid diagnosis of multiprocessor systems", "comments": "5 pages no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fault diagnosis is important to the design and maintenance of large\nmultiprocessor systems. PMC model is the most famous diagnosis model in the\nsystem level diagnosis of multiprocessor systems. Under the PMC model, only\nnode faults are allowed. But in real circumstances, link faults may occur. So\nbased on the PMC model, we propose in this paper a diagnosis model called the\ngeneralized PMC(GPMC) model to adapt to the real circumstances. The foundation\nof GPMC model has been established. And to measure the fault diagnosis\ncapability of multiprocessor systems under the GPMC model, the fault diagnosis\ncapability measuring parameters: $h$-edge restricted diagnosability and\n$h$-vertex restricted edge diagnosability have been introduced. As an\napplication, the $h$-edge restricted diagnosability and $h$-vertex restricted\nedge diagnosability of hypercubes are explored.\n", "versions": [{"version": "v1", "created": "Sun, 17 Sep 2017 00:41:16 GMT"}, {"version": "v2", "created": "Tue, 19 Sep 2017 01:42:10 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Zhu", "Qiang", ""]]}, {"id": "1709.05588", "submitter": "Qiang Zhu Professor", "authors": "Qiang Zhu, Lili Li, Sanyang Liu, Xing Zhang", "title": "Hybrid Fault diagnosis capability analysis of Hypercubes under the PMC\n  model and MM* model", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  System level diagnosis is an important approach for the fault diagnosis of\nmultiprocessor systems. In system level diagnosis, diagnosability is an\nimportant measure of the diagnosis capability of interconnection networks. But\nas a measure, diagnosability can not reflect the diagnosis capability of\nmultiprocessor systems to link faults which may occur in real circumstances. In\nthis paper, we propose the definition of $h$-edge tolerable diagnosability to\nbetter measure the diagnosis capability of interconnection networks under\nhybrid fault circumstances. The $h$-edge tolerable diagnosability of a\nmultiprocessor system $G$ is the maximum number of faulty nodes that the system\ncan guarantee to locate when the number of faulty edges does not exceed\n$h$,denoted by $t_h^{e}(G)$. The PMC model and MM model are the two most widely\nstudied diagnosis models for the system level diagnosis of multiprocessor\nsystems. The hypercubes are the most well-known interconnection networks. In\nthis paper, the $h$-edge tolerable diagnosability of $n$-dimensional hypercube\nunder the PMC model and MM$^{*}$ is determined as follows: $t_h^{e}(Q_n)= n-h$,\nwhere $1\\leq h<n$, $n\\geq3$.\n", "versions": [{"version": "v1", "created": "Sun, 17 Sep 2017 01:15:45 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Zhu", "Qiang", ""], ["Li", "Lili", ""], ["Liu", "Sanyang", ""], ["Zhang", "Xing", ""]]}, {"id": "1709.05635", "submitter": "Alberto Giaretta", "authors": "Alberto Giaretta, Nicola Dragoni and Manuel Mazzara", "title": "Joining Jolie to Docker - Orchestration of Microservices on a\n  Containers-as-a-Service Layer", "comments": "9 pages, 3 figures", "journal-ref": "Proceedings of 5th International Conference in Software\n  Engineering for Defence Applications. SEDA 2016. Advances in Intelligent\n  Systems and Computing, vol 717. Springer, Cham", "doi": "10.1007/978-3-319-70578-1_16", "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is steadily growing and, as IaaS vendors have started to\noffer pay-as-you-go billing policies, it is fundamental to achieve as much\nelasticity as possible, avoiding over-provisioning that would imply higher\ncosts. In this paper, we briefly analyse the orchestration characteristics of\nPaaSSOA, a proposed architecture already implemented for Jolie microservices,\nand Kubernetes, one of the various orchestration plugins for Docker; then, we\noutline similarities and differences of the two approaches, with respect to\ntheir own domain of application. Furthermore, we investigate some ideas to\nachieve a federation of the two technologies, proposing an architectural\ncomposition of Jolie microservices on Docker Container-as-a-Service layer.\n", "versions": [{"version": "v1", "created": "Sun, 17 Sep 2017 10:15:30 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Giaretta", "Alberto", ""], ["Dragoni", "Nicola", ""], ["Mazzara", "Manuel", ""]]}, {"id": "1709.05708", "submitter": "Chahrazed Labba", "authors": "Chahrazed Labba and Narj\\`es Bellamine Ben Saoud", "title": "Cost-Based Assessment of Partitioning Algorithms of Agent-Based Systems\n  on Hybrid Cloud Environments", "comments": "The 27 th European Modelling & Simulation Symposium, bergeggi, Italy,\n  21-23 September 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributing agent-based simulators reveals many challenges while deploying\nthem on a hybrid cloud infrastructure. In fact, a researcher's main motivations\nby running simulations on hybrid clouds, are reaching more scalable systems as\nwell as reducing monetary costs. Indeed, hybrid cloud environment, despite\nproviding scalability and effective control over proper data, requires an\nefficient deployment strategy combining both an efficient partitioning\nmechanism and cost savings. In this paper, we propose a cost deployment model\ndedicated to distributed agent-based simulation systems. This cost model,\ncombining general performance partitioning criteria as well as monetary costs,\nis used to evaluate cluster and grid based partitioning algorithms on hybrid\ncloud environments. The first experimental results show that, for a given\nagent-based model, a good partitioning method used with the suitable hybrid\ncloud environment lead to an efficient and economic deployment.\n", "versions": [{"version": "v1", "created": "Sun, 17 Sep 2017 19:36:48 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Labba", "Chahrazed", ""], ["Saoud", "Narj\u00e8s Bellamine Ben", ""]]}, {"id": "1709.05748", "submitter": "Stefanie Roos", "authors": "Stefanie Roos and Pedro Moreno-Sanchez and Aniket Kate and Ian\n  Goldberg", "title": "Settling Payments Fast and Private: Efficient Decentralized Routing for\n  Path-Based Transactions", "comments": "15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Path-based transaction (PBT) networks, which settle payments from one user to\nanother via a path of intermediaries, are a growing area of research. They\novercome the scalability and privacy issues in cryptocurrencies like Bitcoin\nand Ethereum by replacing expensive and slow on-chain blockchain operations\nwith inexpensive and fast off-chain transfers. In the form of credit networks\nsuch as Ripple and Stellar, they also enable low-price real-time gross\nsettlements across different currencies. For example, SilentWhsipers is a\nrecently proposed fully distributed credit network relying on path-based\ntransactions for secure and in particular private payments without a public\nledger. At the core of a decentralized PBT network is a routing algorithm that\ndiscovers transaction paths between payer and payee. During the last year, a\nnumber of routing algorithms have been proposed. However, the existing ad hoc\nefforts lack either efficiency or privacy. In this work, we first identify\nseveral efficiency concerns in SilentWhsipers. Armed with this knowledge, we\ndesign and evaluate SpeedyMurmurs, a novel routing algorithm for decentralized\nPBT networks using efficient and flexible embedding-based path discovery and\non-demand efficient stabilization to handle the dynamics of a PBT network. Our\nsimulation study, based on real-world data from the currently deployed Ripple\ncredit network, indicates that SpeedyMurmurs reduces the overhead of\nstabilization by up to two orders of magnitude and the overhead of routing a\ntransaction by more than a factor of two. Furthermore, using SpeedyMurmurs\nmaintains at least the same success ratio as decentralized landmark routing,\nwhile providing lower delays. Finally, SpeedyMurmurs achieves key privacy goals\nfor routing in PBT networks.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 02:30:18 GMT"}, {"version": "v2", "created": "Wed, 13 Dec 2017 23:44:37 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Roos", "Stefanie", ""], ["Moreno-Sanchez", "Pedro", ""], ["Kate", "Aniket", ""], ["Goldberg", "Ian", ""]]}, {"id": "1709.05869", "submitter": "Andrzej Pelc", "authors": "Andrzej Pelc", "title": "Use of Information, Memory and Randomization in Asynchronous Gathering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate initial information, unbounded memory and randomization in\ngathering mobile agents on a grid. We construct a state machine, such that it\nis possible to gather, with probability 1, all configurations of its copies.\nThis machine has initial input, unbounded memory, and is randomized. We show\nthat no machine having any two of these capabilities but not the third, can be\nused to gather, with high probability, all configurations.\n  We construct deterministic Turing Machines that are used to gather all\nconnected configurations, and we construct deterministic finite automata that\nare used to gather all contractible connected configurations.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 11:29:43 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Pelc", "Andrzej", ""]]}, {"id": "1709.05871", "submitter": "Vinod Muthusamy", "authors": "Bishwaranjan Bhattacharjee, Scott Boag, Chandani Doshi, Parijat Dube,\n  Ben Herta, Vatche Ishakian, K. R. Jayaram, Rania Khalaf, Avesh Krishna, Yu Bo\n  Li, Vinod Muthusamy, Ruchir Puri, Yufei Ren, Florian Rosenberg, Seetharami R.\n  Seelam, Yandong Wang, Jian Ming Zhang, Li Zhang", "title": "IBM Deep Learning Service", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning driven by large neural network models is overtaking traditional\nmachine learning methods for understanding unstructured and perceptual data\ndomains such as speech, text, and vision. At the same time, the\n\"as-a-Service\"-based business model on the cloud is fundamentally transforming\nthe information technology industry. These two trends: deep learning, and\n\"as-a-service\" are colliding to give rise to a new business model for cognitive\napplication delivery: deep learning as a service in the cloud. In this paper,\nwe will discuss the details of the software architecture behind IBM's deep\nlearning as a service (DLaaS). DLaaS provides developers the flexibility to use\npopular deep learning libraries such as Caffe, Torch and TensorFlow, in the\ncloud in a scalable and resilient manner with minimal effort. The platform uses\na distribution and orchestration layer that facilitates learning from a large\namount of data in a reasonable amount of time across compute nodes. A resource\nprovisioning layer enables flexible job management on heterogeneous resources,\nsuch as graphics processing units (GPUs) and central processing units (CPUs),\nin an infrastructure as a service (IaaS) cloud.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 11:40:48 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Bhattacharjee", "Bishwaranjan", ""], ["Boag", "Scott", ""], ["Doshi", "Chandani", ""], ["Dube", "Parijat", ""], ["Herta", "Ben", ""], ["Ishakian", "Vatche", ""], ["Jayaram", "K. R.", ""], ["Khalaf", "Rania", ""], ["Krishna", "Avesh", ""], ["Li", "Yu Bo", ""], ["Muthusamy", "Vinod", ""], ["Puri", "Ruchir", ""], ["Ren", "Yufei", ""], ["Rosenberg", "Florian", ""], ["Seelam", "Seetharami R.", ""], ["Wang", "Yandong", ""], ["Zhang", "Jian Ming", ""], ["Zhang", "Li", ""]]}, {"id": "1709.06076", "submitter": "Hermes Senger", "authors": "Lucas Venezian Povoa and Cesar Marcondes and Hermes Senger", "title": "Modelling Energy Consumption based on Resource Utilization", "comments": "Submitted to Journal of Supercomputing on 14th June, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power management is an expensive and important issue for large computational\ninfrastructures such as datacenters, large clusters, and computational grids.\nHowever, measuring energy consumption of scalable systems may be impractical\ndue to both cost and complexity for deploying power metering devices on a large\nnumber of machines. In this paper, we propose the use of information about\nresource utilization (e.g. processor, memory, disk operations, and network\ntraffic) as proxies for estimating power consumption. We employ machine\nlearning techniques to estimate power consumption using such information which\nare provided by common operating systems. Experiments with linear regression,\nregression tree, and multilayer perceptron on data from different hardware\nresulted into a model with 99.94\\% of accuracy and 6.32 watts of error in the\nbest case.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 19:17:02 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Povoa", "Lucas Venezian", ""], ["Marcondes", "Cesar", ""], ["Senger", "Hermes", ""]]}, {"id": "1709.06127", "submitter": "Carlos Vega", "authors": "Carlos Vega, Jose Fernando Zazo, Hugo Meyer, Ferad Zyulkyarov, Sergio\n  Lopez Buedo, Javier Aracil", "title": "Diluting the Scalability Boundaries: Exploring the Use of Disaggregated\n  Architectures for High-Level Network Data Analysis", "comments": "8 pages, 6 figures, 2 tables, 32 references. Pre-print. The paper\n  will be presented during the IEEE International Conference on High\n  Performance Computing and Communications in Bangkok, Thailand. 18 - 20\n  December, 2017. To be published in the conference proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional data centers are designed with a rigid architecture of\nfit-for-purpose servers that provision resources beyond the average workload in\norder to deal with occasional peaks of data. Heterogeneous data centers are\npushing towards more cost-efficient architectures with better resource\nprovisioning. In this paper we study the feasibility of using disaggregated\narchitectures for intensive data applications, in contrast to the monolithic\napproach of server-oriented architectures. Particularly, we have tested a\nproactive network analysis system in which the workload demands are highly\nvariable. In the context of the dReDBox disaggregated architecture, the results\nshow that the overhead caused by using remote memory resources is significant,\nbetween 66\\% and 80\\%, but we have also observed that the memory usage is one\norder of magnitude higher for the stress case with respect to average\nworkloads. Therefore, dimensioning memory for the worst case in conventional\nsystems will result in a notable waste of resources. Finally, we found that,\nfor the selected use case, parallelism is limited by memory. Therefore, using a\ndisaggregated architecture will allow for increased parallelism, which, at the\nsame time, will mitigate the overhead caused by remote memory.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 19:07:35 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Vega", "Carlos", ""], ["Zazo", "Jose Fernando", ""], ["Meyer", "Hugo", ""], ["Zyulkyarov", "Ferad", ""], ["Buedo", "Sergio Lopez", ""], ["Aracil", "Javier", ""]]}, {"id": "1709.06160", "submitter": "Ulya R. Karpuzcu", "authors": "Serif Yesil, Ismail Akturk, Ulya R. Karpuzcu", "title": "On Dynamic Precision Scaling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the observation that application phases exhibit varying degrees of\nsensitivity to noise (i.e., accuracy loss) in computation during execution,\nthis paper explores how Dynamic Precision Scaling (DPS) can maximize power\nefficiency by tailoring the precision of computation adaptively to temporal\nchanges in algorithmic noise tolerance. DPS can decrease the arithmetic\nprecision of noise-tolerant phases to result in power savings at the same\noperating speed (or faster execution within the same power budget), while\nkeeping the overall loss in accuracy due to precision reduction bounded.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 20:36:09 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Yesil", "Serif", ""], ["Akturk", "Ismail", ""], ["Karpuzcu", "Ulya R.", ""]]}, {"id": "1709.06175", "submitter": "Anthony Bourached", "authors": "Anthony Bourached", "title": "Blocking Versus Non-Blocking Halo Exchange", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report describes the design, implementation and analysis of a\nnon-blocking halo exchange routine as an alternative to the blocking halo\nexchange routine in the lattice Boltzmann code Ludwig. The alternative,\nnon-blocking, routine is implemented in such a way to allow work-communication\noverlap. Detailed benchmarks in this report show that the non-blocking version\nis a good alternative even without any work-communication overlap.\nWork-Communication overlap can be used to improve the performance of the\nnon-blocking routine. Development and benchmarking were conducted on the UK\nnational supercomputer, ARCHER.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 21:44:21 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Bourached", "Anthony", ""]]}, {"id": "1709.06214", "submitter": "Samir Elouasbi", "authors": "Samir Elouasbi and Andrzej Pelc", "title": "Deterministic rendezvous with detection using beeps", "comments": "A preliminary version of this paper appeared in Proc. 11th\n  International Symposium on Algorithms and Experiments for Wireless Sensor\n  Networks (ALGOSENSORS 2015), LNCS 9536, 85-97", "journal-ref": "International Journal of Foundations of Computer Science 28\n  (2017), 77-97", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two mobile agents, starting at arbitrary, possibly different times from\narbitrary nodes of an unknown network, have to meet at some node. Agents move\nin synchronous rounds: in each round an agent can either stay at the current\nnode or move to one of its neighbors. Agents have different labels which are\npositive integers. Each agent knows its own label, but not the label of the\nother agent. In traditional formulations of the rendezvous problem, meeting is\naccomplished when the agents get to the same node in the same round. We want to\nachieve a more demanding goal, called rendezvous with detection: agents must\nbecome aware that the meeting is accomplished, simultaneously declare this and\nstop. This awareness depends on how an agent can communicate to the other agent\nits presence at a node. We use two variations of the arguably weakest model of\ncommunication, called the beeping model, introduced in [8]. In each round an\nagent can either listen or beep. In the local beeping model, an agent hears a\nbeep in a round if it listens in this round and if the other agent is at the\nsame node and beeps. In the global beeping model, an agent hears a loud beep in\na round if it listens in this round and if the other agent is at the same node\nand beeps, and it hears a soft beep in a round if it listens in this round and\nif the other agent is at some other node and beeps. We first present a\ndeterministic algorithm of rendezvous with detection working, even for the\nlocal beeping model, in an arbitrary unknown network in time polynomial in the\nsize of the network and in the length of the smaller label (i.e., in the\nlogarithm of this label). However, in this algorithm, agents spend a lot of\nenergy: the number of moves that an agent must make, is proportional to the\ntime of rendezvous. It is thus natural to ask if bounded-energy agents can\nalways achieve rendezvous with detection as well...\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 00:58:43 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Elouasbi", "Samir", ""], ["Pelc", "Andrzej", ""]]}, {"id": "1709.06217", "submitter": "Samir Elouasbi", "authors": "Samir Elouasbi and Andrzej Pelc", "title": "Deterministic meeting of sniffing agents in the plane", "comments": "A preliminary version of this paper appeared in the Proc. 23rd\n  International Colloquium on Structural Information and Communication\n  Complexity (SIROCCO 2016), LNCS 9988", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two mobile agents, starting at arbitrary, possibly different times from\narbitrary locations in the plane, have to meet. Agents are modeled as discs of\ndiameter 1, and meeting occurs when these discs touch. Agents have different\nlabels which are integers from the set of 0 to L-1. Each agent knows L and\nknows its own label, but not the label of the other agent. Agents are equipped\nwith compasses and have synchronized clocks. They make a series of moves. Each\nmove specifies the direction and the duration of moving. This includes a null\nmove which consists in staying inert for some time, or forever. In a non-null\nmove agents travel at the same constant speed, normalized to 1. We assume that\nagents have sensors enabling them to estimate the distance from the other agent\n(defined as the distance between centers of discs), but not the direction\ntowards it. We consider two models of estimation. In both models an agent reads\nits sensor at the moment of its appearance in the plane and then at the end of\neach move. This reading (together with the previous ones) determines the\ndecision concerning the next move. In both models the reading of the sensor\ntells the agent if the other agent is already present. Moreover, in the\nmonotone model, each agent can find out, for any two readings in moments t1 and\nt2, whether the distance from the other agent at time t1 was smaller, equal or\nlarger than at time t2. In the weaker binary model, each agent can find out, at\nany reading, whether it is at distance less than \\r{ho} or at distance at least\n\\r{ho} from the other agent, for some real \\r{ho} > 1 unknown to them. Such\ndistance estimation mechanism can be implemented, e.g., using chemical sensors.\nEach agent emits some chemical substance (scent), and the sensor of the other\nagent detects it, i.e., sniffs. The intensity of the scent decreases with the\ndistance.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 01:22:27 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Elouasbi", "Samir", ""], ["Pelc", "Andrzej", ""]]}, {"id": "1709.06416", "submitter": "Shoumik Palkar", "authors": "Shoumik Palkar, James Thomas, Deepak Narayanan, Anil Shanbhag, Rahul\n  Palamuttam, Holger Pirk, Malte Schwarzkopf, Saman Amarasinghe, Samuel Madden,\n  and Matei Zaharia", "title": "Weld: Rethinking the Interface Between Data-Intensive Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data analytics applications combine multiple functions from different\nlibraries and frameworks. Even when each function is optimized in isolation,\nthe performance of the combined application can be an order of magnitude below\nhardware limits due to extensive data movement across these functions. To\naddress this problem, we propose Weld, a new interface between data-intensive\nlibraries that can optimize across disjoint libraries and functions. Weld\nexposes a lazily-evaluated API where diverse functions can submit their\ncomputations in a simple but general intermediate representation that captures\ntheir data-parallel structure. It then optimizes data movement across these\nfunctions and emits efficient code for diverse hardware. Weld can be integrated\ninto existing frameworks such as Spark, TensorFlow, Pandas and NumPy without\nchanging their user-facing APIs. We demonstrate that Weld can speed up\napplications using these frameworks by up to 29x.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 05:37:20 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 20:35:12 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Palkar", "Shoumik", ""], ["Thomas", "James", ""], ["Narayanan", "Deepak", ""], ["Shanbhag", "Anil", ""], ["Palamuttam", "Rahul", ""], ["Pirk", "Holger", ""], ["Schwarzkopf", "Malte", ""], ["Amarasinghe", "Saman", ""], ["Madden", "Samuel", ""], ["Zaharia", "Matei", ""]]}, {"id": "1709.06537", "submitter": "You-Luen Lee", "authors": "You-Luen Lee, Da-Cheng Juan, Xuan-An Tseng, Yu-Ting Chen, and\n  Shih-Chieh Chang", "title": "DC-Prophet: Predicting Catastrophic Machine Failures in DataCenters", "comments": "13 pages, 5 figures, accepted by 2017 ECML PKDD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When will a server fail catastrophically in an industrial datacenter? Is it\npossible to forecast these failures so preventive actions can be taken to\nincrease the reliability of a datacenter? To answer these questions, we have\nstudied what are probably the largest, publicly available datacenter traces,\ncontaining more than 104 million events from 12,500 machines. Among these\nsamples, we observe and categorize three types of machine failures, all of\nwhich are catastrophic and may lead to information loss, or even worse,\nreliability degradation of a datacenter. We further propose a two-stage\nframework-DC-Prophet-based on One-Class Support Vector Machine and Random\nForest. DC-Prophet extracts surprising patterns and accurately predicts the\nnext failure of a machine. Experimental results show that DC-Prophet achieves\nan AUC of 0.93 in predicting the next machine failure, and a F3-score of 0.88\n(out of 1). On average, DC-Prophet outperforms other classical machine learning\nmethods by 39.45% in F3-score.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 07:46:47 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Lee", "You-Luen", ""], ["Juan", "Da-Cheng", ""], ["Tseng", "Xuan-An", ""], ["Chen", "Yu-Ting", ""], ["Chang", "Shih-Chieh", ""]]}, {"id": "1709.06555", "submitter": "Ismail Akturk", "authors": "Ismail Akturk, Ulya R. Karpuzcu", "title": "Trading Computation for Communication: A Taxonomy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A critical challenge for modern system design is meeting the overwhelming\nperformance, storage, and communication bandwidth demand of emerging\napplications within a tightly bound power budget. As both the time and power,\nhence the energy, spent in data communication by far exceeds the energy spent\nin actual data generation (i.e., computation), (re)computing data can easily\nbecome cheaper than storing and retrieving (pre)computed data. Therefore,\ntrading computation for communication can improve energy efficiency by\nminimizing the energy overhead incurred by data storage, retrieval, and\ncommunication. This paper hence provides a taxonomy for the computation vs.\ncommunication trade-off along with quantitative characterization.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 21:59:13 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Akturk", "Ismail", ""], ["Karpuzcu", "Ulya R.", ""]]}, {"id": "1709.06604", "submitter": "Vidhya Tekken Valapil", "authors": "Vidhya Tekken-Valapil and Sandeep S. Kulkarni", "title": "Derivation of Network Reprogramming Protocol with Z3", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks protocols are the heart of communication networks. An efficient\nnetwork protocol does maximum utilization of the underlying network\ncapabilities. Network Protocol synthesis is the process of synthesizing or\nderiving network specific protocols from the requirements of a given specific\nnetwork. In this report, we present a step-by-step approach for the automated\nsynthesis of network protocols from the network specifications. Using SMT\nsolvers to automate the protocol generation is the key idea behind the\npresented synthesis approach. The protocols generated using this approach\nfollowed the most optimal way of data transmission for the given network\nrequirements.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 18:52:31 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Tekken-Valapil", "Vidhya", ""], ["Kulkarni", "Sandeep S.", ""]]}, {"id": "1709.06613", "submitter": "Hyoseung Kim", "authors": "Hyoseung Kim, Pratyush Patel, Shige Wang, and Ragunathan (Raj)\n  Rajkumar", "title": "A Server-based Approach for Predictable GPU Access with Improved\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a server-based approach to manage a general-purpose graphics\nprocessing unit (GPU) in a predictable and efficient manner. Our proposed\napproach introduces a GPU server that is a dedicated task to handle GPU\nrequests from other tasks on their behalf. The GPU server ensures bounded time\nto access the GPU, and allows other tasks to suspend during their GPU\ncomputation to save CPU cycles. By doing so, we address the two major\nlimitations of the existing real-time synchronization-based GPU management\napproach: busy waiting and long priority inversion. We have implemented a\nprototype of the server-based approach on a real embedded platform. This case\nstudy demonstrates the practicality and effectiveness of the server-based\napproach. Experimental results indicate that the server-based approach yields\nsignificant improvements in task schedulability over the existing\nsynchronization-based approach in most practical settings. Although we focus on\na GPU in this paper, the server-based approach can also be used for other types\nof computational accelerators.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 19:09:07 GMT"}, {"version": "v2", "created": "Fri, 11 May 2018 07:36:20 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Kim", "Hyoseung", "", "Raj"], ["Patel", "Pratyush", "", "Raj"], ["Wang", "Shige", "", "Raj"], ["Ragunathan", "", "", "Raj"], ["Rajkumar", "", ""]]}, {"id": "1709.06622", "submitter": "Chun-Nan Chou", "authors": "Shang-Xuan Zou, Chun-Yen Chen, Jui-Lin Wu, Chun-Nan Chou, Chia-Chin\n  Tsao, Kuan-Chieh Tung, Ting-Wei Lin, Cheng-Lung Sung, and Edward Y. Chang", "title": "Distributed Training Large-Scale Deep Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scale of data and scale of computation infrastructures together enable the\ncurrent deep learning renaissance. However, training large-scale deep\narchitectures demands both algorithmic improvement and careful system\nconfiguration. In this paper, we focus on employing the system approach to\nspeed up large-scale training. Via lessons learned from our routine\nbenchmarking effort, we first identify bottlenecks and overheads that hinter\ndata parallelism. We then devise guidelines that help practitioners to\nconfigure an effective system and fine-tune parameters to achieve desired\nspeedup. Specifically, we develop a procedure for setting minibatch size and\nchoosing computation algorithms. We also derive lemmas for determining the\nquantity of key components such as the number of GPUs and parameter servers.\nExperiments and examples show that these guidelines help effectively speed up\nlarge-scale deep learning training.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 09:24:27 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Zou", "Shang-Xuan", ""], ["Chen", "Chun-Yen", ""], ["Wu", "Jui-Lin", ""], ["Chou", "Chun-Nan", ""], ["Tsao", "Chia-Chin", ""], ["Tung", "Kuan-Chieh", ""], ["Lin", "Ting-Wei", ""], ["Sung", "Cheng-Lung", ""], ["Chang", "Edward Y.", ""]]}, {"id": "1709.06686", "submitter": "Antonio Rodrigues", "authors": "J\\\"org Thalheim, Antonio Rodrigues, Istemi Ekin Akkus, Pramod\n  Bhatotia, Ruichuan Chen, Bimal Viswanath, Lei Jiao and Christof Fetzer", "title": "Sieve: Actionable Insights from Monitored Metrics in Microservices", "comments": "This technical report is an extended version of our conference\n  publication: J\\\"org Thalheim, Antonio Rodrigues, Istemi Ekin Akkus, Pramod\n  Bhatotia, Ruichuan Chen, Bimal Viswanath, Lei Jiao, and Christof Fetzer.\n  Sieve: Actionable Insights from Monitored Metrics in Distributed Systems. In\n  Proceedings of Middleware '17, Las Vegas, NV, USA, December 11 - 15, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Major cloud computing operators provide powerful monitoring tools to\nunderstand the current (and prior) state of the distributed systems deployed in\ntheir infrastructure. While such tools provide a detailed monitoring mechanism\nat scale, they also pose a significant challenge for the application\ndevelopers/operators to transform the huge space of monitored metrics into\nuseful insights. These insights are essential to build effective management\ntools for improving the efficiency, resiliency, and dependability of\ndistributed systems.\n  This paper reports on our experience with building and deploying Sieve - a\nplatform to derive actionable insights from monitored metrics in distributed\nsystems. Sieve builds on two core components: a metrics reduction framework,\nand a metrics dependency extractor. More specifically, Sieve first reduces the\ndimensionality of metrics by automatically filtering out unimportant metrics by\nobserving their signal over time. Afterwards, Sieve infers metrics dependencies\nbetween distributed components of the system using a predictive-causality model\nby testing for Granger Causality. We implemented Sieve as a generic platform\nand deployed it for two microservices-based distributed systems: OpenStack and\nShareLatex. Our experience shows that (1) Sieve can reduce the number of\nmetrics by at least an order of magnitude (10 - 100$\\times$), while preserving\nthe statistical equivalence to the total number of monitored metrics; (2) Sieve\ncan dramatically improve existing monitoring infrastructures by reducing the\nassociated overheads over the entire system stack (CPU - 80%, storage - 90%,\nand network - 50%); (3) Lastly, Sieve can be effective to support a wide-range\nof workflows in distributed systems - we showcase two such workflows:\norchestration of autoscaling, and Root Cause Analysis (RCA).\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 00:27:11 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Thalheim", "J\u00f6rg", ""], ["Rodrigues", "Antonio", ""], ["Akkus", "Istemi Ekin", ""], ["Bhatotia", "Pramod", ""], ["Chen", "Ruichuan", ""], ["Viswanath", "Bimal", ""], ["Jiao", "Lei", ""], ["Fetzer", "Christof", ""]]}, {"id": "1709.06808", "submitter": "Yehuda Afek", "authors": "Yehuda Afek, Eli Daian and Eli Gafni", "title": "The Life in 1-Consensus", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the atomic Write and Read Next ($\\text{WRN}_{k}$)\ndeterministic shared memory object, that for any $k\\ge3$, is stronger than\nread-write registers, but is unable to implement $2$-processor consensus. In\nparticular, it refutes the conjecture claiming that every deterministic object\nof consensus number $1$ is computationally equivalent to read-write registers.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 10:49:30 GMT"}, {"version": "v2", "created": "Wed, 27 Sep 2017 07:03:18 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Afek", "Yehuda", ""], ["Daian", "Eli", ""], ["Gafni", "Eli", ""]]}, {"id": "1709.06815", "submitter": "Pekka Abrahamsson", "authors": "Pekka Abrahamsson, Sven Helmer, Nattakarn Phaphoom, Lorenzo Nicolodi,\n  Nick Preda, Lorenzo Miori, Matteo Angriman, Juha Rikkila, Xiaofeng Wang,\n  Karim Hamily, Sara Bugoloni", "title": "Affordable and Energy-Efficient Cloud Computing Clusters: The Bolzano\n  Raspberry Pi Cloud Cluster Experiment", "comments": "This is authors' own copy and self-archived in Arxiv. Copyright\n  holder's version of the published paper can be downloaded at\n  http://ieeexplore.ieee.org/document/6735414/", "journal-ref": "In 2013 IEEE 5th International Conference on (Vol. 2, pp.\n  170-175). IEEE", "doi": "10.1109/CloudCom.2013.121", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our ongoing work building a Raspberry Pi cluster consisting of 300\nnodes. The unique characteristics of this single board computer pose several\nchallenges, but also offer a number of interesting opportunities. On the one\nhand, a single Raspberry Pi can be purchased cheaply and has a low power\nconsumption, which makes it possible to create an affordable and\nenergy-efficient cluster. On the other hand, it lacks in computing power, which\nmakes it difficult to run computationally intensive software on it.\nNevertheless, by combining a large number of Raspberries into a cluster, this\ndrawback can be (partially) offset. Here we report on the first important steps\nof creating our cluster: how to set up and configure the hardware and the\nsystem software, and how to monitor and maintain the system. We also discuss\npotential use cases for our cluster, the two most important being an\ninexpensive and green test bed for cloud computing research and a robust and\nmobile data center for operating in adverse environments.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 11:15:01 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Abrahamsson", "Pekka", ""], ["Helmer", "Sven", ""], ["Phaphoom", "Nattakarn", ""], ["Nicolodi", "Lorenzo", ""], ["Preda", "Nick", ""], ["Miori", "Lorenzo", ""], ["Angriman", "Matteo", ""], ["Rikkila", "Juha", ""], ["Wang", "Xiaofeng", ""], ["Hamily", "Karim", ""], ["Bugoloni", "Sara", ""]]}, {"id": "1709.06816", "submitter": "Gavriel Yarmish", "authors": "Gavriel Yarmish, Philip Listowsky, Simon Dexter", "title": "Distributed Lance-William Clustering Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One important tool is the optimal clustering of data into useful categories.\nDividing similar objects into a smaller number of clusters is of importance in\nmany applications. These include search engines, monitoring of academic\nperformance, biology and wireless networks. We first discuss a number of\nclustering methods. We present a parallel algorithm for the efficient\nclustering of objects into groups based on their similarity to each other. The\ninput consists of an n by n distance matrix. This matrix would have a distance\nranking for each pair of objects. The smaller the number, the more similar the\ntwo objects are to each other. We utilize parallel processors to calculate a\nhierarchal cluster of these n items based on this matrix. Another advantage of\nour method is distribution of the large n by n matrix. We have implemented our\nalgorithm and have found it to be scalable both in terms of processing speed\nand storage.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 11:24:33 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Yarmish", "Gavriel", ""], ["Listowsky", "Philip", ""], ["Dexter", "Simon", ""]]}, {"id": "1709.06921", "submitter": "Alysson Bessani", "authors": "Jo\\~ao Sousa, Alysson Bessani and Marko Vukoli\\'c", "title": "A Byzantine Fault-Tolerant Ordering Service for the Hyperledger Fabric\n  Blockchain Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperledger Fabric (HLF) is a flexible permissioned blockchain platform\ndesigned for business applications beyond the basic digital coin addressed by\nBitcoin and other existing networks. A key property of HLF is its\nextensibility, and in particular the support for multiple ordering services for\nbuilding the blockchain. Nonetheless, the version 1.0 was launched in early\n2017 without an implementation of a Byzantine fault-tolerant (BFT) ordering\nservice. To overcome this limitation, we designed, implemented, and evaluated a\nBFT ordering service for HLF on top of the BFT-SMaRt state machine\nreplication/consensus library, implementing also optimizations for wide-area\ndeployment. Our results show that HLF with our ordering service can achieve up\nto ten thousand transactions per second and write a transaction irrevocably in\nthe blockchain in half a second, even with peers spread in different\ncontinents.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 15:10:45 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Sousa", "Jo\u00e3o", ""], ["Bessani", "Alysson", ""], ["Vukoli\u0107", "Marko", ""]]}, {"id": "1709.06927", "submitter": "Manas Yogi Mr", "authors": "Manas Kumar Yogi, K. Chandrasekhar, G. Vijay Kumar", "title": "Mist Computing: Principles, Trends and Future Direction", "comments": null, "journal-ref": null, "doi": "10.14445/23488387/IJCSE-V4I7P104", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper we present the novel idea of computing near the edge of IOT\narchitecture which enhances the inherent efficiency while computing complex\napplications. This concept is termed as mist computing. We believe this\ncomputing will bring about an massive revolution in future computing\ntechnologies. instead of thrusting the control responsibility to gateways while\ndata transmission the control is decentralised to end nodes which decrease the\ncommunicational delay of the network thereby increasing the throughput.\n", "versions": [{"version": "v1", "created": "Sun, 6 Aug 2017 15:02:15 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Yogi", "Manas Kumar", ""], ["Chandrasekhar", "K.", ""], ["Kumar", "G. Vijay", ""]]}, {"id": "1709.07122", "submitter": "Kartik Lakhotia", "authors": "Kartik Lakhotia, Rajgopal Kannan, Viktor Prasanna", "title": "Accelerating PageRank using Partition-Centric Processing", "comments": "Added acknowledgments. In proceedings of USENIX ATC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PageRank is a fundamental link analysis algorithm that also functions as a\nkey representative of the performance of Sparse Matrix-Vector (SpMV)\nmultiplication. The traditional PageRank implementation generates fine\ngranularity random memory accesses resulting in large amount of wasteful DRAM\ntraffic and poor bandwidth utilization. In this paper, we present a novel\nPartition-Centric Processing Methodology (PCPM) to compute PageRank, that\ndrastically reduces the amount of DRAM communication while achieving high\nsustained memory bandwidth. PCPM uses a Partition-centric abstraction coupled\nwith the Gather-Apply-Scatter (GAS) programming model. By carefully examining\nhow a PCPM based implementation impacts communication characteristics of the\nalgorithm, we propose several system optimizations that improve the execution\ntime substantially. More specifically, we develop (1) a new data layout that\nsignificantly reduces communication and random DRAM accesses, and (2) branch\navoidance mechanisms to get rid of unpredictable data-dependent branches.\n  We perform detailed analytical and experimental evaluation of our approach\nusing 6 large graphs and demonstrate an average 2.7x speedup in execution time\nand 1.7x reduction in communication volume, compared to the state-of-the-art.\nWe also show that unlike other GAS based implementations, PCPM is able to\nfurther reduce main memory traffic by taking advantage of intelligent node\nlabeling that enhances locality. Although we use PageRank as the target\napplication in this paper, our approach can be applied to generic SpMV\ncomputation.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 01:41:34 GMT"}, {"version": "v2", "created": "Mon, 11 Dec 2017 19:26:08 GMT"}, {"version": "v3", "created": "Wed, 7 Feb 2018 09:02:35 GMT"}, {"version": "v4", "created": "Mon, 6 Aug 2018 20:32:23 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Lakhotia", "Kartik", ""], ["Kannan", "Rajgopal", ""], ["Prasanna", "Viktor", ""]]}, {"id": "1709.07250", "submitter": "Mikel Canizo", "authors": "Mikel Canizo, Enrique Onieva, Angel Conde, Santiago Charramendieta,\n  Salvador Trujillo", "title": "Real-time predictive maintenance for wind turbines using Big Data\n  frameworks", "comments": null, "journal-ref": "2017 IEEE International Conference on Prognostics and Health\n  Management (ICPHM)", "doi": "10.1109/ICPHM.2017.7998308", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents the evolution of a solution for predictive maintenance to\na Big Data environment. The proposed adaptation aims for predicting failures on\nwind turbines using a data-driven solution deployed in the cloud and which is\ncomposed by three main modules. (i) A predictive model generator which\ngenerates predictive models for each monitored wind turbine by means of Random\nForest algorithm. (ii) A monitoring agent that makes predictions every 10\nminutes about failures in wind turbines during the next hour. Finally, (iii) a\ndashboard where given predictions can be visualized. To implement the solution\nApache Spark, Apache Kafka, Apache Mesos and HDFS have been used. Therefore, we\nhave improved the previous work in terms of data process speed, scalability and\nautomation. In addition, we have provided fault-tolerant functionality with a\ncentralized access point from where the status of all the wind turbines of a\ncompany localized all over the world can be monitored, reducing O&M costs.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 10:38:39 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Canizo", "Mikel", ""], ["Onieva", "Enrique", ""], ["Conde", "Angel", ""], ["Charramendieta", "Santiago", ""], ["Trujillo", "Salvador", ""]]}, {"id": "1709.07558", "submitter": "Ruben Mayer", "authors": "Ruben Mayer, Harshit Gupta, Enrique Saurez and Umakishore Ramachandran", "title": "FogStore: Toward a Distributed Data Store for Fog Computing", "comments": "To appear in Proceedings of 2017 IEEE Fog World Congress (FWC '17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stateful applications and virtualized network functions (VNFs) can benefit\nfrom state externalization to increase their reliability, scalability, and\ninter-operability. To keep and share the externalized state, distributed data\nstores (DDSs) are a powerful tool allowing for the management of classical\ntrade-offs in consistency, availability and partitioning tolerance. With the\nadvent of Fog and Edge Computing, stateful applications and VNFs are pushed\nfrom the data centers toward the network edge. This poses new challenges on\nDDSs that are tailored to a deployment in Cloud data centers. In this paper, we\npropose two novel design goals for DDSs that are tailored to Fog Computing: (1)\nFog-aware replica placement, and (2) context-sensitive differential\nconsistency. To realize those design goals on top of existing DDSs, we propose\nthe FogStore system. FogStore manages the needed adaptations in replica\nplacement and consistency management transparently, so that existing DDSs can\nbe plugged into the system. To show the benefits of FogStore, we perform a set\nof evaluations using the Yahoo Cloud Serving Benchmark.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 01:05:57 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Mayer", "Ruben", ""], ["Gupta", "Harshit", ""], ["Saurez", "Enrique", ""], ["Ramachandran", "Umakishore", ""]]}, {"id": "1709.07563", "submitter": "Ruben Mayer", "authors": "Ruben Mayer, Leon Graser, Harshit Gupta, Enrique Saurez, Umakishore\n  Ramachandran", "title": "EmuFog: Extensible and Scalable Emulation of Large-Scale Fog Computing\n  Infrastructures", "comments": "To appear in Proceedings of 2017 IEEE Fog World Congress (FWC '17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The diversity of Fog Computing deployment models and the lack of publicly\navailable Fog infrastructure makes the design of an efficient application or\nresource management policy a challenging task. Such research often requires a\ntest framework that facilitates the experimental evaluation of an application\nor protocol design in a repeatable and controllable manner. In this paper, we\npresent EmuFog---an extensible emulation framework tailored for Fog Computing\nscenarios---that enables the from-scratch design of Fog Computing\ninfrastructures and the emulation of real applications and workloads. EmuFog\nenables researchers to design the network topology according to the use-case,\nembed Fog Computing nodes in the topology and run Docker-based applications on\nthose nodes connected by an emulated network. Each of the sub-modules of EmuFog\nare easily extensible, although EmuFog provides a default implementation for\neach of them. The scalability and efficacy of EmuFog are evaluated both on\nsynthetic and real-world network topologies.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 01:29:37 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Mayer", "Ruben", ""], ["Graser", "Leon", ""], ["Gupta", "Harshit", ""], ["Saurez", "Enrique", ""], ["Ramachandran", "Umakishore", ""]]}, {"id": "1709.07594", "submitter": "Sudhakar Singh", "authors": "Sudhakar Singh, Rakhi Garg, P. K. Mishra", "title": "A Comparative Study of Association Rule Mining Algorithms on Grid and\n  Cloud Platform", "comments": "8 pages, preprint", "journal-ref": "International Journal of Emerging Technologies in Computational\n  and Applied Sciences, 2014", "doi": null, "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Association rule mining is a time consuming process due to involving both\ndata intensive and computation intensive nature. In order to mine large volume\nof data and to enhance the scalability and performance of existing sequential\nassociation rule mining algorithms, parallel and distributed algorithms are\ndeveloped. These traditional parallel and distributed algorithms are based on\nhomogeneous platform and are not lucrative for heterogeneous platform such as\ngrid and cloud. This requires design of new algorithms which address the issues\nof good data set partition and distribution, load balancing strategy,\noptimization of communication and synchronization technique among processors in\nsuch heterogeneous system. Grid and cloud are the emerging platform for\ndistributed data processing and various association rule mining algorithms have\nbeen proposed on such platforms. This survey article integrates the brief\narchitectural aspect of distributed system, various recent approaches of grid\nbased and cloud based association rule mining algorithms with comparative\nperception. We differentiate between approaches of association rule mining\nalgorithms developed on these architectures on the basis of data locality,\nprogramming paradigm, fault tolerance, communication cost, partition and\ndistribution of data sets. Although it is not complete in order to cover all\nalgorithms, yet it can be very useful for the new researchers working in the\ndirection of distributed association rule mining algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 05:06:18 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Singh", "Sudhakar", ""], ["Garg", "Rakhi", ""], ["Mishra", "P. K.", ""]]}, {"id": "1709.07605", "submitter": "Charles Jordan", "authors": "David Avis and Charles Jordan", "title": "mts: A light framework for parallelizing tree search codes", "comments": "This complements the earlier tutorial (arXiv:1610.07735) on how to\n  use mts, with which it shares some material. The tutorial should be consulted\n  for specific details of the programming changes to legacy code required. This\n  version included two more applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe mts, a generic framework for parallelizing certain types of tree\nsearch programs including reverse search, backtracking, branch and bound and\nsatisfiability testing. It abstracts and generalizes the ideas used in\nparallelizing lrs, a reverse search code for vertex enumeration. mts supports\nsharing information between processes which is important for applications such\nas satisfiability testing and branch-and-bound. No parallelization is\nimplemented in the legacy single processor programs minimizing the changes\nneeded and simplying debugging. mts is written in C, uses MPI for\nparallelization and can be used on a network of computers. We give four\nexamples of reverse search codes parallelized by using mts: topological sorts,\nspanning trees, triangulations and Galton-Watson trees. We also give a\nparallelization of two codes for satisfiability testing. We give experimental\nresults comparing the parallel codes with other codes for the same problems.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 05:59:21 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 09:40:58 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Avis", "David", ""], ["Jordan", "Charles", ""]]}, {"id": "1709.07688", "submitter": "Mennan Selimi", "authors": "Arjuna Sathiaseelan, Mennan Selimi, Carlos Molina, Adisorn\n  Lertsinsrubtavee, Leandro Navarro, Felix Freitag, Fernando Ramos, Roger Baig", "title": "Towards Decentralised Resilient Community Cloud Infrastructures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen a trend towards decentralisation - from initiatives on\ndecentralized web to decentralized network infrastructures (e.g community\nnetworks). In this position paper, we present an architectural vision for\ndecentralising cloud service infrastructures. Our vision is on the notion of\ncommunity cloud infrastructures on top of decentralised access infrastructures\ni.e. community networks, using resources pooled from the community. Our\narchitectural vision takes into consideration some of the fundamental\nchallenges of integrating the current state of the art virtualisation\ntechnologies such as Software Defined Networking (SDN) into community\ninfrastructures which are highly unreliable. Our proposed design goal is to\ninclude lightweight virtualization and fault tolerance mechanisms into the\narchitecture to ensure sufficient level of reliability to support critical\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 10:55:19 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Sathiaseelan", "Arjuna", ""], ["Selimi", "Mennan", ""], ["Molina", "Carlos", ""], ["Lertsinsrubtavee", "Adisorn", ""], ["Navarro", "Leandro", ""], ["Freitag", "Felix", ""], ["Ramos", "Fernando", ""], ["Baig", "Roger", ""]]}, {"id": "1709.07700", "submitter": "Adam Larat", "authors": "Florence Drui (1,2), Alexandru Fikl (2), Pierre Kestener (2), Samuel\n  Kokh (2), Adam Larat (1,3), Vincent Le Chenadec (1), Marc Massot (1,3) ((1)\n  EM2C, (2) MDLS, (3) FR3487)", "title": "Experimenting with the p4est library for AMR simulations of two-phase\n  flows", "comments": null, "journal-ref": "ESAIM: Proceedings and Surveys, EDP Sciences, 2016, 53, pp.232 -\n  247", "doi": "10.1051/proc/201653014", "report-no": null, "categories": "math.NA cs.DC cs.DM physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many physical problems involve spatial and temporal inhomogeneities that\nrequire a very fine discretization in order to be accurately simulated. Using\nan adaptive mesh, a high level of resolution is used in the appropriate areas\nwhile keeping a coarse mesh elsewhere. This idea allows to save time and\ncomputations, but represents a challenge for distributed-memory environments.\nThe MARS project (for Multiphase Adaptative Refinement Solver) intends to\nassess the parallel library p4est for adaptive mesh, in a case of a finite\nvolume scheme applied to two-phase flows. Besides testing the library's\nperformances, particularly for load balancing, its user-friendliness in use and\nimplementation are also exhibited here. First promising 3D simulations are even\npresented.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 11:41:54 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Drui", "Florence", ""], ["Fikl", "Alexandru", ""], ["Kestener", "Pierre", ""], ["Kokh", "Samuel", ""], ["Larat", "Adam", ""], ["Chenadec", "Vincent Le", ""], ["Massot", "Marc", ""]]}, {"id": "1709.07741", "submitter": "Germ\\'an Andr\\'es Delbianco", "authors": "Aleksandar Nanevski, Anindya Banerjee, Germ\\'an Andr\\'es Delbianco", "title": "Subjective Simulation as a Notion of Morphism for Composing Concurrent\n  Resources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent approaches to verifying programs in separation logics for concurrency\nhave used state transition systems (STSs) to specify the atomic operations of\nprograms. A key challenge in the setting has been to compose such STSs into\nlarger ones, while enabling programs specified under one STS to be linked to a\nlarger one, without reverification. This paper develops a notion of morphism\nbetween two STSs which permits such lifting. The morphisms are a constructive\nform of simulation between the STSs, and lead to a general and concise proof\nsystem. We illustrate the concept and its generality on several disparate\nexamples, including staged construction of a readers/writers lock and its\nproof, and of proofs about quiescence when concurrent programs are executed\nwithout external interference.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 13:35:58 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Nanevski", "Aleksandar", ""], ["Banerjee", "Anindya", ""], ["Delbianco", "Germ\u00e1n Andr\u00e9s", ""]]}, {"id": "1709.07772", "submitter": "Liang Wang", "authors": "Liang Wang, Ben Catterall and Richard Mortier", "title": "Probabilistic Synchronous Parallel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most machine learning and deep neural network algorithms rely on certain\niterative algorithms to optimise their utility/cost functions, e.g. Stochastic\nGradient Descent. In distributed learning, the networked nodes have to work\ncollaboratively to update the model parameters, and the way how they proceed is\nreferred to as synchronous parallel design (or barrier control). Synchronous\nparallel protocol is the building block of any distributed learning framework,\nand its design has direct impact on the performance and scalability of the\nsystem.\n  In this paper, we propose a new barrier control technique - Probabilistic\nSynchronous Parallel (PSP). Com- paring to the previous Bulk Synchronous\nParallel (BSP), Stale Synchronous Parallel (SSP), and (Asynchronous Parallel)\nASP, the proposed solution e ectively improves both the convergence speed and\nthe scalability of the SGD algorithm by introducing a sampling primitive into\nthe system. Moreover, we also show that the sampling primitive can be applied\natop of the existing barrier control mechanisms to derive fully distributed\nPSP-based synchronous parallel.\n  We not only provide a thorough theoretical analysis1 on the convergence of\nPSP-based SGD algorithm, but also implement a full-featured distributed\nlearning framework called Actor and perform intensive evaluation atop of it.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 14:22:39 GMT"}, {"version": "v2", "created": "Thu, 5 Oct 2017 15:40:22 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Wang", "Liang", ""], ["Catterall", "Ben", ""], ["Mortier", "Richard", ""]]}, {"id": "1709.07781", "submitter": "Raphael Hiesgen", "authors": "Raphael Hiesgen, Dominik Charousset, Thomas C. Schmidt", "title": "OpenCL Actors - Adding Data Parallelism to Actor-based Programming with\n  CAF", "comments": "28 pages", "journal-ref": "Springer LNCS 10789, pp. 59--93, 2018", "doi": "10.1007/978-3-030-00302-9_3", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The actor model of computation has been designed for a seamless support of\nconcurrency and distribution. However, it remains unspecific about data\nparallel program flows, while available processing power of modern many core\nhardware such as graphics processing units (GPUs) or coprocessors increases the\nrelevance of data parallelism for general-purpose computation.\n  In this work, we introduce OpenCL-enabled actors to the C++ Actor Framework\n(CAF). This offers a high level interface for accessing any OpenCL device\nwithout leaving the actor paradigm. The new type of actor is integrated into\nthe runtime environment of CAF and gives rise to transparent message passing in\ndistributed systems on heterogeneous hardware. Following the actor logic in\nCAF, OpenCL kernels can be composed while encapsulated in C++ actors, hence\noperate in a multi-stage fashion on data resident at the GPU. Developers are\nthus enabled to build complex data parallel programs from primitives without\nleaving the actor paradigm, nor sacrificing performance. Our evaluations on\ncommodity GPUs, an Nvidia TESLA, and an Intel PHI reveal the expected linear\nscaling behavior when offloading larger workloads. For sub-second duties, the\nefficiency of offloading was found to largely differ between devices. Moreover,\nour findings indicate a negligible overhead over programming with the native\nOpenCL API.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 14:35:27 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Hiesgen", "Raphael", ""], ["Charousset", "Dominik", ""], ["Schmidt", "Thomas C.", ""]]}, {"id": "1709.07790", "submitter": "Roberto Tonelli", "authors": "Andrea Pinna, Roberto Tonelli, Matteo Orr\\'u and Michele Marchesi", "title": "A Petri Nets Model for Blockchain Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Blockchain is a global shared infrastructure where cryptocurrency\ntransactions among addresses are recorded, validated and made publicly\navailable in a peer- to-peer network. To date the best known and important\ncryptocurrency is the bitcoin. In this paper we focus on this cryptocurrency\nand in particular on the modeling of the Bitcoin Blockchain by using the Petri\nNets formalism. The proposed model allows us to quickly collect information\nabout identities owning Bitcoin addresses and to recover measures and\nstatistics on the Bitcoin network. By exploiting algebraic formalism, we\nreconstructed an Entities network associated to Blockchain transactions\ngathering together Bitcoin addresses into the single entity holding permits to\nmanage Bitcoins held by those addresses. The model allows also to identify a\nset of behaviours typical of Bitcoin owners, like that of using an address only\nonce, and to reconstruct chains for this behaviour together with the rate of\nfiring. Our model is highly flexible and can easily be adapted to include\ndifferent features of the Bitcoin crypto-currency system.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 14:50:15 GMT"}, {"version": "v2", "created": "Tue, 26 Sep 2017 16:14:39 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Pinna", "Andrea", ""], ["Tonelli", "Roberto", ""], ["Orr\u00fa", "Matteo", ""], ["Marchesi", "Michele", ""]]}, {"id": "1709.07822", "submitter": "Nima Anari", "authors": "Nima Anari and Vijay V. Vazirani", "title": "Planar Graph Perfect Matching is in NC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.DC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is perfect matching in NC? That is, is there a deterministic fast parallel\nalgorithm for it? This has been an outstanding open question in theoretical\ncomputer science for over three decades, ever since the discovery of RNC\nmatching algorithms. Within this question, the case of planar graphs has\nremained an enigma: On the one hand, counting the number of perfect matchings\nis far harder than finding one (the former is #P-complete and the latter is in\nP), and on the other, for planar graphs, counting has long been known to be in\nNC whereas finding one has resisted a solution.\n  In this paper, we give an NC algorithm for finding a perfect matching in a\nplanar graph. Our algorithm uses the above-stated fact about counting matchings\nin a crucial way. Our main new idea is an NC algorithm for finding a face of\nthe perfect matching polytope at which $\\Omega(n)$ new conditions, involving\nconstraints of the polytope, are simultaneously satisfied. Several other ideas\nare also needed, such as finding a point in the interior of the minimum weight\nface of this polytope and finding a balanced tight odd set in NC.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 15:56:53 GMT"}, {"version": "v2", "created": "Mon, 9 Oct 2017 00:50:32 GMT"}, {"version": "v3", "created": "Mon, 4 Dec 2017 22:02:03 GMT"}, {"version": "v4", "created": "Sat, 21 Apr 2018 21:49:54 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Anari", "Nima", ""], ["Vazirani", "Vijay V.", ""]]}, {"id": "1709.07972", "submitter": "Valentina Breschi", "authors": "Valentina Breschi, Ilya Kolmanovsky, Alberto Bemporad", "title": "Cloud-aided collaborative estimation by ADMM-RLS algorithms for\n  connected vehicle prognostics", "comments": "Extended version, with complete proofs, of a submission to the\n  American Control Conference 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.DC cs.MA eess.SP math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the connectivity of consumer devices is rapidly growing and cloud\ncomputing technologies are becoming more widespread, cloud-aided techniques for\nparameter estimation can be designed to exploit the theoretically unlimited\nstorage memory and computational power of the cloud, while relying on\ninformation provided by multiple sources. With the ultimate goal of developing\nmonitoring and diagnostic strategies, this report focuses on the design of a\nRecursive Least-Squares (RLS) based estimator for identification over a group\nof devices connected to the cloud. The proposed approach, that relies on\nNode-to-Cloud-to-Node (N2C2N) transmissions, is designed so that: (i) estimates\nof the unknown parameters are computed locally and (ii) the local estimates are\nrefined on the cloud. The proposed approach requires minimal changes to local\n(pre-existing) RLS estimators.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 23:38:08 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Breschi", "Valentina", ""], ["Kolmanovsky", "Ilya", ""], ["Bemporad", "Alberto", ""]]}, {"id": "1709.08001", "submitter": "Sandeep Singh Sandha", "authors": "Sandeep Sandha, Xin Xu, Yue Xin, Zhehan Li", "title": "Real-time Log Query Interface for large datasets using Apache Spark", "comments": "8 pages, 9 figures, big dataset query report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Log Query Interface is an interactive web application that allows users to\nquery the very large data logs of MobileInsight easily and efficiently. With\nthis interface, users no longer need to talk to the database through command\nline queries, nor to install the MobileInsight client locally to fetch data.\nUsers can simply select/type the query message through our web based system\nwhich queries the database very efficiently and responds back to user. While\ntesting on 6GB of datasets our system takes less than 1 seconds to respond\nback, the similar queries on traditional MySql database takes more than 60\nseconds. The system gives user the capability to execute all the queries using\nsql query language. User can perform complex join operations on very large\ntables. The query response time is hugely improved by the server side Spark\nclusters, which stores the big datasets in a distributed system and execute the\nquery in parallel on multiple machines.\n", "versions": [{"version": "v1", "created": "Sat, 23 Sep 2017 04:20:00 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Sandha", "Sandeep", ""], ["Xu", "Xin", ""], ["Xin", "Yue", ""], ["Li", "Zhehan", ""]]}, {"id": "1709.08296", "submitter": "Zhenyu Yan", "authors": "Zhenyu Yan (1), Yang Li (2), Rui Tan (1), Jun Huang (3) ((1) School of\n  Computer Science and Engineering, Nanyang Technological University, (2)\n  Advanced Digital Sciences Center, Illinois at Singapore, (3) Center for\n  Energy Efficient Computing and Applications, Peking University)", "title": "Application-Layer Clock Synchronization for Wearables Using Skin\n  Electric Potentials Induced by Powerline Radiation", "comments": "The 15th ACM Conference on Embedded Networked Sensor Systems (SenSys\n  2017)", "journal-ref": null, "doi": "10.1145/3131672.3131681", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design of clock synchronization for networked nodes faces a fundamental\ntrade-off between synchronization accuracy and universality for heterogeneous\nplatforms, because a high synchronization accuracy generally requires\nplatform-dependent hardware-level network packet timestamping. This paper\npresents TouchSync, a new indoor clock synchronization approach for wearables\nthat achieves millisecond accuracy while preserving universality in that it\nuses standard system calls only, such as reading system clock, sampling\nsensors, and sending/receiving network messages. The design of TouchSync is\ndriven by a key finding from our extensive measurements that the skin electric\npotentials (SEPs) induced by powerline radiation are salient, periodic, and\nsynchronous on a same wearer and even across different wearers. TouchSync\nintegrates the SEP signal into the universal principle of Network Time Protocol\nand solves an integer ambiguity problem by fusing the ambiguous results in\nmultiple synchronization rounds to conclude an accurate clock offset between\ntwo synchronizing wearables. With our shared code, TouchSync can be readily\nintegrated into any wearable applications. Extensive evaluation based on our\nArduino and TinyOS implementations shows that TouchSync's synchronization\nerrors are below 3 and 7 milliseconds on the same wearer and between two\nwearers 10 kilometers apart, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 03:01:02 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Yan", "Zhenyu", ""], ["Li", "Yang", ""], ["Tan", "Rui", ""], ["Huang", "Jun", ""]]}, {"id": "1709.08501", "submitter": "Michael Walfish", "authors": "Cheng Tan, Lingfan Yu, Joshua B. Leners, and Michael Walfish", "title": "The Efficient Server Audit Problem, Deduplicated Re-execution, and the\n  Web", "comments": "Extended version of a publication at SOSP 2017. v2 updates the\n  extended version to be consistent with the published SOSP version, and\n  corrects some additional typos", "journal-ref": null, "doi": "10.1145/3132747.3132760", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  You put a program on a concurrent server, but you don't trust the server;\nlater, you get a trace of the actual requests that the server received from its\nclients and the responses that it delivered. You separately get logs from the\nserver; these are untrusted. How can you use the logs to efficiently _verify_\nthat the responses were derived from running the program on the requests? This\nis the _Efficient Server Audit Problem_, and it abstracts real-world scenarios,\nincluding running a web application on an untrusted provider. We give a\nsolution based on several new techniques, including simultaneous replay and\nefficient verification of concurrent executions. We implement the solution for\nPHP web applications. For several applications, our verifier achieves\n5.6--10.9x speedup versus simply re-executing, with less than 10 percent\noverhead for the server.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 14:11:24 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 11:48:52 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Tan", "Cheng", ""], ["Yu", "Lingfan", ""], ["Leners", "Joshua B.", ""], ["Walfish", "Michael", ""]]}, {"id": "1709.08526", "submitter": "\\'Alvaro L\\'opez Garc\\'ia", "authors": "\\'Alvaro L\\'opez Garc\\'ia, Enol Fern\\'andez-del-Castillo, Pablo Orviz\n  Fern\\'andez, Isabel Campos Plasencia, Jes\\'us Marco de Lucas", "title": "Resource provisioning in Science Clouds: Requirements and challenges", "comments": null, "journal-ref": "Software: Practice and Experience. 2017;1-13", "doi": "10.1002/spe.2544", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing has permeated into the information technology industry in the\nlast few years, and it is emerging nowadays in scientific environments. Science\nuser communities are demanding a broad range of computing power to satisfy the\nneeds of high-performance applications, such as local clusters,\nhigh-performance computing systems, and computing grids. Different workloads\nare needed from different computational models, and the cloud is already\nconsidered as a promising paradigm. The scheduling and allocation of resources\nis always a challenging matter in any form of computation and clouds are not an\nexception. Science applications have unique features that differentiate their\nworkloads, hence, their requirements have to be taken into consideration to be\nfulfilled when building a Science Cloud. This paper will discuss what are the\nmain scheduling and resource allocation challenges for any Infrastructure as a\nService provider supporting scientific applications.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 14:44:50 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Garc\u00eda", "\u00c1lvaro L\u00f3pez", ""], ["Fern\u00e1ndez-del-Castillo", "Enol", ""], ["Fern\u00e1ndez", "Pablo Orviz", ""], ["Plasencia", "Isabel Campos", ""], ["de Lucas", "Jes\u00fas Marco", ""]]}, {"id": "1709.08662", "submitter": "Lixing Chen", "authors": "Lixing Chen, Jie Xu", "title": "Collaborative Service Caching for Edge Computing in Dense Small Cell\n  Networks", "comments": "arXiv admin note: text overlap with arXiv:1010.4501 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile Edge Computing (MEC) pushes computing functionalities away from the\ncentralized cloud to the proximity of data sources, thereby reducing service\nprovision latency and saving backhaul network bandwidth. Although computation\noffloading has been extensively studied in the literature, service caching is\nan equally, if not more, important design topic of MEC, yet receives much less\nattention. Service caching refers to caching application services and their\nrelated data (libraries/databases) in the edge server, e.g. MEC-enabled Base\nStation (BS), enabling corresponding computation tasks to be executed. Since\nonly a small number of services can be cached in resource-limited edge server\nat the same time, which services to cache has to be judiciously decided to\nmaximize the system performance. In this paper, we investigate collaborative\nservice caching in MEC-enabled dense small cell (SC) networks. We propose an\nefficient decentralized algorithm, called CSC (Collaborative Service Caching),\nwhere a network of small cell BSs optimize service caching collaboratively to\naddress a number of key challenges in MEC systems, including service\nheterogeneity, spatial demand coupling, and decentralized coordination. Our\nalgorithm is developed based on parallel Gibbs sampling by exploiting the\nspecial structure of the considered problem using graphing coloring. The\nalgorithm significantly improves the time efficiency compared to conventional\nGibbs sampling, yet guarantees provable convergence and optimality. CSC is\nfurther extended to the SC network with selfish BSs, where a coalitional game\nis formulated to incentivize collaboration. A coalition formation algorithm is\ndeveloped by employing the merge-and-split rules and ensures the stability of\nthe SC coalitions.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 18:32:22 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Chen", "Lixing", ""], ["Xu", "Jie", ""]]}, {"id": "1709.08689", "submitter": "Kyriakos Georgiou", "authors": "Samuel Xavier-de-Souza, Eduardo A. Neves, Alex F. A. Furtunato, Luiz\n  F. Q. Silveira, Kyriakos Georgiou, Kerstin I. Eder", "title": "The Benefits of Low Operating Voltage Devices to the Energy Efficiency\n  of Parallel Systems", "comments": null, "journal-ref": null, "doi": "10.1109/E3S.2017.8246198", "report-no": "LAPPS2017_001", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programmable circuits such as general-purpose processors or FPGAs have their\nend-user energy efficiency strongly dependent on the program that they execute.\nUltimately, it is the programmer's ability to code and, in the case of general\npurpose processors, the compiler's ability to translate source code into a\nsequence of native instructions that make the circuit deliver the expected\nperformance to the end user. This way, the benefits of energy-efficient\ncircuits build upon energy-efficient devices could be obfuscated by poorly\nwritten software. Clearly, having well-written software running on conventional\ncircuits is no better in terms of energy efficiency than having poorly written\nsoftware running on energy-efficient circuits. Therefore, to get the most out\nof the energy-saving capabilities of programmable circuits that support low\nvoltage operating modes, it is necessary to address software issues that might\nwork against the benefits of operating in such modes.\n", "versions": [{"version": "v1", "created": "Sun, 13 Aug 2017 11:59:03 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Xavier-de-Souza", "Samuel", ""], ["Neves", "Eduardo A.", ""], ["Furtunato", "Alex F. A.", ""], ["Silveira", "Luiz F. Q.", ""], ["Georgiou", "Kyriakos", ""], ["Eder", "Kerstin I.", ""]]}, {"id": "1709.08765", "submitter": "Michael Rabbat", "authors": "Angelia Nedi\\'c, Alex Olshevsky, Michael G. Rabbat", "title": "Network Topology and Communication-Computation Tradeoffs in\n  Decentralized Optimization", "comments": "32 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In decentralized optimization, nodes cooperate to minimize an overall\nobjective function that is the sum (or average) of per-node private objective\nfunctions. Algorithms interleave local computations with communication among\nall or a subset of the nodes. Motivated by a variety of\napplications---distributed estimation in sensor networks, fitting models to\nmassive data sets, and distributed control of multi-robot systems, to name a\nfew---significant advances have been made towards the development of robust,\npractical algorithms with theoretical performance guarantees. This paper\npresents an overview of recent work in this area. In general, rates of\nconvergence depend not only on the number of nodes involved and the desired\nlevel of accuracy, but also on the structure and nature of the network over\nwhich nodes communicate (e.g., whether links are directed or undirected, static\nor time-varying). We survey the state-of-the-art algorithms and their analyses\ntailored to these different scenarios, highlighting the role of the network\ntopology.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 00:46:01 GMT"}, {"version": "v2", "created": "Mon, 15 Jan 2018 17:45:04 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Nedi\u0107", "Angelia", ""], ["Olshevsky", "Alex", ""], ["Rabbat", "Michael G.", ""]]}, {"id": "1709.08767", "submitter": "Eliu Huerta", "authors": "E. A. Huerta, Roland Haas, Edgar Fajardo, Daniel S. Katz, Stuart\n  Anderson, Peter Couvares, Josh Willis, Timothy Bouvet, Jeremy Enos, William\n  T. C. Kramer, Hon Wai Leong and David Wheeler", "title": "BOSS-LDG: A Novel Computational Framework that Brings Together Blue\n  Waters, Open Science Grid, Shifter and the LIGO Data Grid to Accelerate\n  Gravitational Wave Discovery", "comments": "10 pages, 10 figures. Accepted as a Full Research Paper to the 13th\n  IEEE International Conference on eScience", "journal-ref": "2017 IEEE 13th International Conference on e-Science", "doi": "10.1109/eScience.2017.47", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel computational framework that connects Blue Waters, the\nNSF-supported, leadership-class supercomputer operated by NCSA, to the Laser\nInterferometer Gravitational-Wave Observatory (LIGO) Data Grid via Open Science\nGrid technology. To enable this computational infrastructure, we configured,\nfor the first time, a LIGO Data Grid Tier-1 Center that can submit\nheterogeneous LIGO workflows using Open Science Grid facilities. In order to\nenable a seamless connection between the LIGO Data Grid and Blue Waters via\nOpen Science Grid, we utilize Shifter to containerize LIGO's workflow software.\nThis work represents the first time Open Science Grid, Shifter, and Blue Waters\nare unified to tackle a scientific problem and, in particular, it is the first\ntime a framework of this nature is used in the context of large scale\ngravitational wave data analysis. This new framework has been used in the last\nseveral weeks of LIGO's second discovery campaign to run the most\ncomputationally demanding gravitational wave search workflows on Blue Waters,\nand accelerate discovery in the emergent field of gravitational wave\nastrophysics. We discuss the implications of this novel framework for a wider\necosystem of Higher Performance Computing users.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 00:49:21 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Huerta", "E. A.", ""], ["Haas", "Roland", ""], ["Fajardo", "Edgar", ""], ["Katz", "Daniel S.", ""], ["Anderson", "Stuart", ""], ["Couvares", "Peter", ""], ["Willis", "Josh", ""], ["Bouvet", "Timothy", ""], ["Enos", "Jeremy", ""], ["Kramer", "William T. C.", ""], ["Leong", "Hon Wai", ""], ["Wheeler", "David", ""]]}, {"id": "1709.08800", "submitter": "Giovanni Viglietta", "authors": "Giuseppe A. Di Luna, Paola Flocchini, Nicola Santoro, and Giovanni\n  Viglietta", "title": "TuringMobile: A Turing Machine of Oblivious Mobile Robots with Limited\n  Visibility and its Applications", "comments": "27 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the computational power of a set of mobile\nrobots with limited visibility. At each iteration, a robot takes a snapshot of\nits surroundings, uses the snapshot to compute a destination point, and it\nmoves toward its destination. Each robot is punctiform and memoryless, it\noperates in $\\mathbb{R}^m$, it has a local reference system independent of the\nother robots' ones, and is activated asynchronously by an adversarial\nscheduler. Moreover, robots are non-rigid, in that they may be stopped by the\nscheduler at each move before reaching their destination (but are guaranteed to\ntravel at least a fixed unknown distance before being stopped).\n  We show that despite these strong limitations, it is possible to arrange\n$3m+3k$ of these weak entities in $\\mathbb{R}^m$ to simulate the behavior of a\nstronger robot that is rigid (i.e., it always reaches its destination) and is\nendowed with $k$ registers of persistent memory, each of which can store a real\nnumber. We call this arrangement a TuringMobile. In its simplest form, a\nTuringMobile consisting of only three robots can travel in the plane and store\nand update a single real number. We also prove that this task is impossible\nwith fewer than three robots.\n  Among the applications of the TuringMobile, we focused on Near-Gathering (all\nrobots have to gather in a small-enough disk) and Pattern Formation (of which\nGathering is a special case) with limited visibility. Interestingly, our\ninvestigation implies that both problems are solvable in Euclidean spaces of\nany dimension, even if the visibility graph of the robots is initially\ndisconnected, provided that a small amount of these robots are arranged to form\na TuringMobile. In the special case of the plane, a basic TuringMobile of only\nthree robots is sufficient.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 03:33:44 GMT"}, {"version": "v2", "created": "Mon, 6 Aug 2018 07:08:15 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Di Luna", "Giuseppe A.", ""], ["Flocchini", "Paola", ""], ["Santoro", "Nicola", ""], ["Viglietta", "Giovanni", ""]]}, {"id": "1709.08902", "submitter": "Jialong Shi", "authors": "Jialong Shi, Qingfu Zhang", "title": "A New Cooperative Framework for Parallel Trajectory-Based Metaheuristics", "comments": null, "journal-ref": "Applied Soft Computing 65 (2018) 374-386", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the Parallel Elite Biased framework (PEB framework)\nfor parallel trajectory-based metaheuristics. In the PEB framework, multiple\nsearch processes are executed concurrently. During the search, each process\nsends its best found solutions to its neighboring processes and uses the\nreceived solutions to guide its search. Using the PEB framework, we design a\nparallel variant of Guided Local Search (GLS) called PEBGLS. Extensive\nexperiments have been conducted on the Tianhe-2 supercomputer to study the\nperformance of PEBGLS on the Traveling Salesman Problem (TSP). The experimental\nresults show that PEBGLS is a competitive parallel metaheuristic for the TSP,\nwhich confirms that the PEB framework is useful for designing parallel\ntrajectory-based metaheuristics.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 09:14:33 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 14:24:09 GMT"}, {"version": "v3", "created": "Mon, 19 Mar 2018 09:45:58 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Shi", "Jialong", ""], ["Zhang", "Qingfu", ""]]}, {"id": "1709.08909", "submitter": "Xiaohu Wu", "authors": "Xiaohu Wu, and Francesco De Pellegrini", "title": "Performance Analysis of QoS-Differentiated Pricing in Cloud Computing:\n  An Analytical Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental goal in the design of IaaS service is to enable both\nuser-friendly and cost-effective service access, while attaining high resource\nefficiency for revenue maximization. QoS differentiation is an important lens\nto achieve this design goal. In this paper, we propose the first analytical\nQoS-differentiated resource management and pricing architecture in the cloud\ncomputing context; here, a cloud service provider (CSP) offers a portfolio of\nSLAs. In order to maximize the CSP's revenue, we address two technical\nquestions: (1) how to set the SLA prices so as to direct users to the SLAs best\nfitting their needs, and, (2) determining how many servers should be assigned\nto each SLA, and which users and how many of their jobs are admitted to be\nserved. We propose optimal schemes to jointly determine SLA-based prices and\nperform capacity planning in polynomial time. Our pricing model retains high\nusability at the customer's end. Compared with standard usage-based pricing\nschemes, numerical results show that the proposed scheme can improve the\nrevenue by up to a five-fold increase.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 09:42:32 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 15:04:51 GMT"}, {"version": "v3", "created": "Sat, 24 Mar 2018 16:11:43 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Wu", "Xiaohu", ""], ["De Pellegrini", "Francesco", ""]]}, {"id": "1709.08920", "submitter": "Fabrizio Carcillo", "authors": "Fabrizio Carcillo, Andrea Dal Pozzolo, Yann-A\\\"el Le Borgne, Olivier\n  Caelen, Yannis Mazzer, Gianluca Bontempi", "title": "SCARFF: a Scalable Framework for Streaming Credit Card Fraud Detection\n  with Spark", "comments": null, "journal-ref": "Information Fusion 41C (2018) pp. 182-194", "doi": "10.1016/j.inffus.2017.09.005", "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The expansion of the electronic commerce, together with an increasing\nconfidence of customers in electronic payments, makes of fraud detection a\ncritical factor. Detecting frauds in (nearly) real time setting demands the\ndesign and the implementation of scalable learning techniques able to ingest\nand analyse massive amounts of streaming data. Recent advances in analytics and\nthe availability of open source solutions for Big Data storage and processing\nopen new perspectives to the fraud detection field. In this paper we present a\nSCAlable Real-time Fraud Finder (SCARFF) which integrates Big Data tools\n(Kafka, Spark and Cassandra) with a machine learning approach which deals with\nimbalance, nonstationarity and feedback latency. Experimental results on a\nmassive dataset of real credit card transactions show that this framework is\nscalable, efficient and accurate over a big stream of transactions.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 10:07:22 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Carcillo", "Fabrizio", ""], ["Pozzolo", "Andrea Dal", ""], ["Borgne", "Yann-A\u00ebl Le", ""], ["Caelen", "Olivier", ""], ["Mazzer", "Yannis", ""], ["Bontempi", "Gianluca", ""]]}, {"id": "1709.09099", "submitter": "Chiwan Park", "authors": "Chiwan Park, Ha-Myung Park, Minji Yoon, U Kang", "title": "PMV: Pre-partitioned Generalized Matrix-Vector Multiplication for\n  Scalable Graph Mining", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we analyze enormous networks including the Web and social networks\nwhich have hundreds of billions of nodes and edges? Network analyses have been\nconducted by various graph mining methods including shortest path computation,\nPageRank, connected component computation, random walk with restart, etc. These\ngraph mining methods can be expressed as generalized matrix-vector\nmultiplication which consists of few operations inspired by typical\nmatrix-vector multiplication. Recently, several graph processing systems based\non matrix-vector multiplication or their own primitives have been proposed to\ndeal with large graphs; however, they all have failed on Web-scale graphs due\nto insufficient memory space or the lack of consideration for I/O costs. In\nthis paper, we propose PMV (Pre-partitioned generalized Matrix-Vector\nmultiplication), a scalable distributed graph mining method based on\ngeneralized matrix-vector multiplication on distributed systems. PMV\nsignificantly decreases the communication cost, which is the main bottleneck of\ndistributed systems, by partitioning the input graph in advance and judiciously\napplying execution strategies based on the density of the pre-partitioned\nsub-matrices. Experiments show that PMV succeeds in processing up to 16x larger\ngraphs than existing distributed memory-based graph mining methods, and\nrequires 9x less time than previous disk-based graph mining methods by reducing\nI/O costs significantly.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 15:53:15 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Park", "Chiwan", ""], ["Park", "Ha-Myung", ""], ["Yoon", "Minji", ""], ["Kang", "U", ""]]}, {"id": "1709.09393", "submitter": "Shizhao Sun", "authors": "Shizhao Sun, Wei Chen, Jiang Bian, Xiaoguang Liu, Tie-Yan Liu", "title": "Slim-DP: A Light Communication Data Parallelism for DNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data parallelism has emerged as a necessary technique to accelerate the\ntraining of deep neural networks (DNN). In a typical data parallelism approach,\nthe local workers push the latest updates of all the parameters to the\nparameter server and pull all merged parameters back periodically. However,\nwith the increasing size of DNN models and the large number of workers in\npractice, this typical data parallelism cannot achieve satisfactory training\nacceleration, since it usually suffers from the heavy communication cost due to\ntransferring huge amount of information between workers and the parameter\nserver. In-depth understanding on DNN has revealed that it is usually highly\nredundant, that deleting a considerable proportion of the parameters will not\nsignificantly decline the model performance. This redundancy property exposes a\ngreat opportunity to reduce the communication cost by only transferring the\ninformation of those significant parameters during the parallel training.\nHowever, if we only transfer information of temporally significant parameters\nof the latest snapshot, we may miss the parameters that are insignificant now\nbut have potential to become significant as the training process goes on. To\nthis end, we design an Explore-Exploit framework to dynamically choose the\nsubset to be communicated, which is comprised of the significant parameters in\nthe latest snapshot together with a random explored set of other parameters. We\npropose to measure the significance of the parameter by the combination of its\nmagnitude and gradient. Our experimental results demonstrate that our proposed\nSlim-DP can achieve better training acceleration than standard data parallelism\nand its communication-efficient version by saving communication time without\nloss of accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 08:58:40 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Sun", "Shizhao", ""], ["Chen", "Wei", ""], ["Bian", "Jiang", ""], ["Liu", "Xiaoguang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1709.09491", "submitter": "Vignesh Balaji", "authors": "Vignesh Balaji, Dhruva Tirumala, Brandon Lucia", "title": "Flexible Support for Fast Parallel Commutative Updates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privatizing data is a useful strategy for increasing parallelism in a shared\nmemory multithreaded program. Independent cores can compute independently on\nduplicates of shared data, combining their results at the end of their\ncomputations. Conventional approaches to privatization, however, rely on\nexplicit static or dynamic memory allocation for duplicated state, increasing\nmemory footprint and contention for cache resources, especially in shared\ncaches. In this work, we describe CCache, a system for on-demand privatization\nof data manipulated by commutative operations. CCache garners the benefits of\nprivatization, without the increase in memory footprint or cache occupancy.\nEach core in CCache dynamically privatizes commutatively manipulated data,\noperating on a copy. Periodically or at the end of its computation, the core\nmerges its value with the value resident in memory, and when all cores have\nmerged, the in-memory copy contains the up-to-date value. We describe a\nlow-complexity architectural implementation of CCache that extends a\nconventional multicore to support on-demand privatization without using\nadditional memory for private copies. We evaluate CCache on several high-value\napplications, including random access key-value store, clustering, breadth\nfirst search and graph ranking, showing speedups upto 3.2X.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 15:29:57 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Balaji", "Vignesh", ""], ["Tirumala", "Dhruva", ""], ["Lucia", "Brandon", ""]]}, {"id": "1709.09575", "submitter": "Michael Wehner", "authors": "Eli Dart, Michael F. Wehner, Prabhat", "title": "An Assessment of Data Transfer Performance for Large-Scale Climate Data\n  Analysis and Recommendations for the Data Infrastructure for CMIP6", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We document the data transfer workflow, data transfer performance, and other\naspects of staging approximately 56 terabytes of climate model output data from\nthe distributed Coupled Model Intercomparison Project (CMIP5) archive to the\nNational Energy Research Supercomputing Center (NERSC) at the Lawrence Berkeley\nNational Laboratory required for tracking and characterizing extratropical\nstorms, a phenomena of importance in the mid-latitudes. We present this\nanalysis to illustrate the current challenges in assembling multi-model data\nsets at major computing facilities for large-scale studies of CMIP5 data.\nBecause of the larger archive size of the upcoming CMIP6 phase of model\nintercomparison, we expect such data transfers to become of increasing\nimportance, and perhaps of routine necessity. We find that data transfer rates\nusing the ESGF are often slower than what is typically available to US\nresidences and that there is significant room for improvement in the data\ntransfer capabilities of the ESGF portal and data centers both in terms of\nworkflow mechanics and in data transfer performance. We believe performance\nimprovements of at least an order of magnitude are within technical reach using\ncurrent best practices, as illustrated by the performance we achieved in\ntransferring the complete raw data set between two high performance computing\nfacilities. To achieve these performance improvements, we recommend: that\ncurrent best practices (such as the Science DMZ model) be applied to the data\nservers and networks at ESGF data centers; that sufficient financial and human\nresources be devoted at the ESGF data centers for systems and network\nengineering tasks to support high performance data movement; and that\nperformance metrics for data transfer between ESGF data centers and major\ncomputing facilities used for climate data analysis be established, regularly\ntested, and published.\n", "versions": [{"version": "v1", "created": "Sat, 26 Aug 2017 03:31:29 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Dart", "Eli", ""], ["Wehner", "Michael F.", ""], ["Prabhat", "", ""]]}, {"id": "1709.09597", "submitter": "Abhishek Dubey", "authors": "Karla Kvaternik and Aron Laszka and Michael Walker and Douglas Schmidt\n  and Monika Sturm and Martin lehofer and Abhishek Dubey", "title": "Privacy-Preserving Platform for Transactive Energy Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transactive energy systems (TES) are emerging as a transformative solution\nfor the problems faced by distribution system operators due to an increase in\nthe use of distributed energy resources and a rapid acceleration in renewable\nenergy generation. These, on one hand, pose a decentralized power system\ncontrols problem, requiring strategic microgrid control to maintain stability\nfor the community and for the utility. On the other hand, they require robust\nfinancial markets operating on distributed software platforms that preserve\nprivacy. In this paper, we describe the implementation of a novel,\nblockchain-based transactive energy system. We outline the key requirements and\nmotivation of this platform, describe the lessons learned, and provide a\ndescription of key architectural components of this system.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 16:01:16 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 23:26:19 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Kvaternik", "Karla", ""], ["Laszka", "Aron", ""], ["Walker", "Michael", ""], ["Schmidt", "Douglas", ""], ["Sturm", "Monika", ""], ["lehofer", "Martin", ""], ["Dubey", "Abhishek", ""]]}, {"id": "1709.09601", "submitter": "Abhishek Dubey", "authors": "Jonatan Bergquist and Aron Laszka and Monika Sturm and Abhishek Dubey", "title": "On the Design of Communication and Transaction Anonymity in\n  Blockchain-Based Transactive Microgrids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transactive microgrids are emerging as a transformative solution for the\nproblems faced by distribution system operators due to an increase in the use\nof distributed energy resources and a rapid acceleration in renewable energy\ngeneration, such as wind and solar power. Distributed ledgers have recently\nfound widespread interest in this domain due to their ability to provide\ntransactional integrity across decentralized computing nodes. However, the\nexisting state of the art has not focused on the privacy preservation\nrequirement of these energy systems -- the transaction level data can provide\nmuch greater insights into a prosumer's behavior compared to smart meter data.\nThere are specific safety requirements in transactive microgrids to ensure the\nstability of the grid and to control the load. To fulfil these requirements,\nthe distribution system operator needs transaction information from the grid,\nwhich poses a further challenge to the privacy-goals. This problem is made\nworse by requirement for off-blockchain communication in these networks. In\nthis paper, we extend a recently developed trading workflow called PETra and\ndescribe our solution for communication and transactional anonymity.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 16:12:57 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 23:27:12 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Bergquist", "Jonatan", ""], ["Laszka", "Aron", ""], ["Sturm", "Monika", ""], ["Dubey", "Abhishek", ""]]}, {"id": "1709.09612", "submitter": "Abhishek Dubey", "authors": "Michael A. Walker, Abhishek Dubey, Aron Laszka, and Douglas C. Schmidt", "title": "PlaTIBART: a Platform for Transactive IoT Blockchain Applications with\n  Repeatable Testing", "comments": "Workshop on Middleware and Applications for the Internet of Things\n  (M4IoT) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of blockchain-enabled IoT applications, there is an increased\nneed for related software patterns, middleware concepts, and testing practices\nto ensure adequate quality and productivity. IoT and blockchain each provide\ndifferent design goals, concepts, and practices that must be integrated,\nincluding the distributed actor model and fault tolerance from IoT and\ntransactive information integrity over untrustworthy sources from blockchain.\nBoth IoT and blockchain are emerging technologies and both lack codified\npatterns and practices for development of applications when combined. This\npaper describes PlaTIBART, which is a platform for transactive IoT blockchain\napplications with repeatable testing that combines the Actor pattern (which is\na commonly used model of computation in IoT) together with a custom Domain\nSpecific Language (DSL) and test network management tools. We show how\nPlaTIBART has been applied to develop, test, and analyze fault-tolerant IoT\nblockchain applications.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 16:38:03 GMT"}, {"version": "v2", "created": "Sat, 30 Sep 2017 01:44:46 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Walker", "Michael A.", ""], ["Dubey", "Abhishek", ""], ["Laszka", "Aron", ""], ["Schmidt", "Douglas C.", ""]]}, {"id": "1709.09614", "submitter": "Abhishek Dubey", "authors": "Aron Laszka, Abhishek Dubey, Michael Walker and Douglas Schmidt", "title": "Providing Privacy, Safety, and Security in IoT-Based Transactive Energy\n  Systems using Distributed Ledgers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power grids are undergoing major changes due to rapid growth in renewable\nenergy resources and improvements in battery technology. While these changes\nenhance sustainability and efficiency, they also create significant management\nchallenges as the complexity of power systems increases. To tackle these\nchallenges, decentralized Internet-of-Things (IoT) solutions are emerging,\nwhich arrange local communities into transactive microgrids. Within a\ntransactive microgrid, \"prosumers\" (i.e., consumers with energy generation and\nstorage capabilities) can trade energy with each other, thereby smoothing the\nload on the main grid using local supply. It is hard, however, to provide\nsecurity, safety, and privacy in a decentralized and transactive energy system.\nOn the one hand, prosumers' personal information must be protected from their\ntrade partners and the system operator. On the other hand, the system must be\nprotected from careless or malicious trading, which could destabilize the\nentire grid. This paper describes Privacy-preserving Energy Transactions\n(PETra), which is a secure and safe solution for transactive microgrids that\nenables consumers to trade energy without sacrificing their privacy. PETra\nbuilds on distributed ledgers, such as blockchains, and provides anonymity for\ncommunication, bidding, and trading.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 16:42:08 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Laszka", "Aron", ""], ["Dubey", "Abhishek", ""], ["Walker", "Michael", ""], ["Schmidt", "Douglas", ""]]}, {"id": "1709.09785", "submitter": "Jialong Shi", "authors": "Jialong Shi, Qingfu Zhang, Jianyong Sun", "title": "PPLS/D: Parallel Pareto Local Search based on Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pareto Local Search (PLS) is a basic building block in many metaheuristics\nfor Multiobjective Combinatorial Optimization Problem (MCOP). In this paper, an\nenhanced PLS variant called Parallel Pareto Local Search based on Decomposition\n(PPLS/D) is proposed. PPLS/D improves the efficiency of PLS using the\ntechniques of parallel computation and problem decomposition. It decomposes the\noriginal search space into L subregions and executes L parallel processes\nsearching in these subregions simultaneously. Inside each subregion, the PPLS/D\nprocess is guided by a unique scalar objective function. PPLS/D differs from\nthe well-known Two Phase Pareto Local Search (2PPLS) in that it uses the scalar\nobjective function to guide every move of the PLS procedure in a fine-grained\nmanner. In the experimental studies, PPLS/D is compared against the basic PLS\nand a recently proposed PLS variant on the multiobjective Unconstrained Binary\nQuadratic Programming problems (mUBQPs) and the multiobjective Traveling\nSalesman Problems (mTSPs) with at most four objectives. The experimental\nresults show that, no matter whether the initial solutions are randomly\ngenerated or generated by heuristic methods, PPLS/D always performs\nsignificantly better than the other two PLS variants.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 02:26:58 GMT"}, {"version": "v2", "created": "Sat, 10 Mar 2018 14:52:12 GMT"}, {"version": "v3", "created": "Tue, 27 Mar 2018 08:41:03 GMT"}, {"version": "v4", "created": "Fri, 9 Nov 2018 01:29:51 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Shi", "Jialong", ""], ["Zhang", "Qingfu", ""], ["Sun", "Jianyong", ""]]}, {"id": "1709.09990", "submitter": "Tom C. van der Zanden", "authors": "Tom C. van der Zanden and Hans L. Bodlaender", "title": "Computing Treewidth on the GPU", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a parallel algorithm for computing the treewidth of a graph on a\nGPU. We implement this algorithm in OpenCL, and experimentally evaluate its\nperformance. Our algorithm is based on an $O^*(2^{n})$-time algorithm that\nexplores the elimination orderings of the graph using a Held-Karp like dynamic\nprogramming approach. We use Bloom filters to detect duplicate solutions.\n  GPU programming presents unique challenges and constraints, such as\nconstraints on the use of memory and the need to limit branch divergence. We\nexperiment with various optimizations to see if it is possible to work around\nthese issues. We achieve a very large speed up (up to $77\\times$) compared to\nrunning the same algorithm on the CPU.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 14:34:55 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["van der Zanden", "Tom C.", ""], ["Bodlaender", "Hans L.", ""]]}, {"id": "1709.10119", "submitter": "Chen Feng", "authors": "Chunpu Wang, Chen Feng and Julian Cheng", "title": "Distributed Join-the-Idle-Queue for Low Latency Cloud Services", "comments": "10 pages, 10 figures. This work is inspired by Michael Mitzenmacher's\n  recent work on distributed Join-Idle-Queue (arXiv:1606.01833) as well as\n  Alexander Stolyar's recent work on centralized Join-Idle-Queue\n  (arXiv:1512.07873 and arXiv:1407.6343)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low latency is highly desirable for cloud services. To achieve low response\ntime, stringent timing requirements are needed for task scheduling in a\nlarge-scale server farm spanning thousands of servers. In this paper, we\nconduct an in-depth analysis for distributed Join-the-Idle-Queue (JIQ), a\npromising new approximation of an idealized task-scheduling algorithm. In\nparticular, we derive semi-closed form expressions for the delay performance of\ndistributed JIQ, and we propose a new variant of distributed JIQ that offers\nclear advantages over alternative algorithms for large systems.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 18:15:58 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Wang", "Chunpu", ""], ["Feng", "Chen", ""], ["Cheng", "Julian", ""]]}, {"id": "1709.10140", "submitter": "Carlos Eduardo Arango Gutierrez", "authors": "Carlos Arango, R\\'emy Dernat, John Sanabria", "title": "Performance Evaluation of Container-based Virtualization for High\n  Performance Computing Environments", "comments": "Keywords: Container-based virtualization; Linux containers;\n  Singularity-Containers; Docker; High performance computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.DC cs.PF", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Virtualization technologies have evolved along with the development of\ncomputational environments since virtualization offered needed features at that\ntime such as isolation, accountability, resource allocation, resource fair\nsharing and so on. Novel processor technologies bring to commodity computers\nthe possibility to emulate diverse environments where a wide range of\ncomputational scenarios can be run. Along with processors evolution, system\ndevelopers have created different virtualization mechanisms where each new\ndevelopment enhanced the performance of previous virtualized environments.\nRecently, operating system-based virtualization technologies captured the\nattention of communities abroad (from industry to academy and research) because\ntheir important improvements on performance area.\n  In this paper, the features of three container-based operating systems\nvirtualization tools (LXC, Docker and Singularity) are presented. LXC, Docker,\nSingularity and bare metal are put under test through a customized single node\nHPL-Benchmark and a MPI-based application for the multi node testbed. Also the\ndisk I/O performance, Memory (RAM) performance, Network bandwidth and GPU\nperformance are tested for the COS technologies vs bare metal. Preliminary\nresults and conclusions around them are presented and discussed.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 19:30:05 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Arango", "Carlos", ""], ["Dernat", "R\u00e9my", ""], ["Sanabria", "John", ""]]}, {"id": "1709.10146", "submitter": "Dariusz Dereniowski", "authors": "Shantanu Das, Dariusz Dereniowski and Przemys{\\l}aw Uzna\\'nski", "title": "Energy Constrained Depth First Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.DM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Depth first search is a natural algorithmic technique for constructing a\nclosed route that visits all vertices of a graph. The length of such route\nequals, in an edge-weighted tree, twice the total weight of all edges of the\ntree and this is asymptotically optimal over all exploration strategies. This\npaper considers a variant of such search strategies where the length of each\nroute is bounded by a positive integer $B$ (e.g. due to limited energy\nresources of the searcher). The objective is to cover all the edges of a tree\n$T$ using the minimum number of routes, each starting and ending at the root\nand each being of length at most $B$. To this end, we analyze the following\nnatural greedy tree traversal process that is based on decomposing a depth\nfirst search traversal into a sequence of limited length routes. Given any\narbitrary depth first search traversal $R$ of the tree $T$, we cover $R$ with\nroutes $R_1,\\ldots,R_l$, each of length at most $B$ such that: $R_i$ starts at\nthe root, reaches directly the farthest point of $R$ visited by $R_{i-1}$, then\n$R_i$ continues along the path $R$ as far as possible, and finally $R_i$\nreturns to the root. We call the above algorithm \\emph{piecemeal-DFS} and we\nprove that it achieves the asymptotically minimal number of routes $l$,\nregardless of the choice of $R$. Our analysis also shows that the total length\nof the traversal (and thus the traversal time) of piecemeal-DFS is\nasymptotically minimum over all energy-constrained exploration strategies. The\nfact that $R$ can be chosen arbitrarily means that the exploration strategy can\nbe constructed in an online fashion when the input tree $T$ is not known in\nadvance. Surprisingly, our results show that depth first search is efficient\nfor energy constrained exploration of trees, even though it is known that the\nsame does not hold for energy constrained exploration of arbitrary graphs.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 19:50:10 GMT"}, {"version": "v2", "created": "Sat, 17 Feb 2018 13:46:58 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Das", "Shantanu", ""], ["Dereniowski", "Dariusz", ""], ["Uzna\u0144ski", "Przemys\u0142aw", ""]]}, {"id": "1709.10154", "submitter": "Jingqiu Zhou", "authors": "Jingqiu Zhou, Wang Xuan, Shaoshuai Mou, and Brian. D. O. Anderson", "title": "Finite-Time Distributed Linear Equation Solver for Minimum $l_1$ Norm\n  Solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes distributed algorithms for multi-agent networks to\nachieve a solution in finite time to a linear equation $Ax=b$ where $A$ has\nfull row rank, and with the minimum $l_1$-norm in the underdetermined case\n(where $A$ has more columns than rows). The underlying network is assumed to be\nundirected and fixed, and an analytical proof is provided for the proposed\nalgorithm to drive all agents' individual states to converge to a common value,\nviz a solution of $Ax=b$, which is the minimum $l_1$-norm solution in the\nunderdetermined case. Numerical simulations are also provided as validation of\nthe proposed algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 20:11:50 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Zhou", "Jingqiu", ""], ["Xuan", "Wang", ""], ["Mou", "Shaoshuai", ""], ["Anderson", "Brian. D. O.", ""]]}, {"id": "1709.10157", "submitter": "Xuan Wang", "authors": "Xuan Wang, Jingqiu Zhou, Shaoshuai Mou and Martin J. Corless", "title": "A Distributed Algorithm for Least Square Solutions of Linear Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A distributed discrete-time algorithm is proposed for multi-agent networks to\nachieve a common least squares solution of a group of linear equations, in\nwhich each agent only knows some of the equations and is only able to receive\ninformation from its nearby neighbors. For fixed, connected, and undirected\nnetworks, the proposed discrete-time algorithm results in each agents solution\nestimate to converging exponentially fast to the same least squares solution.\nMoreover, the convergence does not require careful choices of time-varying\nsmall step sizes.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 20:20:13 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Wang", "Xuan", ""], ["Zhou", "Jingqiu", ""], ["Mou", "Shaoshuai", ""], ["Corless", "Martin J.", ""]]}, {"id": "1709.10372", "submitter": "Abdellah Idrissi", "authors": "Abdellah Idrissi and Faouzia Zegrari", "title": "A New Approach for a Better Load Balancing and a Better Distribution of\n  Resources in Cloud Computing", "comments": null, "journal-ref": "(IJACSA) International Journal of Advanced Computer Science and\n  Applications, Vol. 6, No. 10, 2015", "doi": "10.14569/IJACSA.2015.061036", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is a new paradigm where data and services of Information\nTechnology are provided via the Internet by using remote servers. It represents\na new way of delivering computing resources allowing access to the network on\ndemand. Cloud computing consists of several services, each of which can hold\nseveral tasks. As the problem of scheduling tasks is an NP-complete problem,\nthe task management can be an important element in the technology of cloud\ncomputing. To optimize the performance of virtual machines hosted in cloud\ncomputing, several algorithms of scheduling tasks have been proposed. In this\npaper, we present an approach allowing to solve the problem optimally and to\ntake into account the QoS constraints based on the different user requests.\nThis technique, based on the Branch and Bound algorithm, allows to assign tasks\nto different virtual machines while ensuring load balance and a better\ndistribution of resources. The experimental results show that our approach\ngives very promising results for an effective tasks planning. - See more at:\nhttp://thesai.org/Publications/ViewPaper?Volume=6&Issue=10&Code=IJACSA&SerialNo=36#sthash.aV1fxMaQ.dpuf\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2015 20:50:19 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Idrissi", "Abdellah", ""], ["Zegrari", "Faouzia", ""]]}]