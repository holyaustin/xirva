[{"id": "1407.0120", "submitter": "Daniel Schall", "authors": "Daniel Schall and Theo H\\\"arder", "title": "Dynamic Physiological Partitioning on a Shared-nothing Database Cluster", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional DBMS servers are usually over-provisioned for most of their daily\nworkloads and, because they do not show good-enough energy proportionality,\nwaste a lot of energy while underutilized. A cluster of small (wimpy) servers,\nwhere its size can be dynamically adjusted to the current workload, offers\nbetter energy characteristics for these workloads. Yet, data migration,\nnecessary to balance utilization among the nodes, is a non-trivial and\ntime-consuming task that may consume the energy saved. For this reason, a\nsophisticated and easy to adjust partitioning scheme fostering dynamic\nreorganization is needed. In this paper, we adapt a technique originally\ncreated for SMP systems, called physiological partitioning, to distribute data\namong nodes, that allows to easily repartition data without interrupting\ntransactions. We dynamically partition DB tables based on the nodes'\nutilization and given energy constraints and compare our approach with physical\npartitioning and logical partitioning methods. To quantify possible energy\nsaving and its conceivable drawback on query runtimes, we evaluate our\nimplementation on an experimental cluster and compare the results w.r.t.\nperformance and energy consumption. Depending on the workload, we can\nsubstantially save energy without sacrificing too much performance.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jul 2014 07:18:43 GMT"}, {"version": "v2", "created": "Wed, 2 Jul 2014 07:18:59 GMT"}], "update_date": "2014-07-03", "authors_parsed": [["Schall", "Daniel", ""], ["H\u00e4rder", "Theo", ""]]}, {"id": "1407.0122", "submitter": "Kazi Sakib", "authors": "Kazi Sakib, M. S. Hasan and M. A. Hossain", "title": "Effects of Hard Real-Time Constraints in Implementing the Myopic\n  Scheduling Algorithm", "comments": "9 pages, Journal of Computer Science (JCS), Bangladesh, Vol. 1, No.\n  2, December, 2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Myopic is a hard real-time process scheduling algorithm that selects a\nsuitable process based on a heuristic function from a subset (Window)of all\nready processes instead of choosing from all available processes, like original\nheuristic scheduling algorithm. Performance of the algorithm significantly\ndepends on the chosen heuristic function that assigns weight to different\nparameters like deadline, earliest starting time, processing time etc. and the\nsizeof the Window since it considers only k processes from n processes (where,\nk<= n). This research evaluates the performance of the Myopic algorithm for\ndifferent parameters to demonstrate the merits and constraints of the\nalgorithm. A comparative performance of the impact of window size in\nimplementing the Myopic algorithm is presented and discussed through a set of\nexperiments.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jul 2014 07:23:10 GMT"}], "update_date": "2014-07-02", "authors_parsed": [["Sakib", "Kazi", ""], ["Hasan", "M. S.", ""], ["Hossain", "M. A.", ""]]}, {"id": "1407.0375", "submitter": "Charalampos Tsourakakis", "authors": "Charalampos E. Tsourakakis", "title": "Mathematical and Algorithmic Analysis of Network and Biological Data", "comments": "Doctorial thesis, 306 pages, Carnegie Mellon University 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.DM cs.SI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This dissertation contributes to mathematical and algorithmic problems that\narise in the analysis of network and biological data.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jun 2014 02:06:51 GMT"}], "update_date": "2014-07-02", "authors_parsed": [["Tsourakakis", "Charalampos E.", ""]]}, {"id": "1407.0386", "submitter": "Daniel Schall", "authors": "Daniel Schall and Theo H\\\"arder", "title": "Energy and Performance-Can a Wimpy-Node Cluster Challenge a Brawny\n  Server?", "comments": "arXiv admin note: substantial text overlap with arXiv:1407.0120", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional DBMS servers are usually over-provisioned for most of their daily\nworkloads and, because they do not show good energy proportionality, waste a\nlot of energy while underutilized. A cluster of small (wimpy) servers, where\nthe number of nodes can dynamically adjust to the current workload, might offer\nbetter energy characteristics for these workloads. Yet, clusters suffer from\n\"friction losses\" and may not be able to quickly adapt to the workload, whereas\na single, brawny server delivers performance instantaneously. In this paper, we\ncompare a small cluster of lightweight nodes to a single server in terms of\nperformance and energy efficiency. We run several benchmarks, consisting of\nOLTP and OLAP queries at variable utilization to test the system's ability to\nadjust to the workloads. To quantify possible energy saving and its conceivable\ndrawback on query runtime, we evaluate our implementation on a cluster as well\nas on a single, brawny server and compare the results w.r.t. performance and\nenergy consumption. Our findings confirm that - based on the workload - energy\ncan be saved without sacrificing too much performance.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jul 2014 07:29:37 GMT"}, {"version": "v2", "created": "Mon, 7 Jul 2014 07:32:53 GMT"}], "update_date": "2014-07-08", "authors_parsed": [["Schall", "Daniel", ""], ["H\u00e4rder", "Theo", ""]]}, {"id": "1407.0442", "submitter": "Kishori Konwar", "authors": "Seda Davtyan and Kishori M. Konwar and Alexander Russell and Alexander\n  A. Shvartsman", "title": "Technical Report: Dealing with Undependable Workers in Decentralized\n  Network Supercomputing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet supercomputing is an approach to solving partitionable,\ncomputation-intensive problems by harnessing the power of a vast number of\ninterconnected computers. This paper presents a new algorithm for the problem\nof using network supercomputing to perform a large collection of independent\ntasks, while dealing with undependable processors. The adversary may cause the\nprocessors to return bogus results for tasks with certain probabilities, and\nmay cause a subset $F$ of the initial set of processors $P$ to crash. The\nadversary is constrained in two ways. First, for the set of non-crashed\nprocessors $P-F$, the \\emph{average} probability of a processor returning a\nbogus result is inferior to $\\frac{1}{2}$. Second, the adversary may crash a\nsubset of processors $F$, provided the size of $P-F$ is bounded from below. We\nconsider two models: the first bounds the size of $P-F$ by a fractional\npolynomial, the second bounds this size by a poly-logarithm. Both models yield\nadversaries that are much stronger than previously studied. Our randomized\nsynchronous algorithm is formulated for $n$ processors and $t$ tasks, with\n$n\\le t$, where depending on the number of crashes each live processor is able\nto terminate dynamically with the knowledge that the problem is solved with\nhigh probability. For the adversary constrained by a fractional polynomial, the\nround complexity of the algorithm is\n$O(\\frac{t}{n^\\varepsilon}\\log{n}\\log{\\log{n}})$, its work is $O(t\\log{n}\n\\log{\\log{n}})$ and message complexity is $O(n\\log{n}\\log{\\log{n}})$. For the\npoly-log constrained adversary, the round complexity is $O(t)$, work is $O(t\nn^{\\varepsilon})$, %$O(t \\, poly \\log{n})$, and message complexity is\n$O(n^{1+\\varepsilon})$ %$O(n \\, poly \\log{n})$. All bounds are shown to hold\nwith high probability.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jul 2014 02:29:12 GMT"}], "update_date": "2014-07-03", "authors_parsed": [["Davtyan", "Seda", ""], ["Konwar", "Kishori M.", ""], ["Russell", "Alexander", ""], ["Shvartsman", "Alexander A.", ""]]}, {"id": "1407.0696", "submitter": "Kishori Konwar", "authors": "Seda Davtyan and Kishori M. Konwar and Alexander A. Shvartsman", "title": "Technical Report: Estimating Reliability of Workers for Cooperative\n  Distributed Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet supercomputing is an approach to solving partitionable,\ncomputation-intensive problems by harnessing the power of a vast number of\ninterconnected computers. For the problem of using network supercomputing to\nperform a large collection of independent tasks, prior work introduced a\ndecentralized approach and provided randomized synchronous algorithms that\nperform all tasks correctly with high probability, while dealing with\nmisbehaving or crash-prone processors. The main weaknesses of existing\nalgorithms is that they assume either that the \\emph{average} probability of a\nnon-crashed processor returning incorrect results is inferior to $\\frac{1}{2}$,\nor that the probability of returning incorrect results is known to \\emph{each}\nprocessor. Here we present a randomized synchronous distributed algorithm that\ntightly estimates the probability of each processor returning correct results.\nStarting with the set $P$ of $n$ processors, let $F$ be the set of processors\nthat crash. Our algorithm estimates the probability $p_i$ of returning a\ncorrect result for each processor $i \\in P-F$, making the estimates available\nto all these processors. The estimation is based on the $(\\epsilon,\n\\delta)$-approximation, where each estimated probability $\\tilde{p_i}$ of $p_i$\nobeys the bound ${\\sf Pr}[p_i(1-\\epsilon) \\leq \\tilde{p_i} \\leq\np_i(1+\\epsilon)] > 1 - \\delta$, for any constants $\\delta >0$ and $\\epsilon >0$\nchosen by the user. An important aspect of this algorithm is that each\nprocessor terminates without global coordination. We assess the efficiency of\nthe algorithm in three adversarial models as follows. For the model where the\nnumber of non-crashed processors $|P-F|$ is linearly bounded the time\ncomplexity $T(n)$ of the algorithm is $\\Theta(\\log{n})$, work complexity $W(n)$\nis $\\Theta(n\\log{n})$, and message complexity $M(n)$ is $\\Theta(n\\log^2n)$.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jul 2014 02:41:00 GMT"}], "update_date": "2014-07-04", "authors_parsed": [["Davtyan", "Seda", ""], ["Konwar", "Kishori M.", ""], ["Shvartsman", "Alexander A.", ""]]}, {"id": "1407.0898", "submitter": "Franck Iutzeler", "authors": "Pascal Bianchi, Walid Hachem and Franck Iutzeler", "title": "A Coordinate Descent Primal-Dual Algorithm and Application to\n  Distributed Asynchronous Optimization", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.NA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the idea of randomized coordinate descent of $\\alpha$-averaged\noperators, a randomized primal-dual optimization algorithm is introduced, where\na random subset of coordinates is updated at each iteration. The algorithm\nbuilds upon a variant of a recent (deterministic) algorithm proposed by V\\~u\nand Condat that includes the well known ADMM as a particular case. The obtained\nalgorithm is used to solve asynchronously a distributed optimization problem. A\nnetwork of agents, each having a separate cost function containing a\ndifferentiable term, seek to find a consensus on the minimum of the aggregate\nobjective. The method yields an algorithm where at each iteration, a random\nsubset of agents wake up, update their local estimates, exchange some data with\ntheir neighbors, and go idle. Numerical results demonstrate the attractive\nperformance of the method. The general approach can be naturally adapted to\nother situations where coordinate descent convex optimization algorithms are\nused with a random choice of the coordinates.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jul 2014 12:51:58 GMT"}, {"version": "v2", "created": "Fri, 5 Dec 2014 17:03:02 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2015 17:50:25 GMT"}], "update_date": "2015-10-01", "authors_parsed": [["Bianchi", "Pascal", ""], ["Hachem", "Walid", ""], ["Iutzeler", "Franck", ""]]}, {"id": "1407.0978", "submitter": "Laure Millet", "authors": "Laure Millet (LIP6), Maria Potop-Butucaru (LIP6), Nathalie Sznajder\n  (LIP6), S\\'ebastien Tixeuil (LIP6, LINCS, IUF)", "title": "On the Synthesis of Mobile Robots Algorithms: the Case of Ring Gathering", "comments": "International Symposium on Stabilization, Safety, and Security of\n  Distributed Systems (SSS 2014), Paderborn : Germany (2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RecentadvancesinDistributedComputinghighlightmodelsandalgo- rithms for\nautonomous swarms of mobile robots that self-organize and cooperate to solve\nglobal objectives. The overwhelming majority of works so far considers handmade\nalgorithms and correctness proofs. This paper is the first to propose a formal\nframework to automatically design dis- tributed algorithms that are dedicated\nto autonomous mobile robots evolving in a discrete space. As a case study, we\nconsider the problem of gathering all robots at a particular location, not\nknown beforehand. Our contribution is threefold. First, we propose an encoding\nof the gathering problem as a reachability game. Then, we automatically\ngenerate an optimal distributed algorithm for three robots evolv- ing on a\nfixed size uniform ring. Finally, we prove by induction that the generated\nalgorithm is also correct for any ring size except when an impossibility result\nholds (that is, when the number of robots divides the ring size).\n", "versions": [{"version": "v1", "created": "Tue, 1 Jul 2014 12:41:50 GMT"}, {"version": "v2", "created": "Sun, 6 Jul 2014 06:27:16 GMT"}], "update_date": "2014-07-08", "authors_parsed": [["Millet", "Laure", "", "LIP6"], ["Potop-Butucaru", "Maria", "", "LIP6"], ["Sznajder", "Nathalie", "", "LIP6"], ["Tixeuil", "S\u00e9bastien", "", "LIP6, LINCS, IUF"]]}, {"id": "1407.1237", "submitter": "Vinit Kumar", "authors": "Vinit Kumar and Ajay Agarwal", "title": "HT-Paxos: High Throughput State-Machine Replication Protocol for Large\n  Clustered Data Centers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paxos is a prominent theory of state machine replication. Recent data\nintensive Systems those implement state machine replication generally require\nhigh throughput. Earlier versions of Paxos as few of them are classical Paxos,\nfast Paxos and generalized Paxos have a major focus on fault tolerance and\nlatency but lacking in terms of throughput and scalability. A major reason for\nthis is the heavyweight leader. Through offloading the leader, we can further\nincrease throughput of the system. Ring Paxos, Multi Ring Paxos and S-Paxos are\nfew prominent attempts in this direction for clustered data centers. In this\npaper, we are proposing HT-Paxos, a variant of Paxos that one is the best\nsuitable for any large clustered data center. HT-Paxos further offloads the\nleader very significantly and hence increases the throughput and scalability of\nthe system. While at the same time, among high throughput state-machine\nreplication protocols, HT-Paxos provides reasonably low latency and response\ntime.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jul 2014 13:58:50 GMT"}], "update_date": "2014-07-07", "authors_parsed": [["Kumar", "Vinit", ""], ["Agarwal", "Ajay", ""]]}, {"id": "1407.1239", "submitter": "Hong Xu", "authors": "Shuhao Liu, Wei Bai, Hong Xu, Kai Chen, Zhiping Cai", "title": "RepNet: Cutting Tail Latency in Data Center Networks with Flow\n  Replication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data center networks need to provide low latency, especially at the tail, as\ndemanded by many interactive applications. To improve tail latency, existing\napproaches require modifications to switch hardware and/or end-host operating\nsystems, making them difficult to be deployed. We present the design,\nimplementation, and evaluation of RepNet, an application layer transport that\ncan be deployed today. RepNet exploits the fact that only a few paths among\nmany are congested at any moment in the network, and applies simple flow\nreplication to mice flows to opportunistically use the less congested path.\nRepNet has two designs for flow replication: (1) RepSYN, which only replicates\nSYN packets and uses the first connection that finishes TCP handshaking for\ndata transmission, and (2) RepFlow which replicates the entire mice flow. We\nimplement RepNet on {\\tt node.js}, one of the most commonly used platforms for\nnetworked interactive applications. {\\tt node}'s single threaded event-loop and\nnon-blocking I/O make flow replication highly efficient. Performance evaluation\non a real network testbed and in Mininet reveals that RepNet is able to reduce\nthe tail latency of mice flows, as well as application completion times, by\nmore than 50\\%.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jul 2014 14:17:40 GMT"}, {"version": "v2", "created": "Mon, 26 Jan 2015 06:57:31 GMT"}], "update_date": "2015-01-27", "authors_parsed": [["Liu", "Shuhao", ""], ["Bai", "Wei", ""], ["Xu", "Hong", ""], ["Chen", "Kai", ""], ["Cai", "Zhiping", ""]]}, {"id": "1407.1245", "submitter": "Sebastian Nanz", "authors": "Mischael Schill, Sebastian Nanz, Bertrand Meyer", "title": "Dynamic Checking of Safe Concurrent Memory Access using Shared Ownership", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In shared-memory concurrent programming, shared resources can be protected\nusing synchronization mechanisms such as monitors or channels. The connection\nbetween these mechanisms and the resources they protect is, however, only given\nimplicitly; this makes it difficult both for programmers to apply the\nmechanisms correctly and for compilers to check that resources are properly\nprotected. This paper presents a mechanism to automatically check that shared\nmemory is accessed properly, using a methodology called shared ownership. In\ncontrast to traditional ownership, shared ownership offers more flexibility by\npermitting multiple owners of a resource. On the basis of this methodology, we\ndefine an abstract model of resource access that provides operations to manage\ndata dependencies, as well as sharing and transfer of access privileges. The\nmodel is rigorously defined using a formal semantics, and shown to be free from\ndata races. This property can be used to detect unsafe memory accesses when\nsimulating the model together with the execution of a program. The\nexpressiveness and efficiency of the approach is demonstrated on a variety of\nprograms using common synchronization mechanisms.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jul 2014 14:37:38 GMT"}], "update_date": "2014-07-07", "authors_parsed": [["Schill", "Mischael", ""], ["Nanz", "Sebastian", ""], ["Meyer", "Bertrand", ""]]}, {"id": "1407.1428", "submitter": "Avery Miller", "authors": "Avery Miller, Andrzej Pelc", "title": "Fast Rendezvous with Advice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two mobile agents, starting from different nodes of an $n$-node network at\npossibly different times, have to meet at the same node. This problem is known\nas rendezvous. Agents move in synchronous rounds using a deterministic\nalgorithm. In each round, an agent decides to either remain idle or to move to\none of the adjacent nodes. Each agent has a distinct integer label from the set\n$\\{1,...,L\\}$, which it can use in the execution of the algorithm, but it does\nnot know the label of the other agent.\n  If $D$ is the distance between the initial positions of the agents, then\n$\\Omega(D)$ is an obvious lower bound on the time of rendezvous. However, if\neach agent has no initial knowledge other than its label, time $O(D)$ is\nusually impossible to achieve. We study the minimum amount of information that\nhas to be available a priori to the agents to achieve rendezvous in optimal\ntime $\\Theta(D)$. This information is provided to the agents at the start by an\noracle knowing the entire instance of the problem, i.e., the network, the\nstarting positions of the agents, their wake-up rounds, and both of their\nlabels. The oracle helps the agents by providing them with the same binary\nstring called advice, which can be used by the agents during their navigation.\nThe length of this string is called the size of advice. Our goal is to find the\nsmallest size of advice which enables the agents to meet in time $\\Theta(D)$.\nWe show that this optimal size of advice is $\\Theta(D\\log(n/D)+\\log\\log L)$.\nThe upper bound is proved by constructing an advice string of this size, and\nproviding a natural rendezvous algorithm using this advice that works in time\n$\\Theta(D)$ for all networks. The matching lower bound, which is the main\ncontribution of this paper, is proved by exhibiting classes of networks for\nwhich it is impossible to achieve rendezvous in time $\\Theta(D)$ with smaller\nadvice.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jul 2014 19:33:08 GMT"}, {"version": "v2", "created": "Mon, 6 Oct 2014 13:08:32 GMT"}], "update_date": "2014-10-07", "authors_parsed": [["Miller", "Avery", ""], ["Pelc", "Andrzej", ""]]}, {"id": "1407.1520", "submitter": "Vineet Singh", "authors": "Vineet Kumar Singh, Maitreyee Dutta", "title": "Analyzing Cryptographic Algorithms for Secure Cloud Network", "comments": "9 Pages, 8 Figures, IJASCSE ISSN No.-2278-7917, Vol 3, Issue 6, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pay as per usage concept of Cloud computing has brought revolutionary changes\nin the information technology world.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jul 2014 17:54:01 GMT"}], "update_date": "2014-07-08", "authors_parsed": [["Singh", "Vineet Kumar", ""], ["Dutta", "Maitreyee", ""]]}, {"id": "1407.1925", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu, Lorenzo Orecchia", "title": "Using Optimization to Solve Positive LPs Faster in Parallel", "comments": "polished writing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.NA math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Positive linear programs (LP), also known as packing and covering linear\nprograms, are an important class of problems that bridges computer science,\noperations research, and optimization. Despite the consistent efforts on this\nproblem, all known nearly-linear-time algorithms require\n$\\tilde{O}(\\varepsilon^{-4})$ iterations to converge to $1\\pm \\varepsilon$\napproximate solutions. This $\\varepsilon^{-4}$ dependence has not been improved\nsince 1993, and limits the performance of parallel implementations for such\nalgorithms. Moreover, previous algorithms and their analyses rely on update\nsteps and convergence arguments that are combinatorial in nature and do not\nseem to arise naturally from an optimization viewpoint.\n  In this paper, we leverage new insights from optimization theory to construct\na novel algorithm that breaks the longstanding $\\varepsilon^{-4}$ barrier. Our\nalgorithm has a simple analysis and a clear motivation. Our work introduces a\nnumber of novel techniques, such as the combined application of gradient\ndescent and mirror descent, and a truncated, smoothed version of the standard\nmultiplicative weight update, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jul 2014 01:58:11 GMT"}, {"version": "v2", "created": "Thu, 6 Nov 2014 07:03:14 GMT"}, {"version": "v3", "created": "Sun, 13 Nov 2016 05:23:54 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Orecchia", "Lorenzo", ""]]}, {"id": "1407.1963", "submitter": "Fawaz Paraiso", "authors": "Fawaz Paraiso (LIFL, INRIA Lille - Nord Europe), Philippe Merle (INRIA\n  Lille - Nord Europe), Lionel Seinturier (LIFL, INRIA Lille - Nord Europe,\n  IUF)", "title": "soCloud: A service-oriented component-based PaaS for managing\n  portability, provisioning, elasticity, and high availability across multiple\n  clouds", "comments": null, "journal-ref": null, "doi": "10.1007/s00607-014-0421-x", "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-cloud computing is a promising paradigm to support very large scale\nworld wide distributed applications. Multi-cloud computing is the usage of\nmultiple, independent cloud environments, which assumed no priori agreement\nbetween cloud providers or third party. However, multi-cloud computing has to\nface several key challenges such as portability, provisioning, elasticity, and\nhigh availability. Developers will not only have to deploy applications to a\nspecific cloud, but will also have to consider application portability from one\ncloud to another, and to deploy distributed applications spanning multiple\nclouds. This article presents soCloud a service-oriented component-based\nPlatform as a Service (PaaS) for managing portability, elasticity,\nprovisioning, and high availability across multiple clouds. soCloud is based on\nthe OASIS Service Component Architecture (SCA) standard in order to address\nportability. soCloud provides services for managing provisioning, elasticity,\nand high availability across multiple clouds. soCloud has been deployed and\nevaluated on top of ten existing cloud providers: Windows Azure, DELL KACE,\nAmazon EC2, CloudBees, OpenShift, dotCloud, Jelastic, Heroku, Appfog, and an\nEucalyptus private cloud.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jul 2014 06:20:48 GMT"}], "update_date": "2014-07-09", "authors_parsed": [["Paraiso", "Fawaz", "", "LIFL, INRIA Lille - Nord Europe"], ["Merle", "Philippe", "", "INRIA\n  Lille - Nord Europe"], ["Seinturier", "Lionel", "", "LIFL, INRIA Lille - Nord Europe,\n  IUF"]]}, {"id": "1407.2565", "submitter": "Emanuele Natale", "authors": "L. Becchetti, A. Clementi, E. Natale, F. Pasquale, R. Silvestri", "title": "Plurality Consensus in the Gossip Model", "comments": "Corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Plurality Consensus in the Gossip Model over a network of $n$\nanonymous agents. Each agent supports an initial opinion or color. We assume\nthat at the onset, the number of agents supporting the plurality color exceeds\nthat of the agents supporting any other color by a sufficiently-large bias. The\ngoal is to provide a protocol that, with high probability, brings the system\ninto the configuration in which all agents support the (initial) plurality\ncolor. We consider the Undecided-State Dynamics, a well-known protocol which\nuses just one more state (the undecided one) than those necessary to store\ncolors. We show that the speed of convergence of this protocol depends on the\ninitial color configuration as a whole, not just on the gap between the\nplurality and the second largest color community. This dependence is best\ncaptured by a novel notion we introduce, namely, the monochromatic distance\n${md}(\\bar{\\mathbf{c}})$ which measures the distance of the initial color\nconfiguration $\\bar{ \\mathbf {c}}$ from the closest monochromatic one. In the\ncomplete graph, we prove that, for a wide range of the input parameters, this\ndynamics converges within $O({md}(\\bar {\\mathbf {c}}) \\log {n})$ rounds. We\nprove that this upper bound is almost tight in the strong sense: Starting from\nany color configuration $\\bar {\\mathbf {c}}$, the convergence time is\n$\\Omega({md}(\\bar {\\mathbf {c}}))$. Finally, we adapt the Undecided-State\nDynamics to obtain a fast, random walk-based protocol for plurality consensus\non regular expanders. This protocol converges in $O({md}(\\bar {\\mathbf {c}})\n\\mathrm{polylog}(n))$ rounds using only $\\mathrm{polylog}(n)$ local memory. A\nkey-ingredient to achieve the above bounds is a new analysis of the maximum\nnode congestion that results from performing $n$ parallel random walks on\nregular expanders. All our bounds hold with high probability.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jul 2014 17:13:35 GMT"}, {"version": "v2", "created": "Thu, 10 Jul 2014 10:25:04 GMT"}], "update_date": "2014-07-11", "authors_parsed": [["Becchetti", "L.", ""], ["Clementi", "A.", ""], ["Natale", "E.", ""], ["Pasquale", "F.", ""], ["Silvestri", "R.", ""]]}, {"id": "1407.2636", "submitter": "Vijay Gadepally", "authors": "Ashok Krishnamurthy, Siddharth Samsi, Vijay Gadepally", "title": "Parallel MATLAB Techniques", "comments": null, "journal-ref": null, "doi": "10.5772/7046", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter, we show why parallel MATLAB is useful, provide a comparison\nof the different parallel MATLAB choices, and describe a number of applications\nin Signal and Image Processing: Audio Signal Processing, Synthetic Aperture\nRadar (SAR) Processing and Superconducting Quantum Interference Filters\n(SQIFs). Each of these applications have been parallelized using different\nmethods (Task parallel and Data parallel techniques). The applications\npresented may be considered representative of type of problems faced by signal\nand image processing researchers. This chapter will also strive to serve as a\nguide to new signal and image processing parallel programmers, by suggesting a\nparallelization strategy that can be employed when developing a general\nparallel algorithm. The objective of this chapter is to help signal and image\nprocessing algorithm developers understand the advantages of using parallel\nMATLAB to tackle larger problems while staying within the powerful environment\nof MATLAB.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jul 2014 20:54:42 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Krishnamurthy", "Ashok", ""], ["Samsi", "Siddharth", ""], ["Gadepally", "Vijay", ""]]}, {"id": "1407.2889", "submitter": "John-Alexander Assael", "authors": "Charalampos S. Kouzinopoulos, John-Alexander M. Assael, Themistoklis\n  K. Pyrgiotis, and Konstantinos G. Margaritis", "title": "A Hybrid Parallel Implementation of the Aho-Corasick and Wu-Manber\n  Algorithms Using NVIDIA CUDA and MPI Evaluated on a Biological Sequence\n  Database", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple matching algorithms are used to locate the occurrences of patterns\nfrom a finite pattern set in a large input string. Aho-Corasick and Wu-Manber,\ntwo of the most well known algorithms for multiple matching require an\nincreased computing power, particularly in cases where large-size datasets must\nbe processed, as is common in computational biology applications. Over the past\nyears, Graphics Processing Units (GPUs) have evolved to powerful parallel\nprocessors outperforming Central Processing Units (CPUs) in scientific\ncalculations. Moreover, multiple GPUs can be used in parallel, forming hybrid\ncomputer cluster configurations to achieve an even higher processing\nthroughput. This paper evaluates the speedup of the parallel implementation of\nthe Aho-Corasick and Wu-Manber algorithms on a hybrid GPU cluster, when used to\nprocess a snapshot of the Expressed Sequence Tags of the human genome and for\ndifferent problem parameters.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jul 2014 18:15:18 GMT"}], "update_date": "2014-07-11", "authors_parsed": [["Kouzinopoulos", "Charalampos S.", ""], ["Assael", "John-Alexander M.", ""], ["Pyrgiotis", "Themistoklis K.", ""], ["Margaritis", "Konstantinos G.", ""]]}, {"id": "1407.3144", "submitter": "Matteo Ceccarello", "authors": "Matteo Ceccarello, Andrea Pietracaprina, Geppino Pucci and Eli Upfal", "title": "Space and Time Efficient Parallel Graph Decomposition, Clustering, and\n  Diameter Approximation", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a novel parallel decomposition strategy for unweighted, undirected\ngraphs, based on growing disjoint connected clusters from batches of centers\nprogressively selected from yet uncovered nodes. With respect to similar\nprevious decompositions, our strategy exercises a tighter control on both the\nnumber of clusters and their maximum radius.\n  We present two important applications of our parallel graph decomposition:\n(1) $k$-center clustering approximation; and (2) diameter approximation. In\nboth cases, we obtain algorithms which feature a polylogarithmic approximation\nfactor and are amenable to a distributed implementation that is geared for\nmassive (long-diameter) graphs. The total space needed for the computation is\nlinear in the problem size, and the parallel depth is substantially sublinear\nin the diameter for graphs with low doubling dimension. To the best of our\nknowledge, ours are the first parallel approximations for these problems which\nachieve sub-diameter parallel time, for a relevant class of graphs, using only\nlinear space. Besides the theoretical guarantees, our algorithms allow for a\nvery simple implementation on clustered architectures: we report on extensive\nexperiments which demonstrate their effectiveness and efficiency on large\ngraphs as compared to alternative known approaches.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jul 2014 13:12:19 GMT"}, {"version": "v2", "created": "Tue, 21 Oct 2014 16:11:08 GMT"}, {"version": "v3", "created": "Fri, 6 Feb 2015 14:38:45 GMT"}], "update_date": "2015-02-09", "authors_parsed": [["Ceccarello", "Matteo", ""], ["Pietracaprina", "Andrea", ""], ["Pucci", "Geppino", ""], ["Upfal", "Eli", ""]]}, {"id": "1407.3175", "submitter": "Oleg Verbitsky", "authors": "Andreas Krebs and Oleg Verbitsky", "title": "Universal covers, color refinement, and two-variable counting logic:\n  Lower bounds for the depth", "comments": "25 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a connected graph $G$ and its vertex $x$, let $U_x(G)$ denote the\nuniversal cover of $G$ obtained by unfolding $G$ into a tree starting from $x$.\nLet $T=T(n)$ be the minimum number such that, for graphs $G$ and $H$ with at\nmost $n$ vertices each, the isomorphism of $U_x(G)$ and $U_y(H)$ surely follows\nfrom the isomorphism of these rooted trees truncated at depth $T$. Motivated by\napplications in theory of distributed computing, Norris [Discrete Appl. Math.\n1995] asks if $T(n)\\le n$. We answer this question in the negative by\nestablishing that $T(n)=(2-o(1))n$. Our solution uses basic tools of finite\nmodel theory such as a bisimulation version of the Immerman-Lander 2-pebble\ncounting game.\n  The graphs $G_n$ and $H_n$ we construct to prove the lower bound for $T(n)$\nalso show some other tight lower bounds. Both having $n$ vertices, $G_n$ and\n$H_n$ can be distinguished in 2-variable counting logic only with quantifier\ndepth $(1-o(1))n$. It follows that color refinement, the classical procedure\nused in isomorphism testing and other areas for computing the coarsest\nequitable partition of a graph, needs $(1-o(1))n$ rounds to achieve color\nstabilization on each of $G_n$ and $H_n$. Somewhat surprisingly, this number of\nrounds is not enough for color stabilization on the disjoint union of $G_n$ and\n$H_n$, where $(2-o(1))n$ rounds are needed.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jul 2014 14:40:31 GMT"}, {"version": "v2", "created": "Thu, 29 Jan 2015 10:34:42 GMT"}], "update_date": "2015-01-30", "authors_parsed": [["Krebs", "Andreas", ""], ["Verbitsky", "Oleg", ""]]}, {"id": "1407.3286", "submitter": "Srikanth Sastry", "authors": "Srikanth Sastry and Josef Widder", "title": "Solvability-Based Comparison of Failure Detectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Failure detectors are oracles that have been introduced to provide processes\nin asynchronous systems with information about faults. This information can\nthen be used to solve problems otherwise unsolvable in asynchronous systems. A\nnatural question is on the \"minimum amount of information\" a failure detector\nhas to provide for a given problem. This question is classically addressed\nusing a relation that states that a failure detector D is stronger (that is,\nprovides \"more, or better, information\") than a failure detector D' if D can be\nused to implement D'. It has recently been shown that this classic\nimplementability relation has some drawbacks. To overcome this, different\nrelations have been defined, one of which states that a failure detector D is\nstronger than D' if D can solve all the time-free problems solvable by D'. In\nthis paper we compare the implementability-based hierarchy of failure detectors\nto the hierarchy based on solvability. This is done by introducing a new proof\ntechnique for establishing the solvability relation. We apply this technique to\nknown failure detectors from the literature and demonstrate significant\ndifferences between the hierarchies.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jul 2014 20:17:12 GMT"}], "update_date": "2014-07-15", "authors_parsed": [["Sastry", "Srikanth", ""], ["Widder", "Josef", ""]]}, {"id": "1407.3487", "submitter": "Grigori Fursin", "authors": "Grigori Fursin", "title": "Collective Tuning Initiative", "comments": "GCC Developers' Summit'09, 14 June 2009, Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing systems rarely deliver best possible performance due to ever\nincreasing hardware and software complexity and limitations of the current\noptimization technology. Additional code and architecture optimizations are\noften required to improve execution time, size, power consumption, reliability\nand other important characteristics of computing systems. However, it is often\na tedious, repetitive, isolated and time consuming process. In order to\nautomate, simplify and systematize program optimization and architecture\ndesign, we are developing open-source modular plugin-based Collective Tuning\nInfrastructure (CTI, http://cTuning.org) that can distribute optimization\nprocess and leverage optimization experience of multiple users. CTI provides a\nnovel fully integrated, collaborative, \"one button\" approach to improve\nexisting underperfoming computing systems ranging from embedded architectures\nto high-performance servers based on systematic iterative compilation,\nstatistical collective optimization and machine learning. Our experimental\nresults show that it is possible to reduce execution time (and code size) of\nsome programs from SPEC2006 and EEMBC among others by more than a factor of 2\nautomatically. It can also reduce development and testing time considerably.\nTogether with the first production quality machine learning enabled interactive\nresearch compiler (MILEPOST GCC) this infrastructure opens up many research\nopportunities to study and develop future realistic self-tuning and\nself-organizing adaptive intelligent computing systems based on systematic\nstatistical performance evaluation and benchmarking. Finally, using common\noptimization repository is intended to improve the quality and reproducibility\nof the research on architecture and code optimization.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jul 2014 17:13:17 GMT"}], "update_date": "2014-07-15", "authors_parsed": [["Fursin", "Grigori", ""]]}, {"id": "1407.3561", "submitter": "Juan Batiz-Benet", "authors": "Juan Benet", "title": "IPFS - Content Addressed, Versioned, P2P File System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The InterPlanetary File System (IPFS) is a peer-to-peer distributed file\nsystem that seeks to connect all computing devices with the same system of\nfiles. In some ways, IPFS is similar to the Web, but IPFS could be seen as a\nsingle BitTorrent swarm, exchanging objects within one Git repository. In other\nwords, IPFS provides a high throughput content-addressed block storage model,\nwith content-addressed hyper links. This forms a generalized Merkle DAG, a data\nstructure upon which one can build versioned file systems, blockchains, and\neven a Permanent Web. IPFS combines a distributed hashtable, an incentivized\nblock exchange, and a self-certifying namespace. IPFS has no single point of\nfailure, and nodes do not need to trust each other.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jul 2014 08:31:05 GMT"}], "update_date": "2014-07-15", "authors_parsed": [["Benet", "Juan", ""]]}, {"id": "1407.3859", "submitter": "Jeremy Kepner", "authors": "Jeremy Kepner, Christian Anderson, William Arcand, David Bestor, Bill\n  Bergeron, Chansup Byun, Matthew Hubbell, Peter Michaleas, Julie Mullen, David\n  O'Gwynn, Andrew Prout, Albert Reuther, Antonio Rosa, Charles Yee (MIT)", "title": "D4M 2.0 Schema: A General Purpose High Performance Schema for the\n  Accumulo Database", "comments": "6 pages; IEEE HPEC 2013", "journal-ref": null, "doi": "10.1109/HPEC.2013.6670318", "report-no": null, "categories": "cs.DB astro-ph.IM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-traditional, relaxed consistency, triple store databases are the backbone\nof many web companies (e.g., Google Big Table, Amazon Dynamo, and Facebook\nCassandra). The Apache Accumulo database is a high performance open source\nrelaxed consistency database that is widely used for government applications.\nObtaining the full benefits of Accumulo requires using novel schemas. The\nDynamic Distributed Dimensional Data Model (D4M)[http://d4m.mit.edu] provides a\nuniform mathematical framework based on associative arrays that encompasses\nboth traditional (i.e., SQL) and non-traditional databases. For non-traditional\ndatabases D4M naturally leads to a general purpose schema that can be used to\nfully index and rapidly query every unique string in a dataset. The D4M 2.0\nSchema has been applied with little or no customization to cyber,\nbioinformatics, scientific citation, free text, and social media data. The D4M\n2.0 Schema is simple, requires minimal parsing, and achieves the highest\npublished Accumulo ingest rates. The benefits of the D4M 2.0 Schema are\nindependent of the D4M interface. Any interface to Accumulo can achieve these\nbenefits by using the D4M 2.0 Schema\n", "versions": [{"version": "v1", "created": "Tue, 15 Jul 2014 01:54:45 GMT"}], "update_date": "2015-05-26", "authors_parsed": [["Kepner", "Jeremy", "", "MIT"], ["Anderson", "Christian", "", "MIT"], ["Arcand", "William", "", "MIT"], ["Bestor", "David", "", "MIT"], ["Bergeron", "Bill", "", "MIT"], ["Byun", "Chansup", "", "MIT"], ["Hubbell", "Matthew", "", "MIT"], ["Michaleas", "Peter", "", "MIT"], ["Mullen", "Julie", "", "MIT"], ["O'Gwynn", "David", "", "MIT"], ["Prout", "Andrew", "", "MIT"], ["Reuther", "Albert", "", "MIT"], ["Rosa", "Antonio", "", "MIT"], ["Yee", "Charles", "", "MIT"]]}, {"id": "1407.3879", "submitter": "Harshad Prajapati", "authors": "Harshadkumar B. Prajapati and Vipul A. Shah", "title": "Scheduling in Grid Computing Environment", "comments": "Fourth International Conference on Advanced Computing & Communication\n  Technologies (ACCT), 2014", "journal-ref": null, "doi": "10.1109/ACCT.2014.32", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scheduling in Grid computing has been active area of research since its\nbeginning. However, beginners find very difficult to understand related\nconcepts due to a large learning curve of Grid computing. Thus, there is a need\nof concise understanding of scheduling in Grid computing area. This paper\nstrives to present concise understanding of scheduling and related\nunderstanding of Grid computing system. The paper describes overall picture of\nGrid computing and discusses important sub-systems that enable Grid computing\npossible. Moreover, the paper also discusses concepts of resource scheduling\nand application scheduling and also presents classification of scheduling\nalgorithms. Furthermore, the paper also presents methodology used for\nevaluating scheduling algorithms including both real system and simulation\nbased approaches. The presented work on scheduling in Grid containing concise\nunderstandings of scheduling system, scheduling algorithm, and scheduling\nmethodology would be very useful to users and researchers\n", "versions": [{"version": "v1", "created": "Tue, 15 Jul 2014 04:28:09 GMT"}], "update_date": "2014-07-16", "authors_parsed": [["Prajapati", "Harshadkumar B.", ""], ["Shah", "Vipul A.", ""]]}, {"id": "1407.3881", "submitter": "Harshadkumar Prajapati", "authors": "Harshadkumar B. Prajapati and Vipul A. Shah", "title": "Experimental Study of Remote Job Submission and Execution on LRM through\n  Grid Computing Mechanisms", "comments": "Fourth International Conference on Advanced Computing & Communication\n  Technologies (ACCT), 2014", "journal-ref": null, "doi": "10.1109/ACCT.2014.31", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remote job submission and execution is fundamental requirement of distributed\ncomputing done using Cluster computing. However, Cluster computing limits usage\nwithin a single organization. Grid computing environment can allow use of\nresources for remote job execution that are available in other organizations.\nThis paper discusses concepts of batch-job execution using LRM and using Grid.\nThe paper discusses two ways of preparing test Grid computing environment that\nwe use for experimental testing of concepts. This paper presents experimental\ntesting of remote job submission and execution mechanisms through LRM specific\nway and Grid computing ways. Moreover, the paper also discusses various\nproblems faced while working with Grid computing environment and discusses\ntheir trouble-shootings. The understanding and experimental testing presented\nin this paper would become very useful to researchers who are new to the field\nof job management in Grid.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jul 2014 04:53:12 GMT"}], "update_date": "2014-07-16", "authors_parsed": [["Prajapati", "Harshadkumar B.", ""], ["Shah", "Vipul A.", ""]]}, {"id": "1407.4149", "submitter": "Kari Visala", "authors": "Kari Visala", "title": "Hybrid Communication Architecture HCA", "comments": "120 pages", "journal-ref": "Master's thesis, Tampere University of Technology, 2006", "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The beginning of the 21st century has seen many projects on distributed hash\ntables, both research and commercial. One of their aims has been to replace the\nfirst generation of file sharing software with scalable peer-to-peer\narchitectures. On other fronts, the same techniques are applied, for example,\nto content delivery networks, streaming networks, cooperative caches,\ndistributed file systems, and grid computing architectures for scientific use.\nThis trend has emerged because with cooperative peers it is possible to\nasymptotically enhance the use of resouces in sharing of data compared to the\nbasic client-server architecture.\n  The need for distribution of data is wide and one could argue that it is as\nfundamental a building block as the message passing of the Internet. As an\nanswer to this need a new scalable architecture is introduced: Hybrid\nCommunication Architecture (HCA), which provides both data sharing and message\npassing as communication primitives for applications. HCA can be regarded as an\nabstraction layer for communication which is further encapsulated by a\nhigher-level middleware. HCA is aimed at general use, and it is not designed\nfor any particular application. One key idea is to combine data sharing with\nstreaming since together they enable many applications not easily implementable\nwith only one of these features. For example, a game application could share\nthe game world state between clients and modify it by using streaming. The\nother distinctive feature of the system is the use of knowledge of the physical\nnetwork topology in the optimization of the communication. With a feasible\nbusiness model, fault-tolerance, and security features, HCA is aimed eventually\nfor real-life adoption.\n  This thesis presents the specification of the C++ client interface of HCA and\nthe architecture and protocol of the distributed nodes forming the\nimplementation.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jul 2014 21:19:18 GMT"}], "update_date": "2014-07-17", "authors_parsed": [["Visala", "Kari", ""]]}, {"id": "1407.4167", "submitter": "Viveck Cadambe", "authors": "Viveck R. Cadambe and Nancy Lynch and Muriel M\\'edard and Peter Musial", "title": "A Coded Shared Atomic Memory Algorithm for Message Passing Architectures", "comments": "Part of the results to appear in IEEE Network Computing and\n  Applications (NCA), Aug 2014. This report supersedes MIT CSAIL technical\n  report MIT-CSAIL-TR-2013-016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the communication and storage costs of emulating atomic\n(linearizable) multi-writer multi-reader shared memory in distributed\nmessage-passing systems. The paper contains three main contributions: (1) We\npresent a atomic shared-memory emulation algorithm that we call Coded Atomic\nStorage (CAS). This algorithm uses erasure coding methods. In a storage system\nwith $N$ servers that is resilient to $f$ server failures, we show that the\ncommunication cost of CAS is $\\frac{N}{N-2f}$. The storage cost of CAS is\nunbounded. (2) We present a modification of the CAS algorithm known as CAS with\nGarbage Collection (CASGC). The CASGC algorithm is parametrized by an integer\n$\\delta$ and has a bounded storage cost. We show that in every execution where\nthe number of write operations that are concurrent with a read operation is no\nbigger than $\\delta$, the CASGC algorithm with parameter $\\delta$ satisfies\natomicity and liveness. We explicitly characterize the storage cost of CASGC,\nand show that it has the same communication cost as CAS. (3) We describe an\nalgorithm known as the Communication Cost Optimal Atomic Storage (CCOAS)\nalgorithm that achieves a smaller communication cost than CAS and CASGC. In\nparticular, CCOAS incurs read and write communication costs of $\\frac{N}{N-f}$\nmeasured in terms of number of object values. We also discuss drawbacks of\nCCOAS as compared with CAS and CASGC.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jul 2014 22:59:29 GMT"}], "update_date": "2014-07-17", "authors_parsed": [["Cadambe", "Viveck R.", ""], ["Lynch", "Nancy", ""], ["M\u00e9dard", "Muriel", ""], ["Musial", "Peter", ""]]}, {"id": "1407.4245", "submitter": "Elena Reshetova", "authors": "Elena Reshetova, Janne Karhunen, Thomas Nyman, N. Asokan", "title": "Security of OS-level virtualization technologies: Technical report", "comments": "20 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for flexible, low-overhead virtualization is evident on many fronts\nranging from high-density cloud servers to mobile devices. During the past\ndecade OS-level virtualization has emerged as a new, efficient approach for\nvirtualization, with implementations in multiple different Unix-based systems.\nDespite its popularity, there has been no systematic study of OS-level\nvirtualization from the point of view of security. In this report, we conduct a\ncomparative study of several OS-level virtualization systems, discuss their\nsecurity and identify some gaps in current solutions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jul 2014 10:03:51 GMT"}], "update_date": "2014-07-17", "authors_parsed": [["Reshetova", "Elena", ""], ["Karhunen", "Janne", ""], ["Nyman", "Thomas", ""], ["Asokan", "N.", ""]]}, {"id": "1407.4504", "submitter": "Gesualdo Scutari", "authors": "Amir Daneshmand, Francisco Facchinei, Vyacheslav Kungurtsev, and\n  Gesualdo Scutari", "title": "Hybrid Random/Deterministic Parallel Algorithms for Nonconvex Big Data\n  Optimization", "comments": "The order of the authors is alphabetical", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a decomposition framework for the parallel optimization of the sum\nof a differentiable {(possibly nonconvex)} function and a nonsmooth (possibly\nnonseparable), convex one. The latter term is usually employed to enforce\nstructure in the solution, typically sparsity. The main contribution of this\nwork is a novel \\emph{parallel, hybrid random/deterministic} decomposition\nscheme wherein, at each iteration, a subset of (block) variables is updated at\nthe same time by minimizing local convex approximations of the original\nnonconvex function. To tackle with huge-scale problems, the (block) variables\nto be updated are chosen according to a \\emph{mixed random and deterministic}\nprocedure, which captures the advantages of both pure deterministic and random\nupdate-based schemes. Almost sure convergence of the proposed scheme is\nestablished. Numerical results show that on huge-scale problems the proposed\nhybrid random/deterministic algorithm outperforms both random and deterministic\nschemes.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jul 2014 21:42:34 GMT"}, {"version": "v2", "created": "Tue, 2 Sep 2014 23:57:24 GMT"}], "update_date": "2014-09-04", "authors_parsed": [["Daneshmand", "Amir", ""], ["Facchinei", "Francisco", ""], ["Kungurtsev", "Vyacheslav", ""], ["Scutari", "Gesualdo", ""]]}, {"id": "1407.4755", "submitter": "Yi Li", "authors": "Yi Li, Xiaoming Sun, Chengu Wang, David P. Woodruff", "title": "On The Communication Complexity of Linear Algebraic Problems in the\n  Message Passing Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the communication complexity of linear algebraic problems over\nfinite fields in the multi-player message passing model, proving a number of\ntight lower bounds. Specifically, for a matrix which is distributed among a\nnumber of players, we consider the problem of determining its rank, of\ncomputing entries in its inverse, and of solving linear equations. We also\nconsider related problems such as computing the generalized inner product of\nvectors held on different servers. We give a general framework for reducing\nthese multi-player problems to their two-player counterparts, showing that the\nrandomized $s$-player communication complexity of these problems is at least\n$s$ times the randomized two-player communication complexity. Provided the\nproblem has a certain amount of algebraic symmetry, which we formally define,\nwe can show the hardest input distribution is a symmetric distribution, and\ntherefore apply a recent multi-player lower bound technique of Phillips et al.\nFurther, we give new two-player lower bounds for a number of these problems. In\nparticular, our optimal lower bound for the two-player version of the matrix\nrank problem resolves an open question of Sun and Wang.\n  A common feature of our lower bounds is that they apply even to the special\n\"threshold promise\" versions of these problems, wherein the underlying\nquantity, e.g., rank, is promised to be one of just two values, one on each\nside of some critical threshold. These kinds of promise problems are\ncommonplace in the literature on data streaming as sources of hardness for\nreductions giving space lower bounds.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jul 2014 17:56:47 GMT"}], "update_date": "2014-07-18", "authors_parsed": [["Li", "Yi", ""], ["Sun", "Xiaoming", ""], ["Wang", "Chengu", ""], ["Woodruff", "David P.", ""]]}, {"id": "1407.4765", "submitter": "Leif Walsh", "authors": "Zardosht Kasheff, Leif Walsh", "title": "Ark: A Real-World Consensus Implementation", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ark is an implementation of a consensus algorithm similar to Paxos and Raft,\ndesigned as an improvement over the existing consensus algorithm used by\nMongoDB and TokuMX.\n  Ark was designed from first principles, improving on the election algorithm\nused by TokuMX, to fix deficiencies in MongoDB's consensus algorithms that can\ncause data loss. It ultimately has many similarities with Raft, but diverges in\na few ways, mainly to support other features like chained replication and\nunacknowledged writes.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jul 2014 18:32:31 GMT"}], "update_date": "2014-07-18", "authors_parsed": [["Kasheff", "Zardosht", ""], ["Walsh", "Leif", ""]]}, {"id": "1407.4859", "submitter": "Kuldeep Meel", "authors": "Deepak Majeti, Kuldeep S. Meel, Rajkishore Barik, Vivek Sarkar", "title": "ADHA: Automatic Data layout framework for Heterogeneous Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data layouts play a crucial role in determining the performance of a given\napplication running on a given architecture. Existing parallel programming\nframeworks for both multicore and heterogeneous systems leave the onus of\nselecting a data layout to the programmer. Therefore, shifting the burden of\ndata layout selection to optimizing compilers can greatly enhance programmer\nproductivity and application performance. In this work, we introduce {\\ADHA}: a\ntwo-level hierarchal formulation of the data layout problem for modern\nheterogeneous architectures. We have created a reference implementation of ADHA\nin the Heterogeneous Habanero-C (H2C) parallel programming system. ADHA shows\nsignificant performance benefits of up to 6.92$\\times$ compared to manually\nspecified layouts for two benchmark programs running on a CPU+GPU heterogeneous\nplatform.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jul 2014 00:09:04 GMT"}], "update_date": "2014-07-21", "authors_parsed": [["Majeti", "Deepak", ""], ["Meel", "Kuldeep S.", ""], ["Barik", "Rajkishore", ""], ["Sarkar", "Vivek", ""]]}, {"id": "1407.4908", "submitter": "Bogdan Oancea", "authors": "Bogdan Oancea and Raluca Mariana Dragoescu", "title": "Integrating R and Hadoop for Big Data Analysis", "comments": "Romanian Statistical Review no. 2 / 2014", "journal-ref": "Romanian Statistical Review no. 2 / 2014", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Analyzing and working with big data could be very diffi cult using classical\nmeans like relational database management systems or desktop software packages\nfor statistics and visualization. Instead, big data requires large clusters\nwith hundreds or even thousands of computing nodes. Offi cial statistics is\nincreasingly considering big data for deriving new statistics because big data\nsources could produce more relevant and timely statistics than traditional\nsources. One of the software tools successfully and wide spread used for\nstorage and processing of big data sets on clusters of commodity hardware is\nHadoop. Hadoop framework contains libraries, a distributed fi le-system (HDFS),\na resource-management platform and implements a version of the MapReduce\nprogramming model for large scale data processing. In this paper we investigate\nthe possibilities of integrating Hadoop with R which is a popular software used\nfor statistical computing and data visualization. We present three ways of\nintegrating them: R with Streaming, Rhipe and RHadoop and we emphasize the\nadvantages and disadvantages of each solution.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jul 2014 08:17:55 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Oancea", "Bogdan", ""], ["Dragoescu", "Raluca Mariana", ""]]}, {"id": "1407.4958", "submitter": "Stefan Westerlund", "authors": "Stefan Westerlund and Christopher Harris", "title": "A Framework for HI Spectral Source Finding Using Distributed-Memory\n  Supercomputing", "comments": "15 pages, 6 figures", "journal-ref": "Publications of the Astronomical Society of Australia, 2014,\n  Volume 31", "doi": "10.1017/pasa.2014.18", "report-no": null, "categories": "astro-ph.IM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The latest generation of radio astronomy interferometers will conduct all sky\nsurveys with data products consisting of petabytes of spectral line data.\nTraditional approaches to identifying and parameterising the astrophysical\nsources within this data will not scale to datasets of this magnitude, since\nthe performance of workstations will not keep up with the real-time generation\nof data. For this reason, it is necessary to employ high performance computing\nsystems consisting of a large number of processors connected by a\nhigh-bandwidth network. In order to make use of such supercomputers substantial\nmodifications must be made to serial source finding code. To ease the\ntransition, this work presents the Scalable Source Finder Framework, a\nframework providing storage access, networking communication and data\ncomposition functionality, which can support a wide range of source finding\nalgorithms provided they can be applied to subsets of the entire image.\nAdditionally, the Parallel Gaussian Source Finder was implemented using SSoFF,\nutilising Gaussian filters, thresholding, and local statistics. PGSF was able\nto search on a 256GB simulated dataset in under 24 minutes, significantly less\nthan the 8 to 12 hour observation that would generate such a dataset.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jul 2014 11:36:57 GMT"}], "update_date": "2014-07-21", "authors_parsed": [["Westerlund", "Stefan", ""], ["Harris", "Christopher", ""]]}, {"id": "1407.5032", "submitter": "Weiye Zheng", "authors": "Weiye Zheng, Wenchuan Wu, Boming Zhang, Hongbin Sun, Liu Yibing", "title": "A Fully Distributed Reactive Power Optimization and Control Method for\n  Active Distribution Networks", "comments": "This paper has been withdrawn by the author due to a crucial sign\n  error in equations 11 and 26. Also, in P1, active powers have been optimized,\n  which is not suitable. Some crucial assumptions about DGs are not explicitly\n  addressed, either", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a fully distributed reactive power optimization algorithm\nthat can obtain the global optimum of non-convex problems for distribution\nnetworks without a central coordinator. Second-order cone (SOC) relaxation is\nused to achieve exact convexification. A fully distributed algorithm is then\nformulated corresponding to the given division of areas based on an alternating\ndirection method of multipliers (ADMM) algorithm, which is greatly simplified\nby exploiting the structure of active distribution networks (ADNs). The problem\nis solved for each area with very little interchange of boundary information\nbetween neighboring areas. The standard ADMM algorithm is extended using a\nvarying penalty parameter to improve convergence. The validity of the method is\ndemonstrated via numerical simulations on an IEEE 33-node distribution network,\na PG&E 69-node distribution system, and an extended 137-node system.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jul 2014 15:18:01 GMT"}, {"version": "v2", "created": "Thu, 11 Sep 2014 01:28:58 GMT"}], "update_date": "2014-09-12", "authors_parsed": [["Zheng", "Weiye", ""], ["Wu", "Wenchuan", ""], ["Zhang", "Boming", ""], ["Sun", "Hongbin", ""], ["Yibing", "Liu", ""]]}, {"id": "1407.5074", "submitter": "Saber Mirzaei", "authors": "Saber Mirzaei and Flavio Esposito", "title": "An Alloy Verification Model for Consensus-Based Auction Protocols", "comments": null, "journal-ref": null, "doi": "10.1109/ICDCSW.2015.15", "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Max Consensus-based Auction (MCA) protocols are an elegant approach to\nestablish conflict-free distributed allocations in a wide range of network\nutility maximization problems. A set of agents independently bid on a set of\nitems, and exchange their bids with their first hop-neighbors for a distributed\n(max-consensus) winner determination. The use of MCA protocols was proposed,\n$e.g.$, to solve the task allocation problem for a fleet of unmanned aerial\nvehicles, in smart grids, or in distributed virtual network management\napplications. Misconfigured or malicious agents participating in a MCA, or an\nincorrect instantiation of policies can lead to oscillations of the protocol,\ncausing, $e.g.$, Service Level Agreement (SLA) violations.\n  In this paper, we propose a formal, machine-readable, Max-Consensus Auction\nmodel, encoded in the Alloy lightweight modeling language. The model consists\nof a network of agents applying the MCA mechanisms, instantiated with\npotentially different policies, and a set of predicates to analyze its\nconvergence properties. We were able to verify that MCA is not resilient\nagainst rebidding attacks, and that the protocol fails (to achieve a\nconflict-free resource allocation) for some specific combinations of policies.\nOur model can be used to verify, with a \"push-button\" analysis, the convergence\nof the MCA mechanism to a conflict-free allocation of a wide range of policy\ninstantiations.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jul 2014 20:35:57 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2015 21:57:44 GMT"}], "update_date": "2015-12-14", "authors_parsed": [["Mirzaei", "Saber", ""], ["Esposito", "Flavio", ""]]}, {"id": "1407.5320", "submitter": "T.R. Gopalakrishnan Nair", "authors": "Vivek Sharma and T. R. Gopalakrishnan Nair", "title": "An Optimum Scheduling Approach for Creating Optimal Priority of Jobs\n  with Business Values in Cloud Computing", "comments": "8 pages, 6 figures, 6 tables, International Conference on Advances in\n  Cloud Computing (ACC12)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Realizing an optimal task scheduling by taking into account the business\nimportance of jobs has become a matter of interest in pay and use model of\nCloud computing. Introduction of an appropriate model for an efficient task\nscheduling technique could derive benefit to the service providers as well as\nclients. In this paper, we have addressed two major challenges which has\nimplications on the performance of the Cloud system. One of the major issues is\nhandling technical aspects of distributing the tasks for targeted gains and the\nsecond issue is related to the handling of the business priority for\nconcurrently resolving business complexity related to cloud consumers. A\ncoordinated scheduling can be achieved by considering the weightage of both\naspects viz. technical requirements and business requirements appropriately. It\ncan be done in such a way that it meets the QoS requirements of technical\ndomain as well as business domain. Along with the technical priority a business\nBp is required in creating a resultant priority which could be given to stages\nof further processing, like task allocation and arbitration schemes. Here we\nconsider a technical priority Tp that is governed by a semi-adaptive scheduling\nalgorithm whereas the resultant priority is derived in which a Business\nPriority Bp layer encapsulates the Technical Priority Tp to achieve the overall\npriority of the incoming tasks. It results in a Hybrid priority creation, which\nis a combination of both technical priority Tp and business priority Bp. By\ntaking into account the business priority of the jobs it is possible to achieve\na higher service level satisfaction for the tasks which are submitted with\ntheir native technical priority. With this approach the waiting time of the\ntasks tends to get reduced and it gives a better service level satisfaction.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jul 2014 18:28:55 GMT"}], "update_date": "2014-07-22", "authors_parsed": [["Sharma", "Vivek", ""], ["Nair", "T. R. Gopalakrishnan", ""]]}, {"id": "1407.5392", "submitter": "EPTCS", "authors": "Adri\\`a Gasc\\'on (SRI International), Ashish Tiwari (SRI\n  International)", "title": "Synthesis of a simple self-stabilizing system", "comments": "In Proceedings SYNT 2014, arXiv:1407.4937", "journal-ref": "EPTCS 157, 2014, pp. 5-16", "doi": "10.4204/EPTCS.157.5", "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing importance of distributed systems as a computing\nparadigm, a systematic approach to their design is needed. Although the area of\nformal verification has made enormous advances towards this goal, the resulting\nfunctionalities are limited to detecting problems in a particular design. By\nmeans of a classical example, we illustrate a simple template-based approach to\ncomputer-aided design of distributed systems based on leveraging the well-known\ntechnique of bounded model checking to the synthesis setting.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jul 2014 07:27:58 GMT"}], "update_date": "2014-07-22", "authors_parsed": [["Gasc\u00f3n", "Adri\u00e0", "", "SRI International"], ["Tiwari", "Ashish", "", "SRI\n  International"]]}, {"id": "1407.5404", "submitter": "T.R. Gopalakrishnan Nair", "authors": "A. Christy Persya, T.R. Gopalakrishnan Nair", "title": "Model based design of super schedulers managing catastrophic scenario in\n  hard real time systems", "comments": "7 pages, 4 figures,Information Communication and Embedded Systems\n  (ICICES), 2013, IEEE International Conference on, Chennai, India,\n  pp.1149,1155, 21-22 Feb. 2013", "journal-ref": null, "doi": "10.1109/ICICES.2013.6508316", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conventional design of real-time approaches depends heavily on the normal\nperformance of systems and it often becomes incapacitated in dealing with\ncatastrophic scenarios effectively. There are several investigations carried\nout to effectively tackle large scale catastrophe of a plant and how real-time\nsystems must reorganize itself to respond optimally to changing scenarios to\nreduce catastrophe and aid human intervention. The study presented here is in\nthis direction and the model accommodates catastrophe generated tasks while it\ntries to minimize the total number of deadline miss, by dynamically scheduling\nthe unusual pattern of tasks. The problem is NP hard. We prove the methods for\nan optimal scheduling algorithm. We also derive a model to maintain the\nstability of the processes. Moreover, we study the problem of minimizing the\nnumber of processors required for scheduling with a set of periodic and\nsporadic hard real time tasks with primary/backup mechanism to achieve fault\ntolerance. EDF scheduling algorithms are used on each processor to manage\nscenario changes. Finally we present a simulation of super scheduler with\nsmall, medium and large real time tasks pattern for catastrophe management.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jul 2014 07:52:42 GMT"}], "update_date": "2014-07-22", "authors_parsed": [["Persya", "A. Christy", ""], ["Nair", "T. R. Gopalakrishnan", ""]]}, {"id": "1407.5524", "submitter": "Edward Givelberg", "authors": "Edward Givelberg", "title": "Process-Oriented Parallel Programming with an Application to\n  Data-Intensive Computing", "comments": "20 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce process-oriented programming as a natural extension of\nobject-oriented programming for parallel computing. It is based on the\nobservation that every class of an object-oriented language can be instantiated\nas a process, accessible via a remote pointer. The introduction of process\npointers requires no syntax extension, identifies processes with programming\nobjects, and enables processes to exchange information simply by executing\nremote methods. Process-oriented programming is a high-level language\nalternative to multithreading, MPI and many other languages, environments and\ntools currently used for parallel computations. It implements natural\nobject-based parallelism using only minimal syntax extension of existing\nlanguages, such as C++ and Python, and has therefore the potential to lead to\nwidespread adoption of parallel programming. We implemented a prototype system\nfor running processes using C++ with MPI and used it to compute a large\nthree-dimensional Fourier transform on a computer cluster built of commodity\nhardware components. Three-dimensional Fourier transform is a prototype of a\ndata-intensive application with a complex data-access pattern. The\nprocess-oriented code is only a few hundred lines long, and attains very high\ndata throughput by achieving massive parallelism and maximizing hardware\nutilization.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jul 2014 15:16:37 GMT"}], "update_date": "2014-07-22", "authors_parsed": [["Givelberg", "Edward", ""]]}, {"id": "1407.5762", "submitter": "Graeme Smith", "authors": "Graeme Smith and J.W. Sanders and Qin Li", "title": "A macro-level model for investigating the effect of directional bias on\n  network coverage", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random walks have been proposed as a simple method of efficiently searching,\nor disseminating information throughout, communication and sensor networks. In\nnature, animals (such as ants) tend to follow correlated random walks, i.e.,\nrandom walks that are biased towards their current heading. In this paper, we\ninvestigate whether or not complementing random walks with directional bias can\ndecrease the expected discovery and coverage times in networks.\n  To do so, we develop a macro-level model of a directionally biased random\nwalk based on Markov chains. By focussing on regular, connected networks, the\nmodel allows us to efficiently calculate expected coverage times for different\nnetwork sizes and biases. Our analysis shows that directional bias can\nsignificantly reduce coverage time, but only when the bias is below a certain\nvalue which is dependent on the network size.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jul 2014 07:14:16 GMT"}, {"version": "v2", "created": "Mon, 2 Feb 2015 03:04:26 GMT"}], "update_date": "2015-02-03", "authors_parsed": [["Smith", "Graeme", ""], ["Sanders", "J. W.", ""], ["Li", "Qin", ""]]}, {"id": "1407.5917", "submitter": "Giovanni Viglietta", "authors": "Paola Flocchini, Giuseppe Prencipe, Nicola Santoro, Giovanni Viglietta", "title": "Distributed Computing by Mobile Robots: Uniform Circle Formation", "comments": "78 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a set of $n$ simple autonomous mobile robots (asynchronous, no\ncommon coordinate system, no identities, no central coordination, no direct\ncommunication, no memory of the past, non-rigid, deterministic) initially in\ndistinct locations, moving freely in the plane and able to sense the positions\nof the other robots. We study the primitive task of the robots arranging\nthemselves on the vertices of a regular $n$-gon not fixed in advance (Uniform\nCircle Formation). In the literature, the existing algorithmic contributions\nare limited to conveniently restricted sets of initial configurations of the\nrobots and to more powerful robots. The question of whether such simple robots\ncould deterministically form a uniform circle has remained open. In this paper,\nwe constructively prove that indeed the Uniform Circle Formation problem is\nsolvable for any initial configuration in which the robots are in distinct\nlocations, without any additional assumption (if two robots are in the same\nlocation, the problem is easily seen to be unsolvable). In addition to closing\na long-standing problem, the result of this paper also implies that, for\npattern formation, asynchrony is not a computational handicap, and that\nadditional powers such as chirality and rigidity are computationally\nirrelevant.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jul 2014 16:07:00 GMT"}, {"version": "v2", "created": "Mon, 8 Sep 2014 20:53:23 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2015 11:37:57 GMT"}, {"version": "v4", "created": "Sat, 12 Dec 2015 14:51:37 GMT"}, {"version": "v5", "created": "Mon, 12 Sep 2016 07:55:31 GMT"}, {"version": "v6", "created": "Wed, 29 Mar 2017 00:19:02 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Flocchini", "Paola", ""], ["Prencipe", "Giuseppe", ""], ["Santoro", "Nicola", ""], ["Viglietta", "Giovanni", ""]]}, {"id": "1407.6153", "submitter": "Robert Obryk", "authors": "Robert Obryk", "title": "Write-and-f-array: implementation and an application", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new shared memory object: the write-and-f-array, provide its\nwait-free implementation and use it to construct an improved wait-free\nimplementation of the fetch-and-add object. The write-and-f-array generalizes\nsingle-writer write-and-snapshot object in a similar way that the f-array\ngeneralizes the multi-writer snapshot object. More specifically, a\nwrite-and-f-array is parameterized by an associative operator $f$ and is\nconceptually an array with two atomic operations:\n  - write-and-f modifies a single array's element and returns the result of\napplying $f$ to all the elements,\n  - read returns the result of applying $f$ to all the array's elements.\n  We provide a wait-free implementation of an $N$-element write-and-f-array\nwith $O(N \\log N)$ memory complexity, $O(\\log^3 N)$ step complexity of the\nwrite-and-f operation and $O(1)$ step complexity of the read operation. The\nimplementation uses CAS objects and requires their size to be $\\Omega(\\log M)$,\nwhere $M$ is the total number of write-and-f operations executed. We also show,\nhow it can be modified to achieve $O(\\log^2 N)$ step complexity of write-and-f,\nwhile increasing the memory complexity to $O(N \\log^2 N)$.\n  The write-and-f-array can be applied to create a fetch-and-add object for $P$\nprocesses with $O(P \\log P)$ memory complexity and $O(\\log^3 P)$ step\ncomplexity of the fetch-and-add operation. This is the first implementation of\nfetch-and-add with polylogarithmic step complexity and subquadratic memory\ncomplexity that can be implemented without CAS or LL/SC objects of unrealistic\nsize.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jul 2014 09:47:57 GMT"}], "update_date": "2014-07-24", "authors_parsed": [["Obryk", "Robert", ""]]}, {"id": "1407.6295", "submitter": "Xavier Vila\\c{c}a", "authors": "Xavier Vilaca and Luis Rodrigues", "title": "On the Range of Equilibria Utilities of a Repeated Epidemic\n  Dissemination Game with a Mediator", "comments": "14 pages, 2 algorithms, accepted in ICDCN'15, proofs of D4 and D5\n  improved, improved definition of Non-disclosure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider eager-push epidemic dissemination in a complete graph. Time is\ndivided into synchronous stages. In each stage, a source disseminates $\\nu$\nevents. Each event is sent by the source, and forwarded by each node upon its\nfirst reception, to $f$ nodes selected uniformly at random, where $f$ is the\nfanout. We use Game Theory to study the range of $f$ for which equilibria\nstrategies exist, assuming that players are either rational or obedient to the\nprotocol, and that they do not collude. We model interactions as an infinitely\nrepeated game. We devise a monitoring mechanism that extends the repeated game\nwith communication rounds used for exchanging monitoring information, and\ndefine strategies for this extended game. We assume the existence of a trusted\nmediator, that players are computationally bounded such that they cannot break\nthe cryptographic primitives used in our mechanism, and that symmetric\nciphering is cheap. Under these assumptions, we show that, if the size of the\nstream is sufficiently large and players attribute enough value to future\nutilities, then the defined strategies are Sequential Equilibria of the\nextended game for any value of $f$. Moreover, the utility provided to each\nplayer is arbitrarily close to that provided in the original game. This shows\nthat we can persuade rational nodes to follow a dissemination protocol that\nuses any fanout, while arbitrarily minimising the relative overhead of\nmonitoring.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jul 2014 17:02:58 GMT"}, {"version": "v2", "created": "Mon, 28 Jul 2014 09:07:38 GMT"}, {"version": "v3", "created": "Sun, 19 Oct 2014 19:03:07 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["Vilaca", "Xavier", ""], ["Rodrigues", "Luis", ""]]}, {"id": "1407.6317", "submitter": "Srinivasa Rao Ch.", "authors": "Ch.Srinivasa Rao, B. Raveendra Babu", "title": "A Fuzzy Differential Evolution Algorithm for Job Scheduling on\n  Computational Grids", "comments": "6 pages, 9 figures", "journal-ref": null, "doi": "10.14445/22312803/IJCTT-V13P116", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grid computing is the recently growing area of computing that share data,\nstorage, computing across geographically dispersed area. This paper proposes a\nnovel fuzzy approach using Differential Evolution (DE) for scheduling jobs on\ncomputational grids. The fuzzy based DE generates an optimal plan to complete\nthe jobs within a minimum period of time. We evaluate the performance of the\nproposed fuzzy based DE algorithm with Genetic Algorithm (GA), Simulated\nAnnealing (SA), Differential Evolution and fuzzy PSO. Experimental results have\nshown that the new algorithm produces more optimal solutions for the job\nscheduling problems compared to other algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jul 2014 18:08:25 GMT"}], "update_date": "2014-07-24", "authors_parsed": [["Rao", "Ch. Srinivasa", ""], ["Babu", "B. Raveendra", ""]]}, {"id": "1407.6470", "submitter": "Gabriele D'Angelo", "authors": "Gabriele D'Angelo, Moreno Marzolla", "title": "New Trends in Parallel and Distributed Simulation: from Many-Cores to\n  Cloud Computing", "comments": "Simulation Modelling Practice and Theory (SIMPAT), Elsevier, vol. 49\n  (December 2014)", "journal-ref": null, "doi": "10.1016/j.simpat.2014.06.007", "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in computing architectures and networking are bringing\nparallel computing systems to the masses so increasing the number of potential\nusers of these kinds of systems. In particular, two important technological\nevolutions are happening at the ends of the computing spectrum: at the \"small\"\nscale, processors now include an increasing number of independent execution\nunits (cores), at the point that a mere CPU can be considered a parallel\nshared-memory computer; at the \"large\" scale, the Cloud Computing paradigm\nallows applications to scale by offering resources from a large pool on a\npay-as-you-go model. Multi-core processors and Clouds both require applications\nto be suitably modified to take advantage of the features they provide. In this\npaper, we analyze the state of the art of parallel and distributed simulation\ntechniques, and assess their applicability to multi-core architectures or\nClouds. It turns out that most of the current approaches exhibit limitations in\nterms of usability and adaptivity which may hinder their application to these\nnew computing architectures. We propose an adaptive simulation mechanism, based\non the multi-agent system paradigm, to partially address some of those\nlimitations. While it is unlikely that a single approach will work well on both\nsettings above, we argue that the proposed adaptive mechanism has useful\nfeatures which make it attractive both in a multi-core processor and in a Cloud\nsystem. These features include the ability to reduce communication costs by\nmigrating simulation components, and the support for adding (or removing) nodes\nto the execution architecture at runtime. We will also show that, with the help\nof an additional support layer, parallel and distributed simulations can be\nexecuted on top of unreliable resources.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jul 2014 07:05:38 GMT"}, {"version": "v2", "created": "Tue, 4 Apr 2017 14:12:19 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["D'Angelo", "Gabriele", ""], ["Marzolla", "Moreno", ""]]}, {"id": "1407.6486", "submitter": "Daniel Ruprecht", "authors": "Michael Minion, Robert Speck, Matthias Bolten, Matthew Emmett, Daniel\n  Ruprecht", "title": "Interweaving PFASST and Parallel Multigrid", "comments": null, "journal-ref": "SIAM Journal on Scientific Computing 37(5), pp. S244-S263, 2015", "doi": "10.1137/14097536X", "report-no": null, "categories": "math.NA cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The parallel full approximation scheme in space and time (PFASST) introduced\nby Emmett and Minion in 2012 is an iterative strategy for the temporal\nparallelization of ODEs and discretized PDEs. As the name suggests, PFASST is\nsimilar in spirit to a space-time FAS multigrid method performed over multiple\ntime-steps in parallel. However, since the original focus of PFASST has been on\nthe performance of the method in terms of time parallelism, the solution of any\nspatial system arising from the use of implicit or semi-implicit temporal\nmethods within PFASST have simply been assumed to be solved to some desired\naccuracy completely at each sub-step and each iteration by some unspecified\nprocedure. It hence is natural to investigate how iterative solvers in the\nspatial dimensions can be interwoven with the PFASST iterations and whether\nthis strategy leads to a more efficient overall approach. This paper presents\nan initial investigation on the relative performance of different strategies\nfor coupling PFASST iterations with multigrid methods for the implicit\ntreatment of diffusion terms in PDEs. In particular, we compare full accuracy\nmultigrid solves at each sub-step with a small fixed number of multigrid\nV-cycles. This reduces the cost of each PFASST iteration at the possible\nexpense of a corresponding increase in the number of PFASST iterations needed\nfor convergence. Parallel efficiency of the resulting methods is explored\nthrough numerical examples.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jul 2014 08:38:07 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2015 12:39:33 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Minion", "Michael", ""], ["Speck", "Robert", ""], ["Bolten", "Matthias", ""], ["Emmett", "Matthew", ""], ["Ruprecht", "Daniel", ""]]}, {"id": "1407.6603", "submitter": "Zaid Alyasseri", "authors": "Zaid Abdi Alkareem Alyasseri, Kadhim Al-Attar, Mazin Nasser (ISMAIL)", "title": "Parallelize Bubble Sort Algorithm Using OpenMP", "comments": "4 pages, 5 firgyes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sorting has been a profound area for the algorithmic researchers and many\nresources are invested to suggest more works for sorting algorithms. For this\npurpose, many existing sorting algorithms were observed in terms of the\nefficiency of the algorithmic complexity. In this paper we implemented the\nbubble sort algorithm using multithreading (OpenMP). The proposed work tested\non two standard datasets (text file) with different size . The main idea of the\nproposed algorithm is distributing the elements of the input datasets into many\nadditional temporary sub-arrays according to a number of characters in each\nword. The sizes of each of these sub-arrays are decided depending on a number\nof elements with the same number of characters in the input array. We\nimplemented OpenMP using Intel core i7-3610QM ,(8 CPUs),using two approaches\n(vectors of string and array 3D) . Finally, we get the data structure effects\non the performance of the algorithm for that we choice the second approach.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jul 2014 14:47:48 GMT"}], "update_date": "2014-07-25", "authors_parsed": [["Alyasseri", "Zaid Abdi Alkareem", "", "ISMAIL"], ["Al-Attar", "Kadhim", "", "ISMAIL"], ["Nasser", "Mazin", "", "ISMAIL"]]}, {"id": "1407.6745", "submitter": "Erik Saule", "authors": "Ahmet Erdem Sar{\\i}y\\\"uce and Erik Saule and \\\"Umit V.\n  \\c{C}ataly\\\"urek", "title": "On Distributed Graph Coloring with Iterative Recoloring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying the sets of operations that can be executed simultaneously is an\nimportant problem appearing in many parallel applications. By modeling the\noperations and their interactions as a graph, one can identify the independent\noperations by solving a graph coloring problem. Many efficient sequential\nalgorithms are known for this NP-Complete problem, but they are typically\nunsuitable when the operations and their interactions are distributed in the\nmemory of large parallel computers. On top of an existing distributed-memory\ngraph coloring algorithm, we investigate two compatible techniques in this\npaper for fast and scalable distributed-memory graph coloring. First, we\nintroduce an improvement for the distributed post-processing operation, called\nrecoloring, which drastically improves the number of colors. We propose a novel\nand efficient communication scheme for recoloring which enables it to scale\ngracefully. Recoloring must be seeded with an existing coloring of the graph.\nOur second contribution is to introduce a randomized color selection strategy\nfor initial coloring which quickly produces solutions of modest quality. We\nextensively evaluate the impact of our new techniques on existing distributed\nalgorithms and show the time-quality tradeoffs. We show that combining an\ninitial randomized coloring with multiple recoloring iterations yields better\nquality solutions with the smaller runtime at large scale.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jul 2014 22:02:53 GMT"}], "update_date": "2014-07-28", "authors_parsed": [["Sar\u0131y\u00fcce", "Ahmet Erdem", ""], ["Saule", "Erik", ""], ["\u00c7ataly\u00fcrek", "\u00dcmit V.", ""]]}, {"id": "1407.6876", "submitter": "Srivatsan Ravi Mr", "authors": "Petr Kuznetsov and Srivatsan Ravi", "title": "On Partial Wait-Freedom in Transactional Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transactional memory (TM) is a convenient synchronization tool that allows\nconcurrent threads to declare sequences of instructions on shared data as\nspeculative \\emph{transactions} with \"all-or-nothing\" semantics. It is known\nthat dynamic transactional memory cannot provide \\emph{wait-free} progress in\nthe sense that every transaction commits in a finite number of its own steps.\nIn this paper, we explore the costs of providing wait-freedom to only a\n\\emph{subset} of transactions. Since most transactional workloads are believed\nto be read-dominated, we require that read-only transactions commit in the\nwait-free manner, while updating transactions are guaranteed to commit only if\nthey run in the absence of concurrency. We show that this kind of partial\nwait-freedom, combined with attractive requirements like read invisibility or\ndisjoint-access parallelism, incurs considerable complexity costs.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jul 2014 12:52:59 GMT"}, {"version": "v2", "created": "Fri, 15 Aug 2014 15:24:09 GMT"}], "update_date": "2014-08-18", "authors_parsed": [["Kuznetsov", "Petr", ""], ["Ravi", "Srivatsan", ""]]}, {"id": "1407.6878", "submitter": "Zaid Alyasseri", "authors": "Zaid Abdi Alkareem Alyasseri", "title": "Survey of Parallel Computing with MATLAB", "comments": "9 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matlab is one of the most widely used mathematical computing environments in\ntechnical computing. It has an interactive environment which provides high\nperformance computing (HPC) procedures and easy to use. Parallel computing with\nMatlab has been an interested area for scientists of parallel computing\nresearches for a number of years. Where there are many attempts to parallel\nMatlab. In this paper, we present most of the past,present attempts of parallel\nMatlab such as MatlabMPI, bcMPI, pMatlab, Star-P and PCT. Finally, we expect\nthe future attempts.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jul 2014 12:59:26 GMT"}], "update_date": "2014-07-28", "authors_parsed": [["Alyasseri", "Zaid Abdi Alkareem", ""]]}, {"id": "1407.6915", "submitter": "Brad Rees", "authors": "Rostislav Tsiomenko and Bradley S. Rees", "title": "Accelerating Fast Fourier Transforms Using Hadoop and CUDA", "comments": "6 pages Was submitted to ICDCS 2013 but not accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been considerable research into improving Fast Fourier Transform\n(FFT) performance through parallelization and optimization for specialized\nhardware. However, even with those advancements, processing of very large\nfiles, over 1TB in size, still remains prohibitively slow. Analysts performing\nsignal processing are forced to wait hours or days for results, which results\nin a disruption of their workflow and a decrease in productivity. In this paper\nwe present a unique approach that not only parallelizes the workload over\nmulti-cores, but distributes the problem over a cluster of graphics processing\nunit (GPU)-equipped servers. By utilizing Hadoop and CUDA, we can take\nadvantage of inexpensive servers while still exceeding the processing power of\na dedicated supercomputer, as demonstrated in our result using Amazon EC2.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jul 2014 14:25:35 GMT"}], "update_date": "2014-07-28", "authors_parsed": [["Tsiomenko", "Rostislav", ""], ["Rees", "Bradley S.", ""]]}, {"id": "1407.6932", "submitter": "Albert Saa-Garriga", "authors": "Albert Sa\\`a-Garriga, David Castells-Rufas, Jordi Carrabina", "title": "OMP2HMPP: HMPP Source Code Generation from Programs with Pragma\n  Extensions", "comments": "Proceedings of HIP3ES Workshop, Vienna, January, 21st 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-performance computing are based more and more in heterogeneous\narchitectures and GPGPUs have become one of the main integrated blocks in\nthese, as the recently emerged Mali GPU in embedded systems or the NVIDIA GPUs\nin HPC servers. In both GPGPUs, programming could become a hurdle that can\nlimit their adoption, since the programmer has to learn the hardware\ncapabilities and the language to work with these. We present OMP2HMPP, a tool\nthat, automatically trans-lates a high-level C source code(OpenMP) code into\nHMPP. The generated version rarely will differs from a hand-coded HMPP version,\nand will provide an important speedup, near 113%, that could be later improved\nby hand-coded CUDA. The generated code could be transported either to HPC\nservers and to embedded GPUs, due to the commonalities between them.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jul 2014 15:14:08 GMT"}], "update_date": "2014-07-28", "authors_parsed": [["Sa\u00e0-Garriga", "Albert", ""], ["Castells-Rufas", "David", ""], ["Carrabina", "Jordi", ""]]}, {"id": "1407.6954", "submitter": "Robert Kl\\\"ofkorn", "authors": "Martin Alk\\\"amper, Andreas Dedner, Robert Kl\\\"ofkorn, and Martin Nolte", "title": "The DUNE-ALUGrid Module", "comments": "25 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the new DUNE-ALUGrid module. This module contains a\nmajor overhaul of the sources from the ALUgrid library and the binding to the\nDUNE software framework. The main changes include user defined load balancing,\nparallel grid construction, and an redesign of the 2d grid which can now also\nbe used for parallel computations. In addition many improvements have been\nintroduced into the code to increase the parallel efficiency and to decrease\nthe memory footprint.\n  The original ALUGrid library is widely used within the DUNE community due to\nits good parallel performance for problems requiring local adaptivity and\ndynamic load balancing. Therefore, this new model will benefit a number of DUNE\nusers. In addition we have added features to increase the range of problems for\nwhich the grid manager can be used, for example, introducing a 3d tetrahedral\ngrid using a parallel newest vertex bisection algorithm for conforming grid\nrefinement. In this paper we will discuss the new features, extensions to the\nDUNE interface, and explain for various examples how the code is used in\nparallel environments.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jul 2014 16:12:26 GMT"}, {"version": "v2", "created": "Wed, 30 Jul 2014 08:02:59 GMT"}, {"version": "v3", "created": "Sat, 15 Aug 2015 11:23:22 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Alk\u00e4mper", "Martin", ""], ["Dedner", "Andreas", ""], ["Kl\u00f6fkorn", "Robert", ""], ["Nolte", "Martin", ""]]}, {"id": "1407.7061", "submitter": "Ciaran McCreesh", "authors": "Ciaran McCreesh and Patrick Prosser", "title": "A Parallel Branch and Bound Algorithm for the Maximum Labelled Clique\n  Problem", "comments": "Author-final version. Accepted to Optimization Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The maximum labelled clique problem is a variant of the maximum clique\nproblem where edges in the graph are given labels, and we are not allowed to\nuse more than a certain number of distinct labels in a solution. We introduce a\nnew branch-and-bound algorithm for the problem, and explain how it may be\nparallelised. We evaluate an implementation on a set of benchmark instances,\nand show that it is consistently faster than previously published results,\nsometimes by four or five orders of magnitude.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jul 2014 21:11:13 GMT"}, {"version": "v2", "created": "Mon, 17 Nov 2014 14:46:09 GMT"}], "update_date": "2014-11-18", "authors_parsed": [["McCreesh", "Ciaran", ""], ["Prosser", "Patrick", ""]]}, {"id": "1407.7360", "submitter": "Chi Zhou", "authors": "Amelie Chi Zhou, Bingsheng He and Shadi Ibrahim", "title": "A Taxonomy and Survey on eScience as a Service in the Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing has recently evolved as a popular computing infrastructure\nfor many applications. Scientific computing, which was mainly hosted in private\nclusters and grids, has started to migrate development and deployment to the\npublic cloud environment. eScience as a service becomes an emerging and\npromising direction for science computing. We review recent efforts in\ndeveloping and deploying scientific computing applications in the cloud. In\nparticular, we introduce a taxonomy specifically designed for scientific\ncomputing in the cloud, and further review the taxonomy with four major kinds\nof science applications, including life sciences, physics sciences, social and\nhumanities sciences, and climate and earth sciences. Our major finding is that,\ndespite existing efforts in developing cloud-based eScience, eScience still has\na long way to go to fully unlock the power of cloud computing paradigm.\nTherefore, we present the challenges and opportunities in the future\ndevelopment of cloud-based eScience services, and call for collaborations and\ninnovations from both the scientific and computer system communities to address\nthose challenges.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jul 2014 09:14:35 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Zhou", "Amelie Chi", ""], ["He", "Bingsheng", ""], ["Ibrahim", "Shadi", ""]]}, {"id": "1407.7448", "submitter": "Heechul Yun", "authors": "Heechul Yun", "title": "Parallelism-Aware Memory Interference Delay Analysis for COTS Multicore\n  Systems", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern Commercial Off-The-Shelf (COTS) multicore systems, each core can\ngenerate many parallel memory requests at a time. The processing of these\nparallel requests in the DRAM controller greatly affects the memory\ninterference delay experienced by running tasks on the platform. In this paper,\nwe model a modern COTS multicore system which has a nonblocking last-level\ncache (LLC) and a DRAM controller that prioritizes reads over writes. To\nminimize interference, we focus on LLC and DRAM bank partitioned systems. Based\non the model, we propose an analysis that computes a safe upper bound for the\nworst-case memory interference delay. We validated our analysis on a real COTS\nmulticore platform with a set of carefully designed synthetic benchmarks as\nwell as SPEC2006 benchmarks. Evaluation results show that our analysis is more\naccurately capture the worst-case memory interference delay and provides safer\nupper bounds compared to a recently proposed analysis which significantly\nunder-estimate the delay.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jul 2014 08:43:36 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Yun", "Heechul", ""]]}, {"id": "1407.7468", "submitter": "Divjyot Sethi", "authors": "Divjyot Sethi, Muralidhar Talupur, Sharad Malik", "title": "Using Flow Specifications of Parameterized Cache Coherence Protocols for\n  Verifying Deadlock Freedom", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of verifying deadlock freedom for symmetric cache\ncoherence protocols. In particular, we focus on a specific form of deadlock\nwhich is useful for the cache coherence protocol domain and consistent with the\ninternal definition of deadlock in the Murphi model checker: we refer to this\ndeadlock as a system- wide deadlock (s-deadlock). In s-deadlock, the entire\nsystem gets blocked and is unable to make any transition. Cache coherence\nprotocols consist of N symmetric cache agents, where N is an unbounded\nparameter; thus the verification of s-deadlock freedom is naturally a\nparameterized verification problem. Parametrized verification techniques work\nby using sound abstractions to reduce the unbounded model to a bounded model.\nEfficient abstractions which work well for industrial scale protocols typically\nbound the model by replacing the state of most of the agents by an abstract\nenvironment, while keeping just one or two agents as is. However, leveraging\nsuch efficient abstractions becomes a challenge for s-deadlock: a violation of\ns-deadlock is a state in which the transitions of all of the unbounded number\nof agents cannot occur and so a simple abstraction like the one above will not\npreserve this violation. In this work we address this challenge by presenting a\ntechnique which leverages high-level information about the protocols, in the\nform of message sequence dia- grams referred to as flows, for constructing\ninvariants that are collectively stronger than s-deadlock. Efficient\nabstractions can be constructed to verify these invariants. We successfully\nverify the German and Flash protocols using our technique.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jul 2014 16:51:38 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Sethi", "Divjyot", ""], ["Talupur", "Muralidhar", ""], ["Malik", "Sharad", ""]]}, {"id": "1407.7882", "submitter": "Moti Medina", "authors": "Guy Even, Moti Medina, and Dana Ron", "title": "Distributed Maximum Matching in Bounded Degree Graphs", "comments": "arXiv admin note: substantial text overlap with arXiv:1402.3796", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present deterministic distributed algorithms for computing approximate\nmaximum cardinality matchings and approximate maximum weight matchings. Our\nalgorithm for the unweighted case computes a matching whose size is at least\n$(1-\\eps)$ times the optimal in $\\Delta^{O(1/\\eps)} +\nO\\left(\\frac{1}{\\eps^2}\\right) \\cdot\\log^*(n)$ rounds where $n$ is the number\nof vertices in the graph and $\\Delta$ is the maximum degree. Our algorithm for\nthe edge-weighted case computes a matching whose weight is at least $(1-\\eps)$\ntimes the optimal in\n$\\log(\\min\\{1/\\wmin,n/\\eps\\})^{O(1/\\eps)}\\cdot(\\Delta^{O(1/\\eps)}+\\log^*(n))$\nrounds for edge-weights in $[\\wmin,1]$.\n  The best previous algorithms for both the unweighted case and the weighted\ncase are by Lotker, Patt-Shamir, and Pettie~(SPAA 2008). For the unweighted\ncase they give a randomized $(1-\\eps)$-approximation algorithm that runs in\n$O((\\log(n)) /\\eps^3)$ rounds. For the weighted case they give a randomized\n$(1/2-\\eps)$-approximation algorithm that runs in $O(\\log(\\eps^{-1}) \\cdot\n\\log(n))$ rounds. Hence, our results improve on the previous ones when the\nparameters $\\Delta$, $\\eps$ and $\\wmin$ are constants (where we reduce the\nnumber of runs from $O(\\log(n))$ to $O(\\log^*(n))$), and more generally when\n$\\Delta$, $1/\\eps$ and $1/\\wmin$ are sufficiently slowly increasing functions\nof $n$. Moreover, our algorithms are deterministic rather than randomized.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jul 2014 20:42:30 GMT"}, {"version": "v2", "created": "Mon, 4 Aug 2014 06:35:50 GMT"}, {"version": "v3", "created": "Tue, 11 Nov 2014 20:57:53 GMT"}], "update_date": "2014-11-12", "authors_parsed": [["Even", "Guy", ""], ["Medina", "Moti", ""], ["Ron", "Dana", ""]]}, {"id": "1407.7931", "submitter": "EPTCS", "authors": "Giorgio Delzanno (University of Genoa), Arend Rensink (University of\n  Twente), Riccardo Traverso (University of Genoa / FBK-irst)", "title": "Graph- versus Vector-Based Analysis of a Consensus Protocol", "comments": "In Proceedings GRAPHITE 2014, arXiv:1407.7671", "journal-ref": "EPTCS 159, 2014, pp. 44-57", "doi": "10.4204/EPTCS.159.5", "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Paxos distributed consensus algorithm is a challenging case-study for\nstandard, vector-based model checking techniques. Due to asynchronous\ncommunication, exhaustive analysis may generate very large state spaces already\nfor small model instances. In this paper, we show the advantages of graph\ntransformation as an alternative modelling technique. We model Paxos in a rich\ndeclarative transformation language, featuring (among other things) nested\nquantifiers, and we validate our model using the GROOVE model checker, a\ngraph-based tool that exploits isomorphism as a natural way to prune the state\nspace via symmetry reductions. We compare the results with those obtained by\nthe standard model checker Spin on the basis of a vector-based encoding of the\nalgorithm.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jul 2014 03:23:07 GMT"}], "update_date": "2014-07-31", "authors_parsed": [["Delzanno", "Giorgio", "", "University of Genoa"], ["Rensink", "Arend", "", "University of\n  Twente"], ["Traverso", "Riccardo", "", "University of Genoa / FBK-irst"]]}, {"id": "1407.8116", "submitter": "Danny Price", "authors": "D. C. Price, M. A. Clark, B. R. Barsdell, R. Babich, L. J. Greenhill", "title": "Optimizing performance per watt on GPUs in High Performance Computing:\n  temperature, frequency and voltage effects", "comments": "In Computer Science - Research and Development special issue on\n  Energy-Aware High-Performance Computing. The final publication is available\n  at Springer via http://dx.doi.org/10.1007/s00450-015-0300-5", "journal-ref": null, "doi": "10.1007/s00450-015-0300-5", "report-no": null, "categories": "astro-ph.IM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The magnitude of the real-time digital signal processing challenge attached\nto large radio astronomical antenna arrays motivates use of high performance\ncomputing (HPC) systems. The need for high power efficiency (performance per\nwatt) at remote observatory sites parallels that in HPC broadly, where\nefficiency is an emerging critical metric. We investigate how the performance\nper watt of graphics processing units (GPUs) is affected by temperature, core\nclock frequency and voltage. Our results highlight how the underlying physical\nprocesses that govern transistor operation affect power efficiency. In\nparticular, we show experimentally that GPU power consumption grows\nnon-linearly with both temperature and supply voltage, as predicted by physical\ntransistor models. We show lowering GPU supply voltage and increasing clock\nfrequency while maintaining a low die temperature increases the power\nefficiency of an NVIDIA K20 GPU by up to 37-48% over default settings when\nrunning xGPU, a compute-bound code used in radio astronomy. We discuss how\ntemperature-aware power models could be used to reduce power consumption for\nfuture HPC installations. Automatic temperature-aware and application-dependent\nvoltage and frequency scaling (T-DVFS and A-DVFS) may provide a mechanism to\nachieve better power efficiency for a wider range of codes running on GPUs\n", "versions": [{"version": "v1", "created": "Wed, 30 Jul 2014 16:22:22 GMT"}, {"version": "v2", "created": "Thu, 14 Aug 2014 17:23:51 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2015 15:41:30 GMT"}], "update_date": "2015-10-21", "authors_parsed": [["Price", "D. C.", ""], ["Clark", "M. A.", ""], ["Barsdell", "B. R.", ""], ["Babich", "R.", ""], ["Greenhill", "L. J.", ""]]}, {"id": "1407.8142", "submitter": "Julian Shun", "authors": "Julian Shun", "title": "Parallel Wavelet Tree Construction", "comments": "This is a longer version of the paper that appears in the Proceedings\n  of the IEEE Data Compression Conference, 2015", "journal-ref": null, "doi": "10.1109/DCC.2015.7", "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present parallel algorithms for wavelet tree construction with\npolylogarithmic depth, improving upon the linear depth of the recent parallel\nalgorithms by Fuentes-Sepulveda et al. We experimentally show on a 40-core\nmachine with two-way hyper-threading that we outperform the existing parallel\nalgorithms by 1.3--5.6x and achieve up to 27x speedup over the sequential\nalgorithm on a variety of real-world and artificial inputs. Our algorithms show\ngood scalability with increasing thread count, input size and alphabet size. We\nalso discuss extensions to variants of the standard wavelet tree.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jul 2014 17:55:42 GMT"}, {"version": "v2", "created": "Tue, 19 Aug 2014 03:32:05 GMT"}, {"version": "v3", "created": "Sun, 24 Aug 2014 02:36:08 GMT"}, {"version": "v4", "created": "Tue, 13 Jan 2015 21:00:53 GMT"}, {"version": "v5", "created": "Fri, 13 Mar 2015 15:02:26 GMT"}, {"version": "v6", "created": "Tue, 17 Mar 2015 07:21:11 GMT"}, {"version": "v7", "created": "Wed, 1 Apr 2015 06:28:14 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Shun", "Julian", ""]]}, {"id": "1407.8168", "submitter": "Elizabeth Michel", "authors": "Daniel Kimball, Elizabeth Michel, Paul Keltcher, and Michael M. Wolf", "title": "Quantifying the Effect of Matrix Structure on Multithreaded Performance\n  of the SpMV Kernel", "comments": "6 pages, 7 figures. IEEE HPEC 2014", "journal-ref": null, "doi": "10.1109/HPEC.2014.7040991", "report-no": null, "categories": "cs.DC cs.NA cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse matrix-vector multiplication (SpMV) is the core operation in many\ncommon network and graph analytics, but poor performance of the SpMV kernel\nhandicaps these applications. This work quantifies the effect of matrix\nstructure on SpMV performance, using Intel's VTune tool for the Sandy Bridge\narchitecture. Two types of sparse matrices are considered: finite difference\n(FD) matrices, which are structured, and R-MAT matrices, which are\nunstructured. Analysis of cache behavior and prefetcher activity reveals that\nthe SpMV kernel performs far worse with R-MAT matrices than with FD matrices,\ndue to the difference in matrix structure. To address the problems caused by\nunstructured matrices, novel architecture improvements are proposed.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jul 2014 19:37:10 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Kimball", "Daniel", ""], ["Michel", "Elizabeth", ""], ["Keltcher", "Paul", ""], ["Wolf", "Michael M.", ""]]}, {"id": "1407.8433", "submitter": "Christoph Lenzen", "authors": "Pierre Bertrand and Christoph Lenzen", "title": "The 1-2-3-Toolkit for Building Your Own Balls-into-Bins Algorithm", "comments": "brief announcement appears at DISC 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we examine a generic class of simple distributed\nballs-into-bins algorithms. Exploiting the strong concentration bounds that\napply to balls-into-bins games, we provide an iterative method to compute\naccurate estimates of the remaining balls and the load distribution after each\nround. Each algorithm is classified by (i) the load that bins accept in a given\nround, (ii) the number of messages each ball sends in a given round, and (iii)\nwhether each such message is given a rank expressing the sender's inclination\nto commit to the receiving bin (if feasible). This novel ranking mechanism\nresults in notable improvements, in particular in the number of balls that may\ncommit to a bin in the first round of the algorithm. Simulations independently\nverify the correctness of the results and confirm that our approximation is\nhighly accurate even for a moderate number of $10^6$ balls and bins.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jul 2014 14:27:10 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["Bertrand", "Pierre", ""], ["Lenzen", "Christoph", ""]]}, {"id": "1407.8546", "submitter": "Filipe Campos", "authors": "Filipe Campos and Jos\\'e Pereira", "title": "Improving the Scalability of DPWS-Based Networked Infrastructures", "comments": "28 pages, Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Devices Profile for Web Services (DPWS) specification enables seamless\ndiscovery, configuration, and interoperability of networked devices in various\nsettings, ranging from home automation and multimedia to manufacturing\nequipment and data centers. Unfortunately, the sheer simplicity of event\nnotification mechanisms that makes it fit for resource-constrained devices,\nmakes it hard to scale to large infrastructures with more stringent\ndependability requirements, ironically, where self-configuration would be most\nuseful. In this report, we address this challenge with a proposal to integrate\ngossip-based dissemination in DPWS, thus maintaining compatibility with\noriginal assumptions of the specification, and avoiding a centralized\nconfiguration server or custom black-box middleware components. In detail, we\nshow how our approach provides an evolutionary and non-intrusive solution to\nthe scalability limitations of DPWS and experimentally evaluate it with an\nimplementation based on the the Web Services for Devices (WS4D) Java Multi\nEdition DPWS Stack (JMEDS).\n", "versions": [{"version": "v1", "created": "Thu, 31 Jul 2014 19:57:35 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["Campos", "Filipe", ""], ["Pereira", "Jos\u00e9", ""]]}]