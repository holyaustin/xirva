[{"id": "2007.00033", "submitter": "Yanhong Xu", "authors": "Yanhong Xu, Reihaneh Safavi-Naini, Khoa Nguyen, Huaxiong Wang", "title": "Traceable Policy-Based Signatures and Instantiation from Lattices", "comments": "37 pages,5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy-based signatures (PBS) were proposed by Bellare and Fuchsbauer (PKC\n2014) to allow an {\\em authorized} member of an organization to sign a message\non behalf of the organization. The user's authorization is determined by a\npolicy managed by the organization's trusted authority, while the signature\npreserves the privacy of the organization's policy. Signing keys in PBS do not\ninclude user identity information and thus can be passed to others, violating\nthe intention of employing PBS to restrict users' signing capability.\n  In this paper, we introduce the notion of {\\em traceability} for PBS by\nincluding user identity in the signing key such that the trusted authority will\nbe able to open a suspicious signature and recover the signer's identity should\nthe needs arise. We provide rigorous definitions and stringent security notions\nof traceable PBS (TPBS), capturing the properties of PBS suggested by\nBellare-Fuchsbauer and resembling the \"full traceability\" requirement for group\nsignatures put forward by Bellare-Micciancio-Warinschi (Eurocrypt 2003). As a\nproof of concept, we provide a modular construction of TPBS, based on a\nsignature scheme, an encryption scheme and a zero-knowledge proof system.\nFurthermore, to demonstrate the feasibility of achieving TPBS from concrete,\nquantum-resistant assumptions, we give an instantiation based on lattices.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 18:03:01 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Xu", "Yanhong", ""], ["Safavi-Naini", "Reihaneh", ""], ["Nguyen", "Khoa", ""], ["Wang", "Huaxiong", ""]]}, {"id": "2007.00059", "submitter": "Asaf Shabtai", "authors": "Noam Moscovich, Ron Bitton, Yakov Mallah, Masaki Inokuchi, Tomohiko\n  Yagyu, Meir Kalech, Yuval Elovici, Asaf Shabtai", "title": "Autosploit: A Fully Automated Framework for Evaluating the\n  Exploitability of Security Vulnerabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existence of a security vulnerability in a system does not necessarily\nmean that it can be exploited. In this research, we introduce Autosploit -- an\nautomated framework for evaluating the exploitability of vulnerabilities. Given\na vulnerable environment and relevant exploits, Autosploit will automatically\ntest the exploits on different configurations of the environment in order to\nidentify the specific properties necessary for successful exploitation of the\nexisting vulnerabilities. Since testing all possible system configurations is\ninfeasible, we introduce an efficient approach for testing and searching\nthrough all possible configurations of the environment. The efficient testing\nprocess implemented by Autosploit is based on two algorithms: generalized\nbinary splitting and Barinel, which are used for noiseless and noisy\nenvironments respectively. We implemented the proposed framework and evaluated\nit using real vulnerabilities. The results show that Autosploit is able to\nautomatically identify the system properties that affect the ability to exploit\na vulnerability in both noiseless and noisy environments. These important\nresults can be utilized for more accurate and effective risk assessment.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 18:49:18 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Moscovich", "Noam", ""], ["Bitton", "Ron", ""], ["Mallah", "Yakov", ""], ["Inokuchi", "Masaki", ""], ["Yagyu", "Tomohiko", ""], ["Kalech", "Meir", ""], ["Elovici", "Yuval", ""], ["Shabtai", "Asaf", ""]]}, {"id": "2007.00253", "submitter": "Rafael Dowsley", "authors": "Kyle Bittner, Martine De Cock, Rafael Dowsley", "title": "Private Speech Classification with Secure Multiparty Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning in audio signal processing, such as human voice audio signal\nclassification, is a rich application area of machine learning. Legitimate use\ncases include voice authentication, gunfire detection, and emotion recognition.\nWhile there are clear advantages to automated human speech classification,\napplication developers can gain knowledge beyond the professed scope from\nunprotected audio signal processing. In this paper we propose the first\nprivacy-preserving solution for deep learning-based audio classification that\nis provably secure. Our approach, which is based on Secure Multiparty\nComputation, allows to classify a speech signal of one party (Alice) with a\ndeep neural network of another party (Bob) without Bob ever seeing Alice's\nspeech signal in an unencrypted manner. As threat models, we consider both\npassive security, i.e. with semi-honest parties who follow the instructions of\nthe cryptographic protocols, as well as active security, i.e. with malicious\nparties who deviate from the protocols. We evaluate the\nefficiency-security-accuracy trade-off of the proposed solution in a use case\nfor privacy-preserving emotion detection from speech with a convolutional\nneural network. In the semi-honest case we can classify a speech signal in\nunder 0.3 sec; in the malicious case it takes $\\sim$1.6 sec. In both cases\nthere is no leakage of information, and we achieve classification accuracies\nthat are the same as when computations are done on unencrypted data.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 05:26:06 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 20:18:43 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Bittner", "Kyle", ""], ["De Cock", "Martine", ""], ["Dowsley", "Rafael", ""]]}, {"id": "2007.00263", "submitter": "Mohammed K Alzaylaee Dr", "authors": "Suleiman Y. Yerima and Mohammed K. Alzaylaee", "title": "Mobile Botnet Detection: A Deep Learning Approach Using Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Android, being the most widespread mobile operating systems is increasingly\nbecoming a target for malware. Malicious apps designed to turn mobile devices\ninto bots that may form part of a larger botnet have become quite common, thus\nposing a serious threat. This calls for more effective methods to detect\nbotnets on the Android platform. Hence, in this paper, we present a deep\nlearning approach for Android botnet detection based on Convolutional Neural\nNetworks (CNN). Our proposed botnet detection system is implemented as a\nCNN-based model that is trained on 342 static app features to distinguish\nbetween botnet apps and normal apps. The trained botnet detection model was\nevaluated on a set of 6,802 real applications containing 1,929 botnets from the\npublicly available ISCX botnet dataset. The results show that our CNN-based\napproach had the highest overall prediction accuracy compared to other popular\nmachine learning classifiers. Furthermore, the performance results observed\nfrom our model were better than those reported in previous studies on machine\nlearning based Android botnet detection.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 06:19:12 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Yerima", "Suleiman Y.", ""], ["Alzaylaee", "Mohammed K.", ""]]}, {"id": "2007.00300", "submitter": "Arthur Drichel", "authors": "Arthur Drichel, Ulrike Meyer, Samuel Sch\\\"uppen, Dominik Teubert", "title": "Making Use of NXt to Nothing: The Effect of Class Imbalances on DGA\n  Detection Classifiers", "comments": "Accepted at The 15th International Conference on Availability,\n  Reliability and Security (ARES 2020)", "journal-ref": "In The 15th International Conference on Availability, Reliability\n  and Security (ARES 2020), ACM, 9 pages", "doi": "10.1145/3407023.3409190", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous machine learning classifiers have been proposed for binary\nclassification of domain names as either benign or malicious, and even for\nmulticlass classification to identify the domain generation algorithm (DGA)\nthat generated a specific domain name. Both classification tasks have to deal\nwith the class imbalance problem of strongly varying amounts of training\nsamples per DGA. Currently, it is unclear whether the inclusion of DGAs for\nwhich only a few samples are known to the training sets is beneficial or\nharmful to the overall performance of the classifiers. In this paper, we\nperform a comprehensive analysis of various contextless DGA classifiers, which\nreveals the high value of a few training samples per class for both\nclassification tasks. We demonstrate that the classifiers are able to detect\nvarious DGAs with high probability by including the underrepresented classes\nwhich were previously hardly recognizable. Simultaneously, we show that the\nclassifiers' detection capabilities of well represented classes do not\ndecrease.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 07:51:12 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Drichel", "Arthur", ""], ["Meyer", "Ulrike", ""], ["Sch\u00fcppen", "Samuel", ""], ["Teubert", "Dominik", ""]]}, {"id": "2007.00349", "submitter": "Alexander Heinrich", "authors": "Alexander Heinrich, Milan Stute, Matthias Hollick", "title": "DEMO: BTLEmap: Nmap for Bluetooth Low Energy", "comments": "13th ACM Conference on Security and Privacy in Wireless and Mobile\n  Networks", "journal-ref": null, "doi": "10.1145/3395351.3401796", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The market for Bluetooth Low Energy devices is booming and, at the same time,\nhas become an attractive target for adversaries. To improve BLE security at\nlarge, we present BTLEmap, an auditing application for BLE environments.\nBTLEmap is inspired by network discovery and security auditing tools such as\nNmap for IP-based networks. It allows for device enumeration, GATT service\ndiscovery, and device fingerprinting. It goes even further by integrating a BLE\nadvertisement dissector, data exporter, and a user-friendly UI, including a\nproximity view. BTLEmap currently runs on iOS and macOS using Apple's\nCoreBluetooth API but also accepts alternative data inputs such as a Raspberry\nPi to overcome the restricted vendor API. The open-source project is under\nactive development and will provide more advanced capabilities such as\nlong-term device tracking (in spite of MAC address randomization) in the\nfuture.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 09:37:37 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Heinrich", "Alexander", ""], ["Stute", "Milan", ""], ["Hollick", "Matthias", ""]]}, {"id": "2007.00415", "submitter": "Quinten Stokkink", "authors": "Quinten Stokkink, Dick Epema and Johan Pouwelse", "title": "A Truly Self-Sovereign Identity System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital identity is essential to access services such as: online banking,\nincome tax portals, and online higher education. Digital identity is often\noutsourced to central digital identity providers, introducing a critical\ndependency. Self-Sovereign Identity gives citizens the ownership back of their\nown identity. However, proposed solutions concentrate on data disclosure\nprotocols and are unable to produce identity with legal status. We identify how\nrelated work attempts to legalize identity by reintroducing centralization and\ndisregards common attacks on peer-to-peer interactions, missing out on the\nstrong privacy guarantees offered by the data disclosure protocols. To address\nthis problem we present IPv8, a complete system for passport-grade\nSelf-Sovereign Identity. Our design consists of a hierarchy of middleware\nlayers which are minimally required to establish legal viability. IPv8 is\ncomprised of a peer-to-peer middleware stack with Sybil attack resilience and\nstrong privacy through onion routing. No other work has offered an operational\nprototype of an academically pure identity solution without any trusted third\nparties, critical external services, or any server in general.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 12:14:04 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Stokkink", "Quinten", ""], ["Epema", "Dick", ""], ["Pouwelse", "Johan", ""]]}, {"id": "2007.00461", "submitter": "Sabrina Kirrane", "authors": "Sabrina Kirrane, Alessandra Mileo, Axel Polleres, and Stefan Decker", "title": "Query Based Access Control for Linked Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years we have seen significant advances in the technology used to\nboth publish and consume Linked Data. However, in order to support the next\ngeneration of ebusiness applications on top of interlinked machine readable\ndata suitable forms of access control need to be put in place. Although a\nnumber of access control models and frameworks have been put forward, very\nlittle research has been conducted into the security implications associated\nwith granting access to partial data or the correctness of the proposed access\ncontrol mechanisms. Therefore the contributions of this paper are two fold: we\npropose a query rewriting algorithm which can be used to partially restrict\naccess to SPARQL 1.1 queries and updates; and we demonstrate how a set of\ncriteria, which was originally used to verify that an access control policy\nholds over different database states, can be adapted to verify the correctness\nof access control via query rewriting.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 13:01:45 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 07:38:17 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Kirrane", "Sabrina", ""], ["Mileo", "Alessandra", ""], ["Polleres", "Axel", ""], ["Decker", "Stefan", ""]]}, {"id": "2007.00464", "submitter": "Aleieldin Salem", "authors": "Aleieldin Salem", "title": "Towards Accurate Labeling of Android Apps for Reliable Malware Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In training their newly-developed malware detection methods, researchers rely\non threshold-based labeling strategies that interpret the scan reports provided\nby online platforms, such as VirusTotal. The dynamicity of this platform\nrenders those labeling strategies unsustainable over prolonged periods, which\nleads to inaccurate labels. Using inaccurately labeled apps to train and\nevaluate malware detection methods significantly undermines the reliability of\ntheir results, leading to either dismissing otherwise promising detection\napproaches or adopting intrinsically inadequate ones. The infeasibility of\ngenerating accurate labels via manual analysis and the lack of reliable\nalternatives force researchers to utilize VirusTotal to label apps. In the\npaper, we tackle this issue in two manners. Firstly, we reveal the aspects of\nVirusTotal's dynamicity and how they impact threshold-based labeling strategies\nand provide actionable insights on how to use these labeling strategies given\nVirusTotal's dynamicity reliably. Secondly, we motivate the implementation of\nalternative platforms by (a) identifying VirusTotal limitations that such\nplatforms should avoid, and (b) proposing an architecture of how such platforms\ncan be constructed to mitigate VirusTotal's limitations.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 13:02:19 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Salem", "Aleieldin", ""]]}, {"id": "2007.00489", "submitter": "Nalin Asanka Gamagedara Arachchilage", "authors": "J. Samantha Tharani and Nalin Asanka Gamagedara Arachchilage", "title": "Understanding phishers' strategies of mimicking uniform resource\n  locators to leverage phishing attacks: A machine learning approach", "comments": "15", "journal-ref": "Security and Privacy, Willey, 2020", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phishing is a type of social engineering attack with an intention to steal\nuser data, including login credentials and credit card numbers, leading to\nfinancial losses for both organisations and individuals. It occurs when an\nattacker, pretending as a trusted entity, lure a victim into click on a link or\nattachment in an email, or in a text message. Phishing is often launched via\nemail messages or text messages over social networks. Previous research has\nrevealed that phishing attacks can be identified just by looking at URLs.\nIdentifying the techniques which are used by phishers to mimic a phishing URL\nis rather a challenging issue. At present, we have limited knowledge and\nunderstanding of how cybercriminals attempt to mimic URLs with the same look\nand feel of the legitimate ones, to entice people into clicking links.\nTherefore, this paper investigates the feature selection of phishing URLs\n(Uniform Resource Locators), aiming to explore the strategies employed by\nphishers to mimic URLs that can obviously trick people into clicking links. We\nemployed an Information Gain (IG) and Chi-Squared feature selection methods in\nMachine Learning (ML) on a phishing dataset. The dataset contains a total of 48\nfeatures extracted from 5000 phishing and another 5000 legitimate URL from web\npages downloaded from January to May 2015 and from May to June 2017. Our\nresults revealed that there were 10 techniques that phishers used to mimic URLs\nto manipulate humans into clicking links. Identifying these phishing URL\nmanipulation techniques would certainly help to educate individuals and\norganisations and keep them safe from phishing attacks. In addition, the\nfindings of this research will also help develop anti-phishing tools, framework\nor browser plugins for phishing prevention.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 13:46:03 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Tharani", "J. Samantha", ""], ["Arachchilage", "Nalin Asanka Gamagedara", ""]]}, {"id": "2007.00500", "submitter": "Richard Mitev", "authors": "Richard Mitev and Anna Pazii and Markus Miettinen and William Enck and\n  Ahmad-Reza Sadeghi", "title": "LeakyPick: IoT Audio Spy Detector", "comments": null, "journal-ref": null, "doi": "10.1145/3427228.3427277", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manufacturers of smart home Internet of Things (IoT) devices are increasingly\nadding voice assistant and audio monitoring features to a wide range of devices\nincluding smart speakers, televisions, thermostats, security systems, and\ndoorbells. Consequently, many of these devices are equipped with microphones,\nraising significant privacy concerns: users may not always be aware of when\naudio recordings are sent to the cloud, or who may gain access to the\nrecordings. In this paper, we present the LeakyPick architecture that enables\nthe detection of the smart home devices that stream recorded audio to the\nInternet without the user's consent. Our proof-of-concept is a LeakyPick device\nthat is placed in a user's smart home and periodically \"probes\" other devices\nin its environment and monitors the subsequent network traffic for statistical\npatterns that indicate audio transmission. Our prototype is built on a\nRaspberry Pi for less than USD40 and has a measurement accuracy of 94% in\ndetecting audio transmissions for a collection of 8 devices with voice\nassistant capabilities. Furthermore, we used LeakyPick to identify 89 words\nthat an Amazon Echo Dot misinterprets as its wake-word, resulting in unexpected\naudio transmission. LeakyPick provides a cost effective approach for regular\nconsumers to monitor their homes for unexpected audio transmissions to the\ncloud.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 13:58:35 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 12:30:57 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Mitev", "Richard", ""], ["Pazii", "Anna", ""], ["Miettinen", "Markus", ""], ["Enck", "William", ""], ["Sadeghi", "Ahmad-Reza", ""]]}, {"id": "2007.00510", "submitter": "Aleieldin Salem", "authors": "Aleieldin Salem, Sebastian Banescu, Alexander Pretschner", "title": "Maat: Automatically Analyzing VirusTotal for Accurate Labeling and\n  Effective Malware Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The malware analysis and detection research community relies on the online\nplatform VirusTotal to label Android apps based on the scan results of around\n60 antiviral scanners. Unfortunately, there are no standards on how to best\ninterpret the scan results acquired from VirusTotal, which leads to the\nutilization of different threshold-based labeling strategies (e.g., if ten or\nmore scanners deem an app malicious, it is considered malicious). While some of\nthe utilized thresholds may be able to accurately approximate the ground truths\nof apps, the fact that VirusTotal changes the set and versions of the scanners\nit uses makes such thresholds unsustainable over time. We implemented a method,\nMaat, that tackles these issues of standardization and sustainability by\nautomatically generating a Machine Learning (ML)-based labeling scheme, which\noutperforms threshold-based labeling strategies. Using the VirusTotal scan\nreports of 53K Android apps that span one year, we evaluated the applicability\nof Maat's ML-based labeling strategies by comparing their performance against\nthreshold-based strategies. We found that such ML-based strategies (a) can\naccurately and consistently label apps based on their VirusTotal scan reports,\nand (b) contribute to training ML-based detection methods that are more\neffective at classifying out-of-sample apps than their threshold-based\ncounterparts.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 14:15:03 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Salem", "Aleieldin", ""], ["Banescu", "Sebastian", ""], ["Pretschner", "Alexander", ""]]}, {"id": "2007.00677", "submitter": "Luka Music", "authors": "Luka Music, C\\'eline Chevalier, Elham Kashefi", "title": "Dispelling Myths on Superposition Attacks: Formal Security Model and\n  Attack Analyses", "comments": "46 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is of folkloric belief that the security of classical cryptographic\nprotocols is automatically broken if the Adversary is allowed to perform\nsuperposition queries and the honest players forced to perform actions\ncoherently on quantum states. Another widely held intuition is that enforcing\nmeasurements on the exchanged messages is enough to protect protocols from\nthese attacks.\n  However, the reality is much more complex. Security models dealing with\nsuperposition attacks only consider unconditional security. Conversely,\nsecurity models considering computational security assume that all supposedly\nclassical messages are measured, which forbids by construction the analysis of\nsuperposition attacks. Boneh and Zhandry have started to study the quantum\ncomputational security for classical primitives in their seminal work at\nCrypto'13, but only in the single-party setting. To the best of our knowledge,\nan equivalent model in the multiparty setting is still missing.\n  In this work, we propose the first computational security model considering\nsuperposition attacks for multiparty protocols. We show that our new security\nmodel is satisfiable by proving the security of the well-known One-Time-Pad\nprotocol and give an attack on a variant of the equally reputable Yao Protocol\nfor Secure Two-Party Computations. The post-mortem of this attack reveals the\nprecise points of failure, yielding highly counter-intuitive results: Adding\nextra classical communication, which is harmless for classical security, can\nmake the protocol become subject to superposition attacks. We use this newly\nimparted knowledge to construct the first concrete protocol for Secure\nTwo-Party Computation that is resistant to superposition attacks. Our results\nshow that there is no straightforward answer to provide for either the\nvulnerabilities of classical protocols to superposition attacks or the adapted\ncountermeasures.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 18:00:54 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Music", "Luka", ""], ["Chevalier", "C\u00e9line", ""], ["Kashefi", "Elham", ""]]}, {"id": "2007.00711", "submitter": "Miguel Villarreal-Vasquez", "authors": "Miguel Villarreal-Vasquez and Bharat Bhargava", "title": "ConFoc: Content-Focus Protection Against Trojan Attacks on Neural\n  Networks", "comments": "13 pages (excluding references), 7 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have been applied successfully in computer\nvision. However, their wide adoption in image-related applications is\nthreatened by their vulnerability to trojan attacks. These attacks insert some\nmisbehavior at training using samples with a mark or trigger, which is\nexploited at inference or testing time. In this work, we analyze the\ncomposition of the features learned by DNNs at training. We identify that they,\nincluding those related to the inserted triggers, contain both content\n(semantic information) and style (texture information), which are recognized as\na whole by DNNs at testing time. We then propose a novel defensive technique\nagainst trojan attacks, in which DNNs are taught to disregard the styles of\ninputs and focus on their content only to mitigate the effect of triggers\nduring the classification. The generic applicability of the approach is\ndemonstrated in the context of a traffic sign and a face recognition\napplication. Each of them is exposed to a different attack with a variety of\ntriggers. Results show that the method reduces the attack success rate\nsignificantly to values < 1% in all the tested attacks while keeping as well as\nimproving the initial accuracy of the models when processing both benign and\nadversarial data.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 19:25:34 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Villarreal-Vasquez", "Miguel", ""], ["Bhargava", "Bharat", ""]]}, {"id": "2007.00764", "submitter": "Matteo Romiti", "authors": "Matteo Romiti, Friedhelm Victor, Pedro Moreno-Sanchez, Peter Sebastian\n  Nordholt, Bernhard Haslhofer, Matteo Maffei", "title": "Cross-Layer Deanonymization Methods in the Lightning Protocol", "comments": "30 pages, 9 figures, Financial Cryptography and Data Security 2021\n  https://fc21.ifca.ai/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin (BTC) pseudonyms (layer 1) can effectively be deanonymized using\nheuristic clustering techniques. However, while performing transactions\noff-chain (layer 2) in the Lightning Network (LN) seems to enhance privacy, a\nsystematic analysis of the anonymity and privacy leakages due to the\ninteraction between the two layers is missing. We present clustering heuristics\nthat group BTC addresses, based on their interaction with the LN, as well as LN\nnodes, based on shared naming and hosting information. We also present linking\nheuristics that link 45.97% of all LN nodes to 29.61% BTC addresses interacting\nwith the LN. These links allow us to attribute information (e.g., aliases, IP\naddresses) to 21.19% of the BTC addresses contributing to their\ndeanonymization. Further, these deanonymization results suggest that the\nsecurity and privacy of LN payments are weaker than commonly believed, with LN\nusers being at the mercy of as few as five actors that control 36 nodes and\nover 33% of the total capacity. Overall, this is the first paper to present a\nmethod for linking LN nodes with BTC addresses across layers and to discuss\nprivacy and security implications.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 21:16:30 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 09:57:36 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2021 11:25:37 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Romiti", "Matteo", ""], ["Victor", "Friedhelm", ""], ["Moreno-Sanchez", "Pedro", ""], ["Nordholt", "Peter Sebastian", ""], ["Haslhofer", "Bernhard", ""], ["Maffei", "Matteo", ""]]}, {"id": "2007.00765", "submitter": "Fang Liu", "authors": "Fang Liu", "title": "A Statistical Overview on Data Privacy", "comments": "To appear in Notre Dame Journal of Law, Ethics & Public Policy\n  (2020), Volume 34 Issue 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The eruption of big data with the increasing collection and processing of\nvast volumes and variety of data have led to breakthrough discoveries and\ninnovation in science, engineering, medicine, commerce, criminal justice, and\nnational security that would not have been possible in the past. While there\nare many benefits to the collection and usage of big data, there are also\ngrowing concerns among the general public on what personal information is\ncollected and how it is used. In addition to legal policies and regulations,\ntechnological tools and statistical strategies also exist to promote and\nsafeguard individual privacy, while releasing and sharing useful\npopulation-level information. In this overview, I introduce some of these\napproaches, as well as the existing challenges and opportunities in statistical\ndata privacy research and applications to better meet the practical needs of\nprivacy protection and information sharing.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 21:21:20 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Liu", "Fang", ""]]}, {"id": "2007.00772", "submitter": "Yizhen Wang", "authors": "Yizhen Wang, Xiaozhu Meng, Ke Wang, Mihai Christodorescu, Somesh Jha", "title": "Robustness against Relational Adversary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Test-time adversarial attacks have posed serious challenges to the robustness\nof machine-learning models, and in many settings the adversarial perturbation\nneed not be bounded by small $\\ell_p$-norms. Motivated by the\nsemantics-preserving attacks in vision and security domain, we investigate\n$\\textit{relational adversaries}$, a broad class of attackers who create\nadversarial examples that are in a reflexive-transitive closure of a logical\nrelation. We analyze the conditions for robustness and propose\n$\\textit{normalize-and-predict}$ -- a learning framework with provable\nrobustness guarantee. We compare our approach with adversarial training and\nderive an unified framework that provides benefits of both approaches. Guided\nby our theoretical findings, we apply our framework to image classification and\nmalware detection. Results of both tasks show that attacks using relational\nadversaries frequently fool existing models, but our unified framework can\nsignificantly enhance their robustness.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 21:27:38 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 14:42:42 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Wang", "Yizhen", ""], ["Meng", "Xiaozhu", ""], ["Wang", "Ke", ""], ["Christodorescu", "Mihai", ""], ["Jha", "Somesh", ""]]}, {"id": "2007.00826", "submitter": "Pierre-Francois Wolfe", "authors": "Pierre-Francois Wolfe, Rushi Patel, Robert Munafo, Mayank Varia, and\n  Martin Herbordt", "title": "Secret Sharing MPC on FPGAs in the Datacenter", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Party Computation (MPC) is a technique enabling data from several\nsources to be used in a secure computation revealing only the result while\nprotecting the original data, facilitating shared utilization of data sets\ngathered by different entities. The presence of Field Programmable Gate Array\n(FPGA) hardware in datacenters can provide accelerated computing as well as low\nlatency, high bandwidth communication that bolsters the performance of MPC and\nlowers the barrier to using MPC for many applications. In this work, we propose\na Secret Sharing FPGA design based on the protocol described by Araki et al. We\ncompare our hardware design to the original authors' software implementations\nof Secret Sharing and to work accelerating MPC protocols based on Garbled\nCircuits with FPGAs. Our conclusion is that Secret Sharing in the datacenter is\ncompetitive and when implemented on FPGA hardware was able to use at least\n10$\\times$ fewer computer resources than the original work using CPUs.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 01:26:18 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Wolfe", "Pierre-Francois", ""], ["Patel", "Rushi", ""], ["Munafo", "Robert", ""], ["Varia", "Mayank", ""], ["Herbordt", "Martin", ""]]}, {"id": "2007.00894", "submitter": "Beijing University Of Posts Telecommunications", "authors": "Wenzhe Lv, Sheng Wu, Chunxiao Jiang, Yuanhao Cui, Xuesong Qiu and Yan\n  Zhang", "title": "Decentralized Blockchain for Privacy-Preserving Large-Scale Contact\n  Tracing", "comments": "16 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activity-tracking applications and location-based services using short-range\ncommunication (SRC) techniques have been abruptly demanded in the COVID-19\npandemic, especially for automated contact tracing. The attention from both\npublic and policy keeps raising on related practical problems, including\n\\textit{1) how to protect data security and location privacy? 2) how to\nefficiently and dynamically deploy SRC Internet of Thing (IoT) witnesses to\nmonitor large areas?} To answer these questions, in this paper, we propose a\ndecentralized and permissionless blockchain protocol, named \\textit{Bychain}.\nSpecifically, 1) a privacy-preserving SRC protocol for activity-tracking and\ncorresponding generalized block structure is developed, by connecting an\ninteractive zero-knowledge proof protocol and the key escrow mechanism. As a\nresult, connections between personal identity and the ownership of on-chain\nlocation information are decoupled. Meanwhile, the owner of the on-chain\nlocation data can still claim its ownership without revealing the private key\nto anyone else. 2) An artificial potential field-based incentive allocation\nmechanism is proposed to incentivize IoT witnesses to pursue the maximum\nmonitoring coverage deployment. We implemented and evaluated the proposed\nblockchain protocol in the real-world using the Bluetooth 5.0. The storage, CPU\nutilization, power consumption, time delay, and security of each procedure and\nperformance of activities are analyzed. The experiment and security analysis is\nshown to provide a real-world performance evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 05:46:34 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Lv", "Wenzhe", ""], ["Wu", "Sheng", ""], ["Jiang", "Chunxiao", ""], ["Cui", "Yuanhao", ""], ["Qiu", "Xuesong", ""], ["Zhang", "Yan", ""]]}, {"id": "2007.00914", "submitter": "Eugenio Mart\\'inez-C\\'amara", "authors": "Nuria Rodr\\'iguez-Barroso, Goran Stipcich, Daniel Jim\\'enez-L\\'opez,\n  Jos\\'e Antonio Ruiz-Mill\\'an, Eugenio Mart\\'inez-C\\'amara, Gerardo\n  Gonz\\'alez-Seco, M. Victoria Luz\\'on, Miguel \\'Angel Veganzones, Francisco\n  Herrera", "title": "Federated Learning and Differential Privacy: Software tools analysis,\n  the Sherpa.ai FL framework and methodological guidelines for preserving data\n  privacy", "comments": "46 pages, 5 figures", "journal-ref": "Information Fusion 64 (2020) 270-292", "doi": "10.1016/j.inffus.2020.07.009", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high demand of artificial intelligence services at the edges that also\npreserve data privacy has pushed the research on novel machine learning\nparadigms that fit those requirements. Federated learning has the ambition to\nprotect data privacy through distributed learning methods that keep the data in\ntheir data silos. Likewise, differential privacy attains to improve the\nprotection of data privacy by measuring the privacy loss in the communication\namong the elements of federated learning. The prospective matching of federated\nlearning and differential privacy to the challenges of data privacy protection\nhas caused the release of several software tools that support their\nfunctionalities, but they lack of the needed unified vision for those\ntechniques, and a methodological workflow that support their use. Hence, we\npresent the Sherpa.ai Federated Learning framework that is built upon an\nholistic view of federated learning and differential privacy. It results from\nthe study of how to adapt the machine learning paradigm to federated learning,\nand the definition of methodological guidelines for developing artificial\nintelligence services based on federated learning and differential privacy. We\nshow how to follow the methodological guidelines with the Sherpa.ai Federated\nLearning framework by means of a classification and a regression use cases.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 06:47:35 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 07:39:39 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Rodr\u00edguez-Barroso", "Nuria", ""], ["Stipcich", "Goran", ""], ["Jim\u00e9nez-L\u00f3pez", "Daniel", ""], ["Ruiz-Mill\u00e1n", "Jos\u00e9 Antonio", ""], ["Mart\u00ednez-C\u00e1mara", "Eugenio", ""], ["Gonz\u00e1lez-Seco", "Gerardo", ""], ["Luz\u00f3n", "M. Victoria", ""], ["Veganzones", "Miguel \u00c1ngel", ""], ["Herrera", "Francisco", ""]]}, {"id": "2007.00966", "submitter": "Ilya Sapranidi", "authors": "Aleksei Pupyshev, Dmitry Gubanov, Elshan Dzhafarov, Ilya Sapranidi,\n  Inal Kardanov, Vladimir Zhuravlev, Shamil Khalilov, Marc Jansen, Sten\n  Laureyssens, Igor Pavlov, Sasha Ivanov", "title": "Gravity: a blockchain-agnostic cross-chain communication and data\n  oracles protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper intends to propose the architecture of a blockchain-agnostic\nprotocol designed for communication of blockchains amongst each other (i.e.\ncross-chain), and for blockchains with the outside world (i.e. data oracles).\nThe expansive growth of cutting-edge technology in the blockchain industry\noutlines the need and opportunity for addressing oracle consensus in a manner\nboth technologically and economically efficient as well as futureproof.\nBlockchain-agnosticism is inherently limited if proposing a technological\nsolution involves adding one more architectural layer. As such, Gravity\nprotocol is designed to be a truly blockchain-agnostic protocol. By ensuring\nparity through direct integration and by leveraging the stability and security\nof the respective interconnected ecosystems, Gravity circumvents the need for a\ndedicated, public blockchain and a native token. Ultimately, Gravity protocol\nintends to address scalability challenges by providing a solid infrastructure\nfor the creation of gateways, cross-chain applications, and sidechains. This\npaper introduces and defines the concept of Oracle Consensus and its\nimplementation in the Gravity protocol named the Pulse Consensus algorithm. The\nproposed consensus architecture allows Gravity to be considered a singular\ndecentralized blockchain-agnostic oracle.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 08:53:01 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 12:26:30 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Pupyshev", "Aleksei", ""], ["Gubanov", "Dmitry", ""], ["Dzhafarov", "Elshan", ""], ["Sapranidi", "Ilya", ""], ["Kardanov", "Inal", ""], ["Zhuravlev", "Vladimir", ""], ["Khalilov", "Shamil", ""], ["Jansen", "Marc", ""], ["Laureyssens", "Sten", ""], ["Pavlov", "Igor", ""], ["Ivanov", "Sasha", ""]]}, {"id": "2007.01017", "submitter": "Xabier Echeberria-Barrio", "authors": "Xabier Echeberria-Barrio, Amaia Gil-Lerchundi, Ines\n  Goicoechea-Telleria and Raul Orduna-Urrutia", "title": "Deep Learning Defenses Against Adversarial Examples for Dynamic Risk\n  Assessment", "comments": "11 pages, 10 figures, CISIS2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks were first developed decades ago, but it was not until\nrecently that they started being extensively used, due to their computing power\nrequirements. Since then, they are increasingly being applied to many fields\nand have undergone far-reaching advancements. More importantly, they have been\nutilized for critical matters, such as making decisions in healthcare\nprocedures or autonomous driving, where risk management is crucial. Any\nmistakes in the diagnostics or decision-making in these fields could entail\ngrave accidents, and even death. This is preoccupying, because it has been\nrepeatedly reported that it is straightforward to attack this type of models.\nThus, these attacks must be studied to be able to assess their risk, and\ndefenses need to be developed to make models more robust. For this work, the\nmost widely known attack was selected (adversarial attack) and several defenses\nwere implemented against it (i.e. adversarial training, dimensionality reduc\ntion and prediction similarity). The obtained outcomes make the model more\nrobust while keeping a similar accuracy. The idea was developed using a breast\ncancer dataset and a VGG16 and dense neural network model, but the solutions\ncould be applied to datasets from other areas and different convolutional and\ndense deep neural network models.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 11:01:27 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Echeberria-Barrio", "Xabier", ""], ["Gil-Lerchundi", "Amaia", ""], ["Goicoechea-Telleria", "Ines", ""], ["Orduna-Urrutia", "Raul", ""]]}, {"id": "2007.01029", "submitter": "Naoto Yanai", "authors": "Yuichiro Chinen and Naoto Yanai and Jason Paul Cruz and Shingo Okamura", "title": "Hunting for Re-Entrancy Attacks in Ethereum Smart Contracts via Static\n  Analysis", "comments": null, "journal-ref": "IEEE Blockchain 2020", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ethereum smart contracts are programs that are deployed and executed in a\nconsensus-based blockchain managed by a peer-to-peer network. Several\nre-entrancy attacks that aim to steal Ether, the cryptocurrency used in\nEthereum, stored in deployed smart contracts have been found in the recent\nyears. A countermeasure to such attacks is based on dynamic analysis that\nexecutes the smart contracts themselves, but it requires the spending of Ether\nand knowledge of attack patterns for analysis in advance. In this paper, we\npresent a static analysis tool named \\textit{RA (Re-entrancy Analyzer)}, a\ncombination of symbolic execution and equivalence checking by a satisfiability\nmodulo theories solver to analyze smart contract vulnerabilities to re-entrancy\nattacks. In contrast to existing tools, RA supports analysis of inter-contract\nbehaviors by using only the Etherum Virtual Machine bytecodes of target smart\ncontracts, i.e., even without prior knowledge of attack patterns and without\nspending Ether. Furthermore, RA can verify existence of vulnerabilities to\nre-entrancy attacks without execution of smart contracts and it does not\nprovide false positives and false negatives. We also present an implementation\nof RA to evaluate its performance in analyzing the vulnerability of deployed\nsmart contracts to re-entrancy attacks and show that RA can precisely determine\nwhich smart contracts are vulnerable.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 11:30:07 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Chinen", "Yuichiro", ""], ["Yanai", "Naoto", ""], ["Cruz", "Jason Paul", ""], ["Okamura", "Shingo", ""]]}, {"id": "2007.01046", "submitter": "Saar Tochner", "authors": "Maya Dotan and Saar Tochner", "title": "Proofs of Useless Work -- Positive and Negative Results for Wasteless\n  Mining Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many blockchain systems today, including Bitcoin, rely on Proof of Work\n(PoW). Proof of work is crucial to the liveness and security of\ncryptocurrencies. The assumption when using PoW is that a lot of trial and\nerror is required on average before a valid block is generated. One of the main\nconcerns raised with regard to this kind of system is the inherent need to\n\"waste\" energy on \"meaningless\" problems. In fact, the Bitcoin system is\nbelieved to consume more electricity than several small countries [5]. In this\nwork we formally define three properties that are necessary for wasteless PoW\nsystems: (1) solve \"meaningful\" problems (2) solve them efficiently and (3) be\nsecure against double-spend attacks. We analyze these properties and deduce\nconstraints that impose on PoW systems. In particular, we conclude that under\nrealistic assumptions, the set of allowed functions for mining must be preimage\nresistant functions. Finally, we propose a modification to the Bitcoin\nconsensus rule that allows users to upload a certain subset of preimage\nresistant problems and let the mining process solve them. We prove security\nagainst Double-Spend attacks identical to the existing security guarantee in\nBitcoin today.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 12:07:26 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Dotan", "Maya", ""], ["Tochner", "Saar", ""]]}, {"id": "2007.01059", "submitter": "Dima Kagan", "authors": "Dima Kagan, Galit Fuhrmann Alpert, Michael Fire", "title": "Zooming Into Video Conferencing Privacy and Security Threats", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic outbreak, with its related social distancing and\nshelter-in-place measures, has dramatically affected ways in which people\ncommunicate with each other, forcing people to find new ways to collaborate,\nstudy, celebrate special occasions, and meet with family and friends. One of\nthe most popular solutions that have emerged is the use of video conferencing\napplications to replace face-to-face meetings with virtual meetings. This\nresulted in unprecedented growth in the number of video conferencing users. In\nthis study, we explored privacy issues that may be at risk by attending virtual\nmeetings. We extracted private information from collage images of meeting\nparticipants that are publicly posted on the Web. We used image processing,\ntext recognition tools, as well as social network analysis to explore our web\ncrawling curated dataset of over 15,700 collage images, and over 142,000 face\nimages of meeting participants. We demonstrate that video conference users are\nfacing prevalent security and privacy threats. Our results indicate that it is\nrelatively easy to collect thousands of publicly available images of video\nconference meetings and extract personal information about the participants,\nincluding their face images, age, gender, usernames, and sometimes even full\nnames. This type of extracted data can vastly and easily jeopardize people's\nsecurity and privacy both in the online and real-world, affecting not only\nadults but also more vulnerable segments of society, such as young children and\nolder adults. Finally, we show that cross-referencing facial image data with\nsocial network data may put participants at additional privacy risks they may\nnot be aware of and that it is possible to identify users that appear in\nseveral video conference meetings, thus providing a potential to maliciously\naggregate different sources of information about a target individual.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 12:31:54 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Kagan", "Dima", ""], ["Alpert", "Galit Fuhrmann", ""], ["Fire", "Michael", ""]]}, {"id": "2007.01061", "submitter": "Luca Piccolboni", "authors": "Luca Piccolboni, Giuseppe Di Guglielmo, Luca P. Carloni, Simha\n  Sethumadhavan", "title": "CRYLOGGER: Detecting Crypto Misuses Dynamically", "comments": "To appear in the Proceedings of the IEEE Symposium on Security &\n  Privacy (SP) 2021", "journal-ref": null, "doi": "10.1109/SP40001.2021.00010", "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptographic (crypto) algorithms are the essential ingredients of all secure\nsystems: crypto hash functions and encryption algorithms, for example, can\nguarantee properties such as integrity and confidentiality. Developers,\nhowever, can misuse the application programming interfaces (API) of such\nalgorithms by using constant keys and weak passwords. This paper presents\nCRYLOGGER, the first open-source tool to detect crypto misuses dynamically.\nCRYLOGGER logs the parameters that are passed to the crypto APIs during the\nexecution and checks their legitimacy offline by using a list of crypto rules.\nWe compare CRYLOGGER with CryptoGuard, one of the most effective static tools\nto detect crypto misuses. We show that our tool complements the results of\nCryptoGuard, making the case for combining static and dynamic approaches. We\nanalyze 1780 popular Android apps downloaded from the Google Play Store to show\nthat CRYLOGGER can detect crypto misuses on thousands of apps dynamically and\nautomatically. We reverse-engineer 28 Android apps and confirm the issues\nflagged by CRYLOGGER. We also disclose the most critical vulnerabilities to app\ndevelopers and collect their feedback.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 12:33:31 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Piccolboni", "Luca", ""], ["Di Guglielmo", "Giuseppe", ""], ["Carloni", "Luca P.", ""], ["Sethumadhavan", "Simha", ""]]}, {"id": "2007.01114", "submitter": "Federico Turrin", "authors": "Giovanni Barbieri, Mauro Conti, Nils Ole Tippenhauer and Federico\n  Turrin", "title": "Assessing the Use of Insecure ICS Protocols via IXP Network Traffic\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern Industrial Control Systems (ICSs) allow remote communication through\nthe Internet using industrial protocols that were not designed to work with\nexternal networks. To understand security issues related to this practice,\nprior work usually relies on active scans by researchers or services such as\nShodan. While such scans can identify publicly open ports, they cannot identify\nlegitimate use of insecure industrial traffic. In particular, source-based\nfiltering in Network Address Translation or Firewalls prevent detection by\nactive scanning, but do not ensure that insecure communication is not\nmanipulated in transit. In this work, we compare Shodan-only analysis with\nlarge-scale traffic analysis at a local Internet Exchange Point (IXP), based on\nsFlow sampling. This setup allows us to identify ICS endpoints actually\nexchanging industrial traffic over the Internet. Besides, we are able to detect\nscanning activities and what other type of traffic is exchanged by the systems\n(i.e., IT traffic). We find that Shodan only listed less than 2% of hosts that\nwe identified as exchanging industrial traffic, and only 7% of hosts identified\nby Shodan actually exchange industrial traffic. Therefore, Shodan do not allow\nto understand the actual use of insecure industrial protocols on the Internet\nand the current security practices in ICS communications. We show that 75.6% of\nICS hosts still rely on unencrypted communications without integrity\nprotection, leaving those critical systems vulnerable to malicious attacks.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 14:09:30 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 17:10:47 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Barbieri", "Giovanni", ""], ["Conti", "Mauro", ""], ["Tippenhauer", "Nils Ole", ""], ["Turrin", "Federico", ""]]}, {"id": "2007.01116", "submitter": "Valentin Bakoev", "authors": "Valentin Bakoev", "title": "A Method for Fast Computing the Algebraic Degree of Boolean Functions", "comments": "arXiv admin note: text overlap with arXiv:1905.08649", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The algebraic degree of Boolean functions (or vectorial Boolean functions) is\nan important cryptographic parameter that should be computed by fast\nalgorithms. They work in two main ways: (1) by computing the algebraic normal\nform and then searching the monomial of the highest degree in it, or (2) by\nexamination the algebraic properties of the true table vector of a given\nfunction. We have already done four basic steps in the study of the first way,\nand the second one has been studied by other authors. Here we represent a\nmethod for fast computing (the fastest way we know) the algebraic degree of\nBoolean functions. It is a combination of the most efficient components of\nthese two ways and the corresponding algorithms. The theoretical time\ncomplexities of the method are derived in each of the cases when the Boolean\nfunction is represented in a byte-wise or in a bitwise manner. They are of the\nsame type $\\Theta(n.2^n)$ for a Boolean function of $n$ variables, but they\nhave big differences between the constants in $\\Theta$-notation. The\ntheoretical and experimental results shown here demonstrate the advantages of\nthe bitwise approach in computing the algebraic degree - they are dozens of\ntimes faster than the byte-wise approaches.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 06:09:08 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Bakoev", "Valentin", ""]]}, {"id": "2007.01181", "submitter": "Ellen Vitercik", "authors": "Andr\\'es Mu\\~noz Medina, Umar Syed, Sergei Vassilvitskii, Ellen\n  Vitercik", "title": "Private Optimization Without Constraint Violations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of differentially private optimization with linear\nconstraints when the right-hand-side of the constraints depends on private\ndata. This type of problem appears in many applications, especially resource\nallocation. Previous research provided solutions that retained privacy but\nsometimes violated the constraints. In many settings, however, the constraints\ncannot be violated under any circumstances. To address this hard requirement,\nwe present an algorithm that releases a nearly-optimal solution satisfying the\nconstraints with probability 1. We also prove a lower bound demonstrating that\nthe difference between the objective value of our algorithm's solution and the\noptimal solution is tight up to logarithmic factors among all differentially\nprivate algorithms. We conclude with experiments demonstrating that our\nalgorithm can achieve nearly optimal performance while preserving privacy.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 15:08:52 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 02:40:12 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Medina", "Andr\u00e9s Mu\u00f1oz", ""], ["Syed", "Umar", ""], ["Vassilvitskii", "Sergei", ""], ["Vitercik", "Ellen", ""]]}, {"id": "2007.01288", "submitter": "David Mestel", "authors": "David Mestel", "title": "Robust ambiguity for contact tracing", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A known drawback of `decentralised' contact tracing architectures is that\nusers who have been in contact with an infected person are able to precisely\nidentify the relevant contact, and thereby perhaps identify the infected\nperson. In their proposal, the PACT team discuss a simple DH-based protocol to\nmitigate this problem, but dismiss it because it is vulnerable to a malicious\nuser who may deviate from the specified behaviour. This note presents a\nmodified protocol which achieves robustness against a fully malicious user, and\nestablishes some simple security properties.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 17:54:05 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Mestel", "David", ""]]}, {"id": "2007.01299", "submitter": "Renzhi Wang", "authors": "Renzhi Wang, Tianwei Zhang, Xiaofei Xie, Lei Ma, Cong Tian, Felix\n  Juefei-Xu, Yang Liu", "title": "Generating Adversarial Examples with Controllable Non-transferability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks against Deep Neural Networks have been widely studied.\nOne significant feature that makes such attacks particularly powerful is\ntransferability, where the adversarial examples generated from one model can be\neffective against other similar models as well. A large number of works have\nbeen done to increase the transferability. However, how to decrease the\ntransferability and craft malicious samples only for specific target models are\nnot explored yet.\n  In this paper, we design novel attack methodologies to generate adversarial\nexamples with controllable non-transferability. With these methods, an\nadversary can efficiently produce precise adversarial examples to attack a set\nof target models he desires, while keeping benign to other models. The first\nmethod is Reversed Loss Function Ensemble, where the adversary can craft\nqualified examples from the gradients of a reversed loss function. This\napproach is effective for the white-box and gray-box settings. The second\nmethod is Transferability Classification: the adversary trains a\ntransferability-aware classifier from the perturbations of adversarial\nexamples. This classifier further provides the guidance for the generation of\nnon-transferable adversarial examples. This approach can be applied to the\nblack-box scenario. Evaluation results demonstrate the effectiveness and\nefficiency of our proposed methods. This work opens up a new route for\ngenerating adversarial examples with new features and applications.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 11:11:45 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 03:12:20 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Wang", "Renzhi", ""], ["Zhang", "Tianwei", ""], ["Xie", "Xiaofei", ""], ["Ma", "Lei", ""], ["Tian", "Cong", ""], ["Juefei-Xu", "Felix", ""], ["Liu", "Yang", ""]]}, {"id": "2007.01377", "submitter": "Somdip Dey Mr.", "authors": "Somdip Dey, Amit Kumar Singh, Xiaohang Wang, and Klaus Dieter\n  McDonald-Maier", "title": "DATE: Defense Against TEmperature Side-Channel Attacks in DVFS Enabled\n  MPSoCs", "comments": "13 pages, 18 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the constant rise in utilizing embedded devices in daily life, side\nchannels remain a challenge to information flow control and security in such\nsystems. One such important security flaw could be exploited through\ntemperature side-channel attacks, where heat dissipation and propagation from\nthe processing elements are observed over time in order to deduce security\nflaws. In our proposed methodology, DATE: Defense Against TEmperature\nside-channel attacks, we propose a novel approach of reducing spatial and\ntemporal thermal gradient, which makes the system more secure against\ntemperature side-channel attacks, and at the same time increases the\nreliability of the device in terms of lifespan. In this paper, we have also\nintroduced a new metric, Thermal-Security-in-Multi-Processors (TSMP), which is\ncapable of quantifying the security against temperature side-channel attacks on\ncomputing systems, and DATE is evaluated to be 139.24% more secure at the most\nfor certain applications than the state-of-the-art, while reducing thermal\ncycle by 67.42% at the most.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 20:41:23 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Dey", "Somdip", ""], ["Singh", "Amit Kumar", ""], ["Wang", "Xiaohang", ""], ["McDonald-Maier", "Klaus Dieter", ""]]}, {"id": "2007.01459", "submitter": "Quan-Lin Li", "authors": "Quan-Lin Li, Yan-Xia Chang, Xiaole Wu and Guoqing Zhang", "title": "A New Theoretical Framework of Pyramid Markov Processes for Blockchain\n  Selfish Mining", "comments": "76 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.PF math.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide a new theoretical framework of pyramid Markov\nprocesses to solve some open and fundamental problems of blockchain selfish\nmining. To this end, we first describe a more general blockchain selfish mining\nwith both a two-block leading competitive criterion and a new economic\nincentive, and establish a pyramid Markov process to express the dynamic\nbehavior of the selfish mining from both consensus protocol and economic\nincentive. Then we show that the pyramid Markov process is stable and so is the\nblockchain, and its stationary probability vector is matrix-geometric with an\nexplicitly representable rate matrix. Furthermore, we use the stationary\nprobability vector to be able to analyze the waste of computational resource\ndue to generating a lot of orphan (or stale) blocks. Nextly, we set up a\npyramid Markov reward process to investigate the long-run average profits of\nthe honest and dishonest mining pools, respectively. Specifically, we show that\nthe long-run average profits are multivariate linear such that we can measure\nthe improvement of mining efficiency of the dishonest mining pool comparing to\nthe honest mining pool. As a by-product, we build three approximative Markov\nprocesses when the system states are described as the block-number difference\nof two forked block branches. Also, by using their special cases with non\nnetwork latency, we can further provide some useful interpretation for both the\nMarkov chain (Figure 1) and the revenue analysis ((1) to (3)) of the seminal\nwork by Eyal and Sirer (2014). Finally, we use some numerical examples to\nverify the correctness and computability of our theoretical results. We hope\nthat the methodology and results developed in this paper shed light on the\nblockchain selfish mining such that a series of promising research can be\nproduced potentially.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 02:02:35 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 16:58:57 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Li", "Quan-Lin", ""], ["Chang", "Yan-Xia", ""], ["Wu", "Xiaole", ""], ["Zhang", "Guoqing", ""]]}, {"id": "2007.01502", "submitter": "Alejandro Mera", "authors": "Alejandro Mera, Bo Feng, Long Lu, Engin Kirda", "title": "DICE: Automatic Emulation of DMA Input Channels for Dynamic Firmware\n  Analysis", "comments": null, "journal-ref": "42nd IEEE Symposium on Security and Privacy, S&P 2021", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microcontroller-based embedded devices are at the core of Internet-of-Things\nand Cyber-Physical Systems. The security of these devices is of paramount\nimportance. Among the approaches to securing embedded devices, dynamic firmware\nanalysis gained great attention lately, thanks to its offline nature and low\nfalse-positive rates. However, regardless of the analysis and emulation\ntechniques used, existing dynamic firmware analyzers share a major limitation,\nnamely the inability to handle firmware using DMA. It severely limits the types\nof devices supported and firmware code coverage. We present DICE, a drop-in\nsolution for firmware analyzers to emulate DMA input channels and generate or\nmanipulate DMA inputs. DICE is designed to be hardware-independent, and\ncompatible with common MCU firmware and embedded architectures. DICE identifies\nDMA input channels as the firmware writes the source and destination DMA\ntransfer pointers into the DMA controller. Then DICE manipulates the input\ntransferred through DMA on behalf of the firmware analyzer. We integrated DICE\nto the firmware analyzer P2IM (Cortex-M architecture) and a PIC32 emulator\n(MIPS M4K/M-Class architecture). We evaluated it on 83 benchmarks and sample\nfirmware, representing 9 different DMA controllers from 5 different vendors.\nDICE detected 33 out of 37 DMA input channels, with 0 false positives. It\ncorrectly supplied DMA inputs to 21 out of 22 DMA buffers, which previous\nfirmware analyzers cannot achieve due to the lack of DMA emulation. DICE's\noverhead is fairly low, it adds 3.4% on average to P2IM execution time. We also\nfuzz-tested 7 real-world firmware using DICE and compared the results with the\noriginal P2IM. DICE uncovered tremendously more execution paths (as much as\n79X) and found 5 unique previously-unknown bugs that are unreachable without\nDMA emulation. All our source code and dataset are publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 05:23:33 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 17:22:32 GMT"}, {"version": "v3", "created": "Fri, 15 Jan 2021 01:41:47 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Mera", "Alejandro", ""], ["Feng", "Bo", ""], ["Lu", "Long", ""], ["Kirda", "Engin", ""]]}, {"id": "2007.01507", "submitter": "Yuting Liang", "authors": "Yuting Liang, Reza Samavi", "title": "Towards Robust Deep Learning with Ensemble Networks and Noisy Layers", "comments": "Accepted into AAAI RSEML 2021 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide an approach for deep learning that protects against\nadversarial examples in image classification-type networks. The approach relies\non two mechanisms:1) a mechanism that increases robustness at the expense of\naccuracy, and, 2) a mechanism that improves accuracy but does not always\nincrease robustness. We show that an approach combining the two mechanisms can\nprovide protection against adversarial examples while retaining accuracy. We\nformulate potential attacks on our approach with experimental results to\ndemonstrate its effectiveness. We also provide a robustness guarantee for our\napproach along with an interpretation for the guarantee.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 06:04:02 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 18:05:57 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Liang", "Yuting", ""], ["Samavi", "Reza", ""]]}, {"id": "2007.01555", "submitter": "Carlos Segarra", "authors": "Carlos Segarra, Ricard Delgado-Gonzalo, Valerio Schiavoni", "title": "MQT-TZ: Secure MQTT Broker for Biomedical Signal Processing on the Edge", "comments": "The definitive version is published in the proceedings of the 2020\n  Medical Informatics Europe Conference (MIE2020)", "journal-ref": "Volume 270: Digital Personalized Health and Medicine 2020 - Pages\n  332 - 336", "doi": "10.3233/SHTI200177", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Physical health records belong to healthcare providers, but the information\ncontained within belongs to each patient. In an increasing manner, more\nhealth-related data is being acquired by wearables and other IoT devices\nfollowing the ever-increasing trend of the \"Quantified Self\". Even though data\nprotection regulations (e.g., GDPR) encourage the usage of privacy-preserving\nprocessing techniques, most of the current IoT infrastructure was not\noriginally conceived for such purposes. One of the most used communication\nprotocols, MQTT, is a lightweight publish-subscribe protocol commonly used in\nthe Edge and IoT applications. In MQTT, the broker must process data on clear\ntext, hence exposing a large attack surface for a malicious agent to\nsteal/tamper with this health-related data. In this paper, we introduce MQT-TZ,\na secure MQTT broker leveraging Arm TrustZone, a popular Trusted Execution\nEnvironment (TEE). We define a mutual TLS-based handshake and a two-layer\nencryption for end-to-end security using the TEE as a trusted proxy. We provide\nquantitative evaluation of our open-source PoC on streaming ECGs in real time\nand highlight the trade-offs.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 08:47:46 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Segarra", "Carlos", ""], ["Delgado-Gonzalo", "Ricard", ""], ["Schiavoni", "Valerio", ""]]}, {"id": "2007.01561", "submitter": "Alberto Giaretta", "authors": "Matthias Forstmann, Alberto Giaretta, and Jennifer Renoux", "title": "Users' Concern for Privacy in Context-Aware Reasoning Systems", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context-aware reasoning systems allow drawing sophisticated inferences about\nusers' behaviour and physiological condition, by aggregating data from\nseemingly unrelated sources. We conducted a general population online survey to\nevaluate users' concern about the privacy of data gathered by these systems. We\nfound that people are more concerned about third parties accessing data\ngathered by environmental sensors as compared to physiological sensors.\nParticipants also indicated greater concern about unfamiliar third parties\n(e.g., private companies) as opposed to familiar third parties (e.g.,\nrelatives). We further found that these concerns are predicted and (to a lesser\ndegree) causally affected by people's beliefs about how much can be inferred\nfrom these types of data, as well as by their background in computer science.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 09:13:57 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Forstmann", "Matthias", ""], ["Giaretta", "Alberto", ""], ["Renoux", "Jennifer", ""]]}, {"id": "2007.01587", "submitter": "Dashan Gao", "authors": "Dashan Gao, Ben Tan, Ce Ju, Vincent W. Zheng and Qiang Yang", "title": "Privacy Threats Against Federated Matrix Factorization", "comments": "6 pages, 2 figures, 1 table, Accepted for Workshop on Federated\n  Learning for Data Privacy and Confidentiality in Conjunction with IJCAI 2020\n  (FL-IJCAI'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix Factorization has been very successful in practical recommendation\napplications and e-commerce. Due to data shortage and stringent regulations, it\ncan be hard to collect sufficient data to build performant recommender systems\nfor a single company. Federated learning provides the possibility to bridge the\ndata silos and build machine learning models without compromising privacy and\nsecurity. Participants sharing common users or items collaboratively build a\nmodel over data from all the participants. There have been some works exploring\nthe application of federated learning to recommender systems and the privacy\nissues in collaborative filtering systems. However, the privacy threats in\nfederated matrix factorization are not studied. In this paper, we categorize\nfederated matrix factorization into three types based on the partition of\nfeature space and analyze privacy threats against each type of federated matrix\nfactorization model. We also discuss privacy-preserving approaches. As far as\nwe are aware, this is the first study of privacy threats of the matrix\nfactorization method in the federated learning framework.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 09:58:52 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Gao", "Dashan", ""], ["Tan", "Ben", ""], ["Ju", "Ce", ""], ["Zheng", "Vincent W.", ""], ["Yang", "Qiang", ""]]}, {"id": "2007.01648", "submitter": "Michel Kinsy", "authors": "Rashmi Agrawal, Lake Bu, Alan Ehret and Michel A. Kinsy", "title": "Fast Arithmetic Hardware Library For RLWE-Based Homomorphic Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": "Report ascs-r06", "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose an open-source, first-of-its-kind, arithmetic\nhardware library with a focus on accelerating the arithmetic operations\ninvolved in Ring Learning with Error (RLWE)-based somewhat homomorphic\nencryption (SHE). We design and implement a hardware accelerator consisting of\nsubmodules like Residue Number System (RNS), Chinese Remainder Theorem (CRT),\nNTT-based polynomial multiplication, modulo inverse, modulo reduction, and all\nthe other polynomial and scalar operations involved in SHE. For all of these\noperations, wherever possible, we include a hardware-cost efficient serial and\na fast parallel implementation in the library. A modular and parameterized\ndesign approach helps in easy customization and also provides flexibility to\nextend these operations for use in most homomorphic encryption applications\nthat fit well into emerging FPGA-equipped cloud architectures. Using the\nsubmodules from the library, we prototype a hardware accelerator on FPGA. The\nevaluation of this hardware accelerator shows a speed up of approximately 4200x\nand 2950x to evaluate a homomorphic multiplication and addition respectively\nwhen compared to an existing software implementation.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 12:30:32 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Agrawal", "Rashmi", ""], ["Bu", "Lake", ""], ["Ehret", "Alan", ""], ["Kinsy", "Michel A.", ""]]}, {"id": "2007.01668", "submitter": "Atul Mantri", "authors": "Christian Badertscher, Alexandru Cojocaru, L\\'eo Colisson, Elham\n  Kashefi, Dominik Leichtle, Atul Mantri, Petros Wallden", "title": "Security Limitations of Classical-Client Delegated Quantum Computing", "comments": "40 pages, 12 figures", "journal-ref": "ASIACRYPT 2020 In: Moriai S., Wang H. (eds) Advances in Cryptology\n  - ASIACRYPT 2020. Lecture Notes in Computer Science, vol 12492. Springer,\n  Cham", "doi": "10.1007/978-3-030-64834-3_23", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure delegated quantum computing allows a computationally weak client to\noutsource an arbitrary quantum computation to an untrusted quantum server in a\nprivacy-preserving manner. One of the promising candidates to achieve classical\ndelegation of quantum computation is classical-client remote state preparation\n($RSP_{CC}$), where a client remotely prepares a quantum state using a\nclassical channel. However, the privacy loss incurred by employing $RSP_{CC}$\nas a sub-module is unclear.\n  In this work, we investigate this question using the Constructive\nCryptography framework by Maurer and Renner (ICS'11). We first identify the\ngoal of $RSP_{CC}$ as the construction of ideal RSP resources from classical\nchannels and then reveal the security limitations of using $RSP_{CC}$. First,\nwe uncover a fundamental relationship between constructing ideal RSP resources\n(from classical channels) and the task of cloning quantum states. Any\nclassically constructed ideal RSP resource must leak to the server the full\nclassical description (possibly in an encoded form) of the generated quantum\nstate, even if we target computational security only. As a consequence, we find\nthat the realization of common RSP resources, without weakening their\nguarantees drastically, is impossible due to the no-cloning theorem. Second,\nthe above result does not rule out that a specific $RSP_{CC}$ protocol can\nreplace the quantum channel at least in some contexts, such as the Universal\nBlind Quantum Computing (UBQC) protocol of Broadbent et al. (FOCS '09).\nHowever, we show that the resulting UBQC protocol cannot maintain its proven\ncomposable security as soon as $RSP_{CC}$ is used as a subroutine. Third, we\nshow that replacing the quantum channel of the above UBQC protocol by the\n$RSP_{CC}$ protocol QFactory of Cojocaru et al. (Asiacrypt '19), preserves the\nweaker, game-based, security of UBQC.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 13:15:13 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Badertscher", "Christian", ""], ["Cojocaru", "Alexandru", ""], ["Colisson", "L\u00e9o", ""], ["Kashefi", "Elham", ""], ["Leichtle", "Dominik", ""], ["Mantri", "Atul", ""], ["Wallden", "Petros", ""]]}, {"id": "2007.01688", "submitter": "Louis Beziaud", "authors": "Tristan Allard (DRUID), Louis B\\'eziaud (LATECE Laboratory - UQAM\n  Montreal, DRUID), S\\'ebastien Gambs (LATECE Laboratory - UQAM Montreal)", "title": "Online publication of court records: circumventing the\n  privacy-transparency trade-off", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The open data movement is leading to the massive publishing of court records\nonline, increasing transparency and accessibility of justice, and to the design\nof legal technologies building on the wealth of legal data available. However,\nthe sensitive nature of legal decisions also raises important privacy issues.\nCurrent practices solve the resulting privacy versus transparency trade-off by\ncombining access control with (manual or semi-manual) text redaction. In this\nwork, we claim that current practices are insufficient for coping with massive\naccess to legal data (restrictive access control policies is detrimental to\nopenness and to utility while text redaction is unable to provide sound privacy\nprotection) and advocate for a in-tegrative approach that could benefit from\nthe latest developments of the privacy-preserving data publishing domain. We\npresent a thorough analysis of the problem and of the current approaches, and\npropose a straw man multimodal architecture paving the way to a full-fledged\nprivacy-preserving legal data publishing system.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 13:58:01 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Allard", "Tristan", "", "DRUID"], ["B\u00e9ziaud", "Louis", "", "LATECE Laboratory - UQAM\n  Montreal, DRUID"], ["Gambs", "S\u00e9bastien", "", "LATECE Laboratory - UQAM Montreal"]]}, {"id": "2007.01721", "submitter": "Soteris Demetriou", "authors": "Hsiao-Ying Huang, Soteris Demetriou, Rini Banerjee, G\\\"uliz Seray\n  Tuncay, Carl A. Gunter, Masooda Bashir", "title": "Smartphone Security Behavioral Scale: A New Psychometric Measurement for\n  Smartphone Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite widespread use of smartphones, there is no measurement standard\ntargeted at smartphone security behaviors. In this paper we translate a\nwell-known cybersecurity behavioral scale into the smartphone domain and show\nthat we can improve on this translation by following an established\npsychometrics approach surveying 1011 participants. We design a new 14-item\nSmartphone Security Behavioral Scale (SSBS) exhibiting high reliability and\ngood fit to a two-component behavioural model based on technical versus social\nprotection strategies. We then demonstrate how SSBS can be applied to measure\nthe influence of mental health issues on smartphone security behavior\nintentions. We found significant correlations that predict SSBS profiles from\nthree types of MHIs. Conversely, we are able to predict presence of MHIs using\nSSBS profiles.We obtain prediction AUCs of 72.1% for Internet addiction,75.8%\nfor depression and 66.2% for insomnia.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 14:43:50 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 17:54:15 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Huang", "Hsiao-Ying", ""], ["Demetriou", "Soteris", ""], ["Banerjee", "Rini", ""], ["Tuncay", "G\u00fcliz Seray", ""], ["Gunter", "Carl A.", ""], ["Bashir", "Masooda", ""]]}, {"id": "2007.01751", "submitter": "Bilge Yigit Ozkan", "authors": "Bilge Yigit Ozkan and Marco Spruit", "title": "Assessing and Improving Cybersecurity Maturity for SMEs: Standardization\n  aspects", "comments": "8 pages, https://www.raid2018.org/smesecworkshop.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SMEs constitute a very large part of the economy in every country and they\nplay an important role in economic growth and social development. SMEs are\nfrequent targets of cybersecurity attacks similar to large enterprises.\nHowever, unlike large enterprises, SMEs mostly have limited capabilities\nregarding cybersecurity practices. Given the increasing cybersecurity risks and\nthe large impact that the risks may bring to the SMEs, assessing and improving\nthe cybersecurity capabilities is crucial for SMEs for sustainability. This\nresearch aims to provide an approach for SMEs for assessing and improving their\ncybersecurity capabilities by integrating key elements from existing industry\nstandards.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 15:18:02 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Ozkan", "Bilge Yigit", ""], ["Spruit", "Marco", ""]]}, {"id": "2007.02013", "submitter": "Mahawaga Arachchige Pathum Chamikara", "authors": "Pathum Chamikara Mahawaga Arachchige, Peter Bertok, Ibrahim Khalil,\n  Dongxi Liu, Seyit Camtepe", "title": "PPaaS: Privacy Preservation as a Service", "comments": null, "journal-ref": null, "doi": "10.1016/j.comcom.2021.04.006", "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personally identifiable information (PII) can find its way into cyberspace\nthrough various channels, and many potential sources can leak such information.\nData sharing (e.g. cross-agency data sharing) for machine learning and\nanalytics is one of the important components in data science. However, due to\nprivacy concerns, data should be enforced with strong privacy guarantees before\nsharing. Different privacy-preserving approaches were developed for privacy\npreserving data sharing; however, identifying the best privacy-preservation\napproach for the privacy-preservation of a certain dataset is still a\nchallenge. Different parameters can influence the efficacy of the process, such\nas the characteristics of the input dataset, the strength of the\nprivacy-preservation approach, and the expected level of utility of the\nresulting dataset (on the corresponding data mining application such as\nclassification). This paper presents a framework named \\underline{P}rivacy\n\\underline{P}reservation \\underline{a}s \\underline{a} \\underline{S}ervice\n(PPaaS) to reduce this complexity. The proposed method employs selective\nprivacy preservation via data perturbation and looks at different dynamics that\ncan influence the quality of the privacy preservation of a dataset. PPaaS\nincludes pools of data perturbation methods, and for each application and the\ninput dataset, PPaaS selects the most suitable data perturbation approach after\nrigorous evaluation. It enhances the usability of privacy-preserving methods\nwithin its pool; it is a generic platform that can be used to sanitize big data\nin a granular, application-specific manner by employing a suitable combination\nof diverse privacy-preserving algorithms to provide a proper balance between\nprivacy and utility.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 05:44:50 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 00:46:49 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 13:30:54 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Arachchige", "Pathum Chamikara Mahawaga", ""], ["Bertok", "Peter", ""], ["Khalil", "Ibrahim", ""], ["Liu", "Dongxi", ""], ["Camtepe", "Seyit", ""]]}, {"id": "2007.02056", "submitter": "Chuan Ma", "authors": "Chuan Ma, Jun Li, Ming Ding, Bo Liu, Kang Wei, Jian Weng and H.\n  Vincent Poor", "title": "RDP-GAN: A R\\'enyi-Differential Privacy based Generative Adversarial\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial network (GAN) has attracted increasing attention\nrecently owing to its impressive ability to generate realistic samples with\nhigh privacy protection. Without directly interactive with training examples,\nthe generative model can be fully used to estimate the underlying distribution\nof an original dataset while the discriminative model can examine the quality\nof the generated samples by comparing the label values with the training\nexamples. However, when GANs are applied on sensitive or private training\nexamples, such as medical or financial records, it is still probable to divulge\nindividuals' sensitive and private information. To mitigate this information\nleakage and construct a private GAN, in this work we propose a\nR\\'enyi-differentially private-GAN (RDP-GAN), which achieves differential\nprivacy (DP) in a GAN by carefully adding random noises on the value of the\nloss function during training. Moreover, we derive the analytical results of\nthe total privacy loss under the subsampling method and cumulated iterations,\nwhich show its effectiveness on the privacy budget allocation. In addition, in\norder to mitigate the negative impact brought by the injecting noise, we\nenhance the proposed algorithm by adding an adaptive noise tuning step, which\nwill change the volume of added noise according to the testing accuracy.\nThrough extensive experimental results, we verify that the proposed algorithm\ncan achieve a better privacy level while producing high-quality samples\ncompared with a benchmark DP-GAN scheme based on noise perturbation on training\ngradients.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 09:51:02 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Ma", "Chuan", ""], ["Li", "Jun", ""], ["Ding", "Ming", ""], ["Liu", "Bo", ""], ["Wei", "Kang", ""], ["Weng", "Jian", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2007.02163", "submitter": "Mohsin Ur Rahman", "authors": "Mohsin Ur Rahman", "title": "Scalable Role-based Access Control Using The EOS Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Role-based access control (RBAC) policies represent the rights of subjects in\nterms of roles to access resources. This research proposes a scalable, flexible\nand auditable RBAC system using the EOS blockchain platform to meet the\nsecurity requirements of organizations. The EOS blockchain platform for\ndeveloping smart contract and decentralized applications (DAPPs) aims to\naddress the scalability problem found in existing blockchain platforms. This\nsmart contract platform aims to eliminate transaction fees while conducting\nmillions of transactions per second. In our proposed approach, the EOS\nblockchain transparently stores RBAC policies. Administrative roles control\naccess to resources at a higher level according to the way organisations\nperform operations. An organisation creates roles, role hierarchies and\nconstraints to regulate user actions. Therefore, once an RBAC framework is\nestablished, the administrative user (issuer) only needs to grant and revoke\nroles to support changes in the organisational structure. Our proposed\nblockchain-based RBAC supports delegation capabilities using gaseless\ntransactions which makes it adoptable and appealing in a large number of\napplication scenarios. Our proposed solution is application-agnostic and\nwell-suited for diverse use cases. Existing state-of-the art security\nframeworks are not suitable due to the difficulty of scale, higher cost and\nsingle point of failure. Consequently, organisations demand a scalable,\ncost-effective and lightweight access control solution which can better protect\ntheir privacy as well. A proof of concept implementation is developed based on\nthe EOS blockchain. Our experimental results and analysis clearly show that our\nEOS blockchain-based RBAC outperforms existing blockchain platforms in terms of\ncost, latency, block generation time, contract execution time and throughput.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 18:45:14 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Rahman", "Mohsin Ur", ""]]}, {"id": "2007.02209", "submitter": "Yiwen Guo", "authors": "Yiwen Guo and Long Chen and Yurong Chen and Changshui Zhang", "title": "On Connections between Regularizations for Improving DNN Robustness", "comments": "Accepted by TPAMI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes regularization terms proposed recently for improving the\nadversarial robustness of deep neural networks (DNNs), from a theoretical point\nof view. Specifically, we study possible connections between several effective\nmethods, including input-gradient regularization, Jacobian regularization,\ncurvature regularization, and a cross-Lipschitz functional. We investigate them\non DNNs with general rectified linear activations, which constitute one of the\nmost prevalent families of models for image classification and a host of other\nmachine learning applications. We shed light on essential ingredients of these\nregularizations and re-interpret their functionality. Through the lens of our\nstudy, more principled and efficient regularizations can possibly be invented\nin the near future.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 23:43:32 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Guo", "Yiwen", ""], ["Chen", "Long", ""], ["Chen", "Yurong", ""], ["Zhang", "Changshui", ""]]}, {"id": "2007.02220", "submitter": "Roei Schuster", "authors": "Roei Schuster, Congzheng Song, Eran Tromer, Vitaly Shmatikov", "title": "You Autocomplete Me: Poisoning Vulnerabilities in Neural Code Completion", "comments": "Accepted at USENIX Security '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code autocompletion is an integral feature of modern code editors and IDEs.\nThe latest generation of autocompleters uses neural language models, trained on\npublic open-source code repositories, to suggest likely (not just statically\nfeasible) completions given the current context.\n  We demonstrate that neural code autocompleters are vulnerable to poisoning\nattacks. By adding a few specially-crafted files to the autocompleter's\ntraining corpus (data poisoning), or else by directly fine-tuning the\nautocompleter on these files (model poisoning), the attacker can influence its\nsuggestions for attacker-chosen contexts. For example, the attacker can \"teach\"\nthe autocompleter to suggest the insecure ECB mode for AES encryption, SSLv3\nfor the SSL/TLS protocol version, or a low iteration count for password-based\nencryption. Moreover, we show that these attacks can be targeted: an\nautocompleter poisoned by a targeted attack is much more likely to suggest the\ninsecure completion for files from a specific repo or specific developer.\n  We quantify the efficacy of targeted and untargeted data- and model-poisoning\nattacks against state-of-the-art autocompleters based on Pythia and GPT-2. We\nthen evaluate existing defenses against poisoning attacks and show that they\nare largely ineffective.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 01:13:36 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 21:34:38 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 23:12:25 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Schuster", "Roei", ""], ["Song", "Congzheng", ""], ["Tromer", "Eran", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "2007.02234", "submitter": "Yi Li", "authors": "Yi Li, Kevin Gao, Yitao Duan, Wei Xu", "title": "Octopus: Privacy-Preserving Collaborative Evaluation of Loan Stacking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of online lenders, the loan stacking problem has become a\nsignificant issue in the financial industry. One of the key steps in the fight\nagainst it is the querying of the loan history of a borrower from peer lenders.\nThis is especially important in markets without a trusted credit bureau. To\nprotect participants privacy and business interests, we want to hide borrower\nidentities and lenders data from the loan originator, while simultaneously\nverifying that the borrower authorizes the query. In this paper, we propose\nOctopus, a distributed system to execute the query while meeting all the above\nsecurity requirements. Theoretically, Octopus is sound. Practically, it\nintegrates multiple optimizations to reduce communication and computation\noverhead. Evaluation shows that Octopus can run on 800 geographically\ndistributed servers and can perform a query within about 0.5 seconds on\naverage.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 03:57:39 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Li", "Yi", ""], ["Gao", "Kevin", ""], ["Duan", "Yitao", ""], ["Xu", "Wei", ""]]}, {"id": "2007.02285", "submitter": "Xiaoyuan Liu", "authors": "Xiaoyuan Liu, Ni Trieu, Evgenios M. Kornaropoulos, Dawn Song", "title": "BeeTrace: A Unified Platform for Secure Contact Tracing that Breaks Data\n  Silos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact tracing is an important method to control the spread of an infectious\ndisease such as COVID-19. However, existing contact tracing methods alone\ncannot provide sufficient coverage and do not successfully address privacy\nconcerns of the participating entities. Current solutions do not utilize the\nhuge volume of data stored in business databases and individual digital\ndevices. This information is typically stored in data silos and cannot be used\ndue to regulations in place. To successfully unlock the potential of contact\ntracing, we need to consider both data utilization from multiple sources and\nthe privacy of the participating parties. To this end, we propose BeeTrace, a\nunified platform that breaks data silos and deploys state-of-the-art\ncryptographic protocols to guarantee privacy goals.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 10:33:45 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Liu", "Xiaoyuan", ""], ["Trieu", "Ni", ""], ["Kornaropoulos", "Evgenios M.", ""], ["Song", "Dawn", ""]]}, {"id": "2007.02287", "submitter": "Bithin Alangot", "authors": "Bithin Alangot, Daniel Reijsbergen, Sarad Venugopalan and Pawel\n  Szalachowski (Singapore University of Technology and Design, Singapore)", "title": "Decentralized Lightweight Detection of Eclipse Attacks on Bitcoin\n  Clients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clients of permissionless blockchain systems, like Bitcoin, rely on an\nunderlying peer-to-peer network to send and receive transactions. It is\ncritical that a client is connected to at least one honest peer, as otherwise\nthe client can be convinced to accept a maliciously forked view of the\nblockchain. In such an eclipse attack, the client is unable to reliably\ndistinguish the canonical view of the blockchain from the view provided by the\nattacker. The consequences of this can be catastrophic if the client makes\nbusiness decisions based on a distorted view of the blockchain transactions. In\nthis paper, we investigate the design space and propose two approaches for\nBitcoin clients to detect whether an eclipse attack against them is ongoing.\nEach approach chooses a different trade-off between average attack detection\ntime and network load. The first scheme is based on the detection of suspicious\nblock timestamps. The second scheme allows blockchain clients to utilize their\nnatural connections to the Internet (i.e., standard web activity) to gossip\nabout their blockchain views with contacted servers and their other clients.\nOur proposals improve upon previously proposed eclipse attack countermeasures\nwithout introducing any dedicated infrastructure or changes to the Bitcoin\nprotocol and network, and we discuss an implementation. We demonstrate the\neffectiveness of the gossip-based schemes through rigorous analysis using\noriginal Internet traffic traces and real-world deployment. The results\nindicate that our protocol incurs a negligible overhead and detects eclipse\nattacks rapidly with high probability, and is well-suited for practical\ndeployment.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 10:42:58 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Alangot", "Bithin", "", "Singapore University of Technology and Design, Singapore"], ["Reijsbergen", "Daniel", "", "Singapore University of Technology and Design, Singapore"], ["Venugopalan", "Sarad", "", "Singapore University of Technology and Design, Singapore"], ["Szalachowski", "Pawel", "", "Singapore University of Technology and Design, Singapore"]]}, {"id": "2007.02307", "submitter": "Thorsten Holz", "authors": "Ali Abbasi, Jos Wetzels, Thorsten Holz, and Sandro Etalle", "title": "Challenges in Designing Exploit Mitigations for Deeply Embedded Systems", "comments": "Published in 4th IEEE European Symposium on Security and Privacy\n  (EuroS&P'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory corruption vulnerabilities have been around for decades and rank among\nthe most prevalent vulnerabilities in embedded systems. Yet this constrained\nenvironment poses unique design and implementation challenges that\nsignificantly complicate the adoption of common hardening techniques. Combined\nwith the irregular and involved nature of embedded patch management, this\nresults in prolonged vulnerability exposure windows and vulnerabilities that\nare relatively easy to exploit. Considering the sensitive and critical nature\nof many embedded systems, this situation merits significant improvement. In\nthis work, we present the first quantitative study of exploit mitigation\nadoption in 42 embedded operating systems, showing the embedded world to\nsignificantly lag behind the general-purpose world. To improve the security of\ndeeply embedded systems, we subsequently present {\\mu}Armor, an approach to\naddress some of the key gaps identified in our quantitative analysis.\n{\\mu}Armor raises the bar for exploitation of embedded memory corruption\nvulnerabilities, while being adoptable on the short term without incurring\nprohibitive extra performance or storage costs.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 12:12:09 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Abbasi", "Ali", ""], ["Wetzels", "Jos", ""], ["Holz", "Thorsten", ""], ["Etalle", "Sandro", ""]]}, {"id": "2007.02308", "submitter": "Thorsten Holz", "authors": "Jannik Pewny, Philipp Koppe, and Thorsten Holz", "title": "Steroids for DOPed Applications: A Compiler for Automated Data-Oriented\n  Programming", "comments": "Published in 4th IEEE European Symposium on Security and Privacy\n  (EuroS&P'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide-spread adoption of system defenses such as the randomization of\ncode, stack, and heap raises the bar for code-reuse attacks. Thus, attackers\nutilize a scripting engine in target programs like a web browser to prepare the\ncode-reuse chain, e.g., relocate gadget addresses or perform a just-in-time\ngadget search. However, many types of programs do not provide such an execution\ncontext that an attacker can use. Recent advances in data-oriented programming\n(DOP) explored an orthogonal way to abuse memory corruption vulnerabilities and\ndemonstrated that an attacker can achieve Turing-complete computations without\nmodifying code pointers in applications. As of now, constructing DOP exploits\nrequires a lot of manual work.\n  In this paper, we present novel techniques to automate the process of\ngenerating DOP exploits. We implemented a compiler called Steroids that\ncompiles our high-level language SLANG into low-level DOP data structures\ndriving malicious computations at run time. This enables an attacker to specify\nher intent in an application- and vulnerability-independent manner to maximize\nreusability. We demonstrate the effectiveness of our techniques and prototype\nimplementation by specifying four programs of varying complexity in SLANG that\ncalculate the Levenshtein distance, traverse a pointer chain to steal a private\nkey, relocate a ROP chain, and perform a JIT-ROP attack. Steroids compiles each\nof those programs to low-level DOP data structures targeted at five different\napplications including GStreamer, Wireshark, and ProFTPd, which have vastly\ndifferent vulnerabilities and DOP instances. Ultimately, this shows that our\ncompiler is versatile, can be used for both 32- and 64-bit applications, works\nacross bug classes, and enables highly expressive attacks without conventional\ncode-injection or code-reuse techniques in applications lacking a scripting\nengine.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 12:12:40 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Pewny", "Jannik", ""], ["Koppe", "Philipp", ""], ["Holz", "Thorsten", ""]]}, {"id": "2007.02314", "submitter": "Thorsten Holz", "authors": "Behrad Garmany, Martin Stoffel, Robert Gawlik, and Thorsten Holz", "title": "Static Detection of Uninitialized Stack Variables in Binary Code", "comments": "Published in 2019 European Symposium on Research in Computer Security\n  (ESORICS'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More than two decades after the first stack smashing attacks, memory\ncorruption vulnerabilities utilizing stack anomalies are still prevalent and\nplay an important role in practice. Among such vulnerabilities, uninitialized\nvariables play an exceptional role due to their unpleasant property of\nunpredictability: as compilers are tailored to operate fast, costly\ninterprocedural analysis procedures are not used in practice to detect such\nvulnerabilities. As a result, complex relationships that expose uninitialized\nmemory reads remain undiscovered in binary code. Recent vulnerability reports\nshow the versatility on how uninitialized memory reads are utilized in\npractice, especially for memory disclosure and code execution. Research in\nrecent years proposed detection and prevention techniques tailored to source\ncode. To date, however, there has not been much attention for these types of\nsoftware bugs within binary executables.\n  In this paper, we present a static analysis framework to find uninitialized\nvariables in binary executables. We developed methods to lift the binaries into\na knowledge representation which builds the base for specifically crafted\nalgorithms to detect uninitialized reads. Our prototype implementation is\ncapable of detecting uninitialized memory errors in complex binaries such as\nweb browsers and OS kernels, and we detected 7 novel bugs.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 12:32:27 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Garmany", "Behrad", ""], ["Stoffel", "Martin", ""], ["Gawlik", "Robert", ""], ["Holz", "Thorsten", ""]]}, {"id": "2007.02317", "submitter": "Abhishek Singh", "authors": "Ramesh Raskar, Abhishek Singh, Sam Zimmerman, Shrikant Kanaparti", "title": "Adding Location and Global Context to the Google/Apple Exposure\n  Notification Bluetooth API", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact tracing requires a strong understanding of the context of a user, and\nlocation with other sensory data could provide a context for any infection\nencounter. Although Bluetooth technology gives a good insight into the\nproximity aspect of an encounter, it does not provide any location context\nrelated to it which helps to make better decisions. Using the ideas presented\nin this paper, one shall be able to obtain this valuable information that could\naddress the problem of false-positive and false-negative to a certain extent.\nAll of this within the purview of Google/Apple Exposure Notification (GAEN)\nspecification, while preserving complete user privacy. There are four ways of\npropagating context between any two users. Two such methods allow private\nlocation logging, without revealing the location history within an app. The\nother two are encryption-based methods. The first encryption method is a\nvariant of Apple's FindMy protocol, that allows nearby Apple devices to capture\nthe GPS location of a lost Apple device. The second encryption is a minor\nmodification of the existing GAEN protocol so that global context is available\nto a healthy phone only when it is exposed - this is a better option\ncomparatively. It will still be the role of Public Health smartphone app to\ndecide, on how to use the location-time context, to build a full-fledged\ncontact tracing and public health solution. Lastly, we highlight the benefits\nand potential privacy issues with each of these context propagation methods\nproposed here.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 08:03:21 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 04:54:47 GMT"}, {"version": "v3", "created": "Sat, 25 Jul 2020 18:04:51 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Raskar", "Ramesh", ""], ["Singh", "Abhishek", ""], ["Zimmerman", "Sam", ""], ["Kanaparti", "Shrikant", ""]]}, {"id": "2007.02326", "submitter": "Thorsten Holz", "authors": "Jannik Pewny and Thorsten Holz", "title": "EvilCoder: Automated Bug Insertion", "comments": "Published in 32nd Annual Conference on Computer Security Applications\n  (ACSAC'16)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The art of finding software vulnerabilities has been covered extensively in\nthe literature and there is a huge body of work on this topic. In contrast, the\nintentional insertion of exploitable, security-critical bugs has received\nlittle (public) attention yet. Wanting more bugs seems to be counterproductive\nat first sight, but the comprehensive evaluation of bug-finding techniques\nsuffers from a lack of ground truth and the scarcity of bugs.\n  In this paper, we propose EvilCoder, a system to automatically find\npotentially vulnerable source code locations and modify the source code to be\nactually vulnerable. More specifically, we leverage automated program analysis\ntechniques to find sensitive sinks which match typical bug patterns (e.g., a\nsensitive API function with a preceding sanity check), and try to find\ndata-flow connections to user-controlled sources. We then transform the source\ncode such that exploitation becomes possible, for example by removing or\nmodifying input sanitization or other types of security checks. Our tool is\ndesigned to randomly pick vulnerable locations and possible modifications, such\nthat it can generate numerous different vulnerabilities on the same software\ncorpus. We evaluated our tool on several open-source projects such as for\nexample libpng and vsftpd, where we found between 22 and 158 unique connected\nsource-sink pairs per project. This translates to hundreds of potentially\nvulnerable data-flow paths and hundreds of bugs we can insert. We hope to\nsupport future bug-finding techniques by supplying freshly generated,\nbug-ridden test corpora so that such techniques can (finally) be evaluated and\ncompared in a comprehensive and statistically meaningful way.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 12:55:38 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Pewny", "Jannik", ""], ["Holz", "Thorsten", ""]]}, {"id": "2007.02351", "submitter": "Christian Weinert", "authors": "Sebastian P. Bayerl, Tommaso Frassetto, Patrick Jauernig, Korbinian\n  Riedhammer, Ahmad-Reza Sadeghi, Thomas Schneider, Emmanuel Stapf, Christian\n  Weinert", "title": "Offline Model Guard: Secure and Private ML on Mobile Devices", "comments": "Original Publication (in the same form): DATE 2020", "journal-ref": "DATE 2020, pages 460-465", "doi": "10.23919/DATE48585.2020.9116560", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performing machine learning tasks in mobile applications yields a challenging\nconflict of interest: highly sensitive client information (e.g., speech data)\nshould remain private while also the intellectual property of service providers\n(e.g., model parameters) must be protected. Cryptographic techniques offer\nsecure solutions for this, but have an unacceptable overhead and moreover\nrequire frequent network interaction. In this work, we design a practically\nefficient hardware-based solution. Specifically, we build Offline Model Guard\n(OMG) to enable privacy-preserving machine learning on the predominant mobile\ncomputing platform ARM - even in offline scenarios. By leveraging a trusted\nexecution environment for strict hardware-enforced isolation from other system\ncomponents, OMG guarantees privacy of client data, secrecy of provided models,\nand integrity of processing algorithms. Our prototype implementation on an ARM\nHiKey 960 development board performs privacy-preserving keyword recognition\nusing TensorFlow Lite for Microcontrollers in real time.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 14:24:24 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Bayerl", "Sebastian P.", ""], ["Frassetto", "Tommaso", ""], ["Jauernig", "Patrick", ""], ["Riedhammer", "Korbinian", ""], ["Sadeghi", "Ahmad-Reza", ""], ["Schneider", "Thomas", ""], ["Stapf", "Emmanuel", ""], ["Weinert", "Christian", ""]]}, {"id": "2007.02393", "submitter": "Seung-Hun Nam", "authors": "Seung-Hun Nam, Wonhyuk Ahn, In-Jae Yu, Myung-Joon Kwon, Minseok Son,\n  Heung-Kyu Lee", "title": "Deep Convolutional Neural Network for Identifying Seam-Carving Forgery", "comments": null, "journal-ref": null, "doi": "10.1109/TCSVT.2020.3037662", "report-no": null, "categories": "cs.MM cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seam carving is a representative content-aware image retargeting approach to\nadjust the size of an image while preserving its visually prominent content. To\nmaintain visually important content, seam-carving algorithms first calculate\nthe connected path of pixels, referred to as the seam, according to a defined\ncost function and then adjust the size of an image by removing and duplicating\nrepeatedly calculated seams. Seam carving is actively exploited to overcome\ndiversity in the resolution of images between applications and devices; hence,\ndetecting the distortion caused by seam carving has become important in image\nforensics. In this paper, we propose a convolutional neural network (CNN)-based\napproach to classifying seam-carving-based image retargeting for reduction and\nexpansion. To attain the ability to learn low-level features, we designed a CNN\narchitecture comprising five types of network blocks specialized for capturing\nsubtle signals. An ensemble module is further adopted to both enhance\nperformance and comprehensively analyze the features in the local areas of the\ngiven image. To validate the effectiveness of our work, extensive experiments\nbased on various CNN-based baselines were conducted. Compared to the baselines,\nour work exhibits state-of-the-art performance in terms of three-class\nclassification (original, seam inserted, and seam removed). In addition, our\nmodel with the ensemble module is robust for various unseen cases. The\nexperimental results also demonstrate that our method can be applied to\nlocalize both seam-removed and seam-inserted areas.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 17:20:51 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 09:33:23 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Nam", "Seung-Hun", ""], ["Ahn", "Wonhyuk", ""], ["Yu", "In-Jae", ""], ["Kwon", "Myung-Joon", ""], ["Son", "Minseok", ""], ["Lee", "Heung-Kyu", ""]]}, {"id": "2007.02407", "submitter": "Ishai Rosenberg", "authors": "Ihai Rosenberg and Asaf Shabtai and Yuval Elovici and Lior Rokach", "title": "Adversarial Machine Learning Attacks and Defense Methods in the Cyber\n  Security Domain", "comments": "Accepted as a long survey paper at ACM CSUR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years machine learning algorithms, and more specifically deep\nlearning algorithms, have been widely used in many fields, including cyber\nsecurity. However, machine learning systems are vulnerable to adversarial\nattacks, and this limits the application of machine learning, especially in\nnon-stationary, adversarial environments, such as the cyber security domain,\nwhere actual adversaries (e.g., malware developers) exist. This paper\ncomprehensively summarizes the latest research on adversarial attacks against\nsecurity solutions based on machine learning techniques and illuminates the\nrisks they pose. First, the adversarial attack methods are characterized based\non their stage of occurrence, and the attacker's goals and capabilities. Then,\nwe categorize the applications of adversarial attack and defense methods in the\ncyber security domain. Finally, we highlight some characteristics identified in\nrecent research and discuss the impact of recent advancements in other\nadversarial learning domains on future research directions in the cyber\nsecurity domain. This paper is the first to discuss the unique challenges of\nimplementing end-to-end adversarial attacks in the cyber security domain, map\nthem in a unified taxonomy, and use the taxonomy to highlight future research\ndirections.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 18:22:40 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 00:38:42 GMT"}, {"version": "v3", "created": "Sat, 13 Mar 2021 19:31:59 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Rosenberg", "Ihai", ""], ["Shabtai", "Asaf", ""], ["Elovici", "Yuval", ""], ["Rokach", "Lior", ""]]}, {"id": "2007.02617", "submitter": "Maksym Andriushchenko", "authors": "Maksym Andriushchenko, Nicolas Flammarion", "title": "Understanding and Improving Fast Adversarial Training", "comments": "The camera-ready version (accepted at NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent line of work focused on making adversarial training computationally\nefficient for deep learning models. In particular, Wong et al. (2020) showed\nthat $\\ell_\\infty$-adversarial training with fast gradient sign method (FGSM)\ncan fail due to a phenomenon called \"catastrophic overfitting\", when the model\nquickly loses its robustness over a single epoch of training. We show that\nadding a random step to FGSM, as proposed in Wong et al. (2020), does not\nprevent catastrophic overfitting, and that randomness is not important per se\n-- its main role being simply to reduce the magnitude of the perturbation.\nMoreover, we show that catastrophic overfitting is not inherent to deep and\noverparametrized networks, but can occur in a single-layer convolutional\nnetwork with a few filters. In an extreme case, even a single filter can make\nthe network highly non-linear locally, which is the main reason why FGSM\ntraining fails. Based on this observation, we propose a new regularization\nmethod, GradAlign, that prevents catastrophic overfitting by explicitly\nmaximizing the gradient alignment inside the perturbation set and improves the\nquality of the FGSM solution. As a result, GradAlign allows to successfully\napply FGSM training also for larger $\\ell_\\infty$-perturbations and reduce the\ngap to multi-step adversarial training. The code of our experiments is\navailable at https://github.com/tml-epfl/understanding-fast-adv-training.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 10:16:43 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 11:20:16 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Andriushchenko", "Maksym", ""], ["Flammarion", "Nicolas", ""]]}, {"id": "2007.02628", "submitter": "Alessandro Ecclesie Agazzi", "authors": "Alessandro Ecclesie Agazzi", "title": "Smart Home, security concerns of IoT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The IoT (Internet of Things) has become widely popular in the domestic\nenvironments. People are renewing their homes into smart homes; however, the\nprivacy concerns of owning many Internet connected devices with always-on\nenvironmental sensors remain insufficiently addressed. Default and weak\npasswords, cheap materials and hardware, and unencrypted communication are\nidentified as the principal threats and vulnerabilities of IoT devices.\nSolutions and countermeasures are also provided: choosing a strong password,\nstrong authentication mechanisms, check online databases of exposed or default\ncredentials to mitigate the first threat; a selection of smart home devices\nfrom reputable companies and the implementation of the SDN for the Dos/DDoS\nthreat; and finally IDS, HTTPS protocol and VPN for eavesdropping. The paper\nconcludes dealing with a further challenge, \"the lack of technical support\", by\nwhich an auto-configuration approach should be analysed; this could both ease\nthe installation/maintenance and enhance the security in the self configuration\nstep of Smart Home devices.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 10:36:11 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Agazzi", "Alessandro Ecclesie", ""]]}, {"id": "2007.02652", "submitter": "Magnus Westerlund", "authors": "John Wickstr\\\"om and Magnus Westerlund and G\\\"oran Pulkkis", "title": "Rethinking IoT Security: A Protocol Based on Blockchain Smart Contracts\n  for Secure and Automated IoT Deployments", "comments": "Pre-print version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Proliferation of IoT devices in society demands a renewed focus on securing\nthe use and maintenance of such systems. IoT-based systems will have a great\nimpact on society and therefore such systems must have guaranteed resilience.\nWe introduce cryptographic-based building blocks that strive to ensure that\ndistributed IoT networks remain in a healthy condition throughout their\nlifecycle. Our presented solution utilizes deterministic and interlinked smart\ncontracts on the Ethereum blockchain to enforce secured management and\nmaintenance for hardened IoT devices. A key issue investigated is the protocol\ndevelopment for securing IoT device deployments and means for communicating\nsecurely with devices. By supporting values of openness, automation, and\nprovenance, we can introduce novel means that reduce the threats of\nsurveillance and theft, while also improving operator accountability and trust\nin IoT technology.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 11:20:45 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Wickstr\u00f6m", "John", ""], ["Westerlund", "Magnus", ""], ["Pulkkis", "G\u00f6ran", ""]]}, {"id": "2007.02661", "submitter": "Muhammad R. A. Khandaker PhD", "authors": "Md. Tanvir Rahman, Risala T. Khan, Muhammad R. A. Khandaker, and Md.\n  Sifat Ar Salan", "title": "An Automated Contact Tracing Approach for Controlling Covid-19 Spread\n  Based on Geolocation Data from Mobile Cellular Networks", "comments": "Submitted to IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coronavirus (COVID-19) has appeared as the greatest challenge due to its\ncontinuous structural evolution as well as the absence of proper antidotes for\nthis particular virus. The virus mainly spreads and replicates itself among\nmass people through close contact which unfortunately can happen in many\nunpredictable ways. Therefore, to slow down the spread of this novel virus, the\nonly relevant initiatives are to maintain social distance, perform contact\ntracing, use proper safety gears, and impose quarantine measures. But despite\nbeing theoretically possible, these approaches are very difficult to uphold in\ndensely populated countries and areas. Therefore, to control the virus spread,\nresearchers and authorities are considering the use of smartphone based mobile\napplications (apps) to identify the likely infected persons as well as the\nhighly risky zones to maintain isolation and lockdown measures. However, these\nmethods heavily depend on advanced technological features and expose\nsignificant privacy loopholes. In this paper, we propose a new method for\nCOVID-19 contact tracing based on mobile phone users' geolocation data. The\nproposed method will help the authorities to identify the number of probable\ninfected persons without using smartphone based mobile applications. In\naddition, the proposed method can help people take the vital decision of when\nto seek medical assistance by letting them know whether they are already in the\nlist of exposed persons. Numerical examples demonstrate that the proposed\nmethod can significantly outperform the smartphone app-based solutions.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 11:40:23 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Rahman", "Md. Tanvir", ""], ["Khan", "Risala T.", ""], ["Khandaker", "Muhammad R. A.", ""], ["Salan", "Md. Sifat Ar", ""]]}, {"id": "2007.02719", "submitter": "Praneeth Vepakomma", "authors": "Praneeth Vepakomma, Julia Balla, Ramesh Raskar", "title": "Splintering with distributions: A stochastic decoy scheme for private\n  computation", "comments": "28 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performing computations while maintaining privacy is an important problem in\ntodays distributed machine learning solutions. Consider the following two set\nups between a client and a server, where in setup i) the client has a public\ndata vector $\\mathbf{x}$, the server has a large private database of data\nvectors $\\mathcal{B}$ and the client wants to find the inner products $\\langle\n\\mathbf{x,y_k} \\rangle, \\forall \\mathbf{y_k} \\in \\mathcal{B}$. The client does\nnot want the server to learn $\\mathbf{x}$ while the server does not want the\nclient to learn the records in its database. This is in contrast to another\nsetup ii) where the client would like to perform an operation solely on its\ndata, such as computation of a matrix inverse on its data matrix $\\mathbf{M}$,\nbut would like to use the superior computing ability of the server to do so\nwithout having to leak $\\mathbf{M}$ to the server. \\par We present a stochastic\nscheme for splitting the client data into privatized shares that are\ntransmitted to the server in such settings. The server performs the requested\noperations on these shares instead of on the raw client data at the server. The\nobtained intermediate results are sent back to the client where they are\nassembled by the client to obtain the final result.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 13:06:49 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 19:23:39 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Vepakomma", "Praneeth", ""], ["Balla", "Julia", ""], ["Raskar", "Ramesh", ""]]}, {"id": "2007.02730", "submitter": "Pierre-Jean Spaenlehauer", "authors": "Aude Le Gluher and Pierre-Jean Spaenlehauer and Emmanuel Thom\\'e", "title": "Refined Analysis of the Asymptotic Complexity of the Number Field Sieve", "comments": "Accepted for publication in Mathematical Cryptology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical heuristic complexity of the Number Field Sieve (NFS) is the\nsolution of an optimization problem that involves an unknown function, usually\nnoted $o(1)$ and called $\\xi(N)$ throughout this paper, which tends to zero as\nthe entry $N$ grows. The aim of this paper is to find optimal asymptotic\nchoices of the parameters of NFS as $N$ grows, in order to minimize its\nheuristic asymptotic computational cost. This amounts to minimizing a function\nof the parameters of NFS bound together by a non-linear constraint. We provide\nprecise asymptotic estimates of the minimizers of this optimization problem,\nwhich yield refined formulas for the asymptotic complexity of NFS. One of the\nmain outcomes of this analysis is that $\\xi(N)$ has a very slow rate of\nconvergence: We prove that it is equivalent to\n$4{\\log}{\\log}{\\log}\\,N/(3{\\log}{\\log}\\,N)$. Moreover, $\\xi(N)$ has an\nunpredictable behavior for practical estimates of the complexity. Indeed, we\nprovide an asymptotic series expansion of $\\xi$ and numerical experiments\nindicate that this series starts converging only for $N>\\exp(\\exp(25))$, far\nbeyond the practical range of NFS. This raises doubts on the relevance of NFS\nrunning time estimates that are based on setting $\\xi=0$ in the asymptotic\nformula.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 13:10:01 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 13:32:28 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Gluher", "Aude Le", ""], ["Spaenlehauer", "Pierre-Jean", ""], ["Thom\u00e9", "Emmanuel", ""]]}, {"id": "2007.02734", "submitter": "Hadi Mohaghegh Dolatabadi", "authors": "Hadi M. Dolatabadi, Sarah Erfani, Christopher Leckie", "title": "Black-box Adversarial Example Generation with Normalizing Flows", "comments": "Accepted to the 2nd workshop on Invertible Neural Networks,\n  Normalizing Flows, and Explicit Likelihood Models (ICML 2020), Virtual\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network classifiers suffer from adversarial vulnerability:\nwell-crafted, unnoticeable changes to the input data can affect the classifier\ndecision. In this regard, the study of powerful adversarial attacks can help\nshed light on sources of this malicious behavior. In this paper, we propose a\nnovel black-box adversarial attack using normalizing flows. We show how an\nadversary can be found by searching over a pre-trained flow-based model base\ndistribution. This way, we can generate adversaries that resemble the original\ndata closely as the perturbations are in the shape of the data. We then\ndemonstrate the competitive performance of the proposed approach against\nwell-known black-box adversarial attack methods.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 13:14:21 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Dolatabadi", "Hadi M.", ""], ["Erfani", "Sarah", ""], ["Leckie", "Christopher", ""]]}, {"id": "2007.02806", "submitter": "Alain Mermoud", "authors": "Franck Legendre, Mathias Humbert, Alain Mermoud, Vincent Lenders", "title": "Contact Tracing: An Overview of Technologies and Cyber Risks", "comments": "26 pages, Technology Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 2020 COVID-19 pandemic has led to a global lockdown with severe health\nand economical consequences. As a result, authorities around the globe have\nexpressed their needs for better tools to monitor the spread of the virus and\nto support human labor. Researchers and technology companies such as Google and\nApple have offered to develop such tools in the form of contact tracing\napplications. The goal of these applications is to continuously track people's\nproximity and to make the smartphone users aware if they have ever been in\ncontact with positively diagnosed people, so that they could self-quarantine\nand possibly have an infection test. A fundamental challenge with these\nsmartphone-based contact tracing technologies is to ensure the security and\nprivacy of their users. Moving from manual to smartphone-based contact tracing\ncreates new cyber risks that could suddenly affect the entire population. Major\nrisks include for example the abuse of the people's private data by companies\nand/or authorities, or the spreading of wrong alerts by malicious users in\norder to force individuals to go into quarantine. In April 2020, the\nPan-European Privacy-Preserving Proximity Tracing (PEPP-PT) was announced with\nthe goal to develop and evaluate secure solutions for European countries.\nHowever, after a while, several team members left this consortium and created\nDP-3T which has led to an international debate among the experts. At this time,\nit is confusing for the non-expert to follow this debate; this report aims to\nshed light on the various proposed technologies by providing an objective\nassessment of the cybersecurity and privacy risks. We first review the\nstate-of-the-art in digital contact tracing technologies and then explore the\nrisk-utility trade-offs of the techniques proposed for COVID-19. We focus\nspecifically on the technologies that are already adopted by certain countries.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 15:10:20 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Legendre", "Franck", ""], ["Humbert", "Mathias", ""], ["Mermoud", "Alain", ""], ["Lenders", "Vincent", ""]]}, {"id": "2007.03121", "submitter": "Wenbo Ren", "authors": "Wenbo Ren, Xingyu Zhou, Jia Liu, Ness B. Shroff", "title": "Multi-Armed Bandits with Local Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the problem of regret minimization for multi-armed\nbandit (MAB) problems with local differential privacy (LDP) guarantee. In\nstochastic bandit systems, the rewards may refer to the users' activities,\nwhich may involve private information and the users may not want the agent to\nknow. However, in many cases, the agent needs to know these activities to\nprovide better services such as recommendations and news feeds. To handle this\ndilemma, we adopt differential privacy and study the regret upper and lower\nbounds for MAB algorithms with a given LDP guarantee. In this paper, we prove a\nlower bound and propose algorithms whose regret upper bounds match the lower\nbound up to constant factors. Numerical experiments also confirm our\nconclusions.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 23:36:20 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Ren", "Wenbo", ""], ["Zhou", "Xingyu", ""], ["Liu", "Jia", ""], ["Shroff", "Ness B.", ""]]}, {"id": "2007.03172", "submitter": "Song Tian", "authors": "Song Tian", "title": "Translating the discrete logarithm problem on Jacobians of genus 3\n  hyperelliptic curves with $(\\ell,\\ell,\\ell)$-isogenies", "comments": null, "journal-ref": "Journal of Cryptology 2021", "doi": "10.1007/s00145-021-09401-3", "report-no": null, "categories": "math.AG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an algorithm to compute $(\\ell,\\ell,\\ell)$-isogenies from the\nJacobians of genus three hyperelliptic curves to the Jacobians of\nnon-hyperelliptic curves. An important application is to reduce the discrete\nlogarithm problem in the Jacobian of a hyperelliptic curve to the corresponding\nproblem in the Jacobian of a non-hyperelliptic curve.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 02:23:36 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Tian", "Song", ""]]}, {"id": "2007.03302", "submitter": "Thorsten Holz", "authors": "Andre Pawlowski, Victor van der Veen, Dennis Andriesse, Erik van der\n  Kouwe, Thorsten Holz, Cristiano Giuffrida, Herbert Bos", "title": "VPS: Excavating High-Level C++ Constructs from Low-Level Binaries to\n  Protect Dynamic Dispatching", "comments": "Published in Annual Computer Security Applications Conference\n  (ACSAC'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polymorphism and inheritance make C++ suitable for writing complex software,\nbut significantly increase the attack surface because the implementation relies\non virtual function tables (vtables). These vtables contain function pointers\nthat attackers can potentially hijack and in practice, vtable hijacking is one\nof the most important attack vector for C++ binaries.\n  In this paper, we present VTable Pointer Separation (VPS), a practical\nbinary-level defense against vtable hijacking in C++ applications. Unlike\nprevious binary-level defenses, which rely on unsound static analyses to match\nclasses to virtual callsites, VPS achieves a more accurate protection by\nrestricting virtual callsites to validly created objects. More specifically,\nVPS ensures that virtual callsites can only use objects created at valid object\nconstruction sites, and only if those objects can reach the callsite. Moreover,\nVPS explicitly prevents false positives (falsely identified virtual callsites)\nfrom breaking the binary, an issue existing work does not handle correctly or\nat all. We evaluate the prototype implementation of VPS on a diverse set of\ncomplex, real-world applications (MongoDB, MySQL server, Node.js, SPEC\nCPU2017/CPU2006), showing that our approach protects on average 97.8% of all\nvirtual callsites in SPEC CPU2006 and 97.4% in SPEC CPU2017 (all C++\nbenchmarks), with a moderate performance overhead of 11% and 9% geomean,\nrespectively. Furthermore, our evaluation reveals 86 false negatives in VTV, a\npopular source-based defense which is part of GCC.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 09:32:06 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Pawlowski", "Andre", ""], ["van der Veen", "Victor", ""], ["Andriesse", "Dennis", ""], ["van der Kouwe", "Erik", ""], ["Holz", "Thorsten", ""], ["Giuffrida", "Cristiano", ""], ["Bos", "Herbert", ""]]}, {"id": "2007.03330", "submitter": "Hassan Habibi Gharakheili", "authors": "Mohammad Hossein Chinaei and Hassan Habibi Gharakheili and Vijay\n  Sivaraman", "title": "Optimal Witnessing of Healthcare IoT Data Using Blockchain Logging\n  Contract", "comments": "12 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verification of data generated by wearable sensors is increasingly becoming\nof concern to health service providers and insurance companies. There is a need\nfor a verification framework that various authorities can request a\nverification service for the local network data of a target IoT device. In this\npaper, we leverage blockchain as a distributed platform to realize an on-demand\nverification scheme. This allows authorities to automatically transact with\nconnected devices for witnessing services. A public request is made for witness\nstatements on the data of a target IoT that is transmitted on its local\nnetwork, and subsequently, devices (in close vicinity of the target IoT) offer\nwitnessing service.\n  Our contributions are threefold: (1) We develop a system architecture based\non blockchain and smart contract that enables authorities to dynamically avail\na verification service for data of a subject device from a distributed set of\nwitnesses which are willing to provide (in a privacy-preserving manner) their\nlocal wireless measurement in exchange of monetary return; (2) We then develop\na method to optimally select witnesses in such a way that the verification\nerror is minimized subject to monetary cost constraints; (3) Lastly, we\nevaluate the efficacy of our scheme using real Wi-Fi session traces collected\nfrom a five-storeyed building with more than thirty access points,\nrepresentative of a hospital. According to the current pricing schedule of the\nEthereum public blockchain, our scheme enables healthcare authorities to verify\ndata transmitted from a typical wearable device with the verification error of\nthe order 0.01% at cost of less than two dollars for one-hour witnessing\nservice.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 10:34:23 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Chinaei", "Mohammad Hossein", ""], ["Gharakheili", "Hassan Habibi", ""], ["Sivaraman", "Vijay", ""]]}, {"id": "2007.03486", "submitter": "Simon Yusuf Enoch", "authors": "Simon Yusuf Enoch and Jin B. Hong and Mengmeng Ge and Dong Seong Kim", "title": "Composite Metrics for Network Security Analysis", "comments": "21 pages journal", "journal-ref": "Software Networking, 2018(1), 137-160", "doi": "10.13052/jsn2445-9739.2017.007", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security metrics present the security level of a system or a network in both\nqualitative and quantitative ways. In general, security metrics are used to\nassess the security level of a system and to achieve security goals. There are\na lot of security metrics for security analysis, but there is no systematic\nclassification of security metrics that are based on network reachability\ninformation. To address this, we propose a systematic classification of\nexisting security metrics based on network reachability information. Mainly, we\nclassify the security metrics into host-based and network-based metrics. The\nhost-based metrics are classified into metrics ``without probability\" and \"with\nprobability\", while the network-based metrics are classified into \"path-based\"\nand \"non-path based\". Finally, we present and describe an approach to develop\ncomposite security metrics and it's calculations using a Hierarchical Attack\nRepresentation Model (HARM) via an example network. Our novel classification of\nsecurity metrics provides a new methodology to assess the security of a system.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 14:18:31 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 23:44:40 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Enoch", "Simon Yusuf", ""], ["Hong", "Jin B.", ""], ["Ge", "Mengmeng", ""], ["Kim", "Dong Seong", ""]]}, {"id": "2007.03505", "submitter": "Gabriele D'Angelo", "authors": "Mirko Zichichi, Stefano Ferretti, Gabriele D'Angelo", "title": "On the Efficiency of Decentralized File Storage for Personal Information\n  Management Systems", "comments": "To appear in the Proceedings of the 25th IEEE Symposium on Computers\n  and Communications (ISCC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.IR cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an architecture, based on Distributed Ledger Technologies\n(DLTs) and Decentralized File Storage (DFS) systems, to support the use of\nPersonal Information Management Systems (PIMS). DLT and DFS are used to manage\ndata sensed by mobile users equipped with devices with sensing capability. DLTs\nguarantee the immutability, traceability and verifiability of references to\npersonal data, that are stored in DFS. In fact, the inclusion of data digests\nin the DLT makes it possible to obtain an unalterable reference and a\ntamper-proof log, while remaining compliant with the regulations on personal\ndata, i.e. GDPR. We provide an experimental evaluation on the feasibility of\nthe use of DFS. Three different scenarios have been studied: i) a proprietary\nIPFS approach with a dedicated node interfacing with the data producers, ii) a\npublic IPFS service and iii) Sia Skynet. Results show that through proper\nconfiguration of the system infrastructure, it is viable to build a\ndecentralized Personal Data Storage (PDS).\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 14:41:18 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Zichichi", "Mirko", ""], ["Ferretti", "Stefano", ""], ["D'Angelo", "Gabriele", ""]]}, {"id": "2007.03531", "submitter": "Avi Asayag", "authors": "David Yakira, Avi Asayag, Ido Grayevsky, Idit Keidar", "title": "Economically Viable Randomness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of providing blockchain applications with\n\\emph{economically viable randomness} (EVR), namely, randomness that has\nsignificant economic consequences. Applications of EVR include blockchain-based\nlotteries and gambling. An EVR source guarantees (i) secrecy, assuring that the\nrandom bits are kept secret until some predefined condition indicates that they\nare safe to reveal (e.g., the lottery's ticket sale closes), and (ii)\nrobustness, guaranteeing that the random bits are published once the condition\nholds. We formalize the EVR problem and solve it on top of an Ethereum-like\nblockchain abstraction, which supports smart contracts and a transferable\nnative coin. Randomness is generated via a distributed open commit-reveal\nscheme by game-theoretic agents who strive to maximize their coin holdings.\nNote that in an economic setting, such agents might profit from breaking\nsecrecy or robustness, and may engage in side agreements (via smart contracts)\nto this end. Our solution creates an incentive structure that counters such\nattacks. We prove that following the protocol gives rise to a stable state,\ncalled Coalition-Proof Nash Equilibrium, from which no coalition comprised of a\nsubset of the players can agree to deviate. In this stable state, robustness\nand secrecy are satisfied. Finally, we implement our EVR source over Ethereum.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 15:01:27 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Yakira", "David", ""], ["Asayag", "Avi", ""], ["Grayevsky", "Ido", ""], ["Keidar", "Idit", ""]]}, {"id": "2007.03548", "submitter": "Thorsten Holz", "authors": "Jannik Pewny, Philipp Koppe, Lucas Davi, and Thorsten Holz", "title": "Breaking and Fixing Destructive Code Read Defenses", "comments": "Published in 33rd Annual Computer Security Applications Conference\n  (ACSAC'17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Just-in-time return-oriented programming (JIT-ROP) is a powerful memory\ncorruption attack that bypasses various forms of code randomization.\nExecute-only memory (XOM) can potentially prevent these attacks, but requires\nsource code. In contrast, destructive code reads (DCR) provide a trade-off\nbetween security and legacy compatibility. The common belief is that DCR\nprovides strong protection if combined with a high-entropy code randomization.\n  The contribution of this paper is twofold: first, we demonstrate that DCR can\nbe bypassed regardless of the underlying code randomization scheme. To this\nend, we show novel, generic attacks that infer the code layout for highly\nrandomized program code. Second, we present the design and implementation of\nBGDX (Byte-Granular DCR and XOM), a novel mitigation technique that protects\nlegacy binaries against code inference attacks. BGDX enforces memory\npermissions on a byte-granular level allowing us to combine DCR and XOM for\nlegacy, off-the-shelf binaries. Our evaluation shows that BGDX is not only\neffective, but highly efficient, imposing only a geometric mean performance\noverhead of 3.95% on SPEC.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 13:19:02 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Pewny", "Jannik", ""], ["Koppe", "Philipp", ""], ["Davi", "Lucas", ""], ["Holz", "Thorsten", ""]]}, {"id": "2007.03549", "submitter": "Thorsten Holz", "authors": "Benjamin Kollenda, Philipp Koppe, Marc Fyrbiak, Christian Kison,\n  Christof Paar, Thorsten Holz", "title": "An Exploratory Analysis of Microcode as a Building Block for System\n  Defenses", "comments": "Published in ACM SIGSAC Conference on Computer and Communications\n  Security (CCS'18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microcode is an abstraction layer used by modern x86 processors that\ninterprets user-visible CISC instructions to hardware-internal RISC\ninstructions. The capability to update x86 microcode enables a vendor to modify\nCPU behavior in-field, and thus patch erroneous microarchitectural processes or\neven implement new features. Most prominently, the recent Spectre and Meltdown\nvulnerabilities were mitigated by Intel via microcode updates. Unfortunately,\nmicrocode is proprietary and closed source, and there is little publicly\navailable information on its inner workings.\n  In this paper, we present new reverse engineering results that extend and\ncomplement the public knowledge of proprietary microcode. Based on these novel\ninsights, we show how modern system defenses and tools can be realized in\nmicrocode on a commercial, off-the-shelf AMD x86 CPU. We demonstrate how\nwell-established system security defenses such as timing attack mitigations,\nhardware-assisted address sanitization, and instruction set randomization can\nbe realized in microcode. We also present a proof-of-concept implementation of\na microcode-assisted instrumentation framework. Finally, we show how a secure\nmicrocode update mechanism and enclave functionality can be implemented in\nmicrocode to realize a small trusted execution environment. All microcode\nprograms and the whole infrastructure needed to reproduce and extend our\nresults are publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 14:59:31 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Kollenda", "Benjamin", ""], ["Koppe", "Philipp", ""], ["Fyrbiak", "Marc", ""], ["Kison", "Christian", ""], ["Paar", "Christof", ""], ["Holz", "Thorsten", ""]]}, {"id": "2007.03550", "submitter": "Thorsten Holz", "authors": "Robert Gawlik, Philipp Koppe, Benjamin Kollenda, Andre Pawlowski,\n  Behrad Garmany and Thorsten Holz", "title": "Detile: Fine-Grained Information Leak Detection in Script Engines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory disclosure attacks play an important role in the exploitation of\nmemory corruption vulnerabilities. By analyzing recent research, we observe\nthat bypasses of defensive solutions that enforce control-flow integrity or\nattempt to detect return-oriented programming require memory disclosure attacks\nas a fundamental first step. However, research lags behind in detecting such\ninformation leaks.\n  In this paper, we tackle this problem and present a system for fine-grained,\nautomated detection of memory disclosure attacks against scripting engines. The\nbasic insight is as follows: scripting languages, such as JavaScript in web\nbrowsers, are strictly sandboxed. They must not provide any insights about the\nmemory layout in their contexts. In fact, any such information potentially\nrepresents an ongoing memory disclosure attack. Hence, to detect information\nleaks, our system creates a clone of the scripting engine process with a\nre-randomized memory layout. The clone is instrumented to be synchronized with\nthe original process. Any inconsistency in the script contexts of both\nprocesses appears when a memory disclosure was conducted to leak information\nabout the memory layout. Based on this detection approach, we have designed and\nimplemented Detile (\\underline{det}ection of \\underline{i}nformation\n\\underline{le}aks), a prototype for the JavaScript engine in Microsoft's\nInternet Explorer 10/11 on Windows 8.0/8.1. An empirical evaluation shows that\nour tool can successfully detect memory disclosure attacks even against this\nproprietary software.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 15:28:05 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Gawlik", "Robert", ""], ["Koppe", "Philipp", ""], ["Kollenda", "Benjamin", ""], ["Pawlowski", "Andre", ""], ["Garmany", "Behrad", ""], ["Holz", "Thorsten", ""]]}, {"id": "2007.03602", "submitter": "Brian Bockelman", "authors": "Brian Bockelman, Andrea Ceccanti, Ian Collier, Linda Cornwall, Thomas\n  Dack, Jaroslav Guenther, Mario Lassnig, Maarten Litmaath, Paul Millar, Mischa\n  Sall\\'e, Hannah Short, Jeny Teheran, Romain Wartel", "title": "WLCG Authorisation from X.509 to Tokens", "comments": "8 pages, 3 figures, to appear in the proceedings of CHEP 2019", "journal-ref": null, "doi": "10.1051/epjconf/202024503001", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The WLCG Authorisation Working Group was formed in July 2017 with the\nobjective to understand and meet the needs of a future-looking Authentication\nand Authorisation Infrastructure (AAI) for WLCG experiments. Much has changed\nsince the early 2000s when X.509 certificates presented the most suitable\nchoice for authorisation within the grid; progress in token based authorisation\nand identity federation has provided an interesting alternative with notable\nadvantages in usability and compatibility with external (commercial) partners.\nThe need for interoperability in this new model is paramount as infrastructures\nand research communities become increasingly interdependent. Over the past two\nyears, the working group has made significant steps towards identifying a\nsystem to meet the technical needs highlighted by the community during staged\nrequirements gathering activities. Enhancement work has been possible thanks to\nexternally funded projects, allowing existing AAI solutions to be adapted to\nour needs. A cornerstone of the infrastructure is the reliance on a common\ntoken schema in line with evolving standards and best practices, allowing for\nmaximum compatibility and easy cooperation with peer infrastructures and\nservices. We present the work of the group and an analysis of the anticipated\nchanges in authorisation model by moving from X.509 to token based\nauthorisation. A concrete example of token integration in Rucio is presented.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 16:39:30 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Bockelman", "Brian", ""], ["Ceccanti", "Andrea", ""], ["Collier", "Ian", ""], ["Cornwall", "Linda", ""], ["Dack", "Thomas", ""], ["Guenther", "Jaroslav", ""], ["Lassnig", "Mario", ""], ["Litmaath", "Maarten", ""], ["Millar", "Paul", ""], ["Sall\u00e9", "Mischa", ""], ["Short", "Hannah", ""], ["Teheran", "Jeny", ""], ["Wartel", "Romain", ""]]}, {"id": "2007.03621", "submitter": "Ramachandra Raghavendra Prof.", "authors": "Sushma Venkatesh, Haoyu Zhang, Raghavendra Ramachandra, Kiran Raja,\n  Naser Damer, Christoph Busch", "title": "Can GAN Generated Morphs Threaten Face Recognition Systems Equally as\n  Landmark Based Morphs? -- Vulnerability and Detection", "comments": "Accepted in IWBF 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The primary objective of face morphing is to combine face images of different\ndata subjects (e.g. a malicious actor and an accomplice) to generate a face\nimage that can be equally verified for both contributing data subjects. In this\npaper, we propose a new framework for generating face morphs using a newer\nGenerative Adversarial Network (GAN) - StyleGAN. In contrast to earlier works,\nwe generate realistic morphs of both high-quality and high resolution of\n1024$\\times$1024 pixels. With the newly created morphing dataset of 2500\nmorphed face images, we pose a critical question in this work. \\textit{(i) Can\nGAN generated morphs threaten Face Recognition Systems (FRS) equally as\nLandmark based morphs?} Seeking an answer, we benchmark the vulnerability of a\nCommercial-Off-The-Shelf FRS (COTS) and a deep learning-based FRS (ArcFace).\nThis work also benchmarks the detection approaches for both GAN generated\nmorphs against the landmark based morphs using established Morphing Attack\nDetection (MAD) schemes.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 16:52:56 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Venkatesh", "Sushma", ""], ["Zhang", "Haoyu", ""], ["Ramachandra", "Raghavendra", ""], ["Raja", "Kiran", ""], ["Damer", "Naser", ""], ["Busch", "Christoph", ""]]}, {"id": "2007.03651", "submitter": "Christopher M. Poskitt", "authors": "Cheah Huei Yoong, Venkata Reddy Palleti, Arlindo Silva, Christopher M.\n  Poskitt", "title": "Towards Systematically Deriving Defence Mechanisms from Functional\n  Requirements of Cyber-Physical Systems", "comments": "Accepted by the ACM Cyber-Physical System Security Workshop (CPSS\n  2020)", "journal-ref": "In Proc. ACM Cyber-Physical System Security Workshop (CPSS 2020),\n  pages 11-22. ACM, 2020", "doi": "10.1145/3384941.3409589", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The threats faced by cyber-physical systems (CPSs) in critical infrastructure\nhave motivated the development of different attack detection mechanisms, such\nas those that monitor for violations of invariants, i.e. properties that always\nhold in normal operation. Given the complexity of CPSs, several existing\napproaches focus on deriving invariants automatically from data logs, but these\ncan miss possible system behaviours if they are not represented in that data.\nFurthermore, resolving any design flaws identified in this process is costly,\nas the CPS is already built. In this position paper, we propose a systematic\nmethod for deriving invariants before a CPS is built by analysing its\nfunctional requirements. Our method, inspired by the axiomatic design\nmethodology for systems, iteratively analyses dependencies in the design to\nconstruct equations and process graphs that model the invariant relationships\nbetween CPS components. As a preliminary study, we applied it to the design of\na water treatment plant testbed, implementing checkers for two invariants by\nusing decision trees, and finding that they could detect some examples of\nattacks on the testbed with high accuracy and without false positives. Finally,\nwe explore how developing our method further could lead to more robust CPSs and\nreduced costs by identifying design weaknesses before systems are implemented.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 17:40:13 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 05:31:03 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Yoong", "Cheah Huei", ""], ["Palleti", "Venkata Reddy", ""], ["Silva", "Arlindo", ""], ["Poskitt", "Christopher M.", ""]]}, {"id": "2007.03710", "submitter": "Goutam Paul", "authors": "Nayana Das and Goutam Paul", "title": "Cryptanalysis of Quantum Secure Direct Communication Protocol with\n  Mutual Authentication Based on Single Photons and Bell States", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Yan et al. proposed a quantum secure direct communication (QSDC)\nprotocol with authentication using single photons and Einstein-Podolsky-Rosen\n(EPR) pairs (Yan et al., CMC-Computers, Materials \\& Continua, 63(3), 2020). In\nthis work, we show that the QSDC protocol is not secure against\nintercept-and-resend attack and impersonation attack. An eavesdropper can get\nthe full secret message by applying these attacks. We propose a modification of\nthis protocol, which defeats the above attacks along with all the familiar\nattacks.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 18:02:38 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Das", "Nayana", ""], ["Paul", "Goutam", ""]]}, {"id": "2007.03724", "submitter": "Alireza Sadeghi", "authors": "Alireza Sadeghi, Gang Wang, Meng Ma, Georgios B. Giannakis", "title": "Learning while Respecting Privacy and Robustness to Distributional\n  Uncertainties and Adversarial Data", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT cs.SY eess.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data used to train machine learning models can be adversarial--maliciously\nconstructed by adversaries to fool the model. Challenge also arises by privacy,\nconfidentiality, or due to legal constraints when data are geographically\ngathered and stored across multiple learners, some of which may hold even an\n\"anonymized\" or unreliable dataset. In this context, the distributionally\nrobust optimization framework is considered for training a parametric model,\nboth in centralized and federated learning settings. The objective is to endow\nthe trained model with robustness against adversarially manipulated input data,\nor, distributional uncertainties, such as mismatches between training and\ntesting data distributions, or among datasets stored at different workers. To\nthis aim, the data distribution is assumed unknown, and lies within a\nWasserstein ball centered around the empirical data distribution. This robust\nlearning task entails an infinite-dimensional optimization problem, which is\nchallenging. Leveraging a strong duality result, a surrogate is obtained, for\nwhich three stochastic primal-dual algorithms are developed: i) stochastic\nproximal gradient descent with an $\\epsilon$-accurate oracle, which invokes an\noracle to solve the convex sub-problems; ii) stochastic proximal gradient\ndescent-ascent, which approximates the solution of the convex sub-problems via\na single gradient ascent step; and, iii) a distributionally robust federated\nlearning algorithm, which solves the sub-problems locally at different workers\nwhere data are stored. Compared to the empirical risk minimization and\nfederated learning methods, the proposed algorithms offer robustness with\nlittle computation overhead. Numerical tests using image datasets showcase the\nmerits of the proposed algorithms under several existing adversarial attacks\nand distributional uncertainties.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 18:25:25 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Sadeghi", "Alireza", ""], ["Wang", "Gang", ""], ["Ma", "Meng", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "2007.03730", "submitter": "Ping-Yeh Chiang", "authors": "Ping-yeh Chiang, Michael J. Curry, Ahmed Abdelkader, Aounon Kumar,\n  John Dickerson, Tom Goldstein", "title": "Detection as Regression: Certified Object Detection by Median Smoothing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the vulnerability of object detectors to adversarial attacks, very\nfew defenses are known to date. While adversarial training can improve the\nempirical robustness of image classifiers, a direct extension to object\ndetection is very expensive. This work is motivated by recent progress on\ncertified classification by randomized smoothing. We start by presenting a\nreduction from object detection to a regression problem. Then, to enable\ncertified regression, where standard mean smoothing fails, we propose median\nsmoothing, which is of independent interest. We obtain the first\nmodel-agnostic, training-free, and certified defense for object detection\nagainst $\\ell_2$-bounded attacks.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 18:40:19 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 22:13:31 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2020 16:43:49 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Chiang", "Ping-yeh", ""], ["Curry", "Michael J.", ""], ["Abdelkader", "Ahmed", ""], ["Kumar", "Aounon", ""], ["Dickerson", "John", ""], ["Goldstein", "Tom", ""]]}, {"id": "2007.03767", "submitter": "Mustafa Ozdayi", "authors": "Mustafa Safa Ozdayi, Murat Kantarcioglu, Yulia R. Gel", "title": "Defending against Backdoors in Federated Learning with Robust Learning\n  Rate", "comments": "Published at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) allows a set of agents to collaboratively train a\nmodel without sharing their potentially sensitive data. This makes FL suitable\nfor privacy-preserving applications. At the same time, FL is susceptible to\nadversarial attacks due to decentralized and unvetted data. One important line\nof attacks against FL is the backdoor attacks. In a backdoor attack, an\nadversary tries to embed a backdoor functionality to the model during training\nthat can later be activated to cause a desired misclassification. To prevent\nbackdoor attacks, we propose a lightweight defense that requires minimal change\nto the FL protocol. At a high level, our defense is based on carefully\nadjusting the aggregation server's learning rate, per dimension and per round,\nbased on the sign information of agents' updates. We first conjecture the\nnecessary steps to carry a successful backdoor attack in FL setting, and then,\nexplicitly formulate the defense based on our conjecture. Through experiments,\nwe provide empirical evidence that supports our conjecture, and we test our\ndefense against backdoor attacks under different settings. We observe that\neither backdoor is completely eliminated, or its accuracy is significantly\nreduced. Overall, our experiments suggest that our defense significantly\noutperforms some of the recently proposed defenses in the literature. We\nachieve this by having minimal influence over the accuracy of the trained\nmodels. In addition, we also provide convergence rate analysis for our proposed\nscheme.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 23:38:35 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2020 03:07:54 GMT"}, {"version": "v3", "created": "Sun, 13 Jun 2021 05:48:42 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ozdayi", "Mustafa Safa", ""], ["Kantarcioglu", "Murat", ""], ["Gel", "Yulia R.", ""]]}, {"id": "2007.03809", "submitter": "Saul Johnson", "authors": "Saul Johnson and Jo\\~ao F. Ferreira and Alexandra Mendes and Julien\n  Cordry", "title": "Skeptic: Automatic, Justified and Privacy-Preserving Password\n  Composition Policy Selection", "comments": "15 pages, 15 figures, 10 tables", "journal-ref": null, "doi": "10.1145/3320269.3384762", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of password composition policy to enforce on a password-protected\nsystem represents a critical security decision, and has been shown to\nsignificantly affect the vulnerability of user-chosen passwords to guessing\nattacks. In practice, however, this choice is not usually rigorous or\njustifiable, with a tendency for system administrators to choose password\ncomposition policies based on intuition alone. In this work, we propose a novel\nmethodology that draws on password probability distributions constructed from\nlarge sets of real-world password data which have been filtered according to\nvarious password composition policies. Password probabilities are then\nredistributed to simulate different user password reselection behaviours in\norder to automatically determine the password composition policy that will\ninduce the distribution of user-chosen passwords with the greatest uniformity,\na metric which we show to be a useful proxy to measure overall resistance to\npassword guessing attacks. Further, we show that by fitting power-law equations\nto the password probability distributions we generate, we can justify our\nchoice of password composition policy without any direct access to user\npassword data. Finally, we present Skeptic---a software toolkit that implements\nthis methodology, including a DSL to enable system administrators with no\nbackground in password security to compare and rank password composition\npolicies without resorting to expensive and time-consuming user studies.\nDrawing on 205,176,321 pass words across 3 datasets, we lend validity to our\napproach by demonstrating that the results we obtain align closely with\nfindings from a previous empirical study into password composition policy\neffectiveness.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 22:12:13 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Johnson", "Saul", ""], ["Ferreira", "Jo\u00e3o F.", ""], ["Mendes", "Alexandra", ""], ["Cordry", "Julien", ""]]}, {"id": "2007.03813", "submitter": "Yingxue Zhou", "authors": "Yingxue Zhou, Zhiwei Steven Wu, Arindam Banerjee", "title": "Bypassing the Ambient Dimension: Private SGD with Gradient Subspace\n  Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentially private SGD (DP-SGD) is one of the most popular methods for\nsolving differentially private empirical risk minimization (ERM). Due to its\nnoisy perturbation on each gradient update, the error rate of DP-SGD scales\nwith the ambient dimension $p$, the number of parameters in the model. Such\ndependence can be problematic for over-parameterized models where $p \\gg n$,\nthe number of training samples. Existing lower bounds on private ERM show that\nsuch dependence on $p$ is inevitable in the worst case. In this paper, we\ncircumvent the dependence on the ambient dimension by leveraging a\nlow-dimensional structure of gradient space in deep networks -- that is, the\nstochastic gradients for deep nets usually stay in a low dimensional subspace\nin the training process. We propose Projected DP-SGD that performs noise\nreduction by projecting the noisy gradients to a low-dimensional subspace,\nwhich is given by the top gradient eigenspace on a small public dataset. We\nprovide a general sample complexity analysis on the public dataset for the\ngradient subspace identification problem and demonstrate that under certain\nlow-dimensional assumptions the public sample complexity only grows\nlogarithmically in $p$. Finally, we provide a theoretical analysis and\nempirical evaluations to show that our method can substantially improve the\naccuracy of DP-SGD in the high privacy regime (corresponding to low privacy\nloss $\\epsilon$).\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 22:31:01 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 23:07:28 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Zhou", "Yingxue", ""], ["Wu", "Zhiwei Steven", ""], ["Banerjee", "Arindam", ""]]}, {"id": "2007.03856", "submitter": "Vaikkunth Mugunthan", "authors": "Vaikkunth Mugunthan, Ravi Rahman and Lalana Kagal", "title": "BlockFLow: An Accountable and Privacy-Preserving Solution for Federated\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning enables the development of a machine learning model among\ncollaborating agents without requiring them to share their underlying data.\nHowever, malicious agents who train on random data, or worse, on datasets with\nthe result classes inverted, can weaken the combined model. BlockFLow is an\naccountable federated learning system that is fully decentralized and\nprivacy-preserving. Its primary goal is to reward agents proportional to the\nquality of their contribution while protecting the privacy of the underlying\ndatasets and being resilient to malicious adversaries. Specifically, BlockFLow\nincorporates differential privacy, introduces a novel auditing mechanism for\nmodel contribution, and uses Ethereum smart contracts to incentivize good\nbehavior. Unlike existing auditing and accountability methods for federated\nlearning systems, our system does not require a centralized test dataset,\nsharing of datasets between the agents, or one or more trusted auditors; it is\nfully decentralized and resilient up to a 50% collusion attack in a malicious\ntrust model. When run on the public Ethereum blockchain, BlockFLow uses the\nresults from the audit to reward parties with cryptocurrency based on the\nquality of their contribution. We evaluated BlockFLow on two datasets that\noffer classification tasks solvable via logistic regression models. Our results\nshow that the resultant auditing scores reflect the quality of the honest\nagents' datasets. Moreover, the scores from dishonest agents are statistically\nlower than those from the honest agents. These results, along with the\nreasonable blockchain costs, demonstrate the effectiveness of BlockFLow as an\naccountable federated learning system.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 02:24:26 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Mugunthan", "Vaikkunth", ""], ["Rahman", "Ravi", ""], ["Kagal", "Lalana", ""]]}, {"id": "2007.03905", "submitter": "Rahat Masood Dr.", "authors": "Weixian Yao, Yexuan Li, Weiye Lin, Tianhui Hu, Imran Chowdhury, Rahat\n  Masood, Suranga Seneviratne", "title": "Security Apps under the Looking Glass: An Empirical Analysis of Android\n  Security Apps", "comments": "10 pages, 13 figures, 3 tables, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Third-party security apps are an integral part of the Android app ecosystem.\nMany users install them as an extra layer of protection for their devices.\nThere are hundreds of such security apps, both free and paid in Google Play\nStore and some of them are downloaded millions of times. By installing security\napps, the smartphone users place a significant amount of trust towards the\nsecurity companies who developed these apps, because a fully functional mobile\nsecurity app requires access to many smartphone resources such as the storage,\ntext messages and email, browser history, and information about other installed\napplications. Often these resources contain highly sensitive personal\ninformation. As such, it is essential to understand the mobile security apps\necosystem to assess whether is it indeed beneficial to install them. To this\nend, in this paper, we present the first empirical study of Android security\napps. We analyse 100 Android security apps from multiple aspects such as\nmetadata, static analysis, and dynamic analysis and presents insights to their\noperations and behaviours. Our results show that 20% of the security apps we\nstudied potentially resell the data they collect from smartphones to third\nparties; in some cases, even without the user consent. Also, our experiments\nshow that around 50% of the security apps fail to identify malware installed on\na smartphone.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 05:20:20 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Yao", "Weixian", ""], ["Li", "Yexuan", ""], ["Lin", "Weiye", ""], ["Hu", "Tianhui", ""], ["Chowdhury", "Imran", ""], ["Masood", "Rahat", ""], ["Seneviratne", "Suranga", ""]]}, {"id": "2007.03915", "submitter": "Zhiguo Wan", "authors": "Yan Zhou, Zhiguo Wan, Zhangshuang Guan", "title": "Open-Pub: A Transparent yet Privacy-Preserving Academic Publication\n  System based on Blockchain", "comments": "Protoytpe implemented and detailed expeirmental performance results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Academic publications of latest research results are crucial to advance the\ndevelopment of all disciplines. However, there are several severe disadvantages\nin current academic publication systems. The first is the misconduct during the\npublication process due to the opaque paper review process. An anonymous\nreviewer may give biased comments to a paper without being noticed because the\ncomments are seldom published for evaluation. Second, access to research papers\nis restricted to only subscribers, and even the authors cannot access their own\npapers. To address the above problems, we propose Open-Pub, a decentralized,\ntransparent yet privacy-preserving academic publication scheme using the\nblockchain technology. In Open-Pub, we first design a threshold identity-based\ngroup signature (TIBGS) that protects identities of signers using verifiable\nsecret sharing. Then we develop a strong double-blind mechanism to protect the\nidentities of authors and reviewers. With this strong double-blind mechanism,\nauthors can choose to submit papers anonymously, and validators distribute\npapers anonymously to reviewers on the blockchain according to their research\ninterests. This process is publicly recorded and traceable on the blockchain so\nas to realize transparent peer preview. To evaluate its efficiency, we\nimplement Open-Pub based on Ethereum and conduct comprehensive experiments to\nevaluate its performance, including computation cost and processing delay. The\nexperiment results show that Open-Pub is highly efficient in computation and\nprocessing anonymous transactions.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 06:38:56 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 15:22:02 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Zhou", "Yan", ""], ["Wan", "Zhiguo", ""], ["Guan", "Zhangshuang", ""]]}, {"id": "2007.03972", "submitter": "Nitish Mital", "authors": "Nitish Mital, Cong Ling, Deniz Gunduz", "title": "Secure Distributed Matrix Computation with Discrete Fourier Transform", "comments": "Under journal review, 13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of secure distributed matrix computation (SDMC),\nwhere a \\textit{user} can query a function of data matrices generated at\ndistributed \\textit{source} nodes. We assume the availability of $N$ honest but\ncurious computation servers, which are connected to the sources, the user, and\neach other through orthogonal and reliable communication links. Our goal is to\nminimize the amount of data that must be transmitted from the sources to the\nservers, called the \\textit{upload cost}, while guaranteeing that no $T$\ncolluding servers can learn any information about the source matrices, and the\nuser cannot learn any information beyond the computation result. We first focus\non secure distributed matrix multiplication (SDMM), considering two matrices,\nand propose a novel polynomial coding scheme using the properties of finite\nfield discrete Fourier transform, which achieves an upload cost significantly\nlower than the existing results in the literature. We then generalize the\nproposed scheme to include straggler mitigation, as well as to the\nmultiplication of multiple matrices while keeping the input matrices, the\nintermediate computation results, as well as the final result secure against\nany $T$ colluding servers. We also consider a special case, called computation\nwith own data, where the data matrices used for computation belong to the user.\nIn this case, we drop the security requirement against the user, and show that\nthe proposed scheme achieves the minimal upload cost. We then propose methods\nfor performing other common matrix computations securely on distributed\nservers, including changing the parameters of secret sharing, matrix transpose,\nmatrix exponentiation, solving a linear system, and matrix inversion, which are\nthen used to show how arbitrary matrix polynomials can be computed securely on\ndistributed servers using the proposed procedure.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 09:03:59 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Mital", "Nitish", ""], ["Ling", "Cong", ""], ["Gunduz", "Deniz", ""]]}, {"id": "2007.03975", "submitter": "Qizhi Zhang", "authors": "Qizhi Zhang, Lichun Li, Shan Yin, Juanjuan Sun", "title": "MPC Protocol for G-module and its Application in Secure Compare and ReLU", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure comparison and secure selection are two fundamental MPC (secure\nMulti-Party Computation) protocols. One important application of these\nprotocols is the secure ReLU and DReLU computation in privacy preserving deep\nlearning. In this paper, we introduce G-module, a mathematics tool, to\nre-design such protocols. In mathematics, given a group G, a G-module is an\nabelian group M on which G acts compatibly with the abelian group structure on\nM.\n  We design three secure protocols for three G-module operations. i.e.\n\"G-module action\", \"Cross G-module action\" and \"G-module recover\". As far as we\nknow, this is the first work on secure G-module operations. Based on them, we\ndesign secure comparison, selection, ReLU and DReLU protocols, which improve\ncommunication efficiency by 2X to 10X compared with state of arts. Our\nprotocols are very computation efficient too. They do not require public key\noperations or any other expensive operations.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 09:09:52 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 02:41:06 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2021 09:11:20 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Zhang", "Qizhi", ""], ["Li", "Lichun", ""], ["Yin", "Shan", ""], ["Sun", "Juanjuan", ""]]}, {"id": "2007.03987", "submitter": "Johann Knechtel", "authors": "Johann Knechtel, Satwik Patnaik, Mohammed Nabeel, Mohammed Ashraf,\n  Yogesh S. Chauhan, J\\\"org Henkel, Ozgur Sinanoglu, Hussam Amrouch", "title": "Power Side-Channel Attacks in Negative Capacitance Transistor (NCFET)", "comments": null, "journal-ref": null, "doi": "10.1109/MM.2020.3005883", "report-no": null, "categories": "cs.CR physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Side-channel attacks have empowered bypassing of cryptographic components in\ncircuits. Power side-channel (PSC) attacks have received particular traction,\nowing to their non-invasiveness and proven effectiveness. Aside from prior art\nfocused on conventional technologies, this is the first work to investigate the\nemerging Negative Capacitance Transistor (NCFET) technology in the context of\nPSC attacks. We implement a CAD flow for PSC evaluation at design-time. It\nleverages industry-standard design tools, while also employing the\nwidely-accepted correlation power analysis (CPA) attack. Using standard-cell\nlibraries based on the 7nm FinFET technology for NCFET and its counterpart CMOS\nsetup, our evaluation reveals that NCFET-based circuits are more resilient to\nthe classical CPA attack, due to the considerable effect of negative\ncapacitance on the switching power. We also demonstrate that the thicker the\nferroelectric layer, the higher the resiliency of the NCFET-based circuit,\nwhich opens new doors for optimization and trade-offs.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 09:49:30 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Knechtel", "Johann", ""], ["Patnaik", "Satwik", ""], ["Nabeel", "Mohammed", ""], ["Ashraf", "Mohammed", ""], ["Chauhan", "Yogesh S.", ""], ["Henkel", "J\u00f6rg", ""], ["Sinanoglu", "Ozgur", ""], ["Amrouch", "Hussam", ""]]}, {"id": "2007.03989", "submitter": "Johann Knechtel", "authors": "Haocheng Li, Satwik Patnaik, Abhrajit Sengupta, Haoyu Yang, Johann\n  Knechtel, Bei Yu, Evangeline F. Y. Young, Ozgur Sinanoglu", "title": "Attacking Split Manufacturing from a Deep Learning Perspective", "comments": null, "journal-ref": null, "doi": "10.1145/3316781.3317780", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of integrated circuit split manufacturing which delegates the\nfront-end-of-line (FEOL) and back-end-of-line (BEOL) parts to different\nfoundries, is to prevent overproduction, piracy of the intellectual property\n(IP), or targeted insertion of hardware Trojans by adversaries in the FEOL\nfacility. In this work, we challenge the security promise of split\nmanufacturing by formulating various layout-level placement and routing hints\nas vector- and image-based features. We construct a sophisticated deep neural\nnetwork which can infer the missing BEOL connections with high accuracy.\nCompared with the publicly available network-flow attack [1], for the same set\nof ISCAS-85 benchmarks, we achieve 1.21X accuracy when splitting on M1 and\n1.12X accuracy when splitting on M3 with less than 1% running time.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 09:50:00 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Li", "Haocheng", ""], ["Patnaik", "Satwik", ""], ["Sengupta", "Abhrajit", ""], ["Yang", "Haoyu", ""], ["Knechtel", "Johann", ""], ["Yu", "Bei", ""], ["Young", "Evangeline F. Y.", ""], ["Sinanoglu", "Ozgur", ""]]}, {"id": "2007.04025", "submitter": "Sylvain Chatel", "authors": "Sylvain Chatel, Apostolos Pyrgelis, Juan R. Troncoso-Pastoriza, and\n  Jean-Pierre Hubaux", "title": "Privacy and Integrity Preserving Computations with CRISP", "comments": null, "journal-ref": "USENIX Security Symposium 2021", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the digital era, users share their personal data with service providers to\nobtain some utility, e.g., access to high-quality services. Yet, the induced\ninformation flows raise privacy and integrity concerns. Consequently, cautious\nusers may want to protect their privacy by minimizing the amount of information\nthey disclose to curious service providers. Service providers are interested in\nverifying the integrity of the users' data to improve their services and obtain\nuseful knowledge for their business. In this work, we present a generic\nsolution to the trade-off between privacy, integrity, and utility, by achieving\nauthenticity verification of data that has been encrypted for offloading to\nservice providers. Based on lattice-based homomorphic encryption and\ncommitments, as well as zero-knowledge proofs, our construction enables a\nservice provider to process and reuse third-party signed data in a\nprivacy-friendly manner with integrity guarantees. We evaluate our solution on\ndifferent use cases such as smart-metering, disease susceptibility, and\nlocation-based activity tracking, thus showing its versatility. Our solution\nachieves broad generality, quantum-resistance, and relaxes some assumptions of\nstate-of-the-art solutions without affecting performance.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 11:02:59 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 17:06:40 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 10:06:11 GMT"}, {"version": "v4", "created": "Tue, 12 Jan 2021 11:25:53 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Chatel", "Sylvain", ""], ["Pyrgelis", "Apostolos", ""], ["Troncoso-Pastoriza", "Juan R.", ""], ["Hubaux", "Jean-Pierre", ""]]}, {"id": "2007.04036", "submitter": "Riccardo Longo", "authors": "Michele Battagliola, Riccardo Longo, Alessio Meneghetti, Massimiliano\n  Sala (Department of Mathematics, University of Trento, Italy)", "title": "Threshold ECDSA with an Offline Recovery Party", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A $(t,n)-$ threshold signature scheme enables distributed signing among $n$\nplayers such that any subgroup of size $t$ can sign, whereas any group with\nfewer players cannot. Our goal is to produce signatures that are compatible\nwith an existing centralized signature scheme: the key generation and signature\nalgorithm are replaced by a communication protocol between the parties, but the\nverification algorithm remains identical to that of a signature issued using\nthe centralized algorithm. Starting from the threshold schemes for the ECDSA\nsignature due to R. Gennaro and S. Goldfeder, we present the first protocol\nthat supports multiparty signatures with an offline participant during the Key\nGeneration Phase, without relying on a trusted third party. Following\nwell-established approaches, we prove our scheme secure against adaptive\nmalicious adversaries.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 11:27:45 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 14:43:08 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Battagliola", "Michele", "", "Department of Mathematics, University of Trento, Italy"], ["Longo", "Riccardo", "", "Department of Mathematics, University of Trento, Italy"], ["Meneghetti", "Alessio", "", "Department of Mathematics, University of Trento, Italy"], ["Sala", "Massimiliano", "", "Department of Mathematics, University of Trento, Italy"]]}, {"id": "2007.04086", "submitter": "Noureddine Lasla", "authors": "Noureddine Lasla and Lina Alsahan and Mohamed Abdallah and Mohamed\n  Younis", "title": "Green-PoW: An Energy-Efficient Blockchain Proof-of-Work Consensus\n  Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper opts to mitigate the energy-inefficiency of the Blockchain\nProof-of-Work (PoW) consensus algorithm by rationally repurposing the power\nspent during the mining process. The original PoW mining scheme is designed to\nconsider one block at a time and assign a reward to the first place winner of a\ncomputation race. To reduce the mining-related energy consumption, we propose\nto compensate the computation effort of the runner(s)-up of a mining round, by\ngranting them exclusivity of solving the upcoming block in the next round. This\nwill considerably reduce the number of competing nodes in the next round and\nconsequently, the consumed energy. Our proposed scheme divides time into\nepochs, where each comprises two mining rounds; in the first one, all network\nnodes can participate in the mining process, whereas in the second round only\nrunners-up can take part. Thus, the overall mining energy consumption can be\nreduced to nearly $50\\%$. To the best of our knowledge, our proposed scheme is\nthe first to considerably improve the energy consumption of the original PoW\nalgorithm. Our analysis demonstrates the effectiveness of our scheme in\nreducing energy consumption, the probability of fork occurrences, the level of\nmining centralization presented in the original PoW algorithm, and the effect\nof transaction censorship attack.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 12:46:09 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Lasla", "Noureddine", ""], ["Alsahan", "Lina", ""], ["Abdallah", "Mohamed", ""], ["Younis", "Mohamed", ""]]}, {"id": "2007.04109", "submitter": "Sajedul Talukder", "authors": "Sajedul Talukder and Md. Iftekharul Islam Sakib and Zahidur Talukder", "title": "Giving Up Privacy For Security: A Survey On Privacy Trade-off During\n  Pandemic Emergency", "comments": "20 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the COVID-19 pandemic continues to be as complex as ever, the\ncollection and exchange of data in the light of fighting coronavirus poses a\nmajor challenge for privacy systems around the globe. The disease's size and\nmagnitude is not uncommon but it appears to be at the point of hysteria\nsurrounding it. Consequently, in a very short time, extreme measures for\ndealing with the situation appear to have become the norm. Any such actions\naffect the privacy of individuals in particular. For some cases, there is\nintensive monitoring of the whole population while the medical data of those\ndiagnosed with the virus is commonly circulated through institutions and\nnations. This may well be in the interest of saving the world from a deadly\ndisease, but is it really appropriate and right? Although creative solutions\nhave been implemented in many countries to address the issue, proponents of\nprivacy are concerned that technologies will eventually erode privacy, while\nregulators and privacy supporters are worried about what kind of impact this\ncould bring. While that tension has always been present, privacy has been\nthrown into sharp relief by the sheer urgency of containing an exponentially\nspreading virus. The essence of this dilemma indicates that establishing the\nright equilibrium will be the best solution. The jurisprudence concerning cases\nregarding the willingness of public officials to interfere with the\nconstitutional right to privacy in the interests of national security or public\nhealth has repeatedly proven that a reasonable balance can be reached.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 09:14:27 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Talukder", "Sajedul", ""], ["Sakib", "Md. Iftekharul Islam", ""], ["Talukder", "Zahidur", ""]]}, {"id": "2007.04116", "submitter": "Thorsten Holz", "authors": "Patrick Wollgast, Robert Gawlik, Behrad Garmany, Benjamin Kollenda,\n  Thorsten Holz", "title": "Automated Multi-Architectural Discovery of CFI-Resistant Code Gadgets", "comments": "Published in 21st European Symposium on Research in Computer Security\n  (ESORICS'16)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory corruption vulnerabilities are still a severe threat for software\nsystems. To thwart the exploitation of such vulnerabilities, many different\nkinds of defenses have been proposed in the past. Most prominently,\nControl-Flow Integrity (CFI) has received a lot of attention recently. Several\nproposals were published that apply coarse-grained policies with a low\nperformance overhead. However, their security remains questionable as recent\nattacks have shown.\n  To ease the assessment of a given CFI implementation, we introduce a\nframework to discover code gadgets for code-reuse attacks that conform to\ncoarse-grained CFI policies. For this purpose, binary code is extracted and\ntransformed to a symbolic representation in an architecture-independent manner.\nAdditionally, code gadgets are verified to provide the needed functionality for\na security researcher. We show that our framework finds more CFI-compatible\ngadgets compared to other code gadget discovery tools. Furthermore, we\ndemonstrate that code gadgets needed to bypass CFI solutions on the ARM\narchitecture can be discovered by our framework as well.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 15:36:00 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Wollgast", "Patrick", ""], ["Gawlik", "Robert", ""], ["Garmany", "Behrad", ""], ["Kollenda", "Benjamin", ""], ["Holz", "Thorsten", ""]]}, {"id": "2007.04125", "submitter": "Peter Hillmann", "authors": "Matthias Schopp, Peter Hillmann", "title": "Agile Approach for IT Forensics Management", "comments": "Journal of Internet Technology and Secured Transactions (JITST) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.IR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The forensic investigation of cyber attacks and IT incidents is becoming\nincreasingly difficult due to increasing complexity and intensify networking.\nEspecially with Advanced Attacks (AT) like the increasing Advanced Persistent\nThreats an agile approach is indispensable. Several systems are involved in an\nattack (multi-host attacks). Current forensic models and procedures show\nconsiderable deficits in the process of analyzing such attacks. For this\npurpose, this paper presents the novel flower model, which uses agile methods\nand forms a new forensic management approach. In this way, the growing\nchallenges of ATs are met. In the forensic investigation of such attacks, big\ndata problems have to be solved due to the amount of data that needs to be\nanalyzed. The proposed model meets this requirement by precisely defining the\nquestions that need to be answered in an early state and collecting only the\nevidence usable in court proceedings that is needed to answer these questions.\nAdditionally, the novel flower model for AT is presented that meets the\ndifferent phases of an investigation process.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 13:48:50 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Schopp", "Matthias", ""], ["Hillmann", "Peter", ""]]}, {"id": "2007.04391", "submitter": "Liwei Song", "authors": "Liwei Song, Vikash Sehwag, Arjun Nitin Bhagoji, Prateek Mittal", "title": "A Critical Evaluation of Open-World Machine Learning", "comments": "Presented at the ICML 2020 Workshop on Uncertainty and Robustness in\n  Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-world machine learning (ML) combines closed-world models trained on\nin-distribution data with out-of-distribution (OOD) detectors, which aim to\ndetect and reject OOD inputs. Previous works on open-world ML systems usually\nfail to test their reliability under diverse, and possibly adversarial\nconditions. Therefore, in this paper, we seek to understand how resilient are\nstate-of-the-art open-world ML systems to changes in system components? With\nour evaluation across 6 OOD detectors, we find that the choice of\nin-distribution data, model architecture and OOD data have a strong impact on\nOOD detection performance, inducing false positive rates in excess of $70\\%$.\nWe further show that OOD inputs with 22 unintentional corruptions or\nadversarial perturbations render open-world ML systems unusable with false\npositive rates of up to $100\\%$. To increase the resilience of open-world ML,\nwe combine robust classifiers with OOD detection techniques and uncover a new\ntrade-off between OOD detection and robustness.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 19:40:07 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Song", "Liwei", ""], ["Sehwag", "Vikash", ""], ["Bhagoji", "Arjun Nitin", ""], ["Mittal", "Prateek", ""]]}, {"id": "2007.04399", "submitter": "Petros Spachos", "authors": "Pai Chet Ng, Petros Spachos, Stefano Gregori, Konstantinos Plataniotis", "title": "Epidemic Exposure Notification with Smartwatch: A Proximity-Based\n  Privacy-Preserving Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Businesses planning for the post-pandemic world are looking for innovative\nways to protect the health and welfare of their employees and customers.\nWireless technologies can play a key role in assisting contact tracing to\nquickly halt a local infection outbreak and prevent further spread. In this\nwork, we present a wearable proximity and exposure notification solution based\non a smartwatch that also promotes safe physical distancing in business,\nhospitality, or recreational facilities. Our proximity-based privacy-preserving\ncontact tracing (P$^3$CT) leverages the Bluetooth Low Energy (BLE) technology\nfor reliable proximity sensing, and an ambient signature protocol for\npreserving identity. Proximity sensing exploits the received signal strength\n(RSS) to detect the user's interaction and thus classifying them into low- or\nhigh-risk with respect to a patient diagnosed with an infectious disease. More\nprecisely, a user is notified of their exposure based on their interactions, in\nterms of distance and time, with a patient. Our privacy-preserving protocol\nuses the ambient signatures to ensure that users' identities be anonymized. We\ndemonstrate the feasibility of our proposed solution through extensive\nexperimentation.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 19:55:33 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Ng", "Pai Chet", ""], ["Spachos", "Petros", ""], ["Gregori", "Stefano", ""], ["Plataniotis", "Konstantinos", ""]]}, {"id": "2007.04444", "submitter": "Tanusree Sharma", "authors": "Tanusree Sharma and Masooda Bashir", "title": "Are PETs (Privacy Enhancing Technologies) Giving Protection for\n  Smartphones? -- A Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With smartphone technologies enhanced way of interacting with the world\naround us, it has also been paving the way for easier access to our private and\npersonal information. This has been amplified by the existence of numerous\nembedded sensors utilized by millions of apps to users. While mobile apps have\npositively transformed many aspects of our lives with new functionalities, many\nof these applications are taking advantage of vast amounts of data, privacy\napps, a form of Privacy Enhancing Technology can be an effective privacy\nmanagement tool for smartphones. To protect against vulnerabilities related to\nthe collection, storage, and sharing of sensitive data, developers are building\nnumerous privacy apps. However, there has been a lack of discretion in this\nparticular area which calls for a proper assessment to understand the\nfar-reaching utilization of these apps among users. During this process we have\nconducted an evaluation of the most popular privacy apps from our total\ncollection of five hundred and twelve to demonstrate their functionality\nspecific data protections they are claiming to offer, both technologically and\nconventionally, measuring up to standards. Taking their offered security\nfunctionalities as a scale, we conducted forensic experiments to indicate where\nthey are failing to be consistent in maintaining protection. For legitimate\nvalidation of security gaps in assessed privacy apps, we have also utilized\nNIST and OWASP guidelines. We believe this study will be efficacious for\ncontinuous improvement and can be considered as a foundation towards a common\nstandard for privacy and security measures for an app's development stage.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 21:33:00 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Sharma", "Tanusree", ""], ["Bashir", "Masooda", ""]]}, {"id": "2007.04490", "submitter": "Noman Haider", "authors": "Noman Haider, Muhammad Zeeshan Baig, Muhammad Imran", "title": "Artificial Intelligence and Machine Learning in 5G Network Security:\n  Opportunities, advantages, and future research trends", "comments": "7 Pages, 3 figures, 1 table, (Magazine type article)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent technological and architectural advancements in 5G networks have\nproven their worth as the deployment has started over the world. Key\nperformance elevating factor from access to core network are softwareization,\ncloudification and virtualization of key enabling network functions. Along with\nthe rapid evolution comes the risks, threats and vulnerabilities in the system\nfor those who plan to exploit it. Therefore, ensuring fool proof end-to-end\n(E2E) security becomes a vital concern. Artificial intelligence (AI) and\nmachine learning (ML) can play vital role in design, modelling and automation\nof efficient security protocols against diverse and wide range of threats. AI\nand ML has already proven their effectiveness in different fields for\nclassification, identification and automation with higher accuracy. As 5G\nnetworks' primary selling point has been higher data rates and speed, it will\nbe difficult to tackle wide range of threats from different points using\ntypical/traditional protective measures. Therefore, AI and ML can play central\nrole in protecting highly data-driven softwareized and virtualized network\ncomponents. This article presents AI and ML driven applications for 5G network\nsecurity, their implications and possible research directions. Also, an\noverview of key data collection points in 5G architecture for threat\nclassification and anomaly detection are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 01:02:13 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Haider", "Noman", ""], ["Baig", "Muhammad Zeeshan", ""], ["Imran", "Muhammad", ""]]}, {"id": "2007.04570", "submitter": "Mesbah Uddin", "authors": "Mesbah Uddin, Md. Badruddoja Majumder, Md. Sakib Hasan, Garrett S.\n  Rose", "title": "A Secure Back-up and Restore for Resource-Constrained IoT based on\n  Nanotechnology", "comments": "Content: 17 pages with 15 figures and 7 tables Submitted to IEEE IoT\n  Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emergence of IoT (Internet of things), huge amounts of sensitive\ndata are being processed and transmitted everyday in edge devices with little\nto no security. Due to their aggressive power management schemes, it is a\ncommon and necessary technique to make a back-up of their program states and\nother necessary data in a non-volatile memory (NVM) before going to sleep or\nlow power mode. However, this memory is often left unprotected as adding robust\nsecurity measures tends to be expensive for these resource constrained systems.\nIn this paper, we propose a lightweight security system for NVM during low\npower mode. This security architecture uses the memristor, an emerging\nnanoscale device which is used to build hardware security primitives like PUF\n(physical unclonable function) based encryption-decryption, true random number\ngenerators (TRNG), and memory integrity checking. A reliability enhancement\ntechnique for this PUF is also proposed which shows how this system would work\neven with less-than-100\\% reliable PUF responses. Together, with all these\ntechniques, we have established a dual layer security protocol (data\nencryption+integrity check) which provides reasonable security to an embedded\nprocessor while being very lightweight in terms of area, power, and computation\ntime. A complete system design is demonstrated with 65$n$m CMOS and emerging\nmemristive technology. With this, we have provided a detailed and accurate\nestimation of resource overhead. Analysis of the security of the whole system\nis also provided.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 05:52:41 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Uddin", "Mesbah", ""], ["Majumder", "Md. Badruddoja", ""], ["Hasan", "Md. Sakib", ""], ["Rose", "Garrett S.", ""]]}, {"id": "2007.04608", "submitter": "Geoffrey Goodell", "authors": "Geoffrey Goodell", "title": "Serverless Electronic Mail", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a simple approach to peer-to-peer electronic mail that would\nallow users of ordinary workstations and mobile devices to exchange messages\nwithout relying upon third-party mail server operators. Crucially, the system\nallows participants to establish and use multiple unlinked identities for\ncommunication with each other. The architecture leverages ordinary SMTP for\nmessage delivery and Tor for peer-to-peer communication. The design offers a\nrobust, unintrusive method to use self-certifying Tor onion service names to\nbootstrap a web of trust based on public keys for end-to-end authentication and\nencryption, which in turn can be used to facilitate message delivery when the\nsender and recipient are not online simultaneously. We show how the system can\ninteroperate with existing email systems and paradigms, allowing users to hold\nmessages that others can retrieve via IMAP or to operate as a relay between\nsystem participants and external email users. Finally, we show how it is\npossible to use a broadcast protocol to implement mailing lists and how\ndistributed ledger technology might be used to bootstrap consensus about shared\nknowledge among list members.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 07:35:29 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 17:32:53 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Goodell", "Geoffrey", ""]]}, {"id": "2007.04673", "submitter": "Piyush Kumar Sharma", "authors": "Piyush Kumar Sharma, Shashwat Chaudhary, Nikhil Hassija, Mukulika\n  Maity, and Sambuddho Chakravarty", "title": "The Road Not Taken: Re-thinking the Feasibility of Voice Calling Over\n  Tor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anonymous VoIP calls over the Internet holds great significance for\nprivacy-conscious users, whistle-blowers and political activists alike. Prior\nresearch deems popular anonymization systems like Tor unsuitable for providing\nrequisite performance guarantees that real-time applications like VoIP need.\nTheir claims are backed by studies that may no longer be valid due to constant\nadvancements in Tor. Moreover, we believe that these studies lacked the\nrequisite diversity and comprehensiveness. Thus, conclusions from these studies\nled them to propose novel and tailored solutions. However, no such system is\navailable for immediate use. Additionally, operating such new systems would\nincur significant costs for recruiting users and volunteered relays, to provide\nthe necessary anonymity guarantees.\n  It thus becomes imperative that the exact performance of VoIP over Tor be\nquantified and analyzed so that the potential performance bottlenecks can be\namended. We thus conducted an extensive empirical study across various in-lab\nand real-world scenarios to shed light on VoIP performance over Tor. In over\n0.5 million measurements spanning 12 months, across seven countries and\ncovering about 6650 Tor relays, we observed that Tor supports good voice\nquality (Perceptual Evaluation of Speech Quality (PESQ) >3 and oneway delay\n<400ms) in more than 85% of cases. Further analysis indicates that in general\nfor most Tor relays, the contentions due to cross-traffic were low enough to\nsupport VoIP calls, that are anyways transmitted at low rates (<120 Kbps). Our\nfindings are supported by concordant measurements using iperf that show more\nthan the adequate available bandwidth for most cases. Data published by the Tor\nMetrics also corroborates the same. Hence, unlike prior efforts, our research\nreveals that Tor is suitable for supporting anonymous VoIP calls.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 10:00:17 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Sharma", "Piyush Kumar", ""], ["Chaudhary", "Shashwat", ""], ["Hassija", "Nikhil", ""], ["Maity", "Mukulika", ""], ["Chakravarty", "Sambuddho", ""]]}, {"id": "2007.04760", "submitter": "Lynsay Shepherd", "authors": "Lynsay A. Shepherd, Stefano De Paoli, Jim Conacher", "title": "Human-Computer Interaction Considerations When Developing Cyber Ranges", "comments": "5 pages, short discussion paper", "journal-ref": "2020 International Journal of Information Security and Cybercrime\n  9(2), pp.28-32", "doi": "10.19107/IJISC.2020.02.04", "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of cyber-attacks are continuing to rise globally. It is therefore\nvital for organisations to develop the necessary skills to secure their assets\nand to protect critical national infrastructure. In this short paper, we\noutline upon human-computer interaction elements which should be considered\nwhen developing a cybersecurity training platform, in an effort to maintain\nlevels of user engagement. We provide an overview of existing training\nplatforms before covering specialist cyber ranges. Aspects of human-computer\ninteraction are noted with regards to their relevance in the context of cyber\nranges. We conclude with design suggestions when developing a cyber range\nplatform.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 13:08:05 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Shepherd", "Lynsay A.", ""], ["De Paoli", "Stefano", ""], ["Conacher", "Jim", ""]]}, {"id": "2007.04771", "submitter": "Joao Ferreira", "authors": "Jo\\~ao F. Ferreira, Pedro Cruz, Thomas Durieux, Rui Abreu", "title": "SmartBugs: A Framework to Analyze Solidity Smart Contracts", "comments": "arXiv admin note: text overlap with arXiv:1910.10601", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few years, there has been substantial research on automated\nanalysis, testing, and debugging of Ethereum smart contracts. However, it is\nnot trivial to compare and reproduce that research. To address this, we present\nSmartBugs, an extensible and easy-to-use execution framework that simplifies\nthe execution of analysis tools on smart contracts written in Solidity, the\nprimary language used in Ethereum. SmartBugs is currently distributed with\nsupport for 10 tools and two datasets of Solidity contracts. The first dataset\ncan be used to evaluate the precision of analysis tools, as it contains 143\nannotated vulnerable contracts with 208 tagged vulnerabilities. The second\ndataset contains 47,518 unique contracts collected through Etherscan. We\ndiscuss how SmartBugs supported the largest experimental setup to date both in\nthe number of tools and in execution time. Moreover, we show how it enables\neasy integration and comparison of analysis tools by presenting a new extension\nto the tool SmartCheck that improves substantially the detection of\nvulnerabilities related to the DASP10 categories Bad Randomness, Time\nManipulation, and Access Control (identified vulnerabilities increased from 11%\nto 24%).\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 15:16:58 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 08:08:38 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Ferreira", "Jo\u00e3o F.", ""], ["Cruz", "Pedro", ""], ["Durieux", "Thomas", ""], ["Abreu", "Rui", ""]]}, {"id": "2007.04932", "submitter": "Rosana Montanez Rodriguez", "authors": "Rosana Montanez Rodriguez, Edward Golob and Shouhuai Xu", "title": "Human Cognition through the Lens of Social Engineering Cyberattacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social engineering cyberattacks are a major threat because they often prelude\nsophisticated and devastating cyberattacks. Social engineering cyberattacks are\na kind of psychological attack that exploits weaknesses in human cognitive\nfunctions. Adequate defense against social engineering cyberattacks requires a\ndeeper understanding of what aspects of human cognition are exploited by these\ncyberattacks, why humans are susceptible to these cyberattacks, and how we can\nminimize or at least mitigate their damage. These questions have received some\namount of attention but the state-of-the-art understanding is superficial and\nscattered in the literature. In this paper, we review human cognition through\nthe lens of social engineering cyberattacks. Then, we propose an extended\nframework of human cognitive functions to accommodate social engineering\ncyberattacks. We cast existing studies on various aspects of social engineering\ncyberattacks into the extended framework, while drawing a number of insights\nthat represent the current understanding and shed light on future research\ndirections. The extended framework might inspire future research endeavors\ntowards a new sub-field that can be called Cybersecurity Cognitive Psychology,\nwhich tailors or adapts principles of Cognitive Psychology to the cybersecurity\ndomain while embracing new notions and concepts that are unique to the\ncybersecurity domain.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 17:02:50 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 03:16:31 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Rodriguez", "Rosana Montanez", ""], ["Golob", "Edward", ""], ["Xu", "Shouhuai", ""]]}, {"id": "2007.05084", "submitter": "Kartik Sreenivasan", "authors": "Hongyi Wang, Kartik Sreenivasan, Shashank Rajput, Harit Vishwakarma,\n  Saurabh Agarwal, Jy-yong Sohn, Kangwook Lee, Dimitris Papailiopoulos", "title": "Attack of the Tails: Yes, You Really Can Backdoor Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to its decentralized nature, Federated Learning (FL) lends itself to\nadversarial attacks in the form of backdoors during training. The goal of a\nbackdoor is to corrupt the performance of the trained model on specific\nsub-tasks (e.g., by classifying green cars as frogs). A range of FL backdoor\nattacks have been introduced in the literature, but also methods to defend\nagainst them, and it is currently an open question whether FL systems can be\ntailored to be robust against backdoors. In this work, we provide evidence to\nthe contrary. We first establish that, in the general case, robustness to\nbackdoors implies model robustness to adversarial examples, a major open\nproblem in itself. Furthermore, detecting the presence of a backdoor in a FL\nmodel is unlikely assuming first order oracles or polynomial time. We couple\nour theoretical results with a new family of backdoor attacks, which we refer\nto as edge-case backdoors. An edge-case backdoor forces a model to misclassify\non seemingly easy inputs that are however unlikely to be part of the training,\nor test data, i.e., they live on the tail of the input distribution. We explain\nhow these edge-case backdoors can lead to unsavory failures and may have\nserious repercussions on fairness, and exhibit that with careful tuning at the\nside of the adversary, one can insert them across a range of machine learning\ntasks (e.g., image classification, OCR, text prediction, sentiment analysis).\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 21:50:54 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Wang", "Hongyi", ""], ["Sreenivasan", "Kartik", ""], ["Rajput", "Shashank", ""], ["Vishwakarma", "Harit", ""], ["Agarwal", "Saurabh", ""], ["Sohn", "Jy-yong", ""], ["Lee", "Kangwook", ""], ["Papailiopoulos", "Dimitris", ""]]}, {"id": "2007.05111", "submitter": "Narges Dastanpour", "authors": "Mahsa Teymourzadeh, Roshanak Vahed, Soulmaz Alibeygi, and Narges\n  Dastanpour", "title": "Security in Wireless Sensor Networks: Issues and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A wireless sensor network (WSN) has important applications such as remote\nenvironmental monitoring and target tracking. In addition, Wireless Sensor\nnetworks is an emerging technology and have great potential to be employed in\ncritical situations like battlefields and commercial applications such as\nbuilding, traffic surveillance, habitat monitoring and smart homes and many\nmore scenarios. One of the major challenges wireless sensor networks face today\nis security. This has been enabled by the availability for a kind of possible\nattacks; the innate power and recall limit of sensor nodes earn customary\nsecurity solutions unfeasible. These sensors are equipped with wireless\ninterfaces with which they can communicate with one pther to form a network. In\nthis paper we present a survey of security issues in WSNs, address the state of\nthe art in research\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 23:58:59 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Teymourzadeh", "Mahsa", ""], ["Vahed", "Roshanak", ""], ["Alibeygi", "Soulmaz", ""], ["Dastanpour", "Narges", ""]]}, {"id": "2007.05157", "submitter": "Audra McMillan", "authors": "Daniel Alabi, Audra McMillan, Jayshree Sarathy, Adam Smith and Salil\n  Vadhan", "title": "Differentially Private Simple Linear Regression", "comments": "20 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Economics and social science research often require analyzing datasets of\nsensitive personal information at fine granularity, with models fit to small\nsubsets of the data. Unfortunately, such fine-grained analysis can easily\nreveal sensitive individual information. We study algorithms for simple linear\nregression that satisfy differential privacy, a constraint which guarantees\nthat an algorithm's output reveals little about any individual input data\nrecord, even to an attacker with arbitrary side information about the dataset.\nWe consider the design of differentially private algorithms for simple linear\nregression for small datasets, with tens to hundreds of datapoints, which is a\nparticularly challenging regime for differential privacy. Focusing on a\nparticular application to small-area analysis in economics research, we study\nthe performance of a spectrum of algorithms we adapt to the setting. We\nidentify key factors that affect their performance, showing through a range of\nexperiments that algorithms based on robust estimators (in particular, the\nTheil-Sen estimator) perform well on the smallest datasets, but that other more\nstandard algorithms do better as the dataset size increases.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 04:28:43 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Alabi", "Daniel", ""], ["McMillan", "Audra", ""], ["Sarathy", "Jayshree", ""], ["Smith", "Adam", ""], ["Vadhan", "Salil", ""]]}, {"id": "2007.05212", "submitter": "Immanuel Kunz", "authors": "Immanuel Kunz, Valentina Casola, Angelika Schneider, Christian Banse\n  and Julian Sch\\\"utte", "title": "Towards Tracking Data Flows in Cloud Architectures", "comments": "11 pages, 5 figures, 2020 IEEE 13th International Conference on Cloud\n  Computing (CLOUD)", "journal-ref": null, "doi": "10.1109/CLOUD49709.2020.00066", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As cloud services become central in an increasing number of applications,\nthey process and store more personal and business-critical data. At the same\ntime, privacy and compliance regulations such as GDPR, the EU ePrivacy\nregulation, PCI, and the upcoming EU Cybersecurity Act raise the bar for secure\nprocessing and traceability of critical data. Especially the demand to provide\ninformation about existing data records of an individual and the ability to\ndelete them on demand is central in privacy regulations. Common to these\nrequirements is that cloud providers must be able to track data as it flows\nacross the different services to ensure that it never moves outside of the\nlegitimate realm, and it is known at all times where a specific copy of a\nrecord that belongs to a specific individual or business process is located.\nHowever, current cloud architectures do neither provide the means to\nholistically track data flows across different services nor to enforce policies\non data flows. In this paper, we point out the deficits in the data flow\ntracking functionalities of major cloud providers by means of a set of\npractical experiments. We then generalize from these experiments introducing a\ngeneric architecture that aims at solving the problem of cloud-wide data flow\ntracking and show how it can be built in a Kubernetes-based prototype\nimplementation.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 07:31:47 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Kunz", "Immanuel", ""], ["Casola", "Valentina", ""], ["Schneider", "Angelika", ""], ["Banse", "Christian", ""], ["Sch\u00fctte", "Julian", ""]]}, {"id": "2007.05259", "submitter": "Oksana Kulyk", "authors": "Camilla Nadja Fleron, Jonas Kofod J{\\o}rgensen, Oksana Kulyk, and Elda\n  Paja", "title": "\"It's Not Something We Have Talked to Our Team About\": Results From a\n  Preliminary Investigation of Cybersecurity Challenges in Denmark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although Denmark is reportedly one of the most digitised countries in Europe,\nIT security in Danish companies has not followed along. To shed light into the\nchallenges that companies experience with implementing IT security, we\nconducted a preliminary study running semi-structured interviews with four\nemployees from four different companies, asking about their IT security and\nwhat they need to reduce risks of cyber threats. Our results show that\ncompanies are lacking fundamental security protection and are in need of\nguidance and tools to help them implementing basic security practices, while\nraising awareness of cyber threats. Based on our findings and with the\ninspiration of the latest reports and international security standards, we\ndiscuss steps towards further investigation towards developing a framework\ntargeting SMEs that want to adopt straightforward and actionable IT security\nguidance.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 09:07:39 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Fleron", "Camilla Nadja", ""], ["J\u00f8rgensen", "Jonas Kofod", ""], ["Kulyk", "Oksana", ""], ["Paja", "Elda", ""]]}, {"id": "2007.05265", "submitter": "William Buchanan Prof", "authors": "Gulshan Kumara, Rahul Sahaa, William J Buchanan, G. Geethaa, Reji\n  Thomasa, Tai-Hoon Kimc, Mamoun Alazab", "title": "Decentralized Accessibility of e-commerce Products through Blockchain\n  Technology", "comments": null, "journal-ref": "Sustainable Cities and Society, 102361 (2020)", "doi": "10.1016/j.scs.2020.102361", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A distributed and transparent ledger system is considered for various\ne-commerce products including health medicines, electronics, security\nappliances, food products and many more to ensure technological and e-commerce\nsustainability. This solution, named as 'PRODCHAIN', is a generic blockchain\nframework with lattice-based cryptographic processes for reducing the\ncomplexity for tracing the e-commerce products. Moreover, we have introduced a\nrating based consensus process called Proof of Accomplishment (PoA). The\nsolution has been analyzed and experimental studies are performed on Ethereum\nnetwork. The results are discussed in terms of latency and throughput which\nprove the efficiency of PRODCHAIN in e-commerce products and services. The\npresented solution is beneficial for improving the traceability of the products\nensuring the social and financial sustainability. This work will help the\nresearchers to gain knowledge about the blockchain implications for supply\nchain possibilities in future developments for society.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 09:21:25 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Kumara", "Gulshan", ""], ["Sahaa", "Rahul", ""], ["Buchanan", "William J", ""], ["Geethaa", "G.", ""], ["Thomasa", "Reji", ""], ["Kimc", "Tai-Hoon", ""], ["Alazab", "Mamoun", ""]]}, {"id": "2007.05285", "submitter": "Mengce Zheng", "authors": "Ping Wang, Ping Chen, Zhimin Luo, Gaofeng Dong, Mengce Zheng, Nenghai\n  Yu, Honggang Hu", "title": "Enhancing the Performance of Practical Profiling Side-Channel Attacks\n  Using Conditional Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, many profiling side-channel attacks based on Machine Learning and\nDeep Learning have been proposed. Most of them focus on reducing the number of\ntraces required for successful attacks by optimizing the modeling algorithms.\nIn previous work, relatively sufficient traces need to be used for training a\nmodel. However, in the practical profiling phase, it is difficult or impossible\nto collect sufficient traces due to the constraint of various resources. In\nthis case, the performance of profiling attacks is inefficient even if proper\nmodeling algorithms are used. In this paper, the main problem we consider is\nhow to conduct more efficient profiling attacks when sufficient profiling\ntraces cannot be obtained. To deal with this problem, we first introduce the\nConditional Generative Adversarial Network (CGAN) in the context of\nside-channel attacks. We show that CGAN can generate new traces to enlarge the\nsize of the profiling set, which improves the performance of profiling attacks.\nFor both unprotected and protected cryptographic algorithms, we find that CGAN\ncan effectively learn the leakage of traces collected in their implementations.\nWe also apply it to different modeling algorithms. In our experiments, the\nmodel constructed with the augmented profiling set can reduce the required\nattack traces by more than half, which means the generated traces can provide\nuseful information as the real traces.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 10:09:56 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Wang", "Ping", ""], ["Chen", "Ping", ""], ["Luo", "Zhimin", ""], ["Dong", "Gaofeng", ""], ["Zheng", "Mengce", ""], ["Yu", "Nenghai", ""], ["Hu", "Honggang", ""]]}, {"id": "2007.05296", "submitter": "Ijaz Ahmad Dr.", "authors": "Ijaz Ahmad", "title": "Improving Software Defined Cognitive and Secure Networking", "comments": "85 pages, 12 figures, PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional communication networks consist of large sets of vendor-specific\nmanually configurable devices which are hardwired with specific control logic\nor algorithms. The resulting networks comprise distributed control plane\narchitectures that are complex in nature, difficult to integrate and operate,\nand are least efficient in terms of resource usage. However, the rapid increase\nin data traffic requires an integrated use of diverse access technologies and\nautonomic network operations with increased efficiency. Therefore, the concepts\nof Software Defined Networking (SDN) are proposed that decouple the network\ncontrol plane from the data-forwarding plane. The SDN control plane can\nintegrate a diverse set of devices, and tune them at run-time through\nvendor-agnostic programmable Application Programming Interfaces (APIs). This\nthesis proposes software defined cognitive networking to enable intelligent use\nof network resources. Different radio access technologies, including cognitive\nradios, are integrated through a common control platform to increase the\noverall network performance. The architectural framework of software defined\ncognitive networking is presented alongside the experimental performance\nevaluation. Since SDN enables applications to change the network behavior and\ncentralizes the network control plane to oversee the whole network, it is\nhighly important to investigate security of SDNs. Therefore, this thesis finds\npotential security vulnerabilities in SDN, studies proposed security platforms\nand architectures for those vulnerabilities, and presents future directions for\nunresolved security vulnerabilities. Furthermore, this thesis also investigates\nthe potential security challenges and their solutions for the enabling\ntechnologies of 5G, such as SDN, cloud technologies, and virtual network\nfunctions, and provides key insights into increasing the security of 5G\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 10:50:21 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Ahmad", "Ijaz", ""]]}, {"id": "2007.05315", "submitter": "Jo\\~ao Batista Matos J\\'unior", "authors": "Jo\\~ao Batista Pereira Matos Ju\\'unior, Lucas Carvalho Cordeiro,\n  Marcelo d'Amorim, Xiaowei Huang", "title": "Generating Adversarial Inputs Using A Black-box Differential Technique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Networks (NNs) are known to be vulnerable to adversarial attacks. A\nmalicious agent initiates these attacks by perturbing an input into another one\nsuch that the two inputs are classified differently by the NN. In this paper,\nwe consider a special class of adversarial examples, which can exhibit not only\nthe weakness of NN models - as do for the typical adversarial examples - but\nalso the different behavior between two NN models. We call them\ndifference-inducing adversarial examples or DIAEs. Specifically, we propose\nDAEGEN, the first black-box differential technique for adversarial input\ngeneration. DAEGEN takes as input two NN models of the same classification\nproblem and reports on output an adversarial example. The obtained adversarial\nexample is a DIAE, so that it represents a point-wise difference in the input\nspace between the two NN models. Algorithmically, DAEGEN uses a local\nsearch-based optimization algorithm to find DIAEs by iteratively perturbing an\ninput to maximize the difference of two models on predicting the input. We\nconduct experiments on a spectrum of benchmark datasets (e.g., MNIST, ImageNet,\nand Driving) and NN models (e.g., LeNet, ResNet, Dave, and VGG). Experimental\nresults are promising. First, we compare DAEGEN with two existing white-box\ndifferential techniques (DeepXplore and DLFuzz) and find that under the same\nsetting, DAEGEN is 1) effective, i.e., it is the only technique that succeeds\nin generating attacks in all cases, 2) precise, i.e., the adversarial attacks\nare very likely to fool machines and humans, and 3) efficient, i.e, it requires\na reasonable number of classification queries. Second, we compare DAEGEN with\nstate-of-the-art black-box adversarial attack methods (simba and tremba), by\nadapting them to work on a differential setting. The experimental results show\nthat DAEGEN performs better than both of them.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 11:25:31 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Ju\u00fanior", "Jo\u00e3o Batista Pereira Matos", ""], ["Cordeiro", "Lucas Carvalho", ""], ["d'Amorim", "Marcelo", ""], ["Huang", "Xiaowei", ""]]}, {"id": "2007.05337", "submitter": "Billy Bob Brumley", "authors": "Alejandro Cabrera Aldaya, Billy Bob Brumley", "title": "Online Template Attacks: Revisited", "comments": null, "journal-ref": null, "doi": "10.46586/tches.v2021.i3.28-59", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An online template attack (OTA) is a powerful technique previously used to\nattack elliptic curve scalar multiplication algorithms. This attack has only\nbeen analyzed in the realm of power consumption and EM side channels, where the\nsignals leak related to the value being processed. However, microarchitecture\nsignals have no such feature, invalidating some assumptions from previous OTA\nworks.\n  In this paper, we revisit previous OTA descriptions, proposing a generic\nframework and evaluation metrics for any side-channel signal. Our analysis\nreveals OTA features not previously considered, increasing its application\nscenarios and requiring a fresh countermeasure analysis to prevent it.\n  In this regard, we demonstrate that OTAs can work in the backward direction,\nallowing to mount an augmented projective coordinates attack with respect to\nthe proposal by Naccache, Smart and Stern (Eurocrypt 2004). This demonstrates\nthat randomizing the initial targeted algorithm state does not prevent the\nattack as believed in previous works.\n  We analyze three libraries libgcrypt, mbedTLS, and wolfSSL using two\nmicroarchitecture side channels. For the libgcrypt case, we target its EdDSA\nimplementation using Curve25519 twist curve. We obtain similar results for\nmbedTLS and wolfSSL with curve secp256r1. For each library, we execute\nextensive attack instances that are able to recover the complete scalar in all\ncases using a single trace.\n  This work demonstrates that microarchitecture online template attacks are\nalso very powerful in this scenario, recovering secret information without\nknowing a leakage model. This highlights the importance of developing\nsecure-by-default implementations, instead of fix-on-demand ones.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 12:30:30 GMT"}, {"version": "v2", "created": "Sun, 11 Jul 2021 05:46:25 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Aldaya", "Alejandro Cabrera", ""], ["Brumley", "Billy Bob", ""]]}, {"id": "2007.05373", "submitter": "Joris Dugueperoux", "authors": "Joris Dugu\\'ep\\'eroux (DRUID), Tristan Allard (DRUID)", "title": "From Task Tuning to Task Assignment in Privacy-Preserving Crowdsourcing\n  Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.DB cs.DC cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Specialized worker profiles of crowdsourcing platforms may contain a large\namount of identifying and possibly sensitive personal information (e.g.,\npersonal preferences, skills, available slots, available devices) raising\nstrong privacy concerns. This led to the design of privacy-preserving\ncrowdsourcing platforms, that aim at enabling efficient crowd-sourcing\nprocesses while providing strong privacy guarantees even when the platform is\nnot fully trusted. In this paper, we propose two contributions. First, we\npropose the PKD algorithm with the goal of supporting a large variety of\naggregate usages of worker profiles within a privacy-preserving crowdsourcing\nplatform. The PKD algorithm combines together homomorphic encryption and\ndifferential privacy for computing (perturbed) partitions of the\nmulti-dimensional space of skills of the actual population of workers and a\n(perturbed) COUNT of workers per partition. Second, we propose to benefit from\nrecent progresses in Private Information Retrieval techniques in order to\ndesign a solution to task assignment that is both private and affordable. We\nperform an in-depth study of the problem of using PIR techniques for proposing\ntasks to workers, show that it is NP-Hard, and come up with the PKD PIR Packing\nheuristic that groups tasks together according to the partitioning output by\nthe PKD algorithm. In a nutshell, we design the PKD algorithm and the PKD PIR\nPacking heuristic, we prove formally their security against honest-but-curious\nworkers and/or platform, we analyze their complexities, and we demonstrate\ntheir quality and affordability in real-life scenarios through an extensive\nexperimental evaluation performed over both synthetic and realistic datasets.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 13:21:18 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Dugu\u00e9p\u00e9roux", "Joris", "", "DRUID"], ["Allard", "Tristan", "", "DRUID"]]}, {"id": "2007.05522", "submitter": "Bernardo Huberman", "authors": "Bernardo Huberman, Bob Lund and Jing Wang", "title": "Quantum Secured Internet Transport", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.NI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing represents an emerging threat to the public key\ninfrastructure underlying transport layer security (TLS) widely used in the\nInternet. This paper describes how QKD symmetric keys can be used with TLS to\nprovide quantum computing resistant security for existing Internet\napplications. We also implement and test a general hybrid key delivery\narchitecture with QKD over long distance fibers between secure sites, and\nwireless key distribution over short distance within each site Finally we show\nhow this same capability can be extended to a TLS cipher scheme with perfect\nsecurity.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 17:57:06 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Huberman", "Bernardo", ""], ["Lund", "Bob", ""], ["Wang", "Jing", ""]]}, {"id": "2007.05553", "submitter": "Mikko Heikkil\\\"a", "authors": "Mikko A. Heikkil\\\"a, Antti Koskela, Kana Shimizu, Samuel Kaski, Antti\n  Honkela", "title": "Differentially private cross-silo federated learning", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strict privacy is of paramount importance in distributed machine learning.\nFederated learning, with the main idea of communicating only what is needed for\nlearning, has been recently introduced as a general approach for distributed\nlearning to enhance learning and improve security. However, federated learning\nby itself does not guarantee any privacy for data subjects. To quantify and\ncontrol how much privacy is compromised in the worst-case, we can use\ndifferential privacy.\n  In this paper we combine additively homomorphic secure summation protocols\nwith differential privacy in the so-called cross-silo federated learning\nsetting. The goal is to learn complex models like neural networks while\nguaranteeing strict privacy for the individual data subjects. We demonstrate\nthat our proposed solutions give prediction accuracy that is comparable to the\nnon-distributed setting, and are fast enough to enable learning models with\nmillions of parameters in a reasonable time.\n  To enable learning under strict privacy guarantees that need privacy\namplification by subsampling, we present a general algorithm for oblivious\ndistributed subsampling. However, we also argue that when malicious parties are\npresent, a simple approach using distributed Poisson subsampling gives better\nprivacy.\n  Finally, we show that by leveraging random projections we can further\nscale-up our approach to larger models while suffering only a modest\nperformance loss.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 18:15:10 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Heikkil\u00e4", "Mikko A.", ""], ["Koskela", "Antti", ""], ["Shimizu", "Kana", ""], ["Kaski", "Samuel", ""], ["Honkela", "Antti", ""]]}, {"id": "2007.05556", "submitter": "Panagiotis Papadopoulos", "authors": "Gon\\c{c}alo Pestana, I\\~nigo Querejeta-Azurmendi, Panagiotis\n  Papadopoulos, Benjamin Livshits", "title": "THEMIS: Decentralized and Trustless Ad Platform with Reporting Integrity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online advertising fuels the (seemingly) free internet. However, although\nusers can access most websites free of charge, they need to pay a heavy cost on\ntheir privacy and blindly trust third parties and intermediaries that absorb\ngreat amounts of adrevenues and user data. This is one of the reasons users opt\nout from advertising by resorting ad blockers thatin turn cost publishers\nmillions of dollars in lost adrevenues. Existing privacy-preserving advertising\napproaches(e.g., Adnostic, Privad, Brave Ads) from both industry and academia\ncannot guarantee the integrity of the performance analytics they provide to\nadvertisers, while they also rely on centralized management that users have to\ntrust without being able to audit. In this paper, we propose THEMIS, a novel\nprivacy-by-design ad platform that is decentralized and requires zero trust\nfrom users. THEMIS (i) provides auditability to all participants, (ii) rewards\nusers for viewing ads, and (iii) allows advertisers to verify the performance\nand billing reports of their ad campaigns. To demonstrate the feasibility and\npracticability of our approach, we implemented a prototype of THEMIS using a\ncombination of smart contracts and zero-knowledge schemes. Performance\nevaluation results show that during adreward payouts, THEMIS can support more\nthan 51M users on a single-sidechain setup or 153M users ona multi-sidechain\nsetup, thus proving that THEMIS scales linearly.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 18:24:19 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 17:13:38 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Pestana", "Gon\u00e7alo", ""], ["Querejeta-Azurmendi", "I\u00f1igo", ""], ["Papadopoulos", "Panagiotis", ""], ["Livshits", "Benjamin", ""]]}, {"id": "2007.05573", "submitter": "Yutong Gao", "authors": "Yutong Gao, Yi Pan", "title": "Improved Detection of Adversarial Images Using Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques are immensely deployed in both industry and\nacademy. Recent studies indicate that machine learning models used for\nclassification tasks are vulnerable to adversarial examples, which limits the\nusage of applications in the fields with high precision requirements. We\npropose a new approach called Feature Map Denoising to detect the adversarial\ninputs and show the performance of detection on the mixed dataset consisting of\nadversarial examples generated by different attack algorithms, which can be\nused to associate with any pre-trained DNNs at a low cost. Wiener filter is\nalso introduced as the denoise algorithm to the defense model, which can\nfurther improve performance. Experimental results indicate that good accuracy\nof detecting the adversarial examples can be achieved through our Feature Map\nDenoising algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 19:02:24 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Gao", "Yutong", ""], ["Pan", "Yi", ""]]}, {"id": "2007.05596", "submitter": "Mohammad Mohammadinodoushan", "authors": "Mohammad Mohammadinodoushan", "title": "Hardware Implementation of Keyless Encryption Scheme for Internet of\n  Things Based on Image of Memristors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) is rapidly increasing the number of connected\ndevices. This causes new concerns towards solutions for authenticating numerous\nIoT devices. Most of these devices are resource-constrained. Therefore, the use\nof long-secret keys, in traditional cryptography schemes can be hard to\nimplement. Also, the key generation, distribution, and storage are very\ncomplex. Moreover, the goal of many reported cyber-attacks is accessing the\nkey. Therefore, researchers have shown an increased interest in designing\nkeyless encryption schemes recently. In this report, we are going to explain\nthe details of the implementation of the keyless protocol by taking advantage\nof known technology modules such as microcontrollers (MCU), and hash functions.\nPhysical Unclonable Functions (PUFs) have been used in many cryptographic\napplications such as Password Management Systems, key exchange, Key Generation.\nIn this report, we are going to explain the details of the hardware\nimplementation of keyless encryption in the MCU. Different kinds of memristors\nhave been used in the past. In this work, a look-up-table containing memristor\ncells value at the various current levels is used since the physical component\nis unavailable yet. The hardware that is used to implement the system is an\nevaluation-board of SAMV71 MCU, which is used to implement the control system\nand hardware hashing.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 20:11:58 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 01:18:47 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Mohammadinodoushan", "Mohammad", ""]]}, {"id": "2007.05614", "submitter": "Roi Bar Zur", "authors": "Roi Bar-Zur, Ittay Eyal and Aviv Tamar", "title": "Efficient MDP Analysis for Selfish-Mining in Blockchains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A proof of work (PoW) blockchain protocol distributes rewards to its\nparticipants, called miners, according to their share of the total\ncomputational power. Sufficiently large miners can perform selfish mining -\ndeviate from the protocol to gain more than their fair share. Such systems are\nthus secure if all miners are smaller than a threshold size so their best\nresponse is following the protocol.\n  To find the threshold, one has to identify the optimal strategy for miners of\ndifferent sizes, i.e., solve a Markov Decision Process (MDP). However, because\nof the PoW difficulty adjustment mechanism, the miners' utility is a non-linear\nratio function. We therefore call this an Average Reward Ratio (ARR) MDP.\nSapirshtein et al.\\ were the first to solve ARR MDPs by solving a series of\nstandard MDPs that converge to the ARR MDP solution.\n  In this work, we present a novel technique for solving an ARR MDP by solving\na single standard MDP. The crux of our approach is to augment the MDP such that\nit terminates randomly, within an expected number of rounds. We call this\nProbabilistic Termination Optimization (PTO), and the technique applies to any\nMDP whose utility is a ratio function. We bound the approximation error of PTO\n- it is inversely proportional to the expected number of rounds before\ntermination, a parameter that we control. Empirically, PTO's complexity is an\norder of magnitude lower than the state of the art.\n  PTO can be easily applied to different blockchains. We use it to tighten the\nbound on the threshold for selfish mining in Ethereum.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 21:22:03 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 17:36:40 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Bar-Zur", "Roi", ""], ["Eyal", "Ittay", ""], ["Tamar", "Aviv", ""]]}, {"id": "2007.05817", "submitter": "Guanxiong Liu", "authors": "Guanxiong Liu, Issa Khalil, Abdallah Khreishah, Abdulelah Algosaibi,\n  Adel Aldalbahi, Mohammed Alaneem, Abdulaziz Alhumam, Mohammed Anan", "title": "ManiGen: A Manifold Aided Black-box Generator of Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models, especially neural network (NN) classifiers, have\nacceptable performance and accuracy that leads to their wide adoption in\ndifferent aspects of our daily lives. The underlying assumption is that these\nmodels are generated and used in attack free scenarios. However, it has been\nshown that neural network based classifiers are vulnerable to adversarial\nexamples. Adversarial examples are inputs with special perturbations that are\nignored by human eyes while can mislead NN classifiers. Most of the existing\nmethods for generating such perturbations require a certain level of knowledge\nabout the target classifier, which makes them not very practical. For example,\nsome generators require knowledge of pre-softmax logits while others utilize\nprediction scores.\n  In this paper, we design a practical black-box adversarial example generator,\ndubbed ManiGen. ManiGen does not require any knowledge of the inner state of\nthe target classifier. It generates adversarial examples by searching along the\nmanifold, which is a concise representation of input data. Through extensive\nset of experiments on different datasets, we show that (1) adversarial examples\ngenerated by ManiGen can mislead standalone classifiers by being as successful\nas the state-of-the-art white-box generator, Carlini, and (2) adversarial\nexamples generated by ManiGen can more effectively attack classifiers with\nstate-of-the-art defenses.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 17:34:17 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Liu", "Guanxiong", ""], ["Khalil", "Issa", ""], ["Khreishah", "Abdallah", ""], ["Algosaibi", "Abdulelah", ""], ["Aldalbahi", "Adel", ""], ["Alaneem", "Mohammed", ""], ["Alhumam", "Abdulaziz", ""], ["Anan", "Mohammed", ""]]}, {"id": "2007.05828", "submitter": "Ka-Ho Chow", "authors": "Ka-Ho Chow, Ling Liu, Mehmet Emre Gursoy, Stacey Truex, Wenqi Wei,\n  Yanzhao Wu", "title": "Understanding Object Detection Through An Adversarial Lens", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks based object detection models have revolutionized\ncomputer vision and fueled the development of a wide range of visual\nrecognition applications. However, recent studies have revealed that deep\nobject detectors can be compromised under adversarial attacks, causing a victim\ndetector to detect no object, fake objects, or mislabeled objects. With object\ndetection being used pervasively in many security-critical applications, such\nas autonomous vehicles and smart cities, we argue that a holistic approach for\nan in-depth understanding of adversarial attacks and vulnerabilities of deep\nobject detection systems is of utmost importance for the research community to\ndevelop robust defense mechanisms. This paper presents a framework for\nanalyzing and evaluating vulnerabilities of the state-of-the-art object\ndetectors under an adversarial lens, aiming to analyze and demystify the attack\nstrategies, adverse effects, and costs, as well as the cross-model and\ncross-resolution transferability of attacks. Using a set of quantitative\nmetrics, extensive experiments are performed on six representative deep object\ndetectors from three popular families (YOLOv3, SSD, and Faster R-CNN) with two\nbenchmark datasets (PASCAL VOC and MS COCO). We demonstrate that the proposed\nframework can serve as a methodical benchmark for analyzing adversarial\nbehaviors and risks in real-time object detection systems. We conjecture that\nthis framework can also serve as a tool to assess the security risks and the\nadversarial robustness of deep object detectors to be deployed in real-world\napplications.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 18:41:47 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Chow", "Ka-Ho", ""], ["Liu", "Ling", ""], ["Gursoy", "Mehmet Emre", ""], ["Truex", "Stacey", ""], ["Wei", "Wenqi", ""], ["Wu", "Yanzhao", ""]]}, {"id": "2007.05876", "submitter": "Lan Luo", "authors": "Lan Luo, Yue Zhang, Cliff C. Zou, Xinhui Shao, Zhen Ling and Xinwen Fu", "title": "On Runtime Software Security of TrustZone-M based IoT Devices", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) devices have been increasingly integrated into our\ndaily life. However, such smart devices suffer a broad attack surface.\nParticularly, attacks targeting the device software at runtime are challenging\nto defend against if IoT devices use resource-constrained microcontrollers\n(MCUs). TrustZone-M, a TrustZone extension for MCUs, is an emerging security\ntechnique fortifying MCU based IoT devices. This paper presents the first\nsecurity analysis of potential software security issues in TrustZone-M enabled\nMCUs. We explore the stack-based buffer overflow (BOF) attack for code\ninjection, return-oriented programming (ROP) attack, heap-based BOF attack,\nformat string attack, and attacks against Non-secure Callable (NSC) functions\nin the context of TrustZone-M. We validate these attacks using the TrustZone-M\nenabled SAM L11 MCU. Strategies to mitigate these software attacks are also\ndiscussed.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 00:03:39 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Luo", "Lan", ""], ["Zhang", "Yue", ""], ["Zou", "Cliff C.", ""], ["Shao", "Xinhui", ""], ["Ling", "Zhen", ""], ["Fu", "Xinwen", ""]]}, {"id": "2007.05922", "submitter": "Amir Andalib", "authors": "Amir Andalib and Vahid Tabataba Vakili", "title": "A Novel Dimension Reduction Scheme for Intrusion Detection Systems in\n  IoT Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) brings new challenges to the security solutions of\ncomputer networks. So far, intrusion detection system (IDS) is one of the\neffective security tools, but the vast amount of data that is generated by\nheterogeneous protocols and \"things\" alongside the constrained resources of the\nhosts, make some of the present IDS schemes defeated. To grant IDSs the ability\nof working in the IoT environments, in this paper, we propose a new distributed\ndimension reduction scheme which addresses the limited resources challenge. A\nnovel autoencoder (AE) designed, and it learns to generate a latent space.\nThen, the constrained hosts/probes use the generated weights to lower the\ndimension with a single operation. The compressed data is transferred to a\ncentral IDS server to verify the traffic type. This scheme aims to lower the\nneeded bandwidth to transfer data by compressing it and also reduce the\noverhead of the compression task in the hosts. The proposed scheme is evaluated\non three well-known network traffic datasets (UNSW-NB15, TON\\_IoT20 and\nNSL-KDD), and the results show that we can have a 3-dimensional latent space\n(about 90\\% compression) without any remarkable fall in IDS detection accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 06:27:29 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Andalib", "Amir", ""], ["Vakili", "Vahid Tabataba", ""]]}, {"id": "2007.05955", "submitter": "John Galea", "authors": "John Galea and Daniel Kroening", "title": "The Taint Rabbit: Optimizing Generic Taint Analysis with Dynamic Fast\n  Path Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generic taint analysis is a pivotal technique in software security. However,\nit suffers from staggeringly high overhead. In this paper, we explore the\nhypothesis whether just-in-time (JIT) generation of fast paths for tracking\ntaint can enhance the performance. To this end, we present the Taint Rabbit,\nwhich supports highly customizable user-defined taint policies and combines a\nJIT with fast context switching. Our experimental results suggest that this\ncombination outperforms notable existing implementations of generic taint\nanalysis and bridges the performance gap to specialized trackers. For instance,\nDytan incurs an average overhead of 237x, while the Taint Rabbit achieves 1.7x\non the same set of benchmarks. This compares favorably to the 1.5x overhead\ndelivered by the bitwise, non-generic, taint engine LibDFT.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 10:33:07 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Galea", "John", ""], ["Kroening", "Daniel", ""]]}, {"id": "2007.05975", "submitter": "Benjamin Rubinstein", "authors": "Tobias Edwards, Benjamin I. P. Rubinstein, Zuhe Zhang, Sanming Zhou", "title": "A Graph Symmetrisation Bound on Channel Information Leakage under\n  Blowfish Privacy", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blowfish privacy is a recent generalisation of differential privacy that\nenables improved utility while maintaining privacy policies with semantic\nguarantees, a factor that has driven the popularity of differential privacy in\ncomputer science. This paper relates Blowfish privacy to an important measure\nof privacy loss of information channels from the communications theory\ncommunity: min-entropy leakage. Symmetry in an input data neighbouring relation\nis central to known connections between differential privacy and min-entropy\nleakage. But while differential privacy exhibits strong symmetry, Blowfish\nneighbouring relations correspond to arbitrary simple graphs owing to the\nframework's flexible privacy policies. To bound the min-entropy leakage of\nBlowfish-private mechanisms we organise our analysis over symmetrical\npartitions corresponding to orbits of graph automorphism groups. A construction\nmeeting our bound with asymptotic equality demonstrates tightness.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 12:38:32 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 06:43:47 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Edwards", "Tobias", ""], ["Rubinstein", "Benjamin I. P.", ""], ["Zhang", "Zuhe", ""], ["Zhou", "Sanming", ""]]}, {"id": "2007.05991", "submitter": "George Bissias", "authors": "George Bissias", "title": "Radium: Improving Dynamic PoW Targeting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most PoW blockchain protocols operate with a simple mechanism whereby a\nthreshold is set for each block and miners generate block hashes until one of\nthose values falls below the threshold. Although largely effective, this\nmechanism produces blocks at a highly variable rate and also leaves a\nblockchain susceptible to chain death, i.e. abandonment in the event that the\nthreshold is set too high to attract any miners. A recent innovation called\nreal-time block rate targeting, or RTT, fixes these problems by reducing the\ntarget throughout the mining interval. RTT exhibits much less variable block\ntimes and even features the ability to fully adjust the target after each\nblock. However, as we show in this paper, RTT also suffers from a critical\nvulnerability whereby miners deviate form the protocol to increase their\nprofits. We introduce the Radium protocol, which mitigates this vulnerability\nin RTT while retaining lower variance block times, responsive target\nadjustment, and lowering the risk of chain death. We also show that Radium's\nsusceptibility to the doublespend attack and orphaned blocks remains similar to\nBitcoin.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 13:53:27 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Bissias", "George", ""]]}, {"id": "2007.06022", "submitter": "Muhammad Baqer Mollah Mr.", "authors": "Muhammad Baqer Mollah, Jun Zhao, Dusit Niyato, Yong Liang Guan, Chau\n  Yuen, Sumei Sun, Kwok-Yan Lam, Leong Hai Koh", "title": "Blockchain for the Internet of Vehicles towards Intelligent\n  Transportation Systems: A Survey", "comments": "28 Pages, 17 Figures, 4 tables", "journal-ref": "IEEE Internet of Things Journal 2020", "doi": "10.1109/JIOT.2020.3028368", "report-no": null, "categories": "cs.CR cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Vehicles (IoV) is an emerging concept that is believed to help\nrealise the vision of intelligent transportation systems (ITS). IoV has become\nan important research area of impactful applications in recent years due to the\nrapid advancements in vehicular technologies, high throughput satellite\ncommunication, Internet of Things and cyber-physical systems. IoV enables the\nintegration of smart vehicles with the Internet and system components\nattributing to their environment such as public infrastructures, sensors,\ncomputing nodes, pedestrians and other vehicles. By allowing the development of\na common information exchange platform between vehicles and heterogeneous\nvehicular networks, this integration aims to create a better environment and\npublic space to the people as well as to enhance safety for all road users.\nBeing a participatory data exchange and storage, the underlying information\nexchange platform of IoV needs to be secure, transparent and immutable in order\nto achieve the intended objectives of ITS. In this connection, the adoption of\nblockchain as a system platform for supporting the information exchange needs\nof IoV has been explored. Due to their decentralized and immutable nature, IoV\napplications enabled by blockchain are believed to have a number of desirable\nproperties such as decentralization, security, transparency, immutability, and\nautomation. In this paper, we present a contemporary survey on the latest\nadvancement in blockchain for IoV. Particularly, we highlight the different\napplication scenarios of IoV after carefully reviewing the recent literatures.\nWe also investigate several key challenges where blockchain is applied in IoV.\nFurthermore, we present the future opportunities and explore further research\ndirections of IoV as a key enabler of ITS.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 15:53:02 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 03:51:17 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Mollah", "Muhammad Baqer", ""], ["Zhao", "Jun", ""], ["Niyato", "Dusit", ""], ["Guan", "Yong Liang", ""], ["Yuen", "Chau", ""], ["Sun", "Sumei", ""], ["Lam", "Kwok-Yan", ""], ["Koh", "Leong Hai", ""]]}, {"id": "2007.06032", "submitter": "Hatem Hajri", "authors": "Th\\'eo Combey, Ant\\'onio Loison, Maxime Faucher and Hatem Hajri", "title": "Probabilistic Jacobian-based Saliency Maps Attacks", "comments": "Journal Machine Learning and Knowledge Extraction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network classifiers (NNCs) are known to be vulnerable to malicious\nadversarial perturbations of inputs including those modifying a small fraction\nof the input features named sparse or $L_0$ attacks. Effective and fast $L_0$\nattacks, such as the widely used Jacobian-based Saliency Map Attack (JSMA) are\npractical to fool NNCs but also to improve their robustness. In this paper, we\nshow that penalising saliency maps of JSMA by the output probabilities and the\ninput features of the NNC allows to obtain more powerful attack algorithms that\nbetter take into account each input's characteristics. This leads us to\nintroduce improved versions of JSMA, named Weighted JSMA (WJSMA) and Taylor\nJSMA (TJSMA), and demonstrate through a variety of white-box and black-box\nexperiments on three different datasets (MNIST, CIFAR-10 and GTSRB), that they\nare both significantly faster and more efficient than the original targeted and\nnon-targeted versions of JSMA. Experiments also demonstrate, in some cases,\nvery competitive results of our attacks in comparison with the Carlini-Wagner\n(CW) $L_0$ attack, while remaining, like JSMA, significantly faster (WJSMA and\nTJSMA are more than 50 times faster than CW $L_0$ on CIFAR-10). Therefore, our\nnew attacks provide good trade-offs between JSMA and CW for $L_0$ real-time\nadversarial testing on datasets such as the ones previously cited. Codes are\npublicly available through the link\nhttps://github.com/probabilistic-jsmas/probabilistic-jsmas.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 16:32:26 GMT"}, {"version": "v2", "created": "Sun, 9 Aug 2020 10:34:10 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2020 15:06:02 GMT"}, {"version": "v4", "created": "Thu, 10 Dec 2020 11:19:11 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Combey", "Th\u00e9o", ""], ["Loison", "Ant\u00f3nio", ""], ["Faucher", "Maxime", ""], ["Hajri", "Hatem", ""]]}, {"id": "2007.06119", "submitter": "Nazanin Takbiri", "authors": "Nazanin Takbiri, Minting Chen, Dennis L. Goeckel, Amir Houmansadr,\n  Hossein Pishro-Nik", "title": "Asymptotic Privacy Loss due to Time Series Matching of Dependent Users", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) promises to improve user utility by tuning\napplications to user behavior, but revealing the characteristics of a user's\nbehavior presents a significant privacy risk. Our previous work has established\nthe challenging requirements for anonymization to protect users' privacy in a\nBayesian setting in which we assume a powerful adversary who has perfect\nknowledge of the prior distribution for each user's behavior. However, even\nsophisticated adversaries do not often have such perfect knowledge; hence, in\nthis paper, we turn our attention to an adversary who must learn user behavior\nfrom past data traces of limited length. We also assume there exists dependency\nbetween data traces of different users, and the data points of each user are\ndrawn from a normal distribution. Results on the lengths of training sequences\nand data sequences that result in a loss of user privacy are presented.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 22:42:20 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Takbiri", "Nazanin", ""], ["Chen", "Minting", ""], ["Goeckel", "Dennis L.", ""], ["Houmansadr", "Amir", ""], ["Pishro-Nik", "Hossein", ""]]}, {"id": "2007.06201", "submitter": "Rourab Paul", "authors": "Rourab Paul, Nimisha Ghosh, Amlan Chakrabarti, Prasant Mahapatra", "title": "The Blockchain Based Auditor on Secret key Life Cycle in Reconfigurable\n  Platform", "comments": "Manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing sophistication of cyber attacks, vulnerabilities in high\ncomputing systems and increasing dependency on cryptography to protect our\ndigital data make it more important to keep secret keys safe and secure. Few\nmajor issues on secret keys like incorrect use of keys, inappropriate storage\nof keys, inadequate protection of keys, insecure movement of keys, lack of\naudit logging, insider threats and non-destruction of keys can compromise the\nwhole security system dangerously. In this article, we have proposed and\nimplemented an isolated secret key memory which can log life cycle of secret\nkeys cryptographically using blockchain (BC) technology. We have also\nimplemented a special custom bus interconnect which receives custom crypto\ninstruction from Processing Element (PE). During the execution of crypto\ninstructions, the architecture assures that secret key will never come in the\nprocessor area and the movement of secret keys to various crypto core is\nrecorded cryptographically after the proper authentication process controlled\nby proposed hardware based BC. To the best of our knowledge, this is the first\nwork which uses blockchain based solution to address the issues of the life\ncycle of the secret keys in hardware platform. The additional cost of resource\nusage and timing complexity we spent to implement the proposed idea is very\nnominal. We have used Xilinx Vivado EDA tool and Artix 7 FPGA board.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 06:03:11 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Paul", "Rourab", ""], ["Ghosh", "Nimisha", ""], ["Chakrabarti", "Amlan", ""], ["Mahapatra", "Prasant", ""]]}, {"id": "2007.06236", "submitter": "Bal\\'azs Pej\\'o", "authors": "Bal\\'azs Pej\\'o and Gergely Bicz\\'ok", "title": "Quality Inference in Federated Learning with Secure Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Collaborative machine learning algorithms are developed both for efficiency\nreasons, and to ensure the privacy protection of sensitive data used for\nprocessing. Federated learning is the most popular of these methods, where 1)\nlearning is done locally, and 2) only a subset of the participants contribute\nin each training round. Despite individual data is not shared explicitly,\nrecent studies showed that federated learning models could still leak\ninformation. In this paper we focus on the quality of individual training\ndatasets, and show that such information could be inferred and connected to\nspecific participants even when secure aggregation is applied. Specifically, we\nuse three simple scoring rules for evaluating per round aggregated updates in\nthe federated learning process, and mount a novel differential quality\ninference attack (i.e., relative quality ordering reconstruction). Through a\nseries of image recognition experiments we show that the attack is able to\ninfer the relative quality ordering of participants. Whilst an attack in the\ntraditional sense, quality inference could also improve the federated learning\nprocess: we demonstrate how it can be used to (i) boost training efficiency and\n(ii) detect misbehavior. Finally, as a system designer might want to alleviate\nquality inference in certain use-cases, we discuss mitigation approaches.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 08:36:04 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 08:18:28 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Pej\u00f3", "Bal\u00e1zs", ""], ["Bicz\u00f3k", "Gergely", ""]]}, {"id": "2007.06308", "submitter": "Alireza Shojaifar", "authors": "Alireza Shojaifar and Samuel A. Fricker", "title": "SMEs' Confidentiality Concerns for Security Information Sharing", "comments": "10 pages, 2 figures, 14th International Symposium on Human Aspects of\n  Information Security & Assurance (HAISA 2020)", "journal-ref": null, "doi": "10.1007/978-3-030-57404-8_22", "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Small and medium-sized enterprises are considered an essential part of the EU\neconomy, however, highly vulnerable to cyberattacks. SMEs have specific\ncharacteristics which separate them from large companies and influence their\nadoption of good cybersecurity practices. To mitigate the SMEs' cybersecurity\nadoption issues and raise their awareness of cyber threats, we have designed a\nself-paced security assessment and capability improvement method, CYSEC. CYSEC\nis a security awareness and training method that utilises self-reporting\nquestionnaires to collect companies' information about cybersecurity awareness,\npractices, and vulnerabilities to generate automated recommendations for\ncounselling. However, confidentiality concerns about cybersecurity information\nhave an impact on companies' willingness to share their information. Security\ninformation sharing decreases the risk of incidents and increases users'\nself-efficacy in security awareness programs. This paper presents the results\nof semi-structured interviews with seven chief information security officers of\nSMEs to evaluate the impact of online consent communication on motivation for\ninformation sharing. The results were analysed in respect of the Self\nDetermination Theory. The findings demonstrate that online consent with\nmultiple options for indicating a suitable level of agreement improved\nmotivation for information sharing. This allows many SMEs to participate in\nsecurity information sharing activities and supports security experts to have a\nbetter overview of common vulnerabilities. The final publication is available\nat Springer via https://doi.org/10.1007/978-3-030-57404-8_22\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 10:59:40 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 16:19:50 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Shojaifar", "Alireza", ""], ["Fricker", "Samuel A.", ""]]}, {"id": "2007.06319", "submitter": "Lars Schlieper", "authors": "Lars Schlieper", "title": "In-place implementation of Quantum-Gimli", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an in-place implementation of the $\\textbf{Gimli}$ permutation, a\nNIST round 2 candidate for lightweight cryptography and provide an upper bound\nfor the required quantum resource in depth and gate-counts. In particular, we\ndo not use any ancilla bits and the state that our circuit produces is not\nentangled with any input, which offers further freedom in the usability and\nallows for a widespread use in different applications in a plug-and-play\nmanner.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 11:31:38 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Schlieper", "Lars", ""]]}, {"id": "2007.06353", "submitter": "Dung Hoang Duong", "authors": "Willy Susilo, Dung Hoang Duong, Huy Quoc Le, Josef Pieprzyk", "title": "Puncturable Encryption: A Generic Construction from Delegatable Fully\n  Key-Homomorphic Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Puncturable encryption (PE), proposed by Green and Miers at IEEE S&P 2015, is\na kind of public key encryption that allows recipients to revoke individual\nmessages by repeatedly updating decryption keys without communicating with\nsenders. PE is an essential tool for constructing many interesting\napplications, such as asynchronous messaging systems, forward-secret zero\nround-trip time protocols, public-key watermarking schemes and forward-secret\nproxy re-encryptions. This paper revisits PEs from the observation that the\npuncturing property can be implemented as efficiently computable functions.\nFrom this view, we propose a generic PE construction from the fully\nkey-homomorphic encryption, augmented with a key delegation mechanism (DFKHE)\nfrom Boneh et al. at Eurocrypt 2014. We show that our PE construction enjoys\nthe selective security under chosen plaintext attacks (that can be converted\ninto the adaptive security with some efficiency loss) from that of DFKHE in the\nstandard model. Basing on the framework, we obtain the first post-quantum\nsecure PE instantiation that is based on the learning with errors problem,\nselective secure under chosen plaintext attacks (CPA) in the standard model. We\nalso discuss about the ability of modification our framework to support the\nunbounded number of ciphertext tags inspired from the work of Brakerski and\nVaikuntanathan at CRYPTO 2016.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 12:55:53 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Susilo", "Willy", ""], ["Duong", "Dung Hoang", ""], ["Le", "Huy Quoc", ""], ["Pieprzyk", "Josef", ""]]}, {"id": "2007.06605", "submitter": "Om Thakkar", "authors": "Borja Balle, Peter Kairouz, H. Brendan McMahan, Om Thakkar, Abhradeep\n  Thakurta", "title": "Privacy Amplification via Random Check-Ins", "comments": "Updated proof for $(\\epsilon_0, \\delta_0)$-DP local randomizers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Differentially Private Stochastic Gradient Descent (DP-SGD) forms a\nfundamental building block in many applications for learning over sensitive\ndata. Two standard approaches, privacy amplification by subsampling, and\nprivacy amplification by shuffling, permit adding lower noise in DP-SGD than\nvia na\\\"{\\i}ve schemes. A key assumption in both these approaches is that the\nelements in the data set can be uniformly sampled, or be uniformly permuted --\nconstraints that may become prohibitive when the data is processed in a\ndecentralized or distributed fashion. In this paper, we focus on conducting\niterative methods like DP-SGD in the setting of federated learning (FL) wherein\nthe data is distributed among many devices (clients). Our main contribution is\nthe \\emph{random check-in} distributed protocol, which crucially relies only on\nrandomized participation decisions made locally and independently by each\nclient. It has privacy/accuracy trade-offs similar to privacy amplification by\nsubsampling/shuffling. However, our method does not require server-initiated\ncommunication, or even knowledge of the population size. To our knowledge, this\nis the first privacy amplification tailored for a distributed learning\nframework, and it may have broader applicability beyond FL. Along the way, we\nextend privacy amplification by shuffling to incorporate $(\\epsilon,\\delta)$-DP\nlocal randomizers, and exponentially improve its guarantees. In practical\nregimes, this improvement allows for similar privacy and utility using data\nfrom an order of magnitude fewer users.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 18:14:09 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 16:26:38 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Balle", "Borja", ""], ["Kairouz", "Peter", ""], ["McMahan", "H. Brendan", ""], ["Thakkar", "Om", ""], ["Thakurta", "Abhradeep", ""]]}, {"id": "2007.06622", "submitter": "Hadi Abdullah", "authors": "Hadi Abdullah, Kevin Warren, Vincent Bindschaedler, Nicolas Papernot,\n  and Patrick Traynor", "title": "SoK: The Faults in our ASRs: An Overview of Attacks against Automatic\n  Speech Recognition and Speaker Identification Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech and speaker recognition systems are employed in a variety of\napplications, from personal assistants to telephony surveillance and biometric\nauthentication. The wide deployment of these systems has been made possible by\nthe improved accuracy in neural networks. Like other systems based on neural\nnetworks, recent research has demonstrated that speech and speaker recognition\nsystems are vulnerable to attacks using manipulated inputs. However, as we\ndemonstrate in this paper, the end-to-end architecture of speech and speaker\nsystems and the nature of their inputs make attacks and defenses against them\nsubstantially different than those in the image space. We demonstrate this\nfirst by systematizing existing research in this space and providing a taxonomy\nthrough which the community can evaluate future work. We then demonstrate\nexperimentally that attacks against these models almost universally fail to\ntransfer. In so doing, we argue that substantial additional work is required to\nprovide adequate mitigations in this space.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 18:52:25 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 14:59:27 GMT"}, {"version": "v3", "created": "Tue, 21 Jul 2020 17:42:56 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Abdullah", "Hadi", ""], ["Warren", "Kevin", ""], ["Bindschaedler", "Vincent", ""], ["Papernot", "Nicolas", ""], ["Traynor", "Patrick", ""]]}, {"id": "2007.06625", "submitter": "Ioannis Zografopoulos", "authors": "Ioannis Zografopoulos and Charalambos Konstantinou", "title": "DERauth: A Battery-based Authentication Scheme for Distributed Energy\n  Resources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decades, power systems have experienced drastic transformations\nin order to address the growth in energy demand, reduce carbon emissions, and\nenhance power quality and energy efficiency. This shift to the smart grid\nconcept involves, among others, the utilization of distributed energy resources\n(DERs) such as rooftop solar panels and storage systems, contributing towards\ngrid decentralization while improving control over power generation. In order\nto seamlessly integrate DERs into power systems, embedded devices are used to\nsupport the communication and control functions of DERs. As a result,\nvulnerabilities of such components can be ported to the industrial environment.\nInsecure control networks and protocols further exacerbate the problem. Towards\nreducing the attack surface, we present an authentication scheme for DERs,\nDERauth, which leverages the inherent entropy of the DER battery energy storage\nsystem (BESS) as a root-of-trust. The DER authentication is achieved using a\nchallenge-reply mechanism that relies on the corresponding DER's BESS\nstate-of-charge (SoC) and voltage measurements. A dynamically updating process\nensures that the BESS state is up-to-date. We evaluate our proof-of-concept in\na prototype development that uses lithium-ion (li-ion) batteries for the BESS.\nThe robustness of our design is assessed against modeling attacks performed by\nneural networks.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 18:53:45 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Zografopoulos", "Ioannis", ""], ["Konstantinou", "Charalambos", ""]]}, {"id": "2007.06629", "submitter": "Avelino Zorzo F", "authors": "Guilherme Girotto, Avelino Francisco Zorzo", "title": "Robin: A Web Security Tool", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Thanks to the advance of technology, all kinds of applications are becoming\nmore complete and capable of performing complex tasks that save much of our\ntime. But to perform these tasks, applications require that some personal\ninformation are shared, for example credit card, bank accounts, email\naddresses, etc. All these data must be transferred securely between the final\nuser and the institution application. Nonetheless, several applications might\ncontain residual flaws that may be explored by criminals in order to steal\nusers data. Hence, to help information security professionals and developers to\nperform penetration tests (pentests) on web applications, this paper presents\nRobin: A Web Security Tool. The tool is also applied to a real case study in\nwhich a very dangerous vulnerability was found. This vulnerability is also\ndescribed in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 19:01:01 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Girotto", "Guilherme", ""], ["Zorzo", "Avelino Francisco", ""]]}, {"id": "2007.06704", "submitter": "Florence Regol", "authors": "Florence Regol, Soumyasundar Pal and Mark Coates", "title": "Node Copying for Protection Against Graph Neural Network Topology\n  Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks can affect the performance of existing deep learning\nmodels. With the increased interest in graph based machine learning techniques,\nthere have been investigations which suggest that these models are also\nvulnerable to attacks. In particular, corruptions of the graph topology can\ndegrade the performance of graph based learning algorithms severely. This is\ndue to the fact that the prediction capability of these algorithms relies\nmostly on the similarity structure imposed by the graph connectivity.\nTherefore, detecting the location of the corruption and correcting the induced\nerrors becomes crucial. There has been some recent work which tackles the\ndetection problem, however these methods do not address the effect of the\nattack on the downstream learning task. In this work, we propose an algorithm\nthat uses node copying to mitigate the degradation in classification that is\ncaused by adversarial attacks. The proposed methodology is applied only after\nthe model for the downstream task is trained and the added computation cost\nscales well for large graphs. Experimental results show the effectiveness of\nour approach for several real world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 18:09:55 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Regol", "Florence", ""], ["Pal", "Soumyasundar", ""], ["Coates", "Mark", ""]]}, {"id": "2007.06751", "submitter": "Sarbartha Banerjee", "authors": "Sarbartha Banerjee, Prakash Ramrakhyani, Shijia Wei and Mohit Tiwari", "title": "SESAME: Software defined Enclaves to Secure Inference Accelerators with\n  Multi-tenant Execution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware-enclaves that target complex CPU designs compromise both security\nand performance. Programs have little control over micro-architecture, which\nleads to side-channel leaks, and then have to be transformed to have worst-case\ncontrol- and data-flow behaviors and thus incur considerable slowdown. We\npropose to address these security and performance problems by bringing enclaves\ninto the realm of accelerator-rich architectures. The key idea is to construct\nsoftware-defined enclaves (SDEs) where the protections and slowdown are tied to\nan application-defined threat model and tuned by a compiler for the\naccelerator's specific domain. This vertically integrated approach requires new\nhardware data-structures to partition, clear, and shape the utilization of\nhardware resources; and a compiler that instantiates and schedules these\ndata-structures to create multi-tenant enclaves on accelerators. We demonstrate\nour ideas with a comprehensive prototype -- Sesame -- that includes\nmodifications to compiler, ISA, and microarchitecture to a decoupled access\nexecute (DAE) accelerator framework for deep learning models. Our security\nevaluation shows that classifiers that could distinguish different layers in\nVGG, ResNet, and AlexNet, fail to do so when run using Sesame. Our\nsynthesizable hardware prototype (on a Xilinx Pynq board) demonstrates how the\ncompiler and micro-architecture enables threat-model-specific trade-offs in\ncode size increase ranging from 3-7 $\\%$ and run-time performance overhead for\nspecific defenses ranging from 3.96$\\%$ to 34.87$\\%$ (across confidential\ninputs and models and single vs. multi-tenant systems).\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 00:59:28 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 01:29:55 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Banerjee", "Sarbartha", ""], ["Ramrakhyani", "Prakash", ""], ["Wei", "Shijia", ""], ["Tiwari", "Mohit", ""]]}, {"id": "2007.06763", "submitter": "Will Pearce", "authors": "Will Pearce, Nick Landers, and Nancy Fulda", "title": "Machine Learning for Offensive Security: Sandbox Classification Using\n  Decision Trees and Artificial Neural Networks", "comments": "SAI Conference on Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The merits of machine learning in information security have primarily focused\non bolstering defenses. However, machine learning (ML) techniques are not\nreserved for organizations with deep pockets and massive data repositories; the\ndemocratization of ML has lead to a rise in the number of security teams using\nML to support offensive operations. The research presented here will explore\ntwo models that our team has used to solve a single offensive task, detecting a\nsandbox. Using process list data gathered with phishing emails, we will\ndemonstrate the use of Decision Trees and Artificial Neural Networks to\nsuccessfully classify sandboxes, thereby avoiding unsafe execution. This paper\naims to give unique insight into how a real offensive team is using machine\nlearning to support offensive operations.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 01:45:40 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Pearce", "Will", ""], ["Landers", "Nick", ""], ["Fulda", "Nancy", ""]]}, {"id": "2007.06813", "submitter": "Guoxiong Su", "authors": "Guoxiong Su, Wenyuan Yang, Zhengding Luo, Yinghong Zhang, Zhiqiang\n  Bai, Yuesheng Zhu", "title": "BDTF: A Blockchain-Based Data Trading Framework with Trusted Execution\n  Environment", "comments": "6 pages, 5figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for data trading promotes the emergence of data market. However, in\nconventional data markets, both data buyers and data sellers have to use a\ncentralized trading platform which might be dishonest. A dishonest centralized\ntrading platform may steal and resell the data seller's data, or may refuse to\nsend data after receiving payment from the data buyer. It seriously affects the\nfair data transaction and harm the interests of both parties to the\ntransaction. To address this issue, we propose a novel blockchain-based data\ntrading framework with Trusted Execution Environment (TEE) to provide a trusted\ndecentralized platform for fair data trading. In our design, a blockchain\nnetwork is proposed to realize the payments from data buyers to data sellers,\nand a trusted exchange is built by using a TEE for the first time to achieve\nfair data transmission. With these help, data buyers and data sellers can\nconduct transactions directly. We implement our proposed framework on Ethereum\nand Intel SGX, security analysis and experimental results have demonstrated\nthat the framework proposed can effectively guarantee the fair completion of\ndata tradings.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 04:46:54 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Su", "Guoxiong", ""], ["Yang", "Wenyuan", ""], ["Luo", "Zhengding", ""], ["Zhang", "Yinghong", ""], ["Bai", "Zhiqiang", ""], ["Zhu", "Yuesheng", ""]]}, {"id": "2007.06818", "submitter": "Waqas Aman", "authors": "Waqas Aman, M. Mahboob Ur Rahman, Hassan T. Abbas, Muhammad Arslan\n  Khalid, Muhammad A. Imran, Akram Alomainy, Qammer H. Abbasi", "title": "Securing the Insecure: A First-Line-of-Defense for Nanoscale\n  Communication Systems Operating in THz Band", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nanoscale communication systems operating in Ter-ahertz (THz) band are\nanticipated to revolutionise the healthcaresystems of the future. Global\nwireless data traffic is undergoinga rapid growth. However, wireless systems,\ndue to their broad-casting nature, are vulnerable to malicious security\nbreaches. Inaddition, advances in quantum computing poses a risk to\nexistingcrypto-based information security. It is of the utmost importanceto\nmake the THz systems resilient to potential active and passiveattacks which may\nlead to devastating consequences, especiallywhen handling sensitive patient\ndata in healthcare systems. Newstrategies are needed to analyse these malicious\nattacks and topropose viable countermeasures. In this manuscript, we presenta\nnew authentication mechanism for nanoscale communicationsystems operating in\nTHz band at the physical layer. We assessedan impersonation attack on a THz\nsystem. We propose usingpath loss as a fingerprint to conduct authentication\nvia two-stephypothesis testing for a transmission device. We used hiddenMarkov\nModel (HMM) viterbi algorithm to enhance the outputof hypothesis testing. We\nalso conducted transmitter identificationusing maximum likelihood and Gaussian\nmixture model (GMM)expectation maximization algorithms. Our simulations\nshowedthat the error probabilities are a decreasing functions of SNR. At 10 dB\nwith 0.2 false alarm, the detection probability was almostone. We further\nobserved that HMM out-performs hypothesistesting at low SNR regime (10%\nincrease in accuracy is recordedat SNR =5 dB) whereas the GMM is useful when\ngroundtruths are noisy. Our work addresses major security gaps facedby\ncommunication system either through malicious breachesor quantum computing,\nenabling new applications of nanoscalesystems for Industry 4.0.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 05:01:41 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Aman", "Waqas", ""], ["Rahman", "M. Mahboob Ur", ""], ["Abbas", "Hassan T.", ""], ["Khalid", "Muhammad Arslan", ""], ["Imran", "Muhammad A.", ""], ["Alomainy", "Akram", ""], ["Abbasi", "Qammer H.", ""]]}, {"id": "2007.06855", "submitter": "Song Bian", "authors": "Song Bian, Xiaowei Xu, Weiwen Jiang, Yiyu Shi, Takashi Sato", "title": "BUNET: Blind Medical Image Segmentation Based on Secure UNET", "comments": "11 pages, 2 figures, in Proceedings of International Conference on\n  Medical Image Computing and Computer Assisted Intervention (MICCAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The strict security requirements placed on medical records by various privacy\nregulations become major obstacles in the age of big data. To ensure efficient\nmachine learning as a service schemes while protecting data confidentiality, in\nthis work, we propose blind UNET (BUNET), a secure protocol that implements\nprivacy-preserving medical image segmentation based on the UNET architecture.\nIn BUNET, we efficiently utilize cryptographic primitives such as homomorphic\nencryption and garbled circuits (GC) to design a complete secure protocol for\nthe UNET neural architecture. In addition, we perform extensive architectural\nsearch in reducing the computational bottleneck of GC-based secure activation\nprotocols with high-dimensional input data. In the experiment, we thoroughly\nexamine the parameter space of our protocol, and show that we can achieve up to\n14x inference time reduction compared to the-state-of-the-art secure inference\ntechnique on a baseline architecture with negligible accuracy degradation.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 07:05:23 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Bian", "Song", ""], ["Xu", "Xiaowei", ""], ["Jiang", "Weiwen", ""], ["Shi", "Yiyu", ""], ["Sato", "Takashi", ""]]}, {"id": "2007.06865", "submitter": "Hamed Nemati", "authors": "Hamed Nemati, Roberto Guanciale, Pablo Buiras, Andreas Lindner", "title": "Speculative Leakage in ARM Cortex-A53", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent Spectre attacks have demonstrated that modern microarchitectural\noptimizations can make software insecure. These attacks use features like\npipelining, out-of-order and speculation to extract information about the\nmemory contents of a process via side-channels. In this paper we demonstrate\nthat Cortex-A53 is affected by speculative leakage even if the\nmicroarchitecture does not support out-of-order execution. We named this new\nclass of vulnerabilities SiSCloak.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 07:19:59 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 09:15:29 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Nemati", "Hamed", ""], ["Guanciale", "Roberto", ""], ["Buiras", "Pablo", ""], ["Lindner", "Andreas", ""]]}, {"id": "2007.06881", "submitter": "Dung Hoang Duong", "authors": "Huy Quoc Le, Dung Hoang Duong, Willy Susilo, Josef Pieprzyk", "title": "Trapdoor Delegation and HIBE from Middle-Product LWE in Standard Model", "comments": "ACNS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At CRYPTO 2017, Rosca, Sakzad, Stehle and Steinfeld introduced the\nMiddle--Product LWE (MPLWE) assumption which is as secure as Polynomial-LWE for\na large class of polynomials, making the corresponding cryptographic schemes\nmore flexible in choosing the underlying polynomial ring in design while still\nkeeping the equivalent efficiency. Recently at TCC 2019, Lombardi,\nVaikuntanathan and Vuong introduced a variant of MPLWE assumption and\nconstructed the first IBE scheme based on MPLWE. Their core technique is to\nconstruct lattice trapdoors compatible with MPLWE in the same paradigm of\nGentry, Peikert and Vaikuntanathan at STOC 2008. However, their method cannot\ndirectly offer a Hierachical IBE construction. In this paper, we make a step\nfurther by proposing a novel trapdoor delegation mechanism for an extended\nfamily of polynomials from which we construct, for the first time, a\nHierachical IBE scheme from MPLWE. Our Hierachy IBE scheme is provably secure\nin the standard model.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 07:46:25 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Le", "Huy Quoc", ""], ["Duong", "Dung Hoang", ""], ["Susilo", "Willy", ""], ["Pieprzyk", "Josef", ""]]}, {"id": "2007.06884", "submitter": "Dung Hoang Duong", "authors": "Huy Quoc Le, Dung Hoang Duong, Willy Susilo, Ha Thanh Nguyen Tran,\n  Viet Cuong Trinh, Josef Pieprzyk, Thomas Plantard", "title": "Lattice Blind Signatures with Forward Security", "comments": "ACISP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blind signatures play an important role in both electronic cash and\nelectronic voting systems. Blind signatures should be secure against various\nattacks (such as signature forgeries). The work puts a special attention to\nsecret key exposure attacks, which totally break digital signatures. Signatures\nthat resist secret key exposure attacks are called forward secure in the sense\nthat disclosure of a current secret key does not compromise past secret keys.\nThis means that forward-secure signatures must include a mechanism for\nsecret-key evolution over time periods.\n  This paper gives a construction of the first blind signature that is forward\nsecure. The construction is based on the SIS assumption in the lattice setting.\nThe core techniques applied are the binary tree data structure for the time\nperiods and the trapdoor delegation for the key-evolution mechanism.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 07:52:08 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Le", "Huy Quoc", ""], ["Duong", "Dung Hoang", ""], ["Susilo", "Willy", ""], ["Tran", "Ha Thanh Nguyen", ""], ["Trinh", "Viet Cuong", ""], ["Pieprzyk", "Josef", ""], ["Plantard", "Thomas", ""]]}, {"id": "2007.06953", "submitter": "Yanjun Zhang", "authors": "Yanjun Zhang, Guangdong Bai, Xue Li, Caitlin Curtis, Chen Chen, Ryan K\n  L Ko", "title": "PrivColl: Practical Privacy-Preserving Collaborative Machine Learning", "comments": "20 pages, 3 figures, to be published in 25th European Symposium on\n  Research in Computer Security (ESORICS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative learning enables two or more participants, each with their own\ntraining dataset, to collaboratively learn a joint model. It is desirable that\nthe collaboration should not cause the disclosure of either the raw datasets of\neach individual owner or the local model parameters trained on them. This\nprivacy-preservation requirement has been approached through differential\nprivacy mechanisms, homomorphic encryption (HE) and secure multiparty\ncomputation (MPC), but existing attempts may either introduce the loss of model\naccuracy or imply significant computational and/or communicational overhead. In\nthis work, we address this problem with the lightweight additive secret sharing\ntechnique. We propose PrivColl, a framework for protecting local data and local\nmodels while ensuring the correctness of training processes. PrivColl employs\nsecret sharing technique for securely evaluating addition operations in a\nmultiparty computation environment, and achieves practicability by employing\nonly the homomorphic addition operations. We formally prove that it guarantees\nprivacy preservation even though the majority (n-2 out of n) of participants\nare corrupted. With experiments on real-world datasets, we further demonstrate\nthat PrivColl retains high efficiency. It achieves a speedup of more than 45X\nover the state-of-the-art MPC/HE based schemes for training linear/logistic\nregression, and 216X faster for training neural network.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 10:30:04 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Zhang", "Yanjun", ""], ["Bai", "Guangdong", ""], ["Li", "Xue", ""], ["Curtis", "Caitlin", ""], ["Chen", "Chen", ""], ["Ko", "Ryan K L", ""]]}, {"id": "2007.06985", "submitter": "Mathieu Garchery", "authors": "Mathieu Garchery and Michael Granitzer", "title": "ADSAGE: Anomaly Detection in Sequences of Attributed Graph Edges applied\n  to insider threat detection at fine-grained level", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous works on the CERT insider threat detection case have neglected graph\nand text features despite their relevance to describe user behavior.\nAdditionally, existing systems heavily rely on feature engineering and audit\ndata aggregation to detect malicious activities. This is time consuming,\nrequires expert knowledge and prevents tracing back alerts to precise user\nactions. To address these issues we introduce ADSAGE to detect anomalies in\naudit log events modeled as graph edges. Our general method is the first to\nperform anomaly detection at edge level while supporting both edge sequences\nand attributes, which can be numeric, categorical or even text. We describe how\nADSAGE can be used for fine-grained, event level insider threat detection in\ndifferent audit logs from the CERT use case. Remarking that there is no\nstandard benchmark for the CERT problem, we use a previously proposed\nevaluation setting based on realistic recall-based metrics. We evaluate ADSAGE\non authentication, email traffic and web browsing logs from the CERT insider\nthreat datasets, as well as on real-world authentication events. ADSAGE is\neffective to detect anomalies in authentications, modeled as user to computer\ninteractions, and in email communications. Simple baselines give surprisingly\nstrong results as well. We also report performance split by malicious scenarios\npresent in the CERT datasets: interestingly, several detectors are\ncomplementary and could be combined to improve detection. Overall, our results\nshow that graph features are informative to characterize malicious insider\nactivities, and that detection at fine-grained level is possible.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 12:05:05 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Garchery", "Mathieu", ""], ["Granitzer", "Michael", ""]]}, {"id": "2007.06993", "submitter": "Kathrin Grosse", "authors": "Nico D\\\"ottling, Kathrin Grosse, Michael Backes, Ian Molloy", "title": "Adversarial Examples and Metrics", "comments": "25 pages, 1 figure, under submission, fixe typos from previous\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are a type of attack on machine learning (ML) systems\nwhich cause misclassification of inputs. Achieving robustness against\nadversarial examples is crucial to apply ML in the real world. While most prior\nwork on adversarial examples is empirical, a recent line of work establishes\nfundamental limitations of robust classification based on cryptographic\nhardness. Most positive and negative results in this field however assume that\nthere is a fixed target metric which constrains the adversary, and we argue\nthat this is often an unrealistic assumption. In this work we study the\nlimitations of robust classification if the target metric is uncertain.\nConcretely, we construct a classification problem, which admits robust\nclassification by a small classifier if the target metric is known at the time\nthe model is trained, but for which robust classification is impossible for\nsmall classifiers if the target metric is chosen after the fact. In the\nprocess, we explore a novel connection between hardness of robust\nclassification and bounded storage model cryptography.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 12:20:53 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 11:50:21 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["D\u00f6ttling", "Nico", ""], ["Grosse", "Kathrin", ""], ["Backes", "Michael", ""], ["Molloy", "Ian", ""]]}, {"id": "2007.07001", "submitter": "Yigit Alparslan", "authors": "Ken Alparslan, Yigit Alparslan, Matthew Burlick", "title": "Adversarial Attacks against Neural Networks in Audio Domain: Exploiting\n  Principal Components", "comments": "8 pages, 14 figures, fixed typos, enumerated equations, fixed\n  equation (4) latex error, clarified author contributions via footnote", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Adversarial attacks are inputs that are similar to original inputs but\naltered on purpose. Speech-to-text neural networks that are widely used today\nare prone to misclassify adversarial attacks. In this study, first, we\ninvestigate the presence of targeted adversarial attacks by altering wave forms\nfrom Common Voice data set. We craft adversarial wave forms via Connectionist\nTemporal Classification Loss Function, and attack DeepSpeech, a speech-to-text\nneural network implemented by Mozilla. We achieve 100% adversarial success rate\n(zero successful classification by DeepSpeech) on all 25 adversarial wave forms\nthat we crafted. Second, we investigate the use of PCA as a defense mechanism\nagainst adversarial attacks. We reduce dimensionality by applying PCA to these\n25 attacks that we created and test them against DeepSpeech. We observe zero\nsuccessful classification by DeepSpeech, which suggests PCA is not a good\ndefense mechanism in audio domain. Finally, instead of using PCA as a defense\nmechanism, we use PCA this time to craft adversarial inputs under a black-box\nsetting with minimal adversarial knowledge. With no knowledge regarding the\nmodel, parameters, or weights, we craft adversarial attacks by applying PCA to\nsamples from Common Voice data set and achieve 100% adversarial success under\nblack-box setting again when tested against DeepSpeech. We also experiment with\ndifferent percentage of components necessary to result in a classification\nduring attacking process. In all cases, adversary becomes successful.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 12:35:03 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 21:43:06 GMT"}, {"version": "v3", "created": "Wed, 13 Jan 2021 16:28:22 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Alparslan", "Ken", ""], ["Alparslan", "Yigit", ""], ["Burlick", "Matthew", ""]]}, {"id": "2007.07016", "submitter": "Andrew Buzzell", "authors": "Andrew Buzzell", "title": "Public Goods From Private Data -- An Efficacy and Justification Paradox\n  for Digital Contact Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Debate about the adoption of digital contact tracing (DCT) apps to control\nthe spread of COVID-19 has focussed on risks to individual privacy (Sharma &\nBashir 2020, Tang 2020). This emphasis reveals significant challenges to\nethical deployment of DCT, but generates constraints which undermine\njustification to implement DCT. It would be a mistake to view this result\nsolely as the successful operation of ethical foresight analysis (Floridi &\nStrait 2020), preventing deployment of potentially harmful technology.\nPrivacy-centric analysis treats data as private property, frames the\nrelationship between individuals and governments as adversarial, entrenches\ntechnology platforms as gatekeepers, and supports a conception of emergency\npublic health authority as limited by individual consent and considerable\ncorporate influence that is in some tension with the more communitarian values\nthat typically inform public health ethics. To overcome the barriers to ethical\nand effective DCT, and develop infrastructure and policy that supports the\nrealization of potential public benefits of digital technology, a public\nresource conception of aggregate data should be developed.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 13:08:29 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Buzzell", "Andrew", ""]]}, {"id": "2007.07046", "submitter": "Manuel Kalmbach", "authors": "Manuel Kalmbach, Mathias Gottschlag, Tim Schmidt, Frank Bellosa", "title": "TurboCC: A Practical Frequency-Based Covert Channel With Intel Turbo\n  Boost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covert channels are communication channels used by attackers to transmit\ninformation from a compromised system when the access control policy of the\nsystem does not allow doing so. Previous work has shown that CPU frequency\nscaling can be used as a covert channel to transmit information between\notherwise isolated processes. Modern systems either try to save power or try to\noperate near their power limits in order to maximize performance, so they\nimplement mechanisms to vary the frequency based on load. Existing covert\nchannels based on this approach are either easily thwarted by software\ncountermeasures or only work on completely idle systems. In this paper, we show\nhow the automatic frequency scaling provided by Intel Turbo Boost can be used\nto construct a covert channel that is both hard to prevent without significant\nperformance impact and can tolerate significant background system load. As\nIntel Turbo Boost selects the maximum CPU frequency based on the number of\nactive cores, our covert channel modulates information onto the maximum CPU\nfrequency by placing load on multiple additional CPU cores. Our prototype of\nthe covert channel achieves a throughput of up to 61 bit/s on an idle system\nand up to 43 bit/s on a system with 25% utilization.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 14:13:35 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Kalmbach", "Manuel", ""], ["Gottschlag", "Mathias", ""], ["Schmidt", "Tim", ""], ["Bellosa", "Frank", ""]]}, {"id": "2007.07048", "submitter": "Martin Harrigan", "authors": "Liam Hickey and Martin Harrigan", "title": "The Bisq DAO: On the Privacy Cost of Participation", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bisq DAO is a core component of Bisq, a decentralized cryptocurrency\nexchange. The purpose of the Bisq DAO is to decentralize the governance and\nfinance functions of the exchange. However, by interacting with the Bisq DAO,\nparticipants necessarily publish data to the Bitcoin blockchain and broadcast\nadditional data to the Bisq peer-to-peer network. We examine the privacy cost\nto participants in sharing this data. Specifically, we use a novel address\nclustering heuristic to construct the one-to-many mappings from participants to\naddresses on the Bitcoin blockchain and augment the address clusters with data\nstored within the Bisq peer-to-peer network. We show that this technique\naggregates activity performed by each participant: trading, voting, transfers,\netc. We identify instances where participants are operating under multiple\naliases, some of which are real-world names. We identify the dominant\ntransactors and their role in a two-sided market. We conclude with suggestions\nto better protect the privacy of participants in the future.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 14:14:50 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Hickey", "Liam", ""], ["Harrigan", "Martin", ""]]}, {"id": "2007.07155", "submitter": "Mohammad Shojaeshafiei", "authors": "Mohammad Shojaeshafiei, Letha Etzkorn, and Michael Anderson", "title": "multiple layers of fuzzy logic to quantify vulnerabilies in iot", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying vulnerabilities of network systems has been a highly\ncontroversial issue in the fields of network security and IoT. Much research\nhas been conducted on this purpose; however, these have many ambiguities and\nuncertainties. In this paper, we investigate the quantification of\nvulnerability in the Department of Transportation (DOT) as our proof of\nconcept. We initiate the analysis of security requirements, using Security\nQuality Requirements Engineering (SQUARE) for security requirements\nelicitation. Then we apply published security standards such as NIST SP-800 and\nISO 27001 to map our security factors and sub-factors. Finally, we propose our\nMulti-layered Fuzzy Logic (MFL) approach based on Goal question Metrics (GQM)\nto quantify network security and IoT (Mobile Devices) vulnerability in DOT.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 16:14:51 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Shojaeshafiei", "Mohammad", ""], ["Etzkorn", "Letha", ""], ["Anderson", "Michael", ""]]}, {"id": "2007.07205", "submitter": "Ivan Evtimov", "authors": "Ivan Evtimov, Weidong Cui, Ece Kamar, Emre Kiciman, Tadayoshi Kohno,\n  Jerry Li", "title": "Security and Machine Learning in the Real World", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) models deployed in many safety- and business-critical\nsystems are vulnerable to exploitation through adversarial examples. A large\nbody of academic research has thoroughly explored the causes of these blind\nspots, developed sophisticated algorithms for finding them, and proposed a few\npromising defenses. A vast majority of these works, however, study standalone\nneural network models. In this work, we build on our experience evaluating the\nsecurity of a machine learning software product deployed on a large scale to\nbroaden the conversation to include a systems security view of these\nvulnerabilities. We describe novel challenges to implementing systems security\nbest practices in software with ML components. In addition, we propose a list\nof short-term mitigation suggestions that practitioners deploying machine\nlearning modules can use to secure their systems. Finally, we outline\ndirections for new research into machine learning attacks and defenses that can\nserve to advance the state of ML systems security.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 16:57:12 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Evtimov", "Ivan", ""], ["Cui", "Weidong", ""], ["Kamar", "Ece", ""], ["Kiciman", "Emre", ""], ["Kohno", "Tadayoshi", ""], ["Li", "Jerry", ""]]}, {"id": "2007.07236", "submitter": "Chengzhi Mao", "authors": "Chengzhi Mao, Amogh Gupta, Vikram Nitin, Baishakhi Ray, Shuran Song,\n  Junfeng Yang, and Carl Vondrick", "title": "Multitask Learning Strengthens Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep networks achieve strong accuracy on a range of computer vision\nbenchmarks, they remain vulnerable to adversarial attacks, where imperceptible\ninput perturbations fool the network. We present both theoretical and empirical\nanalyses that connect the adversarial robustness of a model to the number of\ntasks that it is trained on. Experiments on two datasets show that attack\ndifficulty increases as the number of target tasks increase. Moreover, our\nresults suggest that when models are trained on multiple tasks at once, they\nbecome more robust to adversarial attacks on individual tasks. While\nadversarial defense remains an open challenge, our results suggest that deep\nnetworks are vulnerable partly because they are trained on too few tasks.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 17:52:45 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 02:03:46 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Mao", "Chengzhi", ""], ["Gupta", "Amogh", ""], ["Nitin", "Vikram", ""], ["Ray", "Baishakhi", ""], ["Song", "Shuran", ""], ["Yang", "Junfeng", ""], ["Vondrick", "Carl", ""]]}, {"id": "2007.07428", "submitter": "Daniel Moghimi", "authors": "Daniel Moghimi", "title": "Data Sampling on MDS-resistant 10th Generation Intel Core (Ice Lake)", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microarchitectural Data Sampling (MDS) is a set of hardware vulnerabilities\nin Intel CPUs that allows an attacker to leak bytes of data from memory loads\nand stores across various security boundaries. On affected CPUs, some of these\nvulnerabilities were patched via microcode updates. Additionally, Intel\nannounced that the newest microarchitectures, namely Cascade Lake and Ice Lake,\nwere not affected by MDS. While Cascade Lake turned out to be vulnerable to the\nZombieLoad v2 MDS attack (also known as TAA), Ice Lake was not affected by this\nattack.\n  In this technical report, we show a variant of MSBDS (CVE2018-12126), an MDS\nattack, also known as Fallout, that works on Ice Lake CPUs. This variant was\nautomatically synthesized using Transynther, a tool to find new variants of\nMeltdown-type attacks. Based on the findings of Transynther, we analyze\ndifferent microcodes regarding this issue, showing that only microcode versions\nafter January 2020 prevent exploitation of the vulnerability. These results\nshow that Transynther is a valuable tool to find new variants, and also to test\nfor regressions possibly introduced with microcode updates.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 01:48:03 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Moghimi", "Daniel", ""]]}, {"id": "2007.07435", "submitter": "Hadi Mohaghegh Dolatabadi", "authors": "Hadi M. Dolatabadi, Sarah Erfani, Christopher Leckie", "title": "AdvFlow: Inconspicuous Black-box Adversarial Attacks using Normalizing\n  Flows", "comments": "Accepted to the 34th Conference on Neural Information Processing\n  Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning classifiers are susceptible to well-crafted, imperceptible\nvariations of their inputs, known as adversarial attacks. In this regard, the\nstudy of powerful attack models sheds light on the sources of vulnerability in\nthese classifiers, hopefully leading to more robust ones. In this paper, we\nintroduce AdvFlow: a novel black-box adversarial attack method on image\nclassifiers that exploits the power of normalizing flows to model the density\nof adversarial examples around a given target image. We see that the proposed\nmethod generates adversaries that closely follow the clean data distribution, a\nproperty which makes their detection less likely. Also, our experimental\nresults show competitive performance of the proposed approach with some of the\nexisting attack methods on defended classifiers. The code is available at\nhttps://github.com/hmdolatabadi/AdvFlow.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 02:13:49 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 00:36:25 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Dolatabadi", "Hadi M.", ""], ["Erfani", "Sarah", ""], ["Leckie", "Christopher", ""]]}, {"id": "2007.07499", "submitter": "Sid Chi-Kin Chau", "authors": "Lingjuan Lyu, Sid Chi-Kin Chau, Nan Wang and Yifeng Zheng", "title": "Cloud-based Privacy-Preserving Collaborative Consumption for Sharing\n  Economy", "comments": "To appear in IEEE Trans. Cloud Computing", "journal-ref": null, "doi": "10.1109/TCC.2020.3010235", "report-no": null, "categories": "cs.CR cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing has been a dominant paradigm for a variety of information\nprocessing platforms, particularly for enabling various popular applications of\nsharing economy. However, there is a major concern regarding data privacy on\nthese cloud-based platforms. This work presents novel cloud-based\nprivacy-preserving solutions to support collaborative consumption applications\nfor sharing economy. In typical collaborative consumption, information\nprocessing platforms need to enable fair cost-sharing among multiple users for\nutilizing certain shared facilities and communal services. Our cloud-based\nprivacy-preserving protocols, based on homomorphic Paillier cryptosystems, can\nensure that the cloud-based operator can only obtain an aggregate schedule of\nall users in facility sharing, or a service schedule conforming to service\nprovision rule in communal service sharing, but is unable to track the personal\nschedules or demands of individual users. More importantly, the participating\nusers are still able to settle cost-sharing among themselves in a fair manner\nfor the incurred costs, without knowing each other's private schedules or\ndemands. Our privacy-preserving protocols involve no other third party who may\ncompromise privacy. We also provide an extensive evaluation study and a\nproof-of-concept system prototype of our protocols.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 06:06:07 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Lyu", "Lingjuan", ""], ["Chau", "Sid Chi-Kin", ""], ["Wang", "Nan", ""], ["Zheng", "Yifeng", ""]]}, {"id": "2007.07501", "submitter": "Nikolay Prudkovskiy", "authors": "Nikolay Prudkovskiy", "title": "Static analysis of executable files by machine learning methods", "comments": "36 pages, 13 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes how to detect malicious executable files based on static\nanalysis of their binary content. The stages of pre-processing and cleaning\ndata extracted from different areas of executable files are analyzed. Methods\nof encoding categorical attributes of executable files are considered, as are\nways to reduce the feature field dimension and select characteristic features\nin order to effectively represent samples of binary executable files for\nfurther training classifiers. An ensemble training approach was applied in\norder to aggregate forecasts from each classifier, and an ensemble of\nclassifiers of various feature groups of executable file attributes was created\nin order to subsequently develop a system for detecting malicious files in an\nuninsulated environment.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 06:15:15 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Prudkovskiy", "Nikolay", ""]]}, {"id": "2007.07528", "submitter": "James Chiang", "authors": "James Chiang", "title": "Bitcoin Trace-Net: Formal Contract Verification at Signing Time", "comments": "Currently under submission. Earlier version presented at MIT\n  Cryptoeconomic Systems Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart contracting protocols promise to regulate the transfer of\ncryptocurrency amongst participants in a trustless manner. A safe smart\ncontract implementation should ensure that each participant can always append a\ncontract transaction to the blockchain in order move the contract towards\nsecure completion. To this goal, we propose Bitcoin Trace-Net, a contract\nverification framework which generates an executable symbolic model from the\nunderlying contract implementation. A Trace-Net model consists of a Petri Net\nformalism enriched with a Dolev-Yao-like actor knowledge model. The explicit\nsymbolic actor knowledge model supports the verification of contracts featuring\ncryptographic sub-protocols, which may not be observable on the blockchain.\nTrace-Net is sufficiently expressive to accurately model blockchain semantics\nsuch as the delay between a transaction broadcast and its subsequent\nconfirmation, as well as adversarial blockchain reorganizations of finite\ndepths, both of which can break smart contract safety. As an implementation\nlevel framework, Trace-Net can be instantiated at run-time to monitor and\nverify smart contract protocol executions.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 08:04:14 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Chiang", "James", ""]]}, {"id": "2007.07586", "submitter": "Michael Rodler", "authors": "Tobias Cloosters, Michael Rodler, Lucas Davi", "title": "TeeRex: Discovery and Exploitation of Memory Corruption Vulnerabilities\n  in SGX Enclaves", "comments": "To be published at the 29th USENIX Security Symposium 2020\n  (https://www.usenix.org/conference/usenixsecurity20/presentation/cloosters)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intel's Software Guard Extensions (SGX) introduced new instructions to switch\nthe processor to enclave mode which protects it from introspection. While the\nenclave mode strongly protects the memory and the state of the processor, it\ncannot withstand memory corruption errors inside the enclave code. In this\npaper, we show that the attack surface of SGX enclaves provides new challenges\nfor enclave developers as exploitable memory corruption vulnerabilities are\neasily introduced into enclave code. We develop TeeRex to automatically analyze\nenclave binary code for vulnerabilities introduced at the host-to-enclave\nboundary by means of symbolic execution. Our evaluation on public enclave\nbinaries reveal that many of them suffer from memory corruption errors allowing\nan attacker to corrupt function pointers or perform arbitrary memory writes. As\nwe will show, TeeRex features a specifically tailored framework for SGX\nenclaves that allows simple proof-of-concept exploit construction to assess the\ndiscovered vulnerabilities. Our findings reveal vulnerabilities in multiple\nenclaves, including enclaves developed by Intel, Baidu, and WolfSSL, as well as\nbiometric fingerprint software deployed on popular laptop brands.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 10:06:40 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 08:29:53 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Cloosters", "Tobias", ""], ["Rodler", "Michael", ""], ["Davi", "Lucas", ""]]}, {"id": "2007.07646", "submitter": "Maria Rigaki", "authors": "Maria Rigaki and Sebastian Garcia", "title": "A Survey of Privacy Attacks in Machine Learning", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning becomes more widely used, the need to study its\nimplications in security and privacy becomes more urgent. Although the body of\nwork in privacy has been steadily growing over the past few years, research on\nthe privacy aspects of machine learning has received less focus than the\nsecurity aspects. Our contribution in this research is an analysis of more than\n40 papers related to privacy attacks against machine learning that have been\npublished during the past seven years. We propose an attack taxonomy, together\nwith a threat model that allows the categorization of different attacks based\non the adversarial knowledge, and the assets under attack. An initial\nexploration of the causes of privacy leaks is presented, as well as a detailed\nanalysis of the different attacks. Finally, we present an overview of the most\ncommonly proposed defenses and a discussion of the open problems and future\ndirections identified during our analysis.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 12:09:53 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 10:37:25 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Rigaki", "Maria", ""], ["Garcia", "Sebastian", ""]]}, {"id": "2007.07753", "submitter": "Peter Hillmann", "authors": "Sandro Passarelli, Cem G\\\"undogan, Lars Stiemert, Matthias Schopp,\n  Peter Hillmann", "title": "NERD: Neural Network for Edict of Risky Data Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.DC cs.IR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber incidents can have a wide range of cause from a simple connection loss\nto an insistent attack. Once a potential cyber security incidents and system\nfailures have been identified, deciding how to proceed is often complex.\nEspecially, if the real cause is not directly in detail determinable.\nTherefore, we developed the concept of a Cyber Incident Handling Support\nSystem. The developed system is enriched with information by multiple sources\nsuch as intrusion detection systems and monitoring tools. It uses over twenty\nkey attributes like sync-package ratio to identify potential security incidents\nand to classify the data into different priority categories. Afterwards, the\nsystem uses artificial intelligence to support the further decision-making\nprocess and to generate corresponding reports to brief the Board of Directors.\nOriginating from this information, appropriate and detailed suggestions are\nmade regarding the causes and troubleshooting measures. Feedback from users\nregarding the problem solutions are included into future decision-making by\nusing labelled flow data as input for the learning process. The prototype shows\nthat the decision making can be sustainably improved and the Cyber Incident\nHandling process becomes much more effective.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 14:24:48 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Passarelli", "Sandro", ""], ["G\u00fcndogan", "Cem", ""], ["Stiemert", "Lars", ""], ["Schopp", "Matthias", ""], ["Hillmann", "Peter", ""]]}, {"id": "2007.07772", "submitter": "Jesse Goodman", "authors": "Eshan Chattopadhyay, Jesse Goodman", "title": "Explicit Designs and Extractors", "comments": "32 pages; additional main theorem (small-space extractors for\n  polylogarithmic entropy); other additional smaller results; improved\n  presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give significantly improved explicit constructions of three related\npseudorandom objects.\n  1. Extremal designs: An $(n,r,s)$-design, or $(n,r,s)$-partial Steiner\nsystem, is an $r$-uniform hypergraph over $n$ vertices with pairwise hyperedge\nintersections of size $<s$. For all constants $r\\geq s\\in\\mathbb{N}$ with $r$\neven, we explicitly construct $(n,r,s)$-designs $(G_n)_{n\\in\\mathbb{N}}$ with\nindependence number $\\alpha(G_n)\\leq O(n^{\\frac{2(r-s)}{r}})$. This gives the\nfirst derandomization of a result by R\\\"odl and \\v{S}inajov\\'a (Random\nStructures & Algorithms, 1994).\n  2. Extractors for adversarial sources: By combining our designs with\nleakage-resilient extractors (Chattopadhyay et al., FOCS 2020), we establish a\nnew, simple framework for extracting from adversarial sources of locality $0$.\nAs a result, we obtain significantly improved low-error extractors for these\nsources. For any constant $\\delta>0$, we extract from $(N,K,n,$\npolylog$(n))$-adversarial sources of locality $0$, given just $K\\geq N^\\delta$\ngood sources. The previous best result (Chattopadhyay et al., STOC 2020)\nrequired $K\\geq N^{1/2+o(1)}$.\n  3. Extractors for small-space sources: Using a known reduction to adversarial\nsources, we immediately obtain improved low-error extractors for space $s$\nsources over $n$ bits that require entropy $k\\geq n^{1/2+\\delta}\\cdot\ns^{1/2-\\delta}$, whereas the previous best result (Chattopadhyay et al., STOC\n2020) required $k\\geq n^{2/3+\\delta}\\cdot s^{1/3-\\delta}$. On the other hand,\nusing a new reduction from small-space sources to affine sources, we obtain\nnear-optimal extractors for small-space sources in the polynomial error regime.\nOur extractors require just $k\\geq s\\cdot\\log^Cn$ entropy for some constant\n$C$, which is an exponential improvement over the previous best result, which\nrequired $k\\geq s^{1.1}\\cdot2^{\\log^{0.51}n}$ (Chattopadhyay and Li, STOC\n2016).\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 15:45:27 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 23:58:10 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Chattopadhyay", "Eshan", ""], ["Goodman", "Jesse", ""]]}, {"id": "2007.08041", "submitter": "Minh Pham", "authors": "Minh Pham, Kaiqi Xiong", "title": "A Survey on Security Attacks and Defense Techniques for Connected and\n  Autonomous Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous Vehicle has been transforming intelligent transportation systems.\nAs telecommunication technology improves, autonomous vehicles are getting\nconnected to each other and to infrastructures, forming Connected and\nAutonomous Vehicles (CAVs). CAVs will help humans achieve safe, efficient, and\nautonomous transportation systems. However, CAVs will face significant security\nchallenges because many of their components are vulnerable to attacks, and a\nsuccessful attack on a CAV may have significant impacts on other CAVs and\ninfrastructures due to their communications. In this paper, we conduct a survey\non 184 papers from 2000 to 2020 to understand state-of-the-art CAV attacks and\ndefense techniques. This survey first presents a comprehensive overview of\nsecurity attacks and their corresponding countermeasures on CAVs. We then\ndiscuss the details of attack models based on the targeted CAV components of\nattacks, access requirements, and attack motives. Finally, we identify some\ncurrent research challenges and trends from the perspectives of both academic\nresearch and industrial development. Based on our studies of academic\nliterature and industrial publications, we have not found any strong connection\nbetween academic research and industry's implementation on CAV-related security\nissues. While efforts from CAV manufacturers to secure CAVs have been reported,\nthere is no evidence to show that CAVs on the market have the ability to defend\nagainst some novel attack models that the research community has recently\nfound. This survey may give researchers and engineers a better understanding of\nthe current status and trend of CAV security for CAV future improvement.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 00:11:08 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Pham", "Minh", ""], ["Xiong", "Kaiqi", ""]]}, {"id": "2007.08110", "submitter": "Yue Gao", "authors": "Yue Gao, Or Sheffet", "title": "Private Approximations of a Convex Hull in Low Dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the first differentially private algorithms that estimate a variety\nof geometric features of points in the Euclidean space, such as diameter,\nwidth, volume of convex hull, min-bounding box, min-enclosing ball etc. Our\nwork relies heavily on the notion of \\emph{Tukey-depth}. Instead of\n(non-privately) approximating the convex-hull of the given set of points $P$,\nour algorithms approximate the geometric features of the $\\kappa$-Tukey region\ninduced by $P$ (all points of Tukey-depth $\\kappa$ or greater). Moreover, our\napproximations are all bi-criteria: for any geometric feature $\\mu$ our\n$(\\alpha,\\Delta)$-approximation is a value \"sandwiched\" between\n$(1-\\alpha)\\mu(D_P(\\kappa))$ and $(1+\\alpha)\\mu(D_P(\\kappa-\\Delta))$.\n  Our work is aimed at producing a \\emph{$(\\alpha,\\Delta)$-kernel of\n$D_P(\\kappa)$}, namely a set $\\mathcal{S}$ such that (after a shift) it holds\nthat $(1-\\alpha)D_P(\\kappa)\\subset \\mathsf{CH}(\\mathcal{S}) \\subset\n(1+\\alpha)D_P(\\kappa-\\Delta)$. We show that an analogous notion of a bi-critera\napproximation of a directional kernel, as originally proposed by Agarwal et\nal~[2004], \\emph{fails} to give a kernel, and so we result to subtler notions\nof approximations of projections that do yield a kernel. First, we give\ndifferentially private algorithms that find $(\\alpha,\\Delta)$-kernels for a\n\"fat\" Tukey-region. Then, based on a private approximation of the min-bounding\nbox, we find a transformation that does turn $D_P(\\kappa)$ into a \"fat\" region\n\\emph{but only if} its volume is proportional to the volume of\n$D_P(\\kappa-\\Delta)$. Lastly, we give a novel private algorithm that finds a\ndepth parameter $\\kappa$ for which the volume of $D_P(\\kappa)$ is comparable to\n$D_P(\\kappa-\\Delta)$. We hope this work leads to the further study of the\nintersection of differential privacy and computational geometry.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 04:49:50 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 22:13:59 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Gao", "Yue", ""], ["Sheffet", "Or", ""]]}, {"id": "2007.08121", "submitter": "Sunandan Adhikary", "authors": "Sunandan Adhikary, Ipsita Koley, Sumana Ghosh, Saurav Kumar Ghosh,\n  Soumyajit Dey, Debdeep Mukhopadhyay", "title": "Skip to Secure: Securing Cyber-physical Control Loops with Intentionally\n  Skipped Executions", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of provably securing a given control loop\nimplementation in the presence of adversarial interventions on data exchange\nbetween plant and controller. Such interventions can be thwarted using\ncontinuously operating monitoring systems and also cryptographic techniques,\nboth of which consume network and computational resources. We provide a\nprincipled approach for intentional skipping of control loop executions which\nmay qualify as a useful control theoretic countermeasure against stealthy\nattacks which violate message integrity and authenticity. As is evident from\nour experiments, such a control theoretic counter-measure helps in lowering the\ncryptographic security measure overhead and resulting resource consumption in\nControl Area Network (CAN) based automotive CPS without compromising\nperformance and safety.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 05:30:07 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Adhikary", "Sunandan", ""], ["Koley", "Ipsita", ""], ["Ghosh", "Sumana", ""], ["Ghosh", "Saurav Kumar", ""], ["Dey", "Soumyajit", ""], ["Mukhopadhyay", "Debdeep", ""]]}, {"id": "2007.08248", "submitter": "Louis Tajan", "authors": "Louis Tajan and Dirk Westhoff", "title": "Approach for GDPR Compliant Detection of COVID-19 Infection Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While prospect of tracking mobile devices' users is widely discussed all over\nEuropean countries to counteract COVID-19 propagation, we propose a Bloom\nfilter based construction providing users' location privacy and preventing mass\nsurveillance. We apply a solution based on Bloom filters data structure that\nallows a third party, a government agency, to perform some privacy-preserving\nset relations on a mobile telco's access logfile. By computing set relations,\nthe government agency, given the knowledge of two identified persons, has an\ninstrument that provides a (possible) infection chain from the initial to the\nfinal infected user no matter at which location on a worldwide scale they are.\nThe benefit of our approach is that intermediate possible infected users can be\nidentified and subsequently contacted by the agency. With such approach, we\nstate that solely identities of possible infected users will be revealed and\nlocation privacy of others will be preserved. To this extent, it meets General\nData Protection Regulation (GDPR)requirements in this area.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 10:47:43 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 08:08:30 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Tajan", "Louis", ""], ["Westhoff", "Dirk", ""]]}, {"id": "2007.08255", "submitter": "Martin Barrere", "authors": "Mart\\'in Barr\\`ere and Chris Hankin", "title": "MaxSAT Evaluation 2020 -- Benchmark: Identifying Maximum Probability\n  Minimal Cut Sets in Fault Trees", "comments": "5 pages, 1 figure. To appear in Proceedings of the MaxSAT Evaluation\n  2020 (MSE'20). https://maxsat-evaluations.github.io/2020/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DM cs.LO cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a MaxSAT benchmark focused on the identification of\nMaximum Probability Minimal Cut Sets (MPMCSs) in fault trees. We address the\nMPMCS problem by transforming the input fault tree into a weighted logical\nformula that is then used to build and solve a Weighted Partial MaxSAT problem.\nThe benchmark includes 80 cases with fault trees of different size and\ncomposition as well as the optimal cost and solution for each case.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 11:05:24 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Barr\u00e8re", "Mart\u00edn", ""], ["Hankin", "Chris", ""]]}, {"id": "2007.08273", "submitter": "Shaofeng Li", "authors": "Shaofeng Li, Shiqing Ma, Minhui Xue, Benjamin Zi Hao Zhao", "title": "Deep Learning Backdoors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intuitively, a backdoor attack against Deep Neural Networks (DNNs) is to\ninject hidden malicious behaviors into DNNs such that the backdoor model\nbehaves legitimately for benign inputs, yet invokes a predefined malicious\nbehavior when its input contains a malicious trigger. The trigger can take a\nplethora of forms, including a special object present in the image (e.g., a\nyellow pad), a shape filled with custom textures (e.g., logos with particular\ncolors) or even image-wide stylizations with special filters (e.g., images\naltered by Nashville or Gotham filters). These filters can be applied to the\noriginal image by replacing or perturbing a set of image pixels.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 11:54:20 GMT"}, {"version": "v2", "created": "Sat, 6 Feb 2021 09:02:57 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Li", "Shaofeng", ""], ["Ma", "Shiqing", ""], ["Xue", "Minhui", ""], ["Zhao", "Benjamin Zi Hao", ""]]}, {"id": "2007.08296", "submitter": "Fady Copty", "authors": "Fady Copty, Andre Kassis, Sharon Keidar-Barner, Dov Murik", "title": "Deep ahead-of-threat virtual patching", "comments": "IOSec 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications have security vulnerabilities that can be exploited. It is\npractically impossible to find all of them due to the NP-complete nature of the\ntesting problem. Security solutions provide defenses against these attacks\nthrough continuous application testing, fast-patching of vulnerabilities,\nautomatic deployment of patches, and virtual patching detection techniques\ndeployed in network and endpoint security tools. These techniques are limited\nby the need to find vulnerabilities before the black-hats. We propose an\ninnovative technique to virtually patch vulnerabilities before they are found.\nWe leverage testing techniques for supervised-learning data generation, and\nshow how artificial intelligence techniques can use this data to create\npredictive deep neural-network models that read an application's input and\npredict in real time whether it is a potential malicious input. We set up an\nahead-of-threat experiment in which we generated data on old versions of an\napplication, and then evaluated the predictive model accuracy on\nvulnerabilities found years later. Our experiments show ahead-of-threat\ndetection on LibXML2 and LibTIFF vulnerabilities with 91.3% and 93.7% accuracy,\nrespectively. We expect to continue work on this field of research and provide\nahead-of-threat virtual patching for more libraries. Success in this research\ncan change the current state of endless racing after application\nvulnerabilities and put the defenders one step ahead of the attackers\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 12:33:28 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Copty", "Fady", ""], ["Kassis", "Andre", ""], ["Keidar-Barner", "Sharon", ""], ["Murik", "Dov", ""]]}, {"id": "2007.08303", "submitter": "Klaus Kursawe", "authors": "Klaus Kursawe", "title": "Wendy, the Good Little Fairness Widget", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of decentralized trading markets introduces a number of new\nchallenges for consensus protocols. In addition to the `usual' attacks -- a\nsubset of the validators trying to prevent disagreement -- there is now the\npossibility of financial fraud, which can abuse properties not normally\nconsidered critical in consensus protocols. We investigate the issues of\nattackers manipulating or exploiting the order in which transactions are\nscheduled in the blockchain. More concretely, we look into relative order\nfairness, i.e., ways we can assure that the relative order of transactions is\nfair. We show that one of the more intuitive definitions of fairness is\nimpossible to achieve. We then present Wendy, a group of low overhead protocols\nthat can implement different concepts of fairness. Wendy acts as an additional\nwidget for an existing blockchain, and is largely agnostic to the underlying\nblockchain and its security assumptions. Furthermore, it is possible to apply a\nthe protocol only for a subset of the transactions, and thus run several\nindependent fair markets on the same chain.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 12:43:31 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Kursawe", "Klaus", ""]]}, {"id": "2007.08306", "submitter": "Ciprian Oprisa", "authors": "Francisc Moldovan and Ciprian Oprisa", "title": "A Framework for Threats Analysis Using Software-Defined Networking", "comments": null, "journal-ref": null, "doi": "10.1109/ICCP.2018.8516636", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to analyze network threats is very important in security\nresearch. Traditional approaches, involving sandboxing technology are limited\nto simulating a single host, missing local network attacks. This issue is\naddressed by designing a threat analysis framework that uses software-defined\nnetworking for simulating arbitrary networks. The presented system offers\nflexibility, allowing a security researcher to define a virtual network that is\nable to capture malicious actions and to be restored to the initial state\nafterwards. Both the framework design and common usage scenarios are described.\nBy providing this framework, we aim to ease the analysis effort in combating\ncyberthreats.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 12:53:09 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Moldovan", "Francisc", ""], ["Oprisa", "Ciprian", ""]]}, {"id": "2007.08319", "submitter": "Rafa G\\'alvez", "authors": "Rafa G\\'alvez, Veelasha Moonsamy, Claudia Diaz", "title": "Less is More: A privacy-respecting Android malware classifier using\n  Federated Learning", "comments": "21 pages, 8 figures, accepted in PoPETS 2021.4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper we present LiM (\"Less is More\"), a malware classification\nframework that leverages Federated Learning to detect and classify malicious\napps in a privacy-respecting manner. Information about newly installed apps is\nkept locally on users' devices, so that the provider cannot infer which apps\nwere installed by users. At the same time, input from all users is taken into\naccount in the federated learning process and they all benefit from better\nclassification performance. A key challenge of this setting is that users do\nnot have access to the ground truth (i.e. they cannot correctly identify\nwhether an app is malicious). To tackle this, LiM uses a safe semi-supervised\nensemble that maximizes classification accuracy with respect to a baseline\nclassifier trained by the service provider (i.e. the cloud). We implement LiM\nand show that the cloud server has F1 score of 95%, while clients have perfect\nrecall with only 1 false positive in >100 apps, using a dataset of 25K clean\napps and 25K malicious apps, 200 users and 50 rounds of federation.\nFurthermore, we conduct a security analysis and demonstrate that LiM is robust\nagainst both poisoning attacks by adversaries who control half of the clients,\nand inference attacks performed by an honest-but-curious cloud server. Further\nexperiments with MaMaDroid's dataset confirm resistance against poisoning\nattacks and a performance improvement due to the federation.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 13:20:33 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 08:22:34 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 09:41:05 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["G\u00e1lvez", "Rafa", ""], ["Moonsamy", "Veelasha", ""], ["Diaz", "Claudia", ""]]}, {"id": "2007.08428", "submitter": "Chaitanya Devaguptapu", "authors": "Chaitanya Devaguptapu, Devansh Agarwal, Gaurav Mittal, Vineeth N\n  Balasubramanian", "title": "On Adversarial Robustness: A Neural Architecture Search perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial robustness of deep learning models has gained much traction in\nthe last few years. Various attacks and defenses are proposed to improve the\nadversarial robustness of modern-day deep learning architectures. While all\nthese approaches help improve the robustness, one promising direction for\nimproving adversarial robustness is un-explored, i.e., the complex topology of\nthe neural network architecture. In this work, we answer the following\nquestion: \"Can the complex topology of a neural network give adversarial\nrobustness without any form of adversarial training?\" empirically by\nexperimenting with different hand-crafted and NAS based architectures. Our\nfindings show that, for small-scale attacks, NAS-based architectures are more\nrobust for small-scale datasets and simple tasks than hand-crafted\narchitectures. However, as the dataset's size or the task's complexity\nincrease, hand-crafted architectures are more robust than NAS-based\narchitectures. We perform the first large scale study to understand adversarial\nrobustness purely from an architectural perspective. Our results show that\nrandom sampling in the search space of DARTS (a popular NAS method) with simple\nensembling can improve the robustness to PGD attack by nearly ~12\\%. We show\nthat NAS, which is popular for SoTA accuracy, can provide adversarial accuracy\nas a free add-on without any form of adversarial training. Our results show\nthat leveraging the power of neural network topology with methods like\nensembles can be an excellent way to achieve adversarial robustness without any\nform of adversarial training. We also introduce a metric that can be used to\ncalculate the trade-off between clean accuracy and adversarial robustness.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 16:07:10 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 14:34:28 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Devaguptapu", "Chaitanya", ""], ["Agarwal", "Devansh", ""], ["Mittal", "Gaurav", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "2007.08432", "submitter": "Stacey Truex", "authors": "Vale Tolpegin, Stacey Truex, Mehmet Emre Gursoy, and Ling Liu", "title": "Data Poisoning Attacks Against Federated Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is an emerging paradigm for distributed training of\nlarge-scale deep neural networks in which participants' data remains on their\nown devices with only model updates being shared with a central server.\nHowever, the distributed nature of FL gives rise to new threats caused by\npotentially malicious participants. In this paper, we study targeted data\npoisoning attacks against FL systems in which a malicious subset of the\nparticipants aim to poison the global model by sending model updates derived\nfrom mislabeled data. We first demonstrate that such data poisoning attacks can\ncause substantial drops in classification accuracy and recall, even with a\nsmall percentage of malicious participants. We additionally show that the\nattacks can be targeted, i.e., they have a large negative impact only on\nclasses that are under attack. We also study attack longevity in early/late\nround training, the impact of malicious participant availability, and the\nrelationships between the two. Finally, we propose a defense strategy that can\nhelp identify malicious participants in FL to circumvent poisoning attacks, and\ndemonstrate its effectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 16:16:57 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 19:10:13 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Tolpegin", "Vale", ""], ["Truex", "Stacey", ""], ["Gursoy", "Mehmet Emre", ""], ["Liu", "Ling", ""]]}, {"id": "2007.08457", "submitter": "Ning Yu", "authors": "Ning Yu, Vladislav Skripniuk, Sahar Abdelnabi, Mario Fritz", "title": "Artificial Fingerprinting for Generative Models: Rooting Deepfake\n  Attribution in Training Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.CY cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photorealistic image generation has reached a new level of quality due to the\nbreakthroughs of generative adversarial networks (GANs). Yet, the dark side of\nsuch deepfakes, the malicious use of generated media, raises concerns about\nvisual misinformation. While existing research work on deepfake detection\ndemonstrates high accuracy, it is subject to advances in generation techniques\nand adversarial iterations on detection countermeasure techniques. Thus, we\nseek a proactive and sustainable solution on deepfake detection, that is\nagnostic to the evolution of generative models, by introducing artificial\nfingerprints into the models.\n  Our approach is simple and effective. We first embed artificial fingerprints\ninto training data, then validate a surprising discovery on the transferability\nof such fingerprints from training data to generative models, which in turn\nappears in the generated deepfakes. Experiments show that our fingerprinting\nsolution (1) holds for a variety of cutting-edge generative models, (2) leads\nto a negligible side effect on generation quality, (3) stays robust against\nimage-level and model-level perturbations, (4) stays hard to be detected by\nadversaries, and (5) converts deepfake detection and attribution into trivial\ntasks and outperforms the recent state-of-the-art baselines. Our solution\ncloses the responsibility loop between publishing pre-trained generative model\ninventions and their possible misuses, which makes it independent of the\ncurrent arms race.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 16:49:55 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 21:46:54 GMT"}, {"version": "v3", "created": "Fri, 9 Oct 2020 04:17:39 GMT"}, {"version": "v4", "created": "Wed, 16 Dec 2020 00:32:00 GMT"}, {"version": "v5", "created": "Wed, 31 Mar 2021 00:49:28 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Yu", "Ning", ""], ["Skripniuk", "Vladislav", ""], ["Abdelnabi", "Sahar", ""], ["Fritz", "Mario", ""]]}, {"id": "2007.08469", "submitter": "Qisheng Zhang", "authors": "Qisheng Zhang, Jin-Hee Cho, Terrence J. Moore, Ing-Ray Chen", "title": "Vulnerability-Aware Resilient Networks: Software Diversity-based Network\n  Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By leveraging the principle of software polyculture to ensure security in a\nnetwork, we proposed a vulnerability-based software diversity metric to\ndetermine how a network topology can be adapted to minimize security\nvulnerability while maintaining maximum network connectivity. Our proposed\nsoftware diversity-based adaptation (SDA) scheme estimates a node's software\ndiversity based on the vulnerabilities of software packages installed on other\nnodes on attack paths reachable to the node and employs it for edge\nadaptations, such as removing an edge with a neighboring node that exposes high\nsecurity vulnerability because two connected nodes use the same software\npackages or a neighboring node may have high software vulnerability or adding\nan edge with another node with less or no security vulnerability because the\ntwo nodes use different software packages or have low vulnerabilities\nassociated with them. To validate the proposed SDA scheme, we conducted\nextensive experiments comparing the proposed SDA scheme with counterpart\nbaseline schemes in real networks. Our simulation experimental results proved\nthe outperformance of our proposed SDA compared to the existing counterparts\nand provided insightful findings in terms of the effectiveness and efficiency\nof the proposed SDA scheme under three real network topologies with vastly\ndifferent network density.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 17:10:39 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Zhang", "Qisheng", ""], ["Cho", "Jin-Hee", ""], ["Moore", "Terrence J.", ""], ["Chen", "Ing-Ray", ""]]}, {"id": "2007.08595", "submitter": "Truc Nguyen", "authors": "Truc D. T. Nguyen, My T. Thai", "title": "A Blockchain-based Iterative Double Auction Protocol using Multiparty\n  State Channels", "comments": null, "journal-ref": null, "doi": "10.1145/3389249", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the iterative double auction has been widely used in many different\napplications, one of the major problems in its current implementations is that\nthey rely on a trusted third party to handle the auction process. This imposes\nthe risk of single point of failures, monopoly, and bribery. In this paper, we\naim to tackle this problem by proposing a novel decentralized and trustless\nframework for iterative double auction based on blockchain. Our design adopts\nthe smart contract and state channel technologies to enable a double auction\nprocess among parties that do not need to trust each other, while minimizing\nthe blockchain transactions. In specific, we propose an extension to the\noriginal concept of state channels that can support multiparty computation.\nThen we provide a formal development of the proposed framework and prove the\nsecurity of our design against adversaries. Finally, we develop a\nproof-of-concept implementation of our framework using Elixir and Solidity, on\nwhich we conduct various experiments to demonstrate its feasibility and\npracticality.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 19:53:57 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Nguyen", "Truc D. T.", ""], ["Thai", "My T.", ""]]}, {"id": "2007.08596", "submitter": "Truc Nguyen", "authors": "Lan N. Nguyen, Truc D. T. Nguyen, Thang N. Dinh, My T. Thai", "title": "OptChain: Optimal Transactions Placement for Scalable Blockchain\n  Sharding", "comments": null, "journal-ref": null, "doi": "10.1109/ICDCS.2019.00059", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in blockchain sharding protocols is that more than 95%\ntransactions are cross-shard. Not only those cross-shard transactions degrade\nthe system throughput but also double the confirmation time, and exhaust an\nalready scarce network bandwidth. Are cross-shard transactions imminent for\nsharding schemes? In this paper, we propose a new sharding paradigm, called\nOptChain, in which cross-shard transactions are minimized, resulting in almost\ntwice faster confirmation time and throughput. By treating transactions as a\nstream of nodes in an online graph, OptChain utilizes a lightweight and\non-the-fly transaction placement method to group both related and soon-related\ntransactions into the same shards. At the same time, OptChain maintains a\ntemporal balance among shards to guarantee the high parallelism. Our\ncomprehensive and large-scale simulation using Oversim P2P library confirms a\nsignificant boost in performance with up to 10 folds reduction in cross-shard\ntransactions, more than twice reduction in confirmation time, and 50% increase\nin throughput. When combined with Omniledger sharding protocol, OptChain\ndelivers a 6000 transactions per second throughput with 10.5s confirmation\ntime.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 19:54:51 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Nguyen", "Lan N.", ""], ["Nguyen", "Truc D. T.", ""], ["Dinh", "Thang N.", ""], ["Thai", "My T.", ""]]}, {"id": "2007.08600", "submitter": "Truc Nguyen", "authors": "Truc Nguyen, My T. Thai", "title": "Denial-of-Service Vulnerability of Hash-based Transaction Sharding:\n  Attacks and Countermeasures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since 2016, sharding has become an auspicious solution to tackle the\nscalability issue in legacy blockchain systems. Despite its potential to\nstrongly boost the blockchain throughput, sharding comes with its own security\nissues. To ease the process of deciding which shard to place transactions,\nexisting sharding protocols use a hash-based transaction sharding in which the\nhash value of a transaction determines its output shard. Unfortunately, we show\nthat this mechanism opens up a loophole that could be exploited to conduct a\nsingle-shard flooding attack, a type of Denial-of-Service (DoS) attack, to\noverwhelm a single shard that ends up reducing the performance of the system as\na whole.\n  To counter the single-shard flooding attack, we propose a countermeasure that\nessentially eliminates the loophole by rejecting the use of hash-based\ntransaction sharding. The countermeasure leverages the Trusted Execution\nEnvironment (TEE) to let blockchain's validators securely execute a transaction\nsharding algorithm with a negligible overhead. We provide a formal\nspecification for the countermeasure and analyze its security properties in the\nUniversal Composability (UC) framework. Finally, a proof-of-concept is\ndeveloped to demonstrate the feasibility and practicality of our solution.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 19:58:41 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 15:39:18 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Nguyen", "Truc", ""], ["Thai", "My T.", ""]]}, {"id": "2007.08644", "submitter": "Maximino DiGiacomo-Castillo", "authors": "Max DiGiacomo-Castillo, Yiyun Liang, Advay Pal, John C. Mitchell", "title": "Model Checking Bitcoin and other Proof-of-Work Consensus Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bitcoin Backbone Protocol [GKL15] is an abstraction of the bitcoin\nproof-of-work consensus protocol. We use a model-checking tool (UPPAALSMC) to\nexamine the concrete security of proof-ofwork consensus by varying protocol\nparameters and using an adversary that leverages the selfish mining strategy\nintroduced in [GKL15]. We provide insights into modeling proof-of-work\nprotocols and demonstrate tradeoffs between operating parameters. Applying this\nmethodology to protocol design options, we show that the uniform tie-breaking\nrule from [ES18] decreases the failure rate of the chain quality property, but\nincreases the failure rate of the common prefix property. This tradeoff\nillustrates how design decisions affect protocol properties, within a range of\nconcrete operating conditions, in a manner that is not evident from prior\nasymptotic analysis.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 21:14:20 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["DiGiacomo-Castillo", "Max", ""], ["Liang", "Yiyun", ""], ["Pal", "Advay", ""], ["Mitchell", "John C.", ""]]}, {"id": "2007.08688", "submitter": "Qisheng Zhang", "authors": "Qisheng Zhang, Abdullah Zubair Mohammed, Zelin Wan, Jin-Hee Cho,\n  Terrence J. Moore", "title": "Diversity-By-Design for Dependable and Secure Cyber-Physical Systems: A\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diversity-based security approaches have been studied for several decades\nsince the 1970's. The concept of diversity-by-design emerged in the 1980's and,\nsince then, diversity-based system design research has been explored to build\nmore secure and dependable systems. In this work, we are particularly\ninterested in providing an in-depth, comprehensive survey of existing\ndiversity-based approaches, insights, and future work directions for those who\nwant to conduct research on developing secure and dependable cyber-physical\nsystems (CPSs) using diversity as a system design feature. To be specific, this\nsurvey paper provides: (i) The common concept of diversity based on a\nmultidisciplinary study of diversity from nine different fields along with the\nhistorical evolution of diversity-by-design for security; (ii) The design\nprinciples of diversity-based approaches; (iii) The key benefits and caveats of\nusing diversity-by-design; (iv) The key concerns of CPS environments in\nintroducing diversity-by-design; (v) A variety of existing diversity-based\napproaches based on five different classifications; (vi) The types of attacks\nmitigated by existing diversity-based approaches; (vii) The overall trends of\nevaluation methodologies used in diversity-based approaches, in terms of\nmetrics, datasets, and testbeds; and (viii) The insights, lessons, and gaps\nidentified from this extensive survey.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 23:25:36 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Zhang", "Qisheng", ""], ["Mohammed", "Abdullah Zubair", ""], ["Wan", "Zelin", ""], ["Cho", "Jin-Hee", ""], ["Moore", "Terrence J.", ""]]}, {"id": "2007.08707", "submitter": "Zhi Zhang", "authors": "Zhi Zhang, Yueqiang Cheng, Dongxi Liu, Surya Nepal, Zhi Wang, and\n  Yuval Yarom", "title": "PThammer: Cross-User-Kernel-Boundary Rowhammer through Implicit Accesses", "comments": "Preprint of the work accepted at the International Symposium on\n  Microarchitecture (MICRO) 2020. arXiv admin note: text overlap with\n  arXiv:1912.03076", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rowhammer is a hardware vulnerability in DRAM memory, where repeated access\nto memory can induce bit flips in neighboring memory locations. Being a\nhardware vulnerability, rowhammer bypasses all of the system memory protection,\nallowing adversaries to compromise the integrity and confidentiality of data.\nRowhammer attacks have shown to enable privilege escalation, sandbox escape,\nand cryptographic key disclosures. Recently, several proposals suggest\nexploiting the spatial proximity between the accessed memory location and the\nlocation of the bit flip for a defense against rowhammer. These all aim to deny\nthe attacker's permission to access memory locations near sensitive data. In\nthis paper, we question the core assumption underlying these defenses. We\npresent PThammer, a confused-deputy attack that causes accesses to memory\nlocations that the attacker is not allowed to access. Specifically, PThammer\nexploits the address translation process of modern processors, inducing the\nprocessor to generate frequent accesses to protected memory locations. We\nimplement PThammer, demonstrating that it is a viable attack, resulting in a\nsystem compromise (e.g., kernel privilege escalation). We further evaluate the\neffectiveness of proposed software-only defenses showing that PThammer can\novercome those.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 01:10:53 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 04:12:39 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Zhang", "Zhi", ""], ["Cheng", "Yueqiang", ""], ["Liu", "Dongxi", ""], ["Nepal", "Surya", ""], ["Wang", "Zhi", ""], ["Yarom", "Yuval", ""]]}, {"id": "2007.08745", "submitter": "Yiming Li", "authors": "Yiming Li, Baoyuan Wu, Yong Jiang, Zhifeng Li, Shu-Tao Xia", "title": "Backdoor Learning: A Survey", "comments": "12 pages. A curated list of backdoor learning resources in this paper\n  is presented in the Github Repo\n  (https://github.com/THUYimingLi/backdoor-learning-resources). We will try our\n  best to continuously maintain the repo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backdoor attack intends to embed hidden backdoor into deep neural networks\n(DNNs), such that the attacked model performs well on benign samples, whereas\nits prediction will be maliciously changed if the hidden backdoor is activated\nby the attacker-defined trigger. This threat could happen when the training\nprocess is not fully controlled, such as training on third-party datasets or\nadopting third-party models, which poses a new and realistic threat. Although\nbackdoor learning is an emerging and rapidly growing research area, its\nsystematic review, however, remains blank. In this paper, we present the first\ncomprehensive survey of this realm. We summarize and categorize existing\nbackdoor attacks and defenses based on their characteristics, and provide a\nunified framework for analyzing poisoning-based backdoor attacks. Besides, we\nalso analyze the relation between backdoor attacks and relevant fields ($i.e.,$\nadversarial attacks and data poisoning), and summarize widely adopted benchmark\ndatasets. Finally, we briefly outline certain future research directions\nrelying upon reviewed works. A curated list of backdoor-related resources is\nalso available at\n\\url{https://github.com/THUYimingLi/backdoor-learning-resources}.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 04:09:20 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 06:27:07 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 02:14:14 GMT"}, {"version": "v4", "created": "Sun, 14 Feb 2021 04:46:10 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Li", "Yiming", ""], ["Wu", "Baoyuan", ""], ["Jiang", "Yong", ""], ["Li", "Zhifeng", ""], ["Xia", "Shu-Tao", ""]]}, {"id": "2007.08775", "submitter": "Hitoshi Kiya", "authors": "Ayana Kawamura, Yuma Kinoshita, Takayuki Nakachi, Sayaka Shiota, and\n  Hitoshi Kiya", "title": "A Privacy-Preserving Machine Learning Scheme Using EtC Images", "comments": "To appear in IEICE Trans. Fundamentals", "journal-ref": null, "doi": "10.1587/transfun.2020SMP0022", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a privacy-preserving machine learning scheme with\nencryption-then-compression (EtC) images, where EtC images are images encrypted\nby using a block-based encryption method proposed for EtC systems with JPEG\ncompression. In this paper, a novel property of EtC images is first discussed,\nalthough EtC ones was already shown to be compressible as a property. The novel\nproperty allows us to directly apply EtC images to machine learning algorithms\nnon-specialized for computing encrypted data. In addition, the proposed scheme\nis demonstrated to provide no degradation in the performance of some typical\nmachine learning algorithms including the support vector machine algorithm with\nkernel trick and random forests under the use of z-score normalization. A\nnumber of facial recognition experiments with are carried out to confirm the\neffectiveness of the proposed scheme.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 06:29:15 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Kawamura", "Ayana", ""], ["Kinoshita", "Yuma", ""], ["Nakachi", "Takayuki", ""], ["Shiota", "Sayaka", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "2007.08795", "submitter": "Vipin Kumar Kukkala", "authors": "Vipin Kumar Kukkala, Sooryaa Vignesh Thiruloga and Sudeep Pasricha", "title": "INDRA: Intrusion Detection using Recurrent Autoencoders in Automotive\n  Embedded Systems", "comments": "12 pages, 15 figures, 3 tables, accepted in CASES 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's vehicles are complex distributed embedded systems that are\nincreasingly being connected to various external systems. Unfortunately, this\nincreased connectivity makes the vehicles vulnerable to security attacks that\ncan be catastrophic. In this work, we present a novel Intrusion Detection\nSystem (IDS) called INDRA that utilizes a Gated Recurrent Unit (GRU) based\nrecurrent autoencoder to detect anomalies in Controller Area Network (CAN)\nbus-based automotive embedded systems. We evaluate our proposed framework under\ndifferent attack scenarios and also compare it with the best known prior works\nin this area.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 07:39:21 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Kukkala", "Vipin Kumar", ""], ["Thiruloga", "Sooryaa Vignesh", ""], ["Pasricha", "Sudeep", ""]]}, {"id": "2007.08803", "submitter": "Mahdi Soleymani", "authors": "Mahdi Soleymani, Hessam Mahdavifar, A. Salman Avestimehr", "title": "Privacy-Preserving Distributed Learning in the Analog Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the critical problem of distributed learning over data while\nkeeping it private from the computational servers. The state-of-the-art\napproaches to this problem rely on quantizing the data into a finite field, so\nthat the cryptographic approaches for secure multiparty computing can then be\nemployed. These approaches, however, can result in substantial accuracy losses\ndue to fixed-point representation of the data and computation overflows. To\naddress these critical issues, we propose a novel algorithm to solve the\nproblem when data is in the analog domain, e.g., the field of real/complex\nnumbers. We characterize the privacy of the data from both\ninformation-theoretic and cryptographic perspectives, while establishing a\nconnection between the two notions in the analog domain. More specifically, the\nwell-known connection between the distinguishing security (DS) and the mutual\ninformation security (MIS) metrics is extended from the discrete domain to the\ncontinues domain. This is then utilized to bound the amount of information\nabout the data leaked to the servers in our protocol, in terms of the DS\nmetric, using well-known results on the capacity of single-input\nmultiple-output (SIMO) channel with correlated noise. It is shown how the\nproposed framework can be adopted to do computation tasks when data is\nrepresented using floating-point numbers. We then show that this leads to a\nfundamental trade-off between the privacy level of data and accuracy of the\nresult. As an application, we also show how to train a machine learning model\nwhile keeping the data as well as the trained model private. Then numerical\nresults are shown for experiments on the MNIST dataset. Furthermore,\nexperimental advantages are shown comparing to fixed-point implementations over\nfinite fields.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 07:56:39 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Soleymani", "Mahdi", ""], ["Mahdavifar", "Hessam", ""], ["Avestimehr", "A. Salman", ""]]}, {"id": "2007.08813", "submitter": "Simon Duque Anton", "authors": "Simon D Duque Anton, Hans Dieter Schotten", "title": "Intrusion Detection in Binary Process Data: Introducing the\n  Hamming-distance to Matrix Profiles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The digitisation of industry provides a plethora of novel applications that\nincrease flexibility and reduce setup and maintenance time as well as cost.\nFurthermore, novel use cases are created by the digitisation of industry,\ncommonly known as Industry 4.0 or the Industrial Internet of Things,\napplications make use of communication and computation technology that is\nbecoming available. This enables novel business use cases, such as the digital\ntwin, customer individual production, and data market places. However, the\ninter-connectivity such use cases rely on also significantly increases the\nattack surface of industrial enterprises. Sabotage and espionage are aimed at\ndata, which is becoming the most crucial asset of an enterprise. Since the\nrequirements on security solutions in industrial networks are inherently\ndifferent from office networks, novel approaches for intrusion detection need\nto be developed. In this work, process data of a real water treatment process\nthat contains attacks is analysed. Analysis is performed by an extension of\nMatrix Profiles, a motif discovery algorithm for time series. By extending\nMatrix Profiles with a Hammingdistance metric, binary and tertiary actuators\ncan be integrated into the analysis in a meaningful fashion. This algorithm\nrequires low training effort while providing accurate results. Furthermore, it\ncan be employed in a real-time fashion. Selected actuators in the data set are\nanalysed to highlight the applicability of the extended Matrix Profiles.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 08:19:23 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Anton", "Simon D Duque", ""], ["Schotten", "Hans Dieter", ""]]}, {"id": "2007.08871", "submitter": "Ijaz Ahmad Dr.", "authors": "Ijaz Ahmad, Ilkka Harjula, Jarno Pinola", "title": "Overview of Security of Virtual Mobile Networks", "comments": "6 pages, 1 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  5G is enabling different services over the same physical infrastructure\nthrough the concepts and technologies of virtualization, softwarization,\nslicing and cloud computing. Virtual Mobile Networks (VMNs), using these\nconcepts, provide an opportunity to share the same physical infrastructure\namong multiple operators. Each VMN Operator (VMNO) can have own distinct\noperating and support systems. However, the technologies used to enable VMNs\nhave their own explicit security challenges and solutions. The integrated\nenvironment built upon virtualization, softwarization, and cloudification,\nthus, will have complex security requirements and implications. In this vain,\nthis article provides an overview of the security challenges and potential\nsolutions for VMNs.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 09:58:43 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Ahmad", "Ijaz", ""], ["Harjula", "Ilkka", ""], ["Pinola", "Jarno", ""]]}, {"id": "2007.08885", "submitter": "Florian Fischer", "authors": "Florian Fischer and Matthias Niedermaier and Thomas Hanka and Peter\n  Knauer and Dominik Merli", "title": "Analysis of Industrial Device Architectures for Real-Time Operations\n  under Denial of Service Attacks", "comments": "First published in the 22nd International Conference on Information\n  and Communications Security (ICICS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More and more industrial devices are connected to IP-based networks, as this\nis essential for the success of Industry 4.0. However, this interconnection\nalso results in an increased attack surface for various network-based attacks.\nOne of the easiest attacks to carry out are DoS attacks, in which the attacked\ntarget is overloaded due to high network traffic and corresponding CPU load.\nTherefore, the attacked device can no longer provide its regular services. This\nis especially critical for devices, which perform real-time operations in\nindustrial processes. To protect against DoS attacks, there is the possibility\nof throttling network traffic at the perimeter, e.g. by a firewall, to develop\nrobust device architectures. In this paper, we analyze various concepts for\nsecure device architectures and compare them with regard to their robustness\nagainst DoS attacks. Here, special attention is paid to how the control process\nof an industrial controller behaves during the attack. For this purpose, we\ncompare different schedulers on single-core and dual-core Linux-based systems,\nas well as a heterogeneous multi-core architecture under various network loads\nand additional system stress.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 10:24:15 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Fischer", "Florian", ""], ["Niedermaier", "Matthias", ""], ["Hanka", "Thomas", ""], ["Knauer", "Peter", ""], ["Merli", "Dominik", ""]]}, {"id": "2007.08911", "submitter": "Ehsan Toreini", "authors": "Ehsan Toreini, Mhairi Aitken, Kovila P. L. Coopamootoo, Karen Elliott,\n  Vladimiro Gonzalez Zelaya, Paolo Missier, Magdalene Ng, Aad van Moorsel", "title": "Technologies for Trustworthy Machine Learning: A Survey in a\n  Socio-Technical Context", "comments": "We are updating some sections to include more recent advances", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concerns about the societal impact of AI-based services and systems has\nencouraged governments and other organisations around the world to propose AI\npolicy frameworks to address fairness, accountability, transparency and related\ntopics. To achieve the objectives of these frameworks, the data and software\nengineers who build machine-learning systems require knowledge about a variety\nof relevant supporting tools and techniques. In this paper we provide an\noverview of technologies that support building trustworthy machine learning\nsystems, i.e., systems whose properties justify that people place trust in\nthem. We argue that four categories of system properties are instrumental in\nachieving the policy objectives, namely fairness, explainability, auditability\nand safety & security (FEAS). We discuss how these properties need to be\nconsidered across all stages of the machine learning life cycle, from data\ncollection through run-time model inference. As a consequence, we survey in\nthis paper the main technologies with respect to all four of the FEAS\nproperties, for data-centric as well as model-centric stages of the machine\nlearning system life cycle. We conclude with an identification of open research\nproblems, with a particular focus on the connection between trustworthy machine\nlearning technologies and their implications for individuals and society.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 11:39:20 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 09:40:31 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Toreini", "Ehsan", ""], ["Aitken", "Mhairi", ""], ["Coopamootoo", "Kovila P. L.", ""], ["Elliott", "Karen", ""], ["Zelaya", "Vladimiro Gonzalez", ""], ["Missier", "Paolo", ""], ["Ng", "Magdalene", ""], ["van Moorsel", "Aad", ""]]}, {"id": "2007.08955", "submitter": "Rodothea Myrsini Tsoupidi", "authors": "Rodothea Myrsini Tsoupidi, Roberto Casta\\~neda Lozano and Benoit\n  Baudry", "title": "Constraint-Based Software Diversification for Efficient Mitigation of\n  Code-Reuse Attacks", "comments": "15 pages, 26th International Conference on Principles and Practice of\n  Constraint Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern software deployment process produces software that is uniform, and\nhence vulnerable to large-scale code-reuse attacks. Compiler-based\ndiversification improves the resilience and security of software systems by\nautomatically generating different assembly code versions of a given program.\nExisting techniques are efficient but do not have a precise control over the\nquality of the generated code variants.\n  This paper introduces Diversity by Construction (DivCon), a constraint-based\ncompiler approach to software diversification. Unlike previous approaches,\nDivCon allows users to control and adjust the conflicting goals of diversity\nand code quality. A key enabler is the use of Large Neighborhood Search (LNS)\nto generate highly diverse assembly code efficiently.\n  Experiments using two popular compiler benchmark suites confirm that there is\na trade-off between quality of each assembly code version and diversity of the\nentire pool of versions. Our results show that DivCon allows users to trade\nbetween these two properties by generating diverse assembly code for a range of\nquality bounds. In particular, the experiments show that DivCon is able to\nmitigate code-reuse attacks effectively while delivering near-optimal code (<\n10% optimality gap).\n  For constraint programming researchers and practitioners, this paper\ndemonstrates that LNS is a valuable technique for finding diverse solutions.\nFor security researchers and software engineers, DivCon extends the scope of\ncompiler-based diversification to performance-critical and resource-constrained\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 13:01:44 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Tsoupidi", "Rodothea Myrsini", ""], ["Lozano", "Roberto Casta\u00f1eda", ""], ["Baudry", "Benoit", ""]]}, {"id": "2007.09032", "submitter": "Abhijith Manchikanti Venkata", "authors": "Abhijith Manchikanti Venkata, Dinesh Reddy Jeeru, Vittal K.P", "title": "Design And Modelling An Attack on Multiplexer Based Physical Unclonable\n  Function", "comments": "5 pages, 6 figures ,Published with International Journal of\n  Engineering Trends and Technology (IJETT)", "journal-ref": "International Journal of Engineering Trends and Technology\n  68.6(2020):63-67", "doi": "10.14445/22315381/IJETT-V68I6P210S", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper deals with study of the physical unclonable functions and\nspecifically the design of arbiter based PUF (APUF) and extends the work on\ndifferent types of attacks on the PUF designs to break the security of the\ndevice, which includes advanced computational algorithms. Machine learning (ML)\nbased attacks are successful in attacking existing designs. So in this, the\nresistance of the modified, proposed design of APUF is examined by modelling\nthe attack based on the logistic regression a MLbased algorithm. The design is\nvalidated on Basys-3 Artix -7 FPGA board with a part number (xc7a35tcpg236-1).\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 14:54:04 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Venkata", "Abhijith Manchikanti", ""], ["Jeeru", "Dinesh Reddy", ""], ["P", "Vittal K.", ""]]}, {"id": "2007.09047", "submitter": "Ben Weintraub", "authors": "Ben Weintraub, Cristina Nita-Rotaru, Stefanie Roos", "title": "Exploiting Centrality: Attacks in Payment Channel Networks with Local\n  Routing", "comments": "16 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Payment channel networks (PCN) enable scalable blockchain transactions\nwithout fundamentally changing the underlying distributed ledger algorithm.\nHowever, routing a payment via multiple channels in a PCN requires locking\ncollateral for potentially long periods of time. Adversaries can abuse this\nmechanism to conduct denial-of-service attacks. Previous work on\ndenial-of-service attacks focused on source routing, which is unlikely to\nremain a viable routing approach as these networks grow.\n  In this work we examine the effectiveness of attacks in PCNs that use routing\nalgorithms based on local knowledge, where compromised intermediate nodes delay\nor drop transactions to create denial-of-service. We focus on SpeedyMurmurs as\na representative of such protocols. Our attack simulations show that\nSpeedyMurmurs is resilient to attacks by randomly selected intermediate nodes\nbecause it dynamically adjusts using local knowledge. We further consider\nattackers that control a significant fractions of paths and we show that this\nability to route around problematic regions becomes insufficient for such\nattackers. We propose methods to incentivize payment channel networks with less\ncentral nodes and more diverse paths and show through simulation that these\nmethods effectively mitigate the identified denial-of-service attacks.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 15:24:01 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Weintraub", "Ben", ""], ["Nita-Rotaru", "Cristina", ""], ["Roos", "Stefanie", ""]]}, {"id": "2007.09071", "submitter": "Solon Falas", "authors": "Solon Falas, Charalambos Konstantinou, Maria K. Michael", "title": "A Modular End-to-End Framework for Secure Firmware Updates on Embedded\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Firmware refers to device read-only resident code which includes microcode\nand macro-instruction -level routines. For Internet-of-Things (IoT) devices\nwithout an operating system, firmware includes all the necessary instructions\non how such embedded systems operate and communicate. Thus, firmware updates\nare an essential part of device functionality. They provide the ability to\npatch vulnerabilities, address operational issues, and improve device\nreliability and performance during the lifetime of the system. This process,\nhowever, is often exploited by attackers in order to inject malicious firmware\ncode into the embedded device. In this paper, we present a framework for secure\nfirmware updates on embedded systems. The approach is based on hardware\nprimitives and cryptographic modules, and it can be deployed in environments\nwhere communication channels might be insecure. The implementation of the\nframework is flexible as it can be adapted in regards to the IoT device's\navailable hardware resources and constraints. Our security analysis shows that\nour framework is resilient to a variety of attack vectors. The experimental\nsetup demonstrates the feasibility of the approach. By implementing a variety\nof test cases on FPGA, we demonstrate the adaptability and performance of the\nframework. Experiments indicate that the update procedure for a 1183kB firmware\nimage could be achieved, in a secure manner, under 1.73 seconds.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 15:51:28 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 17:24:35 GMT"}, {"version": "v3", "created": "Wed, 14 Jul 2021 10:32:51 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Falas", "Solon", ""], ["Konstantinou", "Charalambos", ""], ["Michael", "Maria K.", ""]]}, {"id": "2007.09085", "submitter": "Ofer Yifrach-Stav", "authors": "Marcel Hollenstein, David Naccache, Peter B. R{\\o}nne, Peter Y A Ryan,\n  Robert Weil, and Ofer Yifrach-Stav", "title": "Preservation of DNA Privacy During the Large Scale Detection of COVID-19", "comments": "10 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As humanity struggles to contain the global COVID-19 pandemic, privacy\nconcerns are emerging regarding confinement, tracing and testing. The\nscientific debate concerning privacy of the COVID-19 tracing efforts has been\nintense, especially focusing on the choice between centralised and\ndecentralised tracing apps. The privacy concerns regarding COVID-19 testing,\nhowever, have not received as much attention even though the privacy at stake\nis arguably even higher. COVID-19 tests require the collection of samples.\nThose samples possibly contain viral material but inevitably also human DNA.\nPatient DNA is not necessary for the test but it is technically impossible to\navoid collecting it. The unlawful preservation, or misuse, of such samples at a\nmassive scale may hence disclose patient DNA information with far-reaching\nprivacy consequences. Inspired by the cryptographic concept of\n\"Indistinguishability under Chosen Plaintext Attack\", this paper poses the\nblueprint of novel types of tests allowing to detect viral presence without\nleaving persisting traces of the patient's DNA. Authors are listed in\nalphabetical order.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 16:08:49 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 19:32:07 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Hollenstein", "Marcel", ""], ["Naccache", "David", ""], ["R\u00f8nne", "Peter B.", ""], ["Ryan", "Peter Y A", ""], ["Weil", "Robert", ""], ["Yifrach-Stav", "Ofer", ""]]}, {"id": "2007.09098", "submitter": "Ranwa Al Mallah", "authors": "Ranwa Al Mallah, Bilal Farooq", "title": "Actor-based Risk Analysis for Blockchains in Smart Mobility", "comments": "arXiv admin note: text overlap with arXiv:1904.11908 by other authors", "journal-ref": null, "doi": "10.1145/3410699.3413794", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain technology is a crypto-based secure ledger for data storage and\ntransfer through decentralized, trustless peer-to-peer systems. Despite its\nadvantages, previous studies have shown that the technology is not completely\nsecure against cyber attacks. Thus, it is crucial to perform domain specific\nrisk analysis to measure how viable the attacks are on the system, their impact\nand consequently the risk exposure. Specifically, in this paper, we carry out\nan analysis in terms of quantifying the risk associated to an operational\nmulti-layered Blockchain framework for Smart Mobility Data-markets (BSMD). We\nconduct an actor-based analysis to determine the impact of the attacks. The\nanalysis identified five attack goals and five types of attackers that violate\nthe security of the blockchain system. In the case study of the public\npermissioned BSMD, we highlight the highest risk factors according to their\nimpact on the victims in terms of monetary, privacy, integrity and trust. Four\nattack goals represent a risk in terms of economic losses and one attack goal\ncontains many threats that represent a risk that is either unacceptable or\nundesirable.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 00:03:28 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 17:13:03 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Mallah", "Ranwa Al", ""], ["Farooq", "Bilal", ""]]}, {"id": "2007.09208", "submitter": "Nhuong Nguyen", "authors": "Marten van Dijk, Nhuong V. Nguyen, Toan N. Nguyen, Lam M. Nguyen, Quoc\n  Tran-Dinh, Phuong Ha Nguyen", "title": "Asynchronous Federated Learning with Reduced Number of Rounds and with\n  Differential Privacy from Less Aggregated Gaussian Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The feasibility of federated learning is highly constrained by the\nserver-clients infrastructure in terms of network communication. Most newly\nlaunched smartphones and IoT devices are equipped with GPUs or sufficient\ncomputing hardware to run powerful AI models. However, in case of the original\nsynchronous federated learning, client devices suffer waiting times and regular\ncommunication between clients and server is required. This implies more\nsensitivity to local model training times and irregular or missed updates,\nhence, less or limited scalability to large numbers of clients and convergence\nrates measured in real time will suffer. We propose a new algorithm for\nasynchronous federated learning which eliminates waiting times and reduces\noverall network communication - we provide rigorous theoretical analysis for\nstrongly convex objective functions and provide simulation results. By adding\nGaussian noise we show how our algorithm can be made differentially private --\nnew theorems show how the aggregated added Gaussian noise is significantly\nreduced.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 19:47:16 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["van Dijk", "Marten", ""], ["Nguyen", "Nhuong V.", ""], ["Nguyen", "Toan N.", ""], ["Nguyen", "Lam M.", ""], ["Tran-Dinh", "Quoc", ""], ["Nguyen", "Phuong Ha", ""]]}, {"id": "2007.09256", "submitter": "Asaf Shabtai", "authors": "Yoni Birman, Ziv Ido, Gilad Katz and Asaf Shabtai", "title": "Hierarchical Deep Reinforcement Learning Approach for Multi-Objective\n  Scheduling With Varying Queue Sizes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-objective task scheduling (MOTS) is the task scheduling while\noptimizing multiple and possibly contradicting constraints. A challenging\nextension of this problem occurs when every individual task is a\nmulti-objective optimization problem by itself. While deep reinforcement\nlearning (DRL) has been successfully applied to complex sequential problems,\nits application to the MOTS domain has been stymied by two challenges. The\nfirst challenge is the inability of the DRL algorithm to ensure that every item\nis processed identically regardless of its position in the queue. The second\nchallenge is the need to manage large queues, which results in large neural\narchitectures and long training times. In this study we present MERLIN, a\nrobust, modular and near-optimal DRL-based approach for multi-objective task\nscheduling. MERLIN applies a hierarchical approach to the MOTS problem by\ncreating one neural network for the processing of individual tasks and another\nfor the scheduling of the overall queue. In addition to being smaller and with\nshorted training times, the resulting architecture ensures that an item is\nprocessed in the same manner regardless of its position in the queue.\nAdditionally, we present a novel approach for efficiently applying DRL-based\nsolutions on very large queues, and demonstrate how we effectively scale MERLIN\nto process queue sizes that are larger by orders of magnitude than those on\nwhich it was trained. Extensive evaluation on multiple queue sizes show that\nMERLIN outperforms multiple well-known baselines by a large margin (>22%).\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 21:59:06 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Birman", "Yoni", ""], ["Ido", "Ziv", ""], ["Katz", "Gilad", ""], ["Shabtai", "Asaf", ""]]}, {"id": "2007.09270", "submitter": "Asma Aloufi", "authors": "Asma Aloufi and Peizhao Hu and Yongsoo Song and Kristin Lauter", "title": "Computing Blindfolded on Data Homomorphically Encrypted under Multiple\n  Keys: An Extended Survey", "comments": "(Author's version). This paper is an early extended draft of the\n  survey that is being submitted to ACM CSUR and has been uploaded to ArXiv.org\n  for feedback from stakeholders", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New cryptographic techniques such as homomorphic encryption (HE) allow\ncomputations to be outsourced to and evaluated blindfolded in a resourceful\ncloud. These computations often require private data owned by multiple\nparticipants, engaging in joint evaluation of some functions. For example,\nGenome-Wide Association Study (GWAS) is becoming feasible because of recent\nproliferation of genome sequencing technology. Due to the sensitivity of\ngenomic data, these data should be encrypted using different keys. However,\nsupporting computation on ciphertexts encrypted under multiple keys is a\nnon-trivial task. In this paper, we present a comprehensive survey on different\nstate-of-the-art cryptographic techniques and schemes that are commonly used.\nWe review techniques and schemes including Attribute-Based Encryption (ABE),\nProxy Re-Encryption (PRE), Threshold Homomorphic Encryption (ThHE), and\nMulti-Key Homomorphic Encryption (MKHE). We analyze them based on different\nsystem and security models, and examine their complexities. We share lessons\nlearned and draw observations for designing better schemes with reduced\noverheads.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 22:49:02 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 20:51:40 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Aloufi", "Asma", ""], ["Hu", "Peizhao", ""], ["Song", "Yongsoo", ""], ["Lauter", "Kristin", ""]]}, {"id": "2007.09327", "submitter": "Ibrahim Ahmed", "authors": "Ibrahim H. Ahmed, Josiah P. Hanna, Elliot Fosong, and Stefano V.\n  Albrecht", "title": "Towards Quantum-Secure Authentication and Key Agreement via Abstract\n  Multi-Agent Interaction", "comments": "Published at the 19th International Conference on Practical\n  Applications of Agents and Multi-Agent Systems (PAAMS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current methods for authentication and key agreement based on public-key\ncryptography are vulnerable to quantum computing. We propose a novel approach\nbased on artificial intelligence research in which communicating parties are\nviewed as autonomous agents which interact repeatedly using their private\ndecision models. Authentication and key agreement are decided based on the\nagents' observed behaviors during the interaction. The security of this\napproach rests upon the difficulty of modeling the decisions of interacting\nagents from limited observations, a problem which we conjecture is also hard\nfor quantum computing. We release PyAMI, a prototype authentication and key\nagreement system based on the proposed method. We empirically validate our\nmethod for authenticating legitimate users while detecting different types of\nadversarial attacks. Finally, we show how reinforcement learning techniques can\nbe used to train server models which effectively probe a client's decisions to\nachieve more sample-efficient authentication.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 04:22:02 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 16:13:41 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Ahmed", "Ibrahim H.", ""], ["Hanna", "Josiah P.", ""], ["Fosong", "Elliot", ""], ["Albrecht", "Stefano V.", ""]]}, {"id": "2007.09339", "submitter": "Sasi Kumar Murakonda", "authors": "Sasi Kumar Murakonda, Reza Shokri", "title": "ML Privacy Meter: Aiding Regulatory Compliance by Quantifying the\n  Privacy Risks of Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When building machine learning models using sensitive data, organizations\nshould ensure that the data processed in such systems is adequately protected.\nFor projects involving machine learning on personal data, Article 35 of the\nGDPR mandates it to perform a Data Protection Impact Assessment (DPIA). In\naddition to the threats of illegitimate access to data through security\nbreaches, machine learning models pose an additional privacy risk to the data\nby indirectly revealing about it through the model predictions and parameters.\nGuidances released by the Information Commissioner's Office (UK) and the\nNational Institute of Standards and Technology (US) emphasize on the threat to\ndata from models and recommend organizations to account for and estimate these\nrisks to comply with data protection regulations. Hence, there is an immediate\nneed for a tool that can quantify the privacy risk to data from models.\n  In this paper, we focus on this indirect leakage about training data from\nmachine learning models. We present ML Privacy Meter, a tool that can quantify\nthe privacy risk to data from models through state of the art membership\ninference attack techniques. We discuss how this tool can help practitioners in\ncompliance with data protection regulations, when deploying machine learning\nmodels.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 06:21:35 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Murakonda", "Sasi Kumar", ""], ["Shokri", "Reza", ""]]}, {"id": "2007.09342", "submitter": "Mengmeng Ge", "authors": "Mengmeng Ge, Naeem Firdous Syed, Xiping Fu, Zubair Baig, Antonio\n  Robles-Kelly", "title": "Toward a Deep Learning-Driven Intrusion Detection Approach for Internet\n  of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) has brought along immense benefits to our daily\nlives encompassing a diverse range of application domains that we regularly\ninteract with, ranging from healthcare automation to transport and smart\nenvironments. However, due to the limitation of constrained resources and\ncomputational capabilities, IoT networks are prone to various cyber attacks.\nThus, defending the IoT network against adversarial attacks is of vital\nimportance. In this paper, we present a novel intrusion detection approach for\nIoT networks through the application of a deep learning technique. We adopt a\ncutting-edge IoT dataset comprising IoT traces and realistic attack traffic,\nincluding denial of service, distributed denial of service, reconnaissance and\ninformation theft attacks. We utilise the header field information in\nindividual packets as generic features to capture general network behaviours,\nand develop a feed-forward neural networks model with embedding layers (to\nencode high-dimensional categorical features) for multi-class classification.\nThe concept of transfer learning is subsequently adopted to encode\nhigh-dimensional categorical features to build a binary classifier. Results\nobtained through the evaluation of the proposed approach demonstrate a high\nclassification accuracy for both binary and multi-class classifiers.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 06:36:04 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Ge", "Mengmeng", ""], ["Syed", "Naeem Firdous", ""], ["Fu", "Xiping", ""], ["Baig", "Zubair", ""], ["Robles-Kelly", "Antonio", ""]]}, {"id": "2007.09370", "submitter": "Lingjuan Lyu", "authors": "Lingjuan Lyu, Yitong Li, Karthik Nandakumar, Jiangshan Yu, Xingjun Ma", "title": "How to Democratise and Protect AI: Fair and Differentially Private\n  Decentralised Deep Learning", "comments": "Accepted for publication in TDSC", "journal-ref": null, "doi": "10.1109/TDSC.2020.3006287", "report-no": null, "categories": "cs.CR cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper firstly considers the research problem of fairness in\ncollaborative deep learning, while ensuring privacy. A novel reputation system\nis proposed through digital tokens and local credibility to ensure fairness, in\ncombination with differential privacy to guarantee privacy. In particular, we\nbuild a fair and differentially private decentralised deep learning framework\ncalled FDPDDL, which enables parties to derive more accurate local models in a\nfair and private manner by using our developed two-stage scheme: during the\ninitialisation stage, artificial samples generated by Differentially Private\nGenerative Adversarial Network (DPGAN) are used to mutually benchmark the local\ncredibility of each party and generate initial tokens; during the update stage,\nDifferentially Private SGD (DPSGD) is used to facilitate collaborative\nprivacy-preserving deep learning, and local credibility and tokens of each\nparty are updated according to the quality and quantity of individually\nreleased gradients. Experimental results on benchmark datasets under three\nrealistic settings demonstrate that FDPDDL achieves high fairness, yields\ncomparable accuracy to the centralised and distributed frameworks, and delivers\nbetter accuracy than the standalone framework.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 09:06:10 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Lyu", "Lingjuan", ""], ["Li", "Yitong", ""], ["Nandakumar", "Karthik", ""], ["Yu", "Jiangshan", ""], ["Ma", "Xingjun", ""]]}, {"id": "2007.09371", "submitter": "Fengxiang He", "authors": "Fengxiang He, Bohan Wang, Dacheng Tao", "title": "Tighter Generalization Bounds for Iterative Differentially Private\n  Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the relationship between generalization and privacy\npreservation in iterative learning algorithms by two sequential steps. We first\nestablish an alignment between generalization and privacy preservation for any\nlearning algorithm. We prove that $(\\varepsilon, \\delta)$-differential privacy\nimplies an on-average generalization bound for multi-database learning\nalgorithms which further leads to a high-probability bound for any learning\nalgorithm. This high-probability bound also implies a PAC-learnable guarantee\nfor differentially private learning algorithms. We then investigate how the\niterative nature shared by most learning algorithms influence privacy\npreservation and further generalization. Three composition theorems are\nproposed to approximate the differential privacy of any iterative algorithm\nthrough the differential privacy of its every iteration. By integrating the\nabove two steps, we eventually deliver generalization bounds for iterative\nlearning algorithms, which suggest one can simultaneously enhance privacy\npreservation and generalization. Our results are strictly tighter than the\nexisting works. Particularly, our generalization bounds do not rely on the\nmodel size which is prohibitively large in deep learning. This sheds light to\nunderstanding the generalizability of deep learning. These results apply to a\nwide spectrum of learning algorithms. In this paper, we apply them to\nstochastic gradient Langevin dynamics and agnostic federated learning as\nexamples.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 09:12:03 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 04:41:55 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["He", "Fengxiang", ""], ["Wang", "Bohan", ""], ["Tao", "Dacheng", ""]]}, {"id": "2007.09409", "submitter": "Isha Pali", "authors": "Isha Pali, Lisa Krishania, Divya Chadha, Asmita Kandar, Gaurav\n  Varshney, Sneha Shukla", "title": "A Comprehensive Survey of Aadhar and Security Issues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of Aadhaar came with the need for a unique identity for every\nindividual. To implement this, the Indian government created the authority\nUIDAI to distribute and generate user identities for every individual based on\ntheir demographic and biometric data. After the implementation, came the\nsecurity issues and challenges of Aadhaar and its authentication. So, our study\nfocuses on the journey of Aadhaar from its history to the current condition.\nThe paper also describes the authentication process, and the updates happened\nover time. We have also provided an analysis of the security attacks witnessed\nso far as well as the possible countermeasure and its classification. Our main\naim is to cover all the security aspects related to Aadhaar to avoid possible\nsecurity attacks. Also, we have included the current updates and news related\nto Aadhaar.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 11:19:23 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Pali", "Isha", ""], ["Krishania", "Lisa", ""], ["Chadha", "Divya", ""], ["Kandar", "Asmita", ""], ["Varshney", "Gaurav", ""], ["Shukla", "Sneha", ""]]}, {"id": "2007.09466", "submitter": "Sergio L\\'opez Bernal", "authors": "Sergio L\\'opez Bernal, Alberto Huertas Celdr\\'an, Lorenzo Fern\\'andez\n  Maim\\'o, Michael Taynnan Barros, Sasitharan Balasubramaniam, Gregorio\n  Mart\\'inez P\\'erez", "title": "Cyberattacks on Miniature Brain Implants to Disrupt Spontaneous Neural\n  Signaling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Brain-Computer Interfaces (BCI) arose as systems that merge computing systems\nwith the human brain to facilitate recording, stimulation, and inhibition of\nneural activity. Over the years, the development of BCI technologies has\nshifted towards miniaturization of devices that can be seamlessly embedded into\nthe brain and can target single neuron or small population sensing and control.\nWe present a motivating example highlighting vulnerabilities of two promising\nmicron-scale BCI technologies, demonstrating the lack of security and privacy\nprinciples in existing solutions. This situation opens the door to a novel\nfamily of cyberattacks, called neuronal cyberattacks, affecting neuronal\nsignaling. This paper defines the first two neural cyberattacks, Neuronal\nFlooding (FLO) and Neuronal Scanning (SCA), where each threat can affect the\nnatural activity of neurons. This work implements these attacks in a neuronal\nsimulator to determine their impact over the spontaneous neuronal behavior,\ndefining three metrics: number of spikes, percentage of shifts, and dispersion\nof spikes. Several experiments demonstrate that both cyberattacks produce a\nreduction of spikes compared to spontaneous behavior, generating a rise in\ntemporal shifts and a dispersion increase. Mainly, SCA presents a higher impact\nthan FLO in the metrics focused on the number of spikes and dispersion, where\nFLO is slightly more damaging, considering the percentage of shifts.\nNevertheless, the intrinsic behavior of each attack generates a differentiation\non how they alter neuronal signaling. FLO is adequate to generate an immediate\nimpact on the neuronal activity, whereas SCA presents higher effectiveness for\ndamages to the neural signaling in the long-term.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 16:25:46 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 14:55:42 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Bernal", "Sergio L\u00f3pez", ""], ["Celdr\u00e1n", "Alberto Huertas", ""], ["Maim\u00f3", "Lorenzo Fern\u00e1ndez", ""], ["Barros", "Michael Taynnan", ""], ["Balasubramaniam", "Sasitharan", ""], ["P\u00e9rez", "Gregorio Mart\u00ednez", ""]]}, {"id": "2007.09512", "submitter": "Aditya Shinde", "authors": "Aditya Shinde, Prashant Doshi, Omid Setayeshfar", "title": "Active Deception using Factored Interactive POMDPs to Recognize Cyber\n  Attacker's Intent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an intelligent and adaptive agent that employs deception\nto recognize a cyber adversary's intent. Unlike previous approaches to cyber\ndeception, which mainly focus on delaying or confusing the attackers, we focus\non engaging with them to learn their intent. We model cyber deception as a\nsequential decision-making problem in a two-agent context. We introduce\nfactored finitely nested interactive POMDPs (I-POMDPx) and use this framework\nto model the problem with multiple attacker types. Our approach models cyber\nattacks on a single honeypot host across multiple phases from the attacker's\ninitial entry to reaching its adversarial objective. The defending\nI-POMDPx-based agent uses decoys to engage with the attacker at multiple phases\nto form increasingly accurate predictions of the attacker's behavior and\nintent. The use of I-POMDPs also enables us to model the adversary's mental\nstate and investigate how deception affects their beliefs. Our experiments in\nboth simulation and on a real host show that the I-POMDPx-based agent performs\nsignificantly better at intent recognition than commonly used deception\nstrategies on honeypots.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 20:09:15 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Shinde", "Aditya", ""], ["Doshi", "Prashant", ""], ["Setayeshfar", "Omid", ""]]}, {"id": "2007.09537", "submitter": "Adam Hastings", "authors": "Adam Hastings and Simha Sethumadhavan", "title": "A New Doctrine for Hardware Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we promote the idea that recent woes in hardware security are\nnot because of a lack of technical solutions but rather because market forces\nand incentives prevent those with the ability to fix problems from doing so. At\nthe root of the problem is the fact that hardware security comes at a cost;\nPresent issues in hardware security can be seen as the result of the players in\nthe game of hardware security finding ways of avoiding paying this cost. We\nformulate this idea into a doctrine of security, namely the Doctrine of Shared\nBurdens. Three cases studies---Rowhammer, Spectre, and Meltdown---are\ninterpreted though the lens of this doctrine. Our doctrine illuminates why\nthese problems and exist and what can be done about them.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 23:40:26 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Hastings", "Adam", ""], ["Sethumadhavan", "Simha", ""]]}, {"id": "2007.09588", "submitter": "Mahmood Azhar Qureshi", "authors": "Mahmood Azhar Qureshi and Arslan Munir", "title": "PUF-RLA: A PUF-based Reliable and Lightweight Authentication Protocol\n  employing Binary String Shuffling", "comments": "Published in the 2019 IEEE International Conference on Computer\n  Design (ICCD)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physically unclonable functions (PUFs) can be employed for device\nidentification, authentication, secret key storage, and other security tasks.\nHowever, PUFs are susceptible to modeling attacks if a number of PUFs'\nchallenge-response pairs (CRPs) are exposed to the adversary. Furthermore, many\nof the embedded devices requiring authentication have stringent resource\nconstraints and thus require a lightweight authentication mechanism. We propose\nPUF-RLA, a PUF-based lightweight, highly reliable authentication scheme\nemploying binary string shuffling. The proposed scheme enhances the reliability\nof PUF as well as alleviates the resource constraints by employing error\ncorrection in the server instead of the device without compromising the\nsecurity. The proposed PUF-RLA is robust against brute force, replay, and\nmodeling attacks. In PUF-RLA, we introduce an inexpensive yet secure stream\nauthentication scheme inside the device which authenticates the server before\nthe underlying PUF can be invoked. This prevents an adversary from brute\nforcing the device's PUF to acquire CRPs essentially locking out the device\nfrom unauthorized model generation. Additionally, we also introduce a\nlightweight CRP obfuscation mechanism involving XOR and shuffle operations.\nResults and security analysis verify that the PUF-RLA is secure against brute\nforce, replay, and modeling attacks, and provides ~99% reliable authentication.\nIn addition, PUF-RLA provides a reduction of 63% and 74% for look-up tables\n(LUTs) and register count, respectively, in FPGA compared to a recently\nproposed approach while providing additional authentication advantages.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 04:24:38 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Qureshi", "Mahmood Azhar", ""], ["Munir", "Arslan", ""]]}, {"id": "2007.09647", "submitter": "Shuchang Tao", "authors": "Shuchang Tao, Huawei Shen, Qi Cao, Liang Hou, Xueqi Cheng", "title": "Adversarial Immunization for Certifiable Robustness on Graphs", "comments": "Accepted by the WSDM 2021; Code:\n  https://github.com/TaoShuchang/AdvImmune", "journal-ref": null, "doi": "10.1145/3437963.3441782", "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite achieving strong performance in semi-supervised node classification\ntask, graph neural networks (GNNs) are vulnerable to adversarial attacks,\nsimilar to other deep learning models. Existing researches focus on developing\neither robust GNN models or attack detection methods against adversarial\nattacks on graphs. However, little research attention is paid to the potential\nand practice of immunization to adversarial attacks on graphs. In this paper,\nwe propose and formulate the graph adversarial immunization problem, i.e.,\nvaccinating an affordable fraction of node pairs, connected or unconnected, to\nimprove the certifiable robustness of graph against any admissible adversarial\nattack. We further propose an effective algorithm, called AdvImmune, which\noptimizes with meta-gradient in a discrete way to circumvent the\ncomputationally expensive combinatorial optimization when solving the\nadversarial immunization problem. Experiments are conducted on two citation\nnetworks and one social network. Experimental results demonstrate that the\nproposed AdvImmune method remarkably improves the ratio of robust nodes by 12%,\n42%, 65%, with an affordable immune budget of only 5% edges.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 10:41:10 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 09:25:59 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2020 01:28:32 GMT"}, {"version": "v4", "created": "Fri, 28 May 2021 06:54:55 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Tao", "Shuchang", ""], ["Shen", "Huawei", ""], ["Cao", "Qi", ""], ["Hou", "Liang", ""], ["Cheng", "Xueqi", ""]]}, {"id": "2007.09696", "submitter": "Xiaoqi Li", "authors": "Xiaoqi Li, Ting Chen, Xiapu Luo, Tao Zhang, Le Yu, Zhou Xu", "title": "STAN: Towards Describing Bytecodes of Smart Contract", "comments": "In Proc. of the 20th IEEE International Conference on Software\n  Quality, Reliability and Security (QRS), 2020", "journal-ref": "In Proc. of the 20th IEEE International Conference on Software\n  Quality, Reliability and Security (QRS), 2020", "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More than eight million smart contracts have been deployed into Ethereum,\nwhich is the most popular blockchain that supports smart contract. However,\nless than 1% of deployed smart contracts are open-source, and it is difficult\nfor users to understand the functionality and internal mechanism of those\nclosed-source contracts. Although a few decompilers for smart contracts have\nbeen recently proposed, it is still not easy for users to grasp the semantic\ninformation of the contract, not to mention the potential misleading due to\ndecompilation errors. In this paper, we propose the first system named STAN to\ngenerate descriptions for the bytecodes of smart contracts to help users\ncomprehend them. In particular, for each interface in a smart contract, STAN\ncan generate four categories of descriptions, including functionality\ndescription, usage description, behavior description, and payment description,\nby leveraging symbolic execution and NLP (Natural Language Processing)\ntechniques. Extensive experiments show that STAN can generate adequate,\naccurate, and readable descriptions for contract's bytecodes, which have\npractical value for users.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 15:48:35 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Li", "Xiaoqi", ""], ["Chen", "Ting", ""], ["Luo", "Xiapu", ""], ["Zhang", "Tao", ""], ["Yu", "Le", ""], ["Xu", "Zhou", ""]]}, {"id": "2007.09698", "submitter": "Jianbing Ni", "authors": "Miao He, Jianbing Ni, Dongxiao Liu, Haomiao Yang, Xuemin (Sherman)\n  Shen", "title": "Private, Fair, and Verifiable Aggregate Statistics for Mobile\n  Crowdsensing in Blockchain Era", "comments": "This paper has been accepted by IEEE/CIC ICCC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose FairCrowd, a private, fair, and verifiable\nframework for aggregate statistics in mobile crowdsensing based on the public\nblockchain. In specific, mobile users are incentivized to collect and share\nprivate data values (e.g., current locations) to fufill a commonly interested\ntask released by a customer, and the crowdsensing server computes aggregate\nstatistics over the values of mobile users (e.g., the most popular location)\nfor the customer. By utilizing the ElGamal encryption, the server learns nearly\nnothing about the private data or the statistical result. The correctness of\naggregate statistics can be publicly verified by using a new efficient and\nverifiable computation approach. Moreover, the fairness of incentive is\nguaranteed based on the public blockchain in the presence of greedy service\nprovider, customers, and mobile users, who may launch payment-escaping,\npayment-reduction, free-riding, double-reporting, and Sybil attacks to corrupt\nreward distribution. Finally, FairCrowd is proved to achieve verifiable\naggregate statistics with privacy preservation for mobile users. Extensive\nexperiments are conducted to demonstrate the high efficiency of FairCrowd for\naggregate statistics in mobile crowdsensing.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 15:56:36 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["He", "Miao", "", "Sherman"], ["Ni", "Jianbing", "", "Sherman"], ["Liu", "Dongxiao", "", "Sherman"], ["Yang", "Haomiao", "", "Sherman"], ["Xuemin", "", "", "Sherman"], ["Shen", "", ""]]}, {"id": "2007.09802", "submitter": "Muneeb Ul Hassan", "authors": "Muneeb Ul Hassan, Mubashir Husain Rehmani, and Jinjun Chen", "title": "Performance Evaluation of Differential Privacy Mechanisms in Blockchain\n  based Smart Metering", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of differential privacy emerged as a strong notion to protect\ndatabase privacy in an untrusted environment. Later on, researchers proposed\nseveral variants of differential privacy in order to preserve privacy in\ncertain other scenarios, such as real-time cyber physical systems. Since then,\ndifferential privacy has rigorously been applied to certain other domains which\nhas the need of privacy preservation. One such domain is decentralized\nblockchain based smart metering, in which smart meters acting as blockchain\nnodes sent their real-time data to grid utility databases for real-time\nreporting. This data is further used to carry out statistical tasks, such as\nload forecasting, demand response calculation, etc. However, in case if any\nintruder gets access to this data it can leak privacy of smart meter users. In\nthis context, differential privacy can be used to protect privacy of this data.\nIn this chapter, we carry out comparison of four variants of differential\nprivacy (Laplace, Gaussian, Uniform, and Geometric) in blockchain based smart\nmetering scenario. We test these variants on smart metering data and carry out\ntheir performance evaluation by varying different parameters. Experimental\noutcomes shows at low privacy budget ($\\varepsilon$) and at low reading\nsensitivity value ($\\delta$), these privacy preserving mechanisms provide high\nprivacy by adding large amount of noise. However, among these four privacy\npreserving parameters Geometric parameters is more suitable for protecting high\npeak values and Laplace mechanism is more suitable for protecting low peak\nvalues at ($\\varepsilon$ = 0.01).\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 22:24:03 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Hassan", "Muneeb Ul", ""], ["Rehmani", "Mubashir Husain", ""], ["Chen", "Jinjun", ""]]}, {"id": "2007.10044", "submitter": "Martin Eker{\\aa}", "authors": "Martin Eker{\\aa}", "title": "On completely factoring any integer efficiently in a single run of an\n  order finding algorithm", "comments": "A minor issue in the proof of Lemma 2 has been corrected. Two\n  references have furthermore been added, the introduction has been improved,\n  and a number of other minor improvements have been made. No results are\n  affected by this revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that given the order of a single element selected uniformly at random\nfrom $\\mathbb Z_N^*$, we can with very high probability, and for any integer\n$N$, efficiently find the complete factorization of $N$ in polynomial time.\nThis implies that a single run of the quantum part of Shor's factoring\nalgorithm is usually sufficient. All prime factors of $N$ can then be recovered\nwith negligible computational cost in a classical post-processing step. The\nclassical algorithm required for this step is essentially due to Miller.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 12:32:34 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 18:47:50 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Eker\u00e5", "Martin", ""]]}, {"id": "2007.10115", "submitter": "Apostolos Modas", "authors": "Apostolos Modas, Ricardo Sanchez-Matilla, Pascal Frossard, Andrea\n  Cavallaro", "title": "Towards robust sensing for Autonomous Vehicles: An adversarial\n  perspective", "comments": null, "journal-ref": "IEEE Signal Processing Magazine, Volume 37, Issue 4, Pages 14 -\n  23, July 2020", "doi": "10.1109/MSP.2020.2985363", "report-no": null, "categories": "eess.SP cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous Vehicles rely on accurate and robust sensor observations for\nsafety critical decision-making in a variety of conditions. Fundamental\nbuilding blocks of such systems are sensors and classifiers that process\nultrasound, RADAR, GPS, LiDAR and camera signals~\\cite{Khan2018}. It is of\nprimary importance that the resulting decisions are robust to perturbations,\nwhich can take the form of different types of nuisances and data\ntransformations, and can even be adversarial perturbations (APs). Adversarial\nperturbations are purposefully crafted alterations of the environment or of the\nsensory measurements, with the objective of attacking and defeating the\nautonomous systems. A careful evaluation of the vulnerabilities of their\nsensing system(s) is necessary in order to build and deploy safer systems in\nthe fast-evolving domain of AVs. To this end, we survey the emerging field of\nsensing in adversarial settings: after reviewing adversarial attacks on sensing\nmodalities for autonomous systems, we discuss countermeasures and present\nfuture research directions.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 05:25:15 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Modas", "Apostolos", ""], ["Sanchez-Matilla", "Ricardo", ""], ["Frossard", "Pascal", ""], ["Cavallaro", "Andrea", ""]]}, {"id": "2007.10168", "submitter": "Davide Andreoletti", "authors": "Davide Andreoletti, and Omran Ayoub, and Silvia Giordano, and Massimo\n  Tornatore, and Giacomo Verticale", "title": "Privacy-Preserving Multi-Operator Contact Tracing for Early Detection of\n  Covid19 Contagions", "comments": null, "journal-ref": null, "doi": "10.1109/GCWKSHPS50303.2020.9367403", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The outbreak of coronavirus disease 2019 (covid-19) is imposing a severe\nworldwide lock-down. Contact tracing based on smartphones' applications (apps)\nhas emerged as a possible solution to trace contagions and enforce a more\nsustainable selective quarantine. However, a massive adoption of these apps is\nrequired to reach the critical mass needed for effective contact tracing. As an\nalternative, geo-location technologies in next generation networks (e.g., 5G)\ncan enable Mobile Operators (MOs) to perform passive tracing of users' mobility\nand contacts with a promised accuracy of down to one meter. To effectively\ndetect contagions, the identities of positive individuals, which are known only\nby a Governmental Authority (GA), are also required. Note that, besides being\nextremely sensitive, these data might also be critical from a business\nperspective. Hence, MOs and the GA need to exchange and process users'\ngeo-locations and infection status data in a privacy-preserving manner. In this\nwork, we propose a privacy-preserving protocol that enables multiple MOs and\nthe GA to share and process users' data to make only the final users discover\nthe number of their contacts with positive individuals. The protocol is based\non existing privacy-enhancing strategies that guarantee that users' mobility\nand infection status are only known to their MOs and to the GA, respectively.\nFrom extensive simulations, we observe that the cost to guarantee total privacy\n(evaluated in terms of data overhead introduced by the protocol) is acceptable,\nand can also be significantly reduced if we accept a negligible compromise in\nusers' privacy.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 14:44:57 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Andreoletti", "Davide", ""], ["Ayoub", "Omran", ""], ["Giordano", "Silvia", ""], ["Tornatore", "Massimo", ""], ["Verticale", "Giacomo", ""]]}, {"id": "2007.10204", "submitter": "Tatsumi Oba", "authors": "Tatsumi Oba, Tadahiro Taniguchi", "title": "Graph Convolutional Network-based Suspicious Communication Pair\n  Estimation for Industrial Control Systems", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whitelisting is considered an effective security monitoring method for\nnetworks used in industrial control systems, where the whitelists consist of\nobserved tuples of the IP address of the server, the TCP/UDP port number, and\nIP address of the client (communication triplets). However, this method causes\nfrequent false detections. To reduce false positives due to a simple\nwhitelist-based judgment, we propose a new framework for scoring communications\nto judge whether the communications not present in whitelists are normal or\nanomalous. To solve this problem, we developed a graph convolutional\nnetwork-based suspicious communication pair estimation using relational graph\nconvolution networks, and evaluated its performance. For this, we collected the\nnetwork traffic of three factories owned by Panasonic Corporation, Japan. The\nproposed method achieved a receiver operating characteristic area under the\ncurve of 0.957, which outperforms baseline approaches such as DistMult, a\nmethod that directly optimizes the node embeddings, and heuristics, which score\nthe triplets using first- and second-order proximities of multigraphs. This\nmethod enables security operators to concentrate on significant alerts.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 16:16:56 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Oba", "Tatsumi", ""], ["Taniguchi", "Tadahiro", ""]]}, {"id": "2007.10240", "submitter": "Zehua Ma", "authors": "Zehua Ma, Weiming Zhang, Han Fang, Xiaoyi Dong, Linfeng Geng, and\n  Nenghai Yu", "title": "Local Geometric Distortions Resilient Watermarking Scheme Based on\n  Symmetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an efficient watermark attack method, geometric distortions destroy the\nsynchronization between watermark encoder and decoder. And the local geometric\ndistortion is a famous challenge in the watermark field. Although a lot of\ngeometric distortions resilient watermarking schemes have been proposed, few of\nthem perform well against local geometric distortion like random bending attack\n(RBA). To address this problem, this paper proposes a novel watermark\nsynchronization process and the corresponding watermarking scheme. In our\nscheme, the watermark bits are represented by random patterns. The message is\nencoded to get a watermark unit, and the watermark unit is flipped to generate\na symmetrical watermark. Then the symmetrical watermark is embedded into the\nspatial domain of the host image in an additive way. In watermark extraction,\nwe first get the theoretically mean-square error minimized estimation of the\nwatermark. Then the auto-convolution function is applied to this estimation to\ndetect the symmetry and get a watermark units map. According to this map, the\nwatermark can be accurately synchronized, and then the extraction can be done.\nExperimental results demonstrate the excellent robustness of the proposed\nwatermarking scheme to local geometric distortions, global geometric\ndistortions, common image processing operations, and some kinds of combined\nattacks.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 16:27:59 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Ma", "Zehua", ""], ["Zhang", "Weiming", ""], ["Fang", "Han", ""], ["Dong", "Xiaoyi", ""], ["Geng", "Linfeng", ""], ["Yu", "Nenghai", ""]]}, {"id": "2007.10246", "submitter": "Diane Hosfelt", "authors": "Nicole Shadowen and Diane Hosfelt", "title": "Addressing the Privacy Implications of Mixed Reality: A Regulatory\n  Approach", "comments": "Presented at the CHI 2020 Workshop on Exploring Potentially Abusive\n  Ethical, Social and Political Implications of Mixed Reality Research in HCI\n  (https://chi2020.acm.org/accepted-workshops/#W37)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed reality (MR) technologies are emerging into the mainstream with\naffordable devices like the Oculus Quest. These devices blend the physical and\nvirtual in novel ways that blur the lines that exist in legal precedent, like\nthose between speech and conduct. In this paper, we discuss the challenges of\nregulating immersive technologies, focusing on the potential for extensive data\ncollection, and examine the trade-offs of three potential approaches to\nprotecting data privacy in the context of mixed reality environments.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 16:35:17 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Shadowen", "Nicole", ""], ["Hosfelt", "Diane", ""]]}, {"id": "2007.10397", "submitter": "Yoshimichi Nakatsuka", "authors": "Yoshimichi Nakatsuka, Ercan Ozturk, Andrew Paverd, Gene Tsudik", "title": "CACTI: Captcha Avoidance via Client-side TEE Integration", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preventing abuse of web services by bots is an increasingly important\nproblem, as abusive activities grow in both volume and variety. CAPTCHAs are\nthe most common way for thwarting bot activities. However, they are often\nineffective against bots and frustrating for humans. In addition, some recent\nCAPTCHA techniques diminish user privacy. Meanwhile, client-side Trusted\nExecution Environments (TEEs) are becoming increasingly widespread (notably,\nARM TrustZone and Intel SGX), allowing establishment of trust in a small part\n(trust anchor or TCB) of client-side hardware. This prompts the question: can a\nTEE help reduce (or remove entirely) user burden of solving CAPTCHAs?\n  In this paper, we design CACTI: CAPTCHA Avoidance via Client-side TEE\nIntegration. Using client-side TEEs, CACTI allows legitimate clients to\ngenerate unforgeable rate-proofs demonstrating how frequently they have\nperformed specific actions. These rate-proofs can be sent to web servers in\nlieu of solving CAPTCHAs. CACTI provides strong client privacy guarantees,\nsince the information is only sent to the visited website and authenticated\nusing a group signature scheme. Our evaluations show that overall latency of\ngenerating and verifying a CACTI rate-proof is less than 0.25 sec, while\nCACTI's bandwidth overhead is over 98% lower than that of current CAPTCHA\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 18:30:49 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Nakatsuka", "Yoshimichi", ""], ["Ozturk", "Ercan", ""], ["Paverd", "Andrew", ""], ["Tsudik", "Gene", ""]]}, {"id": "2007.10457", "submitter": "Sailik Sengupta", "authors": "Sailik Sengupta, Subbarao Kambhampati", "title": "Multi-agent Reinforcement Learning in Bayesian Stackelberg Markov Games\n  for Adaptive Moving Target Defense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of cybersecurity has mostly been a cat-and-mouse game with the\ndiscovery of new attacks leading the way. To take away an attacker's advantage\nof reconnaissance, researchers have proposed proactive defense methods such as\nMoving Target Defense (MTD). To find good movement strategies, researchers have\nmodeled MTD as leader-follower games between the defender and a\ncyber-adversary. We argue that existing models are inadequate in sequential\nsettings when there is incomplete information about a rational adversary and\nyield sub-optimal movement strategies. Further, while there exists an array of\nwork on learning defense policies in sequential settings for cyber-security,\nthey are either unpopular due to scalability issues arising out of incomplete\ninformation or tend to ignore the strategic nature of the adversary simplifying\nthe scenario to use single-agent reinforcement learning techniques. To address\nthese concerns, we propose (1) a unifying game-theoretic model, called the\nBayesian Stackelberg Markov Games (BSMGs), that can model uncertainty over\nattacker types and the nuances of an MTD system and (2) a Bayesian Strong\nStackelberg Q-learning (BSS-Q) approach that can, via interaction, learn the\noptimal movement policy for BSMGs within a reasonable time. We situate BSMGs in\nthe landscape of incomplete-information Markov games and characterize the\nnotion of Strong Stackelberg Equilibrium (SSE) in them. We show that our\nlearning approach converges to an SSE of a BSMG and then highlight that the\nlearned movement policy (1) improves the state-of-the-art in MTD for\nweb-application security and (2) converges to an optimal policy in MTD domains\nwith incomplete information about adversaries even when prior information about\nrewards and transitions is absent.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 20:34:53 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Sengupta", "Sailik", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "2007.10512", "submitter": "Ayush Jain", "authors": "Ayush Jain, Tanjidur Rahman, Ujjwal Guin", "title": "ATPG-Guided Fault Injection Attacks on Logic Locking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic Locking is a well-accepted protection technique to enable trust in the\noutsourced design and fabrication processes of integrated circuits (ICs) where\nthe original design is modified by incorporating additional key gates in the\nnetlist, resulting in a key-dependent functional circuit. The original\nfunctionality of the chip is recovered once it is programmed with the secret\nkey, otherwise, it produces incorrect results for some input patterns. Over the\npast decade, different attacks have been proposed to break logic locking,\nsimultaneously motivating researchers to develop more secure countermeasures.\nIn this paper, we propose a novel stuck-at fault-based differential fault\nanalysis (DFA) attack, which can be used to break logic locking that relies on\na stored secret key. This proposed attack is based on self-referencing, where\nthe secret key is determined by injecting faults in the key lines and comparing\nthe response with its fault-free counterpart. A commercial ATPG tool can be\nused to generate test patterns that detect these faults, which will be used in\nDFA to determine the secret key. One test pattern is sufficient to determine\none key bit, which results in at most |K| test patterns to determine the entire\nsecret key of size |K|. The proposed attack is generic and can be extended to\nbreak any logic locked circuits.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 22:18:28 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Jain", "Ayush", ""], ["Rahman", "Tanjidur", ""], ["Guin", "Ujjwal", ""]]}, {"id": "2007.10513", "submitter": "Weijie Liu", "authors": "Weijie Liu, Wenhao Wang, Xiaofeng Wang, Xiaozhu Meng, Yaosong Lu,\n  Hongbo Chen, Xinyu Wang, Qingtao Shen, Kai Chen, Haixu Tang, Yi Chen and Luyi\n  Xing", "title": "Confidential Attestation: Efficient in-Enclave Verification of Privacy\n  Policy Compliance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A trusted execution environment (TEE) such as Intel Software Guard Extension\n(SGX) runs a remote attestation to prove to a data owner the integrity of the\ninitial state of an enclave, including the program to operate on her data. For\nthis purpose, the data-processing program is supposed to be open to the owner,\nso its functionality can be evaluated before trust can be established. However,\nincreasingly there are application scenarios in which the program itself needs\nto be protected. So its compliance with privacy policies as expected by the\ndata owner should be verified without exposing its code.\n  To this end, this paper presents CAT, a new model for TEE-based confidential\nattestation. Our model is inspired by Proof-Carrying Code, where a code\ngenerator produces proof together with the code and a code consumer verifies\nthe proof against the code on its compliance with security policies. Given that\nthe conventional solutions do not work well under the resource-limited and\nTCB-frugal TEE, we propose a new design that allows an untrusted out-enclave\ngenerator to analyze the source code of a program when compiling it into binary\nand a trusted in-enclave consumer efficiently verifies the correctness of the\ninstrumentation and the presence of other protection before running the binary.\nOur design strategically moves most of the workload to the code generator,\nwhich is responsible for producing well-formatted and easy-to-check code, while\nkeeping the consumer simple. Also, the whole consumer can be made public and\nverified through a conventional attestation. We implemented this model on Intel\nSGX and demonstrate that it introduces a very small part of TCB. We also\nthoroughly evaluated its performance on micro- and macro- benchmarks and\nreal-world applications, showing that the new design only incurs a small\noverhead when enforcing several categories of security policies.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 22:19:33 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Liu", "Weijie", ""], ["Wang", "Wenhao", ""], ["Wang", "Xiaofeng", ""], ["Meng", "Xiaozhu", ""], ["Lu", "Yaosong", ""], ["Chen", "Hongbo", ""], ["Wang", "Xinyu", ""], ["Shen", "Qingtao", ""], ["Chen", "Kai", ""], ["Tang", "Haixu", ""], ["Chen", "Yi", ""], ["Xing", "Luyi", ""]]}, {"id": "2007.10528", "submitter": "Chuka Oham", "authors": "Chuka Oham, Regio Michelin, Salil S. Kanhere, Raja Jurdak and Sanjay\n  Jha", "title": "B-FERL: Blockchain based Framework for Securing Smart Vehicles", "comments": "11 Pages, 8 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ubiquity of connecting technologies in smart vehicles and the incremental\nautomation of its functionalities promise significant benefits, including a\nsignificant decline in congestion and road fatalities. However, increasing\nautomation and connectedness broadens the attack surface and heightens the\nlikelihood of a malicious entity successfully executing an attack. In this\npaper, we propose a Blockchain based Framework for sEcuring smaRt vehicLes\n(B-FERL). B-FERL uses permissioned blockchain technology to tailor information\naccess to restricted entities in the connected vehicle ecosystem. It also uses\na challenge-response data exchange between the vehicles and roadside units to\nmonitor the internal state of the vehicle to identify cases of in-vehicle\nnetwork compromise. In order to enable authentic and valid communication in the\nvehicular network, only vehicles with a verifiable record in the blockchain can\nexchange messages. Through qualitative arguments, we show that B-FERL is\nresilient to identified attacks. Also, quantitative evaluations in an emulated\nscenario show that B-FERL ensures a suitable response time and required storage\nsize compatible with realistic scenarios. Finally, we demonstrate how B-FERL\nachieves various important functions relevant to the automotive ecosystem such\nas trust management, vehicular forensics and secure vehicular networks.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 23:28:24 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Oham", "Chuka", ""], ["Michelin", "Regio", ""], ["Kanhere", "Salil S.", ""], ["Jurdak", "Raja", ""], ["Jha", "Sanjay", ""]]}, {"id": "2007.10529", "submitter": "Tianbo Gu", "authors": "Jinyue Song, Tianbo Gu, Xiaotao Feng, Yunjie Ge, Prasant Mohapatra", "title": "Blockchain Meets COVID-19: A Framework for Contact Information Sharing\n  and Risk Notification System", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 causes a global epidemic infection, which is the most severe\ninfection disaster in human history. In the absence of particular medication\nand vaccines, tracing and isolating the source of infection is the best option\nto slow the spread of the virus and reduce infection and death rates among the\npopulation. There are three main obstacles in the process of tracing the\ninfection: 1) Patient's electronic health record is stored in a traditional\ncentralized database that could be stolen and tampered with the infection data,\n2) The confidential personal identity of the infected user may be revealed to a\nthird party or organization, 3) Existing infection tracing systems do not trace\ninfections from multiple dimensions. Either the system is location-based or\nindividual-based tracing. In this work, we propose a global COVID-19\ninformation sharing system that utilizes the Blockchain, Smart Contract, and\nBluetooth technologies. The proposed system unifies location-based and\nBluetooth-based contact tracing services into the Blockchain platform, where\nthe automatically executed smart contracts are deployed so that users can get\nconsistent and non-tamperable virus trails. The anonymous functionality\nprovided by the Blockchain and Bluetooth technology protects the user's\nidentity privacy. With our proposed analysis formula for estimating the\nprobability of infection, users can take measures to protect themselves in\nadvance. We also implement a prototype system to demonstrate the feasibility\nand effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 23:36:46 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Song", "Jinyue", ""], ["Gu", "Tianbo", ""], ["Feng", "Xiaotao", ""], ["Ge", "Yunjie", ""], ["Mohapatra", "Prasant", ""]]}, {"id": "2007.10541", "submitter": "Alejandro Ranchal-Pedrosa", "authors": "Alejandro Ranchal-Pedrosa, Vincent Gramoli", "title": "Blockchain Is Dead, Long Live Blockchain! Accountable State Machine\n  Replication for Longlasting Blockchain", "comments": "19 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The long-standing impossibility of reaching agreement restricts the lifespan\nof blockchains. In fact, the consensus on a block to be appended to any\nblockchain succeeds either with some probability or at the condition that two\nthirds of the $n$ replicas are not Byzantine. In the former case, the\nprobability that the blockchain fails grows exponentially with the number of\nnewly appended blocks. In the latter case, the blockchain fails as soon as a\ncoalition bribes $f=n/3$ replicas. As a result, one may wonder whether\nblockchains are doomed to fail.\n  In this paper, we answer this question in the negative by proposing the first\nLonglasting Blockchain system, \\emph{LLB}. LLB builds upon the observation that\nblockchains are rarely subject to benign faults. As opposed to probabilistic\nblockchains, LLB solves consensus deterministically when $f<n/3$. As opposed to\nByzantine fault tolerant blockchains, it resolves a series of disagreements by\nreducing eventually the number of deceitful replicas from $n/3\\leq f<2n/3$ to\n$f'<n'/3$ among a new set of $n'$ replicas. To demonstrate its effectiveness,\nwe implement two coalition attacks and a zero loss payment application that\nforces replicas that misbehave to reimburse conflicting transactions. Finally,\nLLB outperforms the raw state machine replication at the heart of Facebook's\nLibra and achieves performance comparable to a scalable blockchain that cannot\ntolerate $n/3$ failures.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 00:57:25 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 23:42:46 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Ranchal-Pedrosa", "Alejandro", ""], ["Gramoli", "Vincent", ""]]}, {"id": "2007.10560", "submitter": "Zhaoxiong Yang", "authors": "Zhaoxiong Yang, Shuihai Hu, Kai Chen", "title": "FPGA-Based Hardware Accelerator of Homomorphic Encryption for Efficient\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing awareness of privacy protection and data fragmentation\nproblem, federated learning has been emerging as a new paradigm of machine\nlearning. Federated learning tends to utilize various privacy preserving\nmechanisms to protect the transferred intermediate data, among which\nhomomorphic encryption strikes a balance between security and ease of\nutilization. However, the complicated operations and large operands impose\nsignificant overhead on federated learning. Maintaining accuracy and security\nmore efficiently has been a key problem of federated learning. In this work, we\ninvestigate a hardware solution, and design an FPGA-based homomorphic\nencryption framework, aiming to accelerate the training phase in federated\nlearning. The root complexity lies in searching for a compact architecture for\nthe core operation of homomorphic encryption, to suit the requirement of\nfederated learning about high encryption throughput and flexibility of\nconfiguration. Our framework implements the representative Paillier homomorphic\ncryptosystem with high level synthesis for flexibility and portability, with\ncareful optimization on the modular multiplication operation in terms of\nprocessing clock cycle, resource usage and clock frequency. Our accelerator\nachieves a near-optimal execution clock cycle, with a better DSP-efficiency\nthan existing designs, and reduces the encryption time by up to 71% during\ntraining process of various federated learning models.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 01:59:58 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Yang", "Zhaoxiong", ""], ["Hu", "Shuihai", ""], ["Chen", "Kai", ""]]}, {"id": "2007.10608", "submitter": "Sugata Gangopadhyay", "authors": "Tanmoy Kanti Das, S. Gangopadhyay, Jianying Zhou", "title": "SSIDS: Semi-Supervised Intrusion Detection System by Extending the\n  Logical Analysis of Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prevention of cyber attacks on the critical network resources has become an\nimportant issue as the traditional Intrusion Detection Systems (IDSs) are no\nlonger effective due to the high volume of network traffic and the deceptive\npatterns of network usage employed by the attackers. Lack of sufficient amount\nof labeled observations for the training of IDSs makes the semi-supervised IDSs\na preferred choice. We propose a semi-supervised IDS by extending a data\nanalysis technique known as Logical Analysis of Data, or LAD in short, which\nwas proposed as a supervised learning approach. LAD uses partially defined\nBoolean functions (pdBf) and their extensions to find the positive and the\nnegative patterns from the past observations for classification of future\nobservations. We extend the LAD to make it semi-supervised to design an IDS.\nThe proposed SSIDS consists of two phases: offline and online. The offline\nphase builds the classifier by identifying the behavior patterns of normal and\nabnormal network usage. Later, these patterns are transformed into rules for\nclassification and the rules are used during the online phase for the detection\nof abnormal network behaviors. The performance of the proposed SSIDS is far\nbetter than the existing semi-supervised IDSs and comparable with the\nsupervised IDSs as evident from the experimental results.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 05:32:41 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Das", "Tanmoy Kanti", ""], ["Gangopadhyay", "S.", ""], ["Zhou", "Jianying", ""]]}, {"id": "2007.10650", "submitter": "Xiaohan Hao", "authors": "Xiaohan Hao, Wei Ren, Ruoting Xiong, Xianghan Zheng, Tianqing Zhu,\n  Neal N. Xiong", "title": "Fair and autonomous sharing of federate learning models in mobile\n  Internet of Things", "comments": "We found that there are some algorithm errors in our scheme, which\n  need to be modified. We need to revise our paper and resubmit it in the\n  future", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federate learning can conduct machine learning as well as protect the privacy\nof self-owned training data on corresponding ends, instead of having to upload\nto a central trusted data aggregation server. In mobile scenarios, a\ncentralized trusted server may not be existing, and even though it exists, the\ndelay will not be manageable, e.g., smart driving cars. Thus, mobile federate\nlearning at the edge with privacy-awareness is attracted more and more\nattentions. It then imposes a problem - after data are trained on a mobile\nterminal to obtain a learned model, how to share the model parameters among\nothers to create more accurate and robust accumulative final model. This kind\nof model sharing confronts several challenges, e.g., the sharing must be\nconducted without a third trusted party (autonomously), and the sharing must be\nfair as model training (by training data)is valuable. To tackle the above\nchallenges, we propose a smart contract and IPFS (Inter-Planetary File System)\nbased model sharing protocol and algorithms to address the challenges. The\nproposed protocol does not rely on a trusted third party, where\nindividual-learned models are shared/stored in corresponding ends. Conducted\nthrough extensive experiments, three main steps of the proposed protocol are\nevaluated. The average executive time of the three steps are 0.059s, 0.060s and\n0.032s, demonstrating its efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 08:09:06 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 09:49:57 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Hao", "Xiaohan", ""], ["Ren", "Wei", ""], ["Xiong", "Ruoting", ""], ["Zheng", "Xianghan", ""], ["Zhu", "Tianqing", ""], ["Xiong", "Neal N.", ""]]}, {"id": "2007.10752", "submitter": "Alptekin Temizel", "authors": "Kaan Furkan Alt{\\i}nok, Af\\c{s}in Peker, Alptekin Temizel", "title": "Bit-level Parallelization of 3DES Encryption on GPU", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Triple DES (3DES) is a standard fundamental encryption algorithm, used in\nseveral electronic payment applications and web browsers. In this paper, we\npropose a parallel implementation of 3DES on GPU. Since 3DES encrypts data with\n64-bit blocks, our approach considers each 64-bit block a kernel block and\nassign a separate thread to process each bit. Algorithm's permutation\noperations, XOR operations, and S-box operations are done in parallel within\nthese kernel blocks. The implementation benefits from the use of constant and\nshared memory types to optimize memory access. The results show an average\n10.70x speed-up against the baseline multi-threaded CPU implementation. The\nimplementation is publicly available at\nhttps://github.com/kaanfurkan35/3DES_GPU\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 12:28:48 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Alt\u0131nok", "Kaan Furkan", ""], ["Peker", "Af\u015fin", ""], ["Temizel", "Alptekin", ""]]}, {"id": "2007.10755", "submitter": "Yao Wang", "authors": "Yao Wang and Zhengtai Chang", "title": "Authentication against Man-in-the-Middle Attack with a Time-variant\n  Reconfigurable Dual-LFSR-based Arbiter PUF", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the expansion of the Internet of Things industry, the information\nsecurity of Internet of Things devices attracts much attention. Traditional\nencryption algorithms require sensitive information such as keys to be stored\nin memory, and also need the support of operating system, which is obviously\nunacceptable for resource-constrained Internet of Things terminals. Physical\nnot cloning function by extracting the chip is inevitable in the process of\nmanufacturing process deviation, the introduction of the corresponding function\nrelationship between incentive and response, not to need the storage user\nsensitive information, and only when electricity will respond, in power\nresponse immediately disappear, this can save a lot of resources of equipment\nand the power consumption. However, PUF is vulnerable to modeling attacks, and\nthe traditional methods such as the challenge obfuscation method are\ntime-invariant, which is equivalent to adding a fixed function to the front\nstage of a traditional APUF circuit. Therefore, it can be potentially modelling\nattacked with sufficient CRPs. In order to further enhance APUF circuit\nresistance to modelling attack, this paper proposes a dual-LFSR-based APUF\ncircuit with time-variant challenge obfuscation. Besides, traditional\nauthentication scheme generally adopts the one-time key scheme to enhance\nresistance to man-in-the-middle attack. The two-time authentication scheme\nproposed in this paper can improve the ability of RFID system to resist\nman-in-the-middle attack without sacrificing CRPs.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 12:33:29 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Wang", "Yao", ""], ["Chang", "Zhengtai", ""]]}, {"id": "2007.10760", "submitter": "Yansong Gao Dr", "authors": "Yansong Gao, Bao Gia Doan, Zhi Zhang, Siqi Ma, Jiliang Zhang, Anmin\n  Fu, Surya Nepal, and Hyoungshick Kim", "title": "Backdoor Attacks and Countermeasures on Deep Learning: A Comprehensive\n  Review", "comments": "29 pages, 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work provides the community with a timely comprehensive review of\nbackdoor attacks and countermeasures on deep learning. According to the\nattacker's capability and affected stage of the machine learning pipeline, the\nattack surfaces are recognized to be wide and then formalized into six\ncategorizations: code poisoning, outsourcing, pretrained, data collection,\ncollaborative learning and post-deployment. Accordingly, attacks under each\ncategorization are combed. The countermeasures are categorized into four\ngeneral classes: blind backdoor removal, offline backdoor inspection, online\nbackdoor inspection, and post backdoor removal. Accordingly, we review\ncountermeasures, and compare and analyze their advantages and disadvantages. We\nhave also reviewed the flip side of backdoor attacks, which are explored for i)\nprotecting intellectual property of deep learning models, ii) acting as a\nhoneypot to catch adversarial example attacks, and iii) verifying data deletion\nrequested by the data contributor.Overall, the research on defense is far\nbehind the attack, and there is no single defense that can prevent all types of\nbackdoor attacks. In some cases, an attacker can intelligently bypass existing\ndefenses with an adaptive attack. Drawing the insights from the systematic\nreview, we also present key areas for future research on the backdoor, such as\nempirical security evaluations from physical trigger attacks, and in\nparticular, more efficient and practical countermeasures are solicited.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 12:49:12 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 09:57:20 GMT"}, {"version": "v3", "created": "Sun, 2 Aug 2020 08:38:25 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Gao", "Yansong", ""], ["Doan", "Bao Gia", ""], ["Zhang", "Zhi", ""], ["Ma", "Siqi", ""], ["Zhang", "Jiliang", ""], ["Fu", "Anmin", ""], ["Nepal", "Surya", ""], ["Kim", "Hyoungshick", ""]]}, {"id": "2007.10987", "submitter": "Heiko Ludwig", "authors": "Heiko Ludwig, Nathalie Baracaldo, Gegi Thomas, Yi Zhou, Ali Anwar,\n  Shashank Rajamoni, Yuya Ong, Jayaram Radhakrishnan, Ashish Verma, Mathieu\n  Sinn, Mark Purcell, Ambrish Rawat, Tran Minh, Naoise Holohan, Supriyo\n  Chakraborty, Shalisha Whitherspoon, Dean Steuer, Laura Wynter, Hifaz Hassan,\n  Sean Laguna, Mikhail Yurochkin, Mayank Agarwal, Ebube Chuba, Annie Abay", "title": "IBM Federated Learning: an Enterprise Framework White Paper V0.1", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is an approach to conduct machine learning without\ncentralizing training data in a single place, for reasons of privacy,\nconfidentiality or data volume. However, solving federated machine learning\nproblems raises issues above and beyond those of centralized machine learning.\nThese issues include setting up communication infrastructure between parties,\ncoordinating the learning process, integrating party results, understanding the\ncharacteristics of the training data sets of different participating parties,\nhandling data heterogeneity, and operating with the absence of a verification\ndata set.\n  IBM Federated Learning provides infrastructure and coordination for federated\nlearning. Data scientists can design and run federated learning jobs based on\nexisting, centralized machine learning models and can provide high-level\ninstructions on how to run the federation. The framework applies to both Deep\nNeural Networks as well as ``traditional'' approaches for the most common\nmachine learning libraries. {\\proj} enables data scientists to expand their\nscope from centralized to federated machine learning, minimizing the learning\ncurve at the outset while also providing the flexibility to deploy to different\ncompute environments and design custom fusion algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 05:32:00 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Ludwig", "Heiko", ""], ["Baracaldo", "Nathalie", ""], ["Thomas", "Gegi", ""], ["Zhou", "Yi", ""], ["Anwar", "Ali", ""], ["Rajamoni", "Shashank", ""], ["Ong", "Yuya", ""], ["Radhakrishnan", "Jayaram", ""], ["Verma", "Ashish", ""], ["Sinn", "Mathieu", ""], ["Purcell", "Mark", ""], ["Rawat", "Ambrish", ""], ["Minh", "Tran", ""], ["Holohan", "Naoise", ""], ["Chakraborty", "Supriyo", ""], ["Whitherspoon", "Shalisha", ""], ["Steuer", "Dean", ""], ["Wynter", "Laura", ""], ["Hassan", "Hifaz", ""], ["Laguna", "Sean", ""], ["Yurochkin", "Mikhail", ""], ["Agarwal", "Mayank", ""], ["Chuba", "Ebube", ""], ["Abay", "Annie", ""]]}, {"id": "2007.11099", "submitter": "Mario Gleirscher", "authors": "Mario Gleirscher and Nikita Johnson and Panayiotis Karachristou and\n  Radu Calinescu and James Law and John Clark", "title": "Challenges in the Safety-Security Co-Assurance of Collaborative\n  Industrial Robots", "comments": "23 pages, 4 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coordinated assurance of interrelated critical properties, such as system\nsafety and cyber-security, is one of the toughest challenges in critical\nsystems engineering. In this chapter, we summarise approaches to the\ncoordinated assurance of safety and security. Then, we highlight the state of\nthe art and recent challenges in human-robot collaboration in manufacturing\nboth from a safety and security perspective. We conclude with a list of\nprocedural and technological issues to be tackled in the coordinated assurance\nof collaborative industrial robots.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 14:34:18 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Gleirscher", "Mario", ""], ["Johnson", "Nikita", ""], ["Karachristou", "Panayiotis", ""], ["Calinescu", "Radu", ""], ["Law", "James", ""], ["Clark", "John", ""]]}, {"id": "2007.11115", "submitter": "Jinhyun So", "authors": "Jinhyun So, Basak Guler, A. Salman Avestimehr", "title": "Byzantine-Resilient Secure Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure federated learning is a privacy-preserving framework to improve\nmachine learning models by training over large volumes of data collected by\nmobile users. This is achieved through an iterative process where, at each\niteration, users update a global model using their local datasets. Each user\nthen masks its local model via random keys, and the masked models are\naggregated at a central server to compute the global model for the next\niteration. As the local models are protected by random masks, the server cannot\nobserve their true values. This presents a major challenge for the resilience\nof the model against adversarial (Byzantine) users, who can manipulate the\nglobal model by modifying their local models or datasets. Towards addressing\nthis challenge, this paper presents the first single-server Byzantine-resilient\nsecure aggregation framework (BREA) for secure federated learning. BREA is\nbased on an integrated stochastic quantization, verifiable outlier detection,\nand secure model aggregation approach to guarantee Byzantine-resilience,\nprivacy, and convergence simultaneously. We provide theoretical convergence and\nprivacy guarantees and characterize the fundamental trade-offs in terms of the\nnetwork size, user dropouts, and privacy protection. Our experiments\ndemonstrate convergence in the presence of Byzantine users, and comparable\naccuracy to conventional federated learning benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 22:15:11 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 21:57:10 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["So", "Jinhyun", ""], ["Guler", "Basak", ""], ["Avestimehr", "A. Salman", ""]]}, {"id": "2007.11210", "submitter": "Benjamin Zi Hao Zhao", "authors": "Benjamin Zi Hao Zhao, Hassan Jameel Asghar, Mohamed Ali Kaafar,\n  Francesca Trevisan and Haiyue Yuan", "title": "Exploiting Behavioral Side-Channels in Observation Resilient Cognitive\n  Authentication Schemes", "comments": "Accepted into ACM Transactions on Privacy and Security. 32 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observation Resilient Authentication Schemes (ORAS) are a class of shared\nsecret challenge-response identification schemes where a user mentally computes\nthe response via a cognitive function to authenticate herself such that\neavesdroppers cannot readily extract the secret. Security evaluation of ORAS\ngenerally involves quantifying information leaked via observed\nchallenge-response pairs. However, little work has evaluated information leaked\nvia human behavior while interacting with these schemes. A common way to\nachieve observation resilience is by including a modulus operation in the\ncognitive function. This minimizes the information leaked about the secret due\nto the many-to-one map from the set of possible secrets to a given response. In\nthis work, we show that user behavior can be used as a side-channel to obtain\nthe secret in such ORAS. Specifically, the user's eye-movement patterns and\nassociated timing information can deduce whether a modulus operation was\nperformed (a fundamental design element), to leak information about the secret.\nWe further show that the secret can still be retrieved if the deduction is\nerroneous, a more likely case in practice. We treat the vulnerability\nanalytically, and propose a generic attack algorithm that iteratively obtains\nthe secret despite the \"faulty\" modulus information. We demonstrate the attack\non five ORAS, and show that the secret can be retrieved with considerably less\nchallenge-response pairs than non-side-channel attacks (e.g.,\nalgebraic/statistical attacks). In particular, our attack is applicable on\nMod10, a one-time-pad based scheme, for which no non-side-channel attack\nexists. We field test our attack with a small-scale eye-tracking user study.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 05:45:43 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Zhao", "Benjamin Zi Hao", ""], ["Asghar", "Hassan Jameel", ""], ["Kaafar", "Mohamed Ali", ""], ["Trevisan", "Francesca", ""], ["Yuan", "Haiyue", ""]]}, {"id": "2007.11403", "submitter": "Hadi Sehat", "authors": "Hadi Sehat, Elena Pagnin and Daniel E.Lucani", "title": "Yggdrasil: Privacy-aware Dual Deduplication in Multi Client Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes Yggdrasil, a protocol for privacy-aware dual data\ndeduplication in multi client settings. Yggdrasil is designed to reduce the\ncloud storage space while safeguarding the privacy of the client's outsourced\ndata. Yggdrasil combines three innovative tools to achieve this goal. First,\ngeneralized deduplication, an emerging technique to reduce data footprint.\nSecond, non-deterministic transformations that are described compactly and\nimprove the degree of data compression in the Cloud (across users). Third, data\npreprocessing in the clients in the form of lightweight, privacy-driven\ntransformations prior to upload. This guarantees that an honest-but-curious\nCloud service trying to retrieve the client's actual data will face a high\ndegree of uncertainty as to what the original data is. We provide a\nmathematical analysis of the measure of uncertainty as well as the compression\npotential of our protocol. Our experiments with a HDFS log data set shows that\n49% overall compression can be achieved, with clients storing only 12% for\nprivacy and the Cloud storing the rest. This is achieved while ensuring that\neach fragment uploaded to the Cloud would have 10^296 possible original strings\nfrom the client. Higher uncertainty is possible, with some reduction of\ncompression potential.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 13:08:32 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Sehat", "Hadi", ""], ["Pagnin", "Elena", ""], ["Lucani", "Daniel E.", ""]]}, {"id": "2007.11427", "submitter": "Karl Norrman", "authors": "Karl Norrman, Vaishnavi Sundararajan and Alessandro Bruni", "title": "Formal Analysis of EDHOC Key Establishment for Constrained IoT Devices", "comments": "12 pages; version 3 is the version accepted to SECRYPT 2021", "journal-ref": "In Proceedings of the 18th International Conference on Security\n  and Cryptography (2021), ISBN 978-989-758-524-1, ISSN 2184-7711, pages\n  210-221", "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constrained IoT devices are becoming ubiquitous in society and there is a\nneed for secure communication protocols that respect the constraints under\nwhich these devices operate. EDHOC is an authenticated key establishment\nprotocol for constrained IoT devices, currently being standardized by the\nInternet Engineering Task Force (IETF). A rudimentary version of EDHOC with\nonly two key establishment methods was formally analyzed in 2018. Since then,\nthe protocol has evolved significantly and several new key establishment\nmethods have been added. In this paper, we present a formal analysis of all\nEDHOC methods in an enhanced symbolic Dolev-Yao model using the Tamarin tool.\nWe show that not all methods satisfy the authentication notion injective of\nagreement, but that they all do satisfy a notion of implicit authentication, as\nwell as Perfect Forward Secrecy (PFS) of the session key material. We identify\nother weaknesses to which we propose improvements. For example, a party may\nintend to establish a session key with a certain peer, but end up establishing\nit with another, trusted but compromised, peer. We communicated our findings\nand proposals to the IETF, which has incorporated some of these in newer\nversions of the standard.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 13:35:49 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 17:46:56 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 13:41:41 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Norrman", "Karl", ""], ["Sundararajan", "Vaishnavi", ""], ["Bruni", "Alessandro", ""]]}, {"id": "2007.11480", "submitter": "Tiantian Gong", "authors": "Tiantian Gong, Mohsen Minaei, Wenhai Sun, Aniket Kate", "title": "Towards Overcoming the Undercutting Problem", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For Bitcoin and similar cryptocurrencies, their mining processes are\ncurrently incentivized with fixed block rewards and voluntary transaction fees.\nHowever, the block rewards are supposed to vanish gradually and the remaining\nincentive of transaction fees is optional and arbitrary. Under those\ncircumstances, Carlsten et al.[CCS~2016] find that an interesting undercutting\nattack, where the attacker deliberately forks an existing chain by leaving\nwealthy transactions unclaimed to attract petty complaint miners to its fork,\ncan become the equilibrium strategy for miners. Motivated by similar\nphenomenons in economics, we take a closer look at the undercutting analysis\nand find the result to be questionable: In [CCS~2016], fees are accumulated at\na fixed rate and miners can collect all unclaimed fees regardless of block size\nlimit, which is often not feasible in practice. Besides, ignoring a potentially\nlarge amount of fees unclaimable in a single block can inaccurately inflate the\nprofitability of undercutting.\n  In this work, we define a model that considers claimable fees based on\navailable transactions that can be assembled into the block size limit and\nupgrades petty compliant miners to be rational where they decide whether to\nmove to other chains subject to expected returns from different choices. In\nthis new model, we first identify the conditions that are necessary to make\nundercutting profitable. Second, we propose a defense against undercutting by\nmanipulating transactions selected into the new block to invalidate the\nabove-identified conditions. Finally, we complement the above analytical\nresults with an experimental analysis over Bitcoin and Monero. We demonstrate\nthat our conditions for undercutting to be profitable are effective (an\nincrease of 0.5-4.5% in Bitcoin and 8% in Monero) and the avoidance technique\nfulfills its purpose of allowing miners to earn around fair shares.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 15:01:56 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 19:47:50 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Gong", "Tiantian", ""], ["Minaei", "Mohsen", ""], ["Sun", "Wenhai", ""], ["Kate", "Aniket", ""]]}, {"id": "2007.11481", "submitter": "Billy Bob Brumley", "authors": "Dmitry Belyavsky, Billy Bob Brumley, Jes\\'us-Javier Chi-Dom\\'inguez,\n  Luis Rivera-Zamarripa, Igor Ustinov", "title": "Set It and Forget It! Turnkey ECC for Instant Integration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Historically, Elliptic Curve Cryptography (ECC) is an active field of applied\ncryptography where recent focus is on high speed, constant time, and formally\nverified implementations. While there are a handful of outliers where all these\nconcepts join and land in real-world deployments, these are generally on a\ncase-by-case basis: e.g.\\ a library may feature such X25519 or P-256 code, but\nnot for all curves. In this work, we propose and implement a methodology that\nfully automates the implementation, testing, and integration of ECC stacks with\nthe above properties. We demonstrate the flexibility and applicability of our\nmethodology by seamlessly integrating into three real-world projects: OpenSSL,\nMozilla's NSS, and the GOST OpenSSL Engine, achieving roughly 9.5x, 4.5x,\n13.3x, and 3.7x speedup on any given curve for key generation, key agreement,\nsigning, and verifying, respectively. Furthermore, we showcase the efficacy of\nour testing methodology by uncovering flaws and vulnerabilities in OpenSSL, and\na specification-level vulnerability in a Russian standard. Our work bridges the\ngap between significant applied cryptography research results and deployed\nsoftware, fully automating the process.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 15:04:17 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Belyavsky", "Dmitry", ""], ["Brumley", "Billy Bob", ""], ["Chi-Dom\u00ednguez", "Jes\u00fas-Javier", ""], ["Rivera-Zamarripa", "Luis", ""], ["Ustinov", "Igor", ""]]}, {"id": "2007.11524", "submitter": "Milad Nasr", "authors": "Milad Nasr, Reza Shokri and Amir houmansadr", "title": "Improving Deep Learning with Differential Privacy using Gradient\n  Encoding and Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models leak significant amounts of information about their\ntraining datasets. Previous work has investigated training models with\ndifferential privacy (DP) guarantees through adding DP noise to the gradients.\nHowever, such solutions (specifically, DPSGD), result in large degradations in\nthe accuracy of the trained models. In this paper, we aim at training deep\nlearning models with DP guarantees while preserving model accuracy much better\nthan previous works. Our key technique is to encode gradients to map them to a\nsmaller vector space, therefore enabling us to obtain DP guarantees for\ndifferent noise distributions. This allows us to investigate and choose noise\ndistributions that best preserve model accuracy for a target privacy budget. We\nalso take advantage of the post-processing property of differential privacy by\nintroducing the idea of denoising, which further improves the utility of the\ntrained models without degrading their DP guarantees. We show that our\nmechanism outperforms the state-of-the-art DPSGD; for instance, for the same\nmodel accuracy of $96.1\\%$ on MNIST, our technique results in a privacy bound\nof $\\epsilon=3.2$ compared to $\\epsilon=6$ of DPSGD, which is a significant\nimprovement.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 16:33:14 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Nasr", "Milad", ""], ["Shokri", "Reza", ""], ["houmansadr", "Amir", ""]]}, {"id": "2007.11621", "submitter": "Reihaneh Torkzadehmahani", "authors": "Reihaneh Torkzadehmahani, Reza Nasirigerdeh, David B. Blumenthal, Tim\n  Kacprowski, Markus List, Julian Matschinske, Julian Sp\\\"ath, Nina Kerstin\n  Wenke, B\\'ela Bihari, Tobias Frisch, Anne Hartebrodt, Anne-Christin\n  Hausschild, Dominik Heider, Andreas Holzinger, Walter H\\\"otzendorfer, Markus\n  Kastelitz, Rudolf Mayer, Cristian Nogales, Anastasia Pustozerova, Richard\n  R\\\"ottger, Harald H.H.W. Schmidt, Ameli Schwalber, Christof Tschohl, Andrea\n  Wohner, Jan Baumbach", "title": "Privacy-preserving Artificial Intelligence Techniques in Biomedicine", "comments": "17 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial intelligence (AI) has been successfully applied in numerous\nscientific domains. In biomedicine, AI has already shown tremendous potential,\ne.g. in the interpretation of next-generation sequencing data and in the design\nof clinical decision support systems. However, training an AI model on\nsensitive data raises concerns about the privacy of individual participants.\nFor example, summary statistics of a genome-wide association study can be used\nto determine the presence or absence of an individual in a given dataset. This\nconsiderable privacy risk has led to restrictions in accessing genomic and\nother biomedical data, which is detrimental for collaborative research and\nimpedes scientific progress. Hence, there has been a substantial effort to\ndevelop AI methods that can learn from sensitive data while protecting\nindividuals' privacy. This paper provides a structured overview of recent\nadvances in privacy-preserving AI techniques in biomedicine. It places the most\nimportant state-of-the-art approaches within a unified taxonomy and discusses\ntheir strengths, limitations, and open problems. As the most promising\ndirection, we suggest combining federated machine learning as a more scalable\napproach with other additional privacy preserving techniques. This would allow\nto merge the advantages to provide privacy guarantees in a distributed way for\nbiomedical applications. Nonetheless, more research is necessary as hybrid\napproaches pose new challenges such as additional network or computation\noverhead.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 18:35:55 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 15:32:38 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Torkzadehmahani", "Reihaneh", ""], ["Nasirigerdeh", "Reza", ""], ["Blumenthal", "David B.", ""], ["Kacprowski", "Tim", ""], ["List", "Markus", ""], ["Matschinske", "Julian", ""], ["Sp\u00e4th", "Julian", ""], ["Wenke", "Nina Kerstin", ""], ["Bihari", "B\u00e9la", ""], ["Frisch", "Tobias", ""], ["Hartebrodt", "Anne", ""], ["Hausschild", "Anne-Christin", ""], ["Heider", "Dominik", ""], ["Holzinger", "Andreas", ""], ["H\u00f6tzendorfer", "Walter", ""], ["Kastelitz", "Markus", ""], ["Mayer", "Rudolf", ""], ["Nogales", "Cristian", ""], ["Pustozerova", "Anastasia", ""], ["R\u00f6ttger", "Richard", ""], ["Schmidt", "Harald H. H. W.", ""], ["Schwalber", "Ameli", ""], ["Tschohl", "Christof", ""], ["Wohner", "Andrea", ""], ["Baumbach", "Jan", ""]]}, {"id": "2007.11663", "submitter": "Sanchari Das", "authors": "Reyhan Duezguen, Peter Mayer, Sanchari Das, Melanie Volkamer", "title": "Towards Secure and Usable Authentication for Augmented and Virtual\n  Reality Head-Mounted Displays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Immersive technologies, including augmented and virtual reality (AR & VR)\ndevices, have enhanced digital communication along with a considerable increase\nin digital threats. Thus, authentication becomes critical in AR & VR\ntechnology, particularly in shared spaces. In this paper, we propose applying\nthe ZeTA protocol that allows secure authentication even in shared spaces for\nthe AR & VR context. We explain how it can be used with the available\ninteraction methods provided by Head-Mounted Displays. In future work, our\nresearch goal is to evaluate different designs of ZeTA (e.g., interaction\nmodes) concerning their usability and users' risk perception regarding their\nsecurity - while using a cross-cultural approach.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 20:34:14 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 01:14:27 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Duezguen", "Reyhan", ""], ["Mayer", "Peter", ""], ["Das", "Sanchari", ""], ["Volkamer", "Melanie", ""]]}, {"id": "2007.11687", "submitter": "Georgios Karopoulos", "authors": "Tania Martin, Georgios Karopoulos, Jos\\'e L. Hern\\'andez-Ramos,\n  Georgios Kambourakis, and Igor Nai Fovino", "title": "Demystifying COVID-19 digital contact tracing: A survey on frameworks\n  and mobile apps", "comments": "34 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coronavirus pandemic is a new reality and it severely affects the modus\nvivendi of the international community. In this context, governments are\nrushing to devise or embrace novel surveillance mechanisms and monitoring\nsystems to fight the outbreak. The development of digital tracing apps, which\namong others are aimed at automatising and globalising the prompt alerting of\nindividuals at risk in a privacy-preserving manner is a prominent example of\nthis ongoing effort. Very promptly, a number of digital contact tracing\narchitectures has been sprouted, followed by relevant app implementations\nadopted by governments worldwide. Bluetooth, and specifically its Low Energy\n(BLE) power-conserving variant has emerged as the most promising short-range\nwireless network technology to implement the contact tracing service. This work\noffers the first to our knowledge, full-fledged review of the most concrete\ncontact tracing architectures proposed so far in a global scale. This endeavour\ndoes not only embrace the diverse types of architectures and systems, namely\ncentralised, decentralised, or hybrid, but it equally addresses the client\nside, i.e., the apps that have been already deployed in Europe by each country.\nThere is also a full-spectrum adversary model section, which does not only\namalgamate the previous work in the topic, but also brings new insights and\nangles to contemplate upon.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 21:22:20 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 15:08:59 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Martin", "Tania", ""], ["Karopoulos", "Georgios", ""], ["Hern\u00e1ndez-Ramos", "Jos\u00e9 L.", ""], ["Kambourakis", "Georgios", ""], ["Fovino", "Igor Nai", ""]]}, {"id": "2007.11693", "submitter": "Ye Wang", "authors": "Ye Wang, Shuchin Aeron, Adnan Siraj Rakin, Toshiaki Koike-Akino,\n  Pierre Moulin", "title": "Robust Machine Learning via Privacy/Rate-Distortion Theory", "comments": "9 pages, 2 figures, accepted at 2021 IEEE International Symposium on\n  Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.GT cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust machine learning formulations have emerged to address the prevalent\nvulnerability of deep neural networks to adversarial examples. Our work draws\nthe connection between optimal robust learning and the privacy-utility tradeoff\nproblem, which is a generalization of the rate-distortion problem. The saddle\npoint of the game between a robust classifier and an adversarial perturbation\ncan be found via the solution of a maximum conditional entropy problem. This\ninformation-theoretic perspective sheds light on the fundamental tradeoff\nbetween robustness and clean data performance, which ultimately arises from the\ngeometric structure of the underlying data distribution and perturbation\nconstraints.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 21:34:59 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 21:13:24 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Wang", "Ye", ""], ["Aeron", "Shuchin", ""], ["Rakin", "Adnan Siraj", ""], ["Koike-Akino", "Toshiaki", ""], ["Moulin", "Pierre", ""]]}, {"id": "2007.11707", "submitter": "Wei-Ning Chen", "authors": "Wei-Ning Chen, Peter Kairouz, Ayfer \\\"Ozg\\\"ur", "title": "Breaking the Communication-Privacy-Accuracy Trilemma", "comments": "35 pages, 9 figures, submitted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two major challenges in distributed learning and estimation are 1) preserving\nthe privacy of the local samples; and 2) communicating them efficiently to a\ncentral server, while achieving high accuracy for the end-to-end task. While\nthere has been significant interest in addressing each of these challenges\nseparately in the recent literature, treatments that simultaneously address\nboth challenges are still largely missing. In this paper, we develop novel\nencoding and decoding mechanisms that simultaneously achieve optimal privacy\nand communication efficiency in various canonical settings.\n  In particular, we consider the problems of mean estimation and frequency\nestimation under $\\varepsilon$-local differential privacy and $b$-bit\ncommunication constraints. For mean estimation, we propose a scheme based on\nKashin's representation and random sampling, with order-optimal estimation\nerror under both constraints. For frequency estimation, we present a mechanism\nthat leverages the recursive structure of Walsh-Hadamard matrices and achieves\norder-optimal estimation error for all privacy levels and communication\nbudgets. As a by-product, we also construct a distribution estimation mechanism\nthat is rate-optimal for all privacy regimes and communication constraints,\nextending recent work that is limited to $b=1$ and $\\varepsilon=O(1)$. Our\nresults demonstrate that intelligent encoding under joint privacy and\ncommunication constraints can yield a performance that matches the optimal\naccuracy achievable under either constraint alone.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 22:43:01 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 20:50:56 GMT"}, {"version": "v3", "created": "Tue, 20 Apr 2021 19:13:09 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Chen", "Wei-Ning", ""], ["Kairouz", "Peter", ""], ["\u00d6zg\u00fcr", "Ayfer", ""]]}, {"id": "2007.11709", "submitter": "Fatemeh Vakhshiteh", "authors": "Fatemeh Vakhshiteh, Ahmad Nickabadi and Raghavendra Ramachandra", "title": "Adversarial Attacks against Face Recognition: A Comprehensive Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face recognition (FR) systems have demonstrated outstanding verification\nperformance, suggesting suitability for real-world applications ranging from\nphoto tagging in social media to automated border control (ABC). In an advanced\nFR system with deep learning-based architecture, however, promoting the\nrecognition efficiency alone is not sufficient, and the system should also\nwithstand potential kinds of attacks designed to target its proficiency. Recent\nstudies show that (deep) FR systems exhibit an intriguing vulnerability to\nimperceptible or perceptible but natural-looking adversarial input images that\ndrive the model to incorrect output predictions. In this article, we present a\ncomprehensive survey on adversarial attacks against FR systems and elaborate on\nthe competence of new countermeasures against them. Further, we propose a\ntaxonomy of existing attack and defense methods based on different criteria. We\ncompare attack methods on the orientation and attributes and defense approaches\non the category. Finally, we explore the challenges and potential research\ndirection.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 22:46:00 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 12:05:03 GMT"}, {"version": "v3", "created": "Sat, 6 Feb 2021 14:46:56 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Vakhshiteh", "Fatemeh", ""], ["Nickabadi", "Ahmad", ""], ["Ramachandra", "Raghavendra", ""]]}, {"id": "2007.11778", "submitter": "Celia Ralha", "authors": "Jefferson Viana Fonseca Abreu, Jorge Henrique Cabral Fernandes, Jo\\~ao\n  Jos\\'e Costa Gondim, C\\'elia Ghedini Ralha", "title": "Bot Development for Social Engineering Attacks on Twitter", "comments": "8 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A series of bots performing simulated social engineering attacks using\nphishing in the Twitter platform was developed to identify potentially unsafe\nuser behavior. In this work different bot versions were developed to collect\nfeedback data after stimuli directed to 1,287 twitter accounts for 38\nconsecutive days. The results were not conclusive about the existence of\npreceptors for unsafe behavior, but we conclude that despite Twiter's security\nthis kind of attack is still feasible.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 04:11:30 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Abreu", "Jefferson Viana Fonseca", ""], ["Fernandes", "Jorge Henrique Cabral", ""], ["Gondim", "Jo\u00e3o Jos\u00e9 Costa", ""], ["Ralha", "C\u00e9lia Ghedini", ""]]}, {"id": "2007.11818", "submitter": "Mohammad Behnia", "authors": "Mohammad Behnia, Prateek Sahu, Riccardo Paccagnella, Jiyong Yu, Zirui\n  Zhao, Xiang Zou, Thomas Unterluggauer, Josep Torrellas, Carlos Rozas, Adam\n  Morrison, Frank Mckeen, Fangfei Liu, Ron Gabor, Christopher W. Fletcher,\n  Abhishek Basak, Alaa Alameldeen", "title": "Speculative Interference Attacks: Breaking Invisible Speculation Schemes", "comments": "Updated CR Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent security vulnerabilities that target speculative execution (e.g.,\nSpectre) present a significant challenge for processor design. The highly\npublicized vulnerability uses speculative execution to learn victim secrets by\nchanging cache state. As a result, recent computer architecture research has\nfocused on invisible speculation mechanisms that attempt to block changes in\ncache state due to speculative execution. Prior work has shown significant\nsuccess in preventing Spectre and other vulnerabilities at modest performance\ncosts. In this paper, we introduce speculative interference attacks, which show\nthat prior invisible speculation mechanisms do not fully block these\nspeculation-based attacks. We make two key observations. First, misspeculated\nyounger instructions can change the timing of older, bound-to-retire\ninstructions, including memory operations. Second, changing the timing of a\nmemory operation can change the order of that memory operation relative to\nother memory operations, resulting in persistent changes to the cache state.\nUsing these observations, we demonstrate (among other attack variants) that\nsecret information accessed by mis-speculated instructions can change the order\nof bound-to-retire loads. Load timing changes can therefore leave\nsecret-dependent changes in the cache, even in the presence of invisible\nspeculation mechanisms. We show that this problem is not easy to fix:\nSpeculative interference converts timing changes to persistent cache-state\nchanges, and timing is typically ignored by many cache-based defenses. We\ndevelop a framework to understand the attack and demonstrate concrete\nproof-of-concept attacks against invisible speculation mechanisms. We provide\nsecurity definitions sufficient to block speculative interference attacks;\ndescribe a simple defense mechanism with a high performance cost; and discuss\nhow future research can improve its performance.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 06:36:38 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 20:19:50 GMT"}, {"version": "v3", "created": "Sat, 12 Sep 2020 23:41:46 GMT"}, {"version": "v4", "created": "Fri, 23 Apr 2021 16:30:22 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Behnia", "Mohammad", ""], ["Sahu", "Prateek", ""], ["Paccagnella", "Riccardo", ""], ["Yu", "Jiyong", ""], ["Zhao", "Zirui", ""], ["Zou", "Xiang", ""], ["Unterluggauer", "Thomas", ""], ["Torrellas", "Josep", ""], ["Rozas", "Carlos", ""], ["Morrison", "Adam", ""], ["Mckeen", "Frank", ""], ["Liu", "Fangfei", ""], ["Gabor", "Ron", ""], ["Fletcher", "Christopher W.", ""], ["Basak", "Abhishek", ""], ["Alameldeen", "Alaa", ""]]}, {"id": "2007.11820", "submitter": "Junli Shen", "authors": "Junli Shen, Maocai Xia", "title": "AI Data poisoning attack: Manipulating game AI of Go", "comments": "Fixed some inappropriate information from previous versions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the extensive use of AI in various fields, the issue of AI security has\nbecome more significant. The AI data poisoning attacks will be the most\nthreatening approach against AI security after the adversarial examples. As the\ncontinuous updating of AI applications online, the data pollution models can be\nuploaded by attackers to achieve a certain malicious purpose. Recently, the\nresearch on AI data poisoning attacks is mostly out of practice and use\nself-built experimental environments so that it cannot be as close to reality\nas adversarial example attacks. This article's first contribution is to provide\na solution and a breakthrough for the aforementioned issue with research\nlimitations, to aim at data poisoning attacks that target real businesses, in\nthis case: data poisoning attacks on real Go AI. We install a Trojan virus into\nthe real Go AI that manipulates the AI's behavior. It is the first time that we\nsucceed in manipulating complicated AI and provide a reliable approach to the\nAI data poisoning attack verification method. The method of building Trojan in\nthis article can be expanded to more practical algorithms for other fields such\nas content recommendation, text translation, and intelligent dialogue.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 06:40:46 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 01:59:16 GMT"}, {"version": "v3", "created": "Thu, 30 Jul 2020 02:17:40 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Shen", "Junli", ""], ["Xia", "Maocai", ""]]}, {"id": "2007.11839", "submitter": "Peter Kietzmann", "authors": "Peter Kietzmann, Thomas C. Schmidt, and Matthias W\\\"ahlisch", "title": "A Guideline on Pseudorandom Number Generation (PRNG) in the IoT", "comments": "43 pages, 11 figures, 11 tables", "journal-ref": "ACM Comput. Surv. 54, 6, Article 112 (July 2021), 38 pages", "doi": "10.1145/3453159", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random numbers are an essential input to many functions on the Internet of\nThings (IoT). Common use cases of randomness range from low-level packet\ntransmission to advanced algorithms of artificial intelligence as well as\nsecurity and trust, which heavily rely on unpredictable random sources. In the\nconstrained IoT, though, unpredictable random sources are a challenging desire\ndue to limited resources, deterministic real-time operations, and frequent lack\nof a user interface.\n  In this paper, we revisit the generation of randomness from the perspective\nof an IoT operating system (OS) that needs to support general purpose or\ncrypto-secure random numbers. We analyse the potential attack surface, derive\ncommon requirements, and discuss the potentials and shortcomings of current IoT\nOSs. A systematic evaluation of current IoT hardware components and popular\nsoftware generators based on well-established test suits and on experiments for\nmeasuring performance give rise to a set of clear recommendations on how to\nbuild such a random subsystem and which generators to use.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 08:03:48 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 10:12:12 GMT"}, {"version": "v3", "created": "Wed, 14 Jul 2021 21:12:03 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Kietzmann", "Peter", ""], ["Schmidt", "Thomas C.", ""], ["W\u00e4hlisch", "Matthias", ""]]}, {"id": "2007.11928", "submitter": "Pietro Tedeschi", "authors": "Pietro Tedeschi, Spiridon Bakiras, Roberto Di Pietro", "title": "IoTrace: A Flexible, Efficient, and Privacy-Preserving IoT-enabled\n  Architecture for Contact Tracing", "comments": "7 pages", "journal-ref": null, "doi": "10.1109/MCOM.001.2000729", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact tracing promises to help fight the spread of Covid-19 via an early\ndetection of possible contagion events. To this end, most existing solutions\nshare the following architecture: smartphones continuously broadcast random\nbeacons that are intercepted by nearby devices and stored into their local\ncontact logs. In this paper, we propose an IoT-enabled architecture for contact\ntracing that relaxes the smartphone-centric assumption, and provide a solution\nthat enjoys the following features: (i) it reduces the overhead on the end-user\nto the bare minimum -- the mobile device only broadcasts its beacons; (ii) it\nprovides the user with a degree of privacy not achieved by competing solutions\n-- even in the most privacy adverse scenario, the solution provides\nk-anonymity; and, (iii) it is flexible: the same architecture can be configured\nto support several models -- ranging from the fully decentralized to the fully\ncentralized ones -- and the system parameters can be tuned to support the\ntracing of several social interaction models. We also highlight open issues and\ndiscuss a number of future research directions.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 11:04:41 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 13:35:24 GMT"}, {"version": "v3", "created": "Mon, 2 Nov 2020 07:46:18 GMT"}, {"version": "v4", "created": "Sat, 2 Jan 2021 08:28:18 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Tedeschi", "Pietro", ""], ["Bakiras", "Spiridon", ""], ["Di Pietro", "Roberto", ""]]}, {"id": "2007.11934", "submitter": "Marcel Neunhoeffer", "authors": "Marcel Neunhoeffer, Zhiwei Steven Wu, Cynthia Dwork", "title": "Private Post-GAN Boosting", "comments": null, "journal-ref": "International Conference on Learning Representations, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentially private GANs have proven to be a promising approach for\ngenerating realistic synthetic data without compromising the privacy of\nindividuals. Due to the privacy-protective noise introduced in the training,\nthe convergence of GANs becomes even more elusive, which often leads to poor\nutility in the output generator at the end of training. We propose Private\npost-GAN boosting (Private PGB), a differentially private method that combines\nsamples produced by the sequence of generators obtained during GAN training to\ncreate a high-quality synthetic dataset. To that end, our method leverages the\nPrivate Multiplicative Weights method (Hardt and Rothblum, 2010) to reweight\ngenerated samples. We evaluate Private PGB on two dimensional toy data, MNIST\nimages, US Census data and a standard machine learning prediction task. Our\nexperiments show that Private PGB improves upon a standard private GAN approach\nacross a collection of quality measures. We also provide a non-private variant\nof PGB that improves the data quality of standard GAN training.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 11:20:14 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 16:53:34 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Neunhoeffer", "Marcel", ""], ["Wu", "Zhiwei Steven", ""], ["Dwork", "Cynthia", ""]]}, {"id": "2007.11955", "submitter": "Arindam Pal", "authors": "Rizka Purwanto, Arindam Pal, Alan Blair, Sanjay Jha", "title": "PhishZip: A New Compression-based Algorithm for Detecting Phishing\n  Websites", "comments": "To appear in the proceedings of IEEE Conference on Communications and\n  Network Security (CNS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phishing has grown significantly in the past few years and is predicted to\nfurther increase in the future. The dynamics of phishing introduce challenges\nin implementing a robust phishing detection system and selecting features which\ncan represent phishing despite the change of attack. In this paper, we propose\nPhishZip which is a novel phishing detection approach using a compression\nalgorithm to perform website classification and demonstrate a systematic way to\nconstruct the word dictionaries for the compression models using word\noccurrence likelihood analysis. PhishZip outperforms the use of best-performing\nHTML-based features in past studies, with a true positive rate of 80.04%. We\nalso propose the use of compression ratio as a novel machine learning feature\nwhich significantly improves machine learning based phishing detection over\nprevious studies. Using compression ratios as additional features, the true\npositive rate significantly improves by 30.3% (from 51.47% to 81.77%), while\nthe accuracy increases by 11.84% (from 71.20% to 83.04%).\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 00:32:06 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Purwanto", "Rizka", ""], ["Pal", "Arindam", ""], ["Blair", "Alan", ""], ["Jha", "Sanjay", ""]]}, {"id": "2007.11956", "submitter": "Eduardo Lopez", "authors": "Eduardo Lopez, Kamran Sartipi", "title": "Detecting the Insider Threat with Long Short Term Memory (LSTM) Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information systems enable many organizational processes in every industry.\nThe efficiencies and effectiveness in the use of information technologies\ncreate an unintended byproduct: misuse by existing users or somebody\nimpersonating them - an insider threat. Detecting the insider threat may be\npossible if thorough analysis of electronic logs, capturing user behaviors,\ntakes place. However, logs are usually very large and unstructured, posing\nsignificant challenges for organizations. In this study, we use deep learning,\nand most specifically Long Short Term Memory (LSTM) recurrent networks for\nenabling the detection. We demonstrate through a very large, anonymized dataset\nhow LSTM uses the sequenced nature of the data for reducing the search space\nand making the work of a security analyst more effective.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 23:29:01 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Lopez", "Eduardo", ""], ["Sartipi", "Kamran", ""]]}, {"id": "2007.11981", "submitter": "Kaizheng Liu", "authors": "Kaizheng Liu, Ming Yang, Zhen Ling, Huaiyu Yan, Yue Zhang, Xinwen Fu,\n  and Wei Zhao", "title": "On Manually Reverse Engineering Communication Protocols of Linux Based\n  IoT Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IoT security and privacy has raised grave concerns. Efforts have been made to\ndesign tools to identify and understand vulnerabilities of IoT systems. Most of\nthe existing protocol security analysis techniques rely on a well understanding\nof the underlying communication protocols. In this paper, we systematically\npresent the first manual reverse engineering framework for discovering\ncommunication protocols of embedded Linux based IoT systems. We have\nsuccessfully applied our framework to reverse engineer a number of IoT systems.\nAs an example, we present a detailed use of the framework reverse-engineering\nthe WeMo smart plug communication protocol by extracting the firmware from the\nflash, performing static and dynamic analysis of the firmware and analyzing\nnetwork traffic. The discovered protocol exposes severe design flaws that allow\nattackers to control or deny the service of victim plugs. Our manual reverse\nengineering framework is generic and can be applied to both read-only and\nwritable Embedded Linux filesystems.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 12:54:57 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 14:33:24 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Liu", "Kaizheng", ""], ["Yang", "Ming", ""], ["Ling", "Zhen", ""], ["Yan", "Huaiyu", ""], ["Zhang", "Yue", ""], ["Fu", "Xinwen", ""], ["Zhao", "Wei", ""]]}, {"id": "2007.12070", "submitter": "Chuanshuai Chen", "authors": "Chuanshuai Chen, Jiazhu Dai", "title": "Mitigating backdoor attacks in LSTM-based Text Classification Systems by\n  Backdoor Keyword Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been proved that deep neural networks are facing a new threat called\nbackdoor attacks, where the adversary can inject backdoors into the neural\nnetwork model through poisoning the training dataset. When the input containing\nsome special pattern called the backdoor trigger, the model with backdoor will\ncarry out malicious task such as misclassification specified by adversaries. In\ntext classification systems, backdoors inserted in the models can cause spam or\nmalicious speech to escape detection. Previous work mainly focused on the\ndefense of backdoor attacks in computer vision, little attention has been paid\nto defense method for RNN backdoor attacks regarding text classification. In\nthis paper, through analyzing the changes in inner LSTM neurons, we proposed a\ndefense method called Backdoor Keyword Identification (BKI) to mitigate\nbackdoor attacks which the adversary performs against LSTM-based text\nclassification by data poisoning. This method can identify and exclude\npoisoning samples crafted to insert backdoor into the model from training data\nwithout a verified and trusted dataset. We evaluate our method on four\ndifferent text classification datset: IMDB, DBpedia ontology, 20 newsgroups and\nReuters-21578 dataset. It all achieves good performance regardless of the\ntrigger sentences.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 09:05:16 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 16:05:45 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 03:45:46 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Chen", "Chuanshuai", ""], ["Dai", "Jiazhu", ""]]}, {"id": "2007.12087", "submitter": "James Jordon", "authors": "James Jordon, Daniel Jarrett, Jinsung Yoon, Tavian Barnes, Paul\n  Elbers, Patrick Thoral, Ari Ercole, Cheng Zhang, Danielle Belgrave and\n  Mihaela van der Schaar", "title": "Hide-and-Seek Privacy Challenge", "comments": "19 pages, 5 figures. Part of the NeurIPS 2020 competition track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The clinical time-series setting poses a unique combination of challenges to\ndata modeling and sharing. Due to the high dimensionality of clinical time\nseries, adequate de-identification to preserve privacy while retaining data\nutility is difficult to achieve using common de-identification techniques. An\ninnovative approach to this problem is synthetic data generation. From a\ntechnical perspective, a good generative model for time-series data should\npreserve temporal dynamics, in the sense that new sequences respect the\noriginal relationships between high-dimensional variables across time. From the\nprivacy perspective, the model should prevent patient re-identification by\nlimiting vulnerability to membership inference attacks. The NeurIPS 2020\nHide-and-Seek Privacy Challenge is a novel two-tracked competition to\nsimultaneously accelerate progress in tackling both problems. In our\nhead-to-head format, participants in the synthetic data generation track (i.e.\n\"hiders\") and the patient re-identification track (i.e. \"seekers\") are directly\npitted against each other by way of a new, high-quality intensive care\ntime-series dataset: the AmsterdamUMCdb dataset. Ultimately, we seek to advance\ngenerative techniques for dense and high-dimensional temporal data streams that\nare (1) clinically meaningful in terms of fidelity and predictivity, as well as\n(2) capable of minimizing membership privacy risks in terms of the concrete\nnotion of patient re-identification.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 15:50:59 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 17:10:18 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Jordon", "James", ""], ["Jarrett", "Daniel", ""], ["Yoon", "Jinsung", ""], ["Barnes", "Tavian", ""], ["Elbers", "Paul", ""], ["Thoral", "Patrick", ""], ["Ercole", "Ari", ""], ["Zhang", "Cheng", ""], ["Belgrave", "Danielle", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2007.12105", "submitter": "S{\\o}ren Eller Thomsen", "authors": "S{\\o}ren Eller Thomsen and Bas Spitters", "title": "Formalizing Nakamoto-Style Proof of Stake", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fault-tolerant distributed systems move the trust in a single party to a\nmajority of parties participating in the protocol. This makes blockchain based\ncrypto-currencies possible: they allow parties to agree on a total order of\ntransactions without a trusted third party. To trust a distributed system, the\nsecurity of the protocol and the correctness of the implementation must be\nindisputable.\n  We present the first machine checked proof that guarantees both safety and\nliveness for a consensus algorithm. We verify a Proof of Stake (PoS)\nNakamoto-style blockchain (NSB) protocol, using the foundational proof\nassistant Coq.\n  In particular, we consider a PoS NSB in a synchronous network with a static\nset of corrupted parties. We define execution semantics for this setting and\nprove chain growth, chain quality, and common prefix which together imply both\nsafety and liveness.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 16:12:53 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 10:37:43 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Thomsen", "S\u00f8ren Eller", ""], ["Spitters", "Bas", ""]]}, {"id": "2007.12283", "submitter": "Martin Garriga", "authors": "Martin Garriga, Stefano Dalla Palma, Maximiliano Arias, Alan De\n  Renzis, Remo Pareschi, Damian Andrew Tamburri", "title": "Blockchain and Cryptocurrencies: a Classification and Comparison of\n  Architecture Drivers", "comments": "Accepted for publication at journal Concurrency and Computation:\n  Practice and Experience. Special Issue on distributed large scale\n  applications and environments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain is a decentralized transaction and data management solution, the\ntechnological leap behind the success of Bitcoin and other cryptocurrencies. As\nthe variety of existing blockchains and distributed ledgers continues to\nincrease, adopters should focus on selecting the solution that best fits their\nneeds and the requirements of their decentralized applications, rather than\ndeveloping yet another blockchain from scratch. In this paper we present a\nconceptual framework to aid software architects, developers, and decision\nmakers to adopt the right blockchain technology. The framework exposes the\ninterrelation between technological decisions and architectural features,\ncapturing the knowledge from existing academic literature, industrial products,\ntechnical forums/blogs, and experts' feedback. We empirically show the\napplicability of our framework by dissecting the platforms behind Bitcoin and\nother top 10 cryptocurrencies, aided by a focus group with researchers and\nindustry practitioners. Then, we leverage the framework together with key\nnotions of the Architectural Tradeoff Analysis Method (ATAM) to analyze four\nreal-world blockchain case studies from industry and academia. Results shown\nthat applying our framework leads to a deeper understanding of the\narchitectural tradeoffs, allowing to assess technologies more objectively and\nselect the one that best fit developers needs, ultimately cutting costs,\nreducing time-to-market and accelerating return on investment.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 22:40:23 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Garriga", "Martin", ""], ["Palma", "Stefano Dalla", ""], ["Arias", "Maximiliano", ""], ["De Renzis", "Alan", ""], ["Pareschi", "Remo", ""], ["Tamburri", "Damian Andrew", ""]]}, {"id": "2007.12327", "submitter": "Shana Moothedath", "authors": "Shana Moothedath, Dinuka Sahabandu, Joey Allen, Linda Bushnell, Wenke\n  Lee, Radha Poovendran", "title": "Stochastic Dynamic Information Flow Tracking Game using Supervised\n  Learning for Detecting Advanced Persistent Threats", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced persistent threats (APTs) are organized prolonged cyberattacks by\nsophisticated attackers. Although APT activities are stealthy, they interact\nwith the system components and these interactions lead to information flows.\nDynamic Information Flow Tracking (DIFT) has been proposed as one of the\neffective ways to detect APTs using the information flows. However, wide range\nsecurity analysis using DIFT results in a significant increase in performance\noverhead and high rates of false-positives and false-negatives generated by\nDIFT. In this paper, we model the strategic interaction between APT and DIFT as\na non-cooperative stochastic game. The game unfolds on a state space\nconstructed from an information flow graph (IFG) that is extracted from the\nsystem log. The objective of the APT in the game is to choose transitions in\nthe IFG to find an optimal path in the IFG from an entry point of the attack to\nan attack target. On the other hand, the objective of DIFT is to dynamically\nselect nodes in the IFG to perform security analysis for detecting APT. Our\ngame model has imperfect information as the players do not have information\nabout the actions of the opponent. We consider two scenarios of the game (i)\nwhen the false-positive and false-negative rates are known to both players and\n(ii) when the false-positive and false-negative rates are unknown to both\nplayers. Case (i) translates to a game model with complete information and we\npropose a value iteration-based algorithm and prove the convergence. Case (ii)\ntranslates to a game with unknown transition probabilities. In this case, we\npropose Hierarchical Supervised Learning (HSL) algorithm that integrates a\nneural network, to predict the value vector of the game, with a policy\niteration algorithm to compute an approximate equilibrium. We implemented our\nalgorithms on real attack datasets and validated the performance of our\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 03:09:26 GMT"}, {"version": "v2", "created": "Sat, 26 Jun 2021 00:31:19 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Moothedath", "Shana", ""], ["Sahabandu", "Dinuka", ""], ["Allen", "Joey", ""], ["Bushnell", "Linda", ""], ["Lee", "Wenke", ""], ["Poovendran", "Radha", ""]]}, {"id": "2007.12336", "submitter": "Adnan Siraj Rakin", "authors": "Adnan Siraj Rakin, Zhezhi He, Jingtao Li, Fan Yao, Chaitali\n  Chakrabarti and Deliang Fan", "title": "T-BFA: Targeted Bit-Flip Adversarial Weight Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional Deep Neural Network (DNN) security is mostly related to the\nwell-known adversarial input example attack. Recently, another dimension of\nadversarial attack, namely, attack on DNN weight parameters, has been shown to\nbe very powerful. As a representative one, the Bit-Flip-based adversarial\nweight Attack (BFA) injects an extremely small amount of faults into weight\nparameters to hijack the executing DNN function. Prior works of BFA focus on\nun-targeted attack that can hack all inputs into a random output class by\nflipping a very small number of weight bits stored in computer memory. This\npaper proposes the first work of targeted BFA based (T-BFA) adversarial weight\nattack on DNNs, which can intentionally mislead selected inputs to a target\noutput class. The objective is achieved by identifying the weight bits that are\nhighly associated with classification of a targeted output through a\nclass-dependent weight bit ranking algorithm. Our proposed T-BFA performance is\nsuccessfully demonstrated on multiple DNN architectures for image\nclassification tasks. For example, by merely flipping 27 out of 88 million\nweight bits of ResNet-18, our T-BFA can misclassify all the images from 'Hen'\nclass into 'Goose' class (i.e., 100 % attack success rate) in ImageNet dataset,\nwhile maintaining 59.35 % validation accuracy. Moreover, we successfully\ndemonstrate our T-BFA attack in a real computer prototype system running DNN\ncomputation, with Ivy Bridge-based Intel i7 CPU and 8GB DDR3 memory.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 03:58:25 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 06:16:53 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 04:54:21 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Rakin", "Adnan Siraj", ""], ["He", "Zhezhi", ""], ["Li", "Jingtao", ""], ["Yao", "Fan", ""], ["Chakrabarti", "Chaitali", ""], ["Fan", "Deliang", ""]]}, {"id": "2007.12412", "submitter": "Wojciech Jamroga", "authors": "Wojciech Jamroga, Yan Kim, Damian Kurpiewski, Peter Y. A. Ryan", "title": "Model Checkers Are Cool: How to Model Check Voting Protocols in Uppaal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LO cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The design and implementation of an e-voting system is a challenging task.\nFormal analysis can be of great help here. In particular, it can lead to a\nbetter understanding of how the voting system works, and what requirements on\nthe system are relevant. In this paper, we propose that the state-of-art model\nchecker Uppaal provides a good environment for modelling and preliminary\nverification of voting protocols. To illustrate this, we present an Uppaal\nmodel of Pr\\^et \\`a Voter, together with some natural extensions. We also show\nhow to verify a variant of receipt-freeness, despite the severe limitations of\nthe property specification language in the model checker.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 09:05:06 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 11:28:35 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Jamroga", "Wojciech", ""], ["Kim", "Yan", ""], ["Kurpiewski", "Damian", ""], ["Ryan", "Peter Y. A.", ""]]}, {"id": "2007.12416", "submitter": "Qi Gu", "authors": "Qi Gu, Zhihua Xia, Xingming Sun", "title": "MSPPIR: Multi-source privacy-preserving image retrieval in cloud\n  computing", "comments": "this version adds notations and repair some mistakes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content-Based Image Retrieval (CBIR) techniques have been widely researched\nand in service with the help of cloud computing like Google Images. However,\nthe images always contain rich sensitive information. In this case, the privacy\nprotection become a big problem as the cloud always can't be fully trusted.\nMany privacy-preserving image retrieval schemes have been proposed, in which\nthe image owner can upload the encrypted images to the cloud, and the owner\nhimself or the authorized user can execute the secure retrieval with the help\nof cloud. Nevertheless, few existing researches notice the multi-source scene\nwhich is more practical. In this paper, we analyze the difficulties in\nMulti-Source Privacy-Preserving Image Retrieval (MSPPIR). Then we use the image\nin JPEG-format as the example, to propose a scheme called JES-MSIR, namely a\nnovel JPEG image Encryption Scheme which is made for Multi-Source content-based\nImage Retrieval. JES-MSIR can support the requirements of MSPPIR, including the\nconstant-rounds secure retrieval from multiple sources and the union of\nmultiple sources for better retrieval services. Experiment results and security\nanalysis on the proposed scheme show its efficiency, security and accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 09:13:45 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 04:23:33 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 08:05:11 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Gu", "Qi", ""], ["Xia", "Zhihua", ""], ["Sun", "Xingming", ""]]}, {"id": "2007.12442", "submitter": "Carlos Segarra", "authors": "Carlos Segarra and Ricard Delgado-Gonzalo and Valerio Schiavoni", "title": "MQT-TZ: Hardening IoT Brokers Using ARM TrustZone", "comments": "10 pages, SRDS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The publish-subscribe paradigm is an efficient communication scheme with\nstrong decoupling between the nodes, that is especially fit for large-scale\ndeployments. It adapts natively to very dynamic settings and it is used in a\ndiversity of real-world scenarios, including finance, smart cities, medical\nenvironments, or IoT sensors. Several of the mentioned application scenarios\nrequire increasingly stringent security guarantees due to the sensitive nature\nof the exchanged messages as well as the privacy demands of the\nclients/stakeholders/receivers. MQTT is a lightweight topic-based\npublish-subscribe protocol popular in edge and IoT settings, a de-facto\nstandard widely adopted nowadays by the industry and researchers. However, MQTT\nbrokers must process data in clear, hence exposing a large attack surface. This\npaper presents MQT-TZ, a secure MQTT broker leveraging Arm TrustZone, a trusted\nexecution environment (TEE) commonly found even on inexpensive devices largely\navailable on the market (such as Raspberry Pi units). We define a mutual\nTLS-based handshake and a two-layer encryption for end-to-end security using\nthe TEE as a trusted proxy. The experimental evaluation of our fully\nimplemented prototype with micro-, macro-benchmarks, as well as with real-world\nindustrial workloads from a MedTech use-case, highlights several trade-offs\nusing TrustZone TEE. We report several lessons learned while building and\nevaluating our system. We release MQT-TZ as open-source.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 10:36:58 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 10:06:42 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Segarra", "Carlos", ""], ["Delgado-Gonzalo", "Ricard", ""], ["Schiavoni", "Valerio", ""]]}, {"id": "2007.12477", "submitter": "Joel Colloc", "authors": "Jo\\\"el Colloc (IDEES)", "title": "An Object Oriented Approach For the Protection of Information Systems", "comments": "in French. INFORSID 1991 Paris Pantheon Sorbonne, 1991, Paris, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a protection system making use of encapsulation, messages\ncommunication, interface functions coming from an object oriented model\ndescribed in previous works. Each user represents himself to the system by the\nmean of his \"USER\" object type. The recognition procedure is suitable to every\none's needs. Any user's objects and types are labeled with a personal\nsignature, exclusively provided and known by the system. Administrator's rights\nare restricted to backup procedures. The system verify each messages access, it\nis robust because partitioned, flexible, suitable and psychologically\nacceptable.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 08:12:39 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Colloc", "Jo\u00ebl", "", "IDEES"]]}, {"id": "2007.12501", "submitter": "Bhaskar Ramasubramanian", "authors": "Bhaskar Ramasubramanian, Luyao Niu, Andrew Clark, Linda Bushnell,\n  Radha Poovendran", "title": "Secure Control in Partially Observable Environments to Satisfy LTL\n  Specifications", "comments": "Provisionally accepted to the IEEE Transactions on Automatic Control.\n  arXiv admin note: text overlap with arXiv:1903.06873", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.GT cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the synthesis of control policies for an agent that has to\nsatisfy a temporal logic specification in a partially observable environment,\nin the presence of an adversary. The interaction of the agent (defender) with\nthe adversary is modeled as a partially observable stochastic game. The goal is\nto generate a defender policy to maximize satisfaction of a given temporal\nlogic specification under any adversary policy. The search for policies is\nlimited to the space of finite state controllers, which leads to a tractable\napproach to determine policies. We relate the satisfaction of the specification\nto reaching (a subset of) recurrent states of a Markov chain. We present an\nalgorithm to determine a set of defender and adversary finite state controllers\nof fixed sizes that will satisfy the temporal logic specification, and prove\nthat it is sound. We then propose a value-iteration algorithm to maximize the\nprobability of satisfying the temporal logic specification under finite state\ncontrollers of fixed sizes. Lastly, we extend this setting to the scenario\nwhere the size of the finite state controller of the defender can be increased\nto improve the satisfaction probability. We illustrate our approach with an\nexample.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 23:52:59 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 00:10:34 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Ramasubramanian", "Bhaskar", ""], ["Niu", "Luyao", ""], ["Clark", "Andrew", ""], ["Bushnell", "Linda", ""], ["Poovendran", "Radha", ""]]}, {"id": "2007.12556", "submitter": "Jean-Guillaume Dumas", "authors": "Gaspard Anthoine (CASC), Jean-Guillaume Dumas (CASC), Michael Hanling,\n  M\\'elanie de Jonghe (CASC), Aude Maignan (CASC), Cl\\'ement Pernet (CASC),\n  Daniel Roche", "title": "Dynamic proofs of retrievability with low server storage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proofs of Retrievability (PoRs) are protocols which allow a client to store\ndata remotely and to efficiently ensure, via audits, that the entirety of that\ndata is still intact. A dynamic PoR system also supports efficient retrieval\nand update of any small portion of the data. We propose new, simple protocols\nfor dynamic PoR that are designed for practical efficiency, trading decreased\npersistent storage for increased server computation, and show in fact that this\ntradeoff is inherent via a lower bound proof of time-space for any PoR scheme.\nNotably, ours is the first dynamic PoR which does not require any special\nencoding of the data stored on the server, meaning it can be trivially composed\nwith any database service or with existing techniques for encryption or\nredundancy. Our implementation and deployment on Google Cloud Platform\ndemonstrates our solution is scalable: for example, auditing a 1TB file takes\njust less than 5 minutes and costs less than $0.08 USD. We also present several\nfurther enhancements, reducing the amount of client storage, or the\ncommunication bandwidth, or allowing public verifiability, wherein any\nuntrusted third party may conduct an audit.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 15:02:46 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 08:52:55 GMT"}, {"version": "v3", "created": "Tue, 8 Jun 2021 14:54:55 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Anthoine", "Gaspard", "", "CASC"], ["Dumas", "Jean-Guillaume", "", "CASC"], ["Hanling", "Michael", "", "CASC"], ["de Jonghe", "M\u00e9lanie", "", "CASC"], ["Maignan", "Aude", "", "CASC"], ["Pernet", "Cl\u00e9ment", "", "CASC"], ["Roche", "Daniel", ""]]}, {"id": "2007.12557", "submitter": "Ziyao Liu", "authors": "Ziyao Liu, Ivan Tjuawinata, Chaoping Xing, Kwok-Yan Lam", "title": "MPC-enabled Privacy-Preserving Neural Network Training against Malicious\n  Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of secure multiparty computation (MPC) in machine learning,\nespecially privacy-preserving neural network training, has attracted tremendous\nattention from the research community in recent years. MPC enables several data\nowners to jointly train a neural network while preserving the data privacy of\neach participant. However, most of the previous works focus on semi-honest\nthreat model that cannot withstand fraudulent messages sent by malicious\nparticipants. In this paper, we propose an approach for constructing efficient\n$n$-party protocols for secure neural network training that can provide\nsecurity for all honest participants even when a majority of the parties are\nmalicious. Compared to the other designs that provide semi-honest security in a\ndishonest majority setting, our actively secure neural network training incurs\naffordable efficiency overheads of around 2X and 2.7X in LAN and WAN settings,\nrespectively. Besides, we propose a scheme to allow additive shares defined\nover an integer ring $\\mathbb{Z}_N$ to be securely converted to additive shares\nover a finite field $\\mathbb{Z}_Q$, which may be of independent interest. Such\nconversion scheme is essential in securely and correctly converting shared\nBeaver triples defined over an integer ring generated in the preprocessing\nphase to triples defined over a field to be used in the calculation in the\nonline phase.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 15:03:51 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 07:11:55 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2021 05:51:53 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Liu", "Ziyao", ""], ["Tjuawinata", "Ivan", ""], ["Xing", "Chaoping", ""], ["Lam", "Kwok-Yan", ""]]}, {"id": "2007.12633", "submitter": "Tajdar Jawaid", "authors": "Tajdar Jawaid", "title": "Privacy vs National Security", "comments": null, "journal-ref": null, "doi": "10.14445/22312803/IJCTT-V68I7P101", "report-no": null, "categories": "cs.OH cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are growing concerns and anxiety about privacy among the general public\nespecially after the revelations of former NSA contractor and whistleblowers\nlike Edward Snowden and others. While privacy is the fundamental concept of\nbeing human, the growing tug-of-war between an individuals privacy and freedom\nvs national security has renewed the concerns about where the fine balance\nshould lie between the two. For the first time in history the technological\nadvancement has made the mass data gathering, analysis, and storage a\nfinancially and technologically feasible option for the governments and private\nbusinesses. This has led to the growing interest of governments and security\nagencies around the globe to develop sophisticated algorithms using the power\nof Big-Data, Machine-Learning and Artificial Intelligence. The technology has\nenabled governments and private businesses to collect and store thousands of\ndata points on every individual, which has put an individuals privacy under\nconstant threat. This article analyses the individual's privacy concepts and\nits perceived link with national security. The article will also discuss the\nvarious aspects of privacy and national-security, arguments of both sides and\nwhere a boundary should be drawn between privacy and national security.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 19:35:10 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Jawaid", "Tajdar", ""]]}, {"id": "2007.12674", "submitter": "Audra McMillan", "authors": "Mark Bun and J\\\"org Drechsler and Marco Gaboardi and Audra McMillan", "title": "Controlling Privacy Loss in Survey Sampling (Working Paper)", "comments": "Working paper, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social science and economics research is often based on data collected in\nsurveys. Due to time and budgetary constraints, this data is often collected\nusing complex sampling schemes designed to increase accuracy while reducing the\ncosts of data collection. A commonly held belief is that the sampling process\naffords the data subjects some additional privacy. This intuition has been\nformalized in the differential privacy literature for simple random sampling: a\ndifferentially private mechanism run on a simple random subsample of a\npopulation provides higher privacy guarantees than when run on the entire\npopulation. In this work we initiate the study of the privacy implications of\nmore complicated sampling schemes including cluster sampling and stratified\nsampling. We find that not only do these schemes often not amplify privacy, but\nthat they can result in privacy degradation.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 17:43:08 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Bun", "Mark", ""], ["Drechsler", "J\u00f6rg", ""], ["Gaboardi", "Marco", ""], ["McMillan", "Audra", ""]]}, {"id": "2007.12729", "submitter": "Raphael Fettaya", "authors": "Raphael Fettaya and Yishay Mansour", "title": "Detecting malicious PDF using CNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malicious PDF files represent one of the biggest threats to computer\nsecurity. To detect them, significant research has been done using handwritten\nsignatures or machine learning based on manual feature extraction. Those\napproaches are both time-consuming, require significant prior knowledge and the\nlist of features has to be updated with each newly discovered vulnerability. In\nthis work, we propose a novel algorithm that uses an ensemble of Convolutional\nNeural Network (CNN) on the byte level of the file, without any handcrafted\nfeatures. We show, using a data set of 90000 files downloadable online, that\nour approach maintains a high detection rate (94%) of PDF malware and even\ndetects new malicious files, still undetected by most antiviruses. Using\nautomatically generated features from our CNN network, and applying a\nclustering algorithm, we also obtain high similarity between the antiviruses'\nlabels and the resulting clusters.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 18:27:45 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2020 10:15:50 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Fettaya", "Raphael", ""], ["Mansour", "Yishay", ""]]}, {"id": "2007.12861", "submitter": "Jiaming Zhang", "authors": "Jiaming Zhang, Jitao Sang, Xian Zhao, Xiaowen Huang, Yanfeng Sun,\n  Yongli Hu", "title": "Adversarial Privacy-preserving Filter", "comments": "Accepted by ACM Multimedia 2020", "journal-ref": null, "doi": "10.1145/3394171.3413906", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While widely adopted in practical applications, face recognition has been\ncritically discussed regarding the malicious use of face images and the\npotential privacy problems, e.g., deceiving payment system and causing personal\nsabotage. Online photo sharing services unintentionally act as the main\nrepository for malicious crawler and face recognition applications. This work\naims to develop a privacy-preserving solution, called Adversarial\nPrivacy-preserving Filter (APF), to protect the online shared face images from\nbeing maliciously used.We propose an end-cloud collaborated adversarial attack\nsolution to satisfy requirements of privacy, utility and nonaccessibility.\nSpecifically, the solutions consist of three modules: (1) image-specific\ngradient generation, to extract image-specific gradient in the user end with a\ncompressed probe model; (2) adversarial gradient transfer, to fine-tune the\nimage-specific gradient in the server cloud; and (3) universal adversarial\nperturbation enhancement, to append image-independent perturbation to derive\nthe final adversarial noise. Extensive experiments on three datasets validate\nthe effectiveness and efficiency of the proposed solution. A prototype\napplication is also released for further evaluation.We hope the end-cloud\ncollaborated attack framework could shed light on addressing the issue of\nonline multimedia sharing privacy-preserving issues from user side.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 05:41:00 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 05:12:11 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Zhang", "Jiaming", ""], ["Sang", "Jitao", ""], ["Zhao", "Xian", ""], ["Huang", "Xiaowen", ""], ["Sun", "Yanfeng", ""], ["Hu", "Yongli", ""]]}, {"id": "2007.12892", "submitter": "Iustina Andronic", "authors": "Iustina Andronic and Ludwig K\\\"urzinger and Edgar Ricardo Chavez Rosas\n  and Gerhard Rigoll and Bernhard U. Seeber", "title": "MP3 Compression To Diminish Adversarial Noise in End-to-End Speech\n  Recognition", "comments": "Submitted and accepted at SPECOM 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CR cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio Adversarial Examples (AAE) represent specially created inputs meant to\ntrick Automatic Speech Recognition (ASR) systems into misclassification. The\npresent work proposes MP3 compression as a means to decrease the impact of\nAdversarial Noise (AN) in audio samples transcribed by ASR systems. To this\nend, we generated AAEs with the Fast Gradient Sign Method for an end-to-end,\nhybrid CTC-attention ASR system. Our method is then validated by two objective\nindicators: (1) Character Error Rates (CER) that measure the speech decoding\nperformance of four ASR models trained on uncompressed, as well as\nMP3-compressed data sets and (2) Signal-to-Noise Ratio (SNR) estimated for both\nuncompressed and MP3-compressed AAEs that are reconstructed in the time domain\nby feature inversion. We found that MP3 compression applied to AAEs indeed\nreduces the CER when compared to uncompressed AAEs. Moreover, feature-inverted\n(reconstructed) AAEs had significantly higher SNRs after MP3 compression,\nindicating that AN was reduced. In contrast to AN, MP3 compression applied to\nutterances augmented with regular noise resulted in more transcription errors,\ngiving further evidence that MP3 encoding is effective in diminishing only AN.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 09:25:32 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Andronic", "Iustina", ""], ["K\u00fcrzinger", "Ludwig", ""], ["Rosas", "Edgar Ricardo Chavez", ""], ["Rigoll", "Gerhard", ""], ["Seeber", "Bernhard U.", ""]]}, {"id": "2007.12909", "submitter": "Ehsan Nowroozi", "authors": "Mauro Barni, Kassem Kallas, Ehsan Nowroozi, Benedetta Tondi", "title": "CNN Detection of GAN-Generated Face Images based on Cross-Band\n  Co-occurrences Analysis", "comments": "(6 pages, 2 figures, 4 tables), (IEEE International Workshop on\n  Information Forensics and Security - WIFS 2020, New York, USA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Last-generation GAN models allow to generate synthetic images which are\nvisually indistinguishable from natural ones, raising the need to develop tools\nto distinguish fake and natural images thus contributing to preserve the\ntrustworthiness of digital images. While modern GAN models can generate very\nhigh-quality images with no visible spatial artifacts, reconstruction of\nconsistent relationships among colour channels is expectedly more difficult. In\nthis paper, we propose a method for distinguishing GAN-generated from natural\nimages by exploiting inconsistencies among spectral bands, with specific focus\non the generation of synthetic face images. Specifically, we use cross-band\nco-occurrence matrices, in addition to spatial co-occurrence matrices, as input\nto a CNN model, which is trained to distinguish between real and synthetic\nfaces. The results of our experiments confirm the goodness of our approach\nwhich outperforms a similar detection technique based on intra-band spatial\nco-occurrences only. The performance gain is particularly significant with\nregard to robustness against post-processing, like geometric transformations,\nfiltering and contrast manipulations.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 10:55:04 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 12:43:28 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Barni", "Mauro", ""], ["Kallas", "Kassem", ""], ["Nowroozi", "Ehsan", ""], ["Tondi", "Benedetta", ""]]}, {"id": "2007.12923", "submitter": "Omri Shmueli", "authors": "Omri Shmueli", "title": "Multi-theorem (Malicious) Designated-Verifier NIZK for QMA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first non-interactive zero-knowledge argument system for QMA\nwith multi-theorem security. Our protocol setup constitutes an additional\nimprovement and is constructed in the malicious designated-verifier (MDV-NIZK)\nmodel (Quach, Rothblum, and Wichs, EUROCRYPT 2019), where the setup consists of\na trusted part that includes only a common uniformly random string and an\nuntrusted part of classical public and secret verification keys, which even if\nsampled maliciously by the verifier, the zero knowledge property still holds.\nThe security of our protocol is established under the Learning with Errors\nAssumption. Our main technical contribution is showing a general transformation\nthat compiles any sigma protocol into a reusable MDV-NIZK protocol, using NIZK\nfor NP. Our technique is classical but works for quantum protocols and allows\nthe construction of a reusable MDV-NIZK for QMA.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 13:14:49 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Shmueli", "Omri", ""]]}, {"id": "2007.12934", "submitter": "Reza Shokri", "authors": "Anshul Aggarwal, Trevor E. Carlson, Reza Shokri, Shruti Tople", "title": "SOTERIA: In Search of Efficient Neural Networks for Private Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ML-as-a-service is gaining popularity where a cloud server hosts a trained\nmodel and offers prediction (inference) service to users. In this setting, our\nobjective is to protect the confidentiality of both the users' input queries as\nwell as the model parameters at the server, with modest computation and\ncommunication overhead. Prior solutions primarily propose fine-tuning\ncryptographic methods to make them efficient for known fixed model\narchitectures. The drawback with this line of approach is that the model itself\nis never designed to operate with existing efficient cryptographic\ncomputations. We observe that the network architecture, internal functions, and\nparameters of a model, which are all chosen during training, significantly\ninfluence the computation and communication overhead of a cryptographic method,\nduring inference. Based on this observation, we propose SOTERIA -- a training\nmethod to construct model architectures that are by-design efficient for\nprivate inference. We use neural architecture search algorithms with the dual\nobjective of optimizing the accuracy of the model and the overhead of using\ncryptographic primitives for secure inference. Given the flexibility of\nmodifying a model during training, we find accurate models that are also\nefficient for private computation. We select garbled circuits as our underlying\ncryptographic primitive, due to their expressiveness and efficiency, but this\napproach can be extended to hybrid multi-party computation settings. We\nempirically evaluate SOTERIA on MNIST and CIFAR10 datasets, to compare with the\nprior work. Our results confirm that SOTERIA is indeed effective in balancing\nperformance and accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 13:53:02 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Aggarwal", "Anshul", ""], ["Carlson", "Trevor E.", ""], ["Shokri", "Reza", ""], ["Tople", "Shruti", ""]]}, {"id": "2007.13073", "submitter": "Kai Zhou", "authors": "Kai Zhou and Yevgeniy Vorobeychik", "title": "Robust Collective Classification against Structural Attacks", "comments": "UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collective learning methods exploit relations among data points to enhance\nclassification performance. However, such relations, represented as edges in\nthe underlying graphical model, expose an extra attack surface to the\nadversaries. We study adversarial robustness of an important class of such\ngraphical models, Associative Markov Networks (AMN), to structural attacks,\nwhere an attacker can modify the graph structure at test time. We formulate the\ntask of learning a robust AMN classifier as a bi-level program, where the inner\nproblem is a challenging non-linear integer program that computes optimal\nstructural changes to the AMN. To address this technical challenge, we first\nrelax the attacker problem, and then use duality to obtain a convex quadratic\nupper bound for the robust AMN problem. We then prove a bound on the quality of\nthe resulting approximately optimal solutions, and experimentally demonstrate\nthe efficacy of our approach. Finally, we apply our approach in a transductive\nlearning setting, and show that robust AMN is much more robust than\nstate-of-the-art deep learning methods, while sacrificing little in accuracy on\nnon-adversarial data.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 07:42:45 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Zhou", "Kai", ""], ["Vorobeychik", "Yevgeniy", ""]]}, {"id": "2007.13086", "submitter": "Abigail Goldsteen", "authors": "Abigail Goldsteen, Gilad Ezov, Ron Shmelkin, Micha Moffie, Ariel\n  Farkash", "title": "Anonymizing Machine Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a known tension between the need to analyze personal data to drive\nbusiness and privacy concerns. Many data protection regulations, including the\nEU General Data Protection Regulation (GDPR) and the California Consumer\nProtection Act (CCPA), set out strict restrictions and obligations on companies\nthat collect or process personal data. Moreover, machine learning models\nthemselves can be used to derive personal information, as demonstrated by\nrecent membership and attribute inference attacks. Anonymized data, however, is\nexempt from data protection principles and obligations. Thus, models built on\nanonymized data are also exempt from any privacy obligations, in addition to\nproviding better protection against such attacks on the training data. Learning\non anonymized data typically results in a significant degradation in accuracy.\nWe address this challenge by guiding our anonymization using the knowledge\nencoded within the model, and targeting it to minimize the impact on the\nmodel's accuracy, a process we call accuracy-guided anonymization. We\ndemonstrate that by focusing on the model's accuracy rather than information\nloss, our method outperforms state of the art k-anonymity methods in terms of\nthe achieved utility, in particular with high values of k and large numbers of\nquasi-identifiers. We also demonstrate that our approach achieves similar\nresults in its ability to prevent membership inference attacks as alternative\napproaches based on differential privacy. This shows that model-guided\nanonymization can, in some cases, be a legitimate substitute for such methods,\nwhile averting some of their inherent drawbacks such as complexity, performance\noverhead and being fitted to specific model types. As opposed to methods that\nrely on adding noise during training, our approach does not rely on making any\nmodifications to the training algorithm itself.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 09:29:03 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 13:03:13 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Goldsteen", "Abigail", ""], ["Ezov", "Gilad", ""], ["Shmelkin", "Ron", ""], ["Moffie", "Micha", ""], ["Farkash", "Ariel", ""]]}, {"id": "2007.13113", "submitter": "Jos Craaijo", "authors": "Jos Craaijo", "title": "IdSan: An identity-based memory sanitizer for fuzzing binaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most memory sanitizers work by instrumenting the program at compile time.\nThere are only a handful of memory sanitizers that can sanitize a binary\nprogram without source code. Most are location-based, and are therefore unable\nto detect overflows of global variables or variables on the stack. In this\npaper we introduce an identity-based memory sanitizer for binary AArch64\nprograms which does not need access to the source code. It is able to detect\noverflows of stack- and global variables if the user provides some annotations\nor DWARF debugging information is available, as well as dynamically allocated\nmemory.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 12:14:47 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Craaijo", "Jos", ""]]}, {"id": "2007.13117", "submitter": "Simon Perrault", "authors": "Pavithren V S Pakianathan, Simon Perrault", "title": "Towards Inclusive Design for Privacy and Security Perspectives from an\n  Aging Society", "comments": "4 + 2 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, older adults in Singapore have been massively\nconnecting to the Internet using Smartphone. However due to the ever-changing\nnature of Technology and Cybersecurity landscape, an older adult's limited\ntechnical and Privacy and Security (P & S) knowledge, experience and declining\ncognitive and physical abilities puts them at higher risks. Furthermore\nmainstream smartphone applications, which are generally not designed with older\nadults in mind, could result in mismatched mental models thereby creating\nusability issues. We interviewed 10 older adults above 65 and 10 adults\nassisting them based in Singapore to investigate how smartphone P & S can be\nredesigned inclusively by addressing the needs of older adults and people who\nsupport them. Our results show that socio-cultural factors affected the process\nof getting or providing P & S help, culture and attitude affected learning\nbehaviours and older adults expressed heterogeneous P & S preferences based on\ncontextual factors and level of convenience, however there are opportunities\nfor the mechanisms to be senior-friendly. Due to the complex relationship\nbetween an older adult's milieu and technology, we aim to utilize a technology\nprobe to investigate further and contribute towards an inclusive P & S model.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 12:31:58 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Pakianathan", "Pavithren V S", ""], ["Perrault", "Simon", ""]]}, {"id": "2007.13175", "submitter": "Atsuki Momose", "authors": "Atsuki Momose, Ling Ren", "title": "Optimal Communication Complexity of Authenticated Byzantine Agreement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Byzantine Agreement (BA) is one of the most fundamental problems in\ndistributed computing, and its communication complexity is an important\nefficiency metric. It is well known that quadratic communication is necessary\nfor BA in the worst case due to a lower bound by Dolev and Reischuk. This lower\nbound has been shown to be tight for the unauthenticated setting with $f < n/3$\nby Berman et al. but a considerable gap remains for the authenticated setting\nwith $n/3 \\le f < n/2$.\n  This paper provides two results towards closing this gap. Both protocols have\na quadratic communication complexity and have different trade-offs in\nresilience and assumptions. The first protocol achieves the optimal resilience\nof $f < n/2$ but requires a trusted setup for threshold signature. The second\nprotocol achieves near optimal resilience $f \\le (1/2 - \\varepsilon)n$ in the\nstandard PKI model.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 16:45:50 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 06:25:09 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2020 12:02:23 GMT"}, {"version": "v4", "created": "Fri, 29 Jan 2021 12:59:10 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Momose", "Atsuki", ""], ["Ren", "Ling", ""]]}, {"id": "2007.13182", "submitter": "Molla Rashied Hussein", "authors": "Molla Rashied Hussein, Abdullah Bin Shams, Ehsanul Hoque Apu,\n  Khondaker Abdullah Al Mamun and Mohammad Shahriar Rahman", "title": "Digital Surveillance Systems for Tracing COVID-19: Privacy and Security\n  Challenges with Recommendations", "comments": "Submitted to ICAICT 2020 (2nd International Conference on Advanced\n  Information and Communication Technology) on June 30, 2020 and is under\n  review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coronavirus disease 2019, i.e. COVID-19 has imposed the public health measure\nof keeping social distancing for preventing mass transmission of COVID-19. For\nmonitoring the social distancing and keeping the trace of transmission, we are\nobligated to develop various types of digital surveillance systems, which\ninclude contact tracing systems and drone-based monitoring systems. Due to the\ninconvenience of manual labor, traditional contact tracing systems are\ngradually replaced by the efficient automated contact tracing applications that\nare developed for smartphones. However, the commencement of automated contact\ntracing applications introduces the inevitable privacy and security challenges.\nNevertheless, unawareness and/or lack of smartphone usage among mass people\nlead to drone-based monitoring systems. These systems also invite unwelcomed\nprivacy and security challenges. This paper discusses the recently designed and\ndeveloped digital surveillance system applications with their protocols\ndeployed in several countries around the world. Their privacy and security\nchallenges are discussed as well as analyzed from the viewpoint of privacy\nacts. Several recommendations are suggested separately for automated contact\ntracing systems and drone-based monitoring systems, which could further be\nexplored and implemented afterwards to prevent any possible privacy violation\nand protect an unsuspecting person from any potential cyber attack.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 17:09:58 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Hussein", "Molla Rashied", ""], ["Shams", "Abdullah Bin", ""], ["Apu", "Ehsanul Hoque", ""], ["Mamun", "Khondaker Abdullah Al", ""], ["Rahman", "Mohammad Shahriar", ""]]}, {"id": "2007.13233", "submitter": "Najla Al-Taleb", "authors": "Najla Al-Taleb, Nazar Abbas Saqib, Atta-ur-Rahman, Sujata Dash", "title": "Cyber Threat Intelligence for Secure Smart City", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart city improved the quality of life for the citizens by implementing\ninformation communication technology (ICT) such as the internet of things\n(IoT). Nevertheless, the smart city is a critical environment that needs to\nsecure it is network and data from intrusions and attacks. This work proposes a\nhybrid deep learning (DL) model for cyber threat intelligence (CTI) to improve\nthreats classification performance based on convolutional neural network (CNN)\nand quasi-recurrent neural network (QRNN). We use QRNN to provide a real-time\nthreat classification model. The evaluation results of the proposed model\ncompared to the state-of-the-art models show that the proposed model\noutperformed the other models. Therefore, it will help in classifying the smart\ncity threats in a reasonable time.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 22:39:33 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Al-Taleb", "Najla", ""], ["Saqib", "Nazar Abbas", ""], ["Atta-ur-Rahman", "", ""], ["Dash", "Sujata", ""]]}, {"id": "2007.13272", "submitter": "Bhaskar Ramasubramanian", "authors": "Bhaskar Ramasubramanian, Luyao Niu, Andrew Clark, Linda Bushnell,\n  Radha Poovendran", "title": "Privacy-Preserving Resilience of Cyber-Physical Systems to Adversaries", "comments": "Accepted to the IEEE Conference on Decision and Control (CDC), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.LO cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A cyber-physical system (CPS) is expected to be resilient to more than one\ntype of adversary. In this paper, we consider a CPS that has to satisfy a\nlinear temporal logic (LTL) objective in the presence of two kinds of\nadversaries. The first adversary has the ability to tamper with inputs to the\nCPS to influence satisfaction of the LTL objective. The interaction of the CPS\nwith this adversary is modeled as a stochastic game. We synthesize a controller\nfor the CPS to maximize the probability of satisfying the LTL objective under\nany policy of this adversary. The second adversary is an eavesdropper who can\nobserve labeled trajectories of the CPS generated from the previous step. It\ncould then use this information to launch other kinds of attacks. A labeled\ntrajectory is a sequence of labels, where a label is associated to a state and\nis linked to the satisfaction of the LTL objective at that state. We use\ndifferential privacy to quantify the indistinguishability between states that\nare related to each other when the eavesdropper sees a labeled trajectory. Two\ntrajectories of equal length will be differentially private if they are\ndifferentially private at each state along the respective trajectories. We use\na skewed Kantorovich metric to compute distances between probability\ndistributions over states resulting from actions chosen according to policies\nfrom related states in order to quantify differential privacy. Moreover, we do\nthis in a manner that does not affect the satisfaction probability of the LTL\nobjective. We validate our approach on a simulation of a UAV that has to\nsatisfy an LTL objective in an adversarial environment.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 02:12:21 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Ramasubramanian", "Bhaskar", ""], ["Niu", "Luyao", ""], ["Clark", "Andrew", ""], ["Bushnell", "Linda", ""], ["Poovendran", "Radha", ""]]}, {"id": "2007.13300", "submitter": "Chandra Thapa", "authors": "Chandra Thapa, Jun Wen Tang, Alsharif Abuadbba, Yansong Gao, Seyit\n  Camtepe, Surya Nepal, Mahathir Almashor, Yifeng Zheng", "title": "Evaluation of Federated Learning in Phishing Email Detection", "comments": "Submitted for journal publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of Artificial Intelligence (AI) to detect phishing emails is\nprimarily dependent on large-scale centralized datasets, which opens it up to a\nmyriad of privacy, trust, and legal issues. Moreover, organizations are loathed\nto share emails, given the risk of leakage of commercially sensitive\ninformation. So, it is uncommon to obtain sufficient emails to train a global\nAI model efficiently. Accordingly, privacy-preserving distributed and\ncollaborative machine learning, particularly Federated Learning (FL), is a\ndesideratum. Already prevalent in the healthcare sector, questions remain\nregarding the effectiveness and efficacy of FL-based phishing detection within\nthe context of multi-organization collaborations. To the best of our knowledge,\nthe work herein is the first to investigate the use of FL in email\nanti-phishing. This paper builds upon a deep neural network model, particularly\nRNN and BERT for phishing email detection. It analyzes the FL-entangled\nlearning performance under various settings, including balanced and\nasymmetrical data distribution. Our results corroborate comparable performance\nstatistics of FL in phishing email detection to centralized learning for\nbalanced datasets, and low organization counts. Moreover, we observe a\nvariation in performance when increasing organizational counts. For a fixed\ntotal email dataset, the global RNN based model suffers by a 1.8% accuracy drop\nwhen increasing organizational counts from 2 to 10. In contrast, BERT accuracy\nrises by 0.6% when going from 2 to 5 organizations. However, if we allow\nincreasing the overall email dataset with the introduction of new organizations\nin the FL framework, the organizational level performance is improved by\nachieving a faster convergence speed. Besides, FL suffers in its overall global\nmodel performance due to highly unstable outputs if the email dataset\ndistribution is highly asymmetric.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 03:58:00 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 01:22:50 GMT"}, {"version": "v3", "created": "Fri, 21 May 2021 06:17:50 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Thapa", "Chandra", ""], ["Tang", "Jun Wen", ""], ["Abuadbba", "Alsharif", ""], ["Gao", "Yansong", ""], ["Camtepe", "Seyit", ""], ["Nepal", "Surya", ""], ["Almashor", "Mahathir", ""], ["Zheng", "Yifeng", ""]]}, {"id": "2007.13333", "submitter": "Qiaosheng Zhang", "authors": "Qiaosheng Zhang and Vincent Y. F. Tan", "title": "Covert Identification over Binary-Input Discrete Memoryless Channels", "comments": "Accepted for publication in IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the covert identification problem in which a sender aims\nto reliably convey an identification (ID) message to a set of receivers via a\nbinary-input discrete memoryless channel (BDMC), and simultaneously to\nguarantee that the communication is covert with respect to a warden who\nmonitors the communication via another independent BDMC. We prove a square-root\nlaw for the covert identification problem. This states that an ID message of\nsize \\exp(\\exp(\\Theta(\\sqrt{n}))) can be transmitted over n channel uses. We\nthen characterize the exact pre-constant in the \\Theta(.) notation. This\nconstant is referred to as the covert identification capacity. We show that it\nequals the recently developed covert capacity in the standard covert\ncommunication problem, and somewhat surprisingly, the covert identification\ncapacity can be achieved without any shared key between the sender and\nreceivers. The achievability proof relies on a random coding argument with\npulse-position modulation (PPM), coupled with a second stage which performs\ncode refinements. The converse proof relies on an expurgation argument as well\nas results for channel resolvability with stringent input constraints.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 07:17:50 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 02:05:35 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Zhang", "Qiaosheng", ""], ["Tan", "Vincent Y. F.", ""]]}, {"id": "2007.13372", "submitter": "Dinislam Abdulgalimov", "authors": "Dinislam Abdulgalimov, Timur Osadchiy", "title": "Our House is Our Glassy Castle: Challenges of Pervasive Computing in\n  Private Spaces", "comments": "5 pages, CHI 2017 conference, \"Making Home: Asserting Agency in the\n  Age of IoT\" workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Modern society is going through the transformation under the influence of\nInformation Technologies. Internet of Things as one of the latest facet of it\nbecoming more visible and widely spread. We wish to reflect and discuss the\ncurrent concerns regarding its expansion. Our particular interests lie in the\nincreasing of usability and comfortability through the unification of the IoT\nprotocols and security measures. As well as addressing the privacy concerns and\ndiscussing the possible changings in the perception of privacy and personal\nspace concepts.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 08:42:48 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Abdulgalimov", "Dinislam", ""], ["Osadchiy", "Timur", ""]]}, {"id": "2007.13410", "submitter": "Sean McKeown", "authors": "Christopher Kelly, Nikolaos Pitropakis, Sean McKeown, Costas\n  Lambrinoudakis", "title": "Testing And Hardening IoT Devices Against the Mirai Botnet", "comments": "8 pages, conference paper", "journal-ref": null, "doi": "10.1109/CyberSecurity49315.2020.9138887", "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large majority of cheap Internet of Things (IoT) devices that arrive brand\nnew, and are configured with out-of-the-box settings, are not being properly\nsecured by the manufactures, and are vulnerable to existing malware lurking on\nthe Internet. Among them is the Mirai botnet which has had its source code\nleaked to the world, allowing any malicious actor to configure and unleash it.\nA combination of software assets not being utilised safely and effectively are\nexposing consumers to a full compromise. We configured and attacked 4 different\nIoT devices using the Mirai libraries. Our experiments concluded that three out\nof the four devices were vulnerable to the Mirai malware and became infected\nwhen deployed using their default configuration. This demonstrates that the\noriginal security configurations are not sufficient to provide acceptable\nlevels of protection for consumers, leaving their devices exposed and\nvulnerable. By analysing the Mirai libraries and its attack vectors, we were\nable to determine appropriate device configuration countermeasures to harden\nthe devices against this botnet, which were successfully validated through\nexperimentation.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 10:15:37 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Kelly", "Christopher", ""], ["Pitropakis", "Nikolaos", ""], ["McKeown", "Sean", ""], ["Lambrinoudakis", "Costas", ""]]}, {"id": "2007.13585", "submitter": "Anmin Fu", "authors": "Anmin Fu, Xianglong Zhang, Naixue Xiong, Yansong Gao, Huaqun Wang", "title": "VFL: A Verifiable Federated Learning with Privacy-Preserving for Big\n  Data in Industrial IoT", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the strong analytical ability of big data, deep learning has been\nwidely applied to train the collected data in industrial IoT. However, for\nprivacy issues, traditional data-gathering centralized learning is not\napplicable to industrial scenarios sensitive to training sets. Recently,\nfederated learning has received widespread attention, since it trains a model\nby only relying on gradient aggregation without accessing training sets. But\nexisting researches reveal that the shared gradient still retains the sensitive\ninformation of the training set. Even worse, a malicious aggregation server may\nreturn forged aggregated gradients. In this paper, we propose the VFL,\nverifiable federated learning with privacy-preserving for big data in\nindustrial IoT. Specifically, we use Lagrange interpolation to elaborately set\ninterpolation points for verifying the correctness of the aggregated gradients.\nCompared with existing schemes, the verification overhead of VFL remains\nconstant regardless of the number of participants. Moreover, we employ the\nblinding technology to protect the privacy of the gradients submitted by the\nparticipants. If no more than n-2 of n participants collude with the\naggregation server, VFL could guarantee the encrypted gradients of other\nparticipants not being inverted. Experimental evaluations corroborate the\npractical performance of the presented VFL framework with high accuracy and\nefficiency.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 14:04:42 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 08:12:26 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Fu", "Anmin", ""], ["Zhang", "Xianglong", ""], ["Xiong", "Naixue", ""], ["Gao", "Yansong", ""], ["Wang", "Huaqun", ""]]}, {"id": "2007.13633", "submitter": "Molla Rashied Hussein", "authors": "Molla Rashied Hussein, Ehsanul Hoque Apu, Shahriar Shahabuddin,\n  Abdullah Bin Shams and Russell Kabir", "title": "Overview of digital health surveillance system during COVID-19 pandemic:\n  public health issues and misapprehensions", "comments": "Submitted to the Elsevier Journal of Health Policy and Technology on\n  June 16,2020 and is under review (last update: July 15, 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Without proper medication and vaccination for the COVID-19, many governments\nare using automated digital healthcare surveillance system to prevent and\ncontrol the spread. There is not enough literature explaining the concerns and\nprivacy issues; hence, we have briefly explained the topics in this paper. We\nfocused on digital healthcare surveillance system's privacy concerns and\ndifferent segments. Further research studies should be conducted in different\nsectors. This paper provides an overview based on the published articles, which\nare not focusing on the privacy issues that much. Artificial intelligence and\n5G networks combine the advanced digital healthcare surveillance system;\nwhereas Bluetooth-based contact tracing systems have fewer privacy concerns.\nMore studies are required to find the appropriate digital healthcare\nsurveillance system, which would be ideal for monitoring, controlling, and\npredicting the COVID-19 trajectory.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 15:18:31 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Hussein", "Molla Rashied", ""], ["Apu", "Ehsanul Hoque", ""], ["Shahabuddin", "Shahriar", ""], ["Shams", "Abdullah Bin", ""], ["Kabir", "Russell", ""]]}, {"id": "2007.13639", "submitter": "Pengcheng Xia", "authors": "Pengcheng Xia, Haoyu Wang, Xiapu Luo, Lei Wu, Yajin Zhou, Guangdong\n  Bai, Guoai Xu, Gang Huang, Xuanzhe Liu", "title": "Don't Fish in Troubled Waters! Characterizing Coronavirus-themed\n  Cryptocurrency Scams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As COVID-19 has been spreading across the world since early 2020, a growing\nnumber of malicious campaigns are capitalizing the topic of COVID-19. COVID-19\nthemed cryptocurrency scams are increasingly popular during the pandemic.\nHowever, these newly emerging scams are poorly understood by our community. In\nthis paper, we present the first measurement study of COVID-19 themed\ncryptocurrency scams. We first create a comprehensive taxonomy of COVID-19\nscams by manually analyzing the existing scams reported by users from online\nresources. Then, we propose a hybrid approach to perform the investigation by:\n1) collecting reported scams in the wild; and 2) detecting undisclosed ones\nbased on information collected from suspicious entities (e.g., domains, tweets,\netc). We have collected 195 confirmed COVID-19 cryptocurrency scams in total,\nincluding 91 token scams, 19 giveaway scams, 9 blackmail scams, 14 crypto\nmalware scams, 9 Ponzi scheme scams, and 53 donation scams. We then identified\nover 200 blockchain addresses associated with these scams, which lead to at\nleast 330K US dollars in losses from 6,329 victims. For each type of scams, we\nfurther investigated the tricks and social engineering techniques they used. To\nfacilitate future research, we have released all the well-labelled scams to the\nresearch community.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 15:40:05 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 12:43:09 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Xia", "Pengcheng", ""], ["Wang", "Haoyu", ""], ["Luo", "Xiapu", ""], ["Wu", "Lei", ""], ["Zhou", "Yajin", ""], ["Bai", "Guangdong", ""], ["Xu", "Guoai", ""], ["Huang", "Gang", ""], ["Liu", "Xuanzhe", ""]]}, {"id": "2007.13647", "submitter": "Pranav Singh Kumar", "authors": "Pranav Kumar Singh, Roshan Singh, and Sukumar Nandi", "title": "V-CARE: A Blockchain Based Framework for Secure Vehicle Health Record\n  System", "comments": "The work is published in IEEE COMSOC MMTC Communications - Frontiers\n  Vol. 15, No. 4, July 2020, Page 12-17", "journal-ref": null, "doi": null, "report-no": "https://mmc.committees.comsoc.org/files/2020/07/MMTC_Communication_Frontier_July_2020.pdf", "categories": "cs.DC cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the biggest challenges associated with connected and autonomous\nvehicles (CAVs) is to maintain and make use of vehicles health records (VHR).\nVHR can facilitate different entities to offer various services in a proactive,\ntransparent, secure, reliable and in an efficient manner. The state-of-the-art\nsolutions for maintaining the VHR are centralized in nature, mainly owned by\nmanufacturer and authorized in-vehicle device developers. Owners, drivers, and\nother key service providers have limited accessibility and control to the VHR.\nWe need to change the strategy from single or limited party access to\nmulti-party access to VHR in an secured manner so that all stakeholders of\nintelligent transportation system (ITS) can be benefited from this. Any\nunauthorized attempt to alter the data should also be prevented. Blockchain is\none such potential candidate, which can facilitate the sharing of such data\namong different participating organizations and individuals. For example,\nowners, manufacturers, trusted third parties, road authorities, insurance\ncompanies, charging stations, and car selling ventures can access VHR stored on\nthe blockchain in a permissioned, secured, and with a higher level of\nconfidence. In this paper, a blockchain-based decentralized secure system for\nV-CARE is proposed to manage records in an interoperable framework that leads\nto improved ITS services in terms of safety, availability, reliability,\nefficiency, and maintenance. Insurance based on pay-how-you-drive (PHYD), and\nsale and purchase of used vehicles can also be made more transparent and\nreliable without compromising the confidentiality and security of sensitive\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 09:37:18 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Singh", "Pranav Kumar", ""], ["Singh", "Roshan", ""], ["Nandi", "Sukumar", ""]]}, {"id": "2007.13660", "submitter": "Yuhan Liu", "authors": "Yuhan Liu, Ananda Theertha Suresh, Felix Yu, Sanjiv Kumar, Michael\n  Riley", "title": "Learning discrete distributions: user vs item-level privacy", "comments": "NeurIPS 2020, 38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of the literature on differential privacy focuses on item-level privacy,\nwhere loosely speaking, the goal is to provide privacy per item or training\nexample. However, recently many practical applications such as federated\nlearning require preserving privacy for all items of a single user, which is\nmuch harder to achieve. Therefore understanding the theoretical limit of\nuser-level privacy becomes crucial.\n  We study the fundamental problem of learning discrete distributions over $k$\nsymbols with user-level differential privacy. If each user has $m$ samples, we\nshow that straightforward applications of Laplace or Gaussian mechanisms\nrequire the number of users to be $\\mathcal{O}(k/(m\\alpha^2) +\nk/\\epsilon\\alpha)$ to achieve an $\\ell_1$ distance of $\\alpha$ between the true\nand estimated distributions, with the privacy-induced penalty\n$k/\\epsilon\\alpha$ independent of the number of samples per user $m$. Moreover,\nwe show that any mechanism that only operates on the final aggregate counts\nshould require a user complexity of the same order. We then propose a mechanism\nsuch that the number of users scales as $\\tilde{\\mathcal{O}}(k/(m\\alpha^2) +\nk/\\sqrt{m}\\epsilon\\alpha)$ and hence the privacy penalty is\n$\\tilde{\\Theta}(\\sqrt{m})$ times smaller compared to the standard mechanisms in\ncertain settings of interest. We further show that the proposed mechanism is\nnearly-optimal under certain regimes.\n  We also propose general techniques for obtaining lower bounds on restricted\ndifferentially private estimators and a lower bound on the total variation\nbetween binomial distributions, both of which might be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 16:15:14 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 17:42:38 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2021 22:15:07 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Liu", "Yuhan", ""], ["Suresh", "Ananda Theertha", ""], ["Yu", "Felix", ""], ["Kumar", "Sanjiv", ""], ["Riley", "Michael", ""]]}, {"id": "2007.13733", "submitter": "Song Zhang", "authors": "Song Zhang, Xiaochuan Luo, Eugene Litvinov", "title": "Serverless computing for cloud-based power grid emergency generation\n  dispatch", "comments": null, "journal-ref": null, "doi": "10.1016/j.ijepes.2020.106366", "report-no": null, "categories": "physics.soc-ph cs.CR cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Operating a modern power grid reliably in case of SCADA/EMS failure or amid\ndifficult times like COVID-19 pandemic is a challenging task for grid\noperators. In [11], a PMU-based emergency generation dispatch scheme has been\nproposed to help the system operators with the supply and demand balancing;\nhowever, its realization highly relies on the control center infrastructure for\ncomputing and communication. This work, rather than using the on-premises\nserver and dispatch communication system, proposes and implements a\ncloud-centric serverless architecture to ensure the operation continuity\nregardless of local infrastructure's availability and accessibility. Through\nits prototype implementation and evaluation at ISO New England, the solution\nhas demonstrated two major advantages. Firstly, the cloud infrastructure is\nindependent and fault-tolerant, providing grid monitoring and control\ncapability even when EMS loses the corresponding functionality or when\noperators need to work remotely away from the control center. Secondly, the\noverall design is event-driven using serverless cloud services in response to\nthe SCADA/EMS failure event. Thanks to \"serverless\", the burden of the server\nprovisioning and maintenance can be avoided from the user side. The cost of\nusing public cloud services for this solution is extremely low since it is\narchitected and implemented based on the event-driven Function-as-a-Service\n(FaaS) model. This work also develops a comprehensive cyber security mechanism\nto comply with critical infrastructure requirements for the power grid, which\ncan serve as an exemplary framework for other grid operators to secure their\ncloud services.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 18:13:23 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Zhang", "Song", ""], ["Luo", "Xiaochuan", ""], ["Litvinov", "Eugene", ""]]}, {"id": "2007.13808", "submitter": "Miguel A. Arroyo", "authors": "Mohamed Tarek Ibn Ziad, Miguel A. Arroyo, Simha Sethumadhavan", "title": "SPAM: Stateless Permutation of Application Memory", "comments": "Mohamed Tarek Ibn Ziad and Miguel A. Arroyo both contributed equally\n  to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the Stateless Permutation of Application Memory\n(SPAM), a software defense that enables fine-grained data permutation for C\nprograms. The key benefits include resilience against attacks that directly\nexploit software errors (i.e., spatial and temporal memory safety violations)\nin addition to attacks that exploit hardware vulnerabilities such as ColdBoot,\nRowHammer or hardware side-channels to disclose or corrupt memory using a\nsingle cohesive technique. Unlike prior work, SPAM is stateless by design\nmaking it automatically applicable to multi-threaded applications.\n  We implement SPAM as an LLVM compiler pass with an extension to the\ncompiler-rt runtime. We evaluate it on the C subset of the SPEC2017 benchmark\nsuite and three real-world applications: the Nginx web server, the Duktape\nJavascript interpreter, and the WolfSSL cryptographic library. We further show\nSPAM's scalability by running a multi-threaded benchmark suite. SPAM has\ngreater security coverage and comparable performance overheads to\nstate-of-the-art software techniques for memory safety on contemporary x86_64\nprocessors. Our security evaluation confirms SPAM's effectiveness in preventing\nintra/inter spatial/temporal memory violations by making the attacker success\nchances as low as 1/16!.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 18:46:57 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2020 19:24:59 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 16:08:41 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Ziad", "Mohamed Tarek Ibn", ""], ["Arroyo", "Miguel A.", ""], ["Sethumadhavan", "Simha", ""]]}, {"id": "2007.13850", "submitter": "Pankaj Khatiwada", "authors": "Pankaj Khatiwada, Hari Bhusal, Ayan Chatterjee, Martin W. Gerdess", "title": "A Proposed Access Control-Based Privacy Preservation Model to Share\n  Healthcare Data in Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Healthcare data in cloud computing facilitates the treatment of patients\nefficiently by sharing information about personal health data between the\nhealthcare providers for medical consultation. Furthermore, retaining the\nconfidentiality of data and patients' identity is a another challenging task.\nThis paper presents the concept of an access control-based (AC) privacy\npreservation model for the mutual authentication of users and data owners in\nthe proposed digital system. The proposed model offers a high-security\nguarantee and high efficiency. The proposed digital system consists of four\ndifferent entities, user, data owner, cloud server, and key generation center\n(KGC). This approach makes the system more robust and highly secure, which has\nbeen verified with multiple scenarios. Besides, the proposed model consisted of\nthe setup phase, key generation phase, encryption phase, validation phase,\naccess control phase, and data sharing phase. The setup phases are run by the\ndata owner, which takes input as a security parameter and generates the system\nmaster key and security parameter. Then, in the key generation phase, the\nprivate key is generated by KGC and is stored in the cloud server. After that,\nthe generated private key is encrypted. Then, the session key is generated by\nKGC and granted to the user and cloud server for storing, and then, the results\nare verified in the validation phase using validation messages. Finally, the\ndata is shared with the user and decrypted at the user-end. The proposed model\noutperforms other methods with a maximal genuine data rate of 0.91.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 20:32:51 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Khatiwada", "Pankaj", ""], ["Bhusal", "Hari", ""], ["Chatterjee", "Ayan", ""], ["Gerdess", "Martin W.", ""]]}, {"id": "2007.14030", "submitter": "Neil Shah", "authors": "Neil Shah, Grant Ho, Marco Schweighauser, M.H. Afifi, Asaf Cidon,\n  David Wagner", "title": "A Large-Scale Analysis of Attacker Activity in Compromised Enterprise\n  Accounts", "comments": "Extended report of workshop paper presented at the 1st MLHat Workshop\n  (MLHat Security and ML 2020). KDD, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a large-scale characterization of attacker activity across 111\nreal-world enterprise organizations. We develop a novel forensic technique for\ndistinguishing between attacker activity and benign activity in compromised\nenterprise accounts that yields few false positives and enables us to perform\nfine-grained analysis of attacker behavior. Applying our methods to a set of\n159 compromised enterprise accounts, we quantify the duration of time attackers\nare active in accounts and examine thematic patterns in how attackers access\nand leverage these hijacked accounts. We find that attackers frequently dwell\nin accounts for multiple days to weeks, suggesting that delayed (non-real-time)\ndetection can still provide significant value. Based on an analysis of the\nattackers' timing patterns, we observe two distinct modalities in how attackers\naccess compromised accounts, which could be explained by the existence of a\nspecialized market for hijacked enterprise accounts: where one class of\nattackers focuses on compromising and selling account access to another class\nof attackers who exploit the access such hijacked accounts provide. Ultimately,\nour analysis sheds light on the state of enterprise account hijacking and\nhighlights fruitful directions for a broader space of detection methods,\nranging from new features that home in on malicious account behavior to the\ndevelopment of non-real-time detection methods that leverage malicious activity\nafter an attack's initial point of compromise to more accurately identify\nattacks.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 07:20:37 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Shah", "Neil", ""], ["Ho", "Grant", ""], ["Schweighauser", "Marco", ""], ["Afifi", "M. H.", ""], ["Cidon", "Asaf", ""], ["Wagner", "David", ""]]}, {"id": "2007.14181", "submitter": "Kevin Wallis", "authors": "Kevin Wallis, Jan Stodt, Eugen Jastremskoj and Christoph Reich", "title": "Agreements between Enterprises digitized by Smart Contracts in the\n  Domain of Industry 4.0", "comments": "CCSEA, BIoT, DKMP, CLOUD, NLCAI, SIPRO - 2020 pp. 23-32, 2020. CS &\n  IT - CSCP 2020", "journal-ref": null, "doi": "10.5121/csit.2020.101003", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The digital transformation of companies is expected to increase the digital\ninterconnection between different companies to develop optimized, customized,\nhybrid business models. These cross-company business models require secure,\nreliable, and traceable logging and monitoring of contractually agreed\ninformation sharing between machine tools, operators, and service providers.\nThis paper discusses how the major requirements for building hybrid business\nmodels can be tackled by the blockchain for building a chain of trust and smart\ncontracts for digitized contracts. A machine maintenance use case is used to\ndiscuss the readiness of smart contracts for the automation of workflows\ndefined in contracts. Furthermore, it is shown that the number of failures is\nsignificantly improved by using these contracts and a blockchain.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 13:08:01 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Wallis", "Kevin", ""], ["Stodt", "Jan", ""], ["Jastremskoj", "Eugen", ""], ["Reich", "Christoph", ""]]}, {"id": "2007.14191", "submitter": "Nicolas Papernot", "authors": "Nicolas Papernot, Abhradeep Thakurta, Shuang Song, Steve Chien,\n  \\'Ulfar Erlingsson", "title": "Tempered Sigmoid Activations for Deep Learning with Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because learning sometimes involves sensitive data, machine learning\nalgorithms have been extended to offer privacy for training data. In practice,\nthis has been mostly an afterthought, with privacy-preserving models obtained\nby re-running training with a different optimizer, but using the model\narchitectures that already performed well in a non-privacy-preserving setting.\nThis approach leads to less than ideal privacy/utility tradeoffs, as we show\nhere. Instead, we propose that model architectures are chosen ab initio\nexplicitly for privacy-preserving training.\n  To provide guarantees under the gold standard of differential privacy, one\nmust bound as strictly as possible how individual training points can possibly\naffect model updates. In this paper, we are the first to observe that the\nchoice of activation function is central to bounding the sensitivity of\nprivacy-preserving deep learning. We demonstrate analytically and\nexperimentally how a general family of bounded activation functions, the\ntempered sigmoids, consistently outperform unbounded activation functions like\nReLU. Using this paradigm, we achieve new state-of-the-art accuracy on MNIST,\nFashionMNIST, and CIFAR10 without any modification of the learning procedure\nfundamentals or differential privacy analysis.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 13:19:45 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Papernot", "Nicolas", ""], ["Thakurta", "Abhradeep", ""], ["Song", "Shuang", ""], ["Chien", "Steve", ""], ["Erlingsson", "\u00dalfar", ""]]}, {"id": "2007.14195", "submitter": "Jan Stodt", "authors": "Jan Stodt, Christoph Reich", "title": "Data Confidentiality In P2P Communication And Smart Contracts Of\n  Blockchain In Industry 4.0", "comments": "10 pages, 4 figures", "journal-ref": "10th International Conference on Computer Science, Engineering and\n  Applications (CCSEA 2020), July 25~26, 2020, London, United Kingdom", "doi": "10.5121/csit.2020.101001", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Increased collaborative production and dynamic selection of production\npartners within industry 4.0 manufacturing leads to ever-increasing automatic\ndata exchange between companies. Automatic and unsupervised data exchange\ncreates new attack vectors, which could be used by a malicious insider to leak\nsecrets via an otherwise considered secure channel without anyone noticing. In\nthis paper we reflect upon approaches to prevent the exposure of secret data\nvia blockchain technology, while also providing auditable proof of data\nexchange. We show that previous blockchain based privacy protection approaches\noffer protection, but give the control of the data to (potentially not\ntrustworthy) third parties, which also can be considered a privacy violation.\nThe approach taken in this paper is not utilize centralized data storage for\ndata. It realizes data confidentiality of P2P communication and data processing\nin smart contracts of blockchains.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 13:23:15 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Stodt", "Jan", ""], ["Reich", "Christoph", ""]]}, {"id": "2007.14266", "submitter": "Jun Xu", "authors": "Chengbin Pang, Ruotong Yu, Yaohui Chen, Eric Koskinen, Georgios\n  Portokalidis, Bing Mao, Jun Xu", "title": "SoK: All You Ever Wanted to Know About x86/x64 Binary Disassembly But\n  Were Afraid to Ask", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disassembly of binary code is hard, but necessary for improving the security\nof binary software. Over the past few decades, research in binary disassembly\nhas produced many tools and frameworks, which have been made available to\nresearchers and security professionals. These tools employ a variety of\nstrategies that grant them different characteristics. The lack of\nsystematization, however, impedes new research in the area and makes selecting\nthe right tool hard, as we do not understand the strengths and weaknesses of\nexisting tools. In this paper, we systematize binary disassembly through the\nstudy of nine popular, open-source tools. We couple the manual examination of\ntheir code bases with the most comprehensive experimental evaluation (thus far)\nusing 3,788 binaries. Our study yields a comprehensive description and\norganization of strategies for disassembly, classifying them as either\nalgorithm or else heuristic. Meanwhile, we measure and report the impact of\nindividual algorithms on the results of each tool. We find that while\nprincipled algorithms are used by all tools, they still heavily rely on\nheuristics to increase code coverage. Depending on the heuristics used,\ndifferent coverage-vs-correctness trade-offs come in play, leading to tools\nwith different strengths and weaknesses. We envision that these findings will\nhelp users pick the right tool and assist researchers in improving binary\ndisassembly.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 14:22:59 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Pang", "Chengbin", ""], ["Yu", "Ruotong", ""], ["Chen", "Yaohui", ""], ["Koskinen", "Eric", ""], ["Portokalidis", "Georgios", ""], ["Mao", "Bing", ""], ["Xu", "Jun", ""]]}, {"id": "2007.14298", "submitter": "Nitin Verma", "authors": "Hemant Rana, Nitin Verma", "title": "Enhanced Quantum Key Distribution using Hybrid Channels and Natural\n  Random Numbers", "comments": "3 figures; 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since the introduction of quantum computation by Richard Feynman in 1982,\nQuantum computation has shown exemplary results in various applications of\ncomputer science including unstructured database search, factorization,\nmolecular simulations to name a few. Some of the recent developments include\nquantum machine learning, quantum neural networks, quantum walks on graphs,\nfault tolerant scalable quantum computers using error correction codes etc. One\nof the crucial modern applications of quantum information is quantum\ncryptography and secure key distribution over quantum channels which have\nseveral advantages over classical channels, especially detection of\neavesdropping. Based on such properties of quantum systems and quantum\nchannels, In this paper we propose three secure key distribution protocols\nbased on a blend of classical and quantum channels. Also the proposed protocols\nexploits the property of quantum computers to generate natural random numbers\nthat can be easily transmitted using a single qubit over a quantum channel and\ncan be used for distributing keys to the involved parties in a communication\nnetwork.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 15:14:59 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Rana", "Hemant", ""], ["Verma", "Nitin", ""]]}, {"id": "2007.14319", "submitter": "Mazharul Islam", "authors": "Mazharul Islam, Sazzadur Rahaman, Na Meng, Behnaz Hassanshahi,\n  Padmanabhan Krishnan, Danfeng (Daphne) Yao", "title": "Coding Practices and Recommendations of Spring Security for Enterprise\n  Applications", "comments": null, "journal-ref": "IEEE Secure Development Conference. Atlanta, GA, September 2020", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spring security is tremendously popular among practitioners for its ease of\nuse to secure enterprise applications. In this paper, we study the application\nframework misconfiguration vulnerabilities in the light of Spring security,\nwhich is relatively understudied in the existing literature. Towards that goal,\nwe identify 6 types of security anti-patterns and 4 insecure vulnerable\ndefaults by conducting a measurement-based approach on 28 Spring applications.\nOur analysis shows that security risks associated with the identified security\nanti-patterns and insecure defaults can leave the enterprise application\nvulnerable to a wide range of high-risk attacks. To prevent these high-risk\nattacks, we also provide recommendations for practitioners. Consequently, our\nstudy has contributed one update to the official Spring security documentation\nwhile other security issues identified in this study are being considered for\nfuture major releases by Spring security community.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 15:40:35 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Islam", "Mazharul", "", "Daphne"], ["Rahaman", "Sazzadur", "", "Daphne"], ["Meng", "Na", "", "Daphne"], ["Hassanshahi", "Behnaz", "", "Daphne"], ["Krishnan", "Padmanabhan", "", "Daphne"], ["Danfeng", "", "", "Daphne"], ["Yao", "", ""]]}, {"id": "2007.14321", "submitter": "Christopher A. Choquette-Choo", "authors": "Christopher A. Choquette-Choo, Florian Tramer, Nicholas Carlini, and\n  Nicolas Papernot", "title": "Label-Only Membership Inference Attacks", "comments": "16 pages, 11 figures, 2 tables Revision 2: 19 pages, 12 figures, 3\n  tables. Improved text and additional experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Membership inference attacks are one of the simplest forms of privacy leakage\nfor machine learning models: given a data point and model, determine whether\nthe point was used to train the model. Existing membership inference attacks\nexploit models' abnormal confidence when queried on their training data. These\nattacks do not apply if the adversary only gets access to models' predicted\nlabels, without a confidence measure. In this paper, we introduce label-only\nmembership inference attacks. Instead of relying on confidence scores, our\nattacks evaluate the robustness of a model's predicted labels under\nperturbations to obtain a fine-grained membership signal. These perturbations\ninclude common data augmentations or adversarial examples. We empirically show\nthat our label-only membership inference attacks perform on par with prior\nattacks that required access to model confidences. We further demonstrate that\nlabel-only attacks break multiple defenses against membership inference attacks\nthat (implicitly or explicitly) rely on a phenomenon we call confidence\nmasking. These defenses modify a model's confidence scores in order to thwart\nattacks, but leave the model's predicted labels unchanged. Our label-only\nattacks demonstrate that confidence-masking is not a viable defense strategy\nagainst membership inference. Finally, we investigate worst-case label-only\nattacks, that infer membership for a small number of outlier data points. We\nshow that label-only attacks also match confidence-based attacks in this\nsetting. We find that training models with differential privacy and (strong) L2\nregularization are the only known defense strategies that successfully prevents\nall attacks. This remains true even when the differential privacy budget is too\nhigh to offer meaningful provable guarantees.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 15:44:31 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 01:42:20 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Choquette-Choo", "Christopher A.", ""], ["Tramer", "Florian", ""], ["Carlini", "Nicholas", ""], ["Papernot", "Nicolas", ""]]}, {"id": "2007.14423", "submitter": "Oded Leiba", "authors": "Omer Shlomovits, Oded Leiba", "title": "JugglingSwap: Scriptless Atomic Cross-Chain Swaps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The blockchain space is changing constantly. New chains are being implemented\nfrequently with different use cases in mind. As more and more types of crypto\nassets are getting real world value there is an increasing need for blockchain\ninteroperability. Exchange services today are still dominated by central\nparties which require custody of funds. This trust imposes costs and security\nrisks as frequent breaches testify. Atomic cross-chain swaps (ACCS) allow\nmutual distrusting parties to securely exchange crypto assets in a peer-to-peer\nmanner while preserving self-custody. Fundamental ACCS protocols leveraged the\nscripting capabilities of blockchains to conditionalize the transfer of funds\nbetween trading parties. Recent work showed that such protocols can be realized\nin a scriptless setting. This has many benefits to blockchains throughput,\nefficiency of swap protocols and also to fungibility and privacy. The proposed\nprotocols are limited to assets transferable by either Schnorr signatures or\nECDSA that are assuming the same elliptic curve parameters. In this work we\npresent JugglingSwap, a scriptless atomic cross-chain swap protocol with a\nhigher degree of interoperability. We weaken the assumptions about blockchains\nthat can be included in the ACCS protocol, and only require that (1) a\nthreshold variant exists to the underlying digital signature scheme and (2) it\nis based on the elliptic curve discrete logarithm problem (ECDLP). The fair\nexchange is achieved by a gradual release of secrets. To achieve this we use a\nnew building block we call Juggling: a public key verifiable encryption scheme\nto transfer segments of secret shares between parties, which can also be of\nseparate interest. Juggling is then tailored to a specific private key\nmanagement system design with threshold signatures security.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 18:16:45 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Shlomovits", "Omer", ""], ["Leiba", "Oded", ""]]}, {"id": "2007.14497", "submitter": "Shangqing Zhao", "authors": "Zhuo Lu, Cliff Wang, Shangqing Zhao", "title": "Cyber Deception for Computer and Network Security: Survey and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber deception has recently received increasing attentions as a promising\nmechanism for proactive cyber defense. Cyber deception strategies aim at\ninjecting intentionally falsified information to sabotage the early stage of\nattack reconnaissance and planning in order to render the final attack action\nharmless or ineffective. Motivated by recent advances in cyber deception\nresearch, we in this paper provide a formal view of cyber deception, and review\nhigh-level deception schemes and actions. We also summarize and classify recent\nresearch results of cyber defense techniques built upon the concept of cyber\ndeception, including game-theoretic modeling at the strategic level,\nnetwork-level deception, in-host-system deception and cryptography based\ndeception. Finally, we lay out and discuss in detail the research challenges\ntowards developing full-fledged cyber deception frameworks and mechanisms.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 21:48:29 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Lu", "Zhuo", ""], ["Wang", "Cliff", ""], ["Zhao", "Shangqing", ""]]}, {"id": "2007.14521", "submitter": "Sourav Das", "authors": "Sourav Das, Vinith Krishnan, Ling Ren", "title": "Efficient Cross-Shard Transaction Execution in Sharded Blockchains", "comments": "New Experimental results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sharding is a promising blockchain scaling solution. But it currently suffers\nfrom high latency and low throughput when it comes to cross-shard transactions,\ni.e., transactions that require coordination from multiple shards. The root\ncause of these limitations arise from the use of the classic two-phase commit\nprotocol, which involves locking assets for extended periods of time. This\npaper presents Rivet, a new paradigm for blockchain sharding that achieves\nlower latency and higher throughput for cross-shard transactions. Rivet has a\nsingle reference shard running consensus, and multiple worker shards\nmaintaining disjoint states and processing a subset of transactions in the\nsystem. Rivet obviates the need for consensus within each worker shard, and as\na result, tolerates more failures within a shard and lowers communication\noverhead. We prove the correctness and security of Rivet. We also propose a\nmore realistic framework for evaluating sharded blockchains by creating a\nbenchmark based on real Ethereum transactions. An evaluation of our prototype\nimplementation of Rivet and the baseline two-phase commit, atop 50+ AWS EC2\ninstances, using our evaluation framework demonstrates the latency and\nthroughput improvements for cross-shard transactions.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 23:11:56 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 03:11:16 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Das", "Sourav", ""], ["Krishnan", "Vinith", ""], ["Ren", "Ling", ""]]}, {"id": "2007.14570", "submitter": "Long Cheng", "authors": "Song Liao, Christin Wilson, Long Cheng, Hongxin Hu, Huixing Deng", "title": "Measuring the Effectiveness of Privacy Policies for Voice Assistant\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice Assistants (VA) such as Amazon Alexa and Google Assistant are quickly\nand seamlessly integrating into people's daily lives. The increased reliance on\nVA services raises privacy concerns such as the leakage of private\nconversations and sensitive information. Privacy policies play an important\nrole in addressing users' privacy concerns and informing them about the data\ncollection, storage, and sharing practices. VA platforms (both Amazon Alexa and\nGoogle Assistant) allow third-party developers to build new voice-apps and\npublish them to the app store. Voice-app developers are required to provide\nprivacy policies to disclose their apps' data practices. However, little is\nknown whether these privacy policies are informative and trustworthy or not on\nemerging VA platforms. On the other hand, many users invoke voice-apps through\nvoice and thus there exists a usability challenge for users to access these\nprivacy policies. In this paper, we conduct the first large-scale data\nanalytics to systematically measure the effectiveness of privacy policies\nprovided by voice-app developers on two mainstream VA platforms. We seek to\nunderstand the quality and usability issues of privacy policies provided by\ndevelopers in the current app stores. We analyzed 64,720 Amazon Alexa skills\nand 2,201 Google Assistant actions. Our work also includes a user study to\nunderstand users' perspectives on VA's privacy policies. Our findings reveal a\nworrisome reality of privacy policies in two mainstream voice-app stores, where\nthere exists a substantial number of problematic privacy policies.\nSurprisingly, Google and Amazon even have official voice-apps violating their\nown requirements regarding the privacy policy.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 03:17:51 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Liao", "Song", ""], ["Wilson", "Christin", ""], ["Cheng", "Long", ""], ["Hu", "Hongxin", ""], ["Deng", "Huixing", ""]]}, {"id": "2007.14724", "submitter": "Pascal Oser", "authors": "Pascal Oser, Sebastian Feger, Pawe{\\l} W. Wo\\'zniak, Jakob Karolus,\n  Dayana Spagnuelo, Akash Gupta, Stefan L\\\"uders, Albrecht Schmidt, and Frank\n  Kargl", "title": "SAFER: Development and Evaluation of an IoT Device Risk Assessment\n  Framework in a Multinational Organization", "comments": null, "journal-ref": null, "doi": "10.1145/3414173", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users of Internet of Things (IoT) devices are often unaware of their security\nrisks and cannot sufficiently factor security considerations into their device\nselection. This puts networks, infrastructure and users at risk. We developed\nand evaluated SAFER, an IoT device risk assessment framework designed to\nimprove users' ability to assess the security of connected devices. We deployed\nSAFER in a large multinational organization that permits use of private\ndevices. To evaluate the framework, we conducted a mixed-method study with 20\nemployees. Our findings suggest that SAFER increases users' awareness of\nsecurity issues. It provides valuable advice and impacts device selection.\nBased on our findings, we discuss implications for the design of device risk\nassessment tools, with particular regard to the relationship between risk\ncommunication and user perceptions of device complexity.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 10:17:44 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Oser", "Pascal", ""], ["Feger", "Sebastian", ""], ["Wo\u017aniak", "Pawe\u0142 W.", ""], ["Karolus", "Jakob", ""], ["Spagnuelo", "Dayana", ""], ["Gupta", "Akash", ""], ["L\u00fcders", "Stefan", ""], ["Schmidt", "Albrecht", ""], ["Kargl", "Frank", ""]]}, {"id": "2007.14729", "submitter": "Shuhei Nakamura", "authors": "Shuhei Nakamura", "title": "Formal Power Series on Algebraic Cryptanalysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cryptography, attacks that utilize a Gr\\\"{o}bner basis have broken several\ncryptosystems. The complexity of computing a Gr\\\"{o}bner basis dominates the\noverall computing and its estimation is important for such cryptanalysis. The\ncomplexity is given by using the solving degree, but it is hard to decide this\nvalue of a large scale system arisen from cryptography. Thus the degree of\nregularity and the first fall degree are used as proxies for the solving degree\nbased on a wealth of experiments. If a given system is semi-regular, the\ncomplexity is estimated by using the degree of regularity derived from a\ncertain power series, otherwise, by using the first fall degree derived from a\nconstruction of a syzygy. The degree of regularity is also defined on a\nnon-semi-regular system and is experimentally larger than the first fall\ndegree, but those relation is not clear theoretically. Moreover, in contrast to\nthe degree of regularity, the first fall degree has been investigated\nspecifically for each cryptosystem and its discussion on generic systems is not\ngiven. In this paper, we show an upper bound for the first fall degree of a\npolynomial system over a sufficiently large field. In detail, we prove that\nthis upper bound for a non-semi-regular system is the degree of regularity.\nMoreover, we prove that the upper bound for a multi-graded polynomial system is\na certain value only decided by its multi-degree. Furthermore, we show that the\ncondition for the order of a field in our results is satisfied in attacks\nagainst actual multivariate cryptosystems. Consequently, under a reasonable\ncondition for the order of a field, we clear a relation between the first fall\ndegree and the degree of regularity and provide a theoretical method using a\nmultivariate power series for cryptanalysis.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 10:36:20 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Nakamura", "Shuhei", ""]]}, {"id": "2007.14748", "submitter": "Takayuki Sasaki", "authors": "Takayuki Sasaki, Yusuke Shimada", "title": "Towards a Backdoorless Network Architecture Based on Remote Attestation\n  and Backdoor Inspection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To keep a system secure, all devices in the system need to be benign. To\navoid malicious and/or compromised devices, network access control such as\nauthentication using a credential and remote attestation based on trusted\nhardware has been used. These techniques ensure the authenticity and integrity\nof the devices, but do not mitigate risks of a backdoor embedded in the devices\nby the developer. To tackle this problem, we propose a novel architecture that\nintegrates remote attestation and backdoor inspection. Specifically, the\nbackdoor inspection result is stored in a server and the verifier retrieves and\nchecks the backdoor inspection result when the remote attestation is performed.\nMoreover, we discuss issues to deploy the proposed architecture to the real\nworld.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 11:22:59 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 23:31:42 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Sasaki", "Takayuki", ""], ["Shimada", "Yusuke", ""]]}, {"id": "2007.14756", "submitter": "Takayuki Sasaki", "authors": "Takayuki Sasaki, Shuichi Karino, Mikiya Tani, Kazuaki Nakajima, Koki\n  Tomita, Norio Yamagaki", "title": "Security Architecture for Trustworthy Systems in 5G Era", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems using 5G are expected to be used in various cases of Society 5.0 and\nIndustrie 4.0 such as smart cities, smart factories, and also critical\ninfrastructures. These systems are essential for our life, thus cyberattacks\nagainst the system must be prevented. In this paper, we tackle two problems\nposed by 5G features: system construction using multi-vendor devices and\nsoftwarized functions. Specifically, there are supply-chain risks that\nmalicious devices are used in the construction phase. Moreover, the softwarized\nnetwork functions are easy to be attacked compared to hardware. To cope with\nthese problems, we propose a concept of architecture comprising a blockchain to\nrecord security events including supply-chain information and a tamper\ndetection engine to ensure the integrity of software components in 5G system.\nWe implement the initial prototype of the architecture and show its\nfeasibility.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 11:50:27 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Sasaki", "Takayuki", ""], ["Karino", "Shuichi", ""], ["Tani", "Mikiya", ""], ["Nakajima", "Kazuaki", ""], ["Tomita", "Koki", ""], ["Yamagaki", "Norio", ""]]}, {"id": "2007.14861", "submitter": "Constance Beguier", "authors": "Constance Beguier and Eric W. Tramel", "title": "SAFER: Sparse Secure Aggregation for Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning enables one to train a common machine learning model\nacross separate, privately-held datasets via distributed model training. During\nfederated training, only intermediate model parameters are transmitted to a\ncentral server which aggregates these parameters to create a new common model,\nthus exposing only intermediate parameters rather than the training data\nitself. However, some attacks (e.g. membership inference) are able to infer\nproperties of local data from these intermediate model parameters. Hence,\nperforming the aggregation of these client-specific model parameters in a\nsecure way is required. Additionally, the communication cost is often the\nbottleneck of the federated systems, especially for large neural networks. So,\nlimiting the number and the size of communications is necessary to efficiently\ntrain large neural architectures. In this article, we present an efficient and\nsecure protocol for performing secure aggregation over compressed model updates\nin the context of collaborative, few-party federated learning, a context common\nin the medical, healthcare, and biotechnical use-cases of federated systems. By\nmaking compression-based federated techniques amenable to secure computation,\nwe develop a secure aggregation protocol between multiple servers with very low\ncommunication and computation costs and without preprocessing overhead. Our\nexperiments demonstrate the efficiency of this new approach for secure\nfederated training of deep convolutional neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 14:28:30 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 06:28:49 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Beguier", "Constance", ""], ["Tramel", "Eric W.", ""]]}, {"id": "2007.14915", "submitter": "Zhili Chen Prof.", "authors": "Zhili Chen, Xin Chen", "title": "Secure Computation Framework for Multiple Data Providers Against\n  Malicious Adversaries", "comments": "13 pages, 11 figures", "journal-ref": "submission of CCS 2020", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the great development of secure multi-party computation, many\npractical secure computation schemes have been proposed. As an example,\ndifferent secure auction mechanisms have been widely studied, which can protect\nbid privacy while satisfying various economic properties. However, as far as we\nknow, none of them solve the secure computation problems for multiple data\nproviders (e.g., secure cloud resource auctions) in the malicious security\nmodel. In this paper, we use the techniques of cut-and-choose and garbled\ncircuits to propose a general secure computation framework for multiple data\nproviders against malicious adversaries. Specifically, our framework checks\ninput consistency with the cut-and-choose paradigm, conducts maliciously secure\ncomputations by running two independent garbled circuits, and verifies the\ncorrectness of output by comparing two versions of outputs. Theoretical\nanalysis shows that our framework is secure against a malicious computation\nparty, or a subset of malicious data providers. Taking secure cloud resource\nauctions as an example, we implement our framework. Extensive experimental\nevaluations show that the performance of the proposed framework is acceptable\nin practice.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 15:40:51 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Chen", "Zhili", ""], ["Chen", "Xin", ""]]}, {"id": "2007.14916", "submitter": "Alan Sherman", "authors": "Enka Blanchard, Ted Selker, Alan T. Sherman", "title": "Boardroom Voting: Verifiable Voting with Ballot Privacy Using Low-Tech\n  Cryptography in a Single Room", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A boardroom election is an election that takes place in a single room -- the\nboardroom -- in which all voters can see and hear each other. We present an\ninitial exploration of boardroom elections with ballot privacy and voter\nverifiability that use only \"low-tech cryptography\" without using computers to\nmark or collect ballots. Specifically, we define the problem, introduce several\nbuilding blocks, and propose a new protocol that combines these blocks in novel\nways. Our new building blocks include \"foldable ballots\" that can be rotated to\nhide the alignment of ballot choices with voting marks, and \"visual secrets\"\nthat are easy to remember and use but hard to describe. Although closely seated\nparticipants in a boardroom election have limited privacy, the protocol ensures\nthat no one can determine how others voted. Moreover, each voter can verify\nthat their ballot was correctly cast, collected, and counted, without being\nable to prove how they voted, providing assurance against undue influence.\nLow-tech cryptography is useful in situations where constituents do not trust\ncomputer technology, and it avoids the complex auditing requirements of\nend-to-end cryptographic voting systems such as Pr\\^{e}t-\\`{a}-Voter. This\npaper's building blocks and protocol are meant to be a proof of concept that\nmight be tested for usability and improved.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 15:40:51 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 16:57:59 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Blanchard", "Enka", ""], ["Selker", "Ted", ""], ["Sherman", "Alan T.", ""]]}, {"id": "2007.14946", "submitter": "Claudio Di Ciccio", "authors": "Roman M\\\"uhlberger, Stefan Bachhofner, Eduardo Castell\\'o Ferrer,\n  Claudio Di Ciccio, Ingo Weber, Maximilian W\\\"ohrer, Uwe Zdun", "title": "Foundational Oracle Patterns: Connecting Blockchain to the Off-chain\n  World", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-58779-6_3", "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain has evolved into a platform for decentralized applications, with\nbeneficial properties like high integrity, transparency, and resilience against\ncensorship and tampering. However, blockchains are closed-world systems which\ndo not have access to external state. To overcome this limitation, oracles have\nbeen introduced in various forms and for different purposes. However so far\ncommon oracle best practices have not been dissected, classified, and studied\nin their fundamental aspects. In this paper, we address this gap by studying\nfoundational blockchain oracle patterns in two foundational dimensions\ncharacterising the oracles: (i) the data flow direction, i.e., inbound and\noutbound data flow, from the viewpoint of the blockchain; and (ii) the\ninitiator of the data flow, i.e., whether it is push or pull-based\ncommunication. We provide a structured description of the four patterns in\ndetail, and discuss an implementation of these patterns based on use cases. On\nthis basis we conduct a quantitative analysis, which results in the insight\nthat the four different patterns are characterized by distinct performance and\ncosts profiles.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 16:39:02 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["M\u00fchlberger", "Roman", ""], ["Bachhofner", "Stefan", ""], ["Ferrer", "Eduardo Castell\u00f3", ""], ["Di Ciccio", "Claudio", ""], ["Weber", "Ingo", ""], ["W\u00f6hrer", "Maximilian", ""], ["Zdun", "Uwe", ""]]}, {"id": "2007.14995", "submitter": "Garrett Gu", "authors": "Garrett Gu and Hovav Shacham", "title": "Return-Oriented Programming in RISC-V", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RISC-V is an open-source hardware ISA based on the RISC design principles,\nand has been the subject of some novel ROP mitigation technique proposals due\nto its open-source nature. However, very little work has actually evaluated\nwhether such an attack is feasible assuming a typical RISC-V implementation. We\nshow that RISC-V ROP can be used to perform Turing complete calculation and\narbitrary function calls by leveraging gadgets found in a version of the GNU\nlibc library. Using techniques such as self-modifying ROP chains and\nalgorithmic ROP chain generation, we demonstrate the power of RISC-V ROP by\ncreating a compiler that converts code of arbitrary complexity written in a\npopular Turing-complete language into RISC-V ROP chains.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 05:10:22 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Gu", "Garrett", ""], ["Shacham", "Hovav", ""]]}, {"id": "2007.15030", "submitter": "Eugenio Mart\\'inez-C\\'amara", "authors": "Nuria Rodr\\'iguez-Barroso, Eugenio Mart\\'inez-C\\'amara, M. Victoria\n  Luz\\'on, Gerardo Gonz\\'alez Seco, Miguel \\'Angel Veganzones, Francisco\n  Herrera", "title": "Dynamic Federated Learning Model for Identifying Adversarial Clients", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning, as a distributed learning that conducts the training on\nthe local devices without accessing to the training data, is vulnerable to\ndirty-label data poisoning adversarial attacks. We claim that the federated\nlearning model has to avoid those kind of adversarial attacks through filtering\nout the clients that manipulate the local data. We propose a dynamic federated\nlearning model that dynamically discards those adversarial clients, which\nallows to prevent the corruption of the global learning model. We evaluate the\ndynamic discarding of adversarial clients deploying a deep learning\nclassification model in a federated learning setting, and using the EMNIST\nDigits and Fashion MNIST image classification datasets. Likewise, we analyse\nthe capacity of detecting clients with poor data distribution and reducing the\nnumber of rounds of learning by selecting the clients to aggregate. The results\nshow that the dynamic selection of the clients to aggregate enhances the\nperformance of the global learning model, discards the adversarial and poor\nclients and reduces the rounds of learning.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 18:02:11 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Rodr\u00edguez-Barroso", "Nuria", ""], ["Mart\u00ednez-C\u00e1mara", "Eugenio", ""], ["Luz\u00f3n", "M. Victoria", ""], ["Seco", "Gerardo Gonz\u00e1lez", ""], ["Veganzones", "Miguel \u00c1ngel", ""], ["Herrera", "Francisco", ""]]}, {"id": "2007.15145", "submitter": "Yuan Liu Prof.", "authors": "Yixiao Lan, Yuan Liu, Boyang Li", "title": "Proof of Learning (PoLe): Empowering Machine Learning with Consensus\n  Building on Blockchains", "comments": "11 pages,8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The progress of deep learning (DL), especially the recent development of\nautomatic design of networks, has brought unprecedented performance gains at\nheavy computational cost. On the other hand, blockchain systems routinely\nperform a huge amount of computation that does not achieve practical purposes\nin order to build Proof-of-Work (PoW) consensus from decentralized\nparticipants. In this paper, we propose a new consensus mechanism, Proof of\nLearning (PoLe), which directs the computation spent for consensus toward\noptimization of neural networks (NN). In our mechanism, the training/testing\ndata are released to the entire blockchain network (BCN) and the consensus\nnodes train NN models on the data, which serves as the proof of learning. When\nthe consensus on the BCN considers a NN model to be valid, a new block is\nappended to the blockchain. We experimentally compare the PoLe protocol with\nProof of Work (PoW) and show that PoLe can achieve a more stable block\ngeneration rate, which leads to more efficient transaction processing. We also\nintroduce a novel cheating prevention mechanism, Secure Mapping Layer (SML),\nwhich can be straightforwardly implemented as a linear NN layer. Empirical\nevaluation shows that SML can detect cheating nodes at small cost to the\npredictive performance.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 22:53:43 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Lan", "Yixiao", ""], ["Liu", "Yuan", ""], ["Li", "Boyang", ""]]}, {"id": "2007.15147", "submitter": "Varun Chandrasekaran", "authors": "Jayaram Raghuram, Varun Chandrasekaran, Somesh Jha, Suman Banerjee", "title": "A General Framework For Detecting Anomalous Inputs to DNN Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting anomalous inputs, such as adversarial and out-of-distribution (OOD)\ninputs, is critical for classifiers (including deep neural networks or DNNs)\ndeployed in real-world applications. While prior works have proposed various\nmethods to detect such anomalous samples using information from the internal\nlayer representations of a DNN, there is a lack of consensus on a principled\napproach for the different components of such a detection method. As a result,\noften heuristic and one-off methods are applied for different aspects of this\nproblem. We propose an unsupervised anomaly detection framework based on the\ninternal DNN layer representations in the form of a meta-algorithm with\nconfigurable components. We proceed to propose specific instantiations for each\ncomponent of the meta-algorithm based on ideas grounded in statistical testing\nand anomaly detection. We evaluate the proposed methods on well-known image\nclassification datasets with strong adversarial attacks and OOD inputs,\nincluding an adaptive attack that uses the internal layer representations of\nthe DNN (often not considered in prior work). Comparisons with five\nrecently-proposed competing detection methods demonstrates the effectiveness of\nour method in detecting adversarial and OOD inputs.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 22:57:57 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 03:37:27 GMT"}, {"version": "v3", "created": "Thu, 17 Jun 2021 15:04:47 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Raghuram", "Jayaram", ""], ["Chandrasekaran", "Varun", ""], ["Jha", "Somesh", ""], ["Banerjee", "Suman", ""]]}, {"id": "2007.15215", "submitter": "Deepti Gupta", "authors": "Deepti Gupta, Olumide Kayode, Smriti Bhatt, Maanak Gupta, and Ali\n  Saman Tosun", "title": "Learner's Dilemma: IoT Devices Training Strategies in Collaborative Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growth of Internet of Things (IoT) and mo-bile edge computing,\nbillions of smart devices are interconnected to develop applications used in\nvarious domains including smart homes, healthcare and smart manufacturing. Deep\nlearning has been extensively utilized in various IoT applications which\nrequire huge amount of data for model training. Due to privacy requirements,\nsmart IoT devices do not release data to a remote third party for their use. To\novercome this problem, collaborative approach to deep learning, also known as\nCollaborative DeepLearning (CDL) has been largely employed in data-driven\napplications. This approach enables multiple edge IoT devices to train their\nmodels locally on mobile edge devices. In this paper,we address IoT device\ntraining problem in CDL by analyzing the behavior of mobile edge devices using\na game-theoretic model,where each mobile edge device aims at maximizing the\naccuracy of its local model at the same time limiting the overhead of\nparticipating in CDL. We analyze the Nash Equilibrium in anN-player static game\nmodel. We further present a novel cluster-based fair strategy to approximately\nsolve the CDL game to enforce mobile edge devices for cooperation. Our\nexperimental results and evaluation analysis in a real-world smart home\ndeployment show that 80% mobile edge devices are ready to cooperate in CDL,\nwhile 20% of them do not train their local models collaboratively.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 03:54:32 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Gupta", "Deepti", ""], ["Kayode", "Olumide", ""], ["Bhatt", "Smriti", ""], ["Gupta", "Maanak", ""], ["Tosun", "Ali Saman", ""]]}, {"id": "2007.15227", "submitter": "Yating Wei", "authors": "Wei Chen, Yating Wei, Zhiyong Wang, Shuyue Zhou, Bingru Lin, Zhiguang\n  Zhou", "title": "Federated Visualization: A Privacy-preserving Strategy for Decentralized\n  Visualization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel privacy preservation strategy for decentralized\nvisualization. The key idea is to imitate the flowchart of the federated\nlearning framework, and reformulate the visualization process within a\nfederated infrastructure. The federation of visualization is fulfilled by\nleveraging a shared global module that composes the encrypted externalizations\nof transformed visual features of data pieces in local modules. We design two\nimplementations of federated visualization: a prediction-based scheme, and a\nquery-based scheme. We demonstrate the effectiveness of our approach with a set\nof visual forms, and verify its robustness with evaluations. We report the\nvalue of federated visualization in real scenarios with an expert review.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 04:57:26 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Chen", "Wei", ""], ["Wei", "Yating", ""], ["Wang", "Zhiyong", ""], ["Zhou", "Shuyue", ""], ["Lin", "Bingru", ""], ["Zhou", "Zhiguang", ""]]}, {"id": "2007.15248", "submitter": "Nandan Kumar Jha", "authors": "Nandan Kumar Jha, Sparsh Mittal, Binod Kumar, and Govardhan Mattela", "title": "DeepPeep: Exploiting Design Ramifications to Decipher the Architecture\n  of Compact DNNs", "comments": "Accepted at The ACM Journal on Emerging Technologies in Computing\n  Systems (JETC), 2020. 25 pages, 11 tables, and 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The remarkable predictive performance of deep neural networks (DNNs) has led\nto their adoption in service domains of unprecedented scale and scope. However,\nthe widespread adoption and growing commercialization of DNNs have underscored\nthe importance of intellectual property (IP) protection. Devising techniques to\nensure IP protection has become necessary due to the increasing trend of\noutsourcing the DNN computations on the untrusted accelerators in cloud-based\nservices. The design methodologies and hyper-parameters of DNNs are crucial\ninformation, and leaking them may cause massive economic loss to the\norganization. Furthermore, the knowledge of DNN's architecture can increase the\nsuccess probability of an adversarial attack where an adversary perturbs the\ninputs and alter the prediction.\n  In this work, we devise a two-stage attack methodology \"DeepPeep\" which\nexploits the distinctive characteristics of design methodologies to\nreverse-engineer the architecture of building blocks in compact DNNs. We show\nthe efficacy of \"DeepPeep\" on P100 and P4000 GPUs. Additionally, we propose\nintelligent design maneuvering strategies for thwarting IP theft through the\nDeepPeep attack and proposed \"Secure MobileNet-V1\". Interestingly, compared to\nvanilla MobileNet-V1, secure MobileNet-V1 provides a significant reduction in\ninference latency ($\\approx$60%) and improvement in predictive performance\n($\\approx$2%) with very-low memory and computation overheads.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 06:01:41 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Jha", "Nandan Kumar", ""], ["Mittal", "Sparsh", ""], ["Kumar", "Binod", ""], ["Mattela", "Govardhan", ""]]}, {"id": "2007.15260", "submitter": "Gabriele D'Angelo", "authors": "Luca Serena, Gabriele D'Angelo, Stefano Ferretti", "title": "Implications of Dissemination Strategies on the Security of Distributed\n  Ledgers", "comments": "Proceedings of the 3rd Workshop on Cryptocurrencies and Blockchains\n  for Distributed Systems (CryBlock 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a simulation study on security attacks over Distributed\nLedger Technologies (DLTs). We specifically focus on attacks at the underlying\npeer-to-peer layer of these systems, that is in charge of disseminating\nmessages containing data and transaction to be spread among all participants.\nIn particular, we consider the Sybil attack, according to which a malicious\nnode creates many Sybils that drop messages coming from a specific attacked\nnode, or even all messages from honest nodes. Our study shows that the\nselection of the specific dissemination protocol, as well as the amount of\nconnections each peer has, have an influence on the resistance to this attack.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 06:52:04 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Serena", "Luca", ""], ["D'Angelo", "Gabriele", ""], ["Ferretti", "Stefano", ""]]}, {"id": "2007.15290", "submitter": "Han Qiu", "authors": "Yi Zeng, Han Qiu, Gerard Memmi, Meikang Qiu", "title": "A Data Augmentation-based Defense Method Against Adversarial Attacks in\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) in Computer Vision (CV) are well-known to be\nvulnerable to Adversarial Examples (AEs), namely imperceptible perturbations\nadded maliciously to cause wrong classification results. Such variability has\nbeen a potential risk for systems in real-life equipped DNNs as core\ncomponents. Numerous efforts have been put into research on how to protect DNN\nmodels from being tackled by AEs. However, no previous work can efficiently\nreduce the effects caused by novel adversarial attacks and be compatible with\nreal-life constraints at the same time. In this paper, we focus on developing a\nlightweight defense method that can efficiently invalidate full whitebox\nadversarial attacks with the compatibility of real-life constraints. From basic\naffine transformations, we integrate three transformations with randomized\ncoefficients that fine-tuned respecting the amount of change to the defended\nsample. Comparing to 4 state-of-art defense methods published in top-tier AI\nconferences in the past two years, our method demonstrates outstanding\nrobustness and efficiency. It is worth highlighting that, our model can\nwithstand advanced adaptive attack, namely BPDA with 50 rounds, and still helps\nthe target model maintain an accuracy around 80 %, meanwhile constraining the\nattack success rate to almost zero.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 08:06:53 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Zeng", "Yi", ""], ["Qiu", "Han", ""], ["Memmi", "Gerard", ""], ["Qiu", "Meikang", ""]]}, {"id": "2007.15310", "submitter": "Junyu Lin", "authors": "Junyu Lin, Lei Xu, Yingqi Liu, Xiangyu Zhang", "title": "Black-box Adversarial Sample Generation Based on Differential Evolution", "comments": "29 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are being used in various daily tasks such as\nobject detection, speech processing, and machine translation. However, it is\nknown that DNNs suffer from robustness problems -- perturbed inputs called\nadversarial samples leading to misbehaviors of DNNs. In this paper, we propose\na black-box technique called Black-box Momentum Iterative Fast Gradient Sign\nMethod (BMI-FGSM) to test the robustness of DNN models. The technique does not\nrequire any knowledge of the structure or weights of the target DNN. Compared\nto existing white-box testing techniques that require accessing model internal\ninformation such as gradients, our technique approximates gradients through\nDifferential Evolution and uses approximated gradients to construct adversarial\nsamples. Experimental results show that our technique can achieve 100% success\nin generating adversarial samples to trigger misclassification, and over 95%\nsuccess in generating samples to trigger misclassification to a specific target\noutput label. It also demonstrates better perturbation distance and better\ntransferability. Compared to the state-of-the-art black-box technique, our\ntechnique is more efficient. Furthermore, we conduct testing on the commercial\nAliyun API and successfully trigger its misbehavior within a limited number of\nqueries, demonstrating the feasibility of real-world black-box attack.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 08:43:45 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Lin", "Junyu", ""], ["Xu", "Lei", ""], ["Liu", "Yingqi", ""], ["Zhang", "Xiangyu", ""]]}, {"id": "2007.15348", "submitter": "Zhiyun Wang", "authors": "Zhiyun Wang, Jiayu Zhang, Xiaoyu Ji, Wenyuan Xu, Gang Qu, Minjian Zhao", "title": "Who Is Charging My Phone? Identifying Wireless Chargers via\n  Fingerprinting", "comments": "Sorry, the content of this paper has to be revised a lot, so we\n  decided to withdraw it first", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing popularity of the Internet of Things(IoT) devices, the\ndemand for fast and convenient battery charging services grows rapidly.\nWireless charging is a promising technology for such a purpose and its usage\nhas become ubiquitous. However, the close distance between the charger and the\ndevice being charged not only makes proximity-based and near field\ncommunication attacks possible, but also introduces a new type of\nvulnerabilities. In this paper, we propose to create fingerprints for wireless\nchargers based on the intrinsic non-linear distortion effects of the underlying\ncharging circuit. Using such fingerprints, we design the WirelessID system to\ndetect potential short-range malicious wireless charging attacks. WirelessID\ncollects signals in the standby state of the charging process and sends them to\na trusted server, which can extract the fingerprint and then identify the\ncharger.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 09:54:37 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 13:45:05 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Wang", "Zhiyun", ""], ["Zhang", "Jiayu", ""], ["Ji", "Xiaoyu", ""], ["Xu", "Wenyuan", ""], ["Qu", "Gang", ""], ["Zhao", "Minjian", ""]]}, {"id": "2007.15528", "submitter": "Zheng Li", "authors": "Zheng Li and Yang Zhang", "title": "Membership Leakage in Label-Only Exposures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) has been widely adopted in various privacy-critical\napplications, e.g., face recognition and medical image analysis. However,\nrecent research has shown that ML models are vulnerable to attacks against\ntheir training data. Membership inference is one major attack in this domain:\nGiven a data sample and model, an adversary aims to determine whether the\nsample is part of the model's training set. Existing membership inference\nattacks leverage the confidence scores returned by the model as their inputs\n(score-based attacks). However, these attacks can be easily mitigated if the\nmodel only exposes the predicted label, i.e., the final model decision.\n  In this paper, we propose decision-based membership inference attacks and\ndemonstrate that label-only exposures are also vulnerable to membership\nleakage. In particular, we develop two types of decision-based attacks, namely\ntransfer-attack and boundary-attack. Empirical evaluation shows that our\ndecision-based attacks can achieve remarkable performance, and even outperform\nthe previous score-based attacks. We further present new insights on the\nsuccess of membership inference based on quantitative and qualitative analysis,\ni.e., member samples of a model are more distant to the model's decision\nboundary than non-member samples. Finally, we evaluate multiple defense\nmechanisms against our decision-based attacks and show that our two types of\nattacks can bypass most of these defenses.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 15:27:55 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 17:50:29 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Li", "Zheng", ""], ["Zhang", "Yang", ""]]}, {"id": "2007.15591", "submitter": "Jiazhi Xia", "authors": "Jiazhi Xia, Tianxiang Chen, Lei Zhang, Wei Chen, Yang Chen, Xiaolong\n  Zhang, Cong Xie, Tobias Schreck", "title": "SMAP: A Joint Dimensionality Reduction Scheme for Secure Multi-Party\n  Visualization", "comments": "12 pages, 10 figures. Conditionally accepted by VAST 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, as data becomes increasingly complex and distributed, data analyses\noften involve several related datasets that are stored on different servers and\nprobably owned by different stakeholders. While there is an emerging need to\nprovide these stakeholders with a full picture of their data under a global\ncontext, conventional visual analytical methods, such as dimensionality\nreduction, could expose data privacy when multi-party datasets are fused into a\nsingle site to build point-level relationships. In this paper, we reformulate\nthe conventional t-SNE method from the single-site mode into a secure\ndistributed infrastructure. We present a secure multi-party scheme for joint\nt-SNE computation, which can minimize the risk of data leakage. Aggregated\nvisualization can be optionally employed to hide disclosure of point-level\nrelationships. We build a prototype system based on our method, SMAP, to\nsupport the organization, computation, and exploration of secure joint\nembedding. We demonstrate the effectiveness of our approach with three case\nstudies, one of which is based on the deployment of our system in real-world\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 16:54:57 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Xia", "Jiazhi", ""], ["Chen", "Tianxiang", ""], ["Zhang", "Lei", ""], ["Chen", "Wei", ""], ["Chen", "Yang", ""], ["Zhang", "Xiaolong", ""], ["Xie", "Cong", ""], ["Schreck", "Tobias", ""]]}, {"id": "2007.15759", "submitter": "Jedidiah Crandall", "authors": "Scott Levy and Jedidiah R. Crandall", "title": "The Program with a Personality: Analysis of Elk Cloner, the First\n  Personal Computer Virus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although self-replicating programs and viruses have existed since the 1960s\nand 70s, Elk Cloner was the first virus to circulate among personal computers\nin the wild. Despite its historical significance, it received comparatively\nlittle attention when it first appeared in 1982. In this paper, we: present the\nfirst detailed examination of the operation and structure of Elk Cloner;\ndiscuss the effect of environmental characteristics on its virulence; and\nprovide supporting evidence for several hypotheses about why its release was\nlargely ignored in the early 1980s.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 22:16:45 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Levy", "Scott", ""], ["Crandall", "Jedidiah R.", ""]]}, {"id": "2007.15789", "submitter": "Lichao Sun", "authors": "Lichao Sun, Jianwei Qian, Xun Chen", "title": "LDP-FL: Practical Private Aggregation in Federated Learning with Local\n  Differential Privacy", "comments": "Accepted by IJCAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Train machine learning models on sensitive user data has raised increasing\nprivacy concerns in many areas. Federated learning is a popular approach for\nprivacy protection that collects the local gradient information instead of real\ndata. One way to achieve a strict privacy guarantee is to apply local\ndifferential privacy into federated learning. However, previous works do not\ngive a practical solution due to three issues. First, the noisy data is close\nto its original value with high probability, increasing the risk of information\nexposure. Second, a large variance is introduced to the estimated average,\ncausing poor accuracy. Last, the privacy budget explodes due to the high\ndimensionality of weights in deep learning models. In this paper, we proposed a\nnovel design of local differential privacy mechanism for federated learning to\naddress the abovementioned issues. It is capable of making the data more\ndistinct from its original value and introducing lower variance. Moreover, the\nproposed mechanism bypasses the curse of dimensionality by splitting and\nshuffling model updates. A series of empirical evaluations on three commonly\nused datasets, MNIST, Fashion-MNIST and CIFAR-10, demonstrate that our solution\ncan not only achieve superior deep learning performance but also provide a\nstrong privacy guarantee at the same time.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 01:08:57 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 11:24:54 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Sun", "Lichao", ""], ["Qian", "Jianwei", ""], ["Chen", "Xun", ""]]}, {"id": "2007.15802", "submitter": "Ren Wang", "authors": "Ren Wang, Gaoyuan Zhang, Sijia Liu, Pin-Yu Chen, Jinjun Xiong, Meng\n  Wang", "title": "Practical Detection of Trojan Neural Networks: Data-Limited and\n  Data-Free Cases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the training data are maliciously tampered, the predictions of the\nacquired deep neural network (DNN) can be manipulated by an adversary known as\nthe Trojan attack (or poisoning backdoor attack). The lack of robustness of\nDNNs against Trojan attacks could significantly harm real-life machine learning\n(ML) systems in downstream applications, therefore posing widespread concern to\ntheir trustworthiness. In this paper, we study the problem of the Trojan\nnetwork (TrojanNet) detection in the data-scarce regime, where only the weights\nof a trained DNN are accessed by the detector. We first propose a data-limited\nTrojanNet detector (TND), when only a few data samples are available for\nTrojanNet detection. We show that an effective data-limited TND can be\nestablished by exploring connections between Trojan attack and\nprediction-evasion adversarial attacks including per-sample attack as well as\nall-sample universal attack. In addition, we propose a data-free TND, which can\ndetect a TrojanNet without accessing any data samples. We show that such a TND\ncan be built by leveraging the internal response of hidden neurons, which\nexhibits the Trojan behavior even at random noise inputs. The effectiveness of\nour proposals is evaluated by extensive experiments under different model\narchitectures and datasets including CIFAR-10, GTSRB, and ImageNet.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 02:00:38 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Wang", "Ren", ""], ["Zhang", "Gaoyuan", ""], ["Liu", "Sijia", ""], ["Chen", "Pin-Yu", ""], ["Xiong", "Jinjun", ""], ["Wang", "Meng", ""]]}, {"id": "2007.15805", "submitter": "He Shuang", "authors": "He Shuang, Michelle Wong, David Lie", "title": "Using Context and Interactions to Verify User-Intended Network Requests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Client-side malware can attack users by tampering with applications or user\ninterfaces to generate requests that users did not intend. We propose Verified\nIntention (VInt), which ensures a network request, as received by a service, is\nuser-intended. VInt is based on \"seeing what the user sees\" (context). VInt\nscreenshots the user interface as the user interacts with a security-sensitive\nform. There are two main components. First, VInt ensures output integrity and\nauthenticity by validating the context, ensuring the user sees correctly\nrendered information. Second, VInt extracts user-intended inputs from the\non-screen user-provided inputs, with the assumption that a human user checks\nwhat they entered. Using the user-intended inputs, VInt deems a request to be\nuser-intended if the request is generated properly from the user-intended\ninputs while the user is shown the correct information. VInt is implemented\nusing image analysis and Optical Character Recognition (OCR). Our evaluation\nshows that VInt is accurate and efficient.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 02:08:18 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Shuang", "He", ""], ["Wong", "Michelle", ""], ["Lie", "David", ""]]}, {"id": "2007.15850", "submitter": "Sohaib Ahmad", "authors": "Sohaib Ahmad, Christopher Geiger, Benjamin Fuller", "title": "Resist : Reconstruction of irises from templates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iris recognition systems transform an iris image into a feature vector. The\nseminal pipeline segments an image into iris and non-iris pixels, normalizes\nthis region into a fixed-dimension rectangle, and extracts features which are\nstored and called a template (Daugman, 2009). This template is stored on a\nsystem. A future reading of an iris can be transformed and compared against\ntemplate vectors to determine or verify the identity of an individual. As\ntemplates are often stored together, they are a valuable target to an attacker.\nWe show how to invert templates across a variety of iris recognition systems.\nThat is, we show how to transform templates into realistic looking iris images\nthat are also deemed as the same iris by the corresponding recognition system.\nOur inversion is based on a convolutional neural network architecture we call\nRESIST (REconStructing IriSes from Templates). We apply RESIST to a traditional\nGabor filter pipeline, to a DenseNet (Huang et al., CVPR 2017) feature\nextractor, and to a DenseNet architecture that works without normalization.\nBoth DenseNet feature extractors are based on the recent ThirdEye recognition\nsystem (Ahmad and Fuller, BTAS 2019). When training and testing using the\nND-0405 dataset, reconstructed images demonstrate a rank-1 accuracy of 100%,\n76%, and 96% respectively for the three pipelines. The core of our approach is\nsimilar to an autoencoder. However, standalone training the core produced low\naccuracy. The final architecture integrates into an generative adversarial\nnetwork (Goodfellow et al., NeurIPS, 2014) producing higher accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 05:08:28 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 05:19:59 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Ahmad", "Sohaib", ""], ["Geiger", "Christopher", ""], ["Fuller", "Benjamin", ""]]}, {"id": "2007.15881", "submitter": "Pawel Szalachowski", "authors": "Pawel Szalachowski", "title": "Password-authenticated Decentralized Identities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Password-authenticated identities, where users establish username-password\npairs with individual servers and use them later on for authentication, is the\nmost widespread user authentication method over the Internet. Although they are\nsimple, user-friendly, and broadly adopted, they offer insecure authentication\nand position server operators as trusted parties, giving them full control over\nusers' identities. To mitigate these limitations, many identity systems have\nembraced public-key cryptography and the concept of decentralization. All these\nsystems, however, require users to create and manage public-private keypairs.\nUnfortunately, users usually do not have the required knowledge and resources\nto properly handle their cryptographic secrets, which arguably contributed to\nfailures of many end-user-focused public-key infrastructures (PKIs). In fact,\nas for today, no end-user PKI, able to authenticate users to web servers, has a\nsignificant adoption rate.\n  In this paper, we propose Password-authenticated Decentralized Identities\n(PDIDs), an identity and authentication framework where users can register\ntheir self-sovereign username-password pairs and use them as universal\ncredentials. Our system provides global namespace, human-meaningful usernames,\nand resilience against username collision attacks. A user's identity can be\nused to authenticate the user to any server without revealing that server\nanything about the password, such that no offline dictionary attacks are\npossible against the password. We analyze PDIDs and implement it using existing\ninfrastructures and tools. We report on our implementation and evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 07:29:48 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Szalachowski", "Pawel", ""]]}, {"id": "2007.15902", "submitter": "Yongjie Yuan", "authors": "Liang Yang and Yongjie Yuan", "title": "Secrecy Outage Probability Analysis for RIS-Assisted NOMA Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the physical layer security (PLS) for a novel reconfigurable\nintelligent surface (RIS)-assisted non-orthogonal multiple access (NOMA) system\nin a multi-user scenario is investigated, where we consider the worst case that\nthe eavesdropper also utilizes the advantage of the RISs. More specifically, we\nderive analytical results for the secrecy outage probability (SOP). From the\nnumerical results, we observe that the use of RISs can improve the secrecy\nperformance compared to traditional NOMA systems. However, for the worst case\nthat the received signals at the eavesdropper comes from the RISs and source,\nincreasing the number of intelligent elements on the RIS has a negative impact\non the secrecy performance. At high SNRs, the system's SOP tends to a constant.\nFinally, the secrecy performance can be improved through the group selection.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 08:34:48 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Yang", "Liang", ""], ["Yuan", "Yongjie", ""]]}, {"id": "2007.15909", "submitter": "Georgios Selimis", "authors": "Rui Wang, Georgios Selimis, Roel Maes, Sven Goossens", "title": "Long-term continuous assessment of SRAM PUF and source of random numbers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The qualities of Physical Unclonable Functions (PUFs) suffer from several\nnoticeable degradations due to silicon aging. In this paper, we investigate the\nlong-term effects of silicon aging on PUFs derived from the start-up behavior\nof Static Random Access Memories (SRAM). Previous research on SRAM aging is\nbased on transistor-level simulation or accelerated aging test at high\ntemperature and voltage to observe aging effects within a short period of time.\nIn contrast, we have run a long-term continuous power-up test on 16 Arduino\nLeonardo boards under nominal conditions for two years. In total, we collected\naround 175 million measurements for reliability, uniqueness and randomness\nevaluations. Analysis shows that the number of bits that flip with respect to\nthe reference increased by 19.3% while min-entropy of SRAM PUF noise improves\nby 19.3% on average after two years of aging. The impact of aging on\nreliability is smaller under nominal conditions than was previously assessed by\nthe accelerated aging test. The test we conduct in this work more closely\nresembles the conditions of a device in the field, and therefore we more\naccurately evaluate how silicon aging affects SRAM PUFs.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 08:59:50 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Wang", "Rui", ""], ["Selimis", "Georgios", ""], ["Maes", "Roel", ""], ["Goossens", "Sven", ""]]}, {"id": "2007.15919", "submitter": "Jan Philipp Thoma", "authors": "Jan Philipp Thoma, Jakob Feldtkeller, Markus Krausz, Tim G\\\"uneysu,\n  Daniel J. Bernstein", "title": "BasicBlocker: ISA Redesign to Make Spectre-Immune CPUs Faster", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has revealed an ever-growing class of microarchitectural\nattacks that exploit speculative execution, a standard feature in modern\nprocessors. Proposed and deployed countermeasures involve a variety of compiler\nupdates, firmware updates, and hardware updates. None of the deployed\ncountermeasures have convincing security arguments, and many of them have\nalready been broken.\n  The obvious way to simplify the analysis of speculative-execution attacks is\nto eliminate speculative execution. This is normally dismissed as being\nunacceptably expensive, but the underlying cost analyses consider only software\nwritten for current instruction-set architectures, so they do not rule out the\npossibility of a new instruction-set architecture providing acceptable\nperformance without speculative execution. A new ISA requires compiler and\nhardware updates, but these are happening in any case.\n  This paper introduces BasicBlocker, a generic ISA modification that works for\nall common ISAs and that allows non-speculative CPUs to obtain most of the\nperformance benefit that would have been provided by speculative execution. To\ndemonstrate the feasibility of BasicBlocker, this paper defines a variant of\nthe RISC-V ISA called BBRISC-V and provides a thorough evaluation on both a\n5-stage in-order soft core and a superscalar out-of-order processor using an\nassociated compiler and a variety of benchmark programs.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 09:30:45 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 10:37:33 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Thoma", "Jan Philipp", ""], ["Feldtkeller", "Jakob", ""], ["Krausz", "Markus", ""], ["G\u00fcneysu", "Tim", ""], ["Bernstein", "Daniel J.", ""]]}, {"id": "2007.15956", "submitter": "Weitao Xu", "authors": "Weitao Xu, Junqing Zhang, Shunqi Huang, Chengwen Luo, Wei Li", "title": "Key Generation for Internet of Things: A Contemporary Survey", "comments": "35 pages, 5 tables, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Key generation is a promising technique to bootstrap secure communications\nfor the Internet of Things (IoT) devices that have no prior knowledge between\neach other. In the past few years, a variety of key generation protocols and\nsystems have been proposed. In this survey, we review and categorise recent key\ngeneration systems based on a novel taxonomy. Then, we provide both\nquantitative and qualitative comparisons of existing approaches. We also\ndiscuss the security vulnerabilities of key generation schemes and possible\ncountermeasures. Finally, we discuss the current challenges and point out\nseveral potential research directions.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 10:57:20 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 08:49:17 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Xu", "Weitao", ""], ["Zhang", "Junqing", ""], ["Huang", "Shunqi", ""], ["Luo", "Chengwen", ""], ["Li", "Wei", ""]]}, {"id": "2007.16147", "submitter": "Jaydip Sen", "authors": "Jaydip Sen, Sidra Mehtab, Michael Ekonde Sone, Veeramreddy Jyothsna,\n  Koneti Munivara Prasad, Rajeev Singh, Teek Parval Sharma, Anton Noskov,\n  Ignacio Velasquez, Angelica Caro, Alfonco Rodriguez, Tamer S. A. Fatayer,\n  Altaf O. Mulani, Pradeep B. Mane, Roshan Chitrakar, Roshan Bhusal, Prajwol\n  Maharjan", "title": "Computer and Network Security", "comments": "175 pages, 87 figures and 44 Tables", "journal-ref": null, "doi": "10.5772/intechopen.78497", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of Internet of Things and with the explosive worldwide growth of\nelectronic data volume, and associated need of processing, analysis and storage\nof such humongous volume of data, several new challenges are faced in\nprotecting privacy of sensitive data and securing systems by designing novel\nschemes for secure authentication, integrity protection, encryption and\nnon-repudiation. Lightweight symmetric key cryptography and adaptive network\nsecurity algorithms are in demand for mitigating these challenges. This book\npresents some of the state-of-the-art research work in the field of\ncryptography and security in computing and communications. It is a valuable\nsource of knowledge for researchers, engineers, practitioners, graduate and\ndoctoral students who are working in the field of cryptography, network\nsecurity and security and privacy issues in the Internet of Things (IoT), and\nmachine learning application in security. It will also be useful for faculty\nmembers of graduate schools and universities.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 15:54:29 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Sen", "Jaydip", ""], ["Mehtab", "Sidra", ""], ["Sone", "Michael Ekonde", ""], ["Jyothsna", "Veeramreddy", ""], ["Prasad", "Koneti Munivara", ""], ["Singh", "Rajeev", ""], ["Sharma", "Teek Parval", ""], ["Noskov", "Anton", ""], ["Velasquez", "Ignacio", ""], ["Caro", "Angelica", ""], ["Rodriguez", "Alfonco", ""], ["Fatayer", "Tamer S. A.", ""], ["Mulani", "Altaf O.", ""], ["Mane", "Pradeep B.", ""], ["Chitrakar", "Roshan", ""], ["Bhusal", "Roshan", ""], ["Maharjan", "Prajwol", ""]]}, {"id": "2007.16175", "submitter": "Elmira Karimi", "authors": "Elmira Karimi, Yunsi Fei, David Kaeli", "title": "Hardware/Software Obfuscation against Timing Side-channel Attack on a\n  GPU", "comments": "2020 IEEE International Symposium on Hardware Oriented Security and\n  Trust (HOST)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GPUs are increasingly being used in security applications, especially for\naccelerating encryption/decryption. While GPUs are an attractive platform in\nterms of performance, the security of these devices raises a number of\nconcerns. One vulnerability is the data-dependent timing information, which can\nbe exploited by adversary to recover the encryption key. Memory system features\nare frequently exploited since they create detectable timing variations. In\nthis paper, our attack model is a coalescing attack, which leverages a critical\nGPU microarchitectural feature -- the coalescing unit. As multiple concurrent\nGPU memory requests can refer to the same cache block, the coalescing unit\ncollapses them into a single memory transaction. The access time of an\nencryption kernel is dependent on the number of transactions. Correlation\nbetween a guessed key value and the associated timing samples can be exploited\nto recover the secret key. In this paper, a series of hardware/software\ncountermeasures are proposed to obfuscate the memory timing side channel,\nmaking the GPU more resilient without impacting performance. Our hardware-based\napproach attempts to randomize the width of the coalescing unit to lower the\nsignal-to-noise ratio. We present a hierarchical Miss Status Holding Register\n(MSHR) design that can merge transactions across different warps. This feature\nboosts performance, while, at the same time, secures the execution. We also\npresent a software-based approach to permute the organization of critical data\nstructures, significantly changing the coalescing behavior and introducing a\nhigh degree of randomness. Equipped with our new protections, the effort to\nlaunch a successful attack is increased up to 1433X . 178X, while also\nimproving encryption/decryption performance up to 7%.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 17:00:50 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Karimi", "Elmira", ""], ["Fei", "Yunsi", ""], ["Kaeli", "David", ""]]}]