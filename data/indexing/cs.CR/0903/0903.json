[{"id": "0903.0069", "submitter": "Pierre-Louis Cayrel", "authors": "Pierre-Louis Cayrel, Philippe Gaborit, David Galindo and Marc Girault", "title": "Improved identity-based identification using correcting codes", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new identity-based identification scheme based on\nerror-correcting codes is proposed. Two well known code-based schemes are\ncombined : the signature scheme by Courtois, Finiasz and Sendrier and an\nidentification scheme by Stern. A proof of security for the scheme in the\nRandom Oracle Model is given.\n", "versions": [{"version": "v1", "created": "Sat, 28 Feb 2009 12:05:58 GMT"}], "update_date": "2009-03-03", "authors_parsed": [["Cayrel", "Pierre-Louis", ""], ["Gaborit", "Philippe", ""], ["Galindo", "David", ""], ["Girault", "Marc", ""]]}, {"id": "0903.0682", "submitter": "Raymond Chi-Wing Wong", "authors": "Raymond Chi-Wing Wong, Ada Wai-Chee Fu, Jia Liu, Ke Wang and Yabo Xu", "title": "Preserving Individual Privacy in Serial Data Publishing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While previous works on privacy-preserving serial data publishing consider\nthe scenario where sensitive values may persist over multiple data releases, we\nfind that no previous work has sufficient protection provided for sensitive\nvalues that can change over time, which should be the more common case. In this\nwork we propose to study the privacy guarantee for such transient sensitive\nvalues, which we call the global guarantee. We formally define the problem for\nachieving this guarantee and derive some theoretical properties for this\nproblem. We show that the anonymized group sizes used in the data anonymization\nis a key factor in protecting individual privacy in serial publication. We\npropose two strategies for anonymization targeting at minimizing the average\ngroup size and the maximum group size. Finally, we conduct experiments on a\nmedical dataset to show that our method is highly efficient and also produces\npublished data of very high utility.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2009 09:36:29 GMT"}], "update_date": "2009-03-05", "authors_parsed": [["Wong", "Raymond Chi-Wing", ""], ["Fu", "Ada Wai-Chee", ""], ["Liu", "Jia", ""], ["Wang", "Ke", ""], ["Xu", "Yabo", ""]]}, {"id": "0903.0802", "submitter": "Tomasz Truderung", "authors": "Ralf Kuesters, Tomasz Truderung", "title": "An Epistemic Approach to Coercion-Resistance for Electronic Voting\n  Protocols", "comments": "An extended version of a paper from IEEE Symposium on Security and\n  Privacy (S&P) 2009", "journal-ref": null, "doi": "10.1109/SP.2009.13", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coercion resistance is an important and one of the most intricate security\nrequirements of electronic voting protocols. Several definitions of coercion\nresistance have been proposed in the literature, including definitions based on\nsymbolic models. However, existing definitions in such models are rather\nrestricted in their scope and quite complex.\n  In this paper, we therefore propose a new definition of coercion resistance\nin a symbolic setting, based on an epistemic approach. Our definition is\nrelatively simple and intuitive. It allows for a fine-grained formulation of\ncoercion resistance and can be stated independently of a specific, symbolic\nprotocol and adversary model. As a proof of concept, we apply our definition to\nthree voting protocols. In particular, we carry out the first rigorous analysis\nof the recently proposed Civitas system. We precisely identify those conditions\nunder which this system guarantees coercion resistance or fails to be coercion\nresistant. We also analyze protocols proposed by Lee et al. and Okamoto.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2009 16:49:00 GMT"}, {"version": "v2", "created": "Fri, 29 May 2009 10:51:25 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Kuesters", "Ralf", ""], ["Truderung", "Tomasz", ""]]}, {"id": "0903.2071", "submitter": "Laszlo Kish", "authors": "Laszlo B. Kish and Tamas Horvath", "title": "Notes on Recent Approaches Concerning the\n  Kirchhoff-Law-Johnson-Noise-based Secure Key Exchange", "comments": "Accepted for publication in Physics Letters A on May 29, 2009. In the\n  present version, DOI and acceptance info is added in the pdf file, too", "journal-ref": "Physics Letters A 373 (2009) 2858-2868", "doi": "10.1016/j.physleta.2009.05.077", "report-no": null, "categories": "physics.gen-ph cs.CR physics.class-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We critically analyze the results and claims in [Physics Letters A 373 (2009)\n901-904].\n  We show that the strong security leak appeared in the simulations is only an\nartifact and not caused by \"multiple reflections\". Since no wave modes exist at\ncable length of 5% of the shortest wavelength of the signal, no wave is present\nto reflect it.\n  In the high wave impedance limit, the conditions used in the simulations are\nheavily unphysical (requiring cable diameters up to 28000 times greater than\nthe measured size of the known universe) and the results are modeling artifacts\ndue to the unphysical values.\n  At the low cable impedance limit, the observed artifacts are due to violating\nthe recommended (and tested) conditions by neglecting the cable capacitance\nrestrictions and using about 100 times longer cable than recommended without\ncable capacitance compensation arrangement.\n  We implement and analyze the general circuitry of Liu's circulator and\nconfirm that they are conceptually secure against passive attacks. We introduce\nan asymmetric, more robust version without feedback loop. Then we crack all\nthese systems by an active attack: a circulator-based man-in-the middle attack.\n  Finally, we analyze the proposed method to increase security by dropping only\nhigh-risk bits. We point out the differences between different types of\nhigh-risk bits and show the shortage of this strategy for some simple key\nexchange protocols.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2009 16:55:25 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2009 16:01:25 GMT"}, {"version": "v3", "created": "Sat, 23 May 2009 18:05:25 GMT"}, {"version": "v4", "created": "Fri, 5 Jun 2009 23:41:07 GMT"}, {"version": "v5", "created": "Tue, 30 Jun 2009 02:23:09 GMT"}], "update_date": "2014-02-07", "authors_parsed": [["Kish", "Laszlo B.", ""], ["Horvath", "Tamas", ""]]}, {"id": "0903.2171", "submitter": "Rick Kuhn", "authors": "David F. Ferraiolo and D. Richard Kuhn", "title": "Role-Based Access Controls", "comments": "pp. 554 - 563", "journal-ref": "15th National Computer Security Conference, Baltimore, MD. October\n  13-16, 1992", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Mandatory Access Controls (MAC) are appropriate for multilevel secure\nmilitary applications, Discretionary Access Controls (DAC) are often perceived\nas meeting the security processing needs of industry and civilian government.\nThis paper argues that reliance on DAC as the principal method of access\ncontrol is unfounded and inappropriate for many commercial and civilian\ngovernment organizations. The paper describes a type of non-discretionary\naccess control - role-based access control (RBAC) - that is more central to the\nsecure processing needs of non-military systems than DAC.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2009 14:00:28 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2009 13:53:46 GMT"}], "update_date": "2009-06-03", "authors_parsed": [["Ferraiolo", "David F.", ""], ["Kuhn", "D. Richard", ""]]}, {"id": "0903.2682", "submitter": "Abedelaziz Mohaisen", "authors": "Abedelaziz Mohaisen, Dowon Hong, and DaeHun Nyang", "title": "Privacy in Location Based Services: Primitives Toward the Solution", "comments": "Appeared in proceeding of NCM 2008", "journal-ref": null, "doi": "10.1109/NCM.2008.137", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Location based services (LBS) are one of the most promising and innovative\ndirections of convergence technologies resulting of emergence of several fields\nincluding database systems, mobile communication, Internet technology, and\npositioning systems. Although being initiated as early as middle of 1990's, it\nis only recently that the LBS received a systematic profound research interest\ndue to its commercial and technological impact. As the LBS is related to the\nuser's location which can be used to trace the user's activities, a strong\nprivacy concern has been raised. To preserve the user's location, several\nintelligent works have been introduced though many challenges are still\nawaiting solutions. This paper introduces a survey on LBS systems considering\nboth localization technologies, model and architectures guaranteeing privacy.\nWe also overview cryptographic primitive to possibly use in preserving LBS's\nprivacy followed by fruitful research directions basically concerned with the\nprivacy issue.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2009 01:31:58 GMT"}], "update_date": "2009-03-17", "authors_parsed": [["Mohaisen", "Abedelaziz", ""], ["Hong", "Dowon", ""], ["Nyang", "DaeHun", ""]]}, {"id": "0903.2693", "submitter": "Kang Ning", "authors": "Kang Ning", "title": "A Pseudo DNA Cryptography Method", "comments": "A small work that quite some people asked about", "journal-ref": null, "doi": "10.1016/j.compeleceng.2012.02.007", "report-no": null, "categories": "cs.CR cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The DNA cryptography is a new and very promising direction in cryptography\nresearch. DNA can be used in cryptography for storing and transmitting the\ninformation, as well as for computation. Although in its primitive stage, DNA\ncryptography is shown to be very effective. Currently, several DNA computing\nalgorithms are proposed for quite some cryptography, cryptanalysis and\nsteganography problems, and they are very powerful in these areas. However, the\nuse of the DNA as a means of cryptography has high tech lab requirements and\ncomputational limitations, as well as the labor intensive extrapolation means\nso far. These make the efficient use of DNA cryptography difficult in the\nsecurity world now. Therefore, more theoretical analysis should be performed\nbefore its real applications.\n  In this project, We do not intended to utilize real DNA to perform the\ncryptography process; rather, We will introduce a new cryptography method based\non central dogma of molecular biology. Since this method simulates some\ncritical processes in central dogma, it is a pseudo DNA cryptography method.\nThe theoretical analysis and experiments show this method to be efficient in\ncomputation, storage and transmission; and it is very powerful against certain\nattacks. Thus, this method can be of many uses in cryptography, such as an\nenhancement insecurity and speed to the other cryptography methods. There are\nalso extensions and variations to this method, which have enhanced security,\neffectiveness and applicability.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2009 04:22:45 GMT"}], "update_date": "2012-03-07", "authors_parsed": [["Ning", "Kang", ""]]}, {"id": "0903.2904", "submitter": "Andreas Bauer", "authors": "Andreas Bauer, Rajeev Gore, Alwen Tiu", "title": "A decidable policy language for history-based transaction monitoring", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-642-03466-4_6", "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online trading invariably involves dealings between strangers, so it is\nimportant for one party to be able to judge objectively the trustworthiness of\nthe other. In such a setting, the decision to trust a user may sensibly be\nbased on that user's past behaviour. We introduce a specification language\nbased on linear temporal logic for expressing a policy for categorising the\nbehaviour patterns of a user depending on its transaction history. We also\npresent an algorithm for checking whether the transaction history obeys the\nstated policy. To be useful in a real setting, such a language should allow one\nto express realistic policies which may involve parameter quantification and\nquantitative or statistical patterns. We introduce several extensions of linear\ntemporal logic to cater for such needs: a restricted form of universal and\nexistential quantification; arbitrary computable functions and relations in the\nterm language; and a \"counting\" quantifier for counting how many times a\nformula holds in the past. We then show that model checking a transaction\nhistory against a policy, which we call the history-based transaction\nmonitoring problem, is PSPACE-complete in the size of the policy formula and\nthe length of the history. The problem becomes decidable in polynomial time\nwhen the policies are fixed. We also consider the problem of transaction\nmonitoring in the case where not all the parameters of actions are observable.\nWe formulate two such \"partial observability\" monitoring problems, and show\ntheir decidability under certain restrictions.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2009 06:23:44 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Bauer", "Andreas", ""], ["Gore", "Rajeev", ""], ["Tiu", "Alwen", ""]]}, {"id": "0903.3182", "submitter": "Elena Dubrova", "authors": "Elena Dubrova", "title": "Finding matching initial states for equivalent NLFSRs in the fibonacci\n  and the galois configurations", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a mapping between initial states of the Fibonacci and the\nGalois configurations of NLFSRs is established. We show how to choose initial\nstates for two configurations so that the resulting output sequences are\nequivalent.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2009 15:29:31 GMT"}], "update_date": "2009-03-19", "authors_parsed": [["Dubrova", "Elena", ""]]}, {"id": "0903.3218", "submitter": "Josh Karlin", "authors": "Josh Karlin (University of New Mexico), Stephanie Forrest (University\n  of New Mexico and the Santa Fe Institute), Jennifer Rexford (Princeton\n  University)", "title": "Nation-State Routing: Censorship, Wiretapping, and BGP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The treatment of Internet traffic is increasingly affected by national\npolicies that require the ISPs in a country to adopt common protocols or\npractices. Examples include government enforced censorship, wiretapping, and\nprotocol deployment mandates for IPv6 and DNSSEC. If an entire nation's worth\nof ISPs apply common policies to Internet traffic, the global implications\ncould be significant. For instance, how many countries rely on China or Great\nBritain (known traffic censors) to transit their traffic? These kinds of\nquestions are surprisingly difficult to answer, as they require combining\ninformation collected at the prefix, Autonomous System, and country level, and\ngrappling with incomplete knowledge about the AS-level topology and routing\npolicies. In this paper we develop the first framework for country-level\nrouting analysis, which allows us to answer questions about the influence of\neach country on the flow of international traffic. Our results show that some\ncountries known for their national policies, such as Iran and China, have\nrelatively little effect on interdomain routing, while three countries (the\nUnited States, Great Britain, and Germany) are central to international\nreachability, and their policies thus have huge potential impact.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2009 18:38:30 GMT"}], "update_date": "2009-03-19", "authors_parsed": [["Karlin", "Josh", "", "University of New Mexico"], ["Forrest", "Stephanie", "", "University\n  of New Mexico and the Santa Fe Institute"], ["Rexford", "Jennifer", "", "Princeton\n  University"]]}, {"id": "0903.3276", "submitter": "Vitaly Shmatikov", "authors": "Arvind Narayanan, Vitaly Shmatikov", "title": "De-anonymizing Social Networks", "comments": "Published in the 30th IEEE Symposium on Security and Privacy, 2009.\n  The definitive version is available at:\n  http://www.cs.utexas.edu/~shmat/shmat_oak09.pdf Frequently Asked Questions\n  are answered at: http://www.cs.utexas.edu/~shmat/socialnetworks-faq.html", "journal-ref": null, "doi": "10.1109/SP.2009.22", "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operators of online social networks are increasingly sharing potentially\nsensitive information about users and their relationships with advertisers,\napplication developers, and data-mining researchers. Privacy is typically\nprotected by anonymization, i.e., removing names, addresses, etc.\n  We present a framework for analyzing privacy and anonymity in social networks\nand develop a new re-identification algorithm targeting anonymized\nsocial-network graphs. To demonstrate its effectiveness on real-world networks,\nwe show that a third of the users who can be verified to have accounts on both\nTwitter, a popular microblogging service, and Flickr, an online photo-sharing\nsite, can be re-identified in the anonymous Twitter graph with only a 12% error\nrate.\n  Our de-anonymization algorithm is based purely on the network topology, does\nnot require creation of a large number of dummy \"sybil\" nodes, is robust to\nnoise and all existing defenses, and works even when the overlap between the\ntarget network and the adversary's auxiliary information is small.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2009 06:55:46 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Narayanan", "Arvind", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "0903.3480", "submitter": "Teddy Furon", "authors": "Teddy Furon and Luis Perez-Freire", "title": "Worst case attacks against binary probabilistic traitor tracing codes", "comments": "submitted to IEEE Trans. on Information Forensics and Security", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An insightful view into the design of traitor tracing codes should\nnecessarily consider the worst case attacks that the colluders can lead. This\npaper takes an information-theoretic point of view where the worst case attack\nis defined as the collusion strategy minimizing the achievable rate of the\ntraitor tracing code. Two different decoders are envisaged, the joint decoder\nand the simple decoder, as recently defined by P. Moulin\n\\cite{Moulin08universal}. Several classes of colluders are defined with\nincreasing power. The worst case attack is derived for each class and each\ndecoder when applied to Tardos' codes and a probabilistic version of the\nBoneh-Shaw construction. This contextual study gives the real rates achievable\nby the binary probabilistic traitor tracing codes. Attacks usually considered\nin literature, such as majority or minority votes, are indeed largely\nsuboptimal. This article also shows the utmost importance of the time-sharing\nconcept in a probabilistic codes.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2009 09:44:23 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2009 09:16:06 GMT"}], "update_date": "2009-08-18", "authors_parsed": [["Furon", "Teddy", ""], ["Perez-Freire", "Luis", ""]]}, {"id": "0903.3786", "submitter": "Ruoheng Liu", "authors": "Ruoheng Liu, Tie Liu, H. Vincent Poor, Shlomo Shamai (Shitz)", "title": "Multiple-Input Multiple-Output Gaussian Broadcast Channels with\n  Confidential Messages", "comments": "Submitted to the IEEE Transactions on Information Theory, March 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper considers the problem of secret communication over a two-receiver\nmultiple-input multiple-output (MIMO) Gaussian broadcast channel. The\ntransmitter has two independent messages, each of which is intended for one of\nthe receivers but needs to be kept asymptotically perfectly secret from the\nother. It is shown that, surprisingly, under a matrix power constraint both\nmessages can be simultaneously transmitted at their respective maximal secrecy\nrates. To prove this result, the MIMO Gaussian wiretap channel is revisited and\na new characterization of its secrecy capacity is provided via a new coding\nscheme that uses artificial noise and random binning.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2009 04:26:25 GMT"}], "update_date": "2009-03-24", "authors_parsed": [["Liu", "Ruoheng", "", "Shitz"], ["Liu", "Tie", "", "Shitz"], ["Poor", "H. Vincent", "", "Shitz"], ["Shamai", "Shlomo", "", "Shitz"]]}, {"id": "0903.3900", "submitter": "Osman Ugus", "authors": "Osman Ugus, Dirk Westhoff, Ralf Laue, Abdulhadi Shoufan, and Sorin A.\n  Huss", "title": "Optimized Implementation of Elliptic Curve Based Additive Homomorphic\n  Encryption for Wireless Sensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When deploying wireless sensor networks (WSNs) in public environments it may\nbecome necessary to secure their data storage and transmission against possible\nattacks such as node-compromise and eavesdropping. The nodes feature only small\ncomputational and energy resources, thus requiring efficient algorithms. As a\nsolution for this problem the TinyPEDS approach was proposed in [7], which\nutilizes the Elliptic Curve ElGamal (EC-ElGamal) cryptosystem for additive\nhomomorphic encryption allowing concealed data aggregation. This work presents\nan optimized implementation of EC-ElGamal on a MicaZ mote, which is a typical\nsensor node platform with 8-bit processor for WSNs. Compared to the best\nprevious result, our implementation is at least 44% faster for fixed-point\nmultiplication. Because most parts of the algorithm are similar to standard\nElliptic Curve algorithms, the results may be reused in other realizations on\nconstrained devices as well.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2009 16:43:01 GMT"}], "update_date": "2009-03-24", "authors_parsed": [["Ugus", "Osman", ""], ["Westhoff", "Dirk", ""], ["Laue", "Ralf", ""], ["Shoufan", "Abdulhadi", ""], ["Huss", "Sorin A.", ""]]}, {"id": "0903.4014", "submitter": "Jun Muramatsu", "authors": "Jun Muramatsu and Shigeki Miyake", "title": "Construction of Codes for Wiretap Channel and Secret Key Agreement from\n  Correlated Source Outputs by Using Sparse Matrices", "comments": "A part of this paper is presented in part at 2009 IEEE Information\n  Theory Workshop (ITW2009), Taormina, Italy, pp.105-109, 2009. This paper is\n  submitted to IEEE Transactions on Information Theory. 34 pages", "journal-ref": "IEEE Transactions on Information Theory, vol. 58, no. 2, pp.\n  671-692, Feb. 2012", "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to prove coding theorems for the wiretap channel\ncoding problem and secret key agreement problem based on the the notion of a\nhash property for an ensemble of functions. These theorems imply that codes\nusing sparse matrices can achieve the optimal rate. Furthermore, fixed-rate\nuniversal coding theorems for a wiretap channel and a secret key agreement are\nalso proved.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2009 05:29:04 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2010 06:22:59 GMT"}], "update_date": "2012-05-22", "authors_parsed": [["Muramatsu", "Jun", ""], ["Miyake", "Shigeki", ""]]}, {"id": "0903.4258", "submitter": "Martin Burkhart", "authors": "Martin Burkhart, Mario Strasser, Dilip Many, Xenofontas Dimitropoulos", "title": "SEPIA: Security through Private Information Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": "TIK-Report No. 298", "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure multiparty computation (MPC) allows joint privacy-preserving\ncomputations on data of multiple parties. Although MPC has been studied\nsubstantially, building solutions that are practical in terms of computation\nand communication cost is still a major challenge. In this paper, we\ninvestigate the practical usefulness of MPC for multi-domain network security\nand monitoring. We first optimize MPC comparison operations for processing high\nvolume data in near real-time. We then design privacy-preserving protocols for\nevent correlation and aggregation of network traffic statistics, such as\naddition of volume metrics, computation of feature entropy, and distinct item\ncount. Optimizing performance of parallel invocations, we implement our\nprotocols along with a complete set of basic operations in a library called\nSEPIA. We evaluate the running time and bandwidth requirements of our protocols\nin realistic settings on a local cluster as well as on PlanetLab and show that\nthey work in near real-time for up to 140 input providers and 9 computation\nnodes. Compared to implementations using existing general-purpose MPC\nframeworks, our protocols are significantly faster, requiring, for example, 3\nminutes for a task that takes 2 days with general-purpose frameworks. This\nimprovement paves the way for new applications of MPC in the area of\nnetworking. Finally, we run SEPIA's protocols on real traffic traces of 17\nnetworks and show how they provide new possibilities for distributed\ntroubleshooting and early anomaly detection.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2009 08:23:07 GMT"}, {"version": "v2", "created": "Wed, 13 May 2009 08:07:39 GMT"}, {"version": "v3", "created": "Fri, 2 Oct 2009 12:55:49 GMT"}, {"version": "v4", "created": "Tue, 16 Feb 2010 16:10:46 GMT"}], "update_date": "2010-02-16", "authors_parsed": [["Burkhart", "Martin", ""], ["Strasser", "Mario", ""], ["Many", "Dilip", ""], ["Dimitropoulos", "Xenofontas", ""]]}, {"id": "0903.4510", "submitter": "Kunal Talwar", "authors": "Anupam Gupta, Katrina Ligett, Frank McSherry, Aaron Roth and Kunal\n  Talwar", "title": "Differentially Private Combinatorial Optimization", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the following problem: given a metric space, some of whose points\nare \"clients\", open a set of at most $k$ facilities to minimize the average\ndistance from the clients to these facilities. This is just the well-studied\n$k$-median problem, for which many approximation algorithms and hardness\nresults are known. Note that the objective function encourages opening\nfacilities in areas where there are many clients, and given a solution, it is\noften possible to get a good idea of where the clients are located. However,\nthis poses the following quandary: what if the identity of the clients is\nsensitive information that we would like to keep private? Is it even possible\nto design good algorithms for this problem that preserve the privacy of the\nclients?\n  In this paper, we initiate a systematic study of algorithms for discrete\noptimization problems in the framework of differential privacy (which\nformalizes the idea of protecting the privacy of individual input elements). We\nshow that many such problems indeed have good approximation algorithms that\npreserve differential privacy; this is even in cases where it is impossible to\npreserve cryptographic definitions of privacy while computing any non-trivial\napproximation to even the_value_ of an optimal solution, let alone the entire\nsolution.\n  Apart from the $k$-median problem, we study the problems of vertex and set\ncover, min-cut, facility location, Steiner tree, and the recently introduced\nsubmodular maximization problem, \"Combinatorial Public Projects\" (CPP).\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2009 05:08:46 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2009 01:19:22 GMT"}], "update_date": "2009-11-11", "authors_parsed": [["Gupta", "Anupam", ""], ["Ligett", "Katrina", ""], ["McSherry", "Frank", ""], ["Roth", "Aaron", ""], ["Talwar", "Kunal", ""]]}, {"id": "0903.5177", "submitter": "Shlomi Dolev", "authors": "Shlomi Dolev, Marina Kopeetsky, Adi Shamir", "title": "RFID Authentication, Efficient Proactive Information Security within\n  Computational Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider repeated communication sessions between a RFID Tag (e.g., Radio\nFrequency Identification, RFID Tag) and a RFID Verifier. A proactive\ninformation theoretic security scheme is proposed. The scheme is based on the\nassumption that the information exchanged during at least one of every n\nsuccessive communication sessions is not exposed to an adversary. The Tag and\nthe Verifier maintain a vector of n entries that is repeatedly refreshed by\npairwise xoring entries, with a new vector of n entries that is randomly chosen\nby the Tag and sent to the Verifier as a part of each communication session.\nThe general case in which the adversary does not listen in k > 0 sessions among\nany n successive communication sessions is also considered. A lower bound of\nn(k+1) for the number of random numbers used during any n successive\ncommunication sessions is proven. In other words, we prove that an algorithm\nmust use at least n(k+1) new random numbers during any n successive\ncommunication sessions. Then a randomized scheme that uses only O(n log n) new\nrandom numbers is presented. A computational secure scheme which is based on\nthe information theoretic secure scheme is used to ensure that even in the case\nthat the adversary listens in all the information exchanges, the communication\nbetween the Tag and the Verifier is secure.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2009 10:43:45 GMT"}], "update_date": "2009-03-31", "authors_parsed": [["Dolev", "Shlomi", ""], ["Kopeetsky", "Marina", ""], ["Shamir", "Adi", ""]]}]