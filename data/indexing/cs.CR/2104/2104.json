[{"id": "2104.00176", "submitter": "Abhishek Kulkarni", "authors": "Abhishek N. Kulkarni, Shuo Han, Nandi O. Leslie, Charles A. Kamhoua,\n  and Jie Fu", "title": "Qualitative Planning in Imperfect Information Games with Active Sensing\n  and Reactive Sensor Attacks: Cost of Unawareness", "comments": "7 pages, 5 figures, Submitted to CDC2021; Revised Alg. 2 to fix a\n  typo and notation, results unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.FL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the probabilistic planning problem where the agent (called Player\n1, or P1) can jointly plan the control actions and sensor queries in a sensor\nnetwork and an attacker (called player 2, or P2) can carry out attacks on the\nsensors. We model such an adversarial interaction using a formal model -- a\nreachability game with partially controllable observation functions. The main\ncontribution of this paper is to assess the cost of P1's unawareness: Suppose\nP1 misinterprets the sensor failures as probabilistic node failures due to\nunreliable network communication, and P2 is aware of P1's misinterpretation in\naddition to her partial observability. Then, from which states can P2 carry out\nsensor attacks to ensure, with probability one, that P1 will not be able to\ncomplete her reachability task even though, due to misinterpretation, P1\nbelieves that she can almost-surely achieve her task. We develop an algorithm\nto solve the almost-sure winning sensor-attack strategy given P1's\nobservation-based strategy. Our attack analysis could be used for attack\ndetection in wireless communication networks and the design of provably secured\nattack-aware sensor allocation in decision-theoretic models for cyber-physical\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 00:43:10 GMT"}, {"version": "v2", "created": "Sun, 2 May 2021 18:55:10 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Kulkarni", "Abhishek N.", ""], ["Han", "Shuo", ""], ["Leslie", "Nandi O.", ""], ["Kamhoua", "Charles A.", ""], ["Fu", "Jie", ""]]}, {"id": "2104.00236", "submitter": "Jack Li", "authors": "Jianhua Li, Ximeng Liu, Jiong Jin, Shui Yu", "title": "Too Expensive to Attack: A Joint Defense Framework to Mitigate\n  Distributed Attacks for the Internet of Things Grid", "comments": "10 pages, 10 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The distributed denial of service (DDoS) attack is detrimental to businesses\nand individuals as we are heavily relying on the Internet. Due to remarkable\nprofits, crackers favor DDoS as cybersecurity weapons in attacking servers,\ncomputers, IoT devices, and even the entire Internet. Many current detection\nand mitigation solutions concentrate on specific technologies in combating\nDDoS, whereas the attacking expense and the cross-defender collaboration have\nnot drawn enough attention. Under this circumstance, we revisit the DDoS attack\nand defense in terms of attacking cost and populations of both parties,\nproposing a joint defense framework to incur higher attacking expense in a grid\nof Internet service providers (ISPs), businesses, individuals, and third-party\norganizations (IoT Grid). Meanwhile, the defender's cost does not grow much\nduring combats. The skyrocket of attacking expense discourages profit-driven\nattackers from launching further attacks effectively. The quantitative\nevaluation and experimental assessment reinforce the effectiveness of our\nframework.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 03:40:29 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Li", "Jianhua", ""], ["Liu", "Ximeng", ""], ["Jin", "Jiong", ""], ["Yu", "Shui", ""]]}, {"id": "2104.00245", "submitter": "Zhe Zhang", "authors": "Zhe Zhang and Linjun Zhang", "title": "High-Dimensional Differentially-Private EM Algorithm: Methods and\n  Near-Optimal Statistical Guarantees", "comments": "45 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a general framework to design differentially\nprivate expectation-maximization (EM) algorithms in high-dimensional latent\nvariable models, based on the noisy iterative hard-thresholding. We derive the\nstatistical guarantees of the proposed framework and apply it to three specific\nmodels: Gaussian mixture, mixture of regression, and regression with missing\ncovariates. In each model, we establish the near-optimal rate of convergence\nwith differential privacy constraints, and show the proposed algorithm is\nminimax rate optimal up to logarithm factors. The technical tools developed for\nthe high-dimensional setting are then extended to the classic low-dimensional\nlatent variable models, and we propose a near rate-optimal EM algorithm with\ndifferential privacy guarantees in this setting. Simulation studies and real\ndata analysis are conducted to support our results.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 04:08:34 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Zhang", "Zhe", ""], ["Zhang", "Linjun", ""]]}, {"id": "2104.00284", "submitter": "Benjamin Shreeve Dr", "authors": "Benjamin Shreeve, Joseph Hallett, Matthew Edwards, Kopo M. Ramokapane,\n  Richard Atkins and Awais Rashid", "title": "The best laid plans or lack thereof: Security decision-making of\n  different stakeholder groups", "comments": "13 pages plus 2 page appendix. IEEE Transactions on Software\n  Engineering 2020", "journal-ref": null, "doi": "10.1109/TSE.2020.3023735", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber security requirements are influenced by the priorities and decisions of\na range of stakeholders. Board members and CISOs determine strategic\npriorities. Managers have responsibility for resource allocation and project\nmanagement. Legal professionals concern themselves with regulatory compliance.\nLittle is understood about how the security decision-making approaches of these\ndifferent stakeholders contrast, and if particular groups of stakeholders have\na better appreciation of security requirements during decision-making. Are risk\nanalysts better decision makers than CISOs? Do security experts exhibit more\neffective strategies than board members? This paper explores the effect that\ndifferent experience and diversity of expertise has on the quality of a team's\ncyber security decision-making and whether teams with members from more varied\nbackgrounds perform better than those with more focused, homogeneous skill\nsets. Using data from 208 sessions and 948 players of a tabletop game run in\nthe wild by a major national organization over 16 months, we explore how\nchoices are affected by player background (e.g.,~cyber security experts versus\nrisk analysts, board-level decision makers versus technical experts) and\ndifferent team make-ups (homogeneous teams of security experts versus various\nmixes). We find that no group of experts makes significantly better game\ndecisions than anyone else, and that their biases lead them to not fully\ncomprehend what they are defending or how the defenses work.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 06:41:59 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Shreeve", "Benjamin", ""], ["Hallett", "Joseph", ""], ["Edwards", "Matthew", ""], ["Ramokapane", "Kopo M.", ""], ["Atkins", "Richard", ""], ["Rashid", "Awais", ""]]}, {"id": "2104.00296", "submitter": "Bhagyashri Tushir", "authors": "Holden Gordon, Christopher Batula, Bhagyashri Tushir, Behnam Dezfouli,\n  Yuhong Liu", "title": "Securing Smart Homes via Software-Defined Networking and Low-Cost\n  Traffic Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IoT devices have become popular targets for various network attacks due to\ntheir lack of industry-wide security standards. In this work, we focus on smart\nhome IoT device identification and defending them against Distributed Denial of\nService (DDoS) attacks. The proposed framework protects smart homes by using\nVLAN-based network isolation. This architecture has two VLANs: one with\nnon-verified devices and the other with verified devices, both of which are\nmanaged by the SDN controller. Lightweight stateless flow-based features,\nincluding ICMP, TCP, and UDP protocol percentage, packet count and size, and IP\ndiversity ratio, are proposed for efficient feature collections. Further\nanalysis is performed to minimize training data to run on resource-constrained\nedge devices in smart home networks. Three popular machine learning algorithms,\nincluding K-Nearest-Neighbors, Random Forest, and Support Vector Machines, are\nused to classify IoT devices and detect different types of DDoS attacks,\nincluding TCP-SYN, UDP, and ICMP. The system's effectiveness and efficiency are\nevaluated by emulating a network consisting of an Open vSwitch, Faucet SDN\ncontroller, and several IoT device traces from two different testbeds.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 07:05:39 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 21:27:10 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Gordon", "Holden", ""], ["Batula", "Christopher", ""], ["Tushir", "Bhagyashri", ""], ["Dezfouli", "Behnam", ""], ["Liu", "Yuhong", ""]]}, {"id": "2104.00447", "submitter": "Zhaoyang Lyu", "authors": "Zhaoyang Lyu, Minghao Guo, Tong Wu, Guodong Xu, Kehuan Zhang, Dahua\n  Lin", "title": "Towards Evaluating and Training Verifiably Robust Neural Networks", "comments": "Accepted to CVPR 2021 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent works have shown that interval bound propagation (IBP) can be used to\ntrain verifiably robust neural networks. Reseachers observe an intriguing\nphenomenon on these IBP trained networks: CROWN, a bounding method based on\ntight linear relaxation, often gives very loose bounds on these networks. We\nalso observe that most neurons become dead during the IBP training process,\nwhich could hurt the representation capability of the network. In this paper,\nwe study the relationship between IBP and CROWN, and prove that CROWN is always\ntighter than IBP when choosing appropriate bounding lines. We further propose a\nrelaxed version of CROWN, linear bound propagation (LBP), that can be used to\nverify large networks to obtain lower verified errors than IBP. We also design\na new activation function, parameterized ramp function (ParamRamp), which has\nmore diversity of neuron status than ReLU. We conduct extensive experiments on\nMNIST, CIFAR-10 and Tiny-ImageNet with ParamRamp activation and achieve\nstate-of-the-art verified robustness. Code and the appendix are available at\nhttps://github.com/ZhaoyangLyu/VerifiablyRobustNN.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 13:03:48 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 02:31:33 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 07:11:50 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Lyu", "Zhaoyang", ""], ["Guo", "Minghao", ""], ["Wu", "Tong", ""], ["Xu", "Guodong", ""], ["Zhang", "Kehuan", ""], ["Lin", "Dahua", ""]]}, {"id": "2104.00460", "submitter": "Lampis Alevizos", "authors": "Lampis Alevizos, Vinh Thong Ta, Max Hashem Eiza", "title": "Augmenting Zero Trust Architecture to Endpoints Using Blockchain: A\n  Systematic Review", "comments": "(1) Fixed the reference numbering (2) Fixed syntax errors,\n  improvements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the purpose of defending against lateral movement in todays borderless\nnetworks, Zero Trust Architecture (ZTA) adoption is gaining momentum.\nConsidering a full scale ZTA implementation, it is unlikely that adversaries\nwill be able to spread through the network starting from a compromised\nendpoint. However, the already authenticated and authorised session of the\ncompromised endpoint can be leveraged to perform limited, though malicious\nactivities, ultimately rendering the endpoints the Achilles heel of ZTA. To\neffectively detect such attacks, distributed collaborative intrusion detection\nsystems with attack scenario-based approach have been developed. Nonetheless,\nAdvanced Persistent Threats (APTs) have demonstrated their ability to bypass\nthis approach with high success ratio. As a result, adversaries can pass\nundetected or potentially alter the detection logging mechanisms to achieve a\nstealthy presence. Recently, blockchain technology has demonstrated solid use\ncases in the cyber security domain. Motivated by the convergence of ZTA and\nblockchain-based intrusion detection and prevention, in this paper, we examine\nhow ZTA can be augmented onto endpoints. Namely, we perform a systematic review\nof ZTA models, real-world architectures with the focus on endpoints, and\nblockchain-based intrusion detection systems. We discuss the potential of\nblockchains immutability fortifying the detection process, and the identified\nopen challenges as well as the possible solutions and future directions.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 13:44:29 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 22:31:44 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 20:26:23 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Alevizos", "Lampis", ""], ["Ta", "Vinh Thong", ""], ["Eiza", "Max Hashem", ""]]}, {"id": "2104.00461", "submitter": "Klaus V. Gleissenthall", "authors": "Rami Gokhan Kici and Klaus v. Gleissenthall and Deian Stefan and\n  Ranjit Jhala", "title": "Solver-Aided Constant-Time Circuit Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Xenon, a solver-aided method for formally verifying that Verilog\nhardware executes in constant-time. Xenon scales to realistic hardware designs\nby drastically reducing the effort needed to localize the root cause of\nverification failures via a new notion of constant-time counterexamples, which\nXenon uses to automatically synthesize a minimal set of secrecy assumptions.\nXenon further exploits modularity in Verilog code via a notion of module\nsummaries, thereby avoiding duplicate work across multiple module\ninstantiations. We show how Xenon's assumption synthesis and summaries enable\nthe verification of a variety of circuits including AES, a highly modular\nAES-256 implementation where modularity cuts verification from six hours to\nunder three seconds, and ScarV, a timing channel hardened RISC-V\nmicro-controller whose size exceeds previously verified designs by an order of\nmagnitude.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 13:44:53 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Kici", "Rami Gokhan", ""], ["Gleissenthall", "Klaus v.", ""], ["Stefan", "Deian", ""], ["Jhala", "Ranjit", ""]]}, {"id": "2104.00489", "submitter": "Pavlos Papadopoulos", "authors": "Daniele Romanini, Adam James Hall, Pavlos Papadopoulos, Tom Titcombe,\n  Abbas Ismail, Tudor Cebere, Robert Sandmann, Robin Roehm, Michael A. Hoeh", "title": "PyVertical: A Vertical Federated Learning Framework for Multi-headed\n  SplitNN", "comments": "ICLR 2021 Workshop on Distributed and Private Machine Learning (DPML\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce PyVertical, a framework supporting vertical federated learning\nusing split neural networks. The proposed framework allows a data scientist to\ntrain neural networks on data features vertically partitioned across multiple\nowners while keeping raw data on an owner's device. To link entities shared\nacross different datasets' partitions, we use Private Set Intersection on IDs\nassociated with data points. To demonstrate the validity of the proposed\nframework, we present the training of a simple dual-headed split neural network\nfor a MNIST classification task, with data samples vertically distributed\nacross two data owners and a data scientist.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 14:21:33 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 18:15:08 GMT"}, {"version": "v3", "created": "Wed, 14 Apr 2021 08:05:04 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Romanini", "Daniele", ""], ["Hall", "Adam James", ""], ["Papadopoulos", "Pavlos", ""], ["Titcombe", "Tom", ""], ["Ismail", "Abbas", ""], ["Cebere", "Tudor", ""], ["Sandmann", "Robert", ""], ["Roehm", "Robin", ""], ["Hoeh", "Michael A.", ""]]}, {"id": "2104.00547", "submitter": "Michael Kuperberg", "authors": "Michael Kuperberg, Matthias Geipel", "title": "Blockchain and BIM (Building Information Modeling): Progress in Academia\n  and Industry", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In construction, BIM (Building Information Modeling) promises to increase\nquality of data and to provide a shared, uniform view to all parties. While BIM\ntools and exchange formats exist, the distribution and safeguarding of data is\nan ongoing challenge. Distributed Ledger Technology and Blockchains offer a\npossible solution to this task, and they promise quality attributes such as\ntamper resistance, traceability/auditability and safe digitalization of assets\nand intellectual property. However, the practical application and adoption of\nDistributed Ledger Technology in the built environment requires a good\nunderstanding of tool maturity, performance and standardization. Also,\nuser-oriented integration of BIM tools with the blockchain backend needs\nattention. The contribution of this paper is an overview over both industrial\nand academic progress at the intersection of BIM and blockchains/DLT.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 15:34:20 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 06:12:10 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Kuperberg", "Michael", ""], ["Geipel", "Matthias", ""]]}, {"id": "2104.00604", "submitter": "Simon Hinga Mr.", "authors": "Simon Karanja Hinga", "title": "Design and development of an Aerial Surveillance Security System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Aerial security means performing security-aimed monitoring and surveillance\noperations with the help of airborne vehicles. This kind of activities suggest\nthat human officers (security organizations, law enforcement, police etc.)\nwould be able to remotely monitor and view video and data acquired from Drones\nwhile planning and evaluating their operations. The spectrum of applications\nwhere drones are used for security purposes is vast: scouting and reporting\nemergencies, monitoring accidents and crimes, surveillance of a certain\nlandscape area, operating in highly busy and pedestrians as well as their\ntracking from up in the sky, and so on. The project will serve as a bridge to\nconnect actual happening in areas that cannot be navigated easily by security\npersonnel of corporate institution as the Drone will be used to hover and\nrecord the actual happening as it transmit to a ground station which records\nand analyses the events as they streams in, also due its capability of flying\nover different altitudes the drone can generally be used on areas with rugged\nterrains or over water bodies for a time dependent on its power capacity.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 16:35:57 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Hinga", "Simon Karanja", ""]]}, {"id": "2104.00634", "submitter": "Gias Uddin", "authors": "Gias Uddin", "title": "Security and Machine Learning Adoption in IoT: A Preliminary Study of\n  IoT Developer Discussions", "comments": null, "journal-ref": "2021 3rd International Workshop on Software Engineering Research &\n  Practices for the Internet of Things (SERP4IoT)", "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) is defined as the connection between places and\nphysical objects (i.e., things) over the internet/network via smart computing\ndevices. Traditionally, we learn about the IoT ecosystem/problems by conducting\nsurveys of IoT developers/practitioners. Another way to learn is by analyzing\nIoT developer discussions in popular online developer forums like Stack\nOverflow (SO). However, we are aware of no such studies that focused on IoT\ndevelopers' security and ML-related discussions in SO. This paper offers the\nresults of preliminary study of IoT developer discussions in SO. We find around\n12% of sentences contain security discussions, while around 0.12% sentences\ncontain ML- related discussions. We find that IoT developers discussing\nsecurity issues frequently inquired about how the shared data can be stored,\nshared, and transferred securely across IoT devices and users. We also find\nthat IoT developers are interested to adopt deep neural network-based ML models\ninto their IoT devices, but they find it challenging to accommodate those into\ntheir resource-constrained IoT devices. Our findings offer implications for IoT\nvendors and researchers to develop and design novel techniques for improved\nsecurity and ML adoption into IoT devices.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 17:27:46 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Uddin", "Gias", ""]]}, {"id": "2104.00648", "submitter": "AKM Bahalul Haque", "authors": "AKM Bahalul Haque, AKM Najmul Islam, Sami Hyrynsalmi, Bilal Naqvi, and\n  Kari Smolander", "title": "GDPR Compliant Blockchains-A Systematic Literature Review", "comments": "Accepted for Publication in IEEE Access", "journal-ref": "IEEE Access , 2021", "doi": "10.1109/ACCESS.2021.3069877", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although blockchain-based digital services promise trust, accountability, and\ntransparency, multiple paradoxes between blockchains and GDPR have been\nhighlighted in the recent literature. Some of the recent literature also\nproposed possible solutions to these paradoxes. This article aims to conduct a\nsystematic literature review on GDPR compliant blockchains and synthesize the\nfindings. In particular, the goal was to identify 1) the GDPR articles that\nhave been explored in prior literature; 2) the relevant research domains that\nhave been explored, and 3) the research gaps. Our findings synthesized that the\nblockchains relevant GDPR articles can be categorized into six major groups,\nnamely data deletion and modification (Article 16, 17, and 18), protection by\ndesign by default (Article 25), responsibilities of controllers and processors\n(Article 24, 26, and 28), consent management (Article 7), data processing\nprinciples and lawfulness (Article 5,6 and 12), and territorial scope (Article\n3). We also found seven research domains where GDPR compliant blockchains have\nbeen discussed, which include IoT, financial data, healthcare, personal\nidentity, online data, information governance, and smart city. From our\nanalysis, we have identified a few key research gaps and present a future\nresearch direction.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 17:44:59 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Haque", "AKM Bahalul", ""], ["Islam", "AKM Najmul", ""], ["Hyrynsalmi", "Sami", ""], ["Naqvi", "Bilal", ""], ["Smolander", "Kari", ""]]}, {"id": "2104.00654", "submitter": "Bo Chen", "authors": "Bo Chen, Calvin Hawkins, Kasra Yazdani, Matthew Hale", "title": "Edge Differential Privacy for Algebraic Connectivity of Graphs", "comments": "8 pages, 5 figures, submitted to 60th IEEE Conference on Decision and\n  Control 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MA cs.SI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are the dominant formalism for modeling multi-agent systems. The\nalgebraic connectivity of a graph is particularly important because it provides\nthe convergence rates of consensus algorithms that underlie many multi-agent\ncontrol and optimization techniques. However, sharing the value of algebraic\nconnectivity can inadvertently reveal sensitive information about the topology\nof a graph, such as connections in social networks. Therefore, in this work we\npresent a method to release a graph's algebraic connectivity under a\ngraph-theoretic form of differential privacy, called edge differential privacy.\nEdge differential privacy obfuscates differences among graphs' edge sets and\nthus conceals the absence or presence of sensitive connections therein. We\nprovide privacy with bounded Laplace noise, which improves accuracy relative to\nconventional unbounded noise. The private algebraic connectivity values are\nanalytically shown to provide accurate estimates of consensus convergence\nrates, as well as accurate bounds on the diameter of a graph and the mean\ndistance between its nodes. Simulation results confirm the utility of private\nalgebraic connectivity in these contexts.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 17:50:18 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Chen", "Bo", ""], ["Hawkins", "Calvin", ""], ["Yazdani", "Kasra", ""], ["Hale", "Matthew", ""]]}, {"id": "2104.00687", "submitter": "Gregory D. Kahanamoku-Meyer", "authors": "Gregory D. Kahanamoku-Meyer, Soonwon Choi, Umesh V. Vazirani, Norman\n  Y. Yao", "title": "Classically-Verifiable Quantum Advantage from a Computational Bell Test", "comments": "11 pages, 4 figures, 1 table (main text); 10 pages, 1 table (methods\n  + supplementary information)", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and analyze a novel interactive protocol for demonstrating quantum\ncomputational advantage, which is efficiently classically verifiable. Our\nprotocol relies upon the cryptographic hardness of trapdoor claw-free functions\n(TCFs). Through a surprising connection to Bell's inequality, our protocol\navoids the need for an adaptive hardcore bit, with essentially no increase in\nthe quantum circuit complexity and no extra cryptographic assumptions.\nCrucially, this expands the set of compatible TCFs, and we propose two new\nconstructions: one based upon the decisional Diffie-Hellman problem and the\nother based upon Rabin's function, $x^2 \\bmod N$. We also describe two unique\nfeatures of our interactive protocol: (i) it allows one to discard so-called\n\"garbage bits\", thereby removing the need for reversibility in the quantum\ncircuits, and (ii) there exists a natural post-selection scheme, which\nsignificantly reduces the fidelity needed to demonstrate quantum advantage.\nFinally, we design several efficient circuits for $x^2 \\bmod N$ and describe a\nblueprint for their implementation on a Rydberg-atom-based quantum computer.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 18:00:00 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Kahanamoku-Meyer", "Gregory D.", ""], ["Choi", "Soonwon", ""], ["Vazirani", "Umesh V.", ""], ["Yao", "Norman Y.", ""]]}, {"id": "2104.00779", "submitter": "Filipo Sharevski", "authors": "Filipo Sharevski, Raniem Alsaadi, Peter Jachim, Emma Pieroni", "title": "Misinformation Warning Labels: Twitter's Soft Moderation Effects on\n  COVID-19 Vaccine Belief Echoes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Twitter, prompted by the rapid spread of alternative narratives, started\nactively warning users about the spread of COVID-19 misinformation. This form\nof soft moderation comes in two forms: as a warning cover before the Tweet is\ndisplayed to the user and as a warning tag below the Tweet. This study\ninvestigates how each of the soft moderation forms affects the perceived\naccuracy of COVID-19 vaccine misinformation on Twitter. The results suggest\nthat the warning covers work, but not the tags, in reducing the perception of\naccuracy of COVID-19 vaccine misinformation on Twitter. \"Belief echoes\" do\nexist among Twitter users, unfettered by any warning labels, in relationship to\nthe perceived safety and efficacy of the COVID-19 vaccine as well as the\nvaccination hesitancy for themselves and their children. The implications of\nthese results are discussed in the context of usable security affordances for\ncombating misinformation on social media.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 21:50:19 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Sharevski", "Filipo", ""], ["Alsaadi", "Raniem", ""], ["Jachim", "Peter", ""], ["Pieroni", "Emma", ""]]}, {"id": "2104.00782", "submitter": "Filipo Sharevski", "authors": "Peter Jachim, Filipo Sharevski, Emma Pieroni", "title": "\"TL;DR:\" Out-of-Context Adversarial Text Summarization and Hashtag\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents Out-of-Context Summarizer, a tool that takes arbitrary\npublic news articles out of context by summarizing them to coherently fit\neither a liberal- or conservative-leaning agenda. The Out-of-Context Summarizer\nalso suggests hashtag keywords to bolster the polarization of the summary, in\ncase one is inclined to take it to Twitter, Parler or other platforms for\ntrolling. Out-of-Context Summarizer achieved 79% precision and 99% recall when\nsummarizing COVID-19 articles, 93% precision and 93% recall when summarizing\npolitically-centered articles, and 87% precision and 88% recall when taking\nliberally-biased articles out of context. Summarizing valid sources instead of\nsynthesizing fake text, the Out-of-Context Summarizer could fairly pass the\n\"adversarial disclosure\" test, but we didn't take this easy route in our paper.\nInstead, we used the Out-of-Context Summarizer to push the debate of potential\nmisuse of automated text generation beyond the boilerplate text of responsible\ndisclosure of adversarial language models.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 22:03:44 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Jachim", "Peter", ""], ["Sharevski", "Filipo", ""], ["Pieroni", "Emma", ""]]}, {"id": "2104.00822", "submitter": "Maximiliano Cristia", "authors": "Adri\\'an Silveira and Gustavo Betarte and Maximiliano Cristi\\'a and\n  Carlos Luna", "title": "A Formal Analysis of the MimbleWimble Cryptocurrency Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  MimbleWimble (MW) is a privacy-oriented cryptocurrency technology which\nprovides security and scalability properties that distinguish it from other\nprotocols of its kind. We present and discuss those properties and outline the\nbasis of a model-driven verification approach to address the certification of\nthe correctness of the protocol implementations. In particular, we propose an\nidealized model that is key in the described verification process, and identify\nand precisely state sufficient conditions for our model to ensure the\nverification of relevant security properties of MW. Since MW is built on top of\na consensus protocol, we develop a Z specification of one such protocol and\npresent an excerpt of the $\\{log\\}$ prototype generated from the Z\nspecification. This $\\{log\\}$ prototype can be used as an executable model\nwhere simulations can be run. This allows us to analyze the behavior of the\nprotocol without having to implement it in a low level programming language.\nFinally, we analyze the Grin and Beam implementations of MW in their current\nstate of development.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 00:15:30 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Silveira", "Adri\u00e1n", ""], ["Betarte", "Gustavo", ""], ["Cristi\u00e1", "Maximiliano", ""], ["Luna", "Carlos", ""]]}, {"id": "2104.00832", "submitter": "Guntur Dharma Putra", "authors": "Guntur Dharma Putra, Volkan Dedeoglu, Salil S Kanhere, Raja Jurdak,\n  Aleksandar Ignjatovic", "title": "Trust-based Blockchain Authorization for IoT", "comments": "12 pages, 10 figures, submitted to IEEE Transactions on Network and\n  Service Management", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Authorization or access control limits the actions a user may perform on a\ncomputer system, based on predetermined access control policies, thus\npreventing access by illegitimate actors. Access control for the Internet of\nThings (IoT) should be tailored to take inherent IoT network scale and device\nresource constraints into consideration. However, common authorization systems\nin IoT employ conventional schemes, which suffer from overheads and\ncentralization. Recent research trends suggest that blockchain has the\npotential to tackle the issues of access control in IoT. However, proposed\nsolutions overlook the importance of building dynamic and flexible access\ncontrol mechanisms. In this paper, we design a decentralized attribute-based\naccess control mechanism with an auxiliary Trust and Reputation System (TRS)\nfor IoT authorization. Our system progressively quantifies the trust and\nreputation scores of each node in the network and incorporates the scores into\nthe access control mechanism to achieve dynamic and flexible access control. We\ndesign our system to run on a public blockchain, but we separate the storage of\nsensitive information, such as user's attributes, to private sidechains for\nprivacy preservation. We implement our solution in a public Rinkeby Ethereum\ntest-network interconnected with a lab-scale testbed. Our evaluations consider\nvarious performance metrics to highlight the applicability of our solution for\nIoT contexts.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 01:09:34 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Putra", "Guntur Dharma", ""], ["Dedeoglu", "Volkan", ""], ["Kanhere", "Salil S", ""], ["Jurdak", "Raja", ""], ["Ignjatovic", "Aleksandar", ""]]}, {"id": "2104.00863", "submitter": "Philip Derbeko", "authors": "Philip Derbeko and Shlomi Dolev", "title": "PolyDNN: Polynomial Representation of NN for Communication-less SMPC\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The structure and weights of Deep Neural Networks (DNN) typically encode and\ncontain very valuable information about the dataset that was used to train the\nnetwork.\n  One way to protect this information when DNN is published is to perform an\ninterference of the network using secure multi-party computations (MPC).\n  In this paper, we suggest a translation of deep neural networks to\npolynomials, which are easier to calculate efficiently with MPC techniques.\n  We show a way to translate complete networks into a single polynomial and how\nto calculate the polynomial with an efficient and information-secure MPC\nalgorithm.\n  The calculation is done without intermediate communication between the\nparticipating parties, which is beneficial in several cases, as explained in\nthe paper.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 02:59:37 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 03:24:20 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Derbeko", "Philip", ""], ["Dolev", "Shlomi", ""]]}, {"id": "2104.00872", "submitter": "Matvey Soloviev", "authors": "Matvey Soloviev, Joseph Y. Halpern", "title": "Security Properties as Nested Causal Statements", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thinking in terms of causality helps us structure how different parts of a\nsystem depend on each other, and how interventions on one part of a system may\nresult in changes to other parts. Therefore, formal models of causality are an\nattractive tool for reasoning about security, which concerns itself with\nsafeguarding properties of a system against interventions that may be\nmalicious. As we show, many security properties are naturally expressed as\nnested causal statements: not only do we consider what caused a particular\nundesirable effect, but we also consider what caused this causal relationship\nitself to hold. We present a natural way to extend the Halpern-Pearl (HP)\nframework for causality to capture such nested causal statements. This\nextension adds expressivity, enabling the HP framework to distinguish between\ncausal scenarios that it could not previously naturally tell apart. We moreover\nrevisit some design decisions of the HP framework that were made with\nnon-nested causal statements in mind, such as the choice to treat specific\nvalues of causal variables as opposed to the variables themselves as causes,\nand may no longer be appropriate for nested ones.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 03:29:00 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Soloviev", "Matvey", ""], ["Halpern", "Joseph Y.", ""]]}, {"id": "2104.01011", "submitter": "Amir Mohammad Naseri", "authors": "Amir Mohammad Naseri, Walter Lucia, Mohammad Mannan, Amr Youssef", "title": "On Securing Cloud-hosted Cyber-physical Systems Using Trusted Execution\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, cloud control systems have gained increasing attention from the\nresearch community as a solution to implement networked cyber-physical systems\n(CPSs). Such an architecture can reduce deployment and maintenance costs albeit\nat the expense of additional security and privacy concerns. In this paper,\nfirst, we discuss state-of-the-art security solutions for cloud control systems\nand their limitations. Then, we propose a novel control architecture based on\nTrusted Execution Environments (TEE). We show that such an approach can\npotentially address major security and privacy issues for cloud-hosted control\nsystems. Finally, we present an implementation setup based on Intel Software\nGuard Extensions (SGX) and validate its effectiveness on a testbed system.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 00:42:45 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Naseri", "Amir Mohammad", ""], ["Lucia", "Walter", ""], ["Mannan", "Mohammad", ""], ["Youssef", "Amr", ""]]}, {"id": "2104.01026", "submitter": "Ying He", "authors": "Ying He, Zhili Shen, Chang Xia, Wei Tong, Jingyu Hua, Sheng Zhong", "title": "SGBA: A Stealthy Scapegoat Backdoor Attack against Deep Neural Networks", "comments": "14 pages, 14 figures, 10 tables and 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of Deep Neural Networks (DNNs) and the substantial\ndemand growth of DNN model sharing and reuse, a gap for backdoors remains. A\nbackdoor can be injected into a third-party model and is extremely stealthy in\nthe normal situation, and thus has been widely discussed. Nowadays, the\nbackdoor attack on deep neural networks has become a serious concern, which\nbrings extensive research about attack and defense around backdoors in DNN.\n  In this paper, we propose a stealthy scapegoat backdoor attack that can\nescape mainstream detection schemes, which can detect the backdoor either in\nthe class level or the model level. We create a scapegoat to mislead the\ndetection schemes in the class level and at the same time make our target model\nan adversarial input to the detection schemes in the model level. It reveals\nthat although many effective backdoor defense schemes have been put forward,\nthe backdoor attack on DNN still needs to be dealt with. The evaluation results\non three benchmark datasets demonstrate that the proposed attack has an\nexcellent performance in both aggressivity and stealthiness against two\nstate-of-the-art defense schemes.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 12:51:18 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 12:33:45 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["He", "Ying", ""], ["Shen", "Zhili", ""], ["Xia", "Chang", ""], ["Tong", "Wei", ""], ["Hua", "Jingyu", ""], ["Zhong", "Sheng", ""]]}, {"id": "2104.01255", "submitter": "Attique Ur Rehman", "authors": "Ayesha Arshad, Attique Ur Rehman, Sabeen Javaid, Tahir Muhammad Ali,\n  Javed Anjum Sheikh, Muhammad Azeem", "title": "A Systematic Literature Review on Phishing and Anti-Phishing Techniques", "comments": null, "journal-ref": "Pakistan J Engg & Tech 2021, 4, 163-168", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Phishing is the number one threat in the world of internet. Phishing attacks\nare from decades and with each passing year it is becoming a major problem for\ninternet users as attackers are coming with unique and creative ideas to breach\nthe security. In this paper, different types of phishing and anti-phishing\ntechniques are presented. For this purpose, the Systematic Literature\nReview(SLR) approach is followed to critically define the proposed research\nquestions. At first 80 articles were extracted from different repositories.\nThese articles were then filtered out using Tollgate Approach to find out\ndifferent types of phishing and anti-phishing techniques. Research study\nevaluated that spear phishing, Email Spoofing, Email Manipulation and phone\nphishing are the most commonly used phishing techniques. On the other hand,\naccording to the SLR, machine learning approaches have the highest accuracy of\npreventing and detecting phishing attacks among all other anti-phishing\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 21:50:38 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Arshad", "Ayesha", ""], ["Rehman", "Attique Ur", ""], ["Javaid", "Sabeen", ""], ["Ali", "Tahir Muhammad", ""], ["Sheikh", "Javed Anjum", ""], ["Azeem", "Muhammad", ""]]}, {"id": "2104.01281", "submitter": "Stefano Souza", "authors": "Stefano M P C Souza and Daniel G Silva", "title": "Monte Carlo execution time estimation for Privacy-preserving Distributed\n  Function Evaluation protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PF", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recent developments in Machine Learning and Deep Learning depend heavily on\ncloud computing and specialized hardware, such as GPUs and TPUs. This forces\nthose using those models to trust private data to cloud servers. Such scenario\nhas prompted a large interest on Homomorphic Cryptography and Secure\nMulti-Party Computation protocols that allow the use of cloud computing power\nin a privacy-preserving manner.\n  When comparing the efficiency of such protocols, most works in literature\nresort to complexity analysis that gives asymptotic higher-bounding limits of\ncomputational cost when input size tends to infinite. These limits may be very\ndifferent from the actual cost or execution time, when performing such\ncomputations over small, or average-sized datasets.\n  We argue that Monte Carlo methods can render better computational cost and\ntime estimates, fostering better design and implementation decisions for\ncomplex systems, such as Privacy-Preserving Machine Learning Frameworks.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 00:04:07 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Souza", "Stefano M P C", ""], ["Silva", "Daniel G", ""]]}, {"id": "2104.01289", "submitter": "Jinghui Liao", "authors": "Jinghui Liao, Fengwei Zhang, Wenhai Sun, Weisong Shi", "title": "Speedster: A TEE-assisted State Channel System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State channel network is the most popular layer-2 solution to theissues of\nscalability, high transaction fees, and low transaction throughput of public\nBlockchain networks. However, the existing works have limitations that curb the\nwide adoption of the technology, such as the expensive creation and closure of\nchannels, strict synchronization between the main chain and off-chain channels,\nfrozen deposits, and inability to execute multi-party smart contracts. In this\nwork, we present Speedster, an account-based state-channel system that aims to\naddress the above issues. To this end, Speedster leverages the latest\ndevelopment of secure hardware to create dispute-free certified channels that\ncan be operated efficiently off the Blockchain. Speedster is fully\ndecentralized and provides better privacy protection. It supports fast native\nmulti-party contract execution, which is missing in prior TEE-enabled channel\nnetworks. Compared to the Lightning Network, Speedster improves the throughput\nby about 10,000X and generates 97% less on-chain data with a comparable network\nscale.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 02:05:33 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Liao", "Jinghui", ""], ["Zhang", "Fengwei", ""], ["Sun", "Wenhai", ""], ["Shi", "Weisong", ""]]}, {"id": "2104.01369", "submitter": "Teimour Hosseinalizadeh", "authors": "Teimour Hosseinalizadeh, Fatih Turkmen, Nima Monshizadeh", "title": "Private Computation of Polynomials over Networks", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study concentrates on preserving privacy in a network of agents where\neach agent desires to evaluate a polynomial function over the private values of\nits immediate neighbors. We provide an algorithm for the exact evaluation of\nthis function while preserving privacy of the involved agents. The solution is\nbased on two cryptographic primitives: Paillier as a Partially Homomorphic\nEncryption scheme and multiplicative-additive secret sharing. The provided\nscheme covers a large class of polynomial functions in distributed systems.\nMoreover, conditions guaranteeing the privacy preservation of the private value\nof an agent against a set of colluding agents are derived. The simulation\nresults demonstrate that the proposed scheme can be employed in a network to\nenhance privacy at the cost of extra communication and computation budgets.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 10:37:17 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Hosseinalizadeh", "Teimour", ""], ["Turkmen", "Fatih", ""], ["Monshizadeh", "Nima", ""]]}, {"id": "2104.01398", "submitter": "Tatsuya Chuman", "authors": "Tatsuya Chuman, Hitoshi Kiya", "title": "Block Scrambling Image Encryption Used in Combination with Data\n  Augmentation for Privacy-Preserving DNNs", "comments": "To be appeared in IEEE ICCE-TW 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel learnable image encryption method for\nprivacy-preserving deep neural networks (DNNs). The proposed method is carried\nout on the basis of block scrambling used in combination with data augmentation\ntechniques such as random cropping, horizontal flip and grid mask. The use of\nblock scrambling enhances robustness against various attacks, and in contrast,\nthe combination with data augmentation enables us to maintain a high\nclassification accuracy even when using encrypted images. In an image\nclassification experiment, the proposed method is demonstrated to be effective\nin privacy-preserving DNNs.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 13:10:44 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 15:15:22 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Chuman", "Tatsuya", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "2104.01446", "submitter": "Christian Pilato", "authors": "Christian Pilato and Francesco Regazzoni", "title": "High-Level Synthesis of Security Properties via Software-Level\n  Abstractions", "comments": "Accepted for presentation at the 1st Workshop on Languages, Tools,\n  and Techniques for Accelerator Design (LATTE'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-level synthesis (HLS) is a key component for the hardware acceleration\nof applications, especially thanks to the diffusion of reconfigurable devices\nin many domains, from data centers to edge devices. HLS reduces development\ntimes by allowing designers to raise the abstraction level and use automated\nmethods for hardware generation. Since security concerns are becoming more and\nmore relevant for data-intensive applications, we investigate how to abstract\nsecurity properties and use HLS for their integration with the accelerator\nfunctionality. We use the case of dynamic information flow tracking, showing\nhow classic software-level abstractions can be efficiently used to hide\nimplementation details to the designers.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 16:39:34 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Pilato", "Christian", ""], ["Regazzoni", "Francesco", ""]]}, {"id": "2104.01494", "submitter": "Aly El Gamal", "authors": "Rehana Mahfuz, Rajeev Sahay, Aly El Gamal", "title": "Mitigating Gradient-based Adversarial Attacks via Denoising and\n  Compression", "comments": "13 pages, 2 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based adversarial attacks on deep neural networks pose a serious\nthreat, since they can be deployed by adding imperceptible perturbations to the\ntest data of any network, and the risk they introduce cannot be assessed\nthrough the network's original training performance. Denoising and\ndimensionality reduction are two distinct methods that have been independently\ninvestigated to combat such attacks. While denoising offers the ability to\ntailor the defense to the specific nature of the attack, dimensionality\nreduction offers the advantage of potentially removing previously unseen\nperturbations, along with reducing the training time of the network being\ndefended. We propose strategies to combine the advantages of these two defense\nmechanisms. First, we propose the cascaded defense, which involves denoising\nfollowed by dimensionality reduction. To reduce the training time of the\ndefense for a small trade-off in performance, we propose the hidden layer\ndefense, which involves feeding the output of the encoder of a denoising\nautoencoder into the network. Further, we discuss how adaptive attacks against\nthese defenses could become significantly weak when an alternative defense is\nused, or when no defense is used. In this light, we propose a new metric to\nevaluate a defense which measures the sensitivity of the adaptive attack to\nmodifications in the defense. Finally, we present a guideline for building an\nordered repertoire of defenses, a.k.a. a defense infrastructure, that adjusts\nto limited computational resources in presence of uncertainty about the attack\nstrategy.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 22:57:01 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Mahfuz", "Rehana", ""], ["Sahay", "Rajeev", ""], ["Gamal", "Aly El", ""]]}, {"id": "2104.01518", "submitter": "Tram Truong-Huu", "authors": "Sai Praveen Kadiyala and Akella Kartheek and Tram Truong-Huu", "title": "Program Behavior Analysis and Clustering using Performance Counters", "comments": "DYNAMICS 2020: DYnamic and Novel Advances in Machine Learning and\n  Intelligent Cyber Security (DYNAMICS) Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding the dynamic behavior of computer programs during normal working\nconditions is an important task, which has multiple security benefits such as\nthe development of behavior-based anomaly detection, vulnerability discovery,\nand patching. Existing works achieved this goal by collecting and analyzing\nvarious data including network traffic, system calls, instruction traces, etc.\nIn this paper, we explore the use of a new type of data, performance counters,\nto analyze the dynamic behavior of programs. Using existing primitives, we\ndevelop a tool named perfextract to capture data from different performance\ncounters for a program during its startup time, thus forming multiple time\nseries to represent the dynamic behavior of the program. We analyze the\ncollected data and develop a semi-supervised clustering algorithm that allows\nus to classify each program using its performance counter time series into a\nspecific group and to identify the intrinsic behavior of that group. We carry\nout extensive experiments with 18 real-world programs that belong to 4 groups\nincluding web browsers, text editors, image viewers, and audio players. The\nexperimental results show that the examined programs can be accurately\ndifferentiated based on their performance counter data regardless of whether\nprograms are run in physical or virtual environments.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 02:17:58 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Kadiyala", "Sai Praveen", ""], ["Kartheek", "Akella", ""], ["Truong-Huu", "Tram", ""]]}, {"id": "2104.01631", "submitter": "Colin C. Ife", "authors": "Colin C. Ife, Yun Shen, Steven J. Murdoch, and Gianluca Stringhini", "title": "Marked for Disruption: Tracing the Evolution of Malware Delivery\n  Operations Targeted for Takedown", "comments": "14 pages, to appear in RAID 2021 conference", "journal-ref": null, "doi": "10.1145/3471621.3471844", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The malware and botnet phenomenon is among the most significant threats to\ncybersecurity today. Consequently, law enforcement agencies, security\ncompanies, and researchers are constantly seeking to disrupt these malicious\noperations through so-called takedown counter-operations. Unfortunately, the\nsuccess of these takedowns is mixed. Furthermore, very little is understood as\nto how botnets and malware delivery operations respond to takedown attempts. We\npresent a comprehensive study of three malware delivery operations that were\ntargeted for takedown in 2015-16 using global download metadata provided by a\nmajor security company. In summary, we found that: (1) Distributed delivery\narchitectures were commonly used, indicating the need for better security\nhygiene and coordination by the (ab)used service providers. (2) A minority of\nmalware binaries were responsible for the majority of download activity,\nsuggesting that detecting these \"super binaries\" would yield the most benefit\nto the security community. (3) The malware operations exhibited displacing and\ndefiant behaviours following their respective takedown attempts. We argue that\nthese \"predictable\" behaviours could be factored into future takedown\nstrategies. (4) The malware operations also exhibited previously undocumented\nbehaviours, such as Dridex dropping competing brands of malware, or Dorkbot and\nUpatre heavily relying on upstream dropper malware. These \"unpredictable\"\nbehaviours indicate the need for researchers to use better threat-monitoring\ntechniques.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 15:41:30 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 21:39:03 GMT"}, {"version": "v3", "created": "Wed, 7 Jul 2021 16:42:21 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Ife", "Colin C.", ""], ["Shen", "Yun", ""], ["Murdoch", "Steven J.", ""], ["Stringhini", "Gianluca", ""]]}, {"id": "2104.01776", "submitter": "Dinh Nguyen", "authors": "Dinh C. Nguyen, Ming Ding, Quoc-Viet Pham, Pubudu N. Pathirana, Long\n  Bao Le, Aruna Seneviratne, Jun Li, Dusit Niyato, H. Vincent Poor", "title": "Federated Learning Meets Blockchain in Edge Computing: Opportunities and\n  Challenges", "comments": "Accepted at the IEEE Internet of Things Journal, 19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mobile edge computing (MEC) has been envisioned as a promising paradigm to\nhandle the massive volume of data generated from ubiquitous mobile devices for\nenabling intelligent services with the help of artificial intelligence (AI).\nTraditionally, AI techniques often require centralized data collection and\ntraining in a single entity, e.g., an MEC server, which is now becoming a weak\npoint due to data privacy concerns and high data communication overheads. In\nthis context, federated learning (FL) has been proposed to provide\ncollaborative data training solutions, by coordinating multiple mobile devices\nto train a shared AI model without exposing their data, which enjoys\nconsiderable privacy enhancement. To improve the security and scalability of FL\nimplementation, blockchain as a ledger technology is attractive for realizing\ndecentralized FL training without the need for any central server.\nParticularly, the integration of FL and blockchain leads to a new paradigm,\ncalled FLchain, which potentially transforms intelligent MEC networks into\ndecentralized, secure, and privacy-enhancing systems. This article presents an\noverview of the fundamental concepts and explores the opportunities of FLchain\nin MEC networks. We identify several main topics in FLchain design, including\ncommunication cost, resource allocation, incentive mechanism, security and\nprivacy protection. The key solutions for FLchain design are provided, and the\nlessons learned as well as the outlooks are also discussed. Then, we\ninvestigate the applications of FLchain in popular MEC domains, such as edge\ndata sharing, edge content caching and edge crowdsensing. Finally, important\nresearch challenges and future directions are also highlighted.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 05:19:52 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Nguyen", "Dinh C.", ""], ["Ding", "Ming", ""], ["Pham", "Quoc-Viet", ""], ["Pathirana", "Pubudu N.", ""], ["Le", "Long Bao", ""], ["Seneviratne", "Aruna", ""], ["Li", "Jun", ""], ["Niyato", "Dusit", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2104.01789", "submitter": "Guannan Lou", "authors": "Yao Deng, Tiehua Zhang, Guannan Lou, Xi Zheng, Jiong Jin, Qing-Long\n  Han", "title": "Deep Learning-Based Autonomous Driving Systems: A Survey of Attacks and\n  Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid development of artificial intelligence, especially deep learning\ntechnology, has advanced autonomous driving systems (ADSs) by providing precise\ncontrol decisions to counterpart almost any driving event, spanning from\nanti-fatigue safe driving to intelligent route planning. However, ADSs are\nstill plagued by increasing threats from different attacks, which could be\ncategorized into physical attacks, cyberattacks and learning-based adversarial\nattacks. Inevitably, the safety and security of deep learning-based autonomous\ndriving are severely challenged by these attacks, from which the\ncountermeasures should be analyzed and studied comprehensively to mitigate all\npotential risks. This survey provides a thorough analysis of different attacks\nthat may jeopardize ADSs, as well as the corresponding state-of-the-art defense\nmechanisms. The analysis is unrolled by taking an in-depth overview of each\nstep in the ADS workflow, covering adversarial attacks for various deep\nlearning models and attacks in both physical and cyber context. Furthermore,\nsome promising research directions are suggested in order to improve deep\nlearning-based autonomous driving safety, including model robustness training,\nmodel testing and verification, and anomaly detection based on cloud/edge\nservers.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 06:31:47 GMT"}, {"version": "v2", "created": "Sat, 10 Apr 2021 02:28:02 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Deng", "Yao", ""], ["Zhang", "Tiehua", ""], ["Lou", "Guannan", ""], ["Zheng", "Xi", ""], ["Jin", "Jiong", ""], ["Han", "Qing-Long", ""]]}, {"id": "2104.01808", "submitter": "Ziyue Huang", "authors": "Ziyue Huang, Yuan Qiu, Ke Yi, Graham Cormode", "title": "Frequency Estimation Under Multiparty Differential Privacy: One-shot and\n  Streaming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the fundamental problem of frequency estimation under both privacy\nand communication constraints, where the data is distributed among $k$ parties.\nWe consider two application scenarios: (1) one-shot, where the data is static\nand the aggregator conducts a one-time computation; and (2) streaming, where\neach party receives a stream of items over time and the aggregator continuously\nmonitors the frequencies. We adopt the model of multiparty differential privacy\n(MDP), which is more general than local differential privacy (LDP) and\n(centralized) differential privacy. Our protocols achieve optimality (up to\nlogarithmic factors) permissible by the more stringent of the two constraints.\nIn particular, when specialized to the $\\varepsilon$-LDP model, our protocol\nachieves an error of $\\sqrt{k}/(e^{\\Theta(\\varepsilon)}-1)$ using $O(k\\max\\{\n\\varepsilon, \\frac{1}{\\varepsilon} \\})$ bits of communication and $O(k \\log u)$\nbits of public randomness, where $u$ is the size of the domain.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 08:15:20 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 13:24:01 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Huang", "Ziyue", ""], ["Qiu", "Yuan", ""], ["Yi", "Ke", ""], ["Cormode", "Graham", ""]]}, {"id": "2104.01813", "submitter": "Yan Xu", "authors": "Yan Xu, Yongliang Cheng", "title": "Semi-supervised Variational Temporal Convolutional Network for IoT\n  Communication Multi-anomaly Detection", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The consumer Internet of Things (IoT) have developed in recent years. Mass\nIoT devices are constructed to build a huge communications network. But these\ndevices are insecure in reality, it means that the communications network are\nexposed by the attacker. Moreover, the IoT communication network also faces\nwith variety of sudden errors. Therefore, it easily leads to that is vulnerable\nwith the threat of attacker and system failure. The severe situation of IoT\ncommunication network motivates the development of new techniques to\nautomatically detect multi-anomaly. In this paper, we propose SS-VTCN, a\nsemi-supervised network for IoT multiple anomaly detection that works well\neffectively for IoT communication network. SS-VTCN is designed to capture the\nnormal patterns of the IoT traffic data based on the distribution whether it is\nlabeled or not by learning their representations with key techniques such as\nVariational Autoencoders and Temporal Convolutional Network. This network can\nuse the encode data to predict preliminary result, and reconstruct input data\nto determine anomalies by the representations. Extensive evaluation experiments\nbased on a benchmark dataset and a real consumer smart home dataset demonstrate\nthat SS-VTCN is more suitable than supervised and unsupervised method with\nbetter performance when compared other state-of-art semi-supervised method.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 08:51:24 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Xu", "Yan", ""], ["Cheng", "Yongliang", ""]]}, {"id": "2104.01835", "submitter": "Rao Heena", "authors": "Heena (1, 2) ((1) Center of excellence in cybersecurity, Institute for\n  Development and Research in Banking Technology (IDRBT), Hyderabad, India, (2)\n  School of Computer Science and Information Sciences (SCIS), University of\n  Hyderabad, Hyderabad, India)", "title": "Advances In Malware Detection- An Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Malware has become a widely used means in cyber attacks in recent decades\nbecause of various new obfuscation techniques used by malwares. In order to\nprotect the systems, data and information, detection of malware is needed as\nearly as possible. There are various studies on malware detection techniques\nthat have been done but there is no method which can detect the malware\ncompletely and make malware detection problematic. Static Malware analysis is\nvery effective for known malwares but it does not work for zero day malware\nwhich leads to the need of dynamic malware detection and the behaviour based\nmalware detection is comparatively good among all detection techniques like\nsignature based, deep learning based, mobile/IOT and cloud based detection but\nstill it is not able to detect all zero day malware which shows the malware\ndetection is very challenging task and need more techniques for malware\ndetection. This paper describes a literature review of various methods of\nmalware detection. A short description of each method is provided and discusses\nvarious studies already done in the advanced malware detection field and their\ncomparison based on the detection method used, accuracy and other parameters.\nApart from this we will discuss various malware detection tools, dataset and\ntheir sources which can be used in further study. This paper gives you the\ndetailed knowledge of advanced malwares, its detection methods, how you can\nprotect your devices and data from malware attacks and it gives the comparison\nof different studies on malware detection.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 10:12:11 GMT"}, {"version": "v2", "created": "Sat, 8 May 2021 13:35:34 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Heena", "", ""]]}, {"id": "2104.01907", "submitter": "Fajun Sun", "authors": "Fajun Sun, Selena He, Xiaotong Zhang, Fanfan Shen, Qingan Li, Yanxiang\n  He", "title": "TinyAKE: A More Practicable and Trustable Scheme for Authenticated Key\n  Establishment in WSNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The characteristics of high loss rate, resource constraint, being eager for\ngood security haven't been fully considered in the existing key establishment\nprotocols of wireless sensor networks. Analyzing the key establishing problem\nfrom the MAC and physical layers, existing protocols are not practicable enough\ndue to their overlong agreement packets and single round key establishment. To\nmitigate the impact of these problems, a group of design principles for secure\nsensor networks has been presented and TinyAKE, an authenticated key transport\nprotocol based on lightweight certificate, is proposed in this paper. The\nsecurity of TinyAKE are proved with the theory of indistinguishability,\nmeanwhile, the correctness is also proved, the performance is analyzed and\ncompared with the existing similar protocols. Finally TinyAKE is implemented in\nthe TinyOS with TinyECC. Our evaluation shows that TinyAKE is a more\npracticable and trustable authenticated key establishment protocol than\nexisting protocols. The experimental result shows that the key transport with\ncertificate mechanism is feasible in WSNs. Moreover, the simulation results\nshow that the optimal number of repeated negotiation is one when the secure\nconnectivity rate of TinyAKE is improved by using the repeated key negotiation.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 13:37:18 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Sun", "Fajun", ""], ["He", "Selena", ""], ["Zhang", "Xiaotong", ""], ["Shen", "Fanfan", ""], ["Li", "Qingan", ""], ["He", "Yanxiang", ""]]}, {"id": "2104.01918", "submitter": "Wang Taotao", "authors": "Long Shi, Taotao Wang, Jun Li, and Shengli Zhang", "title": "Pooling is not Favorable: Decentralize Mining Power of PoW Blockchain\n  Using Age-of-Work", "comments": "13 pages, 9 figues", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Proof-of-Work (PoW) blockchains, the average waiting time to generate a\nblock is inversely proportional to the computing power of the miner. To reduce\nthe average block generation time, a group of individual miners can form a\nmining pool to aggregate their computing power to solve the puzzle together and\nshare the reward contained in the block. However, if the aggregated computing\npower of the pool forms a substantial portion of the total computing power in\nthe network, the pooled mining undermines the core spirit of blockchain, i.e.,\nthe decentralization, and harms its security. To discourage the pooled mining,\nwe develop a new consensus protocol called Proof-of-Age (PoA) that builds upon\nthe native PoW protocol. The core idea of PoA lies in using Age-of-Work (AoW)\nto measure the effective mining period that the miner has devoted to\nmaintaining the security of blockchain. Unlike in the native PoW protocol, in\nour PoA protocol, miners benefit from its effective mining period even if they\nhave not successfully mined a block. We first employ a continuous time Markov\nchain (CTMC) to model the block generation process of the PoA based blockchain.\nBased on this CTMC model, we then analyze the block generation rates of the\nmining pool and solo miner respectively. Our analytical results verify that\nunder PoA, the block generation rates of miners in the mining pool are reduced\ncompared to that of solo miners, thereby disincentivizing the pooled mining.\nFinally, we simulate the mining process in the PoA blockchain to demonstrate\nthe consistency of the analytical results.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 14:00:04 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Shi", "Long", ""], ["Wang", "Taotao", ""], ["Li", "Jun", ""], ["Zhang", "Shengli", ""]]}, {"id": "2104.01987", "submitter": "Weijie J. Su", "authors": "Jinshuo Dong, Aaron Roth, Weijie J. Su", "title": "Rejoinder: Gaussian Differential Privacy", "comments": "Updated the references. Rejoinder to discussions on Gaussian\n  Differential Privacy, read to the Royal Statistical Society in December 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this rejoinder, we aim to address two broad issues that cover most\ncomments made in the discussion. First, we discuss some theoretical aspects of\nour work and comment on how this work might impact the theoretical foundation\nof privacy-preserving data analysis. Taking a practical viewpoint, we next\ndiscuss how f-differential privacy (f-DP) and Gaussian differential privacy\n(GDP) can make a difference in a range of applications.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 16:27:56 GMT"}, {"version": "v2", "created": "Sat, 26 Jun 2021 02:40:17 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Dong", "Jinshuo", ""], ["Roth", "Aaron", ""], ["Su", "Weijie J.", ""]]}, {"id": "2104.02000", "submitter": "Yapeng Tian", "authors": "Yapeng Tian and Chenliang Xu", "title": "Can audio-visual integration strengthen robustness under multimodal\n  attacks?", "comments": "CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose to make a systematic study on machines multisensory\nperception under attacks. We use the audio-visual event recognition task\nagainst multimodal adversarial attacks as a proxy to investigate the robustness\nof audio-visual learning. We attack audio, visual, and both modalities to\nexplore whether audio-visual integration still strengthens perception and how\ndifferent fusion mechanisms affect the robustness of audio-visual models. For\ninterpreting the multimodal interactions under attacks, we learn a\nweakly-supervised sound source visual localization model to localize sounding\nregions in videos. To mitigate multimodal attacks, we propose an audio-visual\ndefense approach based on an audio-visual dissimilarity constraint and external\nfeature memory banks. Extensive experiments demonstrate that audio-visual\nmodels are susceptible to multimodal adversarial attacks; audio-visual\nintegration could decrease the model robustness rather than strengthen under\nmultimodal attacks; even a weakly-supervised sound source visual localization\nmodel can be successfully fooled; our defense method can improve the\ninvulnerability of audio-visual networks without significantly sacrificing\nclean model performance.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 16:46:45 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Tian", "Yapeng", ""], ["Xu", "Chenliang", ""]]}, {"id": "2104.02107", "submitter": "Neal Mangaokar", "authors": "Neal Mangaokar, Jiameng Pu, Parantapa Bhattacharya, Chandan K. Reddy,\n  Bimal Viswanath", "title": "Jekyll: Attacking Medical Image Diagnostics using Deep Generative Models", "comments": "Published in proceedings of the 5th European Symposium on Security\n  and Privacy (EuroS&P '20)", "journal-ref": null, "doi": "10.1109/EuroSP48549.2020.00017", "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in deep neural networks (DNNs) have shown tremendous promise in the\nmedical domain. However, the deep learning tools that are helping the domain,\ncan also be used against it. Given the prevalence of fraud in the healthcare\ndomain, it is important to consider the adversarial use of DNNs in manipulating\nsensitive data that is crucial to patient healthcare. In this work, we present\nthe design and implementation of a DNN-based image translation attack on\nbiomedical imagery. More specifically, we propose Jekyll, a neural style\ntransfer framework that takes as input a biomedical image of a patient and\ntranslates it to a new image that indicates an attacker-chosen disease\ncondition. The potential for fraudulent claims based on such generated 'fake'\nmedical images is significant, and we demonstrate successful attacks on both\nX-rays and retinal fundus image modalities. We show that these attacks manage\nto mislead both medical professionals and algorithmic detection schemes.\nLastly, we also investigate defensive measures based on machine learning to\ndetect images generated by Jekyll.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 18:23:36 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Mangaokar", "Neal", ""], ["Pu", "Jiameng", ""], ["Bhattacharya", "Parantapa", ""], ["Reddy", "Chandan K.", ""], ["Viswanath", "Bimal", ""]]}, {"id": "2104.02261", "submitter": "Sanjay Kariyappa", "authors": "Sanjay Kariyappa, Ousmane Dia and Moinuddin K Qureshi", "title": "Enabling Inference Privacy with Adaptive Noise Injection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User-facing software services are becoming increasingly reliant on remote\nservers to host Deep Neural Network (DNN) models, which perform inference tasks\nfor the clients. Such services require the client to send input data to the\nservice provider, who processes it using a DNN and returns the output\npredictions to the client. Due to the rich nature of the inputs such as images\nand speech, the input often contains more information than what is necessary to\nperform the primary inference task. Consequently, in addition to the primary\ninference task, a malicious service provider could infer secondary (sensitive)\nattributes from the input, compromising the client's privacy. The goal of our\nwork is to improve inference privacy by injecting noise to the input to hide\nthe irrelevant features that are not conducive to the primary classification\ntask. To this end, we propose Adaptive Noise Injection (ANI), which uses a\nlight-weight DNN on the client-side to inject noise to each input, before\ntransmitting it to the service provider to perform inference. Our key insight\nis that by customizing the noise to each input, we can achieve state-of-the-art\ntrade-off between utility and privacy (up to 48.5% degradation in\nsensitive-task accuracy with <1% degradation in primary accuracy),\nsignificantly outperforming existing noise injection schemes. Our method does\nnot require prior knowledge of the sensitive attributes and incurs minimal\ncomputational overheads.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 03:06:21 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Kariyappa", "Sanjay", ""], ["Dia", "Ousmane", ""], ["Qureshi", "Moinuddin K", ""]]}, {"id": "2104.02263", "submitter": "Mahmoud Badr", "authors": "Seham A. Alansar, Mahmoud M. Badr, Mohamed Mahmoud, and Waleed\n  Alasmary", "title": "Efficient and Privacy-Preserving Infection Control System for\n  Covid-19-Like Pandemics using Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact tracing is a very effective way to control the COVID-19-like\npandemics. It aims to identify individuals who closely contacted an infected\nperson during the incubation period of the virus and notify them to quarantine.\nHowever, the existing systems suffer from privacy, security, and efficiency\nissues. To address these limitations, in this paper, we propose an efficient\nand privacy-preserving Blockchain-based infection control system. Instead of\ndepending on a single authority to run the system, a group of health\nauthorities, that form a consortium Blockchain, run our system. Using\nBlockchain technology not only secures our system against single point of\nfailure and denial of service attacks, but also brings transparency because all\ntransactions can be validated by different parties. Although contact tracing is\nimportant, it is not enough to effectively control an infection. Thus, unlike\nmost of the existing systems that focus only on contact tracing, our system\nconsists of three integrated subsystems, including contact tracing, public\nplaces access control, and safe-places recommendation. The access control\nsubsystem prevents infected people from visiting public places to prevent\nspreading the virus, and the recommendation subsystem categorizes zones based\non the infection level so that people can avoid visiting contaminated zones.\nOur analysis demonstrates that our system is secure and preserves the privacy\nof the users against identification, social graph disclosure, and tracking\nattacks, while thwarting false reporting (or panic) attacks. Moreover, our\nextensive performance evaluations demonstrate the scalability of our system\n(which is desirable in pandemics) due to its low communication, computation,\nand storage overheads.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 03:09:14 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Alansar", "Seham A.", ""], ["Badr", "Mahmoud M.", ""], ["Mahmoud", "Mohamed", ""], ["Alasmary", "Waleed", ""]]}, {"id": "2104.02361", "submitter": "Yiming Li", "authors": "Yiming Li, Tongqing Zhai, Yong Jiang, Zhifeng Li, Shu-Tao Xia", "title": "Backdoor Attack in the Physical World", "comments": "This work was done when Yiming Li was an intern at Tencent AI Lab,\n  supported by the Tencent Rhino-Bird Elite Training Program (2020). This is a\n  6-pages short version of our ongoing work, `Rethinking the Trigger of\n  Backdoor Attack' (arXiv:2004.04692). It is accepted by the non-archival ICLR\n  2021 workshop on Robust and Reliable Machine Learning in the Real World.\n  arXiv admin note: substantial text overlap with arXiv:2004.04692", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backdoor attack intends to inject hidden backdoor into the deep neural\nnetworks (DNNs), such that the prediction of infected models will be\nmaliciously changed if the hidden backdoor is activated by the attacker-defined\ntrigger. Currently, most existing backdoor attacks adopted the setting of\nstatic trigger, $i.e.,$ triggers across the training and testing images follow\nthe same appearance and are located in the same area. In this paper, we revisit\nthis attack paradigm by analyzing trigger characteristics. We demonstrate that\nthis attack paradigm is vulnerable when the trigger in testing images is not\nconsistent with the one used for training. As such, those attacks are far less\neffective in the physical world, where the location and appearance of the\ntrigger in the digitized image may be different from that of the one used for\ntraining. Moreover, we also discuss how to alleviate such vulnerability. We\nhope that this work could inspire more explorations on backdoor properties, to\nhelp the design of more advanced backdoor attack and defense methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 08:37:33 GMT"}, {"version": "v2", "created": "Sat, 24 Apr 2021 16:40:13 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Li", "Yiming", ""], ["Zhai", "Tongqing", ""], ["Jiang", "Yong", ""], ["Li", "Zhifeng", ""], ["Xia", "Shu-Tao", ""]]}, {"id": "2104.02551", "submitter": "Federico Maggi", "authors": "Federico Maggi, Andrea Guglielmini", "title": "RFQuack: A Universal Hardware-Software Toolkit for Wireless Protocol\n  (Security) Analysis and Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Software-defined radios (SDRs) are indispensable for signal reconnaissance\nand physical-layer dissection, but despite we have advanced tools like\nUniversal Radio Hacker, SDR-based approaches require substantial effort.\n  Contrarily, RF dongles such as the popular Yard Stick One are easy to use and\nguarantee a deterministic physical-layer implementation. However, they're not\nvery flexible, as each dongle is a static hardware system with a monolithic\nfirmware.\n  We present RFquack, an open-source tool and library firmware that combines\nthe flexibility of a software-based approach with the determinism and\nperformance of embedded RF frontends. RFquack is based on a multi-radio\nhardware system with swappable RF frontends, and a firmware that exposes a\nuniform, hardware-agnostic API. RFquack focuses on a structured firmware\narchitecture that allows high- and low-level interaction with the RF frontends.\nIt facilitates the development of host-side scripts and firmware plug-ins, to\nimplement efficient data-processing pipelines or interactive protocols, thanks\nto the multi-radio support. RFquack has an IPython shell and 9 firmware modules\nfor: spectrum scanning, automatic carrier detection and bitrate estimation,\nheadless operation with remote management, in-flight packet filtering and\nmanipulation, MouseJack, and RollJam (as examples).\n  We used RFquack to setup RF hacking contests, analyze industrial-grade\ndevices and key fobs, on which we found and reported 11 vulnerabilities in\ntheir RF protocols.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 14:46:00 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Maggi", "Federico", ""], ["Guglielmini", "Andrea", ""]]}, {"id": "2104.02612", "submitter": "Martijn de Vos", "authors": "Martijn de Vos and Johan Pouwelse", "title": "ASTANA: Practical String Deobfuscation for Android Applications Using\n  Program Slicing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Software obfuscation is widely used by Android developers to protect the\nsource code of their applications against adversarial reverse-engineering\nefforts. A specific type of obfuscation, string obfuscation, transforms the\ncontent of all string literals in the source code to non-interpretable text and\ninserts logic to deobfuscate these string literals at runtime. In this work, we\ndemonstrate that string obfuscation is easily reversible. We present ASTANA, a\npractical tool for Android applications to recovers the human-readable content\nfrom obfuscated string literals. ASTANA makes minimal assumptions about the\nobfuscation logic or application structure. The key idea is to execute the\ndeobfuscation logic for a specific (obfuscated) string literal, which yields\nthe original string value. To obtain the relevant deobfuscation logic, we\npresent a lightweight and optimistic algorithm, based on program slicing\ntechniques. By an experimental evaluation with 100 popular real-world financial\napplications, we demonstrate the practicality of ASTANA. We verify the\ncorrectness of our deobfuscation tool and provide insights in the behaviour of\nstring obfuscators applied by the developers of the evaluated Android\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 15:50:29 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["de Vos", "Martijn", ""], ["Pouwelse", "Johan", ""]]}, {"id": "2104.02655", "submitter": "Tao Li", "authors": "Tao Li and Min Soo Choi", "title": "DeepBlur: A Simple and Effective Method for Natural Image Obfuscation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing privacy concern due to the popularity of social media and\nsurveillance systems, along with advances in face recognition software.\nHowever, established image obfuscation techniques are either vulnerable to\nre-identification attacks by human or deep learning models, insufficient in\npreserving image fidelity, or too computationally intensive to be practical. To\ntackle these issues, we present DeepBlur, a simple yet effective method for\nimage obfuscation by blurring in the latent space of an unconditionally\npre-trained generative model that is able to synthesize photo-realistic facial\nimages. We compare it with existing methods by efficiency and image quality,\nand evaluate against both state-of-the-art deep learning models and industrial\nproducts (e.g., Face++, Microsoft face service). Experiments show that our\nmethod produces high quality outputs and is the strongest defense for most test\ncases.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 19:31:26 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Li", "Tao", ""], ["Choi", "Min Soo", ""]]}, {"id": "2104.02739", "submitter": "Albert Cheu", "authors": "Albert Cheu, Maxim Zhilyaev", "title": "Differentially Private Histograms in the Shuffle Model from Fake Users", "comments": "29 pages. May 3 updates: (1) experiments that compared results with\n  prior work. (2) moved count-min section to the main body (3) expanded\n  introduction May 29 updates: (1) further improved introduction (2) enhanced\n  reduction in communication complexity (3) included reference to GKMP20\n  protocol", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been much recent work in the shuffle model of differential privacy,\nparticularly for approximate $d$-bin histograms. While these protocols achieve\nlow error, the number of messages sent by each user -- the message complexity\n-- has so far scaled with $d$ or the privacy parameters. The message complexity\nis an informative predictor of a shuffle protocol's resource consumption. We\npresent a protocol whose message complexity is two when there are sufficiently\nmany users. The protocol essentially pairs each row in the dataset with a fake\nrow and performs a simple randomization on all rows. We show that the error\nintroduced by the protocol is small, using rigorous analysis as well as\nexperiments on real-world data. We also prove that corrupt users have a\nrelatively low impact on our protocol's estimates.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 18:24:57 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 18:55:35 GMT"}, {"version": "v3", "created": "Sat, 29 May 2021 16:31:17 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Cheu", "Albert", ""], ["Zhilyaev", "Maxim", ""]]}, {"id": "2104.02759", "submitter": "Ivan Geffner", "authors": "Ivan Geffner, Joseph Y. Halpern", "title": "Lower Bounds Implementing Mediators in Asynchronous Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Abraham, Dolev, Geffner, and Halpern proved that, in asynchronous systems, a\n$(k,t)$-robust equilibrium for $n$ players and a trusted mediator can be\nimplemented without the mediator as long as $n > 4(k+t)$, where an equilibrium\nis $(k,t)$-robust if, roughly speaking, no coalition of $t$ players can\ndecrease the payoff of any of the other players, and no coalition of $k$\nplayers can increase their payoff by deviating. We prove that this bound is\ntight, in the sense that if $n \\le 4(k+t)$ there exist $(k,t)$-robust\nequilibria with a mediator that cannot be implemented by the players alone.\nEven though implementing $(k,t)$-robust mediators seems closely related to\nimplementing asynchronous multiparty $(k+t)$-secure computation \\cite{BCG93},\nto the best of our knowledge there is no known straightforward reduction from\none problem to another. Nevertheless, we show that there is a non-trivial\nreduction from a slightly weaker notion of $(k+t)$-secure computation, which we\ncall $(k+t)$-strict secure computation, to implementing $(k,t)$-robust\nmediators. We prove the desired lower bound by showing that there are functions\non $n$ variables that cannot be $(k+t)$-strictly securely computed if $n \\le\n4(k+t)$. This also provides a simple alternative proof for the well-known lower\nbound of $4t+1$ on asynchronous secure computation in the presence of up to $t$\nmalicious agents.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 19:45:20 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Geffner", "Ivan", ""], ["Halpern", "Joseph Y.", ""]]}, {"id": "2104.02774", "submitter": "Huadong Mo", "authors": "Jianyu Xu, Bin Liu, Huadong Mo, Daoyi Dong", "title": "Bayesian adversarial multi-node bandit for optimal smart grid protection\n  against cyber attacks", "comments": null, "journal-ref": "Automatica, 2021", "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The cybersecurity of smart grids has become one of key problems in developing\nreliable modern power and energy systems. This paper introduces a\nnon-stationary adversarial cost with a variation constraint for smart grids and\nenables us to investigate the problem of optimal smart grid protection against\ncyber attacks in a relatively practical scenario. In particular, a Bayesian\nmulti-node bandit (MNB) model with adversarial costs is constructed and a new\nregret function is defined for this model. An algorithm called Thompson-Hedge\nalgorithm is presented to solve the problem and the superior performance of the\nproposed algorithm is proven in terms of the convergence rate of the regret\nfunction. The applicability of the algorithm to real smart grid scenarios is\nverified and the performance of the algorithm is also demonstrated by numerical\nexamples.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 10:45:21 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Xu", "Jianyu", ""], ["Liu", "Bin", ""], ["Mo", "Huadong", ""], ["Dong", "Daoyi", ""]]}, {"id": "2104.02815", "submitter": "Haoyu Zhang", "authors": "Haoyu Zhang, Marcel Grimmer, Raghavendra Ramachandra, Kiran Raja,\n  Christoph Busch", "title": "On the Applicability of Synthetic Data for Face Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face verification has come into increasing focus in various applications\nincluding the European Entry/Exit System, which integrates face recognition\nmechanisms. At the same time, the rapid advancement of biometric authentication\nrequires extensive performance tests in order to inhibit the discriminatory\ntreatment of travellers due to their demographic background. However, the use\nof face images collected as part of border controls is restricted by the\nEuropean General Data Protection Law to be processed for no other reason than\nits original purpose. Therefore, this paper investigates the suitability of\nsynthetic face images generated with StyleGAN and StyleGAN2 to compensate for\nthe urgent lack of publicly available large-scale test data. Specifically, two\ndeep learning-based (SER-FIQ, FaceQnet v1) and one standard-based (ISO/IEC TR\n29794-5) face image quality assessment algorithm is utilized to compare the\napplicability of synthetic face images compared to real face images extracted\nfrom the FRGC dataset. Finally, based on the analysis of impostor score\ndistributions and utility score distributions, our experiments reveal\nnegligible differences between StyleGAN vs. StyleGAN2, and further also minor\ndiscrepancies compared to real face images.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 22:12:30 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Zhang", "Haoyu", ""], ["Grimmer", "Marcel", ""], ["Ramachandra", "Raghavendra", ""], ["Raja", "Kiran", ""], ["Busch", "Christoph", ""]]}, {"id": "2104.02890", "submitter": "Sara Jafarbeiki", "authors": "Sara Jafarbeiki, Amin Sakzad, Shabnam Kasra Kermanshahi, Raj Gaire,\n  Ron Steinfeld, Shangqi Lai, Gad Abraham", "title": "PrivGenDB: Efficient and privacy-preserving query executions over\n  encrypted SNP-Phenotype database", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Searchable symmetric encryption (SSE) has been used to protect the\nconfidentiality of genomic data while providing substring search and range\nqueries on a sequence of genomic data, but it has not been studied for\nprotecting single nucleotide polymorphism (SNP)-phenotype data. In this\narticle, we propose a novel model, PrivGenDB, for securely storing and\nefficiently conducting different queries on genomic data outsourced to an\nhonest-but-curious cloud server. To instantiate PrivGenDB, we use SSE to ensure\nconfidentiality while conducting different types of queries on encrypted\ngenomic data, phenotype and other information of individuals to help\nanalysts/clinicians in their analysis/care. To the best of our knowledge,\nPrivGenDB construction is the first SSE-based approach ensuring the\nconfidentiality of shared SNP-phenotype data through encryption while making\nthe computation/query process efficient and scalable for biomedical research\nand care. Furthermore, it supports a variety of query types on genomic data,\nincluding count queries, Boolean queries, and k'-out-of-k match queries.\nFinally, the PrivGenDB model handles the dataset containing both genotype and\nphenotype, and it also supports storing and managing other metadata like gender\nand ethnicity privately. Computer evaluations on a dataset with 5,000 records\nand 1,000 SNPs demonstrate that a count/Boolean query and a k'-out-of-k match\nquery over 40 SNPs take approximately 4.3s and 86.4{\\mu}s, respectively, that\noutperforms the existing schemes.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 03:28:29 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 06:09:20 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Jafarbeiki", "Sara", ""], ["Sakzad", "Amin", ""], ["Kermanshahi", "Shabnam Kasra", ""], ["Gaire", "Raj", ""], ["Steinfeld", "Ron", ""], ["Lai", "Shangqi", ""], ["Abraham", "Gad", ""]]}, {"id": "2104.02987", "submitter": "Peterson Yuhala", "authors": "Peterson Yuhala, Pascal Felber, Valerio Schiavoni, Alain Tchana", "title": "Plinius: Secure and Persistent Machine Learning Model Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the increasing popularity of cloud based machine learning (ML)\ntechniques there comes a need for privacy and integrity guarantees for ML data.\nIn addition, the significant scalability challenges faced by DRAM coupled with\nthe high access-times of secondary storage represent a huge performance\nbottleneck for ML systems. While solutions exist to tackle the security aspect,\nperformance remains an issue. Persistent memory (PM) is resilient to power loss\n(unlike DRAM), provides fast and fine-granular access to memory (unlike disk\nstorage) and has latency and bandwidth close to DRAM (in the order of ns and\nGB/s, respectively). We present PLINIUS, a ML framework using Intel SGX\nenclaves for secure training of ML models and PM for fault tolerance\nguarantees. P LINIUS uses a novel mirroring mechanism to create and maintain\n(i) encrypted mirror copies of ML models on PM, and (ii) encrypted training\ndata in byte-addressable PM, for near-instantaneous data recovery after a\nsystem failure. Compared to disk-based checkpointing systems,PLINIUS is 3.2x\nand 3.7x faster respectively for saving and restoring models on real PM\nhardware, achieving robust and secure ML model training in SGX enclaves.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 08:35:59 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 06:03:57 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Yuhala", "Peterson", ""], ["Felber", "Pascal", ""], ["Schiavoni", "Valerio", ""], ["Tchana", "Alain", ""]]}, {"id": "2104.03018", "submitter": "Peter Christen", "authors": "Sirintra Vaiwsri, Thilina Ranbaduge, Peter Christen, and Kee Siong Ng", "title": "Accurate and Efficient Suffix Tree Based Privacy-Preserving String\n  Matching", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of calculating similarities between strings held by different\norganizations without revealing these strings is an increasingly important\nproblem in areas such as health informatics, national censuses, genomics, and\nfraud detection. Most existing privacy-preserving string comparison functions\nare either based on comparing sets of encoded character q-grams, allow only\nexact matching of encrypted strings, or they are aimed at long genomic\nsequences that have a small alphabet. The set-based privacy-preserving\nsimilarity functions commonly used to compare name and address strings in the\ncontext of privacy-preserving record linkage do not take the positions of\nsub-strings into account. As a result, two very different strings can\npotentially be considered as an exact match leading to wrongly linked records.\nExisting set-based techniques also cannot identify the length of the longest\ncommon sub-string across two strings. In this paper we propose a novel approach\nfor accurate and efficient privacy-preserving string matching based on suffix\ntrees that are encoded using chained hashing. We incorporate a hashing based\nencoding technique upon the encoded suffixes to improve privacy against\nfrequency attacks such as those exploiting Benford's law. Our approach allows\nvarious operations to be performed without the strings to be compared being\nrevealed: the length of the longest common sub-string, do two strings have the\nsame beginning, middle or end, and the longest common sub-string similarity\nbetween two strings. These functions allow a more accurate comparison of, for\nexample, bank account, credit card, or telephone numbers, which cannot be\ncompared appropriately with existing privacy-preserving string matching\ntechniques. Our evaluation on several data sets with different types of strings\nvalidates the privacy and accuracy of our proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 09:45:22 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Vaiwsri", "Sirintra", ""], ["Ranbaduge", "Thilina", ""], ["Christen", "Peter", ""], ["Ng", "Kee Siong", ""]]}, {"id": "2104.03032", "submitter": "David M\\\"odinger", "authors": "David M\\\"odinger and Juri Dispan and Franz J. Hauck", "title": "Shared-Dining: Broadcasting Secret Shares using Dining-Cryptographers\n  Groups", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A k-anonymous broadcast can be implemented using a small group of dining\ncryptographers to first share the message, followed by a flooding phase started\nby group members. Members have little incentive to forward the message in a\ntimely manner, as forwarding incurs costs, or they may even profit from keeping\nthe message. In worst case, this leaves the true originator as the only sender,\nrendering the dining-cryptographers phase useless and compromising their\nprivacy. We present a novel approach using a modified dining-cryptographers\nprotocol to distributed shares of an (n,k)-Shamir's secret sharing scheme.\nFinally, all group members broadcast their received share through the network,\nallowing any recipient of k shares to reconstruct the message, enforcing\nanonymity. If less than k group members broadcast their shares, the message\ncannot be decoded thus preventing privacy breaches for the originator. Our\nsystem provides (n-|attackers|)-anonymity for up to k-1 attackers and has\nlittle performance impact on dissemination. We show these results in a security\nanalysis and performance evaluation based on a proof-of-concept prototype.\nThroughput rates between 10 and 100 kB/s are enough for many real applications\nwith high privacy requirements, e.g., financial blockchain system.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 10:15:25 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["M\u00f6dinger", "David", ""], ["Dispan", "Juri", ""], ["Hauck", "Franz J.", ""]]}, {"id": "2104.03044", "submitter": "Aristodemos Paphitis", "authors": "Aristodemos Paphitis, Nicolas Kourtellis, Michael Sirivianos", "title": "A First Look into the Structural Properties and Resilience of Blockchain\n  Overlays", "comments": "23 pages, 8 figures, 6 tables, submitted to ACM IMC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Blockchain (BC) systems are highly distributed peer-to-peer networks that\noffer an alternative to centralized services and promise robustness to\ncoordinated attacks. However, the resilience and overall security of a BC\nsystem rests heavily on the structural properties of its underlying\npeer-to-peer overlay. Despite their success, BC overlay networks' critical\ndesign aspects, connectivity properties and network-layer inter-dependencies\nare still poorly understood. In this work, we set out to fill this gap and\nstudy the most important overlay network structural properties and robustness\nto targeted attacks of seven distinct BC networks. In particular, we probe and\ncrawl these BC networks every two hours to gather information about all their\navailable peers, over a duration of 28 days. We analyze 335 network snapshots\nper BC network, for a total of 2345 snapshots. We construct, at frequent\nintervals, connectivity graphs for each BC network, consisting of all potential\nconnections between peers. We analyze the structural graph properties of these\nnetworks and compare them across the seven BC networks. We also study how these\nproperties associate with the resilience of each network to partitioning\nattacks, i.e., when peers are selected, attacked and taken offline, using\ndifferent selection strategies driven by the aforementioned structural\nproperties. In fact, we show that by targeting fewer than 10 highly-connected\npeers, major BCs such as Bitcoin can be partitioned into disjoint, i.e.,\ndisconnected, components. Finally, we uncover a hidden interconnection between\ndifferent BC networks, where certain peers participate in more than one BC\nnetwork, which has serious implications for the robustness of the overall BC\nnetwork ecosystem.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 10:44:23 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 13:19:32 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Paphitis", "Aristodemos", ""], ["Kourtellis", "Nicolas", ""], ["Sirivianos", "Michael", ""]]}, {"id": "2104.03152", "submitter": "Bogdan Cebere", "authors": "Ayoub Benaissa, Bilal Retiat, Bogdan Cebere, Alaa Eddine Belfedhal", "title": "TenSEAL: A Library for Encrypted Tensor Operations Using Homomorphic\n  Encryption", "comments": "ICLR 2021 Workshop on Distributed and Private Machine Learning (DPML\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning algorithms have achieved remarkable results and are widely\napplied in a variety of domains. These algorithms often rely on sensitive and\nprivate data such as medical and financial records. Therefore, it is vital to\ndraw further attention regarding privacy threats and corresponding defensive\ntechniques applied to machine learning models. In this paper, we present\nTenSEAL, an open-source library for Privacy-Preserving Machine Learning using\nHomomorphic Encryption that can be easily integrated within popular machine\nlearning frameworks. We benchmark our implementation using MNIST and show that\nan encrypted convolutional neural network can be evaluated in less than a\nsecond, using less than half a megabyte of communication.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 14:32:38 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 04:44:18 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Benaissa", "Ayoub", ""], ["Retiat", "Bilal", ""], ["Cebere", "Bogdan", ""], ["Belfedhal", "Alaa Eddine", ""]]}, {"id": "2104.03168", "submitter": "Chengbin Pang", "authors": "Chengbin Pang, Ruotong Yu, Dongpeng Xu, Eric Koskinen, Georgios\n  Portokalidis, Jun Xu", "title": "Towards Optimal Use of Exception Handling Information for Function\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Function entry detection is critical for security of binary code.\nConventional methods heavily rely on patterns, inevitably missing true\nfunctions and introducing errors. Recently, call frames have been used in\nexception-handling for function start detection. However, existing methods have\ntwo problems. First, they combine call frames with heuristic-based approaches,\nwhich often brings error and uncertain benefits. Second, they trust the\nfidelity of call frames, without handling the errors that are introduced by\ncall frames. In this paper, we first study the coverage and accuracy of\nexisting approaches in detecting function starts using call frames. We found\nthat recursive disassembly with call frames can maximize coverage, and using\nextra heuristic-based approaches does not improve coverage and actually hurts\naccuracy. Second, we unveil call-frame errors and develop the first approach to\nfix them, making their use more reliable.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 14:57:01 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Pang", "Chengbin", ""], ["Yu", "Ruotong", ""], ["Xu", "Dongpeng", ""], ["Koskinen", "Eric", ""], ["Portokalidis", "Georgios", ""], ["Xu", "Jun", ""]]}, {"id": "2104.03277", "submitter": "Venkatraman Ramakrishna", "authors": "Bishakh Chandra Ghosh, Venkatraman Ramakrishna, Chander Govindarajan,\n  Dushyant Behl, Dileban Karunamoorthy, Ermyas Abebe, Sandip Chakraborty", "title": "Decentralized Cross-Network Identity Management for Blockchain\n  Interoperation", "comments": "9 pages, 5 figures, accepted for publication in the proceedings of\n  the IEEE International Conference on Blockchain and Cryptocurrency (ICBC)\n  2021", "journal-ref": null, "doi": "10.1109/ICBC51069.2021.9461064", "report-no": null, "categories": "cs.DC cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Interoperation for data sharing between permissioned blockchain networks\nrelies on networks' abilities to independently authenticate requests and\nvalidate proofs accompanying the data; these typically contain digital\nsignatures. This requires counterparty networks to know the identities and\ncertification chains of each other's members, establishing a common trust basis\nrooted in identity. But permissioned networks are ad hoc consortia of existing\norganizations, whose network affiliations may not be well-known or\nwell-established even though their individual identities are. In this paper, we\ndescribe an architecture and set of protocols for distributed identity\nmanagement across permissioned blockchain networks to establish a trust basis\nfor data sharing. Networks wishing to interoperate can associate with one or\nmore distributed identity registries that maintain credentials on shared\nledgers managed by groups of reputed identity providers. A network's\nparticipants possess self-sovereign decentralized identities (DIDs) on these\nregistries and can obtain privacy-preserving verifiable membership credentials.\nDuring interoperation, networks can securely and dynamically discover each\nothers' latest membership lists and members' credentials. We implement a\nsolution based on Hyperledger Indy and Aries, and demonstrate its viability and\nusefulness by linking a trade finance network with a trade logistics network,\nboth built on Hyperledger Fabric. We also analyze the extensibility, security,\nand trustworthiness of our system.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 17:31:45 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Ghosh", "Bishakh Chandra", ""], ["Ramakrishna", "Venkatraman", ""], ["Govindarajan", "Chander", ""], ["Behl", "Dushyant", ""], ["Karunamoorthy", "Dileban", ""], ["Abebe", "Ermyas", ""], ["Chakraborty", "Sandip", ""]]}, {"id": "2104.03283", "submitter": "Thomas Dover", "authors": "Thomas P. Dover", "title": "Evaluating Medical IoT (MIoT) Device Security using NISTIR-8228\n  Expectations", "comments": "Update to original publication. Revised version incorporates relevant\n  information from (Presidential) Executive Order published May 12, 2021\n  (Executive Order on Improving the Nation's Cybersecurity)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How do healthcare organizations (from small Practices to large HDOs) evaluate\nadherence to the cybersecurity and privacy protection of Medical Internet of\nThings (MIoT) used in clinical settings? This paper suggests an approach for\nsuch evaluation using National Institute of Standards and Technology (NIST)\nguidance. Through application of NISTIR 8228 Expectations it is possible to\nquantitatively assess cybersecurity and privacy protection, and determine\nrelative compliance with recommended standards. This approach allows\norganizations to evaluate the level of risk a MiOT device poses to IT systems\nand to determine whether or not to permit its use in healthcare/IT\nenvironments.\n  This paper reviews the current state of IoT/MiOT cybersecurity and privacy\nprotection using historical and current industry guidance & best-practices;\nrecommendations by federal agencies; NIST publications; and federal law. It\nthen presents similarities and differences between IOT/MiOT devices and\n\"traditional\" (or classic) Information Technology (IT) hardware, and cites\nseveral challenges IoT/MiOT pose to cybersecurity and privacy protection.\n  Finally, a practical approach to evaluating cybersecurity and privacy\nprotection is offered along with enhancements for validating assessment\nresults. In so doing it will demonstrate general compliance with both NIST\nguidance and HIPAA/HITECH requirements.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 17:40:44 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 23:14:38 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Dover", "Thomas P.", ""]]}, {"id": "2104.03354", "submitter": "Shantanu Sharma", "authors": "Yin Li, Dhrubajyoti Ghosh, Peeyush Gupta, Sharad Mehrotra, Nisha\n  Panwar, Shantanu Sharma", "title": "Prism: Private Verifiable Set Computation over Multi-Owner Outsourced\n  Databases", "comments": "This paper has been accepted in ACM SIGMOD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR cs.DC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes Prism, a secret sharing based approach to compute private\nset operations (i.e., intersection and union), as well as aggregates over\noutsourced databases belonging to multiple owners. Prism enables data owners to\npre-load the data onto non-colluding servers and exploits the additive and\nmultiplicative properties of secret-shares to compute the above-listed\noperations in (at most) two rounds of communication between the servers\n(storing the secret-shares) and the querier, resulting in a very efficient\nimplementation. Also, Prism does not require communication among the servers\nand supports result verification techniques for each operation to detect\nmalicious adversaries. Experimental results show that Prism scales both in\nterms of the number of data owners and database sizes, to which prior\napproaches do not scale.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 19:08:15 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Li", "Yin", ""], ["Ghosh", "Dhrubajyoti", ""], ["Gupta", "Peeyush", ""], ["Mehrotra", "Sharad", ""], ["Panwar", "Nisha", ""], ["Sharma", "Shantanu", ""]]}, {"id": "2104.03366", "submitter": "Md Imran Hossen", "authors": "Md Imran Hossen, Yazhou Tu, Md Fazle Rabby, Md Nazmul Islam, Hui Cao\n  and Xiali Hei", "title": "An Object Detection based Solver for Google's Image reCAPTCHA v2", "comments": "Accepted at the 23rd International Symposium on Research in Attacks,\n  Intrusions and Defenses (RAID 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Previous work showed that reCAPTCHA v2's image challenges could be solved by\nautomated programs armed with Deep Neural Network (DNN) image classifiers and\nvision APIs provided by off-the-shelf image recognition services. In response\nto emerging threats, Google has made significant updates to its image reCAPTCHA\nv2 challenges that can render the prior approaches ineffective to a great\nextent. In this paper, we investigate the robustness of the latest version of\nreCAPTCHA v2 against advanced object detection based solvers. We propose a\nfully automated object detection based system that breaks the most advanced\nchallenges of reCAPTCHA v2 with an online success rate of 83.25%, the highest\nsuccess rate to date, and it takes only 19.93 seconds (including network\ndelays) on average to crack a challenge. We also study the updated security\nfeatures of reCAPTCHA v2, such as anti-recognition mechanisms, improved\nanti-bot detection techniques, and adjustable security preferences. Our\nextensive experiments show that while these security features can provide some\nresistance against automated attacks, adversaries can still bypass most of\nthem. Our experimental findings indicate that the recent advances in object\ndetection technologies pose a severe threat to the security of image captcha\ndesigns relying on simple object detection as their underlying AI problem.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 19:35:33 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Hossen", "Md Imran", ""], ["Tu", "Yazhou", ""], ["Rabby", "Md Fazle", ""], ["Islam", "Md Nazmul", ""], ["Cao", "Hui", ""], ["Hei", "Xiali", ""]]}, {"id": "2104.03413", "submitter": "Yi Zeng", "authors": "Yi Zeng, Won Park, Z. Morley Mao and Ruoxi Jia", "title": "Rethinking the Backdoor Attacks' Triggers: A Frequency Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backdoor attacks have been considered a severe security threat to deep\nlearning. Such attacks can make models perform abnormally on inputs with\npredefined triggers and still retain state-of-the-art performance on clean\ndata. While backdoor attacks have been thoroughly investigated in the image\ndomain from both attackers' and defenders' sides, an analysis in the frequency\ndomain has been missing thus far.\n  This paper first revisits existing backdoor triggers from a frequency\nperspective and performs a comprehensive analysis. Our results show that many\ncurrent backdoor attacks exhibit severe high-frequency artifacts, which persist\nacross different datasets and resolutions. We further demonstrate these\nhigh-frequency artifacts enable a simple way to detect existing backdoor\ntriggers at a detection rate of 98.50% without prior knowledge of the attack\ndetails and the target model. Acknowledging previous attacks' weaknesses, we\npropose a practical way to create smooth backdoor triggers without\nhigh-frequency artifacts and study their detectability. We show that existing\ndefense works can benefit by incorporating these smooth triggers into their\ndesign consideration. Moreover, we show that the detector tuned over stronger\nsmooth triggers can generalize well to unseen weak smooth triggers. In short,\nour work emphasizes the importance of considering frequency analysis when\ndesigning both backdoor attacks and defenses in deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 22:05:28 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 18:49:01 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Zeng", "Yi", ""], ["Park", "Won", ""], ["Mao", "Z. Morley", ""], ["Jia", "Ruoxi", ""]]}, {"id": "2104.03466", "submitter": "Zekai Chen", "authors": "Zekai Chen, Dingshuo Chen, Xiao Zhang, Zixuan Yuan, Xiuzhen Cheng", "title": "Learning Graph Structures with Transformer for Multivariate Time Series\n  Anomaly Detection in IoT", "comments": "12 pages, 5 figures, Accepted by IEEE Internet of Things Journal 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world IoT systems, which include a variety of internet-connected\nsensory devices, produce substantial amounts of multivariate time series data.\nMeanwhile, vital IoT infrastructures like smart power grids and water\ndistribution networks are frequently targeted by cyber-attacks, making anomaly\ndetection an important study topic. Modeling such relatedness is, nevertheless,\nunavoidable for any efficient and effective anomaly detection system, given the\nintricate topological and nonlinear connections that are originally unknown\namong sensors. Furthermore, detecting anomalies in multivariate time series is\ndifficult due to their temporal dependency and stochasticity. This paper\npresented GTA, a new framework for multivariate time series anomaly detection\nthat involves automatically learning a graph structure, graph convolution, and\nmodeling temporal dependency using a Transformer-based architecture. The\nconnection learning policy, which is based on the Gumbel-softmax sampling\napproach to learn bi-directed links among sensors directly, is at the heart of\nlearning graph structure. To describe the anomaly information flow between\nnetwork nodes, we introduced a new graph convolution called Influence\nPropagation convolution. In addition, to tackle the quadratic complexity\nbarrier, we suggested a multi-branch attention mechanism to replace the\noriginal multi-head self-attention method. Extensive experiments on four\npublicly available anomaly detection benchmarks further demonstrate the\nsuperiority of our approach over alternative state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 01:45:28 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 02:11:39 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Chen", "Zekai", ""], ["Chen", "Dingshuo", ""], ["Zhang", "Xiao", ""], ["Yuan", "Zixuan", ""], ["Cheng", "Xiuzhen", ""]]}, {"id": "2104.03499", "submitter": "Misbah Shafi", "authors": "Misbah Shafi, Rakesh Kumar Jha", "title": "Half-Duplex Attack: An Effectual Attack Modelling in D2D Communication", "comments": null, "journal-ref": null, "doi": "10.1109/COMSNETS48256.2020.9027360", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The visualization of future generation Wireless Communication Network WCN\nredirects the presumption of onward innovations, the fulfillment of user\ndemands in the form of high data rates, energy efficiency, low latency, and\nlong-range services. To content these demands, various technologies such as\nmassive MIMO Multiple Input Multiple Output, UDN Ultra Dense Network, spectrum\nsharing, D2D Device to Device communication were improvised in the next\ngeneration WCN. In comparison to previous technologies, these technologies\nexhibit flat architecture, the involvement of clouds in the network,\ncentralized architecture incorporating small cells which creates vulnerable\nbreaches initiating menaces to the security of the network. The half-duplex\nattack is another threat to the WCN, where the resource spoofing mechanism is\nattained in the downlink phase of D2D communication. Instead of triggering an\nattack on both uplink and downlink, solely downlink is targeted by the\nattacker. This scheme allows the reduced failed attempt rate of the attacker as\ncompared to the conventional attacks. The analysis is determined on the basis\nof Poissons distribution to determine the probability of failed attempts of\nhalf duplex attack in contrast to a full duplex attack\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 04:18:45 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Shafi", "Misbah", ""], ["Jha", "Rakesh Kumar", ""]]}, {"id": "2104.03504", "submitter": "Misbah Shafi", "authors": "Misbah Shafi, Rakesh Kumar Jha, Manish Sabraj", "title": "A Survey on Security Issues of 5G NR: Perspective of Artificial Dust and\n  Artificial Rain", "comments": null, "journal-ref": null, "doi": "10.1016/j.jnca.2020.102597", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  5G NR (New Radio) incorporates concepts of novel technologies such as\nspectrum sharing, D2D communication, UDN, and massive MIMO. However, providing\nsecurity and identifying the security threats to these technologies occupies\nthe prime concern. This paper intends to provide an ample survey of security\nissues and their countermeasures encompassed in the technologies of 5G NR.\nFurther, security concerns of each technology are defined mathematically.\nThereby defining the impact on the factors of security. Moreover, a methodology\nis developed in which the influence on security due to artificially generated\nrain and artificially generated dust on the wireless communication network is\nstudied. By doing so, an attacking scenario is identified, where a half-duplex\nattack in D2D communication is attained. Half-duplex attack specifies the\nattack solely on the downlink to spoof the allocated resources, with reduced\nmiss-rate. Thus, ultra-reliable and adequate advances are required to be\naddressed to remove the obstacles that create a hindrance in achieving the\nsecured and authenticated communicating network\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 04:37:13 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Shafi", "Misbah", ""], ["Jha", "Rakesh Kumar", ""], ["Sabraj", "Manish", ""]]}, {"id": "2104.03508", "submitter": "Misbah Shafi", "authors": "Misbah Shafi, Rakesh Kumar Jha", "title": "AR Based Half-Duplex Attack in Beyond 5G networks", "comments": null, "journal-ref": null, "doi": "10.1109/JSYST.2020.2990363", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the evolution of WCN (Wireless communication networks), the absolute\nfulfillment of security occupies the fundamental concern. In view of security,\nwe have identified another research direction based on the attenuation impact\nof rain in WCN. An approach is initiated by an eavesdropper in which a secure\ncommunication environment is degraded by generating Artificial Rain (AR), which\ncreates an abatement in the secrecy rate, and the cybersecurity gets\ncompromised. By doing so, an attacking scenario is perceived, in which an\nintruder models a Half-Duplex (HD) attack. Half-Duplex specifies the attack on\nthe downlink instead of targeting both uplink and downlink. This allows the\nattacker to alleviate the miss-rate of the attacking attempts. The layout for\nthe HD attack is explained using RRC (Radio Resource Control)-setup. Further,\nwe have determined and examined the performance parameters such as secrecy\nrate, energy efficiency, miss-rate, sensitivity in the presence of AR. Further\ncomparison of rural and urban scenarios in the presence and absence of AR is\ncarried out concerning the variation in secrecy rate with respect to the\nmillimeter-wave frequencies and distance. Lastly, the methodology of the HD\nattack is simulated, revealing that the HD attack maintains a low miss rate\nwith improved performance as compared to the performance and miss-rate attained\nby the full-duplex attack\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 04:50:51 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Shafi", "Misbah", ""], ["Jha", "Rakesh Kumar", ""]]}, {"id": "2104.03566", "submitter": "Charles-Edmond Bichot", "authors": "Alain Menelet, Charles-Edmond Bichot (LIRIS, ECL)", "title": "Characterization of Android malware based on subgraph isomorphism", "comments": "in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Android operating system is the most spread mobile platform in the world.\nTherefor attackers are producing an incredible number of malware applications\nfor Android. Our aim is to detect Android's malware in order to protect the\nuser. To do so really good results are obtained by dynamic analysis of\nsoftware, but it requires complex environments. In order to achieve the same\nlevel of precision we analyze the machine code and investigate the frequencies\nof ngrams of opcodes in order to detect singular code blocks. This allow us to\nconstruct a database of infected code blocks. Then, because attacker may modify\nand organized differently the infected injected code in their new malware, we\nperform not only a semantic comparison of the tested software with the database\nof infected code blocks but also a structured comparison. To do such comparison\nwe compute subgraph isomorphism. It allows us to characterize precisely if the\ntested software is a malware and if so in witch family it belongs. Our method\nis tested both on a laboratory database and a set of real data. It achieves an\nalmost perfect detection rate.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 07:31:18 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Menelet", "Alain", "", "LIRIS, ECL"], ["Bichot", "Charles-Edmond", "", "LIRIS, ECL"]]}, {"id": "2104.03586", "submitter": "Charles-Edmond Bichot", "authors": "Alain Menelet, Charles-Edmond Bichot (LIRIS, ECL)", "title": "Characterization of Android malware based on opcode analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Android operating system is the most spread mobile platform in the world.\nTherefor attackers are producing an incredible number of malware applications\nfor Android. Our aim is to detect Android's malware in order to protect the\nuser. To do so really good results are obtained by dynamic analysis of\nsoftware, but it requires complex environments. In order to achieve the same\nlevel of precision we analyze the machine code and investigate the frequencies\nof ngrams of opcodes in order to detect singular code blocks. This allow us to\nconstruct a database of infected code blocks. Then, because attacker may modify\nand organized differently the infected injected code in their new malware, we\nperform not only a semantic comparison of the tested software with the database\nof infected code blocks but also a structured comparison. To do such comparison\nwe compute subgraph isomorphism. It allows us to characterize precisely if the\ntested software is a malware and if so in witch family it belongs. Our method\nis tested both on a laboratory database and a set of real data. It achieves an\nalmost perfect detection rate.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 07:55:19 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Menelet", "Alain", "", "LIRIS, ECL"], ["Bichot", "Charles-Edmond", "", "LIRIS, ECL"]]}, {"id": "2104.03594", "submitter": "Li Zhang", "authors": "Li Zhang and Vrizlynn L. L. Thing", "title": "Three Decades of Deception Techniques in Active Cyber Defense --\n  Retrospect and Outlook", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deception techniques have been widely seen as a game changer in cyber\ndefense. In this paper, we review representative techniques in honeypots,\nhoneytokens, and moving target defense, spanning from the late 1980s to the\nyear 2021. Techniques from these three domains complement with each other and\nmay be leveraged to build a holistic deception based defense. However, to the\nbest of our knowledge, there has not been a work that provides a systematic\nretrospect of these three domains all together and investigates their\nintegrated usage for orchestrated deceptions. Our paper aims to fill this gap.\nBy utilizing a tailored cyber kill chain model which can reflect the current\nthreat landscape and a four-layer deception stack, a two-dimensional taxonomy\nis developed, based on which the deception techniques are classified. The\ntaxonomy literally answers which phases of a cyber attack campaign the\ntechniques can disrupt and which layers of the deception stack they belong to.\nCyber defenders may use the taxonomy as a reference to design an organized and\ncomprehensive deception plan, or to prioritize deception efforts for a budget\nconscious solution. We also discuss two important points for achieving active\nand resilient cyber defense, namely deception in depth and deception lifecycle,\nwhere several notable proposals are illustrated. Finally, some outlooks on\nfuture research directions are presented, including dynamic integration of\ndifferent deception techniques, quantified deception effects and deception\noperation cost, hardware-supported deception techniques, as well as techniques\ndeveloped based on better understanding of the human element.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 08:15:00 GMT"}], "update_date": "2021-04-10", "authors_parsed": [["Zhang", "Li", ""], ["Thing", "Vrizlynn L. L.", ""]]}, {"id": "2104.03631", "submitter": "Daniel Reti", "authors": "Daniel Reti, Daniel Fraunholz, Janis Zemitis, Daniel Schneider, Hans\n  Dieter Schotten", "title": "Deep Down the Rabbit Hole: On References in Networks of Decoy Elements", "comments": null, "journal-ref": "2020 International Conference on Cyber Security and Protection of\n  Digital Services (Cyber Security)", "doi": "10.1109/CyberSecurity49315.2020.9138850", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deception technology has proven to be a sound approach against threats to\ninformation systems. Aside from well-established honeypots, decoy elements,\nalso known as honeytokens, are an excellent method to address various types of\nthreats. Decoy elements are causing distraction and uncertainty to an attacker\nand help detecting malicious activity. Deception is meant to be complementing\nfirewalls and intrusion detection systems. Particularly insider threats may be\nmitigated with deception methods. While current approaches consider the use of\nmultiple decoy elements as well as context-sensitivity, they do not\nsufficiently describe a relationship between individual elements. In this work,\ninter-referencing decoy elements are introduced as a plausible extension to\nexisting deception frameworks, leading attackers along a path of decoy\nelements. A theoretical foundation is introduced, as well as a stochastic model\nand a reference implementation. It was found that the proposed system is\nsuitable to enhance current decoy frameworks by adding a further dimension of\ninter-connectivity and therefore improve intrusion detection and prevention.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 09:34:05 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Reti", "Daniel", ""], ["Fraunholz", "Daniel", ""], ["Zemitis", "Janis", ""], ["Schneider", "Daniel", ""], ["Schotten", "Hans Dieter", ""]]}, {"id": "2104.03651", "submitter": "Daniel Reti", "authors": "Daniel Reti, Norman Becker", "title": "Escape the Fake: Introducing Simulated Container-Escapes for Honeypots", "comments": null, "journal-ref": "2020 Workshop on Next Generation Networks and Applications (NGNA)", "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of network security, the concept of honeypots is well\nestablished in research as well as in production. Honeypots are used to imitate\na legitimate target on the network and to raise an alert on any interaction.\nThis does not only help learning about a breach, but also allows researchers to\nstudy the techniques of an attacker. With the rise of cloud computing,\ncontainer-based virtualization gained popularity for application deployment.\nThis paper investigates the possibilities of container-based honeypots and\nintroduces the concept of simulating container escapes as a deception\ntechnique.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 10:16:03 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Reti", "Daniel", ""], ["Becker", "Norman", ""]]}, {"id": "2104.03654", "submitter": "Hemlata Tak", "authors": "Hemlata Tak, Jee-weon Jung, Jose Patino, Massimiliano Todisco and\n  Nicholas Evans", "title": "Graph Attention Networks for Anti-Spoofing", "comments": "Submitted to INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CR cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The cues needed to detect spoofing attacks against automatic speaker\nverification are often located in specific spectral sub-bands or temporal\nsegments. Previous works show the potential to learn these using either\nspectral or temporal self-attention mechanisms but not the relationships\nbetween neighbouring sub-bands or segments. This paper reports our use of graph\nattention networks (GATs) to model these relationships and to improve spoofing\ndetection performance. GATs leverage a self-attention mechanism over graph\nstructured data to model the data manifold and the relationships between nodes.\nOur graph is constructed from representations produced by a ResNet. Nodes in\nthe graph represent information either in specific sub-bands or temporal\nsegments. Experiments performed on the ASVspoof 2019 logical access database\nshow that our GAT-based model with temporal attention outperforms all of our\nbaseline single systems. Furthermore, GAT-based systems are complementary to a\nset of existing systems. The fusion of GAT-based models with more conventional\ncountermeasures delivers a 47% relative improvement in performance compared to\nthe best performing single GAT system.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 10:18:17 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Tak", "Hemlata", ""], ["Jung", "Jee-weon", ""], ["Patino", "Jose", ""], ["Todisco", "Massimiliano", ""], ["Evans", "Nicholas", ""]]}, {"id": "2104.03666", "submitter": "Daniel Reti", "authors": "Daniel Reti, David Klaa{\\ss}en, Simon Duque Anton, Hans Dieter\n  Schotten", "title": "Secure (S)Hell: Introducing an SSH Deception Proxy Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deceiving an attacker in the network security domain is a well established\napproach, mainly achieved through deployment of honeypots consisting of open\nnetwork ports with the sole purpose of raising an alert on a connection. With\nattackers becoming more careful to avoid honeypots, other decoy elements on\nreal host systems continue to create uncertainty for attackers. This\nuncertainty makes an attack more difficult, as an attacker cannot be sure\nwhether the system does contain deceptive elements or not. Consequently, each\naction of an attacker could lead to the discovery. In this paper a framework is\nproposed for placing decoy elements through an SSH proxy, allowing to deploy\ndecoy elements on-the-fly without the need for a modification of the protected\nhost system.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 10:28:27 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Reti", "Daniel", ""], ["Klaa\u00dfen", "David", ""], ["Anton", "Simon Duque", ""], ["Schotten", "Hans Dieter", ""]]}, {"id": "2104.03674", "submitter": "Jing Xu", "authors": "Jing Xu, Minhui (Jason) Xue, Stjepan Picek", "title": "Explainability-based Backdoor Attacks Against Graph Neural Networks", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Backdoor attacks represent a serious threat to neural network models. A\nbackdoored model will misclassify the trigger-embedded inputs into an\nattacker-chosen target label while performing normally on other benign inputs.\nThere are already numerous works on backdoor attacks on neural networks, but\nonly a few works consider graph neural networks (GNNs). As such, there is no\nintensive research on explaining the impact of trigger injecting position on\nthe performance of backdoor attacks on GNNs.\n  To bridge this gap, we conduct an experimental investigation on the\nperformance of backdoor attacks on GNNs. We apply two powerful GNN\nexplainability approaches to select the optimal trigger injecting position to\nachieve two attacker objectives -- high attack success rate and low clean\naccuracy drop. Our empirical results on benchmark datasets and state-of-the-art\nneural network models demonstrate the proposed method's effectiveness in\nselecting trigger injecting position for backdoor attacks on GNNs. For\ninstance, on the node classification task, the backdoor attack with trigger\ninjecting position selected by GraphLIME reaches over $84 \\%$ attack success\nrate with less than $2.5 \\%$ accuracy drop\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 10:43:40 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 13:31:52 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Xu", "Jing", "", "Jason"], ["Minhui", "", "", "Jason"], ["Xue", "", ""], ["Picek", "Stjepan", ""]]}, {"id": "2104.03763", "submitter": "Lotfi ben Othmane", "authors": "Mubark Jedh, Lotfi ben Othmane, Noor Ahmed, Bharat Bhargava", "title": "Detection of Message Injection Attacks onto the CAN Bus using Similarity\n  of Successive Messages-Sequence Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The smart features of modern cars are enabled by a number of Electronic\nControl Units (ECUs) components that communicate through an in-vehicle network,\nknown as Controller Area Network (CAN) bus. The fundamental challenge is the\nsecurity of the communication link where an attacker can inject messages (e.g.,\nincrease the speed) that may impact the safety of the driver. Developing an\neffective defensive security solution depends on the knowledge of the identity\nof the ECUs, which is proprietary information. This paper proposes a message\ninjection attack detection mechanism that is independent of the IDs of the\nECUs, which is achieved by capturing the patterns in the message sequences.\nFirst, we represent the sequencing ofther messages in a given time-interval as\na direct graph and compute the similarities of the successive graphs using the\ncosine similarity and Pearson correlation. Then, we apply threshold, change\npoint detection, and Long Short-Term Memory (LSTM)-Recurrent NeuralNetwork\n(RNN) to detect and predict malicious message injections into the CAN bus. The\nevaluation of the methods using a dataset collected from a moving vehicle under\nmalicious RPM and speed reading message injections show a detection accuracy of\n98.45% when using LSTM-RNN and 97.32% when using a threshold method. Further,\nthe pace of detecting the change isfast for the case of injection of RPM\nreading messagesbut slow for the case of injection of speed readingsmessages.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 13:29:57 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 02:43:06 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Jedh", "Mubark", ""], ["Othmane", "Lotfi ben", ""], ["Ahmed", "Noor", ""], ["Bhargava", "Bharat", ""]]}, {"id": "2104.03813", "submitter": "Yifeng Zheng", "authors": "Jihyeon Ryu, Yifeng Zheng, Yansong Gao, Sharif Abuadbba, Junyaup Kim,\n  Dongho Won, Surya Nepal, Hyoungshick Kim, Cong Wang", "title": "Can Differential Privacy Practically Protect Collaborative Deep Learning\n  Inference for the Internet of Things?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Collaborative inference has recently emerged as an intriguing framework for\napplying deep learning to Internet of Things (IoT) applications, which works by\nsplitting a DNN model into two subpart models respectively on\nresource-constrained IoT devices and the cloud. Even though IoT applications'\nraw input data is not directly exposed to the cloud in such framework,\nrevealing the local-part model's intermediate output still entails privacy\nrisks. For mitigation of privacy risks, differential privacy could be adopted\nin principle. However, the practicality of differential privacy for\ncollaborative inference under various conditions remains unclear. For example,\nit is unclear how the calibration of the privacy budget epsilon will affect the\nprotection strength and model accuracy in presence of the state-of-the-art\nreconstruction attack targeting collaborative inference, and whether a good\nprivacy-utility balance exists. In this paper, we provide the first systematic\nstudy to assess the effectiveness of differential privacy for protecting\ncollaborative inference in presence of the reconstruction attack, through\nextensive empirical evaluations on various datasets. Our results show\ndifferential privacy can be used for collaborative inference when confronted\nwith the reconstruction attack, with insights provided about privacyutility\ntrade-offs. Specifically, across the evaluated datasets, we observe there\nexists a suitable privacy budget range (particularly 100<=epsilon<=200 in our\nevaluation) providing a good tradeoff between utility and privacy protection.\nOur key observation drawn from our study is that differential privacy tends to\nperform better in collaborative inference for datasets with smaller intraclass\nvariations, which, to our knowledge, is the first easy-toadopt practical\nguideline.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 14:46:33 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Ryu", "Jihyeon", ""], ["Zheng", "Yifeng", ""], ["Gao", "Yansong", ""], ["Abuadbba", "Sharif", ""], ["Kim", "Junyaup", ""], ["Won", "Dongho", ""], ["Nepal", "Surya", ""], ["Kim", "Hyoungshick", ""], ["Wang", "Cong", ""]]}, {"id": "2104.03814", "submitter": "Jingbo Zhou", "authors": "Jingbo Zhou, Xinmiao Zhang", "title": "Algorithmic Obfuscation for LDPC Decoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to protect intellectual property against untrusted foundry, many\nlogic-locking schemes have been developed. The main idea of logic locking is to\ninsert a key-controlled block into a circuit to make the circuit function\nincorrectly without right keys. However, in the case that the algorithm\nimplemented by the circuit is naturally fault-tolerant or self-correcting,\nexisting logic-locking schemes do not affect the system performance much even\nif wrong keys are used. One example is low-density parity-check (LDPC)\nerror-correcting decoder, which has broad applications in digital\ncommunications and storage. This paper proposes two algorithmic-level\nobfuscation methods for LDPC decoders. By modifying the decoding process and\nlocking the stopping criterion, our new designs substantially degrade the\ndecoder throughput and/or error-correcting performance when the wrong key is\nused. Besides, our designs are also resistant to the SAT, AppSAT and removal\nattacks. For an example LDPC decoder, our proposed methods reduce the\nthroughput to less than 1/3 and/or increase the decoder error rate by at least\ntwo orders of magnitude with only 0.33% area overhead.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 14:49:15 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Zhou", "Jingbo", ""], ["Zhang", "Xinmiao", ""]]}, {"id": "2104.03863", "submitter": "Gauthier Gidel", "authors": "S\\'ebastien Bubeck, Yeshwanth Cherapanamjeri, Gauthier Gidel and\n  R\\'emi Tachet des Combes", "title": "A single gradient step finds adversarial examples on random two-layers\n  neural networks", "comments": "Added a comment about universal adversarial perturbations. 18 pages,\n  7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Daniely and Schacham recently showed that gradient descent finds adversarial\nexamples on random undercomplete two-layers ReLU neural networks. The term\n\"undercomplete\" refers to the fact that their proof only holds when the number\nof neurons is a vanishing fraction of the ambient dimension. We extend their\nresult to the overcomplete case, where the number of neurons is larger than the\ndimension (yet also subexponential in the dimension). In fact we prove that a\nsingle step of gradient descent suffices. We also show this result for any\nsubexponential width random neural network with smooth activation function.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 16:06:54 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 22:13:17 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Cherapanamjeri", "Yeshwanth", ""], ["Gidel", "Gauthier", ""], ["Combes", "R\u00e9mi Tachet des", ""]]}, {"id": "2104.03868", "submitter": "Kubilay Ahmet K\\\"u\\c{c}\\\"uk", "authors": "Kubilay Ahmet K\\\"u\\c{c}\\\"uk, Andrew Martin", "title": "CRC: Fully General Model of Confidential Remote Computing", "comments": "37 pages, 7 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Digital services have been offered through remote systems for decades. The\nquestions of how these systems can be built in a trustworthy manner and how\ntheir security properties can be understood are given fresh impetus by recent\nhardware developments, allowing a fuller, more general, exploration of the\npossibilities than has previously been seen in the literature. Drawing on and\nconsolidating the disparate strains of research, technologies and methods\nemployed throughout the adaptation of confidential computing, we present a\nnovel, dedicated Confidential Remote Computing (CRC) model. CRC proposes a\ncompact solution for next-generation applications to be built on strong\nhardware-based security primitives, control of secure software products'\ntrusted computing base, and a way to make correct use of proofs and evidence\nreports generated by the attestation mechanisms. The CRC model illustrates the\ntrade-offs between decentralisation, task size and transparency overhead. We\nconclude the paper with six lessons learned from our approach, and suggest two\nfuture research directions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 16:22:51 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["K\u00fc\u00e7\u00fck", "Kubilay Ahmet", ""], ["Martin", "Andrew", ""]]}, {"id": "2104.03881", "submitter": "George Monta\\~nez", "authors": "George D. Montanez", "title": "Permutation Encoding for Text Steganography: A Short Tutorial", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We explore a method of encoding secret messages using factoradic numbering of\npermuted lists of text or numeric elements. Encoding and decoding methods are\nprovided, with code, and key aspects of the correctness of the methods are\nformally proven. The method of encoding is simple and provides a working\nexample of using textual and numeric lists as a stenagographic channel. Given\nthe ubiquity of lists, such channels are already present but are often unused.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 16:40:45 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Montanez", "George D.", ""]]}, {"id": "2104.04030", "submitter": "Saverio Giallorenzo", "authors": "Asmita Dalela, Saverio Giallorenzo, Oksana Kulyk, Jacopo Mauro, and\n  Elda Paja", "title": "A Mixed-method Study on Security and Privacy Practices in Danish\n  Companies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increased levels of digitalization in society expose companies to new\nsecurity threats, requiring them to establish adequate security and privacy\nmeasures. Additionally, the presence of exogenous forces like new regulations,\ne.g., GDPR and the global COVID-19 pandemic, pose new challenges for companies\nthat should preserve an adequate level of security while having to adapt to\nchange. In this paper, we investigate such challenges through a two-phase study\nin companies located in Denmark -- a country characterized by a high level of\ndigitalization and trust -- focusing on software development and tech-related\ncompanies. Our results show a number of issues, most notably i) a misalignment\nbetween software developers and management when it comes to the implementation\nof security and privacy measures, ii) difficulties in adapting company\npractices in light of implementing GDPR compliance, and iii) different views on\nthe need to adapt security measures to cope with the COVID-19 pandemic.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 20:01:39 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Dalela", "Asmita", ""], ["Giallorenzo", "Saverio", ""], ["Kulyk", "Oksana", ""], ["Mauro", "Jacopo", ""], ["Paja", "Elda", ""]]}, {"id": "2104.04054", "submitter": "Abhijitt Dhavlle", "authors": "Abhijitt Dhavlle", "title": "Adversarial Learning Inspired Emerging Side-Channel Attacks and Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolving attacks on the vulnerabilities of the computing systems demand novel\ndefense strategies to keep pace with newer attacks. This report discusses\nprevious works on side-channel attacks (SCAs) and defenses for cache-targeted\nand physical proximity attacks. We then discuss the proposed Entropy-Shield as\na defense against timing SCAs, and explain how we can extend the same to\nhardware-based implementations of crypto applications as \"Entropy-Shield for\nFPGA\". We then discuss why we want to build newer attacks with the hope of\ncoming up with better defense strategies.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 20:56:58 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Dhavlle", "Abhijitt", ""]]}, {"id": "2104.04071", "submitter": "Gautam Srivastava", "authors": "Farrah Huntinghawk, Candace Richard, Sarah Plosker, Gautam Srivastava", "title": "Expanding Cybersecurity Knowledge Through an Indigenous Lens: A First\n  Look", "comments": "9 pages, 0 figures", "journal-ref": "2020 IEEE CCECE, London, ON, Canada, 2020, pp. 1-4", "doi": "10.1109/CCECE47787.2020.9255753.", "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Decolonization and Indigenous education are at the forefront of Canadian\ncontent currently in Academia. Over the last few decades, we have seen some\nmajor changes in the way in which we share information. In particular, we have\nmoved into an age of electronically-shared content, and there is an increasing\nexpectation in Canada that this content is both culturally significant and\nrelevant. In this paper, we discuss an ongoing community engagement initiative\nwith First Nations communities in the Western Manitoba region. The initiative\ninvolves knowledge-sharing activities that focus on the topic of cybersecurity,\nand are aimed at a public audience. This initial look into our educational\nproject focuses on the conceptual analysis and planning stage. We are\ndeveloping a \"Cybersecurity 101\" mini-curriculum, to be implemented over\nseveral one-hour long workshops aimed at diverse groups (these public workshops\nmay include a wide range of participants, from tech-adverse to tech-savvy).\nLearning assessment tools have been built in to the workshop program. We have\ncreated informational and promotional pamphlets, posters, lesson plans, and\nfeedback questionnaires which we believe instill relevance and personal\nconnection to this topic, helping to bridge gaps in accessibility for\nIndigenous communities while striving to build positive, reciprocal\nrelationships. Our methodology is to approach the subject from a community\nneeds and priorities perspective. Activities are therefore being tailored to\nfit each community.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 19:25:01 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Huntinghawk", "Farrah", ""], ["Richard", "Candace", ""], ["Plosker", "Sarah", ""], ["Srivastava", "Gautam", ""]]}, {"id": "2104.04077", "submitter": "Filipo Sharevski", "authors": "Donald Gover and Filipo Sharevski", "title": "Two Truths and a Lie: Exploring Soft Moderation of COVID-19\n  Misinformation with Amazon Alexa", "comments": "arXiv admin note: text overlap with arXiv:2104.00779", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we analyzed the perceived accuracy of COVID-19 vaccine Tweets\nwhen they were spoken back by a third-party Amazon Alexa skill. We mimicked the\nsoft moderation that Twitter applies to COVID-19 misinformation content in both\nforms of warning covers and warning tags to investigate whether the third-party\nskill could affect how and when users heed these warnings. The results from a\n304-participant study suggest that the spoken back warning covers may not work\nas intended, even when converted from text to speech. We controlled for\nCOVID-19 vaccination hesitancy and political leanings and found that the\nvaccination hesitant Alexa users ignored any type of warning as long as the\nTweets align with their personal beliefs. The politically independent users\ntrusted Alexa less then their politically-laden counterparts and that helped\nthem accurately perceiving truthful COVID-19 information. We discuss soft\nmoderation adaptations for voice assistants to achieve the intended effect of\ncurbing COVID-19 misinformation.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 22:37:34 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Gover", "Donald", ""], ["Sharevski", "Filipo", ""]]}, {"id": "2104.04111", "submitter": "Yang Gao", "authors": "Yang Gao, Tyler Vuong, Mahsa Elyasi, Gaurav Bharaj, Rita Singh", "title": "Generalized Spoofing Detection Inspired from Audio Generation Artifacts", "comments": "Camera ready version. Accepted by INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CR eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art methods for audio generation suffer from fingerprint\nartifacts and repeated inconsistencies across temporal and spectral domains.\nSuch artifacts could be well captured by the frequency domain analysis over the\nspectrogram. Thus, we propose a novel use of long-range spectro-temporal\nmodulation feature -- 2D DCT over log-Mel spectrogram for the audio deepfake\ndetection. We show that this feature works better than log-Mel spectrogram,\nCQCC, MFCC, as a suitable candidate to capture such artifacts. We employ\nspectrum augmentation and feature normalization to decrease overfitting and\nbridge the gap between training and test dataset along with this novel feature\nintroduction. We developed a CNN-based baseline that achieved a 0.0849 t-DCF\nand outperformed the previously top single systems reported in the ASVspoof\n2019 challenge. Finally, by combining our baseline with our proposed 2D DCT\nspectro-temporal feature, we decrease the t-DCF score down by 14% to 0.0737,\nmaking it a state-of-the-art system for spoofing detection. Furthermore, we\nevaluate our model using two external datasets, showing the proposed feature's\ngeneralization ability. We also provide analysis and ablation studies for our\nproposed feature and results.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 23:02:56 GMT"}, {"version": "v2", "created": "Sat, 26 Jun 2021 00:14:30 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Gao", "Yang", ""], ["Vuong", "Tyler", ""], ["Elyasi", "Mahsa", ""], ["Bharaj", "Gaurav", ""], ["Singh", "Rita", ""]]}, {"id": "2104.04241", "submitter": "MaungMaung AprilPyone", "authors": "MaungMaung AprilPyone and Hitoshi Kiya", "title": "Piracy-Resistant DNN Watermarking by Block-Wise Image Transformation\n  with Secret Key", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel DNN watermarking method that utilizes a\nlearnable image transformation method with a secret key. The proposed method\nembeds a watermark pattern in a model by using learnable transformed images and\nallows us to remotely verify the ownership of the model. As a result, it is\npiracy-resistant, so the original watermark cannot be overwritten by a pirated\nwatermark, and adding a new watermark decreases the model accuracy unlike most\nof the existing DNN watermarking methods. In addition, it does not require a\nspecial pre-defined training set or trigger set. We empirically evaluated the\nproposed method on the CIFAR-10 dataset. The results show that it was resilient\nagainst fine-tuning and pruning attacks while maintaining a high\nwatermark-detection accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 08:21:53 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["AprilPyone", "MaungMaung", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "2104.04268", "submitter": "Xiquan Guan", "authors": "Xiquan Guan, Huamin Feng, Weiming Zhang, Hang Zhou, Jie Zhang, and\n  Nenghai Yu", "title": "Reversible Watermarking in Deep Convolutional Neural Networks for\n  Integrity Authentication", "comments": "Accepted to ACM MM 2020", "journal-ref": null, "doi": "10.1145/3394171.3413729", "report-no": null, "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks have made outstanding contributions in\nmany fields such as computer vision in the past few years and many researchers\npublished well-trained network for downloading. But recent studies have shown\nserious concerns about integrity due to model-reuse attacks and backdoor\nattacks. In order to protect these open-source networks, many algorithms have\nbeen proposed such as watermarking. However, these existing algorithms modify\nthe contents of the network permanently and are not suitable for integrity\nauthentication. In this paper, we propose a reversible watermarking algorithm\nfor integrity authentication. Specifically, we present the reversible\nwatermarking problem of deep convolutional neural networks and utilize the\npruning theory of model compression technology to construct a host sequence\nused for embedding watermarking information by histogram shift. As shown in the\nexperiments, the influence of embedding reversible watermarking on the\nclassification performance is less than 0.5% and the parameters of the model\ncan be fully recovered after extracting the watermarking. At the same time, the\nintegrity of the model can be verified by applying the reversible watermarking:\nif the model is modified illegally, the authentication information generated by\noriginal model will be absolutely different from the extracted watermarking\ninformation.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 09:32:21 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Guan", "Xiquan", ""], ["Feng", "Huamin", ""], ["Zhang", "Weiming", ""], ["Zhou", "Hang", ""], ["Zhang", "Jie", ""], ["Yu", "Nenghai", ""]]}, {"id": "2104.04293", "submitter": "Iosif Salem", "authors": "Krzysztof Pietrzak (1), Iosif Salem (2), Stefan Schmid (2), Michelle\n  Yeo (1) ((1) IST Austria, (2) Faculty of Computer Science, University of\n  Vienna)", "title": "LightPIR: Privacy-Preserving Route Discovery for Payment Channel\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Payment channel networks are a promising approach to improve the scalability\nof cryptocurrencies: they allow to perform transactions in a peer-to-peer\nfashion, along multi-hop routes in the network, without requiring consensus on\nthe blockchain. However, during the discovery of cost-efficient routes for the\ntransaction, critical information may be revealed about the transacting\nentities.\n  This paper initiates the study of privacy-preserving route discovery\nmechanisms for payment channel networks. In particular, we present LightPIR, an\napproach which allows a source to efficiently discover a shortest path to its\ndestination without revealing any information about the endpoints of the\ntransaction. The two main observations which allow for an efficient solution in\nLightPIR are that: (1) surprisingly, hub labelling algorithms - which were\ndeveloped to preprocess \"street network like\" graphs so one can later\nefficiently compute shortest paths - also work well for the graphs underlying\npayment channel networks, and that (2) hub labelling algorithms can be directly\ncombined with private information retrieval.\n  LightPIR relies on a simple hub labeling heuristic on top of existing hub\nlabeling algorithms which leverages the specific topological features of\ncryptocurrency networks to further minimize storage and bandwidth overheads. In\na case study considering the Lightning network, we show that our approach is an\norder of magnitude more efficient compared to a privacy-preserving baseline\nbased on using private information retrieval on a database that stores all\npairs shortest paths.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 10:41:23 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Pietrzak", "Krzysztof", ""], ["Salem", "Iosif", ""], ["Schmid", "Stefan", ""], ["Yeo", "Michelle", ""]]}, {"id": "2104.04334", "submitter": "Samuel Pagliarini", "authors": "Felipe Almeida, Levent Aksoy, Jaan Raik, Samuel Pagliarini", "title": "Side-Channel Attacks on Triple Modular Redundancy Schemes", "comments": "4-pager", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interplay between security and reliability is poorly understood. This\npaper shows how triple modular redundancy affects a side-channel attack (SCA).\nOur counterintuitive findings show that modular redundancy can increase SCA\nresiliency.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 12:39:00 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 06:10:47 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Almeida", "Felipe", ""], ["Aksoy", "Levent", ""], ["Raik", "Jaan", ""], ["Pagliarini", "Samuel", ""]]}, {"id": "2104.04478", "submitter": "Alexandria LeClerc", "authors": "Glencora Borradaile, Kelsy Kretschmer, Michele Gretes and Alexandria\n  LeClerc", "title": "The Motivated Can Encrypt (Even with PGP)", "comments": "To be published in: Proceedings of the 21st Privacy Enhancing\n  Technology Symposium (PoPETS), Issue 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing end-to-end-encrypted (E2EE) email systems, mainly PGP, have long\nbeen evaluated in controlled lab settings. While these studies have exposed\nusability obstacles for the average user and offer design improvements, there\nexist users with an immediate need for private communication, who must cope\nwith existing software and its limitations. We seek to understand whether\nindividuals motivated by concrete privacy threats, such as those vulnerable to\nstate surveillance, can overcome usability issues to adopt complex E2EE tools\nfor long-term use. We surveyed regional activists, as surveillance of social\nmovements is well-documented. Our study group includes individuals from 9\nsocial movement groups in the US who had elected to participate in a workshop\non using Thunderbird+Enigmail for email encryption. These workshops tool place\nprior to mid-2017, via a partnership with a non-profit which supports social\nmovement groups. Six to 40 months after their PGP email encryption training,\nmore than half of the study participants were continuing to use PGP email\nencryption despite intervening widespread deployment of simple E2EE messaging\napps such as Signal. We study the interplay of usability with social factors\nsuch as motivation and the risks that individuals undertake through their\nactivism. We find that while usability is an important factor, it is not enough\nto explain long term use. For example, we find that riskiness of one's activism\nis negatively correlated with long-term PGP use. This study represents the\nfirst long-term study, and the first in-the-wild study, of PGP email encryption\nadoption.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 16:53:02 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Borradaile", "Glencora", ""], ["Kretschmer", "Kelsy", ""], ["Gretes", "Michele", ""], ["LeClerc", "Alexandria", ""]]}, {"id": "2104.04528", "submitter": "Jiyang Chen", "authors": "Jiyang Chen, Tomasz Kloda, Ayoosh Bansal, Rohan Tabish, Chien-Ying\n  Chen, Bo Liu, Sibin Mohan, Marco Caccamo and Lui Sha", "title": "SchedGuard: Protecting against Schedule Leaks Using Linux Containers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time systems have recently been shown to be vulnerable to timing\ninference attacks, mainly due to their predictable behavioral patterns.\nExisting solutions such as schedule randomization lack the ability to protect\nagainst such attacks, often limited by the system's real-time nature. This\npaper presents SchedGuard: a temporal protection framework for Linux-based hard\nreal-time systems that protects against posterior scheduler side-channel\nattacks by preventing untrusted tasks from executing during specific time\nsegments. SchedGuard is integrated into the Linux kernel using cgroups, making\nit amenable to use with container frameworks. We demonstrate the effectiveness\nof our system using a realistic radio-controlled rover platform and\nsynthetically generated workloads. Not only is SchedGuard able to protect\nagainst the attacks mentioned above, but it also ensures that the real-time\ntasks/containers meet their temporal requirements.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 13:16:06 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Chen", "Jiyang", ""], ["Kloda", "Tomasz", ""], ["Bansal", "Ayoosh", ""], ["Tabish", "Rohan", ""], ["Chen", "Chien-Ying", ""], ["Liu", "Bo", ""], ["Mohan", "Sibin", ""], ["Caccamo", "Marco", ""], ["Sha", "Lui", ""]]}, {"id": "2104.04553", "submitter": "Mustafizur Rahman", "authors": "Mustafizur Rahman, Liang Zhou, and Shantanu Chakrabartty (Senior\n  Member, IEEE)", "title": "Secret Key Distribution Protocols Based on Self-Powered Timekeeping\n  Devices", "comments": "11 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present novel secret key distribution protocols using\nlow-cost, hardware chipsets containing millions of synchronized self-powered\ntimers. The secret keys are derived based on the timers' physical dynamic\nresponses which provide security against any potential side-channel attacks,\nmalicious tampering, or snooping. Using the behavioral model of the\nself-powered timers, we first show that the key-strings derived from the timers\ncan pass the randomness test as defined by the National Institute of Standards\nand Technology (NIST) suite. The key-strings are then used in two key exchange\nprotocols which exploit elapsed time as one-way functions. The protocols\nproposed in this paper facilitate secure communication between (a) a user and a\nremote Server; and (b) two users. Using Monte-Carlo simulations, we investigate\nthe scalability and the security of these protocols against different\nadversarial attacks. We also investigate the robustness of these protocols in\nthe presence of real-world operating conditions and we investigate the use of\nerror-correcting codes to mitigate noise-related artifacts.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 18:31:41 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Rahman", "Mustafizur", "", "Senior\n  Member, IEEE"], ["Zhou", "Liang", "", "Senior\n  Member, IEEE"], ["Chakrabartty", "Shantanu", "", "Senior\n  Member, IEEE"]]}, {"id": "2104.04572", "submitter": "Le Xia", "authors": "Le Xia, Yao Sun, Rafiq Swash, Lina Mohjazi, Lei Zhang, and Muhammad\n  Ali Imran", "title": "Smart and Secure CAV Networks Empowered by AI-Enabled Blockchain: Next\n  Frontier for Intelligent Safe-Driving Assessment", "comments": "8 pages, 6 figures, this paper has been submitted to IEEE Network\n  Magazine and is still awaiting the review results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Securing safe-driving for connected and autonomous vehicles (CAVs) continues\nto be a widespread concern despite various sophisticated functions delivered by\nartificial intelligence for in-vehicle devices. Besides, diverse malicious\nnetwork attacks become ubiquitous along with the worldwide implementation of\nthe Internet of Vehicles, which exposes a range of reliability and privacy\nthreats for managing data in CAV networks. Combined with the fact that the\ncapability of existing CAVs in handling intensive computation tasks is limited,\nthis implies a need for designing an efficient assessment system to guarantee\nautonomous driving safety without compromising data security. Motivated by\nthis, in this article, we propose a novel framework, namely Blockchain-enabled\nintElligent Safe-driving assessmenT (BEST), that offers a smart and reliable\napproach for conducting safe driving supervision while protecting vehicular\ninformation. Specifically, a promising solution that exploits a long short-term\nmemory model is introduced to assess the safety level of the moving CAVs. Then,\nwe investigate how a distributed blockchain obtains adequate trustworthiness\nand robustness for CAV data by adopting a byzantine fault tolerance-based\ndelegated proof-of-stake consensus mechanism. Simulation results demonstrate\nthat our presented BEST gains better data credibility with a higher prediction\naccuracy for vehicular safety assessment when compared with existing schemes.\nFinally, we discuss several open challenges that need to be addressed in future\nCAV networks.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 19:08:34 GMT"}, {"version": "v2", "created": "Sun, 4 Jul 2021 11:03:20 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Xia", "Le", ""], ["Sun", "Yao", ""], ["Swash", "Rafiq", ""], ["Mohjazi", "Lina", ""], ["Zhang", "Lei", ""], ["Imran", "Muhammad Ali", ""]]}, {"id": "2104.04637", "submitter": "Abdelhaliem Babiker", "authors": "Abdelhaliem Babiker", "title": "A Novel Provably Secure Key Agreement Protocol Based On Binary Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, a new key agreement protocol is presented. The protocol uses\nexponentiation of matrices over GF(2) to establish the key agreement. Security\nanalysis of the protocol shows that the shared secret key is indistinguishable\nfrom the random under Decisional Diffie-Hellman (DDH) assumption for subgroup\nof matrices over GF(2) with prime order, and furthermore, the analysis shows\nthat, unlike many other exponentiation based protocols, security of the\nprotocol goes beyond the level of security provided by (DDH) assumption and\nintractability of Discrete Logarithm Problem (DLP). Actually, security of the\nprotocol completely transcends the reliance on the DLP in the sense that\nbreaking the DLP does not mean breaking the protocol. Complexity of brute force\nattack on the protocol is equivalent to exhaustive search for the secret key.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 23:15:23 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 17:35:07 GMT"}, {"version": "v3", "created": "Wed, 2 Jun 2021 13:33:47 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Babiker", "Abdelhaliem", ""]]}, {"id": "2104.04671", "submitter": "Changchun Zou", "authors": "Edward L. Amoruso and Stephen P. Johnson and Raghu Avula and Cliff C.\n  Zou", "title": "A Web Infrastructure for Certifying Multimedia News Content for Fake\n  News Defense", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In dealing with altered visual multimedia content, also referred to as fake\nnews, we present a ready-to-deploy extension of the current public key\ninfrastructure (PKI), to provide an endorsement and integrity check platform\nfor newsworthy visual multimedia content. PKI, which is primarily used for Web\ndomain authentication, can directly be utilized with any visual multimedia\nfile. Unlike many other fake news researches that focus on technical multimedia\ndata processing and verification, we enable various news organizations to use\nour developed program to certify/endorse a multimedia news content when they\nbelieve this news piece is truthiness and newsworthy. Our program digitally\nsigns the multimedia news content with the news organization's private key, and\nthe endorsed news content can be posted not only by the endorser, but also by\nany other websites. By installing a web browser extension developed by us, an\nend user can easily verify whether a multimedia news content has been endorsed\nand by which organization. During verification, our browser extension will\npresent to the end user a floating logo next to the image or video. This logo,\nin the shape of a shield, will show whether the image has been endorsed, by\nwhich news organization, and a few more pieces of essential text information of\nthe news multimedia content. The proposed system can be easily integrated to\nother closed-web system such as social media networks and easily applied to\nother non-visual multimedia files.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 03:05:34 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Amoruso", "Edward L.", ""], ["Johnson", "Stephen P.", ""], ["Avula", "Raghu", ""], ["Zou", "Cliff C.", ""]]}, {"id": "2104.04683", "submitter": "Md Imran Hossen", "authors": "Md Imran Hossen and Xiali Hei", "title": "A Low-Cost Attack against the hCaptcha System", "comments": "To appear in the 15th IEEE Workshop on Offensive Technologies (WOOT\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  CAPTCHAs are a defense mechanism to prevent malicious bot programs from\nabusing websites on the Internet. hCaptcha is a relatively new but emerging\nimage CAPTCHA service. This paper presents an automated system that can break\nhCaptcha challenges with a high success rate. We evaluate our system against\n270 hCaptcha challenges from live websites and demonstrate that it can solve\nthem with 95.93% accuracy while taking only 18.76 seconds on average to crack a\nchallenge. We run our attack from a docker instance with only 2GB memory (RAM),\n3 CPUs, and no GPU devices, demonstrating that it requires minimal resources to\nlaunch a successful large-scale attack against the hCaptcha system.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 05:15:15 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Hossen", "Md Imran", ""], ["Hei", "Xiali", ""]]}, {"id": "2104.04709", "submitter": "Zhengqiang Ge", "authors": "Zhengqiang Ge, Zhipeng Zhou, Dong Guo, Qiang Li", "title": "Practical Two-party Privacy-preserving Neural Network Based on Secret\n  Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks, with the capability to provide efficient predictive models,\nhave been widely used in medical, financial, and other fields, bringing great\nconvenience to our lives. However, the high accuracy of the model requires a\nlarge amount of data from multiple parties, raising public concerns about\nprivacy. Privacy-preserving neural network based on multi-party computation is\none of the current methods used to provide model training and inference under\nthe premise of solving data privacy. In this study, we propose a new two-party\nprivacy-preserving neural network training and inference framework in which\nprivacy data is distributed to two non-colluding servers. We construct a\npreprocessing protocol for mask generation, support and realize secret sharing\ncomparison on 2PC, and propose a new method to further reduce the communication\nrounds. Based on the comparison protocol, we construct building blocks such as\ndivision and exponential, and realize the process of training and inference\nthat no longer needs to convert between different types of secret sharings and\nis entirely based on arithmetic secret sharing. Compared with the previous\nworks, our work obtains higher accuracy, which is very close to that of\nplaintext training. While the accuracy has been improved, the runtime is\nreduced, considering the online phase, our work is 5x faster than SecureML,\n4.32-5.75x faster than SecureNN, and is very close to the current optimal 3PC\nimplementation, FALCON. For secure inference, as far as known knowledge is\nconcerned, we should be the current optimal 2PC implementation, which is 4-358x\nfaster than other works.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 08:28:08 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Ge", "Zhengqiang", ""], ["Zhou", "Zhipeng", ""], ["Guo", "Dong", ""], ["Li", "Qiang", ""]]}, {"id": "2104.04742", "submitter": "L\\'eo Colisson", "authors": "L\\'eo Colisson and Fr\\'ed\\'eric Grosshans and Elham Kashefi", "title": "Non-Destructive Zero-Knowledge Proofs on Quantum States, and Multi-Party\n  Generation of Authorized Hidden GHZ States", "comments": "50 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the special no-cloning principle, quantum states appear to be very\nuseful in cryptography. But this very same property also has drawbacks: when\nreceiving a quantum state, it is nearly impossible for the receiver to\nefficiently check non-trivial properties on that state without destroying it.\n  In this work, we initiate the study of Non-Destructive Zero-Knowledge Proofs\non Quantum States. Our method binds a quantum state to a classical encryption\nof that quantum state. That way, the receiver can obtain guarantees on the\nquantum state by asking to the sender to prove properties directly on the\nclassical encryption. This method is therefore non-destructive, and it is\npossible to verify a very large class of properties. For instance, we can force\nthe sender to send different categories of states depending on whether they\nknow a classical password or not. Moreover, we can also provide guarantees to\nthe sender: for example, we can ensure that the receiver will never learn\nwhether the sender knows the password or not.\n  We also extend this method to the multi-party setting. We show how it can\nprove useful to distribute a GHZ state between different parties, in such a way\nthat only parties knowing a secret can be part of this GHZ. Moreover, the\nidentity of the parties that are part of the GHZ remains hidden to any\nmalicious party. A direct application would be to allow a server to create a\nsecret sharing of a qubit between unknown parties, authorized for example by a\nthird party Certification Authority.\n  Finally, we provide simpler \"blind\" versions of the protocols that could\nprove useful in Anonymous Transmission or Quantum Onion Routing, and we\nexplicit a cryptographic function required in our protocols based on the\nLearning With Errors hardness problem.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 11:34:40 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 07:17:27 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Colisson", "L\u00e9o", ""], ["Grosshans", "Fr\u00e9d\u00e9ric", ""], ["Kashefi", "Elham", ""]]}, {"id": "2104.04798", "submitter": "Kaleem Nawaz Khan Mr.", "authors": "Kaleem Nawaz Khan, Muhammad Salman Khan, Mohammad Nauman and Muhammad\n  Yaseen Khan", "title": "Op2Vec: An Opcode Embedding Technique and Dataset Design for End-to-End\n  Detection of Android Malware", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android is one of the leading operating systems for smart phones in terms of\nmarket share and usage. Unfortunately, it is also an appealing target for\nattackers to compromise its security through malicious applications. To tackle\nthis issue, domain experts and researchers are trying different techniques to\nstop such attacks. All the attempts of securing Android platform are somewhat\nsuccessful. However, existing detection techniques have severe shortcomings,\nincluding the cumbersome process of feature engineering. Designing\nrepresentative features require expert domain knowledge. There is a need for\nminimizing human experts' intervention by circumventing handcrafted feature\nengineering. Deep learning could be exploited by extracting deep features\nautomatically. Previous work has shown that operational codes (opcodes) of\nexecutables provide key information to be used with deep learning models for\ndetection process of malicious applications. The only challenge is to feed\nopcodes information to deep learning models. Existing techniques use one-hot\nencoding to tackle the challenge. However, the one-hot encoding scheme has\nsevere limitations. In this paper, we introduce; (1) a novel technique for\nopcodes embedding, which we name Op2Vec, (2) based on the learned Op2Vec we\nhave developed a dataset for end-to-end detection of android malware.\nIntroducing the end-to-end Android malware detection technique avoids\nexpert-intensive handcrafted features extraction, and ensures automation. The\ncomparison shows that Op2Vec outperforms the existing one-hot encoding\ntechnique for opcode embedding and the developed dataset can provide\nsignificant insights for end-to-end detection of Android malware.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 15:56:37 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Khan", "Kaleem Nawaz", ""], ["Khan", "Muhammad Salman", ""], ["Nauman", "Mohammad", ""], ["Khan", "Muhammad Yaseen", ""]]}, {"id": "2104.04958", "submitter": "Mario Di Mauro", "authors": "Mario Di Mauro, Giovanni Galatro, Giancarlo Fortino, Antonio Liotta", "title": "Supervised Feature Selection Techniques in Network Intrusion Detection:\n  a Critical Review", "comments": null, "journal-ref": "Engineering Applications of Artificial Intelligence Volume 101,\n  May 2021, 104216", "doi": "10.1016/j.engappai.2021.104216", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) techniques are becoming an invaluable support for\nnetwork intrusion detection, especially in revealing anomalous flows, which\noften hide cyber-threats. Typically, ML algorithms are exploited to\nclassify/recognize data traffic on the basis of statistical features such as\ninter-arrival times, packets length distribution, mean number of flows, etc.\nDealing with the vast diversity and number of features that typically\ncharacterize data traffic is a hard problem. This results in the following\nissues: i) the presence of so many features leads to lengthy training processes\n(particularly when features are highly correlated), while prediction accuracy\ndoes not proportionally improve; ii) some of the features may introduce bias\nduring the classification process, particularly those that have scarce relation\nwith the data traffic to be classified. To this end, by reducing the feature\nspace and retaining only the most significant features, Feature Selection (FS)\nbecomes a crucial pre-processing step in network management and, specifically,\nfor the purposes of network intrusion detection. In this review paper, we\ncomplement other surveys in multiple ways: i) evaluating more recent datasets\n(updated w.r.t. obsolete KDD 99) by means of a designed-from-scratch\nPython-based procedure; ii) providing a synopsis of most credited FS approaches\nin the field of intrusion detection, including Multi-Objective Evolutionary\ntechniques; iii) assessing various experimental analyses such as feature\ncorrelation, time complexity, and performance. Our comparisons offer useful\nguidelines to network/security managers who are considering the incorporation\nof ML concepts into network intrusion detection, where trade-offs between\nperformance and resource consumption are crucial.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 08:42:01 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Di Mauro", "Mario", ""], ["Galatro", "Giovanni", ""], ["Fortino", "Giancarlo", ""], ["Liotta", "Antonio", ""]]}, {"id": "2104.05023", "submitter": "Shiva Sattarpoor", "authors": "Shiva Sattarpoor, Hamid Barati", "title": "Robust Image Watermarking in Wavelet Domain using GBT-DWT-SVD and Whale\n  Optimization Algorithm", "comments": "no comments", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As digital content can be copied easily, Copyright infringement has become a\nconcern nowadays. Providing a solution to prevent the abuse of such contents is\nvery necessary. One of the most common methods to solve this problem is\nwatermarking. In this method, a logo belongs to the owner of the media is\nembedded in the media. So, they can prove the originality or ownership of the\nmedia content. Images are one of the most important digital media. Therefore,\nin this study, a method for digital image watermarking is proposed. The\nproposed method is based on Graph-based Transform (GBT), Singular Value\nDecomposition (SVD), and Discrete Wavelet Transform (DWT) which uses a Whale\nOptimization Algorithm (WOA) to find the best value for the embedding\ncoefficient in the images as well as optimal blocks. The image is first\ntransformed to a transform domain using the DWT and GBT, and then the watermark\nlogo embedded onto the singular values of the cover image. The objective\nfunction defined for this task is based on the three parameters PSNR and NC, in\nthe presence of image attacks. The results of the proposed algorithm on some\nknown images show a high performance of this method compared to other similar\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 15:05:21 GMT"}, {"version": "v2", "created": "Sat, 1 May 2021 10:03:45 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Sattarpoor", "Shiva", ""], ["Barati", "Hamid", ""]]}, {"id": "2104.05026", "submitter": "Anna Melman", "authors": "Yaroslav Meshcheryakov, Anna Melman, Oleg Evsutin, Vladimir Morozov,\n  Yevgeni Koucheryavy", "title": "On performance of PBFT for IoT-applications with constrained devices", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical systems and the Internet of things (IoT) is becoming an\nintegral part of the digital society. The use of IoT services improves human\nlife in many ways. Protection against cyber threats is an important aspect of\nthe functioning of IoT devices. Malicious activities lead to confidential data\nleakages and incorrect performance of devices are becoming critical. Therefore,\ndevelopment of effective solutions that can protect both IoT devices data and\ndata exchange networks turns in to a real challenge. This study provides a\ncritical analysis of the feasibility of using blockchain technology to protect\nconstrained IoT devices data, justifies the choice of Practical Byzantine Fault\nTolerance (PBFT) consensus algorithm for implementation on such devices, and\nsimulates the main distributed ledger scenarios using PBFT. The simulation\nresults demonstrate the efficiency of the blockchain technology for constrained\ndevices and make it possible to evaluate the applicability limits of the chosen\nconsensus algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 15:20:12 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 09:39:23 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Meshcheryakov", "Yaroslav", ""], ["Melman", "Anna", ""], ["Evsutin", "Oleg", ""], ["Morozov", "Vladimir", ""], ["Koucheryavy", "Yevgeni", ""]]}, {"id": "2104.05070", "submitter": "Dajiang Suo", "authors": "Dajiang Suo, Jinhua Zhao, Sanjay E. Sarma", "title": "Proof of Travel for Trust-Based Data Validation in V2I Communication\n  Part I: Methodology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work on misbehavior detection and trust management for\nVehicle-to-Everything (V2X) communication can identify falsified and malicious\nmessages, enabling witness vehicles to report observations about\nhigh-criticality traffic events. However, there may not exist enough \"benign\"\nvehicles with V2X connectivity or vehicle owners who are willing to opt-in in\nthe early stages of connected-vehicle deployment. In this paper, we propose a\nsecurity protocol for the communication between vehicles and infrastructure,\ntitled Proof-of-Travel (POT), to answer the research question: How can we\ntransform the power of cryptography techniques embedded within the protocol\ninto social and economic mechanisms to simultaneously incentivize\nVehicle-to-Infrastructure (V2I) data sharing activities and validate the data?\n  The key idea is to determine the reputation of and the contribution made by a\nvehicle based on its distance traveled and the information it shared through\nV2I channels. In particular, the total vehicle miles traveled for a vehicle\nmust be testified by digital signatures signed by each infrastructure component\nalong the path of its movement. While building a chain of proofs of spatial\nmovement creates burdens for malicious vehicles, acquiring proofs does not\nresult in extra cost for normal vehicles, which naturally want to move from the\norigin to the destination. The proof of travel for a vehicle can then be used\nto determine the contribution and reward by its altruistic behaviors. We\npropose short-term and long-term incentive designs based on the POT protocol\nand evaluate their security and performance through theoretical analysis and\nsimulations.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 18:25:56 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Suo", "Dajiang", ""], ["Zhao", "Jinhua", ""], ["Sarma", "Sanjay E.", ""]]}, {"id": "2104.05183", "submitter": "Amin Azmoodeh", "authors": "Ali Dehghantanha, Hadis Karimipour, Amin Azmoodeh", "title": "Cybersecurity in Smart Farming: Canada Market Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Cyber Science Lab (CSL) and Smart Cyber-Physical System (SCPS) Lab at the\nUniversity of Guelph conduct a market study of cybersecurity technology\nadoption and requirements for smart and precision farming in Canada. We\nconducted 17 stakeholder/key opinion leader interviews in Canada and the USA,\nas well as conducting extensive secondary research, to complete this study.\nEach interview generally required 15-20 minutes to complete. Interviews were\nconducted using a client-approved interview guide. Secondary and primary\nresearch focussed on the following areas of investigation: Market size and\nsegmentation Market forecast and growth rate Competitive landscape Market\nchallenges/barriers to entry Market trends/growth drivers\nAdoption/commercialization of the technology\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 03:33:45 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Dehghantanha", "Ali", ""], ["Karimipour", "Hadis", ""], ["Azmoodeh", "Amin", ""]]}, {"id": "2104.05185", "submitter": "Pengcheng Xia", "authors": "Pengcheng Xia, Haoyu Wang, Zhou Yu, Xinyu Liu, Xiapu Luo, Guoai Xu", "title": "Ethereum Name Service: the Good, the Bad, and the Ugly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DNS has always been criticized for its inherent design flaws, making the\nsystem vulnerable to kinds of attacks. Besides, DNS domain names are not fully\ncontrolled by the users, which can be easily taken down by the authorities and\nregistrars. Since blockchain has its unique properties like immutability and\ndecentralization, it seems to be promising to build a decentralized name\nservice on blockchain. Ethereum Name Service (ENS), as a novel name service\nbuilt atop Etheruem, has received great attention from the community. Yet, no\nexisting work has systematically studied this emerging system, especially the\nsecurity issues and misbehaviors in ENS. To fill the void, we present the first\nlarge-scale study of ENS by collecting and analyzing millions of event logs\nrelated to ENS. We characterize the ENS system from a number of perspectives.\nOur findings suggest that ENS is showing gradually popularity during its four\nyears' evolution, mainly due to its distributed and open nature that ENS domain\nnames can be set to any kinds of records, even censored and malicious contents.\nWe have identified several security issues and misbehaviors including\ntraditional DNS security issues and new issues introduced by ENS smart\ncontracts. Attackers are abusing the system with thousands of squatting ENS\nnames, a number of scam blockchain addresses and malicious websites, etc. Our\nexploration suggests that our community should invest more effort into the\ndetection and mitigation of issues in Blockchain-based Name Services towards\nbuilding an open and trustworthy name service.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 03:39:01 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Xia", "Pengcheng", ""], ["Wang", "Haoyu", ""], ["Yu", "Zhou", ""], ["Liu", "Xinyu", ""], ["Luo", "Xiapu", ""], ["Xu", "Guoai", ""]]}, {"id": "2104.05293", "submitter": "Mark Vella", "authors": "Simon Joseph Aquilina, Fran Casino, Mark Vella, Joshua Ellul,\n  Constantinos Patsakis", "title": "EtherClue: Digital investigation of attacks on Ethereum smart contracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming errors in Ethereum smart contracts can result in catastrophic\nfinancial losses from stolen cryptocurrency. While vulnerability detectors can\nprevent vulnerable contracts from being deployed, this does not mean that such\ncontracts will not be deployed. Once a vulnerable contract is instantiated on\nthe blockchain and becomes the target of attacks, the identification of exploit\ntransactions becomes indispensable in assessing whether it has been actually\nexploited and identifying which malicious or subverted accounts were involved.\n  In this work, we study the problem of post-factum investigation of Ethereum\nattacks using Indicators of Compromise (IoCs) specially crafted for use in the\nblockchain. IoC definitions need to capture the side-effects of successful\nexploitation in the context of the Ethereum blockchain. Therefore, we define a\nmodel for smart contract execution, comprising multiple abstraction levels that\nmirror the multiple views of code execution on a blockchain. Subsequently, we\ncompare IoCs defined across the different levels in terms of their\neffectiveness and practicality through EtherClue, a prototype tool for\ninvestigating Ethereum security incidents. Our results illustrate that\ncoarse-grained IoCs defined over blocks of transactions can detect exploit\ntransactions with less computation; however, they are contract-specific and\nsuffer from false negatives. On the other hand, fine-grained IoCs defined over\nvirtual machine instructions can avoid these pitfalls at the expense of\nincreased computation which are nevertheless applicable for practical use.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 08:55:33 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Aquilina", "Simon Joseph", ""], ["Casino", "Fran", ""], ["Vella", "Mark", ""], ["Ellul", "Joshua", ""], ["Patsakis", "Constantinos", ""]]}, {"id": "2104.05324", "submitter": "Saeid Ghasemshirazi", "authors": "Saeid Ghasemshirazi, Pouya Heydarabadi", "title": "Exploring the Attack Surface of WebSocket", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the years, with the advancement of technology, Web technology has many\nimprovements. In the early days, the web was one-way communication, and only\nthe customer was able to see the content of the site and could not enter\ninformation. However, day by day, the web made significant progress, and\ntechnologies such as HTTP, ajax, WebSocket introduced that make pages dynamic\nand Give us both sides. In short, it is a new type of communications protocol,\nwhich was faster and more efficient than previous communication protocols.\nAfter the web socket's unveiling, like any other technology, Its security has\nbeen discussed, and technology's security has always been a challenge for us.\nTherefore, in this article, we examine the structure and security problems that\ncan occur in a web socket to choose an excellent alternative to HTTP and use\nit.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 10:08:20 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Ghasemshirazi", "Saeid", ""], ["Heydarabadi", "Pouya", ""]]}, {"id": "2104.05325", "submitter": "Mikko Impi\\\"o", "authors": "Mikko Impi\\\"o, Mehmet Yama\\c{c}, Jenni Raitoharju", "title": "Multi-level reversible encryption for ECG signals using compressive\n  sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy concerns in healthcare have gained interest recently via GDPR, with a\nrising need for privacy-preserving data collection methods that keep personal\ninformation hidden in otherwise usable data. Sometimes data needs to be\nencrypted for several authentication levels, where a semi-authorized user gains\naccess to data stripped of personal or sensitive information, while a\nfully-authorized user can recover the full signal. In this paper, we propose a\ncompressive sensing based multi-level encryption to ECG signals to mask\npossible heartbeat anomalies from semi-authorized users, while preserving the\nbeat structure for heart rate monitoring. Masking is performed both in time and\nfrequency domains. Masking effectiveness is validated using 1D convolutional\nneural networks for heartbeat anomaly classification, while masked signal\nusefulness is validated comparing heartbeat detection accuracy between masked\nand recovered signals. The proposed multi-level encryption method can decrease\nclassification accuracy of heartbeat anomalies by up to 50%, while maintaining\na fairly high R-peak detection accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 10:10:43 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Impi\u00f6", "Mikko", ""], ["Yama\u00e7", "Mehmet", ""], ["Raitoharju", "Jenni", ""]]}, {"id": "2104.05375", "submitter": "Peter Mell", "authors": "Carlos Cardoso Galhardo, Peter Mell, Irena Bojanova, Assane Gueye", "title": "Measurements of the Most Significant Software Security Weaknesses", "comments": "12 pages", "journal-ref": null, "doi": "10.1145/3427228.3427257", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we provide a metric to calculate the most significant software\nsecurity weaknesses as defined by an aggregate metric of the frequency,\nexploitability, and impact of related vulnerabilities. The Common Weakness\nEnumeration (CWE) is a well-known and used list of software security\nweaknesses. The CWE community publishes such an aggregate metric to calculate\nthe `Most Dangerous Software Errors'. However, we find that the published\nequation highly biases frequency and almost ignores exploitability and impact\nin generating top lists of varying sizes. This is due to the differences in the\ndistributions of the component metric values. To mitigate this, we linearize\nthe frequency distribution using a double log function. We then propose a\nvariety of other improvements, provide top lists of the most significant CWEs\nfor 2019, provide an analysis of the identified software security weaknesses,\nand compare them against previously published top lists.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 11:51:50 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Galhardo", "Carlos Cardoso", ""], ["Mell", "Peter", ""], ["Bojanova", "Irena", ""], ["Gueye", "Assane", ""]]}, {"id": "2104.05428", "submitter": "Maha Filali Rotbi Miss", "authors": "Maha Filali Rotbi and Saad Motahhir and Abdelaziz El Ghzizal", "title": "Blockchain technology for a Safe and Transparent Covid-19 Vaccination", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In late 2019, we witnessed the apparition of the covid-19 virus. The virus\nappeared first in Wuhan, and due to people travel was spread worldwide.\nExponential spread as well as high mortality rates, the two characteristics of\nthe SARS-CoV-2 virus that pushed the entire world into a global lock-down.\nHealth and economic crisis, along with social distancing have put the globe in\na highly challenging situation. Unprecedented pressure on the health care\nsystem exposed many loopholes not only in this industry but many other sectors,\nwhich resulted in a set of new challenges that researchers and scientists among\nothers must face. In all these circumstances, we could attend, in a\nsurprisingly short amount of time, the creation of multiple vaccine candidates.\nThe vaccines were clinically tested and approved, which brought us to the phase\nof vaccination. Safety, security, transparency, and traceability are highly\nrequired in this context. As a contribution to assure an efficient vaccination\ncampaign, in this paper we suggest a Blockchain-based system to manage the\nregistration, storage, and distribution of the vaccines.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 09:55:44 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Rotbi", "Maha Filali", ""], ["Motahhir", "Saad", ""], ["Ghzizal", "Abdelaziz El", ""]]}, {"id": "2104.05516", "submitter": "Vitor Pereira", "authors": "Jos\\'e Carlos Bacelar Almeida (1), Manuel Barbosa (1), Karim Eldefrawy\n  (2), St\\'ephane Graham-Lengrand (2), Hugo Pacheco (1) and Vitor Pereira (1,2)\n  ((1) University of Porto (FCUP) and INESC TEC, (2) SRI International)", "title": "Machine-checked ZKP for NP-relations: Formally Verified Security Proofs\n  and Implementations of MPC-in-the-Head", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  MPC-in-the-Head (MitH) is a general framework that allows constructing\nefficient Zero Knowledge protocols for general NP-relations from secure\nmultiparty computation (MPC) protocols. In this paper we give the first\nmachine-checked implementation of this transformation. We begin with an\nEasyCrypt formalization of MitH that preserves the modular structure of MitH\nand can be instantiated with arbitrary MPC protocols that satisfy standard\nnotions of security, which allows us to leverage an existing machine-checked\nsecret-sharing-based MPC protocol development. The resulting concrete ZK\nprotocol is proved secure and correct in EasyCrypt. Using a recently developed\ncode extraction mechanism for EasyCrypt we synthesize a formally verified\nimplementation of the protocol, which we benchmark to get an indication of the\noverhead associated with our formalization choices and code extraction\nmechanism.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 14:45:09 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 22:35:45 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 21:47:07 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Almeida", "Jos\u00e9 Carlos Bacelar", "", "University of Porto"], ["Barbosa", "Manuel", "", "University of Porto"], ["Eldefrawy", "Karim", "", "SRI International"], ["Graham-Lengrand", "St\u00e9phane", "", "SRI International"], ["Pacheco", "Hugo", "", "University of Porto"], ["Pereira", "Vitor", "", "University of Porto", "SRI International"]]}, {"id": "2104.05532", "submitter": "Sam Ainsworth", "authors": "Sam Ainsworth", "title": "GhostMinion: A Strictness-Ordered Cache System for Spectre Mitigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Out-of-order speculation, a technique ubiquitous since the early 1990s,\nremains a fundamental security flaw. Via attacks such as Spectre and Meltdown,\nan attacker can trick a victim, in an otherwise entirely correct program, into\nleaking its secrets through the effects of misspeculated execution, in a way\nthat is entirely invisible to the programmer's model. This has serious\nimplications for application sandboxing and inter-process communication.\n  Designing efficient mitigations, that preserve the performance of\nout-of-order execution, has been a challenge. The speculation-hiding techniques\nin the literature have been shown to not close such channels comprehensively,\nallowing adversaries to redesign attacks. Strong, precise guarantees are\nnecessary, but at the same time mitigations must achieve high performance to be\nadopted. We present Strictness Ordering, a new constraint system that shows how\nwe can comprehensively eliminate transient side channel attacks, while still\nallowing complex speculation and data forwarding between speculative\ninstructions. We then present GhostMinion, a cache modification built using a\nvariety of new techniques designed to provide Strictness Order at only 2.5%\noverhead.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 14:57:56 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Ainsworth", "Sam", ""]]}, {"id": "2104.05571", "submitter": "Junwhan Kim", "authors": "Byunggu Yu, Junwhan Kim", "title": "Using a Neural Network to Detect Anomalies given an N-gram Profile", "comments": "17 pages, 7 figures, 5th International Symposium on Cyber Security\n  Cryptology and Machine Learning (CSCML 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to detect unknown intrusions and runtime errors of computer\nprograms, the cyber-security community has developed various detection\ntechniques. Anomaly detection is an approach that is designed to profile the\nnormal runtime behavior of computer programs in order to detect intrusions and\nerrors as anomalous deviations from the observed normal. However, normal but\nunobserved behavior can trigger false positives. This limitation has\nsignificantly decreased the practical viability of anomaly detection\ntechniques. Reported approaches to this limitation span a simple alert\nthreshold definition to distribution models for approximating all normal\nbehavior based on the limited observation. However, each assumption or\napproximation poses the potential for even greater false positive rates. This\npaper presents our study on how to explain the presence of anomalies using a\nneural network, particularly Long Short-Term Memory, independent of actual data\ndistributions. We present and compare three anomaly detection models, and\nreport on our experience running different types of attacks on an Apache\nHypertext Transfer Protocol server. We performed a comparative study, focusing\non each model's ability to detect the onset of each attack while avoiding false\npositives resulting from unknown normal behavior. Our best-performing model\ndetected the true onset of every attack with zero false positives.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 15:40:43 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 23:55:51 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Yu", "Byunggu", ""], ["Kim", "Junwhan", ""]]}, {"id": "2104.05598", "submitter": "Danilo Gligoroski", "authors": "Danilo Gligoroski", "title": "Entropoid Based Cryptography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.RA", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  By analogy with the developed cryptographic theory of discrete logarithm\nproblems, we define several hard problems in Entropoid based cryptography, such\nas Discrete Entropoid Logarithm Problem (DELP), Computational Entropoid\nDiffie-Hellman problem (CEDHP), and Decisional Entropoid Diffie-Hellman Problem\n(DEDHP). We post a conjecture that DEDHP is hard in Sylow $q$-subquasigroups.\nNext, we instantiate an entropoid Diffie-Hellman key exchange protocol. Due to\nthe non-commutativity and non-associativity, the entropoid based cryptographic\nprimitives are supposed to be resistant to quantum algorithms. At the same\ntime, due to the proposed succinct notation for the power indices, the\ncommunication overhead in the entropoid based Diffie-Hellman key exchange is\nvery low: for 128 bits of security, 64 bytes in total are communicated in both\ndirections, and for 256 bits of security, 128 bytes in total are communicated\nin both directions.\n  Our final contribution is in proposing two entropoid based digital signature\nschemes. The schemes are constructed with the Fiat-Shamir transformation of an\nidentification scheme which security relies on a new hardness assumption:\ncomputing roots in finite entropoids is hard. If this assumption withstands the\ntime's test, the first proposed signature scheme has excellent properties: for\nthe classical security levels between 128 and 256 bits, the public and private\nkey sizes are between 32 and 64, and the signature sizes are between 64 and 128\nbytes. The second signature scheme reduces the finding of the roots in finite\nentropoids to computing discrete entropoid logarithms. In our opinion, this is\na safer but more conservative design, and it pays the price in doubling the key\nsizes and the signature sizes.\n  We give a proof-of-concept implementation in SageMath 9.2 for all proposed\nalgorithms and schemes in an appendix.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 16:20:03 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Gligoroski", "Danilo", ""]]}, {"id": "2104.05743", "submitter": "Pavlos Papadopoulos", "authors": "Tom Titcombe, Adam J. Hall, Pavlos Papadopoulos, Daniele Romanini", "title": "Practical Defences Against Model Inversion Attacks for Split Neural\n  Networks", "comments": "ICLR 2021 Workshop on Distributed and Private Machine Learning (DPML\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe a threat model under which a split network-based federated\nlearning system is susceptible to a model inversion attack by a malicious\ncomputational server. We demonstrate that the attack can be successfully\nperformed with limited knowledge of the data distribution by the attacker. We\npropose a simple additive noise method to defend against model inversion,\nfinding that the method can significantly reduce attack efficacy at an\nacceptable accuracy trade-off on MNIST. Furthermore, we show that NoPeekNN, an\nexisting defensive method, protects different information from exposure,\nsuggesting that a combined defence is necessary to fully protect private user\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 18:12:17 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 11:01:25 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Titcombe", "Tom", ""], ["Hall", "Adam J.", ""], ["Papadopoulos", "Pavlos", ""], ["Romanini", "Daniele", ""]]}, {"id": "2104.05750", "submitter": "Georgios Kampanos", "authors": "Georgios Kampanos and Siamak F. Shahandashti", "title": "Accept All: The Landscape of Cookie Banners in Greece and the UK", "comments": "15 pages, 6 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Cookie banners are devices implemented by websites to allow users to manage\ntheir privacy settings with respect to the use of cookies. They are part of a\nuser's daily web browsing experience since legislation in Europe requires\nwebsites to show such notices. In this paper, we carry out a large-scale study\nof more than 17,000 websites including more than 7,500 cookie banners in Greece\nand the UK to determine compliance and tracking transparency levels. Our\nanalysis shows that although more than 60% of websites store third-party\ncookies in both countries, only less than 50% show a cookie notice and hence a\nsubstantial proportion do not comply with the law even at the very basic level.\nWe find only a small proportion of the surveyed websites providing a direct\nopt-out option, with an overwhelming majority either nudging users towards\nprivacy-intrusive choices or making cookie rejection much harder than consent.\nOur results differ significantly in some cases from previous smaller-scale\nstudies and hence underline the importance of large-scale studies for a better\nunderstanding of the big picture in cookie practices.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 18:23:08 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Kampanos", "Georgios", ""], ["Shahandashti", "Siamak F.", ""]]}, {"id": "2104.05808", "submitter": "George Kesidis", "authors": "Zhen Xiang, David J. Miller, Siheng Chen, Xi Li, and George Kesidis", "title": "A Backdoor Attack against 3D Point Cloud Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vulnerability of 3D point cloud (PC) classifiers has become a grave concern\ndue to the popularity of 3D sensors in safety-critical applications. Existing\nadversarial attacks against 3D PC classifiers are all test-time evasion (TTE)\nattacks that aim to induce test-time misclassifications using knowledge of the\nclassifier. But since the victim classifier is usually not accessible to the\nattacker, the threat is largely diminished in practice, as PC TTEs typically\nhave poor transferability. Here, we propose the first backdoor attack (BA)\nagainst PC classifiers. Originally proposed for images, BAs poison the victim\nclassifier's training set so that the classifier learns to decide to the\nattacker's target class whenever the attacker's backdoor pattern is present in\na given input sample. Significantly, BAs do not require knowledge of the victim\nclassifier. Different from image BAs, we propose to insert a cluster of points\ninto a PC as a robust backdoor pattern customized for 3D PCs. Such clusters are\nalso consistent with a physical attack (i.e., with a captured object in a\nscene). We optimize the cluster's location using an independently trained\nsurrogate classifier and choose the cluster's local geometry to evade possible\nPC preprocessing and PC anomaly detectors (ADs). Experimentally, our BA\nachieves a uniformly high success rate (> 87%) and shows evasiveness against\nstate-of-the-art PC ADs.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 20:47:48 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Xiang", "Zhen", ""], ["Miller", "David J.", ""], ["Chen", "Siheng", ""], ["Li", "Xi", ""], ["Kesidis", "George", ""]]}, {"id": "2104.05871", "submitter": "Alex Malozemoff", "authors": "Marc B. Rosen, James Parker, Alex J. Malozemoff", "title": "Balboa: Bobbing and Weaving around Network Censorship", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Balboa, a link obfuscation framework for censorship\ncircumvention. Balboa provides a general framework for tunneling data through\nexisting applications. Balboa sits between an application and the operating\nsystem, intercepting outgoing network traffic and rewriting it to embed data.\nTo avoid introducing any distinguishable divergence from the expected\napplication behavior, Balboa only rewrites traffic that matches an externally\nspecified \\emph{traffic model} pre-shared between the communicating parties.\nThe traffic model captures some subset of the network traffic (e.g., some\nsubset of music an audio streaming server streams). The sender uses this model\nto replace outgoing data with a pointer to the associated location in the model\nand embed data in the freed up space. The receiver then extracts the data,\nreplacing the pointer with the original data from the model before passing the\ndata on to the application. When using TLS, this approach means that\napplication behavior with Balboa is \\emph{equivalent}, modulo small\n(protocol-dependent) timing differences, to if the application was running\nwithout Balboa.\n  Balboa differs from prior approaches in that it (1) provides a framework for\ntunneling data through arbitrary (TLS-protected) protocols/applications, and\n(2) runs the unaltered application binaries on standard inputs, as opposed to\nmost prior tunneling approaches which run the application on non-standard --\nand thus potentially distinguishable -- inputs.\n  We present two instantiations of Balboa -- one for audio streaming and one\nfor web browsing -- and demonstrate the difficulty of identifying Balboa by a\nmachine learning classifier.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 00:20:47 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Rosen", "Marc B.", ""], ["Parker", "James", ""], ["Malozemoff", "Alex J.", ""]]}, {"id": "2104.05921", "submitter": "Xinyi Zhang", "authors": "Xinyi Zhang, Chengfang Fang, Jie Shi", "title": "Thief, Beware of What Get You There: Towards Understanding Model\n  Extraction Attack", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model extraction increasingly attracts research attentions as keeping\ncommercial AI models private can retain a competitive advantage. In some\nscenarios, AI models are trained proprietarily, where neither pre-trained\nmodels nor sufficient in-distribution data is publicly available. Model\nextraction attacks against these models are typically more devastating.\nTherefore, in this paper, we empirically investigate the behaviors of model\nextraction under such scenarios. We find the effectiveness of existing\ntechniques significantly affected by the absence of pre-trained models. In\naddition, the impacts of the attacker's hyperparameters, e.g. model\narchitecture and optimizer, as well as the utilities of information retrieved\nfrom queries, are counterintuitive. We provide some insights on explaining the\npossible causes of these phenomena. With these observations, we formulate model\nextraction attacks into an adaptive framework that captures these factors with\ndeep reinforcement learning. Experiments show that the proposed framework can\nbe used to improve existing techniques, and show that model extraction is still\npossible in such strict scenarios. Our research can help system designers to\nconstruct better defense strategies based on their scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 03:46:59 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Zhang", "Xinyi", ""], ["Fang", "Chengfang", ""], ["Shi", "Jie", ""]]}, {"id": "2104.05974", "submitter": "Mengmeng Yang", "authors": "Mengmeng Yang, Ivan Tjuawinata, Kwok-Yan Lam, Tianqing Zhu, Jun Zhao", "title": "Fair and Differentially Private Distributed Frequency Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to remain competitive, Internet companies collect and analyse user\ndata for the purpose of improving user experiences. Frequency estimation is a\nwidely used statistical tool which could potentially conflict with the relevant\nprivacy regulations. Privacy preserving analytic methods based on differential\nprivacy have been proposed, which either require a large user base or a trusted\nserver; hence may give big companies an unfair advantage while handicapping\nsmaller organizations in their growth opportunity. To address this issue, this\npaper proposes a fair privacy-preserving sampling-based frequency estimation\nmethod and provides a relation between its privacy guarantee, output accuracy,\nand number of participants. We designed decentralized privacy-preserving\naggregation mechanisms using multi-party computation technique and established\nthat, for a limited number of participants and a fixed privacy level, our\nmechanisms perform better than those that are based on traditional perturbation\nmethods; hence, provide smaller companies a fair growth opportunity. We further\npropose an architectural model to support weighted aggregation in order to\nachieve higher accuracy estimate to cater for users with different privacy\nrequirements. Compared to the unweighted aggregation, our method provides a\nmore accurate estimate. Extensive experiments are conducted to show the\neffectiveness of the proposed methods.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 07:02:16 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Yang", "Mengmeng", ""], ["Tjuawinata", "Ivan", ""], ["Lam", "Kwok-Yan", ""], ["Zhu", "Tianqing", ""], ["Zhao", "Jun", ""]]}, {"id": "2104.05983", "submitter": "Diptapriyo Majumdar", "authors": "Jason Crampton, Gregory Gutin, Diptapriyo Majumdar", "title": "Towards Better Understanding of User Authorization Query Problem via\n  Multi-variable Complexity Analysis", "comments": "Accepted for publication in ACM Transactions on Privacy and Security\n  (TOPS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User authorization queries in the context of role-based access control have\nattracted considerable interest in the last 15 years. Such queries are used to\ndetermine whether it is possible to allocate a set of roles to a user that\nenables the user to complete a task, in the sense that all the permissions\nrequired to complete the task are assigned to the roles in that set. Answering\nsuch a query, in general, must take into account a number of factors,\nincluding, but not limited to, the roles to which the user is assigned and\nconstraints on the sets of roles that can be activated. Answering such a query\nis known to be NP-hard. The presence of multiple parameters and the need to\nfind efficient and exact solutions to the problem suggest that a multi-variate\napproach will enable us to better understand the complexity of the user\nauthorization query problem (UAQ). In this paper, we establish a number of\ncomplexity results for UAQ. Specifically, we show the problem remains hard even\nwhen quite restrictive conditions are imposed on the structure of the problem.\nOur FPT results show that we have to use either a parameter with potentially\nquite large values or quite a restricted version of UAQ. Moreover, our second\nFPT algorithm is complex and requires sophisticated, state-of-the-art\ntechniques. In short, our results show that it is unlikely that all variants of\nUAQ that arise in practice can be solved reasonably quickly in general.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 07:31:00 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Crampton", "Jason", ""], ["Gutin", "Gregory", ""], ["Majumdar", "Diptapriyo", ""]]}, {"id": "2104.05996", "submitter": "Luca Pajola", "authors": "Luca Pajola and Mauro Conti", "title": "Fall of Giants: How popular text-based MLaaS fall against a simple\n  evasion attack", "comments": "Accepted to appear in the Proceedings of the 2021 IEEE European\n  Symposium on Security and Privacy (EUROS&P)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increased demand for machine learning applications made companies offer\nMachine-Learning-as-a-Service (MLaaS). In MLaaS (a market estimated 8000M USD\nby 2025), users pay for well-performing ML models without dealing with the\ncomplicated training procedure. Among MLaaS, text-based applications are the\nmost popular ones (e.g., language translators). Given this popularity, MLaaS\nmust provide resiliency to adversarial manipulations. For example, a wrong\ntranslation might lead to a misunderstanding between two parties. In the text\ndomain, state-of-the-art attacks mainly focus on strategies that leverage ML\nmodels' weaknesses. Unfortunately, not much attention has been given to the\nother pipeline' stages, such as the indexing stage (i.e., when a sentence is\nconverted from a textual to a numerical representation) that, if manipulated,\ncan significantly affect the final performance of the application.\n  In this paper, we propose a novel text evasion technique called\n\"\\textit{Zero-Width} attack\" (ZeW) that leverages the injection of human\nnon-readable characters, affecting indexing stage mechanisms. We demonstrate\nthat our simple yet effective attack deceives MLaaS of \"giants\" such as Amazon,\nGoogle, IBM, and Microsoft. Our case study, based on the manipulation of\nhateful tweets, shows that out of 12 analyzed services, only one is resistant\nto our injection strategy. We finally introduce and test a simple \\textit{input\nvalidation} defense that can prevent our proposed attack.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 08:01:19 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Pajola", "Luca", ""], ["Conti", "Mauro", ""]]}, {"id": "2104.06051", "submitter": "Alessandro Erba", "authors": "Alessandro Erba, Anne M\\\"uller, Nils Ole Tippenhauer", "title": "Practical Pitfalls for Security in OPC UA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2006, the OPC Foundation released the first specification for OPC Unified\nArchitecture protocol, one of the industrial protocols that promises security\nfeatures such as authentication, authorization, integrity, and confidentiality.\nChallenges in the practical adoption of those security features by product\nvendors, libraries implementing the standard, and end-users were not\ninvestigated so far.\n  In this work, we systematically investigate practical challenges to configure\nOPC UA securely. In particular, we review 48 artifacts consisting of products\nand libraries for OPC UA and show that 38 out of the 48 artifacts have one (or\nmore) security issue. In particular, we show that 7 OPC UA artifacts do not\nsupport the security features of the protocol at all. In addition, 31 artifacts\nthat partially feature OPC UA security rely on incomplete libraries and come\nwith misleading instructions. Consequently, relying on those products and\nlibraries will result in vulnerable implementations of OPC UA security\nfeatures. We design, implement and demonstrate attacks in which the attacker\ncan steal credentials exchanged between victims, eavesdrop on process\ninformation, manipulate the physical process through sensor values and actuator\ncommands, and prevent the detection of anomalies in the physical process.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 09:28:21 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Erba", "Alessandro", ""], ["M\u00fcller", "Anne", ""], ["Tippenhauer", "Nils Ole", ""]]}, {"id": "2104.06136", "submitter": "Dominik Mei{\\ss}ner", "authors": "Dominik Mei{\\ss}ner and Frank Kargl and Benjamin Erb", "title": "WAIT: Protecting the Integrity of Web Applications with\n  Binary-Equivalent Transparency", "comments": "To be published in the 36th ACM/SIGAPP Symposium on Applied Computing\n  (SAC '21)", "journal-ref": null, "doi": "10.1145/3412841.3442143", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern single page web applications require client-side executions of\napplication logic, including critical functionality such as client-side\ncryptography. Existing mechanisms such as TLS and Subresource Integrity secure\nthe communication and provide external resource integrity. However, the browser\nis unaware of modifications to the client-side application as provided by the\nserver and the user remains vulnerable against malicious modifications carried\nout on the server side. Our solution makes such modifications transparent and\nempowers the browser to validate the integrity of a web application based on a\npublicly verifiable log. Our Web Application Integrity Transparency (WAIT)\napproach requires (1) an extension for browsers for local integrity\nvalidations, (2) a custom HTTP header for web servers that host the\napplication, and (3) public log servers that serve the verifiable logs. With\nWAIT, the browser can disallow the execution of undisclosed application\nchanges. Also, web application providers cannot dispute their authorship for\npublished modifications anymore. Although our approach cannot prevent every\nconceivable attack on client-side web application integrity, it introduces a\nnovel sense of transparency for users and an increased level of accountability\nfor application providers particularly effective against targeted insider\nattacks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 12:22:10 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Mei\u00dfner", "Dominik", ""], ["Kargl", "Frank", ""], ["Erb", "Benjamin", ""]]}, {"id": "2104.06167", "submitter": "Oleg Geier", "authors": "Oleg Geier and Dominik Herrmann", "title": "The AppChk Crowd-Sourcing Platform: Which third parties are iOS apps\n  talking to?", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we present a platform which is usable by novice users without\ndomain knowledge of experts. The platform consisting of an iOS app to monitor\nnetwork traffic and a website to evaluate the results. Monitoring takes place\non-device; no external server is required. Users can record and share network\nactivity, compare evaluation results, and create rankings on apps and\napp-groups. The results are used to detect new trackers, point out misconduct\nin privacy practices, or automate comparisons on app-attributes like price,\nregion, and category. To demonstrate potential use cases, we compare 75 apps\nbefore and after the iOS 14 release and show that we can detect trends in\napp-specific behavior change over time, for example, by privacy changes in the\nOS. Our results indicate a slight decrease in tracking but also an increase in\ncontacted domains. We identify seven new trackers which are not present in\ncurrent tracking lists such as EasyList. The games category is particularly\nprone to tracking (53% of the traffic) and contacts on average 36.2 domains\nwith 59.3 requests per minute.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 13:19:50 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Geier", "Oleg", ""], ["Herrmann", "Dominik", ""]]}, {"id": "2104.06301", "submitter": "Andreas Bluhm", "authors": "Andreas Bluhm, Matthias Christandl, Florian Speelman", "title": "Position-based cryptography: Single-qubit protocol secure against\n  multi-qubit attacks", "comments": "26 pages, 4 figures. Content significantly expanded. In particular,\n  we have added the function BB84 protocol and prove its security in Section 4.\n  Finally, we give lower bounds for concrete functions in Section 6", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While it is known that unconditionally secure position-based cryptography is\nimpossible both in the classical and the quantum setting, it has been shown\nthat some quantum protocols for position verification are secure against\nattackers which share a quantum state of bounded dimension. In this work, we\nconsider the security of two protocols for quantum position verification that\ncombine a single qubit with classical strings of total length $2n$: The qubit\nrouting protocol, where the classical information prescribes the qubit's\ndestination, and a variant of the BB84-protocol for position verification,\nwhere the classical information prescribes in which basis the qubit should be\nmeasured. We show that either protocol is secure for a randomly chosen function\nif each of the attackers holds at most $n/2 - 5$ qubits. With this, we show for\nthe first time that there exists a quantum position verification protocol where\nthe ratio between the quantum resources an honest prover needs and the quantum\nresources the attackers need to break the protocol is unbounded. The verifiers\nneed only increase the amount of classical resources to force the attackers to\nuse more quantum resources. Concrete efficient functions for both protocols are\nalso given -- at the expense of a weaker but still unbounded ratio of quantum\nresources for successful attackers. Finally, we show that both protocols are\nrobust with respect to noise, making them appealing for applications.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 15:48:11 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 16:13:14 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Bluhm", "Andreas", ""], ["Christandl", "Matthias", ""], ["Speelman", "Florian", ""]]}, {"id": "2104.06307", "submitter": "Bowen Xu", "authors": "Bowen Xu, Fanghong Guo, Changyun Wen, Wen-An Zhang", "title": "Stealthy False Data Injection Attack Detection in Smart Grids with\n  Uncertainties: A Deep Transfer Learning Based Approach", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most traditional false data injection attack (FDIA) detection approaches rely\non static system parameters or a single known snapshot of dynamic ones.\nHowever, such a setting significantly weakens the practicality of these\napproaches when facing the fact that the system parameters are dynamic and\ncannot be accurately known during operation due to the presence of\nuncertainties in practical smart grids. In this paper, we propose an FDIA\ndetection mechanism from the perspective of transfer learning. Specifically,\nthe known initial/approximate system is treated as a source domain, which\nprovides abundant simulated normal and attack data. The real world's unknown\nrunning system is taken as a target domain where sufficient real normal data\nare collected for tracking the latest system states online. The designed\ntransfer strategy that aims at making full use of data in hand is divided into\ntwo optimization stages. In the first stage, a deep neural network (DNN) is\nbuilt by simultaneously optimizing several well-designed terms with both\nsimulated data and real data, and then it is fine-tuned via real data in the\nsecond stage. Several case studies on the IEEE 14-bus power system verify the\neffectiveness of the proposed mechanism.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 15:32:20 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Xu", "Bowen", ""], ["Guo", "Fanghong", ""], ["Wen", "Changyun", ""], ["Zhang", "Wen-An", ""]]}, {"id": "2104.06361", "submitter": "Diego Munuera-Merayo", "authors": "Diego Munuera-Merayo", "title": "On Mignotte Secret Sharing Schemes over Gaussian Integers", "comments": "12 pages. There is one figure in page 6. To be submitted to the\n  Journal of Algebra Combinatorics Discrete Structures and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Secret Sharing Schemes (SSS) are methods for distributing a secret among a\nset of participants. One of the first Secret Sharing Schemes was proposed by M.\nMignotte, based on the Chinese remainder theorem over the ring of integers. In\nthis article we extend the Mignotte's scheme to the ring of Gaussian Integers\nand study some of its properties. While doing this we aim to solve a gap in a\nprevious construction of such extension. In addition we show that any access\nstructure can be made through a SSS over $ \\mathbb{Z}[i]$.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 17:08:42 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 14:24:39 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Munuera-Merayo", "Diego", ""]]}, {"id": "2104.06444", "submitter": "Pieter Hartel", "authors": "Pieter Hartel, Rolf van Wegberg", "title": "Going dark? Analysing the impact of end-to-end encryption on the outcome\n  of Dutch criminal court cases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Former US attorney general William Barr and law enforcement colleagues from\nother countries have published a statement on end-to-end encryption from which\nwe quote: \"while encryption is vital and privacy and cybersecurity must be\nprotected, that should not come at the expense of wholly precluding law\nenforcement\". The main argument put forward by law enforcement is that\nend-to-end encryption (E2EE) hampers authorities prosecuting criminals who rely\non encrypted communication - ranging from drug syndicates to child sexual abuse\nmaterial (CSAM) platforms. This statement, however, is not supported by\nempirical evidence, and therefore not suitable as the sole basis of\npolicymaking. That is why, in our work, we analyse public court data from the\nNetherlands to show to what extent law enforcement agencies and the public\nprosecution service are impacted by the use of E2EE in bringing cases to court\nand their outcome. Our results show that Dutch law enforcement appears to be as\nsuccessful in prosecuting offenders who rely on encrypted communication as\nthose who do not. In contrast to what the US attorney general wants us to\nbelieve, at least the prosecution of cases does not seem hampered by E2EE.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 18:38:22 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Hartel", "Pieter", ""], ["van Wegberg", "Rolf", ""]]}, {"id": "2104.06498", "submitter": "Mohammadreza Begli", "authors": "Mohammadreza Begli, Farnaz Derakhshan", "title": "A multiagent based framework secured with layered SVM-based IDS for\n  remote healthcare systems", "comments": "12 pages in two-column format, 4 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since the number of elderly and patients who are in hospitals and healthcare\ncenters are growing, providing efficient remote healthcare services seems very\nimportant. Currently, most such systems benefit from the distribution and\nautonomy features of multiagent systems and the structure of wireless sensor\nnetworks. On the one hand, securing the data of remote healthcare systems is\none of the most significant concerns; particularly recent types of research\nabout the security of remote healthcare systems keep them secure from\neavesdropping and data modification. On the other hand, existing remote\nhealthcare systems are still vulnerable against other common attacks of\nhealthcare networks such as Denial of Service (DoS) and User to Root (U2R)\nattacks, because they are managed remotely and based on the Internet.\nTherefore, in this paper, we propose a secure framework for remote healthcare\nsystems that consists of two phases. First, we design a healthcare system base\non multiagent technology to collect data from a sensor network. Then, in the\nsecond phase, a layered architecture of intrusion detection systems that uses\nSupport Vector Machine to learn the behavior of network traffic is applied.\nBased on our framework, we implement a secure remote healthcare system and\nevaluate this system against the frequent attacks of healthcare networks such\nas Smurf, Buffer overflow, Neptune, and Pod attacks. In the end, evaluation\nparameters of the layered architecture of intrusion detection systems prove the\nefficiency and correctness of our proposed framework.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 20:34:38 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Begli", "Mohammadreza", ""], ["Derakhshan", "Farnaz", ""]]}, {"id": "2104.06515", "submitter": "Elijah Bouma-Sims", "authors": "Elijah Bouma-Sims, Brad Reaves", "title": "A First Look at Scams on YouTube", "comments": "Presented at the Workshop on Measurements, Attacks, and Defenses for\n  the Web (MADWeb) 2021 hosted at NDSS '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  YouTube has become the second most popular website according to Alexa, and it\nrepresents an enticing platform for scammers to attract victims. Because of the\ncomputational difficulty of classifying multimedia, identifying scams on\nYouTube is more difficult than text-based media. As a consequence, the research\ncommunity to-date has provided little insight into the prevalence, lifetime,\nand operational patterns of scammers on YouTube. In this short paper, we\npresent a preliminary exploration of scam videos on YouTube. We begin by\nidentifying 74 search queries likely to lead to scam videos based on the\nauthors' experience seeing scams during routine browsing. We then manually\nreview and characterize the results to identify 668 scams in 3,700 videos. In a\ndetailed analysis of our classifications and metadata, we find that these scam\nvideos have a median lifetime of nearly nine months, and many rely on external\nwebsites for monetization. We also explore the potential of detecting scams\nfrom metadata alone, finding that metadata does not have enough predictive\npower to distinguish scams from legitimate videos. Our work demonstrates that\nscams are a real problem for YouTube users, motivating future work on this\ntopic.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 20:58:57 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Bouma-Sims", "Elijah", ""], ["Reaves", "Brad", ""]]}, {"id": "2104.06523", "submitter": "Iyiola E. Olatunji", "authors": "Iyiola E. Olatunji, Jens Rauch, Matthias Katzensteiner, Megha Khosla", "title": "A Review of Anonymization for Healthcare Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mining health data can lead to faster medical decisions, improvement in the\nquality of treatment, disease prevention, reduced cost, and it drives\ninnovative solutions within the healthcare sector. However, health data is\nhighly sensitive and subject to regulations such as the General Data Protection\nRegulation (GDPR), which aims to ensure patient's privacy. Anonymization or\nremoval of patient identifiable information, though the most conventional way,\nis the first important step to adhere to the regulations and incorporate\nprivacy concerns. In this paper, we review the existing anonymization\ntechniques and their applicability to various types (relational and\ngraph-based) of health data. Besides, we provide an overview of possible\nattacks on anonymized data. We illustrate via a reconstruction attack that\nanonymization though necessary, is not sufficient to address patient privacy\nand discuss methods for protecting against such attacks. Finally, we discuss\ntools that can be used to achieve anonymization.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 21:44:29 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Olatunji", "Iyiola E.", ""], ["Rauch", "Jens", ""], ["Katzensteiner", "Matthias", ""], ["Khosla", "Megha", ""]]}, {"id": "2104.06540", "submitter": "Aleksandar Kircanski", "authors": "Aleksandar Kircanski and Terence Tarvis", "title": "Coinbugs: Enumerating Common Blockchain Implementation-Level\n  Vulnerabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A good amount of effort has been dedicated to surveying and systematizing\nEthereum smart contract security bug classes. There is, however, a gap in\nliterature when it comes to surveying implementation-level security bugs that\ncommonly occur in basic PoW blockchain node implementations, discovered during\nthe first decade of Bitcoin's existence. This paper attempts to fill this void.\nIn particular, if software which participates in a network by validating and\ngenerating new blocks is developed from scratch, WCGW - What Could Go Wrong?\n  Ten broad bug type categories are listed and for each category, known\nexamples are linked. Blockchain, as designed by the Satoshi's paper is exciting\nand introduces several novel bug classes which are interesting to security\nresearchers. The paper is aimed at security testers aiming to start out in\nblockchain security reviews and blockchain developers as a reference on common\npitfalls.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 22:55:37 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Kircanski", "Aleksandar", ""], ["Tarvis", "Terence", ""]]}, {"id": "2104.06557", "submitter": "Sreya Francis", "authors": "Sreya Francis, Irene Tenison, Irina Rish", "title": "Towards Causal Federated Learning For Enhanced Robustness and Privacy", "comments": null, "journal-ref": "ICLR 2021 Distributed and Private Machine Learning(DPML) Workshop", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning is an emerging privacy-preserving distributed machine\nlearning approach to building a shared model by performing distributed training\nlocally on participating devices (clients) and aggregating the local models\ninto a global one. As this approach prevents data collection and aggregation,\nit helps in reducing associated privacy risks to a great extent. However, the\ndata samples across all participating clients are usually not independent and\nidentically distributed (non-iid), and Out of Distribution(OOD) generalization\nfor the learned models can be poor. Besides this challenge, federated learning\nalso remains vulnerable to various attacks on security wherein a few malicious\nparticipating entities work towards inserting backdoors, degrading the\ngenerated aggregated model as well as inferring the data owned by participating\nentities. In this paper, we propose an approach for learning invariant (causal)\nfeatures common to all participating clients in a federated learning setup and\nanalyze empirically how it enhances the Out of Distribution (OOD) accuracy as\nwell as the privacy of the final learned model.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 00:08:45 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Francis", "Sreya", ""], ["Tenison", "Irene", ""], ["Rish", "Irina", ""]]}, {"id": "2104.06559", "submitter": "Jiajun Zhou", "authors": "Jie Shen, Jiajun Zhou, Yunyi Xie, Shanqing Yu, and Qi Xuan", "title": "Identity Inference on Blockchain using Graph Neural Network", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The anonymity of blockchain has accelerated the growth of illegal activities\nand criminal behaviors on cryptocurrency platforms. Although decentralization\nis one of the typical characteristics of blockchain, we urgently call for\neffective regulation to detect these illegal behaviors to ensure the safety and\nstability of user transactions. Identity inference, which aims to make a\npreliminary inference about account identity, plays a significant role in\nblockchain security. As a common tool, graph mining technique can effectively\nrepresent the interactive information between accounts and be used for identity\ninference. However, existing methods cannot balance scalability and end-to-end\narchitecture, resulting high computational consumption and weak feature\nrepresentation. In this paper, we present a novel approach to analyze user's\nbehavior from the perspective of the transaction subgraph, which naturally\ntransforms the identity inference task into a graph classification pattern and\neffectively avoids computation in large-scale graph. Furthermore, we propose a\ngeneric end-to-end graph neural network model, named $\\text{I}^2 \\text{BGNN}$,\nwhich can accept subgraph as input and learn a function mapping the transaction\nsubgraph pattern to account identity, achieving de-anonymization. Extensive\nexperiments on EOSG and ETHG datasets demonstrate that the proposed method\nachieve the state-of-the-art performance in identity inference.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 00:15:38 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Shen", "Jie", ""], ["Zhou", "Jiajun", ""], ["Xie", "Yunyi", ""], ["Yu", "Shanqing", ""], ["Xuan", "Qi", ""]]}, {"id": "2104.06569", "submitter": "Fumiyuki Kato", "authors": "Fumiyuki Kato and Yang Cao and Masatoshi Yoshikawa", "title": "Preventing Manipulation Attack in Local Differential Privacy using\n  Verifiable Randomization Mechanism", "comments": "accepted by DBSec 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several randomization mechanisms for local differential privacy (LDP) (e.g.,\nrandomized response) are well-studied to improve the utility. However, recent\nstudies show that LDP is generally vulnerable to malicious data providers in\nnature. Because a data collector has to estimate background data distribution\nonly from already randomized data, malicious data providers can manipulate\ntheir output before sending, i.e., randomization would provide them plausible\ndeniability. Attackers can skew the estimations effectively since they are\ncalculated by normalizing with randomization probability defined in the LDP\nprotocol, and can even control the estimations. In this paper, we show how we\nprevent malicious attackers from compromising LDP protocol. Our approach is to\nutilize a verifiable randomization mechanism. The data collector can verify the\ncompleteness of executing an agreed randomization mechanism for every data\nprovider. Our proposed method completely protects the LDP protocol from\noutput-manipulations, and significantly mitigates the expected damage from\nattacks. We do not assume any specific attacks, and it works effectively\nagainst general output-manipulation, and thus is more powerful than previously\nproposed countermeasures. We describe the secure version of three\nstate-of-the-art LDP protocols and empirically show they cause acceptable\noverheads according to several parameters.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 01:00:57 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 07:55:25 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Kato", "Fumiyuki", ""], ["Cao", "Yang", ""], ["Yoshikawa", "Masatoshi", ""]]}, {"id": "2104.06576", "submitter": "Noah Stephens-Davidowitz", "authors": "Divesh Aggarwal, Yanlin Chen, Rajendra Kumar, Zeyong Li, Noah\n  Stephens-Davidowitz", "title": "Dimension-Preserving Reductions Between SVP and CVP in Different\n  $p$-Norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  $ \\newcommand{\\SVP}{\\textsf{SVP}} \\newcommand{\\CVP}{\\textsf{CVP}}\n\\newcommand{\\eps}{\\varepsilon} $We show a number of reductions between the\nShortest Vector Problem and the Closest Vector Problem over lattices in\ndifferent $\\ell_p$ norms ($\\SVP_p$ and $\\CVP_p$ respectively). Specifically, we\npresent the following $2^{\\eps m}$-time reductions for $1 \\leq p \\leq q \\leq\n\\infty$, which all increase the rank $n$ and dimension $m$ of the input lattice\nby at most one:\n  $\\bullet$ a reduction from $\\widetilde{O}(1/\\eps^{1/p})\\gamma$-approximate\n$\\SVP_q$ to $\\gamma$-approximate $\\SVP_p$;\n  $\\bullet$ a reduction from $\\widetilde{O}(1/\\eps^{1/p}) \\gamma$-approximate\n$\\CVP_p$ to $\\gamma$-approximate $\\CVP_q$; and\n  $\\bullet$ a reduction from $\\widetilde{O}(1/\\eps^{1+1/p})$-$\\CVP_q$ to\n$(1+\\eps)$-unique $\\SVP_p$ (which in turn trivially reduces to\n$(1+\\eps)$-approximate $\\SVP_p$).\n  The last reduction is interesting even in the case $p = q$. In particular,\nthis special case subsumes much prior work adapting $2^{O(m)}$-time $\\SVP_p$\nalgorithms to solve $O(1)$-approximate $\\CVP_p$. In the (important) special\ncase when $p = q$, $1 \\leq p \\leq 2$, and the $\\SVP_p$ oracle is exact, we show\na stronger reduction, from $O(1/\\eps^{1/p})\\text{-}\\CVP_p$ to (exact) $\\SVP_p$\nin $2^{\\eps m}$ time. For example, taking $\\eps = \\log m/m$ and $p = 2$ gives a\nslight improvement over Kannan's celebrated polynomial-time reduction from\n$\\sqrt{m}\\text{-}\\CVP_2$ to $\\SVP_2$. We also note that the last two reductions\ncan be combined to give a reduction from approximate-$\\CVP_p$ to $\\SVP_q$ for\nany $p$ and $q$, regardless of whether $p \\leq q$ or $p > q$.\n  Our techniques combine those from the recent breakthrough work of Eisenbrand\nand Venzin (which showed how to adapt the current fastest known algorithm for\nthese problems in the $\\ell_2$ norm to all $\\ell_p$ norms) together with\nsparsification-based techniques.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 01:41:24 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Aggarwal", "Divesh", ""], ["Chen", "Yanlin", ""], ["Kumar", "Rajendra", ""], ["Li", "Zeyong", ""], ["Stephens-Davidowitz", "Noah", ""]]}, {"id": "2104.06652", "submitter": "Abhijitt Dhavlle", "authors": "Abhijitt Dhavlle and Sanket Shukla", "title": "A Novel Malware Detection Mechanism based on Features Extracted from\n  Converted Malware Binary Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our computer systems for decades have been threatened by various types of\nhardware and software attacks of which Malwares have been one of them. This\nmalware has the ability to steal, destroy, contaminate, gain unintended access,\nor even disrupt the entire system. There have been techniques to detect malware\nby performing static and dynamic analysis of malware files, but, stealthy\nmalware has circumvented the static analysis method and for dynamic analysis,\nthere have been previous works that propose different methods to detect malware\nbut, in this work we propose a novel technique to detect malware. We use\nmalware binary images and then extract different features from the same and\nthen employ different ML-classifiers on the dataset thus obtained. We show that\nthis technique is successful in differentiating classes of malware based on the\nfeatures extracted.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 06:55:52 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Dhavlle", "Abhijitt", ""], ["Shukla", "Sanket", ""]]}, {"id": "2104.06744", "submitter": "Nicolas Michael M\\\"uller", "authors": "Nicolas M. M\\\"uller, Simon Roschmann, Konstantin B\\\"ottinger", "title": "Defending against Adversarial Denial-of-Service Attacks", "comments": "Submitted to ACSAC DYNAMICS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data poisoning is one of the most relevant security threats against machine\nlearning and data-driven technologies. Since many applications rely on\nuntrusted training data, an attacker can easily craft malicious samples and\ninject them into the training dataset to degrade the performance of machine\nlearning models. As recent work has shown, such Denial-of-Service (DoS) data\npoisoning attacks are highly effective. To mitigate this threat, we propose a\nnew approach of detecting DoS poisoned instances. In comparison to related\nwork, we deviate from clustering and anomaly detection based approaches, which\noften suffer from the curse of dimensionality and arbitrary anomaly threshold\nselection. Rather, our defence is based on extracting information from the\ntraining data in such a generalized manner that we can identify poisoned\nsamples based on the information present in the unpoisoned portion of the data.\nWe evaluate our defence against two DoS poisoning attacks and seven datasets,\nand find that it reliably identifies poisoned instances. In comparison to\nrelated work, our defence improves false positive / false negative rates by at\nleast 50%, often more.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 09:52:36 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 14:32:01 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["M\u00fcller", "Nicolas M.", ""], ["Roschmann", "Simon", ""], ["B\u00f6ttinger", "Konstantin", ""]]}, {"id": "2104.06824", "submitter": "Jing Ma", "authors": "Jing Ma, Si-Ahmed Naas, Stephan Sigg, Xixiang Lyu", "title": "Privacy-preserving Federated Learning based on Multi-key Homomorphic\n  Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advance of machine learning and the internet of things (IoT),\nsecurity and privacy have become key concerns in mobile services and networks.\nTransferring data to a central unit violates privacy as well as protection of\nsensitive data while increasing bandwidth demands.Federated learning mitigates\nthis need to transfer local data by sharing model updates only. However, data\nleakage still remains an issue. In this paper, we propose xMK-CKKS, a multi-key\nhomomorphic encryption protocol to design a novel privacy-preserving federated\nlearning scheme. In this scheme, model updates are encrypted via an aggregated\npublic key before sharing with a server for aggregation. For decryption,\ncollaboration between all participating devices is required. This scheme\nprevents privacy leakage from publicly shared information in federated\nlearning, and is robust to collusion between $k<N-1$ participating devices and\nthe server. Our experimental evaluation demonstrates that the scheme preserves\nmodel accuracy against traditional federated learning as well as secure\nfederated learning with homomorphic encryption (MK-CKKS, Paillier) and reduces\ncomputational cost compared to Paillier based federated learning. The average\nenergy consumption is 2.4 Watts, so that it is suited to IoT scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 12:54:28 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Ma", "Jing", ""], ["Naas", "Si-Ahmed", ""], ["Sigg", "Stephan", ""], ["Lyu", "Xixiang", ""]]}, {"id": "2104.06989", "submitter": "Nmachi Peace Wosah", "authors": "Nmachi Peace Wosah and Thomas Win", "title": "Phishing Mitigation Techniques: A Literature Survey", "comments": null, "journal-ref": "International Journal of Network Security & Its Applications\n  (IJNSA) Vol.13, No.2, March 2021", "doi": "10.5121/ijnsa.2021.13205", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Email is a channel of communication which is considered to be a confidential\nmedium of communication for exchange of information among individuals and\norganisations. The confidentiality consideration about e-mail is no longer the\ncase as attackers send malicious emails to users to deceive them into\ndisclosing their private personal information such as username, password, and\nbank card details, etc. In search of a solution to combat phishing cybercrime\nattacks, different approaches have been developed. However, the traditional\nexiting solutions have been limited in assisting email users to identify\nphishing emails from legitimate ones. This paper reveals the different email\nand website phishing solutions in phishing attack detection. It first provides\na literature analysis of different existing phishing mitigation approaches. It\nthen provides a discussion on the limitations of the techniques, before\nconcluding with an exploration into how phishing detection can be improved.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 17:16:25 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Wosah", "Nmachi Peace", ""], ["Win", "Thomas", ""]]}, {"id": "2104.07029", "submitter": "Maciej Skorski", "authors": "Maciej Skorski", "title": "Mean-Squared Accuracy of Good-Turing Estimator", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.31351.44960/1", "report-no": null, "categories": "stat.ML cs.CR cs.IT cs.LG math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brilliant method due to Good and Turing allows for estimating objects not\noccurring in a sample. The problem, known under names \"sample coverage\" or\n\"missing mass\" goes back to their cryptographic work during WWII, but over\nyears has found has many applications, including language modeling, inference\nin ecology and estimation of distribution properties. This work characterizes\nthe maximal mean-squared error of the Good-Turing estimator, for any sample\n\\emph{and} alphabet size.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 17:23:46 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Skorski", "Maciej", ""]]}, {"id": "2104.07138", "submitter": "Atif Ahmad", "authors": "Abhineet Gupta, Sean B Maynard, Atif Ahmad", "title": "The Dark Web Phenomenon: A Review and Research Agenda", "comments": "11 pages, Paper presented at the 30th Australasian Conference on\n  Information Systems, Perth, Australia (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The internet can be broadly divided into three parts: surface, deep and dark.\nThe dark web has become notorious in the media for being a hidden part of the\nweb where all manner of illegal activities take place. This review investigates\nhow the dark web is being utilised with an emphasis on cybercrime, and how law\nenforcement plays the role of its adversary. The review describes these hidden\nspaces, sheds light on their history, the activities that they harbour\nincluding cybercrime, the nature of attention they receive, and methodologies\nemployed by law enforcement in an attempt to defeat their purpose. More\nimportantly, it is argued that these spaces should be considered a phenomenon\nand not an isolated occurrence to be taken as merely a natural consequence of\ntechnology. This paper contributes to the area of dark web research by serving\nas a reference document and by proposing a research agenda.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 21:53:32 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Gupta", "Abhineet", ""], ["Maynard", "Sean B", ""], ["Ahmad", "Atif", ""]]}, {"id": "2104.07140", "submitter": "Atif Ahmad", "authors": "Hibah Altukruni, Sean B. Maynard, Moneer Alshaikh, Atif Ahmad", "title": "Exploring Knowledge Leakage Risk in Knowledge-Intensive Organisations:\n  Behavioural aspects and Key controls", "comments": "11 pages", "journal-ref": "ACIS, Perth, Australia. (pp. 75-85) 2019", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Knowledge leakage poses a critical risk to the competitive advantage of\nknowledge-intensive organisations. Although knowledge leakage is a\nhuman-centric security issue, little is known about leakage resulting from\nindividual behaviour and the protective strategies and controls that could be\neffective in mitigating leakage risk. Therefore, this research explores the\nperspectives of security practitioners on the key factors that influence\nknowledge leakage risk in the context of knowledge-intensive organisations. We\nconduct two focus groups to explore these perspectives. The research highlights\nthree types of behavioural controls that mitigate the risk of knowledge\nleakage: human resource management practices, knowledge security training and\nawareness practices, and compartmentalisation practices.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 21:58:03 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Altukruni", "Hibah", ""], ["Maynard", "Sean B.", ""], ["Alshaikh", "Moneer", ""], ["Ahmad", "Atif", ""]]}, {"id": "2104.07141", "submitter": "Atif Ahmad", "authors": "Mazino Onibere, Atif Ahmad, Sean B Maynard", "title": "Dynamic Information Security Management Capability: Strategising for\n  Organisational Performance", "comments": "7 pages", "journal-ref": "ACIS, Perth, Australia. (pp. 674-680) 2019", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The increasing frequency, impact, consequence and sophistication of\ncybersecurity attacks is becoming a strategic concern for boards and executive\nmanagement of organisations. Consequently, in addition to focusing on\nproductivity and performance, organisations are prioritizing Information\nSecurity Management (ISM). However, research has revealed little or no\nconceptualisation of a dynamic ISM capability and its link to organisational\nperformance. In this research, we set out to 1) define and describe an\norganisational level dynamic ISM capability, 2) to develop a strategic model\nthat links resources with this dynamic capability, and then 3) empirically\ndemonstrate how dynamic ISM capability contributes to firm performance. By\ndrawing on Resource-Based Theory (RBT) and Dynamic Capabilities View (DCV), we\nhave developed the Dynamic ISM Capability model to address the identified gap.\nAs we develop this research, we will empirically test this model to demonstrate\ncausality between ISM capability and organisational performance.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 22:00:53 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Onibere", "Mazino", ""], ["Ahmad", "Atif", ""], ["Maynard", "Sean B", ""]]}, {"id": "2104.07144", "submitter": "Atif Ahmad", "authors": "Abid Hussain Shah, Atif Ahmad, Sean B. Maynard, Humza Naseer", "title": "Enhancing Strategic Information Security Management in Organizations\n  through Information Warfare Practices", "comments": "8 pages", "journal-ref": "ACIS, Perth, Australia. (pp. 449-455) 2019", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this short paper we argue that to combat APTs, organizations need a\nstrategic level shift away from a traditional prevention centered approach to\nthat of a response centered one. Drawing on the information warfare (IW)\nparadigm in military studies, and using Dynamic Capability Theory (DCT), this\nresearch examines the applicability of IW capabilities in the corporate domain.\nWe propose a research framework to argue that conventional prevention centred\nresponse capabilities; such as incident response capabilities and IW centred\nsecurity capabilities can be integrated into IW enabled dynamic response\ncapabilities that improve enterprise security performance.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 22:05:44 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Shah", "Abid Hussain", ""], ["Ahmad", "Atif", ""], ["Maynard", "Sean B.", ""], ["Naseer", "Humza", ""]]}, {"id": "2104.07183", "submitter": "Siamak Layeghy", "authors": "Mohanad Sarhan, Siamak Layeghy, Marius Portmann", "title": "An Explainable Machine Learning-based Network Intrusion Detection System\n  for Enabling Generalisability in Securing IoT Networks", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine Learning (ML)-based network intrusion detection systems bring many\nbenefits for enhancing the security posture of an organisation. Many systems\nhave been designed and developed in the research community, often achieving a\nperfect detection rate when evaluated using certain datasets. However, the high\nnumber of academic research has not translated into practical deployments.\nThere are a number of causes behind the lack of production usage. This paper\ntightens the gap by evaluating the generalisability of a common feature set to\ndifferent network environments and attack types. Therefore, two feature sets\n(NetFlow and CICFlowMeter) have been evaluated across three datasets, i.e.\nCSE-CIC-IDS2018, BoT-IoT, and ToN-IoT. The results showed that the NetFlow\nfeature set enhances the two ML models' detection accuracy in detecting\nintrusions across different datasets. In addition, due to the complexity of the\nlearning models, the SHAP, an explainable AI methodology, has been adopted to\nexplain and interpret the classification decisions of two ML models. The\nShapley values of the features have been analysed across multiple datasets to\ndetermine the influence contributed by each feature towards the final ML\nprediction.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 00:44:45 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Sarhan", "Mohanad", ""], ["Layeghy", "Siamak", ""], ["Portmann", "Marius", ""]]}, {"id": "2104.07195", "submitter": "Wei Li", "authors": "Lei Zhang, Wei Bai, Wei Li, Shiming Xia, Qibin Zheng", "title": "Discover the Hidden Attack Path in Multi-domain Cyberspace Based on\n  Reinforcement Learning", "comments": "12 pages, 2 figures, 3 tables. arXiv admin note: substantial text\n  overlap with arXiv:2007.04614", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work, we present a learning-based approach to analysis cyberspace\nsecurity configuration. Unlike prior methods, our approach has the ability to\nlearn from past experience and improve over time. In particular, as we train\nover a greater number of agents as attackers, our method becomes better at\ndiscovering hidden attack paths for previously methods, especially in\nmulti-domain cyberspace. To achieve these results, we pose discovering attack\npaths as a Reinforcement Learning (RL) problem and train an agent to discover\nmulti-domain cyberspace attack paths. To enable our RL policy to discover more\nhidden attack paths and shorter attack paths, we ground representation\nintroduction an multi-domain action select module in RL. Our objective is to\ndiscover more hidden attack paths and shorter attack paths by our proposed\nmethod, to analysis the weakness of cyberspace security configuration. At last,\nwe designed a simulated cyberspace experimental environment to verify our\nproposed method, the experimental results show that our method can discover\nmore hidden multi-domain attack paths and shorter attack paths than existing\nbaseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 01:38:51 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Zhang", "Lei", ""], ["Bai", "Wei", ""], ["Li", "Wei", ""], ["Xia", "Shiming", ""], ["Zheng", "Qibin", ""]]}, {"id": "2104.07215", "submitter": "Abdelatif Hafid", "authors": "Hafid Abdelatif, Senhaji Hafid Abdelhakim, Samih Mustapha", "title": "A Tractable Probabilistic Approach to Analyze Sybil Attacks in\n  Sharding-Based Blockchain Protocols", "comments": "10 pages, 5 figures, 4 tables, Journal article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain like Bitcoin and Ethereum suffer from scalability issues. Sharding\nis one of the most promising and leading solutions to scale blockchain. The\nbasic idea behind sharding is to divide the blockchain network into multiple\ncommittees, where each processing a separate set of transactions, rather than\nthe entire network processes all transactions. In this paper, we propose a\nprobabilistic approach to analyze the security of sharding-based blockchain\nprotocols. Based on this approach, we investigate the threat of Sybil attacks\nin these protocols. The key contribution of our paper is a tractable\nprobabilistic approach to accurately compute the failure probability that at\nleast one committee fails and ultimately compute the probability of a\nsuccessful attack. To show the effectiveness of our approach, we conduct a\nnumerical and comparative analysis of the proposed approach with existing\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 03:29:26 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Abdelatif", "Hafid", ""], ["Abdelhakim", "Senhaji Hafid", ""], ["Mustapha", "Samih", ""]]}, {"id": "2104.07332", "submitter": "Jose Moura", "authors": "Pedro Manso, Jose Moura, Carlos Serrao", "title": "SDN-Based Intrusion Detection System for Early Detection and Mitigation\n  of DDoS Attacks", "comments": "Published in MDPI Information", "journal-ref": "Information 2019, 10, 106", "doi": "10.3390/info10030106", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The current paper addresses relevant network security vulnerabilities\nintroduced by network devices within the emerging paradigm of Internet of\nThings (IoT) as well as the urgent need to mitigate the negative effects of\nsome types of Distributed Denial of Service (DDoS) attacks that try to explore\nthose security weaknesses. We design and implement a Software-Defined Intrusion\nDetection System (IDS) that reactively impairs the attacks at its origin,\nensuring the normal operation of the network infrastructure. Our proposal\nincludes an IDS that automatically detects several DDoS attacks, and then as an\nattack is detected, it notifies a Software Defined Networking (SDN) controller.\nThe current proposal also downloads some convenient traffic forwarding\ndecisions from the SDN controller to network devices. The evaluation results\nsuggest that our proposal timely detects several types of cyber-attacks based\non DDoS, mitigates their negative impacts on the network performance, and\nensures the correct data delivery of normal traffic. Our work sheds light on\nthe programming relevance over an abstracted view of the network infrastructure\nto timely detect a Botnet exploitation, mitigate malicious traffic at its\nsource, and protect benign traffic.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 09:40:59 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Manso", "Pedro", ""], ["Moura", "Jose", ""], ["Serrao", "Carlos", ""]]}, {"id": "2104.07353", "submitter": "Mohammad Sadeq Dousti", "authors": "Ernst Althaus, Mohammad Sadeq Dousti and Stefan Kramer", "title": "Fast Private Parameter Learning and Evaluation for Sum-Product Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A sum-product network (SPN) is a graphical model that allows several types of\ninferences to be drawn efficiently. There are two types of learning for SPNs:\nLearning the architecture of the model, and learning the parameters. In this\npaper, we tackle the second problem: We show how to learn the weights for the\nsum nodes, assuming the architecture is fixed, and the data is horizontally\npartitioned between multiple parties. The computations will preserve the\nprivacy of each participant. Furthermore, we will use secret sharing instead of\n(homomorphic) encryption, which allows fast computations and requires little\ncomputational resources. To this end, we use a novel integer division to\ncompute approximate real divisions. We also show how simple and private\nevaluations can be performed using the learned SPN.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 10:21:51 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Althaus", "Ernst", ""], ["Dousti", "Mohammad Sadeq", ""], ["Kramer", "Stefan", ""]]}, {"id": "2104.07395", "submitter": "Mingfu Xue", "authors": "Mingfu Xue, Can He, Shichang Sun, Jian Wang, Weiqiang Liu", "title": "Robust Backdoor Attacks against Deep Neural Networks in Real Physical\n  World", "comments": null, "journal-ref": "The 20th IEEE International Conference on Trust, Security and\n  Privacy in Computing and Communications (TrustCom 2021)", "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) have been widely deployed in various applications.\nHowever, many researches indicated that DNN is vulnerable to backdoor attacks.\nThe attacker can create a hidden backdoor in target DNN model, and trigger the\nmalicious behaviors by submitting specific backdoor instance. However, almost\nall the existing backdoor works focused on the digital domain, while few\nstudies investigate the backdoor attacks in real physical world. Restricted to\na variety of physical constraints, the performance of backdoor attacks in the\nreal physical world will be severely degraded. In this paper, we propose a\nrobust physical backdoor attack method, PTB (physical transformations for\nbackdoors), to implement the backdoor attacks against deep learning models in\nthe real physical world. Specifically, in the training phase, we perform a\nseries of physical transformations on these injected backdoor instances at each\nround of model training, so as to simulate various transformations that a\nbackdoor may experience in real world, thus improves its physical robustness.\nExperimental results on the state-of-the-art face recognition model show that,\ncompared with the backdoor methods that without PTB, the proposed attack method\ncan significantly improve the performance of backdoor attacks in real physical\nworld. Under various complex physical conditions, by injecting only a very\nsmall ratio (0.5%) of backdoor instances, the attack success rate of physical\nbackdoor attacks with the PTB method on VGGFace is 82%, while the attack\nsuccess rate of backdoor attacks without the proposed PTB method is lower than\n11%. Meanwhile, the normal performance of the target DNN model has not been\naffected.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 11:51:14 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 12:50:49 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Xue", "Mingfu", ""], ["He", "Can", ""], ["Sun", "Shichang", ""], ["Wang", "Jian", ""], ["Liu", "Weiqiang", ""]]}, {"id": "2104.07468", "submitter": "Georgios Leontidis", "authors": "Aiden Durrant, Milan Markovic, David Matthews, David May, Jessica\n  Enright and Georgios Leontidis", "title": "The Role of Cross-Silo Federated Learning in Facilitating Data Sharing\n  in the Agri-Food Sector", "comments": "23 pages, 5 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data sharing remains a major hindering factor when it comes to adopting\nemerging AI technologies in general, but particularly in the agri-food sector.\nProtectiveness of data is natural in this setting; data is a precious commodity\nfor data owners, which if used properly can provide them with useful insights\non operations and processes leading to a competitive advantage. Unfortunately,\nnovel AI technologies often require large amounts of training data in order to\nperform well, something that in many scenarios is unrealistic. However, recent\nmachine learning advances, e.g. federated learning and privacy-preserving\ntechnologies, can offer a solution to this issue via providing the\ninfrastructure and underpinning technologies needed to use data from various\nsources to train models without ever sharing the raw data themselves. In this\npaper, we propose a technical solution based on federated learning that uses\ndecentralized data, (i.e. data that are not exchanged or shared but remain with\nthe owners) to develop a cross-silo machine learning model that facilitates\ndata sharing across supply chains. We focus our data sharing proposition on\nimproving production optimization through soybean yield prediction, and provide\npotential use-cases that such methods can assist in other problem settings. Our\nresults demonstrate that our approach not only performs better than each of the\nmodels trained on an individual data source, but also that data sharing in the\nagri-food sector can be enabled via alternatives to data exchange, whilst also\nhelping to adopt emerging machine learning technologies to boost productivity.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 16:00:28 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Durrant", "Aiden", ""], ["Markovic", "Milan", ""], ["Matthews", "David", ""], ["May", "David", ""], ["Enright", "Jessica", ""], ["Leontidis", "Georgios", ""]]}, {"id": "2104.07532", "submitter": "Hesam Hamledari", "authors": "Hesam Hamledari and Martin Fischer", "title": "Measuring the Impact of Blockchain and Smart Contract on Construction\n  Supply Chain Visibility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work assesses the impact of blockchain and smart contract on the\nvisibility of construction supply chain and in the context of payments\n(intersection of cash and product flows). It uses comparative empirical\nexperiments (Charrette Test Method) to draw comparisons between the visibility\nof state-of-practice and blockchain-enabled payment systems in a commercial\nconstruction project. Comparisons were drawn across four levels of granularity.\nThe findings are twofold: 1) blockchain improved information completeness and\ninformation accuracy respectively by an average 216% and 261% compared with the\ndigital state-of-practice solution. The improvements were significantly more\npronounced for inquiries that had higher product, trade, and temporal\ngranularity; 2) blockchain-enabled solution was robust in the face of increased\ngranularity, while the conventional solution experienced 50% and 66.7% decline\nrespectively in completeness and accuracy of information. The paper concludes\nwith a discussion of mechanisms contributing to visibility and technology\nadoption based on business objectives.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 15:35:28 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Hamledari", "Hesam", ""], ["Fischer", "Martin", ""]]}, {"id": "2104.07712", "submitter": "Simon Vrhovec", "authors": "Luka Jelov\\v{c}an, Simon Vrhovec, Damjan Fujs", "title": "Survey about protection motivation on social networking sites:\n  University of Maribor students, 2018", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper reports on a study aiming to explore factors associated with\nprotection motivation of users on social networking sites. The objectives of\nthis study were to determine how trust in internet service provider, trust in\nsocial media provider, trust in government, privacy concerns, fear of\ngovernment intrusions, locus of control, and perceived threats affect\nprotection motivation of users on social networking sites. The study employed a\ncross-sectional research design. A survey was conducted among University of\nMaribor students between October 2018 and January 2019. A total of 289\nrespondents completed the survey providing for N=276 useful responses after\nexcluding poorly completed responses (27.9 percent response rate). The survey\nquestionnaire was developed in English. A Slovenian translation of the survey\nquestionnaire is available.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 18:34:59 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Jelov\u010dan", "Luka", ""], ["Vrhovec", "Simon", ""], ["Fujs", "Damjan", ""]]}, {"id": "2104.07714", "submitter": "Hamid Haj Seyyed Javadi", "authors": "V. Chegeni, H. Haj Seyyed javadi, M. R Moazami Goudarzi, A. Rezakhani", "title": "Providing a hybrid cryptography algorithm for lightweight authentication\n  protocol in RFID with urban traffic usage case", "comments": "10 pages,2 figures", "journal-ref": null, "doi": "10.22042/isecure.2020.226400.535", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Today, the Internet of Things (IoT) is one of the emerging technologies that\nenable the connection and transfer of information through communication\nnetworks. The main idea of the IoT is the widespread presence of objects such\nas mobile devices, sensors, and RFID. With the increase in traffic volume in\nurban areas, the existing intelligent urban traffic management system based on\nIoT can be vital. Therefore, this paper focused on security in urban traffic\nbased on using RFID. In our scheme, RFID tags chose as the purpose of this\narticle. We, in this paper, present a mutual authentication protocol that leads\nto privacy based on hybrid cryptography. Also, an authentication process with\nRFID tags is proposed that can be read at high speed. The protocol has\nattempted to reduce the complexity of computing. At the same time, the proposed\nmethod can withstand attacks such as spoofing of tag and reader, tag tracking,\nand replay attack.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 18:46:55 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Chegeni", "V.", ""], ["javadi", "H. Haj Seyyed", ""], ["Goudarzi", "M. R Moazami", ""], ["Rezakhani", "A.", ""]]}, {"id": "2104.07768", "submitter": "Matthew Tsao", "authors": "Matthew Tsao, Kaidi Yang, Stephen Zoepf, Marco Pavone", "title": "Trust but Verify: Cryptographic Data Privacy for Mobility Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The era of Big Data has brought with it a richer understanding of user\nbehavior through massive data sets, which can help organizations optimize the\nquality of their services. In the context of transportation research, mobility\ndata can provide Municipal Authorities (MA) with insights on how to operate,\nregulate, or improve the transportation network. Mobility data, however, may\ncontain sensitive information about end users and trade secrets of Mobility\nProviders (MP). Due to this data privacy concern, MPs may be reluctant to\ncontribute their datasets to MA. Using ideas from cryptography, we propose an\ninteractive protocol between a MA and a MP in which MA obtains insights from\nmobility data without MP having to reveal its trade secrets or sensitive data\nof its users. This is accomplished in two steps: a commitment step, and a\ncomputation step. In the first step, Merkle commitments and aggregated traffic\nmeasurements are used to generate a cryptographic commitment. In the second\nstep, MP extracts insights from the data and sends them to MA. Using the\ncommitment and zero-knowledge proofs, MA can certify that the information\nreceived from MP is accurate, without needing to directly inspect the mobility\ndata. We also present a differentially private version of the protocol that is\nsuitable for the large query regime. The protocol is verifiable for both MA and\nMP in the sense that dishonesty from one party can be detected by the other.\nThe protocol can be readily extended to the more general setting with multiple\nMPs via secure multi-party computation.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 20:55:54 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 04:46:51 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Tsao", "Matthew", ""], ["Yang", "Kaidi", ""], ["Zoepf", "Stephen", ""], ["Pavone", "Marco", ""]]}, {"id": "2104.07807", "submitter": "Jan Smeddinck", "authors": "Jack Holt, James Nicholson, Jan David Smeddinck", "title": "From Personal Data to Digital Legacy: Exploring Conflicts in the\n  Sharing, Security and Privacy of Post-mortem Data", "comments": "WWW '21", "journal-ref": null, "doi": "10.1145/3442381.3450030", "report-no": null, "categories": "cs.CR cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As digital technologies become more prevalent there is a growing awareness of\nthe importance of good security and privacy practices. The tools and techniques\nused to achieve this are typically designed with the living user in mind, with\nlittle consideration of how they should or will perform after the user has\ndied. We report on two workshops carried out with users of password managers to\nexplore their views on the post-mortem sharing, security and privacy of a range\nof common digital assets. We discuss a post-mortem privacy paradox where users\nrecognise value in planning for their digital legacy, yet avoid actively doing\nso. Importantly, our findings highlight a tension between the use of\nrecommended security tools during life and facilitating appropriate post-mortem\naccess to chosen assets. We offer design recommendations to facilitate and\nencourage digital legacy planning while promoting good security habits during\nlife.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 22:32:39 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Holt", "Jack", ""], ["Nicholson", "James", ""], ["Smeddinck", "Jan David", ""]]}, {"id": "2104.07815", "submitter": "Trung Dang", "authors": "Trung Dang, Om Thakkar, Swaroop Ramaswamy, Rajiv Mathews, Peter Chin,\n  Fran\\c{c}oise Beaufays", "title": "A Method to Reveal Speaker Identity in Distributed ASR Training, and How\n  to Counter It", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  End-to-end Automatic Speech Recognition (ASR) models are commonly trained\nover spoken utterances using optimization methods like Stochastic Gradient\nDescent (SGD). In distributed settings like Federated Learning, model training\nrequires transmission of gradients over a network. In this work, we design the\nfirst method for revealing the identity of the speaker of a training utterance\nwith access only to a gradient. We propose Hessian-Free Gradients Matching, an\ninput reconstruction technique that operates without second derivatives of the\nloss function (required in prior works), which can be expensive to compute. We\nshow the effectiveness of our method using the DeepSpeech model architecture,\ndemonstrating that it is possible to reveal the speaker's identity with 34%\ntop-1 accuracy (51% top-5 accuracy) on the LibriSpeech dataset. Further, we\nstudy the effect of two well-known techniques, Differentially Private SGD and\nDropout, on the success of our method. We show that a dropout rate of 0.2 can\nreduce the speaker identity accuracy to 0% top-1 (0.5% top-5).\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 23:15:12 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Dang", "Trung", ""], ["Thakkar", "Om", ""], ["Ramaswamy", "Swaroop", ""], ["Mathews", "Rajiv", ""], ["Chin", "Peter", ""], ["Beaufays", "Fran\u00e7oise", ""]]}, {"id": "2104.07899", "submitter": "Francisco J. Rodriguez Lera", "authors": "David Fern\\'andez Gonz\\'alez, Francisco Javier Rodr\\'iguez Lera,\n  Gonzalo Esteban and Camino Fern\\'andez Llamas", "title": "SecDocker: Hardening the Continuous Integration Workflow", "comments": "Preprint: 15 pages, 5 figures, 2 tables. Public repository:\n  https://github.com/uleroboticsgroup/Secdocker", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Current Continuous Integration processes face significant intrinsic\ncybersecurity challenges. The idea is not only to solve and test formal or\nregulatory security requirements of source code but also to adhere to the same\nprinciples to the CI pipeline itself. This paper presents an overview of\ncurrent security issues in CI workflow. It designs, develops, and deploys a new\ntool for the secure deployment of a container-based CI pipeline flow without\nslowing down release cycles. The tool, called \\SD for its Docker-based\napproach, is publicly available in GitHub. It implements a transparent\napplication firewall based on a configuration mechanism avoiding issues in the\nCI workflow associated with intended or unintended container configurations.\nIntegrated with other DevOps Engineers tools, it provides feedback from only\nthose scenarios that match specific patterns, addressing future container\nsecurity issues.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 05:49:08 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Gonz\u00e1lez", "David Fern\u00e1ndez", ""], ["Lera", "Francisco Javier Rodr\u00edguez", ""], ["Esteban", "Gonzalo", ""], ["Llamas", "Camino Fern\u00e1ndez", ""]]}, {"id": "2104.07938", "submitter": "Jens Rauch", "authors": "Jens Rauch, Iyiola E. Olatunji and Megha Khosla", "title": "Achieving differential privacy for $k$-nearest neighbors based outlier\n  detection by data partitioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When applying outlier detection in settings where data is sensitive,\nmechanisms which guarantee the privacy of the underlying data are needed. The\n$k$-nearest neighbors ($k$-NN) algorithm is a simple and one of the most\neffective methods for outlier detection. So far, there have been no attempts\nmade to develop a differentially private ($\\epsilon$-DP) approach for $k$-NN\nbased outlier detection. Existing approaches often relax the notion of\n$\\epsilon$-DP and employ other methods than $k$-NN. We propose a method for\n$k$-NN based outlier detection by separating the procedure into a fitting step\non reference inlier data and then apply the outlier classifier to new data. We\nachieve $\\epsilon$-DP for both the fitting algorithm and the outlier classifier\nwith respect to the reference data by partitioning the dataset into a uniform\ngrid, which yields low global sensitivity. Our approach yields nearly optimal\nperformance on real-world data with varying dimensions when compared to the\nnon-private versions of $k$-NN.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 07:35:26 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Rauch", "Jens", ""], ["Olatunji", "Iyiola E.", ""], ["Khosla", "Megha", ""]]}, {"id": "2104.07949", "submitter": "Daniel Reijsbergen", "authors": "Daniel Reijsbergen, Zheng Yang, Aung Maw, Tien Tuan Anh Dinh, Jianying\n  Zhou", "title": "Transparent Electricity Pricing with Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart grids leverage data from smart meters to improve operations management\nand to achieve cost reductions. The fine-grained meter data also enable pricing\nschemes that simultaneously benefit electricity retailers and users. Our goal\nis to design a practical dynamic pricing protocol for smart grids in which the\nrate charged by a retailer depends on the total demand among its users.\nRealizing this goal is challenging because neither the retailer nor the users\nare trusted. The first challenge is to design a pricing scheme that\nincentivizes consumption behavior that leads to lower costs for both the users\nand the retailer. The second challenge is to prevent the retailer from\ntampering with the data, for example, by claiming that the total consumption is\nmuch higher than its real value. The third challenge is data privacy, that is,\nhow to hide the meter data from adversarial users. To address these challenges,\nwe propose a scheme in which peak rates are charged if either the total or the\nindividual consumptions exceed some thresholds. We formally define a\nprivacy-preserving transparent pricing scheme (PPTP) that allows honest users\nto detect tampering at the retailer while ensuring data privacy. We present two\ninstantiations of PPTP, and prove their security. Both protocols use secure\ncommitments and zero-knowledge proofs. We implement and evaluate the protocols\non server and edge hardware, demonstrating that PPTP has practical performance\nat scale.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 07:56:27 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Reijsbergen", "Daniel", ""], ["Yang", "Zheng", ""], ["Maw", "Aung", ""], ["Dinh", "Tien Tuan Anh", ""], ["Zhou", "Jianying", ""]]}, {"id": "2104.08031", "submitter": "Daniel Kelly", "authors": "Daniel Kelly, Frank G. Glavin, Enda Barrett", "title": "Denial of Wallet -- Defining a Looming Threat to Serverless Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Serverless computing is the latest paradigm in cloud computing, offering a\nframework for the development of event driven, pay-as-you-go functions in a\nhighly scalable environment. While these traits offer a powerful new\ndevelopment paradigm, they have also given rise to a new form of cyber-attack\nknown as Denial of Wallet (forced financial exhaustion). In this work, we\ndefine and identify the threat of Denial of Wallet and its potential attack\npatterns. Also, we demonstrate how this new form of attack can potentially\ncircumvent existing mitigation systems developed for a similar style of attack,\nDenial of Service. Our goal is twofold. Firstly, we will provide a concise and\ninformative overview of this emerging attack paradigm. Secondly, we propose\nthis paper as a starting point to enable researchers and service providers to\ncreate effective mitigation strategies. We include some simulated experiments\nto highlight the potential financial damage that such attacks can cause and the\ncreation of an isolated test bed for continued safe research on these attacks.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 11:00:31 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 13:33:00 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Kelly", "Daniel", ""], ["Glavin", "Frank G.", ""], ["Barrett", "Enda", ""]]}, {"id": "2104.08044", "submitter": "Peilun Wu", "authors": "Peilun Wu, Fan Yan, Hui Guo", "title": "Holmes: An Efficient and Lightweight Semantic Based Anomalous Email\n  Detector", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Email threat is a serious issue for enterprise security, which consists of\nvarious malicious scenarios, such as phishing, fraud, blackmail and\nmalvertisement. Traditional anti-spam gateway commonly requires to maintain a\ngreylist to filter out unexpected emails based on suspicious vocabularies\nexisted in the mail subject and content. However, the signature-based approach\ncannot effectively discover novel and unknown suspicious emails that utilize\nvarious hot topics at present, such as COVID-19 and US election. To address the\nproblem, in this paper, we present Holmes, an efficient and lightweight\nsemantic based engine for anomalous email detection. Holmes can convert each\nevent log of email to a sentence through word embedding then extract\ninteresting items among them by novelty detection. Based on our observations,\nwe claim that, in an enterprise environment, there is a stable relation between\nsenders and receivers, but suspicious emails are commonly from unusual sources,\nwhich can be detected through the rareness selection. We evaluate the\nperformance of Holmes in a real-world enterprise environment, in which it sends\nand receives around 5,000 emails each day. As a result, Holmes can achieve a\nhigh detection rate (output around 200 suspicious emails per day) and maintain\na low false alarm rate for anomaly detection.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 11:42:10 GMT"}, {"version": "v2", "created": "Sun, 25 Apr 2021 09:23:18 GMT"}, {"version": "v3", "created": "Fri, 7 May 2021 06:47:56 GMT"}, {"version": "v4", "created": "Wed, 12 May 2021 07:24:49 GMT"}, {"version": "v5", "created": "Wed, 19 May 2021 06:51:54 GMT"}, {"version": "v6", "created": "Sat, 29 May 2021 13:35:32 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wu", "Peilun", ""], ["Yan", "Fan", ""], ["Guo", "Hui", ""]]}, {"id": "2104.08080", "submitter": "Iqbal H. Sarker", "authors": "Iqbal H. Sarker", "title": "CyberLearning: Effectiveness Analysis of Machine Learning Security\n  Modeling to Detect Cyber-Anomalies and Multi-Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Detecting cyber-anomalies and attacks are becoming a rising concern these\ndays in the domain of cybersecurity. The knowledge of artificial intelligence,\nparticularly, the machine learning techniques can be used to tackle these\nissues. However, the effectiveness of a learning-based security model may vary\ndepending on the security features and the data characteristics. In this paper,\nwe present \"CyberLearning\", a machine learning-based cybersecurity modeling\nwith correlated-feature selection, and a comprehensive empirical analysis on\nthe effectiveness of various machine learning based security models. In our\nCyberLearning modeling, we take into account a binary classification model for\ndetecting anomalies, and multi-class classification model for various types of\ncyber-attacks. To build the security model, we first employ the popular ten\nmachine learning classification techniques, such as naive Bayes, Logistic\nregression, Stochastic gradient descent, K-nearest neighbors, Support vector\nmachine, Decision Tree, Random Forest, Adaptive Boosting, eXtreme Gradient\nBoosting, as well as Linear discriminant analysis. We then present the\nartificial neural network-based security model considering multiple hidden\nlayers. The effectiveness of these learning-based security models is examined\nby conducting a range of experiments utilizing the two most popular security\ndatasets, UNSW-NB15 and NSL-KDD. Overall, this paper aims to serve as a\nreference point for data-driven security modeling through our experimental\nanalysis and findings in the context of cybersecurity.\n", "versions": [{"version": "v1", "created": "Sun, 28 Mar 2021 18:47:16 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Sarker", "Iqbal H.", ""]]}, {"id": "2104.08308", "submitter": "Zimin Chen", "authors": "Zimin Chen, Steve Kommrusch and Martin Monperrus", "title": "Neural Transfer Learning for Repairing Security Vulnerabilities in C\n  Code", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we address the problem of automatic repair of software\nvulnerabilities with deep learning. The major problem with data-driven\nvulnerability repair is that the few existing datasets of known confirmed\nvulnerabilities consist of only a few thousand examples. However, training a\ndeep learning model often requires hundreds of thousands of examples. In this\nwork, we leverage the intuition that the bug fixing task and the vulnerability\nfixing task are related, and the knowledge learned from bug fixes can be\ntransferred to fixing vulnerabilities. In the machine learning community, this\ntechnique is called transfer learning. In this paper, we propose an approach\nfor repairing security vulnerabilities named VRepair which is based on transfer\nlearning. VRepair is first trained on a large bug fix corpus, and is then tuned\non a vulnerability fix dataset, which is an order of magnitudes smaller. In our\nexperiments, we show that a model trained only on a bug fix corpus can already\nfix some vulnerabilities. Then, we demonstrate that transfer learning improves\nthe ability to repair vulnerable C functions. In the end, we present evidence\nthat transfer learning produces more stable and superior neural models for\nvulnerability repair.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 18:32:51 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Chen", "Zimin", ""], ["Kommrusch", "Steve", ""], ["Monperrus", "Martin", ""]]}, {"id": "2104.08323", "submitter": "David Stutz", "authors": "David Stutz, Nandhini Chandramoorthy, Matthias Hein, Bernt Schiele", "title": "Random and Adversarial Bit Error Robustness: Energy-Efficient and Secure\n  DNN Accelerators", "comments": "arXiv admin note: substantial text overlap with arXiv:2006.13977", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network (DNN) accelerators received considerable attention in\nrecent years due to the potential to save energy compared to mainstream\nhardware. Low-voltage operation of DNN accelerators allows to further reduce\nenergy consumption significantly, however, causes bit-level failures in the\nmemory storing the quantized DNN weights. Furthermore, DNN accelerators have\nbeen shown to be vulnerable to adversarial attacks on voltage controllers or\nindividual bits. In this paper, we show that a combination of robust\nfixed-point quantization, weight clipping, as well as random bit error training\n(RandBET) or adversarial bit error training (AdvBET) improves robustness\nagainst random or adversarial bit errors in quantized DNN weights\nsignificantly. This leads not only to high energy savings for low-voltage\noperation as well as low-precision quantization, but also improves security of\nDNN accelerators. Our approach generalizes across operating voltages and\naccelerators, as demonstrated on bit errors from profiled SRAM arrays, and\nachieves robustness against both targeted and untargeted bit-level attacks.\nWithout losing more than 0.8%/2% in test accuracy, we can reduce energy\nconsumption on CIFAR10 by 20%/30% for 8/4-bit quantization using RandBET.\nAllowing up to 320 adversarial bit errors, AdvBET reduces test error from above\n90% (chance level) to 26.22% on CIFAR10.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 19:11:14 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Stutz", "David", ""], ["Chandramoorthy", "Nandhini", ""], ["Hein", "Matthias", ""], ["Schiele", "Bernt", ""]]}, {"id": "2104.08382", "submitter": "Arjun Nitin Bhagoji", "authors": "Arjun Nitin Bhagoji, Daniel Cullina, Vikash Sehwag, Prateek Mittal", "title": "Lower Bounds on Cross-Entropy Loss in the Presence of Test-time\n  Adversaries", "comments": "16 pages, 12 figures; Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the fundamental limits of robust supervised learning has\nemerged as a problem of immense interest, from both practical and theoretical\nstandpoints. In particular, it is critical to determine classifier-agnostic\nbounds on the training loss to establish when learning is possible. In this\npaper, we determine optimal lower bounds on the cross-entropy loss in the\npresence of test-time adversaries, along with the corresponding optimal\nclassification outputs. Our formulation of the bound as a solution to an\noptimization problem is general enough to encompass any loss function depending\non soft classifier outputs. We also propose and provide a proof of correctness\nfor a bespoke algorithm to compute this lower bound efficiently, allowing us to\ndetermine lower bounds for multiple practical datasets of interest. We use our\nlower bounds as a diagnostic tool to determine the effectiveness of current\nrobust training methods and find a gap from optimality at larger budgets.\nFinally, we investigate the possibility of using of optimal classification\noutputs as soft labels to empirically improve robust training.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 21:41:28 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 20:47:26 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Bhagoji", "Arjun Nitin", ""], ["Cullina", "Daniel", ""], ["Sehwag", "Vikash", ""], ["Mittal", "Prateek", ""]]}, {"id": "2104.08456", "submitter": "Jie Jin", "authors": "Shanqing Yu, Jie Jin, Yunyi Xie, Jie Shen and Qi Xuan", "title": "Ponzi Scheme Detection in EthereumTransaction Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of blockchain, an increasing number of users have been\nattracted and many implementations have been refreshed in different fields.\nEspecially in the cryptocurrency investment field, blockchain technology has\nshown vigorous vitality. However, along with the rise of online business,\nnumerous fraudulent activities, e.g., money laundering, bribery, phishing, and\nothers, emerge as the main threat to trading security. Due to the openness of\nEthereum, researchers can easily access Ethereum transaction records and smart\ncontracts, which brings unprecedented opportunities for Ethereum scams\ndetection and analysis. This paper mainly focuses on the Ponzi scheme, a\ntypical fraud, which has caused large property damage to the users in Ethereum.\nBy verifying Ponzi contracts to maintain Ethereum's sustainable development, we\nmodel Ponzi scheme identification and detection as a node classification task.\nIn this paper, we first collect target contracts' transactions to establish\ntransaction networks and propose a detecting model based on graph convolutional\nnetwork (GCN) to precisely distinguishPonzi contracts. Experiments on different\nreal-world Ethereum datasets demonstrate that our proposed model has promising\nresults compared with general machine learning methods to detect Ponzi schemes.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 05:25:50 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Yu", "Shanqing", ""], ["Jin", "Jie", ""], ["Xie", "Yunyi", ""], ["Shen", "Jie", ""], ["Xuan", "Qi", ""]]}, {"id": "2104.08460", "submitter": "Kosuke Toda", "authors": "Kosuke Toda, Naomi Kuze, and Toshimitsu Ushio", "title": "Modeling and control of decision-making of miners in blockchain", "comments": "7 pages, 5 figures, submitted to the journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To maintain blockchain-based services with ensuring its security, it is an\nimportant issue how to decide a mining reward so that the number of miners\nparticipating in the mining increases. We propose a dynamical model of\ndecision-making for miners using an evolutionary game approach and analyze the\nstability of equilibrium points of the proposed model. The proposed model is\ndescribed by the 1st-order differential equation. So, it is simple but its\ntheoretical analysis gives an insight into the characteristics of the\ndecision-making. Through the analysis of the equilibrium points, we show the\ntranscritical bifurcations and hysteresis phenomena of the equilibrium points.\nWe also design a controller that determines the mining reward based on the\nnumber of participating miners to stabilize the state that all miners\nparticipate in the mining. Numerical simulation shows that there is a trade-off\nin the choice of the design parameters.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 05:52:12 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Toda", "Kosuke", ""], ["Kuze", "Naomi", ""], ["Ushio", "Toshimitsu", ""]]}, {"id": "2104.08494", "submitter": "Hitesh Tewari Dr", "authors": "Raman Singh, Ark Nandan Singh Chauhan and Hitesh Tewari", "title": "Blockchain-Enabled End-to-End Encryption for Instant Messaging\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the era of social media and messaging applications, people are becoming\nincreasingly aware of data privacy issues associated with such apps. Major\nmessaging applications are moving towards end-to-end encryption (E2EE) to give\ntheir users the privacy they are demanding. However the current security\nmechanisms employed by different service providers are not unfeigned E2EE\nimplementations, and are blended with many vulnerabilities. In the present\nscenario, the major part of the E2EE mechanism is controlled by the service\nprovider's servers, and the decryption keys are stored by them in case of\nbackup restoration. These shortcomings diminish the user's confidence in the\nprivacy of their data while using these apps. A public Key infrastructure (PKI)\nmechanism can be used to circumvent some of these issues, but it comes with\nhigh monetary costs, which makes it impossible to roll out for millions of\nusers. The paper proposes a blockchain-based E2EE framework that can mitigate\nthe contemporary vulnerabilities in messaging applications. The user's device\ngenerates the public/private key pair during application installation, and asks\nits mobile network operator (MNO) to issue a digital certificate and store it\non the blockchain. A user can fetch a certificate for another user from the\nchat server and communicate securely with them using a ratchet forward\nencryption mechanism.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 09:34:02 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Singh", "Raman", ""], ["Chauhan", "Ark Nandan Singh", ""], ["Tewari", "Hitesh", ""]]}, {"id": "2104.08495", "submitter": "Hitesh Tewari", "authors": "Raman Singh and Hitesh Tewari", "title": "Blockchain-Enabled NextGen Service Architecture for Mobile Internet\n  Offload", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The amalgamation of different generations of mobile cellular networks around\nthe globe has resulted in diverse data speed experiences for end users. At\npresent there are no defined mechanisms in place for a subscriber of one mobile\nnetwork operator (MNO) to use the services of a WiFi provider. Cellular and\nData Service providers also have no standardized procedures to securely\ninteract with each other, and to allow their subscribers to use third party\nservices on a pay-as-you-go basis. This paper proposes a blockchain-based\noffloading framework that allows a subscriber of a mobile operator to\ntemporarily use another MNO or WiFi provider's higher speed network. Smart\ncontracts allow diverse entities such as MNOs, Brokers and WiFi Providers to\nautomatically execute mutual agreements to enable the utilization of third\nparty infrastructure in a secure and controlled manner. To test the proposed\nframework, the offloading of a subscriber from 3G/4G/4G-LTE/5G networks to a\nfixed broadband WiFi network was carried out and the results analyzed. The\noffloading framework was implemented using the ns-3 network simulator, and the\nEthereum blockchain smart contract features were used for the settlement of\ninvoices.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 09:34:27 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Singh", "Raman", ""], ["Tewari", "Hitesh", ""]]}, {"id": "2104.08559", "submitter": "Yujie Cui", "authors": "Yujie Cui, Xu Cheng", "title": "Abusing Cache Line Dirty States to Leak Information in Commercial\n  Processors", "comments": "13 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Caches have been used to construct various types of covert and side channels\nto leak information. Most of the previous cache channels exploit the timing\ndifference between cache hits and cache misses. However, we introduce a new and\nbroader classification of cache covert channel attacks: Hit+Miss, Hit+Hit,\nMiss+Miss. We highlight that cache misses (or cache hits) in different states\nmay have more significant time differences, which can be used as timing\nchannels. Based on the classification, We propose a new type of stable and\nstealthy Miss+Miss cache channel.\n  The write-back caches are widely deployed in modern processors. This paper\npresents in detail how to use replacement latency difference to construct\ntiming-based channels (calles WB channel) to leak information in the write-back\ncache: any modification to a cache line by a sender will set the cache line to\nthe dirty state, and the receiver can observe this through measuring the\nlatency to replace this cache set. We also demonstrate how senders could\nexploit a different number of dirty cache lines in a cache set to improve\ntransmission bandwidth with symbols encoding multiple bits. The peak\ntransmission bandwidths of the WB channels in commercial systems can vary\nbetween 1300 to 4400 Kbps per cache set in the hyper-threaded setting without\nshared memory between the sender and the receiver. Different from most existing\ncache channels that always target specific memory addresses, the new WB\nchannels focus on the cache set and cache line states, making the channel hard\nto be disturbed by other processes on the core and can still work in the cache\nusing a random replacement policy. We also analyzed the stealthiness of WB\nchannels from the perspective of the number of cache loads and cache miss\nrates. Further, This paper discusses and evaluates possible defenses. The paper\nfinishes by discussing various forms of side-channel attacks.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 14:46:50 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Cui", "Yujie", ""], ["Cheng", "Xu", ""]]}, {"id": "2104.08593", "submitter": "Yuval Yarom", "authors": "Ileana Buhan and Lejla Batina and Yuval Yarom and Patrick Schaumont", "title": "SoK: Design Tools for Side-Channel-Aware Implementations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Side-channel attacks that leak sensitive information through a computing\ndevice's interaction with its physical environment have proven to be a severe\nthreat to devices' security, particularly when adversaries have unfettered\nphysical access to the device. Traditional approaches for leakage detection\nmeasure the physical properties of the device. Hence, they cannot be used\nduring the design process and fail to provide root cause analysis. An\nalternative approach that is gaining traction is to automate leakage detection\nby modeling the device. The demand to understand the scope, benefits, and\nlimitations of the proposed tools intensifies with the increase in the number\nof proposals.\n  In this SoK, we classify approaches to automated leakage detection based on\nthe model's source of truth. We classify the existing tools on two main\nparameters: whether the model includes measurements from a concrete device and\nthe abstraction level of the device specification used for constructing the\nmodel. We survey the proposed tools to determine the current knowledge level\nacross the domain and identify open problems. In particular, we highlight the\nabsence of evaluation methodologies and metrics that would compare proposals'\neffectiveness from across the domain. We believe that our results help\npractitioners who want to use automated leakage detection and researchers\ninterested in advancing the knowledge and improving automated leakage\ndetection.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 16:34:22 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 04:04:28 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Buhan", "Ileana", ""], ["Batina", "Lejla", ""], ["Yarom", "Yuval", ""], ["Schaumont", "Patrick", ""]]}, {"id": "2104.08618", "submitter": "Kiavash Satvat", "authors": "Kiavash Satvat, Rigel Gjomemo and V.N. Venkatakrishnan", "title": "EXTRACTOR: Extracting Attack Behavior from Threat Reports", "comments": "6th IEEE European Symposium on Security and Privacy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The knowledge on attacks contained in Cyber Threat Intelligence (CTI) reports\nis very important to effectively identify and quickly respond to cyber threats.\nHowever, this knowledge is often embedded in large amounts of text, and\ntherefore difficult to use effectively. To address this challenge, we propose a\nnovel approach and tool called EXTRACTOR that allows precise automatic\nextraction of concise attack behaviors from CTI reports. EXTRACTOR makes no\nstrong assumptions about the text and is capable of extracting attack behaviors\nas provenance graphs from unstructured text. We evaluate EXTRACTOR using\nreal-world incident reports from various sources as well as reports of DARPA\nadversarial engagements that involve several attack campaigns on various OS\nplatforms of Windows, Linux, and FreeBSD. Our evaluation results show that\nEXTRACTOR can extract concise provenance graphs from CTI reports and show that\nthese graphs can successfully be used by cyber-analytics tools in\nthreat-hunting.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 18:51:00 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Satvat", "Kiavash", ""], ["Gjomemo", "Rigel", ""], ["Venkatakrishnan", "V. N.", ""]]}, {"id": "2104.08638", "submitter": "Priyanka Bose", "authors": "Priyanka Bose, Dipanjan Das, Yanju Chen, Yu Feng, Christopher Kruegel,\n  Giovanni Vigna", "title": "SAILFISH: Vetting Smart Contract State-Inconsistency Bugs in Seconds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents SAILFISH, a scalable system for automatically finding\nstate-inconsistency bugs in smart contracts. To make the analysis tractable, we\nintroduce a hybrid approach that includes (i) a light-weight exploration phase\nthat dramatically reduces the number of instructions to analyze, and (ii) a\nprecise refinement phase based on symbolic evaluation guided by our novel\nvalue-summary analysis, which generates extra constraints to over-approximate\nthe side effects of whole-program execution, thereby ensuring the precision of\nthe symbolic evaluation. We developed a prototype of SAILFISH and evaluated its\nability to detect two state-inconsistency flaws, viz., reentrancy and\ntransaction order dependence (TOD) in Ethereum smart contracts. Further, we\npresent detection rules for other kinds of smart contract flaws that SAILFISH\ncan be extended to detect.\n  Our experiments demonstrate the efficiency of our hybrid approach as well as\nthe benefit of the value summary analysis. In particular, we show that S\nSAILFISH outperforms five state-of-the-art smart contract analyzers (SECURITY,\nMYTHRIL, OYENTE, SEREUM and VANDAL ) in terms of performance, and precision. In\ntotal, SAILFISH discovered 47 previously unknown vulnerable smart contracts out\nof 89,853 smart contracts from ETHERSCAN .\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 20:21:07 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Bose", "Priyanka", ""], ["Das", "Dipanjan", ""], ["Chen", "Yanju", ""], ["Feng", "Yu", ""], ["Kruegel", "Christopher", ""], ["Vigna", "Giovanni", ""]]}, {"id": "2104.08651", "submitter": "Weizhao Jin", "authors": "Weizhao Jin, Xiaoyu Ji, Ruiwen He, Zhou Zhuang, Wenyuan Xu and Yuan\n  Tian", "title": "SMS Goes Nuclear: Fortifying SMS-Based MFA in Online Account Ecosystem", "comments": "11 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of online services, the number of online accounts\nproliferates. The security of a single user account no longer depends merely on\nits own service provider but also the accounts on other service platforms(We\nrefer to this online account environment as Online Account Ecosystem). In this\npaper, we first uncover the vulnerability of Online Account Ecosystem, which\nstems from the defective multi-factor authentication (MFA), specifically the\nones with SMS-based verification, and dependencies among accounts on different\nplatforms. We propose Chain Reaction Attack that exploits the weakest point in\nOnline Account Ecosystem and can ultimately compromise the most secure\nplatform. Furthermore, we design and implement ActFort, a systematic approach\nto detect the vulnerability of Online Account Ecosystem by analyzing the\nauthentication credential factors and sensitive personal information as well as\nevaluating the dependency relationships among online accounts. We evaluate our\nsystem on hundreds of representative online services listed in Alexa in\ndiversified fields. Based on the analysis from ActFort, we provide several\npragmatic insights into the current Online Account Ecosystem and propose\nseveral feasible countermeasures including the online account exposed\ninformation protection mechanism and the built-in authentication to fortify the\nsecurity of Online Account Ecosystem.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 22:20:16 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 20:44:26 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Jin", "Weizhao", ""], ["Ji", "Xiaoyu", ""], ["He", "Ruiwen", ""], ["Zhuang", "Zhou", ""], ["Xu", "Wenyuan", ""], ["Tian", "Yuan", ""]]}, {"id": "2104.08690", "submitter": "Yue Gao", "authors": "Yue Gao, Kassem Fawaz", "title": "Scale-Adv: A Joint Attack on Image-Scaling and Machine Learning\n  Classifiers", "comments": "32 pages, 16 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  As real-world images come in varying sizes, the machine learning model is\npart of a larger system that includes an upstream image scaling algorithm. In\nthis system, the model and the scaling algorithm have become attractive targets\nfor numerous attacks, such as adversarial examples and the recent image-scaling\nattack. In response to these attacks, researchers have developed defense\napproaches that are tailored to attacks at each processing stage. As these\ndefenses are developed in isolation, their underlying assumptions become\nquestionable when viewing them from the perspective of an end-to-end machine\nlearning system. In this paper, we investigate whether defenses against scaling\nattacks and adversarial examples are still robust when an adversary targets the\nentire machine learning system. In particular, we propose Scale-Adv, a novel\nattack framework that jointly targets the image-scaling and classification\nstages. This framework packs several novel techniques, including novel\nrepresentations of the scaling defenses. It also defines two integrations that\nallow for attacking the machine learning system pipeline in the white-box and\nblack-box settings. Based on this framework, we evaluate cutting-edge defenses\nat each processing stage. For scaling attacks, we show that Scale-Adv can evade\nfour out of five state-of-the-art defenses by incorporating adversarial\nexamples. For classification, we show that Scale-Adv can significantly improve\nthe performance of machine learning attacks by leveraging weaknesses in the\nscaling algorithm. We empirically observe that Scale-Adv can produce\nadversarial examples with less perturbation and higher confidence than vanilla\nblack-box and white-box attacks. We further demonstrate the transferability of\nScale-Adv on a commercial online API.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 03:19:15 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Gao", "Yue", ""], ["Fawaz", "Kassem", ""]]}, {"id": "2104.08767", "submitter": "Jinhuan Wang", "authors": "Jinhuan Wang and Pengtao Chen and Shanqing Yu and Qi Xuan", "title": "TSGN: Transaction Subgraph Networks for Identifying Ethereum Phishing\n  Accounts", "comments": "14 pages, 2 fihures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain technology and, in particular, blockchain-based transaction offers\nus information that has never been seen before in the financial world. In\ncontrast to fiat currencies, transactions through virtual currencies like\nBitcoin are completely public. And these transactions of cryptocurrencies are\npermanently recorded on Blockchain and are available at any time. Therefore,\nthis allows us to build transaction networks (TN) to analyze illegal\nphenomenons such as phishing scams in blockchain from a network perspective. In\nthis paper, we propose a Transaction SubGraph Network (TSGN) based\nclassification model to identify phishing accounts in Ethereum. Firstly we\nextract transaction subgraphs for each address and then expand these subgraphs\ninto corresponding TSGNs based on the different mapping mechanisms. We find\nthat TSGNs can provide more potential information to benefit the identification\nof phishing accounts. Moreover, Directed-TSGNs, by introducing direction\nattributes, can retain the transaction flow information that captures the\nsignificant topological pattern of phishing scams. By comparing with the TSGN,\nDirected-TSGN indeed has much lower time complexity, benefiting the graph\nrepresentation learning. Experimental results demonstrate that, combined with\nnetwork representation algorithms, the TSGN model can capture more features to\nenhance the classification algorithm and improve phishing nodes' identification\naccuracy in the Ethereum networks.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 08:12:51 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 13:48:30 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Wang", "Jinhuan", ""], ["Chen", "Pengtao", ""], ["Yu", "Shanqing", ""], ["Xuan", "Qi", ""]]}, {"id": "2104.08776", "submitter": "Hossein Hosseini", "authors": "Hossein Hosseini, Hyunsin Park, Sungrack Yun, Christos Louizos, Joseph\n  Soriaga, Max Welling", "title": "Federated Learning of User Verification Models Without Sharing\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of training User Verification (UV) models in\nfederated setting, where each user has access to the data of only one class and\nuser embeddings cannot be shared with the server or other users. To address\nthis problem, we propose Federated User Verification (FedUV), a framework in\nwhich users jointly learn a set of vectors and maximize the correlation of\ntheir instance embeddings with a secret linear combination of those vectors. We\nshow that choosing the linear combinations from the codewords of an\nerror-correcting code allows users to collaboratively train the model without\nrevealing their embedding vectors. We present the experimental results for user\nverification with voice, face, and handwriting data and show that FedUV is on\npar with existing approaches, while not sharing the embeddings with other users\nor the server.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 08:51:39 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 17:32:41 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Hosseini", "Hossein", ""], ["Park", "Hyunsin", ""], ["Yun", "Sungrack", ""], ["Louizos", "Christos", ""], ["Soriaga", "Joseph", ""], ["Welling", "Max", ""]]}, {"id": "2104.08820", "submitter": "Eliad Tsfadia", "authors": "Niv Buchbinder, Iftach Haitner, Nissan Levi, Eliad Tsfadia", "title": "Fair Coin Flipping: Tighter Analysis and the Many-Party Case", "comments": "Published in SODA 2017", "journal-ref": null, "doi": "10.1137/1.9781611974782.170", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a multi-party fair coin-flipping protocol, the parties output a common\n(close to) unbiased bit, even when some adversarial parties try to bias the\noutput. In this work we focus on the case of an arbitrary number of corrupted\nparties. Cleve [STOC 1986] has shown that in any such $m$-round coin-flipping\nprotocol, the corrupted parties can bias the honest parties' common output bit\nby $\\Theta(1/m)$. For more than two decades, the best known coin-flipping\nprotocol was the one of Awerbuch et al. [Manuscript 1985], who presented a\n$t$-party, $m$-round protocol with bias $\\Theta(t/\\sqrt{m})$. This was changed\nby the breakthrough result of Moran et al. [TCC 2009], who constructed an\n$m$-round, two-party coin-flipping protocol with optimal bias $\\Theta(1/m)$.\nHaitner and Tsfadia [STOC 2014] constructed an $m$-round, three-party\ncoin-flipping protocol with bias $O(\\log^3m / m)$. Still for the case of more\nthan three parties, the best known protocol remained the\n$\\Theta(t/\\sqrt{m})$-bias protocol of Awerbuch et al.\n  We make a step towards eliminating the above gap, presenting a $t$-party,\n$m$-round coin-flipping protocol, with bias $O(\\frac{t^4 \\cdot 2^t \\cdot\n\\sqrt{\\log m}}{m^{1/2+1/\\left(2^{t-1}-2\\right)}})$ for any $t\\le \\tfrac12\n\\log\\log m$. This improves upon the $\\Theta(t/\\sqrt{m})$-bias protocol of\nAwerbuch et al., and in particular, for $t\\in O(1)$ it is an $1/m^{\\frac12 +\n\\Theta(1)}$-bias protocol. For the three-party case, it is an $O(\\sqrt{\\log\nm}/m)$-bias protocol, improving over the $O(\\log^3m / m)$-bias protocol of\nHaitner and Tsfadia.\n  Our protocol generalizes that of Haitner and Tsfadia, by presenting an\nappropriate recovery protocol for the remaining parties to interact in, in the\ncase that some parties abort or are caught cheating. We prove the fairness of\nthe new protocol by presenting a new paradigm for analyzing fairness of\ncoin-flipping protocols.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 11:25:26 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Buchbinder", "Niv", ""], ["Haitner", "Iftach", ""], ["Levi", "Nissan", ""], ["Tsfadia", "Eliad", ""]]}, {"id": "2104.08994", "submitter": "Ashutosh Dutta", "authors": "Ashutosh Dutta, Ehab Al-Shaer, and Samrat Chatterjee", "title": "Constraints Satisfiability Driven Reinforcement Learning for Autonomous\n  Cyber Defense", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.GT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the increasing system complexity and attack sophistication, the\nnecessity of autonomous cyber defense becomes vivid for cyber and\ncyber-physical systems (CPSs). Many existing frameworks in the current\nstate-of-the-art either rely on static models with unrealistic assumptions, or\nfail to satisfy the system safety and security requirements. In this paper, we\npresent a new hybrid autonomous agent architecture that aims to optimize and\nverify defense policies of reinforcement learning (RL) by incorporating\nconstraints verification (using satisfiability modulo theory (SMT)) into the\nagent's decision loop. The incorporation of SMT does not only ensure the\nsatisfiability of safety and security requirements, but also provides constant\nfeedback to steer the RL decision-making toward safe and effective actions.\nThis approach is critically needed for CPSs that exhibit high risk due to\nsafety or security violations. Our evaluation of the presented approach in a\nsimulated CPS environment shows that the agent learns the optimal policy fast\nand defeats diversified attack strategies in 99\\% cases.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 01:08:30 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Dutta", "Ashutosh", ""], ["Al-Shaer", "Ehab", ""], ["Chatterjee", "Samrat", ""]]}, {"id": "2104.09020", "submitter": "Stephen MacDonell", "authors": "Awais Tanveer, Roopak Sinha and Stephen G. MacDonell", "title": "On Design-time Security in IEC 61499 Systems: Conceptualisation,\n  Implementation, and Feasibility", "comments": "Conference paper, 8 pages, 11 figures, 1 table", "journal-ref": "Proceedings of the 16th International Conference on Industrial\n  Informatics (INDIN2018). Porto, Portugal, IEEE Computer Society Press,\n  pp.778-785", "doi": "10.1109/INDIN.2018.8472093", "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-attacks on Industrial Automation and Control Systems (IACS) are rising\nin numbers and sophistication. Embedded controller devices such as Programmable\nLogic Controllers (PLCs), which are central to controlling physical processes,\nmust be secured against attacks on confidentiality, integrity and availability.\nThe focus of this paper is to add design-level support for security in IACS\napplications, especially around inter-PLC communications. We propose an\nend-to-end solution to develop IACS applications with inherent, and parametric\nsupport for security. Built using the IEC 61499 Function Blocks standard, this\nsolution allows us to annotate certain communications as 'secure' during design\ntime. When the application is compiled, these annotations are transformed into\na security layer that implements encrypted communication between PLCs. In this\npaper, we implement a part of this security layer focussed on confidentiality,\ncalled Confidentiality Layer for Function Blocks (CL4FB), which provides a\nrange of encryption/decryption and secure key exchange functionalities. We\nstudy the impact of using CL4FB in IACS applications with real-time\nconstraints. Through a case study focussing on protection functions in\nsmart-grids, we show that varying levels of confidentiality can be achieved\nwhile also meeting hard real-time deadlines.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 02:30:59 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Tanveer", "Awais", ""], ["Sinha", "Roopak", ""], ["MacDonell", "Stephen G.", ""]]}, {"id": "2104.09029", "submitter": "Siamak Layeghy", "authors": "Siamak Layeghy, Marcus Gallagher, Marius Portmann", "title": "Benchmarking the Benchmark -- Analysis of Synthetic NIDS Datasets", "comments": "25 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Network Intrusion Detection Systems (NIDSs) are an increasingly important\ntool for the prevention and mitigation of cyber attacks. A number of labelled\nsynthetic datasets generated have been generated and made publicly available by\nresearchers, and they have become the benchmarks via which new ML-based NIDS\nclassifiers are being evaluated. Recently published results show excellent\nclassification performance with these datasets, increasingly approaching 100\npercent performance across key evaluation metrics such as accuracy, F1 score,\netc. Unfortunately, we have not yet seen these excellent academic research\nresults translated into practical NIDS systems with such near-perfect\nperformance. This motivated our research presented in this paper, where we\nanalyse the statistical properties of the benign traffic in three of the more\nrecent and relevant NIDS datasets, (CIC, UNSW, ...). As a comparison, we\nconsider two datasets obtained from real-world production networks, one from a\nuniversity network and one from a medium size Internet Service Provider (ISP).\nOur results show that the two real-world datasets are quite similar among\nthemselves in regards to most of the considered statistical features. Equally,\nthe three synthetic datasets are also relatively similar within their group.\nHowever, and most importantly, our results show a distinct difference of most\nof the considered statistical features between the three synthetic datasets and\nthe two real-world datasets. Since ML relies on the basic assumption of\ntraining and test datasets being sampled from the same distribution, this\nraises the question of how well the performance results of ML-classifiers\ntrained on the considered synthetic datasets can translate and generalise to\nreal-world networks. We believe this is an interesting and relevant question\nwhich provides motivation for further research in this space.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 03:17:37 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Layeghy", "Siamak", ""], ["Gallagher", "Marcus", ""], ["Portmann", "Marius", ""]]}, {"id": "2104.09041", "submitter": "Bhagyashri Tushir", "authors": "Bhagyashri Tushir, Hetesh Sehgal, Rohan Nair, Behnam Dezfouli, Yuhong\n  Liu", "title": "The Impact of DoS Attacks onResource-constrained IoT Devices:A Study on\n  the Mirai Attack", "comments": "Ubi-Media Computing 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mirai is a type of malware that creates a botnet of internet-connected\ndevices, which can later be used to infect other devices or servers. This paper\naims to analyze and explain the Mirai code and create a low-cost simulation\nenvironment to aid in the dynamic analysis of Mirai. Further, we perform\ncontrolled Denial-of-Service attacks while measuring resource consumption on\nresource-constrained compromised and victim Internet-of-Things (IoT) devices,\nsuch as energy consumption, CPU utilization, memory utilization, Ethernet\ninput/output performance, and Secure Digital card usage. The experimental setup\nshows that when a compromised device sends a User Datagram Protocol (UDP)\nflood, it consumes 38.44% more energy than its regular usage. In the case of\nSecure Digital usage, the victim, when flooded with Transmission Control\nProtocol (TCP) messages, uses 64.6% more storage for reading and 55.45% more\nfor writing. The significant extra resource consumption caused by Mirai attacks\non resource-constrained IoT devices can severely threaten such devices' wide\nadoption and raises great challenges for the security designs in the\nresource-constrained IoT environment.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 04:06:51 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Tushir", "Bhagyashri", ""], ["Sehgal", "Hetesh", ""], ["Nair", "Rohan", ""], ["Dezfouli", "Behnam", ""], ["Liu", "Yuhong", ""]]}, {"id": "2104.09164", "submitter": "Miran Kim", "authors": "Miran Kim and Xiaoqian Jiang and Kristin Lauter and Elkhan Ismayilzada\n  and Shayan Shams", "title": "HEAR: Human Action Recognition via Neural Networks on Homomorphically\n  Encrypted Data", "comments": "14 pages, submitted to a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remote monitoring to support \"aging in place\" is an active area of research.\nAdvanced computer vision technology based on deep learning can provide near\nreal-time home monitoring to detect falling and symptoms related to seizure,\nand stroke. Affordable webcams, together with cloud computing services (to run\nmachine learning algorithms), can potentially bring significant social and\nhealth benefits. However, it has not been deployed in practice because of\nprivacy and security concerns. People may feel uncomfortable sending their\nvideos of daily activities (with potentially sensitive private information) to\na computing service provider (e.g., on a commercial cloud). In this paper, we\npropose a novel strategy to resolve this dilemma by applying fully homomorphic\nencryption (FHE) to an alternative representation of human actions (i.e.,\nskeleton joints), which guarantees information confidentiality while retaining\nhigh-performance action detection at a low cost. We design an FHE-friendly\nneural network for action recognition and present a secure neural network\nevaluation strategy to achieve near real-time action detection. Our framework\nfor private inference achieves an 87.99% recognition accuracy (86.21%\nsensitivity and 99.14% specificity in detecting falls) with a latency of 3.1\nseconds on real-world datasets. Our evaluation shows that our elaborated and\nfine-tuned method reduces the inference latency by 23.81%~74.67% over a\nstraightforward implementation.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 09:41:32 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Kim", "Miran", ""], ["Jiang", "Xiaoqian", ""], ["Lauter", "Kristin", ""], ["Ismayilzada", "Elkhan", ""], ["Shams", "Shayan", ""]]}, {"id": "2104.09172", "submitter": "Tianjin Huang", "authors": "Tianjin Huang, Vlado Menkovski, Yulong Pei, YuHao Wang and Mykola\n  Pechenizkiy", "title": "Direction-Aggregated Attack for Transferable Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to adversarial examples that are crafted\nby imposing imperceptible changes to the inputs. However, these adversarial\nexamples are most successful in white-box settings where the model and its\nparameters are available. Finding adversarial examples that are transferable to\nother models or developed in a black-box setting is significantly more\ndifficult. In this paper, we propose the Direction-Aggregated adversarial\nattacks that deliver transferable adversarial examples. Our method utilizes\naggregated direction during the attack process for avoiding the generated\nadversarial examples overfitting to the white-box model. Extensive experiments\non ImageNet show that our proposed method improves the transferability of\nadversarial examples significantly and outperforms state-of-the-art attacks,\nespecially against adversarial robust models. The best averaged attack success\nrates of our proposed method reaches 94.6\\% against three adversarial trained\nmodels and 94.8\\% against five defense methods. It also reveals that current\ndefense approaches do not prevent transferable adversarial attacks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 09:54:56 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Huang", "Tianjin", ""], ["Menkovski", "Vlado", ""], ["Pei", "Yulong", ""], ["Wang", "YuHao", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "2104.09175", "submitter": "Nampoina Andriamilanto", "authors": "Nampoina Andriamilanto, Tristan Allard", "title": "BrFAST: a Tool to Select Browser Fingerprinting Attributes for Web\n  Authentication According to a Usability-Security Trade-off", "comments": null, "journal-ref": null, "doi": "10.1145/3442442.3458610", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this demonstration, we put ourselves in the place of a website manager who\nseeks to use browser fingerprinting for web authentication. The first step is\nto choose the attributes to implement among the hundreds that are available. To\ndo so, we developed BrFAST, an attribute selection platform that includes\nFPSelect, an algorithm that rigorously selects the attributes according to a\ntrade-off between security and usability. BrFAST is configured with a set of\nparameters for which we provide values for BrFAST to be usable as is. We\nnotably include the resources to use two publicly available browser fingerprint\ndatasets. BrFAST can be extended to use other parameters: other attribute\nselection methods, other measures of security and usability, or other\nfingerprint datasets. BrFAST helps visualize the exploration of the\npossibilities during the search of the best attributes to use, compare the\nproperties of attribute sets, and compare several attribute selection methods.\nDuring the demonstration, we compare the attributes selected by FPSelect with\nthese selected by the usual methods according to the properties of the\nresulting browser fingerprints (e.g., their usability, their unicity).\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 09:56:34 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Andriamilanto", "Nampoina", ""], ["Allard", "Tristan", ""]]}, {"id": "2104.09180", "submitter": "Aritra Banerjee", "authors": "Aritra Banerjee, Michael Clear, Hitesh Tewari", "title": "zkHawk: Practical Private Smart Contracts from MPC-based Hawk", "comments": "9 pages, 6 figures, submitted to IEEE BRAINS'21 Conference\n  Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cryptocurrencies have received a lot of research attention in recent years\nfollowing the release of the first cryptocurrency Bitcoin. With the rise in\ncryptocurrency transactions, the need for smart contracts has also increased.\nSmart contracts, in a nutshell, are digitally executed contracts wherein some\nparties execute a common goal. The main problem with most of the current smart\ncontracts is that there is no privacy for a party's input to the contract from\neither the blockchain or the other parties. Our research builds on the Hawk\nproject that provides transaction privacy along with support for smart\ncontracts. However, Hawk relies on a special trusted party known as a manager,\nwhich must be trusted not to leak each party's input to the smart contract. In\nthis paper, we present a practical private smart contract protocol that\nreplaces the manager with an MPC protocol such that the function to be executed\nby the MPC protocol is relatively lightweight, involving little overhead added\nto the smart contract function, and uses practical sigma protocols and\nhomomorphic commitments to prove to the blockchain that the sum of the incoming\nbalances to the smart contract matches the sum of the outgoing balances.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 10:14:12 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 13:19:11 GMT"}, {"version": "v3", "created": "Mon, 3 May 2021 12:27:18 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Banerjee", "Aritra", ""], ["Clear", "Michael", ""], ["Tewari", "Hitesh", ""]]}, {"id": "2104.09294", "submitter": "Mathieu Briland", "authors": "Mathieu Briland, Fabrice Bouquet", "title": "A Language for Modelling False Data Injection Attacks in Internet of\n  Things", "comments": "8 pages, 6 figures to be published in 3rd International Workshop on\n  Software Engineering Research & Practices for the Internet of Things\n  (SERP4IoT 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) is now omnipresent in all aspects of life and\nprovides a large number of potentially critical services. For this, Internet of\nThings relies on the data collected by objects. Data integrity is therefore\nessential. Unfortunately, this integrity is threatened by a type of attack\nknown as False Data Injection Attack. This consists of an attacker who injects\nfabricated data into a system to modify its behaviour. In this work, we dissect\nand present a method that uses a Domain-Specific Language (DSL) to generate\naltered data, allowing these attacks to be simulated and tested.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 13:33:05 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Briland", "Mathieu", ""], ["Bouquet", "Fabrice", ""]]}, {"id": "2104.09425", "submitter": "Vikash Sehwag", "authors": "Vikash Sehwag, Saeed Mahloujifar, Tinashe Handina, Sihui Dai, Chong\n  Xiang, Mung Chiang, Prateek Mittal", "title": "Improving Adversarial Robustness Using Proxy Distributions", "comments": "24 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the use of proxy distributions, i.e., approximations of the\nunderlying distribution of the training dataset, in both understanding and\nimproving the adversarial robustness in image classification. While additional\ntraining data helps in adversarial training, curating a very large number of\nreal-world images is challenging. In contrast, proxy distributions enable us to\nsample a potentially unlimited number of images and improve adversarial\nrobustness using these samples. We first ask the question: when does\nadversarial robustness benefit from incorporating additional samples from the\nproxy distribution in the training stage? We prove that the difference between\nthe robustness of a classifier on the proxy and original training dataset\ndistribution is upper bounded by the conditional Wasserstein distance between\nthem. Our result confirms the intuition that samples from a proxy distribution\nthat closely approximates training dataset distribution should be able to boost\nadversarial robustness. Motivated by this finding, we leverage samples from\nstate-of-the-art generative models, which can closely approximate training data\ndistribution, to improve robustness. In particular, we improve robust accuracy\nby up to 6.1% and 5.7% in $l_{\\infty}$ and $l_2$ threat model, and certified\nrobust accuracy by 6.7% over baselines not using proxy distributions on the\nCIFAR-10 dataset. Since we can sample an unlimited number of images from a\nproxy distribution, it also allows us to investigate the effect of an\nincreasing number of training samples on adversarial robustness. Here we\nprovide the first large scale empirical investigation of accuracy vs robustness\ntrade-off and sample complexity of adversarial training by training deep neural\nnetworks on 2K to 10M images.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 16:17:12 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Sehwag", "Vikash", ""], ["Mahloujifar", "Saeed", ""], ["Handina", "Tinashe", ""], ["Dai", "Sihui", ""], ["Xiang", "Chong", ""], ["Chiang", "Mung", ""], ["Mittal", "Prateek", ""]]}, {"id": "2104.09437", "submitter": "Quanquan Gu", "authors": "Difan Zou and Spencer Frei and Quanquan Gu", "title": "Provable Robustness of Adversarial Training for Learning Halfspaces with\n  Noise", "comments": "42 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the properties of adversarial training for learning adversarially\nrobust halfspaces in the presence of agnostic label noise. Denoting\n$\\mathsf{OPT}_{p,r}$ as the best robust classification error achieved by a\nhalfspace that is robust to perturbations of $\\ell_{p}$ balls of radius $r$, we\nshow that adversarial training on the standard binary cross-entropy loss yields\nadversarially robust halfspaces up to (robust) classification error $\\tilde\nO(\\sqrt{\\mathsf{OPT}_{2,r}})$ for $p=2$, and $\\tilde O(d^{1/4}\n\\sqrt{\\mathsf{OPT}_{\\infty, r}} + d^{1/2} \\mathsf{OPT}_{\\infty,r})$ when\n$p=\\infty$. Our results hold for distributions satisfying anti-concentration\nproperties enjoyed by log-concave isotropic distributions among others. We\nadditionally show that if one instead uses a nonconvex sigmoidal loss,\nadversarial training yields halfspaces with an improved robust classification\nerror of $O(\\mathsf{OPT}_{2,r})$ for $p=2$, and $O(d^{1/4}\\mathsf{OPT}_{\\infty,\nr})$ when $p=\\infty$. To the best of our knowledge, this is the first work to\nshow that adversarial training provably yields robust classifiers in the\npresence of noise.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 16:35:38 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Zou", "Difan", ""], ["Frei", "Spencer", ""], ["Gu", "Quanquan", ""]]}, {"id": "2104.09562", "submitter": "Hammond Pearce", "authors": "Hammond Pearce, Kaushik Yanamandra, Nikhil Gupta, Ramesh Karri", "title": "FLAW3D: A Trojan-based Cyber Attack on the Physical Outcomes of Additive\n  Manufacturing", "comments": "8 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Additive Manufacturing (AM) systems such as 3D printers use inexpensive\nmicrocontrollers that rarely feature cybersecurity defenses. This is a risk,\nespecially given the rising threat landscape within the larger digital\nmanufacturing domain. In this work we demonstrate this risk by presenting the\ndesign and study of a malicious Trojan (the FLAW3D bootloader) for AVR-based\nMarlin-compatible 3D printers (>100 commercial models). We show that the Trojan\ncan hide from programming tools, and even within tight design constraints (less\nthan 1.7 kilobytes in size), it can compromise the quality of additively\nmanufactured prints and reduce tensile strengths by up to 50%.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 18:49:01 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Pearce", "Hammond", ""], ["Yanamandra", "Kaushik", ""], ["Gupta", "Nikhil", ""], ["Karri", "Ramesh", ""]]}, {"id": "2104.09569", "submitter": "Kartick Kolachala", "authors": "Emrah Sariboz, Kartick Kolachala, Gaurav Panwar, Roopa Vishwanathan,\n  and Satyajayant Misra", "title": "Off-chain Execution and Verification of Computationally Intensive Smart\n  Contracts", "comments": "Scheduled to appear in International Conference on Blockchains and\n  Cryptocurrencies (ICBC-2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We propose a novel framework for off-chain execution and verification of\ncomputationally-intensive smart contracts. Our framework is the first solution\nthat avoids duplication of computing effort across multiple contractors, does\nnot require trusted execution environments, supports computations that do not\nhave deterministic results, and supports general-purpose computations written\nin a high-level language. Our experiments reveal that some intensive\napplications may require as much as 141 million gas, approximately 71x more\nthan the current block gas limit for computation in Ethereum today, and can be\navoided by utilizing the proposed framework.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 18:59:58 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 16:02:45 GMT"}, {"version": "v3", "created": "Sun, 25 Apr 2021 15:49:48 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Sariboz", "Emrah", ""], ["Kolachala", "Kartick", ""], ["Panwar", "Gaurav", ""], ["Vishwanathan", "Roopa", ""], ["Misra", "Satyajayant", ""]]}, {"id": "2104.09583", "submitter": "Raghav Malik", "authors": "Raghav Malik, Vidush Singhal, Benjamin Gottfried, Milind Kulkarni", "title": "Vectorized Secure Evaluation of Decision Forests", "comments": "15 pages, 10 figures", "journal-ref": null, "doi": "10.1145/3453483.3454094", "report-no": null, "categories": "cs.CR cs.PL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As the demand for machine learning-based inference increases in tandem with\nconcerns about privacy, there is a growing recognition of the need for secure\nmachine learning, in which secret models can be used to classify private data\nwithout the model or data being leaked. Fully Homomorphic Encryption (FHE)\nallows arbitrary computation to be done over encrypted data, providing an\nattractive approach to providing such secure inference. While such computation\nis often orders of magnitude slower than its plaintext counterpart, the ability\nof FHE cryptosystems to do \\emph{ciphertext packing} -- that is, encrypting an\nentire vector of plaintexts such that operations are evaluated elementwise on\nthe vector -- helps ameliorate this overhead, effectively creating a SIMD\narchitecture where computation can be vectorized for more efficient evaluation.\nMost recent research in this area has targeted regular, easily vectorizable\nneural network models. Applying similar techniques to irregular ML models such\nas decision forests remains unexplored, due to their complex, hard-to-vectorize\nstructures. In this paper we present COPSE, the first system that exploits\nciphertext packing to perform decision-forest inference. COPSE consists of a\nstaging compiler that automatically restructures and compiles decision forest\nmodels down to a new set of vectorizable primitives for secure inference. We\nfind that COPSE's compiled models outperform the state of the art across a\nrange of decision forest models, often by more than an order of magnitude,\nwhile still scaling well.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 19:32:47 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Malik", "Raghav", ""], ["Singhal", "Vidush", ""], ["Gottfried", "Benjamin", ""], ["Kulkarni", "Milind", ""]]}, {"id": "2104.09650", "submitter": "\\v{S}imon Mandl\\'ik", "authors": "\\v{S}imon Mandl\\'ik and Tom\\'a\\v{s} Pevn\\'y", "title": "Mapping the Internet: Modelling Entity Interactions in Complex\n  Heterogeneous Networks", "comments": "Master thesis, 108 page, 56 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Even though machine learning algorithms already play a significant role in\ndata science, many current methods pose unrealistic assumptions on input data.\nThe application of such methods is difficult due to incompatible data formats,\nor heterogeneous, hierarchical or entirely missing data fragments in the\ndataset. As a solution, we propose a versatile, unified framework called\n`HMill' for sample representation, model definition and training. We review in\ndepth a multi-instance paradigm for machine learning that the framework builds\non and extends. To theoretically justify the design of key components of HMill,\nwe show an extension of the universal approximation theorem to the set of all\nfunctions realized by models implemented in the framework. The text also\ncontains a detailed discussion on technicalities and performance improvements\nin our implementation, which is published for download under the MIT License.\nThe main asset of the framework is its flexibility, which makes modelling of\ndiverse real-world data sources with the same tool possible. Additionally to\nthe standard setting in which a set of attributes is observed for each object\nindividually, we explain how message-passing inference in graphs that represent\nwhole systems of objects can be implemented in the framework. To support our\nclaims, we solve three different problems from the cybersecurity domain using\nthe framework. The first use case concerns IoT device identification from raw\nnetwork observations. In the second problem, we study how malicious binary\nfiles can be classified using a snapshot of the operating system represented as\na directed graph. The last provided example is a task of domain blacklist\nextension through modelling interactions between entities in the network. In\nall three problems, the solution based on the proposed framework achieves\nperformance comparable to specialized approaches.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 21:32:44 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Mandl\u00edk", "\u0160imon", ""], ["Pevn\u00fd", "Tom\u00e1\u0161", ""]]}, {"id": "2104.09667", "submitter": "Ilia Shumailov", "authors": "Ilia Shumailov, Zakhar Shumaylov, Dmitry Kazhdan, Yiren Zhao, Nicolas\n  Papernot, Murat A. Erdogdu, Ross Anderson", "title": "Manipulating SGD with Data Ordering Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning is vulnerable to a wide variety of attacks. It is now well\nunderstood that by changing the underlying data distribution, an adversary can\npoison the model trained with it or introduce backdoors. In this paper we\npresent a novel class of training-time attacks that require no changes to the\nunderlying dataset or model architecture, but instead only change the order in\nwhich data are supplied to the model. In particular, we find that the attacker\ncan either prevent the model from learning, or poison it to learn behaviours\nspecified by the attacker. Furthermore, we find that even a single\nadversarially-ordered epoch can be enough to slow down model learning, or even\nto reset all of the learning progress. Indeed, the attacks presented here are\nnot specific to the model or dataset, but rather target the stochastic nature\nof modern learning procedures. We extensively evaluate our attacks on computer\nvision and natural language benchmarks to find that the adversary can disrupt\nmodel training and even introduce backdoors.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 22:17:27 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 10:22:15 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Shumailov", "Ilia", ""], ["Shumaylov", "Zakhar", ""], ["Kazhdan", "Dmitry", ""], ["Zhao", "Yiren", ""], ["Papernot", "Nicolas", ""], ["Erdogdu", "Murat A.", ""], ["Anderson", "Ross", ""]]}, {"id": "2104.09734", "submitter": "Pasin Manurangsi", "authors": "Alisa Chang, Badih Ghazi, Ravi Kumar, Pasin Manurangsi", "title": "Locally Private k-Means in One Round", "comments": "35 pages. To appear in ICML'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an approximation algorithm for k-means clustering in the one-round\n(aka non-interactive) local model of differential privacy (DP). This algorithm\nachieves an approximation ratio arbitrarily close to the best non private\napproximation algorithm, improving upon previously known algorithms that only\nguarantee large (constant) approximation ratios. Furthermore, this is the first\nconstant-factor approximation algorithm for k-means that requires only one\nround of communication in the local DP model, positively resolving an open\nquestion of Stemmer (SODA 2020). Our algorithmic framework is quite flexible;\nwe demonstrate this by showing that it also yields a similar near-optimal\napproximation algorithm in the (one-round) shuffle DP model.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 03:07:31 GMT"}, {"version": "v2", "created": "Sat, 15 May 2021 05:27:59 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Chang", "Alisa", ""], ["Ghazi", "Badih", ""], ["Kumar", "Ravi", ""], ["Manurangsi", "Pasin", ""]]}, {"id": "2104.09806", "submitter": "Renzheng Wei", "authors": "Renzheng Wei, Lijun Cai, Aimin Yu, Dan Meng", "title": "DeepHunter: A Graph Neural Network Based Approach for Robust Cyber\n  Threat Hunting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber Threat hunting is a proactive search for known attack behaviors in the\norganizational information system. It is an important component to mitigate\nadvanced persistent threats (APTs). However, the attack behaviors recorded in\nprovenance data may not be completely consistent with the known attack\nbehaviors. In this paper, we propose DeepHunter, a graph neural network (GNN)\nbased graph pattern matching approach that can match provenance data against\nknown attack behaviors in a robust way. Specifically, we design a graph neural\nnetwork architecture with two novel networks: attribute embedding networks that\ncould incorporate Indicators of Compromise (IOCs) information, and graph\nembedding networks that could capture the relationships between IOCs. To\nevaluate DeepHunter, we choose five real and synthetic APT attack scenarios.\nResults show that DeepHunter can hunt all attack behaviors, and the accuracy\nand robustness of DeepHunter outperform the state-of-the-art method, Poirot.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 07:37:48 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Wei", "Renzheng", ""], ["Cai", "Lijun", ""], ["Yu", "Aimin", ""], ["Meng", "Dan", ""]]}, {"id": "2104.09828", "submitter": "Florian Wilkens", "authors": "Florian Wilkens and Steffen Haas and Johanna Amann and Mathias Fischer", "title": "Passive, Transparent, and Selective TLS Decryption for Network Security\n  Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet traffic is increasingly encrypted. While this protects the\nconfidentiality and integrity of communication, it prevents network monitoring\nsystems (NMS) and intrusion detection systems (IDSs) from effectively analyzing\nthe now encrypted payloads. Therefore, many enterprise networks have deployed\nman-in-the-middle (MitM) proxies that intercept TLS connections at the network\nborder to examine packet payloads and thus retain some visibility. However,\nrecent studies have shown that TLS interception often reduces connection\nsecurity and potentially introduces additional attack vectors to the network.\nIn this paper, we present a cooperative approach in which end-hosts as\ncryptographic endpoints selectively provide TLS key material to NMS for\ndecryption. This enables endpoints to control who can decrypt which content and\nlets users retain privacy for chosen connections. We implement a prototype\nbased on the Zeek NMS that is able to receive key material from hosts, decrypt\nTLS connections and perform analyzes on the cleartext. The patch is freely\navailable and we plan to upstream our changes to Zeek once they are mature\nenough. In our evaluation, we discuss how our approach conceptually requires\nsignificantly less computational resources compared to the commonly deployed\nMitM proxies. Our experimental results indicate, that TLS decryption increases\na runtime overhead of about 2.5 times of the original runtime on cleartext.\nAdditionally, we show that the latency for transmitting keys between hosts and\nthe NMS can be effectively addressed by buffering traffic at the NMS for at\nleast 40ms, allowing successful decryption of 99.99% of all observed TLS\nconnections.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 08:26:43 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Wilkens", "Florian", ""], ["Haas", "Steffen", ""], ["Amann", "Johanna", ""], ["Fischer", "Mathias", ""]]}, {"id": "2104.09852", "submitter": "Islam Debicha", "authors": "Islam Debicha, Thibault Debatty, Jean-Michel Dricot, Wim Mees", "title": "Adversarial Training for Deep Learning-based Intrusion Detection Systems", "comments": "Already published in The Sixteenth International Conference on\n  Systems (ICONS 2021)", "journal-ref": "The Sixteenth International Conference on Systems (ICONS 2021),\n  pp. 45-49, 2021", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, Deep Neural Networks (DNNs) report state-of-the-art results in many\nmachine learning areas, including intrusion detection. Nevertheless, recent\nstudies in computer vision have shown that DNNs can be vulnerable to\nadversarial attacks that are capable of deceiving them into misclassification\nby injecting specially crafted data. In security-critical areas, such attacks\ncan cause serious damage; therefore, in this paper, we examine the effect of\nadversarial attacks on deep learning-based intrusion detection. In addition, we\ninvestigate the effectiveness of adversarial training as a defense against such\nattacks. Experimental results show that with sufficient distortion, adversarial\nexamples are able to mislead the detector and that the use of adversarial\ntraining can improve the robustness of intrusion detection.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 09:36:24 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Debicha", "Islam", ""], ["Debatty", "Thibault", ""], ["Dricot", "Jean-Michel", ""], ["Mees", "Wim", ""]]}, {"id": "2104.09872", "submitter": "Jiwei Guan", "authors": "Jiwei Guan, Xi Zheng, Chen Wang, Yipeng Zhou and Alireza Jolfa", "title": "Robust Sensor Fusion Algorithms Against Voice Command Attacks in\n  Autonomous Vehicles", "comments": "8 pages, 2 tables, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With recent advances in autonomous driving, Voice Control Systems have become\nincreasingly adopted as human-vehicle interaction methods. This technology\nenables drivers to use voice commands to control the vehicle and will be soon\navailable in Advanced Driver Assistance Systems (ADAS). Prior work has shown\nthat Siri, Alexa and Cortana, are highly vulnerable to inaudible command\nattacks. This could be extended to ADAS in real-world applications and such\ninaudible command threat is difficult to detect due to microphone\nnonlinearities. In this paper, we aim to develop a more practical solution by\nusing camera views to defend against inaudible command attacks where ADAS are\ncapable of detecting their environment via multi-sensors. To this end, we\npropose a novel multimodal deep learning classification system to defend\nagainst inaudible command attacks. Our experimental results confirm the\nfeasibility of the proposed defense methods and the best classification\naccuracy reaches 89.2%. Code is available at\nhttps://github.com/ITSEG-MQ/Sensor-Fusion-Against-VoiceCommand-Attacks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 10:08:46 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 01:47:53 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Guan", "Jiwei", ""], ["Zheng", "Xi", ""], ["Wang", "Chen", ""], ["Zhou", "Yipeng", ""], ["Jolfa", "Alireza", ""]]}, {"id": "2104.09898", "submitter": "Saurab Chhachhi", "authors": "Saurab Chhachhi, Fei Teng", "title": "Market Value of Differentially-Private Smart Meter Data", "comments": "5 pages, 4 figures, submitted to the 2021 IEEE Power & Energy Society\n  Innovative Smart Grid Technologies Conference (ISGT NA)", "journal-ref": null, "doi": "10.1109/ISGT49243.2021.9372228", "report-no": null, "categories": "math.OC cs.CR cs.SY eess.SY q-fin.MF", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper proposes a framework to investigate the value of sharing\nprivacy-protected smart meter data between domestic consumers and load serving\nentities. The framework consists of a discounted differential privacy model to\nensure individuals cannot be identified from aggregated data, a ANN-based\nshort-term load forecasting to quantify the impact of data availability and\nprivacy protection on the forecasting error and an optimal procurement problem\nin day-ahead and balancing markets to assess the market value of the\nprivacy-utility trade-off. The framework demonstrates that when the load\nprofile of a consumer group differs from the system average, which is\nquantified using the Kullback-Leibler divergence, there is significant value in\nsharing smart meter data while retaining individual consumer privacy.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 11:15:03 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Chhachhi", "Saurab", ""], ["Teng", "Fei", ""]]}, {"id": "2104.09971", "submitter": "Valentin Zieglmeier", "authors": "Valentin Zieglmeier and Gabriel Loyola Daiqui", "title": "GDPR-Compliant Use of Blockchain for Secure Usage Logs", "comments": "Peer-reviewed version accepted for publication in the proceedings of\n  the 2021 International Conference on Evaluation and Assessment in Software\n  Engineering (EASE'21)", "journal-ref": null, "doi": "10.1145/3463274.3463349", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unique properties of blockchain enable central requirements of\ndistributed secure logging: Immutability, integrity, and availability.\nEspecially when providing transparency about data usages, a blockchain-based\nsecure log can be beneficial, as no trusted third party is required. Yet, with\ndata governed by privacy legislation such as the GDPR or CCPA, the core\nadvantage of immutability becomes a liability. After a rightful request, an\nindividual's personal data need to be rectified or deleted, which is impossible\nin an immutable blockchain. To solve this issue, we exploit a legal property of\npseudonymized data: They are only regarded personal data if they can be\nassociated with an individual's identity. We make use of this fact by\npresenting P3, a pseudonym provisioning system for secure usage logs including\na protocol for recording new usages. For each new block, a one-time transaction\npseudonym is generated. The pseudonym generation algorithm guarantees\nunlinkability and enables proof of ownership. These properties enable\nGDPR-compliant use of blockchain, as data subjects can exercise their legal\nrights with regards to their personal data. The new-usage protocol ensures\nnon-repudiation, and therefore accountability and liability. Most importantly,\nour approach does not require a trusted third party and is independent of the\nutilized blockchain software.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 14:03:01 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 09:21:52 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Zieglmeier", "Valentin", ""], ["Daiqui", "Gabriel Loyola", ""]]}, {"id": "2104.09979", "submitter": "Xi He", "authors": "He Xi, He Ketai, Lin Shenwen, Yang Jinglin, Mao Hongliang", "title": "Bitcoin Address Clustering Method Based on Multiple Heuristic Conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We analyzed the associations between Bitcoin transactions and addresses to\ncluster address and further find groups of addresses controlled by the same\nentity. It revealed the vulnerabilities of Bitcoin anonymity mechanism, which\ncould be used by the law enforcement agencies to track and crack down illegal\ntransactions. However, single heuristic method and incomplete heuristic\nconditions were difficult to cluster a large number of addresses\ncomprehensively and accurately. Therefore, this paper reviewed a variety of\nheuristics, and used multiple heuristics comprehensively to cluster addresses\nto improve the degree of address aggregation and address recall rate, which\nlaid a foundation for further inferring of entity identity.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 01:53:29 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Xi", "He", ""], ["Ketai", "He", ""], ["Shenwen", "Lin", ""], ["Jinglin", "Yang", ""], ["Hongliang", "Mao", ""]]}, {"id": "2104.09981", "submitter": "Neil Dhir", "authors": "Neil Dhir, Henrique Hoeltgebaum, Niall Adams, Mark Briers, Anthony\n  Burke, Paul Jones", "title": "Prospective Artificial Intelligence Approaches for Active Cyber Defence", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cybercriminals are rapidly developing new malicious tools that leverage\nartificial intelligence (AI) to enable new classes of adaptive and stealthy\nattacks. New defensive methods need to be developed to counter these threats.\nSome cybersecurity professionals are speculating AI will enable corresponding\nnew classes of active cyber defence measures -- is this realistic, or currently\nmostly hype? The Alan Turing Institute, with expert guidance from the UK\nNational Cyber Security Centre and Defence Science Technology Laboratory,\npublished a research roadmap for AI for ACD last year. This position paper\nupdates the roadmap for two of the most promising AI approaches --\nreinforcement learning and causal inference - and describes why they could help\ntip the balance back towards defenders.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 14:07:34 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Dhir", "Neil", ""], ["Hoeltgebaum", "Henrique", ""], ["Adams", "Niall", ""], ["Briers", "Mark", ""], ["Burke", "Anthony", ""], ["Jones", "Paul", ""]]}, {"id": "2104.09994", "submitter": "Pedro Miguel Sanchez Sanchez", "authors": "Valerian Rey, Pedro Miguel S\\'anchez S\\'anchez, Alberto Huertas\n  Celdr\\'an, G\\'er\\^ome Bovet, Martin Jaggi", "title": "Federated Learning for Malware Detection in IoT Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work investigates the possibilities enabled by federated learning\nconcerning IoT malware detection and studies security issues inherent to this\nnew learning paradigm. In this context, a framework that uses federated\nlearning to detect malware affecting IoT devices is presented. N-BaIoT, a\ndataset modeling network traffic of several real IoT devices while affected by\nmalware, has been used to evaluate the proposed framework. Both supervised and\nunsupervised federated models (multi-layer perceptron and autoencoder) able to\ndetect malware affecting seen and unseen IoT devices of N-BaIoT have been\ntrained and evaluated. Furthermore, their performance has been compared to two\ntraditional approaches. The first one lets each participant locally train a\nmodel using only its own data, while the second consists of making the\nparticipants share their data with a central entity in charge of training a\nglobal model. This comparison has shown that the use of more diverse and large\ndata, as done in the federated and centralized methods, has a considerable\npositive impact on the model performance. Besides, the federated models, while\npreserving the participant's privacy, show similar results as the centralized\nones. As an additional contribution and to measure the robustness of the\nfederated approach, an adversarial setup with several malicious participants\npoisoning the federated model has been considered. The baseline model\naggregation averaging step used in most federated learning algorithms appears\nhighly vulnerable to different attacks, even with a single adversary. The\nperformance of other model aggregation functions acting as countermeasures is\nthus evaluated under the same attack scenarios. These functions provide a\nsignificant improvement against malicious participants, but more efforts are\nstill needed to make federated approaches robust.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 13:14:22 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Rey", "Valerian", ""], ["S\u00e1nchez", "Pedro Miguel S\u00e1nchez", ""], ["Celdr\u00e1n", "Alberto Huertas", ""], ["Bovet", "G\u00e9r\u00f4me", ""], ["Jaggi", "Martin", ""]]}, {"id": "2104.10015", "submitter": "Wadii Boulila Prof.", "authors": "Muhammad Almas Khan, Muazzam A Khan, Shahid Latif, Awais Aziz Shah,\n  Mujeeb Ur Rehman, Wadii Boulila, Maha Driss, Jawad Ahmad", "title": "Voting Classifier-based Intrusion Detection for IoT Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Internet of Things (IoT) is transforming human lives by paving the way for\nthe management of physical devices on the edge. These interconnected IoT\nobjects share data for remote accessibility and can be vulnerable to open\nattacks and illegal access. Intrusion detection methods are commonly used for\nthe detection of such kinds of attacks but with these methods, the\nperformance/accuracy is not optimal. This work introduces a novel intrusion\ndetection approach based on an ensemble-based voting classifier that combines\nmultiple traditional classifiers as a base learner and gives the vote to the\npredictions of the traditional classifier in order to get the final prediction.\nTo test the effectiveness of the proposed approach, experiments are performed\non a set of seven different IoT devices and tested for binary attack\nclassification and multi-class attack classification. The results illustrate\nprominent accuracies on Global Positioning System (GPS) sensors and weather\nsensors to 96% and 97% and for other machine learning algorithms to 85% and\n87%, respectively. Furthermore, comparison with other traditional machine\nlearning methods validates the superiority of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 14:48:26 GMT"}, {"version": "v2", "created": "Sun, 25 Apr 2021 10:18:36 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Khan", "Muhammad Almas", ""], ["Khan", "Muazzam A", ""], ["Latif", "Shahid", ""], ["Shah", "Awais Aziz", ""], ["Rehman", "Mujeeb Ur", ""], ["Boulila", "Wadii", ""], ["Driss", "Maha", ""], ["Ahmad", "Jawad", ""]]}, {"id": "2104.10017", "submitter": "Scott Ruoti", "authors": "Sean Oesch, Anuj Gautam, Scott Ruoti", "title": "The Emperor's New Autofill Framework: A Security Analysis of Autofill on\n  iOS and Android", "comments": "13 pages, 5 pages appendix, under submission to IEEE S&P 2022", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Password managers help users more effectively manage their passwords,\nencouraging them to adopt stronger passwords across their many accounts. In\ncontrast to desktop systems where password managers receive no system-level\nsupport, mobile operating systems provide autofill frameworks that are designed\nto integrate with password managers to provide secure and usable autofill for\nbrowsers and other apps installed on mobile devices. In this paper, we conduct\nthe first holistic security evaluation of such frameworks on iOS and Android,\nexamining whether they achieve substantive benefits over the ad-hoc desktop\nenvironment or become a problematic single point of failure. Our results find\nthat while the frameworks address several common issues (e.g., requiring user\ninteraction before autofill), they also enforce insecure behavior and fail to\nprovide the password managers implemented using the frameworks with sufficient\ninformation to override this incorrect behavior. Within mobile browsers, this\nresults in managers being less secure than their desktop counterparts. Within\napps, incorrect handling of WebView controls leads to manager-assisted phishing\nattacks from malicious apps or domains, depending on how autofill is\nimplemented. Based on our results, significant improvements are needed for\nmobile autofill frameworks and we conclude the paper with concrete\nrecommendations for the design and implementation of more secure autofill\nframeworks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 14:54:10 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Oesch", "Sean", ""], ["Gautam", "Anuj", ""], ["Ruoti", "Scott", ""]]}, {"id": "2104.10034", "submitter": "Jason Hiser", "authors": "Molly Buchanan, Jeffrey W. Collyer, Jack W. Davidson, Saikat Dey, Mark\n  Gardner, Jason D. Hiser, Jeffry Lang, Alastair Nottingham, Alina Oprea", "title": "On Generating and Labeling Network Traffic with Realistic,\n  Self-Propagating Malware", "comments": "4+2 pages, 3 figures, 1 table, for AI4CS-SDM21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research and development of techniques which detect or remediate malicious\nnetwork activity require access to diverse, realistic, contemporary data sets\ncontaining labeled malicious connections. In the absence of such data, said\ntechniques cannot be meaningfully trained, tested, and evaluated. Synthetically\nproduced data containing fabricated or merged network traffic is of limited\nvalue as it is easily distinguishable from real traffic by even simple machine\nlearning (ML) algorithms. Real network data is preferable, but while ubiquitous\nis broadly both sensitive and lacking in ground truth labels, limiting its\nutility for ML research.\n  This paper presents a multi-faceted approach to generating a data set of\nlabeled malicious connections embedded within anonymized network traffic\ncollected from large production networks. Real-world malware is defanged and\nintroduced to simulated, secured nodes within those networks to generate\nrealistic traffic while maintaining sufficient isolation to protect real data\nand infrastructure. Network sensor data, including this embedded malware\ntraffic, is collected at a network edge and anonymized for research use.\n  Network traffic was collected and produced in accordance with the\naforementioned methods at two major educational institutions. The result is a\nhighly realistic, long term, multi-institution data set with embedded data\nlabels spanning over 1.5 trillion connections and over a petabyte of sensor log\ndata. The usability of this data set is demonstrated by its utility to our\nartificial intelligence and machine learning (AI/ML) research program.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 15:11:09 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Buchanan", "Molly", ""], ["Collyer", "Jeffrey W.", ""], ["Davidson", "Jack W.", ""], ["Dey", "Saikat", ""], ["Gardner", "Mark", ""], ["Hiser", "Jason D.", ""], ["Lang", "Jeffry", ""], ["Nottingham", "Alastair", ""], ["Oprea", "Alina", ""]]}, {"id": "2104.10076", "submitter": "Yijun Yang", "authors": "Yang Yijun, Gao Ruiyuan, Li Yu, Lai Qiuxia, Xu Qiang", "title": "MixDefense: A Defense-in-Depth Framework for Adversarial Example\n  Detection Based on Statistical and Semantic Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Machine learning with deep neural networks (DNNs) has become one of the\nfoundation techniques in many safety-critical systems, such as autonomous\nvehicles and medical diagnosis systems. DNN-based systems, however, are known\nto be vulnerable to adversarial examples (AEs) that are maliciously perturbed\nvariants of legitimate inputs. While there has been a vast body of research to\ndefend against AE attacks in the literature, the performances of existing\ndefense techniques are still far from satisfactory, especially for adaptive\nattacks, wherein attackers are knowledgeable about the defense mechanisms and\ncraft AEs accordingly. In this work, we propose a multilayer defense-in-depth\nframework for AE detection, namely MixDefense. For the first layer, we focus on\nthose AEs with large perturbations. We propose to leverage the `noise' features\nextracted from the inputs to discover the statistical difference between\nnatural images and tampered ones for AE detection. For AEs with small\nperturbations, the inference result of such inputs would largely deviate from\ntheir semantic information. Consequently, we propose a novel learning-based\nsolution to model such contradictions for AE detection. Both layers are\nresilient to adaptive attacks because there do not exist gradient propagation\npaths for AE generation. Experimental results with various AE attack methods on\nimage classification datasets show that the proposed MixDefense solution\noutperforms the existing AE detection techniques by a considerable margin.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 15:57:07 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Yijun", "Yang", ""], ["Ruiyuan", "Gao", ""], ["Yu", "Li", ""], ["Qiuxia", "Lai", ""], ["Qiang", "Xu", ""]]}, {"id": "2104.10203", "submitter": "Hang Zhou", "authors": "Hang Zhou, Weiming Zhang, Kejiang Chen, Weixiang Li and Nenghai Yu", "title": "Three-Dimensional Mesh Steganography and Steganalysis: A Review", "comments": "Accepted to TVCG", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Three-dimensional (3-D) meshes are commonly used to represent virtual\nsurfaces and volumes. Over the past decade, 3-D meshes have emerged in\nindustrial, medical, and entertainment applications, being of large practical\nsignificance for 3-D mesh steganography and steganalysis. In this article, we\nprovide a systematic survey of the literature on 3-D mesh steganography and\nsteganalysis. Compared with an earlier survey [1], we propose a new taxonomy of\nsteganographic algorithms with four categories: 1) two-state domain, 2) LSB\ndomain, 3) permutation domain, and 4) transform domain. Regarding steganalysis\nalgorithms, we divide them into two categories: 1) universal steganalysis and\n2) specific steganalysis. For each category, the history of technical\ndevelopments and the current technological level are introduced and discussed.\nFinally, we highlight some promising future research directions and challenges\nin improving the performance of 3-D mesh steganography and steganalysis.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 18:46:56 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Zhou", "Hang", ""], ["Zhang", "Weiming", ""], ["Chen", "Kejiang", ""], ["Li", "Weixiang", ""], ["Yu", "Nenghai", ""]]}, {"id": "2104.10232", "submitter": "Valentino Crespi", "authors": "Valentino Crespi (1), Wes Hardaker (1), Sami Abu-El-Haija (1), Aram\n  Galstyan (1) ((1) USC - ISI)", "title": "Identifying botnet IP address clusters using natural language processing\n  techniques on honeypot command logs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Computer security has been plagued by increasing formidable, dynamic,\nhard-to-detect, hard-to-predict, and hard-to-characterize hacking techniques.\nSuch techniques are very often deployed in self-propagating worms capable of\nautomatically infecting vulnerable computer systems and then building large bot\nnetworks, which are then used to launch coordinated attacks on designated\ntargets. In this work, we investigate novel applications of Natural Language\nProcessing (NLP) methods to detect and correlate botnet behaviors through the\nanalysis of honeypot data. In our approach we take observed behaviors in shell\ncommands issued by intruders during captured internet sessions and reduce them\nto collections of stochastic processes that are, in turn, processed with\nmachine learning techniques to build classifiers and predictors. Our technique\nresults in a new ability to cluster botnet source IP address even in the face\nof their desire to obfuscate their penetration attempts through rapid or random\npermutation techniques.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 20:08:25 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Crespi", "Valentino", "", "USC - ISI"], ["Hardaker", "Wes", "", "USC - ISI"], ["Abu-El-Haija", "Sami", "", "USC - ISI"], ["Galstyan", "Aram", "", "USC - ISI"]]}, {"id": "2104.10262", "submitter": "Andr\\'es Molina-Markham", "authors": "Andres Molina-Markham, Ransom K. Winder, Ahmad Ridley", "title": "Network Defense is Not a Game", "comments": "AI4CS, April 2021, NY. arXiv admin note: substantial text overlap\n  with arXiv:2103.07583", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research seeks to apply Artificial Intelligence (AI) to scale and extend the\ncapabilities of human operators to defend networks. A fundamental problem that\nhinders the generalization of successful AI approaches -- i.e., beating humans\nat playing games -- is that network defense cannot be defined as a single game\nwith a fixed set of rules. Our position is that network defense is better\ncharacterized as a collection of games with uncertain and possibly drifting\nrules. Hence, we propose to define network defense tasks as distributions of\nnetwork environments, to: (i) enable research to apply modern AI techniques,\nsuch as unsupervised curriculum learning and reinforcement learning for network\ndefense; and, (ii) facilitate the design of well-defined challenges that can be\nused to compare approaches for autonomous cyberdefense.\n  To demonstrate that an approach for autonomous network defense is practical\nit is important to be able to reason about the boundaries of its applicability.\nHence, we need to be able to define network defense tasks that capture sets of\nadversarial tactics, techniques, and procedures (TTPs); quality of service\n(QoS) requirements; and TTPs available to defenders. Furthermore, the\nabstractions to define these tasks must be extensible; must be backed by\nwell-defined semantics that allow us to reason about distributions of\nenvironments; and should enable the generation of data and experiences from\nwhich an agent can learn.\n  Our approach named Network Environment Design for Autonomous Cyberdefense\ninspired the architecture of FARLAND, a Framework for Advanced Reinforcement\nLearning for Autonomous Network Defense, which we use at MITRE to develop RL\nnetwork defenders that perform blue actions from the MITRE Shield matrix\nagainst attackers with TTPs that drift from MITRE ATT&CK TTPs.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 21:52:51 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Molina-Markham", "Andres", ""], ["Winder", "Ransom K.", ""], ["Ridley", "Ahmad", ""]]}, {"id": "2104.10319", "submitter": "Frederico Araujo", "authors": "Frederico Araujo and Dhilung Kirat and Xiaokui Shu and Teryl Taylor\n  and Jiyong Jang", "title": "Evidential Cyber Threat Hunting", "comments": "5 pages, SDM AI4CS 2021", "journal-ref": "In Proceedings of the 2021 SIAM AI/ML for Cybersecurity Workshop\n  (AI4CS)", "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A formal cyber reasoning framework for automating the threat hunting process\nis described. The new cyber reasoning methodology introduces an operational\nsemantics that operates over three subspaces -- knowledge, hypothesis, and\naction -- to enable human-machine co-creation of threat hypotheses and\nprotective recommendations. An implementation of this framework shows that the\napproach is practical and can be used to generalize evidence-based\nmulti-criteria threat investigations.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 02:38:29 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Araujo", "Frederico", ""], ["Kirat", "Dhilung", ""], ["Shu", "Xiaokui", ""], ["Taylor", "Teryl", ""], ["Jang", "Jiyong", ""]]}, {"id": "2104.10377", "submitter": "Yujing Jiang", "authors": "Yujing Jiang, Xingjun Ma, Sarah Monazam Erfani and James Bailey", "title": "Dual Head Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are known to be vulnerable to adversarial\nexamples/attacks, raising concerns about their reliability in safety-critical\napplications. A number of defense methods have been proposed to train robust\nDNNs resistant to adversarial attacks, among which adversarial training has so\nfar demonstrated the most promising results. However, recent studies have shown\nthat there exists an inherent tradeoff between accuracy and robustness in\nadversarially-trained DNNs. In this paper, we propose a novel technique Dual\nHead Adversarial Training (DH-AT) to further improve the robustness of existing\nadversarial training methods. Different from existing improved variants of\nadversarial training, DH-AT modifies both the architecture of the network and\nthe training strategy to seek more robustness. Specifically, DH-AT first\nattaches a second network head (or branch) to one intermediate layer of the\nnetwork, then uses a lightweight convolutional neural network (CNN) to\naggregate the outputs of the two heads. The training strategy is also adapted\nto reflect the relative importance of the two heads. We empirically show, on\nmultiple benchmark datasets, that DH-AT can bring notable robustness\nimprovements to existing adversarial training methods. Compared with TRADES,\none state-of-the-art adversarial training method, our DH-AT can improve the\nrobustness by 3.4% against PGD40 and 2.3% against AutoAttack, and also improve\nthe clean accuracy by 1.8%.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 06:31:33 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 06:01:25 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Jiang", "Yujing", ""], ["Ma", "Xingjun", ""], ["Erfani", "Sarah Monazam", ""], ["Bailey", "James", ""]]}, {"id": "2104.10379", "submitter": "Owen Arden", "authors": "Owen Arden, Anitha Gollamudi, Ethan Cecchetti, Stephen Chong, and\n  Andrew C. Myers", "title": "A Calculus for Flow-Limited Authorization", "comments": "58 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Real-world applications routinely make authorization decisions based on\ndynamic computation. Reasoning about dynamically computed authority is\nchallenging. Integrity of the system might be compromised if attackers can\nimproperly influence the authorizing computation. Confidentiality can also be\ncompromised by authorization, since authorization decisions are often based on\nsensitive data such as membership lists and passwords. Previous formal models\nfor authorization do not fully address the security implications of permitting\ntrust relationships to change, which limits their ability to reason about\nauthority that derives from dynamic computation. Our goal is an approach to\nconstructing dynamic authorization mechanisms that do not violate\nconfidentiality or integrity.\n  The Flow-Limited Authorization Calculus (FLAC) is a simple, expressive model\nfor reasoning about dynamic authorization as well as an information flow\ncontrol language for securely implementing various authorization mechanisms.\nFLAC combines the insights of two previous models: it extends the Dependency\nCore Calculus with features made possible by the Flow-Limited Authorization\nModel. FLAC provides strong end-to-end information security guarantees even for\nprograms that incorporate and implement rich dynamic authorization mechanisms.\nThese guarantees include noninterference and robust declassification, which\nprevent attackers from influencing information disclosures in unauthorized\nways. We prove these security properties formally for all FLAC programs and\nexplore the expressiveness of FLAC with several examples.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 06:40:25 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Arden", "Owen", ""], ["Gollamudi", "Anitha", ""], ["Cecchetti", "Ethan", ""], ["Chong", "Stephen", ""], ["Myers", "Andrew C.", ""]]}, {"id": "2104.10459", "submitter": "Kenneth Co", "authors": "Kenneth T. Co, David Martinez Rego, Emil C. Lupu", "title": "Jacobian Regularization for Mitigating Universal Adversarial\n  Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Universal Adversarial Perturbations (UAPs) are input perturbations that can\nfool a neural network on large sets of data. They are a class of attacks that\nrepresents a significant threat as they facilitate realistic, practical, and\nlow-cost attacks on neural networks. In this work, we derive upper bounds for\nthe effectiveness of UAPs based on norms of data-dependent Jacobians. We\nempirically verify that Jacobian regularization greatly increases model\nrobustness to UAPs by up to four times whilst maintaining clean performance.\nOur theoretical analysis also allows us to formulate a metric for the strength\nof shared adversarial perturbations between pairs of inputs. We apply this\nmetric to benchmark datasets and show that it is highly correlated with the\nactual observed robustness. This suggests that realistic and practical\nuniversal attacks can be reliably mitigated without sacrificing clean accuracy,\nwhich shows promise for the robustness of machine learning systems.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 11:00:21 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Co", "Kenneth T.", ""], ["Rego", "David Martinez", ""], ["Lupu", "Emil C.", ""]]}, {"id": "2104.10561", "submitter": "Gabriele Costa", "authors": "Gabriele Costa, Fabio Pinelli, Simone Soderi, Gabriele Tolomei", "title": "Covert Channel Attack to Federated Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning (FL) goes beyond traditional, centralized machine learning\nby distributing model training among a large collection of edge clients. These\nclients cooperatively train a global, e.g., cloud-hosted, model without\ndisclosing their local, private training data. The global model is then shared\namong all the participants which use it for local predictions. In this paper,\nwe put forward a novel attacker model aiming at turning FL systems into covert\nchannels to implement a stealth communication infrastructure. The main\nintuition is that, during federated training, a malicious sender can poison the\nglobal model by submitting purposely crafted examples. Although the effect of\nthe model poisoning is negligible to other participants, and does not alter the\noverall model performance, it can be observed by a malicious receiver and used\nto transmit a single bit.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 14:32:03 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Costa", "Gabriele", ""], ["Pinelli", "Fabio", ""], ["Soderi", "Simone", ""], ["Tolomei", "Gabriele", ""]]}, {"id": "2104.10575", "submitter": "Ron Alford", "authors": "Ron Alford (1), Andy Applebaum (1) ((1) The MITRE Corporation)", "title": "Towards Causal Models for Adversary Distractions", "comments": "To be presented in the AI/ML for Cybersecurity workshop at SDM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Automated adversary emulation is becoming an indispensable tool of network\nsecurity operators in testing and evaluating their cyber defenses. At the same\ntime, it has exposed how quickly adversaries can propagate through the network.\nWhile research has greatly progressed on quality decoy generation to fool human\nadversaries, we may need different strategies to slow computer agents. In this\npaper, we show that decoy generation can slow an automated agent's decision\nprocess, but that the degree to which it is inhibited is greatly dependent on\nthe types of objects used. This points to the need to explicitly evaluate decoy\ngeneration and placement strategies against fast moving, automated adversaries.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 15:02:00 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Alford", "Ron", "", "The MITRE Corporation"], ["Applebaum", "Andy", "", "The MITRE Corporation"]]}, {"id": "2104.10586", "submitter": "Hao Cheng", "authors": "Kaidi Xu, Chenan Wang, Hao Cheng, Bhavya Kailkhura, Xue Lin, Ryan\n  Goldhahn", "title": "Mixture of Robust Experts (MoRE):A Robust Denoising Method towards\n  multiple perturbations", "comments": "This paper is a seminar and dicussing paper, which will not be\n  published and printed anywhere. And it will be keep updating", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To tackle the susceptibility of deep neural networks to examples, the\nadversarial training has been proposed which provides a notion of robust\nthrough an inner maximization problem presenting the first-order embedded\nwithin the outer minimization of the training loss. To generalize the\nadversarial robustness over different perturbation types, the adversarial\ntraining method has been augmented with the improved inner maximization\npresenting a union of multiple perturbations e.g., various $\\ell_p$\nnorm-bounded perturbations.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 15:27:07 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 15:05:42 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 15:57:13 GMT"}, {"version": "v4", "created": "Tue, 20 Jul 2021 06:25:54 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Xu", "Kaidi", ""], ["Wang", "Chenan", ""], ["Cheng", "Hao", ""], ["Kailkhura", "Bhavya", ""], ["Lin", "Xue", ""], ["Goldhahn", "Ryan", ""]]}, {"id": "2104.10706", "submitter": "Pratyush Maini", "authors": "Pratyush Maini and Mohammad Yaghini and Nicolas Papernot", "title": "Dataset Inference: Ownership Resolution in Machine Learning", "comments": "Published as a conference paper at ICLR 2021 (Spotlight Presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With increasingly more data and computation involved in their training,\nmachine learning models constitute valuable intellectual property. This has\nspurred interest in model stealing, which is made more practical by advances in\nlearning with partial, little, or no supervision. Existing defenses focus on\ninserting unique watermarks in a model's decision surface, but this is\ninsufficient: the watermarks are not sampled from the training distribution and\nthus are not always preserved during model stealing. In this paper, we make the\nkey observation that knowledge contained in the stolen model's training set is\nwhat is common to all stolen copies. The adversary's goal, irrespective of the\nattack employed, is always to extract this knowledge or its by-products. This\ngives the original model's owner a strong advantage over the adversary: model\nowners have access to the original training data. We thus introduce $dataset$\n$inference$, the process of identifying whether a suspected model copy has\nprivate knowledge from the original model's dataset, as a defense against model\nstealing. We develop an approach for dataset inference that combines\nstatistical testing with the ability to estimate the distance of multiple data\npoints to the decision boundary. Our experiments on CIFAR10, SVHN, CIFAR100 and\nImageNet show that model owners can claim with confidence greater than 99% that\ntheir model (or dataset as a matter of fact) was stolen, despite only exposing\n50 of the stolen model's training points. Dataset inference defends against\nstate-of-the-art attacks even when the adversary is adaptive. Unlike prior\nwork, it does not require retraining or overfitting the defended model.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 18:12:18 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Maini", "Pratyush", ""], ["Yaghini", "Mohammad", ""], ["Papernot", "Nicolas", ""]]}, {"id": "2104.10742", "submitter": "John Emanuello Ph.D.", "authors": "Vance Wong and John Emanuello", "title": "Robustness of ML-Enhanced IDS to Stealthy Adversaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrusion Detection Systems (IDS) enhanced with Machine Learning (ML) have\ndemonstrated the capacity to efficiently build a prototype of \"normal\" cyber\nbehaviors in order to detect cyber threats' activity with greater accuracy than\ntraditional rule-based IDS. Because these are largely black boxes, their\nacceptance requires proof of robustness to stealthy adversaries. Since it is\nimpossible to build a baseline from activity completely clean of that of\nmalicious cyber actors (outside of controlled experiments), the training data\nfor deployed models will be poisoned with examples of activity that analysts\nwould want to be alerted about. We train an autoencoder-based anomaly detection\nsystem on network activity with various proportions of malicious activity mixed\nin and demonstrate that they are robust to this sort of poisoning.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 20:00:31 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Wong", "Vance", ""], ["Emanuello", "John", ""]]}, {"id": "2104.10749", "submitter": "Pietro Borrello", "authors": "Pietro Borrello, Daniele Cono D'Elia, Leonardo Querzoni, Cristiano\n  Giuffrida", "title": "Constantine: Automatic Side-Channel Resistance Using Efficient Control\n  and Data Flow Linearization", "comments": "Proceedings of the ACM Conference on Computer and Communications\n  Security (CCS) 2021. Code and BibTeX entry available at\n  https://github.com/pietroborrello/constantine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of microarchitectural side channels, vendors scramble to deploy\nmitigations for transient execution attacks, but leave traditional side-channel\nattacks against sensitive software (e.g., crypto programs) to be fixed by\ndevelopers by means of constant-time programming (i.e., absence of\nsecret-dependent code/data patterns). Unfortunately, writing constant-time code\nby hand is hard, as evidenced by the many flaws discovered in production side\nchannel-resistant code. Prior efforts to automatically transform programs into\nconstant-time equivalents offer limited security or compatibility guarantees,\nhindering their applicability to real-world software.\n  In this paper, we present Constantine, a compiler-based system to\nautomatically harden programs against microarchitectural side channels.\nConstantine pursues a radical design point where secret-dependent control and\ndata flows are completely linearized (i.e., all involved code/data accesses are\nalways executed). This strategy provides strong security and compatibility\nguarantees by construction, but its natural implementation leads to state\nexplosion in real-world programs. To address this challenge, Constantine relies\non carefully designed optimizations such as just-in-time loop linearization and\naggressive function cloning for fully context-sensitive points-to analysis,\nwhich not only address state explosion, but also lead to an efficient and\ncompatible solution. Constantine yields overheads as low as 16% on standard\nbenchmarks and can handle a fully-fledged component from the production wolfSSL\nlibrary.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 20:25:30 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Borrello", "Pietro", ""], ["D'Elia", "Daniele Cono", ""], ["Querzoni", "Leonardo", ""], ["Giuffrida", "Cristiano", ""]]}, {"id": "2104.10903", "submitter": "Jay Kumar", "authors": "Rajesh Kumar, WenYong Wang, Cheng Yuan, Jay Kumar, Zakria, He Qing,\n  Ting Yang, Abdullah Aman Khan", "title": "Blockchain based Privacy-Preserved Federated Learning for Medical\n  Images: A Case Study of COVID-19 CT Scans", "comments": "15 Pages, 5 Tables, 11 Figures, Journal Paper, Elsevier format", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical health care centers are envisioned as a promising paradigm to handle\nthe massive volume of data of COVID-19 patients using artificial intelligence\n(AI). Traditionally, AI techniques often require centralized data collection\nand training the model in a single organization, which is most common weakness\ndue to the privacy and security of raw data communication. To solve this\nchallenging task, we propose a blockchain-based federated learning framework\nthat provides collaborative data training solutions by coordinating multiple\nhospitals to train and share encrypted federated models without leakage of data\nprivacy. The blockchain ledger technology provides the decentralization of\nfederated learning model without any central server. The proposed homomorphic\nencryption scheme encrypts and decrypts the gradients of model to preserve the\nprivacy. More precisely, the proposed framework: i) train the local model by a\nnovel capsule network to segmentation and classify COVID-19 images, ii) then\nuse the homomorphic encryption scheme to secure the local model that encrypts\nand decrypts the gradients, and finally the model is shared over a\ndecentralized platform through proposed blockchain-based federated learning\nalgorithm. The integration of blockchain and federated learning leads to a new\nparadigm for medical image data sharing in the decentralized network. The\nconducted experimental resultsdemonstrate the performance of the proposed\nscheme.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 07:32:04 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 06:04:39 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Kumar", "Rajesh", ""], ["Wang", "WenYong", ""], ["Yuan", "Cheng", ""], ["Kumar", "Jay", ""], ["Zakria", "", ""], ["Qing", "He", ""], ["Yang", "Ting", ""], ["Khan", "Abdullah Aman", ""]]}, {"id": "2104.10949", "submitter": "Sijun Tan", "authors": "Sijun Tan, Brian Knott, Yuan Tian, and David J. Wu", "title": "CryptGPU: Fast Privacy-Preserving Machine Learning on the GPU", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce CryptGPU, a system for privacy-preserving machine learning that\nimplements all operations on the GPU (graphics processing unit). Just as GPUs\nplayed a pivotal role in the success of modern deep learning, they are also\nessential for realizing scalable privacy-preserving deep learning. In this\nwork, we start by introducing a new interface to losslessly embed cryptographic\noperations over secret-shared values (in a discrete domain) into floating-point\noperations that can be processed by highly-optimized CUDA kernels for linear\nalgebra. We then identify a sequence of \"GPU-friendly\" cryptographic protocols\nto enable privacy-preserving evaluation of both linear and non-linear\noperations on the GPU. Our microbenchmarks indicate that our private GPU-based\nconvolution protocol is over 150x faster than the analogous CPU-based protocol;\nfor non-linear operations like the ReLU activation function, our GPU-based\nprotocol is around 10x faster than its CPU analog.\n  With CryptGPU, we support private inference and private training on\nconvolutional neural networks with over 60 million parameters as well as handle\nlarge datasets like ImageNet. Compared to the previous state-of-the-art, when\nconsidering large models and datasets, our protocols achieve a 2x to 8x\nimprovement in private inference and a 6x to 36x improvement for private\ntraining. Our work not only showcases the viability of performing secure\nmultiparty computation (MPC) entirely on the GPU to enable fast\nprivacy-preserving machine learning, but also highlights the importance of\ndesigning new MPC primitives that can take full advantage of the GPU's\ncomputing capabilities.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 09:21:40 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Tan", "Sijun", ""], ["Knott", "Brian", ""], ["Tian", "Yuan", ""], ["Wu", "David J.", ""]]}, {"id": "2104.11038", "submitter": "Aditya Vempaty", "authors": "Mohammad Niknazar and Aditya Vempaty and Ravi Kokku", "title": "Voice Privacy with Smart Digital Assistants in Educational Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.CR cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The emergence of voice-assistant devices ushers in delightful user\nexperiences not just on the smart home front, but also in diverse educational\nenvironments from classrooms to personalized-learning/tutoring. However, the\nuse of voice as an interaction modality also could result in exposure of user's\nidentity, and hinders the broader adoption of voice interfaces; this is\nespecially important in environments where children are present and their voice\nprivacy needs to be protected. To this end, building on state-of-the-art\ntechniques proposed in the literature, we design and evaluate a practical and\nefficient framework for voice privacy at the source. The approach combines\nspeaker identification (SID) and speech conversion methods to randomly disguise\nthe identity of users right on the device that records the speech, while\nensuring that the transformed utterances of users can still be successfully\ntranscribed by Automatic Speech Recognition (ASR) solutions. We evaluate the\nASR performance of the conversion in terms of word error rate and show the\npromise of this framework in preserving the content of the input speech.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2021 19:58:45 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Niknazar", "Mohammad", ""], ["Vempaty", "Aditya", ""], ["Kokku", "Ravi", ""]]}, {"id": "2104.11041", "submitter": "Ivan Cviti\\'c", "authors": "Ivan Cviti\\'c, Dragan Perakovi\\'c, Marko Peri\\v{s}a and Anca D. Jurcut", "title": "Methodology for Detecting Cyber Intrusions in e-Learning Systems during\n  COVID-19 Pandemic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the scenarios of specific conditions and crises such as the coronavirus\npandemic, the availability of e-learning ecosystem elements is further\nhighlighted. The growing importance for securing such an ecosystem can be seen\nfrom DDoS (Distributed Denial of Service) attacks on e-learning components of\nthe Croatian e-learning system. The negative impact of the conducted attack is\nvisible in numerous users who were prevented from participating in and\nimplementing the planned teaching process. Network anomalies such as conducted\nDDoS attacks were identified as one of the crucial threats to the e-learning\nsystems. In this paper, an overview of the network anomaly phenomenon was given\nand botnets' role in generating DDoS attacks, especially IoT device impact. The\npaper analyzes the impact of the COVID-19 pandemic on the e-learning systems in\nCroatia. Based on the conclusions, a research methodology has been proposed to\ndevelop a cyber-threat detection model that considers the specifics of the\napplication of e-learning systems in crisis, distinguishing flash crowd events\nfrom anomalies in the communication network. The proposed methodology includes\nestablishing a theoretical basis on DDoS and flash crowd event traffic,\ndefining a laboratory testbed setup for data acquisition, development of DDoS\ndetection model, and testing the applicability of the developed model on the\ncase study. The implementation of the proposed methodology can improve the\nquality of the teaching process through timely DDoS detection and it gives\nother socio-economic contributions such as developing a specific research\ndomain, publicly available dataset of network traffic, and raising the\ncyber-security of the e-learning systems.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 13:15:09 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Cviti\u0107", "Ivan", ""], ["Perakovi\u0107", "Dragan", ""], ["Peri\u0161a", "Marko", ""], ["Jurcut", "Anca D.", ""]]}, {"id": "2104.11076", "submitter": "Maura Paterson", "authors": "Maura B. Paterson and Douglas R. Stinson", "title": "Splitting authentication codes with perfect secrecy: new results,\n  constructions and connections with algebraic manipulation detection codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.CO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A splitting BIBD is a type of combinatorial design that can be used to\nconstruct splitting authentication codes with good properties. In this paper we\nshow that a design-theoretic approach is useful in the analysis of more general\nsplitting authentication codes. Motivated by the study of algebraic\nmanipulation detection (AMD) codes, we define the concept of a group generated\nsplitting authentication code. We show that all group-generated authentication\ncodes have perfect secrecy, which allows us to demonstrate that algebraic\nmanipulation detection codes can be considered to be a special case of an\nauthentication code with perfect secrecy.\n  We also investigate splitting BIBDs that can be \"equitably ordered\". These\nsplitting BIBDs yield authentication codes with splitting that also have\nperfect secrecy. We show that, while group generated BIBDs are inherently\nequitably ordered, the concept is applicable to more general splitting BIBDs.\nFor various pairs $(k,c)$, we determine necessary and sufficient (or almost\nsufficient) conditions for the existence of $(v, k \\times c,1)$-splitting BIBDs\nthat can be equitably ordered. The pairs for which we can solve this problem\nare $(k,c) = (3,2), (4,2), (3,3)$ and $(3,4)$, as well as all cases with $k =\n2$.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 13:54:54 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Paterson", "Maura B.", ""], ["Stinson", "Douglas R.", ""]]}, {"id": "2104.11103", "submitter": "Jing Wu", "authors": "Jing Wu, Mingyi Zhou, Ce Zhu, Yipeng Liu, Mehrtash Harandi, Li Li", "title": "Performance Evaluation of Adversarial Attacks: Discrepancies and\n  Solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, adversarial attack methods have been developed to challenge the\nrobustness of machine learning models. However, mainstream evaluation criteria\nexperience limitations, even yielding discrepancies among results under\ndifferent settings. By examining various attack algorithms, including\ngradient-based and query-based attacks, we notice the lack of a consensus on a\nuniform standard for unbiased performance evaluation. Accordingly, we propose a\nPiece-wise Sampling Curving (PSC) toolkit to effectively address the\naforementioned discrepancy, by generating a comprehensive comparison among\nadversaries in a given range. In addition, the PSC toolkit offers options for\nbalancing the computational cost and evaluation effectiveness. Experimental\nresults demonstrate our PSC toolkit presents comprehensive comparisons of\nattack algorithms, significantly reducing discrepancies in practice.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 14:36:51 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Wu", "Jing", ""], ["Zhou", "Mingyi", ""], ["Zhu", "Ce", ""], ["Liu", "Yipeng", ""], ["Harandi", "Mehrtash", ""], ["Li", "Li", ""]]}, {"id": "2104.11105", "submitter": "Mi{\\l}osz Stypi\\'nski", "authors": "Mi{\\l}osz Stypi\\'nski, Marcin Niemiec", "title": "Synchronization of Tree Parity Machines using non-binary input vectors", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural cryptography is the application of artificial neural networks in the\nsubject of cryptography. The functionality of this solution is based on a tree\nparity machine. It uses artificial neural networks to perform secure key\nexchange between network entities. This article proposes improvements to the\nsynchronization of two tree parity machines. The improvement is based on\nlearning artificial neural network using input vectors which have a wider range\nof values than binary ones. As a result, the duration of the synchronization\nprocess is reduced. Therefore, tree parity machines achieve common weights in a\nshorter time due to the reduction of necessary bit exchanges. This approach\nimproves the security of neural cryptography\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 14:38:55 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Stypi\u0144ski", "Mi\u0142osz", ""], ["Niemiec", "Marcin", ""]]}, {"id": "2104.11230", "submitter": "Jiajie Wu", "authors": "Jiajie Wu", "title": "Literature review on vulnerability detection using NLP technology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Vulnerability detection has always been the most important task in the field\nof software security. With the development of technology, in the face of\nmassive source code, automated analysis and detection of vulnerabilities has\nbecome a current research hotspot. For special text files such as source code,\nusing some of the hottest NLP technologies to build models and realize the\nautomatic analysis and detection of source code has become one of the most\nanticipated studies in the field of vulnerability detection. This article does\na brief survey of some recent new documents and technologies, such as CodeBERT,\nand summarizes the previous technologies.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 03:16:51 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Wu", "Jiajie", ""]]}, {"id": "2104.11234", "submitter": "Ivan Cviti\\'c", "authors": "Ivan Cviti\\'c, Dragan Perakovi\\'c, Marko Peri\\v{s}a, Anca D. Jurcut", "title": "Methodology proposal for proactive detection of network anomalies in\n  e-learning system during the COVID-19 scenario", "comments": "arXiv admin note: substantial text overlap with arXiv:2104.11041", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In specific conditions and crisis situations such as the pandemic of\ncoronavirus (SARS-CoV-2), or the COVID-19 disease, e-learning systems be-came\ncrucial for the smooth performing of teaching and other educational pro-cesses.\nIn such scenarios, the availability of e-learning ecosystem elements is further\nhighlighted. An indicator of the importance for securing the availability of\nsuch an ecosystem is evident from the DDoS (Distributed Denial of Service)\nattack on AAI@EduHr as a key authentication service for number of e-learning\nusers in Republic of Croatia. In doing so, numerous users\n(teach-ers/students/administrators) were prevented from implementing and\nparticipat-ing in the planned teaching process. Given that DDoS as an anomaly\nof network traffic has been identified as one of the key threats to the\ne-learning ecosystem in crisis scenarios, this research will focus on overview\nof methodology for de-veloping a model for proactive detection of DDoS traffic.\nThe challenge in de-tection is to effectively differentiate the increased\ntraffic intensity and service requests caused by legitimate user activity\n(flash crowd) from the illegitimate traffic caused by a DDoS attack. The DDoS\ntraffic detection model developed by following analyzed methodology would serve\nas a basis for providing further guidelines and recommendations in the form of\nresponse to events that may negatively affect the availability of e-learning\necosystem elements such as DDoS attack.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 13:28:36 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Cviti\u0107", "Ivan", ""], ["Perakovi\u0107", "Dragan", ""], ["Peri\u0161a", "Marko", ""], ["Jurcut", "Anca D.", ""]]}, {"id": "2104.11469", "submitter": "Jan Philipp Thoma", "authors": "Jan Philipp Thoma, Christian Niesler, Dominic Funke, Gregor Leander,\n  Pierre Mayr, Nils Pohl, Lucas Davi, Tim G\\\"uneysu", "title": "ClepsydraCache -- Preventing Cache Attacks with Time-Based Evictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both the shift towards attacks on the microarchitectural CPU level and the\nongoing transition towards cloud computing and shared VM hosts have\nincreasingly drawn attention towards cache attacks. In these fields of\napplication, cache side-channels lay the cornerstone that is leveraged by\nattackers to exfiltrate secret information from the CPU microarchitecture. We\nbuild upon the observation that current cache side-channel attacks mostly\nexploit the architectural visibility of conflicting cache addresses. With\nClepsydraCache, we break away this foundation by unraveling the linkage between\ncache evictions and accesses to conflicting addresses. Our solution takes a new\napproach that assigns each cache entry a random time-to-live to reduce the\namount of cache conflicts. By making those conflicts unobservable to an\nattacker, ClepsydraCache efficiently protects against attacks like Prime+Probe\nand Flush+Reload. Furthermore, our solution is applicable to large last-level\ncaches which are the most common targets for cache attacks. We implement\nClepsydraCache using the Gem5 simulator and provide a proof-of-concept hardware\ndesign and simulation using 65-nm CMOS technology. ClepsydraCache matches the\nperformance of traditional cache architectures while improving the system\nsecurity against cache attacks.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 08:36:49 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Thoma", "Jan Philipp", ""], ["Niesler", "Christian", ""], ["Funke", "Dominic", ""], ["Leander", "Gregor", ""], ["Mayr", "Pierre", ""], ["Pohl", "Nils", ""], ["Davi", "Lucas", ""], ["G\u00fcneysu", "Tim", ""]]}, {"id": "2104.11470", "submitter": "Zeyu Qin", "authors": "Zeyu Qin, Yanbo Fan, Hongyuan Zha, Baoyuan Wu", "title": "Theoretical Study of Random Noise Defense against Query-Based Black-Box\n  Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The query-based black-box attacks, which don't require any knowledge about\nthe attacked models and datasets, have raised serious threats to machine\nlearning models in many real applications. In this work, we study a simple but\npromising defense technique, dubbed Random Noise Defense (RND) against\nquery-based black-box attacks, which adds proper Gaussian noise to each query.\nIt is lightweight and can be directly combined with any off-the-shelf models\nand other defense strategies. However, the theoretical guarantee of random\nnoise defense is missing, and the actual effectiveness of this defense is not\nyet fully understood. In this work, we present solid theoretical analyses to\ndemonstrate that the defense effect of RND against the query-based black-box\nattack and the corresponding adaptive attack heavily depends on the magnitude\nratio between the random noise added by the defender (i.e., RND) and the random\nnoise added by the attacker for gradient estimation. Extensive experiments on\nCIFAR-10 and ImageNet verify our theoretical studies. Based on RND, we also\npropose a stronger defense method that combines RND with Gaussian augmentation\ntraining (RND-GT) and achieves better defense performance.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 08:39:41 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Qin", "Zeyu", ""], ["Fan", "Yanbo", ""], ["Zha", "Hongyuan", ""], ["Wu", "Baoyuan", ""]]}, {"id": "2104.11515", "submitter": "Nikos Fotiou", "authors": "Nikos Fotiou, Vasilios A. Siris, George C. Polyzos", "title": "Capability-based access control for multi-tenant systems using OAuth 2.0\n  and Verifiable Credentials", "comments": "to appear in 30th International Conference on Computer Communications\n  and Networks (ICCCN 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a capability-based access control technique for sharing Web\nresources, based on Verifiable Credentials (VCs) and OAuth 2.0. VCs are a\nsecure means for expressing claims about a subject. Although VCs are ideal for\nencoding capabilities, the lack of standards for exchanging and using VCs\nimpedes their adoption and limits their interoperability. We mitigate this\nproblem by integrating VCs into the OAuth 2.0 authorization flow. To this end,\nwe propose a new form of OAuth 2.0 access token based on VCs. Our approach\nleverages JSON Web Tokens (JWT) to encode VCs and takes advantage of JWT-based\nmechanisms for proving VC possession. Our solution not only requires minimum\nchanges to existing OAuth 2.0 code bases, but it also removes some of the\ncomplexity of verifying VC claims by relying on JSON Web Signatures: a simple,\nstandardized, and well supported signature format. Additionally, we fill the\ngap of VC generation processes by defining a new protocol that leverages the\nOAuth 2.0 \"client credentials\" grant.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 10:03:37 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 23:21:31 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Fotiou", "Nikos", ""], ["Siris", "Vasilios A.", ""], ["Polyzos", "George C.", ""]]}, {"id": "2104.11576", "submitter": "Erik Hemberg", "authors": "Prakruthi Karuna and Erik Hemberg and Una-May O'Reilly and Nick Rutar", "title": "Automating Cyber Threat Hunting Using NLP, Automated Query Generation,\n  and Genetic Perturbation", "comments": "5 pages 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Scaling the cyber hunt problem poses several key technical challenges.\nDetecting and characterizing cyber threats at scale in large enterprise\nnetworks is hard because of the vast quantity and complexity of the data that\nmust be analyzed as adversaries deploy varied and evolving tactics to\naccomplish their goals. There is a great need to automate all aspects, and,\nindeed, the workflow of cyber hunting. AI offers many ways to support this. We\nhave developed the WILEE system that automates cyber threat hunting by\ntranslating high-level threat descriptions into many possible concrete\nimplementations. Both the (high-level) abstract and (low-level) concrete\nimplementations are represented using a custom domain specific language (DSL).\nWILEE uses the implementations along with other logic, also written in the DSL,\nto automatically generate queries to confirm (or refute) any hypotheses tied to\nthe potential adversarial workflows represented at various layers of\nabstraction.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 13:19:12 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Karuna", "Prakruthi", ""], ["Hemberg", "Erik", ""], ["O'Reilly", "Una-May", ""], ["Rutar", "Nick", ""]]}, {"id": "2104.11580", "submitter": "Maha Allouzi", "authors": "Maha Ali Allouzi, Javed I. Khan", "title": "Identifying and Modeling Security Threats for IoMT Edge Network using\n  Markov Chain and Common Vulnerability Scoring System (CVSS)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this work, we defined an attack vector for networks utilizing the Internet\nof Medical Things (IoMT) devices and compute the probability distribution of\nIoMT security threats based on Markov chain and Common Vulnerability Scoring\nSystem (CVSS). IoMT is an emerging technology that improves patients' quality\nof life by permitting personalized e-health services without restrictions on\ntime and site. The IoMT consists of embedded objects, sensors, and actuators\nthat transmit and receive medical data. These Medical devices are vulnerable to\ndifferent types of security threats, and thus, they pose a significant risk to\npatient's privacy and safety. Because security is a critical factor for\nsuccessfully merging IoMT into pervasive healthcare systems, there is an urgent\nneed for new security mechanisms to prevent threats on the IoMT edge network.\nToward this direction, the first step is defining an attack vector that an\nattacker or unauthorized user can take advantage of to penetrate and tamper\nwith medical data. In this article, we specify a threat model for the IoMT edge\nnetwork. We identify any vulnerabilities or weaknesses within the IoMT network\nthat allow unauthorized privileges and threats that can utilize these\nweaknesses to compromise the IoMT edge network. Finally, we compute the\nprobability distribution of IoMT threats based on the Markov transition\nprobability matrix.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 13:29:54 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Allouzi", "Maha Ali", ""], ["Khan", "Javed I.", ""]]}, {"id": "2104.11616", "submitter": "Paulina Hoyos", "authors": "Carlos A. Cadavid, Paulina Hoyos, Jay Jorgenson, Lejla Smajlovi\\'c,\n  Juan D. V\\'elez", "title": "An integer factorization algorithm which uses diffusion as a\n  computational engine", "comments": "28 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR math.NT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this article we develop an algorithm which computes a divisor of an\ninteger $N$, which is assumed to be neither prime nor the power of a prime. The\nalgorithm uses discrete time heat diffusion on a finite graph. If $N$ has $m$\ndistinct prime factors, then the probability that our algorithm runs\nsuccessfully is at least $p(m) = 1-(m+1)/2^{m}$. We compute the computational\ncomplexity of the algorithm in terms of classical, or digital, steps and in\nterms of diffusion steps, which is a concept that we define here. As we will\ndiscuss below, we assert that a diffusion step can and should be considered as\nbeing comparable to a quantum step for an algorithm which runs on a quantum\ncomputer. With this, we prove that our factorization algorithm uses at most\n$O((\\log N)^{2})$ deterministic steps and at most $O((\\log N)^{2})$ diffusion\nsteps with an implied constant which is effective. By comparison, Shor's\nalgorithm is known to use at most $O((\\log N)^{2}\\log (\\log N) \\log (\\log \\log\nN))$ quantum steps on a quantum computer.\n  As an example of our algorithm, we simulate the diffusion computer algorithm\non a desktop computer and obtain factorizations of $N=33$ and $N=1363$.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 14:11:33 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Cadavid", "Carlos A.", ""], ["Hoyos", "Paulina", ""], ["Jorgenson", "Jay", ""], ["Smajlovi\u0107", "Lejla", ""], ["V\u00e9lez", "Juan D.", ""]]}, {"id": "2104.11632", "submitter": "Andreea Alexandru", "authors": "Andreea B. Alexandru, Anastasios Tsiamis and George J. Pappas", "title": "Encrypted Distributed Lasso for Sparse Data Predictive Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CR cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The least squares problem with L1-regularized regressors, called Lasso, is a\nwidely used approach in optimization problems where sparsity of the regressors\nis desired. This formulation is fundamental for many applications in signal\nprocessing, machine learning and control. As a motivating problem, we\ninvestigate a sparse data predictive control problem, run at a cloud service to\ncontrol a system with unknown model, using L1-regularization to limit the\nbehavior complexity. The input-output data collected for the system is\nprivacy-sensitive, hence, we design a privacy-preserving solution using\nhomomorphically encrypted data. The main challenges are the non-smoothness of\nthe L1-norm, which is difficult to evaluate on encrypted data, as well as the\niterative nature of the Lasso problem. We use a distributed ADMM formulation\nthat enables us to exchange substantial local computation for little\ncommunication between multiple servers. We first give an encrypted multi-party\nprotocol for solving the distributed Lasso problem, by approximating the\nnon-smooth part with a Chebyshev polynomial, evaluating it on encrypted data,\nand using a more cost effective distributed bootstrapping operation. For the\nexample of data predictive control, we prefer a non-homogeneous splitting of\nthe data for better convergence. We give an encrypted multi-party protocol for\nthis non-homogeneous splitting of the Lasso problem to a non-homogeneous set of\nservers: one powerful server and a few less powerful devices, added for\nsecurity reasons. Finally, we provide numerical results for our proposed\nsolutions.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 14:35:52 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Alexandru", "Andreea B.", ""], ["Tsiamis", "Anastasios", ""], ["Pappas", "George J.", ""]]}, {"id": "2104.11636", "submitter": "Talha Ongun", "authors": "Talha Ongun, Simona Boboila, Alina Oprea, Tina Eliassi-Rad, Alastair\n  Nottingham, Jason Hiser, Jack Davidson", "title": "Collaborative Information Sharing for ML-Based Threat Detection", "comments": "6 pages, 5 figures. To be published in AI4CS-SDM2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, coordinated attack campaigns started to become more widespread on\nthe Internet. In May 2017, WannaCry infected more than 300,000 machines in 150\ncountries in a few days and had a large impact on critical infrastructure.\nExisting threat sharing platforms cannot easily adapt to emerging attack\npatterns. At the same time, enterprises started to adopt machine learning-based\nthreat detection tools in their local networks. In this paper, we pose the\nquestion: \\emph{What information can defenders share across multiple networks\nto help machine learning-based threat detection adapt to new coordinated\nattacks?} We propose three information sharing methods across two networks, and\nshow how the shared information can be used in a machine-learning\nnetwork-traffic model to significantly improve its ability of detecting evasive\nself-propagating malware.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 14:40:28 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Ongun", "Talha", ""], ["Boboila", "Simona", ""], ["Oprea", "Alina", ""], ["Eliassi-Rad", "Tina", ""], ["Nottingham", "Alastair", ""], ["Hiser", "Jason", ""], ["Davidson", "Jack", ""]]}, {"id": "2104.11691", "submitter": "Julia Rosenzweig", "authors": "Julia Rosenzweig, Joachim Sicking, Sebastian Houben, Michael Mock,\n  Maram Akila", "title": "Patch Shortcuts: Interpretable Proxy Models Efficiently Find Black-Box\n  Vulnerabilities", "comments": "Under IEEE Copyright; accepted at the SAIAD (Safe Artificial\n  Intelligence for Automated Driving) Workshop at CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important pillar for safe machine learning (ML) is the systematic\nmitigation of weaknesses in neural networks to afford their deployment in\ncritical applications. An ubiquitous class of safety risks are learned\nshortcuts, i.e. spurious correlations a network exploits for its decisions that\nhave no semantic connection to the actual task. Networks relying on such\nshortcuts bear the risk of not generalizing well to unseen inputs.\nExplainability methods help to uncover such network vulnerabilities. However,\nmany of these techniques are not directly applicable if access to the network\nis constrained, in so-called black-box setups. These setups are prevalent when\nusing third-party ML components. To address this constraint, we present an\napproach to detect learned shortcuts using an interpretable-by-design network\nas a proxy to the black-box model of interest. Leveraging the proxy's\nguarantees on introspection we automatically extract candidates for learned\nshortcuts. Their transferability to the black box is validated in a systematic\nfashion. Concretely, as proxy model we choose a BagNet, which bases its\ndecisions purely on local image patches. We demonstrate on the autonomous\ndriving dataset A2D2 that extracted patch shortcuts significantly influence the\nblack box model. By efficiently identifying such patch-based vulnerabilities,\nwe contribute to safer ML models.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 05:44:40 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Rosenzweig", "Julia", ""], ["Sicking", "Joachim", ""], ["Houben", "Sebastian", ""], ["Mock", "Michael", ""], ["Akila", "Maram", ""]]}, {"id": "2104.11763", "submitter": "Frank Bentrem", "authors": "Frank W. Bentrem, Michael A. Corsello, and Joshua J. Palm", "title": "Leveraging Sharing Communities to Achieve Federated Learning for\n  Cybersecurity", "comments": "7 pages, SDM AI4CS 2021", "journal-ref": "In Proceedings of the 2021 SIAM AI/ML for Cybersecurity Workshop\n  (AI4CS)", "doi": null, "report-no": null, "categories": "cs.CR cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automated cyber threat detection in computer networks is a major challenge in\ncybersecurity. The cyber domain has inherent challenges that make traditional\nmachine learning techniques problematic, specifically the need to learn\ncontinually evolving attacks through global collaboration while maintaining\ndata privacy, and the varying resources available to network owners. We present\na scheme to mitigate these difficulties through an architectural approach using\ncommunity model sharing with a streaming analytic pipeline. Our streaming\napproach trains models incrementally as each log record is processed, thereby\nadjusting to concept drift resulting from changing attacks. Further, we\ndesigned a community sharing approach which federates learning through merging\nmodels without the need to share sensitive cyber-log data. Finally, by\nstandardizing data and Machine Learning processes in a modular way, we provide\nnetwork security operators the ability to manage cyber threat events and model\nsensitivity through community member and analytic method weighting in ways that\nare best suited for their available resources and data.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 18:07:43 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 18:45:10 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Bentrem", "Frank W.", ""], ["Corsello", "Michael A.", ""], ["Palm", "Joshua J.", ""]]}, {"id": "2104.11790", "submitter": "Chris van der Ploeg", "authors": "Chris van der Ploeg, Robin Smit, Alexis Siagkris-Lekkos, Frank\n  Benders, Emilia Silvas", "title": "Anomaly Detection from Cyber Threats via Infrastructure to Automated\n  Vehicle", "comments": "7 pages, 8 figures, accepted and submitted for IEEE European Control\n  Conference 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using Infrastructure-to-Vehicle (I2V) information can be of great benefit\nwhen driving autonomously in high-density traffic situations with limited\nvisibility, since the sensing capabilities of the vehicle are enhanced by\nexternal sensors. In this research, a method is introduced to increase the\nvehicle's self-awareness in intersections for one of the largest foreseen\nchallenges when using I2V communication: cyber security. The introduced anomaly\ndetection algorithm, running on the automated vehicle, assesses the health of\nthe I2V communication against multiple cyber security attacks. The analysis is\ndone in a simulation environment, using cyber-attack scenarios from the\nSecredas Project (Cyber Security for Cross Domain Reliable Dependable Automated\nSystems) and provides insights into the limitations the vehicle has when facing\nI2V cyber attacks of different types and amplitudes and when sensor redundancy\nis lost. The results demonstrate that anomalies injected can be robustly\ndetected and mitigated by the autonomous vehicle, allowing it to react more\nsafely and comfortably and maintaining correct object tracking in\nintersections.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 19:13:19 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["van der Ploeg", "Chris", ""], ["Smit", "Robin", ""], ["Siagkris-Lekkos", "Alexis", ""], ["Benders", "Frank", ""], ["Silvas", "Emilia", ""]]}, {"id": "2104.11846", "submitter": "Osman Boyaci", "authors": "Osman Boyaci, Mohammad Rasoul Narimani, Katherine Davis, Muhammad\n  Ismail, Thomas J Overbye, and Erchin Serpedin", "title": "Joint Detection and Localization of Stealth False Data Injection Attacks\n  in Smart Grids using Graph Neural Networks", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  False data injection attacks (FDIA) are becoming an active avenue of research\nas such attacks are more frequently encountered in power systems. Contrary to\nthe detection of these attacks, less attention has been paid to identifying the\nattacked units of the grid. To this end, this work jointly studies detecting\nand localizing the stealth FDIA in modern power grids. Exploiting the inherent\ngraph topology of power systems as well as the spatial correlations of smart\nmeters' data, this paper proposes an approach based on the graph neural network\n(GNN) to identify the presence and location of the FDIA. The proposed approach\nleverages the auto-regressive moving average (ARMA) type graph convolutional\nfilters which offer better noise robustness and frequency response flexibility\ncompared to the polynomial type graph convolutional filters such as Chebyshev.\nTo the best of our knowledge, this is the first work based on GNN that\nautomatically detects and localizes FDIA in power systems. Extensive\nsimulations and visualizations show that the proposed approach outperforms the\navailable methods in both detection and localization FDIA for different IEEE\ntest systems. Thus, the targeted areas in power grids can be identified and\npreventive actions can be taken before the attack impacts the grid.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 00:33:45 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Boyaci", "Osman", ""], ["Narimani", "Mohammad Rasoul", ""], ["Davis", "Katherine", ""], ["Ismail", "Muhammad", ""], ["Overbye", "Thomas J", ""], ["Serpedin", "Erchin", ""]]}, {"id": "2104.11906", "submitter": "Hussain Ahmad", "authors": "Hussain Ahmad, Isuru Dharmadasa, Faheem Ullah and Ali Babar", "title": "A Review on C3I Systems' Security: Vulnerabilities, Attacks, and\n  Countermeasures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Command, Control, Communication, and Intelligence (C3I) system is a kind of\nsystem-of-system that integrates computing machines, sensors, and communication\nnetworks. C3I systems are increasingly used in critical civil and military\noperations for achieving information superiority, assurance, and operational\nefficacy. C3I systems are no exception to the traditional systems facing\nwidespread cyber-threats. However, the sensitive nature of the application\ndomain (e.g., military operations) of C3I systems makes their security a\ncritical concern. For instance, a cyber-attack on military installations can\nhave detrimental impacts on national security. Therefore, in this paper, we\nreview the state-of-the-art on the security of C3I systems. In particular, this\npaper aims to identify the security vulnerabilities, attack vectors, and\ncountermeasures for C3I systems. We used the well-known systematic literature\nreview method to select and review 77 studies on the security of C3I systems.\nOur review enabled us to identify 27 vulnerabilities, 22 attack vectors, and 62\ncountermeasures for C3I systems. This review has also revealed several areas\nfor future research and identified key lessons with regards to C3I systems'\nsecurity.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 08:13:22 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Ahmad", "Hussain", ""], ["Dharmadasa", "Isuru", ""], ["Ullah", "Faheem", ""], ["Babar", "Ali", ""]]}, {"id": "2104.12032", "submitter": "Jason Hong", "authors": "Jason I. Hong, Yuvraj Agarwal, Matt Fredrikson, Mike Czapik, Shawn\n  Hanna, Swarup Sahoo, Judy Chun, Won-Woo Chung, Aniruddh Iyer, Ally Liu, Shen\n  Lu, Rituparna Roychoudhury, Qian Wang, Shan Wang, Siqi Wang, Vida Zhang,\n  Jessica Zhao, Yuan Jiang, Haojian Jin, Sam Kim, Evelyn Kuo, Tianshi Li,\n  Jinping Liu, Yile Liu, Robert Zhang", "title": "The Design of the User Interfaces for Privacy Enhancements for Android", "comments": "58 pages, 21 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the design and design rationale for the user interfaces for\nPrivacy Enhancements for Android (PE for Android). These UIs are built around\ntwo core ideas, namely that developers should explicitly declare the purpose of\nwhy sensitive data is being used, and these permission-purpose pairs should be\nsplit by first party and third party uses. We also present a taxonomy of\npurposes and ways of how these ideas can be deployed in the existing Android\necosystem.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 22:24:18 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Hong", "Jason I.", ""], ["Agarwal", "Yuvraj", ""], ["Fredrikson", "Matt", ""], ["Czapik", "Mike", ""], ["Hanna", "Shawn", ""], ["Sahoo", "Swarup", ""], ["Chun", "Judy", ""], ["Chung", "Won-Woo", ""], ["Iyer", "Aniruddh", ""], ["Liu", "Ally", ""], ["Lu", "Shen", ""], ["Roychoudhury", "Rituparna", ""], ["Wang", "Qian", ""], ["Wang", "Shan", ""], ["Wang", "Siqi", ""], ["Zhang", "Vida", ""], ["Zhao", "Jessica", ""], ["Jiang", "Yuan", ""], ["Jin", "Haojian", ""], ["Kim", "Sam", ""], ["Kuo", "Evelyn", ""], ["Li", "Tianshi", ""], ["Liu", "Jinping", ""], ["Liu", "Yile", ""], ["Zhang", "Robert", ""]]}, {"id": "2104.12086", "submitter": "Chen Zhao", "authors": "Chen Zhao, Zhipeng Gao, Qian Wang, Kaile Xiao, Zijia Mo, M. Jamal Deen", "title": "FedSup: A Communication-Efficient Federated Learning Fatigue Driving\n  Behaviors Supervision Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the proliferation of edge smart devices and the Internet of Vehicles\n(IoV) technologies, intelligent fatigue detection has become one of the\nmost-used methods in our daily driving. To improve the performance of the\ndetection model, a series of techniques have been developed. However, existing\nwork still leaves much to be desired, such as privacy disclosure and\ncommunication cost. To address these issues, we propose FedSup, a\nclient-edge-cloud framework for privacy and efficient fatigue detection.\nInspired by the federated learning technique, FedSup intelligently utilizes the\ncollaboration between client, edge, and cloud server to realizing dynamic model\noptimization while protecting edge data privacy. Moreover, to reduce the\nunnecessary system communication overhead, we further propose a Bayesian\nconvolutional neural network (BCNN) approximation strategy on the clients and\nan uncertainty weighted aggregation algorithm on the cloud to enhance the\ncentral model training efficiency. Extensive experiments demonstrate that the\nFedSup framework is suitable for IoV scenarios and outperforms other mainstream\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 07:16:49 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Zhao", "Chen", ""], ["Gao", "Zhipeng", ""], ["Wang", "Qian", ""], ["Xiao", "Kaile", ""], ["Mo", "Zijia", ""], ["Deen", "M. Jamal", ""]]}, {"id": "2104.12163", "submitter": "Liangfeng Zhang", "authors": "Xin Chen, Liang Feng Zhang", "title": "Two-Server Verifiable Homomorphic Secret Sharing for High-Degree\n  Polynomials", "comments": "Proceedings of the 23rd Information Security Conference (ISC 2020)", "journal-ref": null, "doi": "10.1007/978-3-030-62974-8_5", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Homomorphic secret sharing (HSS) allows multiple input clients to\nsecret-share their data among multiple servers such that each server is able to\nlocally compute a function on its shares to obtain a partial result and all\npartial results enable the reconstruction of the function's value on the\noutsourced data by an output client. The existing HSS schemes for {\\em\nhigh-degree} polynomials either {\\em require a large number of servers} or {\\em\nlack verifiability}, which is essential for ensuring the correctness of the\noutsourced computations. In this paper, we propose a two-server verifiable HSS\n(VHSS) model and construct a scheme that supports the computation of\nhigh-degree polynomials. The degree of the outsourced polynomials can be as\nhigh as a polynomial in the system's security parameter. Despite of using only\n2 servers, our VHSS ensures that each single server learns no information about\nthe outsourced data and no single server is able to persuade the client to\noutput a wrong function value. Our VHSS is significantly more efficient. When\ncomputing degree-7 polynomials, our scheme could be 3-10 times faster than the\npreviously best construction.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 13:48:16 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Chen", "Xin", ""], ["Zhang", "Liang Feng", ""]]}, {"id": "2104.12255", "submitter": "Quan Thoi Minh Nguyen", "authors": "Quan Thoi Minh Nguyen", "title": "0", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  What is the funniest number in cryptography? 0. The reason is that for all x,\nx*0 = 0, i.e., the equation is always satisfied no matter what x is. This\narticle discusses crypto bugs in four BLS signatures' libraries (ethereum/py\necc, supranational/blst, herumi/bls, sigp/milagro bls) that revolve around 0.\nFurthermore, we develop \"splitting zero\" attacks to show a weakness in the\nproof-of-possession aggregate signature scheme standardized in BLS RFC draft\nv4. Eth2 bug bounties program generously awarded $35,000 in total for the\nreported bugs.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 16:07:14 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Nguyen", "Quan Thoi Minh", ""]]}, {"id": "2104.12295", "submitter": "Arlindo Flavio da Concei\\c{c}\\~ao", "authors": "Gabriel de Sousa Matsumura, Luciana Brasil Rebelo dos Santos, Arlindo\n  Flavio da Concei\\c{c}\\~ao, Nandamudi Lankalapalli Vijaykumar", "title": "Vulnerabilities and Open Issues of Smart Contracts: A Systematic Mapping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Smart Contracts (SCs) are programs stored in a Blockchain to ensure\nagreements between two or more parties. Due to the unchangeable essence of\nBlockchain, failures or errors in SCs become perpetual once published. The\nreliability of SCs is essential to avoid financial losses. So, SCs must be\nchecked to ensure the absence of errors. Hence, many studies addressed new\nmethods and tools for zero-bug software in SCs. This paper conducted a\nsystematic literature mapping identifying initiatives and tools to analyze SCs\nand how to deal with the identified vulnerabilities. Besides, this work\nidentifies gaps that may lead to research topics for future work.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 00:46:39 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 04:42:09 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Matsumura", "Gabriel de Sousa", ""], ["Santos", "Luciana Brasil Rebelo dos", ""], ["da Concei\u00e7\u00e3o", "Arlindo Flavio", ""], ["Vijaykumar", "Nandamudi Lankalapalli", ""]]}, {"id": "2104.12298", "submitter": "Arlindo Flavio da Concei\\c{c}\\~ao", "authors": "Alexandre Siqueira, Arlindo Flavio Da Concei\\c{c}\\~ao, Vladimir Rocha", "title": "Blockchains and Self-Sovereign Identities Applied to Healthcare\n  Solutions: A Systematic Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Self-Sovereign Identity (SSI), a Blockchain-based technology for digital\nidentity management, is a promising concept for handling health data. It could\nrepresent a step forward in empowering users, granting them control over their\ndata. This work conducts a systematic literature review to investigate\nstate-of-the-art measures based on SSI and Blockchain technologies for dealing\nwith electronic health records (EHRs), identifying gaps, and determining the\nkey questions for future research. As a result, this review shows a growing\ninterest in Blockchain methods to handle EHRs, but few works consider using the\nself-sovereign identity approaches. The results obtained in this work also\nsuggest that: Blockchain technologies provide a viable alternative to deliver\nEHR solutions such as patient monitoring, healthcare data trading, and\nprescription control; consolidated Blockchain technologies are the preferred\ncore components of most effective strategies; keeping raw health data off-chain\nhelps to create scalable solutions; health data standards make searching\nmedical records in Blockchain structures feasible; Smart Contracts are\nessential components of Blockchain-based EHR solutions; the concepts of data\nownership and Self-Sovereign Identity have been neither adequately defined nor\nemployed in the health context.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 00:58:16 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Siqueira", "Alexandre", ""], ["Da Concei\u00e7\u00e3o", "Arlindo Flavio", ""], ["Rocha", "Vladimir", ""]]}, {"id": "2104.12330", "submitter": "Liangfeng Zhang", "authors": "Xin Chen, Liang Feng Zhang", "title": "Two-Server Delegation of Computation on Label-Encrypted Data", "comments": "IEEE Transactions on Cloud Computing", "journal-ref": null, "doi": "10.1109/TCC.2019.2913375", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Catalano and Fiore propose a scheme to transform a linearly-homomorphic\nencryption into a homomorphic encryption scheme capable of evaluating quadratic\ncomputations on ciphertexts. Their scheme is based on the linearly-homomorphic\nencryption (such as Goldwasser-Micali, Paillier and ElGamal) and need to\nperform large integer operation on servers. Then, their scheme have numerous\ncomputations on the servers. At the same time, their scheme cannot verify the\ncomputations and cannot evaluate more than degree-4 computations. To solve\nthese problems, we no longer use linearly-homomorphic encryption which based on\nnumber theory assumptions. We use label and pseudorandom function to encrypt\nmessage, which significantly reduce the computations on the servers and enable\nus to use homomorphic MACs technology to realize verifiable computations\nnaturally. We also extend the method to construct $d$-server schemes, which\nallow the client to delegate degree-$d$ computations on outsourced data.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 03:34:21 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Chen", "Xin", ""], ["Zhang", "Liang Feng", ""]]}, {"id": "2104.12331", "submitter": "Liangfeng Zhang", "authors": "Liang Feng Zhang", "title": "Multi-Server Verifiable Delegation of Computations: Unconditional\n  Security and Practical Efficiency", "comments": "Information and Computation", "journal-ref": null, "doi": "10.1016/j.ic.2021.104740", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Outsourcing computation has gained significant popularity in recent years due\nto the prevalence of cloud computing. There are two main security concerns in\noutsourcing computation: how to guarantee the cloud server performs the\ncomputation correctly and how to keep the client's data secret. The {\\em\nsingle-server verifiable computation} (SSVC) of Gennaro, Gentry and Parno\n(Crypto'10) enables a client to delegate the computation of a function $f$ on\nany input $x$ with both concerns highly relieved, but only results in {\\em\ncomputationally secure} schemes that\n  {\\em lack practical efficiency}.\n  While the SSVC schemes use a single server, in this paper we develop a {\\em\nmulti-server verifiable computation} (MSVC) model where the client shares both\n$f$ and $x$ among multiple servers, each server performs a set of computations\non its shares, and finally the client reconstructs $f(x)$ from all servers'\nresults. In this MSVC model we propose a generic construction for outsourcing\ncomputations of the form $F{\\bf x}$, where $F$ is a matrix and $\\bf x$ is a\nvector. Our generic construction achieves {\\em information-theoretic security,\ninput privacy} and {\\em function privacy}. By optimizing the parameters, we\nobtain both a 3-server scheme,which uses the least number of servers, and a\n4-server scheme, which incurs the least workload. By decomposing many\npolynomial computations as a two-stage computation, where the first-stage has\nthe form $F{\\bf x}$ and the second-stage is fast, and delegating the\nfirst-stage computation, we obtain MSVC schemes for these polynomials. We\nimplement our MSVC schemes and show that they are among the most {\\em\npractical} ones to date.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 03:35:03 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Zhang", "Liang Feng", ""]]}, {"id": "2104.12385", "submitter": "Tudor Cebere BSc", "authors": "Adam James Hall, Madhava Jay, Tudor Cebere, Bogdan Cebere, Koen\n  Lennart van der Veen, George Muraru, Tongye Xu, Patrick Cason, William\n  Abramson, Ayoub Benaissa, Chinmay Shah, Alan Aboudib, Th\\'eo Ryffel, Kritika\n  Prakash, Tom Titcombe, Varun Kumar Khare, Maddie Shang, Ionesio Junior,\n  Animesh Gupta, Jason Paumier, Nahua Kang, Vova Manannikov, Andrew Trask", "title": "Syft 0.5: A Platform for Universally Deployable Structured Transparency", "comments": "ICLR 2021 Workshop on Distributed and Private Machine Learning (DPML\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Syft 0.5, a general-purpose framework that combines a core group\nof privacy-enhancing technologies that facilitate a universal set of structured\ntransparency systems. This framework is demonstrated through the design and\nimplementation of a novel privacy-preserving inference information flow where\nwe pass homomorphically encrypted activation signals through a split neural\nnetwork for inference. We show that splitting the model further up the\ncomputation chain significantly reduces the computation time of inference and\nthe payload size of activation signals at the cost of model secrecy. We\nevaluate our proposed flow with respect to its provision of the core structural\ntransparency principles.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 07:54:16 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 17:02:42 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Hall", "Adam James", ""], ["Jay", "Madhava", ""], ["Cebere", "Tudor", ""], ["Cebere", "Bogdan", ""], ["van der Veen", "Koen Lennart", ""], ["Muraru", "George", ""], ["Xu", "Tongye", ""], ["Cason", "Patrick", ""], ["Abramson", "William", ""], ["Benaissa", "Ayoub", ""], ["Shah", "Chinmay", ""], ["Aboudib", "Alan", ""], ["Ryffel", "Th\u00e9o", ""], ["Prakash", "Kritika", ""], ["Titcombe", "Tom", ""], ["Khare", "Varun Kumar", ""], ["Shang", "Maddie", ""], ["Junior", "Ionesio", ""], ["Gupta", "Animesh", ""], ["Paumier", "Jason", ""], ["Kang", "Nahua", ""], ["Manannikov", "Vova", ""], ["Trask", "Andrew", ""]]}, {"id": "2104.12426", "submitter": "Pavlos Papadopoulos", "authors": "Pavlos Papadopoulos, Oliver Thornewill von Essen, Nikolaos Pitropakis,\n  Christos Chrysoulas, Alexios Mylonas, William J. Buchanan", "title": "Launching Adversarial Attacks against Network Intrusion Detection\n  Systems for IoT", "comments": "MDPI Mach. Learn. Knowl. Extr. 2021, 3(2), 333-356;\n  https://www.mdpi.com/2624-800X/1/2/14", "journal-ref": "J. Cybersecur. Priv. 2021, 1(2), 252-273", "doi": "10.3390/jcp1020014", "report-no": null, "categories": "cs.LG cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the internet continues to be populated with new devices and emerging\ntechnologies, the attack surface grows exponentially. Technology is shifting\ntowards a profit-driven Internet of Things market where security is an\nafterthought. Traditional defending approaches are no longer sufficient to\ndetect both known and unknown attacks to high accuracy. Machine learning\nintrusion detection systems have proven their success in identifying unknown\nattacks with high precision. Nevertheless, machine learning models are also\nvulnerable to attacks. Adversarial examples can be used to evaluate the\nrobustness of a designed model before it is deployed. Further, using\nadversarial examples is critical to creating a robust model designed for an\nadversarial environment. Our work evaluates both traditional machine learning\nand deep learning models' robustness using the Bot-IoT dataset. Our methodology\nincluded two main approaches. First, label poisoning, used to cause incorrect\nclassification by the model. Second, the fast gradient sign method, used to\nevade detection measures. The experiments demonstrated that an attacker could\nmanipulate or circumvent detection with significant probability.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 09:36:29 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Papadopoulos", "Pavlos", ""], ["von Essen", "Oliver Thornewill", ""], ["Pitropakis", "Nikolaos", ""], ["Chrysoulas", "Christos", ""], ["Mylonas", "Alexios", ""], ["Buchanan", "William J.", ""]]}, {"id": "2104.12602", "submitter": "Alex Sim", "authors": "Jeeyung Kim, Alex Sim, Jinoh Kim, Kesheng Wu, Jaegyoon Hahm", "title": "Improving Botnet Detection with Recurrent Neural Network and Transfer\n  Learning", "comments": "arXiv admin note: text overlap with arXiv:2004.00234", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Botnet detection is a critical step in stopping the spread of botnets and\npreventing malicious activities. However, reliable detection is still a\nchallenging task, due to a wide variety of botnets involving ever-increasing\ntypes of devices and attack vectors. Recent approaches employing machine\nlearning (ML) showed improved performance than earlier ones, but these ML-\nbased approaches still have significant limitations. For example, most ML\napproaches can not incorporate sequential pattern analysis techniques key to\ndetect some classes of botnets. Another common shortcoming of ML-based\napproaches is the need to retrain neural networks in order to detect the\nevolving botnets; however, the training process is time-consuming and requires\nsignificant efforts to label the training data. For fast-evolving botnets, it\nmight take too long to create sufficient training samples before the botnets\nhave changed again. To address these challenges, we propose a novel botnet\ndetection method, built upon Recurrent Variational Autoencoder (RVAE) that\neffectively captures sequential characteristics of botnet activities. In the\nexperiment, this semi-supervised learning method achieves better detection\naccuracy than similar learning methods, especially on hard to detect classes.\nAdditionally, we devise a transfer learning framework to learn from a\nwell-curated source data set and transfer the knowledge to a target problem\ndomain not seen before. Tests show that the true-positive rate (TPR) with\ntransfer learning is higher than the RVAE semi-supervised learning method\ntrained using the target data set (91.8% vs. 68.3%).\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 14:05:01 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Kim", "Jeeyung", ""], ["Sim", "Alex", ""], ["Kim", "Jinoh", ""], ["Wu", "Kesheng", ""], ["Hahm", "Jaegyoon", ""]]}, {"id": "2104.12623", "submitter": "Sebastian Szyller", "authors": "Sebastian Szyller, Vasisht Duddu, Tommi Gr\\\"ondahl, N. Asokan", "title": "Good Artists Copy, Great Artists Steal: Model Extraction Attacks Against\n  Image Translation Generative Adversarial Networks", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are typically made available to potential client\nusers via inference APIs. Model extraction attacks occur when a malicious\nclient uses information gleaned from queries to the inference API of a victim\nmodel $F_V$ to build a surrogate model $F_A$ that has comparable functionality.\nRecent research has shown successful model extraction attacks against image\nclassification, and NLP models. In this paper, we show the first model\nextraction attack against real-world generative adversarial network (GAN) image\ntranslation models. We present a framework for conducting model extraction\nattacks against image translation models, and show that the adversary can\nsuccessfully extract functional surrogate models. The adversary is not required\nto know $F_V$'s architecture or any other information about it beyond its\nintended image translation task, and queries $F_V$'s inference interface using\ndata drawn from the same domain as the training data for $F_V$. We evaluate the\neffectiveness of our attacks using three different instances of two popular\ncategories of image translation: (1) Selfie-to-Anime and (2) Monet-to-Photo\n(image style transfer), and (3) Super-Resolution (super resolution). Using\nstandard performance metrics for GANs, we show that our attacks are effective\nin each of the three cases -- the differences between $F_V$ and $F_A$, compared\nto the target are in the following ranges: Selfie-to-Anime: FID $13.36-68.66$,\nMonet-to-Photo: FID $3.57-4.40$, and Super-Resolution: SSIM: $0.06-0.08$ and\nPSNR: $1.43-4.46$. Furthermore, we conducted a large scale (125 participants)\nuser study on Selfie-to-Anime and Monet-to-Photo to show that human perception\nof the images produced by the victim and surrogate models can be considered\nequivalent, within an equivalence bound of Cohen's $d=0.3$.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 14:50:59 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Szyller", "Sebastian", ""], ["Duddu", "Vasisht", ""], ["Gr\u00f6ndahl", "Tommi", ""], ["Asokan", "N.", ""]]}, {"id": "2104.12810", "submitter": "Simona Etinski", "authors": "Andr\\'e Chailloux, Thomas Debris-Alazard, Simona Etinski", "title": "Classical and Quantum algorithms for generic Syndrome Decoding problems\n  and applications to the Lee metric", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The security of code-based cryptography usually relies on the hardness of the\nsyndrome decoding (SD) problem for the Hamming weight. The best generic\nalgorithms are all improvements of an old algorithm by Prange, and they are\nknown under the name of Information Set Decoding (ISD) algorithms. This work\naims to extend ISD algorithms' scope by changing the underlying weight function\nand alphabet size of SD. More precisely, we show how to use Wagner's algorithm\nin the ISD framework to solve SD for a wide range of weight functions. We also\ncalculate the asymptotic complexities of ISD algorithms both in the classical\nand quantum case. We then apply our results to the Lee metric, which currently\nreceives a significant amount of attention. By providing the parameters of SD\nfor which decoding in the Lee weight seems to be the hardest, our study could\nhave several applications for designing code-based cryptosystems and their\nsecurity analysis, especially against quantum adversaries.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 18:19:56 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Chailloux", "Andr\u00e9", ""], ["Debris-Alazard", "Thomas", ""], ["Etinski", "Simona", ""]]}, {"id": "2104.12848", "submitter": "Luca Demetrio", "authors": "Luca Demetrio and Battista Biggio", "title": "secml-malware: Pentesting Windows Malware Classifiers with Adversarial\n  EXEmples in Python", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has been increasingly used as a first line of defense for\nWindows malware detection. Recent work has however shown that learning-based\nmalware detectors can be evaded by carefully-perturbed input malware samples,\nreferred to as adversarial EXEmples, thus demanding for tools that can ease and\nautomate the adversarial robustness evaluation of such detectors. To this end,\nwe present secml-malware, the first Python library for computing adversarial\nattacks on Windows malware detectors. \\secmlmalware implements state-of-the-art\nwhite-box and black-box attacks on Windows malware classifiers, by leveraging a\nset of feasible manipulations that can be applied to Windows programs while\npreserving their functionality. The library can be used to perform the\npenetration testing and assessment of the adversarial robustness of Windows\nmalware detectors, and it can be easily extended to include novel attack\nstrategies. Our library is available at\nhttps://github.com/pralab/secml_malware.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 19:53:30 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 07:15:40 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Demetrio", "Luca", ""], ["Biggio", "Battista", ""]]}, {"id": "2104.12878", "submitter": "Khondokar Fida Hasan", "authors": "Khondokar Fida Hasan, Anthony Overall, Keyvan Ansari, Gowri\n  Ramachandran, Raja Jurdak", "title": "Security, Privacy and Trust: Cognitive Internet of Vehicles", "comments": "19 pages, book chapter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The recent advancement of cloud technology offers unparallel strength to\nsupport intelligent computations and advanced services to assist with automated\ndecisions to improve road transportation safety and comfort. Besides, the rise\nof machine intelligence propels the technological evolution of transportation\nsystems one step further and leads to a new framework known as Cognitive\nInternet of Vehicles (C-IoV). The redefined cognitive technology in this\nframework promises significant enhancements and optimized network capacities\ncompared with its predecessor framework, the Internet of Vehicles (IoV). CIoV\noffers additional security measures and introduces security and privacy\nconcerns, such as evasion attacks, additional threats of data poisoning, and\nlearning errors, which may likely lead to system failure and road user\nfatalities. Similar to many other public enterprise systems, transportation has\na significant impact on the population. Therefore, it is crucial to understand\nthe evolution and equally essential to identify potential security\nvulnerabilities and issues to offer mitigation towards success. This chapter\noffers discussions framing answers to the following two questions, 1) how and\nin what ways the penetration of the latest technologies are reshaping the\ntransportation system? 2) whether the evolved system is capable of addressing\nthe concerns of cybersecurity? This chapter, therefore, starts presenting the\nevolution of the transportation system followed by a quick overview of the\nevolved CIoV, highlighting the evolved cognitive design. Later it presents how\na cognitive engine can overcome legacy security concerns and also be subjected\nto further potential security, privacy, and trust issues that this cloud-based\nevolved transportation system may encounter.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 21:05:03 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Hasan", "Khondokar Fida", ""], ["Overall", "Anthony", ""], ["Ansari", "Keyvan", ""], ["Ramachandran", "Gowri", ""], ["Jurdak", "Raja", ""]]}, {"id": "2104.13049", "submitter": "Dinh Nguyen", "authors": "Prabadevi B, N Deepa, Quoc-Viet Pham, Dinh C. Nguyen, Praveen Kumar\n  Reddy M, Thippa Reddy G, Pubudu N. Pathirana, Octavia Dobre", "title": "Toward Blockchain for Edge-of-Things: A New Paradigm, Opportunities, and\n  Future Directions", "comments": "Accepted at the IEEE Internet of Things Magazine", "journal-ref": null, "doi": "10.1109/IOTM.0001.2000191", "report-no": null, "categories": "cs.CR eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain is gaining momentum as a promising technology for many application\ndomains, one of them being the Edge-of- Things (EoT) that is enabled by the\nintegration of edge computing and the Internet-of-Things (IoT). Particularly,\nthe amalgamation of blockchain and EoT leads to a new paradigm, called\nblockchain enabled EoT (BEoT) that is crucial for enabling future low-latency\nand high-security services and applications. This article envisions a novel\nBEoT architecture for supporting industrial applications under the management\nof blockchain at the network edge in a wide range of IoT use cases such as\nsmart home, smart healthcare, smart grid, and smart transportation. The\npotentials of BEoT in providing security services are also explored, including\naccess authentication, data privacy preservation, attack detection, and trust\nmanagement. Finally, we point out some key research challenges and future\ndirections in this emerging area.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 08:48:12 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["B", "Prabadevi", ""], ["Deepa", "N", ""], ["Pham", "Quoc-Viet", ""], ["Nguyen", "Dinh C.", ""], ["M", "Praveen Kumar Reddy", ""], ["G", "Thippa Reddy", ""], ["Pathirana", "Pubudu N.", ""], ["Dobre", "Octavia", ""]]}, {"id": "2104.13061", "submitter": "Bal\\'azs Pej\\'o", "authors": "Mathias P. M. Parisot, Balazs Pejo and Dayana Spagnuelo", "title": "Property Inference Attacks on Convolutional Neural Networks: Influence\n  and Implications of Target Model's Complexity", "comments": "The long version of the paper \"Property Inference Attacks,\n  Convolutional Neural Networks, Model Complexity\" from SECRYPT'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine learning models' goal is to make correct predictions for specific\ntasks by learning important properties and patterns from data. By doing so,\nthere is a chance that the model learns properties that are unrelated to its\nprimary task. Property Inference Attacks exploit this and aim to infer from a\ngiven model (\\ie the target model) properties about the training dataset\nseemingly unrelated to the model's primary goal. If the training data is\nsensitive, such an attack could lead to privacy leakage. This paper\ninvestigates the influence of the target model's complexity on the accuracy of\nthis type of attack, focusing on convolutional neural network classifiers. We\nperform attacks on models that are trained on facial images to predict whether\nsomeone's mouth is open. Our attacks' goal is to infer whether the training\ndataset is balanced gender-wise. Our findings reveal that the risk of a privacy\nbreach is present independently of the target model's complexity: for all\nstudied architectures, the attack's accuracy is clearly over the baseline. We\ndiscuss the implication of the property inference on personal data in the light\nof Data Protection Regulations and Guidelines.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 09:19:36 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Parisot", "Mathias P. M.", ""], ["Pejo", "Balazs", ""], ["Spagnuelo", "Dayana", ""]]}, {"id": "2104.13130", "submitter": "Shuo Yuan", "authors": "Shuo Yuan, Bin Cao, Yao Sun, Mugen Peng", "title": "Secure and Efficient Federated Learning Through Layering and Sharding\n  Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) has emerged as a promising master/slave learning\nparadigm to alleviate systemic privacy risks and communication costs incurred\nby cloud-centric machine learning methods. However, it is very challenging to\nresist the single point of failure of the master aggregator and attacks from\nmalicious participants while guaranteeing model convergence speed and accuracy.\nRecently, blockchain has been brought into FL systems transforming the paradigm\nto a decentralized manner thus further improve the system security and learning\nreliability. Unfortunately, the traditional consensus mechanism and\narchitecture of blockchain systems can hardly handle the large-scale FL task\ndue to the huge resource consumption, limited transaction throughput, and high\ncommunication complexity. To address these issues, this paper proposes a\ntwo-layer blockchaindriven FL framework, called as ChainsFL, which is composed\nof multiple subchain networks (subchain layer) and a direct acyclic graph\n(DAG)-based mainchain (mainchain layer). In ChainsFL, the subchain layer limits\nthe scale of each shard for a small range of information exchange, and the\nmainchain layer allows each shard to share and validate the learning model in\nparallel and asynchronously to improve the efficiency of cross-shard\nvalidation. Furthermore, the FL procedure is customized to deeply integrate\nwith blockchain technology, and the modified DAG consensus mechanism is\nproposed to mitigate the distortion caused by abnormal models. In order to\nprovide a proof-ofconcept implementation and evaluation, multiple subchains\nbase on Hyperledger Fabric are deployed as the subchain layer, and the\nself-developed DAG-based mainchain is deployed as the mainchain layer. The\nexperimental results show that ChainsFL provides acceptable and sometimes\nbetter training efficiency and stronger robustness compared with the typical\nexisting FL systems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 12:19:07 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Yuan", "Shuo", ""], ["Cao", "Bin", ""], ["Sun", "Yao", ""], ["Peng", "Mugen", ""]]}, {"id": "2104.13190", "submitter": "Md Tahmid Rahman Laskar", "authors": "Md Tahmid Rahman Laskar, Jimmy Huang, Vladan Smetana, Chris Stewart,\n  Kees Pouw, Aijun An, Stephen Chan, Lei Liu", "title": "Extending Isolation Forest for Anomaly Detection in Big Data via K-Means", "comments": "The final version will be published at ACM Transactions on\n  Cyber-Physical Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Industrial Information Technology (IT) infrastructures are often vulnerable\nto cyberattacks. To ensure security to the computer systems in an industrial\nenvironment, it is required to build effective intrusion detection systems to\nmonitor the cyber-physical systems (e.g., computer networks) in the industry\nfor malicious activities. This paper aims to build such intrusion detection\nsystems to protect the computer networks from cyberattacks. More specifically,\nwe propose a novel unsupervised machine learning approach that combines the\nK-Means algorithm with the Isolation Forest for anomaly detection in industrial\nbig data scenarios. Since our objective is to build the intrusion detection\nsystem for the big data scenario in the industrial domain, we utilize the\nApache Spark framework to implement our proposed model which was trained in\nlarge network traffic data (about 123 million instances of network traffic)\nstored in Elasticsearch. Moreover, we evaluate our proposed model on the live\nstreaming data and find that our proposed system can be used for real-time\nanomaly detection in the industrial setup. In addition, we address different\nchallenges that we face while training our model on large datasets and\nexplicitly describe how these issues were resolved. Based on our empirical\nevaluation in different use-cases for anomaly detection in real-world network\ntraffic data, we observe that our proposed system is effective to detect\nanomalies in big data scenarios. Finally, we evaluate our proposed model on\nseveral academic datasets to compare with other models and find that it\nprovides comparable performance with other state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 16:21:48 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Laskar", "Md Tahmid Rahman", ""], ["Huang", "Jimmy", ""], ["Smetana", "Vladan", ""], ["Stewart", "Chris", ""], ["Pouw", "Kees", ""], ["An", "Aijun", ""], ["Chan", "Stephen", ""], ["Liu", "Lei", ""]]}, {"id": "2104.13193", "submitter": "Prakhar Sharma", "authors": "Prakhar Sharma, Phillip Porras, Steven Cheung, James Carpenter, Vinod\n  Yegneswaran", "title": "Scalable Microservice Forensics and Stability Assessment Using\n  Variational Autoencoders", "comments": "4 pages, appendix, references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a deep learning based approach to containerized application\nruntime stability analysis, and an intelligent publishing algorithm that can\ndynamically adjust the depth of process-level forensics published to a backend\nincident analysis repository. The approach applies variational autoencoders\n(VAEs) to learn the stable runtime patterns of container images, and then\ninstantiates these container-specific VAEs to implement stability detection and\nadaptive forensics publishing. In performance comparisons using a 50-instance\ncontainer workload, a VAE-optimized service versus a conventional eBPF-based\nforensic publisher demonstrates 2 orders of magnitude (OM) CPU performance\nimprovement, a 3 OM reduction in network transport volume, and a 4 OM reduction\nin Elasticsearch storage costs. We evaluate the VAE-based stability detection\ntechnique against two attacks, CPUMiner and HTTP-flood attack, finding that it\nis effective in isolating both anomalies. We believe this technique provides a\nnovel approach to integrating fine-grained process monitoring and\ndigital-forensic services into large container ecosystems that today simply\ncannot be monitored by conventional techniques\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 18:51:41 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Sharma", "Prakhar", ""], ["Porras", "Phillip", ""], ["Cheung", "Steven", ""], ["Carpenter", "James", ""], ["Yegneswaran", "Vinod", ""]]}, {"id": "2104.13195", "submitter": "Nathan Danneman", "authors": "Nathan Danneman, James Hyde", "title": "Predicting Adversary Lateral Movement Patterns with Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper develops a predictive model for which host, in an enterprise\nnetwork, an adversary is likely to compromise next in the course of a campaign.\nSuch a model might support dynamic monitoring or defenses. We generate data for\nthis model using simulated networks, with hosts, users, and adversaries as\nfirst-class entities. We demonstrate the predictive accuracy of the model on\nout-of-sample simulated data, and validate the findings against data captured\nfrom a Red Team event on a live enterprise network\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 16:44:31 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Danneman", "Nathan", ""], ["Hyde", "James", ""]]}, {"id": "2104.13196", "submitter": "Sotirios Katsikeas", "authors": "Sotirios Katsikeas, Pontus Johnson, Mathias Ekstedt, Robert\n  Lagerstr\\\"om", "title": "Research Communities in cyber security: A Comprehensive Literature\n  Review", "comments": "arXiv admin note: text overlap with arXiv:0803.0476 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In order to provide a coherent overview of cyber security research, the\nScopus academic abstract and citation database was mined to create a citation\ngraph of 98,373 authors active in the field between 1949 and early 2020. The\nLouvain community detection algorithm was applied to the graph in order to\nidentify existing research communities. The analysis discovered twelve\ntop-level communities: access control, authentication, biometrics, cryptography\n(I & II), cyber-physical systems, information hiding, intrusion detection,\nmalwares, quantum cryptography, sensor networks, and usable security. These\ntop-level communities were in turn composed of a total of 80 sub-communities.\nThe analysis results are presented for each community in descriptive text,\nsub-community graphs, and tables with, for example, the most-cited papers and\nauthors. A comparison between the detected communities and topical areas\ndefined by other related work, is also presented, demonstrating a greater\nresearcher emphasis on cryptography, quantum cryptography, information hiding\nand biometrics, at the expense of laws and regulation, risk management and\ngovernance, and security software lifecycle.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 14:53:01 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Katsikeas", "Sotirios", ""], ["Johnson", "Pontus", ""], ["Ekstedt", "Mathias", ""], ["Lagerstr\u00f6m", "Robert", ""]]}, {"id": "2104.13215", "submitter": "Elsa Rizk", "authors": "Elsa Rizk and Ali H. Sayed", "title": "A Graph Federated Architecture with Privacy Preserving Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning involves a central processor that works with multiple\nagents to find a global model. The process consists of repeatedly exchanging\nestimates, which results in the diffusion of information pertaining to the\nlocal private data. Such a scheme can be inconvenient when dealing with\nsensitive data, and therefore, there is a need for the privatization of the\nalgorithms. Furthermore, the current architecture of a server connected to\nmultiple clients is highly sensitive to communication failures and\ncomputational overloads at the server. Thus in this work, we develop a private\nmulti-server federated learning scheme, which we call graph federated learning.\nWe use cryptographic and differential privacy concepts to privatize the\nfederated learning algorithm that we extend to the graph structure. We study\nthe effect of privatization on the performance of the learning algorithm for\ngeneral private schemes that can be modeled as additive noise. We show under\nconvexity and Lipschitz conditions, that the privatized process matches the\nperformance of the non-private algorithm, even when we increase the noise\nvariance.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 09:51:24 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Rizk", "Elsa", ""], ["Sayed", "Ali H.", ""]]}, {"id": "2104.13224", "submitter": "Safa Otoum", "authors": "Safa Otoum, Ismaeel Al Ridhawi, Hussein T. Mouftah", "title": "Preventing and Controlling Epidemics through Blockchain-Assisted\n  AI-Enabled Networks", "comments": "Accepted in IEEE Network Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The COVID-19 pandemic, which spread rapidly in late 2019, has revealed that\nthe use of computing and communication technologies provides significant aid in\npreventing, controlling, and combating infectious diseases. With the ongoing\nresearch in next-generation networking (NGN), the use of secure and reliable\ncommunication and networking is of utmost importance when dealing with users'\nhealth records and other sensitive information. Through the adaptation of\nArtificial Intelligence (AI)-enabled NGN, the shape of healthcare systems can\nbe altered to achieve smart and secure healthcare capable of coping with\nepidemics that may emerge at any given moment. In this article, we envision a\ncooperative and distributed healthcare framework that relies on\nstate-of-the-art computing, communication, and intelligence capabilities,\nnamely, Federated Learning (FL), mobile edge computing (MEC), and Blockchain,\nto enable epidemic (or suspicious infectious disease) discovery, remote\nmonitoring, and fast health-authority response. The introduced framework can\nalso enable secure medical data exchange at the edge and between different\nhealth entities. Such a technique, coupled with the low latency and high\nbandwidth functionality of 5G and beyond networks, would enable mass\nsurveillance, monitoring and analysis to occur at the edge. Challenges, issues,\nand design guidelines are also discussed in this article with highlights on\nsome trending solutions.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 20:07:08 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Otoum", "Safa", ""], ["Ridhawi", "Ismaeel Al", ""], ["Mouftah", "Hussein T.", ""]]}, {"id": "2104.13230", "submitter": "Manish Shukla", "authors": "Sanjay Seetharaman, Shubham Malaviya, Rosni KV, Manish Shukla, Sachin\n  Lodha", "title": "Influence Based Defense Against Data Poisoning Attacks in Online\n  Learning", "comments": "18 pages, 3 Figures, 2 Tables, Adversarial Machine Learning, Data\n  Poisoning, Online Learning, Defense, Influence Function", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Data poisoning is a type of adversarial attack on training data where an\nattacker manipulates a fraction of data to degrade the performance of machine\nlearning model. Therefore, applications that rely on external data-sources for\ntraining data are at a significantly higher risk. There are several known\ndefensive mechanisms that can help in mitigating the threat from such attacks.\nFor example, data sanitization is a popular defensive mechanism wherein the\nlearner rejects those data points that are sufficiently far from the set of\ntraining instances. Prior work on data poisoning defense primarily focused on\noffline setting, wherein all the data is assumed to be available for analysis.\nDefensive measures for online learning, where data points arrive sequentially,\nhave not garnered similar interest.\n  In this work, we propose a defense mechanism to minimize the degradation\ncaused by the poisoned training data on a learner's model in an online setup.\nOur proposed method utilizes an influence function which is a classic technique\nin robust statistics. Further, we supplement it with the existing data\nsanitization methods for filtering out some of the poisoned data points. We\nstudy the effectiveness of our defense mechanism on multiple datasets and\nacross multiple attack strategies against an online learner.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 08:39:13 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Seetharaman", "Sanjay", ""], ["Malaviya", "Shubham", ""], ["KV", "Rosni", ""], ["Shukla", "Manish", ""], ["Lodha", "Sachin", ""]]}, {"id": "2104.13254", "submitter": "John Emanuello Ph.D.", "authors": "John Emanuello, Kimberly Ferguson-Walter, Erik Hemberg, Una-May O\n  Reilly, Ahmad Ridley, Dennis Ross, Diane Staheli, William Streilein", "title": "Proceedings - AI/ML for Cybersecurity: Challenges, Solutions, and Novel\n  Ideas at SIAM Data Mining 2021", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malicious cyber activity is ubiquitous and its harmful effects have dramatic\nand often irreversible impacts on society. Given the shortage of cybersecurity\nprofessionals, the ever-evolving adversary, the massive amounts of data which\ncould contain evidence of an attack, and the speed at which defensive actions\nmust be taken, innovations which enable autonomy in cybersecurity must continue\nto expand, in order to move away from a reactive defense posture and towards a\nmore proactive one.\n  The challenges in this space are quite different from those associated with\napplying AI in other domains such as computer vision. The environment suffers\nfrom an incredibly high degree of uncertainty, stemming from the intractability\nof ingesting all the available data, as well as the possibility that malicious\nactors are manipulating the data. Another unique challenge in this space is the\ndynamism of the adversary causes the indicators of compromise to change\nfrequently and without warning.\n  In spite of these challenges, machine learning has been applied to this\ndomain and has achieved some success in the realm of detection. While this\naspect of the problem is far from solved, a growing part of the commercial\nsector is providing ML-enhanced capabilities as a service. Many of these\nentities also provide platforms which facilitate the deployment of these\nautomated solutions. Academic research in this space is growing and continues\nto influence current solutions, as well as strengthen foundational knowledge\nwhich will make autonomous agents in this space a possibility.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 17:35:31 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 15:01:28 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Emanuello", "John", ""], ["Ferguson-Walter", "Kimberly", ""], ["Hemberg", "Erik", ""], ["Reilly", "Una-May O", ""], ["Ridley", "Ahmad", ""], ["Ross", "Dennis", ""], ["Staheli", "Diane", ""], ["Streilein", "William", ""]]}, {"id": "2104.13285", "submitter": "Ricard Delgado-Gonzalo", "authors": "Oscar Benedito, Ricard Delgado-Gonzalo, Valerio Schiavoni", "title": "KEVLAR-TZ: A Secure Cache for ARM TrustZone", "comments": "15 pages, 21st International Conference on Distributed Applications\n  and Interoperable Systems (DAIS21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Edge devices are increasingly in charge of storing privacy-sensitive data, in\nparticular implantables, wearables, and nearables can potentially collect and\nprocess high-resolution vital signs 24/7. Storing and performing computations\nover such data in a privacy-preserving fashion is of paramount importance. We\npresent KEVLAR-TZ, an application-level trusted cache designed to leverage ARM\nTrustZone, a popular trusted execution environment available in consumer-grade\ndevices. To facilitate the integration with existing systems and IoT devices\nand protocols, KEVLAR-TZ exposes a REST-based interface with connection\nendpoints inside the TrustZone enclave. Furthermore, it exploits the on-device\nsecure persistent storage to guarantee durability of data across reboots. We\nfully implemented KEVLAR-TZ on top of the OP-TEE framework, and experimentally\nevaluated its performance. Our results showcase performance trade-offs, for\ninstance in terms of throughput and latency, for various workloads, and we\nbelieve our results can be useful for practitioners and in general developers\nof systems for TrustZone. KEVLAR-TZ is available as open-source at\nhttps://github.com/mqttz/kevlar-tz/.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 15:55:01 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Benedito", "Oscar", ""], ["Delgado-Gonzalo", "Ricard", ""], ["Schiavoni", "Valerio", ""]]}, {"id": "2104.13295", "submitter": "Shirish Singh", "authors": "Shirish Singh and Gail Kaiser", "title": "Metamorphic Detection of Repackaged Malware", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning-based malware detection systems are often vulnerable to\nevasion attacks, in which a malware developer manipulates their malicious\nsoftware such that it is misclassified as benign. Such software hides some\nproperties of the real class or adopts some properties of a different class by\napplying small perturbations. A special case of evasive malware hides by\nrepackaging a bonafide benign mobile app to contain malware in addition to the\noriginal functionality of the app, thus retaining most of the benign properties\nof the original app. We present a novel malware detection system based on\nmetamorphic testing principles that can detect such benign-seeming malware\napps. We apply metamorphic testing to the feature representation of the mobile\napp rather than to the app itself. That is, the source input is the original\nfeature vector for the app and the derived input is that vector with selected\nfeatures removed. If the app was originally classified benign and is indeed\nbenign, the output for the source and derived inputs should be the same class,\ni.e., benign, but if they differ, then the app is exposed as likely malware.\nMalware apps originally classified as malware should retain that classification\nsince only features prevalent in benign apps are removed. This approach enables\nthe machine learning model to classify repackaged malware with reasonably few\nfalse negatives and false positives. Our training pipeline is simpler than many\nexisting ML-based malware detection methods, as the network is trained\nend-to-end to learn appropriate features and perform classification. We\npre-trained our classifier model on 3 million apps collected from the\nwidely-used AndroZoo dataset. We perform an extensive study on other publicly\navailable datasets to show our approach's effectiveness in detecting repackaged\nmalware with more than94% accuracy, 0.98 precision, 0.95 recall, and 0.96 F1\nscore.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 16:08:49 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Singh", "Shirish", ""], ["Kaiser", "Gail", ""]]}, {"id": "2104.13303", "submitter": "Jacopo Soldani", "authors": "Francisco Ponce, Jacopo Soldani, Hern\\'an Astudillo, Antonio Brogi", "title": "Smells and Refactorings for Microservices Security: A Multivocal\n  Literature Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context: Securing microservice-based applications is crucial, as many IT\ncompanies are delivering their businesses through microservices. If security\nsmells affect microservice-based applications, they can possibly suffer from\nsecurity leaks and need to be refactored to mitigate the effects of security\nsmells therein. Objective: As the currently available knowledge on securing\nmicroservices is scattered across different pieces of white and grey\nliterature, our objective here is to distill well-known smells for securing\nmicroservices, together with the refactorings enabling to mitigate the effects\nof such smells. Method: To capture the state of the art and practice in\nsecuring microservices, we conducted a multivocal review of the existing white\nand grey literature on the topic. We systematically analyzed 58 studies\npublished from 2014 until the end of 2020. Results: Ten bad smells for securing\nmicroservices are identified, which we organized in a taxonomy, associating\neach smell with the security properties it may violate and the refactorings\nenabling to mitigate its effects. Conclusions: The security smells and the\ncorresponding refactorings have pragmatic value for practitioners, who can\nexploit them in their daily work on securing microservices. They also serve as\na starting point for researchers wishing to establish new research directions\non securing microservices.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 16:24:09 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Ponce", "Francisco", ""], ["Soldani", "Jacopo", ""], ["Astudillo", "Hern\u00e1n", ""], ["Brogi", "Antonio", ""]]}, {"id": "2104.13318", "submitter": "Rony Komissarov", "authors": "Rony Komissarov, Avishai Wool", "title": "Spoofing Attacks Against Vehicular FMCW Radar", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The safety and security of the passengers in vehicles in the face of cyber\nattacks is a key element in the automotive industry, especially with the\nemergence of the Advanced Driver Assistance Systems (ADAS) and the vast\nimprovement in Autonomous Vehicles (AVs). Such platforms use various sensors,\nincluding cameras, LiDAR and mmWave radar. These sensors themselves may present\na potential security hazard if exploited by an attacker.\n  In this paper we propose a system to attack an automotive FMCW mmWave radar,\nthat uses fast chirp modulation. Using a single rogue radar, our attack system\nis capable of spoofing the distance and velocity measured by the victim vehicle\nsimultaneously, presenting phantom measurements coherent with the laws of\nphysics governing vehicle motion. The attacking radar controls the delay in\norder to spoof its distance, and uses phase compensation and control in order\nto spoof its velocity. After developing the attack theory, we demonstrate the\nspoofing attack by building a proof-of-concept hardware-based system, using a\nSoftware Defined Radio. We successfully demonstrate two real world scenarios in\nwhich the victim radar is spoofed to detect either a phantom emergency stop or\na phantom acceleration, while measuring coherent range and velocity. We also\ndiscuss several countermeasures to the attack, in order to propose ways to\nmitigate the described attack.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 16:50:58 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Komissarov", "Rony", ""], ["Wool", "Avishai", ""]]}, {"id": "2104.13339", "submitter": "Zhaofeng Liu", "authors": "Zhaofeng Liu and Wenlian Lu and Yingying Lang", "title": "An Event-based Parameter Switching Method for Controlling Cybersecurity\n  Dynamics", "comments": "21 pages, 10 figures, 1 algorithm. may be submitted to SciSec\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY math.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new event-based parameter switching method for the\ncontrol tasks of cybersecurity in the context of preventive and reactive cyber\ndefense dynamics. Our parameter switching method helps avoid excessive control\ncosts as well as guarantees the dynamics to converge as our desired speed.\nMeanwhile, it can be proved that this approach is Zeno-free. A new estimation\nmethod with adaptive time windows is used to bridge the gap between the\nprobability state and the sampling state. With the new estimation method,\nseveral practical experiments are given afterwards.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 17:19:55 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Liu", "Zhaofeng", ""], ["Lu", "Wenlian", ""], ["Lang", "Yingying", ""]]}, {"id": "2104.13361", "submitter": "Abigail Mabe", "authors": "Abigail Mabe", "title": "A Chromium-based Memento-aware Web Browser", "comments": "33 pages, 38 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Web browsers provide a user-friendly means of navigating the web. Users rely\non their web browser to provide information about the websites they are\nvisiting, such as the security state. Browsers also provide a user interface\n(UI) with visual cues about each tab that is open, including icons for if the\ntab is playing audio or requires authentication to view. However, current\nbrowsers do not differentiate between the live web and the past web. If a user\nloads an archived webpage, known as a memento, they have to rely on UI elements\npresent within the page itself to inform them that the page they are viewing is\nnot the live web. Additionally, memento-awareness extends beyond recognizing a\npage that has already been archived. The browser should give users the ability\nto archive live webpages, essentially creating mementos of webpages they found\nimportant as they surf the web. In this report, the process to create a\nproof-of-concept browser that is aware of mementos is presented. The browser is\ncreated by adding on to the implementation of the open source web browser by\nGoogle, Chromium. Creating this prototype for a Memento-aware Browser shows\nthat the features implemented fit well into the current Chromium\nimplementation. The user experience is enhanced by adding the\nmemento-awareness, and the changes to the Chromium code base are minimal.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 17:43:18 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Mabe", "Abigail", ""]]}, {"id": "2104.13450", "submitter": "Innfarn Yoo", "authors": "Innfarn Yoo and Huiwen Chang and Xiyang Luo and Ondrej Stava and Ce\n  Liu and Peyman Milanfar and Feng Yang", "title": "Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and\n  Extracting Them from 2D Renderings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Digital watermarking is widely used for copyright protection. Traditional 3D\nwatermarking approaches or commercial software are typically designed to embed\nmessages into 3D meshes, and later retrieve the messages directly from\ndistorted/undistorted watermarked 3D meshes. Retrieving messages from 2D\nrenderings of such meshes, however, is still challenging and underexplored. We\nintroduce a novel end-to-end learning framework to solve this problem through:\n1) an encoder to covertly embed messages in both mesh geometry and textures; 2)\na differentiable renderer to render watermarked 3D objects from different\ncamera angles and under varied lighting conditions; 3) a decoder to recover the\nmessages from 2D rendered images. From extensive experiments, we show that our\nmodels learn to embed information visually imperceptible to humans, and to\nreconstruct the embedded information from 2D renderings robust to 3D\ndistortions. In addition, we demonstrate that our method can be generalized to\nwork with different renderers, such as ray tracers and real-time renderers.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 19:51:39 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 05:37:55 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Yoo", "Innfarn", ""], ["Chang", "Huiwen", ""], ["Luo", "Xiyang", ""], ["Stava", "Ondrej", ""], ["Liu", "Ce", ""], ["Milanfar", "Peyman", ""], ["Yang", "Feng", ""]]}, {"id": "2104.13484", "submitter": "Mahmoud Hossam", "authors": "Mahmoud Hossam, Trung Le, He Zhao, Viet Huynh, Dinh Phung", "title": "Improved and Efficient Text Adversarial Attacks using Target Information", "comments": "Accepted in the International Conference on Learning Representations\n  (ICLR) workshop on Robust and Reliable Machine Learning in the Real World\n  (RobustML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been recently a growing interest in studying adversarial examples\non natural language models in the black-box setting. These methods attack\nnatural language classifiers by perturbing certain important words until the\nclassifier label is changed. In order to find these important words, these\nmethods rank all words by importance by querying the target model word by word\nfor each input sentence, resulting in high query inefficiency. A new\ninteresting approach was introduced that addresses this problem through\ninterpretable learning to learn the word ranking instead of previous expensive\nsearch. The main advantage of using this approach is that it achieves\ncomparable attack rates to the state-of-the-art methods, yet faster and with\nfewer queries, where fewer queries are desirable to avoid suspicion towards the\nattacking agent. Nonetheless, this approach sacrificed the useful information\nthat could be leveraged from the target classifier for that sake of query\nefficiency. In this paper we study the effect of leveraging the target model\noutputs and data on both attack rates and average number of queries, and we\nshow that both can be improved, with a limited overhead of additional queries.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 21:25:55 GMT"}, {"version": "v2", "created": "Sun, 2 May 2021 08:49:09 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Hossam", "Mahmoud", ""], ["Le", "Trung", ""], ["Zhao", "He", ""], ["Huynh", "Viet", ""], ["Phung", "Dinh", ""]]}, {"id": "2104.13543", "submitter": "Bowen Liu", "authors": "Yangguang Tian, Bowen Liu, Yingjiu Li, Pawel Szalachowski, Jianying\n  Zhou", "title": "Accountable Fine-grained Blockchain Rewriting in the Permissionless\n  Setting", "comments": "Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Blockchain rewriting with fine-grained access control allows a user to create\na transaction associated with a set of attributes, while another user (or\nmodifier) who possesses enough rewriting privileges from a trusted authority\nsatisfying the attribute set can rewrite the transaction. However, it lacks\naccountability and is not designed for open blockchains that require no trust\nassumptions. In this work, we introduce accountable fine-grained blockchain\nrewriting in a permissionless setting. The property of accountability allows\nthe modifier's identity and her rewriting privileges to be held accountable for\nthe modified transactions in case of malicious rewriting (e.g., modify the\nregistered content from good to bad). We first present a generic framework to\nsecure blockchain rewriting in the permissionless setting. Second, we present\nan instantiation of our approach and show its practicality through evaluation\nanalysis. Last, we demonstrate that our proof-of-concept implementation can be\neffectively integrated into open blockchains.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 02:47:32 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Tian", "Yangguang", ""], ["Liu", "Bowen", ""], ["Li", "Yingjiu", ""], ["Szalachowski", "Pawel", ""], ["Zhou", "Jianying", ""]]}, {"id": "2104.13660", "submitter": "Roberto Natella", "authors": "Domenico Cotroneo, Luigi De Simone, Roberto Natella", "title": "Timing Covert Channel Analysis of the VxWorks MILS Embedded Hypervisor\n  under the Common Criteria Security Certification", "comments": "To appear on Computers & Security", "journal-ref": null, "doi": "10.1016/j.cose.2021.102307", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Virtualization technology is nowadays adopted in security-critical embedded\nsystems to achieve higher performance and more design flexibility. However, it\nalso comes with new security threats, where attackers leverage timing covert\nchannels to exfiltrate sensitive information from a partition using a trojan.\n  This paper presents a novel approach for the experimental assessment of\ntiming covert channels in embedded hypervisors, with a case study on security\nassessment of a commercial hypervisor product (Wind River VxWorks MILS), in\ncooperation with a licensed laboratory for the Common Criteria security\ncertification. Our experimental analysis shows that it is indeed possible to\nestablish a timing covert channel, and that the approach is useful for system\ndesigners for assessing that their configuration is robust against this kind of\ninformation leakage.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 09:31:05 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Cotroneo", "Domenico", ""], ["De Simone", "Luigi", ""], ["Natella", "Roberto", ""]]}, {"id": "2104.13733", "submitter": "Chuan Guo", "authors": "Chuan Guo, Alexandre Sablayrolles, Herv\\'e J\\'egou, Douwe Kiela", "title": "Gradient-based Adversarial Attacks against Text Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose the first general-purpose gradient-based attack against\ntransformer models. Instead of searching for a single adversarial example, we\nsearch for a distribution of adversarial examples parameterized by a\ncontinuous-valued matrix, hence enabling gradient-based optimization. We\nempirically demonstrate that our white-box attack attains state-of-the-art\nattack performance on a variety of natural language tasks. Furthermore, we show\nthat a powerful black-box transfer attack, enabled by sampling from the\nadversarial distribution, matches or exceeds existing methods, while only\nrequiring hard-label outputs.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 17:43:43 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Guo", "Chuan", ""], ["Sablayrolles", "Alexandre", ""], ["J\u00e9gou", "Herv\u00e9", ""], ["Kiela", "Douwe", ""]]}, {"id": "2104.13785", "submitter": "Jun Kurihara", "authors": "Jun Kurihara and Takeshi Kubo", "title": "Mutualized oblivious DNS ($\\mu$ODNS): Hiding a tree in the wild forest", "comments": "article class, 17pages, 3 figures, 2 tables, the citation [16] is\n  corrected in version 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The traditional Domain Name System (DNS) lacks fundamental features of\nsecurity and privacy in its design. As concerns of privacy increased on the\nInternet, security and privacy enhancements of DNS have been actively\ninvestigated and deployed. Specially for user's privacy in DNS queries, several\nrelay-based anonymization schemes have been recently introduced, however, they\nare vulnerable to the collusion of a relay with a full-service resolver, i.e.,\nidentities of users cannot be hidden to the resolver. This paper introduces a\nnew concept of a multiple-relay-based DNS for user anonymity in DNS queries,\ncalled the mutualized oblivious DNS ($\\mu$ODNS), by extending the concept of\nexisting relay-based schemes. The $\\mu$ODNS introduces a small and reasonable\nassumption that each user has at least one trusted/dedicated relay in a network\nand mutually shares the dedicated one with others. The user just sets the\ndedicated one as his next-hop, first relay, conveying his queries to the\nresolver, and randomly chooses its $0$ or more subsequent relays shared by\nother entities. Under this small assumption, the user's identity is concealed\nto a target resolver in the $\\mu$ODNS even if a certain (unknown) subset of\nrelays collude with the resolver. That is, in $\\mu$ODNS, users can preserve\ntheir privacy and anonymity just by paying a small cost of sharing its\nresource. Moreover, we present a PoC implementation of $\\mu$ODNS that is\npublicly available on the Internet. We also show that by measurement of\nround-trip-time for queries, and our PoC implementation of $\\mu$ODNS achieves\nthe performance comparable to existing relay-based schemes.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 14:18:30 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 00:11:05 GMT"}, {"version": "v3", "created": "Mon, 7 Jun 2021 07:14:39 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Kurihara", "Jun", ""], ["Kubo", "Takeshi", ""]]}, {"id": "2104.13813", "submitter": "Mirko Zichichi", "authors": "Mirko Zichichi, Stefano Ferretti, Gabriele D'Angelo", "title": "MOVO: a dApp for DLT-based Smart Mobility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plenty of research on smart mobility is currently devoted to the inclusion of\nnovel decentralized software architectures to these systems, due to the\ninherent advantages in terms of transparency, traceability, trustworthiness.\nMOVO is a decentralized application (dApp) for smart mobility. It includes: (i)\na module for collecting data from vehicles and smartphones sensors; (ii) a\ncomponent for interacting with Distributed Ledger Technologies (DLT) and\nDecentralized File Storages (DFS), for storing and validating sensor data;\n(iii) a module for \"offline\" interaction between devices. The dApp consists of\nan Android application intended for use inside a vehicle, which helps the\nuser/driver collect contextually generated data (e.g. a driver's stress level,\nan electric vehicle's battery level), which can then be shared through the use\nof DLT (i.e., IOTA DLT and Ethereum smart contracts) and DFS (i.e., IPFS). The\nthird module consists of an implementation of a communication channel that, via\nWi-Fi Direct, allows two devices to exchange data and payment information with\nrespect to DLT (i.e. cryptocurrency and token) assets. In this paper, we\ndescribe the main software components and provide an experimental evaluation\nthat confirms the viability of the MOVO dApp in real mobility scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 15:01:28 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Zichichi", "Mirko", ""], ["Ferretti", "Stefano", ""], ["D'Angelo", "Gabriele", ""]]}, {"id": "2104.13819", "submitter": "Mirko Zichichi", "authors": "Mirko Zichichi, Luca Serena, Stefano Ferretti, Gabriele D'Angelo", "title": "Towards Decentralized Complex Queries over Distributed Ledgers: a Data\n  Marketplace Use-case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Ledger Technologies (DLT) and Decentralized File Storages (DFS)\nare becoming increasingly used to create common, decentralized and trustless\ninfrastructures where participants interact and collaborate in Peer-to-Peer\ninteractions. A prominent use case is represented by decentralized data\nmarketplaces, where users are consumers and providers at the same time, and\ntrustless interactions are required. However, data in DLTs and DFS are usually\nunstructured and there are no efficient mechanisms to query a certain type of\ndata for the search in the market. In this paper, we propose the use of a\nDistributed Hash Table (DHT) as a layer on top of DLTs where, once the data are\nacquired and stored in the ledger, these can be searched through multiple\nkeyword based queries, thanks to the lookup functionalities offered by the DHT.\nThe DHT network is a hypercube overlay structure, organized for an efficient\nprocessing of multiple keyword-based queries. We provide the architecture of\nsuch solution for a decentralized data marketplace and an analysis based on a\nsimulation that proves the viability of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 15:11:50 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 08:53:23 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Zichichi", "Mirko", ""], ["Serena", "Luca", ""], ["Ferretti", "Stefano", ""], ["D'Angelo", "Gabriele", ""]]}, {"id": "2104.13964", "submitter": "Sidra Malik", "authors": "Sidra Malik, Volkan Dedeoglu, Salil Kanhere, Raja Jurdak", "title": "PrivChain: Provenance and Privacy Preservation in Blockchain enabled\n  Supply Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain offers traceability and transparency to supply chain event data\nand hence can help overcome many challenges in supply chain management such as:\ndata integrity, provenance and traceability. However, data privacy concerns\nsuch as the protection of trade secrets have hindered adoption of blockchain\ntechnology. Although consortium blockchains only allow authorised supply chain\nentities to read/write to the ledger, privacy preservation of trade secrets\ncannot be ascertained. In this work, we propose a privacy-preservation\nframework, PrivChain, to protect sensitive data on blockchain using zero\nknowledge proofs. PrivChain provides provenance and traceability without\nrevealing any sensitive information to end-consumers or supply chain entities.\nIts novelty stems from: a) its ability to allow data owners to protect trade\nrelated information and instead provide proofs on the data, and b) an\nintegrated incentive mechanism for entities providing valid proofs over\nprovenance data. In particular, PrivChain uses Zero Knowledge Range Proofs\n(ZKRPs), an efficient variant of ZKPs, to provide origin information without\ndisclosing the exact location of a supply chain product. Furthermore, the\nframework allows to compute proofs and commitments off-line, decoupling the\ncomputational overhead from blockchain. The proof verification process and\nincentive payment initiation are automated using blockchain transactions, smart\ncontracts, and events. A proof of concept implementation on Hyperledger Fabric\nreveals a minimal overhead of using PrivChain for blockchain enabled supply\nchains.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 04:30:28 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Malik", "Sidra", ""], ["Dedeoglu", "Volkan", ""], ["Kanhere", "Salil", ""], ["Jurdak", "Raja", ""]]}, {"id": "2104.14018", "submitter": "Norah Alqahtani", "authors": "Maha Aldosary and Norah Alqahtani", "title": "Federated Identity Management (FIdM) Systems Limitation And Solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Efficient identity management system has become one of the fundamental\nrequirements for ensuring safe, secure, and transparent use of identifiable\ninformation and attributes. FIdM allows users to distribute their identity\ninformation across security domains which increase the portability of their\ndigital identities. However, it also raises new architectural challenges and\nsignificant security and privacy issues that need to be mitigated. In this\npaper, we presented the limitations and risks in Federated Identity Management\nsystem and discuss the results and proposed solutions.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 20:47:16 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Aldosary", "Maha", ""], ["Alqahtani", "Norah", ""]]}, {"id": "2104.14357", "submitter": "Alex Borges Vieira", "authors": "Ronan D. Mendon\\c{c}a, Ot\\'avio S. Gomes, Luiz F. M. Vieira, Marcos A.\n  M. Vieira, Alex B. Vieira, and Jos\\'e A. M. Nacif", "title": "BlockColdChain: Vaccine Cold Chain Blockchain", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a blockchain-based cold chain technology for\nvaccine cooling track. The COVID-19 pandemic has caused the death of millions\nof people. An important step towards ending the pandemic is vaccination.\nVaccines must be kept under control temperature during the whole process, from\nfabrication to the hands of the health professionals who will immunize the\npopulation. However, there are numerous reports of vaccine loss due to\ntemperature variations, and, currently, people getting vaccinated have no\ncontrol if their vaccine was kept safe. Blockchain is a technology solution\nthat can provide public and verifiable records. We review the World Health\nOrganization (WHO) cool chain and Blockchain technology. Moreover, we describe\ncurrent IoT temperature monitoring devices and propose Blockcoldchain to track\nvaccine cold chain using blockchain, thus proving an unalterable vaccine\ntemperature history. Our experimental results using smart contracts demonstrate\nthe system's feasibility.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 12:44:11 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Mendon\u00e7a", "Ronan D.", ""], ["Gomes", "Ot\u00e1vio S.", ""], ["Vieira", "Luiz F. M.", ""], ["Vieira", "Marcos A. M.", ""], ["Vieira", "Alex B.", ""], ["Nacif", "Jos\u00e9 A. M.", ""]]}, {"id": "2104.14380", "submitter": "Fan Mo", "authors": "Fan Mo, Hamed Haddadi, Kleomenis Katevas, Eduard Marin, Diego Perino,\n  Nicolas Kourtellis", "title": "PPFL: Privacy-preserving Federated Learning with Trusted Execution\n  Environments", "comments": "15 pages, 8 figures, accepted to MobiSys 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We propose and implement a Privacy-preserving Federated Learning ($PPFL$)\nframework for mobile systems to limit privacy leakages in federated learning.\nLeveraging the widespread presence of Trusted Execution Environments (TEEs) in\nhigh-end and mobile devices, we utilize TEEs on clients for local training, and\non servers for secure aggregation, so that model/gradient updates are hidden\nfrom adversaries. Challenged by the limited memory size of current TEEs, we\nleverage greedy layer-wise training to train each model's layer inside the\ntrusted area until its convergence. The performance evaluation of our\nimplementation shows that $PPFL$ can significantly improve privacy while\nincurring small system overheads at the client-side. In particular, $PPFL$ can\nsuccessfully defend the trained model against data reconstruction, property\ninference, and membership inference attacks. Furthermore, it can achieve\ncomparable model utility with fewer communication rounds (0.54$\\times$) and a\nsimilar amount of network traffic (1.002$\\times$) compared to the standard\nfederated learning of a complete model. This is achieved while only introducing\nup to ~15% CPU time, ~18% memory usage, and ~21% energy consumption overhead in\n$PPFL$'s client-side.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 14:46:16 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 20:51:12 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Mo", "Fan", ""], ["Haddadi", "Hamed", ""], ["Katevas", "Kleomenis", ""], ["Marin", "Eduard", ""], ["Perino", "Diego", ""], ["Kourtellis", "Nicolas", ""]]}, {"id": "2104.14383", "submitter": "Shuang Zhang", "authors": "Shuang Zhang, Liyao Xiang, Xi Yu, Pengzhi Chu, Yingqi Chen, Chen Cen,\n  Li Wang", "title": "Privacy-Preserving Federated Learning on Partitioned Attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Real-world data is usually segmented by attributes and distributed across\ndifferent parties. Federated learning empowers collaborative training without\nexposing local data or models. As we demonstrate through designed attacks, even\nwith a small proportion of corrupted data, an adversary can accurately infer\nthe input attributes. We introduce an adversarial learning based procedure\nwhich tunes a local model to release privacy-preserving intermediate\nrepresentations. To alleviate the accuracy decline, we propose a defense method\nbased on the forward-backward splitting algorithm, which respectively deals\nwith the accuracy loss and privacy loss in the forward and backward gradient\ndescent steps, achieving the two objectives simultaneously. Extensive\nexperiments on a variety of datasets have shown that our defense significantly\nmitigates privacy leakage with negligible impact on the federated learning\ntask.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 14:49:14 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Zhang", "Shuang", ""], ["Xiang", "Liyao", ""], ["Yu", "Xi", ""], ["Chu", "Pengzhi", ""], ["Chen", "Yingqi", ""], ["Cen", "Chen", ""], ["Wang", "Li", ""]]}, {"id": "2104.14422", "submitter": "Ahmed Raoof", "authors": "Ahmed Raoof, Chung-Horng Lung, Ashraf Matrawy", "title": "Integrating 6LoWPAN Security with RPL Using The Chained Secure Mode\n  Framework", "comments": "6 pages, 5 figures, 2 tables, submitted to Globecom 2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The IPv6 over Low-powered Wireless Personal Area Network (6LoWPAN) protocol\nwas introduced to allow the transmission of Internet Protocol version 6 (IPv6)\npackets using the smaller-size frames of the IEEE 802.15.4 standard, which is\nused in many Internet of Things (IoT) networks. The primary duty of the 6LoWPAN\nprotocol is packet fragmentation and reassembly. However, the protocol standard\ncurrently does not include any security measures, not even authenticating the\nfragments immediate sender. This lack of immediate-sender authentication opens\nthe door for adversaries to launch several attacks on the fragmentation\nprocess, such as the buffer-reservation attacks that lead to a Denial of\nService (DoS) attack and resource exhaustion of the victim nodes. This paper\nproposes a security integration between 6LoWPAN and the Routing Protocol for\nLow Power and Lossy Networks (RPL) through the Chained Secure Mode (CSM)\nframework as a possible solution. Since the CSM framework provides a mean of\nimmediate-sender trust, through the use of Network Coding (NC), and an\nintegration interface for the other protocols (or mechanisms) to use this trust\nto build security decisions, 6LoWPAN can use this integration to build a\nchain-of-trust along the fragments routing path. A proof-of-concept\nimplementation was done in Contiki Operating System (OS), and its security and\nperformance were evaluated against an external adversary launching a\nbuffer-reservation attack. The results from the evaluation showed significant\nmitigation of the attack with almost no increase in power consumption, which\npresents the great potential for such integration to secure the forwarding\nprocess at the 6LoWPAN Adaptation Layer\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 15:40:34 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Raoof", "Ahmed", ""], ["Lung", "Chung-Horng", ""], ["Matrawy", "Ashraf", ""]]}, {"id": "2104.14519", "submitter": "Rohit Chadha", "authors": "Rohit Chadha, A. Prasad Sistla and Mahesh Viswanathan", "title": "On Linear Time Decidability of Differential Privacy for Programs with\n  Unbounded Inputs", "comments": "An extended abstract to be published in 36th Annual IEEE Symposium on\n  Logic in Computer Science (LICS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.FL cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an automata model for describing interesting classes of\ndifferential privacy mechanisms/algorithms that include known mechanisms from\nthe literature. These automata can model algorithms whose inputs can be an\nunbounded sequence of real-valued query answers. We consider the problem of\nchecking whether there exists a constant $d$ such that the algorithm described\nby these automata are $d\\epsilon$-differentially private for all positive\nvalues of the privacy budget parameter $\\epsilon$. We show that this problem\ncan be decided in time linear in the automaton's size by identifying a\nnecessary and sufficient condition on the underlying graph of the automaton.\nThis paper's results are the first decidability results known for algorithms\nwith an unbounded number of query answers taking values from the set of reals.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 17:34:44 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Chadha", "Rohit", ""], ["Sistla", "A. Prasad", ""], ["Viswanathan", "Mahesh", ""]]}, {"id": "2104.14618", "submitter": "Jack West", "authors": "Jack West, Kyuin Lee, Suman Banerjee, Younghyun Kim, George K.\n  Thiruvathukal, Neil Klingensmith", "title": "Moonshine: An Online Randomness Distiller for Zero-Involvement\n  Authentication", "comments": "16 pages, 5 figures, IPSN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Context-based authentication is a method for transparently validating another\ndevice's legitimacy to join a network based on location. Devices can pair with\none another by continuously harvesting environmental noise to generate a random\nkey with no user involvement. However, there are gaps in our understanding of\nthe theoretical limitations of environmental noise harvesting, making it\ndifficult for researchers to build efficient algorithms for sampling\nenvironmental noise and distilling keys from that noise. This work explores the\ninformation-theoretic capacity of context-based authentication mechanisms to\ngenerate random bit strings from environmental noise sources with known\nproperties. Using only mild assumptions about the source process's\ncharacteristics, we demonstrate that commonly-used bit extraction algorithms\nextract only about 10% of the available randomness from a source noise process.\nWe present an efficient algorithm to improve the quality of keys generated by\ncontext-based methods and evaluate it on real key extraction hardware.\nMoonshine is a randomness distiller which is more efficient at extracting bits\nfrom an environmental entropy source than existing methods. Our techniques\nnearly double the quality of keys as measured by the NIST test suite, producing\nkeys that can be used in real-world authentication scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 19:10:26 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["West", "Jack", ""], ["Lee", "Kyuin", ""], ["Banerjee", "Suman", ""], ["Kim", "Younghyun", ""], ["Thiruvathukal", "George K.", ""], ["Klingensmith", "Neil", ""]]}, {"id": "2104.14716", "submitter": "Abdelhaliem Babiker", "authors": "Abdelhaliem Babiker", "title": "A Novel Provably Secure Key-Agreement Using Secret Subgroup Generator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, a new key-agreement scheme is proposed and analyzed. In\naddition to being provably secure in shared secret key indistinguishability\nmodel, the scheme has an interesting feature: while using exponentiation over a\ncyclic subgroup to establish the key-agreement, the generator of that subgroup\nis hidden to secure the scheme against adversaries that are capable of solving\nthe Discrete Logarithm Problem, which means that the scheme might be candidate\nas a post-quantum key exchange scheme.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 01:37:21 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 17:17:46 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Babiker", "Abdelhaliem", ""]]}, {"id": "2104.14808", "submitter": "Jungang Yang", "authors": "Jungang Yang, Liyao Xiang, Weiting Li, Wei Liu, Xinbing Wang", "title": "Improved Matrix Gaussian Mechanism for Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide deployment of machine learning in recent years gives rise to a great\ndemand for large-scale and high-dimensional data, for which the privacy raises\nserious concern. Differential privacy (DP) mechanisms are conventionally\ndeveloped for scalar values, not for structural data like matrices. Our work\nproposes Improved Matrix Gaussian Mechanism (IMGM) for matrix-valued DP, based\non the necessary and sufficient condition of $ (\\varepsilon,\\delta)\n$-differential privacy. IMGM only imposes constraints on the singular values of\nthe covariance matrices of the noise, which leaves room for design. Among the\nlegitimate noise distributions for matrix-valued DP, we find the optimal one\nturns out to be i.i.d. Gaussian noise, and the DP constraint becomes a noise\nlower bound on each element. We further derive a tight composition method for\nIMGM. Apart from the theoretical analysis, experiments on a variety of models\nand datasets also verify that IMGM yields much higher utility than the\nstate-of-the-art mechanisms at the same privacy guarantee.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 07:44:53 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Yang", "Jungang", ""], ["Xiang", "Liyao", ""], ["Li", "Weiting", ""], ["Liu", "Wei", ""], ["Wang", "Xinbing", ""]]}, {"id": "2104.14851", "submitter": "Liangfeng Zhang", "authors": "Yan He and Liang Feng Zhang", "title": "Multi-Matrix Verifiable Computation", "comments": "Cluster Computing-The Journal of Networks, Software Tools and\n  Applications", "journal-ref": null, "doi": "10.1007/s10586-020-03116-z", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The problem of securely outsourcing computation to cloud servers has\nattracted a large amount of attention in recent years. The verifiable\ncomputation of Gennaro, Gentry, Parno (Crypto'10) allows a client to verify the\nserver's computation of a function with substantially less time than performing\nthe outsourced computation from scratch. In a multi-function model (Parno,\nRaykova, Vaikuntanathan; TCC'12) of verifiable computation, the process of\nencoding function and the process of preparing input are decoupled such that\nany client can freely submit a computation request on its input, without having\nto generate an encoding of the function in advance. In this paper, we propose a\nmulti-matrix verifiable computation scheme that allows the secure outsourcing\nof the matrix functions over a finite field. Our scheme is outsourceable. When\nit is used to outsource $m$ linear functions, the scheme is roughly $m$ times\nfaster and has less communication cost than the previously best known scheme by\nFiore and Gennaro (CCS'12), both in the client-side computation and in the\nserver-side computation. We also show the cost saving with detailed\nimplementations.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 09:10:18 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["He", "Yan", ""], ["Zhang", "Liang Feng", ""]]}, {"id": "2104.14862", "submitter": "Wojciech Ozga", "authors": "Wojciech Ozga and Do Le Quoc and Christof Fetzer", "title": "WELES: Policy-driven Runtime Integrity Enforcement of Virtual Machines", "comments": null, "journal-ref": "Proceedings of 2021 IEEE International Conference on Cloud\n  Computing (IEEE CLOUD'21)", "doi": null, "report-no": null, "categories": "cs.CR cs.OS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Trust is of paramount concern for tenants to deploy their security-sensitive\nservices in the cloud. The integrity of VMs in which these services are\ndeployed needs to be ensured even in the presence of powerful adversaries with\nadministrative access to the cloud. Traditional approaches for solving this\nchallenge leverage trusted computing techniques, e.g., vTPM, or hardware CPU\nextensions, e.g., AMD SEV. But, they are vulnerable to powerful adversaries, or\nthey provide only load time (not runtime) integrity measurements of VMs.\n  We propose WELES, a protocol allowing tenants to establish and maintain trust\nin VM runtime integrity of software and its configuration. WELES is transparent\nto the VM configuration and setup. It performs an implicit attestation of VMs\nduring a secure login and binds the VM integrity state with the secure\nconnection. Our prototype's evaluation shows that WELES is practical and incurs\nlow performance overhead.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 09:37:14 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Ozga", "Wojciech", ""], ["Quoc", "Do Le", ""], ["Fetzer", "Christof", ""]]}, {"id": "2104.14906", "submitter": "Spyridon Mastorakis", "authors": "Mian Ahmad Jan and Fazlullah Khan and Spyridon Mastorakis and Muhammad\n  Adil and Aamir Akbar and Nicholas Stergiou", "title": "LightIoT: Lightweight and Secure Communication for Energy-Efficient IoT\n  in Health Informatics", "comments": "This paper has been accepted for publication by the IEEE Transactions\n  on Green Communications and Networking. The copyright is with the IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) is considered as a key enabler of health\ninformatics. IoT-enabled devices are used for in-hospital and in-home patient\nmonitoring to collect and transfer biomedical data pertaining to blood\npressure, electrocardiography (ECG), blood sugar levels, body temperature, etc.\nAmong these devices, wearables have found their presence in a wide range of\nhealthcare applications. These devices generate data in real-time and transmit\nthem to nearby gateways and remote servers for processing and visualization.\nThe data transmitted by these devices are vulnerable to a range of adversarial\nthreats, and as such, privacy and integrity need to be preserved. In this\npaper, we present LightIoT, a lightweight and secure communication approach for\ndata exchanged among the devices of a healthcare infrastructure. LightIoT\noperates in three phases: initialization, pairing, and authentication. These\nphases ensure the reliable transmission of data by establishing secure sessions\namong the communicating entities (wearables, gateways and a remote server).\nStatistical results exhibit that our scheme is lightweight, robust, and\nresilient against a wide range of adversarial attacks and incurs much lower\ncomputational and communication overhead for the transmitted data in the\npresence of existing approaches.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 11:09:05 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Jan", "Mian Ahmad", ""], ["Khan", "Fazlullah", ""], ["Mastorakis", "Spyridon", ""], ["Adil", "Muhammad", ""], ["Akbar", "Aamir", ""], ["Stergiou", "Nicholas", ""]]}, {"id": "2104.14978", "submitter": "Gaigai Tang", "authors": "Gaigai Tang, Lianxiao Meng, Shuangyin Ren, Weipeng Cao, Qiang Wang,\n  Lin Yang", "title": "A comparative study of neural network techniques for automatic software\n  vulnerability detection", "comments": "This paper has been published at April 28,2021. However, there are\n  some experimental data issues in the published manuscript, which are caused\n  by the calculation error of indicators. This paper is a revised version", "journal-ref": null, "doi": "10.1109/TASE49443.2020.00010", "report-no": null, "categories": "cs.SE cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Software vulnerabilities are usually caused by design flaws or implementation\nerrors, which could be exploited to cause damage to the security of the system.\nAt present, the most commonly used method for detecting software\nvulnerabilities is static analysis. Most of the related technologies work based\non rules or code similarity (source code level) and rely on manually defined\nvulnerability features. However, these rules and vulnerability features are\ndifficult to be defined and designed accurately, which makes static analysis\nface many challenges in practical applications. To alleviate this problem, some\nresearchers have proposed to use neural networks that have the ability of\nautomatic feature extraction to improve the intelligence of detection. However,\nthere are many types of neural networks, and different data preprocessing\nmethods will have a significant impact on model performance. It is a great\nchallenge for engineers and researchers to choose a proper neural network and\ndata preprocessing method for a given problem. To solve this problem, we have\nconducted extensive experiments to test the performance of the two most typical\nneural networks (i.e., Bi-LSTM and RVFL) with the two most classical data\npreprocessing methods (i.e., the vector representation and the program\nsymbolization methods) on software vulnerability detection problems and\nobtained a series of interesting research conclusions, which can provide\nvaluable guidelines for researchers and engineers. Specifically, we found that\n1) the training speed of RVFL is always faster than BiLSTM, but the prediction\naccuracy of Bi-LSTM model is higher than RVFL; 2) using doc2vec for vector\nrepresentation can make the model have faster training speed and generalization\nability than using word2vec; and 3) multi-level symbolization is helpful to\nimprove the precision of neural network models.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 01:47:30 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Tang", "Gaigai", ""], ["Meng", "Lianxiao", ""], ["Ren", "Shuangyin", ""], ["Cao", "Weipeng", ""], ["Wang", "Qiang", ""], ["Yang", "Lin", ""]]}, {"id": "2104.14993", "submitter": "Robert Schilling", "authors": "Robert Schilling, Pascal Nasahl, Stefan Mangard", "title": "FIPAC: Thwarting Fault- and Software-Induced Control-Flow Attacks with\n  ARM Pointer Authentication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the improvements of computing technology, more and more applications\nembed powerful ARM processors into their devices. These systems can be attacked\nby redirecting the control-flow of a program to bypass critical pieces of code\nsuch as privilege checks or signature verifications. Control-flow hijacks can\nbe performed using classical software vulnerabilities, physical fault attacks,\nor software-induced fault attacks. To cope with this threat and to protect the\ncontrol-flow, dedicated countermeasures are needed. To counteract control-flow\nhijacks, control-flow integrity~(CFI) aims to be a generic solution. However,\nsoftware-based CFI typically either protects against software or fault attacks,\nbut not against both. While hardware-assisted CFI can mitigate both types of\nattacks, they require extensive hardware modifications. As hardware changes are\nunrealistic for existing ARM architectures, a wide range of systems remains\nunprotected and vulnerable to control-flow attacks.\n  In this work, we present FIPAC, an efficient software-based CFI scheme\nprotecting the execution at basic block granularity of ARM-based devices\nagainst software and fault attacks. FIPAC exploits ARM pointer authentication\nof ARMv8.6-A to implement a cryptographically signed control-flow graph. We\ncryptographically link the correct sequence of executed basic blocks to enforce\nCFI at this granularity. We use an LLVM-based toolchain to automatically\ninstrument programs. The evaluation on SPEC2017 with different security\npolicies shows a code overhead between 54-97\\% and a runtime overhead between\n35-105%. While these overheads are higher than for countermeasures against\nsoftware attacks, FIPAC outperforms related work protecting the control-flow\nagainst fault attacks. FIPAC is an efficient solution to provide protection\nagainst software- and fault-based CFI attacks on basic block level on modern\nARM devices.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 13:27:09 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Schilling", "Robert", ""], ["Nasahl", "Pascal", ""], ["Mangard", "Stefan", ""]]}, {"id": "2104.15055", "submitter": "Rishiraj Bhattacharyya", "authors": "Elena Andreeva, Rishiraj Bhattacharyya, Arnab Roy", "title": "Compactness of Hashing Modes and Efficiency beyond Merkle Tree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We revisit the classical problem of designing optimally efficient\ncryptographically secure hash functions. Hash functions are traditionally\ndesigned via applying modes of operation on primitives with smaller domains.\nThe results of Shrimpton and Stam (ICALP 2008), Rogaway and Steinberger (CRYPTO\n2008), and Mennink and Preneel (CRYPTO 2012) show how to achieve optimally\nefficient designs of $2n$-to-$n$-bit compression functions from non-compressing\nprimitives with asymptotically optimal $2^{n/2-\\epsilon}$-query collision\nresistance. Designing optimally efficient and secure hash functions for larger\ndomains ($> 2n$ bits) is still an open problem.\n  In this work we propose the new \\textit{compactness} efficiency notion. It\nallows us to focus on asymptotically optimally collision resistant hash\nfunction and normalize their parameters based on Stam's bound from CRYPTO 2008\nto obtain maximal efficiency.\n  We then present two tree-based modes of operation\n  -Our first construction is an \\underline{A}ugmented \\underline{B}inary\nT\\underline{r}ee (ABR) mode. The design is a $(2^{\\ell}+2^{\\ell-1}\n-1)n$-to-$n$-bit hash function making a total of $(2^{\\ell}-1)$ calls to\n$2n$-to-$n$-bit compression functions for any $\\ell\\geq 2$. Our construction is\noptimally compact with asymptotically (optimal) $2^{n/2-\\epsilon}$-query\ncollision resistance in the ideal model. For a tree of height $\\ell$, in\ncomparison with Merkle tree, the $ABR$ mode processes additional\n$(2^{\\ell-1}-1)$ data blocks making the same number of internal compression\nfunction calls.\n  -While the $ABR$ mode achieves collision resistance, it fails to achieve\nindifferentiability from a random oracle within $2^{n/3}$ queries. $ABR^{+}$\ncompresses only $1$ less data block than $ABR$ with the same number of\ncompression calls and achieves in addition indifferentiability up to\n$2^{n/2-\\epsilon}$ queries.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 15:22:55 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 11:08:06 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Andreeva", "Elena", ""], ["Bhattacharyya", "Rishiraj", ""], ["Roy", "Arnab", ""]]}, {"id": "2104.15068", "submitter": "Yajin Zhou", "authors": "Siwei Wu, Dabao Wang, Jianting He, Yajin Zhou, Lei Wu, Xingliang Yuan,\n  Qinming He, and Kui Ren", "title": "DeFiRanger: Detecting Price Manipulation Attacks on DeFi Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of Decentralized Finance (DeFi) boosts the Ethereum\necosystem. At the same time, attacks towards DeFi applications (apps) are\nincreasing. However, to the best of our knowledge, existing smart contract\nvulnerability detection tools cannot be directly used to detect DeFi attacks.\nThat's because they lack the capability to recover and understand high-level\nDeFi semantics, e.g., a user trades a token pair X and Y in a Decentralized\nEXchange (DEX).\n  In this work, we focus on the detection of two types of new attacks on DeFi\napps, including direct and indirect price manipulation attacks. The former one\nmeans that an attacker directly manipulates the token price in DEX by\nperforming an unwanted trade in the same DEX by attacking the vulnerable DeFi\napp. The latter one means that an attacker indirectly manipulates the token\nprice of the vulnerable DeFi app (e.g., a lending app). To this end, we propose\na platform-independent way to recover high-level DeFi semantics by first\nconstructing the cash flow tree from raw Ethereum transactions and then lifting\nthe low-level semantics to high-level ones, including token trade, liquidity\nmining, and liquidity cancel. Finally, we detect price manipulation attacks\nusing the patterns expressed with the recovered DeFi semantics.\n  We have implemented a prototype named \\tool{} and applied it to more than 350\nmillion transactions. It successfully detected 432 real-world attacks in the\nwild. We confirm that they belong to four known security incidents and five\nzero-day ones. We reported our findings. Two CVEs have been assigned. We\nfurther performed an attack analysis to reveal the root cause of the\nvulnerability, the attack footprint, and the impact of the attack. Our work\nurges the need to secure the DeFi ecosystem.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 15:38:16 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Wu", "Siwei", ""], ["Wang", "Dabao", ""], ["He", "Jianting", ""], ["Zhou", "Yajin", ""], ["Wu", "Lei", ""], ["Yuan", "Xingliang", ""], ["He", "Qinming", ""], ["Ren", "Kui", ""]]}, {"id": "2104.15109", "submitter": "Jean-Baptiste Truong", "authors": "Jean-Baptiste Truong, William Gallagher, Tian Guo, Robert J. Walls", "title": "Memory-Efficient Deep Learning Inference in Trusted Execution\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study identifies and proposes techniques to alleviate two key\nbottlenecks to executing deep neural networks in trusted execution environments\n(TEEs): page thrashing during the execution of convolutional layers and the\ndecryption of large weight matrices in fully-connected layers. For the former,\nwe propose a novel partitioning scheme, y-plane partitioning, designed to (ii)\nprovide consistent execution time when the layer output is large compared to\nthe TEE secure memory; and (ii) significantly reduce the memory footprint of\nconvolutional layers. For the latter, we leverage quantization and compression.\nIn our evaluation, the proposed optimizations incurred latency overheads\nranging from 1.09X to 2X baseline for a wide range of TEE sizes; in contrast,\nan unmodified implementation incurred latencies of up to 26X when running\ninside of the TEE.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 16:48:14 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Truong", "Jean-Baptiste", ""], ["Gallagher", "William", ""], ["Guo", "Tian", ""], ["Walls", "Robert J.", ""]]}, {"id": "2104.15129", "submitter": "Yulong Tian", "authors": "Yulong Tian, Fnu Suya, Fengyuan Xu, David Evans", "title": "Stealthy Backdoors as Compression Artifacts", "comments": "20 pages, 9 figures, 14 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a backdoor attack on a machine learning model, an adversary produces a\nmodel that performs well on normal inputs but outputs targeted\nmisclassifications on inputs containing a small trigger pattern. Model\ncompression is a widely-used approach for reducing the size of deep learning\nmodels without much accuracy loss, enabling resource-hungry models to be\ncompressed for use on resource-constrained devices. In this paper, we study the\nrisk that model compression could provide an opportunity for adversaries to\ninject stealthy backdoors. We design stealthy backdoor attacks such that the\nfull-sized model released by adversaries appears to be free from backdoors\n(even when tested using state-of-the-art techniques), but when the model is\ncompressed it exhibits highly effective backdoors. We show this can be done for\ntwo common model compression techniques -- model pruning and model\nquantization. Our findings demonstrate how an adversary may be able to hide a\nbackdoor as a compression artifact, and show the importance of performing\nsecurity tests on the models that will actually be deployed not their\nprecompressed version.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 17:35:18 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Tian", "Yulong", ""], ["Suya", "Fnu", ""], ["Xu", "Fengyuan", ""], ["Evans", "David", ""]]}]