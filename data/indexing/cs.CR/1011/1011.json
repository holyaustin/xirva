[{"id": "1011.0168", "submitter": "Laszlo Kish", "authors": "Zoltan Gingl and Laszlo B. Kish", "title": "Ultimate crack and lack of any security in the statistical key exchange\n  protocol with random signals and feedback", "comments": "We have to withdraw our earlier claim because errors have been\n  identified in the calculation and computer simulations. However, we do\n  believe that the protocol can be cracked in a similar fashion that needs only\n  a few measurement, no statistics. Thus we hope that this new family of\n  attacks can be developed into some efficient tool. However, the \"how\" is\n  still an open question thus the Liu-protocol should be considered secure\n  until such solution is found", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We deterministically crack the secure, statistical key exchange protocol\nbased on feedback proposed by Pao-Lo Liu [ J. Lightwave Techology 27 (2009) pp.\n5230-34]. The crack is ultimate and absolute because it works under idealized\nconditions, and produces much higher data visibility for the eavesdropper than\nthe protocol provides for Alice and Bob. Even with the most idealistic driving\nnoise spectrum stated by Liu, during the most secure phase of the protocol, far\naway from the transients, where the system is already in its most secure\nsteady-state, the eavesdropper has 100% success rate in identifying the key\nbits, at the same time when Alice and Bob have less than 100% success rate\nwhile using the Liu protocol. No statistics is needed, Eve can extract the\nsecure bit from two samples of the signal in the two direction. Thus the\nLiu-protocol offers no security against the attack described in this paper.\n", "versions": [{"version": "v1", "created": "Sun, 31 Oct 2010 15:31:58 GMT"}, {"version": "v2", "created": "Sat, 6 Nov 2010 17:41:32 GMT"}, {"version": "v3", "created": "Thu, 30 Dec 2010 05:09:00 GMT"}], "update_date": "2011-01-04", "authors_parsed": [["Gingl", "Zoltan", ""], ["Kish", "Laszlo B.", ""]]}, {"id": "1011.0363", "submitter": "Kumar Krishnan", "authors": "K. Kumar, J. Nafeesa Begum and V. Sumathy", "title": "A Novel Approach Towards Cost Effective Region-Based Group Key Agreement\n  Protocol for Peer - to - Peer Information Sharing in Mobile Ad Hoc Networks", "comments": "19 pages", "journal-ref": "International Journal of peer-to-peer networks (IJP2P) Vol.1,\n  No.1, September 2010", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer-to-peer systems have gained a lot of attention as information sharing\nsystems for the widespread exchange of resources and voluminous information\nthat is easily accessible among thousands of users. However, current\npeer-to-peer information sharing systems work mostly on wired networks. With\nthe growing number of communication-equipped mobile devices that can\nself-organize into infrastructure-less communication platform, namely mobile ad\nhoc networks (MANETs), peer-to-peer information sharing over MANETs becomes a\npromising research area. In this paper, we propose a Region-Based structure\nthat enables efficient and secure peer-to-peer information sharing over MANETs.\nThe implementation shows that the proposed scheme is Secure, scalable,\nefficient, and adaptive to node mobility and provides Reliable information\nsharing.\n", "versions": [{"version": "v1", "created": "Mon, 1 Nov 2010 16:06:06 GMT"}], "update_date": "2010-11-02", "authors_parsed": [["Kumar", "K.", ""], ["Begum", "J. Nafeesa", ""], ["Sumathy", "V.", ""]]}, {"id": "1011.0527", "submitter": "Balu Achimuthu", "authors": "A. Balu, and K. Kuppusamy", "title": "Ciphertext Policy Attribute based Encryption with anonymous access\n  policy", "comments": null, "journal-ref": "International journal of Peer to Peer Networks, pp1-8,Vol 1,\n  Number 1, October 2010", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Ciphertext Policy Attribute based Encryption scheme, the encryptor can fix\nthe policy, who can decrypt the encrypted message. The policy can be formed\nwith the help of attributes. In CP-ABE, access policy is sent along with the\nciphertext. We propose a method in which the access policy need not be sent\nalong with the ciphertext, by which we are able to preserve the privacy of the\nencryptor. The proposed construction is provably secure under Decision Bilinear\nDiffe-Hellman assumption.\n", "versions": [{"version": "v1", "created": "Tue, 2 Nov 2010 07:03:00 GMT"}], "update_date": "2010-11-03", "authors_parsed": [["Balu", "A.", ""], ["Kuppusamy", "K.", ""]]}, {"id": "1011.0755", "submitter": "Nikolai Stoianov", "authors": "Nikolai Todorov Stoianov, Veselin Tsenov Tselkov", "title": "E-Net Models of a Software System for Web Pages Security SECURITY", "comments": "6 pages, 3 figures, Mathematics and Education in Mathematics, 2003\n  Proceedings of the Thirty Second Spring Conference of the Union of Bulgarian\n  Mathematicians,pp.285-290, ISBN 954-8880-14-8", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents solutions for cryptography protection for web pages. The\nsolutions comprise the authors' experience in development and implementation of\nsystems for information security in the Automated Information Systems of\nBulgarian Armed Forces. The architecture, the models and the methods are being\nexplained.\n", "versions": [{"version": "v1", "created": "Tue, 2 Nov 2010 21:21:24 GMT"}], "update_date": "2010-11-04", "authors_parsed": [["Stoianov", "Nikolai Todorov", ""], ["Tselkov", "Veselin Tsenov", ""]]}, {"id": "1011.0792", "submitter": "Cynthia D", "authors": "Cynthia Dhinakaran, Dhinaharan Nagamalai and Jae Kwang Lee", "title": "An Empirical Study of Spam and Spam Vulnerable email Accounts", "comments": "6 pages, 5 Figures, FGCN 2007, IEEE CS", "journal-ref": null, "doi": "10.1109/FGCN.2007.61", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spam messages muddle up users inbox, consume network resources, and build up\nDDoS attacks, spread malware. Our goal is to present a definite figure about\nthe characteristics of spam and spam vulnerable email accounts. These\nevaluations help us to enhance the existing technology to combat spam\neffectively. We collected 400 thousand spam mails from a spam trap set up in a\ncorporate mail server for a period of 14 months form January 2006 to February\n2007. Spammers use common techniques to spam end users regardless of corporate\nserver and public mail server. So we believe that our spam collection is a\nsample of world wide spam traffic. Studying the characteristics of this sample\nhelps us to better understand the features of spam and spam vulnerable e-mail\naccounts. We believe that this analysis is highly useful to develop more\nefficient anti spam techniques. In our analysis we classified spam based on\nattachment and contents. According to our study the four years old heavy users\nemail accounts attract more spam than four years oldlight users mail accounts.\nThe 14 months old relatively new email accounts don't receive spam. In some\nspecial cases like DDoS attacks, the new email accounts receive spam. During\nDDoS attack 14 months old heavy users email accounts have attracted more number\nof spam than 14 months old light users mail accounts.\n", "versions": [{"version": "v1", "created": "Wed, 3 Nov 2010 02:37:52 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Dhinakaran", "Cynthia", ""], ["Nagamalai", "Dhinaharan", ""], ["Lee", "Jae Kwang", ""]]}, {"id": "1011.1050", "submitter": "Cynthia D", "authors": "Cynthia Dhinakaran, Dhinaharan Nagamalai and Jae Kwang Lee", "title": "Characterizing Spam traffic and Spammers", "comments": "6 pages, 4 Figures, ICCIT 2007, IEEE CS", "journal-ref": null, "doi": "10.1109/ICCIT.2007.89", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a tremendous increase in spam traffic these days. Spam messages\nmuddle up users inbox, consume network resources, and build up DDoS attacks,\nspread worms and viruses. Our goal is to present a definite figure about the\ncharacteristics of spam and spammers. Since spammers change their mode of\noperation to counter anti spam technology,continues evaluation of the\ncharacteristics of spam and spammers technology has become mandatory. These\nevaluations help us to enhance the existing technology to combat spam\neffectively. We collected 400 thousand spam mails from a spam trap set up in a\ncorporate mail server for a period of 14 months form January 2006 to February\n2007. Spammers use common techniques to spam end users regardless of corporate\nserver and public mail server. So we believe that our spam collection is a\nsample of world wide spam traffic. Studying the characteristics of this sample\nhelps us to better understand the features of spam and spammers technology. We\nbelieve that this analysis could be useful to develop more efficient anti spam\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 4 Nov 2010 01:49:39 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Dhinakaran", "Cynthia", ""], ["Nagamalai", "Dhinaharan", ""], ["Lee", "Jae Kwang", ""]]}, {"id": "1011.1119", "submitter": "Dan Tavrov", "authors": "Oleg Chertov, Dan Tavrov", "title": "Group Anonymity", "comments": "10 pages, 2 tables. Published by Springer in \"Information Processing\n  and Management of Uncertainty in Knowledge-Based Systems. Applications\". The\n  final publication is available at\n  http://www.springerlink.com/content/u701148783683775/", "journal-ref": "\"Information Processing and Management of Uncertainty in\n  Knowledge-Based Systems. Applications\" (Communications in Computer and\n  Information Science, Volume 81, Part 6, Part 9, 592-601), 2010", "doi": "10.1007/978-3-642-14058-7_61", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years the amount of digital data in the world has risen immensely.\nBut, the more information exists, the greater is the possibility of its\nunwanted disclosure. Thus, the data privacy protection has become a pressing\nproblem of the present time. The task of individual privacy-preserving is being\nthoroughly studied nowadays. At the same time, the problem of statistical\ndisclosure control for collective (or group) data is still open. In this paper\nwe propose an effective and relatively simple (wavelet-based) way to provide\ngroup anonymity in collective data. We also provide a real-life example to\nillustrate the method.\n", "versions": [{"version": "v1", "created": "Thu, 4 Nov 2010 11:36:11 GMT"}], "update_date": "2010-11-05", "authors_parsed": [["Chertov", "Oleg", ""], ["Tavrov", "Dan", ""]]}, {"id": "1011.1121", "submitter": "Dan Tavrov", "authors": "Oleg Chertov, Dan Tavrov", "title": "Providing Group Anonymity Using Wavelet Transform", "comments": "12 pages, 2 tables. Accepted to be printed by Springer in BNCOD 2010\n  proceedings (Lecture Notes in Computer Science series)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing public access to unprotected digital data can pose a threat of\nunwanted disclosing the restricted information. The problem of protecting such\ninformation can be divided into two main subclasses, namely, individual and\ngroup data anonymity. By group anonymity we define protecting important data\npatterns, distributions, and collective features which cannot be determined\nthrough analyzing individual records only. An effective and comparatively\nsimple way of solving group anonymity problem is doubtlessly applying wavelet\ntransform. It's easy-to-implement, powerful enough, and might produce\nacceptable results if used properly. In the paper, we present a novel method of\nusing wavelet transform for providing group anonymity; it is gained through\nredistributing wavelet approximation values, along with simultaneous fixing\ndata mean value and leaving wavelet details unchanged (or proportionally\naltering them). Moreover, we provide a comprehensive example to illustrate the\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 4 Nov 2010 11:45:54 GMT"}], "update_date": "2010-11-05", "authors_parsed": [["Chertov", "Oleg", ""], ["Tavrov", "Dan", ""]]}, {"id": "1011.1127", "submitter": "Dan Tavrov", "authors": "Oleg Chertov, Dan Tavrov", "title": "Group Anonymity: Problems and Solutions", "comments": "13 pages, 6 figures, 1 table. Published by \"Lviv Polytechnica\n  Publishing House\" in \"Information Systems and Networks\"\n  (http://vlp.com.ua/taxonomy/term/3136)", "journal-ref": "Information Systems and Networks, No. 673, pp. 3-15, 2010", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing methods of providing data anonymity preserve individual privacy,\nbut, the task of protecting respondent groups' information in publicly\navailable datasets remains open. Group anonymity lies in hiding (masking) data\npatterns that cannot be revealed by analyzing individual records. We discuss\nmain corresponding problems, and provide methods for solving each one.\nKeywords: group anonymity, wavelet transform.\n", "versions": [{"version": "v1", "created": "Thu, 4 Nov 2010 12:02:53 GMT"}], "update_date": "2010-11-05", "authors_parsed": [["Chertov", "Oleg", ""], ["Tavrov", "Dan", ""]]}, {"id": "1011.1132", "submitter": "Dan Tavrov", "authors": "Oleg Chertov, Dan Tavrov", "title": "Providing Data Group Anonymity Using Concentration Differences", "comments": "10 pages, 2 figures, 2 tables. Published in \"Mathematical Machines\n  and Systems\" (http://www.immsp.kiev.ua/publications/eng/2010_3/)", "journal-ref": "Mathematical Machines and Systems, No. 3, pp. 34-44, 2010", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public access to digital data can turn out to be a cause of undesirable\ninformation disclosure. That's why it is vital to somehow protect the data\nbefore publishing. There exist two main subclasses of such a task, namely,\nproviding individual and group anonymity. In the paper, we introduce a novel\nmethod of protecting group data patterns. Also, we provide a comprehensive\nillustrative example.\n", "versions": [{"version": "v1", "created": "Thu, 4 Nov 2010 12:14:00 GMT"}], "update_date": "2010-11-05", "authors_parsed": [["Chertov", "Oleg", ""], ["Tavrov", "Dan", ""]]}, {"id": "1011.1133", "submitter": "Dan Tavrov", "authors": "Oleg Chertov, Dan Tavrov", "title": "Data Group Anonymity: General Approach", "comments": "8 pages, 2 figures, 1 table. Published in International Journal of\n  Computer Science and Information Security\n  (http://sites.google.com/site/ijcsis/vol-8-no-7-oct-2010)", "journal-ref": "IJCSIS Vol.8 No.7, October 2010, pp. 1-8", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent time, the problem of protecting privacy in statistical data\nbefore they are published has become a pressing one. Many reliable studies have\nbeen accomplished, and loads of solutions have been proposed. Though, all these\nresearches take into consideration only the problem of protecting individual\nprivacy, i.e., privacy of a single person, household, etc. In our previous\narticles, we addressed a completely new type of anonymity problems. We\nintroduced a novel kind of anonymity to achieve in statistical data and called\nit group anonymity. In this paper, we aim at summarizing and generalizing our\nprevious results, propose a complete mathematical description of how to provide\ngroup anonymity, and illustrate it with a couple of real-life examples.\n", "versions": [{"version": "v1", "created": "Thu, 4 Nov 2010 12:21:48 GMT"}], "update_date": "2010-11-05", "authors_parsed": [["Chertov", "Oleg", ""], ["Tavrov", "Dan", ""]]}, {"id": "1011.1261", "submitter": "Yen-Wei Huang", "authors": "Yen-Wei Huang, Pierre Moulin", "title": "On the Saddle-point Solution and the Large-Coalition Asymptotics of\n  Fingerprinting Games", "comments": "submitted to IEEE Trans. on Information Forensics and Security", "journal-ref": null, "doi": "10.1109/TIFS.2011.2168212", "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a fingerprinting game in which the number of colluders and the\ncollusion channel are unknown. The encoder embeds fingerprints into a host\nsequence and provides the decoder with the capability to trace back pirated\ncopies to the colluders.\n  Fingerprinting capacity has recently been derived as the limit value of a\nsequence of maximin games with mutual information as their payoff functions.\nHowever, these games generally do not admit saddle-point solutions and are very\nhard to solve numerically. Here under the so-called Boneh-Shaw marking\nassumption, we reformulate the capacity as the value of a single two-person\nzero-sum game, and show that it is achieved by a saddle-point solution.\n  If the maximal coalition size is k and the fingerprinting alphabet is binary,\nwe show that capacity decays quadratically with k. Furthermore, we prove\nrigorously that the asymptotic capacity is 1/(k^2 2ln2) and we confirm our\nearlier conjecture that Tardos' choice of the arcsine distribution\nasymptotically maximizes the mutual information payoff function while the\ninterleaving attack minimizes it. Along with the asymptotic behavior, numerical\nsolutions to the game for small k are also presented.\n", "versions": [{"version": "v1", "created": "Thu, 4 Nov 2010 20:07:37 GMT"}, {"version": "v2", "created": "Tue, 19 Apr 2011 05:20:03 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Huang", "Yen-Wei", ""], ["Moulin", "Pierre", ""]]}, {"id": "1011.1264", "submitter": "Holenstein Thomas", "authors": "Thomas Holenstein and Robin K\\\"unzler and Stefano Tessaro", "title": "Equivalence of the Random Oracle Model and the Ideal Cipher Model,\n  Revisited", "comments": "Reduced number of rounds from 18 to 14 as this is sufficient for the\n  proof, improved presentation of several lemmas and introduction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the cryptographic problem of constructing an invertible random\npermutation from a public random function (i.e., which can be accessed by the\nadversary). This goal is formalized by the notion of indifferentiability of\nMaurer et al. (TCC 2004). This is the natural extension to the public setting\nof the well-studied problem of building random permutations from random\nfunctions, which was first solved by Luby and Rackoff (Siam J. Comput., '88)\nusing the so-called Feistel construction.\n  The most important implication of such a construction is the equivalence of\nthe random oracle model (Bellare and Rogaway, CCS '93) and the ideal cipher\nmodel, which is typically used in the analysis of several constructions in\nsymmetric cryptography.\n  Coron et al. (CRYPTO 2008) gave a rather involved proof that the six-round\nFeistel construction with independent random round functions is\nindifferentiable from an invertible random permutation. Also, it is known that\nfewer than six rounds do not suffice for indifferentiability. The first\ncontribution (and starting point) of our paper is a concrete distinguishing\nattack which shows that the indifferentiability proof of Coron et al. is not\ncorrect. In addition, we provide supporting evidence that an\nindifferentiability proof for the six-round Feistel construction may be very\nhard to find.\n  To overcome this gap, our main contribution is a proof that the Feistel\nconstruction with eigthteen rounds is indifferentiable from an invertible\nrandom permutation. The approach of our proof relies on assigning to each of\nthe rounds in the construction a unique and specific role needed in the proof.\nThis avoids many of the problems that appear in the six-round case.\n", "versions": [{"version": "v1", "created": "Thu, 4 Nov 2010 20:55:27 GMT"}, {"version": "v2", "created": "Wed, 1 Jun 2011 07:59:47 GMT"}], "update_date": "2011-06-02", "authors_parsed": [["Holenstein", "Thomas", ""], ["K\u00fcnzler", "Robin", ""], ["Tessaro", "Stefano", ""]]}, {"id": "1011.1296", "submitter": "Jonathan Ullman", "authors": "Anupam Gupta, Moritz Hardt, Aaron Roth, Jonathan Ullman", "title": "Privately Releasing Conjunctions and the Statistical Query Barrier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose we would like to know all answers to a set of statistical queries C\non a data set up to small error, but we can only access the data itself using\nstatistical queries. A trivial solution is to exhaustively ask all queries in\nC. Can we do any better?\n  + We show that the number of statistical queries necessary and sufficient for\nthis task is---up to polynomial factors---equal to the agnostic learning\ncomplexity of C in Kearns' statistical query (SQ) model. This gives a complete\nanswer to the question when running time is not a concern.\n  + We then show that the problem can be solved efficiently (allowing arbitrary\nerror on a small fraction of queries) whenever the answers to C can be\ndescribed by a submodular function. This includes many natural concept classes,\nsuch as graph cuts and Boolean disjunctions and conjunctions.\n  While interesting from a learning theoretic point of view, our main\napplications are in privacy-preserving data analysis:\n  Here, our second result leads to the first algorithm that efficiently\nreleases differentially private answers to of all Boolean conjunctions with 1%\naverage error. This presents significant progress on a key open problem in\nprivacy-preserving data analysis.\n  Our first result on the other hand gives unconditional lower bounds on any\ndifferentially private algorithm that admits a (potentially\nnon-privacy-preserving) implementation using only statistical queries. Not only\nour algorithms, but also most known private algorithms can be implemented using\nonly statistical queries, and hence are constrained by these lower bounds. Our\nresult therefore isolates the complexity of agnostic learning in the SQ-model\nas a new barrier in the design of differentially private algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 4 Nov 2010 23:59:08 GMT"}, {"version": "v2", "created": "Sun, 14 Nov 2010 15:36:08 GMT"}, {"version": "v3", "created": "Wed, 15 Dec 2010 00:31:57 GMT"}, {"version": "v4", "created": "Thu, 27 Oct 2011 16:50:37 GMT"}], "update_date": "2011-10-28", "authors_parsed": [["Gupta", "Anupam", ""], ["Hardt", "Moritz", ""], ["Roth", "Aaron", ""], ["Ullman", "Jonathan", ""]]}, {"id": "1011.1375", "submitter": "Aaron Roth", "authors": "Arpita Ghosh, Aaron Roth", "title": "Selling Privacy at Auction", "comments": "Extended Abstract appeared in the proceedings of EC 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of markets for private data, though the lens of\ndifferential privacy. Although the purchase and sale of private data has\nalready begun on a large scale, a theory of privacy as a commodity is missing.\nIn this paper, we propose to build such a theory. Specifically, we consider a\nsetting in which a data analyst wishes to buy information from a population\nfrom which he can estimate some statistic. The analyst wishes to obtain an\naccurate estimate cheaply. On the other hand, the owners of the private data\nexperience some cost for their loss of privacy, and must be compensated for\nthis loss. Agents are selfish, and wish to maximize their profit, so our goal\nis to design truthful mechanisms. Our main result is that such auctions can\nnaturally be viewed and optimally solved as variants of multi-unit procurement\nauctions. Based on this result, we derive auctions for two natural settings\nwhich are optimal up to small constant factors:\n  1. In the setting in which the data analyst has a fixed accuracy goal, we\nshow that an application of the classic Vickrey auction achieves the analyst's\naccuracy goal while minimizing his total payment.\n  2. In the setting in which the data analyst has a fixed budget, we give a\nmechanism which maximizes the accuracy of the resulting estimate while\nguaranteeing that the resulting sum payments do not exceed the analysts budget.\n  In both cases, our comparison class is the set of envy-free mechanisms, which\ncorrespond to the natural class of fixed-price mechanisms in our setting.\n  In both of these results, we ignore the privacy cost due to possible\ncorrelations between an individuals private data and his valuation for privacy\nitself. We then show that generically, no individually rational mechanism can\ncompensate individuals for the privacy loss incurred due to their reported\nvaluations for privacy.\n", "versions": [{"version": "v1", "created": "Fri, 5 Nov 2010 12:04:53 GMT"}, {"version": "v2", "created": "Fri, 19 Nov 2010 15:05:47 GMT"}, {"version": "v3", "created": "Thu, 3 Feb 2011 21:20:18 GMT"}, {"version": "v4", "created": "Tue, 29 Nov 2011 14:51:37 GMT"}], "update_date": "2011-11-30", "authors_parsed": [["Ghosh", "Arpita", ""], ["Roth", "Aaron", ""]]}, {"id": "1011.1529", "submitter": "Jaydip Sen", "authors": "Jaydip Sen", "title": "A Survey on Wireless Sensor Network Security", "comments": "24 pages, 4 figures, 2 tables", "journal-ref": "International Journal of Vommunication Networks and Information\n  Security (IJCNIS), Vol 1, No 2, pp. 55 - 78, August 2009", "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless sensor networks (WSNs) have recently attracted a lot of interest in\nthe research community due their wide range of applications. Due to distributed\nnature of these networks and their deployment in remote areas, these networks\nare vulnerable to numerous security threats that can adversely affect their\nproper functioning. This problem is more critical if the network is deployed\nfor some mission-critical applications such as in a tactical battlefield.\nRandom failure of nodes is also very likely in real-life deployment scenarios.\nDue to resource constraints in the sensor nodes, traditional security\nmechanisms with large overhead of computation and communication are infeasible\nin WSNs. Security in sensor networks is, therefore, a particularly challenging\ntask. This paper discusses the current state of the art in security mechanisms\nfor WSNs. Various types of attacks are discussed and their countermeasures\npresented. A brief discussion on the future direction of research in WSN\nsecurity is also included.\n", "versions": [{"version": "v1", "created": "Sat, 6 Nov 2010 00:50:02 GMT"}], "update_date": "2010-11-09", "authors_parsed": [["Sen", "Jaydip", ""]]}, {"id": "1011.1531", "submitter": "Jaydip Sen", "authors": "Jaydip Sen", "title": "An Agent-Based Intrusion Detection System for Local Area Networks", "comments": "13 pages, 5 figures, 2 tables", "journal-ref": "International Journal of Communication Networks and Information\n  Security (IJCNIS), Vol 2, No 2, August 2010", "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since it is impossible to predict and identify all the vulnerabilities of a\nnetwork beforehand, and penetration into a system by malicious intruders cannot\nalways be prevented, intrusion detection systems (IDSs) are essential entities\nto ensure the security of a networked system. To be effective in carrying out\ntheir functions, the IDSs need to be accurate, adaptive, and extensible. Given\nthese stringent requirements and the high level of vulnerabilities of the\ncurrent days' networks, the design of an IDS has become a very challenging\ntask. Although, an extensive research has been done on intrusion detection in a\ndistributed environment, distributed IDSs suffer from a number of drawbacks\ne.g., high rates of false positives, low detection efficiency etc. In this\npaper, the design of a distributed IDS is proposed that consists of a group of\nautonomous and cooperating agents. In addition to its ability to detect\nattacks, the system is capable of identifying and isolating compromised nodes\nin the network thereby introducing fault-tolerance in its operations. The\nexperiments conducted on the system have shown that it has a high detection\nefficiency and low false positives compared to some of the currently existing\nsystems.\n", "versions": [{"version": "v1", "created": "Sat, 6 Nov 2010 01:05:20 GMT"}], "update_date": "2010-11-13", "authors_parsed": [["Sen", "Jaydip", ""]]}, {"id": "1011.1638", "submitter": "Eric Filiol", "authors": "Anthony Desnos and Robert Erra and Eric Filiol", "title": "Processor-Dependent Malware... and codes", "comments": "13 pages - Extended version of the paper presented at the iAWACS 2009\n  conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware usually target computers according to their operating system. Thus we\nhave Windows malwares, Linux malwares and so on ... In this paper, we consider\na different approach and show on a technical basis how easily malware can\nrecognize and target systems selectively, according to the onboard processor\nchip. This technology is very easy to build since it does not rely on deep\nanalysis of chip logical gates architecture. Floating Point Arithmetic (FPA)\nlooks promising to define a set of tests to identify the processor or, more\nprecisely, a subset of possible processors. We give results for different\nfamilies of processors: AMD, Intel (Dual Core, Atom), Sparc, Digital Alpha,\nCell, Atom ... As a conclusion, we propose two {\\it open problems} that are\nnew, to the authors' knowledge.\n", "versions": [{"version": "v1", "created": "Sun, 7 Nov 2010 14:31:15 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Desnos", "Anthony", ""], ["Erra", "Robert", ""], ["Filiol", "Eric", ""]]}, {"id": "1011.1793", "submitter": "Jaydip Sen", "authors": "Jaydip Sen, Kaustav Goswami", "title": "An Algorithm for Detection of Selfish Nodes in Wireless Mesh Networks", "comments": "6 pages, 6 figures, 3 tables. Conference: International Symposium on\n  Intelligent Information Systems and Applications (IISA'09)", "journal-ref": null, "doi": null, "report-no": "ISBN 978-952-5726-04-6 (Print), 978-952-5726-05-3 (CD-ROM)", "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless mesh networks (WMNs) are evolving as a key technology for\nnext-generation wireless networks showing raid progress and numerous\napplications. These networks have the potential to provide robust and\nhigh-throughput data delivery to wireless users. In a WMN, high speed routers\nequipped with advanced antennas, communicate with each other in a multi-hop\nfashion over wireless channels and form a broadband backhaul. However, the\nthroughput of a WMN may be severely degraded due to presence of some selfish\nrouters that avoid forwarding packets for other nodes even as they send their\nown traffic through the network. This paper presents an algorithm for detection\nof selfish nodes in a WMN. It uses statistical theory of inference for reliable\nclustering of the nodes and is based on local observations by the nodes.\nSimulation results show that the algorithm has a high detection rate while\nhaving a low rate of false positives.\n", "versions": [{"version": "v1", "created": "Mon, 8 Nov 2010 13:13:59 GMT"}], "update_date": "2010-11-09", "authors_parsed": [["Sen", "Jaydip", ""], ["Goswami", "Kaustav", ""]]}, {"id": "1011.2551", "submitter": "Xin Li", "authors": "Xin Li", "title": "On the Problem of Local Randomness in Privacy Amplification with an\n  Active Adversary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of privacy amplification with an active adversary in the\ninformation theoretic setting. In this setting, two parties Alice and Bob start\nout with a shared $n$-bit weak random string $W$, and try to agree on a secret\nrandom key $R$ over a public channel fully controlled by an active and\nunbounded adversary. Typical assumptions are that these two parties have access\nto local private uniform random bits. In this paper we seek to minimize the\nrequirements on the local randomness used by the two parties.\n  We make two improvements over previous results. First, we reduce the number\nof random bits needed for each party to $\\Theta(\\ell+\\log n)$, where $\\ell$ is\nthe security parameter, as long as $W$ has min-entropy $n^{\\Omega(1)}$.\nPreviously, the best known result needs to use $\\Theta((\\ell+\\log n)\\log n)$\nbits. Our result is also asymptotically optimal. Second, we generalize the\nproblem to the case where the two parties only have local weak random sources\ninstead of truly uniform random bits. We show that when each party has a local\nweak random source with min-entropy $> n/2$, there is an efficient privacy\namplification protocol that works nearly as good as if the two parties have\naccess to local uniform random bits. Next, in the case where each party only\nhas a weak random source with arbitrarily linear min-entropy, we give an\nefficient privacy amplification protocol where we can achieve security\nparameter up to $\\Omega(\\log k)$. Our results give the first protocols that\nachieve privacy amplification when each party only has access to a local weak\nrandom source.\n", "versions": [{"version": "v1", "created": "Thu, 11 Nov 2010 04:16:27 GMT"}], "update_date": "2010-11-12", "authors_parsed": [["Li", "Xin", ""]]}, {"id": "1011.2644", "submitter": "Anna Rimoldi", "authors": "Anna Rimoldi and Massimiliano Sala and Enrico Bertolazzi", "title": "Do AES encryptions act randomly?", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Advanced Encryption Standard (AES) is widely recognized as the most\nimportant block cipher in common use nowadays. This high assurance in AES is\ngiven by its resistance to ten years of extensive cryptanalysis, that has shown\nno weakness, not even any deviation from the statistical behaviour expected\nfrom a random permutation. Only reduced versions of the ciphers have been\nbroken, but they are not usually implemented. In this paper we build a\ndistinguishing attack on the AES, exploiting the properties of a novel cipher\nembedding. With our attack we give some statistical evidence that the set of\nAES-$128$ encryptions acts on the message space in a way significantly\ndifferent than that of the set of random permutations acting on the same space.\nWhile we feel that more computational experiments by independent third parties\nare needed in order to validate our statistical results, we show that the\nnon-random behaviour is the same as we would predict using the property of our\nembedding. Indeed, the embedding lowers the nonlinearity of the AES rounds and\ntherefore the AES encryptions tend, on average, to keep low the rank of\nlow-rank matrices constructed in the large space. Our attack needs $2^{23}$\nplaintext-ciphertext pairs and costs the equivalent of $2^{48}$ encryptions.\n  We expect our attack to work also for AES-$192$ and AES-$256$, as confirmed\nby preliminary experiments.\n", "versions": [{"version": "v1", "created": "Thu, 11 Nov 2010 13:17:15 GMT"}], "update_date": "2010-11-12", "authors_parsed": [["Rimoldi", "Anna", ""], ["Sala", "Massimiliano", ""], ["Bertolazzi", "Enrico", ""]]}, {"id": "1011.2946", "submitter": "Anshuman Sinha", "authors": "Anshuman Sinha", "title": "A Survey of System Security in Contactless Electronic Passports", "comments": "11 pages, 5 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  A traditional paper-based passport contains a Machine- Readable Zone (MRZ)\nand a Visual Inspection Zone (VIZ). The MRZ has two lines of the holder's\npersonal data, some document data, and verification characters encoded using\nthe Optical Character Recognition font B (OCRB). The encoded data includes the\nholder's name, date of birth, and other identifying information for the holder\nor the document. The VIZ contains the holder's photo and signature, usually on\nthe data page. However, the MRZ and VIZ can be easily duplicated with normal\ndocument reproduction technology to produce a fake passport which can pass\ntraditional verification. Neither of these features actively verify the\nholder's identity; nor do they bind the holder's identity to the document. A\npassport also contains pages for stamps of visas and of country entry and exit\ndates, which can be easily altered to produce fake permissions and travel\nrecords. The electronic passport, supporting authentication using secure\ncredentials on a tamper-resistant chip, is an attempt to improve on the\nsecurity of the paper-based passport at minimum cost. This paper surveys the\nsecurity mechanisms built into the firstgeneration of authentication mechanisms\nand compares them with second-generation passports. It analyzes and describes\nthe cryptographic protocols used in Basic Access Control (BAC) and Extended\nAccess Control (EAC).\n", "versions": [{"version": "v1", "created": "Fri, 12 Nov 2010 15:28:26 GMT"}], "update_date": "2010-12-13", "authors_parsed": [["Sinha", "Anshuman", ""]]}, {"id": "1011.3096", "submitter": "Feng Xia", "authors": "Yang Liu, Zhikui Chen, Feng Xia, Xiaoning Lv, Fanyu Bu", "title": "A Trust Model Based on Service Classification in Mobile Services", "comments": "IEEE/ACM Internet of Things Symposium (IOTS), in conjunction with\n  GreenCom 2010, IEEE, Hangzhou, China, December 18-20, 2010", "journal-ref": null, "doi": "10.1109/GreenCom-CPSCom.2010.19", "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) and B3G/4G communication are promoting the pervasive\nmobile services with its advanced features. However, security problems are also\nbaffled the development. This paper proposes a trust model to protect the\nuser's security. The billing or trust operator works as an agent to provide a\ntrust authentication for all the service providers. The services are classified\nby sensitive value calculation. With the value, the user's trustiness for\ncorresponding service can be obtained. For decision, three trust regions are\ndivided, which is referred to three ranks: high, medium and low. The trust\nregion tells the customer, with his calculated trust value, which rank he has\ngot and which authentication methods should be used for access. Authentication\nhistory and penalty are also involved with reasons.\n", "versions": [{"version": "v1", "created": "Sat, 13 Nov 2010 03:34:10 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Liu", "Yang", ""], ["Chen", "Zhikui", ""], ["Xia", "Feng", ""], ["Lv", "Xiaoning", ""], ["Bu", "Fanyu", ""]]}, {"id": "1011.3098", "submitter": "Feng Xia", "authors": "Lin Yao, Chi Lin, Xiangwei Kong, Feng Xia, Guowei Wu", "title": "A Clustering-based Location Privacy Protection Scheme for Pervasive\n  Computing", "comments": "The 3rd IEEE/ACM Int Conf on Cyber, Physical and Social Computing\n  (CPSCom), IEEE, Hangzhou, China, December 18-20, 2010", "journal-ref": null, "doi": "10.1109/GreenCom-CPSCom.2010.109", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In pervasive computing environments, Location- Based Services (LBSs) are\nbecoming increasingly important due to continuous advances in mobile networks\nand positioning technologies. Nevertheless, the wide deployment of LBSs can\njeopardize the location privacy of mobile users. Consequently, providing\nsafeguards for location privacy of mobile users against being attacked is an\nimportant research issue. In this paper a new scheme for safeguarding location\nprivacy is proposed. Our approach supports location K-anonymity for a wide\nrange of mobile users with their own desired anonymity levels by clustering.\nThe whole area of all users is divided into clusters recursively in order to\nget the Minimum Bounding Rectangle (MBR). The exact location information of a\nuser is replaced by his MBR. Privacy analysis shows that our approach can\nachieve high resilience to location privacy threats and provide more privacy\nthan users expect. Complexity analysis shows clusters can be adjusted in real\ntime as mobile users join or leave. Moreover, the clustering algorithms possess\nstrong robustness.\n", "versions": [{"version": "v1", "created": "Sat, 13 Nov 2010 04:12:21 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Yao", "Lin", ""], ["Lin", "Chi", ""], ["Kong", "Xiangwei", ""], ["Xia", "Feng", ""], ["Wu", "Guowei", ""]]}, {"id": "1011.3101", "submitter": "Irfan Syamsuddin", "authors": "Irfan Syamsuddin, Junseok Hwang", "title": "A New Fuzzy MCDM Framework to Evaluate E-Government Security Strategy", "comments": "IEEE 4th International Conference on Application of Information and\n  Communication Technologies AICT2010", "journal-ref": null, "doi": "10.1109/ICAICT.2010.5612065", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring security of e-government applications and infrastructures is crucial\nto maintain trust among stakeholders to store, process and exchange information\nover the e-government systems. Due to dynamic and continuous threats on\ne-government information security, policy makers need to perform evaluation on\nexisting information security strategy as to deliver trusted e-government\nservices. This paper presents an information security evaluation framework\nbased on new fuzzy multi criteria decision making (MCDM) to help policy makers\nconduct comprehensive assessment of e-government security strategy.\n", "versions": [{"version": "v1", "created": "Sat, 13 Nov 2010 04:53:45 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Syamsuddin", "Irfan", ""], ["Hwang", "Junseok", ""]]}, {"id": "1011.3148", "submitter": "Nikolai Stoianov", "authors": "Nikolai Stoianov, Veselin Tselkov", "title": "E-net models for distribution, access and use of resources in security\n  information systems", "comments": "2 figures, 2 definitions for interacting,", "journal-ref": "Mathematics and Education in Mathematics, 2004 Proceedings of the\n  Thirty Fourth Spring Conference of the Union of Bulgarian\n  Mathematicians,pp.251 - 256 ISBN 954-8880-17-2", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents solutions for distribution, access and use of resources\nin information security systems. The solutions comprise the authors' experience\nin development and implementation of systems for information security in the\nAutomated Information Systems. The models, the methods and the modus operandi\nare being explained.\n", "versions": [{"version": "v1", "created": "Sat, 13 Nov 2010 17:04:46 GMT"}], "update_date": "2010-12-13", "authors_parsed": [["Stoianov", "Nikolai", ""], ["Tselkov", "Veselin", ""]]}, {"id": "1011.3279", "submitter": "Cynthia D", "authors": "Dhinaharan Nagamalai, Beatrice Cynthia Dhinakaran and Jae Kwang Lee", "title": "Bayesian Based Comment Spam Defending Tool", "comments": "14 Pages,4 Figures, International Journal of Network Security & Its\n  Applications (IJNSA), Vol.2, No.4, October 2010", "journal-ref": null, "doi": "10.5121/ijnsa.2010.2420", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spam messes up user's inbox, consumes network resources and spread worms and\nviruses. Spam is flooding of unsolicited, unwanted e mail. Spam in blogs is\ncalled blog spam or comment spam.It is done by posting comments or flooding\nspams to the services such as blogs, forums,news,email archives and guestbooks.\nBlog spams generally appears on guestbooks or comment pages where spammers fill\na comment box with spam words. In addition to wasting user's time with unwanted\ncomments, spam also consumes a lot of bandwidth. In this paper, we propose a\nsoftware tool to prevent such blog spams by using Bayesian Algorithm based\ntechnique. It is derived from Bayes' Theorem. It gives an output which has a\nprobability that any comment is spam, given that it has certain words in it.\nWith using our past entries and a comment entry, this value is obtained and\ncompared with a threshold value to find if it exceeds the threshold value or\nnot. By using this concept, we developed a software tool to block comment spam.\nThe experimental results show that the Bayesian based tool is working well.\nThis paper has the major findings and their significance of blog spam filter.\n", "versions": [{"version": "v1", "created": "Mon, 15 Nov 2010 02:42:48 GMT"}], "update_date": "2010-11-16", "authors_parsed": [["Nagamalai", "Dhinaharan", ""], ["Dhinakaran", "Beatrice Cynthia", ""], ["Lee", "Jae Kwang", ""]]}, {"id": "1011.3718", "submitter": "Wei Dai", "authors": "Wei Dai", "title": "Commutative-like Encryption: A New Characterization of ElGamal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commutative encryption is a useful but rather strict notion in cryptography.\nIn this paper, we deny a loose variation of commutative\nencryption-commutative-like encryption and give an example: the generalization\nof ElGamal scheme. The application of the new variation is also discussed.\n", "versions": [{"version": "v1", "created": "Tue, 16 Nov 2010 15:05:41 GMT"}], "update_date": "2010-11-17", "authors_parsed": [["Dai", "Wei", ""]]}, {"id": "1011.3879", "submitter": "MinJi Kim", "authors": "MinJi Kim, Muriel Medard, Joao Barros", "title": "Algebraic Watchdog: Mitigating Misbehavior in Wireless Network Coding", "comments": "10 pages, 10 figures, Submitted to IEEE Journal on Selected Areas in\n  Communications (JSAC) \"Advances in Military Networking and Communications\"", "journal-ref": null, "doi": "10.1109/JSAC.2011.111202", "report-no": null, "categories": "cs.CR cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a secure scheme for wireless network coding, called the algebraic\nwatchdog. By enabling nodes to detect malicious behaviors probabilistically and\nuse overheard messages to police their downstream neighbors locally, the\nalgebraic watchdog delivers a secure global self-checking network. Unlike\ntraditional Byzantine detection protocols which are receiver-based, this\nprotocol gives the senders an active role in checking the node downstream. The\nkey idea is inspired by Marti et al.'s watchdog-pathrater, which attempts to\ndetect and mitigate the effects of routing misbehavior.\n  As an initial building block of a such system, we first focus on a two-hop\nnetwork. We present a graphical model to understand the inference process nodes\nexecute to police their downstream neighbors; as well as to compute, analyze,\nand approximate the probabilities of misdetection and false detection. In\naddition, we present an algebraic analysis of the performance using an\nhypothesis testing framework that provides exact formulae for probabilities of\nfalse detection and misdetection.\n  We then extend the algebraic watchdog to a more general network setting, and\npropose a protocol in which we can establish trust in coded systems in a\ndistributed manner. We develop a graphical model to detect the presence of an\nadversarial node downstream within a general multi-hop network. The structure\nof the graphical model (a trellis) lends itself to well-known algorithms, such\nas the Viterbi algorithm, which can compute the probabilities of misdetection\nand false detection. We show analytically that as long as the min-cut is not\ndominated by the Byzantine adversaries, upstream nodes can monitor downstream\nneighbors and allow reliable communication with certain probability. Finally,\nwe present simulation results that support our analysis.\n", "versions": [{"version": "v1", "created": "Wed, 17 Nov 2010 04:00:06 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Kim", "MinJi", ""], ["Medard", "Muriel", ""], ["Barros", "Joao", ""]]}, {"id": "1011.3985", "submitter": "Mahmoud Ramezani Mayiami", "authors": "Mahmoud Ramezani Mayiami, Babak Seyfe, Hamid G. Bafghi", "title": "Perfect Secrecy Using Compressed Sensing", "comments": "3 pages", "journal-ref": null, "doi": "10.1109/IWCIT.2013.6555751", "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the compressed sensing-based encryption and\nproposed the conditions in which the perfect secrecy is obtained. We prove when\nthe Restricted Isometery Property (RIP) is hold and the number of measurements\nis more than two times of sparsity level i.e. M \\geq 2k, the perfect secrecy\ncondition introduced by Shannon is achievable if message block is not equal to\nzero or we have infinite block length\n", "versions": [{"version": "v1", "created": "Wed, 17 Nov 2010 16:08:04 GMT"}], "update_date": "2016-02-02", "authors_parsed": [["Mayiami", "Mahmoud Ramezani", ""], ["Seyfe", "Babak", ""], ["Bafghi", "Hamid G.", ""]]}, {"id": "1011.5242", "submitter": "Stacey Jeffery", "authors": "Anne Broadbent and Stacey Jeffery and Alain Tapp", "title": "Exact, Efficient and Information-Theoretically Secure Voting with an\n  Arbitrary Number of Cheaters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present three voting protocols with unconditional privacy and correctness,\nwithout assuming any bound on the number of corrupt participants. All protocols\nhave polynomial complexity and require private channels and a simultaneous\nbroadcast channel. Unlike previously proposed protocols in this model, the\nprotocols that we present deterministically output the exact tally. Our first\nprotocol is a basic voting scheme which allows voters to interact in order to\ncompute the tally. Privacy of the ballot is unconditional in the sense that\nregardless of the behavior of the dishonest participants nothing can be learned\nthrough the protocol that could not be learned in an ideal realisation.\nUnfortunately, a single dishonest participant can make the protocol abort, in\nwhich case the dishonest participants can nevertheless learn the outcome of the\ntally. Our second protocol introduces voting authorities which improves the\ncommunication complexity by limiting interaction to be only between voters and\nauthorities and among the authorities themselves; the simultaneous broadcast is\nalso limited to the authorities. In the second protocol, as long as a single\nauthority is honest, the privacy is unconditional, however, a single corrupt\nauthority or a single corrupt voter can cause the protocol to abort. Our final\nprotocol provides a safeguard against corrupt voters by enabling a verification\ntechnique to allow the authorities to revoke incorrect votes without aborting\nthe protocol. Finally, we discuss the implementation of a simultaneous\nbroadcast channel with the use of temporary computational assumptions, yielding\nversions of our protocols that achieve everlasting security.\n", "versions": [{"version": "v1", "created": "Tue, 23 Nov 2010 21:33:50 GMT"}], "update_date": "2010-11-25", "authors_parsed": [["Broadbent", "Anne", ""], ["Jeffery", "Stacey", ""], ["Tapp", "Alain", ""]]}, {"id": "1011.5295", "submitter": "Karim Eldefrawy", "authors": "Karim El Defrawy, Srdjan Capkun and Gene Tsudik", "title": "GDB: Group Distance Bounding Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure distance bounding (DB) protocols allow one entity, the verifier, to\nsecurely obtain an upper-bound on the distance to another entity, the prover.\nThus far, DB was considered mostly in the context of a single prover and a\nsingle verifier. There has been no substantial prior work on secure DB in group\nsettings, where a set of provers interact with a set of verifiers. The need for\ngroup distance bounding (GDB) is motivated by many practical scenarios,\nincluding: group device pairing, location-based access control and secure\ndistributed localization. GDB is also useful in mission-critical networks and\nautomotive computer systems. This paper addresses, for the first time, GDB\nprotocols by utilizing the new passive DB primitive and the novel mutual\nmulti-party GDB protocol. We show how they can be used to construct secure and\nefficient GDB protocols for various settings. We analyze security and\nperformance of our protocols and compare them with existing DB techniques when\napplied to group settings.\n", "versions": [{"version": "v1", "created": "Wed, 24 Nov 2010 05:05:14 GMT"}], "update_date": "2010-11-25", "authors_parsed": [["Defrawy", "Karim El", ""], ["Capkun", "Srdjan", ""], ["Tsudik", "Gene", ""]]}, {"id": "1011.5534", "submitter": "Dhananjoy Dey", "authors": "Dhananjoy Dey, Prasanna Raghaw Mishra1, Indranath Sengupta", "title": "GB-hash : Hash Functions Using Groebner Basis", "comments": "The paper has been withdrawn. The authors have found some weaknesses\n  in this design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.AC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this paper we present an improved version of HF-hash, viz., GB-hash : Hash\nFunctions Using Groebner Basis. In case of HF-hash, the compression function\nconsists of 32 polynomials with 64 variables which were taken from the first 32\npolynomials of hidden field equations challenge-1 by forcing last 16 variables\nas 0. In GB-hash we have designed the compression function in such way that\nthese 32 polynomials with 64 variables form a minimal Groebner basis of the\nideal generated by them with respect to graded lexicographical (grlex) ordering\nas well as with respect to graded reverse lexicographical (grevlex) ordering.\nIn this paper we will prove that GB-hash is more secure than HF-hash as well as\nmore secure than SHA-256. We have also compared the efficiency of our GB-hash\nwith SHA-256 and HF-hash.\n", "versions": [{"version": "v1", "created": "Thu, 25 Nov 2010 00:14:19 GMT"}, {"version": "v2", "created": "Tue, 30 Aug 2011 05:04:51 GMT"}], "update_date": "2011-08-31", "authors_parsed": [["Dey", "Dhananjoy", ""], ["Mishra1", "Prasanna Raghaw", ""], ["Sengupta", "Indranath", ""]]}, {"id": "1011.5545", "submitter": "Xiao-Shan Gao", "authors": "Shangwei Zhao, Ruyong Feng and Xiao-Shan Gao", "title": "On Functional Decomposition of Multivariate Polynomials with\n  Differentiation and Homogenization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we give a theoretical analysis for the algorithms to compute\nfunctional decomposition for multivariate polynomials based on differentiation\nand homogenization which are proposed by Ye, Dai, Lam (1999) and Faug$\\mu$ere,\nPerret (2006, 2008, 2009). We show that a degree proper functional\ndecomposition for a set of randomly decomposable quartic homogenous polynomials\ncan be computed using the algorithm with high probability. This solves a\nconjecture proposed by Ye, Dai, and Lam (1999). We also propose a conjecture\nsuch that the decomposition for a set of polynomials can be computed from that\nof its homogenization with high probability. Finally, we prove that the right\ndecomposition factors for a set of polynomials can be computed from its right\ndecomposition factor space. Combining these results together, we prove that the\nalgorithm can compute a degree proper decomposition for a set of randomly\ndecomposable quartic polynomials with probability one when the base field is of\ncharacteristic zero, and with probability close to one when the base field is a\nfinite field with sufficiently large number under the assumption that the\nconjeture is correct.\n", "versions": [{"version": "v1", "created": "Thu, 25 Nov 2010 03:11:19 GMT"}], "update_date": "2010-11-29", "authors_parsed": [["Zhao", "Shangwei", ""], ["Feng", "Ruyong", ""], ["Gao", "Xiao-Shan", ""]]}, {"id": "1011.5566", "submitter": "Vitaly Skachek", "authors": "Son Hoang Dau, Vitaly Skachek and Yeow Meng Chee", "title": "Secure Index Coding with Side Information", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security aspects of the Index Coding with Side Information (ICSI) problem are\ninvestigated. Building on the results of Bar-Yossef et al. (2006), the\nproperties of linear coding schemes for the ICSI problem are further explored.\nThe notion of weak security, considered by Bhattad and Narayanan (2005) in the\ncontext of network coding, is generalized to block security. It is shown that\nthe coding scheme for the ICSI problem based on a linear code C of length n,\nminimum distance d and dual distance d^\\perp, is (d-1-t)-block secure (and\nhence also weakly secure) if the adversary knows in advance t \\le d - 2\nmessages, and is completely insecure if the adversary knows in advance more\nthan n - d^\\perp messages.\n", "versions": [{"version": "v1", "created": "Thu, 25 Nov 2010 08:36:53 GMT"}], "update_date": "2010-11-29", "authors_parsed": [["Dau", "Son Hoang", ""], ["Skachek", "Vitaly", ""], ["Chee", "Yeow Meng", ""]]}, {"id": "1011.5567", "submitter": "Eran Omri", "authors": "Amos Beimel, Eran Omri, and Ilan Orlov", "title": "Secure Multiparty Computation with Partial Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A protocol for computing a functionality is secure if an adversary in this\nprotocol cannot cause more harm than in an ideal computation where parties give\ntheir inputs to a trusted party which returns the output of the functionality\nto all parties. In particular, in the ideal model such computation is fair --\nall parties get the output. Cleve (STOC 1986) proved that, in general, fairness\nis not possible without an honest majority. To overcome this impossibility,\nGordon and Katz (Eurocrypt 2010) suggested a relaxed definition -- 1/p-secure\ncomputation -- which guarantees partial fairness. For two parties, they\nconstruct 1/p-secure protocols for functionalities for which the size of either\ntheir domain or their range is polynomial (in the security parameter). Gordon\nand Katz ask whether their results can be extended to multiparty protocols.\n  We study 1/p-secure protocols in the multiparty setting for general\nfunctionalities. Our main result is constructions of 1/p-secure protocols when\nthe number of parties is constant provided that less than 2/3 of the parties\nare corrupt. Our protocols require that either (1) the functionality is\ndeterministic and the size of the domain is polynomial (in the security\nparameter), or (2) the functionality can be randomized and the size of the\nrange is polynomial. If the size of the domain is constant and the\nfunctionality is deterministic, then our protocol is efficient even when the\nnumber of parties is O(log log n) (where n is the security parameter). On the\nnegative side, we show that when the number of parties is super-constant,\n1/p-secure protocols are not possible when the size of the domain is\npolynomial.\n", "versions": [{"version": "v1", "created": "Thu, 25 Nov 2010 08:37:52 GMT"}], "update_date": "2010-11-29", "authors_parsed": [["Beimel", "Amos", ""], ["Omri", "Eran", ""], ["Orlov", "Ilan", ""]]}, {"id": "1011.5696", "submitter": "Dusko Pavlovic", "authors": "Dusko Pavlovic", "title": "Quantifying and qualifying trust: Spectral decomposition of trust\n  networks", "comments": "18 pages, 4 figures; FAST 2010. Version 2: corrected several typos,\n  added a missing arrow in Fig 1, added 2 sentences to the Abstract", "journal-ref": null, "doi": "10.1007/978-3-642-19751-2_1", "report-no": null, "categories": "cs.CR cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a previous FAST paper, I presented a quantitative model of the process of\ntrust building, and showed that trust is accumulated like wealth: the rich get\nricher. This explained the pervasive phenomenon of adverse selection of trust\ncertificates, as well as the fragility of trust networks in general. But a\nsimple explanation does not always suggest a simple solution. It turns out that\nit is impossible to alter the fragile distribution of trust without sacrificing\nsome of its fundamental functions. A solution for the vulnerability of trust\nmust thus be sought elsewhere, without tampering with its distribution. This\nobservation was the starting point of the present paper. It explores a\ndifferent method for securing trust: not by redistributing it, but by mining\nfor its sources. The method used to break privacy is thus also used to secure\ntrust. A high level view of the mining methods that connect the two is provided\nin terms of *similarity networks*, and *spectral decomposition* of similarity\npreserving maps. This view may be of independent interest, as it uncovers a\ncommon conceptual and structural foundation of mathematical classification\ntheory on one hand, and of the spectral methods of graph clustering and data\nmining on the other hand.\n", "versions": [{"version": "v1", "created": "Fri, 26 Nov 2010 02:42:15 GMT"}, {"version": "v2", "created": "Sun, 19 Dec 2010 01:36:20 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["Pavlovic", "Dusko", ""]]}, {"id": "1011.6505", "submitter": "Xiao-Shan Gao", "authors": "Xiao-Shan Gao and Zhenyu Huang", "title": "Efficient Characteristic Set Algorithms for Equation Solving in Finite\n  Fields and Applications in Cryptanalysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient characteristic set methods for computing solutions of polynomial\nequation systems in a finite field are proposed. The concept of proper\ntriangular sets is introduced and an explicit formula for the number of\nsolutions of a proper and monic (or regular) triangular set is given. An\nimproved zero decomposition algorithm which can be used to reduce the zero set\nof an equation system in general form to the union of zero sets of monic proper\ntriangular sets is proposed. As a consequence, we can give an explicit formula\nfor the number of solutions of an equation system. Bitsize complexity for the\nalgorithm is given in the case of Boolean polynomials. We also give a\nmultiplication free characteristic set method for Boolean polynomials, where\nthe sizes of the polynomials are effectively controlled. The algorithms are\nimplemented in the case of Boolean polynomials and extensive experiments show\nthat they are quite efficient for solving certain classes of Boolean equations.\n", "versions": [{"version": "v1", "created": "Tue, 30 Nov 2010 09:51:40 GMT"}], "update_date": "2010-12-01", "authors_parsed": [["Gao", "Xiao-Shan", ""], ["Huang", "Zhenyu", ""]]}]