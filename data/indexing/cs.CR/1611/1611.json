[{"id": "1611.00306", "submitter": "Krzysztof Szczypiorski", "authors": "Krzysztof Szczypiorski", "title": "StegHash: New Method for Information Hiding in Open Social Networks", "comments": "6 pages, 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a new method for information hiding in open social networks is\nintroduced. The method, called StegHash, is based on the use of hashtags in\nvarious open social networks to connect multimedia files (like images, movies,\nsongs) with embedded hidden messages. The evaluation of the system was\nperformed on two social media services (Twitter and Instagram) with a simple\nenvironment as a proof of concept. The experiments proved that the initial idea\nwas correct, thus the proposed system could create a completely new area of\nthreats in social networks.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 17:36:15 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["Szczypiorski", "Krzysztof", ""]]}, {"id": "1611.00340", "submitter": "Mijung Park", "authors": "Mijung Park, James Foulds, Kamalika Chaudhuri, Max Welling", "title": "Variational Bayes In Private Settings (VIPS)", "comments": "The previous version of this paper had an error in the composition\n  method we used. This version fixed that error", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications of Bayesian data analysis involve sensitive information,\nmotivating methods which ensure that privacy is protected. We introduce a\ngeneral privacy-preserving framework for Variational Bayes (VB), a widely used\noptimization-based Bayesian inference method. Our framework respects\ndifferential privacy, the gold-standard privacy criterion, and encompasses a\nlarge class of probabilistic models, called the Conjugate Exponential (CE)\nfamily. We observe that we can straightforwardly privatise VB's approximate\nposterior distributions for models in the CE family, by perturbing the expected\nsufficient statistics of the complete-data likelihood. For a broadly-used class\nof non-CE models, those with binomial likelihoods, we show how to bring such\nmodels into the CE family, such that inferences in the modified model resemble\nthe private variational Bayes algorithm as closely as possible, using the\nPolya-Gamma data augmentation scheme. The iterative nature of variational Bayes\npresents a further challenge since iterations increase the amount of noise\nneeded. We overcome this by combining: (1) an improved composition method for\ndifferential privacy, called the moments accountant, which provides a tight\nbound on the privacy cost of multiple VB iterations and thus significantly\ndecreases the amount of additive noise; and (2) the privacy amplification\neffect of subsampling mini-batches from large-scale data in stochastic\nlearning. We empirically demonstrate the effectiveness of our method in CE and\nnon-CE models including latent Dirichlet allocation, Bayesian logistic\nregression, and sigmoid belief networks, evaluated on real-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 19:19:49 GMT"}, {"version": "v2", "created": "Mon, 28 Nov 2016 21:09:16 GMT"}, {"version": "v3", "created": "Wed, 21 Dec 2016 23:16:31 GMT"}, {"version": "v4", "created": "Tue, 6 Mar 2018 20:52:01 GMT"}, {"version": "v5", "created": "Mon, 3 Dec 2018 20:32:56 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Park", "Mijung", ""], ["Foulds", "James", ""], ["Chaudhuri", "Kamalika", ""], ["Welling", "Max", ""]]}, {"id": "1611.00374", "submitter": "Anees  Ara", "authors": "Anees Ara, Mznah Al-Rodhaan, Yuan Tian, Abdullah Al-Dhelaan", "title": "A secure service provisioning framework for cyber physical cloud\n  computing systems", "comments": "11 pages, 4 figures, 1 table.\n  http://airccse.org/journal/ijdps/current2015.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber physical systems (CPS) are mission critical systems engineered by\ncombination of cyber and physical systems respectively. These systems are\ntightly coupled, resource constrained systems and have dynamic real time\napplications. Due to the limitation of resources, and in order to improve the\nefficiency of the CPS systems, they are combined with cloud computing\narchitecture, and are called as Cyber Physical Cloud Computing Systems (CPCCS).\nThese CPCCS have critical care applications where security of the systems is a\nmajor concern. Therefore, we propose a Secure Service provisioning architecture\nfor Cyber Physical Cloud Computing Systems (CPCCS), which includes the\ncombination of technologies such as CPS, Cloud Computing and Wireless Sensor\nNetworks. In addition to this, we also highlight various threats/attacks;\nsecurity requirements and mechanisms that are applicable to CPCCS at different\nlayers and propose two security models that can be adapted in a layered\narchitectural format.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2015 11:46:32 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Ara", "Anees", ""], ["Al-Rodhaan", "Mznah", ""], ["Tian", "Yuan", ""], ["Al-Dhelaan", "Abdullah", ""]]}, {"id": "1611.00381", "submitter": "Alireza Jolfaei", "authors": "Alireza Jolfaei", "title": "Comments on an image encryption scheme based on a chaotic Tent map", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently an image encryption scheme based on a chaotic Tent map has been\nproposed by Li et al. This comment shows that this scheme is broken and no\nsecure application can be found for it.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 19:56:28 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Jolfaei", "Alireza", ""]]}, {"id": "1611.00469", "submitter": "Antonis Manousis", "authors": "Antonis Manousis, Roy Ragsdale, Ben Draffin, Adwiteeya Agrawal, Vyas\n  Sekar", "title": "Shedding Light on the Adoption of Let's Encrypt", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let's Encrypt is a new entrant in the Certificate Authority ecosystem that\noffers free and automated certificate signing. It is visionary in its\ncommitment to Certificate Transparency. In this paper, we shed light on the\nadoption patterns of Let's Encrypt \"in the wild\" and inform the future design\nand deployment of this exciting development in the security landscape. We\nanalyze acquisition patterns of certificates as well as their usage and\ndeployment trends in the real world. To this end, we analyze data from\nCertificate Transparency Logs containing records of more then 18 million\ncertificates. We also leverage other sources like Censys, Alexa's historic\nrecords, Geolocation databases, and VirusTotal. We also perform active HTTPS\nmeasurements on the domains owning Let's Encrypt certificates. Our analysis of\ncertificate acquisition shows that (1) the impact of Let's Encrypt is\nparticularly visible in Western Europe; (2) Let's Encrypt has the potential to\ndemocratize HTTPS adoption in countries that are recent entrants to Internet\nadoption; (3) there is anecdotal evidence of popular domains quitting their\npreviously untrustworthy or expensive CAs in order to transition to Let's\nEncrypt; and (4) there is a \"heavy tailed\" behavior where a small number of\ndomains acquire a large number of certificates. With respect to usage, we find\nthat: (1) only 54% of domains actually use the Let's Encrypt certificates they\nhave procured; (2) there are many non-trivial incidents of server\nmisconfigurations; and (3) there is early evidence of use of Let's Encrypt\ncertificates for typosquatting and for malware-laden sites.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 04:43:22 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Manousis", "Antonis", ""], ["Ragsdale", "Roy", ""], ["Draffin", "Ben", ""], ["Agrawal", "Adwiteeya", ""], ["Sekar", "Vyas", ""]]}, {"id": "1611.00742", "submitter": "Peter Henderson", "authors": "Peter Henderson, Muthucumaru Maheswaran", "title": "Chaotic Memory Randomization for Securing Embedded Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedded systems permeate through nearly all aspects of modern society. From\ncars to refrigerators to nuclear refineries, securing these systems has never\nbeen more important. Intrusions, such as the Stuxnet malware which broke the\ncentrifuges in Iran's Natanz refinery, can be catastrophic to not only the\ninfected systems, but even to the wellbeing of the surrounding population.\nModern day protection mechanisms for these embedded systems generally look only\nat protecting the network layer, and those that try to discover malware already\nexisting on a system typically aren't efficient enough to run on a standalone\nembedded system. As such, we present a novel way to ensure that no malware has\nbeen inserted into an embedded system. We chaotically randomize the entire\nmemory space of the application, interspersing watchdog-monitor programs\nthroughout, to monitor that the core application hasn't been infiltrated. By\nvalidating the original program through conventional methods and creating a\nclean reset, we can ensure that any inserted malware is purged from the system\nwith minimal effect on the given system. We also present a software prototype\nto validate the possibility of this approach, but given the limitations and\nvulnerabilities of the prototype, we also suggest a hardware alternative to the\nsystem.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 19:40:28 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Henderson", "Peter", ""], ["Maheswaran", "Muthucumaru", ""]]}, {"id": "1611.00791", "submitter": "Hyrum Anderson", "authors": "Jonathan Woodbridge, Hyrum S. Anderson, Anjum Ahuja and Daniel Grant", "title": "Predicting Domain Generation Algorithms with Long Short-Term Memory\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various families of malware use domain generation algorithms (DGAs) to\ngenerate a large number of pseudo-random domain names to connect to a command\nand control (C&C) server. In order to block DGA C&C traffic, security\norganizations must first discover the algorithm by reverse engineering malware\nsamples, then generating a list of domains for a given seed. The domains are\nthen either preregistered or published in a DNS blacklist. This process is not\nonly tedious, but can be readily circumvented by malware authors using a large\nnumber of seeds in algorithms with multivariate recurrence properties (e.g.,\nbanjori) or by using a dynamic list of seeds (e.g., bedep). Another technique\nto stop malware from using DGAs is to intercept DNS queries on a network and\npredict whether domains are DGA generated. Such a technique will alert network\nadministrators to the presence of malware on their networks. In addition, if\nthe predictor can also accurately predict the family of DGAs, then network\nadministrators can also be alerted to the type of malware that is on their\nnetworks. This paper presents a DGA classifier that leverages long short-term\nmemory (LSTM) networks to predict DGAs and their respective families without\nthe need for a priori feature extraction. Results are significantly better than\nstate-of-the-art techniques, providing 0.9993 area under the receiver operating\ncharacteristic curve for binary classification and a micro-averaged F1 score of\n0.9906. In other terms, the LSTM technique can provide a 90% detection rate\nwith a 1:10000 false positive (FP) rate---a twenty times FP improvement over\ncomparable methods. Experiments in this paper are run on open datasets and code\nsnippets are provided to reproduce the results.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 20:34:56 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Woodbridge", "Jonathan", ""], ["Anderson", "Hyrum S.", ""], ["Ahuja", "Anjum", ""], ["Grant", "Daniel", ""]]}, {"id": "1611.00837", "submitter": "Lannan Luo", "authors": "Lannan Luo, Qiang Zeng, Chen Cao, Kai Chen, Jian Liu, Limin Liu, Neng\n  Gao, Min Yang, Xinyu Xing, and Peng Liu", "title": "Context-aware System Service Call-oriented Symbolic Execution of Android\n  Framework with Application to Exploit Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android Framework is a layer of software that exists in every Android system\nmanaging resources of all Android apps. A vulnerability in Android Framework\ncan lead to severe hacks, such as destroying user data and leaking private\ninformation. With tens of millions of Android devices unpatched due to Android\nfragmentation, vulnerabilities in Android Framework certainly attract attackers\nto exploit them. So far, enormous manual effort is needed to craft such\nexploits. To our knowledge, no research has been done on automatic generation\nof exploits that take advantage of Android Framework vulnerabilities. We make a\nfirst step towards this goal by applying symbolic execution of Android\nFramework to finding bugs and generating exploits. Several challenges have been\nraised by the task. (1) The information of an app flows to Android Framework in\nmultiple intricate steps, making it difficult to identify symbolic inputs. (2)\nAndroid Framework has a complex initialization phase, which exacerbates the\nstate space explosion problem. (3) A straightforward design that builds the\nsymbolic executor as a layer inside the Android system will not work well: not\nonly does the implementation have to ensure the compatibility with the Android\nsystem, but it needs to be maintained whenever Android gets updated. We present\nnovel ideas and techniques to resolve the challenges, and have built the first\nsystem for symbolic execution of Android Framework. It fundamentally changes\nthe state of the art in exploit generation on the Android system, and has been\napplied to constructing new techniques for finding vulnerabilities.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 23:09:23 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Luo", "Lannan", ""], ["Zeng", "Qiang", ""], ["Cao", "Chen", ""], ["Chen", "Kai", ""], ["Liu", "Jian", ""], ["Liu", "Limin", ""], ["Gao", "Neng", ""], ["Yang", "Min", ""], ["Xing", "Xinyu", ""], ["Liu", "Peng", ""]]}, {"id": "1611.01170", "submitter": "Wei Xie", "authors": "Wei Xie, Yang Wang, Steven M. Boker, Donald E. Brown", "title": "PrivLogit: Efficient Privacy-preserving Logistic Regression by Tailoring\n  Numerical Optimizers", "comments": "24 pages, 4 figures. Work done and circulated since 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safeguarding privacy in machine learning is highly desirable, especially in\ncollaborative studies across many organizations. Privacy-preserving distributed\nmachine learning (based on cryptography) is popular to solve the problem.\nHowever, existing cryptographic protocols still incur excess computational\noverhead. Here, we make a novel observation that this is partially due to naive\nadoption of mainstream numerical optimization (e.g., Newton method) and failing\nto tailor for secure computing. This work presents a contrasting perspective:\ncustomizing numerical optimization specifically for secure settings. We propose\na seemingly less-favorable optimization method that can in fact significantly\naccelerate privacy-preserving logistic regression. Leveraging this new method,\nwe propose two new secure protocols for conducting logistic regression in a\nprivacy-preserving and distributed manner. Extensive theoretical and empirical\nevaluations prove the competitive performance of our two secure proposals while\nwithout compromising accuracy or privacy: with speedup up to 2.3x and 8.1x,\nrespectively, over state-of-the-art; and even faster as data scales up. Such\ndrastic speedup is on top of and in addition to performance improvements from\nexisting (and future) state-of-the-art cryptography. Our work provides a new\nway towards efficient and practical privacy-preserving logistic regression for\nlarge-scale studies which are common for modern science.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 20:04:29 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Xie", "Wei", ""], ["Wang", "Yang", ""], ["Boker", "Steven M.", ""], ["Brown", "Donald E.", ""]]}, {"id": "1611.01190", "submitter": "Igor Carboni Oliveira", "authors": "Igor C. Oliveira, Rahul Santhanam", "title": "Conspiracies between Learning Algorithms, Circuit Lower Bounds and\n  Pseudorandomness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove several results giving new and stronger connections between\nlearning, circuit lower bounds and pseudorandomness. Among other results, we\nshow a generic learning speedup lemma, equivalences between various learning\nmodels in the exponential time and subexponential time regimes, a dichotomy\nbetween learning and pseudorandomness, consequences of non-trivial learning for\ncircuit lower bounds, Karp-Lipton theorems for probabilistic exponential time,\nand NC$^1$-hardness for the Minimum Circuit Size Problem.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 21:08:38 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Oliveira", "Igor C.", ""], ["Santhanam", "Rahul", ""]]}, {"id": "1611.01236", "submitter": "Alexey Kurakin", "authors": "Alexey Kurakin, Ian Goodfellow, Samy Bengio", "title": "Adversarial Machine Learning at Scale", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are malicious inputs designed to fool machine learning\nmodels. They often transfer from one model to another, allowing attackers to\nmount black box attacks without knowledge of the target model's parameters.\nAdversarial training is the process of explicitly training a model on\nadversarial examples, in order to make it more robust to attack or to reduce\nits test error on clean inputs. So far, adversarial training has primarily been\napplied to small problems. In this research, we apply adversarial training to\nImageNet. Our contributions include: (1) recommendations for how to succesfully\nscale adversarial training to large models and datasets, (2) the observation\nthat adversarial training confers robustness to single-step attack methods, (3)\nthe finding that multi-step attack methods are somewhat less transferable than\nsingle-step attack methods, so single-step attacks are the best for mounting\nblack-box attacks, and (4) resolution of a \"label leaking\" effect that causes\nadversarially trained models to perform better on adversarial examples than on\nclean examples, because the adversarial example construction process uses the\ntrue label and the model can learn to exploit regularities in the construction\nprocess.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 01:11:02 GMT"}, {"version": "v2", "created": "Sat, 11 Feb 2017 00:15:46 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Kurakin", "Alexey", ""], ["Goodfellow", "Ian", ""], ["Bengio", "Samy", ""]]}, {"id": "1611.01346", "submitter": "Riccardo Aragona", "authors": "Riccardo Aragona, Marco Calderini, Antonio Tortora, Maria Tota", "title": "On the primitivity of PRESENT and other lightweight ciphers", "comments": "to appear on Journal of Algebra and its Applications", "journal-ref": "Journal of Algebra and its Applications, Vol. 17, No. 6, 2018", "doi": "10.1142/S0219498818501153", "report-no": null, "categories": "math.GR cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide two sufficient conditions to guarantee that the round functions of\na translation based cipher generate a primitive group. Furthermore, under the\nsame hypotheses, and assuming that a round of the cipher is strongly proper and\nconsists of m-bit S-Boxes, with m = 3; 4 or 5, we prove that such a group is\nthe alternating group. As an immediate consequence, we deduce that the round\nfunctions of some lightweight translation based ciphers, such as the PRESENT\ncipher, generate the alternating group.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 12:09:11 GMT"}, {"version": "v2", "created": "Thu, 8 Jun 2017 21:59:32 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Aragona", "Riccardo", ""], ["Calderini", "Marco", ""], ["Tortora", "Antonio", ""], ["Tota", "Maria", ""]]}, {"id": "1611.01377", "submitter": "Ruggero Lanotte Dr", "authors": "Ruggero Lanotte and Massimo Merro and Riccardo Muradore and Luca\n  Vigan\\`o", "title": "A Formal Approach to Cyber-Physical Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply formal methods to lay and streamline theoretical foundations to\nreason about Cyber-Physical Systems (CPSs) and cyber-physical attacks. We focus\non %a formal treatment of both integrity and DoS attacks to sensors and\nactuators of CPSs, and on the timing aspects of these attacks. Our\ncontributions are threefold: (1) we define a hybrid process calculus to model\nboth CPSs and cyber-physical attacks; (2) we define a threat model of\ncyber-physical attacks and provide the means to assess attack\ntolerance/vulnerability with respect to a given attack; (3) we formalise how to\nestimate the impact of a successful attack on a CPS and investigate possible\nquantifications of the success chances of an attack. We illustrate definitions\nand results by means of a non-trivial engineering application.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 14:02:20 GMT"}, {"version": "v2", "created": "Fri, 21 Apr 2017 16:52:31 GMT"}], "update_date": "2017-04-24", "authors_parsed": [["Lanotte", "Ruggero", ""], ["Merro", "Massimo", ""], ["Muradore", "Riccardo", ""], ["Vigan\u00f2", "Luca", ""]]}, {"id": "1611.01477", "submitter": "Enis Ulqinaku", "authors": "Enis Ulqinaku, Luka Malisa, Julinda Stefa, Alessandro Mei and Srdjan\n  Capkun", "title": "Using Hover to Compromise the Confidentiality of User Input on Android", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the new hover (floating touch) technology, available in a number\nof today's smartphone models, can be abused by any Android application running\nwith a common SYSTEM_ALERT_WINDOW permission to record all touchscreen input\ninto other applications. Leveraging this attack, a malicious application\nrunning on the system is therefore able to profile user's behavior, capture\nsensitive input such as passwords and PINs as well as record all user's social\ninteractions. To evaluate our attack we implemented Hoover, a proof-of-concept\nmalicious application that runs in the system background and records all input\nto foreground applications. We evaluated Hoover with 40 users, across two\ndifferent Android devices and two input methods, stylus and finger. In the case\nof touchscreen input by finger, Hoover estimated the positions of users' clicks\nwithin an error of 100 pixels and keyboard input with an accuracy of 79%.\nHoover captured users' input by stylus even more accurately, estimating users'\nclicks within 2 pixels and keyboard input with an accuracy of 98%. We discuss\nways of mitigating this attack and show that this cannot be done by simply\nrestricting access to permissions or imposing additional cognitive load on the\nusers since this would significantly constrain the intended use of the hover\ntechnology.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 18:18:38 GMT"}, {"version": "v2", "created": "Wed, 2 Aug 2017 09:06:37 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Ulqinaku", "Enis", ""], ["Malisa", "Luka", ""], ["Stefa", "Julinda", ""], ["Mei", "Alessandro", ""], ["Capkun", "Srdjan", ""]]}, {"id": "1611.01571", "submitter": "Syed Kamran Haider", "authors": "Syed Kamran Haider and Marten van Dijk", "title": "Flat ORAM: A Simplified Write-Only Oblivious RAM Construction for Secure\n  Processors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Oblivious RAM (ORAM) is a cryptographic primitive which obfuscates the access\npatterns to a storage thereby preventing privacy leakage. So far in the current\nliterature, only `fully functional' ORAMs are widely studied which can protect,\nat a cost of considerable performance penalty, against the strong adversaries\nwho can monitor all read and write operations. However, recent research has\nshown that information can still be leaked even if only the write access\npattern (not reads) is visible to the adversary. For such weaker adversaries, a\nfully functional ORAM turns out to be an overkill causing unnecessary\noverheads. Instead, a simple `write-only' ORAM is sufficient, and, more\ninterestingly, is preferred as it can offer far more performance and energy\nefficiency than a fully functional ORAM.\n  In this work, we present Flat ORAM: an efficient write-only ORAM scheme which\noutperforms the closest existing write-only ORAM called HIVE. HIVE suffers from\nperformance bottlenecks while managing the memory occupancy information vital\nfor correctness of the protocol. Flat ORAM resolves these bottlenecks by\nintroducing a simple idea of Occupancy Map (OccMap) which efficiently manages\nthe memory occupancy information resulting in far better performance. Our\nsimulation results show that, on average, Flat ORAM only incurs a moderate\nslowdown of $3\\times$ over the insecure DRAM for memory intensive benchmarks\namong Splash2 and $1.6\\times$ for SPEC06. Compared to HIVE, Flat ORAM offers\n$50\\%$ performance gain on average and up to $80\\%$ energy savings.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 23:53:32 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2017 17:12:20 GMT"}, {"version": "v3", "created": "Mon, 12 Jun 2017 20:16:48 GMT"}, {"version": "v4", "created": "Sun, 10 Sep 2017 09:22:02 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Haider", "Syed Kamran", ""], ["van Dijk", "Marten", ""]]}, {"id": "1611.01683", "submitter": "Thibault de Valroger", "authors": "Thibault de Valroger", "title": "Simulations for Deep Random Secrecy Protocol", "comments": "18 pages. V2: simulations corresponding to an updated protocol has\n  been performed and complemented. Simulated effect of Privacy Amplification is\n  also added. V3: a simulation with a flawed error correcting method is\n  removed. V4: Updated reminder in the formalism of Deep Random assumption.\n  arXiv admin note: substantial text overlap with arXiv:1507.08258; text\n  overlap with arXiv:1605.04576", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present numerical simulations measuring secrecy and efficiency rate of\nPerfect Secrecy protocol presented in former article named Perfect Secrecy\nunder Deep Random assumption. Those simulations specifically measure the\nrespective error rates of both legitimate partner and eavesdropper experimented\nduring the exchange of a data flow through the protocol. Those measured error\nrates also enable us to estimate a lower bound of the Crytpologic Limit\nintroduced in article named Perfect Secrecy under Deep Random assumption. We\ndiscuss the variation of the protocol parameters and their impact on the\nmeasured performance.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 17:43:15 GMT"}, {"version": "v2", "created": "Tue, 23 May 2017 09:02:00 GMT"}, {"version": "v3", "created": "Sun, 10 Sep 2017 18:10:29 GMT"}, {"version": "v4", "created": "Sun, 30 Sep 2018 13:28:12 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["de Valroger", "Thibault", ""]]}, {"id": "1611.01726", "submitter": "Gyuwan Kim", "authors": "Gyuwan Kim, Hayoon Yi, Jangho Lee, Yunheung Paek, Sungroh Yoon", "title": "LSTM-Based System-Call Language Modeling and Robust Ensemble Method for\n  Designing Host-Based Intrusion Detection Systems", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computer security, designing a robust intrusion detection system is one of\nthe most fundamental and important problems. In this paper, we propose a\nsystem-call language-modeling approach for designing anomaly-based host\nintrusion detection systems. To remedy the issue of high false-alarm rates\ncommonly arising in conventional methods, we employ a novel ensemble method\nthat blends multiple thresholding classifiers into a single one, making it\npossible to accumulate 'highly normal' sequences. The proposed system-call\nlanguage model has various advantages leveraged by the fact that it can learn\nthe semantic meaning and interactions of each system call that existing methods\ncannot effectively consider. Through diverse experiments on public benchmark\ndatasets, we demonstrate the validity and effectiveness of the proposed method.\nMoreover, we show that our model possesses high portability, which is one of\nthe key aspects of realizing successful intrusion detection systems.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 04:07:29 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Kim", "Gyuwan", ""], ["Yi", "Hayoon", ""], ["Lee", "Jangho", ""], ["Paek", "Yunheung", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1611.01754", "submitter": "Nhien-An Le-Khac", "authors": "Pieter Van Vliet and M-T. Kechadi and Nhien-An Le-Khac", "title": "Forensics in Industrial Control System: A Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial Control Systems (ICS) are used worldwide in critical\ninfrastructures. An ICS system can be a single embedded system working\nstand-alone for controlling a simple process or ICS can also be a very complex\nDistributed Control System (DCS) connected to Supervisory Control And Data\nAcquisition (SCADA) system(s) in a nuclear power plant. Although ICS are widely\nused to-day, there are very little research on the forensic acquisition and\nanalyze ICS artefacts. In this paper we present a case study of forensics in\nICS where we de-scribe a method of safeguarding important volatile artefacts\nfrom an embedded industrial control system and several other sources\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 10:46:28 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Van Vliet", "Pieter", ""], ["Kechadi", "M-T.", ""], ["Le-Khac", "Nhien-An", ""]]}, {"id": "1611.01907", "submitter": "F. Ozgur Catak", "authors": "Ferhat Ozgur Catak", "title": "Privacy Preserving PageRank Algorithm By Using Secure Multi-Party\n  Computation", "comments": "8 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the problem of privacy preserving computation on\nPageRank algorithm. The idea is to enforce the secure multi party computation\nof the algorithm iteratively using homomorphic encryption based on Paillier\nscheme. In the proposed PageRank computation, a user encrypt its own graph data\nusing asymmetric encryption method, sends the data set into different parties\nin a privacy-preserving manner. Each party computes its own encrypted entity,\nbut learns nothing about the data at other parties.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 06:38:14 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Catak", "Ferhat Ozgur", ""]]}, {"id": "1611.01960", "submitter": "Sven M\\\"uelich", "authors": "Sven M\\\"uelich, Martin Bossert", "title": "A New Error Correction Scheme for Physical Unclonable Functions", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Error correction is an indispensable component when Physical Unclonable\nFunctions (PUFs) are used in cryptographic applications. So far, there exist\nschemes that obtain helper data, which they need within the error correction\nprocess. We introduce a new scheme, which only uses an error correcting code\nwithout any further helper data. The main idea is to construct for each PUF\ninstance an individual code which contains the initial PUF response as\ncodeword. In this work we use LDPC codes, however other code classes are also\npossible. Our scheme allows a trade-off between code rate and cryptographic\nsecurity. In addition, decoding with linear complexity is possible.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 09:59:44 GMT"}, {"version": "v2", "created": "Tue, 8 Nov 2016 08:49:05 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["M\u00fcelich", "Sven", ""], ["Bossert", "Martin", ""]]}, {"id": "1611.02015", "submitter": "Andrew Conway", "authors": "Andrew Conway, Michelle Blom, Lee Naish, Vanessa Teague", "title": "An analysis of New South Wales electronic vote counting", "comments": null, "journal-ref": null, "doi": "10.1145/3014812.3014837", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We re-examine the 2012 local government elections in New South Wales,\nAustralia. The count was conducted electronically using a randomised form of\nthe Single Transferable Vote (STV). It was already well known that randomness\ndoes make a difference to outcomes in some seats. We describe how the process\ncould be amended to include a demonstration that the randomness was chosen\nfairly.\n  Second, and more significantly, we found an error in the official counting\nsoftware, which caused a mistake in the count in the council of Griffith, where\ncandidate Rina Mercuri narrowly missed out on a seat. We believe the software\nerror incorrectly decreased Mercuri's winning probability to about\n10%---according to our count she should have won with 91% probability.\n  The NSW Electoral Commission (NSWEC) corrected their code when we pointed out\nthe error, and made their own announcement.\n  We have since investigated the 2016 local government election (held after\ncorrecting the error above) and found two new errors. We notified the NSWEC\nabout these errors a few days after they posted the results.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 12:20:04 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Conway", "Andrew", ""], ["Blom", "Michelle", ""], ["Naish", "Lee", ""], ["Teague", "Vanessa", ""]]}, {"id": "1611.02257", "submitter": "Hua Sun", "authors": "Hua Sun and Syed A. Jafar", "title": "Multiround Private Information Retrieval: Capacity and Storage Overhead", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.IR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capacity has recently been characterized for the private information\nretrieval (PIR) problem as well as several of its variants. In every case it is\nassumed that all the queries are generated by the user simultaneously. Here we\nconsider multiround PIR, where the queries in each round are allowed to depend\non the answers received in previous rounds. We show that the capacity of\nmultiround PIR is the same as the capacity of single-round PIR (the result is\ngeneralized to also include $T$-privacy constraints). Combined with previous\nresults, this shows that there is no capacity advantage from multiround over\nsingle-round schemes, non-linear over linear schemes or from $\\epsilon$-error\nover zero-error schemes. However, we show through an example that there is an\nadvantage in terms of storage overhead. We provide an example of a multiround,\nnon-linear, $\\epsilon$-error PIR scheme that requires a strictly smaller\nstorage overhead than the best possible with single-round, linear, zero-error\nPIR schemes.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 20:36:40 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Sun", "Hua", ""], ["Jafar", "Syed A.", ""]]}, {"id": "1611.02315", "submitter": "Jacob Steinhardt", "authors": "Moses Charikar and Jacob Steinhardt and Gregory Valiant", "title": "Learning from Untrusted Data", "comments": "Updated based on STOC camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC cs.CR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vast majority of theoretical results in machine learning and statistics\nassume that the available training data is a reasonably reliable reflection of\nthe phenomena to be learned or estimated. Similarly, the majority of machine\nlearning and statistical techniques used in practice are brittle to the\npresence of large amounts of biased or malicious data. In this work we consider\ntwo frameworks in which to study estimation, learning, and optimization in the\npresence of significant fractions of arbitrary data.\n  The first framework, list-decodable learning, asks whether it is possible to\nreturn a list of answers, with the guarantee that at least one of them is\naccurate. For example, given a dataset of $n$ points for which an unknown\nsubset of $\\alpha n$ points are drawn from a distribution of interest, and no\nassumptions are made about the remaining $(1-\\alpha)n$ points, is it possible\nto return a list of $\\operatorname{poly}(1/\\alpha)$ answers, one of which is\ncorrect? The second framework, which we term the semi-verified learning model,\nconsiders the extent to which a small dataset of trusted data (drawn from the\ndistribution in question) can be leveraged to enable the accurate extraction of\ninformation from a much larger but untrusted dataset (of which only an\n$\\alpha$-fraction is drawn from the distribution).\n  We show strong positive results in both settings, and provide an algorithm\nfor robust learning in a very general stochastic optimization setting. This\ngeneral result has immediate implications for robust estimation in a number of\nsettings, including for robustly estimating the mean of distributions with\nbounded second moments, robustly learning mixtures of such distributions, and\nrobustly finding planted partitions in random graphs in which significant\nportions of the graph have been perturbed by an adversary.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 21:43:39 GMT"}, {"version": "v2", "created": "Sun, 11 Jun 2017 17:48:31 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Charikar", "Moses", ""], ["Steinhardt", "Jacob", ""], ["Valiant", "Gregory", ""]]}, {"id": "1611.02675", "submitter": "Rashad Eletreby", "authors": "Rashad Eletreby and Osman Ya\\u{g}an", "title": "$k$-connectivity of inhomogeneous random key graphs with unreliable\n  links", "comments": "Submitted to IEEE Transactions on Mobile Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider secure and reliable connectivity in wireless sensor networks that\nutilize a heterogeneous random key predistribution scheme. We model the\nunreliability of wireless links by an on-off channel model that induces an\nErd\\H{o}s-R\\'enyi graph, while the heterogeneous scheme induces an\ninhomogeneous random key graph. The overall network can thus be modeled by the\nintersection of both graphs. We present conditions (in the form of zero-one\nlaws) on how to scale the parameters of the intersection model so that with\nhigh probability i) all of its nodes are connected to at least $k$ other nodes;\ni.e., the minimum node degree of the graph is no less than $k$ and ii) the\ngraph is $k$-connected, i.e., the graph remains connected even if any $k-1$\nnodes leave the network. We also present numerical results to support these\nconditions in the finite-node regime. Our results are shown to complement and\ngeneralize several previous work in the literature.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 20:27:19 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["Eletreby", "Rashad", ""], ["Ya\u011fan", "Osman", ""]]}, {"id": "1611.02733", "submitter": "Rashad Eletreby", "authors": "Rashad Eletreby and Osman Ya\\u{g}an", "title": "Minimum node degree in inhomogeneous random key graphs with unreliable\n  links", "comments": "In proceedings of the IEEE International Symposium on Information\n  Theory (ISIT) 2016. arXiv admin note: substantial text overlap with\n  arXiv:1610.07576, arXiv:1611.02675", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider wireless sensor networks under a heterogeneous random key\npredistribution scheme and an on-off channel model. The heterogeneous key\npredistribution scheme has recently been introduced by Ya\\u{g}an - as an\nextension to the Eschenauer and Gligor scheme - for the cases when the network\nconsists of sensor nodes with varying level of resources and/or connectivity\nrequirements, e.g., regular nodes vs. cluster heads. The network is modeled by\nthe intersection of the inhomogeneous random key graph (induced by the\nheterogeneous scheme) with an Erd\\H{o}s-R\\'enyi graph (induced by the on/off\nchannel model). We present conditions (in the form of zero-one laws) on how to\nscale the parameters of the intersection model so that with high probability\nall of its nodes are connected to at least $k$ other nodes; i.e., the minimum\nnode degree of the graph is no less than $k$. We also present numerical results\nto support our results in the finite-node regime. The numerical results suggest\nthat the conditions that ensure $k$-connectivity coincide with those ensuring\nthe minimum node degree being no less than $k$.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 20:18:20 GMT"}], "update_date": "2017-01-05", "authors_parsed": [["Eletreby", "Rashad", ""], ["Ya\u011fan", "Osman", ""]]}, {"id": "1611.02787", "submitter": "Bum Jun Kwon", "authors": "Bum Jun Kwon, Virinchi Srinivas, Amol Deshpande, Tudor Dumitra\\c{s}", "title": "Catching Worms, Trojan Horses and PUPs: Unsupervised Detection of Silent\n  Delivery Campaigns", "comments": null, "journal-ref": null, "doi": "10.14722/ndss.2017.23220", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing commoditization of the underground economy has given rise to\nmalware delivery networks, which charge fees for quickly delivering malware or\nunwanted software to a large number of hosts. To provide this service, a key\nmethod is the orchestration of silent delivery campaigns, which involve a group\nof downloaders that receive remote commands and that deliver their payloads\nwithout any user interaction. These campaigns have not been characterized\nsystematically, unlike other aspects of malware delivery networks. Moreover,\nsilent delivery campaigns can evade detection by relying on inconspicuous\ndownloaders on the client side and on disposable domain names on the server\nside. We describe Beewolf, a system for detecting silent delivery campaigns\nfrom Internet-wide records of download events. The key observation behind our\nsystem is that the downloaders involved in these campaigns frequently retrieve\npayloads in lockstep. Beewolf identifies such locksteps in an unsupervised and\ndeterministic manner. By exploiting novel techniques and empirical\nobservations, Beewolf can operate on streaming data. We utilize Beewolf to\nstudy silent delivery campaigns at scale, on a data set of 33.3 million\ndownload events. This investigation yields novel findings, e.g. malware\ndistributed through compromised software update channels, a substantial overlap\nbetween the delivery ecosystems for malware and unwanted software, and several\ntypes of business relationships within these ecosystems. Beewolf achieves over\n92% true positives and fewer than 5% false positives. Moreover, Beewolf can\ndetect suspicious downloaders a median of 165 days ahead of existing anti-virus\nproducts and payload-hosting domains a median of 196 days ahead of existing\nblacklists.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 01:11:45 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Kwon", "Bum Jun", ""], ["Srinivas", "Virinchi", ""], ["Deshpande", "Amol", ""], ["Dumitra\u015f", "Tudor", ""]]}, {"id": "1611.02821", "submitter": "Kwangsu Lee", "authors": "Kwangsu Lee", "title": "Transforming Hidden Vector Encryption Schemes from Composite to Prime\n  Order Groups", "comments": "21 pages, ICISC 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicate encryption is a new type of public key encryption that enables\nsearches on encrypted data. By using predicate encryption, we can search\nkeywords or attributes on encrypted data without decrypting ciphertexts. Hidden\nvector encryption (HVE) is a special kind of predicate encryption. HVE supports\nthe evaluation of conjunctive equality, comparison, and subset operations\nbetween attributes in ciphertexts and attributes in tokens. In this paper, we\nconstruct efficient HVE schemes in prime order bilinear groups derived from\nprevious HVE schemes in composite order bilinear groups, and prove their\nselective security under simple assumptions. To achieve this result, we present\na conversion method that transforms HVE schemes from composite order bilinear\ngroups into prime order bilinear groups. Our method supports any types of prime\norder bilinear groups and uses simple assumptions.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 05:28:40 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Lee", "Kwangsu", ""]]}, {"id": "1611.02875", "submitter": "Doli\\`ere Francis Som\\'e", "authors": "Doli\\`ere Francis Som\\'e, Nataliia Bielova, Tamara Rezk", "title": "On the Content Security Policy Violations due to the Same-Origin Policy", "comments": "8 pages + references for the short version, extended to 19 pages for\n  detailed appendices", "journal-ref": null, "doi": "10.1145/3038912.3052634", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern browsers implement different security policies such as the Content\nSecurity Policy (CSP), a mechanism designed to mitigate popular web\nvulnerabilities, and the Same Origin Policy (SOP), a mechanism that governs\ninteractions between resources of web pages. In this work, we describe how CSP\nmay be violated due to the SOP when a page contains an embedded iframe from the\nsame origin. We analyse 1 million pages from 10,000 top Alexa sites and report\nthat at least 31.1% of current CSP-enabled pages are potentially vulnerable to\nCSP violations. Further considering real-world situations where those pages are\ninvolved in same-origin nested browsing contexts, we found that in at least\n23.5% of the cases, CSP violations are possible. During our study, we also\nidentified a divergence among browsers implementations in the enforcement of\nCSP in srcdoc sandboxed iframes, which actually reveals a problem in\nGecko-based browsers CSP implementation. To ameliorate the problematic\nconflicts of the security mechanisms, we discuss measures to avoid CSP\nviolations.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 10:12:13 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 13:41:25 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Som\u00e9", "Doli\u00e8re Francis", ""], ["Bielova", "Nataliia", ""], ["Rezk", "Tamara", ""]]}, {"id": "1611.02968", "submitter": "Lu\\'is T. A. N. Brand\\~ao", "authors": "Lu\\'is T. A. N. Brand\\~ao, Nicolas Christin, George Danezis", "title": "A Public Comment on NCCoE's White Paper on Privacy-Enhancing Identity\n  Brokers", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The National Cybersecurity Center of Excellence (NCCoE) (in the United\nStates) has published on October 19, 2015, a white paper on \"privacy-enhanced\nidentity brokers.\" We present here a reply to their request for public\ncomments. We enumerate concerns whose consideration we find paramount for the\ndesign of a privacy-enhancing identity brokering solution, for identification\nand authentication of citizens into myriad online services, and we recommend\nhow to incorporate them into a revised white paper. Our observations, focused\non privacy, security, auditability and forensics, are mostly based on a\nrecently published research paper (PETS 2015) about two nation-scale brokered\nidentification systems.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 15:10:09 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Brand\u00e3o", "Lu\u00eds T. A. N.", ""], ["Christin", "Nicolas", ""], ["Danezis", "George", ""]]}, {"id": "1611.03006", "submitter": "Emiliano De Cristofaro", "authors": "Emiliano De Cristofaro and Kaitai Liang and Yuruo Zhang", "title": "Privacy-Preserving Genetic Relatedness Test", "comments": "A preliminary version of this paper appears in the Proceedings of the\n  3rd International Workshop on Genome Privacy and Security (GenoPri'16)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of individuals are turning to Direct-To-Consumer (DTC)\ngenetic testing to learn about their predisposition to diseases, traits, and/or\nancestry. DTC companies like 23andme and Ancestry.com have started to offer\npopular and affordable ancestry and genealogy tests, with services allowing\nusers to find unknown relatives and long-distant cousins. Naturally, access and\npossible dissemination of genetic data prompts serious privacy concerns, thus\nmotivating the need to design efficient primitives supporting private genetic\ntests. In this paper, we present an effective protocol for privacy-preserving\ngenetic relatedness test (PPGRT), enabling a cloud server to run relatedness\ntests on input an encrypted genetic database and a test facility's encrypted\ngenetic sample. We reduce the test to a data matching problem and perform it,\nprivately, using searchable encryption. Finally, a performance evaluation of\nhamming distance based PP-GRT attests to the practicality of our proposals.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 16:37:28 GMT"}, {"version": "v2", "created": "Thu, 10 Nov 2016 02:09:48 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["De Cristofaro", "Emiliano", ""], ["Liang", "Kaitai", ""], ["Zhang", "Yuruo", ""]]}, {"id": "1611.03019", "submitter": "Pascal Mainini", "authors": "Pascal Mainini and Annett Laube-Rosenpflanzer", "title": "Access Control in Linked Data Using WebID", "comments": "Full version of arXiv:1610.04405", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linked Data technologies become increasingly important in many domains. Key\nfactors for their breakthrough are security and trust, especially when sensible\nor personal data are involved. Classical means for access control lack\ngranularity when parts of the Linked Data graph must be protected. The WebID,\ncombining semantic web concepts with methods from certificate based\nauthentication and authorization, seems promising to fulfill all requirements\nconcerning security and trust in the semantic web. In the context of the\nPerSemID project, we challenged the WebID technology in a practical scenario\ncoming from the domain of lifelong learning and student mobility. In our use\ncase of study enrollment, we use WebIDs for authentication and to grant access\nto parts of the triple stores of the different stakeholders. Cross domain\ntriple store interactions are used to exchange data between the involved\nparties. Our fully implemented PoC exemplifies an application built on Linked\nData and WebID and allows us to judge the usability and security of WebID\ntechnology in a real world scenario.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 17:21:35 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Mainini", "Pascal", ""], ["Laube-Rosenpflanzer", "Annett", ""]]}, {"id": "1611.03021", "submitter": "Yu-Xiang Wang", "authors": "Ziqi Liu, Alexander J. Smola, Kyle Soska, Yu-Xiang Wang, Qinghua\n  Zheng, Jun Zhou", "title": "Attributing Hacks", "comments": "Appeared at AISTATS'17. Full version under review at the Electronic\n  Journal of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe an algorithm for estimating the provenance of hacks\non websites. That is, given properties of sites and the temporal occurrence of\nattacks, we are able to attribute individual attacks to joint causes and\nvulnerabilities, as well as estimating the evolution of these vulnerabilities\nover time. Specifically, we use hazard regression with a time-varying additive\nhazard function parameterized in a generalized linear form. The activation\ncoefficients on each feature are continuous-time functions over time. We\nformulate the problem of learning these functions as a constrained variational\nmaximum likelihood estimation problem with total variation penalty and show\nthat the optimal solution is a 0th order spline (a piecewise constant function)\nwith a finite number of known knots. This allows the inference problem to be\nsolved efficiently and at scale by solving a finite dimensional optimization\nproblem. Extensive experiments on real data sets show that our method\nsignificantly outperforms Cox's proportional hazard model. We also conduct a\ncase study and verify that the fitted functions are indeed recovering\nvulnerable features and real-life events such as the release of code to exploit\nthese features in hacker blogs.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 15:26:58 GMT"}, {"version": "v2", "created": "Mon, 14 Aug 2017 18:25:34 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Liu", "Ziqi", ""], ["Smola", "Alexander J.", ""], ["Soska", "Kyle", ""], ["Wang", "Yu-Xiang", ""], ["Zheng", "Qinghua", ""], ["Zhou", "Jun", ""]]}, {"id": "1611.03053", "submitter": "Amr Abed", "authors": "Amr S. Abed, T. Charles Clancy, David S. Levy", "title": "Applying Bag of System Calls for Anomalous Behavior Detection of\n  Applications in Linux Containers", "comments": "Published version available on IEEE Xplore\n  (http://ieeexplore.ieee.org/document/7414047/) arXiv admin note: substantial\n  text overlap with arXiv:1611.03056", "journal-ref": "2015 IEEE Globecom Workshops (GC Wkshps), San Diego, CA, 2015, pp.\n  1-5", "doi": "10.1109/GLOCOMW.2015.7414047", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the results of using bags of system calls for\nlearning the behavior of Linux containers for use in anomaly-detection based\nintrusion detection system. By using system calls of the containers monitored\nfrom the host kernel for anomaly detection, the system does not require any\nprior knowledge of the container nature, neither does it require altering the\ncontainer or the host kernel.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 19:28:40 GMT"}], "update_date": "2017-01-05", "authors_parsed": [["Abed", "Amr S.", ""], ["Clancy", "T. Charles", ""], ["Levy", "David S.", ""]]}, {"id": "1611.03056", "submitter": "Amr Abed", "authors": "Amr S. Abed, Charles Clancy, David S. Levy", "title": "Intrusion Detection System for Applications using Linux Containers", "comments": "The final publication is available at\n  http://link.springer.com/chapter/10.1007%2F978-3-319-24858-5_8. arXiv admin\n  note: substantial text overlap with arXiv:1611.03053", "journal-ref": "STM 2015. LNCS, vol. 9331, pp. 123-135. Springer, Heidelberg\n  (2015)", "doi": "10.1007/978-3-319-24858-5_8", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linux containers are gaining increasing traction in both individual and\nindustrial use, and as these containers get integrated into mission-critical\nsystems, real-time detection of malicious cyber attacks becomes a critical\noperational requirement. This paper introduces a real-time host-based intrusion\ndetection system that can be used to passively detect malfeasance against\napplications within Linux containers running in a standalone or in a cloud\nmulti-tenancy environment. The demonstrated intrusion detection system uses\nbags of system calls monitored from the host kernel for learning the behavior\nof an application running within a Linux container and determining anomalous\ncontainer behavior. Performance of the approach using a database application\nwas measured and results are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 19:37:55 GMT"}], "update_date": "2017-01-05", "authors_parsed": [["Abed", "Amr S.", ""], ["Clancy", "Charles", ""], ["Levy", "David S.", ""]]}, {"id": "1611.03065", "submitter": "Amr Abed", "authors": "Mohamed Azab, Bassem Mokhtar, Amr S. Abed, Mohamed Eltoweissy", "title": "Toward Smart Moving Target Defense for Linux Container Resiliency", "comments": "Published version is available on IEEE Xplore at\n  http://ieeexplore.ieee.org/document/7796855", "journal-ref": "IEEE 41st Conference on Local Computer Networks (2016) 619-622", "doi": "10.1109/LCN.2016.106", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents ESCAPE, an informed moving target defense mechanism for\ncloud containers. ESCAPE models the interaction between attackers and their\ntarget containers as a \"predator searching for a prey\" search game. Live\nmigration of Linux-containers (prey) is used to avoid attacks (predator) and\nfailures. The entire process is guided by a novel host-based\nbehavior-monitoring system that seamlessly monitors containers for indications\nof intrusions and attacks. To evaluate ESCAPE effectiveness, we simulated the\nattack avoidance process based on a mathematical model mimicking the\nprey-vs-predator search game. Simulation results show high container survival\nprobabilities with minimal added overhead.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 20:06:44 GMT"}, {"version": "v2", "created": "Fri, 30 Dec 2016 22:18:03 GMT"}], "update_date": "2017-01-03", "authors_parsed": [["Azab", "Mohamed", ""], ["Mokhtar", "Bassem", ""], ["Abed", "Amr S.", ""], ["Eltoweissy", "Mohamed", ""]]}, {"id": "1611.03186", "submitter": "Parvez Ahammad", "authors": "Heju Jiang, Jasvir Nagra, Parvez Ahammad", "title": "SoK: Applying Machine Learning in Security - A Survey", "comments": "18 pages, 2 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of applying machine learning(ML) to solve problems in security\ndomains is almost 3 decades old. As information and communications grow more\nubiquitous and more data become available, many security risks arise as well as\nappetite to manage and mitigate such risks. Consequently, research on applying\nand designing ML algorithms and systems for security has grown fast, ranging\nfrom intrusion detection systems(IDS) and malware classification to security\npolicy management(SPM) and information leak checking. In this paper, we\nsystematically study the methods, algorithms, and system designs in academic\npublications from 2008-2015 that applied ML in security domains. 98 percent of\nthe surveyed papers appeared in the 6 highest-ranked academic security\nconferences and 1 conference known for pioneering ML applications in security.\nWe examine the generalized system designs, underlying assumptions,\nmeasurements, and use cases in active research. Our examinations lead to 1) a\ntaxonomy on ML paradigms and security domains for future exploration and\nexploitation, and 2) an agenda detailing open and upcoming challenges. Based on\nour survey, we also suggest a point of view that treats security as a game\ntheory problem instead of a batch-trained ML problem.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 05:08:02 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Jiang", "Heju", ""], ["Nagra", "Jasvir", ""], ["Ahammad", "Parvez", ""]]}, {"id": "1611.03252", "submitter": "Abdeljalil Agnaou", "authors": "Abdeljalil Agnaou, Anas Abou El Kalam, Abdellah Ait Ouahman, Mina De\n  Montfort", "title": "Reduce positive and negative falses from attacks collected from the\n  deployment of distributed honeypot network", "comments": null, "journal-ref": "International Journal of Computer Science and Information Security\n  Volume 14 No. 9, September 2016", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Current tools and systems of detecting vulnerabilities simply alert the\nadministrator of attempted attacks against his network or system. However,\ngenerally, the huge number of alerts to analyze and the amount time required to\nupdate security rules after analyzing alerts provides time and opportunity for\nthe attacker to inflict damages. Moreover, most of these tools generate\npositive and negative falses, which may be important to the attacked network.\nOtherwise, many solutions exist such as IPS, but it shows a great defect due,\nfundamentally, to false positives. Indeed, attackers often make IPS block a\nlegitimate traffic when they detect its presence in the attacked network. In\nthis paper we describe an automated algorithm that gives the ability to detect\nattacks before they occurrence, then reduce positive and negative falses rates.\nMoreover, we use a set of data related to malicious traffic captured using a\nnetwork of honeypots to recognize potential threats sources.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 10:52:15 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Agnaou", "Abdeljalil", ""], ["Kalam", "Anas Abou El", ""], ["Ouahman", "Abdellah Ait", ""], ["De Montfort", "Mina", ""]]}, {"id": "1611.03343", "submitter": "Suleiman Yerima", "authors": "Feng Yao, Suleiman Y. Yerima, BooJoong Kang, Sakir Sezer", "title": "Fuzzy Logic-based Implicit Authentication for Mobile Access Control", "comments": "8 pages, SAI Computing Conference (SAI),13-15 July 2016, London, UK.\n  arXiv admin note: text overlap with arXiv:1607.08101", "journal-ref": null, "doi": "10.1109/SAI.2016.7556097", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to address the increasing compromise of user privacy on mobile\ndevices, a Fuzzy Logic based implicit authentication scheme is proposed in this\npaper. The proposed scheme computes an aggregate score based on selected\nfeatures and a threshold in real-time based on current and historic data\ndepicting user routine. The tuned fuzzy system is then applied to the\naggregated score and the threshold to determine the trust level of the current\nuser. The proposed fuzzy-integrated implicit authentication scheme is designed\nto: operate adaptively and completely in the background, require minimal\ntraining period, enable high system accuracy while provide timely detection of\nabnormal activity. In this paper, we explore Fuzzy Logic based authentication\nin depth. Gaussian and triangle-based membership functions are investigated and\ncompared using real data over several weeks from different Android phone users.\nThe presented results show that our proposed Fuzzy Logic approach is a highly\neffective, and viable scheme for lightweight real-time implicit authentication\non mobile devices.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 10:15:32 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Yao", "Feng", ""], ["Yerima", "Suleiman Y.", ""], ["Kang", "BooJoong", ""], ["Sezer", "Sakir", ""]]}, {"id": "1611.03424", "submitter": "Marino Miculan", "authors": "Alessio Mansutti and Marino Miculan", "title": "Deciding Hedged Bisimilarity", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spi-calculus is a formal model for the design and analysis of\ncryptographic protocols: many security properties, such as authentication and\nstrong confidentiality, can be reduced to the verification of behavioural\nequivalences between spi processes. In this paper we provide an algorithm for\ndeciding hedged bisimilarity on finite processes, which is equivalent to barbed\nequivalence (and coarser than framed bisimilarity). This algorithm works with\nany term equivalence satisfying a simple set of conditions, thus encompassing\nmany different encryption schemata.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 17:50:09 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Mansutti", "Alessio", ""], ["Miculan", "Marino", ""]]}, {"id": "1611.03748", "submitter": "Raphael Spreitzer", "authors": "Raphael Spreitzer, Veelasha Moonsamy, Thomas Korak, Stefan Mangard", "title": "Systematic Classification of Side-Channel Attacks: A Case Study for\n  Mobile Devices", "comments": null, "journal-ref": null, "doi": "10.1109/COMST.2017.2779824", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Side-channel attacks on mobile devices have gained increasing attention since\ntheir introduction in 2007. While traditional side-channel attacks, such as\npower analysis attacks and electromagnetic analysis attacks, required physical\npresence of the attacker as well as expensive equipment, an (unprivileged)\napplication is all it takes to exploit the leaking information on modern mobile\ndevices. Given the vast amount of sensitive information that are stored on\nsmartphones, the ramifications of side-channel attacks affect both the security\nand privacy of users and their devices.\n  In this paper, we propose a new categorization system for side-channel\nattacks, which is necessary as side-channel attacks have evolved significantly\nsince their scientific investigations during the smart card era in the 1990s.\nOur proposed classification system allows to analyze side-channel attacks\nsystematically, and facilitates the development of novel countermeasures.\nBesides this new categorization system, the extensive survey of existing\nattacks and attack strategies provides valuable insights into the evolving\nfield of side-channel attacks, especially when focusing on mobile devices. We\nconclude by discussing open issues and challenges in this context and outline\npossible future research directions.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 15:36:19 GMT"}, {"version": "v2", "created": "Fri, 3 Feb 2017 12:40:09 GMT"}, {"version": "v3", "created": "Wed, 6 Dec 2017 19:15:40 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Spreitzer", "Raphael", ""], ["Moonsamy", "Veelasha", ""], ["Korak", "Thomas", ""], ["Mangard", "Stefan", ""]]}, {"id": "1611.03811", "submitter": "Margarita Osadchy", "authors": "Mor Ohana, Orr Dunkelman, Stuart Gibson, Margarita Osadchy", "title": "HoneyFaces: Increasing the Security and Privacy of Authentication Using\n  Synthetic Facial Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main challenges faced by Biometric-based authentication systems is\nthe need to offer secure authentication while maintaining the privacy of the\nbiometric data. Previous solutions, such as Secure Sketch and Fuzzy Extractors,\nrely on assumptions that cannot be guaranteed in practice, and often affect the\nauthentication accuracy.\n  In this paper, we introduce HoneyFaces: the concept of adding a large set of\nsynthetic faces (indistinguishable from real) into the biometric \"password\nfile\". This password inflation protects the privacy of users and increases the\nsecurity of the system without affecting the accuracy of the authentication. In\nparticular, privacy for the real users is provided by \"hiding\" them among a\nlarge number of fake users (as the distributions of synthetic and real faces\nare equal). In addition to maintaining the authentication accuracy, and thus\nnot affecting the security of the authentication process, HoneyFaces offer\nseveral security improvements: increased exfiltration hardness, improved\nleakage detection, and the ability to use a Two-server setting like in\nHoneyWords. Finally, HoneyFaces can be combined with other security and privacy\nmechanisms for biometric data.\n  We implemented the HoneyFaces system and tested it with a password file\ncomposed of 270 real users. The \"password file\" was then inflated to\naccommodate up to $2^{36.5}$ users (resulting in a 56.6 TB \"password file\"). At\nthe same time, the inclusion of additional faces does not affect the true\nacceptance rate or false acceptance rate which were 93.33\\% and 0.01\\%,\nrespectively.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 18:40:32 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Ohana", "Mor", ""], ["Dunkelman", "Orr", ""], ["Gibson", "Stuart", ""], ["Osadchy", "Margarita", ""]]}, {"id": "1611.03814", "submitter": "Nicolas Papernot", "authors": "Nicolas Papernot, Patrick McDaniel, Arunesh Sinha, Michael Wellman", "title": "Towards the Science of Security and Privacy in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in machine learning (ML) in recent years have enabled a dizzying\narray of applications such as data analytics, autonomous systems, and security\ndiagnostics. ML is now pervasive---new systems and models are being deployed in\nevery domain imaginable, leading to rapid and widespread deployment of software\nbased inference and decision making. There is growing recognition that ML\nexposes new vulnerabilities in software systems, yet the technical community's\nunderstanding of the nature and extent of these vulnerabilities remains\nlimited. We systematize recent findings on ML security and privacy, focusing on\nattacks identified on these systems and defenses crafted to date. We articulate\na comprehensive threat model for ML, and categorize attacks and defenses within\nan adversarial framework. Key insights resulting from works both in the ML and\nsecurity communities are identified and the effectiveness of approaches are\nrelated to structural elements of ML algorithms and the data used to train\nthem. We conclude by formally exploring the opposing relationship between model\naccuracy and resilience to adversarial manipulation. Through these\nexplorations, we show that there are (possibly unavoidable) tensions between\nmodel complexity, accuracy, and resilience that must be calibrated for the\nenvironments in which they will be used.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 18:57:15 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Papernot", "Nicolas", ""], ["McDaniel", "Patrick", ""], ["Sinha", "Arunesh", ""], ["Wellman", "Michael", ""]]}, {"id": "1611.03941", "submitter": "Thai Pham", "authors": "Thai Pham and Steven Lee", "title": "Anomaly Detection in Bitcoin Network Using Unsupervised Learning Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of anomaly detection has been studied for a long time. In short,\nanomalies are abnormal or unlikely things. In financial networks, thieves and\nillegal activities are often anomalous in nature. Members of a network want to\ndetect anomalies as soon as possible to prevent them from harming the network's\ncommunity and integrity. Many Machine Learning techniques have been proposed to\ndeal with this problem; some results appear to be quite promising but there is\nno obvious superior method. In this paper, we consider anomaly detection\nparticular to the Bitcoin transaction network. Our goal is to detect which\nusers and transactions are the most suspicious; in this case, anomalous\nbehavior is a proxy for suspicious behavior. To this end, we use three\nunsupervised learning methods including k-means clustering, Mahalanobis\ndistance, and Unsupervised Support Vector Machine (SVM) on two graphs generated\nby the Bitcoin transaction network: one graph has users as nodes, and the other\nhas transactions as nodes.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2016 02:39:41 GMT"}, {"version": "v2", "created": "Sat, 25 Feb 2017 00:56:26 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Pham", "Thai", ""], ["Lee", "Steven", ""]]}, {"id": "1611.03942", "submitter": "Thai Pham", "authors": "Thai Pham and Steven Lee", "title": "Anomaly Detection in the Bitcoin System - A Network Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of anomaly detection has been studied for a long time, and many\nNetwork Analysis techniques have been proposed as solutions. Although some\nresults appear to be quite promising, no method is clearly to be superior to\nthe rest. In this paper, we particularly consider anomaly detection in the\nBitcoin transaction network. Our goal is to detect which users and transactions\nare the most suspicious; in this case, anomalous behavior is a proxy for\nsuspicious behavior. To this end, we use the laws of power degree and\ndensification and local outlier factor (LOF) method (which is proceeded by\nk-means clustering method) on two graphs generated by the Bitcoin transaction\nnetwork: one graph has users as nodes, and the other has transactions as nodes.\n  We remark that the methods used here can be applied to any type of setting\nwith an inherent graph structure, including, but not limited to, computer\nnetworks, telecommunications networks, auction networks, security networks,\nsocial networks, Web networks, or any financial networks. We use the Bitcoin\ntransaction network in this paper due to the availability, size, and\nattractiveness of the data set.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2016 02:50:50 GMT"}, {"version": "v2", "created": "Fri, 24 Feb 2017 23:53:15 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Pham", "Thai", ""], ["Lee", "Steven", ""]]}, {"id": "1611.03982", "submitter": "Binanda Sengupta", "authors": "Binanda Sengupta and Sushmita Ruj", "title": "Efficient Proofs of Retrievability with Public Verifiability for Dynamic\n  Cloud Storage", "comments": "A version of the paper with the same title has been published in IEEE\n  Transactions on Cloud Computing (DOI: 10.1109/TCC.2017.2767584)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud service providers offer various facilities to their clients. The\nclients with limited resources opt for some of these facilities. They can\noutsource their bulk data to the cloud server. The cloud server maintains these\ndata in lieu of monetary benefits. However, a malicious cloud server might\ndelete some of these data to save some space and offer this extra amount of\nstorage to another client. Therefore, the client might not retrieve her file\n(or some portions of it) as often as needed. Proofs of retrievability (POR)\nprovide an assurance to the client that the server is actually storing all of\nher data appropriately and they can be retrieved at any point of time. In a\ndynamic POR scheme, the client can update her data after she uploads them to\nthe cloud server. Moreover, in publicly verifiable POR schemes, the client can\ndelegate her auditing task to some third party specialized for this purpose. In\nthis work, we exploit the homomorphic hashing technique to design a publicly\nverifiable dynamic POR scheme that is more efficient (in terms of bandwidth\nrequired between the client and the server) than the \"state-of-the-art\"\npublicly verifiable dynamic POR scheme. We also analyze security and\nperformance of our scheme.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2016 10:46:44 GMT"}, {"version": "v2", "created": "Wed, 19 Jul 2017 20:09:17 GMT"}, {"version": "v3", "created": "Sun, 3 Sep 2017 12:16:58 GMT"}, {"version": "v4", "created": "Sat, 4 Nov 2017 10:29:08 GMT"}, {"version": "v5", "created": "Sun, 31 Dec 2017 20:38:25 GMT"}, {"version": "v6", "created": "Thu, 16 Aug 2018 09:39:34 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Sengupta", "Binanda", ""], ["Ruj", "Sushmita", ""]]}, {"id": "1611.04216", "submitter": "Sarah Diesburg", "authors": "Sarah M. Diesburg", "title": "Ghosts of Deletions Past: New Secure Deletion Challenges and Solutions", "comments": "4 pages, 2 figures, pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is secure deletion of data still a problem?\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 01:11:22 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Diesburg", "Sarah M.", ""]]}, {"id": "1611.04227", "submitter": "Michel Toulouse", "authors": "Michel Toulouse, Hai Le, Cao Vien Phung, Denis Hock", "title": "Robust Consensus-Based Network Intrusion Detection in Presence of\n  Byzantine Attacks", "comments": "The seventh international symposium of information and communication\n  technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consensus algorithms provide strategies to solve problems in a distributed\nsystem with the added constraint that data can only be shared between adjacent\ncomputing nodes. We find these algorithms in applications for wireless and\nsensor networks, spectrum sensing for cognitive radio, even for some IoT\nservices. However, consensus-based applications are not resilient to\ncompromised nodes sending falsified data to their neighbors, i.e. they can be\nthe target of Byzantine attacks. Several solutions have been proposed in the\nliterature inspired from reputation based systems, outlier detection or\nmodel-based fault detection techniques in process control. We have reviewed\nsome of these solutions, and propose two mitigation techniques to protect the\nconsensus-based Network Intrusion Detection System in\n\\cite{toulouse2015consensus}. We analyze several implementation issues such as\ncomputational overhead, fine tuning of the solution parameters, impacts on the\nconvergence of the consensus phase, accuracy of the intrusion detection system.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 02:28:01 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Toulouse", "Michel", ""], ["Le", "Hai", ""], ["Phung", "Cao Vien", ""], ["Hock", "Denis", ""]]}, {"id": "1611.04426", "submitter": "Sudipta Chattopadhyay", "authors": "Sudipta Chattopadhyay, Moritz Beck, Ahmed Rezine, Andreas Zeller", "title": "Quantifying the Information Leak in Cache Attacks through Symbolic\n  Execution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cache timing attacks allow attackers to infer the properties of a secret\nexecution by observing cache hits and misses. But how much information can\nactually leak through such attacks? For a given program, a cache model, and an\ninput, our CHALICE framework leverages symbolic execution to compute the amount\nof information that can possibly leak through cache attacks. At the core of\nCHALICE is a novel approach to quantify information leak that can highlight\ncritical cache side-channel leaks on arbitrary binary code. In our evaluation\non real-world programs from OpenSSL and Linux GDK libraries, CHALICE\neffectively quantifies information leaks: For an AES-128 implementation on\nLinux, for instance, CHALICE finds that a cache attack can leak as much as 127\nout of 128 bits of the encryption key.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 15:49:00 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Chattopadhyay", "Sudipta", ""], ["Beck", "Moritz", ""], ["Rezine", "Ahmed", ""], ["Zeller", "Andreas", ""]]}, {"id": "1611.04482", "submitter": "Keith Bonawitz", "authors": "Keith Bonawitz, Vladimir Ivanov, Ben Kreuter, Antonio Marcedone, H.\n  Brendan McMahan, Sarvar Patel, Daniel Ramage, Aaron Segal, Karn Seth", "title": "Practical Secure Aggregation for Federated Learning on User-Held Data", "comments": "5 pages, 1 figure. To appear at the NIPS 2016 workshop on Private\n  Multi-Party Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure Aggregation protocols allow a collection of mutually distrust parties,\neach holding a private value, to collaboratively compute the sum of those\nvalues without revealing the values themselves. We consider training a deep\nneural network in the Federated Learning model, using distributed stochastic\ngradient descent across user-held training data on mobile devices, wherein\nSecure Aggregation protects each user's model gradient. We design a novel,\ncommunication-efficient Secure Aggregation protocol for high-dimensional data\nthat tolerates up to 1/3 users failing to complete the protocol. For 16-bit\ninput values, our protocol offers 1.73x communication expansion for $2^{10}$\nusers and $2^{20}$-dimensional vectors, and 1.98x expansion for $2^{14}$ users\nand $2^{24}$ dimensional vectors.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 17:14:55 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Bonawitz", "Keith", ""], ["Ivanov", "Vladimir", ""], ["Kreuter", "Ben", ""], ["Marcedone", "Antonio", ""], ["McMahan", "H. Brendan", ""], ["Patel", "Sarvar", ""], ["Ramage", "Daniel", ""], ["Segal", "Aaron", ""], ["Seth", "Karn", ""]]}, {"id": "1611.04786", "submitter": "Battista Biggio", "authors": "Igino Corona and Battista Biggio and Davide Maiorca", "title": "AdversariaLib: An Open-source Library for the Security Evaluation of\n  Machine Learning Algorithms Under Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present AdversariaLib, an open-source python library for the security\nevaluation of machine learning (ML) against carefully-targeted attacks. It\nsupports the implementation of several attacks proposed thus far in the\nliterature of adversarial learning, allows for the evaluation of a wide range\nof ML algorithms, runs on multiple platforms, and has multi-processing enabled.\nThe library has a modular architecture that makes it easy to use and to extend\nby implementing novel attacks and countermeasures. It relies on other\nwidely-used open-source ML libraries, including scikit-learn and FANN.\nClassification algorithms are implemented and optimized in C/C++, allowing for\na fast evaluation of the simulated attacks. The package is distributed under\nthe GNU General Public License v3, and it is available for download at\nhttp://sourceforge.net/projects/adversarialib.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 10:54:58 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Corona", "Igino", ""], ["Biggio", "Battista", ""], ["Maiorca", "Davide", ""]]}, {"id": "1611.04880", "submitter": "Markus Miettinen", "authors": "Markus Miettinen, Samuel Marchal, Ibbad Hafeez, N. Asokan, Ahmad-Reza\n  Sadeghi, Sasu Tarkoma", "title": "IoT Sentinel: Automated Device-Type Identification for Security\n  Enforcement in IoT", "comments": null, "journal-ref": null, "doi": "10.1109/ICDCS.2017.283", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of the Internet-of-Things (IoT), concerns about the\nsecurity of IoT devices have become prominent. Several vendors are producing\nIP-connected devices for home and small office networks that often suffer from\nflawed security designs and implementations. They also tend to lack mechanisms\nfor firmware updates or patches that can help eliminate security\nvulnerabilities. Securing networks where the presence of such vulnerable\ndevices is given, requires a brownfield approach: applying necessary protection\nmeasures within the network so that potentially vulnerable devices can coexist\nwithout endangering the security of other devices in the same network. In this\npaper, we present IOT SENTINEL, a system capable of automatically identifying\nthe types of devices being connected to an IoT network and enabling enforcement\nof rules for constraining the communications of vulnerable devices so as to\nminimize damage resulting from their compromise. We show that IOT SENTINEL is\neffective in identifying device types and has minimal performance overhead.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 15:07:48 GMT"}, {"version": "v2", "created": "Tue, 13 Dec 2016 11:21:47 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Miettinen", "Markus", ""], ["Marchal", "Samuel", ""], ["Hafeez", "Ibbad", ""], ["Asokan", "N.", ""], ["Sadeghi", "Ahmad-Reza", ""], ["Tarkoma", "Sasu", ""]]}, {"id": "1611.05101", "submitter": "Cunxi Yu", "authors": "Cunxi Yu and Maciej Ciesielski", "title": "Efficient Parallel Verification of Galois Field Multipliers", "comments": "6 pages, 22nd Asia and South Pacific Design Automation Conference\n  (ASP-DAC 2017), Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Galois field (GF) arithmetic is used to implement critical arithmetic\ncomponents in communication and security-related hardware, and verification of\nsuch components is of prime importance. Current techniques for formally\nverifying such components are based on computer algebra methods that proved\nsuccessful in verification of integer arithmetic circuits. However, these\nmethods are sequential in nature and do not offer any parallelism. This paper\npresents an algebraic functional verification technique of gate-level GF (2m )\nmultipliers, in which verification is performed in bit-parallel fashion. The\nmethod is based on extracting a unique polynomial in Galois field of each\noutput bit independently. We demonstrate that this method is able to verify an\nn-bit GF multiplier in n threads. Experiments performed on pre- and\npost-synthesized Mastrovito and Montgomery multipliers show high efficiency up\nto 571 bits.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 00:03:28 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 15:50:19 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Yu", "Cunxi", ""], ["Ciesielski", "Maciej", ""]]}, {"id": "1611.05564", "submitter": "Mark Zhandry", "authors": "Mark Zhandry", "title": "A Note on Quantum-Secure PRPs", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to construct pseudorandom permutations (PRPs) that remain secure\neven if the adversary can query the permutation on a quantum superposition of\ninputs. Such PRPs are called \\emph{quantum-secure}. Our construction combines a\nquantum-secure pseudorandom \\emph{function} together with constructions of\n\\emph{classical} format preserving encryption. By combining known results, we\nobtain the first quantum-secure PRP in this model whose security relies only on\nthe existence of one-way functions. Previously, to the best of the author's\nknowledge, quantum security of PRPs had to be assumed, and there were no prior\nsecurity reductions to simpler primitives, let alone one-way functions.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 05:09:48 GMT"}, {"version": "v2", "created": "Mon, 21 Nov 2016 18:17:26 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Zhandry", "Mark", ""]]}, {"id": "1611.05642", "submitter": "Thibaud Antignac", "authors": "Thibaud Antignac, David Sands, Gerardo Schneider", "title": "Data Minimisation: a Language-Based Approach (Long Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data minimisation is a privacy-enhancing principle considered as one of the\npillars of personal data regulations. This principle dictates that personal\ndata collected should be no more than necessary for the specific purpose\nconsented by the user. In this paper we study data minimisation from a\nprogramming language perspective. We assume that a given program embodies the\npurpose of data collection, and define a data minimiser as a pre-processor for\nthe input which reduces the amount of information available to the program\nwithout compromising its functionality. In this context we study formal\ndefinitions of data minimisation, present different mechanisms and\narchitectures to ensure data minimisation, and provide a procedure to\nsynthesise a correct data minimiser for a given program.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 11:48:29 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Antignac", "Thibaud", ""], ["Sands", "David", ""], ["Schneider", "Gerardo", ""]]}, {"id": "1611.05839", "submitter": "Meysam Mirzaee", "authors": "Erfan khordad, Soroush Akhlaghi, Meysam Mirzaee", "title": "Maximizing the minimum achievable secrecy rate of two-way relay networks\n  using the null space beamforming method", "comments": null, "journal-ref": null, "doi": "10.1049/iet-com.2016.0470", "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns maximizing the minimum achievable secrecy rate of a\ntwo-way relay network in the presence of an eavesdropper, in which two nodes\naim to exchange messages in two hops, using a multi-antenna relay. Throughout\nthe first hop, the two nodes simultaneously transmit their messages to the\nrelay. In the second hop, the relay broadcasts a combination of the received\ninformation to the users such that the transmitted signal lies in the null\nspace of the eavesdropper's channel; this is called null space beamforming\n(NSBF). The best NSBF matrix for maximizing the minimum achievable secrecy rate\nis studied, showing that the problem is not convex in general. To address this\nissue, the problem is divided into three sub-problems: a close-to-optimal\nsolution is derived by using the semi-definite relaxation (SDR) technique.\nSimulation results demonstrate the superiority of the proposed method w.r.t.\nthe most well-known method addressed in the literature.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 20:06:03 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["khordad", "Erfan", ""], ["Akhlaghi", "Soroush", ""], ["Mirzaee", "Meysam", ""]]}, {"id": "1611.06150", "submitter": "Yunlei Zhao", "authors": "Zhengzhong Jin, Yunlei Zhao", "title": "Optimal Key Consensus in Presence of Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we abstract some key ingredients in previous LWE- and\nRLWE-based key exchange protocols, by introducing and formalizing the building\ntool, referred to as key consensus (KC) and its asymmetric variant AKC. KC and\nAKC allow two communicating parties to reach consensus from close values\nobtained by some secure information exchange. We then discover upper bounds on\nparameters for any KC and AKC. KC and AKC are fundamental to lattice based\ncryptography, in the sense that a list of cryptographic primitives based on\nLWR, LWE and RLWE (including key exchange, public-key encryption, and more) can\nbe modularly constructed from them. As a conceptual contribution, this much\nsimplifies the design and analysis of these cryptosystems in the future.\n  We then design and analyze both general and highly practical KC and AKC\nschemes, which are referred to as OKCN and AKCN respectively for presentation\nsimplicity. Based on KC and AKC, we present generic constructions of key\nexchange (KE) from LWR, LWE and RLWE. The generic construction allows versatile\ninstantiations with our OKCN and AKCN schemes, for which we elaborate on\nevaluating and choosing the concrete parameters in order to achieve an\noptimally-balanced performance among security, computational cost, bandwidth\nefficiency, error rate, and operation simplicity.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 16:33:22 GMT"}, {"version": "v2", "created": "Mon, 5 Dec 2016 11:01:42 GMT"}, {"version": "v3", "created": "Thu, 16 Feb 2017 15:45:27 GMT"}, {"version": "v4", "created": "Fri, 6 Oct 2017 15:03:34 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Jin", "Zhengzhong", ""], ["Zhao", "Yunlei", ""]]}, {"id": "1611.06439", "submitter": "Reza Ebrahimi Atani", "authors": "SamanehSorournejad, Zahra Zojaji, Reza Ebrahimi Atani, Amir Hassan\n  Monadjemi", "title": "A Survey of Credit Card Fraud Detection Techniques: Data and Technique\n  Oriented Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credit card plays a very important rule in today's economy. It becomes an\nunavoidable part of household, business and global activities. Although using\ncredit cards provides enormous benefits when used carefully and\nresponsibly,significant credit and financial damages may be caused by\nfraudulent activities. Many techniques have been proposed to confront the\ngrowth in credit card fraud. However, all of these techniques have the same\ngoal of avoiding the credit card fraud; each one has its own drawbacks,\nadvantages and characteristics. In this paper, after investigating difficulties\nof credit card fraud detection, we seek to review the state of the art in\ncredit card fraud detection techniques, data sets and evaluation criteria.The\nadvantages and disadvantages of fraud detection methods are enumerated and\ncompared.Furthermore, a classification of mentioned techniques into two main\nfraud detection approaches, namely, misuses (supervised) and anomaly detection\n(unsupervised) is presented. Again, a classification of techniques is proposed\nbased on capability to process the numerical and categorical data sets.\nDifferent data sets used in literature are then described and grouped into real\nand synthesized data and the effective and common attributes are extracted for\nfurther usage.Moreover, evaluation employed criterions in literature are\ncollected and discussed.Consequently, open issues for credit card fraud\ndetection are explained as guidelines for new researchers.\n", "versions": [{"version": "v1", "created": "Sat, 19 Nov 2016 22:46:13 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["SamanehSorournejad", "", ""], ["Zojaji", "Zahra", ""], ["Atani", "Reza Ebrahimi", ""], ["Monadjemi", "Amir Hassan", ""]]}, {"id": "1611.06816", "submitter": "Adem Efe Gencer", "authors": "Adem Efe Gencer, Robbert van Renesse, Emin G\\\"un Sirer", "title": "Service-Oriented Sharding with Aspen", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of blockchain-based cryptocurrencies has led to an explosion of\nservices using distributed ledgers as their underlying infrastructure. However,\ndue to inherently single-service oriented blockchain protocols, such services\ncan bloat the existing ledgers, fail to provide sufficient security, or\ncompletely forego the property of trustless auditability. Security concerns,\ntrust restrictions, and scalability limits regarding the resource requirements\nof users hamper the sustainable development of loosely-coupled services on\nblockchains.\n  This paper introduces Aspen, a sharded blockchain protocol designed to\nsecurely scale with increasing number of services. Aspen shares the same trust\nmodel as Bitcoin in a peer-to-peer network that is prone to extreme churn\ncontaining Byzantine participants. It enables introduction of new services\nwithout compromising the security, leveraging the trust assumptions, or\nflooding users with irrelevant messages.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 14:53:56 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Gencer", "Adem Efe", ""], ["van Renesse", "Robbert", ""], ["Sirer", "Emin G\u00fcn", ""]]}, {"id": "1611.06952", "submitter": "Sangho Lee", "authors": "Sangho Lee, Ming-Wei Shih, Prasun Gera, Taesoo Kim, Hyesoon Kim,\n  Marcus Peinado", "title": "Inferring Fine-grained Control Flow Inside SGX Enclaves with Branch\n  Shadowing", "comments": "A revised version of this paper will be presented at USENIX Security\n  Symposium 2017. Please cite this paper as Sangho Lee, Ming-Wei Shih, Prasun\n  Gera, Taesoo Kim, Hyesoon Kim, and Marcus Peinado, \"Inferring Fine-grained\n  Control Flow Inside SGX Enclaves with Branch Shadowing,\" in Proceedings of\n  the 26th USENIX Security Symposium (Security), Vancouver, Canada, August 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore a new, yet critical, side-channel attack against\nIntel Software Guard Extension (SGX), called a branch shadowing attack, which\ncan reveal fine-grained control flows (i.e., each branch) of an enclave program\nrunning on real SGX hardware. The root cause of this attack is that Intel SGX\ndoes not clear the branch history when switching from enclave mode to\nnon-enclave mode, leaving the fine-grained traces to the outside world through\na branch-prediction side channel. However, exploiting the channel is not so\nstraightforward in practice because 1) measuring branch\nprediction/misprediction penalties based on timing is too inaccurate to\ndistinguish fine-grained control-flow changes and 2) it requires sophisticated\ncontrol over the enclave execution to force its execution to the interesting\ncode blocks. To overcome these challenges, we developed two novel exploitation\ntechniques: 1) Intel PT- and LBR-based history-inferring techniques and 2)\nAPIC-based technique to control the execution of enclave programs in a\nfine-grained manner. As a result, we could demonstrate our attack by breaking\nrecent security constructs, including ORAM schemes, Sanctum, SGX-Shield, and\nT-SGX. Not limiting our work to the attack itself, we thoroughly studied the\nfeasibility of hardware-based solutions (e.g., branch history clearing) and\nalso proposed a software-based countermeasure, called Zigzagger, to mitigate\nthe branch shadowing attack in practice.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 19:03:11 GMT"}, {"version": "v2", "created": "Fri, 25 Nov 2016 15:28:20 GMT"}, {"version": "v3", "created": "Thu, 1 Jun 2017 22:57:00 GMT"}], "update_date": "2017-06-05", "authors_parsed": [["Lee", "Sangho", ""], ["Shih", "Ming-Wei", ""], ["Gera", "Prasun", ""], ["Kim", "Taesoo", ""], ["Kim", "Hyesoon", ""], ["Peinado", "Marcus", ""]]}, {"id": "1611.07060", "submitter": "Ruffin White", "authors": "Ruffin White, Dr. Henrik I. Christensen, Dr. Morgan Quigley", "title": "SROS: Securing ROS over the wire, in the graph, and through the kernel", "comments": "Workshop contribution presented at IEEE-RAS International Conference\n  on Humanoid Robots (HUMANOIDS). 2016", "journal-ref": "HUMANOIDS 2016 Workshop: Towards Humanoid Robots {OS}", "doi": null, "report-no": null, "categories": "cs.RO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SROS is a proposed addition to the ROS API and ecosystem to support modern\ncryptography and security measures. An overview of current progress will be\npresented, rationalizing each major advancement, including: over-the-wire\ncryptography for all data transport, namespaced access control enforcing graph\npolicies/restrictions, and finally process profiles using Linux Security\nModules to harden a node's resource access. By making the community aware of\nthe vulnerabilities in ROS, as well as the proposed solutions provided by SROS,\nwe intend to improve the state of security for future robotics subsystems.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 21:19:13 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["White", "Ruffin", ""], ["Christensen", "Dr. Henrik I.", ""], ["Quigley", "Dr. Morgan", ""]]}, {"id": "1611.07067", "submitter": "Stefan Wagner", "authors": "Stefan Wagner", "title": "The Use of Application Scanners in Software Product Quality Assessment", "comments": "8 pages, 2 figures", "journal-ref": "Proceedings of the 8th international workshop on Software quality\n  (WoSQ'11). ACM, 2011", "doi": "10.1145/2024587.2024597", "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software development needs continuous quality control for a timely detection\nand removal of quality problems. This includes frequent quality assessments,\nwhich need to be automated as far as possible to be feasible. One way of\nautomation in assessing the security of software are application scanners that\ntest an executing software for vulnerabilities. At present, common quality\nassessments do not integrate such scanners for giving an overall quality\nstatement. This paper presents an integration of application scanners into a\ngeneral quality assessment method based on explicit quality models and Bayesian\nnets. Its applicability and the detection capabilities of common scanners are\ninvestigated in a case study with two open-source web shops.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 21:28:21 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Wagner", "Stefan", ""]]}, {"id": "1611.07109", "submitter": "Jose Javier Gonzalez Ortiz", "authors": "Jose Javier Gonzalez Ortiz and Kevin J. Compton", "title": "A Simple Power Analysis Attack on the Twofish Key Schedule", "comments": "Keywords: Twofish, SPA, Power Attack, Block Cipher, Error Tolerance", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an SPA power attack on the 8-bit implementation of the\nTwofish block cipher. The attack is able to unequivocally recover the secret\nkey even under substantial amounts of error. An initial algorithm is described\nusing exhaustive search on error free data. An error resistant algorithm is\nlater described. It employs several threshold preprocessing stages followed by\na combined approach of least mean squares and an optimized Hamming mask search.\nFurther analysis of 32 and 64-bit Twofish implementations reveals that they are\nsimilarly vulnerable to the described SPA attack.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 00:10:35 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Ortiz", "Jose Javier Gonzalez", ""], ["Compton", "Kevin J.", ""]]}, {"id": "1611.07299", "submitter": "Ayoub Otmani", "authors": "Younes Hatri and Ayoub Otmani and Kenza Guenda", "title": "Cryptanalysis of an Identity-Based Authenticated Key Exchange Protocol", "comments": "To appear in International Journal of Communication Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authenticated Key Exchange (AKE) protocols represent an important\ncryptographic mechanism that enables several parties to communicate securely\nover an open network. Elashry, Mu and Susilo proposed in 2015 an Identity Based\nAuthenticated Key Exchange (IBAKE) protocol where different parties establish\nsecure communication by means of their public identities. The authors also\nintroduced a new security notion for IBAKE protocols called resiliency, that\nis, if a shared secret between a group of parties is compromised or leaked,\nthey can generate another completely new shared secret without the need to set\nup a new key exchange session. They then proved that their IBAKE protocol\nsatisfies this security notion.\n  We analyze the security of their protocol and prove that it has a major\nsecurity flaw which renders it insecure against an impersonation attack. We\nalso disprove the resiliency property of their scheme by proposing an attack\nwhere an adversary can compute any share secret key if just one secret bit is\nleaked.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 13:49:52 GMT"}, {"version": "v2", "created": "Mon, 30 Oct 2017 10:36:46 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Hatri", "Younes", ""], ["Otmani", "Ayoub", ""], ["Guenda", "Kenza", ""]]}, {"id": "1611.07350", "submitter": "Mordechai Guri", "authors": "Mordechai Guri, Yosef Solewicz, Andrey Daidakulov, Yuval Elovici", "title": "SPEAKE(a)R: Turn Speakers to Microphones for Fun and Profit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is possible to manipulate the headphones (or earphones) connected to a\ncomputer, silently turning them into a pair of eavesdropping microphones - with\nsoftware alone. The same is also true for some types of loudspeakers. This\npaper focuses on this threat in a cyber-security context. We present\nSPEAKE(a)R, a software that can covertly turn the headphones connected to a PC\ninto a microphone. We present technical background and explain why most of PCs\nand laptops are susceptible to this type of attack. We examine an attack\nscenario in which malware can use a computer as an eavesdropping device, even\nwhen a microphone is not present, muted, taped, or turned off. We measure the\nsignal quality and the effective distance, and survey the defensive\ncountermeasures.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 15:18:07 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Guri", "Mordechai", ""], ["Solewicz", "Yosef", ""], ["Daidakulov", "Andrey", ""], ["Elovici", "Yuval", ""]]}, {"id": "1611.07383", "submitter": "Hao Zhuang", "authors": "Hao Zhuang and Florian Pydde", "title": "A Non-Intrusive and Context-Based Vulnerability Scoring Framework for\n  Cloud Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the severity of vulnerabilities within cloud services is\nparticularly important for today service administrators.Although many systems,\ne.g., CVSS, have been built to evaluate and score the severity of\nvulnerabilities for administrators, the scoring schemes employed by these\nsystems fail to take into account the contextual information of specific\nservices having these vulnerabilities, such as what roles they play in a\nparticular service. Such a deficiency makes resulting scores unhelpful. This\npaper presents a practical framework, NCVS, that offers automatic and\ncontextual scoring mechanism to evaluate the severity of vulnerabilities for a\nparticular service. Specifically, for a given service S, NCVS first\nautomatically collects S contextual information including topology,\nconfigurations, vulnerabilities and their dependencies. Then, NCVS uses the\ncollected information to build a contextual dependency graph, named CDG, to\nmodel S context. Finally, NCVS scores and ranks all the vulnerabilities in S by\nanalyzing S context, such as what roles the vulnerabilities play in S, and how\ncritical they affect the functionality of S. NCVS is novel and useful, because\n1) context-based vulnerability scoring results are highly relevant and\nmeaningful for administrators to understand each vulnerability importance\nspecific to the target service; and 2) the workflow of NCVS does not need\ninstrumentation or modifications to any source code. Our experimental results\ndemonstrate that NCVS can obtain more relevant vulnerability scoring results\nthan comparable system, such as CVSS.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 16:09:12 GMT"}, {"version": "v2", "created": "Wed, 7 Dec 2016 09:00:11 GMT"}], "update_date": "2016-12-08", "authors_parsed": [["Zhuang", "Hao", ""], ["Pydde", "Florian", ""]]}, {"id": "1611.07392", "submitter": "Santosh Aditham", "authors": "Santosh Aditham, Nagarajan Ranganathan and Srinivas Katkoori", "title": "Call Trace and Memory Access Pattern based Runtime Insider Threat\n  Detection for Big Data Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data platforms such as Hadoop and Spark are being widely adopted both by\nacademia and industry. In this paper, we propose a runtime intrusion detection\ntechnique that understands and works according to the properties of such\ndistributed compute platforms. The proposed method is based on runtime analysis\nof system and library calls and memory access patterns of tasks running on the\ndatanodes (slaves). First, the primary datanode of a big data system creates a\nbehavior profile for every task it executes. A behavior profile includes (a)\ntrace of the system & library calls made, and (b) sequence representing the\nsizes of private and shared memory accesses made during task execution. Then,\nthe process behavior profile is shared with other replica datanodes that are\nscheduled to execute the same task on their copy of the same data. Next, these\nreplica datanodes verify their local tasks with the help of the information\nembedded in the received behavior profiles. This is realized in two steps: (i)\ncomparing the system & library calls metadata, and (ii) statistical matching of\nthe memory access patterns. Finally, datanodes share their observations for\nconsensus and report an intrusion to the namenode (master) if they find any\ndiscrepancy. The proposed solution was tested on a small hadoop cluster using\nthe default MapReduce examples and the results show that our approach can\ndetect insider attacks that cannot be detected with the traditional analysis\nmetrics.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 16:23:39 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Aditham", "Santosh", ""], ["Ranganathan", "Nagarajan", ""], ["Katkoori", "Srinivas", ""]]}, {"id": "1611.07617", "submitter": "arXiv Admin", "authors": "He Zhu", "title": "A New Framework for Ranking Vulnerabilities in the Clouds", "comments": "arXiv admin note: submission has been withdrawn by arXiv\n  administrators due to inappropriate text reuse from external sources", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Qualifying and ranking threat degrees of vulnerabilities in cloud service are\nknown to be full of challenges. Although there have been several efforts aiming\nto address this problem, most of them are too simple or cannot be applied into\ncloud infrastructure. This paper aims to propose a novel framework to qualify\nand rank the vulnerabilities based on their threat degrees in cloud service.\nThrough inputting or constructing service dependency graph, our framework is\nable to generate the importance degree of each service and the ranking list of\nall the vulnerabilities in cloud service. Moreover, our framework can be\nadopted not only into various cloud infrastructures, but also different\ncategories of algorithms according to concrete requirements. To evaluate our\nframework, we adopt AssetRank algorithm into the framework, and present the\nwhole design of our work. Comprehensive experiments prove the effectiveness of\nour framework on qualifying and ranking vulnerabilities in cloud service.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 03:02:39 GMT"}, {"version": "v2", "created": "Tue, 6 Dec 2016 19:25:31 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Zhu", "He", ""]]}, {"id": "1611.07633", "submitter": "Grasha Jacob Mrs", "authors": "Dr. Grasha Jacob and Dr. A. Murugan", "title": "Towards the Secure Storage of Images on Multi-Cloud System", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapidly changing technological realm, there is an urgent need to\nprovide and protect the confidentiality of confidential images when stored in a\ncloud environment. To overcome the security risks associated with single cloud,\nmultiple clouds offered by unrelated cloud providers have to be used. This\npaper outlines an integrated encryption scheme for the secure storage of\nconfidential images on multiple clouds based on DNA sequences.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 03:55:22 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Jacob", "Dr. Grasha", ""], ["Murugan", "Dr. A.", ""]]}, {"id": "1611.07649", "submitter": "Santosh Aditham", "authors": "Santosh Aditham and Nagarajan Ranganathan", "title": "A Novel Control-flow based Intrusion Detection Technique for Big Data\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security and distributed infrastructure are two of the most common\nrequirements for big data software. But the security features of the big data\nplatforms are still premature. It is critical to identify, modify, test and\nexecute some of the existing security mechanisms before using them in the big\ndata world. In this paper, we propose a novel intrusion detection technique\nthat understands and works according to the needs of big data systems. Our\nproposed technique identifies program level anomalies using two methods - a\nprofiling method that models application behavior by creating process\nsignatures from control-flow graphs; and a matching method that checks for\ncoherence among the replica nodes of a big data system by matching the process\nsignatures. The profiling method creates a process signature by reducing the\ncontrol-flow graph of a process to a set of minimum spanning trees and then\ncreates a hash of that set. The matching method first checks for similarity in\nprocess behavior by matching the received process signature with the local\nsignature and then shares the result with all replica datanodes for consensus.\nExperimental results show only 0.8% overhead due to the proposed technique when\ntested on the hadoop map-reduce examples in real-time.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 05:24:38 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Aditham", "Santosh", ""], ["Ranganathan", "Nagarajan", ""]]}, {"id": "1611.07722", "submitter": "Leandros Maglaras A", "authors": "Mohamed Amine Ferrag, Leandros A. Maglaras, Helge Janicke, Jianmin\n  Jiang", "title": "A Survey on Privacy-preserving Schemes for Smart Grid Communications", "comments": "30 pages, 13 figures, 15 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a comprehensive survey of privacy-preserving\nschemes for Smart Grid communications. Specifically, we select and in-detail\nexamine thirty privacy preserving schemes developed for or applied in the\ncontext of Smart Grids. Based on the communication and system models, we\nclassify these schemes that are published between 2013 and 2016, in five\ncategories, including, 1) Smart grid with the advanced metering infrastructure,\n2) Data aggregation communications, 3) Smart grid marketing architecture, 4)\nSmart community of home gateways, and 5) Vehicle-to grid architecture. For each\nscheme, we survey the attacks of leaking privacy, countermeasures, and game\ntheoretic approaches. In addition, we review the survey articles published in\nthe recent years that deal with Smart Grids communications, applications,\nstandardization, and security. Based on the current survey, several\nrecommendations for further research are discussed at the end of this paper.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 10:20:34 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Ferrag", "Mohamed Amine", ""], ["Maglaras", "Leandros A.", ""], ["Janicke", "Helge", ""], ["Jiang", "Jianmin", ""]]}, {"id": "1611.07832", "submitter": "Marcus Hardt", "authors": "A. Biancini, L. Florio, M. Haase, M. Hardt, M. Jankowski, J. Jensen,\n  C. Kanellopoulos, N. Liampotis, S. Licehammer, S. Memon, N. van Dijk, S.\n  Paetow, M. Prochazka, M. Sall\\'e, P. Solagna, U. Stevanovic, D. Vaghetti", "title": "AARC: First draft of the Blueprint Architecture for Authentication and\n  Authorisation Infrastructures", "comments": "This text was part of a (public) EU deliverable document. It has a\n  main part and a long appendix with more details about example infrastructures\n  that were taken into acount", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  AARC (Authentication and Authorisation for Research Communities) is a\ntwo-year EC-funded project to develop and pilot an integrated cross-discipline\nauthentication and authorisation framework, building on existing authentication\nand authorisation infrastructures (AAIs) and production federated\ninfrastructure. AARC also champions federated access and offers tailored\ntraining to complement the actions needed to test AARC results and to promote\nAARC outcomes. This article describes a high-level blueprint architectures for\ninteroperable AAIs.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 15:13:49 GMT"}, {"version": "v2", "created": "Wed, 30 Nov 2016 08:40:56 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Biancini", "A.", ""], ["Florio", "L.", ""], ["Haase", "M.", ""], ["Hardt", "M.", ""], ["Jankowski", "M.", ""], ["Jensen", "J.", ""], ["Kanellopoulos", "C.", ""], ["Liampotis", "N.", ""], ["Licehammer", "S.", ""], ["Memon", "S.", ""], ["van Dijk", "N.", ""], ["Paetow", "S.", ""], ["Prochazka", "M.", ""], ["Sall\u00e9", "M.", ""], ["Solagna", "P.", ""], ["Stevanovic", "U.", ""], ["Vaghetti", "D.", ""]]}, {"id": "1611.07910", "submitter": "Isaac Skog", "authors": "Johan Wahlstr\\\"om, Isaac Skog, Jo\\~ao G. P. Rodrigues, Peter H\\\"andel,\n  Ana Aguiar", "title": "Map-aided Dead-reckoning --- A Study on Locational Privacy in Insurance\n  Telematics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a particle-based framework for estimating the position of a\nvehicle using map information and measurements of speed. Two measurement\nfunctions are considered. The first is based on the assumption that the lateral\nforce on the vehicle does not exceed critical limits derived from physical\nconstraints. The second is based on the assumption that the driver approaches a\ntarget speed derived from the speed limits along the upcoming trajectory.\nPerformance evaluations of the proposed method indicate that end destinations\noften can be estimated with an accuracy in the order of $100\\,[m]$. These\nresults expose the sensitivity and commercial value of data collected in many\nof today's insurance telematics programs, and thereby have privacy implications\nfor millions of policyholders. We end by discussing the strengths and\nweaknesses of different methods for anonymization and privacy preservation in\ntelematics programs.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 10:04:45 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Wahlstr\u00f6m", "Johan", ""], ["Skog", "Isaac", ""], ["Rodrigues", "Jo\u00e3o G. P.", ""], ["H\u00e4ndel", "Peter", ""], ["Aguiar", "Ana", ""]]}, {"id": "1611.07946", "submitter": "Dmitri Strukov B", "authors": "Hussein Nili, Gina C. Adam, Mirko Prezioso, Jeeson Kim, Farnood\n  Merrikh-Bayat, Omid Kavehei, and Dmitri B. Strukov", "title": "Highly-Secure Physically Unclonable Cryptographic Primitives Using\n  Nonlinear Conductance and Analog State Tuning in Memristive Crossbar Arrays", "comments": "24 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cond-mat.other cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapidly expanding hardware-intrinsic security primitives are aimed at\naddressing significant security challenges of a massively interconnected world\nin the age of information technology. The main idea of such primitives is to\nemploy instance-specific process-induced variations in electronic hardware as a\nsource of cryptographic data. Among the emergent technologies, memristive\ndevices provide unique opportunities for security applications due to the\nunderlying stochasticity in their operation. Herein, we report a prototype of a\nrobust, dense, and reconfigurable physical unclonable function primitives based\non the three-dimensional passive metal-oxide memristive crossbar circuits, by\nmaking positive use of process-induced variations in the devices' nonlinear\nI-Vs and their analog tuning. We first characterize security metrics for a\nbasic building block of the security primitives based on a two layer stack with\nmonolithically integrated 10x10 250-nm half-pitch memristive crossbar circuits.\nThe experimental results show that the average uniformity and diffusivity,\nmeasured on a random sample of 6,000 64-bit responses, out of ~697,000 total,\nis close to ideal 50% with 5% standard deviation for both metrics. The\nuniqueness, which was evaluated on a smaller sample by readjusting conductances\nof crosspoint devices within the same crossbar, is also close to the ideal 50%\n+/- 1%, while the smallest bit error rate, i.e. reciprocal of reliability,\nmeasured over 30-day window under +/-20% power supply variations, was ~ 1.5%\n+/- 1%. We then utilize multiple instances of the basic block to demonstrate\nphysically unclonable functional primitive with 10-bit hidden challenge\ngeneration that encodes more than 10^19 challenge response pairs and has\ncomparable uniformity, diffusiveness, and bit error rate.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 19:23:13 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Nili", "Hussein", ""], ["Adam", "Gina C.", ""], ["Prezioso", "Mirko", ""], ["Kim", "Jeeson", ""], ["Merrikh-Bayat", "Farnood", ""], ["Kavehei", "Omid", ""], ["Strukov", "Dmitri B.", ""]]}, {"id": "1611.08098", "submitter": "Moreno Ambrosin", "authors": "Moreno Ambrosin, Arman Anzanpour, Mauro Conti, Tooska Dargahi, Sanaz\n  Rahimi Moosavi, Amir M. Rahmani, and Pasi Liljeberg", "title": "On the Feasibility of Attribute-Based Encryption on Internet of Things\n  Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribute-Based Encryption (ABE) could be an effective cryptographic tool for\nthe secure management of Internet-of-Things (IoT) devices, but its feasibility\nin the IoT has been under-investigated thus far. This article explores such\nfeasibility for well-known IoT platforms, namely, Intel Galileo Gen 2, Intel\nEdison, Raspberry Pi 1 Model B, and Raspberry Pi Zero, and concludes that\nadopting ABE in the IoT is indeed feasible.\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2016 08:45:13 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Ambrosin", "Moreno", ""], ["Anzanpour", "Arman", ""], ["Conti", "Mauro", ""], ["Dargahi", "Tooska", ""], ["Moosavi", "Sanaz Rahimi", ""], ["Rahmani", "Amir M.", ""], ["Liljeberg", "Pasi", ""]]}, {"id": "1611.08252", "submitter": "Grasha Jacob Dr", "authors": "Grasha Jacob and A. Murugan", "title": "An Integrated approach for the Secure Transmission of Images based on\n  DNA Sequences", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As long as human beings exist on this earth, there will be confidential\nimages intended for limited audience. These images have to be transmitted in\nsuch a way that no unauthorized person gets knowledge of them. DNA sequences\nplay a vital role in modern cryptography and DNA sequence based cryptography\nrenders a helping hand for transmission of such confidential images over a\npublic insecure channel as the intended recipient alone can decipher them. This\npaper outlines an integrated encryption scheme based on DNA sequences and\nscrambling according to magic square of doubly even order pattern. Since there\nis negligible correlation between the original and encrypted image this method\nis robust against any type of crypt attack.\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2016 16:55:32 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Jacob", "Grasha", ""], ["Murugan", "A.", ""]]}, {"id": "1611.08294", "submitter": "Wojciech Mazurczyk", "authors": "Krzysztof Cabaj, Marcin Gregorczyk, Wojciech Mazurczyk", "title": "Software-Defined Networking-based Crypto Ransomware Detection Using HTTP\n  Traffic Characteristics", "comments": "14 pages, 13 figures, 3 tables", "journal-ref": "Computers & Electrical Engineering, vol. 66, 2017, pp. 353-368", "doi": "10.1016/j.compeleceng.2017.10.012", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ransomware is currently the key threat for individual as well as corporate\nInternet users. Especially dangerous is crypto ransomware that encrypts\nimportant user data and it is only possible to recover it once a ransom has\nbeen paid. Therefore devising efficient and effective countermeasures is a\nrising necessity. In this paper we present a novel Software-Defined Networking\n(SDN) based detection approach that utilizes characteristics of ransomware\ncommunication. Based on the observation of network communication of two crypto\nransomware families, namely CryptoWall and Locky we conclude that analysis of\nthe HTTP messages' sequences and their respective content sizes is enough to\ndetect such threats. We show feasibility of our approach by designing and\nevaluating the proof-of-concept SDN-based detection system. Experimental\nresults confirm that the proposed approach is feasible and efficient.\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2016 19:43:10 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Cabaj", "Krzysztof", ""], ["Gregorczyk", "Marcin", ""], ["Mazurczyk", "Wojciech", ""]]}, {"id": "1611.08396", "submitter": "Christopher Liebchen", "authors": "Ferdinand Brasser and Lucas Davi and David Gens and Christopher\n  Liebchen and Ahmad-Reza Sadeghi", "title": "CAn't Touch This: Practical and Generic Software-only Defenses Against\n  Rowhammer Attacks", "comments": "-- Clarifications based on intial feedback -- p7: clarified formula\n  p10: included rest of pts/memory (cachebench/ramspeed) in Tab III p12:\n  include discussion on how single-sided rowhammer attacks are mitigated and\n  benchmark selection p13: updated related work p14: updated acknowledgment", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rowhammer is a hardware bug that can be exploited to implement privilege\nescalation and remote code execution attacks. Previous proposals on rowhammer\nmitigation either require hardware changes or follow heuristic-based approaches\n(based on CPU performance counters). To date, there exists no instant\nprotection against rowhammer attacks on legacy systems.\n  In this paper, we present the design and implementation of two practical and\nefficient software-only defenses against rowhammer attacks. Our defenses\nprevent the attacker from leveraging rowhammer to corrupt physically co-located\ndata in memory that is owned by a different system entity. Our first defense,\nB-CATT, extends the system bootloader to disable vulnerable physical memory.\nB-CATT is highly practical, does not require changes to the operating system,\nand can be deployed on virtually all x86-based systems. While B-CATT is able to\nstop all known rowhammer attacks, it does not yet tackle the fundamental\nproblem of missing memory isolation in physical memory. To address this\nproblem, we introduce our second defense G-CATT, a generic solution that\nextends the physical memory allocator of the OS to physically isolate the\nmemory of different system entities (e.g., kernel and user space).\n  As proof of concept, we implemented B-CATT on x86, and our generic defense,\nG-CATT, on x86 and ARM to mitigate rowhammer-based kernel exploits. Our\nextensive evaluation shows that both mitigation schemes (i) can stop available\nreal- world rowhammer attacks, (ii) impose virtually no run-time overhead for\ncommon user and kernel benchmarks as well as commonly used applications, and\n(iii) do not affect the stability of the overall system.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2016 09:37:13 GMT"}, {"version": "v2", "created": "Wed, 7 Dec 2016 12:19:41 GMT"}], "update_date": "2016-12-08", "authors_parsed": [["Brasser", "Ferdinand", ""], ["Davi", "Lucas", ""], ["Gens", "David", ""], ["Liebchen", "Christopher", ""], ["Sadeghi", "Ahmad-Reza", ""]]}, {"id": "1611.08410", "submitter": "Christophe Guyeux", "authors": "Mohammed Bakiri, Jean-Fran\\c{c}ois Couchot, Christophe Guyeux", "title": "FPGA Implementation of $\\mathbb{F}_2$-Linear Pseudorandom Number\n  Generators Based on Zynq MPSoC: a Chaotic Iterations Post Processing Case\n  Study", "comments": "Accepted to Secrypt16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pseudorandom number generation (PRNG) is a key element in hardware security\nplatforms like field-programmable gate array FPGA circuits. In this article, 18\nPRNGs belonging in 4 families (xorshift, LFSR, TGFSR, and LCG) are physically\nimplemented in a FPGA and compared in terms of area, throughput, and\nstatistical tests. Two flows of conception are used for Register Transfer Level\n(RTL) and High-level Synthesis (HLS). Additionally, the relations between\nlinear complexity, seeds, and arithmetic operations on the one hand, and the\nresources deployed in FPGA on the other hand, are deeply investigated. In order\nto do that, a SoC based on Zynq EPP with ARM Cortex-$A9$ MPSoC is developed to\naccelerate the implementation and the tests of various PRNGs on FPGA hardware.\nA case study is finally proposed using chaotic iterations as a post processing\nfor FPGA. The latter has improved the statistical profile of a combination of\nPRNGs that, without it, failed in the so-called TestU01 statistical battery of\ntests.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2016 10:42:34 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Bakiri", "Mohammed", ""], ["Couchot", "Jean-Fran\u00e7ois", ""], ["Guyeux", "Christophe", ""]]}, {"id": "1611.08417", "submitter": "Christophe Guyeux", "authors": "Sara Barakat, Bechara Al Bouna, Mohamed Nassar, Christophe Guyeux", "title": "On the Evaluation of the Privacy Breach in Disassociated Set-Valued\n  Datasets", "comments": "Accepted to Secrypt 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data anonymization is gaining much attention these days as it provides the\nfundamental requirements to safely outsource datasets containing identifying\ninformation. While some techniques add noise to protect privacy others use\ngeneralization to hide the link between sensitive and non-sensitive information\nor separate the dataset into clusters to gain more utility. In the latter,\noften referred to as bucketization, data values are kept intact, only the link\nis hidden to maximize the utility. In this paper, we showcase the limits of\ndisassociation, a bucketization technique that divides a set-valued dataset\ninto $k^m$-anonymous clusters. We demonstrate that a privacy breach might occur\nif the disassociated dataset is subject to a cover problem. We finally evaluate\nthe privacy breach using the quantitative privacy breach detection algorithm on\nreal disassociated datasets.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2016 11:03:55 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Barakat", "Sara", ""], ["Bouna", "Bechara Al", ""], ["Nassar", "Mohamed", ""], ["Guyeux", "Christophe", ""]]}, {"id": "1611.08422", "submitter": "Christophe Guyeux", "authors": "Xiaole Fang, Christophe Guyeux, Qianxue Wang, Jacques M. Bahi", "title": "Randomness and disorder of chaotic iterations. Applications in\n  information security field", "comments": "Accepted to Nolta 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.CD cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design and cryptanalysis of chaotic encryption schemes are major concerns to\nprovide secured information systems. Pursuing our previous research works, some\nwell-defined discrete chaotic iterations that satisfy the reputed Devaney's\ndefinition of chaos have been proposed. In this article, we summarize these\ncontributions and propose applications in the fields of pseudorandom number\ngeneration, hash functions, and symmetric cryptography. For all these\napplications, the proofs of chaotic properties are outlined.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2016 11:23:51 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Fang", "Xiaole", ""], ["Guyeux", "Christophe", ""], ["Wang", "Qianxue", ""], ["Bahi", "Jacques M.", ""]]}, {"id": "1611.08547", "submitter": "Sandra Alves", "authors": "Jo\\~ao S\\'a, Sandra Alves and Sabine Broda", "title": "The G-ACM Tool: using the Drools Rule Engine for Access Control\n  Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the usage of rule engines in a graphical framework\nfor visualising dynamic access control policies. We use the Drools rule engine\nto dynamically compute permissions, following the Category-Based Access Control\nmetamodel.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2016 18:36:16 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["S\u00e1", "Jo\u00e3o", ""], ["Alves", "Sandra", ""], ["Broda", "Sabine", ""]]}, {"id": "1611.08648", "submitter": "Berkay Celik", "authors": "Z. Berkay Celik, David Lopez-Paz, Patrick McDaniel", "title": "Patient-Driven Privacy Control through Generalized Distillation", "comments": "IEEE Symposium on Privacy-Aware Computing (IEEE PAC), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The introduction of data analytics into medicine has changed the nature of\npatient treatment. In this, patients are asked to disclose personal information\nsuch as genetic markers, lifestyle habits, and clinical history. This data is\nthen used by statistical models to predict personalized treatments. However,\ndue to privacy concerns, patients often desire to withhold sensitive\ninformation. This self-censorship can impede proper diagnosis and treatment,\nwhich may lead to serious health complications and even death over time. In\nthis paper, we present privacy distillation, a mechanism which allows patients\nto control the type and amount of information they wish to disclose to the\nhealthcare providers for use in statistical models. Meanwhile, it retains the\naccuracy of models that have access to all patient data under a sufficient but\nnot full set of privacy-relevant information. We validate privacy distillation\nusing a corpus of patients prescribed to warfarin for a personalized dosage. We\nuse a deep neural network to implement privacy distillation for training and\nmaking dose predictions. We find that privacy distillation with sufficient\nprivacy-relevant information i) retains accuracy almost as good as having all\npatient data (only 3\\% worse), and ii) is effective at preventing errors that\nintroduce health-related risks (only 3.9\\% worse under- or over-prescriptions).\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 01:47:00 GMT"}, {"version": "v2", "created": "Fri, 13 Oct 2017 23:49:10 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Celik", "Z. Berkay", ""], ["Lopez-Paz", "David", ""], ["McDaniel", "Patrick", ""]]}, {"id": "1611.08686", "submitter": "Maheswara Rao Valluri", "authors": "Maheswara Rao Valluri", "title": "Cryptanalysis of Xinyu et al.'s NTRU-Lattice Based Key Exchange Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Xinyu et al. proposed a public key exchange protocol, which is based on the\nNTRU-lattice based cryptography. In this paper, we show how Xinyu et al.'s\nNTRU-KE: A lattice based key exchange protocol can be broken, under the\nassumption that a man-in-the middle attack is used for extracting private keys\nof users who participate in the key exchange protocol.\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 09:25:51 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Valluri", "Maheswara Rao", ""]]}, {"id": "1611.08769", "submitter": "Thomas Shortell Iii", "authors": "Thomas Shortell and Ali Shokoufandeh", "title": "Secure Fast Fourier Transform using Fully Homomorphic Encryption", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure signal processing is becoming a de facto model for preserving privacy.\nWe propose a model based on the Fully Homomorphic Encryption (FHE) technique to\nmitigate security breaches. Our framework provides a method to perform a Fast\nFourier Transform (FFT) on a user-specified signal. Using encryption of\nindividual binary values and FHE operations over addition and multiplication,\nwe enable a user to perform the FFT in a fixed point fractional representation\nin binary. Our approach bounds the error of the implementation to enable\nuser-selectable parameters based on the specific application. We verified our\nframework against test cases for one dimensional signals and images (two\ndimensional signals).\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2016 01:17:24 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Shortell", "Thomas", ""], ["Shokoufandeh", "Ali", ""]]}, {"id": "1611.08882", "submitter": "Ilias Giechaskiel", "authors": "Ilias Giechaskiel and Kasper B. Rasmussen and Ken Eguro", "title": "Leaky Wires: Information Leakage and Covert Communication Between FPGA\n  Long Wires", "comments": null, "journal-ref": null, "doi": "10.1145/3196494.3196518", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Field-Programmable Gate Arrays (FPGAs) are integrated circuits that implement\nreconfigurable hardware. They are used in modern systems, creating specialized,\nhighly-optimized integrated circuits without the need to design and manufacture\ndedicated chips. As the capacity of FPGAs grows, it is increasingly common for\ndesigners to incorporate implementations of algorithms and protocols from a\nrange of third-party sources. The monolithic nature of FPGAs means that all\non-chip circuits, including third party black-box designs, must share common\non-chip infrastructure, such as routing resources. In this paper, we observe\nthat a \"long\" routing wire carrying a logical 1 reduces the propagation delay\nof other adjacent but unconnected long wires in the FPGA interconnect, thereby\nleaking information about its state. We exploit this effect and propose a\ncommunication channel that can be used for both covert transmissions between\ncircuits, and for exfiltration of secrets from the chip. We show that the\neffect is measurable for both static and dynamic signals, and that it can be\ndetected using very small on-board circuits. In our prototype, we are able to\ncorrectly infer the logical state of an adjacent long wire over 99% of the\ntime, even without error correction, and for signals that are maintained for as\nlittle as 82us. Using a Manchester encoding scheme, our channel bandwidth is as\nhigh as 6kbps. We characterize the channel in detail and show that it is\nmeasurable even when multiple competing circuits are present and can be\nreplicated on different generations and families of Xilinx devices (Virtex 5,\nVirtex 6, and Artix 7). Finally, we propose countermeasures that can be\ndeployed by systems and tools designers to reduce the impact of this\ninformation leakage.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2016 18:23:07 GMT"}, {"version": "v2", "created": "Thu, 10 Aug 2017 22:29:17 GMT"}, {"version": "v3", "created": "Tue, 13 Mar 2018 18:43:06 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Giechaskiel", "Ilias", ""], ["Rasmussen", "Kasper B.", ""], ["Eguro", "Ken", ""]]}, {"id": "1611.08954", "submitter": "Jalaj Upadhyay", "authors": "Jalaj Upadhyay", "title": "On Low-Space Differentially Private Low-rank Factorization in the\n  Spectral Norm", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank factorization is used in many areas of computer science where one\nperforms spectral analysis on large sensitive data stored in the form of\nmatrices. In this paper, we study differentially private low-rank factorization\nof a matrix with respect to the spectral norm in the turnstile update model. In\nthis problem, given an input matrix $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$\nupdated in the turnstile manner and a target rank $k$, the goal is to find two\nrank-$k$ orthogonal matrices $\\mathbf{U}_k \\in \\mathbb{R}^{m \\times k}$ and\n$\\mathbf{V}_k \\in \\mathbb{R}^{n \\times k}$, and one positive semidefinite\ndiagonal matrix $\\textbf{\\Sigma}_k \\in \\mathbb{R}^{k \\times k}$ such that\n$\\mathbf{A} \\approx \\mathbf{U}_k \\textbf{\\Sigma}_k \\mathbf{V}_k^\\mathsf{T}$\nwith respect to the spectral norm.\n  Our main contributions are two computationally efficient and sub-linear space\nalgorithms for computing a differentially private low-rank factorization. We\nconsider two levels of privacy. In the first level of privacy, we consider two\nmatrices neighboring if their difference has a Frobenius norm at most $1$. In\nthe second level of privacy, we consider two matrices as neighboring if their\ndifference can be represented as an outer product of two unit vectors. Both\nthese privacy levels are stronger than those studied in the earlier papers such\nas Dwork {\\it et al.} (STOC 2014), Hardt and Roth (STOC 2013), and Hardt and\nPrice (NIPS 2014).\n  As a corollary to our results, we get non-private algorithms that compute\nlow-rank factorization in the turnstile update model with respect to the\nspectral norm. We note that, prior to this work, no algorithm that outputs\nlow-rank factorization with respect to the spectral norm in the turnstile\nupdate model was known; i.e., our algorithm gives the first non-private\nlow-rank factorization with respect to the spectral norm in the turnstile\nupdate mode.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 01:57:53 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Upadhyay", "Jalaj", ""]]}, {"id": "1611.09009", "submitter": "Lei Hua", "authors": "Mu Han, Lei Hua, Shidian Ma", "title": "A Self-Authentication and Deniable Efficient Group Key Agreement\n  Protocol for VANET", "comments": "27 page, 7 figures,4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of vehicular ad hoc Network (VANET), it is gaining\nsignificant popularity and receiving increasing attentions from academics and\nindustry in security and efficiency. To address security and efficiency issues,\na self-authentication and deniable efficient group key agreement protocol is\nproposed in this paper. This scheme establishes a group between road-side unit\n(RSU) and vehicles by using self-authentication without certification\nauthority, and enhances certification efficiency by using group key (GK)\ntransmission method. At the same time, to avoid the attacker to attack the\nlegal vehicle by RSU, we adopt deniable group key agreement method to\nnegotiation session key (sk) and use it to transmit GK between RSU. In\naddition, vehicles not only broadcast messages to other vehicles, but also\ncommunicate with other members in the same group. So group communication is\nnecessary in VANET. Finally, the security and performance analysis shown that\nour scheme is security, meanwhile the verification delay, transmission\noverheard and message delay are more efficient than other related schemes in\nauthentication, transmission and communication.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 07:32:50 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Han", "Mu", ""], ["Hua", "Lei", ""], ["Ma", "Shidian", ""]]}, {"id": "1611.09261", "submitter": "Mohit Narayan Rajput", "authors": "Mohit Rajput, Maroti Deshmukh", "title": "A Technique to Share Multiple Secret Images", "comments": "10 pages, 3 figures", "journal-ref": "International Journal of Information Processing, 10(3), 35-44,\n  2016 ISSN : 0973-8215 IK International Publishing House Pvt. Ltd., New Delhi,\n  India", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Cryptography comes under cryptography domain. It deals with encrypting\nand decrypting of visual information like pictures, texts, videos $ etc.$ Multi\nSecret Image Sharing (MSIS) scheme is a part of visual cryptography that\nprovides a protected method to transmit more than one secret images over a\ncommunication channel. Conventionally, transmission of a single secret image is\npossible over a channel at a time. But as technology grows, there emerge a need\nfor sharing more than one secret image. An $(n, n)$-MSIS scheme is used to\nencrypt $n$ secret images into $n$ meaningless noisy images that are stored\nover different servers. To recover $n$ secret images all $n$ noisy images are\nrequired. At earlier time, the main problem with secret sharing schemes was\nthat attacker can partially figure out secret images, even by getting access of\n$n-1$ or fewer noisy images. To tackle with this security issue, there arises a\nneed of secure MSIS scheme, so that attacker can not retrieve any information\nby using less than $n-1$ noisy images. In this paper, we propose a secure $(n,\nn+1)$-MSIS scheme using additive modulo operation for grayscale and colored\nimages. For checking the effectiveness of proposed scheme; Correlation, MSE and\nPSNR techniques are used. The experimental results show that the proposed\nscheme is highly secured and altering of noisy images will not reveal any\npartial information about secret images. The proposed $(n, n+1)$-MSIS scheme\noutperforms the existing MSIS schemes in terms of security.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 17:51:49 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Rajput", "Mohit", ""], ["Deshmukh", "Maroti", ""]]}, {"id": "1611.09332", "submitter": "Alessandro Preziosi", "authors": "Alessandro Preziosi, Diana Berbecaru", "title": "Cryptographically verifiable anonymous voting using pan-european e-IDs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper we explore a method to create anonymous services on top of the\nSTORK framework, to be used for electronic surveys or elections.\n  The STORK project aims to realize a single electronic identification and\nauthentication area across Europe. For verifiable and anonymous voting, users\nshould be authenticated with their e-id (to prevent repeated voting) but the\nvotes should also be anonymous. This is achieved using blind signatures and an\nonion routing system similar to the one used in TOR.\n  In the paper we describe the anonymous voting protocol in detail, we analyze\na reference implementation and, finally, we highlight potential weaknesses and\npropose some improvements.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 20:37:08 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Preziosi", "Alessandro", ""], ["Berbecaru", "Diana", ""]]}, {"id": "1611.09418", "submitter": "Tao Lu", "authors": "Hongrui Wang and Tao Lu and Xiaodai Dong and Peixue Li and Michael Xie", "title": "Hierarchical Online Intrusion Detection for SCADA Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel hierarchical online intrusion detection system (HOIDS) for\nsupervisory control and data acquisition (SCADA) networks based on machine\nlearning algorithms. By utilizing the server-client topology while keeping\nclients distributed for global protection, high detection rate is achieved with\nminimum network impact. We implement accurate models of normal-abnormal binary\ndetection and multi-attack identification based on logistic regression and\nquasi-Newton optimization algorithm using the Broyden-Fletcher-Goldfarb-Shanno\napproach. The detection system is capable of accelerating detection by\ninformation gain based feature selection or principle component analysis based\ndimension reduction. By evaluating our system using the KDD99 dataset and the\nindustrial control system dataset, we demonstrate that HOIDS is highly\nscalable, efficient and cost effective for securing SCADA infrastructures.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 22:54:48 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Wang", "Hongrui", ""], ["Lu", "Tao", ""], ["Dong", "Xiaodai", ""], ["Li", "Peixue", ""], ["Xie", "Michael", ""]]}, {"id": "1611.09564", "submitter": "Nhien-An Le-Khac", "authors": "Muhammad Faheem, M-Tahar Kechadi, Nhien-An Le-Khac", "title": "Toward a new mobile cloud forensic framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphones have created a significant impact on the day to day activities of\nevery individual. Now a days a wide range of Smartphone applications are\navailable and it necessitates high computing resources in order to build these\napplications. Cloud computing offers enormous resources and extends services to\nresource-constrained mobile devices. Mobile Cloud Computing is emerging as a\nkey technology to utilize virtually unlimited resources over the Internet using\nSmartphones. Offloading data and computations to improve productivity, enhance\nperformance, save energy, and improve user experience. Social network\napplications largely utilize Mobile Cloud Computing to reap the benefits. The\nsocial network has witnessed unprecedented growth in the recent years, and\nmillions of registered users access it using Smartphones. The mobile cloud\nsocial network applications introduce not only convenience but also various\nissues related to criminal and illegal activities. Despite being primarily used\nto communicate and socialize with contacts, the multifarious and anonymous\nnature of social networking websites increases susceptibility to cybercrimes.\nTaking into account, the advantage of mobile cloud computing and popularity of\nsocial network applications, it is essential to establish a forensic framework\nbased on mobile cloud platform that solves the problems of today forensic\nrequirements. In this paper we present a mobile cloud forensic framework that\nallows the forensic investigator to collect the automated synchronized copies\nof data on both mobile and cloud servers to prove the evidence of cloud usage.\nWe also show our preliminary results of this study.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 10:53:29 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Faheem", "Muhammad", ""], ["Kechadi", "M-Tahar", ""], ["Le-Khac", "Nhien-An", ""]]}, {"id": "1611.09566", "submitter": "Nhien-An Le-Khac", "authors": "Muhammad Faheem, M-Tahar Kechadi, Nhien-An Le-Khac", "title": "The State of the Art Forensic Techniques in Mobile Cloud Environment: A\n  Survey, Challenges and Current Trends", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphones have become popular in recent days due to the accessibility of a\nwide range of applications. These sophisticated applications demand more\ncomputing resources in a resource constraint smartphone. Cloud computing is the\nmotivating factor for the progress of these applications. The emerging mobile\ncloud computing introduces a new architecture to offload smartphone and utilize\ncloud computing technology to solve resource requirements. The popularity of\nmobile cloud computing is an opportunity for misuse and unlawful activities.\nTherefore, it is a challenging platform for digital forensic investigations due\nto the non-availability of methodologies, tools and techniques. The aim of this\nwork is to analyze the forensic tools and methodologies for crime investigation\nin a mobile cloud platform as it poses challenges in proving the evidence. The\nadvancement of forensic tools and methodologies are much slower than the\ncurrent technology development in mobile cloud computing. Thus, forces the\navailable tools, and techniques become increasingly obsolete. Therefore, it\nopens up the door for the new forensic tools and techniques to cope up with\nrecent developments. Hence, this work presents a detailed survey of forensic\nmethodology and corresponding issues in a mobile device, cloud environment, and\nmobile cloud applications. It mainly focuses on digital forensic issues related\nto mobile cloud applications and also analyze the scope, challenges and\nopportunities. Finally, this work reviewed the forensic procedures of two cloud\nstorage services used for mobile cloud applications such as Dropbox and\nSkyDrive.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 11:00:09 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Faheem", "Muhammad", ""], ["Kechadi", "M-Tahar", ""], ["Le-Khac", "Nhien-An", ""]]}, {"id": "1611.09983", "submitter": "Michele Nogueira", "authors": "Michele Nogueira", "title": "Anticipating Moves to Prevent Botnet Generated DDoS Flooding Attacks", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Volumetric Distributed Denial of Service (DDoS) attacks have been a recurrent\nissue on the Internet. These attacks generate a flooding of fake network\ntraffic to interfere with targeted servers or network links. Despite many\nefforts to detect and mitigate them, attackers have played a game always\ncircumventing countermeasures. Today, there is an increase in the number of\ninfected devices, even more with the advent of the Internet of Things and\nflexible communication technologies. Leveraging device-to-device short range\nwireless communications and others, infected devices can coordinate\nsophisticated botnets, which can be employed to intensify DDoS attacks. The new\ngeneration of botnets is even harder to detect because of their adaptive and\ndynamic behavior yielded by infected mobile portable devices. Additionally,\nbecause there can be a large number of geographically distributed devices,\nbotnets increase DDoS traffic significantly. In face of their new behavior and\nthe increasing volume of DDoS traffic, novel and intelligent-driven approaches\nare required. Specifically, we advocate for {\\em anticipating} trends of DDoS\nattacks in the early stages as much as possible. This work provides an overview\nof approaches that can be employed to anticipate trends of DDoS attacks\ngenerated by botnets in their early stages and brings an insightful discussion\nabout the advantages of each kind of approach and open issues.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 03:07:53 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Nogueira", "Michele", ""]]}, {"id": "1611.10076", "submitter": "Shweta Bhandari", "authors": "Shweta Bhandari, Wafa Ben Jaballah, Vineeta Jain, Vijay Laxmi, Akka\n  Zemmari, Manoj Singh Gaur, Mohamed Mosbah, Mauro Conti", "title": "Android Inter-App Communication Threats and Detection Techniques", "comments": "83 pages, 4 figures, This is a survey paper", "journal-ref": "computers & security 70 (2017) 392-421", "doi": "10.1016/j.cose.2017.07.002", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the digital breakthrough, smart phones have become very essential\ncomponent. Mobile devices are very attractive attack surface for cyber thieves\nas they hold personal details (accounts, locations, contacts, photos) and have\npotential capabilities for eavesdropping (with cameras/microphone, wireless\nconnections). Android, being the most popular, is the target of malicious\nhackers who are trying to use Android app as a tool to break into and control\ndevice. Android malware authors use many anti-analysis techniques to hide from\nanalysis tools. Academic researchers and commercial anti-malware companies are\nputting great effort to detect such malicious apps. They are making use of the\ncombinations of static, dynamic and behavior based analysis techniques. Despite\nof all the security mechanisms provided by Android, apps can carry out\nmalicious actions through collusion. In collusion malicious functionality is\ndivided across multiple apps. Each participating app accomplish its part and\ncommunicate information to another app through Inter Component Communication\n(ICC). ICC do not require any special permissions. Also, there is no compulsion\nto inform user about the communication. Each participating app needs to request\na minimal set of privileges, which may make it appear benign to current\nstate-of-the-art techniques that analyze one app at a time. There are many\nsurveys on app analysis techniques in Android; however they focus on single-app\nanalysis. This survey augments this through focusing only on collusion among\nmultiple-apps. In this paper, we present Android vulnerabilities that may be\nexploited for a possible collusion attack. We cover the existing threat\nanalysis, scenarios, and a detailed comparison of tools for intra and inter-app\nanalysis. To the best of our knowledge this is the first survey on app\ncollusion and state-of-the-art detection tools in Android.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 10:13:50 GMT"}, {"version": "v2", "created": "Thu, 21 Sep 2017 12:31:24 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Bhandari", "Shweta", ""], ["Jaballah", "Wafa Ben", ""], ["Jain", "Vineeta", ""], ["Laxmi", "Vijay", ""], ["Zemmari", "Akka", ""], ["Gaur", "Manoj Singh", ""], ["Mosbah", "Mohamed", ""], ["Conti", "Mauro", ""]]}, {"id": "1611.10087", "submitter": "Martin Plesch", "authors": "Martin Plesch, Marcin Pawlowski, and Matej Pivoluska", "title": "1-out-of-2 Oblivious transfer using flawed Bit-string quantum protocol", "comments": "7 pages", "journal-ref": "PRA 95, 042324 (2017)", "doi": "10.1103/PhysRevA.95.042324", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Oblivious transfer (OT) is an important tool in cryptography. It serves as a\nsubroutine to other complex procedures of both theoretical and practical\nsignificance. Common attribute of OT protocols is that one party (Alice) has to\nsend a message to another party (Bob) and has to stay oblivious on whether Bob\ndid receive the message. Specific (OT) protocols vary by exact definition of\nthe task - in the all-or-nothing protocol Alice sends a single bit-string\nmessage, which Bob is able to read only with 50% probability, whereas in\n1-out-of-2 OT protocol Bob reads one out of two messages sent by Alice. These\ntwo flavours of protocol are known to be equivalent. Recently a computationally\nsecure all-or-nothing OT protocol based on quantum states was developed in [A.\nSouto et. al., PRA 91, 042306], which however cannot be reduced to 1-out-of-2\nOT protocol by standard means. Here we present an elaborated reduction of this\nprotocol which retains the security of the original.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 10:56:54 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Plesch", "Martin", ""], ["Pawlowski", "Marcin", ""], ["Pivoluska", "Matej", ""]]}, {"id": "1611.10107", "submitter": "Joseph Fitzsimons", "authors": "Joseph F. Fitzsimons", "title": "Private quantum computation: An introduction to blind quantum computing\n  and related protocols", "comments": "14 pages, 8 figures. Comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum technologies hold the promise of not only faster algorithmic\nprocessing of data, via quantum computation, but also of more secure\ncommunications, in the form of quantum cryptography. In recent years, a number\nof protocols have emerged which seek to marry these concepts for the purpose of\nsecuring computation rather than communication. These protocols address the\ntask of securely delegating quantum computation to an untrusted device while\nmaintaining the privacy, and in some instances the integrity, of the\ncomputation. We present a review of the progress to date in this emerging area.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 12:00:33 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Fitzsimons", "Joseph F.", ""]]}, {"id": "1611.10181", "submitter": "Stefan Wagner", "authors": "Stefan Wagner", "title": "A Bayesian Network Approach to Assess and Predict Software Quality Using\n  Activity-Based Quality Models", "comments": "32 pages, 6 figures", "journal-ref": "Information and Software Technology, Volume 52, Issue 11, November\n  2010, Pages 1230-1241", "doi": "10.1016/j.infsof.2010.03.016", "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context: Software quality is a complex concept. Therefore, assessing and\npredicting it is still challenging in practice as well as in research.\nActivity-based quality models break down this complex concept into concrete\ndefinitions, more precisely facts about the system, process, and environment as\nwell as their impact on activities performed on and with the system. However,\nthese models lack an operationalisation that would allow them to be used in\nassessment and prediction of quality. Bayesian networks have been shown to be a\nviable means for this task incorporating variables with uncertainty. Objective:\nThe qualitative knowledge contained in activity-based quality models are an\nabundant basis for building Bayesian networks for quality assessment. This\npaper describes a four-step approach for deriving systematically a Bayesian\nnetwork from an assessment goal and a quality model. Method: The four steps of\nthe approach are explained in detail and with running examples. Furthermore, an\ninitial evaluation is performed, in which data from NASA projects and an open\nsource system is obtained. The approach is applied to this data and its\napplicability is analysed. Results: The approach is applicable to the data from\nthe NASA projects and the open source system. However, the predictive results\nvary depending on the availability and quality of the data, especially the\nunderlying general distributions. Conclusion: The approach is viable in a\nrealistic context but needs further investigation in case studies in order to\nanalyse its predictive validity.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 14:38:59 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Wagner", "Stefan", ""]]}, {"id": "1611.10231", "submitter": "Hossien Fereidooni", "authors": "Parvez Faruki (Malaviya National Institute of Technology Jaipur,\n  India) and Hossein Fereidooni (University of Padua, Italy) and Vijay Laxmi\n  (Malaviya National Institute of Technology Jaipur, India) and Mauro Conti\n  (University of Padua, Italy), Manoj Gaur (Malaviya National Institute of\n  Technology Jaipur, India)", "title": "Android Code Protection via Obfuscation Techniques: Past, Present and\n  Future Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile devices have become ubiquitous due to centralization of private user\ninformation, contacts, messages and multiple sensors. Google Android, an\nopen-source mobile Operating System (OS), is currently the market leader.\nAndroid popularity has motivated the malware authors to employ set of cyber\nattacks leveraging code obfuscation techniques. Obfuscation is an action that\nmodifies an application (app) code, preserving the original semantics and\nfunctionality to evade anti-malware. Code obfuscation is a contentious issue.\nTheoretical code analysis techniques indicate that, attaining a verifiable and\nsecure obfuscation is impossible. However, obfuscation tools and techniques are\npopular both among malware developers (to evade anti-malware) and commercial\nsoftware developers (protect intellectual rights). We conducted a survey to\nuncover answers to concrete and relevant questions concerning Android code\nobfuscation and protection techniques. The purpose of this paper is to review\ncode obfuscation and code protection practices, and evaluate efficacy of\nexisting code de-obfuscation tools. In particular, we discuss Android code\nobfuscation methods, custom app protection techniques, and various\nde-obfuscation methods. Furthermore, we review and analyse the obfuscation\ntechniques used by malware authors to evade analysis efforts. We believe that,\nthere is a need to investigate efficiency of the defense techniques used for\ncode protection. This survey would be beneficial to the researchers and\npractitioners, to understand obfuscation and de-obfuscation techniques to\npropose novel solutions on Android.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 15:46:00 GMT"}], "update_date": "2018-08-19", "authors_parsed": [["Faruki", "Parvez", "", "Malaviya National Institute of Technology Jaipur,\n  India"], ["Fereidooni", "Hossein", "", "University of Padua, Italy"], ["Laxmi", "Vijay", "", "Malaviya National Institute of Technology Jaipur, India"], ["Conti", "Mauro", "", "University of Padua, Italy"], ["Gaur", "Manoj", "", "Malaviya National Institute of\n  Technology Jaipur, India"]]}]