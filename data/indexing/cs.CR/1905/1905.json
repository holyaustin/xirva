[{"id": "1905.00062", "submitter": "Xian-Min Jin", "authors": "Xiao-Ling Pang, Lu-Feng Qiao, Ke Sun, Yu Liu, Ai-Lin Yang, Xian-Min\n  Jin", "title": "Experimental Quantum-enhanced Cryptographic Remote Control", "comments": "7 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT), as a cutting-edge integrated cross-technology,\npromises to informationize people's daily lives, while being threatened by\ncontinuous challenges of eavesdropping and tampering. The emerging quantum\ncryptography, harnessing the random nature of quantum mechanics, may also\nenable unconditionally secure control network, beyond the applications in\nsecure communications. Here, we present a quantum-enhanced cryptographic remote\ncontrol scheme that combines quantum randomness and one-time pad algorithm for\ndelivering commands remotely. We experimentally demonstrate this on an unmanned\naircraft vehicle (UAV) control system. We precharge quantum random number (QRN)\ninto controller and controlee before launching UAV, instead of distributing QRN\nlike standard quantum communication during flight. We statistically verify the\nrandomness of both quantum keys and the converted ciphertexts to check the\nsecurity capability. All commands in the air are found to be completely chaotic\nafter encryption, and only matched keys on UAV can decipher those commands\nprecisely. In addition, the controlee does not response to the commands that\nare not or incorrectly encrypted, showing the immunity against interference and\ndecoy. Our work adds true randomness and quantum enhancement into the realm of\nsecure control algorithm in a straightforward and practical fashion, providing\na promoted solution for the security of artificial intelligence and IoT.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 19:00:02 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Pang", "Xiao-Ling", ""], ["Qiao", "Lu-Feng", ""], ["Sun", "Ke", ""], ["Liu", "Yu", ""], ["Yang", "Ai-Lin", ""], ["Jin", "Xian-Min", ""]]}, {"id": "1905.00122", "submitter": "Li Chen", "authors": "Li Chen, Carter Yagemann, Evan Downing", "title": "To believe or not to believe: Validating explanation fidelity for\n  dynamic malware analysis", "comments": "Accepted at the IEEE Computer Vision Pattern Recognition 2019\n  Explainable AI Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Converting malware into images followed by vision-based deep learning\nalgorithms has shown superior threat detection efficacy compared with classical\nmachine learning algorithms. When malware are visualized as images,\nvisual-based interpretation schemes can also be applied to extract insights of\nwhy individual samples are classified as malicious. In this work, via two case\nstudies of dynamic malware classification, we extend the local interpretable\nmodel-agnostic explanation algorithm to explain image-based dynamic malware\nclassification and examine its interpretation fidelity. For both case studies,\nwe first train deep learning models via transfer learning on malware images,\ndemonstrate high classification effectiveness, apply an explanation method on\nthe images, and correlate the results back to the samples to validate whether\nthe algorithmic insights are consistent with security domain expertise. In our\nfirst case study, the interpretation framework identifies indirect calls that\nuniquely characterize the underlying exploit behavior of a malware family. In\nour second case study, the interpretation framework extracts insightful\ninformation such as cryptography-related APIs when applied on images created\nfrom API existence, but generate ambiguous interpretation on images created\nfrom API sequences and frequencies. Our findings indicate that current\nimage-based interpretation techniques are promising for explaining vision-based\nmalware classification. We continue to develop image-based interpretation\nschemes specifically for security applications.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 22:45:30 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Chen", "Li", ""], ["Yagemann", "Carter", ""], ["Downing", "Evan", ""]]}, {"id": "1905.00150", "submitter": "Zhixiong Chen", "authors": "Zhixiong Chen and Andrew Klapper", "title": "On $q$-nearly bent Boolean functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For each non-constant Boolean function $q$, Klapper introduced the notion of\n$q$-transforms of Boolean functions. The {\\em $q$-transform} of a Boolean\nfunction $f$ is related to the Hamming distances from $f$ to the functions\nobtainable from $q$ by nonsingular linear change of basis.\n  In this work we discuss the existence of $q$-nearly bent functions, a new\nfamily of Boolean functions characterized by the $q$-transform. Let $q$ be a\nnon-affine Boolean function. We prove that any balanced Boolean functions\n(linear or non-linear) are $q$-nearly bent if $q$ has weight one, which gives a\npositive answer to an open question (whether there exist non-affine $q$-nearly\nbent functions) proposed by Klapper. We also prove a necessary condition for\nchecking when a function isn't $q$-nearly bent.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 01:09:16 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Chen", "Zhixiong", ""], ["Klapper", "Andrew", ""]]}, {"id": "1905.00154", "submitter": "Saeed Valizadeh", "authors": "Saeed Valizadeh and Marten van Dijk", "title": "On the Convergence Rates of Learning-based Signature Generation Schemes\n  to Contain Self-propagating Malware", "comments": "This work was funded by NSF grant CNS-1413996 \"MACS: A Modular\n  Approach to Cloud Security.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the importance of a defense system's learning\nrates to fight against the self-propagating class of malware such as worms and\nbots. To this end, we introduce a new propagation model based on the\ninteractions between an adversary (and its agents) who wishes to construct a\nzombie army of a specific size, and a defender taking advantage of standard\nsecurity tools and technologies such as honeypots (HPs) and intrusion detection\nand prevention systems (IDPSes) in the network environment. As time goes on,\nthe defender can incrementally learn from the collected/observed attack samples\n(e.g., malware payloads), and therefore being able to generate attack\nsignatures. The generated signatures then are used for filtering next attack\ntraffic and thus containing the attacker's progress in its malware propagation\nmission. Using simulation and numerical analysis, we evaluate the efficacy of\nsignature generation algorithms and in general any learning-based scheme in\nbringing an adversary's maneuvering in the environment to a halt as an\nadversarial containment strategy.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 01:19:32 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Valizadeh", "Saeed", ""], ["van Dijk", "Marten", ""]]}, {"id": "1905.00191", "submitter": "Vasyl Pihur", "authors": "Vasyl Pihur", "title": "The Podium Mechanism: Improving on the Laplace and Staircase Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Podium mechanism guarantees ($\\epsilon, 0$)-differential privacy by\nsampling noise from a \\emph{finite} mixture of three uniform distributions. By\ncarefully constructing such a mixture distribution, we trivially guarantee\nprivacy properties, while minimizing the variance of the noise added to our\ncontinuous outcome. Our gains in variance control are due to the \"truncated\"\nnature of the Podium mechanism where support for the noise distribution is\nmaintained as close as possible to the sensitivity of our data collection,\nunlike the \\emph{infinite} support that characterizes both the Laplace and\nStaircase mechanisms. In a high-privacy regime ($\\epsilon < 1$), the Podium\nmechanism outperforms the other two by 50-70\\% in terms of the noise variance\nreduction, while in a low privacy regime ($\\epsilon \\to \\infty$), it\nasymptotically approaches the Staircase mechanism.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 05:33:20 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 18:18:04 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Pihur", "Vasyl", ""]]}, {"id": "1905.00265", "submitter": "Anis Koubaa", "authors": "Azza Allouch, Omar Cheikhrouhou, Anis Koubaa, Mohamed Khalgui, Tarek\n  Abbes", "title": "MAVSec: Securing the MAVLink Protocol for Ardupilot/PX4 Unmanned Aerial\n  Systems", "comments": "The paper is accepted in the International Wireless Communications\n  and Mobile Computing Conference (IWCMC) in Morocco, June 2019", "journal-ref": "in the International Wireless Communications and Mobile Computing\n  Conference (IWCMC) in Morocco, June 2019", "doi": null, "report-no": "RIOTU-TR06", "categories": "cs.CR cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The MAVLink is a lightweight communication protocol between Unmanned Aerial\nVehicles (UAVs) and ground control stations (GCSs). It defines a set of\nbi-directional messages exchanged between a UAV (aka drone) and a ground\nstation. The messages carry out information about the UAV's states and control\ncommands sent from the ground station. However, the MAVLink protocol is not\nsecure and has several vulnerabilities to different attacks that result in\ncritical threats and safety concerns. Very few studies provided solutions to\nthis problem. In this paper, we discuss the security vulnerabilities of the\nMAVLink protocol and propose MAVSec, a security-integrated mechanism for\nMAVLink that leverages the use of encryption algorithms to ensure the\nprotection of exchanged MAVLink messages between UAVs and GCSs. To validate\nMAVSec, we implemented it in Ardupilot and evaluated the performance of\ndifferent encryption algorithms (i.e. AES-CBC, AES-CTR, RC4, and ChaCha20) in\nterms of memory usage and CPU consumption. The experimental results show that\nChaCha20 has a better performance and is more efficient than other encryption\nalgorithms. Integrating ChaCha20 into MAVLink can guarantee its messages\nconfidentiality, without affecting its performance, while occupying less memory\nand CPU consumption, thus, preserving memory and saving the battery for the\nresource-constrained drone.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 11:17:36 GMT"}, {"version": "v2", "created": "Sat, 4 May 2019 20:45:09 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Allouch", "Azza", ""], ["Cheikhrouhou", "Omar", ""], ["Koubaa", "Anis", ""], ["Khalgui", "Mohamed", ""], ["Abbes", "Tarek", ""]]}, {"id": "1905.00272", "submitter": "Ningyu He", "authors": "Ningyu He, Lei Wu, Haoyu Wang, Yao Guo, Xuxian Jiang", "title": "Characterizing Code Clones in the Ethereum Smart Contract Ecosystem", "comments": "20 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the first large-scale and systematic study to\ncharacterize the code reuse practice in the Ethereum smart contract ecosystem.\nWe first performed a detailed similarity comparison study on a dataset of 10\nmillion contracts we had harvested, and then we further conducted a qualitative\nanalysis to characterize the diversity of the ecosystem, understand the\ncorrelation between code reuse and vulnerabilities, and detect the plagiarist\nDApps. Our analysis revealed that over 96% of the contracts had duplicates,\nwhile a large number of them were similar, which suggests that the ecosystem is\nhighly homogeneous. Our results also suggested that roughly 9.7% of the similar\ncontract pairs have exactly the same vulnerabilities, which we assume were\nintroduced by code clones. In addition, we identified 41 DApps clusters,\ninvolving 73 plagiarized DApps which had caused huge financial loss to the\noriginal creators, accounting for 1/3 of the original market volume.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 11:35:13 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["He", "Ningyu", ""], ["Wu", "Lei", ""], ["Wang", "Haoyu", ""], ["Guo", "Yao", ""], ["Jiang", "Xuxian", ""]]}, {"id": "1905.00299", "submitter": "Kaushik Sarker", "authors": "Kaushik Sarker, Hasibur Rahman, Khandaker Farzana Rahman, Md. Shohel\n  Arman, Saikat Biswas, Touhid Bhuiyan", "title": "A Comparative Analysis of the Cyber Security Strategy of Bangladesh", "comments": null, "journal-ref": null, "doi": "10.5121/ijci.2019.8201", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technology is an endless evolving expression in modern era, which increased\nsecurity concerns and pushed us to create cyber environment. A National Cyber\nSecurity Strategy (NCSS) of a country reflects the state of that country's\ncyber strength which represents the aim and vision of the cyber security of a\ncountry. Formerly, researchers have worked on NCSS by comparing NCSS between\ndifferent nations for international collaboration and harmonization and some\nresearchers worked on policy framework for their respective governments.\nHowever very insignificant attempts had been made to assess the strategic\nstrength of NCSS of Bangladesh by performing cross comparisons on NCSS of\ndifferent Nations. Therefore, the motive of this research is to evaluate the\nrobustness of the existing cyber security strategy of Bangladesh in comparison\nwith some of the most technologically advanced countries in Asian continent and\nothers like USA, Japan, Singapore, Malaysia and India in order to keep the NCSS\nof Bangladesh up-to-date.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 13:04:57 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Sarker", "Kaushik", ""], ["Rahman", "Hasibur", ""], ["Rahman", "Khandaker Farzana", ""], ["Arman", "Md. Shohel", ""], ["Biswas", "Saikat", ""], ["Bhuiyan", "Touhid", ""]]}, {"id": "1905.00304", "submitter": "Emmanouil Vasilomanolakis", "authors": "Carlos Garcia Cordero, Emmanouil Vasilomanolakis, Aidmar Wainakh, Max\n  M\\\"uhlh\\\"auser, Simin Nadjm-Tehrani", "title": "On generating network traffic datasets with synthetic attacks for\n  intrusion detection", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most research in the area of intrusion detection requires datasets to\ndevelop, evaluate or compare systems in one way or another. In this field,\nhowever, finding suitable datasets is a challenge on to itself. Most publicly\navailable datasets have negative qualities that limit their usefulness. In this\narticle, we propose ID2T (Intrusion Detection Dataset Toolkit) to tackle this\nproblem. ID2T facilitates the creation of labeled datasets by injecting\nsynthetic attacks into background traffic. The injected synthetic attacks blend\nthemselves with the background traffic by mimicking the background traffic's\nproperties to eliminate any trace of ID2T's usage.\n  This work has three core contribution areas. First, we present a\ncomprehensive survey on intrusion detection datasets. In the survey, we propose\na classification to group the negative qualities we found in the datasets.\nSecond, the architecture of ID2T is revised, improved and expanded. The\narchitectural changes enable ID2T to inject recent and advanced attacks such as\nthe widespread EternalBlue exploit or botnet communication patterns. The\ntoolkit's new functionality provides a set of tests, known as TIDED (Testing\nIntrusion Detection Datasets), that help identify potential defects in the\nbackground traffic into which attacks are injected. Third, we illustrate how\nID2T is used in different use-case scenarios to evaluate the performance of\nanomaly and signature-based intrusion detection systems in a reproducible\nmanner. ID2T is open source software and is made available to the community to\nexpand its arsenal of attacks and capabilities.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 13:21:10 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Cordero", "Carlos Garcia", ""], ["Vasilomanolakis", "Emmanouil", ""], ["Wainakh", "Aidmar", ""], ["M\u00fchlh\u00e4user", "Max", ""], ["Nadjm-Tehrani", "Simin", ""]]}, {"id": "1905.00325", "submitter": "Florian Kamm\\\"uller", "authors": "Florian Kamm\\\"uller", "title": "QKD in Isabelle -- Bayesian Calculation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a first step towards a formalisation of the Quantum\nKey Distribution algorithm in Isabelle. We focus on the formalisation of the\nmain probabilistic argument why Bob cannot be certain about the key bit sent by\nAlice before he does not have the chance to compare the chosen polarization\nscheme. This means that any adversary Eve is in the same position as Bob and\ncannot be certain about the transmitted keybits. We introduce the necessary\nbasic probability theory, present a graphical depiction of the protocol steps\nand their probabilities, and finally how this is translated into a formal proof\nof the security argument.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 14:27:16 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Kamm\u00fcller", "Florian", ""]]}, {"id": "1905.00441", "submitter": "Yandong Li", "authors": "Yandong Li, Lijun Li, Liqiang Wang, Tong Zhang, Boqing Gong", "title": "NATTACK: Learning the Distributions of Adversarial Examples for an\n  Improved Black-Box Attack on Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Powerful adversarial attack methods are vital for understanding how to\nconstruct robust deep neural networks (DNNs) and for thoroughly testing defense\ntechniques. In this paper, we propose a black-box adversarial attack algorithm\nthat can defeat both vanilla DNNs and those generated by various defense\ntechniques developed recently. Instead of searching for an \"optimal\"\nadversarial example for a benign input to a targeted DNN, our algorithm finds a\nprobability density distribution over a small region centered around the input,\nsuch that a sample drawn from this distribution is likely an adversarial\nexample, without the need of accessing the DNN's internal layers or weights.\nOur approach is universal as it can successfully attack different neural\nnetworks by a single algorithm. It is also strong; according to the testing\nagainst 2 vanilla DNNs and 13 defended ones, it outperforms state-of-the-art\nblack-box or white-box attack methods for most test cases. Additionally, our\nresults reveal that adversarial training remains one of the best defense\ntechniques, and the adversarial examples are not as transferable across\ndefended DNNs as them across vanilla DNNs.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 18:20:09 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 18:26:21 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 19:18:49 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Li", "Yandong", ""], ["Li", "Lijun", ""], ["Wang", "Liqiang", ""], ["Zhang", "Tong", ""], ["Gong", "Boqing", ""]]}, {"id": "1905.00553", "submitter": "Renlord Yang", "authors": "Renlord Yang, Toby Murray, Paul Rimba, Udaya Parampalli", "title": "Empirically Analyzing Ethereum's Gas Mechanism", "comments": "Accepted at IEEE S&B 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ethereum's Gas mechanism attempts to set transaction fees in accordance with\nthe computational cost of transaction execution: a cost borne by default by\nevery node on the network to ensure correct smart contract execution. Gas\nencourages users to author transactions that are efficient to execute and in so\ndoing encourages node diversity, allowing modestly resourced nodes to join and\ncontribute to the security of the network.\n  However, the effectiveness of this scheme relies on Gas costs being correctly\naligned with observed computational costs in reality. In this work, we\nperformed the first large scale empirical study to understand to what degree\nthis alignment exists in practice, by collecting and analyzing Tera-bytes worth\nof nanosecond-precision transaction execution traces. Besides confirming\npotential denial-of-service vectors, our results also shed light on the role of\nI/O in transaction costs which remains poorly captured by the current Gas cost\nmodel. Finally, our results suggest that under the current Gas cost model,\nnodes with modest computational resources are disadvantaged compared to their\nbetter resourced peers, which we identify as an ongoing threat to node\ndiversity and network decentralization.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 02:28:06 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Yang", "Renlord", ""], ["Murray", "Toby", ""], ["Rimba", "Paul", ""], ["Parampalli", "Udaya", ""]]}, {"id": "1905.00631", "submitter": "Jiska Classen", "authors": "Dennis Mantz, Jiska Classen, Matthias Schulz, Matthias Hollick", "title": "InternalBlue - Bluetooth Binary Patching and Experimentation Framework", "comments": null, "journal-ref": null, "doi": "10.1145/3307334.3326089", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bluetooth is one of the most established technologies for short range digital\nwireless data transmission. With the advent of wearables and the Internet of\nThings (IoT), Bluetooth has again gained importance, which makes security\nresearch and protocol optimizations imperative. Surprisingly, there is a lack\nof openly available tools and experimental platforms to scrutinize Bluetooth.\nIn particular, system aspects and close to hardware protocol layers are mostly\nuncovered.\n  We reverse engineer multiple Broadcom Bluetooth chipsets that are widespread\nin off-the-shelf devices. Thus, we offer deep insights into the internal\narchitecture of a popular commercial family of Bluetooth controllers used in\nsmartphones, wearables, and IoT platforms. Reverse engineered functions can\nthen be altered with our InternalBlue Python framework---outperforming\nevaluation kits, which are limited to documented and vendor-defined functions.\nThe modified Bluetooth stack remains fully functional and high-performance.\nHence, it provides a portable low-cost research platform.\n  InternalBlue is a versatile framework and we demonstrate its abilities by\nimplementing tests and demos for known Bluetooth vulnerabilities. Moreover, we\ndiscover a novel critical security issue affecting a large selection of\nBroadcom chipsets that allows executing code within the attacked Bluetooth\nfirmware. We further show how to use our framework to fix bugs in chipsets out\nof vendor support and how to add new security features to Bluetooth firmware.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 09:14:37 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Mantz", "Dennis", ""], ["Classen", "Jiska", ""], ["Schulz", "Matthias", ""], ["Hollick", "Matthias", ""]]}, {"id": "1905.00650", "submitter": "Damien Desfontaines", "authors": "Damien Desfontaines, Esfandiar Mohammadi, Elisabeth Krahmer, David\n  Basin", "title": "Differential privacy with partial knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Differential privacy offers formal quantitative guarantees for algorithms\nover datasets, but it assumes attackers that know and can influence all but one\nrecord in the database. This assumption often vastly overapproximates the\nattackers' actual strength, resulting in unnecessarily poor utility.\n  Recent work has made significant steps towards privacy in the presence of\npartial background knowledge, which can model a realistic attacker's\nuncertainty. Prior work, however, has definitional problems for correlated data\nand does not precisely characterize the underlying attacker model. We propose a\npractical criterion to prevent problems due to correlations, and we show how to\ncharacterize attackers with limited influence or only partial background\nknowledge over the dataset. We use these foundations to analyze practical\nscenarios: we significantly improve known results about the privacy of counting\nqueries under partial knowledge, and we show that thresholding can provide\nformal guarantees against such weak attackers, even with little entropy in the\ndata. These results allow us to draw novel links between k-anonymity and\ndifferential privacy under partial knowledge. Finally, we prove composition\nresults on differential privacy with partial knowledge, which quantifies the\nprivacy leakage of complex mechanisms.\n  Our work provides a basis for formally quantifying the privacy of many\nwidely-used mechanisms, e.g. publishing the result of surveys, elections or\nreferendums, and releasing usage statistics of online services.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 09:59:55 GMT"}, {"version": "v2", "created": "Sat, 4 May 2019 09:57:49 GMT"}, {"version": "v3", "created": "Fri, 13 Dec 2019 16:56:08 GMT"}, {"version": "v4", "created": "Fri, 31 Jan 2020 09:36:16 GMT"}, {"version": "v5", "created": "Fri, 31 Jul 2020 08:38:34 GMT"}, {"version": "v6", "created": "Fri, 27 Nov 2020 22:20:47 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Desfontaines", "Damien", ""], ["Mohammadi", "Esfandiar", ""], ["Krahmer", "Elisabeth", ""], ["Basin", "David", ""]]}, {"id": "1905.00753", "submitter": "Gang Huang", "authors": "Chao Wu, Jun Xiao, Gang Huang, Fei Wu", "title": "Galaxy Learning -- A Position Paper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent rapid development of artificial intelligence (AI, mainly driven by\nmachine learning research, especially deep learning) has achieved phenomenal\nsuccess in various applications. However, to further apply AI technologies in\nreal-world context, several significant issues regarding the AI ecosystem\nshould be addressed. We identify the main issues as data privacy, ownership,\nand exchange, which are difficult to be solved with the current centralized\nparadigm of machine learning training methodology. As a result, we propose a\nnovel model training paradigm based on blockchain, named Galaxy Learning, which\naims to train a model with distributed data and to reserve the data ownership\nfor their owners. In this new paradigm, encrypted models are moved around\ninstead, and are federated once trained. Model training, as well as the\ncommunication, is achieved with blockchain and its smart contracts. Pricing of\ntraining data is determined by its contribution, and therefore it is not about\nthe exchange of data ownership. In this position paper, we describe the\nmotivation, paradigm, design, and challenges as well as opportunities of Galaxy\nLearning.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 11:05:26 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Wu", "Chao", ""], ["Xiao", "Jun", ""], ["Huang", "Gang", ""], ["Wu", "Fei", ""]]}, {"id": "1905.00799", "submitter": "Xiaotao Feng", "authors": "Xiaotao Feng, Qin Wang, Xiaogang Zhu, Sheng Wen", "title": "Bug Searching in Smart Contract", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the frantic development of smart contracts on the Ethereum platform, its\nmarket value has also climbed. In 2016, people were shocked by the loss of\nnearly $50 million in cryptocurrencies from the DAO reentrancy attack. Due to\nthe tremendous amount of money flowing in smart contracts, its security has\nattracted much attention of researchers. In this paper, we investigated several\ncommon smart contract vulnerabilities and analyzed their possible scenarios and\nhow they may be exploited. Furthermore, we survey the smart contract\nvulnerability detection tools for the Ethereum platform in recent years. We\nfound that these tools have similar prototypes in software vulnerability\ndetection technology. Moreover, for the features of public distribution systems\nsuch as Ethereum, we present the new challenges that these software\nvulnerability detection technologies face.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 15:12:18 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Feng", "Xiaotao", ""], ["Wang", "Qin", ""], ["Zhu", "Xiaogang", ""], ["Wen", "Sheng", ""]]}, {"id": "1905.00919", "submitter": "Mohamed Baza", "authors": "Ahmed Shafee, Mohamed Baza, Douglas A. Talbert, Mostafa M. Fouda,\n  Mahmoud Nabil, Mohamed Mahmoud", "title": "Mimic Learning to Generate a Shareable Network Intrusion Detection Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purveyors of malicious network attacks continue to increase the complexity\nand the sophistication of their techniques, and their ability to evade\ndetection continues to improve as well. Hence, intrusion detection systems must\nalso evolve to meet these increasingly challenging threats. Machine learning is\noften used to support this needed improvement. However, training a good\nprediction model can require a large set of labelled training data. Such\ndatasets are difficult to obtain because privacy concerns prevent the majority\nof intrusion detection agencies from sharing their sensitive data. In this\npaper, we propose the use of mimic learning to enable the transfer of intrusion\ndetection knowledge through a teacher model trained on private data to a\nstudent model. This student model provides a mean of publicly sharing knowledge\nextracted from private data without sharing the data itself. Our results\nconfirm that the proposed scheme can produce a student intrusion detection\nmodel that mimics the teacher model without requiring access to the original\ndataset.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 18:14:24 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 17:39:51 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 20:14:47 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Shafee", "Ahmed", ""], ["Baza", "Mohamed", ""], ["Talbert", "Douglas A.", ""], ["Fouda", "Mostafa M.", ""], ["Nabil", "Mahmoud", ""], ["Mahmoud", "Mohamed", ""]]}, {"id": "1905.00922", "submitter": "Minh Ngo", "authors": "Minh Ngo and David A. Naumann and Tamara Rezk", "title": "Type-based Declassification for Free", "comments": "The short version of this paper is accepted in ICFEM 2020. 100 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work provides a study to demonstrate the potential of using\noff-the-shelf programming languages and their theories to build sound\nlanguage-based-security tools. Our study focuses on information flow security\nencompassing declassification policies that allow us to express flexible\nsecurity policies needed for practical requirements. We translate security\npolicies, with declassification, into an interface for which an unmodified\nstandard typechecker can be applied to a source program---if the program\ntypechecks, it provably satisfies the policy. Our proof reduces security\nsoundness---with declassification---to the mathematical foundation of data\nabstraction, Reynolds' abstraction theorem.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 18:23:08 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 14:17:05 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 17:07:07 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Ngo", "Minh", ""], ["Naumann", "David A.", ""], ["Rezk", "Tamara", ""]]}, {"id": "1905.00964", "submitter": "Sailik Sengupta", "authors": "Sailik Sengupta, Ankur Chowdhary, Abdulhakim Sabur, Adel Alshamrani,\n  Dijiang Huang, Subbarao Kambhampati", "title": "A Survey of Moving Target Defenses for Network Security", "comments": "The first two authors contributed equally", "journal-ref": "IEEE Communications Surveys and Tutorials, 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network defenses based on traditional tools, techniques, and procedures fail\nto account for the attacker's inherent advantage present due to the static\nnature of network services and configurations. To take away this asymmetric\nadvantage, Moving Target Defense (MTD) continuously shifts the configuration of\nthe underlying system, in turn reducing the success rate of cyberattacks. In\nthis survey, we analyze the recent advancements made in the development of MTDs\nand define categorizations that capture the key aspects of such defenses. We\nfirst categorize these defenses into different sub-classes depending on what\nthey move, when they move and how they move. In trying to answer the latter\nquestion, we showcase the use of domain knowledge and game-theoretic modeling\ncan help the defender come up with effective and efficient movement strategies.\nSecond, to understand the practicality of these defense methods, we discuss how\nvarious MTDs have been implemented and find that networking technologies such\nas Software Defined Networking and Network Function Virtualization act as key\nenablers for implementing these dynamic defenses. We then briefly highlight MTD\ntest-beds and case-studies to aid readers who want to examine or deploy\nexisting MTD techniques. Third, our survey categorizes proposed MTDs based on\nthe qualitative and quantitative metrics they utilize to evaluate their\neffectiveness in terms of security and performance. We use well-defined metrics\nsuch as risk analysis and performance costs for qualitative evaluation and\nmetrics based on Confidentiality, Integrity, Availability (CIA), attack\nrepresentation, QoS impact, and targeted threat models for quantitative\nevaluation. Finally, we show that our categorization of MTDs is effective in\nidentifying novel research areas and highlight directions for future research.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 21:06:44 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 00:49:22 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Sengupta", "Sailik", ""], ["Chowdhary", "Ankur", ""], ["Sabur", "Abdulhakim", ""], ["Alshamrani", "Adel", ""], ["Huang", "Dijiang", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1905.01002", "submitter": "Pin-Yu Chen", "authors": "Pin-Yu Chen, Sutanay Choudhury, Luke Rodriguez, Alfred Hero, Indrajit\n  Ray", "title": "Enterprise Cyber Resiliency Against Lateral Movement: A Graph Theoretic\n  Approach", "comments": "Technical report for the book chapter \"Towards Cyber-Resiliency\n  Metrics for Action Recommendations Against Lateral Movement Attacks\" in the\n  book \"Industrial Control Systems Security and Resiliency: Practice and\n  Theory\" published by Springer, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lateral movement attacks are a serious threat to enterprise security. In\nthese attacks, an attacker compromises a trusted user account to get a foothold\ninto the enterprise network and uses it to attack other trusted users,\nincreasingly gaining higher and higher privileges. Such lateral attacks are\nvery hard to model because of the unwitting role that users play in the attack\nand even harder to detect and prevent because of their low and slow nature. In\nthis paper, a theoretical framework is presented for modeling lateral movement\nattacks and for proposing a methodology for designing resilient cyber systems\nagainst such attacks. The enterprise is modeled as a tripartite graph capturing\nthe interaction between users, machines, and applications, and a set of\nprocedures is proposed to harden the network by increasing the cost of lateral\nmovement. Strong theoretical guarantees on system resilience are established\nand experimentally validated for large enterprise networks.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 01:46:39 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Chen", "Pin-Yu", ""], ["Choudhury", "Sutanay", ""], ["Rodriguez", "Luke", ""], ["Hero", "Alfred", ""], ["Ray", "Indrajit", ""]]}, {"id": "1905.01018", "submitter": "Tamara Radivilova A", "authors": "Lyudmyla Kirichenko and Vitalii Bulakh and Tamara Radivilova", "title": "Fractal Time Series Analysis of Social Network Activities", "comments": "4", "journal-ref": "2017 4th International Scientific-Practical Conference Problems of\n  Infocommunications. Science and Technology (PIC S&T), Kharkov, Ukraine, 2017,\n  pp. 456-459", "doi": "10.1109/INFOCOMMST.2017.8246438", "report-no": null, "categories": "q-fin.ST cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the work, a comparative correlation and fractal analysis of time series of\nBitcoin crypto currency rate and community activities in social networks\nassociated with Bitcoin was conducted. A significant correlation between the\nBitcoin rate and the community activities was detected. Time series fractal\nanalysis indicated the presence of self-similar and multifractal properties.\nThe results of researches showed that the series having a strong correlation\ndependence have a similar multifractal structure.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 17:10:20 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Kirichenko", "Lyudmyla", ""], ["Bulakh", "Vitalii", ""], ["Radivilova", "Tamara", ""]]}, {"id": "1905.01027", "submitter": "Ivan Homoliak", "authors": "Dominik Breitenbacher, Ivan Homoliak, Yan Lin Aung, Nils Ole\n  Tippenhauer, Yuval Elovici", "title": "HADES-IoT: A Practical Host-Based Anomaly Detection System for IoT\n  Devices (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) devices have become ubiquitous and are spread across\nmany application domains including the industry, transportation, healthcare,\nand households. However, the proliferation of the IoT devices has raised the\nconcerns about their security, especially when observing that many\nmanufacturers focus only on the core functionality of their products due to\nshort time to market and low-cost pressures, while neglecting security aspects.\nMoreover, it does not exist any established or standardized method for\nmeasuring and ensuring the security of IoT devices. Consequently,\nvulnerabilities are left untreated, allowing attackers to exploit IoT devices\nfor various purposes, such as compromising privacy, recruiting devices into a\nbotnet, or misusing devices to perform cryptocurrency mining.\n  In this paper, we present a practical Host-based Anomaly DEtection System for\nIoT (HADES-IoT) that represents the last line of defense. HADES-IoT has\nproactive detection capabilities, provides tamper-proof resistance, and it can\nbe deployed on a wide range of Linux-based IoT devices. The main advantage of\nHADES-IoT is its low performance overhead, which makes it suitable for the IoT\ndomain, where state-of-the-art approaches cannot be applied due to their\nhigh-performance demands. We deployed HADES-IoT on seven IoT devices to\nevaluate its effectiveness and performance overhead. Our experiments show that\nHADES-IoT achieved 100% effectiveness in the detection of current IoT malware\nsuch as VPNFilter and IoTReaper; while on average, requiring only 5.5% of\navailable memory and causing only a low CPU load.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 03:36:49 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Breitenbacher", "Dominik", ""], ["Homoliak", "Ivan", ""], ["Aung", "Yan Lin", ""], ["Tippenhauer", "Nils Ole", ""], ["Elovici", "Yuval", ""]]}, {"id": "1905.01034", "submitter": "Yi Sun", "authors": "Daniel Kang and Yi Sun and Tom Brown and Dan Hendrycks and Jacob\n  Steinhardt", "title": "Transfer of Adversarial Robustness Between Perturbation Types", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the transfer of adversarial robustness of deep neural networks\nbetween different perturbation types. While most work on adversarial examples\nhas focused on $L_\\infty$ and $L_2$-bounded perturbations, these do not capture\nall types of perturbations available to an adversary. The present work\nevaluates 32 attacks of 5 different types against models adversarially trained\non a 100-class subset of ImageNet. Our empirical results suggest that\nevaluating on a wide range of perturbation sizes is necessary to understand\nwhether adversarial robustness transfers between perturbation types. We further\ndemonstrate that robustness against one perturbation type may not always imply\nand may sometimes hurt robustness against other perturbation types. In light of\nthese results, we recommend evaluation of adversarial defenses take place on a\ndiverse range of perturbation types and sizes.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 04:51:07 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Kang", "Daniel", ""], ["Sun", "Yi", ""], ["Brown", "Tom", ""], ["Hendrycks", "Dan", ""], ["Steinhardt", "Jacob", ""]]}, {"id": "1905.01039", "submitter": "Emre Yilmaz", "authors": "Emre Yilmaz, Mohammad Al-Rubaie and J. Morris Chang", "title": "Locally Differentially Private Naive Bayes Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, classification models need to be trained in order to\npredict class labels. When the training data contains personal information\nabout individuals, collecting training data becomes difficult due to privacy\nconcerns. Local differential privacy is a definition to measure the individual\nprivacy when there is no trusted data curator. Individuals interact with an\nuntrusted data aggregator who obtains statistical information about the\npopulation without learning personal data. In order to train a Naive Bayes\nclassifier in an untrusted setting, we propose to use methods satisfying local\ndifferential privacy. Individuals send their perturbed inputs that keep the\nrelationship between the feature values and class labels. The data aggregator\nestimates all probabilities needed by the Naive Bayes classifier. Then, new\ninstances can be classified based on the estimated probabilities. We propose\nsolutions for both discrete and continuous data. In order to eliminate high\namount of noise and decrease communication cost in multi-dimensional data, we\npropose utilizing dimensionality reduction techniques which can be applied by\nindividuals before perturbing their inputs. Our experimental results show that\nthe accuracy of the Naive Bayes classifier is maintained even when the\nindividual privacy is guaranteed under local differential privacy, and that\nusing dimensionality reduction enhances the accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 06:14:18 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Yilmaz", "Emre", ""], ["Al-Rubaie", "Mohammad", ""], ["Chang", "J. Morris", ""]]}, {"id": "1905.01041", "submitter": "Jinquan Luo", "authors": "Jinquan Luo and Junru Ma", "title": "New Perfect Nonlinear Functions and Their Semifields", "comments": "The paper has a fatal mistake which can not be repaired", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.CO math.IT math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, two new classes of perfect nonlinear functions over\n$\\mathbb{F}_{p^{2m}}$ are proposed, where $p$ is an odd prime. Furthermore, we\ninvestigate the nucleus of the corresponding semifields of these functions and\nshow that the semifields are not isotopic to all the known semifields.\nParticularly, the new perfect nonlinear functions are CCZ-inequivalent to other\nclasses in general.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 06:32:32 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 13:51:39 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Luo", "Jinquan", ""], ["Ma", "Junru", ""]]}, {"id": "1905.01051", "submitter": "Pierre Laperdrix", "authors": "Pierre Laperdrix and Nataliia Bielova and Benoit Baudry and Gildas\n  Avoine", "title": "Browser Fingerprinting: A survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With this paper, we survey the research performed in the domain of browser\nfingerprinting, while providing an accessible entry point to newcomers in the\nfield. We explain how this technique works and where it stems from. We analyze\nthe related work in detail to understand the composition of modern fingerprints\nand see how this technique is currently used online. We systematize existing\ndefense solutions into different categories and detail the current challenges\nyet to overcome.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 07:24:32 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 12:46:06 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Laperdrix", "Pierre", ""], ["Bielova", "Nataliia", ""], ["Baudry", "Benoit", ""], ["Avoine", "Gildas", ""]]}, {"id": "1905.01078", "submitter": "Jonathan Peck", "authors": "Jonathan Peck, Claire Nie, Raaghavi Sivaguru, Charles Grumer, Femi\n  Olumofin, Bin Yu, Anderson Nascimento and Martine De Cock", "title": "CharBot: A Simple and Effective Method for Evading DGA Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain generation algorithms (DGAs) are commonly leveraged by malware to\ncreate lists of domain names which can be used for command and control (C&C)\npurposes. Approaches based on machine learning have recently been developed to\nautomatically detect generated domain names in real-time. In this work, we\npresent a novel DGA called CharBot which is capable of producing large numbers\nof unregistered domain names that are not detected by state-of-the-art\nclassifiers for real-time detection of DGAs, including the recently published\nmethods FANCI (a random forest based on human-engineered features) and LSTM.MI\n(a deep learning approach). CharBot is very simple, effective and requires no\nknowledge of the targeted DGA classifiers. We show that retraining the\nclassifiers on CharBot samples is not a viable defense strategy. We believe\nthese findings show that DGA classifiers are inherently vulnerable to\nadversarial attacks if they rely only on the domain name string to make a\ndecision. Designing a robust DGA classifier may, therefore, necessitate the use\nof additional information besides the domain name alone. To the best of our\nknowledge, CharBot is the simplest and most efficient black-box adversarial\nattack against DGA classifiers proposed to date.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 09:02:41 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 13:02:33 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Peck", "Jonathan", ""], ["Nie", "Claire", ""], ["Sivaguru", "Raaghavi", ""], ["Grumer", "Charles", ""], ["Olumofin", "Femi", ""], ["Yu", "Bin", ""], ["Nascimento", "Anderson", ""], ["De Cock", "Martine", ""]]}, {"id": "1905.01233", "submitter": "Joseph I. Choi", "authors": "Joseph I. Choi, Dave 'Jing' Tian, Grant Hernandez, Christopher Patton,\n  Benjamin Mood, Thomas Shrimpton, Kevin R. B. Butler, Patrick Traynor", "title": "A Hybrid Approach to Secure Function Evaluation Using SGX", "comments": "Full version, with proofs, of conference paper at AsiaCCS 2019;\n  updated to include copyright information", "journal-ref": null, "doi": "10.1145/3321705.3329835", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A protocol for two-party secure function evaluation (2P-SFE) aims to allow\nthe parties to learn the output of function $f$ of their private inputs, while\nleaking nothing more. In a sense, such a protocol realizes a trusted oracle\nthat computes $f$ and returns the result to both parties. There have been\ntremendous strides in efficiency over the past ten years, yet 2P-SFE protocols\nremain impractical for most real-time, online computations, particularly on\nmodestly provisioned devices. Intel's Software Guard Extensions (SGX) provides\nhardware-protected execution environments, called enclaves, that may be viewed\nas trusted computation oracles. While SGX provides native CPU speed for secure\ncomputation, previous side-channel and micro-architecture attacks have\ndemonstrated how security guarantees of enclaves can be compromised.\n  In this paper, we explore a balanced approach to 2P-SFE on SGX-enabled\nprocessors by constructing a protocol for evaluating $f$ relative to a\npartitioning of $f$. This approach alleviates the burden of trust on the\nenclave by allowing the protocol designer to choose which components should be\nevaluated within the enclave, and which via standard cryptographic techniques.\nWe describe SGX-enabled SFE protocols (modeling the enclave as an oracle), and\nformalize the strongest-possible notion of 2P-SFE for our setting. We prove our\nprotocol meets this notion when properly realized. We implement the protocol\nand apply it to two practical problems: privacy-preserving queries to a\ndatabase, and a version of Dijkstra's algorithm for privacy-preserving\nnavigation. Our evaluation shows that our SGX-enabled SFE scheme enjoys a 38x\nincrease in performance over garbled-circuit-based SFE. Finally, we justify\nmodeling of the enclave as an oracle by implementing protections against known\nside-channels.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 15:41:47 GMT"}, {"version": "v2", "created": "Mon, 6 May 2019 21:58:41 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Choi", "Joseph I.", ""], ["Tian", "Dave 'Jing'", ""], ["Hernandez", "Grant", ""], ["Patton", "Christopher", ""], ["Mood", "Benjamin", ""], ["Shrimpton", "Thomas", ""], ["Butler", "Kevin R. B.", ""], ["Traynor", "Patrick", ""]]}, {"id": "1905.01267", "submitter": "Xuehui Hu", "authors": "Xuehui Hu, Nishanth Sastry", "title": "Characterising Third Party Cookie Usage in the EU after GDPR", "comments": null, "journal-ref": null, "doi": "10.1145/3292522.3326039", "report-no": null, "categories": "cs.CR cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recently introduced General Data Protection Regulation (GDPR) requires\nthat when obtaining information online that could be used to identify\nindividuals, their consents must be obtained. Among other things, this affects\nmany common forms of cookies, and users in the EU have been presented with\nnotices asking their approvals for data collection. This paper examines the\nprevalence of third party cookies before and after GDPR by using two datasets:\naccesses to top 500 websites according to Alexa.com, and weekly data of cookies\nplaced in users' browsers by websites accessed by 16 UK and China users across\none year.\n  We find that on average the number of third parties dropped by more than 10%\nafter GDPR, but when we examine real users' browsing histories over a year, we\nfind that there is no material reduction in long-term numbers of third party\ncookies, suggesting that users are not making use of the choices offered by\nGDPR for increased privacy. Also, among websites which offer users a choice in\nwhether and how they are tracked, accepting the default choices typically ends\nup storing more cookies on average than on websites which provide a notice of\ncookies stored but without giving users a choice of which cookies, or those\nthat do not provide a cookie notice at all. We also find that top non-EU\nwebsites have fewer cookie notices, suggesting higher levels of tracking when\nvisiting international sites. Our findings have deep implications both for\nunderstanding compliance with GDPR as well as understanding the evolution of\ntracking on the web.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 16:50:57 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Hu", "Xuehui", ""], ["Sastry", "Nishanth", ""]]}, {"id": "1905.01373", "submitter": "Kobbi Nissim", "authors": "Amos Beimel, Kobbi Nissim, Mohammad Zaheri", "title": "Exploring Differential Obliviousness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper Chan et al. [SODA '19] proposed a relaxation of the notion\nof (full) memory obliviousness, which was introduced by Goldreich and Ostrovsky\n[J. ACM '96] and extensively researched by cryptographers. The new notion,\ndifferential obliviousness, requires that any two neighboring inputs exhibit\nsimilar memory access patterns, where the similarity requirement is that of\ndifferential privacy. Chan et al. demonstrated that differential obliviousness\nallows achieving improved efficiency for several algorithmic tasks, including\nsorting, merging of sorted lists, and range query data structures.\n  In this work, we continue the exploration and mapping of differential\nobliviousness, focusing on algorithms that do not necessarily examine all their\ninput. This choice is motivated by the fact that the existence of logarithmic\noverhead ORAM protocols implies that differential obliviousness can yield at\nmost a logarithmic improvement in efficiency for computations that need to\nexamine all their input. In particular, we explore property testing, where we\nshow that differential obliviousness yields an almost linear improvement in\noverhead in the dense graph model, and at most quadratic improvement in the\nbounded degree model. We also explore tasks where a non-oblivious algorithm\nwould need to explore different portions of the input, where the latter would\ndepend on the input itself, and where we show that such a behavior can be\nmaintained under differential obliviousness, but not under full obliviousness.\nOur examples suggest that there would be benefits in further exploring which\nclass of computational tasks are amenable to differential obliviousness.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 22:33:16 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 21:49:48 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Beimel", "Amos", ""], ["Nissim", "Kobbi", ""], ["Zaheri", "Mohammad", ""]]}, {"id": "1905.01412", "submitter": "Minfeng Shao", "authors": "Minfeng Shao and Ying Miao", "title": "On optimal weak algebraic manipulation detection codes and weighted\n  external difference families", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a combinatorial characterization of weak algebraic\nmanipulation detection (AMD) codes via a kind of generalized external\ndifference families called bounded standard weighted external difference\nfamilies (BSWEDFs). By means of this characterization, we improve a known lower\nbound on the maximum probability of successful tampering for the adversary's\nall possible strategies in weak AMD codes. We clarify the relationship between\nweak AMD codes and BSWEDFs with various properties. We also propose several\nexplicit constructions for BSWEDFs, some of which can generate new optimal weak\nAMD codes.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 02:25:43 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 09:05:02 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Shao", "Minfeng", ""], ["Miao", "Ying", ""]]}, {"id": "1905.01430", "submitter": "Zhengping Luo", "authors": "Zhengping Luo, Shangqing Zhao, Zhuo Lu, Jie Xu, and Yalin E. Sagduyu", "title": "When Attackers Meet AI: Learning-empowered Attacks in Cooperative\n  Spectrum Sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Defense strategies have been well studied to combat Byzantine attacks that\naim to disrupt cooperative spectrum sensing by sending falsified versions of\nspectrum sensing data to a fusion center. However, existing studies usually\nassume network or attackers as passive entities, e.g., assuming the prior\nknowledge of attacks is known or fixed. In practice, attackers can actively\nadopt arbitrary behaviors and avoid pre-assumed patterns or assumptions used by\ndefense strategies. In this paper, we revisit this security vulnerability as an\nadversarial machine learning problem and propose a novel learning-empowered\nattack framework named Learning-Evaluation-Beating (LEB) to mislead the fusion\ncenter. Based on the black-box nature of the fusion center in cooperative\nspectrum sensing, our new perspective is to make the adversarial use of machine\nlearning to construct a surrogate model of the fusion center's decision model.\nWe propose a generic algorithm to create malicious sensing data using this\nsurrogate model. Our real-world experiments show that the LEB attack is\neffective to beat a wide range of existing defense strategies with an up to 82%\nof success ratio. Given the gap between the proposed LEB attack and existing\ndefenses, we introduce a non-invasive method named as influence-limiting\ndefense, which can coexist with existing defenses to defend against LEB attack\nor other similar attacks. We show that this defense is highly effective and\nreduces the overall disruption ratio of LEB attack by up to 80%.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 04:58:00 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 21:36:06 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Luo", "Zhengping", ""], ["Zhao", "Shangqing", ""], ["Lu", "Zhuo", ""], ["Xu", "Jie", ""], ["Sagduyu", "Yalin E.", ""]]}, {"id": "1905.01665", "submitter": "Vasilios Siris", "authors": "Vasilios A. Siris, Dimitrios Dimopoulos, Nikos Fotiou, Spyros\n  Voulgaris, George C. Polyzos", "title": "OAuth 2.0 meets Blockchain for Authorization in Constrained IoT\n  Environments", "comments": "Accepted in IEEE 5th World Forum on Internet of Things (WF-IoT),\n  15-18 April 2019, Limerick, Ireland. arXiv admin note: text overlap with\n  arXiv:1905.01671", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present models for utilizing blockchain and smart contract technology with\nthe widely used OAuth 2.0 open authorization framework to provide delegated\nauthorization for constrained IoT devices. The models involve different\ntradeoffs in terms of privacy, delay, and cost, while exploiting key advantages\nof blockchains and smart contracts. These include linking payments to\nauthorization grants, immutably recording authorization information and\npolicies in smart contracts, and offering resilience through the execution of\nsmart contract code on all blockchain nodes.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 11:47:49 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Siris", "Vasilios A.", ""], ["Dimopoulos", "Dimitrios", ""], ["Fotiou", "Nikos", ""], ["Voulgaris", "Spyros", ""], ["Polyzos", "George C.", ""]]}, {"id": "1905.01671", "submitter": "Vasilios Siris", "authors": "Vasilios A. Siris, Dimitrios Dimopoulos, Nikos Fotiou, Spyros\n  Voulgaris, George C. Polyzos", "title": "Interledger Smart Contracts for Decentralized Authorization to\n  Constrained Things", "comments": "Accepted in 2nd Workshop on Cryptocurrencies and Blockchains for\n  Distributed Systems (CryBlock 2019), in conjunction with IEEE INFOCOM, April\n  29 - May 2, 2019, Paris, France. arXiv admin note: text overlap with\n  arXiv:1905.01665", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present models that utilize smart contracts and interledger mechanisms to\nprovide decentralized authorization for constrained IoT devices. The models\ninvolve different tradeoffs in terms of cost, delay, complexity, and privacy,\nwhile exploiting key advantages of smart contracts and multiple blockchains\nthat communicate with interledger mechanisms. These include immutably recording\nhashes of authorization information and policies in smart contracts, resilience\nthrough the execution of smart contract code on all blockchain nodes, and\ncryptographically linking transactions and IoT events recorded on different\nblockchains using hash and time-lock mechanisms. The proposed models are\nevaluated on the public Ethereum testnets Rinkeby and Ropsten, in terms of\nexecution cost (gas), delay, and reduction of data that needs to be sent to the\nconstrained IoT devices.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 12:32:55 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Siris", "Vasilios A.", ""], ["Dimopoulos", "Dimitrios", ""], ["Fotiou", "Nikos", ""], ["Voulgaris", "Spyros", ""], ["Polyzos", "George C.", ""]]}, {"id": "1905.01726", "submitter": "Vikash Sehwag", "authors": "Vikash Sehwag, Arjun Nitin Bhagoji, Liwei Song, Chawin Sitawarin,\n  Daniel Cullina, Mung Chiang, Prateek Mittal", "title": "Better the Devil you Know: An Analysis of Evasion Attacks using\n  Out-of-Distribution Adversarial Examples", "comments": "18 pages, 5 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large body of recent work has investigated the phenomenon of evasion\nattacks using adversarial examples for deep learning systems, where the\naddition of norm-bounded perturbations to the test inputs leads to incorrect\noutput classification. Previous work has investigated this phenomenon in\nclosed-world systems where training and test inputs follow a pre-specified\ndistribution. However, real-world implementations of deep learning\napplications, such as autonomous driving and content classification are likely\nto operate in the open-world environment. In this paper, we demonstrate the\nsuccess of open-world evasion attacks, where adversarial examples are generated\nfrom out-of-distribution inputs (OOD adversarial examples). In our study, we\nuse 11 state-of-the-art neural network models trained on 3 image datasets of\nvarying complexity. We first demonstrate that state-of-the-art detectors for\nout-of-distribution data are not robust against OOD adversarial examples. We\nthen consider 5 known defenses for adversarial examples, including\nstate-of-the-art robust training methods, and show that against these defenses,\nOOD adversarial examples can achieve up to 4$\\times$ higher target success\nrates compared to adversarial examples generated from in-distribution data. We\nalso take a quantitative look at how open-world evasion attacks may affect\nreal-world systems. Finally, we present the first steps towards a robust\nopen-world machine learning system.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 18:06:41 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Sehwag", "Vikash", ""], ["Bhagoji", "Arjun Nitin", ""], ["Song", "Liwei", ""], ["Sitawarin", "Chawin", ""], ["Cullina", "Daniel", ""], ["Chiang", "Mung", ""], ["Mittal", "Prateek", ""]]}, {"id": "1905.01730", "submitter": "Luca Vigan\\`o", "authors": "Luca Vigan\\`o", "title": "Explaining Cybersecurity with Films and the Arts (Extended Abstract)", "comments": "8 pages, 5 figures, presented at the Imagine Math 7 Conference\n  \"Mathematics and Culture\", Venice, March 29-31, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining Cybersecurity with Films and the Arts\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 18:47:11 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Vigan\u00f2", "Luca", ""]]}, {"id": "1905.01827", "submitter": "Warit Sirichotedumrong", "authors": "Warit Sirichotedumrong, Takahiro Maekawa, Yuma Kinoshita and Hitoshi\n  Kiya", "title": "Privacy-Preserving Deep Neural Networks with Pixel-based Image\n  Encryption Considering Data Augmentation in the Encrypted Domain", "comments": "Accepted in the 26th IEEE International Conference on Image\n  Processing (ICIP2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel privacy-preserving scheme for deep neural networks (DNNs)\nthat enables us not to only apply images without visual information to DNNs for\nboth training and testing but to also consider data augmentation in the\nencrypted domain for the first time. In this paper, a novel pixel-based image\nencryption method is first proposed for privacy-preserving DNNs. In addition, a\nnovel adaptation network is considered that reduces the influence of image\nencryption. In an experiment, the proposed method is applied to a well-known\nnetwork, ResNet-18, for image classification. The experimental results\ndemonstrate that conventional privacy-preserving machine learning methods\nincluding the state-of-the-arts cannot be applied to data augmentation in the\nencrypted domain and that the proposed method outperforms them in terms of\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 05:51:24 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Sirichotedumrong", "Warit", ""], ["Maekawa", "Takahiro", ""], ["Kinoshita", "Yuma", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "1905.01858", "submitter": "Jiliang Zhang", "authors": "Jiliang Zhang, Wuqiao Chen, Yuqi Niu", "title": "DeepCheck: A Non-intrusive Control-flow Integrity Checking based on Deep\n  Learning", "comments": "Submitted to S&P 2020, 10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code reuse attack (CRA) is a powerful attack that reuses existing codes to\nhijack the program control flow. Control flow integrity (CFI) is one of the\nmost popular mechanisms to prevent against CRAs. However, current CFI\ntechniques are difficult to be deployed in real applications due to suffering\nseveral issues such as modifying binaries or compiler, extending instruction\nset architectures (ISA) and incurring unacceptable runtime overhead. To address\nthese issues, we propose the first deep learning-based CFI technique, named\nDeepCheck, where the control flow graph (CFG) is split into chains for deep\nneural network (DNN) training. Then the integrity features of CFG can be\nlearned by DNN to detect abnormal control flows. DeepCheck does not interrupt\nthe application and hence incurs zero runtime overhead. Experimental results on\nAdobe Flash Player, Nginx, Proftpd and Firefox show that the average detection\naccuracy of DeepCheck is as high as 98.9%. In addition, 64 ROP exploits created\nby ROPGadget and Ropper are used to further test the effectiveness, which shows\nthat the detection success rate reaches 100%.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 07:45:40 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Zhang", "Jiliang", ""], ["Chen", "Wuqiao", ""], ["Niu", "Yuqi", ""]]}, {"id": "1905.01960", "submitter": "Tamara Radivilova A", "authors": "Tamara Radivilova and Lyudmyla Kirichenko and Dmytro Ageiev and\n  Vitalii Bulakh", "title": "The Methods to Improve Quality of Service by Accounting Secure\n  Parameters", "comments": "10 pages, 1 figure, 1 equation, 1 table. arXiv admin note: text\n  overlap with arXiv:1904.05202", "journal-ref": "In: Hu Z., Petoukhov S., Dychka I., He M. (eds) Advances in\n  Computer Science for Engineering and Education II. ICCSEEA 2019. Advances in\n  Intelligent Systems and Computing, vol 938, pp 346-355. 2020. Springer, Cham", "doi": "10.1007/978-3-030-16621-2_32", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A solution to the problem of ensuring quality of service, providing a greater\nnumber of services with higher efficiency taking into account network security\nis proposed. In this paper, experiments were conducted to analyze the effect of\nself-similarity and attacks on the quality of service parameters. Method of\nbuffering and control of channel capacity and calculating of routing cost\nmethod in the network, which take into account the parameters of traffic\nmultifractality and the probability of detecting attacks in telecommunications\nnetworks were proposed. The both proposed methods accounting the given\nrestrictions on the delay time and the number of lost packets for every type\nquality of service traffic. During simulation the parameters of transmitted\ntraffic (self-similarity, intensity) and the parameters of network (current\nchannel load, node buffer size) were changed and the maximum allowable load of\nnetwork was determined. The results of analysis show that occurrence of\noverload when transmitting traffic over a switched channel associated with\nmultifractal traffic characteristics and presence of attack. It was shown that\nproposed methods can reduce the lost data and improve the efficiency of network\nresources.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 11:49:37 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Radivilova", "Tamara", ""], ["Kirichenko", "Lyudmyla", ""], ["Ageiev", "Dmytro", ""], ["Bulakh", "Vitalii", ""]]}, {"id": "1905.01999", "submitter": "Ferhat Ozgur Catak", "authors": "Ferhat Ozgur Catak, Ahmet Faruk Yaz{\\i}", "title": "A Benchmark API Call Dataset for Windows PE Malware Classification", "comments": "Updated version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of operating system API calls is a promising task in the detection of\nPE-type malware in the Windows operating system. This task is officially\ndefined as running malware in an isolated sandbox environment, recording the\nAPI calls made with the Windows operating system and sequentially analyzing\nthese calls. Here, we have analyzed 7107 different malicious software belonging\nto various families such as virus, backdoor, trojan in an isolated sandbox\nenvironment and transformed these analysis results into a format where\ndifferent classification algorithms and methods can be used. First, we'll\nexplain how we got the malware, and then we'll explain how we've got these\nsoftware bundled into families. Finally, we will describe how to perform\nmalware classification tasks using different computational methods for the\nresearchers who will use the data set we have created.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 12:47:30 GMT"}, {"version": "v2", "created": "Sun, 21 Feb 2021 18:42:46 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Catak", "Ferhat Ozgur", ""], ["Yaz\u0131", "Ahmet Faruk", ""]]}, {"id": "1905.02004", "submitter": "Keju Meng", "authors": "Fuyou Miao, Keju Meng, Wenchao Huang, Yan Xiong, Xingfu Wang", "title": "Ideal Tightly Couple (t,m,n) Secret Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a fundamental cryptographic tool, (t,n)-threshold secret sharing\n((t,n)-SS) divides a secret among n shareholders and requires at least t,\n(t<=n), of them to reconstruct the secret. Ideal (t,n)-SSs are most desirable\nin security and efficiency among basic (t,n)-SSs. However, an adversary, even\nwithout any valid share, may mount Illegal Participant (IP) attack or\nt/2-Private Channel Cracking (t/2-PCC) attack to obtain the secret in most\n(t,n)-SSs.To secure ideal (t,n)-SSs against the 2 attacks, 1) the paper\nintroduces the notion of Ideal Tightly cOupled (t,m,n) Secret Sharing (or\n(t,m,n)-ITOSS ) to thwart IP attack without Verifiable SS; (t,m,n)-ITOSS binds\nall m, (m>=t), participants into a tightly coupled group and requires all\nparticipants to be legal shareholders before recovering the secret. 2) As an\nexample, the paper presents a polynomial-based (t,m,n)-ITOSS scheme, in which\nthe proposed k-round Random Number Selection (RNS) guarantees that adversaries\nhave to crack at least symmetrical private channels among participants before\nobtaining the secret. Therefore, k-round RNS enhances the robustness of\n(t,m,n)-ITOSS against t/2-PCC attack to the utmost. 3) The paper finally\npresents a generalized method of converting an ideal (t,n)-SS into a\n(t,m,n)-ITOSS, which helps an ideal (t,n)-SS substantially improve the\nrobustness against the above 2 attacks.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 12:54:10 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Miao", "Fuyou", ""], ["Meng", "Keju", ""], ["Huang", "Wenchao", ""], ["Xiong", "Yan", ""], ["Wang", "Xingfu", ""]]}, {"id": "1905.02162", "submitter": "Luca Allodi", "authors": "Amber van der Heijden, Luca Allodi", "title": "Cognitive Triaging of Phishing Attacks", "comments": "To appear in USENIX Security 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we employ quantitative measurements of cognitive vulnerability\ntriggers in phishing emails to predict the degree of success of an attack. To\nachieve this we rely on the cognitive psychology literature and develop an\nautomated and fully quantitative method based on machine learning and\neconometrics to construct a triaging mechanism built around the cognitive\nfeatures of a phishing email; we showcase our approach relying on data from the\nanti-phishing division of a large financial organization in Europe. Our\nevaluation shows empirically that an effective triaging mechanism for phishing\nsuccess can be put in place by response teams to effectively prioritize\nremediation efforts (e.g. domain takedowns), by first acting on those attacks\nthat are more likely to collect high response rates from potential victims.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 17:21:50 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 07:10:04 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["van der Heijden", "Amber", ""], ["Allodi", "Luca", ""]]}, {"id": "1905.02175", "submitter": "Dimitris Tsipras", "authors": "Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom,\n  Brandon Tran, Aleksander Madry", "title": "Adversarial Examples Are Not Bugs, They Are Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples have attracted significant attention in machine\nlearning, but the reasons for their existence and pervasiveness remain unclear.\nWe demonstrate that adversarial examples can be directly attributed to the\npresence of non-robust features: features derived from patterns in the data\ndistribution that are highly predictive, yet brittle and incomprehensible to\nhumans. After capturing these features within a theoretical framework, we\nestablish their widespread existence in standard datasets. Finally, we present\na simple setting where we can rigorously tie the phenomena we observe in\npractice to a misalignment between the (human-specified) notion of robustness\nand the inherent geometry of the data.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 17:45:05 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 02:01:14 GMT"}, {"version": "v3", "created": "Wed, 19 Jun 2019 00:25:20 GMT"}, {"version": "v4", "created": "Mon, 12 Aug 2019 14:36:10 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Ilyas", "Andrew", ""], ["Santurkar", "Shibani", ""], ["Tsipras", "Dimitris", ""], ["Engstrom", "Logan", ""], ["Tran", "Brandon", ""], ["Madry", "Aleksander", ""]]}, {"id": "1905.02250", "submitter": "Salvatore D'Oro", "authors": "Salvatore D'Oro, Francesco Restuccia and Tommaso Melodia", "title": "Hiding Data in Plain Sight: Undetectable Wireless Communications Through\n  Pseudo-Noise Asymmetric Shift Keying", "comments": null, "journal-ref": "IEEE International Conference on Computer Communications\n  (INFOCOM'19) 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Undetectable wireless transmissions are fundamental to avoid eavesdroppers.\nTo address this issue, wireless steganography hides covert information inside\nprimary information by slightly modifying the transmitted waveform such that\nprimary information will still be decodable, while covert information will be\nseen as noise by agnostic receivers. Since the addition of covert information\ninevitably decreases the SNR of the primary transmission, key challenges in\nwireless steganography are: i) to assess the impact of the covert channel on\nthe primary channel as a function of different channel conditions; and ii) to\nmake sure that the covert channel is undetectable. Existing approaches are\nprotocol-specific, also we notice that existing wireless technologies rely on\nphase-keying modulations that in most cases do not use the channel up to its\nShannon capacity. Therefore, the residual capacity can be leveraged to\nimplement a wireless system based on a pseudo-noise asymmetric shift keying\n(PN-ASK) modulation, where covert symbols are mapped by shifting the amplitude\nof primary symbols. This way, covert information will be undetectable, since a\nreceiver expecting phase-modulated symbols will see their shift in amplitude as\nan effect of channel/path loss degradation. We first investigate the SER of\nPN-ASK as a function of the channel; then, we find the optimal PN-ASK\nparameters that optimize primary and covert throughput under different channel\ncondition. We evaluate the throughput performance and undetectability of PN-ASK\nthrough extensive simulations and on an experimental testbed based on USRP N210\nsoftware-defined radios. We show that PN-ASK improves the throughput by more\nthan 8x with respect to prior art. Finally, we demonstrate through experiments\nthat PN-ASK is able to transmit covert data on top of IEEE 802.11g frames,\nwhich are correctly decoded by an off-the-shelf laptop WiFi.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 20:00:56 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["D'Oro", "Salvatore", ""], ["Restuccia", "Francesco", ""], ["Melodia", "Tommaso", ""]]}, {"id": "1905.02342", "submitter": "Nhan Duy Truong", "authors": "Nhan Duy Truong, Jing Yan Haw, Syed Muhamad Assad, Ping Koy Lam, Omid\n  Kavehei", "title": "Machine Learning Cryptanalysis of a Quantum Random Number Generator", "comments": "Accepted for publication in IEEE Transactions on Information\n  Forensics and Security. Related code is at\n  https://github.com/Nano-Neuro-Research-Lab/Machine-Learning-Cryptanalysis-of-a-Quantum-Random-Number-Generator", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random number generators (RNGs) that are crucial for cryptographic\napplications have been the subject of adversarial attacks. These attacks\nexploit environmental information to predict generated random numbers that are\nsupposed to be truly random and unpredictable. Though quantum random number\ngenerators (QRNGs) are based on the intrinsic indeterministic nature of quantum\nproperties, the presence of classical noise in the measurement process\ncompromises the integrity of a QRNG. In this paper, we develop a predictive\nmachine learning (ML) analysis to investigate the impact of deterministic\nclassical noise in different stages of an optical continuous variable QRNG. Our\nML model successfully detects inherent correlations when the deterministic\nnoise sources are prominent. After appropriate filtering and randomness\nextraction processes are introduced, our QRNG system, in turn, demonstrates its\nrobustness against ML. We further demonstrate the robustness of our ML approach\nby applying it to uniformly distributed random numbers from the QRNG and a\ncongruential RNG. Hence, our result shows that ML has potentials in\nbenchmarking the quality of RNG devices.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 03:42:04 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 02:59:02 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Truong", "Nhan Duy", ""], ["Haw", "Jing Yan", ""], ["Assad", "Syed Muhamad", ""], ["Lam", "Ping Koy", ""], ["Kavehei", "Omid", ""]]}, {"id": "1905.02383", "submitter": "Jinshuo Dong", "authors": "Jinshuo Dong, Aaron Roth, Weijie J. Su", "title": "Gaussian Differential Privacy", "comments": "v2 revises introduction, adds discussion and fixes some\n  inconsistencies. v3 fixes typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy has seen remarkable success as a rigorous and practical\nformalization of data privacy in the past decade. This privacy definition and\nits divergence based relaxations, however, have several acknowledged\nweaknesses, either in handling composition of private algorithms or in\nanalyzing important primitives like privacy amplification by subsampling.\nInspired by the hypothesis testing formulation of privacy, this paper proposes\na new relaxation, which we term `$f$-differential privacy' ($f$-DP). This\nnotion of privacy has a number of appealing properties and, in particular,\navoids difficulties associated with divergence based relaxations. First, $f$-DP\npreserves the hypothesis testing interpretation. In addition, $f$-DP allows for\nlossless reasoning about composition in an algebraic fashion. Moreover, we\nprovide a powerful technique to import existing results proven for original DP\nto $f$-DP and, as an application, obtain a simple subsampling theorem for\n$f$-DP.\n  In addition to the above findings, we introduce a canonical single-parameter\nfamily of privacy notions within the $f$-DP class that is referred to as\n`Gaussian differential privacy' (GDP), defined based on testing two shifted\nGaussians. GDP is focal among the $f$-DP class because of a central limit\ntheorem we prove. More precisely, the privacy guarantees of \\emph{any}\nhypothesis testing based definition of privacy (including original DP)\nconverges to GDP in the limit under composition. The CLT also yields a\ncomputationally inexpensive tool for analyzing the exact composition of private\nalgorithms.\n  Taken together, this collection of attractive properties render $f$-DP a\nmathematically coherent, analytically tractable, and versatile framework for\nprivate data analysis. Finally, we demonstrate the use of the tools we develop\nby giving an improved privacy analysis of noisy stochastic gradient descent.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 06:57:19 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 17:48:32 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 23:51:04 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Dong", "Jinshuo", ""], ["Roth", "Aaron", ""], ["Su", "Weijie J.", ""]]}, {"id": "1905.02463", "submitter": "Isaac Dunn", "authors": "Isaac Dunn, Hadrien Pouget, Tom Melham, Daniel Kroening", "title": "Adaptive Generation of Unrestricted Adversarial Inputs", "comments": "Updated to include new results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are vulnerable to adversarially-constructed perturbations of\ntheir inputs. Most research so far has considered perturbations of a fixed\nmagnitude under some $l_p$ norm. Although studying these attacks is valuable,\nthere has been increasing interest in the construction of (and robustness to)\nunrestricted attacks, which are not constrained to a small and rather\nartificial subset of all possible adversarial inputs. We introduce a novel\nalgorithm for generating such unrestricted adversarial inputs which, unlike\nprior work, is adaptive: it is able to tune its attacks to the classifier being\ntargeted. It also offers a 400-2,000x speedup over the existing state of the\nart. We demonstrate our approach by generating unrestricted adversarial inputs\nthat fool classifiers robust to perturbation-based attacks. We also show that,\nby virtue of being adaptive and unrestricted, our attack is able to defeat\nadversarial training against it.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 10:54:43 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 12:43:55 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Dunn", "Isaac", ""], ["Pouget", "Hadrien", ""], ["Melham", "Tom", ""], ["Kroening", "Daniel", ""]]}, {"id": "1905.02497", "submitter": "Sudip Mittal", "authors": "Aditya Pingle, Aritran Piplai, Sudip Mittal, Anupam Joshi, James Holt,\n  Richard Zak", "title": "RelExt: Relation Extraction using Deep Learning approaches for\n  Cybersecurity Knowledge Graph Improvement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security Analysts that work in a `Security Operations Center' (SoC) play a\nmajor role in ensuring the security of the organization. The amount of\nbackground knowledge they have about the evolving and new attacks makes a\nsignificant difference in their ability to detect attacks. Open source threat\nintelligence sources, like text descriptions about cyber-attacks, can be stored\nin a structured fashion in a cybersecurity knowledge graph. A cybersecurity\nknowledge graph can be paramount in aiding a security analyst to detect cyber\nthreats because it stores a vast range of cyber threat information in the form\nof semantic triples which can be queried. A semantic triple contains two\ncybersecurity entities with a relationship between them. In this work, we\npropose a system to create semantic triples over cybersecurity text, using deep\nlearning approaches to extract possible relationships. We use the set of\nsemantic triples generated through our system to assert in a cybersecurity\nknowledge graph. Security Analysts can retrieve this data from the knowledge\ngraph, and use this information to form a decision about a cyber-attack.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 12:30:55 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 13:49:36 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Pingle", "Aditya", ""], ["Piplai", "Aritran", ""], ["Mittal", "Sudip", ""], ["Joshi", "Anupam", ""], ["Holt", "James", ""], ["Zak", "Richard", ""]]}, {"id": "1905.02602", "submitter": "Olga Gadyatskaya", "authors": "Stanislav Dashevskyi, Yury Zhauniarovich, Olga Gadyatskaya, Aleksandr\n  Pilgun, Hamza Ouhssain", "title": "Dissecting Android Cryptocurrency Miners", "comments": null, "journal-ref": null, "doi": "10.1145/3374664.3375724", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptojacking applications pose a serious threat to mobile devices. Due to\nthe extensive computations, they deplete the battery fast and can even damage\nthe device. In this work we make a step towards combating this threat. We\ncollected and manually verified a large dataset of Android mining apps. In this\npaper, we analyze the gathered miners and identify how they work, what are the\nmost popular libraries and APIs used to facilitate their development, and what\nstatic features are typical for this class of applications. Further, we\nanalyzed our dataset using VirusTotal. The majority of our samples is\nconsidered malicious by at least one VirusTotal scanner, but 16 apps are not\ndetected by any engine; and at least 5 apks were not seen previously by the\nservice.\n  Mining code could be obfuscated or fetched at runtime, and there are many\nconfusing miner-related apps that actually do not mine. Thus, static features\nalone are not sufficient for miner detection. We have collected a feature set\nof dynamic metrics both for miners and unrelated benign apps, and built a\nmachine learning-based tool for dynamic detection. Our BrenntDroid tool is able\nto detect miners with 95% of accuracy on our dataset.\n  This preprint is a technical report accompanying the paper \"Dissecting\nAndroid Cryptocurrency Miners\" published in ACM CODASPY 2020.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 14:19:45 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 07:54:59 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 11:02:54 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Dashevskyi", "Stanislav", ""], ["Zhauniarovich", "Yury", ""], ["Gadyatskaya", "Olga", ""], ["Pilgun", "Aleksandr", ""], ["Ouhssain", "Hamza", ""]]}, {"id": "1905.02682", "submitter": "Alessio Caminata", "authors": "Alessio Caminata, Elisa Gorla", "title": "The complexity of MinRank", "comments": "Corrected a typo in the formula of the main theorem", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we leverage some of our results from arXiv:1706.06319 to\nproduce a concise and rigorous proof for the complexity of the generalized\nMinRank Problem in the under-defined and well-defined case. Our main theorem\nrecovers and extends previous results by Faug\\`ere, Safey El Din, Spaenlehauer\n(arXiv:1112.4411).\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 16:34:00 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 13:29:02 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Caminata", "Alessio", ""], ["Gorla", "Elisa", ""]]}, {"id": "1905.02713", "submitter": "Juan Tapiador", "authors": "Julien Gamba and Mohammed Rashed and Abbas Razaghpanah and Juan\n  Tapiador and Narseo Vallina-Rodriguez", "title": "An Analysis of Pre-installed Android Software", "comments": null, "journal-ref": "41st IEEE Symposium on Security and Privacy, 18-20 May 2020, San\n  Fransisco, CA, USA", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The open-source nature of the Android OS makes it possible for manufacturers\nto ship custom versions of the OS along with a set of pre-installed apps, often\nfor product differentiation. Some device vendors have recently come under\nscrutiny for potentially invasive private data collection practices and other\npotentially harmful or unwanted behavior of the pre-installed apps on their\ndevices. Yet, the landscape of pre-installed software in Android has largely\nremained unexplored, particularly in terms of the security and privacy\nimplications of such customizations. In this paper, we present the first\nlarge-scale study of pre-installed software on Android devices from more than\n200 vendors. Our work relies on a large dataset of real-world Android firmware\nacquired worldwide using crowd-sourcing methods. This allows us to answer\nquestions related to the stakeholders involved in the supply chain, from device\nmanufacturers and mobile network operators to third-party organizations like\nadvertising and tracking services, and social network platforms. Our study\nallows us to also uncover relationships between these actors, which seem to\nrevolve primarily around advertising and data-driven services. Overall, the\nsupply chain around Android's open source model lacks transparency and has\nfacilitated potentially harmful behaviors and backdoored access to sensitive\ndata and services without user consent or awareness. We conclude the paper with\nrecommendations to improve transparency, attribution, and accountability in the\nAndroid ecosystem.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 17:53:25 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Gamba", "Julien", ""], ["Rashed", "Mohammed", ""], ["Razaghpanah", "Abbas", ""], ["Tapiador", "Juan", ""], ["Vallina-Rodriguez", "Narseo", ""]]}, {"id": "1905.02847", "submitter": "Victor Zakhary", "authors": "Victor Zakhary, Divyakant Agrawal, Amr El Abbadi", "title": "Atomic Commitment Across Blockchains", "comments": null, "journal-ref": null, "doi": "10.14778/3397230.3397231", "report-no": null, "categories": "cs.DB cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent adoption of blockchain technologies and open permissionless\nnetworks suggest the importance of peer-to-peer atomic cross-chain transaction\nprotocols. Users should be able to atomically exchange tokens and assets\nwithout depending on centralized intermediaries such as exchanges. Recent\npeer-to-peer atomic cross-chain swap protocols use hashlocks and timelocks to\nensure that participants comply to the protocol. However, an expired timelock\ncould lead to a violation of the all-or-nothing atomicity property. An honest\nparticipant who fails to execute a smart contract on time due to a crash\nfailure or network delays at her site might end up losing her assets. Although\na crashed participant is the only participant who ends up worse off, current\nproposals are unsuitable for atomic cross-chain transactions in asynchronous\nenvironments where crash failures and network delays are the norm. In this\npaper, we present AC3WN, the first decentralized all-or-nothing atomic\ncross-chain commitment protocol. The redeem and refund events of the smart\ncontracts that exchange assets are modeled as conflicting events. An open\npermissionless network of witnesses is used to guarantee that conflicting\nevents could never simultaneously occur and either all smart contracts in an\natomic cross-chain transaction are redeemed or all of them are refunded.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 00:02:12 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 18:53:12 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Zakhary", "Victor", ""], ["Agrawal", "Divyakant", ""], ["Abbadi", "Amr El", ""]]}, {"id": "1905.02872", "submitter": "Fuqiang Di", "authors": "Zhuo Zhang, Guangyuan Fu, Fuqiang Di, Changlong Li, Jia Liu", "title": "Generative Reversible Data Hiding by Image to Image Translation via GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The traditional reversible data hiding technique is based on cover image\nmodification which inevitably leaves some traces of rewriting that can be more\neasily analyzed and attacked by the warder. Inspired by the cover synthesis\nsteganography based generative adversarial networks, in this paper, a novel\ngenerative reversible data hiding scheme (GRDH) by image translation is\nproposed. First, an image generator is used to obtain a realistic image, which\nis used as an input to the image-to-image translation model with CycleGAN.\nAfter image translation, a stego image with different semantic information will\nbe obtained. The secret message and the original input image can be recovered\nseparately by a well-trained message extractor and the inverse transform of the\nimage translation. Experimental results have verified the effectiveness of the\nscheme.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 02:24:18 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 13:58:20 GMT"}, {"version": "v3", "created": "Mon, 22 Jul 2019 04:41:40 GMT"}, {"version": "v4", "created": "Tue, 30 Jul 2019 16:29:55 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Zhang", "Zhuo", ""], ["Fu", "Guangyuan", ""], ["Di", "Fuqiang", ""], ["Li", "Changlong", ""], ["Liu", "Jia", ""]]}, {"id": "1905.02895", "submitter": "Sudip Mittal", "authors": "Sudip Mittal, Anupam Joshi, Tim Finin", "title": "Cyber-All-Intel: An AI for Security related Threat Intelligence", "comments": "arXiv admin note: substantial text overlap with arXiv:1708.03310", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keeping up with threat intelligence is a must for a security analyst today.\nThere is a volume of information present in `the wild' that affects an\norganization. We need to develop an artificial intelligence system that scours\nthe intelligence sources, to keep the analyst updated about various threats\nthat pose a risk to her organization. A security analyst who is better `tapped\nin' can be more effective.\n  In this paper we present, Cyber-All-Intel an artificial intelligence system\nto aid a security analyst. It is a system for knowledge extraction,\nrepresentation and analytics in an end-to-end pipeline grounded in the\ncybersecurity informatics domain. It uses multiple knowledge representations\nlike, vector spaces and knowledge graphs in a 'VKG structure' to store incoming\nintelligence. The system also uses neural network models to pro-actively\nimprove its knowledge. We have also created a query engine and an alert system\nthat can be used by an analyst to find actionable cybersecurity insights.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 12:15:32 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Mittal", "Sudip", ""], ["Joshi", "Anupam", ""], ["Finin", "Tim", ""]]}, {"id": "1905.03016", "submitter": "Micha{\\l} Kr\\'ol", "authors": "Micha{\\l} Kr\\'ol, Alberto Sonnino, Mustafa Al-Bassam, Argyrios\n  Tasiopoulos, Ioannis Psaras", "title": "Proof-of-Prestige: A Useful Work Reward System for Unverifiable Tasks", "comments": "2019 IEEE International Conference on Blockchain and Cryptocurrency\n  (ICBC 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As cryptographic tokens and altcoins are increasingly being built to serve as\nutility tokens, the notion of useful work consensus protocols, as opposed to\nnumber-crunching PoW consensus, is becoming ever more important. In such\ncontexts, users get rewards from the network after they have carried out some\nspecific task useful for the network. While in some cases the proof of some\nutility or service can be proved, the majority of tasks are impossible to\nverify. In order to deal with such cases, we design Proof-of-Prestige (PoP) - a\nreward system that can run on top of Proof-of-Stake blockchains. PoP introduces\nprestige which is a volatile resource and, in contrast to coins, regenerates\nover time. Prestige can be gained by performing useful work, spent when\nbenefiting from services and directly translates to users minting power. PoP is\nresistant against Sybil and Collude attacks and can be used to reward workers\nfor completing unverifiable tasks, while keeping the system free for the\nend-users. We use two exemplar use-cases to showcase the usefulness of PoP and\nwe build a simulator to assess the cryptoeconomic behaviour of the system in\nterms of prestige transfer between nodes.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 11:51:15 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Kr\u00f3l", "Micha\u0142", ""], ["Sonnino", "Alberto", ""], ["Al-Bassam", "Mustafa", ""], ["Tasiopoulos", "Argyrios", ""], ["Psaras", "Ioannis", ""]]}, {"id": "1905.03108", "submitter": "Jeff Yan", "authors": "Jeff Yan", "title": "From Sicilian mafia to Chinese \"scam villages\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by Gambetta's theory on the origins of the mafia in Sicily, we\nreport a geo-concentrating phenomenon of scams in China, and propose a novel\neconomic explanation. Our analysis has some policy implications.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 10:23:15 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Yan", "Jeff", ""]]}, {"id": "1905.03124", "submitter": "Dima Grigoriev", "authors": "Rostislav Grigorchuk, Dima Grigoriev", "title": "Key-agreement based on automaton groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest several automaton groups as key-agreement platforms for\nAnshl-Anshel-Goldfeld metascheme, they include Grigorchuk and universal\nGrigorchuk groups, Hanoi 3-Towers group, Basilica group and a subgroup of the\naffine group with the unsolvable conjugacy problem\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 14:56:30 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Grigorchuk", "Rostislav", ""], ["Grigoriev", "Dima", ""]]}, {"id": "1905.03156", "submitter": "Zhongyuan Hau", "authors": "Zhongyuan Hau, John H. Castellanos and Jianying Zhou", "title": "Evaluating Cascading Impact of Attacks on Resilience of Industrial\n  Control Systems: A Design-Centric Modeling Approach", "comments": null, "journal-ref": null, "doi": "10.1145/3384941.3409587", "report-no": null, "categories": "cs.CR cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A design-centric modeling approach was proposed to model the behaviour of the\nphysical processes controlled by Industrial Control Systems (ICS) and study the\ncascading impact of data-oriented attacks. A threat model was used as input to\nguide the construction of the CPS model where control components which are\nwithin the adversary's intent and capabilities are extracted. The relevant\ncontrol components are subsequently modeled together with their control\ndependencies and operational design specifications. The approach was\ndemonstrated and validated on a water treatment testbed. Attacks were simulated\non the testbed model where its resilience to attacks was evaluated using\nproposed metrics such as Impact Ratio and Time-to-Critical-State. From the\nanalysis of the attacks, design strengths and weaknesses were identified and\ndesign improvements were recommended to increase the testbed's resilience to\nattacks.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 15:32:49 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 02:25:50 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Hau", "Zhongyuan", ""], ["Castellanos", "John H.", ""], ["Zhou", "Jianying", ""]]}, {"id": "1905.03168", "submitter": "arXiv Admin", "authors": "Gael Kamdem De Teyou and Junior Ziazet", "title": "Convolutional Neural Network for Intrusion Detection System In Cyber\n  Physical Systems", "comments": "This submission has been withdrawn by arXiv administrators due to\n  inappropriate text reuse from external sources", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extensive use of Information and Communication Technology in critical\ninfrastructures such as Industrial Control Systems make them vulnerable to\ncyber-attacks. One particular class of cyber-attacks is advanced persistent\nthreats where highly skilled attackers can steal user authentication\ninformation's and move in the network from host to host until a valuable target\nis reached. The detection of the attacker should occur as soon as possible in\norder to take appropriate response, otherwise the attacker will have enough\ntime to reach sensitive assets. When facing intelligent threats, intelligent\nsolutions have to be designed. Therefore, in this paper, we take advantage of\nrecent progress in deep learning to build a convolutional neural networks that\ncan detect intrusions in cyber physical system. The Intrusion Detection System\nis applied on the NSL-KDD dataset and the performances of the proposed approach\nare presented and compared with the state of art. Results show the\neffectiveness of the techniques.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 15:53:35 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 15:32:43 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["De Teyou", "Gael Kamdem", ""], ["Ziazet", "Junior", ""]]}, {"id": "1905.03240", "submitter": "Majd Latah", "authors": "Majd Latah", "title": "The Art of Social Bots: A Review and a Refined Taxonomy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social bots represent a new generation of bots that make use of online social\nnetworks (OSNs) as a command and control (C\\&C) channel. Malicious social bots\nwere responsible for launching large-scale spam campaigns, promoting low-cap\nstocks, manipulating user's digital influence and conducting political\nastroturf. This paper presents a detailed review on current social bots and\nproper techniques that can be used to fly under the radar of OSNs defences to\nbe undetectable for long periods of time. We also suggest a refined taxonomy of\ndetection approaches from social network perspective, as well as commonly used\ndatasets and their corresponding findings. Our study can help OSN\nadministrators and researchers understand the destructive potential of\nmalicious social bots and can improve the current defence strategies against\nthem.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 17:51:17 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Latah", "Majd", ""]]}, {"id": "1905.03282", "submitter": "Behrooz Razeghi", "authors": "Shideh Rezaeifar, Behrooz Razeghi, Olga Taran, Taras Holotyak, Slava\n  Voloshynovskiy", "title": "Reconstruction of Privacy-Sensitive Data from Protected Templates", "comments": "accepted at ICIP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of data reconstruction from\nprivacy-protected templates, based on recent concept of sparse ternary coding\nwith ambiguization (STCA). The STCA is a generalization of randomization\ntechniques which includes random projections, lossy quantization, and addition\nof ambiguization noise to satisfy the privacy-utility trade-off requirements.\nThe theoretical privacy-preserving properties of STCA have been validated on\nsynthetic data. However, the applicability of STCA to real data and potential\nthreats linked to reconstruction based on recent deep reconstruction algorithms\nare still open problems. Our results demonstrate that STCA still achieves the\nclaimed theoretical performance when facing deep reconstruction attacks for the\nsynthetic i.i.d. data, while for real images special measures are required to\nguarantee proper protection of the templates.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 18:17:01 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Rezaeifar", "Shideh", ""], ["Razeghi", "Behrooz", ""], ["Taran", "Olga", ""], ["Holotyak", "Taras", ""], ["Voloshynovskiy", "Slava", ""]]}, {"id": "1905.03333", "submitter": "Yunhan Jia", "authors": "Yunhan Jia, Yantao Lu, Senem Velipasalar, Zhenyu Zhong, Tao Wei", "title": "Enhancing Cross-task Transferability of Adversarial Examples with\n  Dispersion Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks are known to be vulnerable to carefully crafted adversarial\nexamples, and these malicious samples often transfer, i.e., they maintain their\neffectiveness even against other models. With great efforts delved into the\ntransferability of adversarial examples, surprisingly, less attention has been\npaid to its impact on real-world deep learning deployment. In this paper, we\ninvestigate the transferability of adversarial examples across a wide range of\nreal-world computer vision tasks, including image classification, explicit\ncontent detection, optical character recognition (OCR), and object detection.\nIt represents the cybercriminal's situation where an ensemble of different\ndetection mechanisms need to be evaded all at once. We propose practical attack\nthat overcomes existing attacks' limitation of requiring task-specific loss\nfunctions by targeting on the `dispersion' of internal feature map. We report\nevaluation on four different computer vision tasks provided by Google Cloud\nVision APIs to show how our approach outperforms existing attacks by degrading\nperformance of multiple CV tasks by a large margin with only modest\nperturbations.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 20:56:47 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Jia", "Yunhan", ""], ["Lu", "Yantao", ""], ["Velipasalar", "Senem", ""], ["Zhong", "Zhenyu", ""], ["Wei", "Tao", ""]]}, {"id": "1905.03421", "submitter": "Kazuya Kakizaki", "authors": "Kazuya Kakizaki, Kosuke Yoshida", "title": "Adversarial Image Translation: Unrestricted Adversarial Examples in Face\n  Recognition Systems", "comments": "Kazuya Kakizaki and Kosuke Yoshida share equal contributions.\n  Accepted at AAAI Workshop on Artificial Intelligence Safety (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to recent advances in deep neural networks (DNNs), face recognition\nsystems have become highly accurate in classifying a large number of face\nimages. However, recent studies have found that DNNs could be vulnerable to\nadversarial examples, raising concerns about the robustness of such systems.\nAdversarial examples that are not restricted to small perturbations could be\nmore serious since conventional certified defenses might be ineffective against\nthem. To shed light on the vulnerability to such adversarial examples, we\npropose a flexible and efficient method for generating unrestricted adversarial\nexamples using image translation techniques. Our method enables us to translate\na source image into any desired facial appearance with large perturbations to\ndeceive target face recognition systems. Our experimental results indicate that\nour method achieved about $90$ and $80\\%$ attack success rates under white- and\nblack-box settings, respectively, and that the translated images are\nperceptually realistic and maintain the identifiability of the individual while\nthe perturbations are large enough to bypass certified defenses.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 02:58:45 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 04:05:43 GMT"}, {"version": "v3", "created": "Tue, 28 Jan 2020 06:36:40 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Kakizaki", "Kazuya", ""], ["Yoshida", "Kosuke", ""]]}, {"id": "1905.03454", "submitter": "Di Zhao", "authors": "Di Zhao, Jiqiang Liu, Jialin Wang, Wenjia Niu, Endong Tong, Tong Chen,\n  Gang Li", "title": "Bidirectional RNN-based Few-shot Training for Detecting Multi-stage\n  Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Feint Attack\", as a new type of APT attack, has become the focus of\nattention. It adopts a multi-stage attacks mode which can be concluded as a\ncombination of virtual attacks and real attacks. Under the cover of virtual\nattacks, real attacks can achieve the real purpose of the attacker, as a\nresult, it often caused huge losses inadvertently. However, to our knowledge,\nall previous works use common methods such as Causal-Correlation or Cased-based\nto detect outdated multi-stage attacks. Few attentions have been paid to detect\nthe \"Feint Attack\", because the difficulty of detection lies in the\ndiversification of the concept of \"Feint Attack\" and the lack of professional\ndatasets, many detection methods ignore the semantic relationship in the\nattack. Aiming at the existing challenge, this paper explores a new method to\nsolve the problem. In the attack scenario, the fuzzy clustering method based on\nattribute similarity is used to mine multi-stage attack chains. Then we use a\nfew-shot deep learning algorithm (SMOTE&CNN-SVM) and bidirectional Recurrent\nNeural Network model (Bi-RNN) to obtain the \"Feint Attack\" chains. \"Feint\nAttack\" is simulated by the real attack inserted in the normal causal attack\nchain, and the addition of the real attack destroys the causal relationship of\nthe original attack chain. So we used Bi-RNN coding to obtain the hidden\nfeature of \"Feint Attack\" chain. In the end, our method achieved the goal to\ndetect the \"Feint Attack\" accurately by using the LLDoS1.0 and LLDoS2.0 of\nDARPA2000 and CICIDS2017 of Canadian Institute for Cybersecurity.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 06:38:12 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Zhao", "Di", ""], ["Liu", "Jiqiang", ""], ["Wang", "Jialin", ""], ["Niu", "Wenjia", ""], ["Tong", "Endong", ""], ["Chen", "Tong", ""], ["Li", "Gang", ""]]}, {"id": "1905.03517", "submitter": "Chris Einar San Agustin", "authors": "Chris Einar San Agustin", "title": "Mitigating Deep Learning Vulnerabilities from Adversarial Examples\n  Attack in the Cybersecurity Domain", "comments": "10 pages 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep learning models are known to solve classification and regression\nproblems by employing a number of epoch and training samples on a large dataset\nwith optimal accuracy. However, that doesn't mean they are attack-proof or\nunexposed to vulnerabilities. Newly deployed systems particularly on a public\nenvironment (i.e public networks) are vulnerable to attacks from various\nentities. Moreover, published research on deep learning systems (Goodfellow et\nal., 2014) have determined a significant number of attacks points and a wide\narray of attack surface that has evidence of exploitation from adversarial\nexamples. Successful exploit on these systems could lead to critical real world\nrepercussions. For instance, (1) an adversarial attack on a self-driving car\nrunning a deep reinforcement learning system yields a direct misclassification\non humans causing untoward accidents.(2) a self-driving vehicle misreading a\nred light signal may cause the car to crash to another car (3)\nmisclassification of a pedestrian lane as an intersection lane that could lead\nto car crashes. This is just the tip of the iceberg, computer vision deployment\nare not entirely focused on self-driving cars but on many other areas as well -\nthat would have definitive impact on the real-world. These vulnerabilities must\nbe mitigated at an early stage of development. It is imperative to develop and\nimplement baseline security standards at a global level prior to real-world\ndeployment.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 10:24:39 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Agustin", "Chris Einar San", ""]]}, {"id": "1905.03518", "submitter": "Erik Sy", "authors": "Erik Sy, Tobias Mueller, Christian Burkert, Hannes Federrath, Mathias\n  Fischer", "title": "Enhanced Performance and Privacy for TLS over TCP Fast Open", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small TCP flows make up the majority of web flows. For them, the TCP\nthree-way handshake induces significant delay overhead. The TCP Fast Open (TFO)\nprotocol can significantly decrease this delay via zero round-trip time (0-RTT)\nhandshakes for all TCP handshakes that follow a full initial handshake to the\nsame host. However, this comes at the cost of privacy limitations and also has\nsome performance limitations. In this paper, we investigate the TFP deployment\non popular websites and browsers. We found that a client revisiting a web site\nfor the first time fails to use an abbreviated TFO handshake in 40% of all\ncases due to web server load-balancing using multiple IP addresses. Our\nanalysis further reveals significant privacy problems of the protocol design\nand implementation. Network-based attackers and online trackers can exploit TFO\nto track the online activities of users. As a countermeasure, we introduce a\nnovel protocol called TCP Fast Open Privacy (FOP). TCP FOP prevents tracking by\nnetwork attackers and impedes third-party tracking, while still allowing 0-RTT\nhandshakes as in TFO. As a proof-of-concept, we have implemented the proposed\nprotocol for the Linux kernel and a TLS library. Our measurements indicate that\nTCP FOP outperforms TLS over TFO when websites are served from multiple IP\naddresses.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 10:25:23 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 13:45:36 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Sy", "Erik", ""], ["Mueller", "Tobias", ""], ["Burkert", "Christian", ""], ["Federrath", "Hannes", ""], ["Fischer", "Mathias", ""]]}, {"id": "1905.03571", "submitter": "Nikolaos Alexopoulos", "authors": "Nikolaos Alexopoulos, Emmanouil Vasilomanolakis, Stephane Le Roux,\n  Steven Rowe, Max M\\\"uhlh\\\"auser", "title": "TRIDEnT: Building Decentralized Incentives for Collaborative Security", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sophisticated mass attacks, especially when exploiting zero-day\nvulnerabilities, have the potential to cause destructive damage to\norganizations and critical infrastructure. To timely detect and contain such\nattacks, collaboration among the defenders is critical. By correlating\nreal-time detection information (alerts) from multiple sources (collaborative\nintrusion detection), defenders can detect attacks and take the appropriate\ndefensive measures in time. However, although the technical tools to facilitate\ncollaboration exist, real-world adoption of such collaborative security\nmechanisms is still underwhelming. This is largely due to a lack of trust and\nparticipation incentives for companies and organizations. This paper proposes\nTRIDEnT, a novel collaborative platform that aims to enable and incentivize\nparties to exchange network alert data, thus increasing their overall detection\ncapabilities. TRIDEnT allows parties that may be in a competitive relationship,\nto selectively advertise, sell and acquire security alerts in the form of\n(near) real-time peer-to-peer streams. To validate the basic principles behind\nTRIDEnT, we present an intuitive game-theoretic model of alert sharing, that is\nof independent interest, and show that collaboration is bound to take place\ninfinitely often. Furthermore, to demonstrate the feasibility of our approach,\nwe instantiate our design in a decentralized manner using Ethereum smart\ncontracts and provide a fully functional prototype.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 12:28:20 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Alexopoulos", "Nikolaos", ""], ["Vasilomanolakis", "Emmanouil", ""], ["Roux", "Stephane Le", ""], ["Rowe", "Steven", ""], ["M\u00fchlh\u00e4user", "Max", ""]]}, {"id": "1905.03635", "submitter": "Magali Bardet", "authors": "Magali Bardet, Manon Bertin, Alain Couvreur and Ayoub Otmani", "title": "Practical Algebraic Attack on DAGS", "comments": "16 pages, accepted for publication in the 7th Code-Based Cryptography\n  Workshop 2019", "journal-ref": null, "doi": "10.1007/978-3-030-25922-8_5", "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DAGS scheme is a key encapsulation mechanism (KEM) based on quasi-dyadic\nalternant codes that was submitted to NIST standardization process for a\nquantum resistant public key algorithm. Recently an algebraic attack was\ndevised by Barelli and Couvreur (Asiacrypt 2018) that efficiently recovers the\nprivate key. It shows that DAGS can be totally cryptanalysed by solving a\nsystem of bilinear polynomial equations. However, some sets of DAGS parameters\nwere not broken in practice. In this paper we improve the algebraic attack by\nshowing that the original approach was not optimal in terms of the ratio of the\nnumber of equations to the number of variables. Contrary to the common belief\nthat reducing at any cost the number of variables in a polynomial system is\nalways beneficial, we actually observed that, provided that the ratio is\nincreased and up to a threshold, the solving can be heavily improved by adding\nvariables to the polynomial system. This enables us to recover the private keys\nin a few seconds. Furthermore, our experimentations also show that the maximum\ndegree reached during the computation of the Gr\\\"obner basis is an important\nparameter that explains the efficiency of the attack. Finally, the authors of\nDAGS updated the parameters to take into account the algebraic cryptanalysis of\nBarelli and Couvreur. In the present article, we propose a hybrid approach that\nperforms an exhaustive search on some variables and computes a Gr\\\"obner basis\non the polynomial system involving the remaining variables. We then show that\nthe updated set of parameters corresponding to 128-bit security can be broken\nwith 2^83 operations.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 13:51:15 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Bardet", "Magali", ""], ["Bertin", "Manon", ""], ["Couvreur", "Alain", ""], ["Otmani", "Ayoub", ""]]}, {"id": "1905.03679", "submitter": "Shen Wang", "authors": "Shen Wang, Zhengzhang Chen, Jingchao Ni, Xiao Yu, Zhichun Li, Haifeng\n  Chen, Philip S. Yu", "title": "Adversarial Defense Framework for Graph Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural network (GNN), as a powerful representation learning model on\ngraph data, attracts much attention across various disciplines. However, recent\nstudies show that GNN is vulnerable to adversarial attacks. How to make GNN\nmore robust? What are the key vulnerabilities in GNN? How to address the\nvulnerabilities and defense GNN against the adversarial attacks? In this paper,\nwe propose DefNet, an effective adversarial defense framework for GNNs. In\nparticular, we first investigate the latent vulnerabilities in every layer of\nGNNs and propose corresponding strategies including dual-stage aggregation and\nbottleneck perceptron. Then, to cope with the scarcity of training data, we\npropose an adversarial contrastive learning method to train the GNN in a\nconditional GAN manner by leveraging the high-level graph representation.\nExtensive experiments on three public datasets demonstrate the effectiveness of\nDefNet in improving the robustness of popular GNN variants, such as Graph\nConvolutional Network and GraphSAGE, under various types of adversarial\nattacks.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 15:10:30 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 20:26:51 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Wang", "Shen", ""], ["Chen", "Zhengzhang", ""], ["Ni", "Jingchao", ""], ["Yu", "Xiao", ""], ["Li", "Zhichun", ""], ["Chen", "Haifeng", ""], ["Yu", "Philip S.", ""]]}, {"id": "1905.03685", "submitter": "Qianru Zhou", "authors": "Qianru Zhou, Dimitrios Pezaros", "title": "Evaluation of Machine Learning Classifiers for Zero-Day Intrusion\n  Detection -- An Analysis on CIC-AWS-2018 dataset", "comments": "error found in the manuscript, major revision is required before\n  publish again", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting Zero-Day intrusions has been the goal of Cybersecurity, especially\nintrusion detection for a long time. Machine learning is believed to be the\npromising methodology to solve that problem, numerous models have been proposed\nbut a practical solution is still yet to come, mainly due to the limitation\ncaused by the out-of-date open datasets available. In this paper, we take a\ndeep inspection of the flow-based statistical data generated by CICFlowMeter,\nwith six most popular machine learning classification models for Zero-Day\nattacks detection. The training dataset CIC-AWS-2018 Dataset contains fourteen\ntypes of intrusions, while the testing datasets contains eight different types\nof attacks. The six classification models are evaluated and cross validated on\nCIC-AWS-2018 Dataset for their accuracy in terms of false-positive rate,\ntrue-positive rate, and time overhead. Testing dataset, including eight novel\n(or Zero-Day) real-life attacks and benign traffic flows collected in real\nresearch production network are used to test the performance of the chosen\ndecision tree classifier. Promising results are received with the accuracy as\nhigh as 100% and reasonable time overhead. We argue that with the statistical\ndata collected from CICFlowMeter, simple machine learning models such as the\ndecision tree classification could be able to take charge in detecting Zero-Day\nattacks.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 15:20:18 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 02:02:59 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Zhou", "Qianru", ""], ["Pezaros", "Dimitrios", ""]]}, {"id": "1905.03888", "submitter": "Isaac Sheff", "authors": "Isaac Sheff, Xinwen Wang, Haobin Ni, Robbert van Renesse, Andrew C.\n  Myers", "title": "Charlotte: Composable Authenticated Distributed Data Structures,\n  Technical Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Charlotte, a framework for composable, authenticated distributed\ndata structures. Charlotte data is stored in blocks that reference each other\nby hash. Together, all Charlotte blocks form a directed acyclic graph, the\nblockweb; all observers and applications use subgraphs of the blockweb for\ntheir own data structures. Unlike prior systems, Charlotte data structures are\ncomposable: applications and data structures can operate fully independently\nwhen possible, and share blocks when desired. To support this composability, we\ndefine a language-independent format for Charlotte blocks and a network API for\nCharlotte servers.\n  An authenticated distributed data structure guarantees that data is immutable\nand self-authenticating: data referenced will be unchanged when it is\nretrieved. Charlotte extends these guarantees by allowing applications to plug\nin their own mechanisms for ensuring availability and integrity of data\nstructures. Unlike most traditional distributed systems, including distributed\ndatabases, blockchains, and distributed hash tables, Charlotte supports\nheterogeneous trust: different observers may have their own beliefs about who\nmight fail, and how. Despite heterogeneity of trust, Charlotte presents each\nobserver with a consistent, available view of data.\n  We demonstrate the flexibility of Charlotte by implementing a variety of\nintegrity mechanisms, including consensus and proof of work. We study the power\nof disentangling availability and integrity mechanisms by building a variety of\napplications. The results from these examples suggest that developers can use\nCharlotte to build flexible, fast, composable applications with strong\nguarantees.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 23:25:35 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Sheff", "Isaac", ""], ["Wang", "Xinwen", ""], ["Ni", "Haobin", ""], ["van Renesse", "Robbert", ""], ["Myers", "Andrew C.", ""]]}, {"id": "1905.03915", "submitter": "Bo Chen", "authors": "Li Lei, Kai Cong, Zhenkun Yang, Bo Chen, Fei Xie", "title": "Hardware/Software Co-monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware/Software (HW/SW) interfaces, mostly implemented as devices and\ndevice drivers, are pervasive in various computer systems. Nowadays HW/SW\ninterfaces typically undergo intensive testing and validation before release,\nbut they are still unreliable and insecure when deployed together with computer\nsystems to end users. Escaped logic bugs, hardware transient failures, and\nmalicious exploits are prevalent in HW/SW interactions, making the entire\nsystem vulnerable and unstable.\n  We present HW/SW co-monitoring, a runtime co-verification approach to\ndetecting failures and malicious exploits in device/driver interactions. Our\napproach utilizes a formal device model (FDM), a transaction-level model\nderived from the device specification, to shadow the real device execution.\nBased on the co-execution of the device and FDM, HW/SW co-monitoring carries\nout two-tier runtime checking: (1) device checking checks if the device\nbehaviors conform to the FDM behaviors; (2) property checking detects invalid\ndriver commands issued to the device by verifying system properties against\ndriver/device interactions. We have applied HW/SW co-monitoring to five\nwidely-used devices and their Linux drivers, discovering 9 real bugs and\nvulnerabilities while introducing modest runtime overhead. The results\ndemonstrate the major potential of HW/SW co-monitoring in improving system\nreliability and security.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 02:51:35 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Lei", "Li", ""], ["Cong", "Kai", ""], ["Yang", "Zhenkun", ""], ["Chen", "Bo", ""], ["Xie", "Fei", ""]]}, {"id": "1905.04021", "submitter": "Alberto Giaretta", "authors": "Alberto Giaretta, Stefano Pepe, Nicola Dragoni", "title": "UniquID: A Quest to Reconcile Identity Access Management and the\n  Internet of Things", "comments": "15 pages, 10 figures", "journal-ref": null, "doi": "10.1007/978-3-030-29852-4_20", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) has caused a revolutionary paradigm shift in\ncomputer networking. After decades of human-centered routines, where devices\nwere merely tools that enabled human beings to authenticate themselves and\nperform activities, we are now dealing with a device-centered paradigm: the\ndevices themselves are actors, not just tools for people. Conventional identity\naccess management (IAM) frameworks were not designed to handle the challenges\nof IoT. Trying to use traditional IAM systems to reconcile heterogeneous\ndevices and complex federations of online services (e.g., IoT sensors and cloud\ncomputing solutions) adds a cumbersome architectural layer that can become hard\nto maintain and act as a single point of failure. In this paper, we propose\nUniquID, a blockchain-based solution that overcomes the need for centralized\nIAM architectures while providing scalability and robustness. We also present\nthe experimental results of a proof-of-concept UniquID enrolment network, and\nwe discuss two different use-cases that show the considerable value of a\nblockchain-based IAM.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 09:14:14 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Giaretta", "Alberto", ""], ["Pepe", "Stefano", ""], ["Dragoni", "Nicola", ""]]}, {"id": "1905.04273", "submitter": "Ryan Rogers", "authors": "David Durfee and Ryan Rogers", "title": "Practical Differentially Private Top-$k$ Selection with Pay-what-you-get\n  Composition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of top-$k$ selection over a large domain universe\nsubject to user-level differential privacy. Typically, the exponential\nmechanism or report noisy max are the algorithms used to solve this problem.\nHowever, these algorithms require querying the database for the count of each\ndomain element. We focus on the setting where the data domain is unknown, which\nis different than the setting of frequent itemsets where an apriori type\nalgorithm can help prune the space of domain elements to query. We design\nalgorithms that ensures (approximate) $(\\epsilon,\\delta>0)$-differential\nprivacy and only needs access to the true top-$\\bar{k}$ elements from the data\nfor any chosen $\\bar{k} \\geq k$. This is a highly desirable feature for making\ndifferential privacy practical, since the algorithms require no knowledge of\nthe domain. We consider both the setting where a user's data can modify an\narbitrary number of counts by at most 1, i.e. unrestricted sensitivity, and the\nsetting where a user's data can modify at most some small, fixed number of\ncounts by at most 1, i.e. restricted sensitivity. Additionally, we provide a\npay-what-you-get privacy composition bound for our algorithms. That is, our\nalgorithms might return fewer than $k$ elements when the top-$k$ elements are\nqueried, but the overall privacy budget only decreases by the size of the\noutcome set.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 17:26:07 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 00:22:17 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Durfee", "David", ""], ["Rogers", "Ryan", ""]]}, {"id": "1905.04280", "submitter": "Alireza Poostindouz", "authors": "Setareh Sharifian, Alireza Poostindouz, and Reihaneh Safavi-Naini", "title": "A Capacity-achieving One-message Key Agreement With Finite Blocklength\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information-theoretic secret key agreement (SKA) protocols are a fundamental\ncryptographic primitive that are used to establish a shared secret key between\ntwo or more parties. In a two-party SKA in source model, Alice and Bob have\nsamples of two correlated variables, that are partially leaked to Eve, and\ntheir goal is to establish a shared secret key by communicating over a reliable\npublic channel. Eve must have no information about the established key. In this\npaper, we study the problem of one-message secret key agreement where the key\nis established by Alice sending a single message to Bob. We propose a\none-message SKA (OM-SKA) protocol, prove that it achieves the one-way secret\nkey capacity, and derive finite blocklength approximations of the achievable\nsecret key length. We compare our results with existing OM-SKAs and show the\nprotocol has a unique combination of desirable properties.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 17:39:34 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 03:08:17 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Sharifian", "Setareh", ""], ["Poostindouz", "Alireza", ""], ["Safavi-Naini", "Reihaneh", ""]]}, {"id": "1905.04332", "submitter": "David Mestel", "authors": "David Mestel", "title": "Quantifying information flow in interactive systems", "comments": "32nd IEEE Symposium on Computer Security Foundations (CSF 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of quantifying information flow in interactive\nsystems, modelled as finite-state transducers in the style of Goguen and\nMeseguer. Our main result is that if the system is deterministic then the\ninformation flow is either logarithmic or linear, and there is a\npolynomial-time algorithm to distinguish the two cases and compute the rate of\nlogarithmic flow. To achieve this we first extend the theory of information\nleakage through channels to the case of interactive systems, and establish a\nnumber of results which greatly simplify computation. We then show that for\ndeterministic systems the information flow corresponds to the growth rate of\nantichains inside a certain regular language, a property called the width of\nthe language. In a companion work we have shown that there is a dichotomy\nbetween polynomial and exponential antichain growth, and a polynomial time\nalgorithm to distinguish the two cases and to compute the order of polynomial\ngrowth. We observe that these two cases correspond to logarithmic and linear\ninformation flow respectively. Finally, we formulate several attractive open\nproblems, covering the cases of probabilistic systems, systems with more than\ntwo users and nondeterministic systems where the nondeterminism is assumed to\nbe innocent rather than demonic.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 18:24:56 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Mestel", "David", ""]]}, {"id": "1905.04368", "submitter": "Chee Seng Chan", "authors": "Lixin Fan and KamWoh Ng and Chee Seng Chan", "title": "Digital Passport: A Novel Technological Strategy for Intellectual\n  Property Protection of Convolutional Neural Networks", "comments": "This paper proposes a new timely IPR solution that embed digital\n  passports into CNN models to prevent the unauthorized network usage (i.e.\n  infringement) by paralyzing the networks while maintaining its functionality\n  for verified users", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to prevent deep neural networks from being infringed by unauthorized\nparties, we propose a generic solution which embeds a designated digital\npassport into a network, and subsequently, either paralyzes the network\nfunctionalities for unauthorized usages or maintain its functionalities in the\npresence of a verified passport. Such a desired network behavior is\nsuccessfully demonstrated in a number of implementation schemes, which provide\nreliable, preventive and timely protections against tens of thousands of\nfake-passport deceptions. Extensive experiments also show that the deep neural\nnetwork performance under unauthorized usages deteriorate significantly (e.g.\nwith 33% to 82% reductions of CIFAR10 classification accuracies), while\nnetworks endorsed with valid passports remain intact.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 20:13:38 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Fan", "Lixin", ""], ["Ng", "KamWoh", ""], ["Chan", "Chee Seng", ""]]}, {"id": "1905.04374", "submitter": "S\\'ebastien Rouault", "authors": "El-Mahdi El-Mhamdi and Rachid Guerraoui and S\\'ebastien Rouault", "title": "Fast and Robust Distributed Learning in High Dimension", "comments": "preliminary theoretical draft, complements the SysML 2019 practical\n  paper of which the code is provided at\n  https://github.com/LPD-EPFL/AggregaThor. arXiv admin note: text overlap with\n  arXiv:1703.02757", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Could a gradient aggregation rule (GAR) for distributed machine learning be\nboth robust and fast? This paper answers by the affirmative through\nmulti-Bulyan. Given $n$ workers, $f$ of which are arbitrary malicious\n(Byzantine) and $m=n-f$ are not, we prove that multi-Bulyan can ensure a strong\nform of Byzantine resilience, as well as an ${\\frac{m}{n}}$ slowdown, compared\nto averaging, the fastest (but non Byzantine resilient) rule for distributed\nmachine learning. When $m \\approx n$ (almost all workers are correct),\nmulti-Bulyan reaches the speed of averaging. We also prove that multi-Bulyan's\ncost in local computation is $O(d)$ (like averaging), an important feature for\nML where $d$ commonly reaches $10^9$, while robust alternatives have at least\nquadratic cost in $d$.\n  Our theoretical findings are complemented with an experimental evaluation\nwhich, in addition to supporting the linear $O(d)$ complexity argument, conveys\nthe fact that multi-Bulyan's parallelisability further adds to its efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 16:41:25 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 16:44:25 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["El-Mhamdi", "El-Mahdi", ""], ["Guerraoui", "Rachid", ""], ["Rouault", "S\u00e9bastien", ""]]}, {"id": "1905.04409", "submitter": "Bao Trung Chu", "authors": "Bao Trung Chu, Kenji Hashimoto, and Hiroyuki Seki", "title": "On the Compositionality of Dynamic Leakage and Its Application to the\n  Quantification Problem", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative information flow (QIF) is traditionally defined as the expected\nvalue of information leakage over all feasible program runs and it fails to\nidentify vulnerable programs where only limited number of runs leak large\namount of information. As discussed in Bielova (2016), a good notion for\ndynamic leakage and an efficient way of computing the leakage are needed. To\naddress this problem, the authors have already proposed two notions for dynamic\nleakage and a method of quantifying dynamic leakage based on model counting.\nInspired by the work of Kawamoto et. al. (2017), this paper proposes two\nefficient methods for computing dynamic leakage, a compositional method along\nwith the sequential structure of a program and a parallel computation based on\nthe value domain decomposition. For the former, we also investigate both exact\nand approximated calculations. From the perspective of implementation, we\nutilize binary decision diagrams (BDDs) and deterministic decomposable negation\nnormal forms (d-DNNFs) to represent Boolean formulas in model counting.\nFinally, we show experimental results on several examples.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 00:06:43 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Chu", "Bao Trung", ""], ["Hashimoto", "Kenji", ""], ["Seki", "Hiroyuki", ""]]}, {"id": "1905.04412", "submitter": "Thomas Hardjono", "authors": "Thomas Hardjono and Ned Smith", "title": "Decentralized Trusted Computing Base for Blockchain Infrastructure\n  Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There is a growing interest today in blockchain technology as a possible\nfoundation for the future global financial ecosystem. However, in order for\nthis future financial ecosystem to be truly global, with a high degree of\ninteroperability and stability, a number challenges need to be addressed\nrelated to infrastructure security. One key aspect concerns the security and\nrobustness of the systems that participate in the blockchain peer-to-peer\nnetworks. In this paper we discuss the notion of the decentralized trusted\ncomputing base as an extension of the TCB concept in trusted computing. We\nexplore how a decentralized TCB can be useful to (i) harden individual nodes\nand systems in the blockchain infrastructure, and (ii) be the basis for secure\ngroup-oriented computations making within the P2P network of nodes that make-up\nthe blockchain system.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 00:41:48 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Hardjono", "Thomas", ""], ["Smith", "Ned", ""]]}, {"id": "1905.04436", "submitter": "Jesus Vicente Roig", "authors": "JV Roig, Eunice Grace Gatdula", "title": "HSTS Preloading is Ineffective as a Long-Term, Wide-Scale\n  MITM-Prevention Solution: Results from Analyzing the 2013 - 2017 HSTS Preload\n  List", "comments": "Very short. Supports the need to go HTTPS-everywhere ASAP - opt-in\n  solutions just don't work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HSTS (HTTP Strict Transport Security) serves to protect websites from certain\nattacks by allowing web servers to inform browsers that only secure HTTPS\nconnections should be used. However, this still leaves the initial connection\nunsecured and vulnerable to man-in-the-middle attacks. The HSTS preload list,\nnow supported by most major browsers, is an attempt to close this initial\nvulnerability. In this study, the researchers analyzed the HSTS preload list to\nsee the status of its deployment and industry acceptance as of December 2017.\nThe findings here show a bleak picture: adoption of the HSTS Preload List seem\nto be practically nil for essential industries like Finance, and a significant\npercentage of entries are test sites or nonfunctional.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 03:17:21 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Roig", "JV", ""], ["Gatdula", "Eunice Grace", ""]]}, {"id": "1905.04463", "submitter": "Yongge Wang", "authors": "Yongge Wang", "title": "Another Look at ALGORAND", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ALGORAND is a celebrated public ledger technology. In this paper, we identify\nseveral design flaws of the ALGORAND protocol. In particular, we show that the\nclaimed (proved) fork-free property is not true and several assumptions in\nALGORAND are not realistic in practice. The ALGORAND wiki page\nhttps://golden.com/wiki/Algorand claims that \"the probability of a fork in the\nprotocol is estimated at 1/1,000,000,000 and therefore blocks can be considered\nfinal upon validation\". However, our first attack in this paper shows that a\nmalicious adversary who controls less than 1/3 of the users (or money units)\ncould fork the ALGORAND chain very easily. Our second attack shows that a\nmalicious adversary could use a bribery attack to fork the ALGORAND chain very\neasily also. Furthermore, we show that the celebrated Byzantine Agreement\ncomponent in ALGORAND is not necessary. The Byzantine Agreement is the most\nexpensive part and one of the most innovative parts in the ALGORAND protocol.\nIt is used to avoid forks in ALGORAND. We show that a simple majority vote\ncould be used to achieve the same property that Byzantine Agreement achieves in\nALGORAND under the same network assumption.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 06:54:58 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 21:43:18 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Wang", "Yongge", ""]]}, {"id": "1905.04501", "submitter": "Shangqi Lai", "authors": "Shangqi Lai ((1) and (2)), Xingliang Yuan (1) and Shi-Feng Sun ((1)\n  and (2)) and Joseph K. Liu (1) and Yuhong Liu (3) and Dongxi Liu (2) ((1)\n  Monash University, (2) Data61, CSIRO (3) Santa Clara University)", "title": "GraphSE$^2$: An Encrypted Graph Database for Privacy-Preserving Social\n  Search", "comments": "This is the full version of our AsiaCCS paper \"GraphSE$^2$: An\n  Encrypted Graph Database for Privacy-Preserving Social Search\". It includes\n  the security proof of the proposed scheme. If you want to cite our work,\n  please cite the conference version of it", "journal-ref": null, "doi": "10.1145/3321705.3329803", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose GraphSE$^2$, an encrypted graph database for online\nsocial network services to address massive data breaches. GraphSE$^2$ preserves\nthe functionality of social search, a key enabler for quality social network\nservices, where social search queries are conducted on a large-scale social\ngraph and meanwhile perform set and computational operations on user-generated\ncontents. To enable efficient privacy-preserving social search, GraphSE$^2$\nprovides an encrypted structural data model to facilitate parallel and\nencrypted graph data access. It is also designed to decompose complex social\nsearch queries into atomic operations and realise them via interchangeable\nprotocols in a fast and scalable manner. We build GraphSE$^2$ with various\nqueries supported in the Facebook graph search engine and implement a\nfull-fledged prototype. Extensive evaluations on Azure Cloud demonstrate that\nGraphSE$^2$ is practical for querying a social graph with a million of users.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 11:16:23 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 23:12:43 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Lai", "Shangqi", ""], ["Yuan", "Xingliang", ""], ["Sun", "Shi-Feng", ""], ["Liu", "Joseph K.", ""], ["Liu", "Yuhong", ""], ["Liu", "Dongxi", ""]]}, {"id": "1905.04565", "submitter": "Maolin Zheng", "authors": "Luke Zeng, Shawn Xin, Avadesian Xu, Thomas Pang, Tim Yang, Maolin\n  Zheng", "title": "Seele's New Anti-ASIC Consensus Algorithm with Emphasis on Matrix\n  Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we will present a new PoW consensus algorithm used in Seele's\nmain-net, MPoW (Matrix-Proof-of-Work). Compared to Bitcoin's PoW consensus\nalgorithm, MPoW requires miners to compute the determinants of submatrices from\na matrix constructed with n hashes other than brute-force-hashing using a hash\nfunction to find the target. This paper will evaluate this algorithm's\ncompatibility with difficulty adjustment. Then we will discuss its efficiency\nin countering machines with hashrate advantage, and its feasibility to personal\ncomputers. We believe more innovative consensus protocols can be developed\nbased on this algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 18:08:27 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Zeng", "Luke", ""], ["Xin", "Shawn", ""], ["Xu", "Avadesian", ""], ["Pang", "Thomas", ""], ["Yang", "Tim", ""], ["Zheng", "Maolin", ""]]}, {"id": "1905.04576", "submitter": "Sergio Pastrana", "authors": "Alice Hutchings and Sergio Pastrana", "title": "Understanding eWhoring", "comments": null, "journal-ref": "4th IEEE European Symposium on Security and Privacy 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a new type of online fraud, referred to as\n'eWhoring' by offenders. This crime script analysis provides an overview of the\n'eWhoring' business model, drawing on more than 6,500 posts crawled from an\nonline underground forum. This is an unusual fraud type, in that offenders\nreadily share information about how it is committed in a way that is almost\nprescriptive. There are economic factors at play here, as providing information\nabout how to make money from 'eWhoring' can increase the demand for the types\nof images that enable it to happen. We find that sexualised images are\ntypically stolen and shared online. While some images are shared for free,\nthese can quickly become 'saturated', leading to the demand for (and trade in)\nmore exclusive 'packs'. These images are then sold to unwitting customers who\nbelieve they have paid for a virtual sexual encounter. A variety of online\nservices are used for carrying out this fraud type, including email, video,\ndating sites, social media, classified advertisements, and payment platforms.\nThis analysis reveals potential interventions that could be applied to each\nstage of the crime commission process to prevent and disrupt this crime type.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 19:00:51 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Hutchings", "Alice", ""], ["Pastrana", "Sergio", ""]]}, {"id": "1905.04615", "submitter": "Jason R.C. Nurse Dr", "authors": "Oliver Buckley and Jason R. C. Nurse", "title": "The Language of Biometrics: Analysing Public Perceptions", "comments": null, "journal-ref": "Journal of Information Security and Applications, Volume 47,\n  August 2019, Pages 112-119", "doi": "10.1016/j.jisa.2019.05.001", "report-no": null, "categories": "cs.CR cs.CY cs.ET cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing shift in technology towards biometric solutions, but\none of the biggest barriers to widespread use is the acceptance by the users.\nIn this paper we investigate the understanding, awareness and acceptance of\nbiometrics by the general public. The primary research method was a survey,\nwhich had 282 respondents, designed to gauge public opinion around biometrics.\nAdditionally, qualitative data was captured in the form of the participants'\ndefinition of the term \\textit{biometrics}. We applied thematic analysis as\nwell as an automated Word Vector analysis to this data to provide a deeper\ninsight into the perceptions and understanding of the term. Our results\ndemonstrate that while there is generally a reasonable level of understanding\nof what biometrics are, this is typically limited to the techniques that are\nmost familiar to participants (e.g., fingerprints or facial recognition). Most\nnotably individuals' awareness overlooks emerging areas such as behavioural\nbiometrics (e.g., gait). This was also apparent when we compared participants'\nviews to definitions provided by official, published sources (e.g., ISO, NIST,\nOED, DHS). Overall, this article provides unique insight into the perceptions\nand understanding of biometrics as well as areas where users may lack knowledge\non biometric applications.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 00:45:52 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Buckley", "Oliver", ""], ["Nurse", "Jason R. C.", ""]]}, {"id": "1905.04643", "submitter": "Mohammad G. Raeini", "authors": "Mohammad G. Raeini and Mehrdad Nojoumian", "title": "Secure Error Correction using Multi-Party Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During recent years with the increase of data and data analysis needs,\nprivacy preserving data analysis methods have become of great importance.\nResearchers have proposed different methods for this purpose. Secure\nmulti-party computation is one of such techniques that allows a group of\nparties to evaluate a function on their data without revealing the data. This\nis done by secret sharing approach, in which parties share a piece of their\ndata using polynomials and after doing function evaluation on shares of data\nfinally they do a Lagrange interpolation to get the result. Two approaches have\nbeen proposed in secure multi-party computation for evaluating a function,\narithmetic gates and logical gates. In both of them and since communication is\nan important step in multi-party computation, errors may happen. So, being able\nto detect and correct errors is important. Moreover, as adversaries may\ninterrupt communication or manipulate the data, either in communication or\nduring computation, this error detection and correction provide participating\nparties with a technique to detect such errors. Hence, in this paper we present\na secure multi-party computation error correcting technique that has the\nability to detect and correct errors on players shares. This technique is based\non Berlekamp-Welch error correcting codes and we assume that players shares are\ngenerated using Reed-Solomon codes.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 04:19:59 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Raeini", "Mohammad G.", ""], ["Nojoumian", "Mehrdad", ""]]}, {"id": "1905.04666", "submitter": "Mohamed Baza", "authors": "Mohamed Baza, Marbin Pazos-Revilla, Mahmoud Nabil, Ahmed Sherif,\n  Mohamed Mahmoud, Waleed Alasmary", "title": "Privacy-Preserving and Collusion-Resistant Charging Coordination Schemes\n  for Smart Grid", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy storage units (ESUs) including EVs and home batteries enable several\nattractive features of the modern smart grids such as effective demand response\nand reduced electric bills. However, uncoordinated charging of ESUs stresses\nthe power system. In this paper, we propose privacy-preserving and\ncollusion-resistant charging coordination centralized and decentralized schemes\nfor the smart grid. The centralized scheme is used in case of robust\ncommunication infrastructure that connects the ESUs to the utility, while the\ndecentralized scheme is useful in case of infrastructure not available or\ncostly. In the centralized scheme, each energy storage unit should acquire\nanonymous tokens from a charging controller (CC) to send multiple charging\nrequests to the CC via the aggregator. CC can use the charging requests to\nenough data to run the charging coordination scheme, but it cannot link the\ndata to particular ESUs or reveal any private information. Our centralized\nscheme uses a modified knapsack problem formulation technique to maximize the\namount of power delivered to the ESUs before the charging requests expire\nwithout exceeding the available maximum charging capacity. In the decentralized\nscheme, several ESUs run the scheme in a distributed way with no need to\naggregator or CC. One ESU is selected as a head node that should decrypt the\nciphertext of the aggregated messages of the ESUs' messages and broadcast it to\nthe community while not revealing the ESUs' individual charging demands. Then,\nESUs can coordinate charging requests based on the aggregated charging demand\nwhile not exceeding the maximum charging capacity. Extensive experiments and\nsimulations are conducted to demonstrate that our schemes are efficient and\nsecure against various attacks, and can preserve ESU owner's privacy.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 08:37:01 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 22:45:51 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 05:33:45 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Baza", "Mohamed", ""], ["Pazos-Revilla", "Marbin", ""], ["Nabil", "Mahmoud", ""], ["Sherif", "Ahmed", ""], ["Mahmoud", "Mohamed", ""], ["Alasmary", "Waleed", ""]]}, {"id": "1905.04684", "submitter": "Nicolas Courtois T", "authors": "Nicolas T. Courtois, Aidan Patrick", "title": "Lack of Unique Factorization as a Tool in Block Cipher Cryptanalysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear (or differential) cryptanalysis may seem dull topics for a\nmathematician: they are about super simple invariants characterized by say a\nword on n=64 bits with very few bits at 1, the space of possible attacks is\nsmall, and basic principles are trivial. In contract mathematics offers an\ninfinitely rich world of possibilities. If so, why is that cryptographers have\never found so few attacks on block ciphers? In this paper we argue that\nblack-box methods used so far to find attacks in symmetric cryptography are\ninadequate and we work with a more recent white-box algebraic methodology.\nInvariant attacks can be constructed explicitly through the study of roots of\nthe so-called Fundamental Equation (FE). We also argue that certain properties\nof the ring of Boolean polynomials such as lack of unique factorization allow\nfor a certain type of product construction attacks to flourish. As a proof of\nconcept we show how to construct a complex and non-trivial attack where a\npolynomial of degree 7 is an invariant for any number of rounds for a complex\nblock cipher.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 10:27:47 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Courtois", "Nicolas T.", ""], ["Patrick", "Aidan", ""]]}, {"id": "1905.04691", "submitter": "Yossi Oren", "authors": "Kevin Sam Tharayil, Benyamin Farshteindiker, Shaked Eyal, Nir Hasidim,\n  Roy Hershkovitz, Shani Houri, Ilia Yoffe (Iofedov), Michal Oren, Yossi Oren", "title": "Sensor Defense In-Software (SDI):Practical Software Based Detection of\n  Spoofing Attacks on Position Sensor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Position sensors, such as the gyroscope, the magnetometer and the\naccelerometer, are found in a staggering variety of devices, from smartphones\nand UAVs to autonomous robots. Several works have shown how adversaries can\nmount spoofing attacks to remotely corrupt or even completely control the\noutputs of these sensors. With more and more critical applications relying on\nsensor readings to make important decisions, defending sensors from these\nattacks is of prime importance.\n  In this work we present practical software based defenses against attacks on\ntwo common types of position sensors, specifically the gyroscope and the\nmagnetometer. We first characterize the sensitivity of these sensors to\nacoustic and magnetic adversaries. Next, we present two software-only defenses:\na machine learning based single sensor defense, and a sensor fusion defense\nwhich makes use of the mathematical relationship between the two sensors. We\nperformed a detailed theoretical analysis of our defenses, and implemented them\non a variety of smartphones, as well as on a resource-constrained IoT sensor\nnode. Our defenses do not require any hardware or OS-level modifications,\nmaking it possible to use them with existing hardware. Moreover, they provide a\nhigh detection accuracy, a short detection time and a reasonable power\nconsumption.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 10:52:01 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Tharayil", "Kevin Sam", "", "Iofedov"], ["Farshteindiker", "Benyamin", "", "Iofedov"], ["Eyal", "Shaked", "", "Iofedov"], ["Hasidim", "Nir", "", "Iofedov"], ["Hershkovitz", "Roy", "", "Iofedov"], ["Houri", "Shani", "", "Iofedov"], ["Yoffe", "Ilia", "", "Iofedov"], ["Oren", "Michal", ""], ["Oren", "Yossi", ""]]}, {"id": "1905.04717", "submitter": "Vahid Mirjalili Dr", "authors": "Arun Ross, Sudipta Banerjee, Cunjian Chen, Anurag Chowdhury, Vahid\n  Mirjalili, Renu Sharma, Thomas Swearingen, Shivangi Yadav", "title": "Some Research Problems in Biometrics: The Future Beckons", "comments": "8 pages, 12 figures, ICB-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for reliably determining the identity of a person is critical in a\nnumber of different domains ranging from personal smartphones to border\nsecurity; from autonomous vehicles to e-voting; from tracking child\nvaccinations to preventing human trafficking; from crime scene investigation to\npersonalization of customer service. Biometrics, which entails the use of\nbiological attributes such as face, fingerprints and voice for recognizing a\nperson, is being increasingly used in several such applications. While\nbiometric technology has made rapid strides over the past decade, there are\nseveral fundamental issues that are yet to be satisfactorily resolved. In this\narticle, we will discuss some of these issues and enumerate some of the\nexciting challenges in this field.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 13:06:17 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Ross", "Arun", ""], ["Banerjee", "Sudipta", ""], ["Chen", "Cunjian", ""], ["Chowdhury", "Anurag", ""], ["Mirjalili", "Vahid", ""], ["Sharma", "Renu", ""], ["Swearingen", "Thomas", ""], ["Yadav", "Shivangi", ""]]}, {"id": "1905.04792", "submitter": "Michael Fischer", "authors": "Shea Ketsdever and Michael J. Fischer", "title": "Incentives Don't Solve Blockchain's Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A blockchain faces two fundamental challenges. It must motivate users to\nmaintain the system while preventing a minority of these users from colluding\nand gaining disproportionate control. Many popular public blockchains use\nmonetary incentives to encourage users to behave appropriately. But these same\nincentive schemes create more problems than they solve. Mining rewards cause\ncentralization in \"proof of work\" chains such as Bitcoin. Validator rewards and\npunishments invite attacks in \"proof of stake\" chains. This paper argues why\nthese incentive schemes are detrimental to blockchain. It considers a range of\nother systems---some of which incorporate monetary incentives, some of which do\nnot---to confirm that monetary incentives are neither necessary nor sufficient\nfor good user behavior.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 21:00:44 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Ketsdever", "Shea", ""], ["Fischer", "Michael J.", ""]]}, {"id": "1905.04796", "submitter": "Martin Barrere", "authors": "Mart\\'in Barr\\`ere, Chris Hankin, Nicolas Nicolau, Demetrios G.\n  Eliades, Thomas Parisini", "title": "Identifying Security-Critical Cyber-Physical Components in Industrial\n  Control Systems", "comments": "Keywords: Security metrics, industrial control systems,\n  cyber-physical systems, AND-OR graphs, MAX-SAT resolution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Industrial Control Systems (ICS) have become an appealing\ntarget for cyber attacks, having massive destructive consequences. Security\nmetrics are therefore essential to assess their security posture. In this\npaper, we present a novel ICS security metric based on AND/OR graphs that\nrepresent cyber-physical dependencies among network components. Our metric is\nable to efficiently identify sets of critical cyber-physical components, with\nminimal cost for an attacker, such that if compromised, the system would enter\ninto a non-operational state. We address this problem by efficiently\ntransforming the input AND/OR graph-based model into a weighted logical formula\nthat is then used to build and solve a Weighted Partial MAX-SAT problem. Our\ntool, META4ICS, leverages state-of-the-art techniques from the field of logical\nsatisfiability optimisation in order to achieve efficient computation times.\nOur experimental results indicate that the proposed security metric can\nefficiently scale to networks with thousands of nodes and be computed in\nseconds. In addition, we present a case study where we have used our system to\nanalyse the security posture of a realistic water transport network. We discuss\nour findings on the plant as well as further security applications of our\nmetric.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 21:53:16 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Barr\u00e8re", "Mart\u00edn", ""], ["Hankin", "Chris", ""], ["Nicolau", "Nicolas", ""], ["Eliades", "Demetrios G.", ""], ["Parisini", "Thomas", ""]]}, {"id": "1905.04833", "submitter": "Zheyuan Ryan Shi", "authors": "Zheyuan Ryan Shi, Ariel D. Procaccia, Kevin S. Chan, Sridhar\n  Venkatesan, Noam Ben-Asher, Nandi O. Leslie, Charles Kamhoua, Fei Fang", "title": "Learning and Planning in the Feature Deception Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's high-stakes adversarial interactions feature attackers who constantly\nbreach the ever-improving security measures. Deception mitigates the defender's\nloss by misleading the attacker to make suboptimal decisions. In order to\nformally reason about deception, we introduce the feature deception problem\n(FDP), a domain-independent model and present a learning and planning framework\nfor finding the optimal deception strategy, taking into account the adversary's\npreferences which are initially unknown to the defender. We make the following\ncontributions. (1) We show that we can uniformly learn the adversary's\npreferences using data from a modest number of deception strategies. (2) We\npropose an approximation algorithm for finding the optimal deception strategy\ngiven the learned preferences and show that the problem is NP-hard. (3) We\nperform extensive experiments to validate our methods and results. In addition,\nwe provide a case study of the credit bureau network to illustrate how FDP\nimplements deception on a real-world problem.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 02:18:45 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 02:54:40 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Shi", "Zheyuan Ryan", ""], ["Procaccia", "Ariel D.", ""], ["Chan", "Kevin S.", ""], ["Venkatesan", "Sridhar", ""], ["Ben-Asher", "Noam", ""], ["Leslie", "Nandi O.", ""], ["Kamhoua", "Charles", ""], ["Fang", "Fei", ""]]}, {"id": "1905.05041", "submitter": "Qixuan Zhang", "authors": "Qixuan Zhang, Bowen Xu, Haotian Jing and Zeyu Zheng", "title": "Ques-Chain: an Ethereum Based E-Voting System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ethereum is an open-source, public, blockchain-based distributed computing\nplatform and operating system featuring smart contract functionality. In this\npaper, we proposed an Ethereum based eletronic voting (e-voting) protocol,\nQues-Chain, which can ensure the authentication can be done without hurting\nconfidentiality and the anonymity can be protected without problems of scams at\nthe same time. Furthermore, the authors considered the wider usages Ques-Chain\ncan be applied on, pointing out that it is able to process all kinds of\nmessages and can be used in all fields with similar needs.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 13:58:20 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Zhang", "Qixuan", ""], ["Xu", "Bowen", ""], ["Jing", "Haotian", ""], ["Zheng", "Zeyu", ""]]}, {"id": "1905.05137", "submitter": "Olakunle Ibitoye", "authors": "Olakunle Ibitoye, Omair Shafiq and Ashraf Matrawy", "title": "Analyzing Adversarial Attacks Against Deep Learning for Intrusion\n  Detection in IoT Networks", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks have been widely studied in the field of computer vision\nbut their impact on network security applications remains an area of open\nresearch. As IoT, 5G and AI continue to converge to realize the promise of the\nfourth industrial revolution (Industry 4.0), security incidents and events on\nIoT networks have increased. Deep learning techniques are being applied to\ndetect and mitigate many of such security threats against IoT networks.\nFeedforward Neural Networks (FNN) have been widely used for classifying\nintrusion attacks in IoT networks. In this paper, we consider a variant of the\nFNN known as the Self-normalizing Neural Network (SNN) and compare its\nperformance with the FNN for classifying intrusion attacks in an IoT network.\nOur analysis is performed using the BoT-IoT dataset from the Cyber Range Lab of\nthe center of UNSW Canberra Cyber. In our experimental results, the FNN\noutperforms the SNN for intrusion detection in IoT networks based on multiple\nperformance metrics such as accuracy, precision, and recall as well as\nmulti-classification metrics such as Cohen's Kappa score. However, when tested\nfor adversarial robustness, the SNN demonstrates better resilience against the\nadversarial samples from the IoT dataset, presenting a promising future in the\nquest for safer and more secure deep learning in IoT networks.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 16:43:14 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Ibitoye", "Olakunle", ""], ["Shafiq", "Omair", ""], ["Matrawy", "Ashraf", ""]]}, {"id": "1905.05158", "submitter": "Yujin Kwon", "authors": "Yujin Kwon, Jian Liu, Minjeong Kim, Dawn Song, Yongdae Kim", "title": "Impossibility of Full Decentralization in Permissionless Blockchains", "comments": "This paper is accepted to ACM AFT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin uses blockchain technology and proof-of-work (PoW) mechanism where\nnodes spend computing resources and earn rewards in return for spending these\nresources. This incentive system has caused power to be significantly biased\ntowards a few nodes, called mining pools. In fact, poor decentralization\nappears not only in PoW-based coins but also in coins adopting other mechanisms\nsuch as proof-of-stake (PoS) and delegated proof-of-stake (DPoS). In this\npaper, we target this centralization issue. To this end, we first define (m,\n\\varepsilon, \\delta)-decentralization as a state that satisfies 1) there are at\nleast m participants running a node and 2) the ratio between the total resource\npower of nodes run by the richest and \\delta-th percentile participants is less\nthan or equal to 1+\\varepsilon. To see if it is possible to achieve good\ndecentralization, we introduce sufficient conditions for the incentive system\nof a blockchain to reach (m, \\varepsilon, \\delta)-decentralization. When\nsatisfying the conditions, a blockchain system can reach full decentralization\nwith probability 1. However, to achieve this, the blockchain system should be\nable to assign a positive Sybil cost, where the Sybil cost is defined as the\ndifference between the cost for one participant running multiple nodes and the\ntotal cost for multiple participants each running one node. On the other hand,\nwe prove that when there is no Sybil cost, the probability of reaching (m,\n\\varepsilon, \\delta)-decentralization is upper bounded by a value close to 0,\nconsidering a large rich-poor gap. To determine the conditions that each system\ncannot satisfy, we also analyze protocols of all PoW, PoS, and DPoS coins in\nthe top 100 coins according to our conditions. Finally, we conduct data\nanalysis of these coins to validate our theory.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 17:32:36 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 16:18:13 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Kwon", "Yujin", ""], ["Liu", "Jian", ""], ["Kim", "Minjeong", ""], ["Song", "Dawn", ""], ["Kim", "Yongdae", ""]]}, {"id": "1905.05163", "submitter": "Xintian Han", "authors": "Xintian Han, Yuxuan Hu, Luca Foschini, Larry Chinitz, Lior Jankelson,\n  Rajesh Ranganath", "title": "Adversarial Examples for Electrocardiograms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the electrocardiogram (ECG) has seen a large diffusion in\nboth medical and commercial applications, fueled by the rise of single-lead\nversions. Single-lead ECG can be embedded in medical devices and wearable\nproducts such as the injectable Medtronic Linq monitor, the iRhythm Ziopatch\nwearable monitor, and the Apple Watch Series 4. Recently, deep neural networks\nhave been used to automatically analyze ECG tracings, outperforming even\nphysicians specialized in cardiac electrophysiology in detecting certain rhythm\nirregularities. However, deep learning classifiers have been shown to be\nbrittle to adversarial examples, which are examples created to look\nincontrovertibly belonging to a certain class to a human eye but contain subtle\nfeatures that fool the classifier into misclassifying them into the wrong\nclass. Very recently, adversarial examples have also been created for\nmedical-related tasks. Yet, traditional attack methods to create adversarial\nexamples, such as projected gradient descent (PGD) do not extend directly to\nECG signals, as they generate examples that introduce square wave artifacts\nthat are not physiologically plausible. Here, we developed a method to\nconstruct smoothed adversarial examples for single-lead ECG. First, we\nimplemented a neural network model achieving state-of-the-art performance on\nthe data from the 2017 PhysioNet/Computing-in-Cardiology Challenge for\narrhythmia detection from single lead ECG classification. For this model, we\nutilized a new technique to generate smoothed examples to produce signals that\nare 1) indistinguishable to cardiologists from the original examples and 2)\nincorrectly classified by the neural network. Finally, we show that adversarial\nexamples are not unique and provide a general technique to collate and perturb\nknown adversarial examples to create new ones.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 17:47:25 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 23:04:02 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Han", "Xintian", ""], ["Hu", "Yuxuan", ""], ["Foschini", "Luca", ""], ["Chinitz", "Larry", ""], ["Jankelson", "Lior", ""], ["Ranganath", "Rajesh", ""]]}, {"id": "1905.05186", "submitter": "Nupur Kumari", "authors": "Mayank Singh, Abhishek Sinha, Nupur Kumari, Harshitha Machiraju,\n  Balaji Krishnamurthy, Vineeth N Balasubramanian", "title": "Harnessing the Vulnerability of Latent Layers in Adversarially Trained\n  Models", "comments": "Accepted at IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are vulnerable to adversarial attacks -- small visually\nimperceptible crafted noise which when added to the input drastically changes\nthe output. The most effective method of defending against these adversarial\nattacks is to use the methodology of adversarial training. We analyze the\nadversarially trained robust models to study their vulnerability against\nadversarial attacks at the level of the latent layers. Our analysis reveals\nthat contrary to the input layer which is robust to adversarial attack, the\nlatent layer of these robust models are highly susceptible to adversarial\nperturbations of small magnitude. Leveraging this information, we introduce a\nnew technique Latent Adversarial Training (LAT) which comprises of fine-tuning\nthe adversarially trained models to ensure the robustness at the feature\nlayers. We also propose Latent Attack (LA), a novel algorithm for construction\nof adversarial examples. LAT results in minor improvement in test accuracy and\nleads to a state-of-the-art adversarial accuracy against the universal\nfirst-order adversarial PGD attack which is shown for the MNIST, CIFAR-10,\nCIFAR-100 datasets.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 16:44:03 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 19:38:57 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Singh", "Mayank", ""], ["Sinha", "Abhishek", ""], ["Kumari", "Nupur", ""], ["Machiraju", "Harshitha", ""], ["Krishnamurthy", "Balaji", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "1905.05222", "submitter": "Jason R.C. Nurse Dr", "authors": "Meredydd Williams and Jason R. C. Nurse and Sadie Creese", "title": "Smartwatch games: Encouraging privacy-protective behaviour in a\n  longitudinal study", "comments": "21 pages, 2 figures", "journal-ref": "Computers in Human Behavior, 2019", "doi": "10.1016/j.chb.2019.04.026", "report-no": null, "categories": "cs.HC cs.CR cs.CY cs.ET cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the public claim concern for their privacy, they frequently appear to\noverlook it. This disparity between concern and behaviour is known as the\nPrivacy Paradox. Such issues are particularly prevalent on wearable devices.\nThese products can store personal data, such as text messages and contact\ndetails. However, owners rarely use protective features. Educational games can\nbe effective in encouraging changes in behaviour. Therefore, we developed the\nfirst privacy game for (Android) Wear OS watches. 10 participants used\nsmartwatches for two months, allowing their high-level settings to be\nmonitored. Five individuals were randomly assigned to our treatment group, and\nthey played a dynamically-customised privacy-themed game. To minimise\nconfounding variables, the other five received the same app but lacking the\nprivacy topic. The treatment group improved their protection, with their usage\nof screen locks significantly increasing (p = 0.043). In contrast, 80% of the\ncontrol group continued to never restrict their settings. After the posttest\nphase, we evaluated behavioural rationale through semi-structured interviews.\nPrivacy concerns became more nuanced in the treatment group, with opinions\naligning with behaviour. Actions appeared influenced primarily by three\nfactors: convenience, privacy salience and data sensitivity. This is the first\nsmartwatch game to encourage privacy-protective behaviour.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 18:14:40 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Williams", "Meredydd", ""], ["Nurse", "Jason R. C.", ""], ["Creese", "Sadie", ""]]}, {"id": "1905.05224", "submitter": "Xavier de Carn\\'e de Carnavalet", "authors": "Xavier de Carn\\'e de Carnavalet and Mohammad Mannan", "title": "Privacy and Security Risks of \"Not-a-Virus\" Bundled Adware: The Wajam\n  Case", "comments": "Updated draft, less technical details, added prevalence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Comprehensive case studies on malicious code mostly focus on botnets and\nworms (recently revived with IoT devices), prominent pieces of malware or\nAdvanced Persistent Threats, exploit kits, and ransomware. However, adware\nseldom receives such attention. Previous studies on \"unwanted\" Windows\napplications, including adware, favored breadth of analysis, uncovering ties\nbetween different actors and distribution methods. In this paper, we\ndemonstrate the capabilities, privacy and security risks, and prevalence of a\nparticularly successful and active adware business: Wajam, by tracking its\nevolution over nearly six years. We first study its multi-layer antivirus\nevasion capabilities, a combination of known and newly adapted techniques, that\nensure low detection rates of its daily variants, along with prominent\nfeatures, e.g., traffic interception and browser process injection. Then, we\nlook at the privacy and security implications for infected users, including\nplaintext leaks of browser histories and keyword searches on highly popular\nwebsites, along with arbitrary content injection on HTTPS webpages and remote\ncode execution vulnerabilities. Finally, we study Wajam's prevalence through\nthe popularity of its domains. Once considered as seriously as spyware, adware\nis now merely called \"not-a-virus\", \"optional\" or \"unwanted\" although its\nnegative impact is growing. We emphasize that the adware problem has been\noverlooked for too long, which can reach (or even surplus) the complexity and\nimpact of regular malware, and pose both privacy and security risks to users,\nmore so than many well-known and thoroughly-analyzed malware families.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 18:16:07 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 20:21:47 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["de Carnavalet", "Xavier de Carn\u00e9", ""], ["Mannan", "Mohammad", ""]]}, {"id": "1905.05253", "submitter": "Alexander Kott", "authors": "Michael J. De Lucia, Allison Newcomb, Alexander Kott", "title": "Features and Operation of an Autonomous Agent for Cyber Defense", "comments": null, "journal-ref": "CSIAC Journal, v.7, n.1, April 2019, pp.6-13", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ever increasing number of battlefield devices that are capable of\ncollecting, processing, storing, and communicating information are rapidly\nbecoming interconnected. The staggering number of connected devices on the\nbattlefield greatly increases the possibility that an adversary could find ways\nto exploit hardware or software vulnerabilities, degrading or denying\nWarfighters the assured and secure use of those devices. Autonomous software\nagents will become necessities to manage, defend, and react to cyber threats in\nthe future battlespace. The number of connected devices increases\ndisproportionately to the number of cyber experts that could be available\nwithin an operational environment. In this paper, an autonomous agent\ncapability and a scenario of how it could operate are proposed. The goal of\ndeveloping such capability is to increase the security posture of the Internet\nof Battlefield Things and meet the challenges of an increasingly complex\nbattlefield. This paper describes an illustrative scenario in a notional use\ncase and discusses the challenges associated with such autonomous agents. We\nconclude by offering ideas for potential research into developing autonomous\nagents suitable for cyber defense in a battlefield environment.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 19:18:25 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["De Lucia", "Michael J.", ""], ["Newcomb", "Allison", ""], ["Kott", "Alexander", ""]]}, {"id": "1905.05322", "submitter": "Seemanta Saha", "authors": "Seemanta Saha, William Eiers, Ismet Burak Kadron, Lucas Bang, Tevfik\n  Bultan", "title": "Incremental Adaptive Attack Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information leakage is a significant problem in modern software systems.\nInformation leaks due to side channels are especially hard to detect and\nanalyze. In this paper, we present techniques for automated synthesis of\nadaptive side-channel attacks that recover secret values. Our attack synthesis\ntechniques iteratively generate inputs which, when fed to code that accesses\nthe secret, reveal partial information about the secret based on the\nside-channel observations, reducing the remaining uncertainty about the secret\nin each attack step. Our approach is incremental, reusing results from prior\niterations in each attack step to improve the efficiency of attack synthesis.\nWe use symbolic execution to extract path constraints, automata-based model\ncounting to estimate probabilities of execution paths, and meta-heuristics to\nmaximize information gain based on entropy in order to minimize the number of\nsynthesized attack steps.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 00:19:59 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Saha", "Seemanta", ""], ["Eiers", "William", ""], ["Kadron", "Ismet Burak", ""], ["Bang", "Lucas", ""], ["Bultan", "Tevfik", ""]]}, {"id": "1905.05388", "submitter": "Sumit Tetarave", "authors": "Sumit Kumar Tetarave, Somanath Tripathy", "title": "Robust Node ID Assignment for Mobile P2P Networks", "comments": "13 pages", "journal-ref": null, "doi": "10.1007/s42486-020-00047-x", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advancement of portable mobile wireless devices such as smart-phones,\nPDA, etc., brought mobile peer-to-peer (P2P) as an extension of traditional P2P\nnetworks to provide efficient, low-cost communication among them in a cellular\nnetwork. It is challenging to assign a unique identifier to each user, as an\nadversary can target to disrupt the P2P system, by carefully selecting user IDs\nor obtaining many pseudo-IDs. This work proposes a robust node-ID assignment\nmechanism for secure peer joining in mobile P2P system called PJ-Sec. PJ-Sec\nfacilitates to generate nodeID for a joining peer by a collaborative effort of\nan existing peer (within the vicinity) and pre-selected vicinity head. PJ-Sec\nis formally analyzed using AVISPA model checker and found to be attack\nresistant.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 04:32:37 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Tetarave", "Sumit Kumar", ""], ["Tripathy", "Somanath", ""]]}, {"id": "1905.05454", "submitter": "Olga Taran", "authors": "Olga Taran, Shideh Rezaeifar, Taras Holotyak, Slava Voloshynovskiy", "title": "Robustification of deep net classifiers by key based diversified\n  aggregation with pre-filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address a problem of machine learning system vulnerability\nto adversarial attacks. We propose and investigate a Key based Diversified\nAggregation (KDA) mechanism as a defense strategy. The KDA assumes that the\nattacker (i) knows the architecture of classifier and the used defense\nstrategy, (ii) has an access to the training data set but (iii) does not know\nthe secret key. The robustness of the system is achieved by a specially\ndesigned key based randomization. The proposed randomization prevents the\ngradients' back propagation or the creating of a \"bypass\" system. The\nrandomization is performed simultaneously in several channels and a\nmulti-channel aggregation stabilizes the results of randomization by\naggregating soft outputs from each classifier in multi-channel system. The\nperformed experimental evaluation demonstrates a high robustness and\nuniversality of the KDA against the most efficient gradient based attacks like\nthose proposed by N. Carlini and D. Wagner and the non-gradient based sparse\nadversarial perturbations like OnePixel attacks.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 08:39:09 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Taran", "Olga", ""], ["Rezaeifar", "Shideh", ""], ["Holotyak", "Taras", ""], ["Voloshynovskiy", "Slava", ""]]}, {"id": "1905.05490", "submitter": "Jeroen van Wier", "authors": "Christian Majenz, Christian Schaffner, Jeroen van Wier", "title": "Non-malleability for quantum public-key encryption", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-malleability is an important security property for public-key encryption\n(PKE). Its significance is due to the fundamental unachievability of integrity\nand authenticity guarantees in this setting, rendering it the strongest\nintegrity-like property achievable using only PKE, without digital signatures.\nIn this work, we generalize this notion to the setting of quantum public-key\nencryption. Overcoming the notorious \"recording barrier\" known from\ngeneralizing other integrity-like security notions to quantum encryption, we\ngeneralize one of the equivalent classical definitions, comparison-based\nnon-malleability, and show how it can be fulfilled. In addition, we explore\none-time non-malleability notions for symmetric-key encryption from the\nliterature by defining plaintext and ciphertext variants and by characterizing\ntheir relation.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 10:00:46 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 15:59:43 GMT"}, {"version": "v3", "created": "Fri, 26 Mar 2021 15:30:16 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Majenz", "Christian", ""], ["Schaffner", "Christian", ""], ["van Wier", "Jeroen", ""]]}, {"id": "1905.05562", "submitter": "Shufan Zhang", "authors": "Shufan Zhang, Hu Xiong", "title": "$Laoco\\ddot{o}n$: Scalable and Portable Receipt-free E-voting Protocol\n  without Untappable Channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vote-buying and voter-coercion are the impending threats when deploying\nremote online voting into large scale elections. With a policy of carrot and\nstick, it will encourage voters to deviate from honest voting strategy and\nspoil the democratic election. To deal with this problem, many voting protocols\nproposed their solutions with the notion of receipt-freeness. However, existing\nreceipt-free voting protocols either rely on some impractical assumptions as\nuntappable communication channel, or are burden with heavy voter-side\ncomputation and quadratic tallying complexity. In this paper, we present\n$Laoco\\ddot{o}n$, a brand new cryptographic voting protocol which is practical\nand light-weight to be deployed in large scale online elections. By taking\nadvantage of proxy re-encryption, our protocol can defend vote-buying attacks.\nFurthermore, we introduce a new property, candidate-adaptiveness, in electronic\nvoting which refers to as every candidate knows the real-time vote number\ntowards himself, while he knows nothing about others, nor he buys votes. We\nprove the correctness of our protocol and evaluate the performance with\nexperimental results. Finally we advance some open problems which will be coped\nin our future work.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 12:48:08 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Zhang", "Shufan", ""], ["Xiong", "Hu", ""]]}, {"id": "1905.05605", "submitter": "Shi-Xiong Zhang", "authors": "Shi-Xiong Zhang, Yifan Gong and Dong Yu", "title": "Encrypted Speech Recognition using Deep Polynomial Networks", "comments": "ICASSP 2019, slides@\n  https://www.researchgate.net/publication/333005422_Encrypted_Speech_Recognition_using_deep_polynomial_networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cloud-based speech recognition/API provides developers or enterprises an\neasy way to create speech-enabled features in their applications. However,\nsending audios about personal or company internal information to the cloud,\nraises concerns about the privacy and security issues. The recognition results\ngenerated in cloud may also reveal some sensitive information. This paper\nproposes a deep polynomial network (DPN) that can be applied to the encrypted\nspeech as an acoustic model. It allows clients to send their data in an\nencrypted form to the cloud to ensure that their data remains confidential, at\nmean while the DPN can still make frame-level predictions over the encrypted\nspeech and return them in encrypted form. One good property of the DPN is that\nit can be trained on unencrypted speech features in the traditional way. To\nkeep the cloud away from the raw audio and recognition results, a cloud-local\njoint decoding framework is also proposed. We demonstrate the effectiveness of\nmodel and framework on the Switchboard and Cortana voice assistant tasks with\nsmall performance degradation and latency increased comparing with the\ntraditional cloud-based DNNs.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 00:14:09 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Zhang", "Shi-Xiong", ""], ["Gong", "Yifan", ""], ["Yu", "Dong", ""]]}, {"id": "1905.05694", "submitter": "Xavier Salleras", "authors": "Vanesa Daza and Xavier Salleras", "title": "LASER: Lightweight And SEcure Remote keyless entry protocol (Extended\n  version)", "comments": "Extended version of a paper by the authors published in Proceedings\n  of SECRYPT 2019. The presented solution has been submitted as an invention to\n  be patented with European Patent application number 19382339.0, on May 6th,\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Since Remote Keyless Entry (RKE) systems started to be widely used, several\nvulnerabilities in their protocols have been found. Attacks such as\njamming-and-replay attacks and relay attacks are still effective against most\nrecent RKE systems, even when many secure schemes have been designed. Although\nthey are interesting from a theoretical point of view, the complexity of these\nsolutions is excessive to implement them into a fob. This paper presents a\nlightweight and general solution based on a one message protocol, which\nguarantees the integrity and validity of the authentication in RKE systems,\nprotecting the communication against the well-known jamming-and-replay and\nrelay attacks, without using complex cryptographic schemes. Moreover, we also\nadapt our protocol for passive RKE (PRKE) systems. Our solution also includes a\nnovel frequency-hopping-based approach which mitigates deny-of-service attacks.\nFinally, a prototype has been implemented using non-expensive hardware.\nObtained results assure scalability, effectiveness and robustness.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 16:13:54 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 14:49:47 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Daza", "Vanesa", ""], ["Salleras", "Xavier", ""]]}, {"id": "1905.05725", "submitter": "Claudio Canella", "authors": "Michael Schwarz, Claudio Canella, Lukas Giner, Daniel Gruss", "title": "Store-to-Leak Forwarding: Leaking Data on Meltdown-resistant CPUs\n  (Updated and Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meltdown and Spectre exploit microarchitectural changes the CPU makes during\ntransient out-of-order execution. Using side-channel techniques, these attacks\nenable leaking arbitrary data from memory. As state-of-the-art software\nmitigations for Meltdown may incur significant performance overheads, they are\nonly seen as a temporary solution. Thus, software mitigations are disabled on\nmore recent processors, which are not susceptible to Meltdown anymore.\n  In this paper, we show that Meltdown-like attacks are still possible on\nrecent CPUs which are not vulnerable to the original Meltdown attack. We show\nthat the store buffer - a microarchitectural optimization to reduce the latency\nfor data stores - in combination with the TLB enables powerful attacks. We\npresent several ASLRrelated attacks, including a KASLR break from unprivileged\napplications, and breaking ASLR from JavaScript. We can also mount side-channel\nattacks, breaking the atomicity of TSX, and monitoring control flow of the\nkernel. Furthermore, when combined with a simple Spectre gadget, we can leak\narbitrary data from memory. Our paper shows that Meltdown-like attacks are\nstill possible, and software fixes are still necessary to ensure proper\nisolation between the kernel and user space.\n  This updated extended version of the original paper includes new results and\nexplanations on the root cause of the vulnerability and shows how it is\ndifferent to MDS attacks like Fallout.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 17:14:29 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 10:46:44 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Schwarz", "Michael", ""], ["Canella", "Claudio", ""], ["Giner", "Lukas", ""], ["Gruss", "Daniel", ""]]}, {"id": "1905.05726", "submitter": "Daniel Gruss", "authors": "Michael Schwarz, Moritz Lipp, Daniel Moghimi, Jo Van Bulck, Julian\n  Stecklina, Thomas Prescher, Daniel Gruss", "title": "ZombieLoad: Cross-Privilege-Boundary Data Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In early 2018, Meltdown first showed how to read arbitrary kernel memory from\nuser space by exploiting side-effects from transient instructions. While this\nattack has been mitigated through stronger isolation boundaries between user\nand kernel space, Meltdown inspired an entirely new class of fault-driven\ntransient execution attacks. Particularly, over the past year, Meltdown-type\nattacks have been extended to not only leak data from the L1 cache but also\nfrom various other microarchitectural structures, including the FPU register\nfile and store buffer.\n  In this paper, we present the ZombieLoad attack which uncovers a novel\nMeltdown-type effect in the processor's previously unexplored fill-buffer\nlogic. Our analysis shows that faulting load instructions (i.e., loads that\nhave to be re-issued for either architectural or microarchitectural reasons)\nmay transiently dereference unauthorized destinations previously brought into\nthe fill buffer by the current or a sibling logical CPU. Hence, we report data\nleakage of recently loaded stale values across logical cores. We demonstrate\nZombieLoad's effectiveness in a multitude of practical attack scenarios across\nCPU privilege rings, OS processes, virtual machines, and SGX enclaves. We\ndiscuss both short and long-term mitigation approaches and arrive at the\nconclusion that disabling hyperthreading is the only possible workaround to\nprevent this extremely powerful attack on current processors.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 17:14:37 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Schwarz", "Michael", ""], ["Lipp", "Moritz", ""], ["Moghimi", "Daniel", ""], ["Van Bulck", "Jo", ""], ["Stecklina", "Julian", ""], ["Prescher", "Thomas", ""], ["Gruss", "Daniel", ""]]}, {"id": "1905.05896", "submitter": "Hadi Mardani Kamali", "authors": "Kimia Zamiri Azar, Hadi Mardani Kamali, Houman Homayoun, and Avesta\n  Sasan", "title": "Threats on Logic Locking: A Decade Later", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reduce the cost of ICs and to meet the market's demand, a considerable\nportion of manufacturing supply chain, including silicon fabrication, packaging\nand testing may be pushed offshore. Utilizing a global IC manufacturing supply\nchain, and inclusion of non-trusted parties in the supply chain has raised\nconcerns over security and trust related challenges including those of\noverproduction, counterfeiting, IP piracy, and Hardware Trojans to name a few.\nTo reduce the risk of IC manufacturing in an untrusted and globally distributed\nsupply chain, the researchers have proposed various locking and obfuscation\nmechanisms for hiding the functionality of the ICs during the manufacturing,\nthat requires the activation of the IP after fabrication using the key value(s)\nthat is only known to the IP/IC owner. At the same time, many such proposed\nobfuscation and locking mechanisms are broken with attacks that exploit the\ninherent vulnerabilities in such solutions. The past decade of research in this\narea, has resulted in many such defense and attack solutions. In this paper, we\nreview a decade of research on hardware obfuscation from an attacker\nperspective, elaborate on attack and defense lessons learned, and discuss\nfuture directions that could be exploited for building stronger defenses.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 00:13:18 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Azar", "Kimia Zamiri", ""], ["Kamali", "Hadi Mardani", ""], ["Homayoun", "Houman", ""], ["Sasan", "Avesta", ""]]}, {"id": "1905.05897", "submitter": "Chen Zhu", "authors": "Chen Zhu, W. Ronny Huang, Ali Shafahi, Hengduo Li, Gavin Taylor,\n  Christoph Studer, Tom Goldstein", "title": "Transferable Clean-Label Poisoning Attacks on Deep Neural Nets", "comments": "Accepted to ICML2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Clean-label poisoning attacks inject innocuous looking (and \"correctly\"\nlabeled) poison images into training data, causing a model to misclassify a\ntargeted image after being trained on this data. We consider transferable\npoisoning attacks that succeed without access to the victim network's outputs,\narchitecture, or (in some cases) training data. To achieve this, we propose a\nnew \"polytope attack\" in which poison images are designed to surround the\ntargeted image in feature space. We also demonstrate that using Dropout during\npoison creation helps to enhance transferability of this attack. We achieve\ntransferable attack success rates of over 50% while poisoning only 1% of the\ntraining set.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 00:15:01 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 15:05:37 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Zhu", "Chen", ""], ["Huang", "W. Ronny", ""], ["Shafahi", "Ali", ""], ["Li", "Hengduo", ""], ["Taylor", "Gavin", ""], ["Studer", "Christoph", ""], ["Goldstein", "Tom", ""]]}, {"id": "1905.05965", "submitter": "Jonathon Schwartz", "authors": "Jonathon Schwartz, Hanna Kurniawati", "title": "Autonomous Penetration Testing using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Penetration testing (pentesting) involves performing a controlled attack on a\ncomputer system in order to assess it's security. Although an effective method\nfor testing security, pentesting requires highly skilled practitioners and\ncurrently there is a growing shortage of skilled cyber security professionals.\nOne avenue for alleviating this problem is automate the pentesting process\nusing artificial intelligence techniques. Current approaches to automated\npentesting have relied on model-based planning, however the cyber security\nlandscape is rapidly changing making maintaining up-to-date models of exploits\na challenge. This project investigated the application of model-free\nReinforcement Learning (RL) to automated pentesting. Model-free RL has the key\nadvantage over model-based planning of not requiring a model of the\nenvironment, instead learning the best policy through interaction with the\nenvironment. We first designed and built a fast, low compute simulator for\ntraining and testing autonomous pentesting agents. We did this by framing\npentesting as a Markov Decision Process with the known configuration of the\nnetwork as states, the available scans and exploits as actions, the reward\ndetermined by the value of machines on the network. We then used this simulator\nto investigate the application of model-free RL to pentesting. We tested the\nstandard Q-learning algorithm using both tabular and neural network based\nimplementations. We found that within the simulated environment both tabular\nand neural network implementations were able to find optimal attack paths for a\nrange of different network topologies and sizes without having a model of\naction behaviour. However, the implemented algorithms were only practical for\nsmaller networks and numbers of actions. Further work is needed in developing\nscalable RL algorithms and testing these algorithms in larger and higher\nfidelity environments.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 06:18:14 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Schwartz", "Jonathon", ""], ["Kurniawati", "Hanna", ""]]}, {"id": "1905.05975", "submitter": "Salessawi Ferede Yitbarek", "authors": "Salessawi Ferede Yitbarek, Todd Austin", "title": "Neverland: Lightweight Hardware Extensions for Enforcing Operating\n  System Integrity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The security of applications hinges on the trustworthiness of the operating\nsystem, as applications rely on the OS to protect code and data. As a result,\nmultiple protections for safeguarding the integrity of kernel code and data are\nbeing continuously proposed and deployed. These existing protections, however,\nare far from ideal as they either provide partial protection, or require\ncomplex and high overhead hardware and software stacks.\n  In this work, we present Neverland: a low-overhead, hardware-assisted, memory\nprotection scheme that safeguards the operating system from rootkits and\nkernel-mode malware. Once the system is done booting, Neverland's hardware\ntakes away the operating system's ability to overwrite certain configuration\nregisters, as well as portions of its own physical address space that contain\nkernel code and security-critical data. Furthermore, it prohibits the CPU from\nfetching privileged code from any memory region lying outside the physical\naddresses assigned to the OS kernel and drivers (regardless of virtual page\npermissions). This combination of protections makes it extremely hard for an\nattacker to tamper with the kernel or introduce new privileged code into the\nsystem -- even in the presence of kernel vulnerabilities. Our evaluations show\nthat the extra hardware required to support these protections incurs minimal\nsilicon and energy overheads. Neverland enables operating systems to reduce\ntheir attack surface without having to rely on complex integrity monitoring\nsoftware or hardware.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 06:54:55 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Yitbarek", "Salessawi Ferede", ""], ["Austin", "Todd", ""]]}, {"id": "1905.05984", "submitter": "Simon Duque Anton", "authors": "Simon D. Duque Anton, Mathias Strufe, Hans Dieter Schotten", "title": "Modern Problems Require Modern Solutions: Hybrid Concepts for Industrial\n  Intrusion Detection", "comments": "PREPRINT, published in the proceedings of the 24th ITG Fachtagung\n  Mobilkommunikation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of Industry 4.0 brings a disruption into the processing industry.\nIt is characterised by a high degree of intercommunication, embedded\ncomputation, resulting in a decentralised and distributed handling of data.\nAdditionally, cloud-storage and Software-as-a-Service (SaaS) approaches enhance\na centralised storage and handling of data. This often takes place in\nthird-party networks. Furthermore, Industry 4.0 is driven by novel business\ncases. Lot sizes of one, customer individual production, observation of process\nstate and progress in real-time and remote maintenance, just to name a few. All\nof these new business cases make use of the novel technologies. However, cyber\nsecurity has not been an issue in industry. Industrial networks have been\nconsidered physically separated from public networks. Additionally, the high\nlevel of uniqueness of any industrial network was said to prevent attackers\nfrom exploiting flaws. Those assumptions are inherently broken by the concept\nof Industry 4.0. As a result, an abundance of attack vectors is created. In the\npast, attackers have used those attack vectors in spectacular fashions.\nEspecially Small and Mediumsized Enterprises (SMEs) in Germany struggle to\nadapt to these challenges. Reasons are the cost required for technical\nsolutions and security professionals. In order to enable SMEs to cope with the\ngrowing threat in the cyberspace, the research project IUNO Insec aims at\nproviding and improving security solutions that can be used without specialised\nsecurity knowledge. The project IUNO Insec is briefly introduced in this work.\nFurthermore, contributions in the field of intrusion detection, especially\nmachine learning-based solutions, for industrial environments provided by the\nauthors are presented and set into context.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 07:15:32 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 14:08:41 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Anton", "Simon D. Duque", ""], ["Strufe", "Mathias", ""], ["Schotten", "Hans Dieter", ""]]}, {"id": "1905.05999", "submitter": "Matteo Romiti", "authors": "Matteo Romiti, Aljosha Judmayer, Alexei Zamyatin, Bernhard Haslhofer", "title": "A Deep Dive into Bitcoin Mining Pools: An Empirical Analysis of Mining\n  Shares", "comments": "Conference paper https://weis2019.econinfosec.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Miners play a key role in cryptocurrencies such as Bitcoin: they invest\nsubstantial computational resources in processing transactions and minting new\ncurrency units. It is well known that an attacker controlling more than half of\nthe network's mining power could manipulate the state of the system at will.\nWhile the influence of large mining pools appears evenly split, the actual\ndistribution of mining power within these pools and their economic\nrelationships with other actors remain undisclosed. To this end, we conduct the\nfirst in-depth analysis of mining reward distribution within three of the four\nlargest Bitcoin mining pools and examine their cross-pool economic\nrelationships. Our results suggest that individual miners are simultaneously\noperating across all three pools and that in each analyzed pool a small number\nof actors (<= 20) receives over 50% of all BTC payouts. While the extent of an\noperator's control over the resources of a mining pool remains an open debate,\nour findings are in line with previous research, pointing out centralization\ntendencies in large mining pools and cryptocurrencies in general.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 07:41:18 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Romiti", "Matteo", ""], ["Judmayer", "Aljosha", ""], ["Zamyatin", "Alexei", ""], ["Haslhofer", "Bernhard", ""]]}, {"id": "1905.06122", "submitter": "Igor Ivkic", "authors": "David Hofbauer, Igor Ivkic, Silia Maksuti, Andreas Aldrian, Markus\n  Tauber", "title": "On the Cost of Security Compliance in Information Systems", "comments": null, "journal-ref": "10th International Multi-Conference on Complexity, Informatics and\n  Cybernetics 2019 (IMCIC)", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The onward development of information and communication technology has led to\na new industrial revolution called Industry 4.0. This revolution involves\nCyber-Physical Production Systems (CPPS), which consist of intelligent\nCyber-Physical Systems that may be able to adapt themselves autonomously in a\nproduction environment. At the moment, machines in industrial environments are\noften not connected to the internet, which thus needs a point-to-point\nconnection to access the device if necessary. Through Industry 4.0, these\ndevices should enable remote access for smart maintenance through a connection\nto the outside world. However, this connection opens the gate for possible\ncyber-attacks and thus raises the question about providing security for these\nenvironments. Therefore, this paper used an adapted approach based on SixSigma\nto solve this security problem by investigating security standards. Security\nrequirements were gathered and mapped to controls from well known security\nstandards, formed into a catalog. This catalog includes assessment information\nto check how secure a solution for a use case is and also includes a link to an\nestimation method for implementation cost. Thus this papers outcome shows how\nto make Industry 4.0 use cases secure by fulfilling security standard controls\nand how to estimate the resulting implementation costs.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 12:18:48 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Hofbauer", "David", ""], ["Ivkic", "Igor", ""], ["Maksuti", "Silia", ""], ["Aldrian", "Andreas", ""], ["Tauber", "Markus", ""]]}, {"id": "1905.06124", "submitter": "Igor Ivkic", "authors": "Igor Ivkic, Andreas Mauthe, Markus Tauber", "title": "Towards a Security Cost Model for Cyber-Physical Systems", "comments": null, "journal-ref": "2019 16th IEEE Annual Consumer Communications & Networking\n  Conference (CCNC), Las Vegas, USA", "doi": "10.1109/CCNC.2019.8651751", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In times of Industry 4.0 and cyber-physical systems (CPS) providing security\nis one of the biggest challenges. A cyber attack launched at a CPS poses a huge\nthreat, since a security incident may affect both the cyber and the physical\nworld. Since CPS are very flexible systems, which are capable of adapting to\nenvironmental changes, it is important to keep an overview of the resulting\ncosts of providing security. However, research regarding CPS currently focuses\nmore on engineering secure systems and does not satisfactorily provide\napproaches for evaluating the resulting costs. This paper presents an\ninteraction-based model for evaluating security costs in a CPS. Furthermore,\nthe paper demonstrates in a use case driven study, how this approach could be\nused to model the resulting costs for guaranteeing security.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 12:19:48 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Ivkic", "Igor", ""], ["Mauthe", "Andreas", ""], ["Tauber", "Markus", ""]]}, {"id": "1905.06186", "submitter": "John Collomosse", "authors": "Yifan Yang, Daniel Cooper, John Collomosse, Constantin C. Dr\\u{a}gan,\n  Mark Manulis, Jamie Steane, Arthi Manohar, Jo Briggs, Helen Jones, Wendy\n  Moncur", "title": "TAPESTRY: A Blockchain based Service for Trusted Interaction Online", "comments": "Submitted to IEEE TSC Special Issue on Blockchain Services, May 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel blockchain based service for proving the provenance of\nonline digital identity, exposed as an assistive tool to help non-expert users\nmake better decisions about whom to trust online. Our service harnesses the\ndigital personhood (DP); the longitudinal and multi-modal signals created\nthrough users' lifelong digital interactions, as a basis for evidencing the\nprovenance of identity. We describe how users may exchange trust evidence\nderived from their DP, in a granular and privacy-preserving manner, with other\nusers in order to demonstrate coherence and longevity in their behaviour\nonline. This is enabled through a novel secure infrastructure combining hybrid\non- and off-chain storage combined with deep learning for DP analytics and\nvisualization. We show how our tools enable users to make more effective\ndecisions on whether to trust unknown third parties online, and also to spot\nbehavioural deviations in their own social media footprints indicative of\naccount hijacking.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 13:49:23 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Yang", "Yifan", ""], ["Cooper", "Daniel", ""], ["Collomosse", "John", ""], ["Dr\u0103gan", "Constantin C.", ""], ["Manulis", "Mark", ""], ["Steane", "Jamie", ""], ["Manohar", "Arthi", ""], ["Briggs", "Jo", ""], ["Jones", "Helen", ""], ["Moncur", "Wendy", ""]]}, {"id": "1905.06204", "submitter": "Stefan Schulte", "authors": "Michael Borkowski and Marten Sigwart and Philipp Frauenthaler and\n  Taneli Hukkinen and Stefan Schulte", "title": "DeXTT: Deterministic Cross-Blockchain Token Transfers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current blockchain technologies provide very limited interoperability.\nRestrictions with regards to asset transfers and data exchange between\ndifferent blockchains reduce usability and comfort for users, and hinder novel\ndevelopments within the blockchain space.\n  As a first step towards cross-blockchain interoperability, we propose the\nDeXTT cross-blockchain transfer protocol, which can be used to transfer a token\non any number of blockchains simultaneously in a decentralized manner. We\nprovide a reference implementation using Solidity, and evaluate its\nperformance. We show logarithmic scalability of DeXTT with respect to the\nnumber of participating nodes, and analyze cost requirements of the transferred\ntokens.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 14:19:21 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Borkowski", "Michael", ""], ["Sigwart", "Marten", ""], ["Frauenthaler", "Philipp", ""], ["Hukkinen", "Taneli", ""], ["Schulte", "Stefan", ""]]}, {"id": "1905.06247", "submitter": "Yvan Lucas", "authors": "Yvan Lucas, Pierre-Edouard Portier, L\\'ea Laporte, Olivier Caelen,\n  Liyun He-Guelton, Sylvie Calabretto, Michael Granitzer", "title": "Multiple perspectives HMM-based feature engineering for credit card\n  fraud detection", "comments": "Presented as a poster in the conference SAC 2019: 34th ACM/SIGAPP\n  Symposium on Applied Computing in April 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and data mining techniques have been used extensively in\norder to detect credit card frauds. However, most studies consider credit card\ntransactions as isolated events and not as a sequence of transactions.\n  In this article, we model a sequence of credit card transactions from three\ndifferent perspectives, namely (i) does the sequence contain a Fraud? (ii) Is\nthe sequence obtained by fixing the card-holder or the payment terminal? (iii)\nIs it a sequence of spent amount or of elapsed time between the current and\nprevious transactions? Combinations of the three binary perspectives give eight\nsets of sequences from the (training) set of transactions. Each one of these\nsets is modelled with a Hidden Markov Model (HMM). Each HMM associates a\nlikelihood to a transaction given its sequence of previous transactions. These\nlikelihoods are used as additional features in a Random Forest classifier for\nfraud detection. This multiple perspectives HMM-based approach enables an\nautomatic feature engineering in order to model the sequential properties of\nthe dataset with respect to the classification task. This strategy allows for a\n15% increase in the precision-recall AUC compared to the state of the art\nfeature engineering strategy for credit card fraud detection.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 15:29:49 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Lucas", "Yvan", ""], ["Portier", "Pierre-Edouard", ""], ["Laporte", "L\u00e9a", ""], ["Caelen", "Olivier", ""], ["He-Guelton", "Liyun", ""], ["Calabretto", "Sylvie", ""], ["Granitzer", "Michael", ""]]}, {"id": "1905.06262", "submitter": "Felipe Ducau", "authors": "Felipe N. Ducau, Ethan M. Rudd, Tad M. Heppner, Alex Long, and\n  Konstantin Berlin", "title": "Automatic Malware Description via Attribute Tagging and Similarity\n  Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid proliferation and increased sophistication of malicious\nsoftware (malware), detection methods no longer rely only on manually generated\nsignatures but have also incorporated more general approaches like machine\nlearning detection. Although powerful for conviction of malicious artifacts,\nthese methods do not produce any further information about the type of threat\nthat has been detected neither allows for identifying relationships between\nmalware samples. In this work, we address the information gap between machine\nlearning and signature-based detection methods by learning a representation\nspace for malware samples in which files with similar malicious behaviors\nappear close to each other. We do so by introducing a deep learning based\ntagging model trained to generate human-interpretable semantic descriptions of\nmalicious software, which, at the same time provides potentially more useful\nand flexible information than malware family names.\n  We show that the malware descriptions generated with the proposed approach\ncorrectly identify more than 95% of eleven possible tag descriptions for a\ngiven sample, at a deployable false positive rate of 1% per tag. Furthermore,\nwe use the learned representation space to introduce a similarity index between\nmalware files, and empirically demonstrate using dynamic traces from files'\nexecution, that is not only more effective at identifying samples from the same\nfamilies, but also 32 times smaller than those based on raw feature vectors.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 16:03:46 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 17:52:08 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 16:09:15 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Ducau", "Felipe N.", ""], ["Rudd", "Ethan M.", ""], ["Heppner", "Tad M.", ""], ["Long", "Alex", ""], ["Berlin", "Konstantin", ""]]}, {"id": "1905.06280", "submitter": "Hisham Galal S.", "authors": "Hisham S. Galal and Amr M. Youssef", "title": "Trustee: Full Privacy Preserving Vickrey Auction on top of Ethereum", "comments": "Presented at Financial Cryptography and Data Security 2019, 3rd\n  Workshop on Trusted Smart Contracts", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide deployment of tokens for digital assets on top of Ethereum implies\nthe need for powerful trading platforms. Vickrey auctions have been known to\ndetermine the real market price of items as bidders are motivated to submit\ntheir own monetary valuations without leaking their information to the\ncompetitors. Recent constructions have utilized various cryptographic protocols\nsuch as ZKP and MPC, however, these approaches either are partially\nprivacy-preserving or require complex computations with several rounds. In this\npaper, we overcome these limits by presenting Trustee as a Vickrey auction on\nEthereum which fully preserves bids' privacy at relatively much lower fees.\nTrustee consists of three components: a front-end smart contract deployed on\nEthereum, an Intel SGX enclave, and a relay to redirect messages between them.\nInitially, the enclave generates an Ethereum account and ECDH key-pair.\nSubsequently, the relay publishes the account's address and ECDH public key on\nthe smart contract. As a prerequisite, bidders are encouraged to verify the\nauthenticity and security of Trustee by using the SGX remote attestation\nservice. To participate in the auction, bidders utilize the ECDH public key to\nencrypt their bids and submit them to the smart contract. Once the bidding\ninterval is closed, the relay retrieves the encrypted bids and feeds them to\nthe enclave that autonomously generates a signed transaction indicating the\nauction winner. Finally, the relay submits the transaction to the smart\ncontract which verifies the transaction's authenticity and the parameters'\nconsistency before accepting the claimed auction winner. As part of our\ncontributions, we have made a prototype for Trustee available on Github for the\ncommunity to review and inspect it. Additionally, we analyze the security\nfeatures of Trustee and report on the transactions' gas cost incurred on\nTrustee smart contract.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 16:28:54 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Galal", "Hisham S.", ""], ["Youssef", "Amr M.", ""]]}, {"id": "1905.06361", "submitter": "M. Emre Gursoy", "authors": "Mehmet Emre Gursoy, Acar Tamersoy, Stacey Truex, Wenqi Wei, Ling Liu", "title": "Secure and Utility-Aware Data Collection with Condensed Local\n  Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local Differential Privacy (LDP) is popularly used in practice for\nprivacy-preserving data collection. Although existing LDP protocols offer high\nutility for large user populations (100,000 or more users), they perform poorly\nin scenarios with small user populations (such as those in the cybersecurity\ndomain) and lack perturbation mechanisms that are effective for both ordinal\nand non-ordinal item sequences while protecting sequence length and content\nsimultaneously. In this paper, we address the small user population problem by\nintroducing the concept of Condensed Local Differential Privacy (CLDP) as a\nspecialization of LDP, and develop a suite of CLDP protocols that offer\ndesirable statistical utility while preserving privacy. Our protocols support\ndifferent types of client data, ranging from ordinal data types in finite\nmetric spaces (numeric malware infection statistics), to non-ordinal items (OS\nversions, transaction categories), and to sequences of ordinal and non-ordinal\nitems. Extensive experiments are conducted on multiple datasets, including\ndatasets that are an order of magnitude smaller than those used in existing\napproaches, which show that proposed CLDP protocols yield high utility.\nFurthermore, case studies with Symantec datasets demonstrate that our protocols\naccurately support key cybersecurity-focused tasks of detecting ransomware\noutbreaks, identifying targeted and vulnerable OSs, and inspecting suspicious\nactivities on infected machines.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 18:06:58 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2019 05:51:37 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Gursoy", "Mehmet Emre", ""], ["Tamersoy", "Acar", ""], ["Truex", "Stacey", ""], ["Wei", "Wenqi", ""], ["Liu", "Ling", ""]]}, {"id": "1905.06396", "submitter": "Amir Alipour-Fanid", "authors": "Amir Alipour-Fanid, Monireh Dabaghchian, Ning Wang, Pu Wang, Liang\n  Zhao, Kai Zeng", "title": "Machine Learning-Based Delay-Aware UAV Detection and Operation Mode\n  Identification over Encrypted Wi-Fi Traffic", "comments": null, "journal-ref": "IEEE Transactions on Information Forensics and Security (2019)", "doi": "10.1109/TIFS.2019.2959899", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The consumer UAV (unmanned aerial vehicle) market has grown significantly\nover the past few years. Despite its huge potential in spurring economic growth\nby supporting various applications, the increase of consumer UAVs poses\npotential risks to public security and personal privacy. To minimize the risks,\nefficiently detecting and identifying invading UAVs is in urgent need for both\ninvasion detection and forensics purposes. Given the fact that consumer UAVs\nare usually used in a civilian environment, existing physical detection methods\n(such as radar, vision, and sound) may become ineffective in many scenarios.\nAiming to complement the existing physical detection mechanisms, we propose a\nmachine learning-based framework for fast UAV identification over encrypted\nWi-Fi traffic. It is motivated by the observation that many consumer UAVs use\nWi-Fi links for control and video streaming. The proposed framework extracts\nfeatures derived only from packet size and inter-arrival time of encrypted\nWi-Fi traffic, and can efficiently detect UAVs and identify their operation\nmodes. In order to reduce the online identification time, our framework adopts\na re-weighted $\\ell_1$-norm regularization, which considers the number of\nsamples and computation cost of different features. This framework jointly\noptimizes feature selection and prediction performance in a unified objective\nfunction. To tackle the packet inter-arrival time uncertainty when optimizing\nthe trade-off between the detection accuracy and delay, we utilize Maximum\nLikelihood Estimation (MLE) method to estimate the packet inter-arrival time.\nWe collect a large number of real-world Wi-Fi data traffic of eight types of\nconsumer UAVs and conduct extensive evaluation on the performance of our\nproposed method.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 19:12:43 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 21:45:36 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Alipour-Fanid", "Amir", ""], ["Dabaghchian", "Monireh", ""], ["Wang", "Ning", ""], ["Wang", "Pu", ""], ["Zhao", "Liang", ""], ["Zeng", "Kai", ""]]}, {"id": "1905.06455", "submitter": "Bai Li", "authors": "Bai Li, Changyou Chen, Wenlin Wang, Lawrence Carin", "title": "On Norm-Agnostic Robustness of Adversarial Training", "comments": "4 pages, 2 figures, presented at the ICML 2019 Workshop on\n  Uncertainty and Robustness in Deep Learning. arXiv admin note: text overlap\n  with arXiv:1809.03113", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial examples are carefully perturbed in-puts for fooling machine\nlearning models. A well-acknowledged defense method against such examples is\nadversarial training, where adversarial examples are injected into training\ndata to increase robustness. In this paper, we propose a new attack to unveil\nan undesired property of the state-of-the-art adversarial training, that is it\nfails to obtain robustness against perturbations in $\\ell_2$ and $\\ell_\\infty$\nnorms simultaneously. We discuss a possible solution to this issue and its\nlimitations as well.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 22:07:19 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Li", "Bai", ""], ["Chen", "Changyou", ""], ["Wang", "Wenlin", ""], ["Carin", "Lawrence", ""]]}, {"id": "1905.06460", "submitter": "Hung Dang", "authors": "Hung Dang, Ee-Chien Chang", "title": "Autonomous Membership Service for Enclave Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trusted Execution Environment, or enclave, promises to protect data\nconfidentiality and execution integrity of an outsourced computation on an\nuntrusted host. Extending the protection to distributed applications that run\non physically separated hosts, however, remains non-trivial. For instance, the\ncurrent enclave provisioning model hinders elasticity of cloud applications.\nFurthermore, it remains unclear how an enclave process could verify if there\nexists another concurrently running enclave process instantiated using the same\ncodebase, or count a number of such processes. In this paper, we seek an\nautonomous membership service for enclave applications. The application owner\nonly needs to partake in instantiating the very first process of the\napplication, whereas all subsequent process commission and decommission will be\nadministered by existing and active processes of that very application. To\nachieve both safety and liveness, our protocol design admits unjust\nexcommunication of a non-faulty process from the membership group. We implement\nthe proposed membership service in a system called AMES. Our experimental study\nshows that AMES incurs an overhead of 5% - 16% compared to vanilla enclave\nexecution.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 22:33:42 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Dang", "Hung", ""], ["Chang", "Ee-Chien", ""]]}, {"id": "1905.06492", "submitter": "Marius Silaghi", "authors": "Wesam Eid and Marius C. Silaghi", "title": "Speeding Up Elliptic Curve Multiplication with Mixed-base Representation\n  for Applications to SIDH Ciphers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Elliptic curve multiplications can be improved by replacing the standard\nladder algorithm's base 2 representation of the scalar multiplicand, with\nmixed-base representations with power-of-2 bases, processing the n bits of the\ncurrent digit in one optimized step. For this purpose, we also present a new\nmethodology to compute, for Weierstrass form elliptic curves in the affine\nplane, operations of the type mP+nQ where m and n are small integers. This\nprovides implementations with the lower cost than previous algorithms, using\nonly one inversion. In particular, the proposed techniques enable more\nopportunities for optimizing computations, leading to an important speed-up for\napplications based on elliptic curves, including the post-quantum cryptosystem\nSuper Singular Isogeny Diffie Hellman (SIDH).\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 01:49:32 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 15:21:56 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Eid", "Wesam", ""], ["Silaghi", "Marius C.", ""]]}, {"id": "1905.06494", "submitter": "Fang Liu", "authors": "Fang Liu and Ness Shroff", "title": "Data Poisoning Attacks on Stochastic Bandits", "comments": "Accepted by ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic multi-armed bandits form a class of online learning problems that\nhave important applications in online recommendation systems, adaptive medical\ntreatment, and many others. Even though potential attacks against these\nlearning algorithms may hijack their behavior, causing catastrophic loss in\nreal-world applications, little is known about adversarial attacks on bandit\nalgorithms. In this paper, we propose a framework of offline attacks on bandit\nalgorithms and study convex optimization based attacks on several popular\nbandit algorithms. We show that the attacker can force the bandit algorithm to\npull a target arm with high probability by a slight manipulation of the rewards\nin the data. Then we study a form of online attacks on bandit algorithms and\npropose an adaptive attack strategy against any bandit algorithm without the\nknowledge of the bandit algorithm. Our adaptive attack strategy can hijack the\nbehavior of the bandit algorithm to suffer a linear regret with only a\nlogarithmic cost to the attacker. Our results demonstrate a significant\nsecurity threat to stochastic bandits.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 01:54:31 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Liu", "Fang", ""], ["Shroff", "Ness", ""]]}, {"id": "1905.06635", "submitter": "Seungyong Moon", "authors": "Seungyong Moon, Gaon An, Hyun Oh Song", "title": "Parsimonious Black-Box Adversarial Attacks via Efficient Combinatorial\n  Optimization", "comments": "Accepted and to appear at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving for adversarial examples with projected gradient descent has been\ndemonstrated to be highly effective in fooling the neural network based\nclassifiers. However, in the black-box setting, the attacker is limited only to\nthe query access to the network and solving for a successful adversarial\nexample becomes much more difficult. To this end, recent methods aim at\nestimating the true gradient signal based on the input queries but at the cost\nof excessive queries. We propose an efficient discrete surrogate to the\noptimization problem which does not require estimating the gradient and\nconsequently becomes free of the first order update hyperparameters to tune.\nOur experiments on Cifar-10 and ImageNet show the state of the art black-box\nattack performance with significant reduction in the required queries compared\nto a number of recently proposed methods. The source code is available at\nhttps://github.com/snu-mllab/parsimonious-blackbox-attack.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 10:14:20 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Moon", "Seungyong", ""], ["An", "Gaon", ""], ["Song", "Hyun Oh", ""]]}, {"id": "1905.06685", "submitter": "Steffen Haas", "authors": "Steffen Haas, Florian Wilkens, Mathias Fischer", "title": "Efficient Attack Correlation and Identification of Attack Scenarios\n  based on Network-Motifs", "comments": "S. Haas, F. Wilkens and M. Fischer, \"Efficient Attack Correlation and\n  Identification of Attack Scenarios based on Network-Motifs,\" 2019 IEEE 38th\n  International Performance Computing and Communications Conference (IPCCC),\n  London, United Kingdom, 2019, pp. 1-11. doi: 10.1109/IPCCC47392.2019.8958734", "journal-ref": "2019 IEEE 38th International Performance Computing and\n  Communications Conference (IPCCC), London, United Kingdom, 2019, pp. 1-11", "doi": "10.1109/IPCCC47392.2019.8958734", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An Intrusion Detection System (IDS) to secure computer networks reports\nindicators for an attack as alerts. However, every attack can result in a\nmultitude of IDS alerts that need to be correlated to see the full picture of\nthe attack. In this paper, we present a correlation approach that transforms\nclusters of alerts into a graph structure on which we compute signatures of\nnetwork motifs to characterize these clusters. A motif representation of attack\ncharacteristics is magnitudes smaller than the original alert data, but still\nallows to efficiently compare and correlate attacks with each other and with\nreference signatures. This allows not only to identify known attack scenarios,\ne.g., DDoS, scan, and worm attacks, but also to derive new reference signatures\nfor unknown scenarios. Our results indicate a reliable identification of\nscenarios, even when attacks differ in size and at least slightly in their\ncharacteristics. Applied on real-world alert data, our approach can classify\nand assign attack scenarios of up to 96% of all attacks and can represent their\ncharacteristics using 1% of the size of the full alert data.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 12:23:51 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 08:47:54 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Haas", "Steffen", ""], ["Wilkens", "Florian", ""], ["Fischer", "Mathias", ""]]}, {"id": "1905.06709", "submitter": "Igor Ivkic", "authors": "Elisabeth Bauer, Oliver Schluga, Silia Maksuti, Ani Bicaku, David\n  Hofbauer, Igor Ivkic, Markus Tauber, Alexander W\\\"ohrer", "title": "Towards a Security Baseline for IaaS-Cloud Back-Ends in Industry 4.0", "comments": null, "journal-ref": "2017 12th International Conference for Internet Technology and\n  Secured Transactions (ICITST), Cambridge, UK", "doi": "10.23919/ICITST.2017.8356438", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of cloud based Infrastructure-as-a- Service (IaaS) solutions\nis becoming increasingly popular. However, since IaaS providers and customers\ninteract in a flexible and scalable environment, security remains a serious\nconcern. To handle such security issues, defining a set of security parameters\nin the service level agreements (SLA) between both, IaaS provider and customer,\nis of utmost importance. In this paper, the European Network and Information\nSecurity Agency (ENISA) guidelines are evaluated to extract a set of security\nparameters for IaaS. Furthermore, the level of applicability and implementation\nof this set is used to assess popular industrial and open-source IaaS cloud\nplatforms, respectively VMware and OpenStack. Both platforms provide private\nclouds, used as backend infrastructures in Industry 4.0 application scenarios.\nThe results serve as initial work to identify a security baseline and research\nneeds for creating secure cloud environments for Industry 4.0.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 10:04:51 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Bauer", "Elisabeth", ""], ["Schluga", "Oliver", ""], ["Maksuti", "Silia", ""], ["Bicaku", "Ani", ""], ["Hofbauer", "David", ""], ["Ivkic", "Igor", ""], ["Tauber", "Markus", ""], ["W\u00f6hrer", "Alexander", ""]]}, {"id": "1905.06711", "submitter": "Igor Ivkic", "authors": "Igor Ivkic, Stephan Wolfauer, Thomas Oberhofer, Markus Tauber", "title": "On the Cost of Cyber Security in Smart Business", "comments": null, "journal-ref": "2017 12th International Conference for Internet Technology and\n  Secured Transactions (ICITST), Cambridge, UK", "doi": "10.23919/ICITST.2017.8356395", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a world, as complex and constantly changing as ours cloud computing is a\ndriving force for shaping the IT landscape and changing the way we do business.\nCurrent trends show a world of people, things and services all digitally\ninterconnected via the Internet of Things (IoT). This applies in particular to\nan industrial environment where smart devices and intelligent services pave the\nway for smart factories and smart businesses. This paper investigates in a use\ncase driven study the potential of making use of smart devices to enable\ndirect, automated and voice-controlled smart businesses. Furthermore, the paper\npresents an initial investigation on methodologies for measuring costs of cyber\nsecurity controls for cloud services.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 09:59:39 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Ivkic", "Igor", ""], ["Wolfauer", "Stephan", ""], ["Oberhofer", "Thomas", ""], ["Tauber", "Markus", ""]]}, {"id": "1905.06852", "submitter": "Marten Sigwart", "authors": "Marten Sigwart, Michael Borkowski, Marco Peise, Stefan Schulte, Stefan\n  Tai", "title": "Blockchain-based Data Provenance for the Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As more and more applications and services depend on data collected and\nprovided by Internet of Things (IoT) devices, it is of importance that such\ndata can be trusted. Data provenance solutions together with blockchain\ntechnology are one way to make data more trustworthy. However, current\nsolutions do not address the heterogeneous nature of IoT applications and their\ndata. In this work, we identify functional and non-functional requirements for\na generic IoT data provenance framework, and conceptualise the framework as a\nlayered architecture. Using a proof-of-concept implementation based on Ethereum\nsmart contracts, data provenance can be realised for a wide range of IoT use\ncases. Benefits of a generic framework include simplified adoption and a more\nrapid implementation of data provenance for the IoT.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 13:41:24 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 12:21:47 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Sigwart", "Marten", ""], ["Borkowski", "Michael", ""], ["Peise", "Marco", ""], ["Schulte", "Stefan", ""], ["Tai", "Stefan", ""]]}, {"id": "1905.06853", "submitter": "Tin Leelavimolsilp", "authors": "Tin Leelavimolsilp, Long Tran-Thanh, Sebastian Stein, Viet Hung Nguyen", "title": "Selfish Mining in Proof-of-Work Blockchain with Multiple Miners: An\n  Empirical Evaluation", "comments": "Accepted in PRIMA2019", "journal-ref": null, "doi": "10.1007/978-3-030-33792-6_14", "report-no": null, "categories": "cs.CR cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proof-of-Work blockchain, despite its numerous benefits, is still not an\nentirely secure technology due to the existence of Selfish Mining (SM)\nstrategies that can disrupt the system and its mining economy. While the effect\nof SM has been studied mostly in a two-miners scenario, it has not been\ninvestigated in a more practical context where there are multiple malicious\nminers individually performing SM.\n  To fill this gap, we carry out an empirical study that separately accounts\nfor different numbers of SM miners (who always perform SM) and strategic miners\n(who choose either SM or Nakamoto's mining protocol depending on which\nmaximises their individual mining reward).\n  Our result shows that SM is generally more effective as the number of SM\nminers increases, however its effectiveness does not vary in the presence of a\nlarge number of strategic miners. Under specific mining power distributions, we\nalso demonstrate that multiple miners can perform SM and simultaneously gain\nhigher mining rewards than they should. Surprisingly, we also show that the\nmore strategic miners there are, the more robust the systems become. Since\nblockchain miners should naturally be seen as self-interested strategic miners,\nour findings encourage blockchain system developers and engineers to attract as\nmany miners as possible to prevent SM and similar behaviour.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 13:35:15 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2019 14:04:53 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Leelavimolsilp", "Tin", ""], ["Tran-Thanh", "Long", ""], ["Stein", "Sebastian", ""], ["Nguyen", "Viet Hung", ""]]}, {"id": "1905.06916", "submitter": "Owen Levin", "authors": "Owen Levin, Zihang Meng, Vikas Singh, Xiaojin Zhu", "title": "Fooling Computer Vision into Inferring the Wrong Body Mass Index", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently it's been shown that neural networks can use images of human faces\nto accurately predict Body Mass Index (BMI), a widely used health indicator. In\nthis paper we demonstrate that a neural network performing BMI inference is\nindeed vulnerable to test-time adversarial attacks. This extends test-time\nadversarial attacks from classification tasks to regression. The application we\nhighlight is BMI inference in the insurance industry, where such adversarial\nattacks imply a danger of insurance fraud.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 17:29:08 GMT"}], "update_date": "2019-05-18", "authors_parsed": [["Levin", "Owen", ""], ["Meng", "Zihang", ""], ["Singh", "Vikas", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "1905.06944", "submitter": "Valentin W\\\"ustholz", "authors": "Valentin W\\\"ustholz, Maria Christakis", "title": "Harvey: A Greybox Fuzzer for Smart Contracts", "comments": "arXiv admin note: substantial text overlap with arXiv:1807.07875", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Harvey, an industrial greybox fuzzer for smart contracts, which\nare programs managing accounts on a blockchain. Greybox fuzzing is a\nlightweight test-generation approach that effectively detects bugs and security\nvulnerabilities. However, greybox fuzzers randomly mutate program inputs to\nexercise new paths; this makes it challenging to cover code that is guarded by\nnarrow checks, which are satisfied by no more than a few input values.\nMoreover, most real-world smart contracts transition through many different\nstates during their lifetime, e.g., for every bid in an auction. To explore\nthese states and thereby detect deep vulnerabilities, a greybox fuzzer would\nneed to generate sequences of contract transactions, e.g., by creating bids\nfrom multiple users, while at the same time keeping the search space and test\nsuite tractable. In this experience paper, we explain how Harvey alleviates\nboth challenges with two key fuzzing techniques and distill the main lessons\nlearned. First, Harvey extends standard greybox fuzzing with a method for\npredicting new inputs that are more likely to cover new paths or reveal\nvulnerabilities in smart contracts. Second, it fuzzes transaction sequences in\na targeted and demand-driven way. We have evaluated our approach on 27\nreal-world contracts. Our experiments show that the underlying techniques\nsignificantly increase Harvey's effectiveness in achieving high coverage and\ndetecting vulnerabilities, in most cases orders-of-magnitude faster; they also\nreveal new insights about contract code.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 16:45:16 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["W\u00fcstholz", "Valentin", ""], ["Christakis", "Maria", ""]]}, {"id": "1905.06946", "submitter": "Chao Yan", "authors": "Chao Yan, Haifeng Xu, Yevgeniy Vorobeychik, Bo Li, Daniel Fabbri,\n  Bradley Malin", "title": "To Warn or Not to Warn: Online Signaling in Audit Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Routine operational use of sensitive data is often governed by law and\nregulation. For instance, in the medical domain, there are various statues at\nthe state and federal level that dictate who is permitted to work with\npatients' records and under what conditions. To screen for potential privacy\nbreaches, logging systems are usually deployed to trigger alerts whenever\nsuspicious access is detected. However, such mechanisms are often inefficient\nbecause 1) the vast majority of triggered alerts are false positives, 2) small\nbudgets make it unlikely that a real attack will be detected, and 3) attackers\ncan behave strategically, such that traditional auditing mechanisms cannot\neasily catch them. To improve efficiency, information systems may invoke\nsignaling, so that whenever a suspicious access request occurs, the system can,\nin real time, warn the user that the access may be audited. Then, at the close\nof a finite period, a selected subset of suspicious accesses are audited. This\ngives rise to an online problem in which one needs to determine 1) whether a\nwarning should be triggered and 2) the likelihood that the data request event\nwill be audited. In this paper, we formalize this auditing problem as a\nSignaling Audit Game (SAG), in which we model the interactions between an\nauditor and an attacker in the context of signaling and the usability cost is\nrepresented as a factor of the auditor's payoff. We study the properties of its\nStackelberg equilibria and develop a scalable approach to compute its solution.\nWe show that a strategic presentation of warnings adds value in that SAGs\nrealize significantly higher utility for the auditor than systems without\nsignaling. We illustrate the value of the proposed auditing model and the\nconsistency of its advantages over existing baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 05:08:51 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 20:03:23 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Yan", "Chao", ""], ["Xu", "Haifeng", ""], ["Vorobeychik", "Yevgeniy", ""], ["Li", "Bo", ""], ["Fabbri", "Daniel", ""], ["Malin", "Bradley", ""]]}, {"id": "1905.06987", "submitter": "Adarsh Kyadige", "authors": "Adarsh Kyadige, Ethan M. Rudd, Konstantin Berlin", "title": "Learning from Context: Exploiting and Interpreting File Path Information\n  for Better Malware Detection", "comments": "Submitted to ACM CCS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) used for static portable executable (PE) malware\ndetection typically employs per-file numerical feature vector representations\nas input with one or more target labels during training. However, there is much\northogonal information that can be gleaned from the \\textit{context} in which\nthe file was seen. In this paper, we propose utilizing a static source of\ncontextual information -- the path of the PE file -- as an auxiliary input to\nthe classifier. While file paths are not malicious or benign in and of\nthemselves, they do provide valuable context for a malicious/benign\ndetermination. Unlike dynamic contextual information, file paths are available\nwith little overhead and can seamlessly be integrated into a multi-view static\nML detector, yielding higher detection rates at very high throughput with\nminimal infrastructural changes. Here we propose a multi-view neural network,\nwhich takes feature vectors from PE file content as well as corresponding file\npaths as inputs and outputs a detection score. To ensure realistic evaluation,\nwe use a dataset of approximately 10 million samples -- files and file paths\nfrom user endpoints of an actual security vendor network. We then conduct an\ninterpretability analysis via LIME modeling to ensure that our classifier has\nlearned a sensible representation and see which parts of the file path most\ncontributed to change in the classifier's score. We find that our model learns\nuseful aspects of the file path for classification, while also learning\nartifacts from customers testing the vendor's product, e.g., by downloading a\ndirectory of malware samples each named as their hash. We prune these artifacts\nfrom our test dataset and demonstrate reductions in false negative rate of\n32.3% at a $10^{-3}$ false positive rate (FPR) and 33.1% at $10^{-4}$ FPR, over\na similar topology single input PE file content only model.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 18:36:55 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Kyadige", "Adarsh", ""], ["Rudd", "Ethan M.", ""], ["Berlin", "Konstantin", ""]]}, {"id": "1905.07014", "submitter": "Philipp Frauenthaler", "authors": "Philipp Frauenthaler, Michael Borkowski and Stefan Schulte", "title": "A Framework for Blockchain Interoperability and Runtime Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The suitability of a particular blockchain for a given use case depends\nmainly on the blockchain's functional and non-functional properties. Such\nproperties may vary over time, and thus, a selected blockchain may become\nunsuitable for a given use case. This uncertainty may hinder the widespread\nadoption of blockchain technologies in general. To mitigate the impact of\nvolatile blockchain properties, we propose a framework that monitors several\nblockchains, allows the user to define functional and non-functional\nrequirements, determines the most appropriate blockchain, and enables the\nswitchover to that chain at runtime. Our evaluation using a reference\nimplementation shows that switching to another blockchain can save cost and\nenable users to benefit from better performance and a higher level of trust.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 13:42:46 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Frauenthaler", "Philipp", ""], ["Borkowski", "Michael", ""], ["Schulte", "Stefan", ""]]}, {"id": "1905.07059", "submitter": "David Thaw", "authors": "Carrie Gardner, Abby Waliga, David Thaw, and Sarah Churchman", "title": "Using Camouflaged Cyber Simulations as a Model to Ensure Validity in\n  Cybersecurity Experimentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental research methods describe standards to safeguard scientific\nintegrity and reputability. These methods have been extensively integrated into\ntraditional scientific disciplines and studied in the philosophy of science.\nThe field of cybersecurity is just beginning to develop preliminary research\nstandards and modeling practices. As such, the science of cybersecurity\nroutinely fails to meet empirical research criteria, such as internal validity,\nexternal validity, and construct validity. These standards of experimentation\nenable the development of metrics, create assurance of experimental soundness,\nand aid in the generalizability of results. To facilitate such empirical\nexperimentation in cybersecurity, we propose the adaptation of camouflaged\ncyber simulations as an approach for cybersecurity research. This research tool\nsupports this mechanistic method of experimentation and aids in the\nconstruction of general cybersecurity research best practices.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 23:22:21 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Gardner", "Carrie", ""], ["Waliga", "Abby", ""], ["Thaw", "David", ""], ["Churchman", "Sarah", ""]]}, {"id": "1905.07065", "submitter": "Li Chen", "authors": "Li Chen", "title": "Privacy Preserving Adjacency Spectral Embedding on Stochastic\n  Blockmodels", "comments": "Accepted at Learning and Reasoning with Graph-Structured\n  Representations at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For graphs generated from stochastic blockmodels, adjacency spectral\nembedding is asymptotically consistent. Further, adjacency spectral embedding\ncomposed with universally consistent classifiers is universally consistent to\nachieve the Bayes error. However when the graph contains private or sensitive\ninformation, treating the data as non-private can potentially leak privacy and\nincur disclosure risks. In this paper, we propose a differentially private\nadjacency spectral embedding algorithm for stochastic blockmodels. We\ndemonstrate that our proposed methodology can estimate the latent positions\nclose to, in Frobenius norm, the latent positions by adjacency spectral\nembedding and achieve comparable accuracy at desired privacy parameters in\nsimulated and real world networks.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 23:43:45 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Chen", "Li", ""]]}, {"id": "1905.07082", "submitter": "Yuantian Miao", "authors": "Yuantian Miao, Minhui Xue, Chao Chen, Lei Pan, Jun Zhang, Benjamin Zi\n  Hao Zhao, Dali Kaafar, and Yang Xiang", "title": "The Audio Auditor: User-Level Membership Inference in Internet of Things\n  Voice Services", "comments": "Accepted by PoPETs 2021.1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of deep learning techniques, the popularity of\nvoice services implemented on various Internet of Things (IoT) devices is ever\nincreasing. In this paper, we examine user-level membership inference in the\nproblem space of voice services, by designing an audio auditor to verify\nwhether a specific user had unwillingly contributed audio used to train an\nautomatic speech recognition (ASR) model under strict black-box access. With\nuser representation of the input audio data and their corresponding translated\ntext, our trained auditor is effective in user-level audit. We also observe\nthat the auditor trained on specific data can be generalized well regardless of\nthe ASR model architecture. We validate the auditor on ASR models trained with\nLSTM, RNNs, and GRU algorithms on two state-of-the-art pipelines, the hybrid\nASR system and the end-to-end ASR system. Finally, we conduct a real-world\ntrial of our auditor on iPhone Siri, achieving an overall accuracy exceeding\n80\\%. We hope the methodology developed in this paper and findings can inform\nprivacy advocates to overhaul IoT privacy.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 01:35:26 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 08:04:24 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2019 02:10:51 GMT"}, {"version": "v4", "created": "Fri, 13 Sep 2019 04:38:47 GMT"}, {"version": "v5", "created": "Fri, 18 Sep 2020 14:59:05 GMT"}, {"version": "v6", "created": "Sat, 26 Jun 2021 12:14:13 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Miao", "Yuantian", ""], ["Xue", "Minhui", ""], ["Chen", "Chao", ""], ["Pan", "Lei", ""], ["Zhang", "Jun", ""], ["Zhao", "Benjamin Zi Hao", ""], ["Kaafar", "Dali", ""], ["Xiang", "Yang", ""]]}, {"id": "1905.07112", "submitter": "Nicholas Carlini", "authors": "Nicholas Carlini", "title": "A critique of the DeepSec Platform for Security Analysis of Deep\n  Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At IEEE S&P 2019, the paper \"DeepSec: A Uniform Platform for Security\nAnalysis of Deep Learning Model\" aims to to \"systematically evaluate the\nexisting adversarial attack and defense methods.\" While the paper's goals are\nlaudable, it fails to achieve them and presents results that are fundamentally\nflawed and misleading. We explain the flaws in the DeepSec work, along with how\nits analysis fails to meaningfully evaluate the various attacks and defenses.\nSpecifically, DeepSec (1) evaluates each defense obliviously, using attacks\ncrafted against undefended models; (2) evaluates attacks and defenses using\nincorrect implementations that greatly under-estimate their effectiveness; (3)\nevaluates the robustness of each defense as an average, not based on the most\neffective attack against that defense; (4) performs several statistical\nanalyses incorrectly and fails to report variance; and, (5) as a result of\nthese errors draws invalid conclusions and makes sweeping generalizations.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 04:26:52 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Carlini", "Nicholas", ""]]}, {"id": "1905.07121", "submitter": "Chuan Guo", "authors": "Chuan Guo, Jacob R. Gardner, Yurong You, Andrew Gordon Wilson, Kilian\n  Q. Weinberger", "title": "Simple Black-box Adversarial Attacks", "comments": "Published at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an intriguingly simple method for the construction of adversarial\nimages in the black-box setting. In constrast to the white-box scenario,\nconstructing black-box adversarial images has the additional constraint on\nquery budget, and efficient attacks remain an open problem to date. With only\nthe mild assumption of continuous-valued confidence scores, our highly\nquery-efficient algorithm utilizes the following simple iterative principle: we\nrandomly sample a vector from a predefined orthonormal basis and either add or\nsubtract it to the target image. Despite its simplicity, the proposed method\ncan be used for both untargeted and targeted attacks -- resulting in previously\nunprecedented query efficiency in both settings. We demonstrate the efficacy\nand efficiency of our algorithm on several real world settings including the\nGoogle Cloud Vision API. We argue that our proposed algorithm should serve as a\nstrong baseline for future black-box attacks, in particular because it is\nextremely fast and its implementation requires less than 20 lines of PyTorch\ncode.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 06:00:41 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 14:12:57 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Guo", "Chuan", ""], ["Gardner", "Jacob R.", ""], ["You", "Yurong", ""], ["Wilson", "Andrew Gordon", ""], ["Weinberger", "Kilian Q.", ""]]}, {"id": "1905.07147", "submitter": "Valentin W\\\"ustholz", "authors": "Valentin W\\\"ustholz, Maria Christakis", "title": "Targeted Greybox Fuzzing with Static Lookahead Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic test generation typically aims to generate inputs that explore new\npaths in the program under test in order to find bugs. Existing work has,\ntherefore, focused on guiding the exploration toward program parts that are\nmore likely to contain bugs by using an offline static analysis.\n  In this paper, we introduce a novel technique for targeted greybox fuzzing\nusing an online static analysis that guides the fuzzer toward a set of target\nlocations, for instance, located in recently modified parts of the program.\nThis is achieved by first semantically analyzing each program path that is\nexplored by an input in the fuzzer's test suite. The results of this analysis\nare then used to control the fuzzer's specialized power schedule, which\ndetermines how often to fuzz inputs from the test suite. We implemented our\ntechnique by extending a state-of-the-art, industrial fuzzer for Ethereum smart\ncontracts and evaluate its effectiveness on 27 real-world benchmarks. Using an\nonline analysis is particularly suitable for the domain of smart contracts\nsince it does not require any code instrumentation---instrumentation to\ncontracts changes their semantics. Our experiments show that targeted fuzzing\nsignificantly outperforms standard greybox fuzzing for reaching 83% of the\nchallenging target locations (up to 14x of median speed-up).\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 07:38:19 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["W\u00fcstholz", "Valentin", ""], ["Christakis", "Maria", ""]]}, {"id": "1905.07228", "submitter": "Igor Ivkic", "authors": "Roland Pellegrini, Igor Ivkic, Markus Tauber", "title": "Towards a Security-Aware Benchmarking Framework for\n  Function-as-a-Service", "comments": null, "journal-ref": "8th International Conference on Cloud Computing and Services\n  Science 2018 (CLOSER), Funchal, Portugal", "doi": "10.5220/0006817606660669", "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a world, where complexity increases on a daily basis the\nFunction-as-a-Service (FaaS) cloud model seams to take countermeasures. In\ncomparison to other cloud models, the fast evolving FaaS increasingly abstracts\nthe underlying infrastructure and refocuses on the application logic. This\ntrend brings huge benefits in application and performance but comes with\ndifficulties for benchmarking cloud applications. In this position paper, we\npresent an initial investigation of benchmarking FaaS in close to reality\nproduction systems. Furthermore, we outline the architectural design including\nthe necessary benchmarking metrics. We also discuss the possibility of using\nthe proposed framework for identifying security vulnerabilities.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 10:14:12 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Pellegrini", "Roland", ""], ["Ivkic", "Igor", ""], ["Tauber", "Markus", ""]]}, {"id": "1905.07273", "submitter": "Aditya Kuppa", "authors": "Aditya Kuppa, Slawomir Grzonkowski, Muhammad Rizwan Asghar and\n  Nhien-An Le-Khac", "title": "Finding Rats in Cats: Detecting Stealthy Attacks using Group Anomaly\n  Detection", "comments": "Preprint: Modified, Extended Version will be presented at TrustCom\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced attack campaigns span across multiple stages and stay stealthy for\nlong time periods. There is a growing trend of attackers using off-the-shelf\ntools and pre-installed system applications (such as \\emph{powershell} and\n\\emph{wmic}) to evade the detection because the same tools are also used by\nsystem administrators and security analysts for legitimate purposes for their\nroutine tasks. To start investigations, event logs can be collected from\noperational systems; however, these logs are generic enough and it often\nbecomes impossible to attribute a potential attack to a specific attack group.\nRecent approaches in the literature have used anomaly detection techniques,\nwhich aim at distinguishing between malicious and normal behavior of computers\nor network systems. Unfortunately, anomaly detection systems based on point\nanomalies are too rigid in a sense that they could miss the malicious activity\nand classify the attack, not an outlier. Therefore, there is a research\nchallenge to make better detection of malicious activities. To address this\nchallenge, in this paper, we leverage Group Anomaly Detection (GAD), which\ndetects anomalous collections of individual data points.\n  Our approach is to build a neural network model utilizing Adversarial\nAutoencoder (AAE-$\\alpha$) in order to detect the activity of an attacker who\nleverages off-the-shelf tools and system applications. In addition, we also\nbuild \\textit{Behavior2Vec} and \\textit{Command2Vec} sentence embedding deep\nlearning models specific for feature extraction tasks. We conduct extensive\nexperiments to evaluate our models on real-world datasets collected for a\nperiod of two months. The empirical results demonstrate that our approach is\neffective and robust in discovering targeted attacks, pen-tests, and attack\ncampaigns leveraging custom tools.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 17:16:52 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 13:22:04 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Kuppa", "Aditya", ""], ["Grzonkowski", "Slawomir", ""], ["Asghar", "Muhammad Rizwan", ""], ["Le-Khac", "Nhien-An", ""]]}, {"id": "1905.07387", "submitter": "Ching-Yun Ko", "authors": "Ching-Yun Ko, Zhaoyang Lyu, Tsui-Wei Weng, Luca Daniel, Ngai Wong,\n  Dahua Lin", "title": "POPQORN: Quantifying Robustness of Recurrent Neural Networks", "comments": "10 pages, Ching-Yun Ko and Zhaoyang Lyu contributed equally, accepted\n  to ICML 2019. Please see arXiv source codes for the appendix by clicking\n  [Other formats]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vulnerability to adversarial attacks has been a critical issue for deep\nneural networks. Addressing this issue requires a reliable way to evaluate the\nrobustness of a network. Recently, several methods have been developed to\ncompute $\\textit{robustness quantification}$ for neural networks, namely,\ncertified lower bounds of the minimum adversarial perturbation. Such methods,\nhowever, were devised for feed-forward networks, e.g. multi-layer perceptron or\nconvolutional networks. It remains an open problem to quantify robustness for\nrecurrent networks, especially LSTM and GRU. For such networks, there exist\nadditional challenges in computing the robustness quantification, such as\nhandling the inputs at multiple steps and the interaction between gates and\nstates. In this work, we propose $\\textit{POPQORN}$\n($\\textbf{P}$ropagated-$\\textbf{o}$ut$\\textbf{p}$ut $\\textbf{Q}$uantified\nR$\\textbf{o}$bustness for $\\textbf{RN}$Ns), a general algorithm to quantify\nrobustness of RNNs, including vanilla RNNs, LSTMs, and GRUs. We demonstrate its\neffectiveness on different network architectures and show that the robustness\nquantification on individual steps can lead to new insights.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 17:35:04 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Ko", "Ching-Yun", ""], ["Lyu", "Zhaoyang", ""], ["Weng", "Tsui-Wei", ""], ["Daniel", "Luca", ""], ["Wong", "Ngai", ""], ["Lin", "Dahua", ""]]}, {"id": "1905.07397", "submitter": "Philip Lazos", "authors": "Elias Koutsoupias, Philip Lazos, Paolo Serafino, Foluso Ogunlana", "title": "Blockchain Mining Games with Pay Forward", "comments": null, "journal-ref": null, "doi": "10.1145/3308558.3313740", "report-no": null, "categories": "cs.GT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the strategic implications that arise from adding one extra option\nto the miners participating in the bitcoin protocol. We propose that when\nadding a block, miners also have the ability to pay forward an amount to be\ncollected by the first miner who successfully extends their branch, giving them\nthe power to influence the incentives for mining. We formulate a stochastic\ngame for the study of such incentives and show that with this added option,\nsmaller miners can guarantee that the best response of even substantially more\npowerful miners is to follow the expected behavior intended by the protocol\ndesigner.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 17:51:01 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Koutsoupias", "Elias", ""], ["Lazos", "Philip", ""], ["Serafino", "Paolo", ""], ["Ogunlana", "Foluso", ""]]}, {"id": "1905.07444", "submitter": "Zain Din", "authors": "Zain ul abi Din (1), Panagiotis Tigas (2), Samuel T. King (1 and 5),\n  Benjamin Livshits (3 and 4) ((1) UC Davis, (2) Oxford University, (3) Brave\n  Software, (4) Imperial College London, (5) Bouncer Technologies)", "title": "Percival: Making In-Browser Perceptual Ad Blocking Practical With Deep\n  Learning", "comments": "13 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we present Percival, a browser-embedded, lightweight, deep\nlearning-powered ad blocker. Percival embeds itself within the browser's image\nrendering pipeline, which makes it possible to intercept every image obtained\nduring page execution and to perform blocking based on applying machine\nlearning for image classification to flag potential ads. Our implementation\ninside both Chromium and Brave browsers shows only a minor rendering\nperformance overhead of 4.55%, demonstrating the feasibility of deploying\ntraditionally heavy models (i.e. deep neural networks) inside the critical path\nof the rendering engine of a browser. We show that our image-based ad blocker\ncan replicate EasyList rules with an accuracy of 96.76%. To show the\nversatility of the Percival's approach we present case studies that demonstrate\nthat Percival 1) does surprisingly well on ads in languages other than English;\n2) Percival also performs well on blocking first-party Facebook ads, which have\npresented issues for other ad blockers. Percival proves that image-based\nperceptual ad blocking is an attractive complement to today's dominant approach\nof block lists\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 19:08:01 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 04:31:21 GMT"}, {"version": "v3", "created": "Wed, 20 May 2020 01:30:24 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Din", "Zain ul abi", "", "1 and 5"], ["Tigas", "Panagiotis", "", "1 and 5"], ["King", "Samuel T.", "", "1 and 5"], ["Livshits", "Benjamin", "", "3 and 4"]]}, {"id": "1905.07561", "submitter": "Khaled Nagaty Prof.", "authors": "Khaled Ahmed Nagaty", "title": "Discrete Logarithmic Fuzzy Vault Scheme", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a three fuzzy vault schemes which integrated with discrete\nlogarithmic encryption scheme are proposed. In the first scheme, the message m\nis encoded with discrete logarithmic encryption scheme using randomly generated\nidentity key \\k{appa} for every message and then divided into non-overlapping\nsegments. In the second scheme, the message is divided into non-overlapping\nsegments and each segment is encoded with discrete logarithmic encryption\nscheme using the randomly generated identity key \\k{appa}. In the third scheme,\nthe message is divided into non-overlapping segments where even segments are\nencoded with identity key \\k{appa}_even and odd segments are encoded with\nidentity key \\k{appa}_odd. Identity keys \\k{appa}_even and \\k{appa}_odd are\nrandomly generated for every message. Finally, the encoded segments are\ndeclared as coefficients of a polynomial of specific degree. In all proposed\nschemes, elements of locking set A are used as X-coordinate values to compute\nevaluations of the polynomial by projecting elements of A onto points lying on\nthe polynomial. A large number of random chaff points that do not lie on the\npolynomial are added to create noise to hide the encoded segments. Security\nanalysis has shown the proposed scheme enjoys provable security over classical\nfuzzy vaults.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 09:17:55 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Nagaty", "Khaled Ahmed", ""]]}, {"id": "1905.07573", "submitter": "Sherif Saad", "authors": "Sherif Saad, William Briguglio and Haytham Elmiligi", "title": "The Curious Case of Machine Learning In Malware Detection", "comments": "9 pages", "journal-ref": "5th International Conference on Information Systems Security and\n  Privacy, 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we argue that machine learning techniques are not ready for\nmalware detection in the wild. Given the current trend in malware development\nand the increase of unconventional malware attacks, we expect that dynamic\nmalware analysis is the future for antimalware detection and prevention\nsystems. A comprehensive review of machine learning for malware detection is\npresented. Then, we discuss how malware detection in the wild present unique\nchallenges for the current state-of-the-art machine learning techniques. We\ndefined three critical problems that limit the success of malware detectors\npowered by machine learning in the wild. Next, we discuss possible solutions to\nthese challenges and present the requirements of next-generation malware\ndetection. Finally, we outline potential research directions in machine\nlearning for malware detection.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 10:34:36 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Saad", "Sherif", ""], ["Briguglio", "William", ""], ["Elmiligi", "Haytham", ""]]}, {"id": "1905.07598", "submitter": "Yufan Huang", "authors": "Richeng Jin, Yufan Huang, and Huaiyu Dai", "title": "On the Privacy Guarantees of Gossip Protocols in General Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the privacy guarantees of information dissemination protocols have\nattracted increasing research interests, among which the gossip protocols\nassume vital importance in various information exchange applications. In this\nwork, we study the privacy guarantees of gossip protocols in general networks\nin terms of differential privacy and prediction uncertainty. First, lower\nbounds of the differential privacy guarantees are derived for gossip protocols\nin general networks in both synchronous and asynchronous settings. The\nprediction uncertainty of the source node given a uniform prior is also\ndetermined. For the private gossip algorithm, the differential privacy and\nprediction uncertainty guarantees are derived in closed form. Moreover,\nconsidering that these two metrics may be restrictive in some scenarios, the\nrelaxed variants are proposed. It is found that source anonymity is closely\nrelated to some key network structure parameters in the general network\nsetting. Then, we investigate information spreading in wireless networks with\nunreliable communications, and quantify the tradeoff between differential\nprivacy guarantees and information spreading efficiency. Finally, considering\nthat the attacker may not be present at the beginning of the information\ndissemination process, the scenario of delayed monitoring is studied and the\ncorresponding differential privacy guarantees are evaluated.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 14:47:10 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 05:45:06 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Jin", "Richeng", ""], ["Huang", "Yufan", ""], ["Dai", "Huaiyu", ""]]}, {"id": "1905.07617", "submitter": "Thomas Byrd", "authors": "Thomas Byrd and Vuk Marojevic, Roger Piqueras Jover", "title": "CSAI: Open-Source Cellular Radio Access Network Security Analysis\n  Instrument", "comments": "6 pages, 6 figures, Submitted to IEEE GLOBECOM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our methodology and toolbox that allows analyzing the\nradio access network security of laboratory and commercial 4G and future 5G\ncellular networks. We leverage a free open-source software suite that\nimplements the LTE UE and eNB enabling real-time signaling using software radio\nperipherals. We modify the UE software processing stack to act as an LTE packet\ncollection and examination tool. This is possible because of the openness of\nthe 3GPP specifications. Hence, we are able to receive and decode LTE downlink\nmessages for the purpose of analyzing potential security problems of the\nstandard. This paper shows how to rapidly prototype LTE tools and build a\nsoftware-defined radio access network (RAN) analysis instrument for research\nand education. Using CSAI, the Cellular RAN Security Analysis Instrument, a\nresearcher can analyze broadcast and paging messages of cellular networks. CSAI\nis also able to test networks to aid in the identification of vulnerabilities\nand verify functionality post-remediation. Additionally, we found that it can\ncrash an eNB which motivates equivalent analyses of commercial network\nequipment and its robustness against denial of service attacks.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 17:42:42 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Byrd", "Thomas", ""], ["Marojevic", "Vuk", ""], ["Jover", "Roger Piqueras", ""]]}, {"id": "1905.07643", "submitter": "Gauvain Tanguy Henri Gabriel Isidore Roussel-Tarbouriech", "authors": "Gauvain Tanguy Henri Gabriel Isidore Roussel-Tarbouriech, Noel Menard,\n  Tyler True, Tini Vi, Reisyukaku", "title": "Methodically Defeating Nintendo Switch Security", "comments": "12 pages, 4 figures; corrected some innacuracies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We explain, step by step, how we strategically circumvented the Nintendo\nSwitch's system security, from basic userland code execution, to undermining\nand exposing the secrets of the security co-processor. To this end, we've\nidentified and utilized two distinct analysis procedures. The software-based\nanalysis suffices for reverse-engineering the userland and operating system\nservices, and is necessary for a general architectural understanding of the\nsoftware systems in the Nintendo Switch. While this method is extremely\npowerful and provides significant leverage over the control of the system and\nits software security, a hardware-based method was devised, which employs\nanalysis of the trusted bootstrap code in ROM. This strategy was essential for\nthe goal of defeating the hardware root of trust. Together, these two vectors\nprovide essential insight required to instance a chain of attacks, in order to\ngain ROP code execution from the context of a high-security mode of a secure\nco-processor of a running system, thus allowing us to demonstrate a\nmulti-faceted approach on attacking secure, embedded devices in an unfamiliar\nand novel environment.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 20:48:22 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 02:05:03 GMT"}], "update_date": "2019-08-10", "authors_parsed": [["Roussel-Tarbouriech", "Gauvain Tanguy Henri Gabriel Isidore", ""], ["Menard", "Noel", ""], ["True", "Tyler", ""], ["Vi", "Tini", ""], ["Reisyukaku", "", ""]]}, {"id": "1905.07665", "submitter": "Shaoxiong Ji", "authors": "Shaoxiong Ji and Guodong Long and Shirui Pan and Tianqing Zhu and Jing\n  Jiang and Sen Wang and Xue Li", "title": "Knowledge Transferring via Model Aggregation for Online Social Care", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet and the Web are being increasingly used in proactive social care\nto provide people, especially the vulnerable, with a better life and services,\nand their derived social services generate enormous data. However, the strict\nprotection of privacy makes user's data become an isolated island and limits\nthe predictive performance of standalone clients. To enable effective proactive\nsocial care and knowledge sharing within intelligent agents, this paper\ndevelops a knowledge transferring framework via model aggregation. Under this\nframework, distributed clients perform on-device training, and a third-party\nserver integrates multiple clients' models and redistributes to clients for\nknowledge transferring among users. To improve the generalizability of the\nknowledge sharing, we further propose a novel model aggregation algorithm,\nnamely the average difference descent aggregation (AvgDiffAgg for short). In\nparticular, to evaluate the effectiveness of the learning algorithm, we use a\ncase study on the early detection and prevention of suicidal ideation, and the\nexperiment results on four datasets derived from social communities demonstrate\nthe effectiveness of the proposed learning method.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 00:06:02 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 09:02:47 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Ji", "Shaoxiong", ""], ["Long", "Guodong", ""], ["Pan", "Shirui", ""], ["Zhu", "Tianqing", ""], ["Jiang", "Jing", ""], ["Wang", "Sen", ""], ["Li", "Xue", ""]]}, {"id": "1905.07672", "submitter": "Fu Song", "authors": "Lei Bu, Yuchao Duan, Fu Song, Zhe Zhao", "title": "Taking Care of The Discretization Problem: A Comprehensive Study of the\n  Discretization Problem and A Black-Box Adversarial Attack in Discrete Integer\n  Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous methods for crafting adversarial examples were proposed recently\nwith high success rate. Since most existing machine learning based classifiers\nnormalize images into some continuous, real vector, domain firstly, attacks\noften craft adversarial examples in such domain. However, \"adversarial\"\nexamples may become benign after denormalizing them back into the discrete\ninteger domain, known as the discretization problem. This problem was mentioned\nin some work, but has received relatively little attention.\n  In this work, we first conduct a comprehensive study of existing methods and\ntools for crafting. We theoretically analyze 34 representative methods and\nempirically study 20 representative open source tools for crafting adversarial\nimages. Our study reveals that the discretization problem is far more serious\nthan originally thought. This suggests that the discretization problem should\nbe taken into account seriously when crafting adversarial examples and\nmeasuring attack success rate. As a first step towards addressing this problem\nin black-box scenario, we propose a black-box method which reduces the\nadversarial example searching problem to a derivative-free optimization\nproblem. Our method is able to craft adversarial images by derivative-free\nsearch in the discrete integer domain. Experimental results show that our\nmethod is comparable to recent white-box methods (e.g., FGSM, BIM and C\\&W) and\nachieves significantly higher success rate in terms of adversarial examples in\nthe discrete integer domain than recent black-box methods (e.g., ZOO, NES-PGD\nand Bandits). Moreover, our method is able to handle models that is\nnon-differentiable and successfully break the winner of NIPS 2017 competition\non defense with 95\\% success rate. Our results suggest that discrete\noptimization algorithms open up a promising area of research into effective\nblack-box attacks.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 02:12:13 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 16:23:27 GMT"}, {"version": "v3", "created": "Tue, 17 Sep 2019 04:29:19 GMT"}, {"version": "v4", "created": "Mon, 28 Oct 2019 15:02:00 GMT"}, {"version": "v5", "created": "Sun, 26 Apr 2020 06:38:04 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Bu", "Lei", ""], ["Duan", "Yuchao", ""], ["Song", "Fu", ""], ["Zhao", "Zhe", ""]]}, {"id": "1905.07673", "submitter": "Jared Smith", "authors": "Tyler McDaniel, Jared M. Smith, Max Schuchard", "title": "The Maestro Attack: Orchestrating Malicious Flows with BGP", "comments": "In-submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Maestro attack, a novel Link Flooding Attack (LFA) that\nleverages control-plane traffic engineering techniques to concentrate\nbotnet-sourced Distributed Denial of Service flows on transit links. Executed\nfrom a compromised or malicious Autonomous System (AS), Maestro advertises\nspecific-prefix routes poisoned for selected ASes to collapse inbound traffic\npaths onto a single target link. A greedy heuristic fed by publicly available\nAS relationship data iteratively builds the set of ASes to poison. Given a\ncompromised BGP speaker with advantageous positioning relative to the target\nlink in the Internet topology, an adversary can expect to enhance total flow\ndensity by more than 30%. For a large botnet (e.g., Mirai), that translates to\naugmenting a DDoS by more than a million additional infected hosts.\nInterestingly, the size of the adversary-controlled AS plays little role in\nthis amplification effect. Devastating attacks on core links can be executed by\nsmall, resource-limited ASes. To understand the scope of the attack, we\nevaluate widespread Internet link vulnerability across several metrics,\nincluding BGP betweenness and botnet flow density. We then assess where an\nadversary must be positioned to execute the attack most successfully. Finally,\nwe present effective mitigations for network operators seeking to insulate\nthemselves from this attack.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 02:17:13 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["McDaniel", "Tyler", ""], ["Smith", "Jared M.", ""], ["Schuchard", "Max", ""]]}, {"id": "1905.07681", "submitter": "Roman Overko Mr.", "authors": "Roman Overko, Rodrigo H. Ordonez-Hurtado, Sergiy Zhuk, Pietro Ferraro,\n  Andrew Cullen, and Robert Shorten", "title": "Spatial Positioning Token (SPToken) for Smart Mobility", "comments": "A short version of this paper was submitted to ICCVE 2019: The 8th\n  IEEE International Conference on Connected Vehicles and Expo", "journal-ref": null, "doi": "10.1109/TITS.2020.3029537", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a permissioned distributed ledger technology (DLT) design for\ncrowdsourced smart mobility applications. This architecture is based on a\ndirected acyclic graph architecture (similar to the IOTA tangle) and uses both\nProof-of-Work and Proof-of-Position mechanisms to provide protection against\nspam attacks and malevolent actors. In addition to enabling individuals to\nretain ownership of their data and to monetize it, the architecture also is\nsuitable for distributed privacy-preserving machine learning algorithms, is\nlightweight, and can be implemented in simple internet-of-things (IoT) devices.\nTo demonstrate its efficacy, we apply this framework to reinforcement learning\nsettings where a third party is interested in acquiring information from\nagents. In particular, one may be interested in sampling an unknown vehicular\ntraffic flow in a city, using a DLT-type architecture and without perturbing\nthe density, with the idea of realizing a set of virtual tokens as surrogates\nof real vehicles to explore geographical areas of interest. These tokens, whose\nauthenticated position determines write access to the ledger, are thus used to\nemulate the probing actions of commanded (real) vehicles on a given planned\nroute by \"jumping\" from a passing-by vehicle to another to complete the planned\ntrajectory. Consequently, the environment stays unaffected (i.e., the autonomy\nof participating vehicles is not influenced by the algorithm), regardless of\nthe number of emitted tokens. The design of such a DLT architecture is\npresented, and numerical results from large-scale simulations are provided to\nvalidate the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 10:45:18 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 14:28:06 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 14:26:53 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Overko", "Roman", ""], ["Ordonez-Hurtado", "Rodrigo H.", ""], ["Zhuk", "Sergiy", ""], ["Ferraro", "Pietro", ""], ["Cullen", "Andrew", ""], ["Shorten", "Robert", ""]]}, {"id": "1905.07766", "submitter": "Wenhao Wang", "authors": "Wenhao Wang, Yichen Jiang, Qintao Shen, Weihao Huang, Hao Chen, Shuang\n  Wang, XiaoFeng Wang, Haixu Tang, Kai Chen, Kristin Lauter and Dongdai Lin", "title": "Toward Scalable Fully Homomorphic Encryption Through Light Trusted\n  Computing Assistance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been a long standing problem to securely outsource computation tasks\nto an untrusted party with integrity and confidentiality guarantees. While\nfully homomorphic encryption (FHE) is a promising technique that allows\ncomputations performed on the encrypted data, it suffers from a significant\nslow down to the computation. In this paper we propose a hybrid solution that\nuses the latest hardware Trusted Execution Environments (TEEs) to assist FHE by\nmoving the bootstrapping step, which is one of the major obstacles in designing\npractical FHE schemes, to a secured SGX enclave. TEEFHE, the hybrid system we\ndesigned, makes it possible for homomorphic computations to be performed on\nsmaller ciphertext and secret key, providing better performance and lower\nmemory consumption. We make an effort to mitigate side channel leakages within\nSGX by making the memory access patterns totally independent from the secret\ninformation. The evaluation shows that TEEFHE effectively improves the software\nonly FHE schemes in terms of both time and space.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 16:22:46 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Wang", "Wenhao", ""], ["Jiang", "Yichen", ""], ["Shen", "Qintao", ""], ["Huang", "Weihao", ""], ["Chen", "Hao", ""], ["Wang", "Shuang", ""], ["Wang", "XiaoFeng", ""], ["Tang", "Haixu", ""], ["Chen", "Kai", ""], ["Lauter", "Kristin", ""], ["Lin", "Dongdai", ""]]}, {"id": "1905.07767", "submitter": "Ahmet Bozkir", "authors": "Firat Coskun Dalgic, Ahmet Selman Bozkir, Murat Aydos", "title": "Phish-IRIS: A New Approach for Vision Based Brand Prediction of Phishing\n  Web Pages via Compact Visual Descriptors", "comments": "2nd International Symposium on Multidisciplinary Studies and\n  Innovation Technologies, ISMSIT 2018", "journal-ref": null, "doi": "10.1109/ISMSIT.2018.8567299", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phishing, a continuously growing cyber threat, aims to obtain innocent users'\ncredentials by deceiving them via presenting fake web pages which mimic their\nlegitimate targets. To date, various attempts have been carried out in order to\ndetect phishing pages. In this study, we treat the problem of phishing web page\nidentification as an image classification task and propose a machine learning\naugmented pure vision based approach which extracts and classifies compact\nvisual features from web page screenshots. For this purpose, we employed\nseveral MPEG7 and MPEG7-like compact visual descriptors (SCD, CLD, CEDD, FCTH\nand JCD) to reveal color and edge based discriminative visual cues. Throughout\nthe feature extraction process we have followed two different schemes working\non either whole screenshots in a \"holistic\" manner or equal sized \"patches\"\nconstructing a coarse-to-fine \"pyramidal\" representation. Moreover, for the\ntask of image classification, we have built SVM and Random Forest based machine\nlearning models. In order to assess the performance and generalization\ncapability of the proposed approach, we have collected a mid-sized corpus\ncovering 14 distinct brands and involving 2852 samples. According to the\nconducted experiments, our approach reaches up to 90.5% F1 score via SCD. As a\nresult, compared to other studies, the suggested approach presents a\nlightweight schema serving competitive accuracy and superior feature extraction\nand inferring speed that enables it to be used as a browser plugin.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 16:28:51 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Dalgic", "Firat Coskun", ""], ["Bozkir", "Ahmet Selman", ""], ["Aydos", "Murat", ""]]}, {"id": "1905.07843", "submitter": "Minki Song", "authors": "Minki Song, Seunghwan Lee, Eunsang Lee, Dong-Joon Shin, Young-Sik Kim,\n  Jong-Seon No", "title": "Improving security and bandwidth efficiency of NewHope using\n  error-correction schemes", "comments": "23 pages, 8 figures, Submission to AsiaCrypt 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among many submissions to the NIST post-quantum cryptography (PQC) project,\nNewHope is a promising key encapsulation mechanism (KEM) based on the\nRing-Learning with errors (Ring-LWE) problem. Since the most important factors\nto be considered for PQC are security and cost including bandwidth and\ntime/space complexity, in this paper, by doing exact noise analysis and using\nBose Chaudhuri Hocquenghem (BCH) codes, it is shown that the security and\nbandwidth efficiency of NewHope can be substantially improved. In detail, the\ndecryption failure rate (DFR) of NewHope is recalculated by performing exact\nnoise analysis, and it is shown that the DFR of NewHope has been too\nconservatively calculated. Since the recalculated DFR is much lower than the\nrequired $2^{-128}$, this DFR margin is exploited to improve the security up to\n8.5 \\% or the bandwidth efficiency up to 5.9 \\% without changing the procedure\nof NewHope.\n  The additive threshold encoding (ATE) used in NewHope is a simple error\ncorrecting code (ECC) robust to side channel attack, but its error-correction\ncapability is relatively weak compared with other ECCs. Therefore, if a proper\nerror-correction scheme is applied to NewHope, either security or bandwidth\nefficiency or both can be improved. Among various ECCs, BCH code has been\nwidely studied for its application to cryptosystems due to its advantages such\nas no error floor problem. In this paper, the ATE and total noise channel are\nregarded as a super channel from an information-theoretic viewpoint. Based on\nthis super channel analysis, various concatenated coding schemes of ATE and BCH\ncode for NewHope have been investigated. Through numerical analysis, it is\nrevealed that the security and bandwidth efficiency of NewHope are\nsubstantially improved by using the proposed error-correction schemes.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 01:59:51 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Song", "Minki", ""], ["Lee", "Seunghwan", ""], ["Lee", "Eunsang", ""], ["Shin", "Dong-Joon", ""], ["Kim", "Young-Sik", ""], ["No", "Jong-Seon", ""]]}, {"id": "1905.07893", "submitter": "Jing Chen", "authors": "Jieren Cheng, Chen Zhang, Xiangyan Tang, Victor S. Sheng, Zhe Dong,\n  Junqi Li, Jing Chen", "title": "Adaptive DDoS attack detection method based on multiple-kernel learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed denial of service (DDoS) attacks have caused huge economic losses\nto society. They have become one of the main threats to Internet security. Most\nof the current detection methods based on a single feature and fixed model\nparameters cannot effectively detect early DDoS attacks in cloud and big data\nenvironment. In this paper, an adaptive DDoS attack detection method (ADADM)\nbased on multiple kernel learning (MKL) is proposed. Based on the burstiness of\nDDoS attack flow, the distribution of addresses and the interactivity of\ncommunication, we define five features to describe the network flow\ncharacteristic. Based on the ensemble learning framework, the weight of each\ndimension is adaptively adjusted by increasing the inter-class mean with a\ngradient ascent and reducing the intra-class variance with a gradient descent,\nand the classifier is established to identify an early DDoS attack by training\nsimple multiple kernel learning (SMKL) models with two characteristics\nincluding inter-class mean squared difference growth (M-SMKL) and intra-class\nvariance descent (S-SMKL). The sliding window mechanism is used to coordinate\nthe S-SMKL and M-SMKL to detect the early DDoS attack. The experimental results\nindicate that this method can detect DDoS attacks early and accurately.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 06:11:25 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Cheng", "Jieren", ""], ["Zhang", "Chen", ""], ["Tang", "Xiangyan", ""], ["Sheng", "Victor S.", ""], ["Dong", "Zhe", ""], ["Li", "Junqi", ""], ["Chen", "Jing", ""]]}, {"id": "1905.07940", "submitter": "Alain Brenzikofer", "authors": "Alain Brenzikofer, Noa Melchior", "title": "Privacy-Preserving P2P Energy Market on the Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Quartierstrom creates a peer-to-peer marketplace for locally generated solar\npower. The marketplace is implemented as a smart contract on a permissioned\nblockchain governed by all prosumers. Two privacy-by-design concepts are\npresented which guarantee that the users individual load profile is not leaked\nto any third party despite using a blockchain. The first approach leverages\nUTXO based coin mixing protocols in combination with an account-based on-chain\nsmart contract. The second approach relies on an off-chain smart contract\nrunning in trusted execution environments.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 08:26:00 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Brenzikofer", "Alain", ""], ["Melchior", "Noa", ""]]}, {"id": "1905.08039", "submitter": "Matthew Smith", "authors": "Matthew Smith, Martin Strohmeier, Jon Harman, Vincent Lenders and Ivan\n  Martinovic", "title": "Safety vs. Security: Attacking Avionic Systems with Humans in the Loop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many wireless communications systems found in aircraft lack standard security\nmechanisms, leaving them fundamentally vulnerable to attack. With affordable\nsoftware-defined radios available, a novel threat has emerged, allowing a wide\nrange of attackers to easily interfere with wireless avionic systems. Whilst\nthese vulnerabilities are known, concrete attacks that exploit them are still\nnovel and not yet well understood. This is true in particular with regards to\ntheir kinetic impact on the handling of the attacked aircraft and consequently\nits safety.\n  To investigate this, we invited 30 Airbus A320 type-rated pilots to fly\nsimulator scenarios in which they were subjected to attacks on their avionics.\nWe implement and analyse novel wireless attacks on three safety-related\nsystems: Traffic Collision Avoidance System (TCAS), Ground Proximity Warning\nSystem (GPWS) and the Instrument Landing System (ILS).\n  We found that all three analysed attack scenarios created significant control\nimpact and cost of disruption through turnarounds, avoidance manoeuvres, and\ndiversions. They further increased workload, distrust in the affected system,\nand in 38% of cases caused the attacked safety system to be switched off\nentirely. All pilots felt the scenarios were useful, with 93.3% feeling that\nsimulator training for wireless attacks could be valuable.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 12:33:04 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Smith", "Matthew", ""], ["Strohmeier", "Martin", ""], ["Harman", "Jon", ""], ["Lenders", "Vincent", ""], ["Martinovic", "Ivan", ""]]}, {"id": "1905.08150", "submitter": "Etienne Lemaire", "authors": "Etienne Lemaire (IMS)", "title": "Pretty Modular Symmetric Encryption (PMSE), compact algorithm for\n  ''embedded cryptography'' with quite low computational cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the dataflux shared between IOT systems must be secured from 8-bits\nto 64-bits processors systems. Several symmetric cryptographic algorithm\nalready exist such as AES (Advanced Encryption Standard), RC4, Blowfish, etc.\nIn this work, we propose an 8-bits encryption algorithm, combining several\nideas of standard symmetric encryption algorithms. The aim is to provide a\nefficient, modular and compact algorithm able to tend to truly random\none-time-pad encryption quality even for large data flux. The algorithm\ncombines the implementation of a divergent polynomial with variable\ncoefficients for pseudo-random keys generation, variable bit swapping and\nbitwise operations on data, and the use of one or two passwords. The encryption\nhas been evaluated statistically, tested for image encryption and compared with\nOne-Time-Pad encryption on the same data. Three implementations have been\ntested respectively in C, Javascript and GNU Octave. Encryption time\nperformances are compared with AES on a 8-bits architecture: the Arduino Uno\n(ATmega328) microcontroller. A new concept of self-decryptionable web encrypted\nobject, called Blocksnet is also presented and tested as a potential\napplication of the compact and embedded PMSE algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 07:10:03 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Lemaire", "Etienne", "", "IMS"]]}, {"id": "1905.08164", "submitter": "Dhiman Chakraborty", "authors": "Dhiman Chakraborty, Lucjan Hanzlik, Sven Bugiel", "title": "simTPM: User-centric TPM for Mobile Devices (Technical Report)", "comments": "Accepted at 28th Usenix Security Symposium, 2019. This is the longer\n  version. The bibtex is required as soon as possible, for the camera ready\n  version for the conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trusted Platform Modules are valuable building blocks for security solutions\nand have also been recognized as beneficial for security on mobile platforms,\nlike smartphones and tablets. However, strict space, cost, and power\nconstraints of mobile devices prohibit an implementation as dedicated on-board\nchip and the incumbent implementations are software TPMs protected by Trusted\nExecution Environments. In this paper, we present simTPM, an alternative\nimplementation of a mobile TPM based on the SIM card available in mobile\nplatforms. We solve the technical challenge of implementing a TPM2.0 in the\nresource-constrained SIM card environment and integrate our simTPM into the\nsecure boot chain of the ARM Trusted Firmware on a HiKey960 reference board.\nMost notably, we address the challenge of how a removable TPM can be bound to\nthe host device's root of trust for measurement. As such, our solution not only\nprovides a mobile TPM that avoids additional hardware while using a dedicated,\nstrongly protected environment, but also offers promising synergies with\nco-existing TEE-based TPMs. In particular, simTPM offers a user-centric trusted\nmodule. Using performance benchmarks, we show that our simTPM has competitive\nspeed with a reported TEE-based TPM and a hardware-based TPM.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 15:21:07 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Chakraborty", "Dhiman", ""], ["Hanzlik", "Lucjan", ""], ["Bugiel", "Sven", ""]]}, {"id": "1905.08192", "submitter": "Sahil Suneja", "authors": "Sahil Suneja, Canturk Isci", "title": "Secure Extensibility for System State Extraction via Plugin Sandboxing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new mechanism to securely extend systems data collection\nsoftware with potentially untrusted third-party code. Unlike existing tools\nwhich run extension modules or plugins directly inside the monitored endpoint\n(the guest), we run plugins inside a specially crafted sandbox, so as to\nprotect the guest as well as the software core. To get the right mix of\naccessibility and constraints required for systems data extraction, we create\nour sandbox by combining multiple features exported by an unmodified kernel. We\nhave tested its applicability by successfully sandboxing plugins of an\nopensourced data collection software for containerized guest systems. We have\nalso verified its security posture in terms of successful containment of\nseveral exploits, which would have otherwise directly impacted a guest, if\nshipped inside third-party plugins.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 16:16:17 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Suneja", "Sahil", ""], ["Isci", "Canturk", ""]]}, {"id": "1905.08199", "submitter": "Sarah Helble", "authors": "Sarah C. Helble and Alexander J. Gartner and Jennifer A. McKneely", "title": "Increasing the Security of Weak Passwords: the SPARTAN Interface", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Password authentication suffers from the well-known tradeoff between security\nand usability. Secure passwords are difficult for users to remember, and\nmemorable passwords are often easy to guess. SPARse Two-dimensional\nAuthenticatioN (SPARTAN) allows users to input their textual passwords in a\ntwo-dimensional grid instead of a linear textbox. This interface enables\nrelatively short passwords to have a higher calculated level of security due to\nthe need for an attacker to determine both the text of the password and the\nlocation of each character in the grid. We created a SPARTAN prototype and\nconducted a preliminary user study to evaluate the actual usability and\nsecurity of the SPARTAN interface compared to the linear password entry\ninterface. We find that while user-created SPARTAN passwords tend to be shorter\nthan their linear counterparts, the calculated security of user-created SPARTAN\npasswords is higher than that of user-created linear passwords. We also asked\nparticipants to complete a survey on the usability of the SPARTAN interface and\nidentified some areas of improvement, while prototype interaction provided\nevidence of users becoming more familiar with SPARTAN over time. Finally, we\nperformed an investigation into password-cracking tools, and assert that\nSPARTAN passwords require more resources to crack than their linear\ncounterparts. These findings suggest that SPARTAN is a promising alternative to\nlinear passwords from a security standpoint. Usability of the interface and\nmemorability of SPARTAN passwords is an interesting research question and\nshould be further investigated in future work.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 16:32:32 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 17:24:03 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Helble", "Sarah C.", ""], ["Gartner", "Alexander J.", ""], ["McKneely", "Jennifer A.", ""]]}, {"id": "1905.08232", "submitter": "Parsa Saadatpanah", "authors": "Ali Shafahi, Parsa Saadatpanah, Chen Zhu, Amin Ghiasi, Christoph\n  Studer, David Jacobs, Tom Goldstein", "title": "Adversarially robust transfer learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning, in which a network is trained on one task and re-purposed\non another, is often used to produce neural network classifiers when data is\nscarce or full-scale training is too costly. When the goal is to produce a\nmodel that is not only accurate but also adversarially robust, data scarcity\nand computational limitations become even more cumbersome. We consider robust\ntransfer learning, in which we transfer not only performance but also\nrobustness from a source model to a target domain. We start by observing that\nrobust networks contain robust feature extractors. By training classifiers on\ntop of these feature extractors, we produce new models that inherit the\nrobustness of their parent networks. We then consider the case of fine tuning a\nnetwork by re-training end-to-end in the target domain. When using lifelong\nlearning strategies, this process preserves the robustness of the source\nnetwork while achieving high accuracy. By using such strategies, it is possible\nto produce accurate and robust models with little data, and without the cost of\nadversarial training. Additionally, we can improve the generalization of\nadversarially trained models, while maintaining their robustness.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 17:57:57 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 15:51:23 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Shafahi", "Ali", ""], ["Saadatpanah", "Parsa", ""], ["Zhu", "Chen", ""], ["Ghiasi", "Amin", ""], ["Studer", "Christoph", ""], ["Jacobs", "David", ""], ["Goldstein", "Tom", ""]]}, {"id": "1905.08240", "submitter": "Peter Breuer", "authors": "Peter T. Breuer", "title": "Safe and Chaotic Compilation for Hidden Deterministic Hardware Aliasing", "comments": "11 pages. arXiv admin note: text overlap with arXiv:1901.10926", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR cs.IT cs.PL math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware aliasing occurs when the same logical address can access different\nphysical memory locations. This is a problem for software on some embedded\nsystems and more generally when hardware becomes faulty in irretrievable\nlocations, such as on a Mars Lander. We show how to work around the hardware\nproblem with software logic, compiling code so it works on any platform with\nhardware aliasing with hidden determinism. That is: (i) a copy of an address\naccesses the same location, and (ii) repeating an address calculation exactly\nwill repeat the same access again. Stuck bits can mean that even adding zero to\nan address can make a difference in that environment so nothing but a\nsystematic approach has a chance of working. The technique is extended to\ngenerate aliasing as well as compensate for it, in so-called chaotic\ncompilation, and a sketch proof is included to show it may produce object code\nthat is secure against discovery of the programmer's intention. A prototype\ncompiler implementing the technology covers all of ANSI C except\nlongjmp/setjmp.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 00:42:38 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Breuer", "Peter T.", ""]]}, {"id": "1905.08320", "submitter": "Tianhao Wang", "authors": "Tianhao Wang, Milan Lopuha\\\"a-Zwakenberg, Zitao Li, Boris Skoric,\n  Ninghui Li", "title": "Locally Differentially Private Frequency Estimation with Consistency", "comments": "NDSS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local Differential Privacy (LDP) protects user privacy from the data\ncollector. LDP protocols have been increasingly deployed in the industry. A\nbasic building block is frequency oracle (FO) protocols, which estimate\nfrequencies of values. While several FO protocols have been proposed, the\ndesign goal does not lead to optimal results for answering many queries. In\nthis paper, we show that adding post-processing steps to FO protocols by\nexploiting the knowledge that all individual frequencies should be non-negative\nand they sum up to one can lead to significantly better accuracy for a wide\nrange of tasks, including frequencies of individual values, frequencies of the\nmost frequent values, and frequencies of subsets of values. We consider 10\ndifferent methods that exploit this knowledge differently. We establish\ntheoretical relationships between some of them and conducted extensive\nexperimental evaluations to understand which methods should be used for\ndifferent query tasks.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 19:49:52 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 21:56:31 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Wang", "Tianhao", ""], ["Lopuha\u00e4-Zwakenberg", "Milan", ""], ["Li", "Zitao", ""], ["Skoric", "Boris", ""], ["Li", "Ninghui", ""]]}, {"id": "1905.08348", "submitter": "Wenjie Xiong", "authors": "Wenjie Xiong and Jakub Szefer", "title": "Leaking Information Through Cache LRU States", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Least-Recently Used cache replacement policy and its variants are widely\ndeployed in modern processors. This paper shows for the first time in detail\nthat the LRU states of caches can be used to leak information: any access to a\ncache by a sender will modify the LRU state, and the receiver is able to\nobserve this through a timing measurement. This paper presents LRU timing-based\nchannels both when the sender and the receiver have shared memory, e.g., shared\nlibrary data pages, and when they are separate processes without shared memory.\nIn addition, the new LRU timing-based channels are demonstrated on both Intel\nand AMD processors in scenarios where the sender and the receiver are sharing\nthe cache in both hyper-threaded setting and time-sliced setting. The\ntransmission rate of the LRU channels can be up to 600Kbps per cache set in the\nhyper-threaded setting. Different from the majority of existing cache channels\nwhich require the sender to trigger cache misses, the new LRU channels work\nwith the sender only having cache hits, making the channel faster and more\nstealthy. This paper also demonstrates that the new LRU channels can be used in\ntransient execution attacks, e.g., Spectre. Further, this paper shows that the\nLRU channels pose threats to existing secure cache designs, and this work\ndemonstrates the LRU channels affect the secure PL cache. The paper finishes by\ndiscussing and evaluating possible defenses.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 21:11:13 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 04:15:48 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Xiong", "Wenjie", ""], ["Szefer", "Jakub", ""]]}, {"id": "1905.08408", "submitter": "Stephen D. Miller", "authors": "Percy Deift, Stephen D. Miller, and Thomas Trogdon", "title": "Stopping time signatures for some algorithms in cryptography", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.NT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the normalized distribution of the overall running times of some\ncryptographic algorithms, and what information they reveal about the\nalgorithms. Recent work of Deift, Menon, Olver, Pfrang, and Trogdon has shown\nthat certain numerical algorithms applied to large random matrices exhibit a\ncharacteristic distribution of running times, which depends only on the\nalgorithm but are independent of the choice of probability distributions for\nthe matrices. Different algorithms often exhibit different running time\ndistributions, and so the histograms for these running time distributions\nprovide a time-signature for the algorithms, making it possible, in many cases,\nto distinguish one algorithm from another. In this paper we extend this\nanalysis to cryptographic algorithms, and present examples of such algorithms\nwith time-signatures that are indistinguishable, and others with\ntime-signatures that are clearly distinct.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 02:27:25 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Deift", "Percy", ""], ["Miller", "Stephen D.", ""], ["Trogdon", "Thomas", ""]]}, {"id": "1905.08493", "submitter": "Chengyang Fan", "authors": "Juan Wang, Chengyang Fan, Jie Wang, Yueqiang Cheng, Yinqian Zhang,\n  Wenhui Zhang, Peng Liu, and Hongxin Hu", "title": "SvTPM: A Secure and Efficient vTPM in the Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual Trusted Platform Modules (vTPMs) have been widely used in commercial\ncloud platforms (e.g. Google Cloud, VMware Cloud, and Microsoft Azure) to\nprovide virtual root-of-trust for virtual machines. Unfortunately, current\nstate-of-the-art vTPM implementations are suffering from confidential data\nleakage and high performance overhead. In this paper, we present SvTPM, a\nsecure and efficient software-based vTPM implementation based on\nhardware-rooted Trusted Execution Environment (TEE), providing a whole life\ncycle protection of vTPMs in the cloud. SvTPM offers strong isolation\nprotection, so that cloud tenants or even cloud administrators cannot get\nvTPM's private keys or any other sensitive data. In SvTPM, we identify and\nsolve a couple of critical security challenges for vTPM protection with SGX,\nsuch as NVRAM replacement attack, rollback attacks, trust establishment, and a\nfine-grained trusted clock. We implement a prototype of SvTPM on both QEMU and\nKVM. Performance evaluation results show that SvTPM achieves orders of\nmagnitude of performance gains comparing to the vTPMs protected with physical\nTPM. The launch time of SvTPM is 2600$\\times$ faster than vTPMs built upon\nhardware TPM. In the micro-benchmarks evaluation, we find that the command\nexecution latency of SvTPM is smaller than or equal to the existing schemes.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 08:39:52 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Wang", "Juan", ""], ["Fan", "Chengyang", ""], ["Wang", "Jie", ""], ["Cheng", "Yueqiang", ""], ["Zhang", "Yinqian", ""], ["Zhang", "Wenhui", ""], ["Liu", "Peng", ""], ["Hu", "Hongxin", ""]]}, {"id": "1905.08517", "submitter": "Anwitaman Datta", "authors": "Anwitaman Datta", "title": "Blockchain in the Government Technology Fabric", "comments": "13 pages, 1 Figure, Longer version of paper published in IIAS-Lien\n  2019 conference: Science, Technology and Innovation Policies track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuelled by the success (and hype) around cryptocurrencies, distributed ledger\ntechnologies (DLT), particularly blockchains, have gained a lot of attention\nfrom a wide spectrum of audience who perceive blockchains as a key to carry out\nbusiness processes that have hitherto been cumbersome in a cost and time\neffective manner. Governments across the globe have responded to this promising\nbut nascent technology differently - from being apathetic or adopting a\nwait-and-watch approach: letting the systems shape themselves, to creating\nregulatory sandboxes and sponsoring capacity building, or in some instances\n(arguably) over-regulating and attempting to put the blockchain genie back in\nthe bottle. Possible government role spans across a spectrum: regulating\ncrypto-currencies and initial coin offerings (ICO), formulating regulatory\nframeworks for managing the adoption of blockchains, particularly in critical\ninfrastructure industries, facilitating capacity building, and finally,\nembracing blockchain technology in conducting the activities of the government\nitself - be it internally, or in using them to deliver public services. In this\npaper we survey the last, namely, the use of blockchain and associated\ndistributed ledger technologies in the government technology (GovTech) stack,\nand discuss the merits and concerns associated with the existing initiatives\nand approaches.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 09:39:14 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Datta", "Anwitaman", ""]]}, {"id": "1905.08561", "submitter": "Cong Zuo", "authors": "Cong Zuo, Shi-Feng Sun, Joseph K. Liu, Jun Shao, Josef Pieprzyk", "title": "Dynamic Searchable Symmetric Encryption Schemes Supporting Range Queries\n  with Forward/Backward Privacy", "comments": "ESORICS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic searchable symmetric encryption (DSSE) is a useful cryptographic tool\nin encrypted cloud storage. However, it has been reported that DSSE usually\nsuffers from file-injection attacks and content leak of deleted documents. To\nmitigate these attacks, forward privacy and backward privacy have been\nproposed. Nevertheless, the existing forward/backward-private DSSE schemes can\nonly support single keyword queries. To address this problem, in this paper, we\npropose two DSSE schemes supporting range queries. One is forward-private and\nsupports a large number of documents. The other can achieve backward privacy,\nwhile it can only support a limited number of documents. Finally, we also give\nthe security proofs of the proposed DSSE schemes in the random oracle model.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 11:42:28 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Zuo", "Cong", ""], ["Sun", "Shi-Feng", ""], ["Liu", "Joseph K.", ""], ["Shao", "Jun", ""], ["Pieprzyk", "Josef", ""]]}, {"id": "1905.08595", "submitter": "Sarah Azouvi", "authors": "Sarah Azouvi and Alexander Hicks", "title": "SoK: Tools for Game Theoretic Models of Security for Cryptocurrencies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptocurrencies have garnered much attention in recent years, both from the\nacademic community and industry. One interesting aspect of cryptocurrencies is\ntheir explicit consideration of incentives at the protocol level. Understanding\nhow to incorporate this into the models used to design cryptocurrencies has\nmotivated a large body of work, yet many open problems still exist and current\nsystems rarely deal with incentive related problems well. This issue arises due\nto the gap between Cryptography and Distributed Systems security, which deals\nwith traditional security problems that ignore the explicit consideration of\nincentives, and Game Theory, which deals best with situations involving\nincentives. With this work, we aim to offer a systematization of the work that\nrelates to this problem, considering papers that blend Game Theory with\nCryptography or Distributed systems and discussing how they can be related.\nThis gives an overview of the available tools, and we look at their (potential)\nuse in practice, in the context of existing blockchain based systems that have\nbeen proposed or implemented.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 13:06:38 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 18:16:55 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Azouvi", "Sarah", ""], ["Hicks", "Alexander", ""]]}, {"id": "1905.08742", "submitter": "Matteo Cardaioli", "authors": "Matteo Cardaioli, Mauro Conti, Kiran Balagani and Paolo Gasti", "title": "Your PIN Sounds Good! On The Feasibility of PIN Inference Through Audio\n  Leakage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personal Identification Numbers (PIN) are widely used as authentication\nmethod for systems such as Automated Teller Machines (ATMs) and Point of Sale\n(PoS). Input devices (PIN pads) usually give the user a feedback sound when a\nkey is pressed. In this paper, we propose an attack based on the extraction of\ninter-keystroke timing from the feedback sound when users type their PINs. Our\nattack is able to reach an accuracy of 98% with a mean error of 0.13 +/-6.66\nmilliseconds. We demonstrate that inter-keystroke timing significantly improves\nthe guessing probability of certain subsets of PINs. We believe this represents\na security problem that has to be taken into account for secure PIN generation.\nFurthermore, we identified several attack scenarios where the adversary can\nexploit inter-keystroke timing and additional information about the user or the\nPIN, such as typing behavior. Our results show that combining the\ninter-keystroke timing with other information drastically reduces attempts to\nguess a PIN, outperforming random guessing. With our attack, we are able to\nguess 72% of the 4-digit PINs within 3 attempts. We believe this poses a\nserious security problem for systems that use PIN-based authentication.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 16:38:56 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Cardaioli", "Matteo", ""], ["Conti", "Mauro", ""], ["Balagani", "Kiran", ""], ["Gasti", "Paolo", ""]]}, {"id": "1905.08790", "submitter": "Zirui Xu", "authors": "Zirui Xu, Fuxun Yu, Xiang Chen", "title": "DoPa: A Comprehensive CNN Detection Methodology against Physical\n  Adversarial Attacks", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Convolutional Neural Networks (CNNs) demonstrate a considerable\nvulnerability to adversarial attacks, which can be easily misled by adversarial\nperturbations. With more aggressive methods proposed, adversarial attacks can\nbe also applied to the physical world, causing practical issues to various CNN\npowered applications. To secure CNNs, adversarial attack detection is\nconsidered as the most critical approach. However, most existing works focus on\nsuperficial patterns and merely search a particular method to differentiate the\nadversarial inputs and natural inputs, ignoring the analysis of CNN inner\nvulnerability. Therefore, they can only target to specific physical adversarial\nattacks, lacking expected versatility to different attacks. To address this\nissue, we propose DoPa -- a comprehensive CNN detection methodology for various\nphysical adversarial attacks. By interpreting the CNN's vulnerability, we find\nthat non-semantic adversarial perturbations can activate CNN with significantly\nabnormal activations and even overwhelm other semantic input patterns'\nactivations. Therefore, we add a self-verification stage to analyze the\nsemantics of distinguished activation patterns, which improves the CNN\nrecognition process. We apply such a detection methodology into both image and\naudio CNN recognition scenarios. Experiments show that DoPa can achieve an\naverage rate of 90% success for image attack detection and 92% success for\naudio attack detection.\n  Announcement:[The original DoPa draft on arXiv was modified and submitted to\na conference already, while this short abstract was submitted only for a\npresentation at the KDD 2019 AIoT Workshop.]\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 19:53:38 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 18:56:50 GMT"}, {"version": "v3", "created": "Fri, 23 Aug 2019 20:38:44 GMT"}, {"version": "v4", "created": "Wed, 28 Aug 2019 15:07:07 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Xu", "Zirui", ""], ["Yu", "Fuxun", ""], ["Chen", "Xiang", ""]]}, {"id": "1905.08792", "submitter": "Pascal Giard", "authors": "Jean-Fran\\c{c}ois T\\^etu, Louis-Charles Trudeau, Michiel Van\n  Beirendonck, Alexios Balatsoukas-Stimming, Pascal Giard", "title": "A Standalone FPGA-based Miner for Lyra2REv2 Cryptocurrencies", "comments": "13 pages, accepted for publication in IEEE Trans. Circuits Syst. I.\n  arXiv admin note: substantial text overlap with arXiv:1807.05764", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lyra2REv2 is a hashing algorithm that consists of a chain of individual\nhashing algorithms, and it is used as a proof-of-work function in several\ncryptocurrencies. The most crucial and exotic hashing algorithm in the\nLyra2REv2 chain is a specific instance of the general Lyra2 algorithm. This\nwork presents the first hardware implementation of the specific instance of\nLyra2 that is used in Lyra2REv2. Several properties of the aforementioned\nalgorithm are exploited in order to optimize the design. In addition, an\nFPGA-based hardware implementation of a standalone miner for Lyra2REv2 on a\nXilinx Multi-Processor System on Chip is presented. The proposed Lyra2REv2\nminer is shown to be significantly more energy efficient than both a GPU and a\ncommercially available FPGA-based miner. Finally, we also explain how the\nsimplified Lyra2 and Lyra2REv2 architectures can be modified with minimal\neffort to also support the recent Lyra2REv3 chained hashing algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 14:58:54 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 19:59:10 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["T\u00eatu", "Jean-Fran\u00e7ois", ""], ["Trudeau", "Louis-Charles", ""], ["Van Beirendonck", "Michiel", ""], ["Balatsoukas-Stimming", "Alexios", ""], ["Giard", "Pascal", ""]]}, {"id": "1905.08833", "submitter": "Aron Laszka", "authors": "Afiya Ayman, Shanto Roy, Amin Alipour, Aron Laszka", "title": "Smart Contract Development from the Perspective of Developers: Topics\n  and Issues Discussed on Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain-based platforms are emerging as a transformative technology that\ncan provide reliability, integrity, and auditability without trusted entities.\nOne of the key features of these platforms is the trustworthy decentralized\nexecution of general-purpose computation in the form of smart contracts, which\nare envisioned to have a wide range of applications. As a result, a rapidly\ngrowing and active community of smart-contract developers has emerged in recent\nyears. A number of research efforts have investigated the technological\nchallenges that these developers face, introducing a variety of tools,\nlanguages, and frameworks for smart-contract development, focusing on security.\nHowever, relatively little is known about the community itself, about the\ndevelopers, and about the issues that they face and discuss. To address this\ngap, we study smart-contract developers and their discussions on two social\nmedia sites, Stack Exchange and Medium. We provide insight into the trends and\nkey topics of these discussions, into the developers' interest in various\nsecurity issues and security tools, and into the developers' technological\nbackground.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 19:46:37 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 01:25:44 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Ayman", "Afiya", ""], ["Roy", "Shanto", ""], ["Alipour", "Amin", ""], ["Laszka", "Aron", ""]]}, {"id": "1905.08902", "submitter": "Simon Duque Anton", "authors": "Simon Duque Anton, Daniel Fraunholz, Christoph Lipps, Frederic Pohl,\n  Marc Zimmermann and Hans D. Schotten", "title": "Two Decades of SCADA Exploitation: A Brief History", "comments": null, "journal-ref": null, "doi": "10.1109/AINS.2017.8270432", "report-no": null, "categories": "cs.CR cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the early 1960, industrial process control has been applied by electric\nsystems. In the mid 1970's, the term SCADA emerged, describing the automated\ncontrol and data acquisition. Since most industrial and automation networks\nwere physically isolated, security was not an issue. This changed, when in the\nearly 2000's industrial networks were opened to the public internet. The\nreasons were manifold. Increased interconnectivity led to more productivity,\nsimplicity and ease of use. It decreased the configuration overhead and\ndowntimes for system adjustments. However, it also led to an abundance of new\nattack vectors. In recent time, there has been a remarkable amount of attacks\non industrial companies and infrastructures. In this paper, known attacks on\nindustrial systems are analysed. This is done by investigating the exploits\nthat are available on public sources. The different types of attacks and their\npoints of entry are reviewed in this paper. Trends in exploitation as well as\ntargeted attack campaigns against industrial enterprises are introduced.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 23:51:08 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Anton", "Simon Duque", ""], ["Fraunholz", "Daniel", ""], ["Lipps", "Christoph", ""], ["Pohl", "Frederic", ""], ["Zimmermann", "Marc", ""], ["Schotten", "Hans D.", ""]]}, {"id": "1905.09013", "submitter": "Tamir Tassa", "authors": "Tamir Tassa, Tal Grinshpoun, Avishay Yanai", "title": "A Privacy Preserving Collusion Secure DCOP Algorithm", "comments": "This version is an extension of our IJCAI 2019 paper, with added\n  proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, several studies proposed privacy-preserving algorithms for\nsolving Distributed Constraint Optimization Problems (DCOPs). All of those\nstudies assumed that agents do not collude. In this study we propose the first\nprivacy-preserving DCOP algorithm that is immune to coalitions, under the\nassumption of honest majority. Our algorithm -- PC-SyncBB -- is based on the\nclassical Branch and Bound DCOP algorithm. It offers constraint, topology and\ndecision privacy. We evaluate its performance on different benchmarks, problem\nsizes, and constraint densities. We show that achieving security against\ncoalitions is feasible. As all existing privacy-preserving DCOP algorithms base\ntheir security on assuming solitary conduct of the agents, we view this study\nas an essential first step towards lifting this potentially harmful assumption\nin all those algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 08:27:33 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Tassa", "Tamir", ""], ["Grinshpoun", "Tal", ""], ["Yanai", "Avishay", ""]]}, {"id": "1905.09084", "submitter": "Martin Eker{\\aa}", "authors": "Martin Eker{\\aa}", "title": "Revisiting Shor's quantum algorithm for computing general discrete\n  logarithms", "comments": "The pre-print has been extended to show how slightly better tradeoffs\n  may be achieved, compared to our earlier works, if the group order is known.\n  A minor issue with an integration limit, that lead us to give a rough success\n  probability estimate of 60% to 70%, as opposed to 60% to 82%, has been\n  corrected. The heuristic and results reported in the original pre-print are\n  otherwise unaffected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We heuristically demonstrate that Shor's algorithm for computing general\ndiscrete logarithms, modified to allow the semi-classical Fourier transform to\nbe used with control qubit recycling, achieves a success probability of\napproximately 60% to 82% in a single run. By slightly increasing the number of\ngroup operations that are evaluated quantumly, and by performing a limited\nsearch in the classical post-processing, we furthermore show how the algorithm\ncan be modified to achieve a success probability exceeding 99% in a single run.\nWe provide concrete heuristic estimates of the success probability of the\nmodified algorithm, as a function of the group order, the size of the search\nspace in the classical post-processing, and the additional number of group\noperations evaluated quantumly. In analogy with our earlier works, we show how\nthe modified quantum algorithm may be simulated classically when the logarithm\nand group order are both known. Furthermore, we show how slightly better\ntradeoffs may be achieved, compared to our earlier works, if the group order is\nknown when computing the logarithm.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 11:47:38 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 14:29:43 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Eker\u00e5", "Martin", ""]]}, {"id": "1905.09088", "submitter": "Mohammad Khodaei", "authors": "Mohammad Khodaei, Hamid Noroozi, and Panos Papadimitratos", "title": "Scaling Pseudonymous Authentication for Large Mobile Systems", "comments": "12 pages, 7 figures, Proceedings of the 12th Conference on Security\n  and Privacy in Wireless and Mobile Networks", "journal-ref": "ACM Proceedings of the 12th Conference on Security and Privacy in\n  Wireless and Mobile Networks, Miami, Florida, May 2019", "doi": "10.1145/3317549.3323410", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The central building block of secure and privacy-preserving Vehicular\nCommunication (VC) systems is a Vehicular Public-Key Infrastructure (VPKI),\nwhich provides vehicles with multiple anonymized credentials, termed\npseudonyms. These pseudonyms are used to ensure message authenticity and\nintegrity while preserving vehicle (thus passenger) privacy. In the light of\nemerging large-scale multi-domain VC environments, the efficiency of the VPKI\nand, more broadly, its scalability are paramount. By the same token, preventing\nmisuse of the credentials, in particular, Sybil-based misbehavior, and managing\n\"honest-but-curious\" insiders are other facets of a challenging problem. In\nthis paper, we leverage a state-of-the-art VPKI system and enhance its\nfunctionality towards a highly-available, dynamically-scalable, and resilient\ndesign; this ensures that the system remains operational in the presence of\nbenign failures or resource depletion attacks, and that it dynamically scales\nout, or possibly scales in, according to request arrival rates. Our full-blown\nimplementation on the Google Cloud Platform shows that deploying large-scale\nand efficient VPKI can be cost-effective.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 11:57:46 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Khodaei", "Mohammad", ""], ["Noroozi", "Hamid", ""], ["Papadimitratos", "Panos", ""]]}, {"id": "1905.09093", "submitter": "David Cerezo S\\'anchez", "authors": "David Cerezo S\\'anchez", "title": "Zero-Knowledge Proof-of-Identity: Sybil-Resistant, Anonymous\n  Authentication on Permissionless Blockchains and Incentive Compatible,\n  Strictly Dominant Cryptocurrencies", "comments": "2.1: Proof-of-Personhood Considered Harmful (and Illegal); 4.1.5:\n  Absence of Active Authentication; 4.2.6: Absence of Active Authentication;\n  4.2.7: Removing Single-Points of Failure; 4.3.2: Combining with\n  Non-Zero-Knowledge Authentication; 4.4: Circumventing the Impossibility of\n  Full Decentralization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-Knowledge Proof-of-Identity from trusted public certificates (e.g.,\nnational identity cards and/or ePassports; eSIM) is introduced here to\npermissionless blockchains in order to remove the inefficiencies of\nSybil-resistant mechanisms such as Proof-of-Work (i.e., high energy and\nenvironmental costs) and Proof-of-Stake (i.e., capital hoarding and lower\ntransaction volume). The proposed solution effectively limits the number of\nmining nodes a single individual would be able to run while keeping membership\nopen to everyone, circumventing the impossibility of full decentralization and\nthe blockchain scalability trilemma when instantiated on a blockchain with a\nconsensus protocol based on the cryptographic random selection of nodes.\nResistance to collusion is also considered.\n  Solving one of the most pressing problems in blockchains, a zk-PoI\ncryptocurrency is proved to have the following advantageous properties:\n  - an incentive-compatible protocol for the issuing of cryptocurrency rewards\nbased on a unique Nash equilibrium\n  - strict domination of mining over all other PoW/PoS cryptocurrencies, thus\nthe zk-PoI cryptocurrency becoming the preferred choice by miners is proved to\nbe a Nash equilibrium and the Evolutionarily Stable Strategy\n  - PoW/PoS cryptocurrencies are condemned to pay the Price of Crypto-Anarchy,\nredeemed by the optimal efficiency of zk-PoI as it implements the social\noptimum\n  - the circulation of a zk-PoI cryptocurrency Pareto dominates other PoW/PoS\ncryptocurrencies\n  - the network effects arising from the social networks inherent to national\nidentity cards and ePassports dominate PoW/PoS cryptocurrencies\n  - the lower costs of its infrastructure imply the existence of a unique\nequilibrium where it dominates other forms of payment\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 12:06:03 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 23:13:00 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["S\u00e1nchez", "David Cerezo", ""]]}, {"id": "1905.09100", "submitter": "Daniel Gruss", "authors": "Michael Schwarz, Robert Schilling, Florian Kargl, Moritz Lipp, Claudio\n  Canella, Daniel Gruss", "title": "ConTExT: Leakage-Free Transient Execution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Out-of-order execution and speculative execution are among the biggest\ncontributors to performance and efficiency of modern processors. However, they\nare inconsiderate, leaking secret data during the transient execution of\ninstructions. Many solutions have been proposed against transient execution\nattacks. However, they do not eliminate the leakage entirely or introduce\nunacceptable performance penalties.\n  In this paper, we propose ConTExT, a Considerate Transient Execution\nTechnique. The basic idea of ConTExT is that secrets can enter registers, but\nnot transiently leave them. ConTExT transforms Spectre from a problem that\ncannot be solved purely in software [53], to a problem that is not easy to\nsolve, but solvable in software. For this, ConTExT requires minimal\nmodifications of applications, compilers, operating systems, and the hardware.\nConTExT offers full protection for secrets in memory and secrets in registers.\nWe evaluate the security and performance of ConTExT. With its principled\napproach it inherently mitigates the recently found microarchitectural data\nsampling attacks on small processor buffers. Even when over-approximating, we\nobserve no performance overhead for unprotected code and data, and an overhead\nof 71.14% for security-critical applications, which is below the overhead of\ncurrently recommended state-of-the-art mitigation strategies. The actual\noverhead of ConTExT is below 1% for real-world workloads.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 12:25:03 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Schwarz", "Michael", ""], ["Schilling", "Robert", ""], ["Kargl", "Florian", ""], ["Lipp", "Moritz", ""], ["Canella", "Claudio", ""], ["Gruss", "Daniel", ""]]}, {"id": "1905.09136", "submitter": "Muhammad Ikram", "authors": "Muhammad Ikram, Pierrick Beaume, Mohamed Ali Kaafar", "title": "DaDiDroid: An Obfuscation Resilient Tool for Detecting Android Malware\n  via Weighted Directed Call Graph Modelling", "comments": "9 pages. arXiv admin note: text overlap with arXiv:1801.01633 by\n  other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the number of new mobile malware instances increasing by over 50\\%\nannually since 2012 [24], malware embedding in mobile apps is arguably one of\nthe most serious security issues mobile platforms are exposed to. While\nobfuscation techniques are successfully used to protect the intellectual\nproperty of apps' developers, they are unfortunately also often used by\ncybercriminals to hide malicious content inside mobile apps and to deceive\nmalware detection tools. As a consequence, most of mobile malware detection\napproaches fail in differentiating between benign and obfuscated malicious\napps. We examine the graph features of mobile apps code by building weighted\ndirected graphs of the API calls, and verify that malicious apps often share\nstructural similarities that can be used to differentiate them from benign\napps, even under a heavily \"polluted\" training set where a large majority of\nthe apps are obfuscated. We present DaDiDroid an Android malware app detection\ntool that leverages features of the weighted directed graphs of API calls to\ndetect the presence of malware code in (obfuscated) Android apps. We show that\nDaDiDroid significantly outperforms MaMaDroid [23], a recently proposed malware\ndetection tool that has been proven very efficient in detecting malware in a\nclean non-obfuscated environment. We evaluate DaDiDroid's accuracy and\nrobustness against several evasion techniques using various datasets for a\ntotal of 43,262 benign and 20,431 malware apps. We show that DaDiDroid\ncorrectly labels up to 96% of Android malware samples, while achieving an 91%\naccuracy with an exclusive use of a training set of obfuscated apps.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 13:43:24 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 06:34:01 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2019 22:37:05 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Ikram", "Muhammad", ""], ["Beaume", "Pierrick", ""], ["Kaafar", "Mohamed Ali", ""]]}, {"id": "1905.09162", "submitter": "Giulio Lovisotto", "authors": "Giulio Lovisotto and Simon Eberz and Ivan Martinovic", "title": "Biometric Backdoors: A Poisoning Attack Against Unsupervised Template\n  Updating", "comments": "12 pages", "journal-ref": null, "doi": "10.1109/EuroSP48549.2020.00020", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate the concept of biometric backdoors: a template\npoisoning attack on biometric systems that allows adversaries to stealthily and\neffortlessly impersonate users in the long-term by exploiting the template\nupdate procedure. We show that such attacks can be carried out even by\nattackers with physical limitations (no digital access to the sensor) and zero\nknowledge of training data (they know neither decision boundaries nor user\ntemplate). Based on the adversaries' own templates, they craft several\nintermediate samples that incrementally bridge the distance between their own\ntemplate and the legitimate user's. As these adversarial samples are added to\nthe template, the attacker is eventually accepted alongside the legitimate\nuser. To avoid detection, we design the attack to minimize the number of\nrejected samples.\n  We design our method to cope with the weak assumptions for the attacker and\nwe evaluate the effectiveness of this approach on state-of-the-art face\nrecognition pipelines based on deep neural networks. We find that in scenarios\nwhere the deep network is known, adversaries can successfully carry out the\nattack over 70% of cases with less than ten injection attempts. Even in\nblack-box scenarios, we find that exploiting the transferability of adversarial\nsamples from surrogate models can lead to successful attacks in around 15% of\ncases. Finally, we design a poisoning detection technique that leverages the\nconsistent directionality of template updates in feature space to discriminate\nbetween legitimate and malicious updates. We evaluate such a countermeasure\nwith a set of intra-user variability factors which may present the same\ndirectionality characteristics, obtaining equal error rates for the detection\nbetween 7-14% and leading to over 99% of attacks being detected after only two\nsample injections.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 14:18:32 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 12:06:07 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Lovisotto", "Giulio", ""], ["Eberz", "Simon", ""], ["Martinovic", "Ivan", ""]]}, {"id": "1905.09165", "submitter": "Soham Pal", "authors": "Soham Pal, Yash Gupta, Aditya Shukla, Aditya Kanade, Shirish Shevade,\n  Vinod Ganapathy", "title": "A framework for the extraction of Deep Neural Networks by leveraging\n  public data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models trained on confidential datasets are increasingly\nbeing deployed for profit. Machine Learning as a Service (MLaaS) has made such\nmodels easily accessible to end-users. Prior work has developed model\nextraction attacks, in which an adversary extracts an approximation of MLaaS\nmodels by making black-box queries to it. However, none of these works is able\nto satisfy all the three essential criteria for practical model extraction: (1)\nthe ability to work on deep learning models, (2) the non-requirement of domain\nknowledge and (3) the ability to work with a limited query budget. We design a\nmodel extraction framework that makes use of active learning and large public\ndatasets to satisfy them. We demonstrate that it is possible to use this\nframework to steal deep classifiers trained on a variety of datasets from image\nand text domains. By querying a model via black-box access for its top\nprediction, our framework improves performance on an average over a uniform\nnoise baseline by 4.70x for image tasks and 2.11x for text tasks respectively,\nwhile using only 30% (30,000 samples) of the public dataset at its disposal.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 14:26:04 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Pal", "Soham", ""], ["Gupta", "Yash", ""], ["Shukla", "Aditya", ""], ["Kanade", "Aditya", ""], ["Shevade", "Shirish", ""], ["Ganapathy", "Vinod", ""]]}, {"id": "1905.09186", "submitter": "Jonathan Aigrain", "authors": "Jonathan Aigrain, Marcin Detyniecki", "title": "Detecting Adversarial Examples and Other Misclassifications in Neural\n  Networks by Introspection", "comments": "5 pages, 2 figures, Presented at the ICML 2019 Workshop on\n  Uncertainty and Robustness in Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite having excellent performances for a wide variety of tasks, modern\nneural networks are unable to provide a reliable confidence value allowing to\ndetect misclassifications. This limitation is at the heart of what is known as\nan adversarial example, where the network provides a wrong prediction\nassociated with a strong confidence to a slightly modified image. Moreover,\nthis overconfidence issue has also been observed for regular errors and\nout-of-distribution data. We tackle this problem by what we call introspection,\ni.e. using the information provided by the logits of an already pretrained\nneural network. We show that by training a simple 3-layers neural network on\ntop of the logit activations, we are able to detect misclassifications at a\ncompetitive level.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 15:12:50 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Aigrain", "Jonathan", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "1905.09207", "submitter": "Akbar Siami Namin", "authors": "Moitrayee Chatterjee and Akbar Siami Namin", "title": "Deep Reinforcement Learning for Detecting Malicious Websites", "comments": "8 pages, 2 figures, COMPSAC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phishing is the simplest form of cybercrime with the objective of baiting\npeople into giving away delicate information such as individually recognizable\ndata, banking and credit card details, or even credentials and passwords. This\ntype of simple yet most effective cyber-attack is usually launched through\nemails, phone calls, or instant messages. The credential or private data stolen\nare then used to get access to critical records of the victims and can result\nin extensive fraud and monetary loss. Hence, sending malicious messages to\nvictims is a stepping stone of the phishing procedure. A \\textit{phisher}\nusually setups a deceptive website, where the victims are conned into entering\ncredentials and sensitive information. It is therefore important to detect\nthese types of malicious websites before causing any harmful damages to\nvictims. Inspired by the evolving nature of the phishing websites, this paper\nintroduces a novel approach based on deep reinforcement learning to model and\ndetect malicious URLs. The proposed model is capable of adapting to the dynamic\nbehavior of the phishing websites and thus learn the features associated with\nphishing website detection.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 15:55:22 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Chatterjee", "Moitrayee", ""], ["Namin", "Akbar Siami", ""]]}, {"id": "1905.09222", "submitter": "Akbar Siami Namin", "authors": "Jianjun Zheng and Akbar Siami Namin", "title": "Markov Decision Process to Enforce Moving Target Defence Policies", "comments": "10 pages, 7 figures, COMPSAC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Moving Target Defense (MTD) is an emerging game-changing defense strategy in\ncybersecurity with the goal of strengthening defenders and conversely puzzling\nadversaries in a network environment. The successful deployment of an MTD\nsystem can be affected by several factors including 1) the effectiveness of the\nemployed technique, 2) the deployment strategy, 3) the cost of the MTD\nimplementation, and 4) the impact yielded by the enforced security policies.\nMany research efforts have been spent on introducing a variety of MTD\ntechniques which are often evaluated through simulations. Nevertheless, this\nline of research needs more attention. In particular, the determination of\noptimal cost and policy analysis and the selection of those policies in an MTD\nsetting is still an open research question.\n  To advance the state-of-the-art of this line of research, this paper\nintroduces an approach based on control theory to model, analyze and select\noptimal security policies for Moving Target Defense (MTD) deployment\nstrategies. A Markov Decision Process (MDP) scheme is presented to model states\nof the system from attacking point of view. The employed value iteration method\nis based on the Bellman optimality equation for optimal policy selection for\neach state defined in the system. The model is then utilized to analyze the\nimpact of various costs on the optimal policy. The MDP model is then applied to\ntwo case studies to evaluate the performance of the model.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 16:19:27 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Zheng", "Jianjun", ""], ["Namin", "Akbar Siami", ""]]}, {"id": "1905.09274", "submitter": "Mustafa Al-Bassam", "authors": "Mustafa Al-Bassam", "title": "LazyLedger: A Distributed Data Availability Ledger With Client-Side\n  Smart Contracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose LazyLedger, a design for distributed ledgers where the blockchain\nis optimised for solely ordering and guaranteeing the availability of\ntransaction data. Responsibility for executing and validating transactions is\nshifted to only the clients that have an interest in specific transactions\nrelating to blockchain applications that they use. As the core function of the\nconsensus system of a distributed ledger is to order transactions and ensure\ntheir availability, consensus participants do not necessarily need to be\nconcerned with the contents of those transactions. This reduces the problem of\nblock verification to data availability verification, which can be achieved\nprobabilistically with sub-linear complexity, without downloading the whole\nblock. The amount of resources required to reach consensus can thus be\nminimised, as transaction validity rules can be decoupled from consensus rules.\nWe also implement and evaluate several example LazyLedger applications, and\nvalidate that the workload of clients of specific applications does not\nsignificantly increase when the workload of other applications that use the\nsame chain increase.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 17:59:17 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 15:08:20 GMT"}, {"version": "v3", "created": "Sun, 26 May 2019 16:27:27 GMT"}, {"version": "v4", "created": "Sat, 8 Jun 2019 03:37:55 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Al-Bassam", "Mustafa", ""]]}, {"id": "1905.09336", "submitter": "David Thaw", "authors": "David Thaw, Bret Barkley, Gerry Bella, and Carrie Gardner", "title": "Simulation-Based Cyber Data Collection Efficacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building upon previous research in honeynets and simulations, we present\nefforts from a two-and-a-half-year study using a representative simulation to\ncollect cybersecurity data. Unlike traditional honeypots or honeynets, our\nexperiment utilizes a full-scale operational network to model a small business\nenvironment. The simulation uses default security configurations to defend the\nnetwork, testing the assumption that given standard security baseline, devices\nnetworked to the public Internet will necessarily be hacked. Given network\nactivity appropriate for its context, results support the conclusion that no\nactors where able to break in, despite only default security settings.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 19:22:17 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Thaw", "David", ""], ["Barkley", "Bret", ""], ["Bella", "Gerry", ""], ["Gardner", "Carrie", ""]]}, {"id": "1905.09352", "submitter": "Sadegh Farhang", "authors": "Sadegh Farhang, Mehmet Bahadir Kirdan, Aron Laszka, Jens Grossklags", "title": "Hey Google, What Exactly Do Your Security Patches Tell Us? A Large-Scale\n  Empirical Study on Android Patched Vulnerabilities", "comments": "The 2019 Workshop on the Economics of Information Security (WEIS\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we perform a comprehensive study of 2,470 patched Android\nvulnerabilities that we collect from different data sources such as Android\nsecurity bulletins, CVEDetails, Qualcomm Code Aurora, AOSP Git repository, and\nLinux Patchwork. In our data analysis, we focus on determining the affected\nlayers, OS versions, severity levels, and common weakness enumerations (CWE)\nassociated with the patched vulnerabilities. Further, we assess the timeline of\neach vulnerability, including discovery and patch dates. We find that (i) even\nthough the number of patched vulnerabilities changes considerably from month to\nmonth, the relative number of patched vulnerabilities for each severity level\nremains stable over time, (ii) there is a significant delay in patching\nvulnerabilities that originate from the Linux community or concern Qualcomm\ncomponents, even though Linux and Qualcomm provide and release their own\npatches earlier, (iii) different AOSP versions receive security updates for\ndifferent periods of time, (iv) for 94% of patched Android vulnerabilities, the\ndate of disclosure in public datasets is not before the patch release date, (v)\nthere exist some inconsistencies among public vulnerability data sources, e.g.,\nsome CVE IDs are listed in Android Security bulletins with detailed\ninformation, but in CVEDetails they are listed as unknown, (vi) many patched\nvulnerabilities for newer Android versions likely also affect older versions\nthat do not receive security patches due to end-of-life.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 20:16:25 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Farhang", "Sadegh", ""], ["Kirdan", "Mehmet Bahadir", ""], ["Laszka", "Aron", ""], ["Grossklags", "Jens", ""]]}, {"id": "1905.09359", "submitter": "Mohammad Javad Amiri", "authors": "Victor Zakhary, Mohammad Javad Amiri, Sujaya Maiyya, Divyakant\n  Agrawal, Amr El Abbadi", "title": "Towards Global Asset Management in Blockchain Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Permissionless blockchains (e.g., Bitcoin, Ethereum, etc) have shown a wide\nsuccess in implementing global scale peer-to-peer cryptocurrency systems. In\nsuch blockchains, new currency units are generated through the mining process\nand are used in addition to transaction fees to incentivize miners to maintain\nthe blockchain. Although it is clear how currency units are generated and\ntransacted on, it is unclear how to use the infrastructure of permissionless\nblockchains to manage other assets than the blockchain's currency units (e.g.,\ncars, houses, etc). In this paper, we propose a global asset management system\nby unifying permissioned and permissionless blockchains. A governmental\npermissioned blockchain authenticates the registration of end-user assets\nthrough smart contract deployments on a permissionless blockchain. Afterwards,\nend-users can transact on their assets through smart contract function calls\n(e.g., sell a car, rent a room in a house, etc). In return, end-users get paid\nin currency units of the same blockchain or other blockchains through atomic\ncross-chain transactions and governmental offices receive taxes on these\ntransactions in cryptocurrency units.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 20:44:36 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Zakhary", "Victor", ""], ["Amiri", "Mohammad Javad", ""], ["Maiyya", "Sujaya", ""], ["Agrawal", "Divyakant", ""], ["Abbadi", "Amr El", ""]]}, {"id": "1905.09420", "submitter": "Jordan Awan", "authors": "Matthew Reimherr and Jordan Awan", "title": "Elliptical Perturbations for Differential Privacy", "comments": "13 pages. Published in NeurIPS 2019\n  (https://proceedings.neurips.cc/paper/2019/hash/b3dd760eb02d2e669c604f6b2f1e803f-Abstract.html).\n  This Arxiv document corrects a few minor errors in the published version", "journal-ref": "NeurIPS 32 (2019)", "doi": null, "report-no": null, "categories": "cs.CR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study elliptical distributions in locally convex vector spaces, and\ndetermine conditions when they can or cannot be used to satisfy differential\nprivacy (DP). A requisite condition for a sanitized statistical summary to\nsatisfy DP is that the corresponding privacy mechanism must induce equivalent\nmeasures for all possible input databases. We show that elliptical\ndistributions with the same dispersion operator, $C$, are equivalent if the\ndifference of their means lies in the Cameron-Martin space of $C$. In the case\nof releasing finite-dimensional projections using elliptical perturbations, we\nshow that the privacy parameter $\\ep$ can be computed in terms of a\none-dimensional maximization problem. We apply this result to consider\nmultivariate Laplace, $t$, Gaussian, and $K$-norm noise. Surprisingly, we show\nthat the multivariate Laplace noise does not achieve $\\ep$-DP in any dimension\ngreater than one. Finally, we show that when the dimension of the space is\ninfinite, no elliptical distribution can be used to give $\\ep$-DP; only\n$(\\epsilon,\\delta)$-DP is possible.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 01:15:39 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 17:12:54 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Reimherr", "Matthew", ""], ["Awan", "Jordan", ""]]}, {"id": "1905.09436", "submitter": "Jordan Awan", "authors": "Matthew Reimherr and Jordan Awan", "title": "KNG: The K-Norm Gradient Mechanism", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new mechanism for producing sanitized statistical\nsummaries that achieve \\emph{differential privacy}, called the \\emph{K-Norm\nGradient} Mechanism, or KNG. This new approach maintains the strong flexibility\nof the exponential mechanism, while achieving the powerful utility performance\nof objective perturbation. KNG starts with an inherent objective function\n(often an empirical risk), and promotes summaries that are close to minimizing\nthe objective by weighting according to how far the gradient of the objective\nfunction is from zero. Working with the gradient instead of the original\nobjective function allows for additional flexibility as one can penalize using\ndifferent norms. We show that, unlike the exponential mechanism, the noise\nadded by KNG is asymptotically negligible compared to the statistical error for\nmany problems. In addition to theoretical guarantees on privacy and utility, we\nconfirm the utility of KNG empirically in the settings of linear and quantile\nregression through simulations.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 02:15:49 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Reimherr", "Matthew", ""], ["Awan", "Jordan", ""]]}, {"id": "1905.09455", "submitter": "Michael Segal", "authors": "Roni Mateless and Michael Segal", "title": "Approximate String Matching for DNS Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel approach to identify anomalies in DNS\ntraffic. The traffic time-points data is transformed to a string, which is used\nby new fast appproximate string matching algorithm to detect anomalies. Our\napproach is generic in its nature and allows fast adaptation to different types\nof traffic. We evaluate the approach on a large public dataset of DNS traffic\nbased on 10 days, discovering more than order of magnitude DNS attacks in\ncomparison to auto-regression as a baseline. Moreover, the additional\ncomparison has been made including other common regressors such as Linear\nRegression, Lasso, Random Forest and KNN, all of them showing the superiority\nof our approach.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 04:10:19 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Mateless", "Roni", ""], ["Segal", "Michael", ""]]}, {"id": "1905.09478", "submitter": "Vy-An Phan", "authors": "Vy-An Phan", "title": "Private Queries on Public Certificate Transparency Data", "comments": "27 pages, 3 figures, 2 algorithms", "journal-ref": null, "doi": null, "report-no": "UCB/EECS-2019-27", "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite increasing advancements in today's information exchange\ninfrastructure, the preservation of user data and privacy still remains a\nproblem. Both insecure baselines and secure solutions leak user data. For\nexample, Certificate Transparency (CT) promises significant security\nimprovements to existing Public Key Infrastructure solutions that up-to-now\nhave solely relied on the Certificate Authority hierarchy. CT provides a robust\nauditing layer and transparency solution to quickly detect such compromises,\nbut introduces the requirement that client browsers interact with third-party\nservers when validating a site certificate. In the existing CT system, these\nrequests leak information about each user's browsing habits to the hosting\nserver. It is not a stretch to think that this valuable data could be collected\nand exploited, as corporations and governments have plenty of financial and\npolitical incentive to do so. In this project, we seek to address this problem\nby using an oblivious file sharing system with strong anonymity properties, to\nprovide a more scalable, performant solution to privacy-preserving queries.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 19:22:18 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Phan", "Vy-An", ""]]}, {"id": "1905.09532", "submitter": "Chengyu Song", "authors": "Wookhyun Han, Md Lutfor Rahman, Yuxuan Chen, Chengyu Song, Byoungyoung\n  Lee, Insik Shin", "title": "SynFuzz: Efficient Concolic Execution via Branch Condition Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concolic execution is a powerful program analysis technique for exploring\nexecution paths in a systematic manner. Compare to random-mutation-based\nfuzzing, concolic execution is especially good at exploring paths that are\nguarded by complex and tight branch predicates (e.g., (a*b) == 0xdeadbeef). The\ndrawback, however, is that concolic execution engines are much slower than\nnative execution. One major source of the slowness is that concolic execution\nengines have to the interpret instructions to maintain the symbolic expression\nof program variables. In this work, we propose SynFuzz, a novel approach to\nperform scalable concolic execution. SynFuzz achieves this goal by replacing\ninterpretation with dynamic taint analysis and program synthesis. In\nparticular, to flip a conditional branch, SynFuzz first uses operation-aware\ntaint analysis to record a partial expression (i.e., a sketch) of its branch\npredicate. Then it uses oracle-guided program synthesis to reconstruct the\nsymbolic expression based on input-output pairs. The last step is the same as\ntraditional concolic execution - SynFuzz consults a SMT solver to generate an\ninput that can flip the target branch. By doing so, SynFuzz can achieve an\nexecution speed that is close to fuzzing while retain concolic execution's\ncapability of flipping complex branch predicates. We have implemented a\nprototype of SynFuzz and evaluated it with three sets of programs: real-world\napplications, the LAVA-M benchmark, and the Google Fuzzer Test Suite (FTS). The\nevaluation results showed that SynFuzz was much more scalable than traditional\nconcolic execution engines, was able to find more bugs in LAVA-M than most\nstate-of-the-art concolic execution engine (QSYM), and achieved better code\ncoverage on real-world applications and FTS.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 08:34:23 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Han", "Wookhyun", ""], ["Rahman", "Md Lutfor", ""], ["Chen", "Yuxuan", ""], ["Song", "Chengyu", ""], ["Lee", "Byoungyoung", ""], ["Shin", "Insik", ""]]}, {"id": "1905.09538", "submitter": "Amir Rubin", "authors": "Amir Rubin, Shay Kels, Danny Hendler", "title": "AMSI-Based Detection of Malicious PowerShell Code Using Contextual\n  Embeddings", "comments": "17 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PowerShell is a command-line shell, supporting a scripting language. It is\nwidely used in organizations for configuration management and task automation\nbut is also increasingly used by cybercriminals for launching cyberattacks\nagainst organizations, mainly because it is pre-installed on Windows machines\nand exposes strong functionality that may be leveraged by attackers. This makes\nthe problem of detecting malicious PowerShell code both urgent and challenging.\nMicrosoft's Antimalware Scan Interface (AMSI) allows defending systems to scan\nall the code passed to scripting engines such as PowerShell prior to its\nexecution. In this work, we conduct the first study of malicious PowerShell\ncode detection using the information made available by AMSI.\n  We present several novel deep-learning based detectors of malicious\nPowerShell code that employ pretrained contextual embeddings of words from the\nPowerShell \"language\". A known problem in the cybersecurity domain is that\nlabeled data is relatively scarce in comparison with unlabeled data, making it\ndifficult to devise effective supervised detection of malicious activity of\nmany types. This is also the case with PowerShell code. Our work shows that\nthis problem can be mitigated by learning a pretrained contextual embedding\nbased on unlabeled data.\n  We trained and evaluated our models using real-world data, collected using\nAMSI from a large antimalware vendor. Our performance analysis establishes that\nthe use of unlabeled data for the embedding significantly improved the\nperformance of our detectors. Our best-performing model uses an architecture\nthat enables the processing of textual signals from both the character and\ntoken levels and obtains a true positive rate of nearly 90% while maintaining a\nlow false-positive rate of less than 0.1%.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 08:53:52 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 05:37:35 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Rubin", "Amir", ""], ["Kels", "Shay", ""], ["Hendler", "Danny", ""]]}, {"id": "1905.09543", "submitter": "Igor Korkin", "authors": "Igor Korkin", "title": "MemoryRanger Prevents Hijacking FILE_OBJECT Structures in Windows Kernel", "comments": "10 pages, 5 figures. Korkin, I. (2019, May 15-16). MemoryRanger\n  Prevents Hijacking FILE_OBJECT Structures in Windows Kernel. Paper presented\n  at the Proceedings of the 14th annual Conference on Digital Forensics,\n  Security and Law (CDFSL), Embry-Riddle Aeronautical University, Daytona\n  Beach, Florida, USA. Retrieved from\n  https://commons.erau.edu/adfsl/2019/paper-presentation/7/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Windows OS kernel memory is one of the main targets of cyber-attacks. By\nlaunching such attacks, hackers are succeeding in process privilege escalation\nand tampering with users data by accessing kernel mode memory. This paper\nconsiders a new example of such an attack, which results in access to the files\nopened in an exclusive mode. Windows built-in security features prevent such\nlegal access, but attackers can circumvent them by patching dynamically\nallocated objects. The research shows that the Windows 10, version 1809 x64 is\nvulnerable to this attack. The paper provides an example of using MemoryRanger,\na hypervisor-based solution to prevent such attack by running kernel-mode\ndrivers in isolated kernel memory enclaves.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 08:57:45 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Korkin", "Igor", ""]]}, {"id": "1905.09555", "submitter": "Vishal Sharma", "authors": "Vishal Sharma, Ilsun You, Nadra Guizani", "title": "Security of 5G-V2X: Technologies, Standardization and Research\n  Directions", "comments": "9 pages, 6 figures, Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cellular-Vehicle to Everything (C-V2X) aims at resolving issues pertaining to\nthe traditional usability of Vehicle to Infrastructure (V2I) and Vehicle to\nVehicle (V2V) networking. Specifically, C-V2X lowers the number of entities\ninvolved in vehicular communications and allows the inclusion of\ncellular-security solutions to be applied to V2X. For this, the evolvement of\nLTE-V2X is revolutionary, but it fails to handle the demands of high\nthroughput, ultra-high reliability, and ultra-low latency alongside its\nsecurity mechanisms. To counter this, 5G-V2X is considered as an integral\nsolution, which not only resolves the issues related to LTE-V2X but also\nprovides a function-based network setup. Several reports have been given for\nthe security of 5G, but none of them primarily focuses on the security of\n5G-V2X. This article provides a detailed overview of 5G-V2X with a\nsecurity-based comparison to LTE-V2X. A novel Security Reflex Function\n(SRF)-based architecture is proposed and several research challenges are\npresented related to the security of 5G-V2X. Furthermore, the article lays out\nrequirements of Ultra-Dense and Ultra-Secure (UD-US) transmissions necessary\nfor 5G-V2X.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 09:41:17 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 07:27:45 GMT"}, {"version": "v3", "created": "Wed, 18 Dec 2019 08:42:41 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Sharma", "Vishal", ""], ["You", "Ilsun", ""], ["Guizani", "Nadra", ""]]}, {"id": "1905.09581", "submitter": "Nasser Al-Fannah", "authors": "Nasser Mohammed Al-Fannah, Wanpeng Li and Chris J Mitchell", "title": "Beyond Cookie Monster Amnesia: Real World Persistent Online Tracking", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-99136-8", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Browser fingerprinting is a relatively new method of uniquely identifying\nbrowsers that can be used to track web users. In some ways it is more\nprivacy-threatening than tracking via cookies, as users have no direct control\nover it. A number of authors have considered the wide variety of techniques\nthat can be used to fingerprint browsers; however, relatively little\ninformation is available on how widespread browser fingerprinting is, and what\ninformation is collected to create these fingerprints in the real world. To\nhelp address this gap, we crawled the 10,000 most popular websites; this gave\ninsights into the number of websites that are using the technique, which\nwebsites are collecting fingerprinting information, and exactly what\ninformation is being retrieved. We found that approximately 69\\% of websites\nare, potentially, involved in first-party or third-party browser\nfingerprinting. We further found that third-party browser fingerprinting, which\nis potentially more privacy-damaging, appears to be predominant in practice. We\nalso describe \\textit{FingerprintAlert}, a freely available browser extension\nwe developed that detects and, optionally, blocks fingerprinting attempts by\nvisited websites.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 10:48:55 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Al-Fannah", "Nasser Mohammed", ""], ["Li", "Wanpeng", ""], ["Mitchell", "Chris J", ""]]}, {"id": "1905.09591", "submitter": "Huaxia Wang", "authors": "Huaxia Wang and Chun-Nam Yu", "title": "A Direct Approach to Robust Deep Learning Using Adversarial Networks", "comments": "15 pages", "journal-ref": "ICLR 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been shown to perform well in many classical\nmachine learning problems, especially in image classification tasks. However,\nresearchers have found that neural networks can be easily fooled, and they are\nsurprisingly sensitive to small perturbations imperceptible to humans.\nCarefully crafted input images (adversarial examples) can force a well-trained\nneural network to provide arbitrary outputs. Including adversarial examples\nduring training is a popular defense mechanism against adversarial attacks. In\nthis paper we propose a new defensive mechanism under the generative\nadversarial network (GAN) framework. We model the adversarial noise using a\ngenerative network, trained jointly with a classification discriminative\nnetwork as a minimax game. We show empirically that our adversarial network\napproach works well against black box attacks, with performance on par with\nstate-of-art methods such as ensemble adversarial training and adversarial\ntraining with projected gradient descent.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 11:32:28 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Wang", "Huaxia", ""], ["Yu", "Chun-Nam", ""]]}, {"id": "1905.09655", "submitter": "Pawel Szalachowski", "authors": "Pawel Szalachowski, Daniel Reijsbergen, Ivan Homoliak, Siwei Sun", "title": "StrongChain: Transparent and Collaborative Proof-of-Work Consensus", "comments": "USENIX Security '19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin is the most successful cryptocurrency so far. This is mainly due to\nits novel consensus algorithm, which is based on proof-of-work combined with a\ncryptographically-protected data structure and a rewarding scheme that\nincentivizes nodes to participate. However, despite its unprecedented success\nBitcoin suffers from many inefficiencies. For instance, Bitcoin's consensus\nmechanism has been proved to be incentive-incompatible, its high reward\nvariance causes centralization, and its hardcoded deflation raises questions\nabout its long-term sustainability.\n  In this work, we revise the Bitcoin consensus mechanism by proposing\nStrongChain, a scheme that introduces transparency and incentivizes\nparticipants to collaborate rather than to compete. The core design of our\nprotocol is to reflect and utilize the computing power aggregated on the\nblockchain which is invisible and \"wasted\" in Bitcoin today. Introducing\nrelatively easy, although important changes to Bitcoin's design enables us to\nimprove many crucial aspects of Bitcoin-like cryptocurrencies making it more\nsecure, efficient, and profitable for participants. We thoroughly analyze our\napproach and we present an implementation of StrongChain. The obtained results\nconfirm its efficiency, security, and deployability.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 13:50:31 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Szalachowski", "Pawel", ""], ["Reijsbergen", "Daniel", ""], ["Homoliak", "Ivan", ""], ["Sun", "Siwei", ""]]}, {"id": "1905.09778", "submitter": "Ferdinando Fioretto", "authors": "Ferdinando Fioretto, Terrence W.K. Mak, Pascal Van Hentenryck", "title": "Privacy-Preserving Obfuscation of Critical Infrastructure Networks", "comments": "A version of this paper appears in the Proceedings of the\n  Twenty-Eighth International Joint Conference on Artificial Intelligence\n  (IJCAI-19), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper studies how to release data about a critical infrastructure network\n(e.g., the power network or a transportation network) without disclosing\nsensitive information that can be exploited by malevolent agents, while\npreserving the realism of the network. It proposes a novel obfuscation\nmechanism that combines several privacy-preserving building blocks with a\nbi-level optimization model to significantly improve accuracy. The obfuscation\nis evaluated for both realism and privacy properties on real energy and\ntransportation networks. Experimental results show the obfuscation mechanism\nsubstantially reduces the potential damage of an attack exploiting the released\ndata to harm the real network.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 17:05:17 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 14:17:24 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Fioretto", "Ferdinando", ""], ["Mak", "Terrence W. K.", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "1905.09871", "submitter": "Haidar Khan", "authors": "Haidar Khan, Daniel Park, Azer Khan, B\\\"ulent Yener", "title": "Thwarting finite difference adversarial attacks with output\n  randomization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples pose a threat to deep neural network models in a variety\nof scenarios, from settings where the adversary has complete knowledge of the\nmodel and to the opposite \"black box\" setting. Black box attacks are\nparticularly threatening as the adversary only needs access to the input and\noutput of the model. Defending against black box adversarial example generation\nattacks is paramount as currently proposed defenses are not effective. Since\nthese types of attacks rely on repeated queries to the model to estimate\ngradients over input dimensions, we investigate the use of randomization to\nthwart such adversaries from successfully creating adversarial examples.\nRandomization applied to the output of the deep neural network model has the\npotential to confuse potential attackers, however this introduces a tradeoff\nbetween accuracy and robustness. We show that for certain types of\nrandomization, we can bound the probability of introducing errors by carefully\nsetting distributional parameters. For the particular case of finite difference\nblack box attacks, we quantify the error introduced by the defense in the\nfinite difference estimate of the gradient. Lastly, we show empirically that\nthe defense can thwart two adaptive black box adversarial attack algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 18:58:39 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Khan", "Haidar", ""], ["Park", "Daniel", ""], ["Khan", "Azer", ""], ["Yener", "B\u00fclent", ""]]}, {"id": "1905.09945", "submitter": "Victor Zakhary", "authors": "Victor Zakhary, Ishani Gupta, Rey Tang, Amr El Abbadi", "title": "Multifaceted Privacy: How to Express Your Online Persona without\n  Revealing Your Sensitive Attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works in social network stream analysis show that a user's online\npersona attributes (e.g., gender, ethnicity, political interest, location,\netc.) can be accurately inferred from the topics the user writes about or\nengages with. Attribute and preference inferences have been widely used to\nserve personalized recommendations, directed ads, and to enhance the user\nexperience in social networks. However, revealing a user's sensitive attributes\ncould represent a privacy threat to some individuals. Microtargeting\n(e.g.,Cambridge Analytica scandal), surveillance, and discriminating ads are\nexamples of threats to user privacy caused by sensitive attribute inference. In\nthis paper, we propose Multifaceted privacy, a novel privacy model that aims to\nobfuscate a user's sensitive attributes while publicly preserving the user's\npublic persona. To achieve multifaceted privacy, we build Aegis, a prototype\nclient-centric social network stream processing system that helps preserve\nmultifaceted privacy, and thus allowing social network users to freely express\ntheir online personas without revealing their sensitive attributes of choice.\nAegis allows social network users to control which persona attributes should be\npublicly revealed and which ones should be kept private. For this, Aegis\ncontinuously suggests topics and hashtags to social network users to post in\norder to obfuscate their sensitive attributes and hence confuse content-based\nsensitive attribute inferences. The suggested topics are carefully chosen to\npreserve the user's publicly revealed persona attributes while hiding their\nprivate sensitive persona attributes. Our experiments show that adding as few\nas 0 to 4 obfuscation posts (depending on how revealing the original post is)\nsuccessfully hides the user specified sensitive attributes without changing the\nuser's public persona attributes.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 21:50:55 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Zakhary", "Victor", ""], ["Gupta", "Ishani", ""], ["Tang", "Rey", ""], ["Abbadi", "Amr El", ""]]}, {"id": "1905.09957", "submitter": "Jiefeng Chen", "authors": "Jiefeng Chen, Xi Wu, Vaibhav Rastogi, Yingyu Liang, Somesh Jha", "title": "Robust Attribution Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An emerging problem in trustworthy machine learning is to train models that\nproduce robust interpretations for their predictions. We take a step towards\nsolving this problem through the lens of axiomatic attribution of neural\nnetworks. Our theory is grounded in the recent work, Integrated Gradients (IG),\nin axiomatically attributing a neural network's output change to its input\nchange. We propose training objectives in classic robust optimization models to\nachieve robust IG attributions. Our objectives give principled generalizations\nof previous objectives designed for robust predictions, and they naturally\ndegenerate to classic soft-margin training for one-layer neural networks. We\nalso generalize previous theory and prove that the objectives for different\nrobust optimization models are closely related. Experiments demonstrate the\neffectiveness of our method, and also point to intriguing problems which hint\nat the need for better optimization techniques or better neural network\narchitectures for robust attribution training.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 22:35:41 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 17:04:59 GMT"}, {"version": "v3", "created": "Sat, 26 Oct 2019 20:19:08 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Chen", "Jiefeng", ""], ["Wu", "Xi", ""], ["Rastogi", "Vaibhav", ""], ["Liang", "Yingyu", ""], ["Jha", "Somesh", ""]]}, {"id": "1905.09958", "submitter": "Ren\\'ee Burton", "authors": "Ren\\'ee Burton", "title": "Characterizing Certain DNS DDoS Attacks", "comments": "25 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper details data science research in the area of Cyber Threat\nIntelligence applied to a specific type of Distributed Denial of Service (DDoS)\nattack. We study a DDoS technique prevalent in the Domain Name System (DNS) for\nwhich little malware have been recovered. Using data from a globally\ndistributed set of a passive collectors (pDNS), we create a statistical\nclassifier to identify these attacks and then use unsupervised learning to\ninvestigate the attack events and the malware that generates them. The first\nknown major study of this technique, we discovered that current attacks have\nlittle resemblance to published descriptions and identify several previously\nunpublished features of the attacks. Through a combination of text and time\nseries features, we are able to characterize the dominant malware and\ndemonstrate that the number of global-scale attack systems is relatively small.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 22:38:11 GMT"}, {"version": "v2", "created": "Sat, 20 Jul 2019 16:21:23 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Burton", "Ren\u00e9e", ""]]}, {"id": "1905.10029", "submitter": "Ming Jin", "authors": "Ming Jin, Heng Chang, Wenwu Zhu, Somayeh Sojoudi", "title": "Power up! Robust Graph Convolutional Network against Evasion Attacks\n  based on Graph Powering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) are powerful tools for graph-structured\ndata. However, they have been recently shown to be prone to topological\nattacks. Despite substantial efforts to search for new architectures, it still\nremains a challenge to improve performance in both benign and adversarial\nsituations simultaneously. In this paper, we re-examine the fundamental\nbuilding block of GCN---the Laplacian operator---and highlight some basic flaws\nin the spatial and spectral domains. As an alternative, we propose an operator\nbased on graph powering, and prove that it enjoys a desirable property of\n\"spectral separation.\" Based on the operator, we propose a robust learning\nparadigm, where the network is trained on a family of \"'smoothed\" graphs that\nspan a spatial and spectral range for generalizability. We also use the new\noperator in replacement of the classical Laplacian to construct an architecture\nwith improved spectral robustness, expressivity and interpretability. The\nenhanced performance and robustness are demonstrated in extensive experiments.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 04:43:38 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Jin", "Ming", ""], ["Chang", "Heng", ""], ["Zhu", "Wenwu", ""], ["Sojoudi", "Somayeh", ""]]}, {"id": "1905.10074", "submitter": "Lars Schlieper", "authors": "Alexander May, Lars Schlieper", "title": "Quantum Period Finding is Compression Robust", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study quantum period finding algorithms such as Simon and Shor (and its\nvariants Eker{\\aa}-H{\\aa}stad and Mosca-Ekert). For a periodic function $f$\nthese algorithms produce -- via some quantum embedding of $f$ -- a quantum\nsuperposition $\\sum_x |x\\rangle|f(x)\\rangle$, which requires a certain amount\nof output qubits that represent $|f(x)\\rangle$. We show that one can lower this\namount to a single output qubit by hashing $f$ down to a single bit in an\noracle setting.\n  Namely, we replace the embedding of $f$ in quantum period finding circuits by\noracle access to several embeddings of hashed versions of $f$. We show that on\nexpectation this modification only doubles the required amount of quantum\nmeasurements, while significantly reducing the total number of qubits. For\nexample, for Simon's algorithm that finds periods in $f: \\mathbb{F}_2^n\n\\rightarrow \\mathbb{F}_2^n$ our hashing technique reduces the required output\nqubits from $n$ down to $1$, and therefore the total amount of qubits from $2n$\nto $n+1$. We also show that Simon's algorithm admits real world applications\nwith only $n+1$ qubits by giving a concrete realization of a hashed version of\nthe cryptographic Even-Mansour construction. Moreover, for a variant of Simon's\nalgorithm on Even-Mansour that requires only classical queries to Even-Mansour\nwe save a factor of (roughly) $4$ in the qubits.\n  Our oracle-based hashed version of the Eker{\\aa}-H{\\aa}stad algorithm for\nfactoring $n$-bit RSA reduces the required qubits from $(\\frac 3 2 + o(1))n$\ndown to $(\\frac 1 2 + o(1))n$. We also show a real-world (non-oracle)\napplication in the discrete logarithm setting by giving a concrete realization\nof a hashed version of Mosca-Ekert for the Decisional Diffie Hellman problem in\n$\\mathbb{F}_{p^m}$, thereby reducing the number of qubits by even a linear\nfactor from $m \\log p$ downto $\\log p$.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 07:35:04 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 19:35:58 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 12:47:52 GMT"}, {"version": "v4", "created": "Mon, 15 Feb 2021 15:21:11 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["May", "Alexander", ""], ["Schlieper", "Lars", ""]]}, {"id": "1905.10141", "submitter": "Enis Ulqinaku", "authors": "Enis Ulqinaku and Julinda Stefa and Alessandro Mei", "title": "Scan-and-Pay on Android is Dangerous", "comments": "Published in Infocom MobiSec Workshop 2019, Paris, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile payments have increased significantly in the recent years and\none-to-one money transfers are offered by a wide variety of smartphone\napplications. These applications usually support scan-and-pay -- a technique\nthat allows a payer to easily scan the destination address of the payment\ndirectly from the payee's smartphone screen. This technique is pervasive\nbecause it does not require any particular hardware, only the camera, which is\npresent on all modern smartphones. However, in this work we show that a\nmalicious application can exploit the overlay feature on Android to compromise\nthe integrity of transactions that make use of the scan-and-pay technique. We\nimplement Malview, a proof-of-concept malicious application that runs in the\nbackground on the payee's smartphone and show that it succeeds in redirecting\npayments to a malicious wallet. We analyze the weaknesses of the current\ndefense mechanisms and discuss possible countermeasures against the attack.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 10:49:49 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Ulqinaku", "Enis", ""], ["Stefa", "Julinda", ""], ["Mei", "Alessandro", ""]]}, {"id": "1905.10214", "submitter": "Th\\'eo Ryffel", "authors": "Theo Ryffel, Edouard Dufour-Sans, Romain Gay, Francis Bach, David\n  Pointcheval", "title": "Partially Encrypted Machine Learning using Functional Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning on encrypted data has received a lot of attention thanks to\nrecent breakthroughs in homomorphic encryption and secure multi-party\ncomputation. It allows outsourcing computation to untrusted servers without\nsacrificing privacy of sensitive data. We propose a practical framework to\nperform partially encrypted and privacy-preserving predictions which combines\nadversarial training and functional encryption. We first present a new\nfunctional encryption scheme to efficiently compute quadratic functions so that\nthe data owner controls what can be computed but is not involved in the\ncalculation: it provides a decryption key which allows one to learn a specific\nfunction evaluation of some encrypted data. We then show how to use it in\nmachine learning to partially encrypt neural networks with quadratic activation\nfunctions at evaluation time, and we provide a thorough analysis of the\ninformation leaks based on indistinguishability of data items of the same\nlabel. Last, since most encryption schemes cannot deal with the last\nthresholding operation used for classification, we propose a training method to\nprevent selected sensitive features from leaking, which adversarially optimizes\nthe network against an adversary trying to identify these features. This is\ninteresting for several existing works using partially encrypted machine\nlearning as it comes with little reduction on the model's accuracy and\nsignificantly improves data privacy.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 13:06:53 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 08:41:02 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 17:14:29 GMT"}, {"version": "v4", "created": "Tue, 22 Oct 2019 10:02:43 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Ryffel", "Theo", ""], ["Dufour-Sans", "Edouard", ""], ["Gay", "Romain", ""], ["Bach", "Francis", ""], ["Pointcheval", "David", ""]]}, {"id": "1905.10242", "submitter": "Thomas Nyman", "authors": "Hans Liljestrand and Thomas Nyman and Lachlan J. Gunn and Jan-Erik\n  Ekberg and N. Asokan", "title": "PACStack: an Authenticated Call Stack", "comments": "Author's version of article to appear in USENIX Security '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular run-time attack technique is to compromise the control-flow\nintegrity of a program by modifying function return addresses on the stack. So\nfar, shadow stacks have proven to be essential for comprehensively preventing\nreturn address manipulation. Shadow stacks record return addresses in\nintegrity-protected memory secured with hardware-assistance or software access\ncontrol. Software shadow stacks incur high overheads or trade off security for\nefficiency. Hardware-assisted shadow stacks are efficient and secure, but\nrequire the deployment of special-purpose hardware.\n  We present authenticated call stack (ACS), an approach that uses chained\nmessage authentication codes (MACs). Our prototype, PACStack, uses the ARM\ngeneral purpose hardware mechanism for pointer authentication (PA) to implement\nACS. Via a rigorous security analysis, we show that PACStack achieves security\ncomparable to hardware-assisted shadow stacks without requiring dedicated\nhardware. We demonstrate that PACStack's performance overhead is small (~3%).\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 14:12:43 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 12:35:07 GMT"}, {"version": "v3", "created": "Thu, 4 Jun 2020 10:12:53 GMT"}, {"version": "v4", "created": "Fri, 21 Aug 2020 15:46:00 GMT"}, {"version": "v5", "created": "Thu, 15 Oct 2020 09:47:49 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Liljestrand", "Hans", ""], ["Nyman", "Thomas", ""], ["Gunn", "Lachlan J.", ""], ["Ekberg", "Jan-Erik", ""], ["Asokan", "N.", ""]]}, {"id": "1905.10255", "submitter": "Lachlan Gunn", "authors": "Lachlan J. Gunn and Jian Liu and Bruno Vavala and N. Asokan", "title": "Making Speculative BFT Resilient with Trusted Monotonic Counters", "comments": "\\copyright\\ 2019 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consensus mechanisms used by popular distributed ledgers are highly scalable\nbut notoriously inefficient. Byzantine fault tolerance (BFT) protocols are\nefficient but far less scalable. Speculative BFT protocols such as Zyzzyva and\nZyzzyva5 are efficient and scalable but require a trade-off: Zyzzyva requires\nonly $3f + 1$ replicas to tolerate $f$ faults, but even a single slow replica\nwill make Zyzzyva fall back to more expensive non-speculative operation.\nZyzzyva5 does not require a non-speculative fallback, but requires $5f + 1$\nreplicas in order to tolerate $f$ faults. BFT variants using hardware-assisted\ntrusted components can tolerate a greater proportion of faults, but require\nthat every replica have this hardware.\n  We present SACZyzzyva, addressing these concerns: resilience to slow replicas\nand requiring only $3f + 1$ replicas, with only one replica needing an active\nmonotonic counter at any given time.\n  We experimentally evaluate our protocols, demonstrating low latency and high\nscalability. We prove that SACZyzzyva is optimally robust and that trusted\ncomponents cannot increase fault tolerance unless they are present in greater\nthan two-thirds of replicas.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 14:30:27 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 17:34:10 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Gunn", "Lachlan J.", ""], ["Liu", "Jian", ""], ["Vavala", "Bruno", ""], ["Asokan", "N.", ""]]}, {"id": "1905.10291", "submitter": "Liwei Song", "authors": "Liwei Song, Reza Shokri, Prateek Mittal", "title": "Privacy Risks of Securing Machine Learning Models against Adversarial\n  Examples", "comments": "ACM CCS 2019, code is available at\n  https://github.com/inspire-group/privacy-vs-robustness", "journal-ref": null, "doi": "10.1145/3319535.3354211", "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The arms race between attacks and defenses for machine learning models has\ncome to a forefront in recent years, in both the security community and the\nprivacy community. However, one big limitation of previous research is that the\nsecurity domain and the privacy domain have typically been considered\nseparately. It is thus unclear whether the defense methods in one domain will\nhave any unexpected impact on the other domain.\n  In this paper, we take a step towards resolving this limitation by combining\nthe two domains. In particular, we measure the success of membership inference\nattacks against six state-of-the-art defense methods that mitigate the risk of\nadversarial examples (i.e., evasion attacks). Membership inference attacks\ndetermine whether or not an individual data record has been part of a model's\ntraining set. The accuracy of such attacks reflects the information leakage of\ntraining algorithms about individual members of the training set. Adversarial\ndefense methods against adversarial examples influence the model's decision\nboundaries such that model predictions remain unchanged for a small area around\neach input. However, this objective is optimized on training data. Thus,\nindividual data records in the training set have a significant influence on\nrobust models. This makes the models more vulnerable to inference attacks.\n  To perform the membership inference attacks, we leverage the existing\ninference methods that exploit model predictions. We also propose two new\ninference methods that exploit structural properties of robust models on\nadversarially perturbed data. Our experimental evaluation demonstrates that\ncompared with the natural training (undefended) approach, adversarial defense\nmethods can indeed increase the target model's risk against membership\ninference attacks.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 15:37:22 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 04:34:47 GMT"}, {"version": "v3", "created": "Sun, 25 Aug 2019 19:05:32 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Song", "Liwei", ""], ["Shokri", "Reza", ""], ["Mittal", "Prateek", ""]]}, {"id": "1905.10292", "submitter": "Simon Duque Anton", "authors": "Simon D. Duque Anton and Alexander Hafner and Hans Dieter Schotten", "title": "Devil in the Detail: Attack Scenarios in Industrial Applications", "comments": "Submitted and accepted at the 2019 IEEE Workshop on the Internet of\n  Safe Things", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past years, industrial networks have become increasingly\ninterconnected and opened to private or public networks. This leads to an\nincrease in efficiency and manageability, but also increases the attack\nsurface. Industrial networks often consist of legacy systems that have not been\ndesigned with security in mind. In the last decade, an increase in attacks on\ncyber-physical systems was observed, with drastic consequences on the physical\nwork. In this work, attack vectors on industrial networks are categorised. A\nreal-world process is simulated, attacks are then introduced. Finally, two\nmachine learning-based methods for time series anomaly detection are employed\nto detect the attacks. Matrix Profiles are employed more successfully than a\npredictor Long Short-Term Memory network, a class of neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 15:39:29 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Anton", "Simon D. Duque", ""], ["Hafner", "Alexander", ""], ["Schotten", "Hans Dieter", ""]]}, {"id": "1905.10311", "submitter": "Oleksii Oleksenko", "authors": "Oleksii Oleksenko, Bohdan Trach, Mark Silberstein, Christof Fetzer", "title": "SpecFuzz: Bringing Spectre-type vulnerabilities to the surface", "comments": "To appear in USENIX Security Symposium (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SpecFuzz is the first tool that enables dynamic testing for speculative\nexecution vulnerabilities (e.g., Spectre). The key is a novel concept of\nspeculation exposure: The program is instrumented to simulate speculative\nexecution in software by forcefully executing the code paths that could be\ntriggered due to mispredictions, thereby making the speculative memory accesses\nvisible to integrity checkers (e.g., AddressSanitizer). Combined with the\nconventional fuzzing techniques, speculation exposure enables more precise\nidentification of potential vulnerabilities compared to state-of-the-art static\nanalyzers.\n  Our prototype for detecting Spectre V1 vulnerabilities successfully\nidentifies all known variations of Spectre V1 and decreases the mitigation\noverheads across the evaluated applications, reducing the amount of\ninstrumented branches by up to 77% given a sufficient test coverage.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 16:12:31 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 13:11:27 GMT"}, {"version": "v3", "created": "Fri, 13 Dec 2019 15:01:43 GMT"}, {"version": "v4", "created": "Tue, 10 Mar 2020 10:10:38 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Oleksenko", "Oleksii", ""], ["Trach", "Bohdan", ""], ["Silberstein", "Mark", ""], ["Fetzer", "Christof", ""]]}, {"id": "1905.10314", "submitter": "Ahmed Raoof", "authors": "Ahmed Raoof, Ashraf Matrawy, Chung-Horng Lung", "title": "Secure Routing in IoT: Evaluation of RPL Secure Mode under Attacks", "comments": "6 pages, 9 figures, 2 tables. Accepted at Globecom 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the Routing Protocol for Low Power and Lossy Networks (RPL) became the\nstandard for routing in the Internet of Things (IoT) networks, many researchers\nhad investigated the security aspects of this protocol. However, no work (to\nthe best of our knowledge) has investigated the use of the security mechanisms\nincluded in the protocol standard, due to the fact that there was no\nimplementation for these features in any IoT operating system yet. A partial\nimplementation of RPL security mechanisms was presented recently for Contiki\noperating system (by Perazzo et al.), which provided us with the opportunity to\nexamine RPL security mechanisms. In this paper, we investigate the effects and\nchallenges of using RPL security mechanisms under common routing attacks.\nFirst, a comparison of RPL performance, with and without its security\nmechanisms, under three routing attacks (Blackhole, Selective- Forward, and\nNeighbor attacks) is conducted using several metrics (e.g., average data packet\ndelivery rate, average data packet delay, average power consumption... etc.)\nBased on the observations from this comparison, we came with few suggestions\nthat could reduce the effects of such attacks, without having added security\nmechanisms for RPL.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 16:15:02 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 14:54:19 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Raoof", "Ahmed", ""], ["Matrawy", "Ashraf", ""], ["Lung", "Chung-Horng", ""]]}, {"id": "1905.10328", "submitter": "Gianluca Stringhini", "authors": "Yun Shen, Enrico Mariconti, Pierre-Antoine Vervier, Gianluca\n  Stringhini", "title": "Tiresias: Predicting Security Events Through Deep Learning", "comments": null, "journal-ref": "ACM SIGSAC Conference on Computer and Communications Security\n  (CCS), 2018", "doi": "10.1145/3243734.3243811", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increased complexity of modern computer attacks, there is a need for\ndefenders not only to detect malicious activity as it happens, but also to\npredict the specific steps that will be taken by an adversary when performing\nan attack. However this is still an open research problem, and previous\nresearch in predicting malicious events only looked at binary outcomes (e.g.,\nwhether an attack would happen or not), but not at the specific steps that an\nattacker would undertake. To fill this gap we present Tiresias, a system that\nleverages Recurrent Neural Networks (RNNs) to predict future events on a\nmachine, based on previous observations. We test Tiresias on a dataset of 3.4\nbillion security events collected from a commercial intrusion prevention\nsystem, and show that our approach is effective in predicting the next event\nthat will occur on a machine with a precision of up to 0.93. We also show that\nthe models learned by Tiresias are reasonably stable over time, and provide a\nmechanism that can identify sudden drops in precision and trigger a retraining\nof the system. Finally, we show that the long-term memory typical of RNNs is\nkey in performing event prediction, rendering simpler methods not up to the\ntask.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 16:41:07 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Shen", "Yun", ""], ["Mariconti", "Enrico", ""], ["Vervier", "Pierre-Antoine", ""], ["Stringhini", "Gianluca", ""]]}, {"id": "1905.10447", "submitter": "Yuanshun Yao", "authors": "Yuanshun Yao and Huiying Li and Haitao Zheng and Ben Y. Zhao", "title": "Regula Sub-rosa: Latent Backdoor Attacks on Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has proposed the concept of backdoor attacks on deep neural\nnetworks (DNNs), where misbehaviors are hidden inside \"normal\" models, only to\nbe triggered by very specific inputs. In practice, however, these attacks are\ndifficult to perform and highly constrained by sharing of models through\ntransfer learning. Adversaries have a small window during which they must\ncompromise the student model before it is deployed. In this paper, we describe\na significantly more powerful variant of the backdoor attack, latent backdoors,\nwhere hidden rules can be embedded in a single \"Teacher\" model, and\nautomatically inherited by all \"Student\" models through the transfer learning\nprocess. We show that latent backdoors can be quite effective in a variety of\napplication contexts, and validate its practicality through real-world attacks\nagainst traffic sign recognition, iris identification of lab volunteers, and\nfacial recognition of public figures (politicians). Finally, we evaluate 4\npotential defenses, and find that only one is effective in disrupting latent\nbackdoors, but might incur a cost in classification accuracy as tradeoff.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 21:15:16 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Yao", "Yuanshun", ""], ["Li", "Huiying", ""], ["Zheng", "Haitao", ""], ["Zhao", "Ben Y.", ""]]}, {"id": "1905.10499", "submitter": "Yaohui Chen", "authors": "Yaohui Chen, Dongliang Mu, Jun Xu, Zhichuang Sun, Wenbo Shen, Xinyu\n  Xing, Long Lu, Bing Mao", "title": "PTrix: Efficient Hardware-Assisted Fuzzing for COTS Binary", "comments": "AsiaCCS'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its effectiveness in uncovering software defects, American Fuzzy Lop\n(AFL), one of the best grey-box fuzzers, is inefficient when fuzz-testing\nsource-unavailable programs. AFL's binary-only fuzzing mode, QEMU-AFL, is\ntypically 2-5X slower than its source-available fuzzing mode. The slowdown is\nlargely caused by the heavy dynamic instrumentation. Recent fuzzing techniques\nuse Intel Processor Tracing (PT), a light-weight tracing feature supported by\nrecent Intel CPUs, to remove the need of dynamic instrumentation. However, we\nfound that these PT-based fuzzing techniques are even slower than QEMU-AFL when\nfuzzing real-world programs, making them less effective than QEMU-AFL. This\npoor performance is caused by the slow extraction of code coverage information\nfrom highly compressed PT traces.\n  In this work, we present the design and implementation of PTrix, which fully\nunleashes the benefits of PT for fuzzing via three novel techniques. First,\nPTrix introduces a scheme to highly parallel the processing of PT trace and\ntarget program execution. Second, it directly takes decoded PT trace as\nfeedback for fuzzing, avoiding the expensive reconstruction of code coverage\ninformation. Third, PTrix maintains the new feedback with stronger feedback\nthan edge-based code coverage, which helps reach new code space and defects\nthat AFL may not. We evaluated PTrix by comparing its performance with the\nstate-of-the-art fuzzers. Our results show that, given the same amount of time,\nPTrix achieves a significantly higher fuzzing speed and reaches into code\nregions missed by the other fuzzers. In addition, PTrix identifies 35 new\nvulnerabilities in a set of previously well-fuzzed binaries, showing its\nability to complement existing fuzzers.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 02:03:25 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Chen", "Yaohui", ""], ["Mu", "Dongliang", ""], ["Xu", "Jun", ""], ["Sun", "Zhichuang", ""], ["Shen", "Wenbo", ""], ["Xing", "Xinyu", ""], ["Lu", "Long", ""], ["Mao", "Bing", ""]]}, {"id": "1905.10510", "submitter": "Chang Xiao", "authors": "Chang Xiao, Peilin Zhong and Changxi Zheng", "title": "Enhancing Adversarial Defense by k-Winners-Take-All", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple change to existing neural network structures for better\ndefending against gradient-based adversarial attacks. Instead of using popular\nactivation functions (such as ReLU), we advocate the use of k-Winners-Take-All\n(k-WTA) activation, a C0 discontinuous function that purposely invalidates the\nneural network model's gradient at densely distributed input data points. The\nproposed k-WTA activation can be readily used in nearly all existing networks\nand training methods with no significant overhead. Our proposal is\ntheoretically rationalized. We analyze why the discontinuities in k-WTA\nnetworks can largely prevent gradient-based search of adversarial examples and\nwhy they at the same time remain innocuous to the network training. This\nunderstanding is also empirically backed. We test k-WTA activation on various\nnetwork structures optimized by a training method, be it adversarial training\nor not. In all cases, the robustness of k-WTA networks outperforms that of\ntraditional networks under white-box attacks.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 03:36:40 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 20:14:15 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 00:27:18 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Xiao", "Chang", ""], ["Zhong", "Peilin", ""], ["Zheng", "Changxi", ""]]}, {"id": "1905.10517", "submitter": "Asaf Shabtai", "authors": "Yoni Birman, Shaked Hindi, Gilad Katz, Asaf Shabtai", "title": "Transferable Cost-Aware Security Policy Implementation for Malware\n  Detection Using Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware detection is an ever-present challenge for all organizational\ngatekeepers, who must maintain high detection rates while minimizing\ninterruptions to the organization's workflow. To improve detection rates,\norganizations often deploy an ensemble of detectors. While effective, this\napproach is computationally expensive, since every file - even clear-cut cases\n- needs to be analyzed by all detectors. Moreover, with an ever-increasing\nnumber of files to process, the use of ensembles may incur unacceptable\nprocessing times and costs (e.g., cloud resources). In this study, we propose\nSPIREL, a reinforcement learning-based method for cost-effective malware\ndetection. Our method enables organizations to directly associate costs to\ncorrect/incorrect classification, computing resources and run-time, and then\ndynamically establishes a security policy. This security policy is then\nimplemented, and for each inspected file, a different set of detectors is\nassigned and a different detection threshold is set. Our evaluation on two\nmalware domains- Portable Executable (PE) and Android Application Package\n(APK)files - shows that SPIREL is both accurate and extremely\nresource-efficient: the proposed method either outperforms the best performing\nbaselines while achieving a modest improvement in efficiency, or reduces the\nrequired running time by ~80% while decreasing the accuracy and F1-score by\nonly 0.5%. We also show that our approach is both highly transferable across\ndifferent datasets and adaptable to changes in individual detector performance.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 04:18:00 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 12:37:06 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Birman", "Yoni", ""], ["Hindi", "Shaked", ""], ["Katz", "Gilad", ""], ["Shabtai", "Asaf", ""]]}, {"id": "1905.10518", "submitter": "Gleb Naumenko", "authors": "Gleb Naumenko, Gregory Maxwell, Pieter Wuille, Alexandra Fedorova,\n  Ivan Beschastnikh", "title": "Bandwidth-Efficient Transaction Relay for Bitcoin", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Bitcoin is a top-ranked cryptocurrency that has experienced huge growth and\nsurvived numerous attacks. The protocols making up Bitcoin must therefore\naccommodate the growth of the network and ensure security. Security of the\nBitcoin network depends on connectivity between the nodes. Higher connectivity\nyields better security. In this paper we make two observations: (1) current\nconnectivity in the Bitcoin network is too low for optimal security; (2) at the\nsame time, increasing connectivity will substantially increase the bandwidth\nused by the transaction dissemination protocol, making it prohibitively\nexpensive to operate a Bitcoin node. Half of the total bandwidth needed to\noperate a Bitcoin node is currently used to just announce transactions. Unlike\nblock relay, transaction dissemination has received little attention in prior\nwork. We propose a new transaction dissemination protocol, Erlay, that not only\nreduces the bandwidth consumption by 40% assuming current connectivity, but\nalso keeps the bandwidth use almost constant as the connectivity increases. In\ncontrast, the existing protocol increases the bandwidth consumption linearly\nwith the number of connections. By allowing more connections at a small cost,\nErlay improves the security of the Bitcoin network. And, as we demonstrate,\nErlay also hardens the network against attacks that attempt to learn the origin\nnode of a transaction. Erlay is currently being investigated by the Bitcoin\ncommunity for future use with the Bitcoin protocol.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 04:25:03 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 21:31:20 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Naumenko", "Gleb", ""], ["Maxwell", "Gregory", ""], ["Wuille", "Pieter", ""], ["Fedorova", "Alexandra", ""], ["Beschastnikh", "Ivan", ""]]}, {"id": "1905.10615", "submitter": "Adam Gleave", "authors": "Adam Gleave, Michael Dennis, Cody Wild, Neel Kant, Sergey Levine,\n  Stuart Russell", "title": "Adversarial Policies: Attacking Deep Reinforcement Learning", "comments": "Presented at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) policies are known to be vulnerable to\nadversarial perturbations to their observations, similar to adversarial\nexamples for classifiers. However, an attacker is not usually able to directly\nmodify another agent's observations. This might lead one to wonder: is it\npossible to attack an RL agent simply by choosing an adversarial policy acting\nin a multi-agent environment so as to create natural observations that are\nadversarial? We demonstrate the existence of adversarial policies in zero-sum\ngames between simulated humanoid robots with proprioceptive observations,\nagainst state-of-the-art victims trained via self-play to be robust to\nopponents. The adversarial policies reliably win against the victims but\ngenerate seemingly random and uncoordinated behavior. We find that these\npolicies are more successful in high-dimensional environments, and induce\nsubstantially different activations in the victim policy network than when the\nvictim plays against a normal opponent. Videos are available at\nhttps://adversarialpolicies.github.io/.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 15:23:19 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 19:54:47 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 19:25:56 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Gleave", "Adam", ""], ["Dennis", "Michael", ""], ["Wild", "Cody", ""], ["Kant", "Neel", ""], ["Levine", "Sergey", ""], ["Russell", "Stuart", ""]]}, {"id": "1905.10626", "submitter": "Tianyu Pang", "authors": "Tianyu Pang, Kun Xu, Yinpeng Dong, Chao Du, Ning Chen, Jun Zhu", "title": "Rethinking Softmax Cross-Entropy Loss for Adversarial Robustness", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work shows that adversarially robust generalization requires larger\nsample complexity, and the same dataset, e.g., CIFAR-10, which enables good\nstandard accuracy may not suffice to train robust models. Since collecting new\ntraining data could be costly, we focus on better utilizing the given data by\ninducing the regions with high sample density in the feature space, which could\nlead to locally sufficient samples for robust learning. We first formally show\nthat the softmax cross-entropy (SCE) loss and its variants convey inappropriate\nsupervisory signals, which encourage the learned feature points to spread over\nthe space sparsely in training. This inspires us to propose the Max-Mahalanobis\ncenter (MMC) loss to explicitly induce dense feature regions in order to\nbenefit robustness. Namely, the MMC loss encourages the model to concentrate on\nlearning ordered and compact representations, which gather around the preset\noptimal centers for different classes. We empirically demonstrate that applying\nthe MMC loss can significantly improve robustness even under strong adaptive\nattacks, while keeping state-of-the-art accuracy on clean inputs with little\nextra computation compared to the SCE loss.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 16:11:14 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 14:35:29 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 08:50:47 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Pang", "Tianyu", ""], ["Xu", "Kun", ""], ["Dong", "Yinpeng", ""], ["Du", "Chao", ""], ["Chen", "Ning", ""], ["Zhu", "Jun", ""]]}, {"id": "1905.10676", "submitter": "Michael Felderer", "authors": "J\\\"urgen Gro{\\ss}mann, Michael Felderer, Johannes Viehmann, Ina\n  Schieferdecker", "title": "A Taxonomy to Assess and Tailor Risk-based Testing in Recent Testing\n  Standards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article provides a taxonomy for risk-based testing that serves as a tool\nto define, tailor, or assess risk-based testing approaches in general and to\ninstantiate risk-based testing approaches for the current testing standards\nISO/IEC/IEEE 29119, ETSI EG and OWASP Security Testing Guide in particular. We\ndemonstrate the usefulness of the taxonomy by applying it to the aforementioned\nstandards as well as to the risk-based testing approaches SmartTesting,\nRACOMAT, PRISMA and risk-based test case prioritization using fuzzy expert\nsystems. In this setting, the taxonomy is used to systematically identify\ndeviations between the standards' requirements and the individual testing\napproaches so that we are able to position and compare the testing approaches\nand discuss their potential for practical application.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 21:21:25 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Gro\u00dfmann", "J\u00fcrgen", ""], ["Felderer", "Michael", ""], ["Viehmann", "Johannes", ""], ["Schieferdecker", "Ina", ""]]}, {"id": "1905.10695", "submitter": "Tianfu Wu", "authors": "Zekun Zhang and Tianfu Wu", "title": "Adversarial Distillation for Ordered Top-k Attacks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are vulnerable to adversarial attacks, especially\nwhite-box targeted attacks. One scheme of learning attacks is to design a\nproper adversarial objective function that leads to the imperceptible\nperturbation for any test image (e.g., the Carlini-Wagner (C&W) method). Most\nmethods address targeted attacks in the Top-1 manner. In this paper, we propose\nto learn ordered Top-k attacks (k>= 1) for image classification tasks, that is\nto enforce the Top-k predicted labels of an adversarial example to be the k\n(randomly) selected and ordered labels (the ground-truth label is exclusive).\nTo this end, we present an adversarial distillation framework: First, we\ncompute an adversarial probability distribution for any given ordered Top-k\ntargeted labels with respect to the ground-truth of a test image. Then, we\nlearn adversarial examples by minimizing the Kullback-Leibler (KL) divergence\ntogether with the perturbation energy penalty, similar in spirit to the network\ndistillation method. We explore how to leverage label semantic similarities in\ncomputing the targeted distributions, leading to knowledge-oriented attacks. In\nexperiments, we thoroughly test Top-1 and Top-5 attacks in the ImageNet-1000\nvalidation dataset using two popular DNNs trained with clean ImageNet-1000\ntrain dataset, ResNet-50 and DenseNet-121. For both models, our proposed\nadversarial distillation approach outperforms the C&W method in the Top-1\nsetting, as well as other baseline methods. Our approach shows significant\nimprovement in the Top-5 setting against a strong modified C&W method.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 23:24:15 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Zhang", "Zekun", ""], ["Wu", "Tianfu", ""]]}, {"id": "1905.10723", "submitter": "Lianying Zhao", "authors": "Lianying Zhao and Mohammad Mannan", "title": "TEE-aided Write Protection Against Privileged Data Tampering", "comments": "15 pages, Network and Distributed System Security Symposium (NDSS\n  2019), Feb. 24-27, 2019, San Diego, CA", "journal-ref": null, "doi": "10.14722/ndss.2019.23197", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unauthorized data alteration has been a longstanding threat since the\nemergence of malware. System and application software can be reinstalled and\nhardware can be replaced, but user data is priceless in many cases. Especially\nin recent years, ransomware has become high-impact due to its direct\nmonetization model. State-of-the-art defenses are mostly based on known\nsignature or behavior analysis, and more importantly, require an uncompromised\nOS kernel. However, malware with the highest software privileges has shown its\nobvious existence. We propose to move from current detection/recovery based\nmechanisms to data loss prevention, where the focus is on armoring data instead\nof counteracting malware. Our solution, Inuksuk, relies on today's Trusted\nExecution Environments (TEEs), as available both on the CPU and storage device,\nto achieve programmable write protection. We back up a copy of user-selected\nfiles as write-protected at all times, and subsequent updates are written as\nnew versions securely through TEE. We implement Inuksuk on Windows 7 and 10,\nand Linux (Ubuntu); our core design is OS and application agnostic, and incurs\nno run-time performance penalty for applications. File transfer disruption can\nbe eliminated or alleviated through access modes and customizable update\npolicies (e.g., interval, granularity). For Inuksuk's adoptability in modern\nOSes, we have also ported Flicker (EuroSys 2008), a defacto standard tool for\nin-OS privileged TEE management, to the latest 64-bit Windows.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 04:34:07 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Zhao", "Lianying", ""], ["Mannan", "Mohammad", ""]]}, {"id": "1905.10729", "submitter": "Hebi Li", "authors": "Hebi Li and Qi Xiao and Shixin Tian and Jin Tian", "title": "Purifying Adversarial Perturbation with Adversarially Trained\n  Auto-encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are vulnerable to adversarial examples. Iterative\nadversarial training has shown promising results against strong white-box\nattacks. However, adversarial training is very expensive, and every time a\nmodel needs to be protected, such expensive training scheme needs to be\nperformed. In this paper, we propose to apply iterative adversarial training\nscheme to an external auto-encoder, which once trained can be used to protect\nother models directly. We empirically show that our model outperforms other\npurifying-based methods against white-box attacks, and transfers well to\ndirectly protect other base models with different architectures.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 04:57:55 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Li", "Hebi", ""], ["Xiao", "Qi", ""], ["Tian", "Shixin", ""], ["Tian", "Jin", ""]]}, {"id": "1905.10864", "submitter": "Avishek Bose", "authors": "Avishek Joey Bose, Andre Cianflone, William L. Hamilton", "title": "Generalizable Adversarial Attacks with Latent Variable Perturbation\n  Modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Adversarial attacks on deep neural networks traditionally rely on a\nconstrained optimization paradigm, where an optimization procedure is used to\nobtain a single adversarial perturbation for a given input example. In this\nwork we frame the problem as learning a distribution of adversarial\nperturbations, enabling us to generate diverse adversarial distributions given\nan unperturbed input. We show that this framework is domain-agnostic in that\nthe same framework can be employed to attack different input domains with\nminimal modification. Across three diverse domains---images, text, and\ngraphs---our approach generates whitebox attacks with success rates that are\ncompetitive with or superior to existing approaches, with a new\nstate-of-the-art achieved in the graph domain. Finally, we demonstrate that our\nframework can efficiently generate a diverse set of attacks for a single given\ninput, and is even capable of attacking \\textit{unseen} test instances in a\nzero-shot manner, exhibiting attack generalization.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 19:38:15 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 23:30:40 GMT"}, {"version": "v3", "created": "Mon, 20 Jan 2020 23:22:52 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Bose", "Avishek Joey", ""], ["Cianflone", "Andre", ""], ["Hamilton", "William L.", ""]]}, {"id": "1905.10906", "submitter": "Rita Singh", "authors": "Daanish Ali Khan, Linhong Li, Ninghao Sha, Zhuoran Liu, Abelino\n  Jimenez, Bhiksha Raj and Rita Singh", "title": "Non-Determinism in Neural Networks for Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent breakthroughs in the field of deep learning have led to advancements\nin a broad spectrum of tasks in computer vision, audio processing, natural\nlanguage processing and other areas. In most instances where these tasks are\ndeployed in real-world scenarios, the models used in them have been shown to be\nsusceptible to adversarial attacks, making it imperative for us to address the\nchallenge of their adversarial robustness. Existing techniques for adversarial\nrobustness fall into three broad categories: defensive distillation techniques,\nadversarial training techniques, and randomized or non-deterministic model\nbased techniques. In this paper, we propose a novel neural network paradigm\nthat falls under the category of randomized models for adversarial robustness,\nbut differs from all existing techniques under this category in that it models\neach parameter of the network as a statistical distribution with learnable\nparameters. We show experimentally that this framework is highly robust to a\nvariety of white-box and black-box adversarial attacks, while preserving the\ntask-specific performance of the traditional neural network model.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 23:55:35 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Khan", "Daanish Ali", ""], ["Li", "Linhong", ""], ["Sha", "Ninghao", ""], ["Liu", "Zhuoran", ""], ["Jimenez", "Abelino", ""], ["Raj", "Bhiksha", ""], ["Singh", "Rita", ""]]}, {"id": "1905.10910", "submitter": "Chuka Oham", "authors": "Chuka Oham, Raja Jurdak and Sanjay Jha", "title": "Risk Analysis Study of Fully Autonomous Vehicle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully autonomous vehicles are emerging vehicular technologies that have\ngained significant attention in todays research endeavours. Even though it\npromises to optimize road safety, the proliferation of wireless and sensor\ntechnologies makes it susceptible to cyber threats thus dawdling its adoption.\nThe identification of threats and design of apposite security solutions is\ntherefore pertinent to expedite its adoption. In this paper, we analyse the\nsecurity risks of the communication infrastructure for the fully autonomous\nvehicle using a subset of the TVRA methodology by ETSI. We described the model\nof communication infrastructure. This model clarifies the potential\ncommunication possibilities of the vehicle. Then we defined the security\nobjectives and identified threats. Furthermore, we classified risks and propose\ncountermeasures to facilitate the design of security solutions. We find that\nall identified high impact threats emanates from a particular source and\nrequired encryption mechanisms as countermeasures. Finally, we discovered that\nall threats due to an interaction with humans are of serious consequences.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 00:20:14 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Oham", "Chuka", ""], ["Jurdak", "Raja", ""], ["Jha", "Sanjay", ""]]}, {"id": "1905.10921", "submitter": "Rafael Dowsley", "authors": "Claude Cr\\'epeau and Rafael Dowsley and Anderson C. A. Nascimento", "title": "On the Commitment Capacity of Unfair Noisy Channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noisy channels are a valuable resource from a cryptographic point of view.\nThey can be used for exchanging secret-keys as well as realizing other\ncryptographic primitives such as commitment and oblivious transfer. To be\nreally useful, noisy channels have to be consider in the scenario where a\ncheating party has some degree of control over the channel characteristics.\nDamg\\r{a}rd et al. (EUROCRYPT 1999) proposed a more realistic model where such\nlevel of control is permitted to an adversary, the so called unfair noisy\nchannels, and proved that they can be used to obtain commitment and oblivious\ntransfer protocols. Given that noisy channels are a precious resource for\ncryptographic purposes, one important question is determining the optimal rate\nin which they can be used. The commitment capacity has already been determined\nfor the cases of discrete memoryless channels and Gaussian channels. In this\nwork we address the problem of determining the commitment capacity of unfair\nnoisy channels. We compute a single-letter characterization of the commitment\ncapacity of unfair noisy channels. In the case where an adversary has no\ncontrol over the channel (the fair case) our capacity reduces to the well-known\ncapacity of a discrete memoryless binary symmetric channel.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 01:26:23 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Cr\u00e9peau", "Claude", ""], ["Dowsley", "Rafael", ""], ["Nascimento", "Anderson C. A.", ""]]}, {"id": "1905.11026", "submitter": "Yunhan Jia", "authors": "Yunhan Jia, Yantao Lu, Junjie Shen, Qi Alfred Chen, Zhenyu Zhong, Tao\n  Wei", "title": "Fooling Detection Alone is Not Enough: First Adversarial Attack against\n  Multiple Object Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent work in adversarial machine learning started to focus on the visual\nperception in autonomous driving and studied Adversarial Examples (AEs) for\nobject detection models. However, in such visual perception pipeline the\ndetected objects must also be tracked, in a process called Multiple Object\nTracking (MOT), to build the moving trajectories of surrounding obstacles.\nSince MOT is designed to be robust against errors in object detection, it poses\na general challenge to existing attack techniques that blindly target objection\ndetection: we find that a success rate of over 98% is needed for them to\nactually affect the tracking results, a requirement that no existing attack\ntechnique can satisfy. In this paper, we are the first to study adversarial\nmachine learning attacks against the complete visual perception pipeline in\nautonomous driving, and discover a novel attack technique, tracker hijacking,\nthat can effectively fool MOT using AEs on object detection. Using our\ntechnique, successful AEs on as few as one single frame can move an existing\nobject in to or out of the headway of an autonomous vehicle to cause potential\nsafety hazards. We perform evaluation using the Berkeley Deep Drive dataset and\nfind that on average when 3 frames are attacked, our attack can have a nearly\n100% success rate while attacks that blindly target object detection only have\nup to 25%.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 07:55:05 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 06:29:59 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Jia", "Yunhan", ""], ["Lu", "Yantao", ""], ["Shen", "Junjie", ""], ["Chen", "Qi Alfred", ""], ["Zhong", "Zhenyu", ""], ["Wei", "Tao", ""]]}, {"id": "1905.11067", "submitter": "Kazuto Fukuchi", "authors": "Kazuto Fukuchi, Chia-Mu Yu, Arashi Haishima, Jun Sakuma", "title": "Locally Differentially Private Minimum Finding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CR cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a problem of finding the minimum, in which each user has a\nreal value and we want to estimate the minimum of these values under the local\ndifferential privacy constraint. We reveal that this problem is fundamentally\ndifficult, and we cannot construct a mechanism that is consistent in the worst\ncase. Instead of considering the worst case, we aim to construct a private\nmechanism whose error rate is adaptive to the easiness of estimation of the\nminimum. As a measure of easiness, we introduce a parameter $\\alpha$ that\ncharacterizes the fatness of the minimum-side tail of the user data\ndistribution. As a result, we reveal that the mechanism can achieve\n$O((\\ln^6N/\\epsilon^2N)^{1/2\\alpha})$ error without knowledge of $\\alpha$ and\nthe error rate is near-optimal in the sense that any mechanism incurs\n$\\Omega((1/\\epsilon^2N)^{1/2\\alpha})$ error. Furthermore, we demonstrate that\nour mechanism outperforms a naive mechanism by empirical evaluations on\nsynthetic datasets. Also, we conducted experiments on the MovieLens dataset and\na purchase history dataset and demonstrate that our algorithm achieves\n$\\tilde{O}((1/N)^{1/2\\alpha})$ error adaptively to $\\alpha$.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 09:17:04 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Fukuchi", "Kazuto", ""], ["Yu", "Chia-Mu", ""], ["Haishima", "Arashi", ""], ["Sakuma", "Jun", ""]]}, {"id": "1905.11180", "submitter": "Igor Ivkic", "authors": "Igor Ivkic, Harald Pichler, Mario Zsilak, Andreas Mauthe and Markus\n  Tauber", "title": "A Framework for Measuring the Costs of Security at Runtime", "comments": "https://www.scitepress.org/PublicationsDetail.aspx?ID=X/mD2ocAMT0=&t=1", "journal-ref": null, "doi": "10.5220/0007761604880494", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Industry 4.0, Cyber-Physical Systems (CPS) are formed by components, which\nare interconnected with each other over the Internet of Things (IoT). The\nresulting capabilities of sensing and affecting the physical world offer a vast\nrange of opportunities, yet, at the same time pose new security challenges. To\naddress these challenges there are various IoT Frameworks, which offer\nsolutions for managing and controlling IoT-components and their interactions.\nIn this regard, providing security for an interaction usually requires\nperforming additional security-related tasks (e.g. authorisation, encryption,\netc.) to prevent possible security risks. Research currently focuses more on\ndesigning and developing these frameworks and does not satisfactorily provide\nmethodologies for evaluating the resulting costs of providing security. In this\npaper we propose an initial approach for measuring the resulting costs of\nproviding security for interacting IoT-components by using a Security Cost\nModelling Framework. Furthermore, we describe the necessary building blocks of\nthe framework and provide an experimental design showing how it could be used\nto measure security costs at runtime.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 12:59:02 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Ivkic", "Igor", ""], ["Pichler", "Harald", ""], ["Zsilak", "Mario", ""], ["Mauthe", "Andreas", ""], ["Tauber", "Markus", ""]]}, {"id": "1905.11213", "submitter": "Francesco Croce", "authors": "Francesco Croce, Matthias Hein", "title": "Provable robustness against all adversarial $l_p$-perturbations for\n  $p\\geq 1$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years several adversarial attacks and defenses have been proposed.\nOften seemingly robust models turn out to be non-robust when more sophisticated\nattacks are used. One way out of this dilemma are provable robustness\nguarantees. While provably robust models for specific $l_p$-perturbation models\nhave been developed, we show that they do not come with any guarantee against\nother $l_q$-perturbations. We propose a new regularization scheme,\nMMR-Universal, for ReLU networks which enforces robustness wrt $l_1$- and\n$l_\\infty$-perturbations and show how that leads to the first provably robust\nmodels wrt any $l_p$-norm for $p\\geq 1$.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 13:49:08 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 13:32:07 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Croce", "Francesco", ""], ["Hein", "Matthias", ""]]}, {"id": "1905.11268", "submitter": "Danish Pruthi", "authors": "Danish Pruthi, Bhuwan Dhingra, Zachary C. Lipton", "title": "Combating Adversarial Misspellings with Robust Word Recognition", "comments": "ACL 2019, long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To combat adversarial spelling mistakes, we propose placing a word\nrecognition model in front of the downstream classifier. Our word recognition\nmodels build upon the RNN semi-character architecture, introducing several new\nbackoff strategies for handling rare and unseen words. Trained to recognize\nwords corrupted by random adds, drops, swaps, and keyboard mistakes, our method\nachieves 32% relative (and 3.3% absolute) error reduction over the vanilla\nsemi-character model. Notably, our pipeline confers robustness on the\ndownstream classifier, outperforming both adversarial training and\noff-the-shelf spell checkers. Against a BERT model fine-tuned for sentiment\nanalysis, a single adversarially-chosen character attack lowers accuracy from\n90.3% to 45.8%. Our defense restores accuracy to 75%. Surprisingly, better word\nrecognition does not always entail greater robustness. Our analysis reveals\nthat robustness also depends upon a quantity that we denote the sensitivity.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 14:35:35 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 15:20:17 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Pruthi", "Danish", ""], ["Dhingra", "Bhuwan", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "1905.11360", "submitter": "Zeta Avarikioti", "authors": "Georgia Avarikioti, Eleftherios Kokoris Kogias, Roger Wattenhofer,\n  Dionysis Zindros", "title": "Brick: Asynchronous Payment Channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-chain protocols (channels) are a promising solution to the scalability\nand privacy challenges of blockchain payments. Current proposals, however,\nrequire synchrony assumptions to preserve the safety of a channel, leaking to\nan adversary the exact amount of time needed to control the network for a\nsuccessful attack. In this paper, we introduce Brick, the first payment channel\nthat remains secure under network asynchrony and concurrently provides correct\nincentives. The core idea is to incorporate the conflict resolution process\nwithin the channel by introducing a rational committee of external parties,\ncalled Wardens. Hence, if a party wants to close a channel unilaterally, it can\nonly get the committee's approval for the last valid state. Brick provides\nsub-second latency because it does not employ heavy-weight consensus. Instead,\nBrick uses consistent broadcast to announce updates and close the channel, a\nlight-weight abstraction that is powerful enough to preserve safety and\nliveness to any rational parties. Furthermore, we consider permissioned\nblockchains, where the additional property of auditability might be desired for\nregulatory purposes. We introduce Brick+, an off-chain construction that\nprovides auditability on top of Brick without conflicting with its privacy\nguarantees. We formally define the properties our payment channel construction\nshould fulfill, and prove that both Brick and Brick+ satisfy them. We also\ndesign incentives for Brick such that honest and rational behavior aligns.\nFinally, we provide a reference implementation of the smart contracts in\nSolidity.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 17:45:49 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 14:14:22 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 13:36:46 GMT"}, {"version": "v4", "created": "Fri, 19 Jun 2020 15:12:09 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Avarikioti", "Georgia", ""], ["Kogias", "Eleftherios Kokoris", ""], ["Wattenhofer", "Roger", ""], ["Zindros", "Dionysis", ""]]}, {"id": "1905.11381", "submitter": "Jirong Yi", "authors": "Jirong Yi, Hui Xie, Leixin Zhou, Xiaodong Wu, Weiyu Xu, Raghuraman\n  Mudumbai", "title": "Trust but Verify: An Information-Theoretic Explanation for the\n  Adversarial Fragility of Machine Learning Systems, and a General Defense\n  against Adversarial Attacks", "comments": "44 Pages, 2 Theorems, 35 Figures, 29 Tables. arXiv admin note:\n  substantial text overlap with arXiv:1901.09413", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep-learning based classification algorithms have been shown to be\nsusceptible to adversarial attacks: minor changes to the input of classifiers\ncan dramatically change their outputs, while being imperceptible to humans. In\nthis paper, we present a simple hypothesis about a feature compression property\nof artificial intelligence (AI) classifiers and present theoretical arguments\nto show that this hypothesis successfully accounts for the observed fragility\nof AI classifiers to small adversarial perturbations. Drawing on ideas from\ninformation and coding theory, we propose a general class of defenses for\ndetecting classifier errors caused by abnormally small input perturbations. We\nfurther show theoretical guarantees for the performance of this detection\nmethod. We present experimental results with (a) a voice recognition system,\nand (b) a digit recognition system using the MNIST database, to demonstrate the\neffectiveness of the proposed defense methods. The ideas in this paper are\nmotivated by a simple analogy between AI classifiers and the standard Shannon\nmodel of a communication system.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 21:57:51 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Yi", "Jirong", ""], ["Xie", "Hui", ""], ["Zhou", "Leixin", ""], ["Wu", "Xiaodong", ""], ["Xu", "Weiyu", ""], ["Mudumbai", "Raghuraman", ""]]}, {"id": "1905.11468", "submitter": "Chris Finlay", "authors": "Chris Finlay and Adam M Oberman", "title": "Scaleable input gradient regularization for adversarial robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we revisit gradient regularization for adversarial robustness\nwith some new ingredients. First, we derive new per-image theoretical\nrobustness bounds based on local gradient information. These bounds strongly\nmotivate input gradient regularization. Second, we implement a scaleable\nversion of input gradient regularization which avoids double backpropagation:\nadversarially robust ImageNet models are trained in 33 hours on four consumer\ngrade GPUs. Finally, we show experimentally and through theoretical\ncertification that input gradient regularization is competitive with\nadversarial training. Moreover we demonstrate that gradient regularization does\nnot lead to gradient obfuscation or gradient masking.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 19:40:52 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 14:12:34 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Finlay", "Chris", ""], ["Oberman", "Adam M", ""]]}, {"id": "1905.11475", "submitter": "Xuwang Yin", "authors": "Xuwang Yin, Soheil Kolouri, Gustavo K. Rohde", "title": "Adversarial Example Detection and Classification With Asymmetrical\n  Adversarial Training", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vulnerabilities of deep neural networks against adversarial examples have\nbecome a significant concern for deploying these models in sensitive domains.\nDevising a definitive defense against such attacks is proven to be challenging,\nand the methods relying on detecting adversarial samples are only valid when\nthe attacker is oblivious to the detection mechanism. In this paper we first\npresent an adversarial example detection method that provides performance\nguarantee to norm constrained adversaries. The method is based on the idea of\ntraining adversarial robust subspace detectors using asymmetrical adversarial\ntraining (AAT). The novel AAT objective presents a minimax problem similar to\nthat of GANs; it has the same convergence property, and consequently supports\nthe learning of class conditional distributions. We first demonstrate that the\nminimax problem could be reasonably solved by PGD attack, and then use the\nlearned class conditional generative models to define generative\ndetection/classification models that are both robust and more interpretable. We\nprovide comprehensive evaluations of the above methods, and demonstrate their\ncompetitive performances and compelling properties on adversarial detection and\nrobust classification problems.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 19:51:13 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 03:07:06 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Yin", "Xuwang", ""], ["Kolouri", "Soheil", ""], ["Rohde", "Gustavo K.", ""]]}, {"id": "1905.11503", "submitter": "Hosnieh Sattar", "authors": "Hosnieh Sattar, Katharina Krombholz, Gerard Pons-Moll, Mario Fritz", "title": "Body Shape Privacy in Images: Understanding Privacy and Preventing\n  Automatic Shape Extraction", "comments": null, "journal-ref": "Proc. of the IEEE European Conference on Computer Vision Workshops\n  (ECCVW), CV-COPS@ECCV2020", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern approaches to pose and body shape estimation have recently achieved\nstrong performance even under challenging real-world conditions. Even from a\nsingle image of a clothed person, a realistic looking body shape can be\ninferred that captures a users' weight group and body shape type well. This\nopens up a whole spectrum of applications -- in particular in fashion -- where\nvirtual try-on and recommendation systems can make use of these new and\nautomatized cues. However, a realistic depiction of the undressed body is\nregarded highly private and therefore might not be consented by most people.\nHence, we ask if the automatic extraction of such information can be\neffectively evaded. While adversarial perturbations have been shown to be\neffective for manipulating the output of machine learning models -- in\nparticular, end-to-end deep learning approaches -- state of the art shape\nestimation methods are composed of multiple stages. We perform the first\ninvestigation of different strategies that can be used to effectively\nmanipulate the automatic shape estimation while preserving the overall\nappearance of the original image.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 20:57:52 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 12:11:55 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 11:15:45 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Sattar", "Hosnieh", ""], ["Krombholz", "Katharina", ""], ["Pons-Moll", "Gerard", ""], ["Fritz", "Mario", ""]]}, {"id": "1905.11544", "submitter": "Naveed Akhtar Dr.", "authors": "Naveed Akhtar, Mohammad A. A. K. Jalwana, Mohammed Bennamoun, Ajmal\n  Mian", "title": "Label Universal Targeted Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Label Universal Targeted Attack (LUTA) that makes a deep model\npredict a label of attacker's choice for `any' sample of a given source class\nwith high probability. Our attack stochastically maximizes the log-probability\nof the target label for the source class with first order gradient\noptimization, while accounting for the gradient moments. It also suppresses the\nleakage of attack information to the non-source classes for avoiding the attack\nsuspicions. The perturbations resulting from our attack achieve high fooling\nratios on the large-scale ImageNet and VGGFace models, and transfer well to the\nPhysical World. Given full control over the perturbation scope in LUTA, we also\ndemonstrate it as a tool for deep model autopsy. The proposed attack reveals\ninteresting perturbation patterns and observations regarding the deep models.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 23:53:00 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 05:11:50 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Akhtar", "Naveed", ""], ["Jalwana", "Mohammad A. A. K.", ""], ["Bennamoun", "Mohammed", ""], ["Mian", "Ajmal", ""]]}, {"id": "1905.11564", "submitter": "Mohammad Mahmoody", "authors": "Sanjam Garg, Somesh Jha, Saeed Mahloujifar, Mohammad Mahmoody", "title": "Adversarially Robust Learning Could Leverage Computational Hardness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over recent years, devising classification algorithms that are robust to\nadversarial perturbations has emerged as a challenging problem. In particular,\ndeep neural nets (DNNs) seem to be susceptible to small imperceptible changes\nover test instances. However, the line of work in provable robustness, so far,\nhas been focused on information-theoretic robustness, ruling out even the\nexistence of any adversarial examples. In this work, we study whether there is\na hope to benefit from algorithmic nature of an attacker that searches for\nadversarial examples, and ask whether there is any learning task for which it\nis possible to design classifiers that are only robust against polynomial-time\nadversaries. Indeed, numerous cryptographic tasks can only be secure against\ncomputationally bounded adversaries, and are indeed impossible for\ncomputationally unbounded attackers. Thus, it is natural to ask if the same\nstrategy could help robust learning.\n  We show that computational limitation of attackers can indeed be useful in\nrobust learning by demonstrating the possibility of a classifier for some\nlearning task for which computational and information theoretic adversaries of\nbounded perturbations have very different power. Namely, while computationally\nunbounded adversaries can attack successfully and find adversarial examples\nwith small perturbation, polynomial time adversaries are unable to do so unless\nthey can break standard cryptographic hardness assumptions. Our results,\ntherefore, indicate that perhaps a similar approach to cryptography (relying on\ncomputational hardness) holds promise for achieving computationally robust\nmachine learning. On the reverse directions, we also show that the existence of\nsuch learning task in which computational robustness beats information\ntheoretic robustness requires computational hardness by implying (average-case)\nhardness of NP.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 01:44:22 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 18:55:20 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Garg", "Sanjam", ""], ["Jha", "Somesh", ""], ["Mahloujifar", "Saeed", ""], ["Mahmoody", "Mohammad", ""]]}, {"id": "1905.11582", "submitter": "Ziqiang Zheng", "authors": "Ziqiang Zheng, Hongzhi Liu, Zhibin Yu, Haiyong Zheng, Yang Wu, Yang\n  Yang, Jianbo Shi", "title": "EncryptGAN: Image Steganography with Domain Transform", "comments": "11pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an image steganographic algorithm called EncryptGAN, which\ndisguises private image communication in an open communication channel. The\ninsight is that content transform between two very different domains (e.g.,\nface to flower) allows one to hide image messages in one domain (face) and\ncommunicate using its counterpart in another domain (flower). The key\ningredient in our method, unlike related approaches, is a specially trained\nnetwork to extract transformed images from both domains and use them as the\npublic and private keys. We ensure the image communication remain secret except\nfor the intended recipient even when the content transformation networks are\nexposed.\n  To communicate, one directly pastes the `message' image onto a larger public\nkey image (face). Depending on the location and content of the message image,\nthe `disguise' image (flower) alters its appearance and shape while maintaining\nits overall objectiveness (flower). The recipient decodes the alternated image\nto uncover the original image message using its message image key. We implement\nthe entire procedure as a constrained Cycle-GAN, where the public and the\nprivate key generating network is used as an additional constraint to the cycle\nconsistency. Comprehensive experimental results show our EncryptGAN outperforms\nthe state-of-arts in terms of both encryption and security measures.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 02:57:55 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 01:59:13 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Zheng", "Ziqiang", ""], ["Liu", "Hongzhi", ""], ["Yu", "Zhibin", ""], ["Zheng", "Haiyong", ""], ["Wu", "Yang", ""], ["Yang", "Yang", ""], ["Shi", "Jianbo", ""]]}, {"id": "1905.11587", "submitter": "Guillaume Dupont", "authors": "Guillaume Dupont, Jerry den Hartog, Sandro Etalle, Alexios Lekidis", "title": "Network intrusion detection systems for in-vehicle network - Technical\n  report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern vehicles are complex safety critical cyber physical systems, that are\nconnected to the outside world, with all security implications that brings. To\nenhance vehicle security several network intrusion detection systems (NIDS)\nhave been proposed for the CAN bus, the predominant type of in-vehicle network.\nThe in-vehicle CAN bus, however, is a challenging place to do intrusion\ndetection as messages provide very little information; interpreting them\nrequires specific knowledge about the implementation that is not readily\navailable. In this technical report we collect how existing solutions address\nthis challenge by providing an organized inventory of various CAN NIDSs present\nin the literature, categorizing them based on what information they extract\nfrom the network and how they build their model.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 03:04:03 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Dupont", "Guillaume", ""], ["Hartog", "Jerry den", ""], ["Etalle", "Sandro", ""], ["Lekidis", "Alexios", ""]]}, {"id": "1905.11694", "submitter": "Michael Segal", "authors": "Eyal Nussbaum and Michael Segal", "title": "Privacy Vulnerabilities of Dataset Anonymization Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vast amounts of information of all types are collected daily about people by\ngovernments, corporations and individuals. The information is collected when\nusers register to or use on-line applications, receive health related services,\nuse their mobile phones, utilize search engines, or perform common daily\nactivities. As a result, there is an enormous quantity of privately-owned\nrecords that describe individuals' finances, interests, activities, and\ndemographics. These records often include sensitive data and may violate the\nprivacy of the users if published. The common approach to safeguarding user\ninformation, or data in general, is to limit access to the storage (usually a\ndatabase) by using and authentication and authorization protocol. This way,\nonly users with legitimate permissions can access the user data. In many cases\nthough, the publication of user data for statistical analysis and research can\nbe extremely beneficial for both academic and commercial uses, such as\nstatistical research and recommendation systems. To maintain user privacy when\nsuch a publication occurs many databases employ anonymization techniques,\neither on the query results or the data itself. In this paper we examine\nvariants of 2 such techniques, \"data perturbation\" and \"query-set-size control\"\nand discuss their vulnerabilities. Data perturbation deals with changing the\nvalues of records in the dataset while maintaining a level of accuracy over the\nresulting queries. We focus on a relatively new data perturbation method called\nNeNDS to show a possible partial knowledge attack on its privacy. The\nquery-set-size control allows publication of a query result dependent on having\na minimum set size, k, of records satisfying the query parameters. We show some\nquery types relying on this method may still be used to extract hidden\ninformation, and prove others maintain privacy even when using multiple\nqueries.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 09:13:56 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Nussbaum", "Eyal", ""], ["Segal", "Michael", ""]]}, {"id": "1905.11701", "submitter": "Simon Duque Anton", "authors": "Simon D. Duque Ant\\'on and Hans Dieter Schotten", "title": "Putting Together the Pieces: A Concept for Holistic Industrial Intrusion\n  Detection", "comments": "This is the preprint of a work submitted to and accepted at the\n  proceedings 2019 European Conference on Cyber Warfare and Security (ECCWS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Besides the advantages derived from the ever present communication\nproperties, it increases the attack surface of a network as well. As industrial\nprotocols and systems were not designed with security in mind, spectacular\nattacks on industrial systems occurred over the last years. Most industrial\ncommunication protocols do not provide means to ensure authentication or\nencryption. This means attackers with access to a network can read and write\ninformation. Originally not meant to be connected to public networks, the use\ncases of Industry 4.0 require interconnectivity, often through insecure public\nnetworks. This lead to an increasing interest in information security products\nfor industrial applications. In this work, the concept for holistic intrusion\ndetection methods in an industrial context is presented. It is based on\ndifferent works considering several aspects of industrial environments and\ntheir capabilities to identify intrusions as an anomaly in network or process\ndata. These capabilities are based on preceding experiments on real and\nsynthetic data. In order to justify the concept, an overview of potential and\nactual attack vectors and attacks on industrial systems is provided. It is\nshown that different aspects of industrial facilities, e.g. office IT, shop\nfloor OT, firewalled connections to customers and partners are analysed as well\nas the different layers of the automation pyramid require different methods to\ndetect attacks. Additionally, the singular steps of an attack on industrial\napplications are characterised. Finally, a resulting concept for integration of\nthese methods is proposed, providing the means to detect the different stages\nof an attack by different means.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 09:30:35 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Ant\u00f3n", "Simon D. Duque", ""], ["Schotten", "Hans Dieter", ""]]}, {"id": "1905.11735", "submitter": "Simon D. Duque Anton", "authors": "Simon Duque Anton, Daniel Fraunholz, Stephan Teuber, Hans Dieter\n  Schotten", "title": "A Question of Context: Enhancing Intrusion Detection by Providing\n  Context Information", "comments": "This is a preprint of a work published at the 2017 Internet of Things\n  Business Models, Users, and Networks", "journal-ref": null, "doi": "10.1109/CTTE.2017.8260938", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the fourth industrial revolution, and the resulting increase in\ninterconnectivity, industrial networks are more and more opened to publicly\navailable networks. Apart from the huge benefit in manageability and\nflexibility, the openness also results in a larger attack surface for malicious\nadversaries. In comparison to office environments, industrial networks have\nvery high volumes of data. In addition to that, every delay will most likely\nlead to loss of revenue. Hence, intrusion detection systems for industrial\napplications have different requirements than office-based intrusion detection\nsystems. On the other hand, industrial networks are able to provide a lot of\ncontextual information due to manufacturing execution systems and enterprise\nresource planning. Additionally, industrial networks tend to be more uniform,\nmaking it easier to determine outliers. In this work, an abstract simulation of\nindustrial network behaviour is created. Malicious actions are introduced into\na set of sequences of valid behaviour. Finally, a context-based and\ncontext-less intrusion detection system is used to find the attacks. The\nresults are compared and commented. It can be seen that context information can\nhelp in identifying malicious actions more reliable than intrusion detection\nwith only one source of information, e.g. the network.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 10:51:00 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Anton", "Simon Duque", ""], ["Fraunholz", "Daniel", ""], ["Teuber", "Stephan", ""], ["Schotten", "Hans Dieter", ""]]}, {"id": "1905.11757", "submitter": "Simon D. Duque Anton", "authors": "Simon Duque Anton, Suneetha Kanoor, Daniel Fraunholz, and Hans Dieter\n  Schotten", "title": "Evaluation of Machine Learning-based Anomaly Detection Algorithms on an\n  Industrial Modbus/TCP Data Set", "comments": "This is a preprint of a work published in the Proceedings of the 13th\n  International Conference on Availability, Reliability and Security (ARES\n  2018)", "journal-ref": null, "doi": "10.1145/3230833.3232818", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of the Industrial Internet of Things, communication\ntechnology, originally used in home and office environments, is introduced into\nindustrial applications. Commercial off-the-shelf products, as well as unified\nand well-established communication protocols make this technology easy to\nintegrate and use. Furthermore, productivity is increased in comparison to\nclassic industrial control by making systems easier to manage, set up and\nconfigure. Unfortunately, most attack surfaces of home and office environments\nare introduced into industrial applications as well, which usually have very\nfew security mechanisms in place. Over the last years, several technologies\ntackling that issue have been researched. In this work, machine learning-based\nanomaly detection algorithms are employed to find malicious traffic in a\nsynthetically generated data set of Modbus/TCP communication of a fictitious\nindustrial scenario. The applied algorithms are Support Vector Machine (SVM),\nRandom Forest, k-nearest neighbour and k-means clustering. Due to the synthetic\ndata set, supervised learning is possible. Support Vector Machine and k-nearest\nneighbour perform well with different data sets, while k-nearest neighbour and\nk-means clustering do not perform satisfactorily.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 11:52:25 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Anton", "Simon Duque", ""], ["Kanoor", "Suneetha", ""], ["Fraunholz", "Daniel", ""], ["Schotten", "Hans Dieter", ""]]}, {"id": "1905.11814", "submitter": "FatemehSadat Mireshghallah", "authors": "Fatemehsadat Mireshghallah, Mohammadkazem Taram, Prakash Ramrakhyani,\n  Dean Tullsen, Hadi Esmaeilzadeh", "title": "Shredder: Learning Noise Distributions to Protect Inference Privacy", "comments": "Presented in ASPLOS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide variety of deep neural applications increasingly rely on the cloud to\nperform their compute-heavy inference. This common practice requires sending\nprivate and privileged data over the network to remote servers, exposing it to\nthe service provider and potentially compromising its privacy. Even if the\nprovider is trusted, the data can still be vulnerable over communication\nchannels or via side-channel attacks in the cloud. To that end, this paper aims\nto reduce the information content of the communicated data with as little as\npossible compromise on the inference accuracy by making the sent data noisy. An\nundisciplined addition of noise can significantly reduce the accuracy of\ninference, rendering the service unusable. To address this challenge, this\npaper devises Shredder, an end-to-end framework, that, without altering the\ntopology or the weights of a pre-trained network, learns additive noise\ndistributions that significantly reduce the information content of communicated\ndata while maintaining the inference accuracy. The key idea is finding the\nadditive noise distributions by casting it as a disjoint offline learning\nprocess with a loss function that strikes a balance between accuracy and\ninformation degradation. The loss function also exposes a knob for a\ndisciplined and controlled asymmetric trade-off between privacy and accuracy.\nExperimentation with six real-world DNNs from text processing and image\nclassification shows that Shredder reduces the mutual information between the\ninput and the communicated data to the cloud by 74.70% compared to the original\nexecution while only sacrificing 1.58% loss in accuracy. On average, Shredder\nalso offers a speedup of 1.79x over Wi-Fi and 2.17x over LTE compared to\ncloud-only execution when using an off-the-shelf mobile GPU (Tegra X2) on the\nedge.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 19:59:34 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 16:20:44 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 23:12:58 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Mireshghallah", "Fatemehsadat", ""], ["Taram", "Mohammadkazem", ""], ["Ramrakhyani", "Prakash", ""], ["Tullsen", "Dean", ""], ["Esmaeilzadeh", "Hadi", ""]]}, {"id": "1905.11824", "submitter": "Soham Deshmukh", "authors": "Soham Deshmukh, Rahul Rade, Dr. Faruk Kazi", "title": "Attacker Behaviour Profiling using Stochastic Ensemble of Hidden Markov\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber threat intelligence is one of the emerging areas of focus in\ninformation security. Much of the recent work has focused on rule-based methods\nand detection of network attacks using Intrusion Detection algorithms. In this\npaper we propose a framework for inspecting and modelling the behavioural\naspect of an attacker to obtain better insight predictive power on his future\nactions. For modelling we propose a novel semi-supervised algorithm called\nFusion Hidden Markov Model (FHMM) which is more robust to noise, requires\ncomparatively less training time, and utilizes the benefits of ensemble\nlearning to better model temporal relationships in data. This paper evaluates\nthe performances of FHMM and compares it with both traditional algorithms like\nMarkov Chain, Hidden Markov Model (HMM) and recently developed Deep Recurrent\nNeural Network (Deep RNN) architectures. We conduct the experiments on dataset\nconsisting of real data attacks on a Cowrie honeypot system. FHMM provides\naccuracy comparable to deep RNN architectures at significant lower training\ntime. Given these experimental results, we recommend using FHMM for modelling\ndiscrete temporal data for significantly faster training and better performance\nthan existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 13:56:44 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 19:56:25 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Deshmukh", "Soham", ""], ["Rade", "Rahul", ""], ["Kazi", "Dr. Faruk", ""]]}, {"id": "1905.11831", "submitter": "Yi Xiang Marcus Tan", "authors": "Yi Xiang Marcus Tan, Alfonso Iacovazzi, Ivan Homoliak, Yuval Elovici,\n  Alexander Binder", "title": "Adversarial Attacks on Remote User Authentication Using Behavioural\n  Mouse Dynamics", "comments": "Accepted in 2019 International Joint Conference on Neural Networks\n  (IJCNN). Update of DOI", "journal-ref": null, "doi": "10.1109/IJCNN.2019.8852414", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mouse dynamics is a potential means of authenticating users. Typically, the\nauthentication process is based on classical machine learning techniques, but\nrecently, deep learning techniques have been introduced for this purpose.\nAlthough prior research has demonstrated how machine learning and deep learning\nalgorithms can be bypassed by carefully crafted adversarial samples, there has\nbeen very little research performed on the topic of behavioural biometrics in\nthe adversarial domain. In an attempt to address this gap, we built a set of\nattacks, which are applications of several generative approaches, to construct\nadversarial mouse trajectories that bypass authentication models. These\ngenerated mouse sequences will serve as the adversarial samples in the context\nof our experiments. We also present an analysis of the attack approaches we\nexplored, explaining their limitations. In contrast to previous work, we\nconsider the attacks in a more realistic and challenging setting in which an\nattacker has access to recorded user data but does not have access to the\nauthentication model or its outputs. We explore three different attack\nstrategies: 1) statistics-based, 2) imitation-based, and 3) surrogate-based; we\nshow that they are able to evade the functionality of the authentication\nmodels, thereby impacting their robustness adversely. We show that\nimitation-based attacks often perform better than surrogate-based attacks,\nunless, however, the attacker can guess the architecture of the authentication\nmodel. In such cases, we propose a potential detection mechanism against\nsurrogate-based attacks.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 14:09:15 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 02:30:01 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Tan", "Yi Xiang Marcus", ""], ["Iacovazzi", "Alfonso", ""], ["Homoliak", "Ivan", ""], ["Elovici", "Yuval", ""], ["Binder", "Alexander", ""]]}, {"id": "1905.11873", "submitter": "Constantinos Patsakis", "authors": "Fran Casino and Kim-Kwang Raymond Choo and Constantinos Patsakis", "title": "HEDGE: Efficient Traffic Classification of Encrypted and Compressed\n  Packets", "comments": "Accepted for publication at IEEE Transactions on Information\n  Forensics and Security", "journal-ref": null, "doi": "10.1109/TIFS.2019.2911156", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the size and source of network traffic increase, so does the challenge of\nmonitoring and analysing network traffic. Therefore, sampling algorithms are\noften used to alleviate these scalability issues. However, the use of high\nentropy data streams, through the use of either encryption or compression,\nfurther compounds the challenge as current state of the art algorithms cannot\naccurately and efficiently differentiate between encrypted and compressed\npackets. In this work, we propose a novel traffic classification method named\nHEDGE (High Entropy DistinGuishEr) to distinguish between compressed and\nencrypted traffic. HEDGE is based on the evaluation of the randomness of the\ndata streams and can be applied to individual packets without the need to have\naccess to the entire stream. Findings from the evaluation show that our\napproach outperforms current state of the art. We also make available our\nstatistically sound dataset, based on known benchmarks, to the wider research\ncommunity.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 15:11:56 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Casino", "Fran", ""], ["Choo", "Kim-Kwang Raymond", ""], ["Patsakis", "Constantinos", ""]]}, {"id": "1905.11880", "submitter": "Constantinos Patsakis", "authors": "Constantinos Patsakis and Fran Casino", "title": "Hydras and IPFS: A Decentralised Playground for Malware", "comments": "Published in International Journal of Information Security", "journal-ref": null, "doi": "10.1007/s10207-019-00443-0", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern malware can take various forms, and has reached a very high level of\nsophistication in terms of its penetration, persistence, communication and\nhiding capabilities. The use of cryptography, and of covert communication\nchannels over public and widely used protocols and services, is becoming a\nnorm. In this work, we start by introducing Resource Identifier Generation\nAlgorithms. These are an extension of a well-known mechanism called Domain\nGeneration Algorithms (DGA), which are frequently employed by cybercriminals\nfor bot management and communication. Our extension allows, beyond DNS, the use\nof other protocols. More concretely, we showcase the exploitation of the\nInterPlanetary file system (IPFS). This is a solution for the \"permanent web\",\nwhich enjoys a steadily growing community interest and adoption. The IPFS is,\nin addition, one of the most prominent solutions for blockchain storage. We go\nbeyond the straightforward case of using the IPFS for hosting malicious\ncontent, and explore ways in which a botmaster could employ it, to manage her\nbots, validating our findings experimentally. Finally, we discuss the\nadvantages of our approach for malware authors, its efficacy and highlight its\nextensibility for other distributed storage services.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 15:22:25 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 21:21:50 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Patsakis", "Constantinos", ""], ["Casino", "Fran", ""]]}, {"id": "1905.11905", "submitter": "Sebastian Henningsen", "authors": "Ingolf G.A. Pernice, Sebastian Henningsen, Roman Proskalovich, Martin\n  Florian, Hermann Elendner, Bj\\\"orn Scheuermann", "title": "Monetary Stabilization in Cryptocurrencies - Design Approaches and Open\n  Questions", "comments": "Accepted at IEEE Crypto Valley Conference on Blockchain Technology\n  (CVCBT) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The price volatility of cryptocurrencies is often cited as a major hindrance\nto their wide-scale adoption. Consequently, during the last two years, multiple\nso called stablecoins have surfaced---cryptocurrencies focused on maintaining\nstable exchange rates. In this paper, we systematically explore and analyze the\nstablecoin landscape. Based on a survey of 24 specific stablecoin projects, we\ngo beyond individual coins for extracting general concepts and approaches. We\ncombine our findings with learnings from classical monetary policy, resulting\nin a comprehensive taxonomy of cryptocurrency stabilization. We use our\ntaxonomy to highlight the current state of development from different\nperspectives and show blank spots. For instance, while over 91% of projects\npromote 1-to-1 stabilization targets to external assets, monetary policy\nliterature suggests that the smoothing of short term volatility is often a more\nsustainable alternative. Our taxonomy bridges computer science and economics,\nfostering the transfer of expertise. For example, we find that 38% of the\nreviewed projects use a combination of exchange rate targeting and specific\nstabilization techniques that can render them vulnerable to speculative\neconomic attacks - an avoidable design flaw.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 16:05:35 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Pernice", "Ingolf G. A.", ""], ["Henningsen", "Sebastian", ""], ["Proskalovich", "Roman", ""], ["Florian", "Martin", ""], ["Elendner", "Hermann", ""], ["Scheuermann", "Bj\u00f6rn", ""]]}, {"id": "1905.11947", "submitter": "Cl\\'ement Canonne", "authors": "Cl\\'ement L. Canonne, Gautam Kamath, Audra McMillan, Jonathan Ullman,\n  Lydia Zakynthinou", "title": "Private Identity Testing for High-Dimensional Distributions", "comments": "Improved the bounds and the writing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present novel differentially private identity\n(goodness-of-fit) testers for natural and widely studied classes of\nmultivariate product distributions: Gaussians in $\\mathbb{R}^d$ with known\ncovariance and product distributions over $\\{\\pm 1\\}^{d}$. Our testers have\nimproved sample complexity compared to those derived from previous techniques,\nand are the first testers whose sample complexity matches the order-optimal\nminimax sample complexity of $O(d^{1/2}/\\alpha^2)$ in many parameter regimes.\nWe construct two types of testers, exhibiting tradeoffs between sample\ncomplexity and computational complexity. Finally, we provide a two-way\nreduction between testing a subclass of multivariate product distributions and\ntesting univariate distributions, and thereby obtain upper and lower bounds for\ntesting this subclass of product distributions.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 17:07:38 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 20:33:34 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Canonne", "Cl\u00e9ment L.", ""], ["Kamath", "Gautam", ""], ["McMillan", "Audra", ""], ["Ullman", "Jonathan", ""], ["Zakynthinou", "Lydia", ""]]}, {"id": "1905.12032", "submitter": "Pu Zhao", "authors": "Pu Zhao, Siyue Wang, Cheng Gongye, Yanzhi Wang, Yunsi Fei, Xue Lin", "title": "Fault Sneaking Attack: a Stealthy Framework for Misleading Deep Neural\n  Networks", "comments": "Accepted by the 56th Design Automation Conference (DAC 2019)", "journal-ref": null, "doi": "10.1145/3316781.3317825", "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the great achievements of deep neural networks (DNNs), the\nvulnerability of state-of-the-art DNNs raises security concerns of DNNs in many\napplication domains requiring high reliability.We propose the fault sneaking\nattack on DNNs, where the adversary aims to misclassify certain input images\ninto any target labels by modifying the DNN parameters. We apply ADMM\n(alternating direction method of multipliers) for solving the optimization\nproblem of the fault sneaking attack with two constraints: 1) the\nclassification of the other images should be unchanged and 2) the parameter\nmodifications should be minimized. Specifically, the first constraint requires\nus not only to inject designated faults (misclassifications), but also to hide\nthe faults for stealthy or sneaking considerations by maintaining model\naccuracy. The second constraint requires us to minimize the parameter\nmodifications (using L0 norm to measure the number of modifications and L2 norm\nto measure the magnitude of modifications). Comprehensive experimental\nevaluation demonstrates that the proposed framework can inject multiple\nsneaking faults without losing the overall test accuracy performance.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 18:56:44 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Zhao", "Pu", ""], ["Wang", "Siyue", ""], ["Gongye", "Cheng", ""], ["Wang", "Yanzhi", ""], ["Fei", "Yunsi", ""], ["Lin", "Xue", ""]]}, {"id": "1905.12061", "submitter": "Celine Irvene", "authors": "Celine Irvene, David Formby, Raheem Beyah", "title": "On Evaluating the Effectiveness of the HoneyBot: A Case Study", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, cyber-physical system (CPS) security as applied to robotic\nsystems has become a popular research area. Mainly because robotics systems\nhave traditionally emphasized the completion of a specific objective and lack\nsecurity oriented design. Our previous work, HoneyBot \\cite{celine}, presented\nthe concept and prototype of the first software hybrid interaction honeypot\nspecifically designed for networked robotic systems. The intuition behind\nHoneyBot was that it would be a remotely accessible robotic system that could\nsimulate unsafe actions and physically perform safe actions to fool attackers.\nUnassuming attackers would think they were connected to an ordinary robotic\nsystem, believing their exploits were being successfully executed. All the\nwhile, the HoneyBot is logging all communications and exploits sent to be used\nfor attacker attribution and threat model creation. In this paper, we present\nfindings from the result of a user study performed to evaluate the\neffectiveness of the HoneyBot framework and architecture as it applies to real\nrobotic systems. The user study consisted of 40 participants, was conducted\nover the course of several weeks, and drew from a wide range of participants\naged between 18-60 with varying level of technical expertise. From the study we\nfound that research subjects could not tell the difference between the\nsimulated sensor values and the real sensor values coming from the HoneyBot,\nmeaning the HoneyBot convincingly spoofed communications.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 20:05:24 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Irvene", "Celine", ""], ["Formby", "David", ""], ["Beyah", "Raheem", ""]]}, {"id": "1905.12101", "submitter": "Eugene Bagdasaryan", "authors": "Eugene Bagdasaryan, Vitaly Shmatikov", "title": "Differential Privacy Has Disparate Impact on Model Accuracy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy (DP) is a popular mechanism for training machine\nlearning models with bounded leakage about the presence of specific points in\nthe training data. The cost of differential privacy is a reduction in the\nmodel's accuracy. We demonstrate that in the neural networks trained using\ndifferentially private stochastic gradient descent (DP-SGD), this cost is not\nborne equally: accuracy of DP models drops much more for the underrepresented\nclasses and subgroups.\n  For example, a gender classification model trained using DP-SGD exhibits much\nlower accuracy for black faces than for white faces. Critically, this gap is\nbigger in the DP model than in the non-DP model, i.e., if the original model is\nunfair, the unfairness becomes worse once DP is applied. We demonstrate this\neffect for a variety of tasks and models, including sentiment analysis of text\nand image classification. We then explain why DP training mechanisms such as\ngradient clipping and noise addition have disproportionate effect on the\nunderrepresented and more complex subgroups, resulting in a disparate reduction\nof model accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 21:39:44 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 02:46:17 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Bagdasaryan", "Eugene", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "1905.12121", "submitter": "Yizhen Wang", "authors": "Yizhen Wang, Somesh Jha, Kamalika Chaudhuri", "title": "An Investigation of Data Poisoning Defenses for Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data poisoning attacks -- where an adversary can modify a small fraction of\ntraining data, with the goal of forcing the trained classifier to high loss --\nare an important threat for machine learning in many applications. While a body\nof prior work has developed attacks and defenses, there is not much general\nunderstanding on when various attacks and defenses are effective. In this work,\nwe undertake a rigorous study of defenses against data poisoning for online\nlearning. First, we study four standard defenses in a powerful threat model,\nand provide conditions under which they can allow or resist rapid poisoning. We\nthen consider a weaker and more realistic threat model, and show that the\nsuccess of the adversary in the presence of data poisoning defenses there\ndepends on the \"ease\" of the learning problem.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 22:42:29 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 17:43:59 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 23:44:35 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Wang", "Yizhen", ""], ["Jha", "Somesh", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "1905.12202", "submitter": "Xiao Zhang", "authors": "Saeed Mahloujifar, Xiao Zhang, Mohammad Mahmoody, David Evans", "title": "Empirically Measuring Concentration: Fundamental Limits on Intrinsic\n  Robustness", "comments": "17 pages, 3 figures, 5 tables; NeurIPS final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent works have shown that adversarial examples that fool classifiers\ncan be found by minimally perturbing a normal input. Recent theoretical\nresults, starting with Gilmer et al. (2018b), show that if the inputs are drawn\nfrom a concentrated metric probability space, then adversarial examples with\nsmall perturbation are inevitable. A concentrated space has the property that\nany subset with $\\Omega(1)$ (e.g., 1/100) measure, according to the imposed\ndistribution, has small distance to almost all (e.g., 99/100) of the points in\nthe space. It is not clear, however, whether these theoretical results apply to\nactual distributions such as images. This paper presents a method for\nempirically measuring and bounding the concentration of a concrete dataset\nwhich is proven to converge to the actual concentration. We use it to\nempirically estimate the intrinsic robustness to $\\ell_\\infty$ and $\\ell_2$\nperturbations of several image classification benchmarks. Code for our\nexperiments is available at\nhttps://github.com/xiaozhanguva/Measure-Concentration.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 03:51:34 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 16:36:43 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Mahloujifar", "Saeed", ""], ["Zhang", "Xiao", ""], ["Mahmoody", "Mohammad", ""], ["Evans", "David", ""]]}, {"id": "1905.12228", "submitter": "Peng Chen", "authors": "Peng Chen, Jianzhong Liu, Hao Chen", "title": "Matryoshka: Fuzzing Deeply Nested Branches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Greybox fuzzing has made impressive progress in recent years, evolving from\nheuristics-based random mutation to approaches for solving individual path\nconstraints. However, they have difficulty solving path constraints that\ninvolve deeply nested conditional statements, which are common in image and\nvideo decoders, network packet analyzers, and checksum tools. We propose an\napproach for addressing this problem. First, we identify all the control\nflow-dependent conditional statements of the target conditional statement.\nNext, we select the data flow-dependent conditional statements. Finally, we use\nthree strategies to find an input that satisfies all conditional statements\nsimultaneously. We implemented this approach in a tool called Matryoshka and\ncompared its effectiveness on 13 open source programs against other\nstate-of-the-art fuzzers. Matryoshka found significantly more unique crashes\nthan AFL, QSYM, and Angora. We manually classified those crashes into 41 unique\nnew bugs, and obtained 12 CVEs. Our evaluation also uncovered the key technique\ncontributing to Matryoshka's impressive performance: it collects only the\nnesting constraints that may cause the target conditional statements\nunreachable, which greatly simplifies the constraints that it has to solve.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 05:44:08 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 00:19:36 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Chen", "Peng", ""], ["Liu", "Jianzhong", ""], ["Chen", "Hao", ""]]}, {"id": "1905.12239", "submitter": "Simon D. Duque Anton", "authors": "Simon Duque Anton, Daniel Fraunholz, Christoph Lipps, Khurshid Alam,\n  and Hans Dieter Schotten", "title": "Putting Things in Context: Securing Industrial Authentication with\n  Context Information", "comments": "This is the preprint of a work published in the Intl. Journal on\n  Cyber Situational Awareness (IJCSA)", "journal-ref": null, "doi": "10.22619/IJCSA.2018.100122", "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development in the area of wireless communication, mobile and embedded\ncomputing leads to significant changes in the application of devices. Over the\nlast years, embedded devices were brought into the consumer area creating the\nInternet of Things. Furthermore, industrial applications increasingly rely on\ncommunication through trust boundaries. Networking is cheap and easily\napplicable while providing the possibility to make everyday life more easy and\ncomfortable and industry more efficient and less time-consuming. One of the\ncrucial parts of this interconnected world is sound and secure authentication\nof entities. Only entities with valid authorisation should be enabled to act on\na resource according to an access control scheme. An overview of challenges and\npractices of authentication is provided in this work, with a special focus on\ncontext information as part of security solutions. It can be used for\nauthentication and security solutions in industrial applications. Additional\ninformation about events in networks can aid intrusion detection, especially in\ncombination with security information and event management systems. Finally, an\nauthentication and access control approach, based on context information and -\ndepending on the scenario - multiple factors is presented. The combination of\nmultiple factors with context information makes it secure and at the same time\ncase adaptive, so that the effort always matches, but never exceeds, the\nsecurity demand. This is a common issue of standard cyber security, entities\nhaving to obey strict, inflexible and unhandy policies. This approach has been\nimplemented exemplary based on RADIUS. Different scenarios were considered,\nshowing that this approach is capable of providing flexible and scalable\nsecurity for authentication processes.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 06:32:06 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Anton", "Simon Duque", ""], ["Fraunholz", "Daniel", ""], ["Lipps", "Christoph", ""], ["Alam", "Khurshid", ""], ["Schotten", "Hans Dieter", ""]]}, {"id": "1905.12264", "submitter": "Borja Balle", "authors": "Borja Balle, Gilles Barthe, Marco Gaboardi, Joseph Geumlek", "title": "Privacy Amplification by Mixing and Diffusion Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental result in differential privacy states that the privacy\nguarantees of a mechanism are preserved by any post-processing of its output.\nIn this paper we investigate under what conditions stochastic post-processing\ncan amplify the privacy of a mechanism. By interpreting post-processing as the\napplication of a Markov operator, we first give a series of amplification\nresults in terms of uniform mixing properties of the Markov process defined by\nsaid operator. Next we provide amplification bounds in terms of coupling\narguments which can be applied in cases where uniform mixing is not available.\nFinally, we introduce a new family of mechanisms based on diffusion processes\nwhich are closed under post-processing, and analyze their privacy via a novel\nheat flow argument. On the applied side, we generalize the analysis of \"privacy\namplification by iteration\" in Noisy SGD and show it admits an exponential\nimprovement in the strongly convex case, and study a mechanism based on the\nOrnstein-Uhlenbeck diffusion process which contains the Gaussian mechanism with\noptimal post-processing on bounded inputs as a special case.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 08:07:57 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 14:20:34 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Balle", "Borja", ""], ["Barthe", "Gilles", ""], ["Gaboardi", "Marco", ""], ["Geumlek", "Joseph", ""]]}, {"id": "1905.12282", "submitter": "L\\'eonard Hussenot", "authors": "L\\'eonard Hussenot, Matthieu Geist, Olivier Pietquin", "title": "CopyCAT: Taking Control of Neural Policies with Constant Attacks", "comments": "AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a new perspective on adversarial attacks against deep\nreinforcement learning agents. Our main contribution is CopyCAT, a targeted\nattack able to consistently lure an agent into following an outsider's policy.\nIt is pre-computed, therefore fast inferred, and could thus be usable in a\nreal-time scenario. We show its effectiveness on Atari 2600 games in the novel\nread-only setting. In this setting, the adversary cannot directly modify the\nagent's state -- its representation of the environment -- but can only attack\nthe agent's observation -- its perception of the environment. Directly\nmodifying the agent's state would require a write-access to the agent's inner\nworkings and we argue that this assumption is too strong in realistic settings.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 09:20:37 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 09:28:53 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Hussenot", "L\u00e9onard", ""], ["Geist", "Matthieu", ""], ["Pietquin", "Olivier", ""]]}, {"id": "1905.12386", "submitter": "Erwin Quiring", "authors": "Erwin Quiring, Alwin Maier and Konrad Rieck", "title": "Misleading Authorship Attribution of Source Code using Adversarial\n  Learning", "comments": "USENIX Security Symposium 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel attack against authorship attribution of\nsource code. We exploit that recent attribution methods rest on machine\nlearning and thus can be deceived by adversarial examples of source code. Our\nattack performs a series of semantics-preserving code transformations that\nmislead learning-based attribution but appear plausible to a developer. The\nattack is guided by Monte-Carlo tree search that enables us to operate in the\ndiscrete domain of source code. In an empirical evaluation with source code\nfrom 204 programmers, we demonstrate that our attack has a substantial effect\non two recent attribution methods, whose accuracy drops from over 88% to 1%\nunder attack. Furthermore, we show that our attack can imitate the coding style\nof developers with high accuracy and thereby induce false attributions. We\nconclude that current approaches for authorship attribution are inappropriate\nfor practical application and there is a need for resilient analysis\ntechniques.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 12:51:31 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 08:42:28 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Quiring", "Erwin", ""], ["Maier", "Alwin", ""], ["Rieck", "Konrad", ""]]}, {"id": "1905.12418", "submitter": "Salman Alsubaihi", "authors": "Salman Alsubaihi, Adel Bibi, Modar Alfadly, Abdullah Hamdi and Bernard\n  Ghanem", "title": "Expected Tight Bounds for Robust Training", "comments": "Presented as a RobustML workshop paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training Deep Neural Networks that are robust to norm bounded adversarial\nattacks remains an elusive problem. While exact and inexact verification-based\nmethods are generally too expensive to train large networks, it was\ndemonstrated that bounded input intervals can be inexpensively propagated from\na layer to another through deep networks. This interval bound propagation\napproach (IBP) not only has improved both robustness and certified accuracy but\nwas the first to be employed on large/deep networks. However, due to the very\nloose nature of the IBP bounds, the required training procedure is complex and\ninvolved. In this paper, we closely examine the bounds of a block of layers\ncomposed in the form of Affine-ReLU-Affine. To this end, we propose expected\ntight bounds (true bounds in expectation), referred to as ETB, which are\nprovably tighter than IBP bounds in expectation. We then extend this result to\ndeeper networks through blockwise propagation and show that we can achieve\norders of magnitudes tighter bounds compared to IBP. Furthermore, using a\nsimple standard training procedure, we can achieve impressive\nrobustness-accuracy trade-off on both MNIST and CIFAR10.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 12:07:48 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 10:58:47 GMT"}, {"version": "v3", "created": "Thu, 22 Aug 2019 08:48:13 GMT"}, {"version": "v4", "created": "Thu, 12 Dec 2019 15:28:52 GMT"}, {"version": "v5", "created": "Sat, 12 Jun 2021 22:35:45 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Alsubaihi", "Salman", ""], ["Bibi", "Adel", ""], ["Alfadly", "Modar", ""], ["Hamdi", "Abdullah", ""], ["Ghanem", "Bernard", ""]]}, {"id": "1905.12439", "submitter": "Dorien Herremans", "authors": "Balamurali BT, Kin Wah Edward Lin, Simon Lui, Jer-Ming Chen, Dorien\n  Herremans", "title": "Towards robust audio spoofing detection: a detailed comparison of\n  traditional and learned features", "comments": null, "journal-ref": "IEEE Access. 2019", "doi": null, "report-no": null, "categories": "cs.SD cs.CR cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speaker verification, like every other biometric system, is\nvulnerable to spoofing attacks. Using only a few minutes of recorded voice of a\ngenuine client of a speaker verification system, attackers can develop a\nvariety of spoofing attacks that might trick such systems. Detecting these\nattacks using the audio cues present in the recordings is an important\nchallenge. Most existing spoofing detection systems depend on knowing the used\nspoofing technique. With this research, we aim at overcoming this limitation,\nby examining robust audio features, both traditional and those learned through\nan autoencoder, that are generalizable over different types of replay spoofing.\nFurthermore, we provide a detailed account of all the steps necessary in\nsetting up state-of-the-art audio feature detection, pre-, and postprocessing,\nsuch that the (non-audio expert) machine learning researcher can implement such\nsystems. Finally, we evaluate the performance of our robust replay speaker\ndetection system with a wide variety and different combinations of both\nextracted and machine learned audio features on the `out in the wild' ASVspoof\n2017 dataset. This dataset contains a variety of new spoofing configurations.\nSince our focus is on examining which features will ensure robustness, we base\nour system on a traditional Gaussian Mixture Model-Universal Background Model.\nWe then systematically investigate the relative contribution of each feature\nset. The fused models, based on both the known audio features and the machine\nlearned features respectively, have a comparable performance with an Equal\nError Rate (EER) of 12. The final best performing model, which obtains an EER\nof 10.8, is a hybrid model that contains both known and machine learned\nfeatures, thus revealing the importance of incorporating both types of features\nwhen developing a robust spoofing prediction model.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 06:51:18 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 01:27:28 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["BT", "Balamurali", ""], ["Lin", "Kin Wah Edward", ""], ["Lui", "Simon", ""], ["Chen", "Jer-Ming", ""], ["Herremans", "Dorien", ""]]}, {"id": "1905.12443", "submitter": "Simon Duque Anton", "authors": "Simon Duque Ant\\'on, Michael Gundall, Daniel Fraunholz, Hans Dieter\n  Schotten", "title": "Implementing SCADA Scenarios and Introducing Attacks to Obtain Training\n  Data for Intrusion Detection Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are hardly any data sets publicly available that can be used to\nevaluate intrusion detection algorithms. The biggest threat for industrial\napplications arises from state-sponsored and criminal groups. Often, formerly\nunknown exploits are employed by these attackers, so-called 0-day exploits.\nThey cannot be discovered with signature-based intrusion detection. Thus,\nstatistical or machine learning based anomaly detection lends itself readily.\nThese methods especially, however, need a large amount of labelled training\ndata. In this work, an exemplary industrial use case with real-world industrial\nhardware is presented. Siemens S7 Programmable Logic Controllers are used to\ncontrol a real world-based control application using the OPC UA protocol: A\npump, filling and emptying water tanks. This scenario is used to generate\napplication specific network data. Furthermore, attacks are introduced into\nthis data set. This is done in three ways: First, the normal process is\nmonitored and captured. Common attacks are then synthetically introduced into\nthis data set. Second, malicious behaviour is implemented on the Programmable\nLogic Controller program and executed live, the traffic is captured as well.\nThird, malicious behaviour is implemented on the Programmable Logic Controller\nwhile still keeping the same output behaviour as in normal operation. An\nattacker could exploit an application but forge valid sensor output so that no\nanomaly is detected. Sensors are employed, capturing temperature, sound and\nflow of water to create data that can be correlated to the network data and\nused to still detect the attack. All data is labelled, containing the ground\ntruth, meaning all attacks are known and no unknown attacks occur. This makes\nthem perfect for training of anomaly detection algorithms. The data is\npublished to enable security researchers to evaluate intrusion detection\nsolutions.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 09:20:31 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Ant\u00f3n", "Simon Duque", ""], ["Gundall", "Michael", ""], ["Fraunholz", "Daniel", ""], ["Schotten", "Hans Dieter", ""]]}, {"id": "1905.12457", "submitter": "Chuanshuai Chen", "authors": "Jiazhu Dai, Chuanshuai Chen", "title": "A backdoor attack against LSTM-based text classification systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread use of deep learning system in many applications, the\nadversary has strong incentive to explore vulnerabilities of deep neural\nnetworks and manipulate them. Backdoor attacks against deep neural networks\nhave been reported to be a new type of threat. In this attack, the adversary\nwill inject backdoors into the model and then cause the misbehavior of the\nmodel through inputs including backdoor triggers. Existed research mainly\nfocuses on backdoor attacks in image classification based on CNN, little\nattention has been paid to the backdoor attacks in RNN. In this paper, we\nimplement a backdoor attack in text classification based on LSTM by data\npoisoning. When the backdoor is injected, the model will misclassify any text\nsamples that contains a specific trigger sentence into the target category\ndetermined by the adversary. The existence of the backdoor trigger is stealthy\nand the backdoor injected has little impact on the performance of the model. We\nconsider the backdoor attack in black-box setting where the adversary has no\nknowledge of model structures or training algorithms except for small amount of\ntraining data. We verify the attack through sentiment analysis on the dataset\nof IMDB movie reviews. The experimental results indicate that our attack can\nachieve around 95% success rate with 1% poisoning rate.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 13:44:35 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 14:57:19 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Dai", "Jiazhu", ""], ["Chen", "Chuanshuai", ""]]}, {"id": "1905.12556", "submitter": "Ensar Seker", "authors": "Ensar \\c{S}eker", "title": "Use of Artificial Intelligence Techniques / Applications in Cyber\n  Defense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, considering the speed of the processes and the amount of data used\nin cyber defense, it cannot be expected to have an effective defense by using\nonly human power without the help of automation systems. However, for the\neffective defense against dynamically evolving attacks on networks, it is\ndifficult to develop software with conventional fixed algorithms. This can be\nachieved by using artificial intelligence methods that provide flexibility and\nlearning capability. The likelihood of developing cyber defense capabilities\nthrough increased intelligence of defense systems is quite high. Given the\nproblems associated with cyber defense in real life, it is clear that many\ncyber defense problems can be successfully solved only when artificial\nintelligence methods are used. In this article, the current artificial\nintelligence practices and techniques are reviewed and the use and importance\nof artificial intelligence in cyber defense systems is mentioned. The aim of\nthis article is to be able to explain the use of these methods in the field of\ncyber defense with current examples by considering and analyzing the artificial\nintelligence technologies and methodologies that are currently being developed\nand integrating them with the role and adaptation of the technology and\nmethodology in the defense of cyberspace.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 13:22:50 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["\u015eeker", "Ensar", ""]]}, {"id": "1905.12590", "submitter": "Gianluca Stringhini", "authors": "Yun Shen, Gianluca Stringhini", "title": "ATTACK2VEC: Leveraging Temporal Word Embeddings to Understand the\n  Evolution of Cyberattacks", "comments": null, "journal-ref": "2019 USENIX Security Symposium", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the fact that cyberattacks are constantly growing in complexity, the\nresearch community still lacks effective tools to easily monitor and understand\nthem. In particular, there is a need for techniques that are able to not only\ntrack how prominently certain malicious actions, such as the exploitation of\nspecific vulnerabilities, are exploited in the wild, but also (and more\nimportantly) how these malicious actions factor in as attack steps in more\ncomplex cyberattacks. In this paper we present ATTACK2VEC, a system that uses\ntemporal word embeddings to model how attack steps are exploited in the wild,\nand track how they evolve. We test ATTACK2VEC on a dataset of billions of\nsecurity events collected from the customers of a commercial Intrusion\nPrevention System over a period of two years, and show that our approach is\neffective in monitoring the emergence of new attack strategies in the wild and\nin flagging which attack steps are often used together by attackers (e.g.,\nvulnerabilities that are frequently exploited together). ATTACK2VEC provides a\nuseful tool for researchers and practitioners to better understand cyberattacks\nand their evolution, and use this knowledge to improve situational awareness\nand develop proactive defenses.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 17:10:04 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Shen", "Yun", ""], ["Stringhini", "Gianluca", ""]]}, {"id": "1905.12593", "submitter": "Guillermo Suarez-Tangil", "authors": "Guillermo Suarez-Tangil, Matthew Edwards, Claudia Peersman, Gianluca\n  Stringhini, Awais Rashid, Monica Whitty", "title": "Automatically Dismantling Online Dating Fraud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online romance scams are a prevalent form of mass-marketing fraud in the\nWest, and yet few studies have addressed the technical or data-driven responses\nto this problem. In this type of scam, fraudsters craft fake profiles and\nmanually interact with their victims. Because of the characteristics of this\ntype of fraud and of how dating sites operate, traditional detection methods\n(e.g., those used in spam filtering) are ineffective. In this paper, we present\nthe results of a multi-pronged investigation into the archetype of online\ndating profiles used in this form of fraud, including their use of\ndemographics, profile descriptions, and images, shedding light on both the\nstrategies deployed by scammers to appeal to victims and the traits of victims\nthemselves. Further, in response to the severe financial and psychological harm\ncaused by dating fraud, we develop a system to detect romance scammers on\nonline dating platforms. Our work presents the first system for automatically\ndetecting this fraud. Our aim is to provide an early detection system to stop\nromance scammers as they create fraudulent profiles or before they engage with\npotential victims. Previous research has indicated that the victims of romance\nscams score highly on scales for idealized romantic beliefs. We combine a range\nof structured, unstructured, and deep-learned features that capture these\nbeliefs. No prior work has fully analyzed whether these notions of romance\nintroduce traits that could be leveraged to build a detection system. Our\nensemble machine-learning approach is robust to the omission of profile details\nand performs at high accuracy (97\\%). The system enables development of\nautomated tools for dating site providers and individual users.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 17:12:44 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 12:26:03 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Suarez-Tangil", "Guillermo", ""], ["Edwards", "Matthew", ""], ["Peersman", "Claudia", ""], ["Stringhini", "Gianluca", ""], ["Rashid", "Awais", ""], ["Whitty", "Monica", ""]]}, {"id": "1905.12701", "submitter": "Ahmad Moghimi", "authors": "Marina Minkin, Daniel Moghimi, Moritz Lipp, Michael Schwarz, Jo Van\n  Bulck, Daniel Genkin, Daniel Gruss, Frank Piessens, Berk Sunar, Yuval Yarom", "title": "Fallout: Reading Kernel Writes From User Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, out-of-order execution, an important performance optimization in\nmodern high-end processors, has been revealed to pose a significant security\nthreat, allowing information leaks across security domains. In particular, the\nMeltdown attack leaks information from the operating system kernel to user\nspace, completely eroding the security of the system. To address this and\nsimilar attacks, without incurring the performance costs of software\ncountermeasures, Intel includes hardware-based defenses in its recent Coffee\nLake R processors.\n  In this work, we show that the recent hardware defenses are not sufficient.\nSpecifically, we present Fallout, a new transient execution attack that leaks\ninformation from a previously unexplored microarchitectural component called\nthe store buffer. We show how unprivileged user processes can exploit Fallout\nto reconstruct privileged information recently written by the kernel. We\nfurther show how Fallout can be used to bypass kernel address space\nrandomization. Finally, we identify and explore microcode assists as a hitherto\nignored cause of transient execution.\n  Fallout affects all processor generations we have tested. However, we notice\na worrying regression, where the newer Coffee Lake R processors are more\nvulnerable to Fallout than older generations.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 20:02:55 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Minkin", "Marina", ""], ["Moghimi", "Daniel", ""], ["Lipp", "Moritz", ""], ["Schwarz", "Michael", ""], ["Van Bulck", "Jo", ""], ["Genkin", "Daniel", ""], ["Gruss", "Daniel", ""], ["Piessens", "Frank", ""], ["Sunar", "Berk", ""], ["Yarom", "Yuval", ""]]}, {"id": "1905.12762", "submitter": "Adnan Qayyum", "authors": "Adnan Qayyum, Muhammad Usama, Junaid Qadir, and Ala Al-Fuqaha", "title": "Securing Connected & Autonomous Vehicles: Challenges Posed by\n  Adversarial Machine Learning and The Way Forward", "comments": null, "journal-ref": "IEEE Communications Surveys and Tutorials 2020", "doi": "10.1109/COMST.2020.2975048", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connected and autonomous vehicles (CAVs) will form the backbone of future\nnext-generation intelligent transportation systems (ITS) providing travel\ncomfort, road safety, along with a number of value-added services. Such a\ntransformation---which will be fuelled by concomitant advances in technologies\nfor machine learning (ML) and wireless communications---will enable a future\nvehicular ecosystem that is better featured and more efficient. However, there\nare lurking security problems related to the use of ML in such a critical\nsetting where an incorrect ML decision may not only be a nuisance but can lead\nto loss of precious lives. In this paper, we present an in-depth overview of\nthe various challenges associated with the application of ML in vehicular\nnetworks. In addition, we formulate the ML pipeline of CAVs and present various\npotential security issues associated with the adoption of ML methods. In\nparticular, we focus on the perspective of adversarial ML attacks on CAVs and\noutline a solution to defend against adversarial attacks in multiple settings.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 22:44:17 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Qayyum", "Adnan", ""], ["Usama", "Muhammad", ""], ["Qadir", "Junaid", ""], ["Al-Fuqaha", "Ala", ""]]}, {"id": "1905.12774", "submitter": "Sasi Kumar Murakonda", "authors": "Sasi Kumar Murakonda, Reza Shokri, George Theodorakopoulos", "title": "Quantifying the Privacy Risks of Learning High-Dimensional Graphical\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models leak information about their training data. This enables attackers to\ninfer sensitive information about their training sets, notably determine if a\ndata sample was part of the model's training set. The existing works\nempirically show the possibility of these membership inference (tracing)\nattacks against complex deep learning models. However, the attack results are\ndependent on the specific training data, can be obtained only after the tedious\nprocess of training the model and performing the attack, and are missing any\nmeasure of the confidence and unused potential power of the attack.\n  In this paper, we theoretically analyze the maximum power of tracing attacks\nagainst high-dimensional graphical models, with the focus on Bayesian networks.\nWe provide a tight upper bound on the power (true positive rate) of these\nattacks, with respect to their error (false positive rate), for a given model\nstructure even before learning its parameters. As it should be, the bound is\nindependent of the knowledge and algorithm of any specific attack. It can help\nin identifying which model structures leak more information, how adding new\nparameters to the model increases its privacy risk, and what can be gained by\nadding new data points to decrease the overall information leakage. It provides\na measure of the potential leakage of a model given its structure, as a\nfunction of the model complexity and the size of the training set.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 23:14:45 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 08:03:34 GMT"}, {"version": "v3", "created": "Wed, 17 Feb 2021 05:51:25 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Murakonda", "Sasi Kumar", ""], ["Shokri", "Reza", ""], ["Theodorakopoulos", "George", ""]]}, {"id": "1905.12797", "submitter": "Yuping Lin", "authors": "Yuping Lin, Kasra Ahmadi K. A., Hui Jiang", "title": "Bandlimiting Neural Networks Against Adversarial Attacks", "comments": "Summitted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the adversarial attack and defence problem in deep\nlearning from the perspective of Fourier analysis. We first explicitly compute\nthe Fourier transform of deep ReLU neural networks and show that there exist\ndecaying but non-zero high frequency components in the Fourier spectrum of\nneural networks. We demonstrate that the vulnerability of neural networks\ntowards adversarial samples can be attributed to these insignificant but\nnon-zero high frequency components. Based on this analysis, we propose to use a\nsimple post-averaging technique to smooth out these high frequency components\nto improve the robustness of neural networks against adversarial attacks.\nExperimental results on the ImageNet dataset have shown that our proposed\nmethod is universally effective to defend many existing adversarial attacking\nmethods proposed in the literature, including FGSM, PGD, DeepFool and C&W\nattacks. Our post-averaging method is simple since it does not require any\nre-training, and meanwhile it can successfully defend over 95% of the\nadversarial samples generated by these methods without introducing any\nsignificant performance degradation (less than 1%) on the original clean\nimages.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 00:34:50 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Lin", "Yuping", ""], ["A.", "Kasra Ahmadi K.", ""], ["Jiang", "Hui", ""]]}, {"id": "1905.12857", "submitter": "AKM Bahalul Haque", "authors": "AKM Bahalul Haque, Rabeya Sultana, Mohammad Sajid Fahad, MD Nasif\n  Latif and Md. Amdadul Bari", "title": "XDoser, A Benchmarking Tool for System Load Measurement Using Denial of\n  Service Features", "comments": "12 pages, 11 Figures, 4 tables", "journal-ref": "International Journal of Network Security & Its Applications\n  (IJNSA) Vol. 11, No.3", "doi": "10.5121/ijnsa.2019.11303", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Technology has developed so fast that we feel both safe as well as unsafe in\nboth ways. Systems used today are always prone to attack by malicious users. In\nmost cases, services are hindered because these systems cannot handle the\namount of over loads the attacker provides. So, proper service load measurement\nis necessary. The tool that is being described in this paper for developments\nis based on the Denial of Service methodologies. This tool, XDoser will put a\nsynthetic load on the servers for testing purpose. The HTTP Flood method is\nused which includes an HTTP POST method as it forces the website to gather the\nmaximum resources possible in response to every single request. The tool\ndeveloped in this paper will focus on overloading the backend with multiple\nrequests. So, the tool can be implemented for servers new or old for synthetic\ntest endurance testing.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 05:22:13 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Haque", "AKM Bahalul", ""], ["Sultana", "Rabeya", ""], ["Fahad", "Mohammad Sajid", ""], ["Latif", "MD Nasif", ""], ["Bari", "Md. Amdadul", ""]]}, {"id": "1905.12951", "submitter": "Ehsan Toreini", "authors": "Ehsan Toreini, Maryam Mehrnezhad, Siamak F. Shahandashti, Feng Hao", "title": "DOMtegrity: Ensuring Web Page Integrity against Malicious Browser\n  Extensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address an unsolved problem in the real world: how to\nensure the integrity of the web content in a browser in the presence of\nmalicious browser extensions? The problem of exposing confidential user\ncredentials to malicious extensions has been widely understood, which has\nprompted major banks to deploy two-factor authentication. However, the\nimportance of the `integrity' of the web content has received little attention.\nWe implement two attacks on real-world online banking websites and show that\nignoring the `integrity' of the web content can fundamentally defeat two-factor\nsolutions. To address this problem, we propose a cryptographic protocol called\nDOMtegrity to ensure the end-to-end integrity of the DOM structure of a web\npage from delivering at a web server to the rendering of the page in the user's\nbrowser. DOMtegrity is the first solution that protects DOM integrity without\nmodifying the browser architecture or requiring extra hardware. It works by\nexploiting subtle yet important differences between browser extensions and\nin-line JavaScript code. We show how DOMtegrity prevents the earlier attacks\nand a whole range of man-in-the-browser (MITB) attacks. We conduct extensive\nexperiments on more than 14,000 real-world extensions to evaluate the\neffectiveness of DOMtegrity.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 10:39:28 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Toreini", "Ehsan", ""], ["Mehrnezhad", "Maryam", ""], ["Shahandashti", "Siamak F.", ""], ["Hao", "Feng", ""]]}, {"id": "1905.12974", "submitter": "Anirban Chakraborty", "authors": "Anirban Chakraborty and Sarani Bhattacharya and Sayandeep Saha and\n  Debdeep Mukhopadhyay", "title": "ExplFrame: Exploiting Page Frame Cache for Fault Analysis of Block\n  Ciphers", "comments": "7 pages, 4 figues", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Page Frame Cache (PFC) is a purely software cache, present in modern Linux\nbased operating systems (OS), which stores the page frames that are recently\nbeing released by the processes running on a particular CPU. In this paper, we\nshow that the page frame cache can be maliciously exploited by an adversary to\nsteer the pages of a victim process to some pre-decided attacker-chosen\nlocations in the memory. We practically demonstrate an end-to-end attack,\nExplFrame, where an attacker having only user-level privilege is able to force\na victim process's memory pages to vulnerable locations in DRAM and\ndeterministically conduct Rowhammer to induce faults. We further show that\nthese faults can be exploited for extracting the secret key of table-based\nblock cipher implementations. As a case study, we perform a full-key recovery\non OpenSSL AES by Rowhammer-induced single bit faults in the T-tables. We\npropose an improvised fault analysis technique which can exploit any\nRowhammer-induced bit-flips in the AES T-tables.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 11:37:37 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 10:22:45 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2020 10:51:12 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Chakraborty", "Anirban", ""], ["Bhattacharya", "Sarani", ""], ["Saha", "Sayandeep", ""], ["Mukhopadhyay", "Debdeep", ""]]}, {"id": "1905.12993", "submitter": "Aleksey Fedorov", "authors": "E.O. Kiktenko, M.A. Kudinov, A.A. Bulychev, A.K. Fedorov", "title": "Proof-of-forgery for hash-based signatures", "comments": "16 pages, 4 figures; comments are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present work, a peculiar property of hash-based signatures allowing\ndetection of their forgery event is explored. This property relies on the fact\nthat a successful forgery of a hash-based signature most likely results in a\ncollision with respect to the employed hash function, while the demonstration\nof this collision could serve as convincing evidence of the forgery. Here we\nprove that with properly adjusted parameters Lamport and Winternitz one-time\nsignatures schemes could exhibit a forgery detection availability property.\nThis property is of significant importance in the framework of crypto-agility\nparadigm since the considered forgery detection serves as an alarm that the\nemployed cryptographic hash function becomes insecure to use and the\ncorresponding scheme has to be replaced.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 12:14:42 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Kiktenko", "E. O.", ""], ["Kudinov", "M. A.", ""], ["Bulychev", "A. A.", ""], ["Fedorov", "A. K.", ""]]}, {"id": "1905.13005", "submitter": "Jennifer Cobbe Dr", "authors": "Jatinder Singh and Jennifer Cobbe", "title": "The Security Implications of Data Subject Rights", "comments": null, "journal-ref": null, "doi": "10.1109/MSEC.2019.2914614", "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data protection regulations give individuals rights to obtain the information\nthat entities have on them. However, providing such information can also reveal\naspects of the underlying technical infrastructure and organisational\nprocesses. This article explores the security implications this raises, and\nhighlights the need to consider such in rights fulfillment processes.\n  To appear in IEEE Security & Privacy\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 12:48:44 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Singh", "Jatinder", ""], ["Cobbe", "Jennifer", ""]]}, {"id": "1905.13055", "submitter": "Antony Hosking", "authors": "Adrian Herrera, Hendra Gunadi, Liam Hayes, Shane Magrath, Felix\n  Friedlander, Maggi Sebastian, Michael Norrish, Antony L. Hosking", "title": "Corpus Distillation for Effective Fuzzing: A Comparative Evaluation", "comments": "18 pages, 3 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mutation-based fuzzing typically uses an initial set of non-crashing seed\ninputs (a corpus) from which to generate new inputs by mutation. A corpus of\npotential seeds will often contain thousands of similar inputs. This lack of\ndiversity can lead to wasted fuzzing effort by exhaustive mutation from all\navailable seeds. To address this, fuzzers come with distillation tools (e.g.,\nafl-cmin) that select the smallest subset of seeds that triggers the same range\nof instrumentation data points as the full corpus. Common practice suggests\nthat minimizing the number and cumulative size of the seeds leads to more\nefficient fuzzing, which we explore systematically.\n  We present results of 34+ CPU-years of fuzzing with five distillation\napproaches to understand their impact in finding bugs in real-world software.\nWe evaluate a number of techniques, includibng the existing afl-cmin and\nMinset, and also MoonLight---a freely available, configurable,\nstate-of-the-art, open-source, tool.\n  Our experiments compare the effectiveness of distillation approaches,\ntargeting the Google Fuzzer Test Suite and a diverse set of six real-world\nlibraries and programs, covering 13 different input file formats across 16\nprograms. Our results show that distillation is a necessary precursor to any\nfuzzing campaign when starting with a large initial corpus. We compare the\neffectiveness of alternative distillation approaches. Notably, our experiments\nreveal that state-of-the-art distillation tools (such as MoonLight and Minset)\ndo not exclusively find all of the 33 bugs (in the real-world targets) exposed\nby our combined campaign: each technique appears to have its own strengths. We\nfind (and report) new bugs with MoonLight that are not found by Minset, and\nvice versa. Moreover, afl-cmin fails to reveal many of these bugs. Of the 33\nbugs revealed in our campaign, seven new bugs have received CVEs.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 13:58:34 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 04:01:37 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Herrera", "Adrian", ""], ["Gunadi", "Hendra", ""], ["Hayes", "Liam", ""], ["Magrath", "Shane", ""], ["Friedlander", "Felix", ""], ["Sebastian", "Maggi", ""], ["Norrish", "Michael", ""], ["Hosking", "Antony L.", ""]]}, {"id": "1905.13087", "submitter": "Zhongliang Yang", "authors": "Zhongliang Yang, Ke Wang, Jian Li, Yongfeng Huang and Yu-Jin Zhang", "title": "TS-RNN: Text Steganalysis Based on Recurrent Neural Networks", "comments": "IEEE Signal Processing Letters", "journal-ref": null, "doi": "10.1109/LSP.2019.2920452", "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of natural language processing technologies, more\nand more text steganographic methods based on automatic text generation\ntechnology have appeared in recent years. These models use the powerful\nself-learning and feature extraction ability of the neural networks to learn\nthe feature expression of massive normal texts. Then they can automatically\ngenerate dense steganographic texts which conform to such statistical\ndistribution based on the learned statistical patterns. In this paper, we\nobserve that the conditional probability distribution of each word in the\nautomatically generated steganographic texts will be distorted after embedded\nwith hidden information. We use Recurrent Neural Networks (RNNs) to extract\nthese feature distribution differences and then classify those features into\ncover text and stego text categories. Experimental results show that the\nproposed model can achieve high detection accuracy. Besides, the proposed model\ncan even make use of the subtle differences of the feature distribution of\ntexts to estimate the amount of hidden information embedded in the generated\nsteganographic text.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 15:00:11 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Yang", "Zhongliang", ""], ["Wang", "Ke", ""], ["Li", "Jian", ""], ["Huang", "Yongfeng", ""], ["Zhang", "Yu-Jin", ""]]}, {"id": "1905.13229", "submitter": "Gautam Kamath", "authors": "Mark Bun, Gautam Kamath, Thomas Steinke, Zhiwei Steven Wu", "title": "Private Hypothesis Selection", "comments": "Appeared in NeurIPS 2019. Final version to appear in IEEE\n  Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a differentially private algorithm for hypothesis selection. Given\nsamples from an unknown probability distribution $P$ and a set of $m$\nprobability distributions $\\mathcal{H}$, the goal is to output, in a\n$\\varepsilon$-differentially private manner, a distribution from $\\mathcal{H}$\nwhose total variation distance to $P$ is comparable to that of the best such\ndistribution (which we denote by $\\alpha$). The sample complexity of our basic\nalgorithm is $O\\left(\\frac{\\log m}{\\alpha^2} + \\frac{\\log m}{\\alpha\n\\varepsilon}\\right)$, representing a minimal cost for privacy when compared to\nthe non-private algorithm. We also can handle infinite hypothesis classes\n$\\mathcal{H}$ by relaxing to $(\\varepsilon,\\delta)$-differential privacy.\n  We apply our hypothesis selection algorithm to give learning algorithms for a\nnumber of natural distribution classes, including Gaussians, product\ndistributions, sums of independent random variables, piecewise polynomials, and\nmixture classes. Our hypothesis selection procedure allows us to generically\nconvert a cover for a class to a learning algorithm, complementing known\nlearning lower bounds which are in terms of the size of the packing number of\nthe class. As the covering and packing numbers are often closely related, for\nconstant $\\alpha$, our algorithms achieve the optimal sample complexity for\nmany classes of interest. Finally, we describe an application to private\ndistribution-free PAC learning.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 18:00:00 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 23:12:32 GMT"}, {"version": "v3", "created": "Sat, 25 Jan 2020 23:50:16 GMT"}, {"version": "v4", "created": "Thu, 31 Dec 2020 05:22:24 GMT"}, {"version": "v5", "created": "Mon, 4 Jan 2021 18:30:15 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Bun", "Mark", ""], ["Kamath", "Gautam", ""], ["Steinke", "Thomas", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "1905.13254", "submitter": "Hui Lin", "authors": "Hui Lin", "title": "SDN-based In-network Honeypot: Preemptively Disrupt and Mislead Attacks\n  in IoT Networks", "comments": "Presented at the 1st International Workshop on Security and Privacy\n  for the Internet-of-Things (IoTSec)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting cyber attacks in the network environments used by\nInternet-of-things (IoT) and preventing them from causing physical\nperturbations play an important role in delivering dependable services. To\nachieve this goal, we propose in-network Honeypot based on Software-Defined\nNetworking (SDN) to disrupt and mislead adversaries into exposures while they\nare in an early stage of preparing an attack. Different from traditional\nHoneypot requiring dedicated hardware setup, the in-network Honeypot directly\nreroutes traffic from suspicious nodes and intelligently spoofs the network\ntraffic to them by adding misleading information into normal traffic.\nPreliminary evaluations on real networks demonstrate that the in-network\nHoneypot can have little impacts on the performance of IoT networks.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 18:17:23 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Lin", "Hui", ""]]}, {"id": "1905.13264", "submitter": "Isabel Wagner", "authors": "Isabel Wagner, Yuchen Zhao", "title": "Using Metrics Suites to Improve the Measurement of Privacy in Graphs", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PF cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social graphs are widely used in research (e.g., epidemiology) and business\n(e.g., recommender systems). However, sharing these graphs poses privacy risks\nbecause they contain sensitive information about individuals. Graph\nanonymization techniques aim to protect individual users in a graph, while\ngraph de-anonymization aims to re-identify users. The effectiveness of\nanonymization and de-anonymization algorithms is usually evaluated with privacy\nmetrics. However, it is unclear how strong existing privacy metrics are when\nthey are used in graph privacy. In this paper, we study 26 privacy metrics for\ngraph anonymization and de-anonymization and evaluate their strength in terms\nof three criteria: monotonicity indicates whether the metric indicates lower\nprivacy for stronger adversaries; for within-scenario comparisons, evenness\nindicates whether metric values are spread evenly; and for between-scenario\ncomparisons, shared value range indicates whether metrics use a consistent\nvalue range across scenarios. Our extensive experiments indicate that no single\nmetric fulfills all three criteria perfectly. We therefore use methods from\nmulti-criteria decision analysis to aggregate multiple metrics in a metrics\nsuite, and we show that these metrics suites improve monotonicity compared to\nthe best individual metric. This important result enables more monotonic, and\nthus more accurate, evaluations of new graph anonymization and de-anonymization\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 18:59:17 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Wagner", "Isabel", ""], ["Zhao", "Yuchen", ""]]}, {"id": "1905.13284", "submitter": "Rangeet Pan", "authors": "Rangeet Pan and Md Johirul Islam and Shibbir Ahmed and Hridesh Rajan", "title": "Identifying Classes Susceptible to Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite numerous attempts to defend deep learning based image classifiers,\nthey remain susceptible to the adversarial attacks. This paper proposes a\ntechnique to identify susceptible classes, those classes that are more easily\nsubverted. To identify the susceptible classes we use distance-based measures\nand apply them on a trained model. Based on the distance among original\nclasses, we create mapping among original classes and adversarial classes that\nhelps to reduce the randomness of a model to a significant amount in an\nadversarial setting. We analyze the high dimensional geometry among the feature\nclasses and identify the k most susceptible target classes in an adversarial\nattack. We conduct experiments using MNIST, Fashion MNIST, CIFAR-10 (ImageNet\nand ResNet-32) datasets. Finally, we evaluate our techniques in order to\ndetermine which distance-based measure works best and how the randomness of a\nmodel changes with perturbation.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 20:08:35 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Pan", "Rangeet", ""], ["Islam", "Md Johirul", ""], ["Ahmed", "Shibbir", ""], ["Rajan", "Hridesh", ""]]}, {"id": "1905.13332", "submitter": "Shuai Wang", "authors": "Shuai Wang, Yuyan Bao, Xiao Liu, Pei Wang, Danfeng Zhang, and Dinghao\n  Wu", "title": "Identifying Cache-Based Side Channels through Secret-Augmented Abstract\n  Interpretation", "comments": "The extended version of a paper to appear in the Proceedings of the\n  28th USENIX Security Symposium, 2019, (USENIX Security '19), 30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cache-based side channels enable a dedicated attacker to reveal program\nsecrets by measuring the cache access patterns. Practical attacks have been\nshown against real-world crypto algorithm implementations such as RSA, AES, and\nElGamal. By far, identifying information leaks due to cache-based side\nchannels, either in a static or dynamic manner, remains a challenge: the\nexisting approaches fail to offer high precision, full coverage, and good\nscalability simultaneously, thus impeding their practical use in real-world\nscenarios.\n  In this paper, we propose a novel static analysis method on binaries to\ndetect cache-based side channels. We use abstract interpretation to reason on\nprogram states with respect to abstract values at each program point. To make\nsuch abstract interpretation scalable to real-world cryptosystems while\noffering high precision and full coverage, we propose a novel abstract domain\ncalled the Secret-Augmented Symbolic domain (SAS). SAS tracks program secrets\nand dependencies on them for precision, while it tracks only coarse-grained\npublic information for scalability.\n  We have implemented the proposed technique into a practical tool named CacheS\nand evaluated it on the implementations of widely-used cryptographic algorithms\nin real-world crypto libraries, including Libgcrypt, OpenSSL, and mbedTLS.\nCacheS successfully confirmed a total of 154 information leaks reported by\nprevious research and 54 leaks that were previously unknown. We have reported\nour findings to the developers. And they confirmed that many of those unknown\ninformation leaks do lead to potential side channels.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 21:56:13 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Wang", "Shuai", ""], ["Bao", "Yuyan", ""], ["Liu", "Xiao", ""], ["Wang", "Pei", ""], ["Zhang", "Danfeng", ""], ["Wu", "Dinghao", ""]]}, {"id": "1905.13369", "submitter": "Sam Kumar", "authors": "Sam Kumar, Yuncong Hu, Michael P Andersen, Raluca Ada Popa, David E.\n  Culler", "title": "JEDI: Many-to-Many End-to-End Encryption and Key Delegation for IoT", "comments": "Extended version of a paper accepted at USENIX Security 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the Internet of Things (IoT) emerges over the next decade, developing\nsecure communication for IoT devices is of paramount importance. Achieving\nend-to-end encryption for large-scale IoT systems, like smart buildings or\nsmart cities, is challenging because multiple principals typically interact\nindirectly via intermediaries, meaning that the recipient of a message is not\nknown in advance. This paper proposes JEDI (Joining Encryption and Delegation\nfor IoT), a many-to-many end-to-end encryption protocol for IoT. JEDI encrypts\nand signs messages end-to-end, while conforming to the decoupled communication\nmodel typical of IoT systems. JEDI's keys support expiry and fine-grained\naccess to data, common in IoT. Furthermore, JEDI allows principals to delegate\ntheir keys, restricted in expiry or scope, to other principals, thereby\ngranting access to data and managing access control in a scalable, distributed\nway. Through careful protocol design and implementation, JEDI can run across\nthe spectrum of IoT devices, including ultra low-power deeply embedded sensors\nseverely constrained in CPU, memory, and energy consumption. We apply JEDI to\nan existing IoT messaging system and demonstrate that its overhead is modest.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 01:07:32 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 08:58:56 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Kumar", "Sam", ""], ["Hu", "Yuncong", ""], ["Andersen", "Michael P", ""], ["Popa", "Raluca Ada", ""], ["Culler", "David E.", ""]]}, {"id": "1905.13399", "submitter": "Yuan Gong", "authors": "Yuan Gong, Boyang Li, Christian Poellabauer, Yiyu Shi", "title": "Real-Time Adversarial Attacks", "comments": "To Appear in the Proceedings of the 28th International Joint\n  Conference on Artificial Intelligence (IJCAI 2019). Code:\n  https://github.com/YuanGongND/realtime-adversarial-attack", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, many efforts have demonstrated that modern machine learning\nalgorithms are vulnerable to adversarial attacks, where small, but carefully\ncrafted, perturbations on the input can make them fail. While these attack\nmethods are very effective, they only focus on scenarios where the target model\ntakes static input, i.e., an attacker can observe the entire original sample\nand then add a perturbation at any point of the sample. These attack approaches\nare not applicable to situations where the target model takes streaming input,\ni.e., an attacker is only able to observe past data points and add\nperturbations to the remaining (unobserved) data points of the input. In this\npaper, we propose a real-time adversarial attack scheme for machine learning\nmodels with streaming inputs.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 03:32:10 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 07:49:38 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Gong", "Yuan", ""], ["Li", "Boyang", ""], ["Poellabauer", "Christian", ""], ["Shi", "Yiyu", ""]]}, {"id": "1905.13409", "submitter": "Reza Shokri", "authors": "Te Juin Lester Tan and Reza Shokri", "title": "Bypassing Backdoor Detection Algorithms in Deep Learning", "comments": "IEEE European Symposium on Security and Privacy 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are vulnerable to various adversarial manipulations of\ntheir training data, parameters, and input sample. In particular, an adversary\ncan modify the training data and model parameters to embed backdoors into the\nmodel, so the model behaves according to the adversary's objective if the input\ncontains the backdoor features, referred to as the backdoor trigger (e.g., a\nstamp on an image). The poisoned model's behavior on clean data, however,\nremains unchanged. Many detection algorithms are designed to detect backdoors\non input samples or model parameters, through the statistical difference\nbetween the latent representations of adversarial and clean input samples in\nthe poisoned model. In this paper, we design an adversarial backdoor embedding\nalgorithm that can bypass the existing detection algorithms including the\nstate-of-the-art techniques. We design an adaptive adversarial training\nalgorithm that optimizes the original loss function of the model, and also\nmaximizes the indistinguishability of the hidden representations of poisoned\ndata and clean data. This work calls for designing adversary-aware defense\nmechanisms for backdoor detection.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 04:28:00 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 17:56:42 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Tan", "Te Juin Lester", ""], ["Shokri", "Reza", ""]]}, {"id": "1905.13430", "submitter": "Yair Meidan", "authors": "Yair Meidan, Vinay Sachidananda, Yuval Elovici, and Asaf Shabtai", "title": "Privacy-Preserving Detection of IoT Devices Connected Behind a NAT in a\n  Smart Home Setup", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, telecommunication service providers (telcos) are exposed to\ncyber-attacks executed by compromised IoT devices connected to their customers'\nnetworks. Such attacks might have severe effects not only on the target of\nattacks but also on the telcos themselves. To mitigate those risks we propose a\nmachine learning based method that can detect devices of specific vulnerable\nIoT models connected behind a domestic NAT, thereby identifying home networks\nthat pose a risk to the telco's infrastructure and availability of services. As\npart of the effort to preserve the domestic customers' privacy, our method\nrelies on NetFlow data solely, refraining from inspecting the payload. To\npromote future research in this domain we share our novel dataset, collected in\nour lab from numerous and various commercial IoT devices.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 06:09:16 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Meidan", "Yair", ""], ["Sachidananda", "Vinay", ""], ["Elovici", "Yuval", ""], ["Shabtai", "Asaf", ""]]}, {"id": "1905.13447", "submitter": "Shafiq Ul Rehman", "authors": "Parminder Singh, Shafiq Ul Rehman, Selvakumar Manickam", "title": "Comparative Analysis of State-of-the-Art EDoS Mitigation Techniques in\n  Cloud Computing Environment", "comments": "Anomaly Detection Techniques, Cloud Computing, DDoS Attack, EDoS\n  Attack, Mitigation Techniques, Security Threats", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new variant of the DDoS attack, called Economic Denial of Sustainability\nattack has emerged. Since the cloud service is based on the pay-per-use model,\nthe EDoS attack endeavors to scale up the resource usage over time to the point\nthe purveyor of the server is financially incapable of sustaining the service\ndue to the incurred unaffordable usage charges. The implication of the EDoS\nattack is a major security implication as more elastic cloud services are being\ndeployed. Existing techniques to detect and mitigate such attacks are either\nhave low accuracy or ineffective and, in some cases, aggravate the attack even\nfurther. Therefore, an Enhanced Mitigation Mechanism is proposed to address\nthese shortcomings using OpenFlow and statistical techniques, i.e. Hellinger\nDistance and Entropy. The experiments clearly depicted that EMM is able to\ndetect and mitigate EDoS attacks with high accuracy and it is effective in\nterms of resource utilization compared to existing mitigation techniques. Thus,\ncan be deployed in the cloud environment without the need for additional\nresource requirements.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 07:17:53 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 04:08:15 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Singh", "Parminder", ""], ["Rehman", "Shafiq Ul", ""], ["Manickam", "Selvakumar", ""]]}, {"id": "1905.13474", "submitter": "Rolando Trujillo-Rasua", "authors": "Rolando Trujillo-Rasua", "title": "Secure Memory Erasure in the Presence of Man-in-the-Middle Attackers", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory erasure protocols serve to clean up a device's memory before the\ninstallation of new software. Although this task can be accomplished by direct\nhardware manipulation, remote software-based memory erasure protocols have\nemerged as a more efficient and cost-effective alternative. Existing remote\nmemory erasure protocols, however, still rely on non-standard adversarial\nmodels to operate correctly, thereby requiring additional hardware to restrict\nthe adversary's capabilities. In this work, we provide a formal definition of\nsecure memory erasure within a symbolic security model that utilizes the\nstandard Dolev-Yao adversary. Our main result consists of a restriction on the\nDolev-Yao adversary that we prove necessary and sufficient to solve the problem\nof finding a protocol that satisfies secure memory erasure. We also provide a\ndescription of the resulting protocol using standard cryptographic notation,\nwhich we use to analyze the security and communication complexity trade-off\ncommonly present in this type of protocols.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 09:14:13 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Trujillo-Rasua", "Rolando", ""]]}, {"id": "1905.13532", "submitter": "Ensar Seker", "authors": "Kamile Nur Sevi\\c{s}, Ensar \\c{S}eker", "title": "Cyber Warfare: Terms, Issues, Laws and Controversies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have shown us the importance of cybersecurity. Especially, when\nthe matter is national security, it is even more essential and crucial.\nIncreasing cyber attacks, especially between countries in governmental level,\ncreated a new term cyber warfare. Creating some rules and regulations for this\nkind of war is necessary therefore international justice systems are working on\nit continuously. In this paper, we mentioned fundamental terms of\ncybersecurity, cyber capabilities of some countries, some important cyber\nattacks in near past, and finally, globally applied cyber warfare law for this\nattacks.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 13:22:20 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Sevi\u015f", "Kamile Nur", ""], ["\u015eeker", "Ensar", ""]]}, {"id": "1905.13594", "submitter": "Shuming Jiao", "authors": "Shuming Jiao, Yang Gao, Ting Lei, Zhenwei Xie, Xiaocong Yuan", "title": "Known-plaintext attack and ciphertext-only attack for encrypted\n  single-pixel imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many previous works, a single-pixel imaging (SPI) system is constructed as\nan optical image encryption system. Unauthorized users are not able to\nreconstruct the plaintext image from the ciphertext intensity sequence without\nknowing the illumination pattern key. However, little cryptanalysis about\nencrypted SPI has been investigated in the past. In this work, we propose a\nknown-plaintext attack scheme and a ciphertext-only attack scheme to an\nencrypted SPI system for the first time. The known-plaintext attack is\nimplemented by interchanging the roles of illumination patterns and object\nimages in the SPI model. The ciphertext-only attack is implemented based on the\nstatistical features of single-pixel intensity values. The two schemes can\ncrack encrypted SPI systems and successfully recover the key containing correct\nillumination patterns.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 13:01:22 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Jiao", "Shuming", ""], ["Gao", "Yang", ""], ["Lei", "Ting", ""], ["Xie", "Zhenwei", ""], ["Yuan", "Xiaocong", ""]]}, {"id": "1905.13737", "submitter": "Lucy Li", "authors": "Lucy Li, Bijeeta Pal, Junade Ali, Nick Sullivan, Rahul Chatterjee,\n  Thomas Ristenpart", "title": "Protocols for Checking Compromised Credentials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To prevent credential stuffing attacks, industry best practice now\nproactively checks if user credentials are present in known data breaches.\nRecently, some web services, such as HaveIBeenPwned (HIBP) and Google Password\nCheckup (GPC), have started providing APIs to check for breached passwords. We\nrefer to such services as compromised credential checking (C3) services. We\ngive the first formal description of C3 services, detailing different settings\nand operational requirements, and we give relevant threat models.\n  One key security requirement is the secrecy of a user's passwords that are\nbeing checked. Current widely deployed C3 services have the user share a small\nprefix of a hash computed over the user's password. We provide a framework for\nempirically analyzing the leakage of such protocols, showing that in some\ncontexts knowing the hash prefixes leads to a 12x increase in the efficacy of\nremote guessing attacks. We propose two new protocols that provide stronger\nprotection for users' passwords, implement them, and show experimentally that\nthey remain practical to deploy.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 17:42:50 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 15:17:15 GMT"}, {"version": "v3", "created": "Wed, 4 Sep 2019 14:33:38 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Li", "Lucy", ""], ["Pal", "Bijeeta", ""], ["Ali", "Junade", ""], ["Sullivan", "Nick", ""], ["Chatterjee", "Rahul", ""], ["Ristenpart", "Thomas", ""]]}, {"id": "1905.13746", "submitter": "Sanjay Sahay", "authors": "Sanjay K. Sahay and Mayank Chaudhari", "title": "An Efficient Detection of Malware by Naive Bayes Classifier Using GPGPU", "comments": "Conference paper, 9 pages, 4 figures", "journal-ref": "Springer, Advances in Computer Communication and Computational\n  Sciences, Vol. 924, pp. 255-262, 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to continuous increase in the number of malware (according to AV-Test\ninstitute total ~8 x 10^8 malware are already known, and every day they\nregister ~2.5 x 10^4 malware) and files in the computational devices, it is\nvery important to design a system which not only effectively but can also\nefficiently detect the new or previously unseen malware to prevent/minimize the\ndamages. Therefore, this paper presents a novel group-wise approach for the\nefficient detection of malware by parallelizing the classification using the\npower of GPGPU and shown that by using the Naive Bayes classifier the detection\nspeed-up can be boosted up to 200x. The investigation also shows that the\nclassification time increases significantly with the number of features.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 02:37:09 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Sahay", "Sanjay K.", ""], ["Chaudhari", "Mayank", ""]]}, {"id": "1905.13747", "submitter": "Sanjay Sahay", "authors": "Sanjay K. Sahay and Ashu Sharma", "title": "A Survey on the Detection of Android Malicious Apps", "comments": "Conference paper, 11 pages", "journal-ref": "Springer, Advances in Computer Communication and Computational\n  Sciences, pp 437-446, 2019", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android-based smart devices are exponentially growing, and due to the\nubiquity of the Internet, these devices are globally connected to the different\ndevices/networks. Its popularity, attractive features, and mobility make\nmalware creator to put a number of malicious apps in the market to disrupt and\nannoy the victims. Although to identify the malicious apps, time-to-time\nvarious techniques are proposed. However, it appears that malware developers\nare always ahead of the anti-malware group, and the proposed techniques by the\nanti-malware groups are not sufficient to counter the advanced malicious apps.\nTherefore, to understand the various techniques proposed/used for the\nidentification of Android malicious apps, in this paper, we present a survey\nconducted by us on the work done by the researchers in this field.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 02:27:47 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Sahay", "Sanjay K.", ""], ["Sharma", "Ashu", ""]]}]