[{"id": "1105.0259", "submitter": "Massimiliano Sala Prof.", "authors": "Lara Maines and Matteo Piva and Anna Rimoldi and Massimiliano Sala", "title": "On the provable security of BEAR and LION schemes", "comments": null, "journal-ref": "Applicable Algebra in Engineering, Communication and Computing,\n  2011, vol. 22, p. 413-423", "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.CO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BEAR, LION and LIONESS are block ciphers presented by Biham and Anderson\n(1996), inspired by the famous Luby-Rackoff constructions of block ciphers from\nother cryptographic primitives (1988). The ciphers proposed by Biham and\nAnderson are based on one stream cipher and one hash function. Good properties\nof the primitives ensure good properties of the block cipher. In particular,\nthey are able to prove that their ciphers are immune to any efficient\nknown-plaintext key-recovery attack that can use as input only one\nplaintext-ciphertext pair. Our contribution is showing that these ciphers are\nactually immune to any efficient known-plaintext key-recovery attack that can\nuse as input any number of plaintext-ciphertext pairs. We are able to get this\nimprovement by using slightly weaker hypotheses on the primitives. We also\ndiscuss the attack by Morin (1996).\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2011 08:35:46 GMT"}], "update_date": "2016-04-01", "authors_parsed": [["Maines", "Lara", ""], ["Piva", "Matteo", ""], ["Rimoldi", "Anna", ""], ["Sala", "Massimiliano", ""]]}, {"id": "1105.1071", "submitter": "Yunlei Zhao", "authors": "Andrew C. Yao, Yunlei Zhao", "title": "A New Family of Practical Non-Malleable Diffie-Hellman Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptography algorithm standards play a key role both to the practice of\ninformation security and to cryptography theory research. Among them, the MQV\nand HMQV protocols ((H)MQV, in short) are a family of (implicitly\nauthenticated) Diffie-Hellman key-exchange (DHKE) protocols that are widely\nstandardized and deployed. In this work, from some new perspectives and\napproaches and under some new design rationales and insights, we develop a new\nfamily of practical implicitly authenticated DHKE protocols, which enjoy\nnotable performance among security, privacy, efficiency and easy deployment. We\nmake detailed comparisons between our new DHKE protocols and (H)MQV, showing\nthat the newly developed protocols outperform HMQV in most aspects. Along the\nway, guided by our new design rationales, we also identify a new vulnerability\n(H)MQV, which brings some new perspectives (e.g., computational fairness) to\nthe literature.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2011 13:39:18 GMT"}, {"version": "v2", "created": "Fri, 8 Jul 2011 06:46:35 GMT"}, {"version": "v3", "created": "Sat, 16 Jul 2011 14:38:10 GMT"}, {"version": "v4", "created": "Wed, 9 Nov 2011 03:33:45 GMT"}, {"version": "v5", "created": "Mon, 19 Dec 2011 02:14:48 GMT"}], "update_date": "2011-12-20", "authors_parsed": [["Yao", "Andrew C.", ""], ["Zhao", "Yunlei", ""]]}, {"id": "1105.1086", "submitter": "Shiv Datt Kumar Dr", "authors": "Sumit Kumar Upadhyay, Shiv Datt Kumar and Ramji Lal", "title": "Public Key Protocol Based on Amalgamated Free Product", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the spirit of Diffie Hellman the concept of a protocol algebra is\nintroduced using certain amalgamated free product of Braid group B and Thompson\ngroup T together with a nilpotent subgroup H of index 2.\n", "versions": [{"version": "v1", "created": "Sat, 16 Apr 2011 14:29:27 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Upadhyay", "Sumit Kumar", ""], ["Kumar", "Shiv Datt", ""], ["Lal", "Ramji", ""]]}, {"id": "1105.1141", "submitter": "Paul E. Gunnells", "authors": "Paul E. Gunnells", "title": "On the cryptanalysis of the generalized simultaneous conjugacy search\n  problem and the security of the Algebraic Eraser", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Algebraic Eraser (AE) is a cryptographic primitive that can be used to\nobscure information in certain algebraic cryptosystems. The Colored Burau Key\nAgreement Protocol (CBKAP), which is built on the AE, was introduced by I.\nAnshel, M. Anshel, D. Goldfeld, and S. Lemieux in 2006 as a protocol suitable\nfor use on platforms with constrained computational resources, such as RFID and\nwireless sensors. In 2009 A. Myasnikov and A. Ushnakov proposed an attack on\nCBKAP that attempts to defeat the generalized simultaneous conjugacy search\nproblem, which is the public-key computational problem underlying CBKAP. In\nthis paper we investigate the effectiveness of this attack. Our findings are\nthat success of the attack only comes from applying it to short keys, and that\nwith appropriate keys the attack fails in 100% of cases and does not pose a\nthreat against CBKAP. Moreover, the attack makes assumptions about CBKAP that\ndo not hold in practical implementations, and thus does not represent a threat\nto the use of CBKAP in applications.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2011 18:48:58 GMT"}], "update_date": "2011-05-06", "authors_parsed": [["Gunnells", "Paul E.", ""]]}, {"id": "1105.1234", "submitter": "Andreas Baldi", "authors": "Ghossoon. M. W. Al-Saadoon, Hilal M.Y. Al-Bayatti", "title": "A Comparison of Trojan Virus Behavior in Linux and Windows Operating\n  Systems", "comments": "7 Pages", "journal-ref": "World of Computer Science and Information Technology Journal\n  (WCSIT), Vol. 1, No. 3, 56-62, 2011", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trojan virus attacks pose one of the most serious threats to computer\nsecurity. A Trojan horse is typically separated into two parts - a server and a\nclient. It is the client that is cleverly disguised as significant software and\npositioned in peer-to-peer file sharing networks, or unauthorized download\nwebsites. The most common means of infection is through email attachments. The\ndeveloper of the virus usually uses various spamming techniques in order to\ndistribute the virus to unsuspecting users. Malware developers use chat\nsoftware as another method to spread their Trojan horse viruses such as Yahoo\nMessenger and Skype. The objective of this paper is to explore the network\npacket information and detect the behavior of Trojan attacks to monitoring\noperating systems such as Windows and Linux. This is accomplished by detecting\nand analyzing the Trojan infected packet from a network segment -which passes\nthrough email attachment- before attacking a host computer. The results that\nhave been obtained to detect information and to store infected packets through\nmonitoring when using the web browser also compare the behaviors of Linux and\nWindows using the payload size after implementing the Wireshark sniffer packet\nresults. Conclusions of the figures analysis from the packet captured data to\nanalyze the control bit, and check the behavior of the control bits, and the\nusability of the operating systems Linux and Windows.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2011 06:59:57 GMT"}, {"version": "v2", "created": "Tue, 24 May 2011 13:13:31 GMT"}], "update_date": "2011-05-25", "authors_parsed": [["Al-Saadoon", "Ghossoon. M. W.", ""], ["Al-Bayatti", "Hilal M. Y.", ""]]}, {"id": "1105.1541", "submitter": "Jaydip Sen", "authors": "Jaydip Sen", "title": "An Analysis of Routing Disruption Attack on Dynamic Source Routing\n  Protocol", "comments": "This paper is withdrawn since the results of simulations presented\n  are found to erroneous under certain network topologies. We have corrected\n  the mathematical model and have submitted the corrected version to a\n  journal.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Source Routing (DSR) is a well known source routing protocol for ad\nhoc networks. The algorithm depends on the cooperative participation of the\nnodes that enables route discovery from a source node to a destination node.\nHowever, if a group of nodes do not cooperate, the performance of the DSR\nprotocol may be severely degraded. This paper presents a probabilistic attack\nmodel on the DSR protocol and analyses its effect on the routing performance.\nSimulations results of the model show that the effect of the attack is\ncatastrophic only if a large number of nodes are compromised and there is no\ndetection mechanism. As an interesting observation, the analysis also shows\nthat the attack model can also be used to improve the performance of the DSR\nprotocol.\n", "versions": [{"version": "v1", "created": "Sun, 8 May 2011 18:31:04 GMT"}, {"version": "v2", "created": "Thu, 9 Jun 2011 15:26:30 GMT"}], "update_date": "2012-09-09", "authors_parsed": [["Sen", "Jaydip", ""]]}, {"id": "1105.1572", "submitter": "Jaydip Sen", "authors": "Jaydip Sen, Piyali Roy Chowdhury, and Indranil Sengupta", "title": "Some Aspects of Quantum Cryptography and Network Security", "comments": "This was withdrawn because the key distribution figures Figure 1 and\n  3 in the paper are technically incorrect", "journal-ref": "International Journal HIT Transaction on ECCN (Electronics,\n  Communication, Computers and Networking), pp. 27-36. Volume 1, No: 1, January\n  2006", "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum mechanics is the current best description of the world as we know it.\nExperiments have shown that quantum predictions are accurate up ten places of\ndecimal. In quantum cryptography much work has been devoted to the study of\nQuantum Key Distribution (QKD). The purpose of QKD is to securely distribute\nsecret keys between the users in a network. As a result, several quantum\ncryptographic protocols have been implemented and tested after the advent of\nquantum computing. In this paper, we have given a brief overview of QKD, and\nsome practical networks that integrate QKD in the current Internet security\narchitecture. We have also discussed some aspects of quantum network security\nwith particular attention to Byzantine Agreement Protocol.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2011 02:57:06 GMT"}, {"version": "v2", "created": "Wed, 1 Jun 2011 19:01:43 GMT"}], "update_date": "2012-09-09", "authors_parsed": [["Sen", "Jaydip", ""], ["Chowdhury", "Piyali Roy", ""], ["Sengupta", "Indranil", ""]]}, {"id": "1105.1601", "submitter": "Julien Bringer", "authors": "Julien Bringer and Herv\\'e Chabanne", "title": "Code Reverse Engineering problem for Identification Codes", "comments": "submitted to IEEE Transactions on Information Theory on January,\n  25th, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At ITW'10, Bringer et al. suggest to strengthen their previous identification\nprotocol by extending the Code Reverse Engineering (CRE) problem to\nidentification codes. We first extend security results by Tillich et al. on\nthis very problem. We then prove the security of this protocol using\ninformation theoretical arguments.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2011 08:47:11 GMT"}, {"version": "v2", "created": "Tue, 10 May 2011 07:57:31 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Bringer", "Julien", ""], ["Chabanne", "Herv\u00e9", ""]]}, {"id": "1105.1720", "submitter": "Wajeb Gharibi", "authors": "Wajeb Gharibi, Abdulrahman Mirza", "title": "Software Vulnerabilities, Banking Threats, Botnets and Malware\n  Self-Protection Technologies", "comments": "5 pages", "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 8,\n  Issue 1, January 2011, 236-241", "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information security is the protection of information from a wide range of\nthreats in order to ensure success business continuity by minimizing risks and\nmaximizing the return of investments and business opportunities. In this paper,\nwe study and discuss the software vulnerabilities, banking threats, botnets and\npropose the malware self-protection technologies.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2011 16:36:51 GMT"}], "update_date": "2011-05-10", "authors_parsed": [["Gharibi", "Wajeb", ""], ["Mirza", "Abdulrahman", ""]]}, {"id": "1105.1846", "submitter": "Piotr Bania", "authors": "Piotr Bania", "title": "Securing The Kernel via Static Binary Rewriting and Program Shepherding", "comments": "10 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent Microsoft security bulletins show that kernel vulnerabilities are\nbecoming more and more important security threats. Despite the pretty extensive\nsecurity mitigations many of the kernel vulnerabilities are still exploitable.\nSuccessful kernel exploitation typically grants the attacker maximum privilege\nlevel and results in total machine compromise.\n  To protect against kernel exploitation, we have developed a tool which\nstatically rewrites the Microsoft Windows kernel as well as other kernel level\nmodules. Such rewritten binary files allow us to monitor control flow transfers\nduring operating system execution. At this point we are able to detect whether\nselected control transfer flow is valid or should be considered as an attack\nattempt. Our solution is especially directed towards preventing remote kernel\nexploitation attempts. Additionally, many of the local privilege escalation\nattacks are also blocked (also due to additional mitigation techniques we have\nimplemented). Our tool was tested with Microsoft Windows XP, Windows Vista and\nWindows 7 (under both virtual and physical machines) on IA-32 compatible\nprocessors. Our apparatus is also completely standalone and does not require\nany third party software.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2011 02:54:03 GMT"}], "update_date": "2011-05-11", "authors_parsed": [["Bania", "Piotr", ""]]}, {"id": "1105.1945", "submitter": "Reza Keyvan", "authors": "MohammadReza Keyvanpour (Department of Computer Engineering Al-Zahra\n  University), Somayyeh Seifi Moradi (Department of Computer Engineering\n  Islamic Azad University)", "title": "Classification and Evaluation the Privacy Preserving Data Mining\n  Techniques by using a Data Modification-based Framework", "comments": null, "journal-ref": "International Journal on Computer Science and Engineering\n  (IJCSE)Vol. 3 No. 2 Feb 2011", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the data mining techniques have met a serious challenge due\nto the increased concerning and worries of the privacy, that is, protecting the\nprivacy of the critical and sensitive data. Different techniques and algorithms\nhave been already presented for Privacy Preserving data mining, which could be\nclassified in three common approaches: Data modification approach, Data\nsanitization approach and Secure Multi-party Computation approach. This paper\npresents a Data modification- based Framework for classification and evaluation\nof the privacy preserving data mining techniques. Based on our framework the\ntechniques are divided into two major groups, namely perturbation approach and\nanonymization approach. Also in proposed framework, eight functional criteria\nwill be used to analyze and analogically assessment of the techniques in these\ntwo major groups. The proposed framework provides a good basis for more\naccurate comparison of the given techniques to privacy preserving data mining.\nIn addition, this framework allows recognizing the overlapping amount for\ndifferent approaches and identifying modern approaches in this field.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2011 13:50:18 GMT"}], "update_date": "2011-05-11", "authors_parsed": [["Keyvanpour", "MohammadReza", "", "Department of Computer Engineering Al-Zahra\n  University"], ["Moradi", "Somayyeh Seifi", "", "Department of Computer Engineering\n  Islamic Azad University"]]}, {"id": "1105.2002", "submitter": "Wajeb Gharibi", "authors": "Wajeb Gharibi, Abdulrahman Mirza", "title": "Security Risks and Modern Cyber Security Technologies for Corporate\n  Networks", "comments": "5 pages", "journal-ref": "(IJCSIS) International Journal of Computer Science and Information\n  Security, Vol. 9, No. 1, January 2011", "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article aims to highlight current trends on the market of corporate\nantivirus solutions. Brief overview of modern security threats that can destroy\nIT environment is provided as well as a typical structure and features of\nantivirus suits for corporate users presented on the market. The general\nrequirements for corporate products are determined according to the last report\nfrom av-comparatives.org [1]. The detailed analysis of new features is provided\nbased on an overview of products available on the market nowadays. At the end,\nan enumeration of modern trends in antivirus industry for corporate users\ncompletes this article. Finally, the main goal of this article is to stress an\nattention about new trends suggested by AV vendors in their solutions in order\nto protect customers against newest security threats.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2011 17:33:03 GMT"}], "update_date": "2011-05-11", "authors_parsed": [["Gharibi", "Wajeb", ""], ["Mirza", "Abdulrahman", ""]]}, {"id": "1105.2003", "submitter": "Justin Thaler", "authors": "Graham Cormode, Michael Mitzenmacher, Justin Thaler", "title": "Practical Verified Computation with Streaming Interactive Proofs", "comments": "39 pages, 12 figures, 2 tables. Accepted to ITCS 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When delegating computation to a service provider, as in cloud computing, we\nseek some reassurance that the output is correct and complete. Yet recomputing\nthe output as a check is inefficient and expensive, and it may not even be\nfeasible to store all the data locally. We are therefore interested in proof\nsystems which allow a service provider to prove the correctness of its output\nto a streaming (sublinear space) user, who cannot store the full input or\nperform the full computation herself.\n  Our approach is two-fold. First, we describe a carefully chosen instantiation\nof one of the most efficient general-purpose constructions for arbitrary\ncomputations (streaming or otherwise), due to Goldwasser, Kalai, and Rothblum.\nThis requires several new insights to make the methodology more practical. Our\nmain contribution is in achieving a prover who runs in time O(S(n) log S(n)),\nwhere S(n) is the size of an arithmetic circuit computing the function of\ninterest. Our experimental results demonstrate that a practical general-purpose\nprotocol for verifiable computation may be significantly closer to reality than\npreviously realized.\n  Second, we describe techniques that achieve genuine scalability for protocols\nfine-tuned for specific important problems in streaming and database\nprocessing. Focusing in particular on non-interactive protocols for problems\nranging from matrix-vector multiplication to bipartite perfect matching, we\nbuild on prior work to achieve a prover who runs in nearly linear-time, while\nobtaining optimal tradeoffs between communication cost and the user's working\nmemory. Existing techniques required (substantially) superlinear time for the\nprover. We argue that even if general-purpose methods improve, fine-tuned\nprotocols will remain valuable in real-world settings for key problems, and\nhence special attention to specific problems is warranted.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2011 17:34:25 GMT"}, {"version": "v2", "created": "Tue, 31 May 2011 18:17:03 GMT"}, {"version": "v3", "created": "Fri, 12 Aug 2011 15:20:31 GMT"}, {"version": "v4", "created": "Fri, 25 Nov 2011 22:14:11 GMT"}, {"version": "v5", "created": "Mon, 13 Feb 2012 02:36:57 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Cormode", "Graham", ""], ["Mitzenmacher", "Michael", ""], ["Thaler", "Justin", ""]]}, {"id": "1105.3237", "submitter": "William Lorimer", "authors": "William R. Lorimer", "title": "Double Blind Comparisons using Groups with Infeasible Inversion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Double Blind Comparison is a new cryptographic primitive that allows a user\nwho is in possession of a ciphertext to determine if the corresponding\nplaintext is identical to the plaintext for a different ciphertext held by a\ndifferent user, but only if both users co-operate. Neither user knows anything\nabout the plaintexts corresponding to either ciphertext, and neither user\nlearns anything about the plaintexts as a result of the comparison, other than\nwhether the two plaintexts are identical. Neither user can determine whether\nthe plaintexts are equal without the other user's co-operation. Double Blind\nComparisons have potential application in Anonymous Credentials and the\nDatabase Aggregation Problem. This paper shows how Double Blind Comparisons can\nbe implemented using a Strong Associative One-Way Function (SAOWF). Proof of\nsecurity is given, making an additional assumption that the SAOWF is\nimplemented on a Group with Infeasible Inversion (GII), whose existence was\npostulated by Hohenberger and Molnar.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2011 22:37:02 GMT"}], "update_date": "2011-05-18", "authors_parsed": [["Lorimer", "William R.", ""]]}, {"id": "1105.3239", "submitter": "William Lorimer", "authors": "William R. Lorimer", "title": "Double Blind Comparisons: A New Approach to the Database Aggregation\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Data Aggregation Problem occurs when a large collection of data takes on\na higher security level than any of its individual component records.\nTraditional approaches of breaking up the data and restricting access on a\n\"need to know\" basis take away one of the great advantages of collecting the\ndata in the first place. This paper introduces a new cryptographic primitive,\nDouble Blind Comparisons, which allows two co-operating users, who each have an\nencrypted secret, to determine the equality or inequality of those two secrets,\neven though neither user can discover any information about what the secret is.\nThis paper also introduces a new problem in bilinear groups, conjectured to be\na hard problem. Assuming this conjecture, it is shown that neither user can\ndiscover any information about whether the secrets are equal, without the other\nuser's co-operation. We then look at how Double Blind Comparisons can be used\nto mitigate the Data Aggregation Problem. Finally, the paper concludes with\nsome suggested possibilities for future research and some other potential uses\nfor Double Blind Comparisons.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2011 22:41:22 GMT"}], "update_date": "2011-05-18", "authors_parsed": [["Lorimer", "William R.", ""]]}, {"id": "1105.3388", "submitter": "Tran Ngoc Duong", "authors": "Alice Nguyenova-Stepanikova and Tran Ngoc Duong", "title": "The block cipher NSABC (public domain)", "comments": "22 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce NSABC/w -- Nice-Structured Algebraic Block Cipher using w-bit\nword arithmetic, a 4w-bit analogous of Skipjack [NSA98] with 5w-bit key. The\nSkipjack's internal 4-round Feistel structure is replaced with a w-bit, 2-round\ncascade of a binary operation (x,z)\\mapsto(x\\boxdot z)\\lll(w/2) that permutes a\ntext word x under control of a key word z. The operation \\boxdot, similarly to\nthe multiplication in IDEA [LM91, LMM91], bases on an algebraic group over\nw-bit words, so it is also capable of decrypting by means of the inverse\nelement of z in the group. The cipher utilizes a secret 4w-bit tweak -- an\neasily changeable parameter with unique value for each block encrypted under\nthe same key [LRW02] -- that is derived from the block index and an additional\n4w -bit key. A software implementation for w=64 takes circa 9 clock cycles per\nbyte on x86-64 processors.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2011 14:16:18 GMT"}], "update_date": "2011-05-18", "authors_parsed": [["Nguyenova-Stepanikova", "Alice", ""], ["Duong", "Tran Ngoc", ""]]}, {"id": "1105.3671", "submitter": "Michal Kryczka", "authors": "Michal Kryczka, Ruben Cuevas, Roberto Gonzalez, Angel Cuevas, Arturo\n  Azcorra", "title": "TorrentGuard: stopping scam and malware distribution in the BitTorrent\n  ecosystem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we conduct a large scale measurement study in order to analyse\nthe fake content publishing phenomenon in the BitTorrent Ecosystem. Our results\nreveal that fake content represents an important portion (35%) of those files\nshared in BitTorrent and just a few tens of users are responsible for 90% of\nthis content. Furthermore, more than 99% of the analysed fake files are linked\nto either malware or scam websites. This creates a serious threat for the\nBitTorrent ecosystem. To address this issue, we present a new detection tool\nnamed TorrentGuard for the early detection of fake content. Based on our\nevaluation this tool may prevent the download of more than 35 millions of fake\nfiles per year. This could help to reduce the number of computer infections and\nscams suffered by BitTorrent users. TorrentGuard is already available and it\ncan be accessed through both a webpage or a Vuze plugin.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2011 15:56:24 GMT"}, {"version": "v2", "created": "Thu, 22 Sep 2011 11:18:11 GMT"}, {"version": "v3", "created": "Thu, 19 Apr 2012 21:28:21 GMT"}], "update_date": "2012-04-23", "authors_parsed": [["Kryczka", "Michal", ""], ["Cuevas", "Ruben", ""], ["Gonzalez", "Roberto", ""], ["Cuevas", "Angel", ""], ["Azcorra", "Arturo", ""]]}, {"id": "1105.3716", "submitter": "Marco Valerio Barbera", "authors": "Marco Valerio Barbera and Alessandro Mei", "title": "Personal Marks and Community Certificates: Detecting Clones in Mobile\n  Wireless Networks of Smart-Phones", "comments": "12 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of detecting clones in wireless mobile adhoc\nnetworks. We assume that one of the devices of the network has been cloned.\nEverything, including certificates and secret keys. This can happen quite\neasily, because of a virus that immediately after sending all the content of\nthe infected device to the adversary destroys itself, or just because the owner\nhas left his device unattended for a few minutes in a hostile environment. The\nproblem is to detect this attack. We propose a solution in networks of mobile\ndevices carried by individuals. These networks are composed by nodes that have\nthe capability of using short-range communication technology like blue-tooth or\nWi-Fi, where nodes are carried by mobile users, and where links appear and\ndisappear according to the social relationships between the users. Our idea is\nto use social physical contacts, securely collected by wireless personal\nsmart-phones, as a biometric way to authenticate the legitimate owner of the\ndevice and detect the clone attack. We introduce two mechanisms: Personal Marks\nand Community Certificates. Personal Marks is a simple cryptographic protocol\nthat works very well when the adversary is an insider, a malicious node in the\nnetwork that is part, or not very far, from the social community of the\noriginal device that has been cloned. Community Certificates work very well\nwhen the adversary is an outsider, a node that has the goal of using the stolen\ncredentials when interacting with other nodes that are far in the social\nnetwork from the original device. When combined, these mechanisms provide an\nexcellent protection against this very strong attack. We prove our ideas and\nsolutions with extensive simulations in a real world scenario-with mobility\ntraces collected in a real life experiment\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2011 19:09:04 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Barbera", "Marco Valerio", ""], ["Mei", "Alessandro", ""]]}, {"id": "1105.3790", "submitter": "Jun-Chao Lu", "authors": "Jun-Chao Lu, Yu-Yi Chen, Zhen-Jie Qiu, Jinn-Ke Jan", "title": "A Secure RFID Deactivation/Activation Mechanism for Supporting Customer\n  Service and Consumer Shopping", "comments": "submitting to computer communication (COMCOM) at 2010.12.28", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RFID has been regarded as a time and money-saving solution for a wide variety\nof applications, such as manufacturing, supply chain management, and inventory\ncontrol, etc. However, there are some security problems on RFID in the product\nmanagements. The most concerned issues are the tracking and the location\nprivacy. Numerous scholars tried to solve these problems, but their proposals\ndo not include the after-sales service. In this paper, we propose a purchase\nand after-sales service RFID scheme for shopping mall. The location privacy,\nconfidentiality, data integrity, and some security protection are hold in this\npropose mechanism.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2011 05:13:32 GMT"}], "update_date": "2011-05-20", "authors_parsed": [["Lu", "Jun-Chao", ""], ["Chen", "Yu-Yi", ""], ["Qiu", "Zhen-Jie", ""], ["Jan", "Jinn-Ke", ""]]}, {"id": "1105.3879", "submitter": "Jean-Pierre Flori", "authors": "Herv\\'e Chabanne and G\\'erard Cohen and Jean-Pierre Flori and Alain\n  Patey", "title": "Non-Malleable Codes from the Wire-Tap Channel", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Dziembowski et al. introduced the notion of non-malleable codes\n(NMC), inspired from the notion of non-malleability in cryptography and the\nwork of Gennaro et al. in 2004 on tamper proof security. Informally, when using\nNMC, if an attacker modifies a codeword, decoding this modified codeword will\nreturn either the original message or a completely unrelated value.\n  The definition of NMC is related to a family of modifications authorized to\nthe attacker. In their paper, Dziembowski et al. propose a construction valid\nfor the family of all bit-wise independent functions.\n  In this article, we study the link between the second version of the Wire-Tap\n(WT) Channel, introduced by Ozarow and Wyner in 1984, and NMC. Using\ncoset-coding, we describe a new construction for NMC w.r.t. a subset of the\nfamily of bit-wise independent functions. Our scheme is easier to build and\nmore efficient than the one proposed by Dziembowski et al.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2011 14:07:26 GMT"}], "update_date": "2011-05-20", "authors_parsed": [["Chabanne", "Herv\u00e9", ""], ["Cohen", "G\u00e9rard", ""], ["Flori", "Jean-Pierre", ""], ["Patey", "Alain", ""]]}, {"id": "1105.4125", "submitter": "Olga Ohrimenko", "authors": "Michael T. Goodrich, Michael Mitzenmacher, Olga Ohrimenko, Roberto\n  Tamassia", "title": "Privacy-Preserving Group Data Access via Stateless Oblivious RAM\n  Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of providing privacy-preserving access to an outsourced\nhonest-but-curious data repository for a group of trusted users. We show that\nsuch privacy-preserving data access is possible using a combination of\nprobabilistic encryption, which directly hides data values, and stateless\noblivious RAM simulation, which hides the pattern of data accesses. We give\nsimulations that have only an $O(\\log n)$ amortized time overhead for\nsimulating a RAM algorithm, $\\cal A$, that has a memory of size $n$, using a\nscheme that is data-oblivious with very high probability assuming the\nsimulation has access to a private workspace of size $O(n^\\nu)$, for any given\nfixed constant $\\nu>0$. This simulation makes use of pseudorandom hash\nfunctions and is based on a novel hierarchy of cuckoo hash tables that all\nshare a common stash. We also provide results from an experimental simulation\nof this scheme, showing its practicality. In addition, in a result that may be\nof some theoretical interest, we also show that one can eliminate the\ndependence on pseudorandom hash functions in our simulation while having the\noverhead rise to be $O(\\log^2 n)$.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2011 16:32:19 GMT"}], "update_date": "2011-05-23", "authors_parsed": [["Goodrich", "Michael T.", ""], ["Mitzenmacher", "Michael", ""], ["Ohrimenko", "Olga", ""], ["Tamassia", "Roberto", ""]]}, {"id": "1105.4254", "submitter": "Ashwin Machanavajjhala", "authors": "Ashwin Machanavajjhala (Yahoo! Research), Aleksandra Korolova\n  (Stanford University), Atish Das Sarma (Google)", "title": "Personalized Social Recommendations - Accurate or Private?", "comments": "VLDB2011", "journal-ref": "Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 7, pp.\n  440-450 (2011)", "doi": null, "report-no": null, "categories": "cs.DB cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent surge of social networks like Facebook, new forms of\nrecommendations have become possible - personalized recommendations of ads,\ncontent, and even new friend and product connections based on one's social\ninteractions. Since recommendations may use sensitive social information, it is\nspeculated that these recommendations are associated with privacy risks. The\nmain contribution of this work is in formalizing these expected trade-offs\nbetween the accuracy and privacy of personalized social recommendations.\n  In this paper, we study whether \"social recommendations\", or recommendations\nthat are solely based on a user's social network, can be made without\ndisclosing sensitive links in the social graph. More precisely, we quantify the\nloss in utility when existing recommendation algorithms are modified to satisfy\na strong notion of privacy, called differential privacy. We prove lower bounds\non the minimum loss in utility for any recommendation algorithm that is\ndifferentially private. We adapt two privacy preserving algorithms from the\ndifferential privacy literature to the problem of social recommendations, and\nanalyze their performance in comparison to the lower bounds, both analytically\nand experimentally. We show that good private social recommendations are\nfeasible only for a small subset of the users in the social network or for a\nlenient setting of privacy parameters.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2011 12:09:04 GMT"}], "update_date": "2011-05-24", "authors_parsed": [["Machanavajjhala", "Ashwin", "", "Yahoo! Research"], ["Korolova", "Aleksandra", "", "Stanford University"], ["Sarma", "Atish Das", "", "Google"]]}, {"id": "1105.4514", "submitter": "Elena Dubrova", "authors": "Elena Dubrova", "title": "Synthesis of Parallel Binary Machines", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary machines are a generalization of Feedback Shift Registers (FSRs) in\nwhich both, feedback and feedforward, connections are allowed and no chain\nconnection between the register stages is required. In this paper, we present\nan algorithm for synthesis of binary machines with the minimum number of stages\nfor a given degree of parallelization. Our experimental results show that for\nsequences with high linear complexity such as complementary, Legendre, or truly\nrandom, parallel binary machines are an order of magnitude smaller than\nparallel FSRs generating the same sequence. The presented approach can\npotentially be of advantage for any application which requires sequences with\nhigh spectrum efficiency or high security, such as data transmission, wireless\ncommunications, and cryptography.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2011 14:40:01 GMT"}], "update_date": "2011-05-24", "authors_parsed": [["Dubrova", "Elena", ""]]}, {"id": "1105.4936", "submitter": "Mircea Andrecut Dr", "authors": "M. Andrecut", "title": "Sparse Random Approximation and Lossy Compression", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss a method for sparse signal approximation, which is based on the\ncorrelation of the target signal with a pseudo-random signal, and uses a\nmodification of the greedy matching pursuit algorithm. We show that this\napproach provides an efficient encoding-decoding method, which can be used also\nfor lossy compression and encryption purposes.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2011 05:01:58 GMT"}], "update_date": "2011-05-26", "authors_parsed": [["Andrecut", "M.", ""]]}, {"id": "1105.4991", "submitter": "Katerina Argyraki", "authors": "Iris Safaka, Mahdi J. Siavoshani, Uday Pulleti, Emre Atsan, Christina\n  Fragouli, Katerina Argyraki, Suhas Diggavi", "title": "Exchanging Secrets without Using Cryptography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem where a group of n nodes, connected to the same\nbroadcast channel (e.g., a wireless network), want to generate a common secret\nbitstream, in the presence of an adversary Eve, who tries to obtain information\non the bitstream. We assume that the nodes initially share a (small) piece of\ninformation, but do not have access to any out-of-band channel. We ask the\nquestion: can this problem be solved without relying on Eve's computational\nlimitations, i.e., without using any form of public-key cryptography?\n  We propose a secret-agreement protocol, where the n nodes of the group keep\nexchanging bits until they have all agreed on a bit sequence that Eve cannot\nreconstruct with very high probability. In this task, the nodes are assisted by\na small number of interferers, whose role is to create channel noise in a way\nthat bounds the amount of information Eve can overhear. Our protocol has\npolynomial-time complexity and requires no changes to the physical or MAC layer\nof network devices.\n  First, we formally show that, under standard theoretical assumptions, our\nprotocol is information-theoretically secure, achieves optimal\nsecret-generation rate for n = 2 nodes, and scales well to an arbitrary number\nof nodes. Second, we adapt our protocol to a small wireless 14-square-meter\ntestbed; we experimentally show that, if Eve uses a standard wireless physical\nlayer and is not too close to any of the nodes, 8 nodes can achieve a\nsecret-generation rate of 38 Kbps. To the best of our knowledge, ours is the\nfirst experimental demonstration of information-theoretic secret exchange on a\nwireless network at a rate beyond a few tens of bits per second.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2011 10:50:19 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2012 17:56:02 GMT"}], "update_date": "2012-10-26", "authors_parsed": [["Safaka", "Iris", ""], ["Siavoshani", "Mahdi J.", ""], ["Pulleti", "Uday", ""], ["Atsan", "Emre", ""], ["Fragouli", "Christina", ""], ["Argyraki", "Katerina", ""], ["Diggavi", "Suhas", ""]]}, {"id": "1105.5282", "submitter": "Santiago Escobar", "authors": "Santiago Escobar and Catherine Meadows and Jose Meseguer", "title": "State Space Reduction in the Maude-NRL Protocol Analyzer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Maude-NRL Protocol Analyzer (Maude-NPA) is a tool and inference system\nfor reasoning about the security of cryptographic protocols in which the\ncryptosystems satisfy different equational properties. It both extends and\nprovides a formal framework for the original NRL Protocol Analyzer, which\nsupported equational reasoning in a more limited way. Maude-NPA supports a wide\nvariety of algebraic properties that includes many crypto-systems of interest\nsuch as, for example, one-time pads and Diffie-Hellman. Maude-NPA, like the\noriginal NPA, looks for attacks by searching backwards from an insecure attack\nstate, and assumes an unbounded number of sessions. Because of the unbounded\nnumber of sessions and the support for different equational theories, it is\nnecessary to develop ways of reducing the search space and avoiding infinite\nsearch paths. In order for the techniques to prove useful, they need not only\nto speed up the search, but should not violate completeness, so that failure to\nfind attacks still guarantees security. In this paper we describe some state\nspace reduction techniques that we have implemented in Maude-NPA. We also\nprovide completeness proofs, and experimental evaluations of their effect on\nthe performance of Maude-NPA.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2011 13:22:19 GMT"}], "update_date": "2011-05-30", "authors_parsed": [["Escobar", "Santiago", ""], ["Meadows", "Catherine", ""], ["Meseguer", "Jose", ""]]}, {"id": "1105.5346", "submitter": "Joshua Brandon Holden", "authors": "Joshua Holden, Margaret M. Robinson", "title": "Counting Fixed Points, Two-Cycles, and Collisions of the Discrete\n  Exponential Function using p-adic Methods", "comments": "14 pages, no figures", "journal-ref": "Journal of the Australian Mathematical Society, 92: 163-178, 2012", "doi": "10.1017/S1446788712000262", "report-no": null, "categories": "math.NT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brizolis asked for which primes p greater than 3 does there exist a pair (g,\nh) such that h is a fixed point of the discrete exponential map with base g, or\nequivalently h is a fixed point of the discrete logarithm with base g. Zhang\n(1995) and Cobeli and Zaharescu (1999) answered with a \"yes\" for sufficiently\nlarge primes and gave estimates for the number of such pairs when g and h are\nprimitive roots modulo p. In 2000, Campbell showed that the answer to Brizolis\nwas \"yes\" for all primes. The first author has extended this question to\nquestions about counting fixed points, two-cycles, and collisions of the\ndiscrete exponential map. In this paper, we use p-adic methods, primarily\nHensel's lemma and p-adic interpolation, to count fixed points, two cycles,\ncollisions, and solutions to related equations modulo powers of a prime p.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2011 16:46:57 GMT"}], "update_date": "2012-12-04", "authors_parsed": [["Holden", "Joshua", ""], ["Robinson", "Margaret M.", ""]]}, {"id": "1105.5681", "submitter": "Rahul Mukerjee", "authors": "Mausumi Bose and Rahul Mukerjee", "title": "Improving Anonymity in Shared Key Primitives Based on Perfect Hash\n  Families", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new scheme for sharing symmetric key operations among a set of\nparticipants according to a (t,n) threshold access structure. We focus on\nanonymity properties of this scheme and show that this scheme provides improved\nvalues of anonymity measures than the existing ones. In particular, the scheme\ncan provide optimal and equitable participant anonymity when it is based on\nbalanced perfect hash families.\n", "versions": [{"version": "v1", "created": "Sat, 28 May 2011 03:45:29 GMT"}], "update_date": "2011-05-31", "authors_parsed": [["Bose", "Mausumi", ""], ["Mukerjee", "Rahul", ""]]}, {"id": "1105.5803", "submitter": "Philip Stark", "authors": "Josh Benaloh, Douglas Jones, Eric Lazarus, Mark Lindeman, and Philip\n  B. Stark", "title": "SOBA: Secrecy-preserving Observable Ballot-level Audit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SOBA is an approach to election verification that provides observers with\njustifiably high confidence that the reported results of an election are\nconsistent with an audit trail (\"ballots\"), which can be paper or electronic.\nSOBA combines three ideas: (1) publishing cast vote records (CVRs) separately\nfor each contest, so that anyone can verify that each reported contest outcome\nis correct, if the CVRs reflect voters' intentions with sufficient accuracy;\n(2) shrouding a mapping between ballots and the CVRs for those ballots to\nprevent the loss of privacy that could occur otherwise; (3) assessing the\naccuracy with which the CVRs reflect voters' intentions for a collection of\ncontests while simultaneously assessing the integrity of the shrouded mapping\nbetween ballots and CVRs by comparing randomly selected ballots to the CVRs\nthat purport to represent them. Step (1) is related to work by the Humboldt\nCounty Election Transparency Project, but publishing CVRs separately for\nindividual contests rather than images of entire ballots preserves privacy.\nStep (2) requires a cryptographic commitment from elections officials.\nObservers participate in step (3), which relies on the \"super-simple\nsimultaneous single-ballot risk-limiting audit.\" Step (3) is designed to reveal\nrelatively few ballots if the shrouded mapping is proper and the CVRs\naccurately reflect voter intent. But if the reported outcomes of the contests\ndiffer from the outcomes that a full hand count would show, step (3) is\nguaranteed to have a large chance of requiring all the ballots to be counted by\nhand, thereby limiting the risk that an incorrect outcome will become official\nand final.\n", "versions": [{"version": "v1", "created": "Sun, 29 May 2011 17:00:20 GMT"}, {"version": "v2", "created": "Sat, 2 Jul 2011 21:46:34 GMT"}], "update_date": "2011-07-05", "authors_parsed": [["Benaloh", "Josh", ""], ["Jones", "Douglas", ""], ["Lazarus", "Eric", ""], ["Lindeman", "Mark", ""], ["Stark", "Philip B.", ""]]}, {"id": "1105.6163", "submitter": "Vinod M. Prabhakaran", "authors": "Vinod M. Prabhakaran and Manoj M. Prabhakaran", "title": "Assisted Common Information: Further Results", "comments": "8 pages, 3 figures, 1 appendix; to be presented at the IEEE\n  International Symposium on Information Theory, 2011", "journal-ref": null, "doi": "10.1109/ISIT.2011.6034098", "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We presented assisted common information as a generalization of\nG\\'acs-K\\\"orner (GK) common information at ISIT 2010. The motivation for our\nformulation was to improve upperbounds on the efficiency of protocols for\nsecure two-party sampling (which is a form of secure multi-party computation).\nOur upperbound was based on a monotonicity property of a rate-region (called\nthe assisted residual information region) associated with the assisted common\ninformation formulation. In this note we present further results. We explore\nthe connection of assisted common information with the Gray-Wyner system. We\nshow that the assisted residual information region and the Gray-Wyner region\nare connected by a simple relationship: the assisted residual information\nregion is the increasing hull of the Gray-Wyner region under an affine map.\nSeveral known relationships between GK common information and Gray-Wyner system\nfall out as consequences of this. Quantities which arise in other source coding\ncontexts acquire new interpretations. In previous work we showed that assisted\ncommon information can be used to derive upperbounds on the rate at which a\npair of parties can {\\em securely sample} correlated random variables, given\ncorrelated random variables from another distribution. Here we present an\nexample where the bound derived using assisted common information is much\nbetter than previously known bounds, and in fact is tight. This example\nconsiders correlated random variables defined in terms of standard variants of\noblivious transfer, and is interesting on its own as it answers a natural\nquestion about these cryptographic primitives.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2011 05:26:17 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Prabhakaran", "Vinod M.", ""], ["Prabhakaran", "Manoj M.", ""]]}, {"id": "1105.6320", "submitter": "Mohit Kohli", "authors": "Mohit Kohli", "title": "Transformation from Identity Stone Age to Digital Identity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Technological conversion, political interests and Business drivers has\ntriggered a means, to establish individual characterization and\npersonalization. People started raising concerns on multiple identities managed\nacross various zones and hence various solutions were designed. Technological\nadvancement has brought various issues and concerns around Identity assurance,\nprivacy and policy enabled common Authentication framework. A compressive\nframework is needed to established common identity model to address national\nneeds like standards, regulation and laws, minimum risk, interoperability and\nto provide user with a consistent context or user experience.\n  This document focuses on Transformation path of identity stone age to\nIdentity as in state. It defines a digital identity zone model (DIZM) to\nshowcase the Global Identity defined across the ecosystem. Also, provide\ninsight of emerging Technology trend to enable Identity assurance, privacy and\npolicy enabled common Authentication framework.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2011 15:49:14 GMT"}], "update_date": "2011-06-01", "authors_parsed": [["Kohli", "Mohit", ""]]}]