[{"id": "1701.00104", "submitter": "Theodosios Mourouzis", "authors": "Theodosis Mourouzis, Marcin Wojcik, Nikos Komninos", "title": "On The Security Evaluation of Partial Password Implementations", "comments": "14 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A partial password is a mode of password-based authentication that is widely\nused, especially in the financial sector. It is based on a challenge-response\nprotocol, where at each login attempt, a challenge requesting characters from\nrandomly selected positions of a pre-shared secret is presented to the user.\nThis model could be seen as a cheap way of preventing for example a malware or\na key-logger installed on a user's device to learn the full password in a\nsingle step. Despite of the widespread adoption of this mechanism, especially\nby many UK banks, there is limited material in the open literature. Questions\nlike how the security of the scheme varies with the sampling method employed to\nform the challenges or what are the existing server-side implementations are\nleft unaddressed. In this paper, we study questions like how the security of\nthis mechanism varies in relation to the number of challenge-response pairs\navailable to an attacker under different ways of generating challenges. In\naddition, we discuss possible server-side implementations as \"unofficially\"\nlisted in different online forums by information security ex- perts. To the\nbest of our knowledge there is no formal academic literature in this direction\nand one of the aims of this paper is to motivate other researchers to study\nthis topic.\n", "versions": [{"version": "v1", "created": "Sat, 31 Dec 2016 13:57:17 GMT"}], "update_date": "2017-01-03", "authors_parsed": [["Mourouzis", "Theodosis", ""], ["Wojcik", "Marcin", ""], ["Komninos", "Nikos", ""]]}, {"id": "1701.00159", "submitter": "Maleh Yassine", "authors": "Yassine Maleh, Abdellah Ezzati", "title": "Study and Development of a New Symmetric Key Management Scheme for\n  Wireless Sensor Networks", "comments": "6 pages, 5 figures, Advanced Information Technology, Services and\n  Systems (AIT2S) Conference 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless Sensor Network (WSN) is consisting of independent and distributed\nsensors to monitor physical or environmental conditions, such as temperature,\nsound, pressure, etc. However, the limited resources of sensors and hostile\nenvironments in which they could be deployed, make this type of networks\nvulnerable to several types of attacks similar to those occurring in ad hoc\nnetworks. The most crucial and fundamental challenge that WSN is facing is\nsecurity. The primary subject of all my work is to address this issue. Due to\nminimum capacity in term of memory cost, processing and physical accessibility\nto sensors devices the security attacks are problematic. They are mostly\ndeployed in open area so are more exposed to different kinds of attacks. They\nmust be designed in a way to successfully recover itself from different kinds\nof attacks. In this paper, we proposed a new lightweight cryptography algorithm\nbased on LEAP+. Our evaluations on TOSSIM give a precise and detailed idea of\nthe extra cost of consumption of resources needed to ensure the high level of\nexpected security.\n", "versions": [{"version": "v1", "created": "Sat, 31 Dec 2016 18:42:55 GMT"}], "update_date": "2017-01-03", "authors_parsed": [["Maleh", "Yassine", ""], ["Ezzati", "Abdellah", ""]]}, {"id": "1701.00220", "submitter": "Asaf Shabtai", "authors": "Andrey Finkelstein, Ron Biton, Rami Puzis, Asaf Shabtai", "title": "Classification of Smartphone Users Using Internet Traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, smartphone devices are owned by a large portion of the population and\nhave become a very popular platform for accessing the Internet. Smartphones\nprovide the user with immediate access to information and services. However,\nthey can easily expose the user to many privacy risks. Applications that are\ninstalled on the device and entities with access to the device's Internet\ntraffic can reveal private information about the smartphone user and steal\nsensitive content stored on the device or transmitted by the device over the\nInternet. In this paper, we present a method to reveal various demographics and\ntechnical computer skills of smartphone users by their Internet traffic\nrecords, using machine learning classification models. We implement and\nevaluate the method on real life data of smartphone users and show that\nsmartphone users can be classified by their gender, smoking habits, software\nprogramming experience, and other characteristics.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jan 2017 08:12:49 GMT"}], "update_date": "2017-01-03", "authors_parsed": [["Finkelstein", "Andrey", ""], ["Biton", "Ron", ""], ["Puzis", "Rami", ""], ["Shabtai", "Asaf", ""]]}, {"id": "1701.00401", "submitter": "Yassine Maleh", "authors": "Yassine Maleh (LAVETE), Abdellah Ezzati (LAVETE)", "title": "Study and Development of a Symmetric protocol to secure communications\n  in WSN", "comments": "in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless Sensor Network (WSN) is consisting of independent and distributed\nsensors to monitor physical or environmental conditions, such as temperature,\nsound, pressure, etc. The most crucial and fundamental challenge facing WSN is\nsecurity. Due to minimum capacity in-term of memory cost, processing and\nphysical accessibility to sensors devices the security attacks are problematic.\nThey are mostly deployed in open area, which expose them to different kinds of\nattacks. In this paper, we present an illustration of different attacks and\nvulnerabilities in WSN. Then we proposed a new lightweight cryptography\nalgorithm for identifying compromised node in WSN called Leap Enhanced. Our\nevaluations on TOSSIM give a precise and detailed idea of the extra cost of\nconsumption of resources needed to ensure the high level of expected security\ncompared to other cryptography schemes in literature.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jan 2017 14:21:54 GMT"}], "update_date": "2017-01-03", "authors_parsed": [["Maleh", "Yassine", "", "LAVETE"], ["Ezzati", "Abdellah", "", "LAVETE"]]}, {"id": "1701.00436", "submitter": "David Sanchez", "authors": "David S\\'anchez and Montserrat Batet", "title": "Toward sensitive document release with privacy guarantees", "comments": null, "journal-ref": "Engineering Applications of Artificial Intelligence 59:23-34\n  (2017)", "doi": "10.1016/j.engappai.2016.12.013", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy has become a serious concern for modern Information Societies. The\nsensitive nature of much of the data that are daily exchanged or released to\nuntrusted parties requires that responsible organizations undertake appropriate\nprivacy protection measures. Nowadays, much of these data are texts (e.g.,\nemails, messages posted in social media, healthcare outcomes, etc.) that,\nbecause of their unstructured and semantic nature, constitute a challenge for\nautomatic data protection methods. In fact, textual documents are usually\nprotected manually, in a process known as document redaction or sanitization.\nTo do so, human experts identify sensitive terms (i.e., terms that may reveal\nidentities and/or confidential information) and protect them accordingly (e.g.,\nvia removal or, preferably, generalization). To relieve experts from this\nburdensome task, in a previous work we introduced the theoretical basis of\nC-sanitization, an inherently semantic privacy model that provides the basis to\nthe development of automatic document redaction/sanitization algorithms and\noffers clear and a priori privacy guarantees on data protection; even though\nits potential benefits C-sanitization still presents some limitations when\napplied to practice (mainly regarding flexibility, efficiency and accuracy). In\nthis paper, we propose a new more flexible model, named (C, g(C))-sanitization,\nwhich enables an intuitive configuration of the trade-off between the desired\nlevel of protection (i.e., controlled information disclosure) and the\npreservation of the utility of the protected data (i.e., amount of semantics to\nbe preserved). Moreover, we also present a set of technical solutions and\nalgorithms that provide an efficient and scalable implementation of the model\nand improve its practical accuracy, as we also illustrate through empirical\nexperiments.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jan 2017 16:20:18 GMT"}], "update_date": "2017-01-03", "authors_parsed": [["S\u00e1nchez", "David", ""], ["Batet", "Montserrat", ""]]}, {"id": "1701.00740", "submitter": "Javier Parra-Arnau", "authors": "Javier Parra-Arnau", "title": "Optimized, Direct Sale of Privacy in Personal-Data Marketplaces", "comments": "15 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Very recently, we are witnessing the emergence of a number of start-ups that\nenables individuals to sell their private data directly to brokers and\nbusinesses. While this new paradigm may shift the balance of power between\nindividuals and companies that harvest data, it raises some practical,\nfundamental questions for users of these services: how they should decide which\ndata must be vended and which data protected, and what a good deal is. In this\nwork, we investigate a mechanism that aims at helping users address these\nquestions. The investigated mechanism relies on a hard-privacy model and allows\nusers to share partial or complete profile data with broker companies in\nexchange for an economic reward. The theoretical analysis of the trade-off\nbetween privacy and money posed by such mechanism is the object of this work.\nWe adopt a generic measure of privacy although part of our analysis focuses on\nsome important examples of Bregman divergences. We find a parametric solution\nto the problem of optimal exchange of privacy for money, and obtain a\nclosed-form expression and characterize the trade-off between\nprofile-disclosure risk and economic reward for several interesting cases.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jan 2017 16:33:27 GMT"}], "update_date": "2017-01-04", "authors_parsed": [["Parra-Arnau", "Javier", ""]]}, {"id": "1701.00752", "submitter": "Cynthia Dwork", "authors": "John Abowd, Lorenzo Alvisi, Cynthia Dwork, Sampath Kannan, Ashwin\n  Machanavajjhala, and Jerome Reiter", "title": "Privacy-Preserving Data Analysis for the Federal Statistical Agencies", "comments": "A Computing Community Consortium (CCC) white paper, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Government statistical agencies collect enormously valuable data on the\nnation's population and business activities. Wide access to these data enables\nevidence-based policy making, supports new research that improves society,\nfacilitates training for students in data science, and provides resources for\nthe public to better understand and participate in their society. These data\nalso affect the private sector. For example, the Employment Situation in the\nUnited States, published by the Bureau of Labor Statistics, moves markets.\nNonetheless, government agencies are under increasing pressure to limit access\nto data because of a growing understanding of the threats to data privacy and\nconfidentiality.\n  \"De-identification\" - stripping obvious identifiers like names, addresses,\nand identification numbers - has been found inadequate in the face of modern\ncomputational and informational resources.\n  Unfortunately, the problem extends even to the release of aggregate data\nstatistics. This counter-intuitive phenomenon has come to be known as the\nFundamental Law of Information Recovery. It says that overly accurate estimates\nof too many statistics can completely destroy privacy. One may think of this as\ndeath by a thousand cuts. Every statistic computed from a data set leaks a\nsmall amount of information about each member of the data set - a tiny cut.\nThis is true even if the exact value of the statistic is distorted a bit in\norder to preserve privacy. But while each statistical release is an almost\nharmless little cut in terms of privacy risk for any individual, the cumulative\neffect can be to completely compromise the privacy of some individuals.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jan 2017 17:29:11 GMT"}], "update_date": "2017-01-04", "authors_parsed": [["Abowd", "John", ""], ["Alvisi", "Lorenzo", ""], ["Dwork", "Cynthia", ""], ["Kannan", "Sampath", ""], ["Machanavajjhala", "Ashwin", ""], ["Reiter", "Jerome", ""]]}, {"id": "1701.00773", "submitter": "Mark Strembeck", "authors": "Ema Ku\\v{s}en, Mark Strembeck", "title": "Security-related Research in Ubiquitous Computing -- Results of a\n  Systematic Literature Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In an endeavor to reach the vision of ubiquitous computing where users are\nable to use pervasive services without spatial and temporal constraints, we are\nwitnessing a fast growing number of mobile and sensor-enhanced devices becoming\navailable. However, in order to take full advantage of the numerous benefits\noffered by novel mobile devices and services, we must address the related\nsecurity issues. In this paper, we present results of a systematic literature\nreview (SLR) on security-related topics in ubiquitous computing environments.\nIn our study, we found 5165 scientific contributions published between 2003 and\n2015. We applied a systematic procedure to identify the threats,\nvulnerabilities, attacks, as well as corresponding defense mechanisms that are\ndiscussed in those publications. While this paper mainly discusses the results\nof our study, the corresponding SLR protocol which provides all details of the\nSLR is also publicly available for download.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jan 2017 18:56:39 GMT"}], "update_date": "2017-01-04", "authors_parsed": [["Ku\u0161en", "Ema", ""], ["Strembeck", "Mark", ""]]}, {"id": "1701.00939", "submitter": "Dmitry Krotov", "authors": "Dmitry Krotov, John J Hopfield", "title": "Dense Associative Memory is Robust to Adversarial Inputs", "comments": null, "journal-ref": "Neural Computation Volume 30, Issue 12, December 2018 p.3151-3167", "doi": "10.1162/neco_a_01143", "report-no": null, "categories": "cs.LG cs.CR cs.CV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) trained in a supervised way suffer from two known\nproblems. First, the minima of the objective function used in learning\ncorrespond to data points (also known as rubbish examples or fooling images)\nthat lack semantic similarity with the training data. Second, a clean input can\nbe changed by a small, and often imperceptible for human vision, perturbation,\nso that the resulting deformed input is misclassified by the network. These\nfindings emphasize the differences between the ways DNN and humans classify\npatterns, and raise a question of designing learning algorithms that more\naccurately mimic human perception compared to the existing methods.\n  Our paper examines these questions within the framework of Dense Associative\nMemory (DAM) models. These models are defined by the energy function, with\nhigher order (higher than quadratic) interactions between the neurons. We show\nthat in the limit when the power of the interaction vertex in the energy\nfunction is sufficiently large, these models have the following three\nproperties. First, the minima of the objective function are free from rubbish\nimages, so that each minimum is a semantically meaningful pattern. Second,\nartificial patterns poised precisely at the decision boundary look ambiguous to\nhuman subjects and share aspects of both classes that are separated by that\ndecision boundary. Third, adversarial images constructed by models with small\npower of the interaction vertex, which are equivalent to DNN with rectified\nlinear units (ReLU), fail to transfer to and fool the models with higher order\ninteractions. This opens up a possibility to use higher order models for\ndetecting and stopping malicious adversarial attacks. The presented results\nsuggest that DAM with higher order energy functions are closer to human visual\nperception than DNN with ReLUs.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jan 2017 09:40:09 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Krotov", "Dmitry", ""], ["Hopfield", "John J", ""]]}, {"id": "1701.00982", "submitter": "Gaojie Chen", "authors": "Gaojie Chen and Justin P. Coon and Marco Di Renzo", "title": "Secrecy Outage Analysis for Downlink Transmissions in the Presence of\n  Randomly Located Eavesdroppers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the secrecy outage probability in the downlink for wireless\nnetworks with spatially (Poisson) distributed eavesdroppers (EDs) under the\nassumption that the base station employs transmit antenna selection (TAS) to\nenhance secrecy performance. We compare the cases where the receiving user\nequipment (UE) operates in half-duplex (HD) mode and full-duplex (FD) mode. In\nthe latter case, the UE simultaneously receives the intended downlink message\nand transmits a jamming signal to strengthen secrecy. We investigate two models\nof (semi)passive eavesdropping: (1) EDs act independently and (2) EDs collude\nto intercept the transmitted message. For both of these models, we obtain\nexpressions for the secrecy outage probability in the downlink for HD and FD UE\noperation. The expressions for HD systems have very accurate approximate or\nexact forms in terms of elementary and/or special functions for all path loss\nexponents. Those related to the FD systems have exact integral forms for\ngeneral path loss exponents, while exact closed forms are given for specific\nexponents. A closed-form approximation is also derived for the FD case with\ncolluding EDs. The resulting analysis shows that the reduction in the secrecy\noutage probability is logarithmic in the number of antennas used for TAS and\nidentifies conditions under which HD operation should be used instead of FD\njamming at the UE. These performance trends and exact relations between system\nparameters can be used to develop adaptive power allocation and duplex\noperation methods in practice. Examples of such techniques are alluded to\nherein.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jan 2017 12:20:13 GMT"}], "update_date": "2017-01-05", "authors_parsed": [["Chen", "Gaojie", ""], ["Coon", "Justin P.", ""], ["Di Renzo", "Marco", ""]]}, {"id": "1701.01061", "submitter": "Samuel Weiser", "authors": "Samuel Weiser and Mario Werner", "title": "SGXIO: Generic Trusted I/O Path for Intel SGX", "comments": "To appear in CODASPY'16", "journal-ref": null, "doi": "10.1145/3029806.3029822", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Application security traditionally strongly relies upon security of the\nunderlying operating system. However, operating systems often fall victim to\nsoftware attacks, compromising security of applications as well. To overcome\nthis dependency, Intel introduced SGX, which allows to protect application code\nagainst a subverted or malicious OS by running it in a hardware-protected\nenclave. However, SGX lacks support for generic trusted I/O paths to protect\nuser input and output between enclaves and I/O devices.\n  This work presents SGXIO, a generic trusted path architecture for SGX,\nallowing user applications to run securely on top of an untrusted OS, while at\nthe same time supporting trusted paths to generic I/O devices. To achieve this,\nSGXIO combines the benefits of SGX's easy programming model with traditional\nhypervisor-based trusted path architectures. Moreover, SGXIO can tweak insecure\ndebug enclaves to behave like secure production enclaves. SGXIO surpasses\ntraditional use cases in cloud computing and makes SGX technology usable for\nprotecting user-centric, local applications against kernel-level keyloggers and\nlikewise. It is compatible to unmodified operating systems and works on a\nmodern commodity notebook out of the box. Hence, SGXIO is particularly\npromising for the broad x86 community to which SGX is readily available.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jan 2017 16:17:23 GMT"}], "update_date": "2017-01-05", "authors_parsed": [["Weiser", "Samuel", ""], ["Werner", "Mario", ""]]}, {"id": "1701.01093", "submitter": "Shiva Kasiviswanathan", "authors": "Shiva Prasad Kasiviswanathan, Kobbi Nissim, Hongxia Jin", "title": "Private Incremental Regression", "comments": "To appear in PODS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data is continuously generated by modern data sources, and a recent challenge\nin machine learning has been to develop techniques that perform well in an\nincremental (streaming) setting. In this paper, we investigate the problem of\nprivate machine learning, where as common in practice, the data is not given at\nonce, but rather arrives incrementally over time.\n  We introduce the problems of private incremental ERM and private incremental\nregression where the general goal is to always maintain a good empirical risk\nminimizer for the history observed under differential privacy. Our first\ncontribution is a generic transformation of private batch ERM mechanisms into\nprivate incremental ERM mechanisms, based on a simple idea of invoking the\nprivate batch ERM procedure at some regular time intervals. We take this\nconstruction as a baseline for comparison. We then provide two mechanisms for\nthe private incremental regression problem. Our first mechanism is based on\nprivately constructing a noisy incremental gradient function, which is then\nused in a modified projected gradient procedure at every timestep. This\nmechanism has an excess empirical risk of $\\approx\\sqrt{d}$, where $d$ is the\ndimensionality of the data. While from the results of [Bassily et al. 2014]\nthis bound is tight in the worst-case, we show that certain geometric\nproperties of the input and constraint set can be used to derive significantly\nbetter results for certain interesting regression problems.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jan 2017 18:18:07 GMT"}], "update_date": "2017-01-05", "authors_parsed": [["Kasiviswanathan", "Shiva Prasad", ""], ["Nissim", "Kobbi", ""], ["Jin", "Hongxia", ""]]}, {"id": "1701.01590", "submitter": "Ruohan Cao", "authors": "Ruohan Cao", "title": "Detecting Arbitrary Attacks Using Continuous Secured Side Information in\n  Wireless Networks", "comments": "arXiv admin note: substantial text overlap with arXiv:1612.01707", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on Byzantine attack detection for Gaussian two-hop one-way\nrelay network, where an amplify-and-forward relay may conduct Byzantine attacks\nby forwarding altered symbols to the destination. For facilitating attack\ndetection, we utilize the openness of wireless medium to make the destination\nobserve some secured signals that are not attacked. Then, a detection scheme is\ndeveloped for the destination by using its secured observations to\nstatistically check other observations from the relay. On the other hand,\nnotice the Gaussian channel is continuous, which allows the possible Byzantine\nattacks to be conducted within continuous alphabet(s). The existing work on\ndiscrete channel is not applicable for investigating the performance of the\nproposed scheme. The main contribution of this paper is to prove that if and\nonly if the wireless relay network satisfies a non-manipulable channel\ncondition, the proposed detection scheme achieves asymptotic errorless\nperformance against arbitrary attacks that allow the stochastic distributions\nof altered symbols to vary arbitrarily and depend on each other. No pre-shared\nsecret or secret transmission is needed for the detection. Furthermore, we also\nprove that the relay network is non-manipulable as long as all channel\ncoefficients are non-zero, which is not essential restrict for many practical\nsystems.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jan 2017 10:44:13 GMT"}, {"version": "v2", "created": "Mon, 9 Jan 2017 11:48:25 GMT"}, {"version": "v3", "created": "Fri, 4 Aug 2017 10:04:02 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Cao", "Ruohan", ""]]}, {"id": "1701.01664", "submitter": "Nicolas Mayer", "authors": "Nicolas Mayer, Jocelyn Aubert, Eric Grandry, Christophe Feltus, Elio\n  Goettelmann", "title": "An Integrated Conceptual Model for Information System Security Risk\n  Management and Enterprise Architecture Management based on TOGAF, ArchiMate,\n  IAF and DoDAF", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk management is today a major steering tool for any organization wanting\nto deal with Information System (IS) security. However, IS Security Risk\nManagement (ISSRM) remains difficult to establish and maintain, mainly in a\ncontext of multi-regulations with complex and inter-connected IS. We claim that\na connection with Enterprise Architecture Management (EAM) contributes to deal\nwith these issues. A first step towards a better integration of both domains is\nto define an integrated EAM-ISSRM conceptual model. Among the steps of the\nresearch method followed to define such an integrated EAM-ISSRM conceptual,\nthis technical report presents the whole outputs (through alignment tables) of\nthe conceptual alignment between concepts used to model EA (based on ArchiMate,\nTOGAF, IAF and DoDAF) and concepts of the ISSRM domain model.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jan 2017 15:29:45 GMT"}], "update_date": "2017-01-09", "authors_parsed": [["Mayer", "Nicolas", ""], ["Aubert", "Jocelyn", ""], ["Grandry", "Eric", ""], ["Feltus", "Christophe", ""], ["Goettelmann", "Elio", ""]]}, {"id": "1701.01900", "submitter": "Jinxue Zhang", "authors": "Jinxue Zhang", "title": "Private Social Network Data Sharing", "comments": "The experiment section needs more evaluations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing popularity of online social network brings huge privacy threat\nfor the end users. While existing work focus on inferring sensitive attributes\nfrom the social network such as age, location and gender, little has been done\non how to protect the users' privacy by preventing the malicious inference. In\nthis paper we investigated the privacy vulnerability of the existing social\nnetwork and designed a privacy-preserving framework. We evaluated the\nframework's privacy and usefulness guarantees, demonstrated its effectiveness\non classification and the defense against the privacy attack.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jan 2017 01:09:11 GMT"}, {"version": "v2", "created": "Wed, 17 May 2017 18:37:26 GMT"}, {"version": "v3", "created": "Mon, 24 Jul 2017 06:28:39 GMT"}, {"version": "v4", "created": "Wed, 26 Jul 2017 17:39:05 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Zhang", "Jinxue", ""]]}, {"id": "1701.01926", "submitter": "Cong Zhao", "authors": "Cong Zhao, Shusen Yang, Xinyu Yang, Julie McCann", "title": "Rapid, User-Transparent, and Trustworthy Device Pairing for D2D-Enabled\n  Mobile Crowdsourcing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile Crowdsourcing is a promising service paradigm utilizing ubiquitous\nmobile devices to facilitate largescale crowdsourcing tasks (e.g. urban sensing\nand collaborative computing). Many applications in this domain require\nDevice-to-Device (D2D) communications between participating devices for\ninteractive operations such as task collaborations and file transmissions.\nConsidering the private participating devices and their opportunistic\nencountering behaviors, it is highly desired to establish secure and\ntrustworthy D2D connections in a fast and autonomous way, which is vital for\nimplementing practical Mobile Crowdsourcing Systems (MCSs). In this paper, we\ndevelop an efficient scheme, Trustworthy Device Pairing (TDP), which achieves\nuser-transparent secure D2D connections and reliable peer device selections for\ntrustworthy D2D communications. Through rigorous analysis, we demonstrate the\neffectiveness and security intensity of TDP in theory. The performance of TDP\nis evaluated based on both real-world prototype experiments and extensive\ntrace-driven simulations. Evaluation results verify our theoretical analysis\nand show that TDP significantly outperforms existing approaches in terms of\npairing speed, stability, and security.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jan 2017 08:30:06 GMT"}], "update_date": "2017-01-10", "authors_parsed": [["Zhao", "Cong", ""], ["Yang", "Shusen", ""], ["Yang", "Xinyu", ""], ["McCann", "Julie", ""]]}, {"id": "1701.01927", "submitter": "Maike Massierer", "authors": "Sean Ballentine, Aurore Guillevic, Elisa Lorenzo Garc\\'ia, Chloe\n  Martindale, Maike Massierer, Benjamin Smith, Jaap Top", "title": "Isogenies for point counting on genus two hyperelliptic curves with\n  maximal real multiplication", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Schoof's classic algorithm allows point-counting for elliptic curves over\nfinite fields in polynomial time. This algorithm was subsequently improved by\nAtkin, using factorizations of modular polynomials, and by Elkies, using a\ntheory of explicit isogenies. Moving to Jacobians of genus-2 curves, the\ncurrent state of the art for point counting is a generalization of Schoof's\nalgorithm. While we are currently missing the tools we need to generalize\nElkies' methods to genus 2, recently Martindale and Milio have computed\nanalogues of modular polynomials for genus-2 curves whose Jacobians have real\nmultiplication by maximal orders of small discriminant. In this article, we\nprove Atkin-style results for genus-2 Jacobians with real multiplication by\nmaximal orders, with a view to using these new modular polynomials to improve\nthe practicality of point-counting algorithms for these curves.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jan 2017 08:54:10 GMT"}, {"version": "v2", "created": "Wed, 19 Apr 2017 08:01:42 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Ballentine", "Sean", ""], ["Guillevic", "Aurore", ""], ["Garc\u00eda", "Elisa Lorenzo", ""], ["Martindale", "Chloe", ""], ["Massierer", "Maike", ""], ["Smith", "Benjamin", ""], ["Top", "Jaap", ""]]}, {"id": "1701.01928", "submitter": "Cong Zhao", "authors": "Cong Zhao, Xinyu Yang, Wei Yu, Xianghua Yao, Jie Lin, Xin Li", "title": "Cheating-Resilient Incentive Scheme for Mobile Crowdsensing Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile Crowdsensing is a promising paradigm for ubiquitous sensing, which\nexplores the tremendous data collected by mobile smart devices with prominent\nspatial-temporal coverage. As a fundamental property of Mobile Crowdsensing\nSystems, temporally recruited mobile users can provide agile, fine-grained, and\neconomical sensing labors, however their self-interest cannot guarantee the\nquality of the sensing data, even when there is a fair return. Therefore, a\nmechanism is required for the system server to recruit well-behaving users for\ncredible sensing, and to stimulate and reward more contributive users based on\nsensing truth discovery to further increase credible reporting. In this paper,\nwe develop a novel Cheating-Resilient Incentive (CRI) scheme for Mobile\nCrowdsensing Systems, which achieves credibility-driven user recruitment and\npayback maximization for honest users with quality data. Via theoretical\nanalysis, we demonstrate the correctness of our design. The performance of our\nscheme is evaluated based on extensive realworld trace-driven simulations. Our\nevaluation results show that our scheme is proven to be effective in terms of\nboth guaranteeing sensing accuracy and resisting potential cheating behaviors,\nas demonstrated in practical scenarios, as well as those that are intentionally\nharsher.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jan 2017 09:00:31 GMT"}], "update_date": "2017-01-10", "authors_parsed": [["Zhao", "Cong", ""], ["Yang", "Xinyu", ""], ["Yu", "Wei", ""], ["Yao", "Xianghua", ""], ["Lin", "Jie", ""], ["Li", "Xin", ""]]}, {"id": "1701.01960", "submitter": "Hiroki Okada", "authors": "Hiroki Okada and Ken Umeno", "title": "Randomness Evaluation with the Discrete Fourier Transform Test Based on\n  Exact Analysis of the Reference Distribution", "comments": "22 pages, 4 figures", "journal-ref": null, "doi": "10.1109/TIFS.2017.2656473", "report-no": "T-IFS-06137-2016.R2", "categories": "cs.CR stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problems in the discrete Fourier transform (DFT)\ntest included in NIST SP 800-22 released by the National Institute of Standards\nand Technology (NIST), which is a collection of tests for evaluating both\nphysical and pseudo-random number generators for cryptographic applications.\nThe most crucial problem in the DFT test is that its reference distribution of\nthe test statistic is not derived mathematically but rather numerically\nestimated, the DFT test for randomness is based on a pseudo-random number\ngenerator (PRNG). Therefore, the present DFT test should not be used unless the\nreference distribution is mathematically derived. Here, we prove that a power\nspectrum, which is a component of the test statistic, follows a chi-squared\ndistribution with 2 degrees of freedom. Based on this fact, we propose a test\nwhose reference distribution of the test statistic is mathematically derived.\nFurthermore, the results of testing non-random sequences and several PRNGs\nshowed that the proposed test is more reliable and definitely more sensitive\nthan the present DFT test.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jan 2017 14:02:52 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Okada", "Hiroki", ""], ["Umeno", "Ken", ""]]}, {"id": "1701.02120", "submitter": "Jun Wang", "authors": "Jun Wang and Qiang Tang", "title": "Differentially Private Neighborhood-based Recommender Systems", "comments": "Accepted by IFIP SEC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy issues of recommender systems have become a hot topic for the society\nas such systems are appearing in every corner of our life. In contrast to the\nfact that many secure multi-party computation protocols have been proposed to\nprevent information leakage in the process of recommendation computation, very\nlittle has been done to restrict the information leakage from the\nrecommendation results. In this paper, we apply the differential privacy\nconcept to neighborhood-based recommendation methods (NBMs) under a\nprobabilistic framework. We first present a solution, by directly calibrating\nLaplace noise into the training process, to differential-privately find the\nmaximum a posteriori parameters similarity. Then we connect differential\nprivacy to NBMs by exploiting a recent observation that sampling from the\nscaled posterior distribution of a Bayesian model results in provably\ndifferentially private systems. Our experiments show that both solutions allow\npromising accuracy with a modest privacy budget, and the second solution yields\nbetter accuracy if the sampling asymptotically converges. We also compare our\nsolutions to the recent differentially private matrix factorization (MF)\nrecommender systems, and show that our solutions achieve better accuracy when\nthe privacy budget is reasonably small. This is an interesting result because\nMF systems often offer better accuracy when differential privacy is not\napplied.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2017 10:11:08 GMT"}, {"version": "v2", "created": "Fri, 10 Mar 2017 10:33:48 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Wang", "Jun", ""], ["Tang", "Qiang", ""]]}, {"id": "1701.02145", "submitter": "Elike Hodo Mr", "authors": "Elike Hodo, Xavier Bellekens, Andrew Hamilton, Christos Tachtatzis and\n  Robert Atkinson", "title": "Shallow and Deep Networks Intrusion Detection System: A Taxonomy and\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrusion detection has attracted a considerable interest from researchers\nand industries. The community, after many years of research, still faces the\nproblem of building reliable and efficient IDS that are capable of handling\nlarge quantities of data, with changing patterns in real time situations. The\nwork presented in this manuscript classifies intrusion detection systems (IDS).\nMoreover, a taxonomy and survey of shallow and deep networks intrusion\ndetection systems is presented based on previous and current works. This\ntaxonomy and survey reviews machine learning techniques and their performance\nin detecting anomalies. Feature selection which influences the effectiveness of\nmachine learning (ML) IDS is discussed to explain the role of feature selection\nin the classification and training phase of ML IDS. Finally, a discussion of\nthe false and true positive alarm rates is presented to help researchers model\nreliable and efficient machine learning based intrusion detection systems.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2017 11:46:58 GMT"}], "update_date": "2017-01-10", "authors_parsed": [["Hodo", "Elike", ""], ["Bellekens", "Xavier", ""], ["Hamilton", "Andrew", ""], ["Tachtatzis", "Christos", ""], ["Atkinson", "Robert", ""]]}, {"id": "1701.02243", "submitter": "Marco Gramaglia", "authors": "Marco Gramaglia, Marco Fiore, Alberto Tarable, Albert Banchs", "title": "$k^{\\tau,\\epsilon}$-anonymity: Towards Privacy-Preserving Publishing of\n  Spatiotemporal Trajectory Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile network operators can track subscribers via passive or active\nmonitoring of device locations. The recorded trajectories offer an\nunprecedented outlook on the activities of large user populations, which\nenables developing new networking solutions and services, and scaling up\nstudies across research disciplines. Yet, the disclosure of individual\ntrajectories raises significant privacy concerns: thus, these data are often\nprotected by restrictive non-disclosure agreements that limit their\navailability and impede potential usages. In this paper, we contribute to the\ndevelopment of technical solutions to the problem of privacy-preserving\npublishing of spatiotemporal trajectories of mobile subscribers. We propose an\nalgorithm that generalizes the data so that they satisfy\n$k^{\\tau,\\epsilon}$-anonymity, an original privacy criterion that thwarts\nattacks on trajectories. Evaluations with real-world datasets demonstrate that\nour algorithm attains its objective while retaining a substantial level of\naccuracy in the data. Our work is a step forward in the direction of open,\nprivacy-preserving datasets of spatiotemporal trajectories.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2017 16:24:32 GMT"}], "update_date": "2017-01-10", "authors_parsed": [["Gramaglia", "Marco", ""], ["Fiore", "Marco", ""], ["Tarable", "Alberto", ""], ["Banchs", "Albert", ""]]}, {"id": "1701.02446", "submitter": "Amit Tambe", "authors": "Juan Guarnizo, Amit Tambe, Suman Sankar Bhunia, Mart\\'in Ochoa, Nils\n  Tippenhauer, Asaf Shabtai and Yuval Elovici", "title": "SIPHON: Towards Scalable High-Interaction Physical Honeypots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In recent years, the emerging Internet-of-Things (IoT) has led to rising\nconcerns about the security of networked embedded devices. In this work, we\nfocus on the adaptation of Honeypots for improving the security of IoTs.\nLow-interaction honeypots are used so far in the context of IoT. Such honeypots\nare limited and easily detectable, and thus, there is a need to find ways how\nto develop high-interaction, reliable, IoT honeypots that will attract skilled\nattackers. In this work, we propose the SIPHON architecture - a Scalable\nhigh-Interaction Honeypot platform for IoT devices. Our architecture leverages\nIoT devices that are physically at one location and are connected to the\nInternet through so-called wormholes distributed around the world. The\nresulting architecture allows exposing few physical devices over a large number\nof geographically distributed IP addresses. We demonstrate the proposed\narchitecture in a large scale experiment with 39 wormhole instances in 16\ncities in 9 countries. Based on this setup, six physical IP cameras, one NVR\nand one IP printer are presented as 85 real IoT devices on the Internet,\nattracting a daily traffic of 700MB for a period of two months. A preliminary\nanalysis of the collected traffic indicates that devices in some cities\nattracted significantly more traffic than others (ranging from 600 000 incoming\nTCP connections for the most popular destination to less than 50000 for the\nleast popular). We recorded over 400 brute-force login attempts to the\nweb-interface of our devices using a total of 1826 distinct credentials, from\nwhich 11 attempts were successful. Moreover, we noted login attempts to Telnet\nand SSH ports some of which used credentials found in the recently disclosed\nMirai malware.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jan 2017 06:27:00 GMT"}, {"version": "v2", "created": "Thu, 12 Jan 2017 03:35:13 GMT"}], "update_date": "2017-01-13", "authors_parsed": [["Guarnizo", "Juan", ""], ["Tambe", "Amit", ""], ["Bhunia", "Suman Sankar", ""], ["Ochoa", "Mart\u00edn", ""], ["Tippenhauer", "Nils", ""], ["Shabtai", "Asaf", ""], ["Elovici", "Yuval", ""]]}, {"id": "1701.02711", "submitter": "Saed Alrabaee", "authors": "Saed Alrabaee, Paria Shirani, Mourad Debbabi, and Lingyu Wang", "title": "On the Feasibility of Malware Authorship Attribution", "comments": "FPS 2016", "journal-ref": "Foundations and Practice of Security 2016 Volume 10128 of the\n  series Lecture Notes in Computer Science pp 256-272", "doi": "10.1007/978-3-319-51966-1_17", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many occasions in which the security community is interested to\ndiscover the authorship of malware binaries, either for digital forensics\nanalysis of malware corpora or for thwarting live threats of malware invasion.\nSuch a discovery of authorship might be possible due to stylistic features\ninherent to software codes written by human programmers. Existing studies of\nauthorship attribution of general purpose software mainly focus on source code,\nwhich is typically based on the style of programs and environment. However,\nthose features critically depend on the availability of the program source\ncode, which is usually not the case when dealing with malware binaries. Such\nprogram binaries often do not retain many semantic or stylistic features due to\nthe compilation process. Therefore, authorship attribution in the domain of\nmalware binaries based on features and styles that will survive the compilation\nprocess is challenging. This paper provides the state of the art in this\nliterature. Further, we analyze the features involved in those techniques. By\nusing a case study, we identify features that can survive the compilation\nprocess. Finally, we analyze existing works on binary authorship attribution\nand study their applicability to real malware binaries.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jan 2017 18:09:31 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Alrabaee", "Saed", ""], ["Shirani", "Paria", ""], ["Debbabi", "Mourad", ""], ["Wang", "Lingyu", ""]]}, {"id": "1701.02896", "submitter": "Mohammed Alsaedi Dr", "authors": "Mohammed Alsaedi", "title": "Colored Image Encryption and Decryption Using Chaotic Lorenz System and\n  DCT2", "comments": "22 pages, 15 Figures, IJCSIS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a scheme for the encryption and decryption of colored images\nby using the Lorenz system and the discrete cosine transform in two dimensions\n(DCT2) is proposed. Although chaos is random, it has deterministic features\nthat can be used for encryption; further, the same sequences can be produced at\nthe transmitter and receiver under the same initial conditions. Another\nproperty of DCT2 is that the energy is concentrated in some elements of the\ncoefficients. These two properties are used to efficiently encrypt and recover\nthe image at the receiver by using three different keys with three different\npredefined number of shifts for each instance of key usage. Simulation results\nand statistical analysis show that the scheme high performance in weakening the\ncorrelation between the pixels of the image that resulted from the inverse of\nhighest energy values of DCT2 that form 99.9 % of the energy as well as those\nof the difference image.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jan 2017 09:11:57 GMT"}], "update_date": "2017-01-12", "authors_parsed": [["Alsaedi", "Mohammed", ""]]}, {"id": "1701.02911", "submitter": "Ryutaroh Matsumoto", "authors": "Ryutaroh Matsumoto", "title": "Quantum Stabilizer Codes Can Realize Access Structures Impossible by\n  Classical Secret Sharing", "comments": "LaTeX2e, 5 pages, no figure. Comments from readers are welcome", "journal-ref": "IEICE Trans. Fundamentals, vol.E100-A, no.12, pp. 2738-2739, Dec.\n  2017", "doi": "10.1587/transfun.E100.A.2738", "report-no": null, "categories": "quant-ph cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show a simple example of a secret sharing scheme encoding classical secret\nto quantum shares that can realize an access structure impossible by classical\ninformation processing with limitation on the size of each share. The example\nis based on quantum stabilizer codes.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jan 2017 10:06:34 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Matsumoto", "Ryutaroh", ""]]}, {"id": "1701.03229", "submitter": "Nalin Asanka Gamagedara Arachchilage", "authors": "Awanthika Senarath, Nalin Asanka Gamagedara Arachchilage, B. B. Gupta", "title": "Security Strength Indicator in Fallback Authentication: Nudging Users\n  for Better Answers in Secret Questions", "comments": "5 pages in International Journal for Infonomics (IJI), 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe ongoing work that focuses on improving the\nstrength of the answers to security questions. The ultimate goal of the\nproposed research is to evaluate the possibility of nudging users towards\nstrong answers for ubiquitous security questions. In this research we are\nproposing a user interface design for fallback authentication to encourage\nusers to design stronger answers. The proposed design involves visual feedback\nto the user based on mnemonics which attempts to give visual feedback to the\nuser on the strength of the answer provided and guide the user to creatively\ndesign a stronger answer.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jan 2017 04:42:42 GMT"}], "update_date": "2017-01-13", "authors_parsed": [["Senarath", "Awanthika", ""], ["Arachchilage", "Nalin Asanka Gamagedara", ""], ["Gupta", "B. B.", ""]]}, {"id": "1701.03904", "submitter": "Christian Zenger", "authors": "Christan Zenger, Hendrik Vogt, Jan Zimmer, Aydin Sezgin, Christof Paar", "title": "The Passive Eavesdropper Affects my Channel: Secret-Key Rates under\n  Real-World Conditions (Extended Version)", "comments": "Full measurement in Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Channel-reciprocity based key generation (CRKG) has gained significant\nimportance as it has recently been proposed as a potential lightweight security\nsolution for IoT devices. However, the impact of the attacker's position in\nclose range has only rarely been evaluated in practice, posing an open research\nproblem about the security of real-world realizations. Furthermore, this would\nfurther bridge the gap between theoretical channel models and their\npractice-oriented realizations. For security metrics, we utilize\ncross-correlation, mutual information, and a lower bound on secret-key\ncapacity. We design a practical setup of three parties such that the channel\nstatistics, although based on joint randomness, are always reproducible. We run\nexperiments to obtain channel states and evaluate the aforementioned metrics\nfor the impact of an attacker depending on his position. It turns out the\nattacker himself affects the outcome, which has not been adequately regarded\nyet in standard channel models.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jan 2017 11:23:12 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Zenger", "Christan", ""], ["Vogt", "Hendrik", ""], ["Zimmer", "Jan", ""], ["Sezgin", "Aydin", ""], ["Paar", "Christof", ""]]}, {"id": "1701.03945", "submitter": "George Bissias", "authors": "George Bissias and Brian Levine and Nikunj Kapadia", "title": "Securing the Assets of Decentralized Applications using Financial\n  Derivatives (DRAFT)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ethereum contracts can be designed to function as fully decentralized\napplications called DAPPs. Many DAPPs have already been fielded, including an\nonline marketplace, a role playing game, a prediction market, and an Internet\nservice provider. Unfortunately, DAPPs can be hacked, and the assets they\ncontrol can be stolen. A recent attack on an Ethereum decentralized application\ncalled The DAO demonstrated that smart contract bugs are more than an academic\nconcern. Ether worth tens of millions of US dollars was extracted by an\nattacker from The DAO, sending the value of its tokens and the overall exchange\nprice of ether tumbling.\n  We present a market-based technique for insuring the ether holdings of a DAPP\nusing futures contracts indexed by the trade price of ether for DAPP tokens.\nUnder fairly general circumstances, our technique is capable of recovering the\nmajority of ether lost from theft with high probability even when all of the\nether holdings are stolen; and the only cost to DAPP token holders is an\nadjustable ether withdrawal fee. If the probability of a margin call in $d$\ndays is $p$ for a futures contract with 20 times leverage, then our approach\nwill allow for the recovery of half the stolen ether with probability $p$ and a\nwithdrawal fee of 5%. A higher withdrawal fee of 25% allows for more than 80%\nof the ether to be recovered with probability $p$.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jan 2017 16:35:03 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Bissias", "George", ""], ["Levine", "Brian", ""], ["Kapadia", "Nikunj", ""]]}, {"id": "1701.03977", "submitter": "Brian Levine", "authors": "A. Pinar Ozisik and Brian Neil Levine", "title": "An Explanation of Nakamoto's Analysis of Double-spend Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental attack against blockchain systems is the double-spend attack.\nIn this tutorial, we provide a very detailed explanation of just one section of\nSatoshi Nakamoto's original paper where the attack's probability of success is\nstated. We show the derivation of the mathematics relied upon by Nakamoto to\ncreate a model of the attack. We also validate the model with a Monte Carlo\nsimulation, and we determine which model component is not perfect.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2017 00:49:41 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Ozisik", "A. Pinar", ""], ["Levine", "Brian Neil", ""]]}, {"id": "1701.04013", "submitter": "Florian Otterbein", "authors": "Florian Otterbein, Tim Ohlendorf, Marian Margraf", "title": "The German eID as an Authentication Token on Android Devices", "comments": "International Journal of Computer Science and Information Security,\n  December 2016, Vol. 14 No.12", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Due to the rapid increase of digitization within our society, digital\nidentities gain more and more importance. Provided by the German eID solution,\nevery citizen has the ability to identify himself against various governmental\nand private organizations with the help of his personal electronic ID card and\na corresponding card reader. While there are several solutions available for\ndesktop use of the eID infrastructure, mobile approaches have to be payed more\nattention. In this paper we present a new approach for using the German eID\nconcept on an Android device without the need of the actual identity card and\ncard reader. A security evaluation of our approach reveals that two\nnon-critical vulnerabilities on the architecture can't be avoided.\nNevertheless, no sensitive information are compromised. A proof of concept\nshows that an actual implementation faces some technical issues which have to\nbe solved in the future.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2017 09:45:52 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Otterbein", "Florian", ""], ["Ohlendorf", "Tim", ""], ["Margraf", "Marian", ""]]}, {"id": "1701.04045", "submitter": "Valentin W\\\"ustholz", "authors": "Valentin W\\\"ustholz and Oswaldo Olivo and Marijn J. H. Heule and Isil\n  Dillig", "title": "Static Detection of DoS Vulnerabilities in Programs that use Regular\n  Expressions (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.FL cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an algorithmic complexity attack, a malicious party takes advantage of the\nworst-case behavior of an algorithm to cause denial-of-service. A prominent\nalgorithmic complexity attack is regular expression denial-of-service (ReDoS),\nin which the attacker exploits a vulnerable regular expression by providing a\ncarefully-crafted input string that triggers worst-case behavior of the\nmatching algorithm. This paper proposes a technique for automatically finding\nReDoS vulnerabilities in programs. Specifically, our approach automatically\nidentifies vulnerable regular expressions in the program and determines whether\nan \"evil\" input string can be matched against a vulnerable regular expression.\nWe have implemented our proposed approach in a tool called REXPLOITER and found\n41 exploitable security vulnerabilities in Java web applications.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2017 14:05:07 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["W\u00fcstholz", "Valentin", ""], ["Olivo", "Oswaldo", ""], ["Heule", "Marijn J. H.", ""], ["Dillig", "Isil", ""]]}, {"id": "1701.04137", "submitter": "Yansong Gao", "authors": "Yansong Gao and Damith C. Ranasinghe", "title": "PUF-FSM: A Controlled Strong PUF", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the PUF finite state machine (PUF-FSM) that is served as\na practical {\\it controlled} strong PUF. Previous controlled PUF designs have\nthe difficulties of stabilizing the noisy PUF responses where the error\ncorrection logic is required. In addition, the computed helper data to assist\nerror correcting, however, leaks information, which poses the controlled PUF\nunder the threatens of fault attacks or reliability-based attacks. The PUF-FSM\neschews the error correction logic and the computation, storage and loading of\nthe helper data on-chip by only employing error-free responses judiciously\ndetermined on demand in the absence of an Arbiter PUF with a large CRP space.\nIn addition, the access to the PUF-FSM is controlled by the trusted entity.\nControl in means of i) restricting challenges presented to the PUF and ii)\nfurther preventing repeated response evaluations to gain unreliability\nside-channel information are foundations of defensing the most powerful\nmodeling attacks. The PUF-FSM goes beyond authentications/identifications to\nsuch as key generations and advanced cryptographic applications built upon a\nshared key.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2017 01:42:26 GMT"}, {"version": "v2", "created": "Wed, 25 Jan 2017 21:51:18 GMT"}], "update_date": "2017-01-27", "authors_parsed": [["Gao", "Yansong", ""], ["Ranasinghe", "Damith C.", ""]]}, {"id": "1701.04174", "submitter": "M\\'ario S. Alvim", "authors": "M\\'ario S. Alvim, Piotr Mardziel, Michael Hicks", "title": "Quantifying vulnerability of secret generation using hyper-distributions\n  (extended version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional approaches to Quantitative Information Flow (QIF) represent the\nadversary's prior knowledge of possible secret values as a single probability\ndistribution. This representation may miss important structure. For instance,\nrepresenting prior knowledge about passwords of a system's users in this way\noverlooks the fact that many users generate passwords using some strategy.\nKnowledge of such strategies can help the adversary in guessing a secret, so\nignoring them may underestimate the secret's vulnerability. In this paper we\nexplicitly model strategies as distributions on secrets, and generalize the\nrepresentation of the adversary's prior knowledge from a distribution on\nsecrets to an environment, which is a distribution on strategies (and, thus, a\ndistribution on distributions on secrets, called a hyper-distribution). By\napplying information-theoretic techniques to environments we derive several\nmeaningful generalizations of the traditional approach to QIF. In particular,\nwe disentangle the vulnerability of a secret from the vulnerability of the\nstrategies that generate secrets, and thereby distinguish security by\naggregation--which relies on the uncertainty over strategies--from security by\nstrategy--which relies on the intrinsic uncertainty within a strategy. We also\ndemonstrate that, in a precise way, no further generalization of prior\nknowledge (e.g., by using distributions of even higher order) is needed to\nsoundly quantify the vulnerability of the secret.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2017 05:44:05 GMT"}, {"version": "v2", "created": "Sat, 21 Jan 2017 12:05:31 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Alvim", "M\u00e1rio S.", ""], ["Mardziel", "Piotr", ""], ["Hicks", "Michael", ""]]}, {"id": "1701.04185", "submitter": "Rohit M Thanki", "authors": "Rohit M. Thanki, Ved Vyas Dwivedi and Komal R. Borisagar", "title": "A Watermarking Technique Using Discrete Curvelet Transform for Security\n  of Multiple Biometric Features", "comments": null, "journal-ref": "International Journal of Information Processing,volume 10, issue\n  1, pp. 103 - 114 (2016)", "doi": null, "report-no": null, "categories": "cs.MM cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The robustness and security of the biometric watermarking approach can be\nimproved by using a multiple watermarking. This multiple watermarking proposed\nfor improving security of biometric features and data. When the imposter tries\nto create the spoofed biometric feature, the invisible biometric watermark\nfeatures can provide appropriate protection to multimedia data. In this paper,\na biometric watermarking technique with multiple biometric watermarks are\nproposed in which biometric features of fingerprint, face, iris and signature\nis embedded in the image. Before embedding, fingerprint, iris, face and\nsignature features are extracted using Shen-Castan edge detection and Principal\nComponent Analysis. These all biometric watermark features are embedded into\nvarious mid band frequency curvelet coefficients of host image. All four\nfingerprint features, iris features, facial features and signature features are\nthe biometric characteristics of the individual and they are used for cross\nverification and copyright protection if any manipulation occurs. The proposed\ntechnique is fragile enough; features cannot be extracted from the watermarked\nimage when an imposter tries to remove watermark features illegally. It can use\nfor multiple copyright authentication and verification.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2017 06:41:21 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Thanki", "Rohit M.", ""], ["Dwivedi", "Ved Vyas", ""], ["Borisagar", "Komal R.", ""]]}, {"id": "1701.04222", "submitter": "Aristide Tossou", "authors": "Aristide C. Y. Tossou and Christos Dimitrakakis", "title": "Achieving Privacy in the Adversarial Multi-Armed Bandit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we improve the previously best known regret bound to achieve\n$\\epsilon$-differential privacy in oblivious adversarial bandits from\n$\\mathcal{O}{(T^{2/3}/\\epsilon)}$ to $\\mathcal{O}{(\\sqrt{T} \\ln T /\\epsilon)}$.\nThis is achieved by combining a Laplace Mechanism with EXP3. We show that\nthough EXP3 is already differentially private, it leaks a linear amount of\ninformation in $T$. However, we can improve this privacy by relying on its\nintrinsic exponential mechanism for selecting actions. This allows us to reach\n$\\mathcal{O}{(\\sqrt{\\ln T})}$-DP, with a regret of $\\mathcal{O}{(T^{2/3})}$\nthat holds against an adaptive adversary, an improvement from the best known of\n$\\mathcal{O}{(T^{3/4})}$. This is done by using an algorithm that run EXP3 in a\nmini-batch loop. Finally, we run experiments that clearly demonstrate the\nvalidity of our theoretical analysis.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2017 10:04:05 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Tossou", "Aristide C. Y.", ""], ["Dimitrakakis", "Christos", ""]]}, {"id": "1701.04371", "submitter": "Mohaned Chraiti", "authors": "Mohaned Chraiti, Ali Ghrayeb, Chadi Assi and Mazen O. Hasna", "title": "On the Achievable Secrecy Diversity of Cooperative Networks with\n  Untrusted Relays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative relaying is often deployed to enhance the communication\nreliability (i.e., diversity order) and consequently the end-to-end achievable\nrate. However, this raises several security concerns when the relays are\nuntrusted since they may have access to the relayed message. In this paper, we\nstudy the achievable secrecy diversity order of cooperative networks with\nuntrusted relays. In particular, we consider a network with an N-antenna\ntransmitter (Alice), K single-antenna relays, and a single-antenna destination\n(Bob). We consider the general scenario where there is no relation between N\nand K, and therefore K can be larger than N. Alice and Bob are assumed to be\nfar away from each other, and all communication is done through the relays,\ni.e., there is no direct link. Providing secure communication while enhancing\nthe diversity order has been shown to be very challenging. In fact, it has been\nshown in the literature that the maximum achievable secrecy diversity order for\nthe adopted system model is one (while using artificial noise jamming). In this\npaper, we adopt a nonlinear interference alignment scheme that we have proposed\nrecently to transmit the signals from Alice to Bob. We analyze the proposed\nscheme in terms of the achievable secrecy rate and secrecy diversity order.\nAssuming Gaussian inputs, we derive an explicit expression for the achievable\nsecrecy rate and show analytically that a secrecy diversity order of up to\nmin(N,K)-1 can be achieved using the proposed technique. We provide several\nnumerical examples to validate the obtained analytical results and demonstrate\nthe superiority of the proposed technique to its counterparts that exist in the\nliterature.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jan 2017 10:45:05 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Chraiti", "Mohaned", ""], ["Ghrayeb", "Ali", ""], ["Assi", "Chadi", ""], ["Hasna", "Mazen O.", ""]]}, {"id": "1701.04439", "submitter": "Giulia Fanti", "authors": "Shaileshh Bojja Venkatakrishnan, Giulia Fanti, and Pramod Viswanath", "title": "Dandelion: Redesigning the Bitcoin Network for Anonymity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin and other cryptocurrencies have surged in popularity over the last\ndecade. Although Bitcoin does not claim to provide anonymity for its users, it\nenjoys a public perception of being a `privacy-preserving' financial system. In\nreality, cryptocurrencies publish users' entire transaction histories in\nplaintext, albeit under a pseudonym; this is required for transaction\nvalidation. Therefore, if a user's pseudonym can be linked to their human\nidentity, the privacy fallout can be significant. Recently, researchers have\ndemonstrated deanonymization attacks that exploit weaknesses in the Bitcoin\nnetwork's peer-to-peer (P2P) networking protocols. In particular, the P2P\nnetwork currently forwards content in a structured way that allows observers to\ndeanonymize users. In this work, we redesign the P2P network from first\nprinciples with the goal of providing strong, provable anonymity guarantees. We\npropose a simple networking policy called Dandelion, which achieves\nnearly-optimal anonymity guarantees at minimal cost to the network's utility.\nWe also provide a practical implementation of Dandelion.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2017 19:51:31 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Venkatakrishnan", "Shaileshh Bojja", ""], ["Fanti", "Giulia", ""], ["Viswanath", "Pramod", ""]]}, {"id": "1701.04470", "submitter": "Takeshi Koshiba", "authors": "Masahito Hayashi, Takeshi Koshiba", "title": "Universal Construction of Cheater-Identifiable Secret Sharing Against\n  Rushing Cheaters Based on Message Authentication", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For conventional secret sharing, if cheaters can submit possibly forged\nshares after observing shares of the honest users in the reconstruction phase\nthen they cannot only disturb the protocol but also only they may reconstruct\nthe true secret. To overcome the problem, secret sharing scheme with properties\nof cheater-identification have been proposed. Existing protocols for\ncheater-identifiable secret sharing assumed non-rushing cheaters or honest\nmajority. In this paper, we remove both conditions simultaneously, and give its\nuniversal construction from any secret sharing scheme. To resolve this end, we\npropose the concepts of \"individual identification\" and \"agreed\nidentification\".\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2017 22:12:03 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 02:03:12 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Hayashi", "Masahito", ""], ["Koshiba", "Takeshi", ""]]}, {"id": "1701.04507", "submitter": "Huan Feng", "authors": "Huan Feng, Kassem Fawaz, and Kang G. Shin", "title": "Continuous Authentication for Voice Assistants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice has become an increasingly popular User Interaction (UI) channel,\nmainly contributing to the ongoing trend of wearables, smart vehicles, and home\nautomation systems. Voice assistants such as Siri, Google Now and Cortana, have\nbecome our everyday fixtures, especially in scenarios where touch interfaces\nare inconvenient or even dangerous to use, such as driving or exercising.\nNevertheless, the open nature of the voice channel makes voice assistants\ndifficult to secure and exposed to various attacks as demonstrated by security\nresearchers. In this paper, we present VAuth, the first system that provides\ncontinuous and usable authentication for voice assistants. We design VAuth to\nfit in various widely-adopted wearable devices, such as eyeglasses,\nearphones/buds and necklaces, where it collects the body-surface vibrations of\nthe user and matches it with the speech signal received by the voice\nassistant's microphone. VAuth guarantees that the voice assistant executes only\nthe commands that originate from the voice of the owner. We have evaluated\nVAuth with 18 users and 30 voice commands and find it to achieve an almost\nperfect matching accuracy with less than 0.1% false positive rate, regardless\nof VAuth's position on the body and the user's language, accent or mobility.\nVAuth successfully thwarts different practical attacks, such as replayed\nattacks, mangled voice attacks, or impersonation attacks. It also has low\nenergy and latency overheads and is compatible with most existing voice\nassistants.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2017 01:39:49 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Feng", "Huan", ""], ["Fawaz", "Kassem", ""], ["Shin", "Kang G.", ""]]}, {"id": "1701.04525", "submitter": "Bo Luo", "authors": "Abdulmalik Humayed, Jingqiang Lin, Fengjun Li, Bo Luo", "title": "Cyber-Physical Systems Security -- A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the exponential growth of cyber-physical systems (CPS), new security\nchallenges have emerged. Various vulnerabilities, threats, attacks, and\ncontrols have been introduced for the new generation of CPS. However, there\nlack a systematic study of CPS security issues. In particular, the\nheterogeneity of CPS components and the diversity of CPS systems have made it\nvery difficult to study the problem with one generalized model.\n  In this paper, we capture and systematize existing research on CPS security\nunder a unified framework. The framework consists of three orthogonal\ncoordinates: (1) from the \\emph{security} perspective, we follow the well-known\ntaxonomy of threats, vulnerabilities, attacks and controls; (2)from the\n\\emph{CPS components} perspective, we focus on cyber, physical, and\ncyber-physical components; and (3) from the \\emph{CPS systems} perspective, we\nexplore general CPS features as well as representative systems (e.g., smart\ngrids, medical CPS and smart cars). The model can be both abstract to show\ngeneral interactions of a CPS application and specific to capture any details\nwhen needed. By doing so, we aim to build a model that is abstract enough to be\napplicable to various heterogeneous CPS applications; and to gain a modular\nview of the tightly coupled CPS components. Such abstract decoupling makes it\npossible to gain a systematic understanding of CPS security, and to highlight\nthe potential sources of attacks and ways of protection.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2017 04:43:36 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Humayed", "Abdulmalik", ""], ["Lin", "Jingqiang", ""], ["Li", "Fengjun", ""], ["Luo", "Bo", ""]]}, {"id": "1701.04556", "submitter": "Siamak Solat", "authors": "Siamak Solat (UPMC)", "title": "Security of Electronic Payment Systems: A Comprehensive Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This comprehensive survey deliberated over the security of electronic payment\nsystems. In our research, we focused on either dominant systems or new attempts\nand innovations to improve the level of security of the electronic payment\nsystems. This survey consists of the Card-present (CP) transactions and a\nreview of its dominant system i.e. EMV including several researches at\nCambridge university to designate variant types of attacks against this\nstandard which demonstrates lack of a secure \"offline\" authentication method\nthat is one of the main purpose of using the smart cards instead of magnetic\nstripe cards which are not able to participate in authentication process, the\nevaluation of the EMV migration from RSA cryptosystem to ECC based cryptosystem\n3. The evaluation of the Card-not-present transactions approaches including 3D\nSecure, 3D SET, SET/EMV and EMV/CAP, the impact of concept of Tokenization and\nthe role of Blind Signatures schemes in electronic cash and E-payment systems,\nuse of quantum key distribution (QKD) in electronic payment systems to achieve\nunconditional security rather than only computational assurance of the security\nlevel by using traditional cryptography, the evaluation of Near Field\nCommunication (NFC) and the contactless payment systems such as Google wallet,\nAndroid Pay and Apple Pay, the assessment of the electronic currency and peer\nto peer payment systems such as Bitcoin. The criterion of our survey for the\nmeasurement and the judgment about the quality of the security in electronic\npayment systems was this quote: \"The security of a system is only as strong as\nits weakest link\"\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2017 08:11:06 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Solat", "Siamak", "", "UPMC"]]}, {"id": "1701.04739", "submitter": "Octavian Suciu", "authors": "Rock Stevens, Octavian Suciu, Andrew Ruef, Sanghyun Hong, Michael\n  Hicks, Tudor Dumitra\\c{s}", "title": "Summoning Demons: The Pursuit of Exploitable Bugs in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Governments and businesses increasingly rely on data analytics and machine\nlearning (ML) for improving their competitive edge in areas such as consumer\nsatisfaction, threat intelligence, decision making, and product efficiency.\nHowever, by cleverly corrupting a subset of data used as input to a target's ML\nalgorithms, an adversary can perturb outcomes and compromise the effectiveness\nof ML technology. While prior work in the field of adversarial machine learning\nhas studied the impact of input manipulation on correct ML algorithms, we\nconsider the exploitation of bugs in ML implementations. In this paper, we\ncharacterize the attack surface of ML programs, and we show that malicious\ninputs exploiting implementation bugs enable strictly more powerful attacks\nthan the classic adversarial machine learning techniques. We propose a\nsemi-automated technique, called steered fuzzing, for exploring this attack\nsurface and for discovering exploitable bugs in machine learning programs, in\norder to demonstrate the magnitude of this threat. As a result of our work, we\nresponsibly disclosed five vulnerabilities, established three new CVE-IDs, and\nilluminated a common insecure practice across many machine learning systems.\nFinally, we outline several research directions for further understanding and\nmitigating this threat.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2017 15:59:17 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Stevens", "Rock", ""], ["Suciu", "Octavian", ""], ["Ruef", "Andrew", ""], ["Hong", "Sanghyun", ""], ["Hicks", "Michael", ""], ["Dumitra\u015f", "Tudor", ""]]}, {"id": "1701.04940", "submitter": "Ke Tian", "authors": "Xiaokui Shu, Ke Tian, Andrew Ciambrone and Danfeng Yao", "title": "Breaking the Target: An Analysis of Target Data Breach and Lessons\n  Learned", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates and examines the events leading up to the second most\ndevastating data breach in history: the attack on the Target Corporation. It\nincludes a thorough step-by-step analysis of this attack and a comprehensive\nanatomy of the malware named BlackPOS. Also, this paper provides insight into\nthe legal aspect of cybercrimes, along with a prosecution and sentence example\nof the well-known TJX case. Furthermore, we point out an urgent need for\nimproving security mechanisms in existing systems of merchants and propose\nthree security guidelines and defenses. Credit card security is discussed at\nthe end of the paper with several best practices given to customers to hide\ntheir card information in purchase transactions.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2017 04:31:25 GMT"}], "update_date": "2018-08-19", "authors_parsed": [["Shu", "Xiaokui", ""], ["Tian", "Ke", ""], ["Ciambrone", "Andrew", ""], ["Yao", "Danfeng", ""]]}, {"id": "1701.05007", "submitter": "Sandra Siby", "authors": "Sandra Siby, Rajib Ranjan Maiti and Nils Tippenhauer", "title": "IoTScanner: Detecting and Classifying Privacy Threats in IoT\n  Neighborhoods", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In the context of the emerging Internet of Things (IoT), a proliferation of\nwireless connectivity can be expected. That ubiquitous wireless communication\nwill be hard to centrally manage and control, and can be expected to be opaque\nto end users. As a result, owners and users of physical space are threatened to\nlose control over their digital environments.\n  In this work, we propose the idea of an IoTScanner. The IoTScanner integrates\na range of radios to allow local reconnaissance of existing wireless\ninfrastructure and participating nodes. It enumerates such devices, identifies\nconnection patterns, and provides valuable insights for technical support and\nhome users alike. Using our IoTScanner, we attempt to classify actively\nstreaming IP cameras from other non-camera devices using simple heuristics. We\nshow that our classification approach achieves a high accuracy in an IoT\nsetting consisting of a large number of IoT devices. While related work usually\nfocuses on detecting either the infrastructure, or eavesdropping on traffic\nfrom a specific node, we focus on providing a general overview of operations in\nall observed networks. We do not assume prior knowledge of used SSIDs,\npreshared passwords, or similar.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2017 11:00:39 GMT"}], "update_date": "2017-01-19", "authors_parsed": [["Siby", "Sandra", ""], ["Maiti", "Rajib Ranjan", ""], ["Tippenhauer", "Nils", ""]]}, {"id": "1701.05323", "submitter": "Liao Zhang", "authors": "Liao Zhang", "title": "An Implementation of SCADA Network Security Testbed", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The security of industrial network has become an increasing concern in\nindustry infrastructure operation. Motivated by on-going collaborations with\nFortinet Corp., a security company, this project implements a testbed for\nsupervisory control and data acquisition (SCADA) network security research by\nsoftware emulation. Concepts about SCADA and Modbus protocol are reviewed in\nthe report. Besides Modbus, vulnerabilities about several other industrial\nprotocols are also studied for this project. In this report, a typical tank\nsystem following Modbus protocol is built as a testbed. Both attack and defense\ntoolkits are introduced to emulate the attack and protection of the Modbus\nnetwork. The emulation platform is also capable of entrapping hackers and\ngathering their activity data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2017 07:43:21 GMT"}], "update_date": "2017-01-20", "authors_parsed": [["Zhang", "Liao", ""]]}, {"id": "1701.05403", "submitter": "Do Le Quoc", "authors": "Do Le Quoc and Martin Beck and Pramod Bhatotia and Ruichuan Chen and\n  Christof Fetzer and Thorsten Strufe", "title": "Privacy Preserving Stream Analytics: The Marriage of Randomized Response\n  and Approximate Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to preserve users' privacy while supporting high-utility analytics for\nlow-latency stream processing? To answer this question: we describe the design,\nimplementation, and evaluation of PRIVAPPROX, a data analytics system for\nprivacy-preserving stream processing. PRIVAPPROX provides three properties: (i)\nPrivacy: zero-knowledge privacy guarantees for users, a privacy bound tighter\nthan the state-of-the-art differential privacy; (ii) Utility: an interface for\ndata analysts to systematically explore the trade-offs between the output\naccuracy (with error-estimation) and query execution budget; (iii) Latency:\nnear real-time stream processing based on a scalable \"synchronization-free\"\ndistributed architecture. The key idea behind our approach is to marry two\nexisting techniques together: namely, sampling (used in the context of\napproximate computing) and randomized response (used in the context of\nprivacy-preserving analytics). The resulting marriage is complementary - it\nachieves stronger privacy guarantees and also improves performance, a necessary\ningredient for achieving low-latency stream analytics.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2017 13:16:27 GMT"}, {"version": "v2", "created": "Mon, 6 Feb 2017 15:32:17 GMT"}, {"version": "v3", "created": "Wed, 8 Feb 2017 23:43:43 GMT"}, {"version": "v4", "created": "Tue, 21 Mar 2017 15:17:46 GMT"}, {"version": "v5", "created": "Mon, 5 Jun 2017 14:02:17 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Quoc", "Do Le", ""], ["Beck", "Martin", ""], ["Bhatotia", "Pramod", ""], ["Chen", "Ruichuan", ""], ["Fetzer", "Christof", ""], ["Strufe", "Thorsten", ""]]}, {"id": "1701.05449", "submitter": "Jerome Darmont", "authors": "Varunya Attasena (ERIC), Nouria Harbi (ERIC), J\\'er\\^ome Darmont\n  (ERIC)", "title": "A Novel Multi-Secret Sharing Approach for Secure Data Warehousing and\n  On-Line Analysis Processing in the Cloud", "comments": null, "journal-ref": "International Journal of Data Warehousing and Mining, 11 (2),\n  pp.22 - 43 (2015)", "doi": "10.4018/ijdwm.2015040102", "report-no": null, "categories": "cs.DB cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing helps reduce costs, increase business agility and deploy\nsolutions with a high return on investment for many types of applications,\nincluding data warehouses and on-line analytical processing. However, storing\nand transferring sensitive data into the cloud raises legitimate security\nconcerns. In this paper, we propose a new multi-secret sharing approach for\ndeploying data warehouses in the cloud and allowing on-line analysis\nprocessing, while enforcing data privacy, integrity and availability. We first\nvalidate the relevance of our approach theoretically and then experimentally\nwith both a simple random dataset and the Star Schema Benchmark. We also\ndemonstrate its superiority to related methods.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2017 14:54:21 GMT"}], "update_date": "2017-01-20", "authors_parsed": [["Attasena", "Varunya", "", "ERIC"], ["Harbi", "Nouria", "", "ERIC"], ["Darmont", "J\u00e9r\u00f4me", "", "ERIC"]]}, {"id": "1701.05601", "submitter": "Hamzeh Ghasemzadeh", "authors": "Hamzeh Ghasemzadeh, Mehdi Tajik Khass, Hamed Mehrara", "title": "Jigsaw Cryptanalysis of Audio Scrambling Systems", "comments": "Submitted journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently it was shown that permutation-only multimedia ciphers can completely\nbe broken in a chosen-plaintext scenario. Apparently, chosen-plaintext scenario\nmodels a very resourceful adversary and does not hold in many practical\nsituations. To show that these ciphers are totally broken, we propose a\ncipher-text only attack on these ciphers. To that end, we investigate speech\npermutation-only ciphers and show that inherent redundancies of speech signal\ncan pave the path for a successful cipher-text only attack. For this task\ndifferent concepts and techniques are merged together. First, Short Time\nFourier Transform (STFT) is employed to extract regularities of audio signal in\nboth time and frequency. Then, it is shown that cipher-texts can be considered\nas a set of scrambled puzzles. Then different techniques such as estimation,\nimage processing, branch and bound, and graph theory are fused together to\ncreate and solve these puzzles. After extracting the keys from the solved\npuzzles, they are applied on the scrambled signal. Conducted tests show that\nthe proposed method achieves objective and subjective intelligibility of 87.8%\nand 92.9%. These scores are 50.9% and 34.6% higher than scores of previous\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2017 21:09:03 GMT"}], "update_date": "2017-01-23", "authors_parsed": [["Ghasemzadeh", "Hamzeh", ""], ["Khass", "Mehdi Tajik", ""], ["Mehrara", "Hamed", ""]]}, {"id": "1701.05608", "submitter": "Hamzeh Ghasemzadeh", "authors": "Hamzeh Ghasemzadeh, Ali Payandeh, Mohammad Reza Aref", "title": "A Hybrid DOS-Tolerant PKC-Based Key Management System for WSNs", "comments": "Submitted journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security is a critical and vital task in wireless sensor networks, therefore\ndifferent key management systems have been proposed, many of which are based on\nsymmetric cryptography. Such systems are very energy efficient, but they lack\nsome other desirable characteristics. On the other hand, systems based on\npublic key cryptography have those desirable characteristics, but they consume\nmore energy. Recently based on authenticated messages from base station a new\nPKC based key agreement protocol was proposed. We show this method is\nsusceptible to a form of denial of service attack where resources of the\nnetwork can be exhausted with bogus messages. Then, we propose two different\nimprovements to solve this vulnerability. Simulation results show that these\nnew protocols retain desirable characteristics of the basic method and solve\nits deficiencies.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2017 21:31:16 GMT"}], "update_date": "2017-01-23", "authors_parsed": [["Ghasemzadeh", "Hamzeh", ""], ["Payandeh", "Ali", ""], ["Aref", "Mohammad Reza", ""]]}, {"id": "1701.05637", "submitter": "Wei-Che Wang", "authors": "Wei-Che Wang, Yair Yona, Suhas Diggavi and Puneet Gupta", "title": "Design and Analysis of Stability-Guaranteed PUFs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of stability is one of the major limitations that constrains PUF\nfrom being put in widespread practical use. In this paper, we propose a weak\nPUF and a strong PUF that are both completely stable with 0% intra-distance.\nThese PUFs are called Locally Enhanced Defectivity (LED)PUF. The source of\nrandomness of a LEDPUF is extracted from locally enhance defectivity without\naffecting other parts of the chip. A LEDPUF is a pure functional PUF that does\nnot require any kinds of correction schemes as conventional parametric PUFs do.\nA weak LEDPUF is constructed by forming arrays of Directed Self Assembly (DSA)\nrandom connections is presented, and the strong LEDPUF is implemented by using\nthe weak LEDPUF as the key of a keyed-hash message authentication code (HMAC).\nOur simulation and statistical results show that the entropy of the weak LEDPUF\nbits is close to ideal, and the inter-distances of both weak and strong LEDPUFs\nare about 50%, which means that these LEDPUFs are not only stable but also\nunique. We develop a new unified framework for evaluating the level of security\nof PUFs, based on password security, by using information theoretic tools of\nguesswork. The guesswork model allows to quantitatively compare, with a single\nunified metric, PUFs with varying levels of stability, bias and available side\ninformation. In addition, it generalizes other measures to evaluate the\nsecurity level such as min-entropy and mutual information. We evaluate\nguesswork-based security of some measured SRAM and Ring Oscillator PUFs as an\nexample and compare them with LEDPUF to show that stability has a more severe\nimpact on the PUF security than biased responses. Furthermore, we find the\nguesswork of three new problems: Guesswork under probability of attack failure,\nthe guesswork of idealized version of a message authentication code, and the\nguesswork of strong PUFs that are used for authentication.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2017 23:02:19 GMT"}], "update_date": "2017-01-23", "authors_parsed": [["Wang", "Wei-Che", ""], ["Yona", "Yair", ""], ["Diggavi", "Suhas", ""], ["Gupta", "Puneet", ""]]}, {"id": "1701.05681", "submitter": "Edwin Dauber Jr.", "authors": "Edwin Dauber, Aylin Caliskan, Richard Harang, Gregory Shearer, Michael\n  Weisman, Frederica Nelson, Rachel Greenstadt", "title": "Git Blame Who?: Stylistic Authorship Attribution of Small, Incomplete\n  Source Code Fragments", "comments": null, "journal-ref": "Dauber, E., Caliskan, A., Harang, R., et al. (2019). Git Blame\n  Who?: Stylistic Authorship Attribution of Small, Incomplete Source Code\n  Fragments. Proceedings on Privacy Enhancing Technologies, 2019(3), pp.\n  389-408", "doi": "10.2478/popets-2019-0053", "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program authorship attribution has implications for the privacy of\nprogrammers who wish to contribute code anonymously. While previous work has\nshown that complete files that are individually authored can be attributed, we\nshow here for the first time that accounts belonging to open source\ncontributors containing short, incomplete, and typically uncompilable fragments\ncan also be effectively attributed.\n  We propose a technique for authorship attribution of contributor accounts\ncontaining small source code samples, such as those that can be obtained from\nversion control systems or other direct comparison of sequential versions. We\nshow that while application of previous methods to individual small source code\nsamples yields an accuracy of about 73% for 106 programmers as a baseline, by\nensembling and averaging the classification probabilities of a sufficiently\nlarge set of samples belonging to the same author we achieve 99% accuracy for\nassigning the set of samples to the correct author. Through these results, we\ndemonstrate that attribution is an important threat to privacy for programmers\neven in real-world collaborative environments such as GitHub. Additionally, we\npropose the use of calibration curves to identify samples by unknown and\npreviously unencountered authors in the open world setting. We show that we can\nalso use these calibration curves in the case that we do not have linking\ninformation and thus are forced to classify individual samples directly. This\nis because the calibration curves allow us to identify which samples are more\nlikely to have been correctly attributed. Using such a curve can help an\nanalyst choose a cut-off point which will prevent most misclassifications, at\nthe cost of causing the rejection of some of the more dubious correct\nattributions.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jan 2017 04:17:30 GMT"}, {"version": "v2", "created": "Thu, 16 Mar 2017 22:18:24 GMT"}, {"version": "v3", "created": "Fri, 26 Jul 2019 00:43:15 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Dauber", "Edwin", ""], ["Caliskan", "Aylin", ""], ["Harang", "Richard", ""], ["Shearer", "Gregory", ""], ["Weisman", "Michael", ""], ["Nelson", "Frederica", ""], ["Greenstadt", "Rachel", ""]]}, {"id": "1701.05955", "submitter": "Amirsina Torfi", "authors": "Amirsina Torfi, Sobhan Soleymani, Seyed Mehdi Iranmanesh, Hadi Kazemi,\n  Rouzbeh Asghari Shirvani, Vahid Tabataba Vakili", "title": "Polar Coding for Achieving the Capacity of Marginal Channels in\n  Nonbinary-Input Setting", "comments": "Accepted to be published in \"51th Conference on Information Sciences\n  and Systems\", Baltimore, Maryland", "journal-ref": "51th Annual Conference on Information Sciences and Systems (CISS),\n  1-6 (2017)", "doi": "10.1109/CISS.2017.7926162", "report-no": null, "categories": "cs.IT cs.CC cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving information-theoretic security using explicit coding scheme in\nwhich unlimited computational power for eavesdropper is assumed, is one of the\nmain topics is security consideration. It is shown that polar codes are\ncapacity achieving codes and have a low complexity in encoding and decoding. It\nhas been proven that polar codes reach to secrecy capacity in the binary-input\nwiretap channels in symmetric settings for which the wiretapper's channel is\ndegraded with respect to the main channel. The first task of this paper is to\npropose a coding scheme to achieve secrecy capacity in asymmetric\nnonbinary-input channels while keeping reliability and security conditions\nsatisfied. Our assumption is that the wiretap channel is stochastically\ndegraded with respect to the main channel and message distribution is\nunspecified. The main idea is to send information set over good channels for\nBob and bad channels for Eve and send random symbols for channels that are good\nfor both. In this scheme the frozen vector is defined over all possible choices\nusing polar codes ensemble concept. We proved that there exists a frozen vector\nfor which the coding scheme satisfies reliability and security conditions. It\nis further shown that uniform distribution of the message is the necessary\ncondition for achieving secrecy capacity.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jan 2017 00:32:34 GMT"}, {"version": "v2", "created": "Mon, 6 Feb 2017 22:18:32 GMT"}], "update_date": "2017-05-25", "authors_parsed": [["Torfi", "Amirsina", ""], ["Soleymani", "Sobhan", ""], ["Iranmanesh", "Seyed Mehdi", ""], ["Kazemi", "Hadi", ""], ["Shirvani", "Rouzbeh Asghari", ""], ["Vakili", "Vahid Tabataba", ""]]}, {"id": "1701.06481", "submitter": "Jan Reineke", "authors": "Pablo Ca\\~nones and Boris K\\\"opf and Jan Reineke", "title": "Security Analysis of Cache Replacement Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern computer architectures share physical resources between different\nprograms in order to increase area-, energy-, and cost-efficiency.\nUnfortunately, sharing often gives rise to side channels that can be exploited\nfor extracting or transmitting sensitive information. We currently lack\ntechniques for systematic reasoning about this interplay between security and\nefficiency. In particular, there is no established way for quantifying security\nproperties of shared caches.\n  In this paper, we propose a novel model that enables us to characterize\nimportant security properties of caches. Our model encompasses two aspects: (1)\nThe amount of information that can be absorbed by a cache, and (2) the amount\nof information that can effectively be extracted from the cache by an\nadversary. We use our model to compute both quantities for common cache\nreplacement policies (FIFO, LRU, and PLRU) and to compare their isolation\nproperties. We further show how our model for information extraction leads to\nan algorithm that can be used to improve the bounds delivered by the CacheAudit\nstatic analyzer.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2017 16:27:30 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Ca\u00f1ones", "Pablo", ""], ["K\u00f6pf", "Boris", ""], ["Reineke", "Jan", ""]]}, {"id": "1701.06562", "submitter": "Qiang Cao", "authors": "Qiang Cao, Vamsi Thummala, Jeffrey S. Chase, Yuanjun Yao, Bing Xie", "title": "Certificate Linking and Caching for Logical Trust", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SAFE is a data-centric platform for building multi-domain networked systems,\ni.e., systems whose participants are controlled by different principals.\nParticipants make trust decisions by issuing local queries over logic content\nexchanged in certificates. The contribution of SAFE is to address a key barrier\nto practical use of logical trust: the problem of identifying, gathering, and\nassembling the certificates that are relevant to each trust decision.\n  SAFE uses a simple linking abstraction to organize and share certificates\naccording to scripted primitives that implement the application's trust kernel\nand isolate it from logic concerns. We show that trust scripting with logical\ndata exchange yields compact trust cores for example applications: federated\nnaming, nested groups and roles, secure IP prefix delegation and routing,\nattestation-based access control, and a federated infrastructure-as-a-service\nsystem. Linking allows granular control over dynamic logic content based on\ndependency relationships, enabling a logic server to make secure inferences at\nhigh throughput.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jan 2017 21:05:17 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Cao", "Qiang", ""], ["Thummala", "Vamsi", ""], ["Chase", "Jeffrey S.", ""], ["Yao", "Yuanjun", ""], ["Xie", "Bing", ""]]}, {"id": "1701.06726", "submitter": "Iddo Bentov", "authors": "Iddo Bentov, Ranjit Kumaresan, Andrew Miller", "title": "Instantaneous Decentralized Poker", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present efficient protocols for amortized secure multiparty computation\nwith penalties and secure cash distribution, of which poker is a prime example.\nOur protocols have an initial phase where the parties interact with a\ncryptocurrency network, that then enables them to interact only among\nthemselves over the course of playing many poker games in which money changes\nhands.\n  The high efficiency of our protocols is achieved by harnessing the power of\nstateful contracts. Compared to the limited expressive power of Bitcoin\nscripts, stateful contracts enable richer forms of interaction between standard\nsecure computation and a cryptocurrency.\n  We formalize the stateful contract model and the security notions that our\nprotocols accomplish, and provide proofs using the simulation paradigm.\nMoreover, we provide a reference implementation in Ethereum/Solidity for the\nstateful contracts that our protocols are based on.\n  We also adopt our off-chain cash distribution protocols to the special case\nof stateful duplex micropayment channels, which are of independent interest. In\ncomparison to Bitcoin based payment channels, our duplex channel implementation\nis more efficient and has additional features.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2017 04:24:40 GMT"}, {"version": "v2", "created": "Thu, 26 Jan 2017 07:00:10 GMT"}, {"version": "v3", "created": "Sat, 11 Feb 2017 05:26:58 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Bentov", "Iddo", ""], ["Kumaresan", "Ranjit", ""], ["Miller", "Andrew", ""]]}, {"id": "1701.06743", "submitter": "Martin Ochoa", "authors": "Mart\\'in Ochoa, Sebastian Banescu, Cynthia Disenfeld, Gilles Barthe,\n  Vijay Ganesh", "title": "Reasoning about Probabilistic Defense Mechanisms against Remote Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite numerous countermeasures proposed by practitioners and researchers,\nremote control-flow alteration of programs with memory-safety vulnerabilities\ncontinues to be a realistic threat. Guaranteeing that complex software is\ncompletely free of memory-safety vulnerabilities is extremely expensive.\nProbabilistic countermeasures that depend on random secret keys are\ninteresting, because they are an inexpensive way to raise the bar for attackers\nwho aim to exploit memory-safety vulnerabilities. Moreover, some\ncountermeasures even support legacy systems. However, it is unclear how to\nquantify and compare the effectiveness of different probabilistic\ncountermeasures or combinations of such countermeasures. In this paper we\npropose a methodology to rigorously derive security bounds for probabilistic\ncountermeasures. We argue that by representing security notions in this setting\nas events in probabilistic games, similarly as done with cryptographic security\ndefinitions, concrete and asymptotic guarantees can be obtained against\nrealistic attackers. These guarantees shed light on the effectiveness of single\ncountermeasures and their composition and allow practitioners to more precisely\ngauge the risk of an attack.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2017 06:09:08 GMT"}, {"version": "v2", "created": "Fri, 17 Feb 2017 05:50:46 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Ochoa", "Mart\u00edn", ""], ["Banescu", "Sebastian", ""], ["Disenfeld", "Cynthia", ""], ["Barthe", "Gilles", ""], ["Ganesh", "Vijay", ""]]}, {"id": "1701.06817", "submitter": "Nidhi Rastogi", "authors": "Nidhi Rastogi, James Hendler", "title": "WhatsApp security and role of metadata in preserving privacy", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  WhatsApp messenger is arguably the most popular mobile app available on all\nsmart-phones. Over one billion people worldwide for free messaging, calling,\nand media sharing use it. In April 2016, WhatsApp switched to a default\nend-to-end encrypted service. This means that all messages (SMS), phone calls,\nvideos, audios, and any other form of information exchanged cannot be read by\nany unauthorized entity since WhatsApp. In this paper we analyze the WhatsApp\nmessaging platform and critique its security architecture along with a focus on\nits privacy preservation mechanisms. We report that the Signal Protocol, which\nforms the basis of WhatsApp end-to-end encryption, does offer protection\nagainst forward secrecy, and MITM to a large extent. Finally, we argue that\nsimply encrypting the end-to-end channel cannot preserve privacy. The metadata\ncan reveal just enough information to show connections between people, their\npatterns, and personal information. This paper elaborates on the security\narchitecture of WhatsApp and performs an analysis on the various protocols\nused. This enlightens us on the status quo of the app security and what further\nmeasures can be used to fill existing gaps without compromising the usability.\nWe start by describing the following (i) important concepts that need to be\nunderstood to properly understand security, (ii) the security architecture,\n(iii) security evaluation, (iv) followed by a summary of our work. Some of the\nimportant concepts that we cover in this paper before evaluating the\narchitecture are - end-to-end encryption (E2EE), signal protocol, and\ncurve25519. The description of the security architecture covers key management,\nend-to-end encryption in WhatsApp, Authentication Mechanism, Message Exchange,\nand finally the security evaluation. We then cover importance of metadata and\nrole it plays in conserving privacy with respect to whatsapp.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2017 11:21:33 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Rastogi", "Nidhi", ""], ["Hendler", "James", ""]]}, {"id": "1701.06823", "submitter": "Nidhi Rastogi", "authors": "Nidhi Rastogi, James Hendler", "title": "Graph Analytics for anomaly detection in homogeneous wireless networks -\n  A Simulation Approach", "comments": "5 pages, 4 figures, ICCWS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the Internet of Things (IoT) devices are exposed to various kinds of\nattacks when connected to the Internet. An attack detection mechanism that\nunderstands the limitations of these severely resource-constrained devices is\nnecessary. This is important since current approaches are either customized for\nwireless networks or for the conventional Internet with heavy data\ntransmission. Also, the detection mechanism need not always be as\nsophisticated. Simply signaling that an attack is taking place may be enough in\nsome situations, for example in NIDS using anomaly detection. In graph\nnetworks, central nodes are the nodes that bear the most influence in the\nnetwork. The purpose of this research is to explore experimentally the\nrelationship between the behavior of central nodes and anomaly detection when\nan attack spreads through a network. As a result, we propose a novel anomaly\ndetection approach using this unique methodology which has been unexplored so\nfar in communication networks. Also, in the experiment, we identify presence of\nan attack originating and propagating throughout a network of IoT using our\nmethodology.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2017 11:46:03 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Rastogi", "Nidhi", ""], ["Hendler", "James", ""]]}, {"id": "1701.07044", "submitter": "Rotem Liss", "authors": "Michel Boyer, Matty Katz, Rotem Liss, Tal Mor", "title": "Experimentally feasible protocol for semiquantum key distribution", "comments": "6 pages", "journal-ref": "Phys. Rev. A 96, 062335 (2017)", "doi": "10.1103/PhysRevA.96.062335", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum key distribution (QKD) protocols make it possible for two quantum\nparties to generate a secret shared key. Semiquantum key distribution (SQKD)\nprotocols, such as \"QKD with classical Bob\" and \"QKD with classical Alice\"\n(that have both been proven robust), achieve this goal even if one of the\nparties is classical. However, existing SQKD protocols are not experimentally\nfeasible with current technology. Here we suggest a new protocol, \"Classical\nAlice with a controllable mirror\", that can be experimentally implemented with\ncurrent technology (using 4-level systems instead of qubits), and we prove it\nto be robust.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2017 19:14:12 GMT"}, {"version": "v2", "created": "Fri, 29 Dec 2017 16:15:32 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Boyer", "Michel", ""], ["Katz", "Matty", ""], ["Liss", "Rotem", ""], ["Mor", "Tal", ""]]}, {"id": "1701.07075", "submitter": "Li-Chun Wang", "authors": "Yu-Jia Chen, Li-Chun Wang", "title": "Privacy Protection for Mobile Cloud Data: A Network Coding Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taking into account of both the huge computing power of intruders and\nuntrusted cloud servers, we develop an enhanced secure pseudonym scheme to\nprotect the privacy of mobile cloud data. To face the huge computing power\nchallenge, we develop an unconditionally secure lightweight network coding\npseudonym scheme. For the privacy issue of untrusted cloud server, we further\ndesign a two tier network coding to decouple the stored mobile cloud data from\nthe owner pseudonyms. Therefore, our proposed network coding based pseudonym\nscheme can simultaneously defend against attackers from both outside and\ninside. We implement our proposed two-tier light-weight network coding\nmechanism in a group location based service (LBS) using untrusted cloud\ndatabase. Compared to computationally secure Hash-based pseudonym, our proposed\nscheme is not only unconditionally secure, but also can reduce more than 90\npercent of processing time as well as 10 percent of energy consumption.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jan 2017 14:58:38 GMT"}], "update_date": "2017-01-26", "authors_parsed": [["Chen", "Yu-Jia", ""], ["Wang", "Li-Chun", ""]]}, {"id": "1701.07172", "submitter": "Prabhat Kushwaha", "authors": "Prabhat Kushwaha and Ayan Mahalanobis", "title": "A Probabilistic Baby-Step Giant-Step Algorithm", "comments": null, "journal-ref": "SECRYPT 2017", "doi": "10.5220/0006396304010406", "report-no": "ISBN 978-989-758-259-2", "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new algorithm to solve the discrete logarithm problem is\npresented which is similar to the usual baby-step giant-step algorithm. Our\nalgorithm exploits the order of the discrete logarithm in the multiplicative\ngroup of a finite field. Using randomization with parallelized collision\nsearch, our algorithm indicates some weakness in NIST curves over prime fields\nwhich are considered to be the most conservative and safest curves among all\nNIST curves.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jan 2017 06:03:28 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Kushwaha", "Prabhat", ""], ["Mahalanobis", "Ayan", ""]]}, {"id": "1701.07179", "submitter": "Doyen Sahoo", "authors": "Doyen Sahoo, Chenghao Liu, and Steven C.H. Hoi", "title": "Malicious URL Detection using Machine Learning: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malicious URL, a.k.a. malicious website, is a common and serious threat to\ncybersecurity. Malicious URLs host unsolicited content (spam, phishing,\ndrive-by exploits, etc.) and lure unsuspecting users to become victims of scams\n(monetary loss, theft of private information, and malware installation), and\ncause losses of billions of dollars every year. It is imperative to detect and\nact on such threats in a timely manner. Traditionally, this detection is done\nmostly through the usage of blacklists. However, blacklists cannot be\nexhaustive, and lack the ability to detect newly generated malicious URLs. To\nimprove the generality of malicious URL detectors, machine learning techniques\nhave been explored with increasing attention in recent years. This article aims\nto provide a comprehensive survey and a structural understanding of Malicious\nURL Detection techniques using machine learning. We present the formal\nformulation of Malicious URL Detection as a machine learning task, and\ncategorize and review the contributions of literature studies that addresses\ndifferent dimensions of this problem (feature representation, algorithm design,\netc.). Further, this article provides a timely and comprehensive survey for a\nrange of different audiences, not only for machine learning researchers and\nengineers in academia, but also for professionals and practitioners in\ncybersecurity industry, to help them understand the state of the art and\nfacilitate their own research and practical applications. We also discuss\npractical issues in system design, open research challenges, and point out some\nimportant directions for future research.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jan 2017 06:46:14 GMT"}, {"version": "v2", "created": "Thu, 16 Mar 2017 07:12:50 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2019 10:38:24 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Sahoo", "Doyen", ""], ["Liu", "Chenghao", ""], ["Hoi", "Steven C. H.", ""]]}, {"id": "1701.07232", "submitter": "Rishabh Singh", "authors": "Patrice Godefroid, Hila Peleg, Rishabh Singh", "title": "Learn&Fuzz: Machine Learning for Input Fuzzing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.LG cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzing consists of repeatedly testing an application with modified, or\nfuzzed, inputs with the goal of finding security vulnerabilities in\ninput-parsing code. In this paper, we show how to automate the generation of an\ninput grammar suitable for input fuzzing using sample inputs and\nneural-network-based statistical machine-learning techniques. We present a\ndetailed case study with a complex input format, namely PDF, and a large\ncomplex security-critical parser for this format, namely, the PDF parser\nembedded in Microsoft's new Edge browser. We discuss (and measure) the tension\nbetween conflicting learning and fuzzing goals: learning wants to capture the\nstructure of well-formed inputs, while fuzzing wants to break that structure in\norder to cover unexpected code paths and find bugs. We also present a new\nalgorithm for this learn&fuzz challenge which uses a learnt input probability\ndistribution to intelligently guide where to fuzz inputs.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jan 2017 10:01:39 GMT"}], "update_date": "2017-01-26", "authors_parsed": [["Godefroid", "Patrice", ""], ["Peleg", "Hila", ""], ["Singh", "Rishabh", ""]]}, {"id": "1701.07331", "submitter": "Brian Thompson", "authors": "Brian Thompson, Richard Harang", "title": "Identifying Key Cyber-Physical Terrain (Extended Version)", "comments": "16 pages, extended version of paper published in Proceedings of the\n  International Workshop on Security & Privacy Analytics (IWSPA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high mobility of Army tactical networks, combined with their close\nproximity to hostile actors, elevates the risks associated with short-range\nnetwork attacks. The connectivity model for such short range connections under\nactive operations is extremely fluid, and highly dependent upon the physical\nspace within which the element is operating, as well as the patterns of\nmovement within that space. To handle these dependencies, we introduce the\nnotion of \"key cyber-physical terrain\": locations within an area of operations\nthat allow for effective control over the spread of proximity-dependent malware\nin a mobile tactical network, even as the elements of that network are in\nconstant motion with an unpredictable pattern of node-to-node connectivity. We\nprovide an analysis of movement models and approximation strategies for finding\nsuch critical nodes, and demonstrate via simulation that we can identify such\nkey cyber-physical terrain quickly and effectively.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jan 2017 14:23:25 GMT"}], "update_date": "2017-01-27", "authors_parsed": [["Thompson", "Brian", ""], ["Harang", "Richard", ""]]}, {"id": "1701.07416", "submitter": "Jean-Pierre  Tillich", "authors": "Thomas Debris-Alazard and Jean-Pierre Tillich", "title": "Statistical Decoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The security of code-based cryptography relies primarily on the hardness of\ngeneric decoding with linear codes. The best generic decoding algorithms are\nall improvements of an old algorithm due to Prange: they are known under the\nname of information set decoding techniques (ISD). A while ago a generic\ndecoding algorithm which does not belong to this family was proposed:\nstatistical decoding. It is a randomized algorithm that requires the\ncomputation of a large set of parity-check equations of moderate weight. We\nsolve here several open problems related to this decoding algorithm.\n  We give in particular the asymptotic complexity of this algorithm, give a\nrather efficient way of computing the parity-check equations needed for it\ninspired by ISD techniques and give a lower bound on its complexity showing\nthat when it comes to decoding on the Gilbert-Varshamov bound it can never be\nbetter than Prange's algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jan 2017 18:22:47 GMT"}, {"version": "v2", "created": "Wed, 8 Feb 2017 18:16:44 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Debris-Alazard", "Thomas", ""], ["Tillich", "Jean-Pierre", ""]]}, {"id": "1701.07518", "submitter": "Amr Abdelaziz", "authors": "Amr Abdelaziz, C. Emre Koksal, Hesham El Gamal, Ashraf D. Elbayoumy", "title": "On The Compound MIMO Wiretap Channel with Mean Feedback", "comments": "To appear at ISIT 2017 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compound MIMO wiretap channel with double sided uncertainty is considered\nunder channel mean information model. In mean information model, channel\nvariations are centered around its mean value which is fed back to the\ntransmitter. We show that the worst case main channel is anti-parallel to the\nchannel mean information resulting in an overall unit rank channel. Further,\nthe worst eavesdropper channel is shown to be isotropic around its mean\ninformation. Accordingly, we provide the capacity achieving beamforming\ndirection. We show that the saddle point property holds under mean information\nmodel, and thus, compound secrecy capacity equals to the worst case capacity\nover the class of uncertainty. Moreover, capacity achieving beamforming\ndirection is found to require matrix inversion, thus, we derive the null\nsteering (NS) beamforming as an alternative suboptimal solution that does not\nrequire matrix inversion. NS beamformer is in the direction orthogonal to the\neavesdropper mean channel that maintains the maximum possible gain in mean main\nchannel direction. Extensive computer simulation reveals that NS performs very\nclose to the optimal solution. It also verifies that, NS beamforming\noutperforms both maximum ratio transmission (MRT) and zero forcing (ZF)\nbeamforming approaches over the entire SNR range. Finally, An equivalence\nrelation with MIMO wiretap channel in Rician fading environment is established.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jan 2017 23:34:39 GMT"}, {"version": "v2", "created": "Fri, 24 Feb 2017 02:17:42 GMT"}, {"version": "v3", "created": "Thu, 9 Mar 2017 08:28:39 GMT"}, {"version": "v4", "created": "Wed, 3 May 2017 16:18:36 GMT"}], "update_date": "2017-05-04", "authors_parsed": [["Abdelaziz", "Amr", ""], ["Koksal", "C. Emre", ""], ["Gamal", "Hesham El", ""], ["Elbayoumy", "Ashraf D.", ""]]}, {"id": "1701.07666", "submitter": "Bogdan Groza", "authors": "Bogdan Groza", "title": "Traffic models with adversarial vehicle behaviour", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the impact of adversarial actions on vehicles in traffic. Current\nadvances in assisted/autonomous driving technologies are supposed to reduce the\nnumber of casualties, but this seems to be desired despite the recently proved\ninsecurity of in-vehicle communication buses or components. Fortunately to some\nextent, while compromised cars have become a reality, the numerous attacks\nreported so far on in-vehicle electronics are exclusively concerned with\nimpairments of a single target. In this work we put adversarial behavior under\na more complex scenario where driving decisions deluded by corrupted\nelectronics can affect more than one vehicle. Particularly, we focus our\nattention on chain collisions involving multiple vehicles that can be amplified\nby simple adversarial interventions, e.g., delaying taillights or falsifying\nspeedometer readings. We provide metrics for assessing adversarial impact and\nconsider safety margins against adversarial actions. Moreover, we discuss\nintelligent adversarial behaviour by which the creation of rogue platoons is\npossible and speed manipulations become stealthy to human drivers. We emphasize\nthat our work does not try to show the mere fact that imprudent speeds and\nheadways lead to chain-collisions, but points out that an adversary may favour\nsuch scenarios (eventually keeping his actions stealthy for human drivers) and\nfurther asks for quantifying the impact of adversarial activity or whether\nexisting traffic regulations are prepared for such situations.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2017 11:57:48 GMT"}], "update_date": "2017-01-27", "authors_parsed": [["Groza", "Bogdan", ""]]}, {"id": "1701.07671", "submitter": "Fatmah Bamashmoos", "authors": "Fatmah Bamashmoos, Ian Holyer, Theo Tryfonas, Przemyslaw Woznowski", "title": "Towards Secure SPARQL Queries in Semantic Web Applications using PHP\n  (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Semantic Web (SW) is a significant advancement in the field of Internet\ntechnologies and an uncharted territory as far as security is concerned. In\nthis paper we investigate and assess the impact of known attacks of\nSPARQL/SPARUL injections on Semantic Web applications developed in PHP. We\nhighlight future challenges of developing robust Semantic Web applications\nusing PHP. Our results demonstrate and quantify impacts on Confidentiality,\nIntegrity and Availability (CIA) breaches of data in Semantic Web applications.\nOur recommendations are targeted to PHP developers, to encourage them to\nintegrate security as early in their design and coding practice as possible.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2017 12:27:56 GMT"}], "update_date": "2017-01-27", "authors_parsed": [["Bamashmoos", "Fatmah", ""], ["Holyer", "Ian", ""], ["Tryfonas", "Theo", ""], ["Woznowski", "Przemyslaw", ""]]}, {"id": "1701.07676", "submitter": "Gianmarco Baldini", "authors": "Gianmarco Baldini, Gary Steri, Raimondo Giuliani, Vladimir Kyovtorov", "title": "Mobile phone identification through the built-in magnetometers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile phones identification through their built in components has been\ndemonstrated in literature for various types of sensors including the camera,\nmicrophones and accelerometers. The identification is performed by the\nexploitation of the small but significant differences in the electronic\ncircuits generated during the production process. Thus, these differences\nbecome an intrinsic property of the electronic components, which can be\ndetected and become an unique fingerprint of the component and of the mobile\nphone. In this paper, we investigate the identification of mobile phones\nthrough their builtin magnetometers, which has not been reported in literature\nyet. Magnetometers are stimulated with different waveforms using a solenoid\nconnected to a computer s audio board. The identification is performed\nanalyzing the digital output of the magnetometer through the use of statistical\nfeatures and the Support Vector Machine (SVM) machine learning algorithm. We\nprove that this technique can distinguish different models and brands with very\nhigh accuracy but it can only distinguish phones of the same model with limited\naccuracy.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2017 12:42:45 GMT"}], "update_date": "2017-01-27", "authors_parsed": [["Baldini", "Gianmarco", ""], ["Steri", "Gary", ""], ["Giuliani", "Raimondo", ""], ["Kyovtorov", "Vladimir", ""]]}, {"id": "1701.07774", "submitter": "Ying Dong", "authors": "Ying Dong, Yuqing Zhang", "title": "Adaptively Detecting Malicious Queries in Web Attacks", "comments": null, "journal-ref": null, "doi": "10.1007/s11432-017-9288-4", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web request query strings (queries), which pass parameters to the referenced\nresource, are always manipulated by attackers to retrieve sensitive data and\neven take full control of victim web servers and web applications. However,\nexisting malicious query detection approaches in the current literature cannot\ncope with changing web attacks with constant detection models. In this paper,\nwe propose AMODS, an adaptive system that periodically updates the detection\nmodel to detect the latest unknown attacks. We also propose an adaptive\nlearning strategy, called SVM HYBRID, leveraged by our system to minimize\nmanual work. In the evaluation, an up-to-date detection model is trained on a\nten-day query dataset collected from an academic institute's web server logs.\nOur system outperforms existing web attack detection methods, with an F-value\nof 94.79% and FP rate of 0.09%. The total number of malicious queries obtained\nby SVM HYBRID is 2.78 times that by the popular Support Vector Machine Adaptive\nLearning (SVM AL) method. The malicious queries obtained can be used to update\nthe Web Application Firewall (WAF) signature library.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2017 16:56:01 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 09:09:04 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Dong", "Ying", ""], ["Zhang", "Yuqing", ""]]}, {"id": "1701.07807", "submitter": "Hua Sun", "authors": "Hua Sun and Syed A. Jafar", "title": "Private Information Retrieval from MDS Coded Data with Colluding\n  Servers: Settling a Conjecture by Freij-Hollanti et al.", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.IR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A $(K, N, T, K_c)$ instance of the MDS-TPIR problem is comprised of $K$\nmessages and $N$ distributed servers. Each message is separately encoded\nthrough a $(K_c, N)$ MDS storage code. A user wishes to retrieve one message,\nas efficiently as possible, while revealing no information about the desired\nmessage index to any colluding set of up to $T$ servers. The fundamental limit\non the efficiency of retrieval, i.e., the capacity of MDS-TPIR is known only at\nthe extremes where either $T$ or $K_c$ belongs to $\\{1,N\\}$. The focus of this\nwork is a recent conjecture by Freij-Hollanti, Gnilke, Hollanti and Karpuk\nwhich offers a general capacity expression for MDS-TPIR. We prove that the\nconjecture is false by presenting as a counterexample a PIR scheme for the\nsetting $(K, N, T, K_c) = (2,4,2,2)$, which achieves the rate $3/5$, exceeding\nthe conjectured capacity, $4/7$. Insights from the counterexample lead us to\ncapacity characterizations for various instances of MDS-TPIR including all\ncases with $(K, N, T, K_c) = (2,N,T,N-1)$, where $N$ and $T$ can be arbitrary.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2017 18:35:53 GMT"}, {"version": "v2", "created": "Mon, 30 Jan 2017 17:13:14 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Sun", "Hua", ""], ["Jafar", "Syed A.", ""]]}, {"id": "1701.07860", "submitter": "Xunchao Hu", "authors": "Xunchao Hu, Yao Cheng, Yue Duan, Andrew Henderson, Heng Yin", "title": "JSForce: A Forced Execution Engine for Malicious JavaScript Detection", "comments": "15 pages,conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The drastic increase of JavaScript exploitation attacks has led to a strong\ninterest in developing techniques to enable malicious JavaScript analysis.\nExisting analysis tech- niques fall into two general categories: static\nanalysis and dynamic analysis. Static analysis tends to produce inaccurate\nresults (both false positive and false negative) and is vulnerable to a wide\nseries of obfuscation techniques. Thus, dynamic analysis is constantly gaining\npopularity for exposing the typical features of malicious JavaScript. However,\nexisting dynamic analysis techniques possess limitations such as limited code\ncoverage and incomplete environment setup, leaving a broad attack surface for\nevading the detection. To overcome these limitations, we present the design and\nimplementation of a novel JavaScript forced execution engine named JSForce\nwhich drives an arbitrary JavaScript snippet to execute along different paths\nwithout any input or environment setup. We evaluate JSForce using 220,587 HTML\nand 23,509 PDF real- world samples. Experimental results show that by adopting\nour forced execution engine, the malicious JavaScript detection rate can be\nsubstantially boosted by 206.29% using same detection policy without any\nnoticeable false positive increase. We also make JSForce publicly available as\nan online service and will release the source code to the security community\nupon the acceptance for publication.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2017 19:59:32 GMT"}], "update_date": "2017-01-30", "authors_parsed": [["Hu", "Xunchao", ""], ["Cheng", "Yao", ""], ["Duan", "Yue", ""], ["Henderson", "Andrew", ""], ["Yin", "Heng", ""]]}, {"id": "1701.07914", "submitter": "Takeshi Koshiba", "authors": "Ryota Iwamoto, Takeshi Koshiba", "title": "Non-Malleable Codes Against Affine Errors", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-malleable code is a relaxed version of error-correction codes and the\ndecoding of modified codewords results in the original message or a completely\nunrelated value. Thus, if an adversary corrupts a codeword then he cannot get\nany information from the codeword. This means that non-malleable codes are\nuseful to provide a security guarantee in such situations that the adversary\ncan overwrite the encoded message. In 2010, Dziembowski et al. showed a\nconstruction for non-malleable codes against the adversary who can falsify\ncodewords bitwise independently. In this paper, we consider an extended\nadversarial model (affine error model) where the adversary can falsify\ncodewords bitwise independently or replace some bit with the value obtained by\napplying an affine map over a limited number of bits. We prove that the\nnon-malleable codes (for the bitwise error model) provided by Dziembowski et\nal. are still non-malleable against the adversary in the affine error model.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jan 2017 00:47:35 GMT"}], "update_date": "2017-01-30", "authors_parsed": [["Iwamoto", "Ryota", ""], ["Koshiba", "Takeshi", ""]]}, {"id": "1701.08034", "submitter": "Florian Kohnh\\\"auser", "authors": "Florian Kohnh\\\"auser, Niklas B\\\"uscher, Sebastian Gabmeyer, Stefan\n  Katzenbeisser", "title": "Scalable Attestation Resilient to Physical Attacks for Embedded Devices\n  in Mesh Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interconnected embedded devices are increasingly used invarious scenarios,\nincluding industrial control, building automation, or emergency communication.\nAs these systems commonly process sensitive information or perform safety\ncritical tasks, they become appealing targets for cyber attacks. A promising\ntechnique to remotely verify the safe and secure operation of networked\nembedded devices is remote attestation. However, existing attestation protocols\nonly protect against software attacks or show very limited scalability. In this\npaper, we present the first scalable attestation protocol for interconnected\nembedded devices that is resilient to physical attacks. Based on the assumption\nthat physical attacks require an adversary to capture and disable devices for\nsome time, our protocol identifies devices with compromised hardware and\nsoftware. Compared to existing solutions, our protocol reduces ommunication\ncomplexity and runtimes by orders of magnitude, precisely identifies\ncompromised devices, supports highly dynamic and partitioned network\ntopologies, and is robust against failures. We show the security of our\nprotocol and evaluate it in static as well as dynamic network topologies. Our\nresults demonstrate that our protocol is highly efficient in well-connected\nnetworks and robust to network disruptions.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jan 2017 12:42:52 GMT"}], "update_date": "2017-01-30", "authors_parsed": [["Kohnh\u00e4user", "Florian", ""], ["B\u00fcscher", "Niklas", ""], ["Gabmeyer", "Sebastian", ""], ["Katzenbeisser", "Stefan", ""]]}, {"id": "1701.08058", "submitter": "Emrah Akyol", "authors": "Emrah Akyol, Kenneth Rose, Tamer Basar, Cedric Langbort", "title": "Optimal Communication Strategies in Networked Cyber-Physical Systems\n  with Adversarial Elements", "comments": "submitted to IEEE Transactions on Signal and Information Processing\n  over Networks, Special Issue on Distributed Signal Processing for Security\n  and Privacy in Networked Cyber-Physical Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR cs.IT cs.MA math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies optimal communication and coordination strategies in\ncyber-physical systems for both defender and attacker within a game-theoretic\nframework. We model the communication network of a cyber-physical system as a\nsensor network which involves one single Gaussian source observed by many\nsensors, subject to additive independent Gaussian observation noises. The\nsensors communicate with the estimator over a coherent Gaussian multiple access\nchannel. The aim of the receiver is to reconstruct the underlying source with\nminimum mean squared error. The scenario of interest here is one where some of\nthe sensors are captured by the attacker and they act as the adversary\n(jammer): they strive to maximize distortion. The receiver (estimator) knows\nthe captured sensors but still cannot simply ignore them due to the multiple\naccess channel, i.e., the outputs of all sensors are summed to generate the\nestimator input. We show that the ability of transmitter sensors to secretly\nagree on a random event, that is \"coordination\", plays a key role in the\nanalysis...\n", "versions": [{"version": "v1", "created": "Fri, 27 Jan 2017 14:15:12 GMT"}], "update_date": "2017-01-30", "authors_parsed": [["Akyol", "Emrah", ""], ["Rose", "Kenneth", ""], ["Basar", "Tamer", ""], ["Langbort", "Cedric", ""]]}, {"id": "1701.08241", "submitter": "Yansong Gao", "authors": "Yansong Gao, Hua Ma, Geifei Li, Shaza Zeitouni, Said F. Al-Sarawi,\n  Derek Abbott, Ahmad-Reza Sadeghi, Damith C. Ranasinghe", "title": "Exploiting PUF Models for Error Free Response Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical unclonable functions (PUF) extract secrets from randomness inherent\nin manufacturing processes. PUFs are utilized for basic cryptographic tasks\nsuch as authentication and key generation, and more recently, to realize key\nexchange and bit commitment requiring a large number of error free responses\nfrom a strong PUF. We propose an approach to eliminate the need to implement\nexpensive on-chip error correction logic implementation and the associated\nhelper data storage to reconcile naturally noisy PUF responses. In particular,\nwe exploit a statistical model of an Arbiter PUF (APUF) constructed under the\nnominal operating condition during the challenge response enrollment phase by a\ntrusted party to judiciously select challenges that yield error-free responses\neven across a wide operating conditions, specifically, a $ \\pm 20\\% $ supply\nvoltage variation and a $ 40^{\\crc} $ temperature variation. We validate our\napproach using measurements from two APUF datasets. Experimental results\nindicate that large number of error-free responses can be generated on demand\nunder worst-case when PUF response error rate is up to 16.68\\%.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2017 03:06:33 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Gao", "Yansong", ""], ["Ma", "Hua", ""], ["Li", "Geifei", ""], ["Zeitouni", "Shaza", ""], ["Al-Sarawi", "Said F.", ""], ["Abbott", "Derek", ""], ["Sadeghi", "Ahmad-Reza", ""], ["Ranasinghe", "Damith C.", ""]]}, {"id": "1701.08308", "submitter": "Christos Perentis", "authors": "Christos Perentis, Michele Vescovi, Chiara Leonardi, Corrado Moiso,\n  Mirco Musolesi, Fabio Pianesi, Bruno Lepri", "title": "Anonymous or not? Understanding the Factors Affecting Personal Mobile\n  Data Disclosure", "comments": "19 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide adoption of mobile devices and social media platforms have\ndramatically increased the collection and sharing of personal information. More\nand more frequently, users are called to take decisions concerning the\ndisclosure of their personal information. In this study, we investigate the\nfactors affecting users' choices toward the disclosure of their personal data,\nincluding not only their demographic and self-reported individual\ncharacteristics, but also their social interactions and their mobility patterns\ninferred from months of mobile phone data activity. We report the findings of a\nfield-study conducted with a community of 63 subjects provided with (i) a\nsmart-phone and (ii) a Personal Data Store (PDS) enabling them to control the\ndisclosure of their data. We monitor the sharing behavior of our participants\nthrough the PDS, and evaluate the contribution of different factors affecting\ntheir disclosing choices of location and social interaction data. Our analysis\nshows that social interaction inferred by mobile phones is an important factor\nrevealing willingness to share, regardless of the data type. In addition, we\nprovide further insights on the individual traits relevant to the prediction of\nsharing behavior.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2017 18:00:54 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Perentis", "Christos", ""], ["Vescovi", "Michele", ""], ["Leonardi", "Chiara", ""], ["Moiso", "Corrado", ""], ["Musolesi", "Mirco", ""], ["Pianesi", "Fabio", ""], ["Lepri", "Bruno", ""]]}, {"id": "1701.08312", "submitter": "Ronald Rivest", "authors": "Ronald L. Rivest", "title": "ClipAudit: A Simple Risk-Limiting Post-Election Audit", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple risk-limiting audit for elections, ClipAudit. To\ndetermine whether candidate A (the reported winner) actually beat candidate B\nin a plurality election, ClipAudit draws ballots at random, without\nreplacement, until either all cast ballots have been drawn, or until \\[ a - b\n\\ge \\beta \\sqrt{a+b}\n  \\] where $a$ is the number of ballots in the sample for the reported winner\nA, and $b$ is the number of ballots in the sample for opponent B, and where\n$\\beta$ is a constant determined a priori as a function of the number $n$ of\nballots cast and the risk-limit $\\alpha$. ClipAudit doesn't depend on the\nunofficial margin (as does Bravo). We show how to extend ClipAudit to contests\nwith multiple winners or losers, or to multiple contests.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2017 18:51:10 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Rivest", "Ronald L.", ""]]}, {"id": "1701.08371", "submitter": "Raphael Couturier", "authors": "Hassan Noura and Lama Sleem and Rapha\\\"el Couturier", "title": "A Revision of a New Chaos-Based Image Encryption System: Weaknesses and\n  Limitations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lately, multimedia encryption has been the focus of attention in many\nresearches. Recently, a large number of encryption algorithms has been\npresented to protect image contents.The main objective of modern image\nencryption schemes is to reduce the computation complexity in order to respond\nto the real time multimedia and/or limited resources requirements without\ndegrading the high level of security. In fact, most of the recent solutions are\nbased on the chaotic theory. However, the majority of chaotic systems suffers\nfrom different limitations and their implementation is difficult at the\nhardware level because of the non integer operations that are employed\nrequiring huge resources and latency. In this paper, we analyze the new\nchaos-based image encryption system presented in~\\cite{el2016new}. It uses a\nstatic binary diffusion layer, followed by a key dependent bit-permutation\nlayer that only iterates for one round. Based on their results in this paper,\nwe claim that the uniformity and avalanche effect can be reached from the first\nround. However, we tried to verify the results but our conclusion was that\nthese results were wrong because it was shown that at least 6 iterations are\nnecessary to ensure the required cryptographic performance such as the\nplain-sensitivity property. Therefore, the required execution time must be\nmultiplied by 6 and consequently this will increase the latency. In addition to\nall aforementioned problems, we find that ensuring the avalanche effect in the\nwhole image introduces a high error propagation. In order to solve this\nproblem, we recommend to ensure the avalanche effect in the level of blocks\ninstead of the whole image.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jan 2017 12:56:59 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Noura", "Hassan", ""], ["Sleem", "Lama", ""], ["Couturier", "Rapha\u00ebl", ""]]}, {"id": "1701.08419", "submitter": "Nicolas Ruiz", "authors": "Nicolas Ruiz", "title": "On some consequences of the permutation paradigm for data anonymization:\n  centrality of permutation matrices, universal measures of disclosure risk and\n  information loss, evaluation by dominance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the permutation paradigm has been proposed in data anonymization to\ndescribe any micro data masking method as permutation, paving the way for\nperforming meaningful analytical comparisons of methods, something that is\ndifficult currently in statistical disclosure control research. This paper\nexplores some consequences of this paradigm by establishing some class of\nuniversal measures of disclosure risk and information loss that can be used for\nthe evaluation and comparison of any method, under any parametrization and\nindependently of the characteristics of the data to be anonymized. These\nmeasures lead to the introduction in data anonymization of the concepts of\ndominance in disclosure risk and information loss, which formalise the fact\nthat different parties involved in micro data transaction can all have\ndifferent sensitivities to privacy and information.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jan 2017 19:22:16 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Ruiz", "Nicolas", ""]]}, {"id": "1701.08421", "submitter": "Iddo Bentov", "authors": "Iddo Bentov, Alex Mizrahi, Meni Rosenfeld", "title": "Decentralized Prediction Market without Arbiters", "comments": "4th Bitcoin workshop - Financial Cryptography 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a prediction market in which all aspects are controlled by market\nforces, in particular the correct outcomes of events are decided by the market\nitself rather than by trusted arbiters. This kind of a decentralized prediction\nmarket can sustain betting on events whose outcome may remain unresolved for a\nlong or even unlimited time period, and can facilitate trades among\nparticipants who are spread across diverse geographical locations, may wish to\nremain anonymous and/or avoid burdensome identification procedures, and are\ndistrustful of each other. We describe how a cryptocurrency such as Bitcoin can\nbe enhanced to accommodate a truly decentralized prediction market, by\nemploying an innovative variant of the Colored Coins concept. We examine the\ngame-theoretic properties of our design, and offer extensions that enable other\nfinancial instruments as well as real-time exchange.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jan 2017 19:43:10 GMT"}, {"version": "v2", "created": "Tue, 31 Jan 2017 03:25:35 GMT"}, {"version": "v3", "created": "Tue, 7 Mar 2017 21:54:43 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Bentov", "Iddo", ""], ["Mizrahi", "Alex", ""], ["Rosenfeld", "Meni", ""]]}, {"id": "1701.08644", "submitter": "Sinong Wang", "authors": "Sinong Wang and Ness Shroff", "title": "Security Game with Non-additive Utilities and Multiple Attacker\n  Resources", "comments": "accepted in Sigmetrics 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been significant interest in studying security games for modeling\nthe interplay of attacks and defenses on various systems involving critical\ninfrastructure, financial system security, political campaigns, and civil\nsafeguarding. However, existing security game models typically either assume\nadditive utility functions, or that the attacker can attack only one target.\nSuch assumptions lead to tractable analysis, but miss key inherent dependencies\nthat exist among different targets in current complex networks. In this paper,\nwe generalize the classical security game models to allow for non-additive\nutility functions. We also allow attackers to be able to attack multiple\ntargets. We examine such a general security game from a theoretical perspective\nand provide a unified view. In particular, we show that each security game is\nequivalent to a combinatorial optimization problem over a set system\n$\\varepsilon$, which consists of defender's pure strategy space. The key\ntechnique we use is based on the transformation, projection of a polytope, and\nthe elipsoid method. This work settles several open questions in security game\ndomain and significantly extends the state of-the-art of both the polynomial\nsolvable and NP-hard class of the security game.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jan 2017 15:18:03 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Wang", "Sinong", ""], ["Shroff", "Ness", ""]]}, {"id": "1701.08676", "submitter": "Christian Johansen", "authors": "Sergiu Bursuc and Christian Johansen and Shiwei Xu", "title": "Automated verification of dynamic root of trust protocols (long version)", "comments": "27 pages with Appendix", "journal-ref": "International Conference on Principles of Security and Trust. POST\n  2017. Lecture Notes in Computer Science, vol 10204, pp. 95-116. Springer", "doi": "10.1007/978-3-662-54455-6_5", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Automated verification of security protocols based on dynamic root of trust,\ntypically relying on protected hardware such as TPM, involves several\nchallenges that we address in this paper. We model the semantics of trusted\ncomputing platforms (including CPU, TPM, OS, and other essential components)\nand of associated protocols in a classical process calculus accepted by\nProVerif. As part of the formalization effort, we introduce new equational\ntheories for representing TPM specific platform states and dynamically loaded\nprograms. Formal models for such an extensive set of features cannot be readily\nhandled by ProVerif, due especially to the search space generated by unbounded\nextensions of TPM registers. In this context we introduce a transformation of\nthe TPM process, that simplifies the structure of the search space for\nautomated verification, while preserving the security properties of interest.\nThis allows to run ProVerif on our proposed models, so we can derive\nautomatically security guarantees for protocols running in a dynamic root of\ntrust context.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jan 2017 16:17:19 GMT"}, {"version": "v2", "created": "Tue, 7 Mar 2017 14:52:07 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Bursuc", "Sergiu", ""], ["Johansen", "Christian", ""], ["Xu", "Shiwei", ""]]}, {"id": "1701.08891", "submitter": "Shihao Yan", "authors": "Shihao Yan, Biao He, Yirui Cong, and Xiangyun Zhou", "title": "Covert Communication with Finite Blocklength in AWGN Channels", "comments": "Accepted by IEEE ICC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covert communication is to achieve a reliable transmission from a transmitter\nto a receiver while guaranteeing an arbitrarily small probability of this\ntransmission being detected by a warden. In this work, we study the covert\ncommunication in AWGN channels with finite blocklength, in which the number of\nchannel uses is finite. Specifically, we analytically prove that the entire\nblock (all available channel uses) should be utilized to maximize the effective\nthroughput of the transmission subject to a predetermined covert requirement.\nThis is a nontrivial result because more channel uses results in more\nobservations at the warden for detecting the transmission. We also determine\nthe maximum allowable transmit power per channel use, which is shown to\ndecrease as the blocklength increases. Despite the decrease in the maximum\nallowable transmit power per channel use, the maximum allowable total power\nover the entire block is proved to increase with the blocklength, which leads\nto the fact that the effective throughput increases with the blocklength.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2017 02:31:48 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Yan", "Shihao", ""], ["He", "Biao", ""], ["Cong", "Yirui", ""], ["Zhou", "Xiangyun", ""]]}]