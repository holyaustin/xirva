[{"id": "2103.00039", "submitter": "Shuang Song", "authors": "Peter Kairouz, Brendan McMahan, Shuang Song, Om Thakkar, Abhradeep\n  Thakurta, Zheng Xu", "title": "Practical and Private (Deep) Learning without Sampling or Shuffling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider training models with differential privacy (DP) using mini-batch\ngradients. The existing state-of-the-art, Differentially Private Stochastic\nGradient Descent (DP-SGD), requires privacy amplification by sampling or\nshuffling to obtain the best privacy/accuracy/computation trade-offs.\nUnfortunately, the precise requirements on exact sampling and shuffling can be\nhard to obtain in important practical scenarios, particularly federated\nlearning (FL). We design and analyze a DP variant of\nFollow-The-Regularized-Leader (DP-FTRL) that compares favorably (both\ntheoretically and empirically) to amplified DP-SGD, while allowing for much\nmore flexible data access patterns. DP-FTRL does not use any form of privacy\namplification.\n  The code is available at\nhttps://github.com/google-research/federated/tree/master/dp_ftrl and\nhttps://github.com/google-research/DP-FTRL .\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 20:16:26 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 23:45:09 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Kairouz", "Peter", ""], ["McMahan", "Brendan", ""], ["Song", "Shuang", ""], ["Thakkar", "Om", ""], ["Thakurta", "Abhradeep", ""], ["Xu", "Zheng", ""]]}, {"id": "2103.00044", "submitter": "Georgios Bakirtzis", "authors": "Georgios Bakirtzis, Fabrizio Genovese, Cody H. Fleming", "title": "Yoneda Hacking: The Algebra of Attacker Actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our work focuses on modeling security of systems from their component-level\ndesigns. Towards this goal we develop a categorical formalism to model attacker\nactions. Equipping the categorical formalism with algebras produces two\ninteresting results for security modeling. First, using the Yoneda lemma, we\nare able to model attacker reconnaissance missions. In this context, the Yoneda\nlemma formally shows us that if two system representations, one being complete\nand the other being the attacker's incomplete view, agree at every possible\ntest, then they behave the same. The implication is that attackers can still\nsuccessfully exploit the system even with incomplete information. Second, we\nmodel the possible changes that can occur to the system via an exploit. An\nexploit either manipulates the interactions between system components, for\nexample, providing the wrong values to a sensor, or changes the components\nthemselves, for example, manipulating the firmware of a global positioning\nsystem (GPS). One additional benefit of using category theory is that\nmathematical operations can be represented as formal diagrams, which is useful\nfor applying this analysis in a model-based design setting. We illustrate this\nmodeling framework using a cyber-physical system model of an unmanned aerial\nvehicle (UAV). We demonstrate and model two types of attacks (1) a rewiring\nattack, which violates data integrity, and (2) a rewriting attack, which\nviolates availability.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 20:34:08 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Bakirtzis", "Georgios", ""], ["Genovese", "Fabrizio", ""], ["Fleming", "Cody H.", ""]]}, {"id": "2103.00078", "submitter": "Couvreur Alain", "authors": "Anne Canteaut, Alain Couvreur, L\\'eo Perrin", "title": "Recovering or Testing Extended-Affine Equivalence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DM cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Extended Affine (EA) equivalence is the equivalence relation between two\nvectorial Boolean functions $F$ and $G$ such that there exist two affine\npermutations $A$, $B$, and an affine function $C$ satisfying $G = A \\circ F\n\\circ B + C$. While a priori simple, it is very difficult in practice to test\nwhether two functions are EA-equivalent. This problem has two variants:\nEA-testing deals with figuring out whether the two functions can be\nEA-equivalent, and EA-recovery is about recovering the tuple $(A,B,C)$ if it\nexists.\n  In this paper, we present a new efficient algorithm that efficiently solves\nthe EA-recovery problem for quadratic functions. Though its worst-case\ncomplexity is obtained when dealing with APN functions, it supersedes all\npreviously known algorithms in terms of performance, even in this case. This\napproach is based on the Jacobian matrix of the functions, a tool whose study\nin this context can be of independent interest.\n  In order to tackle EA-testing efficiently, the best approach in practice\nrelies on class invariants. We provide an overview of the literature on said\ninvariants along with a new one based on the \\emph{ortho-derivative} which is\napplicable to quadratic APN functions, a specific type of functions that is of\ngreat interest, and of which tens of thousands need to be sorted into distinct\nEA-classes. Our ortho-derivative-based invariant is both very fast to compute,\nand highly discriminating.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 22:52:29 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Canteaut", "Anne", ""], ["Couvreur", "Alain", ""], ["Perrin", "L\u00e9o", ""]]}, {"id": "2103.00082", "submitter": "Michael Cochez", "authors": "Leandro Eichenberger, Michael Cochez, Benjamin Heitmann, Stefan Decker", "title": "Secure Evaluation of Knowledge Graph Merging Gain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding out the differences and commonalities between the knowledge of two\nparties is an important task. Such a comparison becomes necessary, when one\nparty wants to determine how much it is worth to acquire the knowledge of the\nsecond party, or similarly when two parties try to determine, whether a\ncollaboration could be beneficial. When these two parties cannot trust each\nother (for example, due to them being competitors) performing such a comparison\nis challenging as neither of them would be willing to share any of their\nassets. This paper addresses this problem for knowledge graphs, without a need\nfor non-disclosure agreements nor a third party during the protocol.\n  During the protocol, the intersection between the two knowledge graphs is\ndetermined in a privacy preserving fashion. This is followed by the computation\nof various metrics, which give an indication of the potential gain from\nobtaining the other parties knowledge graph, while still keeping the actual\nknowledge graph contents secret. The protocol makes use of blind signatures and\n(counting) Bloom filters to reduce the amount of leaked information. Finally,\nthe party who wants to obtain the other's knowledge graph can get a part of\nsuch in a way that neither party is able to know beforehand which parts of the\ngraph are obtained (i.e., they cannot choose to only get or share the good\nparts). After inspection of the quality of this part, the Buyer can decide to\nproceed with the transaction.\n  The analysis of the protocol indicates that the developed protocol is secure\nagainst malicious participants. Further experimental analysis shows that the\nresource consumption scales linear with the number of statements in the\nknowledge graph.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 23:19:53 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Eichenberger", "Leandro", ""], ["Cochez", "Michael", ""], ["Heitmann", "Benjamin", ""], ["Decker", "Stefan", ""]]}, {"id": "2103.00250", "submitter": "Valentina Poggioni", "authors": "A.E. Baia, G. Di Bari, V. Poggioni", "title": "Effective Universal Unrestricted Adversarial Attacks using a MOE\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that Deep Leaning models are susceptible to\nadversarial examples, which are data, in general images, intentionally modified\nto fool a machine learning classifier. In this paper, we present a\nmulti-objective nested evolutionary algorithm to generate universal\nunrestricted adversarial examples in a black-box scenario. The unrestricted\nattacks are performed through the application of well-known image filters that\nare available in several image processing libraries, modern cameras, and mobile\napplications. The multi-objective optimization takes into account not only the\nattack success rate but also the detection rate. Experimental results showed\nthat this approach is able to create a sequence of filters capable of\ngenerating very effective and undetectable attacks.\n", "versions": [{"version": "v1", "created": "Sat, 27 Feb 2021 15:43:06 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Baia", "A. E.", ""], ["Di Bari", "G.", ""], ["Poggioni", "V.", ""]]}, {"id": "2103.00254", "submitter": "Thomas Moser", "authors": "David Chaum, Christian Grothoff, Thomas Moser", "title": "How to Issue a Central Bank Digital Currency", "comments": "Swiss National Bank Working Paper3/2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.CR q-fin.EC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  With the emergence of Bitcoin and recently proposed stablecoins from\nBigTechs, such as Diem (formerly Libra), central banks face growing competition\nfrom private actors offering their own digital alternative to physical cash. We\ndo not address the normative question whether a central bank should issue a\ncentral bank digital currency (CBDC) or not. Instead, we contribute to the\ncurrent research debate by showing how a central bank could do so, if desired.\nWe propose a token-based system without distributed ledger technology and show\nhow earlier-deployed, software-only electronic cash can be improved upon to\npreserve transaction privacy, meet regulatory requirements in a compelling way,\nand offer a level of quantum-resistant protection against systemic privacy\nrisk. Neither monetary policy nor financial stability would be materially\naffected because a CBDC with this design would replicate physical cash rather\nthan bank deposits.\n", "versions": [{"version": "v1", "created": "Sat, 27 Feb 2021 15:46:51 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Chaum", "David", ""], ["Grothoff", "Christian", ""], ["Moser", "Thomas", ""]]}, {"id": "2103.00342", "submitter": "Raouf Kerkouche", "authors": "Raouf Kerkouche and Gergely \\'Acs and Claude Castelluccia and Pierre\n  Genev\\`es", "title": "Constrained Differentially Private Federated Learning for Low-bandwidth\n  Devices", "comments": "arXiv admin note: text overlap with arXiv:2011.05578", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning becomes a prominent approach when different entities want\nto learn collaboratively a common model without sharing their training data.\nHowever, Federated learning has two main drawbacks. First, it is quite\nbandwidth inefficient as it involves a lot of message exchanges between the\naggregating server and the participating entities. This bandwidth and\ncorresponding processing costs could be prohibitive if the participating\nentities are, for example, mobile devices. Furthermore, although federated\nlearning improves privacy by not sharing data, recent attacks have shown that\nit still leaks information about the training data. This paper presents a novel\nprivacy-preserving federated learning scheme. The proposed scheme provides\ntheoretical privacy guarantees, as it is based on Differential Privacy.\nFurthermore, it optimizes the model accuracy by constraining the model learning\nphase on few selected weights. Finally, as shown experimentally, it reduces the\nupstream and downstream bandwidth by up to 99.9% compared to standard federated\nlearning, making it practical for mobile systems.\n", "versions": [{"version": "v1", "created": "Sat, 27 Feb 2021 22:25:06 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Kerkouche", "Raouf", ""], ["\u00c1cs", "Gergely", ""], ["Castelluccia", "Claude", ""], ["Genev\u00e8s", "Pierre", ""]]}, {"id": "2103.00345", "submitter": "Ruochen Jiao", "authors": "Ruochen Jiao, Hengyi Liang, Takami Sato, Junjie Shen, Qi Alfred Chen\n  and Qi Zhu", "title": "End-to-end Uncertainty-based Mitigation of Adversarial Attacks to\n  Automated Lane Centering", "comments": "8 pages for conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CR cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the development of advanced driver-assistance systems (ADAS) and\nautonomous vehicles, machine learning techniques that are based on deep neural\nnetworks (DNNs) have been widely used for vehicle perception. These techniques\noffer significant improvement on average perception accuracy over traditional\nmethods, however, have been shown to be susceptible to adversarial attacks,\nwhere small perturbations in the input may cause significant errors in the\nperception results and lead to system failure. Most prior works addressing such\nadversarial attacks focus only on the sensing and perception modules. In this\nwork, we propose an end-to-end approach that addresses the impact of\nadversarial attacks throughout perception, planning, and control modules. In\nparticular, we choose a target ADAS application, the automated lane centering\nsystem in OpenPilot, quantify the perception uncertainty under adversarial\nattacks, and design a robust planning and control module accordingly based on\nthe uncertainty analysis. We evaluate our proposed approach using both the\npublic dataset and production-grade autonomous driving simulator. The\nexperiment results demonstrate that our approach can effectively mitigate the\nimpact of adversarial attacks and can achieve 55% to 90% improvement over the\noriginal OpenPilot.\n", "versions": [{"version": "v1", "created": "Sat, 27 Feb 2021 22:36:32 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Jiao", "Ruochen", ""], ["Liang", "Hengyi", ""], ["Sato", "Takami", ""], ["Shen", "Junjie", ""], ["Chen", "Qi Alfred", ""], ["Zhu", "Qi", ""]]}, {"id": "2103.00363", "submitter": "Guoyang Xie", "authors": "Guoyang Xie, Jinbao Wang, Guo Yu, Feng Zheng, Yaochu Jin", "title": "Tiny Adversarial Mulit-Objective Oneshot Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to limited computational cost and energy consumption, most neural network\nmodels deployed in mobile devices are tiny. However, tiny neural networks are\ncommonly very vulnerable to attacks. Current research has proved that larger\nmodel size can improve robustness, but little research focuses on how to\nenhance the robustness of tiny neural networks. Our work focuses on how to\nimprove the robustness of tiny neural networks without seriously deteriorating\nof clean accuracy under mobile-level resources. To this end, we propose a\nmulti-objective oneshot network architecture search (NAS) algorithm to obtain\nthe best trade-off networks in terms of the adversarial accuracy, the clean\naccuracy and the model size. Specifically, we design a novel search space based\non new tiny blocks and channels to balance model size and adversarial\nperformance. Moreover, since the supernet significantly affects the performance\nof subnets in our NAS algorithm, we reveal the insights into how the supernet\nhelps to obtain the best subnet under white-box adversarial attacks.\nConcretely, we explore a new adversarial training paradigm by analyzing the\nadversarial transferability, the width of the supernet and the difference\nbetween training the subnets from scratch and fine-tuning. Finally, we make a\nstatistical analysis for the layer-wise combination of certain blocks and\nchannels on the first non-dominated front, which can serve as a guideline to\ndesign tiny neural network architectures for the resilience of adversarial\nperturbations.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2021 00:54:09 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Xie", "Guoyang", ""], ["Wang", "Jinbao", ""], ["Yu", "Guo", ""], ["Zheng", "Feng", ""], ["Jin", "Yaochu", ""]]}, {"id": "2103.00433", "submitter": "Steffen Wendzel", "authors": "Wojciech Mazurczyk and Steffen Wendzel and Mehdi Chourib and J\\\"org\n  Keller", "title": "Countering Adaptive Network Covert Communication with Dynamic Wardens", "comments": null, "journal-ref": "Elsevier FGCS, Volume 94, May 2019, Pages 712-725", "doi": "10.1016/j.future.2018.12.047", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network covert channels are hidden communication channels in computer\nnetworks. They influence several factors of the cybersecurity economy. For\ninstance, by improving the stealthiness of botnet communications, they aid and\npreserve the value of darknet botnet sales. Covert channels can also be used to\nsecretly exfiltrate confidential data out of organizations, potentially\nresulting in loss of market/research advantage. Considering the above, efforts\nare needed to develop effective countermeasures against such threats. Thus in\nthis paper, based on the introduced novel warden taxonomy, we present and\nevaluate a new concept of a dynamic warden. Its main novelty lies in the\nmodification of the warden's behavior over time, making it difficult for the\nadaptive covert communication parties to infer its strategy and perform a\nsuccessful hidden data exchange. Obtained experimental results indicate the\neffectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2021 09:31:13 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Mazurczyk", "Wojciech", ""], ["Wendzel", "Steffen", ""], ["Chourib", "Mehdi", ""], ["Keller", "J\u00f6rg", ""]]}, {"id": "2103.00474", "submitter": "Jason R.C. Nurse Dr", "authors": "Jason R. C. Nurse", "title": "Cybersecurity Awareness", "comments": null, "journal-ref": "In: Jajodia S., Samarati P., Yung M. (eds) Encyclopedia of\n  Cryptography, Security and Privacy. Springer, Berlin, Heidelberg (2021)", "doi": "10.1007/978-3-642-27739-9_1596-1", "report-no": null, "categories": "cs.CR cs.CY cs.HC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybersecurity awareness can be viewed as the level of appreciation,\nunderstanding or knowledge of cybersecurity or information security aspects.\nSuch aspects include cognizance of cyber risks and threats, but also\nappropriate protection measures.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2021 11:54:58 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Nurse", "Jason R. C.", ""]]}, {"id": "2103.00484", "submitter": "Khalid Malik", "authors": "Momina Masood, Marriam Nawaz, Khalid Mahmood Malik, Ali Javed, Aun\n  Irtaza", "title": "Deepfakes Generation and Detection: State-of-the-art, open challenges,\n  countermeasures, and way forward", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SD eess.AS eess.IV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Easy access to audio-visual content on social media, combined with the\navailability of modern tools such as Tensorflow or Keras, open-source trained\nmodels, and economical computing infrastructure, and the rapid evolution of\ndeep-learning (DL) methods, especially Generative Adversarial Networks (GAN),\nhave made it possible to generate deepfakes to disseminate disinformation,\nrevenge porn, financial frauds, hoaxes, and to disrupt government functioning.\nThe existing surveys have mainly focused on deepfake video detection only. No\nattempt has been made to review approaches for detection and generation of both\naudio and video deepfakes. This paper provides a comprehensive review and\ndetailed analysis of existing tools and machine learning (ML) based approaches\nfor deepfake generation and the methodologies used to detect such manipulations\nfor the detection and generation of both audio and video deepfakes. For each\ncategory of deepfake, we discuss information related to manipulation\napproaches, current public datasets, and key standards for the performance\nevaluation of deepfake detection techniques along with their results.\nAdditionally, we also discuss open challenges and enumerate future directions\nto guide future researchers on issues that need to be considered to improve the\ndomains of both the deepfake generation and detection. This work is expected to\nassist the readers in understanding the creation and detection mechanisms of\ndeepfake, along with their current limitations and future direction.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 18:26:50 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Masood", "Momina", ""], ["Nawaz", "Marriam", ""], ["Malik", "Khalid Mahmood", ""], ["Javed", "Ali", ""], ["Irtaza", "Aun", ""]]}, {"id": "2103.00499", "submitter": "Steffen Wendzel", "authors": "Steffen Wendzel", "title": "Protocol-independent Detection of \"Messaging Ordering\" Network Covert\n  Channels", "comments": null, "journal-ref": "Published in Proc. ARES 2019 (CUING Workshop)", "doi": "10.1145/3339252.3341477", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detection methods are available for several known covert channels. However, a\ntype of covert channel that received little attention within the last decade is\nthe \"message ordering\" channel. Such a covert channel changes the order of PDUs\n(protocol data units, i.e. packets) transferred over the network to encode\nhidden information. The advantage of these channels is that they cannot be\nblocked easily as they do not modify header content but instead mimic typical\nnetwork behavior such as TCP segments that arrive in a different order than\nthey were sent.\n  Contribution: In this paper, we show a protocol-independent approach to\ndetect message ordering channels. Our approach is based on a modified\ncompressibility score. We analyze the detectability of message ordering\nchannels and whether several types of message ordering channels differ in their\ndetectability.\n  Results: Our results show that the detection of message ordering channels\ndepends on their number of utilized PDUs. First, we performed a rough threshold\nselection by hand, which we later optimized using the C4.5 decision tree\nclassifier. We were able to detect message ordering covert channels with an\naccuracy and F1 score of >= 99.5% and a false-positive rate < 1% and < 0.1% if\nthey use sequences of 3 or 4 PDUs, respectively. Simpler channels that only\nmanipulate a sequence of two PDUs were detectable with an accuracy and F1 score\nof 94.5% and were linked to a false-positive rate of 5.19%. We thus consider\nour approach suitable for real-world detection scenarios with channels\nutilizing 3 or 4 PDUs while the detection of channels utilizing 2 PDUs should\nbe improved further.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2021 13:02:07 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Wendzel", "Steffen", ""]]}, {"id": "2103.00540", "submitter": "Palina Tolmach", "authors": "Palina Tolmach, Yi Li, Shang-Wei Lin, Yang Liu", "title": "Formal Analysis of Composable DeFi Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized finance (DeFi) has become one of the most successful\napplications of blockchain and smart contracts. The DeFi ecosystem enables a\nwide range of crypto-financial activities, while the underlying smart contracts\noften contain bugs, with many vulnerabilities arising from the unforeseen\nconsequences of composing DeFi protocols together. In this paper, we propose a\nformal process-algebraic technique that models DeFi protocols in a\ncompositional manner to allow for efficient property verification. We also\nconduct a case study to demonstrate the proposed approach in analyzing the\ncomposition of two interacting DeFi protocols, namely, Curve and Compound.\nFinally, we discuss how the proposed modeling and verification approach can be\nused to analyze financial and security properties of interest.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2021 15:47:20 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 05:51:54 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Tolmach", "Palina", ""], ["Li", "Yi", ""], ["Lin", "Shang-Wei", ""], ["Liu", "Yang", ""]]}, {"id": "2103.00590", "submitter": "Antonin Durey", "authors": "Antonin Durey, Pierre Laperdrix, Walter Rudametkin, Romain Rouvoy", "title": "An iterative technique to identify browser fingerprinting scripts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Browser fingerprinting is a stateless identification technique based on\nbrowser properties. Together, they form an identifier that can be collected\nwithout users' notice and has been studied to be unique and stable. As this\ntechnique relies on browser properties that serve legitimate purposes, the\ndetection of this technique is challenging. While several studies propose\nclassification techniques, none of these are publicly available, making them\ndifficult to reproduce. This paper proposes a new browser fingerprinting\ndetection technique. Based on an incremental process, it relies on both\nautomatic and manual decisions to be both reliable and fast. The automatic step\nmatches API calls similarities between scripts while the manual step is\nrequired to classify a script with different calls. We publicly share our\nalgorithm and implementation to improve the general knowledge on the subject.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2021 19:10:29 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Durey", "Antonin", ""], ["Laperdrix", "Pierre", ""], ["Rudametkin", "Walter", ""], ["Rouvoy", "Romain", ""]]}, {"id": "2103.00602", "submitter": "David Noever", "authors": "David Noever, Samantha E. Miller Noever", "title": "Virus-MNIST: A Benchmark Malware Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The short note presents an image classification dataset consisting of 10\nexecutable code varieties and approximately 50,000 virus examples. The\nmalicious classes include 9 families of computer viruses and one benign set.\nThe image formatting for the first 1024 bytes of the Portable Executable (PE)\nmirrors the familiar MNIST handwriting dataset, such that most of the\npreviously explored algorithmic methods can transfer with minor modifications.\nThe designation of 9 virus families for malware derives from unsupervised\nlearning of class labels; we discover the families with KMeans clustering that\nexcludes the non-malicious examples. As a benchmark using deep learning methods\n(MobileNetV2), we find an overall 80% accuracy for virus identification by\nfamilies when beneware is included. We also find that once a positive malware\ndetection occurs (by signature or heuristics), the projection of the first 1024\nbytes into a thumbnail image can classify with 87% accuracy the type of virus.\nThe work generalizes what other malware investigators have demonstrated as\npromising convolutional neural networks originally developed to solve image\nproblems but applied to a new abstract domain in pixel bytes from executable\nfiles. The dataset is available on Kaggle and Github.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2021 19:55:19 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Noever", "David", ""], ["Noever", "Samantha E. Miller", ""]]}, {"id": "2103.00637", "submitter": "Mohit Sewak", "authors": "Hemant Rathore, Sanjay K. Sahay, Shivin Thukral, Mohit Sewak", "title": "Detection of Malicious Android Applications: Classical Machine Learning\n  vs. Deep Neural Network Integrated with Clustering", "comments": "BROADNETS, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today anti-malware community is facing challenges due to the ever-increasing\nsophistication and volume of malware attacks developed by adversaries.\nTraditional malware detection mechanisms are not able to cope-up with\nnext-generation malware attacks. Therefore in this paper, we propose effective\nand efficient Android malware detection models based on machine learning and\ndeep learning integrated with clustering. We performed a comprehensive study of\ndifferent feature reduction, classification and clustering algorithms over\nvarious performance metrics to construct the Android malware detection models.\nOur experimental results show that malware detection models developed using\nRandom Forest eclipsed deep neural network and other classifiers on the\nmajority of performance metrics. The baseline Random Forest model without any\nfeature reduction achieved the highest AUC of 99.4%. Also, the segregating of\nvector space using clustering integrated with Random Forest further boosted the\nAUC to 99.6% in one cluster and direct detection of Android malware in another\ncluster, thus reducing the curse of dimensionality. Additionally, we found that\nfeature reduction in detection models does improve the model efficiency\n(training and testing time) many folds without much penalty on the\neffectiveness of the detection model.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2021 21:50:57 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Rathore", "Hemant", ""], ["Sahay", "Sanjay K.", ""], ["Thukral", "Shivin", ""], ["Sewak", "Mohit", ""]]}, {"id": "2103.00643", "submitter": "Mohit Sewak", "authors": "Hemant Rathore, Sanjay K. Sahay, Ritvik Rajvanshi, Mohit Sewak", "title": "Identification of Significant Permissions for Efficient Android Malware\n  Detection", "comments": "BROADNETS, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since Google unveiled Android OS for smartphones, malware are thriving with\n3Vs, i.e. volume, velocity, and variety. A recent report indicates that one out\nof every five business/industry mobile application leaks sensitive personal\ndata. Traditional signature/heuristic-based malware detection systems are\nunable to cope up with current malware challenges and thus threaten the Android\necosystem. Therefore recently researchers have started exploring machine\nlearning and deep learning based malware detection systems. In this paper, we\nperformed a comprehensive feature analysis to identify the significant Android\npermissions and propose an efficient Android malware detection system using\nmachine learning and deep neural network. We constructed a set of $16$\npermissions ($8\\%$ of the total set) derived from variance threshold,\nauto-encoders, and principal component analysis to build a malware detection\nengine that consumes less train and test time without significant compromise on\nthe model accuracy. Our experimental results show that the Android malware\ndetection model based on the random forest classifier is most balanced and\nachieves the highest area under curve score of $97.7\\%$, which is better than\nthe current state-of-art systems. We also observed that deep neural networks\nattain comparable accuracy to the baseline results but with a massive\ncomputational penalty.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2021 22:07:08 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Rathore", "Hemant", ""], ["Sahay", "Sanjay K.", ""], ["Rajvanshi", "Ritvik", ""], ["Sewak", "Mohit", ""]]}, {"id": "2103.00676", "submitter": "Tom Roth", "authors": "Tom Roth, Yansong Gao, Alsharif Abuadbba, Surya Nepal, Wei Liu", "title": "Token-Modification Adversarial Attacks for Natural Language Processing:\n  A Survey", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are now many adversarial attacks for natural language processing\nsystems. Of these, a vast majority achieve success by modifying individual\ndocument tokens, which we call here a \\textit{token-modification} attack. Each\ntoken-modification attack is defined by a specific combination of fundamental\n\\textit{components}, such as a constraint on the adversary or a particular\nsearch algorithm. Motivated by this observation, we survey existing\ntoken-modification attacks and extract the components of each. We use an\nattack-independent framework to structure our survey which results in an\neffective categorisation of the field and an easy comparison of components. We\nhope this survey will guide new researchers to this field and spark further\nresearch into the individual attack components.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 01:00:09 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Roth", "Tom", ""], ["Gao", "Yansong", ""], ["Abuadbba", "Alsharif", ""], ["Nepal", "Surya", ""], ["Liu", "Wei", ""]]}, {"id": "2103.00695", "submitter": "Roozbeh Yousefzadeh", "authors": "Roozbeh Yousefzadeh", "title": "Federated Learning without Revealing the Decision Boundaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We consider the recent privacy preserving methods that train the models not\non original images, but on mixed images that look like noise and hard to trace\nback to the original images. We explain that those mixed images will be samples\non the decision boundaries of the trained model, and although such methods\nsuccessfully hide the contents of images from the entity in charge of federated\nlearning, they provide crucial information to that entity about the decision\nboundaries of the trained model. Once the entity has exact samples on the\ndecision boundaries of the model, they may use it for effective adversarial\nattacks on the model during training and/or afterwards. If we have to hide our\nimages from that entity, how can we trust them with the decision boundaries of\nour model? As a remedy, we propose a method to encrypt the images, and have a\ndecryption module hidden inside the model. The entity in charge of federated\nlearning will only have access to a set of complex-valued coefficients, but the\nmodel will first decrypt the images and then put them through the convolutional\nlayers. This way, the entity will not see the training images and they will not\nknow the location of the decision boundaries of the model.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 02:11:41 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Yousefzadeh", "Roozbeh", ""]]}, {"id": "2103.00777", "submitter": "Fangyu Gai", "authors": "Fangyu Gai, Ali Farahbakhsh, Jianyu Niu, Chen Feng, Ivan Beschastnikh,\n  Hao Duan", "title": "Dissecting the Performance of Chained-BFT", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Permissioned blockchains employ Byzantine fault-tolerant (BFT) state machine\nreplication (SMR) to reach agreement on an ever-growing, linearly ordered log\nof transactions. A new paradigm, combined with decades of research in BFT SMR\nand blockchain (namely chained-BFT, or cBFT), has emerged for directly\nconstructing blockchain protocols. Chained-BFT protocols have a unifying\npropose-vote scheme instead of multiple different voting phases with a set of\nvoting and commit rules to guarantee safety and liveness. However, distinct\nvoting and commit rules impose varying impacts on performance under different\nworkloads, network conditions, and Byzantine attacks. Therefore, a fair\ncomparison of the proposed protocols poses a challenge that has not yet been\naddressed by existing work.\n  We fill this gap by studying a family of cBFT protocols with a two-pronged\nsystematic approach. First, we present an evaluation framework, Bamboo, for\nquick prototyping of cBFT protocols and that includes helpful benchmarking\nfacilities. To validate Bamboo, we introduce an analytic model using queuing\ntheory which also offers a back-of-the-envelope guide for dissecting these\nprotocols. We build multiple cBFT protocols using Bamboo and we are the first\nto fairly compare three representatives (i.e., HotStuff, two-chain HotStuff,\nand Streamlet). We evaluated these protocols under various parameters and\nscenarios, including two Byzantine attacks that have not been widely discussed\nin the literature. Our findings reveal interesting trade-offs (e.g.,\nresponsiveness vs. forking-resilience) between different cBFT protocols and\ntheir design choices, which provide developers and researchers with insights\ninto the design and implementation of this protocol family.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 06:01:08 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Gai", "Fangyu", ""], ["Farahbakhsh", "Ali", ""], ["Niu", "Jianyu", ""], ["Feng", "Chen", ""], ["Beschastnikh", "Ivan", ""], ["Duan", "Hao", ""]]}, {"id": "2103.00847", "submitter": "Shahroz Tariq", "authors": "Shahroz Tariq, Sowon Jeon, Simon S. Woo", "title": "Am I a Real or Fake Celebrity? Measuring Commercial Face Recognition Web\n  APIs under Deepfake Impersonation Attack", "comments": "27 pages, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, significant advancements have been made in face recognition\ntechnologies using Deep Neural Networks. As a result, companies such as\nMicrosoft, Amazon, and Naver offer highly accurate commercial face recognition\nweb services for diverse applications to meet the end-user needs. Naturally,\nhowever, such technologies are threatened persistently, as virtually any\nindividual can quickly implement impersonation attacks. In particular, these\nattacks can be a significant threat for authentication and identification\nservices, which heavily rely on their underlying face recognition technologies'\naccuracy and robustness. Despite its gravity, the issue regarding deepfake\nabuse using commercial web APIs and their robustness has not yet been\nthoroughly investigated. This work provides a measurement study on the\nrobustness of black-box commercial face recognition APIs against Deepfake\nImpersonation (DI) attacks using celebrity recognition APIs as an example case\nstudy. We use five deepfake datasets, two of which are created by us and\nplanned to be released. More specifically, we measure attack performance based\non two scenarios (targeted and non-targeted) and further analyze the differing\nsystem behaviors using fidelity, confidence, and similarity metrics.\nAccordingly, we demonstrate how vulnerable face recognition technologies from\npopular companies are to DI attack, achieving maximum success rates of 78.0%\nand 99.9% for targeted (i.e., precise match) and non-targeted (i.e., match with\nany celebrity) attacks, respectively. Moreover, we propose practical defense\nstrategies to mitigate DI attacks, reducing the attack success rates to as low\nas 0% and 0.02% for targeted and non-targeted attacks, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 08:40:10 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 07:56:46 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Tariq", "Shahroz", ""], ["Jeon", "Sowon", ""], ["Woo", "Simon S.", ""]]}, {"id": "2103.00862", "submitter": "Mingrui Zhang Mr.", "authors": "Mingrui Zhang, Jianzhong Liu, Fuchen Ma, Huafeng Zhang, Yu Jiang", "title": "IntelliGen: Automatic Driver Synthesis for FuzzTesting", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzing is a technique widely used in vulnerability detection. The process\nusually involves writing effective fuzz driver programs, which, when done\nmanually, can be extremely labor intensive. Previous attempts at automation\nleave much to be desired, in either degree of automation or quality of output.\nIn this paper, we propose IntelliGen, a framework that constructs valid fuzz\ndrivers automatically. First, IntelliGen determines a set of entry functions\nand evaluates their respective chance of exhibiting a vulnerability. Then,\nIntelliGen generates fuzz drivers for the entry functions through hierarchical\nparameter replacement and type inference. We implemented IntelliGen and\nevaluated its effectiveness on real-world programs selected from the Android\nOpen-Source Project, Google's fuzzer-test-suite and industrial collaborators.\nIntelliGen covered on average 1.08X-2.03X more basic blocks and 1.36X-2.06X\nmore paths over state-of-the-art fuzz driver synthesizers FUDGE and FuzzGen.\nIntelliGen performed on par with manually written drivers and found 10 more\nbugs.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 09:22:59 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Zhang", "Mingrui", ""], ["Liu", "Jianzhong", ""], ["Ma", "Fuchen", ""], ["Zhang", "Huafeng", ""], ["Jiang", "Yu", ""]]}, {"id": "2103.00996", "submitter": "Shun Takagi", "authors": "Shun Takagi, Yang Cao, Masatoshi Yoshikawa", "title": "Asymmetric Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, differential privacy (DP) is getting attention as a privacy\ndefinition when publishing statistics of a dataset. However, when answering a\ndecision problem with a DP mechanism, it causes a two-sided error. This\ncharacteristic of DP is not desirable when publishing risk information such as\nconcerning COVID-19. This paper proposes relaxing DP to mitigate the limitation\nand improve the utility of published information. First, we define a policy\nthat separates information into sensitive and non-sensitive. Then, we define\nasymmetric differential privacy (ADP) that provides the same privacy guarantee\nas DP to sensitive information. This partial protection induces asymmetricity\nin privacy protection to improve utility and allow a one-sided error mechanism.\nFollowing ADP, we propose two mechanisms for two tasks based on counting query\nwith utilizing these characteristics: top-$k$ query and publishing risk\ninformation of viruses with an accuracy guarantee. Finally, we conducted\nexperiments to evaluate proposed algorithms using real-world datasets and show\ntheir practicality and improvement of the utility, comparing state-of-the-art\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 13:39:46 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Takagi", "Shun", ""], ["Cao", "Yang", ""], ["Yoshikawa", "Masatoshi", ""]]}, {"id": "2103.01019", "submitter": "Supriya Adhatarao", "authors": "Supriya Adhatarao, C\\'edric Lauradoux and Cristiana Santos", "title": "Why IP-based Subject Access Requests Are Denied?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the legal status of IP addresses is complex. In Europe, the\nGeneral Data Protection Regulation (GDPR) is supposed to have leveraged the\nlegal status of IP addresses as personal data, but recent decisions from the\nEuropean Court of Justice undermine this view. In the hope to clarify this\nsituation, we have looked on how 109 websites deal with IP addresses. First, we\nanalyzed the privacy policies of these websites to determine how they\nconsidered IP addresses. Most of them acknowledge in their privacy policy the\nfact that IP addresses are personal data. Second, we submitted subject access\nrequests based on the IP addresses used to visit different websites. Our\nrequests were often denied. Websites justify their answers with different\nexplanations suchlike: you need to register, or IP addresses do not allow to\nidentify you, to name a few. This situation is rather frustrating for any user\nwanting to exercise his/her rights: IP addresses are personal data on (legal)\npapers, but there are no means to exercise the rights thereto. One maybe\ntempted to say that IP addresses are not personal data. We make several\nproposals to improve this situation by modifying how IP addresses are allocated\nto a user.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 14:13:32 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 21:21:14 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Adhatarao", "Supriya", ""], ["Lauradoux", "C\u00e9dric", ""], ["Santos", "Cristiana", ""]]}, {"id": "2103.01116", "submitter": "Heju Li", "authors": "Rui Wang, Heju Li, Erwu Liu", "title": "Blockchain-Based Federated Learning in Mobile Edge Networks with\n  Application in Internet of Vehicles", "comments": "14 pages,7 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid increase of the data scale in Internet of Vehicles (IoV) system\nparadigm, hews out new possibilities in boosting the service quality for the\nemerging applications through data sharing. Nevertheless, privacy concerns are\nmajor bottlenecks for data providers to share private data in traditional IoV\nnetworks. To this end, federated learning (FL) as an emerging learning\nparadigm, where data providers only send local model updates trained on their\nlocal raw data rather than upload any raw data, has been recently proposed to\nbuild a privacy-preserving data sharing models. Unfortunately, by analyzing on\nthe differences of uploaded local model updates from data providers, private\ninformation can still be divulged, and performance of the system cannot be\nguaranteed when partial federated nodes executes malicious behavior.\nAdditionally, traditional cloud-based FL poses challenges to the communication\noverhead with the rapid increase of terminal equipment in IoV system. All these\nissues inspire us to propose an autonomous blockchain empowered\nprivacy-preserving FL framework in this paper, where the mobile edge computing\n(MEC) technology was naturally integrated in IoV system.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 16:38:40 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Wang", "Rui", ""], ["Li", "Heju", ""], ["Liu", "Erwu", ""]]}, {"id": "2103.01147", "submitter": "Igor Semaev", "authors": "Alessandro Budroni and Igor Semaev", "title": "New Public-Key Crypto-System EHT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this note, an LWE problem with a hidden trapdoor is introduced. It is used\nto construct an efficient public-key crypto-system EHT. The new system is\nsignificantly different from LWE based NIST candidates like FrodoKEM. The\nperformance of EHT compares favorably with FrodoKEM.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 17:31:19 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Budroni", "Alessandro", ""], ["Semaev", "Igor", ""]]}, {"id": "2103.01193", "submitter": "Guillermo Angeris", "authors": "Guillermo Angeris, Alex Evans, Tarun Chitra", "title": "A Note on Privacy in Constant Function Market Makers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.AP math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constant function market makers (CFMMs) such as Uniswap, Balancer, Curve, and\nmStable, among many others, make up some of the largest decentralized exchanges\non Ethereum and other blockchains. Because all transactions are public in\ncurrent implementations, a natural next question is if there exist similar\ndecentralized exchanges which are privacy-preserving; i.e., if a transaction's\nquantities are hidden from the public view, then an adversary cannot correctly\nreconstruct the traded quantities from other public information. In this note,\nwe show that privacy is impossible with the usual implementations of CFMMs\nunder most reasonable models of an adversary and provide some mitigating\nstrategies.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 18:37:39 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Angeris", "Guillermo", ""], ["Evans", "Alex", ""], ["Chitra", "Tarun", ""]]}, {"id": "2103.01262", "submitter": "Arsenia (Ersi) Chorti", "authors": "Gustavo A. Nunez Segura, Arsenia Chorti, Cintia Borges Margi", "title": "Centralized and Distributed Intrusion Detection for Resource Constrained\n  Wireless SDN Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software-defined networking (SDN) was devised to simplify network management\nand automate infrastructure sharing in wired networks. These benefits motivated\nthe application of SDN in wireless sensor networks to leverage solutions for\ncomplex applications. However, some of the core SDN traits turn the networks\nprone to denial of service attacks (DoS). There are proposals in the literature\nto detect DoS in wireless SDN networks, however, not without shortcomings:\nthere is little focus on resource constraints, high detection rates have been\nreported only for small networks, and the detection is disengaged from the\nidentification of the type of the attack or the attacker. Our work targets\nthese shortcomings by introducing a lightweight, online change point detector\nto monitor performance metrics that are impacted when the network is under\nattack. A key novelty is that the proposed detector is able to operate in\neither centralized or distributed mode. The centralized detector has very high\ndetection rates and can further distinguish the type of the attack (from a list\nof known attacks). On the other hand, the distributed detector provides\ninformation that allows to identify the nodes launching the attack. Our\nproposal is tested over IEEE 802.15.4 networks. The results show detection\nrates exceeding $96\\%$ in networks of 36 and 100 nodes and identification of\nthe type of the attack with a probability exceeding $0.89$ when using the\ncentralized approach. Additionally, for some types of attack it was possible to\npinpoint the attackers with an identification probability over $0.93$ when\nusing distributed detectors.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 19:18:35 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Segura", "Gustavo A. Nunez", ""], ["Chorti", "Arsenia", ""], ["Margi", "Cintia Borges", ""]]}, {"id": "2103.01322", "submitter": "Muhammad R. A. Khandaker PhD", "authors": "Shakila Zaman, Muhammad R. A. Khandaker, Risala T. Khan, Faisal Tariq,\n  and Kai-Kit Wong", "title": "Thinking Out of the Blocks: Holochain for Distributed Security in IoT\n  Healthcare", "comments": "Submitted to IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet-of-Things (IoT) is an emerging and cognitive technology which\nconnects a massive number of smart physical devices with virtual objects\noperating in diverse platforms through the internet. IoT is increasingly being\nimplemented in distributed settings, making footprints in almost every sector\nof our life. Unfortunately, for healthcare systems, the entities connected to\nthe IoT networks are exposed to an unprecedented level of security threats.\nRelying on a huge volume of sensitive and personal data, IoT healthcare systems\nare facing unique challenges in protecting data security and privacy. Although\nblockchain has posed to be the solution in this scenario thanks to its inherent\ndistributed ledger technology (DLT), it suffers from major setbacks of\nincreasing storage and computation requirements with the network size. This\npaper proposes a holochain-based security and privacy-preserving framework for\nIoT healthcare systems that overcomes these challenges and is particularly\nsuited for resource constrained IoT scenarios. The performance and thorough\nsecurity analyses demonstrate that a holochain-based IoT healthcare system is\nsignificantly better compared to blockchain and other existing systems.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 21:39:36 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Zaman", "Shakila", ""], ["Khandaker", "Muhammad R. A.", ""], ["Khan", "Risala T.", ""], ["Tariq", "Faisal", ""], ["Wong", "Kai-Kit", ""]]}, {"id": "2103.01340", "submitter": "Bhaskar Krishnamachari", "authors": "Ayten Kahya, Bhaskar Krishnamachari, Seokgu Yun", "title": "Reducing the Volatility of Cryptocurrencies -- A Survey of Stablecoins", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the wake of financial crises, stablecoins are gaining adoption among\ndigital currencies. We discuss how stablecoins help reduce the volatility of\ncryptocurrencies by surveying different types of stablecoins and their\nstability mechanisms. We classify different approaches to stablecoins in three\nmain categories i) fiat or asset backed, ii) crypto-collateralized and iii)\nalgorithmic stablecoins, giving examples of concrete projects in each class. We\nassess the relative tradeoffs between the different approaches. We also discuss\nchallenges associated with the future of stablecoins and their adoption, their\nadoption and point out future research directions.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 22:54:20 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Kahya", "Ayten", ""], ["Krishnamachari", "Bhaskar", ""], ["Yun", "Seokgu", ""]]}, {"id": "2103.01344", "submitter": "Ali Rahimi", "authors": "Ali Rahimi, Mohammad Ali Maddah-Ali", "title": "Multi-Party Proof Generation in QAP-based zk-SNARKs", "comments": "31 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-knowledge succinct non-interactive argument of knowledge (zkSNARK)\nallows a party, known as the prover, to convince another party, known as the\nverifier, that he knows a private value $v$, without revealing it, such that\n$F(u,v)=y$ for some function $F$ and public values $u$ and $y$. There are\nvarious versions of zk-SNARK, among them, Quadratic Arithmetic Program\n(QAP)-based zk-SNARK has been widely used in practice, specially in Blockchain\ntechnology. This is attributed to two desirable features; its fixed-size proof\nand the very light computation load of the verifier. However, the computation\nload of the prover in QAP-based zkSNARKs, is very heavy, even-though it is\ndesigned to be very efficient. This load can be beyond the prover's computation\npower to handle, and has to be offloaded to some external servers. In the\nexisting offloading solutions, either (i) the load of computation, offloaded to\neach sever, is a fraction of the prover's primary computation (e.g., DZIK),\nhowever the servers need to be trusted, (ii) the servers are not required to be\ntrusted, but the computation complexity imposed to each one is the same as the\nprover's primary computation (e.g., Trinocchio). In this paper, we present a\nscheme, which has the benefits of both solutions. In particular, we propose a\nsecure multi-party proof generation algorithm where the prover can delegate its\ntask to $N $ servers, where (i) even if a group of $T \\in \\mathbb{N}$ servers,\n$T\\le N$, collude, they cannot gain any information about the secret value $v$,\n(ii) the computation complexity of each server is less than $1/(N-T)$ of the\nprover's primary computation. The design is such that we don't lose the\nefficiency of the prover's algorithm in the process of delegating the tasks to\nexternal servers.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 23:00:10 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Rahimi", "Ali", ""], ["Maddah-Ali", "Mohammad Ali", ""]]}, {"id": "2103.01371", "submitter": "Nalin Asanka Gamagedara Arachchilage", "authors": "Abdulrahman Alhazmi and Nalin Asanka Gamagedara Arachchilage", "title": "I'm all Ears! Listening to Software Developers on Putting GDPR\n  Principles into Software Development Practice", "comments": "18", "journal-ref": "Personal and Ubiquitous Computing, Springer, 2021", "doi": null, "report-no": null, "categories": "cs.CR cs.HC cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Previous research has been carried out to identify the impediments that\nprevent developers from incorporating privacy protocols into software\napplications. No research has been carried out to find out why developers are\nnot able to develop systems that preserve-privacy while specifically\nconsidering the General Data Protection Regulation principles (GDPR\nprinciples). Consequently, this paper aims to examine the issues, which prevent\ndevelopers from creating applications, which consider and include GDPR\nprinciples into their software systems. From our research findings, we\nidentified the lack of familiarity with GDPR principles by developers as one of\nthe obstacles that prevent GDPR onboarding. Those who were familiar with the\nprinciples did not have the requisite knowledge about the principles including\ntheir techniques. Developers focused on functional than on privacy\nrequirements. Unavailability of resourceful online tools and lack of support\nfrom institutions and clients were also identified as issues inimical to the\nonboarding of GDPR principles.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 00:12:02 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Alhazmi", "Abdulrahman", ""], ["Arachchilage", "Nalin Asanka Gamagedara", ""]]}, {"id": "2103.01396", "submitter": "Nandan Kumar Jha", "authors": "Nandan Kumar Jha, Zahra Ghodsi, Siddharth Garg, Brandon Reagen", "title": "DeepReDuce: ReLU Reduction for Fast Private Inference", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent rise of privacy concerns has led researchers to devise methods for\nprivate neural inference -- where inferences are made directly on encrypted\ndata, never seeing inputs. The primary challenge facing private inference is\nthat computing on encrypted data levies an impractically-high latency penalty,\nstemming mostly from non-linear operators like ReLU. Enabling practical and\nprivate inference requires new optimization methods that minimize network ReLU\ncounts while preserving accuracy. This paper proposes DeepReDuce: a set of\noptimizations for the judicious removal of ReLUs to reduce private inference\nlatency. The key insight is that not all ReLUs contribute equally to accuracy.\nWe leverage this insight to drop, or remove, ReLUs from classic networks to\nsignificantly reduce inference latency and maintain high accuracy. Given a\ntarget network, DeepReDuce outputs a Pareto frontier of networks that tradeoff\nthe number of ReLUs and accuracy. Compared to the state-of-the-art for private\ninference DeepReDuce improves accuracy and reduces ReLU count by up to 3.5%\n(iso-ReLU count) and 3.5$\\times$ (iso-accuracy), respectively.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 01:16:53 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 13:08:33 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Jha", "Nandan Kumar", ""], ["Ghodsi", "Zahra", ""], ["Garg", "Siddharth", ""], ["Reagen", "Brandon", ""]]}, {"id": "2103.01496", "submitter": "Wenxiao Wang", "authors": "Wenxiao Wang (1), Tianhao Wang (2), Lun Wang (3), Nanqing Luo (4), Pan\n  Zhou (4), Dawn Song (3), Ruoxi Jia (5) ((1) Tsinghua University, (2) Harvard\n  University, (3) University of California, Berkeley, (4) Huazhong University\n  of Science and Technology, (5) Virginia Tech)", "title": "DPlis: Boosting Utility of Differentially Private Deep Learning via\n  Randomized Smoothing", "comments": "The 21st Privacy Enhancing Technologies Symposium (PETS), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques have achieved remarkable performance in wide-ranging\ntasks. However, when trained on privacy-sensitive datasets, the model\nparameters may expose private information in training data. Prior attempts for\ndifferentially private training, although offering rigorous privacy guarantees,\nlead to much lower model performance than the non-private ones. Besides,\ndifferent runs of the same training algorithm produce models with large\nperformance variance. To address these issues, we propose DPlis--Differentially\nPrivate Learning wIth Smoothing. The core idea of DPlis is to construct a\nsmooth loss function that favors noise-resilient models lying in large flat\nregions of the loss landscape. We provide theoretical justification for the\nutility improvements of DPlis. Extensive experiments also demonstrate that\nDPlis can effectively boost model quality and training stability under a given\nprivacy budget.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 06:33:14 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2021 16:08:44 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Wang", "Wenxiao", ""], ["Wang", "Tianhao", ""], ["Wang", "Lun", ""], ["Luo", "Nanqing", ""], ["Zhou", "Pan", ""], ["Song", "Dawn", ""], ["Jia", "Ruoxi", ""]]}, {"id": "2103.01516", "submitter": "Hilal Asi", "authors": "Hilal Asi, Vitaly Feldman, Tomer Koren, Kunal Talwar", "title": "Private Stochastic Convex Optimization: Optimal Rates in $\\ell_1$\n  Geometry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic convex optimization over an $\\ell_1$-bounded domain is ubiquitous\nin machine learning applications such as LASSO but remains poorly understood\nwhen learning with differential privacy. We show that, up to logarithmic\nfactors the optimal excess population loss of any\n$(\\varepsilon,\\delta)$-differentially private optimizer is $\\sqrt{\\log(d)/n} +\n\\sqrt{d}/\\varepsilon n.$ The upper bound is based on a new algorithm that\ncombines the iterative localization approach of~\\citet{FeldmanKoTa20} with a\nnew analysis of private regularized mirror descent. It applies to $\\ell_p$\nbounded domains for $p\\in [1,2]$ and queries at most $n^{3/2}$ gradients\nimproving over the best previously known algorithm for the $\\ell_2$ case which\nneeds $n^2$ gradients. Further, we show that when the loss functions satisfy\nadditional smoothness assumptions, the excess loss is upper bounded (up to\nlogarithmic factors) by $\\sqrt{\\log(d)/n} + (\\log(d)/\\varepsilon n)^{2/3}.$\nThis bound is achieved by a new variance-reduced version of the Frank-Wolfe\nalgorithm that requires just a single pass over the data. We also show that the\nlower bound in this case is the minimum of the two rates mentioned above.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 06:53:44 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Asi", "Hilal", ""], ["Feldman", "Vitaly", ""], ["Koren", "Tomer", ""], ["Talwar", "Kunal", ""]]}, {"id": "2103.01527", "submitter": "Mingfu Xue", "authors": "Mingfu Xue, Shichang Sun, Can He, Yushu Zhang, Jian Wang, Weiqiang Liu", "title": "ActiveGuard: An Active DNN IP Protection Technique via Adversarial\n  Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The training of Deep Neural Networks (DNN) is costly, thus DNN can be\nconsidered as the intellectual properties (IP) of model owners. To date, most\nof the existing protection works focus on verifying the ownership after the DNN\nmodel is stolen, which cannot resist piracy in advance. To this end, we propose\nan active DNN IP protection method based on adversarial examples against DNN\npiracy, named ActiveGuard. ActiveGuard aims to achieve authorization control\nand users' fingerprints management through adversarial examples, and can\nprovide ownership verification. Specifically, ActiveGuard exploits the\nelaborate adversarial examples as users' fingerprints to distinguish authorized\nusers from unauthorized users. Legitimate users can enter fingerprints into DNN\nfor identity authentication and authorized usage, while unauthorized users will\nobtain poor model performance due to an additional control layer. In addition,\nActiveGuard enables the model owner to embed a watermark into the weights of\nDNN. When the DNN is illegally pirated, the model owner can extract the\nembedded watermark and perform ownership verification. Experimental results\nshow that, for authorized users, the test accuracy of LeNet-5 and Wide Residual\nNetwork (WRN) models are 99.15% and 91.46%, respectively, while for\nunauthorized users, the test accuracy of the two DNNs are only 8.92% (LeNet-5)\nand 10% (WRN), respectively. Besides, each authorized user can pass the\nfingerprint authentication with a high success rate (up to 100%). For ownership\nverification, the embedded watermark can be successfully extracted, while the\nnormal performance of the DNN model will not be affected. Further, ActiveGuard\nis demonstrated to be robust against fingerprint forgery attack, model\nfine-tuning attack and pruning attack.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 07:16:20 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Xue", "Mingfu", ""], ["Sun", "Shichang", ""], ["He", "Can", ""], ["Zhang", "Yushu", ""], ["Wang", "Jian", ""], ["Liu", "Weiqiang", ""]]}, {"id": "2103.01568", "submitter": "Mahtab Mirmohseni Dr", "authors": "Ali Khalesi, Mahtab Mirmohseni, and Mohammad Ali Maddah-Ali", "title": "The Capacity Region of Distributed Multi-User Secret Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of distributed multi-user secret sharing,\nincluding a trusted master node, $N\\in \\mathbb{N}$ storage nodes, and $K$\nusers, where each user has access to the contents of a subset of storage nodes.\nEach user has an independent secret message with certain rate, defined as the\nsize of the message normalized by the size of a storage node. Having access to\nthe secret messages, the trusted master node places encoded shares in the\nstorage nodes, such that (i) each user can recover its own message from the\ncontent of the storage nodes that it has access to, (ii) each user cannot gain\nany information about the message of any other user. We characterize the\ncapacity region of the distributed multi-user secret sharing, defined as the\nset of all achievable rate tuples, subject to the correctness and privacy\nconstraints. In the achievable scheme, for each user, the master node forms a\npolynomial with the degree equal to the number of its accessible storage nodes\nminus one, where the value of this polynomial at certain points are stored as\nthe encoded shares. The message of that user is embedded in some of the\ncoefficients of the polynomial. The remaining coefficients are determined such\nthat the content of each storage node serves as the encoded shares for all\nusers that have access to that storage node.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 08:45:37 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Khalesi", "Ali", ""], ["Mirmohseni", "Mahtab", ""], ["Maddah-Ali", "Mohammad Ali", ""]]}, {"id": "2103.01607", "submitter": "Chenguo Lin", "authors": "Chaoning Zhang, Chenguo Lin, Philipp Benz, Kejiang Chen, Weiming Zhang\n  and In So Kweon", "title": "A Brief Survey on Deep Learning Based Data Hiding, Steganography and\n  Watermarking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data hiding is the art of concealing messages with limited perceptual\nchanges. Recently, deep learning has provided enriching perspectives for it and\nmade significant progress. In this work, we conduct a brief yet comprehensive\nreview of existing literature and outline three meta-architectures. Based on\nthis, we summarize specific strategies for various applications of deep hiding,\nincluding steganography, light field messaging and watermarking. Finally,\nfurther insight into deep hiding is provided through incorporating the\nperspective of adversarial attack.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 10:01:03 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Zhang", "Chaoning", ""], ["Lin", "Chenguo", ""], ["Benz", "Philipp", ""], ["Chen", "Kejiang", ""], ["Zhang", "Weiming", ""], ["Kweon", "In So", ""]]}, {"id": "2103.01748", "submitter": "Luca Verderame", "authors": "Meriem Guerar, Luca Verderame, Mauro Migliardi, Francesco Palmieri and\n  Alessio Merlo", "title": "Gotta CAPTCHA 'Em All: A Survey of Twenty years of the Human-or-Computer\n  Dilemma", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent study has found that malicious bots generated nearly a quarter of\noverall website traffic in 2019 [100]. These malicious bots perform activities\nsuch as price and content scraping, account creation and takeover, credit card\nfraud, denial of service, etc. Thus, they represent a serious threat to all\nbusinesses in general, but are especially troublesome for e-commerce, travel\nand financial services. One of the most common defense mechanisms against bots\nabusing online services is the introduction of Completely Automated Public\nTuring test to tell Computers and Humans Apart (CAPTCHA), so it is extremely\nimportant to understand which CAPTCHA schemes have been designed and their\nactual effectiveness against the ever-evolving bots. To this end, this work\nprovides an overview of the current state-of-the-art in the field of CAPTCHA\nschemes and defines a new classification that includes all the emerging\nschemes. In addition, for each identified CAPTCHA category, the most successful\nattack methods are summarized by also describing how CAPTCHA schemes evolved to\nresist bot attacks, and discussing the limitations of different CAPTCHA schemes\nfrom the security, usability and compatibility point of view. Finally, an\nassessment of the open issues, challenges, and opportunities for further study\nis provided, paving the road toward the design of the next-generation secure\nand user-friendly CAPTCHA schemes.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 14:29:14 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Guerar", "Meriem", ""], ["Verderame", "Luca", ""], ["Migliardi", "Mauro", ""], ["Palmieri", "Francesco", ""], ["Merlo", "Alessio", ""]]}, {"id": "2103.01754", "submitter": "Abhishek Singh", "authors": "Abhishek Singh, Ramesh Raskar, Anna Lysyanskaya", "title": "Safepaths: Vaccine Diary Protocol and Decentralized Vaccine Coordination\n  System using a Privacy Preserving User Centric Experience", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this early draft, we present an end-to-end decentralized protocol for the\nsecure and privacy preserving workflow of vaccination, vaccination status\nverification, and adverse reactions or symptoms reporting. The proposed system\nimproves the efficiency, privacy, equity, and effectiveness of the existing\nmanual system while remaining interoperable with its capabilities. We also\ndiscuss various security concerns and alternate methodologies based on the\nproposed protocols.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 05:07:08 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Singh", "Abhishek", ""], ["Raskar", "Ramesh", ""], ["Lysyanskaya", "Anna", ""]]}, {"id": "2103.01781", "submitter": "Malin Prematilake", "authors": "Malin Prematilake, Younghyun Kim, Vijay Raghunathan, Anand\n  Raghunathan, N.K. Jha", "title": "HW/SW Framework for Improving the Safety of Implantable and Wearable\n  Medical Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Implantable and wearable medical devices (IWMDs) are widely used for the\nmonitoring and therapy of an increasing range of medical conditions.\nImprovements in medical devices, enabled by advances in low-power processors,\nmore complex firmware, and wireless connectivity, have greatly improved\ntherapeutic outcomes and patients' quality-of-life. However, security attacks,\nmalfunctions and sometimes user errors have raised great concerns regarding the\nsafety of IWMDs. In this work, we present a HW/SW (Hardware/Software) framework\nfor improving the safety of IWMDs, wherein a set of safety rules and a rule\ncheck mechanism are used to monitor both the extrinsic state (the patient's\nphysiological parameters sensed by the IWMD) and the internal state of the IWMD\n(I/O activities of the microcontroller) to infer unsafe operations that may be\ntriggered by user errors, software bugs, or security attacks. We discuss how\nthis approach can be realized in the context of a artificial pancreas with\nwireless connectivity and implement a prototype to demonstrate its\neffectiveness in improving safety at modest overheads.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2021 17:40:57 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Prematilake", "Malin", ""], ["Kim", "Younghyun", ""], ["Raghunathan", "Vijay", ""], ["Raghunathan", "Anand", ""], ["Jha", "N. K.", ""]]}, {"id": "2103.01914", "submitter": "Dorjan Hitaj", "authors": "Dorjan Hitaj, Giulio Pagnotta, Iacopo Masi, Luigi V. Mancini", "title": "Evaluating the Robustness of Geometry-Aware Instance-Reweighted\n  Adversarial Training", "comments": "6 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this technical report, we evaluate the adversarial robustness of a very\nrecent method called \"Geometry-aware Instance-reweighted Adversarial\nTraining\"[7]. GAIRAT reports state-of-the-art results on defenses to\nadversarial attacks on the CIFAR-10 dataset. In fact, we find that a network\ntrained with this method, while showing an improvement over regular adversarial\ntraining (AT), is biasing the model towards certain samples by re-scaling the\nloss. Indeed, this leads the model to be susceptible to attacks that scale the\nlogits. The original model shows an accuracy of 59% under AutoAttack - when\ntrained with additional data with pseudo-labels. We provide an analysis that\nshows the opposite. In particular, we craft a PGD attack multiplying the logits\nby a positive scalar that decreases the GAIRAT accuracy from from 55% to 44%,\nwhen trained solely on CIFAR-10. In this report, we rigorously evaluate the\nmodel and provide insights into the reasons behind the vulnerability of GAIRAT\nto this adversarial attack. The code to reproduce our evaluation is made\navailable at https://github.com/giuxhub/GAIRAT-LSA\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 18:15:42 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 13:04:35 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Hitaj", "Dorjan", ""], ["Pagnotta", "Giulio", ""], ["Masi", "Iacopo", ""], ["Mancini", "Luigi V.", ""]]}, {"id": "2103.01936", "submitter": "Boris \\v{S}kori\\'c", "authors": "Boris Skoric and Zef Wolffs", "title": "Diagrammatic security proof for 8-state encoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dirac notation is the most common way to describe quantum states and\noperations on states. It is very convenient and allows for quick visual\ndistinction between vectors, scalars and operators. For quantum processes that\ninvolve interactions of multiple systems an even better visualisation has been\nproposed by Coecke and Kissinger, in the form of a diagrammatic formalism\n[CK2017]. Their notation expresses formulas in the form of diagrams, somewhat\nsimilar to Feynman diagrams, and is more general than the circuit notation for\nquantum computing.\n  This document consists of two parts. (1) We give a brief summary of the\ndiagrammatic notation of quantum processes, tailored to readers who already\nknow quantum physics and are not interested in general process theory. For this\naudience our summary is less daunting than the encyclopaedic book by Coecke and\nKissinger [CK2017], and on the other hand more accessible than the\nultra-compact introduction of [KTW2017]. We deviate a somewhat from\n[CK2017,KTW2017] in that we do not assume basis states to equal their own\ncomplex conjugate; this means that we do not use symmetric notation for basis\nstates, and it leads us to explicitly show arrows on wires where they are\nusually omitted.\n  (2) We extend the work of Kissinger, Tull and Westerbaan [KTW2017] which\ngives a diagrammatic security proof for BB84 and 6-state Quantum Key\nDistribution. Their proof is based on a sequence of diagrammatic manipulations\nthat works when the bases used in the protocol are mutually unbiased. We extend\nthis result to 8-state encoding, which has been proposed as a tool in quantum\nkey recycling protocols [SdV2017,LS2018], and which does not have mutually\nunbiased bases.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 18:51:20 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Skoric", "Boris", ""], ["Wolffs", "Zef", ""]]}, {"id": "2103.01953", "submitter": "Wei-Ting Chang", "authors": "Mohamed Seif, Wei-Ting Chang, Ravi Tandon", "title": "Privacy Amplification for Federated Learning via User Sampling and\n  Wireless Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of federated learning over a wireless\nchannel with user sampling, modeled by a Gaussian multiple access channel,\nsubject to central and local differential privacy (DP/LDP) constraints. It has\nbeen shown that the superposition nature of the wireless channel provides a\ndual benefit of bandwidth efficient gradient aggregation, in conjunction with\nstrong DP guarantees for the users. Specifically, the central DP privacy\nleakage has been shown to scale as $\\mathcal{O}(1/K^{1/2})$, where $K$ is the\nnumber of users. It has also been shown that user sampling coupled with\northogonal transmission can enhance the central DP privacy leakage with the\nsame scaling behavior. In this work, we show that, by join incorporating both\nwireless aggregation and user sampling, one can obtain even stronger privacy\nguarantees. We propose a private wireless gradient aggregation scheme, which\nrelies on independently randomized participation decisions by each user. The\ncentral DP leakage of our proposed scheme scales as $\\mathcal{O}(1/K^{3/4})$.\nIn addition, we show that LDP is also boosted by user sampling. We also present\nanalysis for the convergence rate of the proposed scheme and study the\ntradeoffs between wireless resources, convergence, and privacy theoretically\nand empirically for two scenarios when the number of sampled participants are\n$(a)$ known, or $(b)$ unknown at the parameter server.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 18:59:37 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Seif", "Mohamed", ""], ["Chang", "Wei-Ting", ""], ["Tandon", "Ravi", ""]]}, {"id": "2103.02014", "submitter": "Avishek Bose", "authors": "Andjela Mladenovic, Avishek Joey Bose, Hugo Berard, William L.\n  Hamilton, Simon Lacoste-Julien, Pascal Vincent, Gauthier Gidel", "title": "Online Adversarial Attacks", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks expose important vulnerabilities of deep learning models,\nyet little attention has been paid to settings where data arrives as a stream.\nIn this paper, we formalize the online adversarial attack problem, emphasizing\ntwo key elements found in real-world use-cases: attackers must operate under\npartial knowledge of the target model, and the decisions made by the attacker\nare irrevocable since they operate on a transient data stream. We first\nrigorously analyze a deterministic variant of the online threat model by\ndrawing parallels to the well-studied $k$-secretary problem in theoretical\ncomputer science and propose Virtual+, a simple yet practical online algorithm.\nOur main theoretical result show Virtual+ yields provably the best competitive\nratio over all single-threshold algorithms for $k<5$ -- extending previous\nanalysis of the $k$-secretary problem. We also introduce the \\textit{stochastic\n$k$-secretary} -- effectively reducing online blackbox transfer attacks to a\n$k$-secretary problem under noise -- and prove theoretical bounds on the\nperformance of \\textit{any} online algorithms adapted to this setting. Finally,\nwe complement our theoretical results by conducting experiments on both MNIST\nand CIFAR-10 with both vanilla and robust classifiers, revealing not only the\nnecessity of online algorithms in achieving near-optimal performance but also\nthe rich interplay of a given attack strategy towards online attack selection,\nenabling simple strategies like FGSM to outperform classically strong whitebox\nadversaries.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 20:36:04 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 16:47:35 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 02:19:04 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Mladenovic", "Andjela", ""], ["Bose", "Avishek Joey", ""], ["Berard", "Hugo", ""], ["Hamilton", "William L.", ""], ["Lacoste-Julien", "Simon", ""], ["Vincent", "Pascal", ""], ["Gidel", "Gauthier", ""]]}, {"id": "2103.02061", "submitter": "Alberto Inselvini", "authors": "Alberto Inselvini", "title": "Spam Prevention Using zk-SNARKs for Anonymous Peer-to-Peer Content\n  Sharing Systems", "comments": "16 pages, originally written in Nov. 2019 but published on Arxiv now\n  after some minor improvements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Decentralized unpermissioned peer-to-peer networks are inherently vulnerable\nto spam when they allow arbitrary participants to submit content to a common\npublic index or registry; preventing this is difficult due to the absence of a\ncentral arbitrator who can act as a gate-keeper. For this reason indexing of\nnew content even in otherwise decentralized networks (e.g. Bittorrent with DHT,\nIPFS) has generally been left to centralized services such as torrent sites.\n  Decentralized methods for spam prevention, such as Web of Trust, already\nexist[1][2] but they require submitters to assume pseudonymous identities and\nestablish trust over time.\n  In this paper we present a method of spam prevention that works under the\nassumption that the participants are fully anonymous and do not want different\nsubmissions of theirs to be linked to each other.\n  By spam we do not specifically mean unsolicited advertising; rather it is the\npractice of adding a large amount of content in a short time, saturating the\ncapacity of the network, and causing denial of service to peers. The purpose of\nour solution is to prevent users from saturating the system, and can be\ndescribed as rate-limiting. The system should be censorship resistant: it\nshould not be possible for submissions to be excluded because of the content\nitself, or for users to be excluded based on what they submit.\n  We first discuss a solution based on a single, centralized rate-limiter that\nis censorship resistant and anonymous, then we extend this to a fully\ndecentralized blockchain-based system and present methods to make it economical\nand scalable.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 22:19:35 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Inselvini", "Alberto", ""]]}, {"id": "2103.02079", "submitter": "Tom Goldstein", "authors": "Eitan Borgnia, Jonas Geiping, Valeriia Cherepanova, Liam Fowl, Arjun\n  Gupta, Amin Ghiasi, Furong Huang, Micah Goldblum, Tom Goldstein", "title": "DP-InstaHide: Provably Defusing Poisoning and Backdoor Attacks with\n  Differentially Private Data Augmentations", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data poisoning and backdoor attacks manipulate training data to induce\nsecurity breaches in a victim model. These attacks can be provably deflected\nusing differentially private (DP) training methods, although this comes with a\nsharp decrease in model performance. The InstaHide method has recently been\nproposed as an alternative to DP training that leverages supposed privacy\nproperties of the mixup augmentation, although without rigorous guarantees. In\nthis work, we show that strong data augmentations, such as mixup and random\nadditive noise, nullify poison attacks while enduring only a small accuracy\ntrade-off. To explain these finding, we propose a training method,\nDP-InstaHide, which combines the mixup regularizer with additive noise. A\nrigorous analysis of DP-InstaHide shows that mixup does indeed have privacy\nadvantages, and that training with k-way mixup provably yields at least k times\nstronger DP guarantees than a naive DP mechanism. Because mixup (as opposed to\nnoise) is beneficial to model performance, DP-InstaHide provides a mechanism\nfor achieving stronger empirical performance against poisoning attacks than\nother known DP methods.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 23:07:31 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 06:40:34 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Borgnia", "Eitan", ""], ["Geiping", "Jonas", ""], ["Cherepanova", "Valeriia", ""], ["Fowl", "Liam", ""], ["Gupta", "Arjun", ""], ["Ghiasi", "Amin", ""], ["Huang", "Furong", ""], ["Goldblum", "Micah", ""], ["Goldstein", "Tom", ""]]}, {"id": "2103.02171", "submitter": "Sandip Ghosal", "authors": "Sandip Ghosal and R. K. Shyamasundar", "title": "An Axiomatic Approach to Detect Information Leaks in Concurrent Programs", "comments": "5 pages, 2 figures; accepted paper for the 43rd International\n  Conference on Software Engineering (ICSE 2021), Track: New Ideas and Emerging\n  Results (NIER)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Realizing flow security in a concurrent environment is extremely challenging,\nprimarily due to non-deterministic nature of execution. The difficulty is\nfurther exacerbated from a security angle if sequential threads disclose\ncontrol locations through publicly observable statements like print, sleep,\ndelay, etc. Such observations lead to internal and external timing attacks.\nInspired by previous works that use classical Hoare style proof systems for\nestablishing correctness of distributed (real-time) programs, in this paper, we\ndescribe a method for finding information leaks in concurrent programs through\nthe introduction of leaky assertions at observable program points. Specifying\nleaky assertions akin to classic assertions, we demonstrate how information\nleaks can be detected in a concurrent context. To our knowledge, this is the\nfirst such work that enables integration of different notions of\nnon-interference used in functional and security context. While the approach is\nsound and relatively complete in the classic sense, it enables the use of\nalgorithmic techniques that enable programmers to come up with leaky assertions\nthat enable checking for information leaks in sensitive applications.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 04:34:23 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Ghosal", "Sandip", ""], ["Shyamasundar", "R. K.", ""]]}, {"id": "2103.02209", "submitter": "Xinyuan Sun", "authors": "Shaokai Lin, Xinyuan Sun, Jianan Yao, Ronghui Gu", "title": "SciviK: A Versatile Framework for Specifying and Verifying Smart\n  Contracts", "comments": "22 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing adoption of smart contracts on blockchains poses new security\nrisks that can lead to significant monetary loss, while existing approaches\neither provide no (or partial) security guarantees for smart contracts or\nrequire huge proof effort. To address this challenge, we present SciviK, a\nversatile framework for specifying and verifying industrial-grade smart\ncontracts. SciviK's versatile approach extends previous efforts with three key\ncontributions: (i) an expressive annotation system enabling built-in directives\nfor vulnerability pattern checking, neural-based loop invariant inference, and\nthe verification of rich properties of real-world smart contracts (ii) a\nfine-grained model for the Ethereum Virtual Machine (EVM) that provides\nlow-level execution semantics, (iii) an IR-level verification framework\nintegrating both SMT solvers and the Coq proof assistant.\n  We use SciviK to specify and verify security properties for 12 benchmark\ncontracts and a real-world Decentralized Finance (DeFi) smart contract. Among\nall 158 specified security properties (in six types), 151 properties can be\nautomatically verified within 2 seconds, five properties can be automatically\nverified after moderate modifications, and two properties are manually proved\nwith around 200 lines of Coq code.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 06:45:05 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Lin", "Shaokai", ""], ["Sun", "Xinyuan", ""], ["Yao", "Jianan", ""], ["Gu", "Ronghui", ""]]}, {"id": "2103.02228", "submitter": "Liyi Zhou", "authors": "Liyi Zhou, Kaihua Qin, Antoine Cully, Benjamin Livshits, Arthur\n  Gervais", "title": "On the Just-In-Time Discovery of Profit-Generating Transactions in DeFi\n  Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate two methods that allow us to automatically\ncreate profitable DeFi trades, one well-suited to arbitrage and the other\napplicable to more complicated settings. We first adopt the Bellman-Ford-Moore\nalgorithm with DEFIPOSER-ARB and then create logical DeFi protocol models for a\ntheorem prover in DEFIPOSER-SMT. While DEFIPOSER-ARB focuses on DeFi\ntransactions that form a cycle and performs very well for arbitrage,\nDEFIPOSER-SMT can detect more complicated profitable transactions. We estimate\nthat DEFIPOSER-ARB and DEFIPOSER-SMT can generate an average weekly revenue of\n191.48ETH (76,592USD) and 72.44ETH (28,976USD) respectively, with the highest\ntransaction revenue being 81.31ETH(32,524USD) and22.40ETH (8,960USD)\nrespectively. We further show that DEFIPOSER-SMT finds the known economic bZx\nattack from February 2020, which yields 0.48M USD. Our forensic investigations\nshow that this opportunity existed for 69 days and could have yielded more\nrevenue if exploited one day earlier. Our evaluation spans 150 days, given 96\nDeFi protocol actions, and 25 assets.\n  Looking beyond the financial gains mentioned above, forks deteriorate the\nblockchain consensus security, as they increase the risks of double-spending\nand selfish mining. We explore the implications of DEFIPOSER-ARB and\nDEFIPOSER-SMT on blockchain consensus. Specifically, we show that the trades\nidentified by our tools exceed the Ethereum block reward by up to 874x. Given\noptimal adversarial strategies provided by a Markov Decision Process (MDP), we\nquantify the value threshold at which a profitable transaction qualifies as\nMiner ExtractableValue (MEV) and would incentivize MEV-aware miners to fork the\nblockchain. For instance, we find that on Ethereum, a miner with a hash rate of\n10% would fork the blockchain if an MEV opportunity exceeds 4x the block\nreward.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 07:42:35 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Zhou", "Liyi", ""], ["Qin", "Kaihua", ""], ["Cully", "Antoine", ""], ["Livshits", "Benjamin", ""], ["Gervais", "Arthur", ""]]}, {"id": "2103.02260", "submitter": "David Fischer", "authors": "Jiali Xing, David Fischer, Nitya Labh, Ryan Piersma, Benjamin C. Lee,\n  Yu Amy Xia, Tuhin Sahai, Vahid Tarokh", "title": "Talaria: A Framework for Simulation of Permissioned Blockchains for\n  Logistics and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present Talaria, a novel permissioned blockchain simulator\nthat supports numerous protocols and use cases, most notably in supply chain\nmanagement. Talaria extends the capability of BlockSim, an existing blockchain\nsimulator, to include permissioned blockchains and serves as a foundation for\nfurther private blockchain assessment. Talaria is designed with both practical\nByzantine Fault Tolerance (pBFT) and simplified version of Proof-of-Authority\nconsensus protocols, but can be revised to include other permissioned protocols\nwithin its modular framework. Moreover, Talaria is able to simulate different\ntypes of malicious authorities and a variable daily transaction load at each\nnode. In using Talaria, business practitioners and policy planners have an\nopportunity to measure, evaluate, and adapt a range of blockchain solutions for\ncommercial operations.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 08:43:30 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 00:22:10 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Xing", "Jiali", ""], ["Fischer", "David", ""], ["Labh", "Nitya", ""], ["Piersma", "Ryan", ""], ["Lee", "Benjamin C.", ""], ["Xia", "Yu Amy", ""], ["Sahai", "Tuhin", ""], ["Tarokh", "Vahid", ""]]}, {"id": "2103.02282", "submitter": "Milan Stute", "authors": "Alexander Heinrich, Milan Stute, Tim Kornhuber, Matthias Hollick", "title": "Who Can Find My Devices? Security and Privacy of Apple's Crowd-Sourced\n  Bluetooth Location Tracking System", "comments": "Accepted at Privacy Enhancing Technologies Symposium (PETS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Overnight, Apple has turned its hundreds-of-million-device ecosystem into the\nworld's largest crowd-sourced location tracking network called offline finding\n(OF). OF leverages online finder devices to detect the presence of missing\noffline devices using Bluetooth and report an approximate location back to the\nowner via the Internet. While OF is not the first system of its kind, it is the\nfirst to commit to strong privacy goals. In particular, OF aims to ensure\nfinder anonymity, untrackability of owner devices, and confidentiality of\nlocation reports. This paper presents the first comprehensive security and\nprivacy analysis of OF. To this end, we recover the specifications of the\nclosed-source OF protocols by means of reverse engineering. We experimentally\nshow that unauthorized access to the location reports allows for accurate\ndevice tracking and retrieving a user's top locations with an error in the\norder of 10 meters in urban areas. While we find that OF's design achieves its\nprivacy goals, we discover two distinct design and implementation flaws that\ncan lead to a location correlation attack and unauthorized access to the\nlocation history of the past seven days, which could deanonymize users. Apple\nhas partially addressed the issues following our responsible disclosure.\nFinally, we make our research artifacts publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 09:46:34 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Heinrich", "Alexander", ""], ["Stute", "Milan", ""], ["Kornhuber", "Tim", ""], ["Hollick", "Matthias", ""]]}, {"id": "2103.02301", "submitter": "Vasileios Mavroeidis Dr.", "authors": "Vasileios Mavroeidis, Ryan Hohimer, Tim Casey, Audun J{\\o}sang", "title": "Threat Actor Type Inference and Characterization within Cyber Threat\n  Intelligence", "comments": "This article has been removed by arXiv administrators because the\n  submitter did not have the authority to assign the license at the time of\n  submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the cyber threat landscape is constantly becoming increasingly complex and\npolymorphic, the more critical it becomes to understand the enemy and its modus\noperandi for anticipatory threat reduction. Even though the cyber security\ncommunity has developed a certain maturity in describing and sharing technical\nindicators for informing defense components, we still struggle with\nnon-uniform, unstructured, and ambiguous higher-level information, such as the\nthreat actor context, thereby limiting our ability to correlate with different\nsources to derive more contextual, accurate, and relevant intelligence. We see\nthe need to overcome this limitation in order to increase our ability to\nproduce and better operationalize cyber threat intelligence. Our research\ndemonstrates how commonly agreed upon controlled vocabularies for\ncharacterizing threat actors and their operations can be used to enrich cyber\nthreat intelligence and infer new information at a higher contextual level that\nis explicable and queryable. In particular, we present an ontological approach\nto automatically inferring the types of threat actors based on their personas,\nunderstanding their nature, and capturing polymorphism and changes in their\nbehavior and characteristics over time. Such an approach not only enables\ninteroperability by providing a structured way and means for sharing highly\ncontextual cyber threat intelligence but also derives new information at\nmachine speed and minimizes cognitive biases that manual classification\napproaches entail.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 10:26:34 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 10:20:45 GMT"}, {"version": "v3", "created": "Sun, 11 Apr 2021 14:27:25 GMT"}, {"version": "v4", "created": "Mon, 19 Apr 2021 12:19:48 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Mavroeidis", "Vasileios", ""], ["Hohimer", "Ryan", ""], ["Casey", "Tim", ""], ["J\u00f8sang", "Audun", ""]]}, {"id": "2103.02579", "submitter": "Srivathsan Morkonda Gnanasekaran", "authors": "Srivathsan G. Morkonda, Paul C. van Oorschot, Sonia Chiasson", "title": "Exploring Privacy Implications in OAuth Deployments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single sign-on authentication systems such as OAuth 2.0 are widely used in\nweb services. They allow users to use accounts registered with major identity\nproviders such as Google and Facebook to login on multiple services (relying\nparties). These services can both identify users and access a subset of the\nuser's data stored with the provider. We empirically investigate the end-user\nprivacy implications of OAuth 2.0 implementations in relying parties most\nvisited around the world. We collect data on the use of OAuth-based logins in\nthe Alexa Top 500 sites per country for five countries. We categorize user data\nmade available by four identity providers (Google, Facebook, Apple and\nLinkedIn) and evaluate popular services accessing user data from the SSO\nplatforms of these providers. Many services allow users to choose from multiple\nlogin options (with different identity providers). Our results reveal that\nservices request different categories and amounts of personal data from\ndifferent providers, with at least one choice undeniably more\nprivacy-intrusive. These privacy choices (and their privacy implications) are\nhighly invisible to users. Based on our analysis, we also identify areas which\ncould improve user privacy and help users make informed decisions.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 18:22:13 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Morkonda", "Srivathsan G.", ""], ["van Oorschot", "Paul C.", ""], ["Chiasson", "Sonia", ""]]}, {"id": "2103.02606", "submitter": "Luca Gambazzi", "authors": "Luca Gambazzi, Patrick Schaller, Alain Mermoud, Vincent Lenders", "title": "Blockchain in Cyberdefence: A Technology Review from a Swiss Perspective", "comments": "22 pages, 9 figures arXiv:1903.07602 arXiv:1806.10929 arXiv:1311.0243", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Since the advent of bitcoin in 2008, the concept of a blockchain has widely\nspread. Besides crypto currencies and trading activities, there is a wide range\nof potential application areas where blockchains are providing the main\nbuilding block for secure solutions. From a technical point of view, a\nblockchain involves a set of cryptographic primitives to provide a data\nstructure with security and trust properties. However, a blockchain is not a\ngolden bullet. It may be well suited for some problems, but often an\ninappropriate data structure for many applications. In this paper, we review\nthe high-level concept of a blockchain and present possible applications in the\nmilitary field. Our review is targeted to readers with little prior domain\nknowledge as a support to decide where it makes sense to use a blockchain and\nwhere a blockchain might not be the right tool at hand.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 15:10:22 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Gambazzi", "Luca", ""], ["Schaller", "Patrick", ""], ["Mermoud", "Alain", ""], ["Lenders", "Vincent", ""]]}, {"id": "2103.02637", "submitter": "Jide Edu S", "authors": "Jide S Edu, Xavier Ferrer-Aran, Jose M Such, Guillermo Suarez-Tangi", "title": "SkillVet: Automated Traceability Analysis of Amazon Alexa Skills", "comments": "17pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Third-party software, or skills, are essential components in Smart Personal\nAssistants (SPA). The number of skills has grown rapidly, dominated by a\nchanging environment that has no clear business model. Skills can access\npersonal information and this may pose a risk to users. However, there is\nlittle information about how this ecosystem works, let alone the tools that can\nfacilitate its study. In this paper, we present the largest systematic\nmeasurement of the Amazon Alexa skill ecosystem to date. We study developers'\npractices in this ecosystem, including how they collect and justify the need\nfor sensitive information, by designing a methodology to identify\nover-privileged skills with broken privacy policies. We collect 199,295 Alexa\nskills and uncover that around 43% of the skills (and 50% of the developers)\nthat request these permissions follow bad privacy practices, including\n(partially) broken data permissions traceability. In order to perform this kind\nof analysis at scale, we present SkillVet that leverages machine learning and\nnatural language processing techniques, and generates high-accuracy prediction\nsets. We report a number of concerning practices including how developers can\nbypass Alexa's permission system through account linking and conversational\nskills, and offer recommendations on how to improve transparency, privacy and\nsecurity. Resulting from the responsible disclosure we have conducted,13% of\nthe reported issues no longer pose a threat at submission time.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 19:09:32 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Edu", "Jide S", ""], ["Ferrer-Aran", "Xavier", ""], ["Such", "Jose M", ""], ["Suarez-Tangi", "Guillermo", ""]]}, {"id": "2103.02668", "submitter": "Jing Yang Ms.", "authors": "Jing Yang, Qian Guo, Thomas Johansson, and Michael Lentmaier", "title": "Revisiting the Concrete Security of Goldreich's Pseudorandom Generator", "comments": "20 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local pseudorandom generators are a class of fundamental cryptographic\nprimitives having very broad applications in theoretical cryptography.\nFollowing Couteau et al.'s work in ASIACRYPT 2018, this paper further studies\nthe concrete security of one important class of local pseudorandom generators,\ni.e., Goldreich's pseudorandom generators. Our first attack is of the\nguess-and-determine type. Our result significantly improves the\nstate-of-the-art algorithm proposed by Couteau et al., in terms of both\nasymptotic and concrete complexity, and breaks all the challenge parameters\nthey proposed. For instance, for a parameter set suggested for 128 bits of\nsecurity, we could solve the instance faster by a factor of about $2^{61}$,\nthereby destroying the claimed security completely. Our second attack further\nexploits the extremely sparse structure of the predicate $P_5$ and combines\nideas from iterative decoding. This novel attack, named guess-and-decode,\nsubstantially improves the guess-and-determine approaches for\ncryptographic-relevant parameters. All the challenge parameter sets proposed in\nCouteau et al.'s work in ASIACRYPT 2018 aiming for 80-bit (128-bit) security\nlevels can be solved in about $2^{58}$ ($2^{78}$) operations. We suggest new\nparameters for achieving 80-bit (128-bit) security with respect to our attacks.\nWe also extend the attack to other promising predicates and investigate their\nresistance.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 20:39:26 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Yang", "Jing", ""], ["Guo", "Qian", ""], ["Johansson", "Thomas", ""], ["Lentmaier", "Michael", ""]]}, {"id": "2103.02683", "submitter": "Liam Fowl", "authors": "Liam Fowl, Ping-yeh Chiang, Micah Goldblum, Jonas Geiping, Arpit\n  Bansal, Wojtek Czaja, Tom Goldstein", "title": "Preventing Unauthorized Use of Proprietary Data: Poisoning for Secure\n  Dataset Release", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large organizations such as social media companies continually release data,\nfor example user images. At the same time, these organizations leverage their\nmassive corpora of released data to train proprietary models that give them an\nedge over their competitors. These two behaviors can be in conflict as an\norganization wants to prevent competitors from using their own data to\nreplicate the performance of their proprietary models. We solve this problem by\ndeveloping a data poisoning method by which publicly released data can be\nminimally modified to prevent others from train-ing models on it. Moreover, our\nmethod can be used in an online fashion so that companies can protect their\ndata in real time as they release it.We demonstrate the success of our approach\nonImageNet classification and on facial recognition.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 19:12:34 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 04:55:01 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Fowl", "Liam", ""], ["Chiang", "Ping-yeh", ""], ["Goldblum", "Micah", ""], ["Geiping", "Jonas", ""], ["Bansal", "Arpit", ""], ["Czaja", "Wojtek", ""], ["Goldstein", "Tom", ""]]}, {"id": "2103.02700", "submitter": "Maxime Bombar", "authors": "Maxime Bombar and Alain Couvreur", "title": "Decoding supercodes of Gabidulin codes and applications to cryptanalysis", "comments": "PQCrypto 2021. The Sage code is available on Github:\n  https://github.com/mbombar/Attack_on_LIGA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article discusses the decoding of Gabidulin codes and shows how to\nextend the usual decoder to any supercode of a Gabidulin code at the cost of a\nsignificant decrease of the decoding radius. Using this decoder, we provide\npolynomial time attacks on the rank-metric encryption schemes RAMESSES and\nLIGA.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 21:42:44 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 07:53:32 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Bombar", "Maxime", ""], ["Couvreur", "Alain", ""]]}, {"id": "2103.02702", "submitter": "Supriya Adhatarao", "authors": "Supriya Adhatarao, C\\'edric Lauradoux", "title": "Robust PDF Files Forensics Using Coding Style", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying how a file has been created is often interesting in security. It\ncan be used by both attackers and defenders. Attackers can exploit this\ninformation to tune their attacks and defenders can understand how a malicious\nfile has been created after an incident. In this work, we want to identify how\na PDF file has been created. This problem is important because PDF files are\nextremely popular: many organizations publish PDF files online and malicious\nPDF files are commonly used by attackers. Our approach to detect which software\nhas been used to produce a PDF file is based on coding style: given patterns\nthat are only created by certain PDF producers. We have analyzed the coding\nstyle of 900 PDF files produced using 11 PDF producers on 3 different Operating\nSystems. We have obtained a set of 192 rules which can be used to identify 11\nPDF producers. We have tested our detection tool on 508836 PDF files published\non scientific preprints servers. Our tool is able to detect certain producers\nwith an accuracy of 100%. Its overall detection is still high (74%). We were\nable to apply our tool to identify how online PDF services work and to spot\ninconsistency.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 21:44:37 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Adhatarao", "Supriya", ""], ["Lauradoux", "C\u00e9dric", ""]]}, {"id": "2103.02707", "submitter": "Supriya Adhatarao", "authors": "Supriya Adhatarao, C\\'edric Lauradoux", "title": "Exploitation and Sanitization of Hidden Data in PDF Files", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organizations publish and share more and more electronic documents like PDF\nfiles. Unfortunately, most organizations are unaware that these documents can\ncompromise sensitive information like authors names, details on the information\nsystem and architecture. All these information can be exploited easily by\nattackers to footprint and later attack an organization. In this paper, we\nanalyze hidden data found in the PDF files published by an organization. We\ngathered a corpus of 39664 PDF files published by 75 security agencies from 47\ncountries. We have been able to measure the quality and quantity of information\nexposed in these PDF files. It can be effectively used to find weak links in an\norganization: employees who are running outdated software. We have also\nmeasured the adoption of PDF files sanitization by security agencies. We\nidentified only 7 security agencies which sanitize few of their PDF files\nbefore publishing. Unfortunately, we were still able to find sensitive\ninformation within 65% of these sanitized PDF files. Some agencies are using\nweak sanitization techniques: it requires to remove all the hidden sensitive\ninformation from the file and not just to remove the data at the surface.\nSecurity agencies need to change their sanitization methods.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 21:52:17 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 17:16:12 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Adhatarao", "Supriya", ""], ["Lauradoux", "C\u00e9dric", ""]]}, {"id": "2103.02711", "submitter": "Mark Stamp", "authors": "Aparna Sunil Kale and Fabio Di Troia and Mark Stamp", "title": "Malware Classification with Word Embedding Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Malware classification is an important and challenging problem in information\nsecurity. Modern malware classification techniques rely on machine learning\nmodels that can be trained on features such as opcode sequences, API calls, and\nbyte $n$-grams, among many others. In this research, we consider opcode\nfeatures. We implement hybrid machine learning techniques, where we engineer\nfeature vectors by training hidden Markov models -- a technique that we refer\nto as HMM2Vec -- and Word2Vec embeddings on these opcode sequences. The\nresulting HMM2Vec and Word2Vec embedding vectors are then used as features for\nclassification algorithms. Specifically, we consider support vector machine\n(SVM), $k$-nearest neighbor ($k$-NN), random forest (RF), and convolutional\nneural network (CNN) classifiers. We conduct substantial experiments over a\nvariety of malware families. Our experiments extend well beyond any previous\nwork in this field.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 21:57:11 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Kale", "Aparna Sunil", ""], ["Di Troia", "Fabio", ""], ["Stamp", "Mark", ""]]}, {"id": "2103.02718", "submitter": "Matthew Ciolino", "authors": "Josh Kalin, David Noever, Matthew Ciolino", "title": "A Modified Drake Equation for Assessing Adversarial Risk to Machine\n  Learning Models", "comments": "8 Pages, 2 Figures, 3 Equations, 27 References, SAIM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning models present a risk of adversarial attack when deployed in\nproduction. Quantifying the contributing factors and uncertainties using\nempirical measures could assist the industry with assessing the risk of\ndownloading and deploying common model types. This work proposes modifying the\ntraditional Drake Equation's formalism to estimate the number of potentially\nsuccessful adversarial attacks on a deployed model. The Drake Equation is\nfamously used for parameterizing uncertainties and it has been used in many\nresearch fields outside of its original intentions to estimate the number of\nradio-capable extra-terrestrial civilizations. While previous work has outlined\nmethods for discovering vulnerabilities in public model architectures, the\nproposed equation seeks to provide a semi-quantitative benchmark for evaluating\nand estimating the potential risk factors for adversarial attacks.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 22:07:31 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 13:57:06 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Kalin", "Josh", ""], ["Noever", "David", ""], ["Ciolino", "Matthew", ""]]}, {"id": "2103.02746", "submitter": "Mark Stamp", "authors": "Dennis Dang and Fabio Di Troia and Mark Stamp", "title": "Malware Classification Using Long Short-Term Memory Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Signature and anomaly based techniques are the quintessential approaches to\nmalware detection. However, these techniques have become increasingly\nineffective as malware has become more sophisticated and complex. Researchers\nhave therefore turned to deep learning to construct better performing model. In\nthis paper, we create four different long-short term memory (LSTM) based models\nand train each to classify malware samples from 20 families. Our features\nconsist of opcodes extracted from malware executables. We employ techniques\nused in natural language processing (NLP), including word embedding and\nbidirection LSTMs (biLSTM), and we also use convolutional neural networks\n(CNN). We find that a model consisting of word embedding, biLSTMs, and CNN\nlayers performs best in our malware classification experiments.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 23:14:03 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Dang", "Dennis", ""], ["Di Troia", "Fabio", ""], ["Stamp", "Mark", ""]]}, {"id": "2103.02753", "submitter": "Mark Stamp", "authors": "Jing Zhao and Samanvitha Basole and Mark Stamp", "title": "Malware Classification with GMM-HMM Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Discrete hidden Markov models (HMM) are often applied to malware detection\nand classification problems. However, the continuous analog of discrete HMMs,\nthat is, Gaussian mixture model-HMMs (GMM-HMM), are rarely considered in the\nfield of cybersecurity. In this paper, we use GMM-HMMs for malware\nclassification and we compare our results to those obtained using discrete\nHMMs. As features, we consider opcode sequences and entropy-based sequences.\nFor our opcode features, GMM-HMMs produce results that are comparable to those\nobtained using discrete HMMs, whereas for our entropy-based features, GMM-HMMs\ngenerally improve significantly on the classification results that we have\nachieved with discrete HMMs.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 23:23:48 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Zhao", "Jing", ""], ["Basole", "Samanvitha", ""], ["Stamp", "Mark", ""]]}, {"id": "2103.02762", "submitter": "Yansong Gao Dr", "authors": "Yansong Gao, Minki Kim, Chandra Thapa, Sharif Abuadbba, Zhi Zhang,\n  Seyit A. Camtepe, Hyoungshick Kim, Surya Nepal", "title": "Evaluation and Optimization of Distributed Machine Learning Techniques\n  for Internet of Things", "comments": "14 pages. arXiv admin note: text overlap with arXiv:2003.13376", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Federated learning (FL) and split learning (SL) are state-of-the-art\ndistributed machine learning techniques to enable machine learning training\nwithout accessing raw data on clients or end devices. However, their\n\\emph{comparative training performance} under real-world resource-restricted\nInternet of Things (IoT) device settings, e.g., Raspberry Pi, remains barely\nstudied, which, to our knowledge, have not yet been evaluated and compared,\nrendering inconvenient reference for practitioners. This work firstly provides\nempirical comparisons of FL and SL in real-world IoT settings regarding (i)\nlearning performance with heterogeneous data distributions and (ii) on-device\nexecution overhead. Our analyses in this work demonstrate that the learning\nperformance of SL is better than FL under an imbalanced data distribution but\nworse than FL under an extreme non-IID data distribution. Recently, FL and SL\nare combined to form splitfed learning (SFL) to leverage each of their benefits\n(e.g., parallel training of FL and lightweight on-device computation\nrequirement of SL). This work then considers FL, SL, and SFL, and mount them on\nRaspberry Pi devices to evaluate their performance, including training time,\ncommunication overhead, power consumption, and memory usage. Besides\nevaluations, we apply two optimizations. Firstly, we generalize SFL by\ncarefully examining the possibility of a hybrid type of model training at the\nserver-side. The generalized SFL merges sequential (dependent) and parallel\n(independent) processes of model training and is thus beneficial for a system\nwith large-scaled IoT devices, specifically at the server-side operations.\nSecondly, we propose pragmatic techniques to substantially reduce the\ncommunication overhead by up to four times for the SL and (generalized) SFL.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 23:55:37 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Gao", "Yansong", ""], ["Kim", "Minki", ""], ["Thapa", "Chandra", ""], ["Abuadbba", "Sharif", ""], ["Zhang", "Zhi", ""], ["Camtepe", "Seyit A.", ""], ["Kim", "Hyoungshick", ""], ["Nepal", "Surya", ""]]}, {"id": "2103.02841", "submitter": "Berker Pek\\\"oz", "authors": "Murat Karabacak, Berker Pek\\\"oz, G\\\"okhan Mumcu and H\\\"useyin Arslan", "title": "Arraymetrics: Authentication Through Chaotic Antenna Array Geometries", "comments": "in IEEE Communications Letters", "journal-ref": null, "doi": "10.1109/LCOMM.2021.3063049", "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in computing have resulted in an emerging need for multi-factor\nauthentication using an amalgamation of cryptographic and physical keys. This\nletter presents a novel authentication approach using a combination of signal\nand antenna activation sequences, and most importantly, perturbed antenna array\ngeometries. Possible degrees of freedom in perturbing antenna array geometries\naffected physical properties and their detection are presented. Channel\nestimation for the plurality of validly authorized arrays is discussed.\nAccuracy is investigated as a function of signal-to-noise ratio (SNR) and\nnumber of authorized arrays. It is observed that the proposed authentication\nscheme can provide 1% false authentication rate at 10 dB SNR, while it is\nachieving less than 1% missed authentication rates.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 05:38:10 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Karabacak", "Murat", ""], ["Pek\u00f6z", "Berker", ""], ["Mumcu", "G\u00f6khan", ""], ["Arslan", "H\u00fcseyin", ""]]}, {"id": "2103.02872", "submitter": "Ipsita Koley", "authors": "Ipsita Koley, Sunandan Adhikary and Soumyajit Dey", "title": "An RL-Based Adaptive Detection Strategy to Secure Cyber-Physical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increased dependence on networked, software based control has escalated the\nvulnerabilities of Cyber Physical Systems (CPSs). Detection and monitoring\ncomponents developed leveraging dynamical systems theory are often employed as\nlightweight security measures for protecting such safety critical CPSs against\nfalse data injection attacks. However, existing approaches do not correlate\nattack scenarios with parameters of detection systems. In the present work, we\npropose a Reinforcement Learning (RL) based framework which adaptively sets the\nparameters of such detectors based on experience learned from attack scenarios,\nmaximizing detection rate and minimizing false alarms in the process while\nattempting performance preserving control actions.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 07:38:50 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Koley", "Ipsita", ""], ["Adhikary", "Sunandan", ""], ["Dey", "Soumyajit", ""]]}, {"id": "2103.02873", "submitter": "Bin Wang", "authors": "Bin Wang, Han Liu, Chao Liu, Zhiqiang Yang, Qian Ren, Huixuan Zheng,\n  Hong Lei", "title": "BLOCKEYE: Hunting For DeFi Attacks on Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Decentralized finance, i.e., DeFi, has become the most popular type of\napplication on many public blockchains (e.g., Ethereum) in recent years.\nCompared to the traditional finance, DeFi allows customers to flexibly\nparticipate in diverse blockchain financial services (e.g., lending, borrowing,\ncollateralizing, exchanging etc.) via smart contracts at a relatively low cost\nof trust. However, the open nature of DeFi inevitably introduces a large attack\nsurface, which is a severe threat to the security of participants funds. In\nthis paper, we proposed BLOCKEYE, a real-time attack detection system for DeFi\nprojects on the Ethereum blockchain. Key capabilities provided by BLOCKEYE are\ntwofold: (1) Potentially vulnerable DeFi projects are identified based on an\nautomatic security analysis process, which performs symbolic reasoning on the\ndata flow of important service states, e.g., asset price, and checks whether\nthey can be externally manipulated. (2) Then, a transaction monitor is\ninstalled offchain for a vulnerable DeFi project. Transactions sent not only to\nthat project but other associated projects as well are collected for further\nsecurity analysis. A potential attack is flagged if a violation is detected on\na critical invariant configured in BLOCKEYE, e.g., Benefit is achieved within a\nvery short time and way much bigger than the cost. We applied BLOCKEYE in\nseveral popular DeFi projects and managed to discover potential security\nattacks that are unreported before. A video of BLOCKEYE is available at\nhttps://youtu.be/7DjsWBLdlQU.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 07:41:12 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Wang", "Bin", ""], ["Liu", "Han", ""], ["Liu", "Chao", ""], ["Yang", "Zhiqiang", ""], ["Ren", "Qian", ""], ["Zheng", "Huixuan", ""], ["Lei", "Hong", ""]]}, {"id": "2103.02895", "submitter": "Daniel Bernau", "authors": "Dominik Wunderlich, Daniel Bernau, Francesco Ald\\`a, Javier\n  Parra-Arnau, Thorsten Strufe", "title": "On the privacy-utility trade-off in differentially private hierarchical\n  text classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical models for text classification can leak sensitive or\nconfidential training data information to adversaries due to training data\nmemorization. Using differential privacy during model training can mitigate\nleakage attacks against trained models by perturbing the training optimizer.\nHowever, for hierarchical text classification a multiplicity of model\narchitectures is available and it is unclear whether some architectures yield a\nbetter trade-off between remaining model accuracy and model leakage under\ndifferentially private training perturbation than others. We use a white-box\nmembership inference attack to assess the information leakage of three widely\nused neural network architectures for hierarchical text classification under\ndifferential privacy. We show that relatively weak differential privacy\nguarantees already suffice to completely mitigate the membership inference\nattack, thus resulting only in a moderate decrease in utility. More\nspecifically, for large datasets with long texts we observed transformer-based\nmodels to achieve an overall favorable privacy-utility trade-off, while for\nsmaller datasets with shorter texts CNNs are preferable.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 08:51:00 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Wunderlich", "Dominik", ""], ["Bernau", "Daniel", ""], ["Ald\u00e0", "Francesco", ""], ["Parra-Arnau", "Javier", ""], ["Strufe", "Thorsten", ""]]}, {"id": "2103.02913", "submitter": "Daniel Bernau", "authors": "Daniel Bernau, G\\\"unther Eibl, Philip W. Grassal, Hannah Keller,\n  Florian Kerschbaum", "title": "Quantifying identifiability to choose and audit $\\epsilon$ in\n  differentially private deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy allows bounding the influence that training data records\nhave on a machine learning model. To use differential privacy in machine\nlearning, data scientists must choose privacy parameters $(\\epsilon,\\delta)$.\nChoosing meaningful privacy parameters is key, since models trained with weak\nprivacy parameters might result in excessive privacy leakage, while strong\nprivacy parameters might overly degrade model utility. However, privacy\nparameter values are difficult to choose for two main reasons. First, the\ntheoretical upper bound on privacy loss $(\\epsilon,\\delta)$ might be loose,\ndepending on the chosen sensitivity and data distribution of practical\ndatasets. Second, legal requirements and societal norms for anonymization often\nrefer to individual identifiability, to which $(\\epsilon,\\delta)$ are only\nindirectly related.\n  We transform $(\\epsilon,\\delta)$ to a bound on the Bayesian posterior belief\nof the adversary assumed by differential privacy concerning the presence of any\nrecord in the training dataset. The bound holds for multidimensional queries\nunder composition, and we show that it can be tight in practice. Furthermore,\nwe derive an identifiability bound, which relates the adversary assumed in\ndifferential privacy to previous work on membership inference adversaries. We\nformulate an implementation of this differential privacy adversary that allows\ndata scientists to audit model training and compute empirical identifiability\nscores and empirical $(\\epsilon,\\delta)$.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 09:35:58 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 21:22:28 GMT"}, {"version": "v3", "created": "Tue, 20 Jul 2021 13:30:21 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Bernau", "Daniel", ""], ["Eibl", "G\u00fcnther", ""], ["Grassal", "Philip W.", ""], ["Keller", "Hannah", ""], ["Kerschbaum", "Florian", ""]]}, {"id": "2103.03046", "submitter": "Hongbin Liu", "authors": "Hongbin Liu, Jinyuan Jia, Neil Zhenqiang Gong", "title": "PointGuard: Provably Robust 3D Point Cloud Classification", "comments": "Published in IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D point cloud classification has many safety-critical applications such as\nautonomous driving and robotic grasping. However, several studies showed that\nit is vulnerable to adversarial attacks. In particular, an attacker can make a\nclassifier predict an incorrect label for a 3D point cloud via carefully\nmodifying, adding, and/or deleting a small number of its points. Randomized\nsmoothing is state-of-the-art technique to build certifiably robust 2D image\nclassifiers. However, when applied to 3D point cloud classification, randomized\nsmoothing can only certify robustness against adversarially modified points.\n  In this work, we propose PointGuard, the first defense that has provable\nrobustness guarantees against adversarially modified, added, and/or deleted\npoints. Specifically, given a 3D point cloud and an arbitrary point cloud\nclassifier, our PointGuard first creates multiple subsampled point clouds, each\nof which contains a random subset of the points in the original point cloud;\nthen our PointGuard predicts the label of the original point cloud as the\nmajority vote among the labels of the subsampled point clouds predicted by the\npoint cloud classifier. Our first major theoretical contribution is that we\nshow PointGuard provably predicts the same label for a 3D point cloud when the\nnumber of adversarially modified, added, and/or deleted points is bounded. Our\nsecond major theoretical contribution is that we prove the tightness of our\nderived bound when no assumptions on the point cloud classifier are made.\nMoreover, we design an efficient algorithm to compute our certified robustness\nguarantees. We also empirically evaluate PointGuard on ModelNet40 and ScanNet\nbenchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 14:09:37 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 09:02:55 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Liu", "Hongbin", ""], ["Jia", "Jinyuan", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "2103.03076", "submitter": "Yanghao Zhang", "authors": "Fu Wang, Yanghao Zhang, Yanbin Zheng, Wenjie Ruan", "title": "Gradient-Guided Dynamic Efficient Adversarial Training", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is arguably an effective but time-consuming way to train\nrobust deep neural networks that can withstand strong adversarial attacks. As a\nresponse to the inefficiency, we propose the Dynamic Efficient Adversarial\nTraining (DEAT), which gradually increases the adversarial iteration during\ntraining. Moreover, we theoretically reveal that the connection of the lower\nbound of Lipschitz constant of a given network and the magnitude of its partial\nderivative towards adversarial examples. Supported by this theoretical finding,\nwe utilize the gradient's magnitude to quantify the effectiveness of\nadversarial training and determine the timing to adjust the training procedure.\nThis magnitude based strategy is computational friendly and easy to implement.\nIt is especially suited for DEAT and can also be transplanted into a wide range\nof adversarial training methods. Our post-investigation suggests that\nmaintaining the quality of the training adversarial examples at a certain level\nis essential to achieve efficient adversarial training, which may shed some\nlight on future studies.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 14:57:53 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Wang", "Fu", ""], ["Zhang", "Yanghao", ""], ["Zheng", "Yanbin", ""], ["Ruan", "Wenjie", ""]]}, {"id": "2103.03078", "submitter": "Philippe Burlina", "authors": "William Paul, Yinzhi Cao, Miaomiao Zhang, and Phil Burlina", "title": "Defending Medical Image Diagnostics against Privacy Attacks using\n  Generative Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.CY cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) models used in medical imaging diagnostics can be\nvulnerable to a variety of privacy attacks, including membership inference\nattacks, that lead to violations of regulations governing the use of medical\ndata and threaten to compromise their effective deployment in the clinic. In\ncontrast to most recent work in privacy-aware ML that has been focused on model\nalteration and post-processing steps, we propose here a novel and complementary\nscheme that enhances the security of medical data by controlling the data\nsharing process. We develop and evaluate a privacy defense protocol based on\nusing a generative adversarial network (GAN) that allows a medical data sourcer\n(e.g. a hospital) to provide an external agent (a modeler) a proxy dataset\nsynthesized from the original images, so that the resulting diagnostic systems\nmade available to model consumers is rendered resilient to privacy attackers.\nWe validate the proposed method on retinal diagnostics AI used for diabetic\nretinopathy that bears the risk of possibly leaking private information. To\nincorporate concerns of both privacy advocates and modelers, we introduce a\nmetric to evaluate privacy and utility performance in combination, and\ndemonstrate, using these novel and classical metrics, that our approach, by\nitself or in conjunction with other defenses, provides state of the art (SOTA)\nperformance for defending against privacy attacks.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 15:02:57 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Paul", "William", ""], ["Cao", "Yinzhi", ""], ["Zhang", "Miaomiao", ""], ["Burlina", "Phil", ""]]}, {"id": "2103.03080", "submitter": "Md. Monowar Anjum", "authors": "Md. Monowar Anjum, Shahrear Iqbal, Benoit Hamelin", "title": "Analyzing the Usefulness of the DARPA OpTC Dataset in Cyber Threat\n  Detection Research", "comments": "Accepted in ACM SACMAT 2021", "journal-ref": null, "doi": "10.1145/3450569.3463573", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Maintaining security and privacy in real-world enterprise networks is\nbecoming more and more challenging. Cyber actors are increasingly employing\npreviously unreported and state-of-the-art techniques to break into corporate\nnetworks. To develop novel and effective methods to thwart these sophisticated\ncyberattacks, we need datasets that reflect real-world enterprise scenarios to\na high degree of accuracy. However, precious few such datasets are publicly\navailable. Researchers still predominantly use the decade-old KDD datasets,\nhowever, studies showed that these datasets do not adequately reflect modern\nattacks like Advanced Persistent Threats(APT). In this work, we analyze the\nusefulness of the recently introduced DARPA Operationally Transparent Cyber\n(OpTC) dataset in this regard. We describe the content of the dataset in detail\nand present a qualitative analysis. We show that the OpTC dataset is an\nexcellent candidate for advanced cyber threat detection research while also\nhighlighting its limitations. Additionally, we propose several research\ndirections where this dataset can be useful.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 15:03:45 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 00:15:31 GMT"}, {"version": "v3", "created": "Sat, 8 May 2021 19:31:45 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Anjum", "Md. Monowar", ""], ["Iqbal", "Shahrear", ""], ["Hamelin", "Benoit", ""]]}, {"id": "2103.03085", "submitter": "Jelle Don", "authors": "Jelle Don, Serge Fehr, Christian Majenz and Christian Schaffner", "title": "Online-Extractability in the Quantum Random-Oracle Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show the following generic result. Whenever a quantum query algorithm in\nthe quantum random-oracle model outputs a classical value $t$ that is promised\nto be in some tight relation with $H(x)$ for some $x$, then $x$ can be\nefficiently extracted with almost certainty. The extraction is by means of a\nsuitable simulation of the random oracle and works online, meaning that it is\nstraightline, i.e., without rewinding, and on-the-fly, i.e., during the\nprotocol execution and without disturbing it.\n  The technical core of our result is a new commutator bound that bounds the\noperator norm of the commutator of the unitary operator that describes the\nevolution of the compressed oracle (which is used to simulate the random oracle\nabove) and of the measurement that extracts $x$.\n  We show two applications of our generic online extractability result. We show\ntight online extractability of commit-and-open $\\Sigma$-protocols in the\nquantum setting, and we offer the first non-asymptotic post-quantum security\nproof of the textbook Fujisaki-Okamoto transformation, i.e, without adjustments\nto facilitate the proof.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 15:09:08 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Don", "Jelle", ""], ["Fehr", "Serge", ""], ["Majenz", "Christian", ""], ["Schaffner", "Christian", ""]]}, {"id": "2103.03181", "submitter": "Zhuolun Xiang", "authors": "Rati Gelashvili, Lefteris Kokoris-Kogias, Alexander Spiegelman,\n  Zhuolun Xiang", "title": "Be Prepared When Network Goes Bad: An Asynchronous View-Change Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of permissioned blockchain systems demands BFT SMR protocols\nthat are efficient under good network conditions (synchrony) and robust under\nbad network conditions (asynchrony). The state-of-the-art partially synchronous\nBFT SMR protocols provide optimal linear communication cost per decision under\nsynchrony and good leaders, but lose liveness under asynchrony. On the other\nhand, the state-of-the-art asynchronous BFT SMR protocols are live even under\nasynchrony, but always pay quadratic cost even under synchrony. In this paper,\nwe propose a BFT SMR protocol that achieves the best of both worlds -- optimal\nlinear cost per decision under good networks and leaders, optimal quadratic\ncost per decision under bad networks, and remains always live.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 17:40:33 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Gelashvili", "Rati", ""], ["Kokoris-Kogias", "Lefteris", ""], ["Spiegelman", "Alexander", ""], ["Xiang", "Zhuolun", ""]]}, {"id": "2103.03209", "submitter": "Kenji Saito", "authors": "Kenji Saito, Akimitsu Shiseki, Mitsuyasu Takada, Hiroki Yamamoto,\n  Masaaki Saitoh, Hiroaki Ohkawa, Hirofumi Andou, Naotake Miyamoto, Kazuaki\n  Yamakawa, Kiyoshi Kurakawa, Tomohiro Yabushita, Yuji Yamada, Go Masuda,\n  Kazuyuki Masuda", "title": "Requirement Analyses and Evaluations of Blockchain Platforms per\n  Possible Use Cases", "comments": "50 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is said that blockchain will contribute to the digital transformation of\nsociety in a wide range of ways, from the management of public and private\ndocuments to the traceability in various industries, as well as digital\ncurrencies. A number of so-called blockchain platforms have been developed, and\nexperiments and applications have been carried out on them. But are these\nplatforms really conducive to practical use of the blockchain concept?\n  To answer the question, we need to better understand what the technology\ncalled blockchain really is. We need to sort out the confusion we see in\nunderstanding what blockchain was invented for and what it means. We also need\nto clarify the structure of its applications.\n  This document provides a generic model of understanding blockchain and its\napplications. We introduce design patterns to classify the platforms. We\ncategorize possible use cases by identifying the structure among applications,\nand organize the functional, performance, operational and legal requirements\nfor each such case.\n  Based on the categorization and criteria, we evaluated and compared the\nfollowing platforms: Hyperledger Fabric, Hyperledger Iroha, Hyperledger Indy,\nEthereum, Quorum/Hyperledger Besu, Ethereum 2.0, Polkadot, Corda and BBc-1. We\nhave tried to be fair in our evaluations and comparisons, but we also expect to\nprovoke discussion.\n  The intended readers for this document is anyone involved in development of\napplication systems who wants to understand blockchain and their platforms,\nincluding non-engineers and non-technologists. The assessments in this document\nwill allow readers to understand the technological requirements for the\nblockchain platforms, to question existing technologies, and to choose the\nappropriate platforms for the applications they envision. The comparisons\nhopefully will also be useful as a guide for designing new technologies.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 18:27:57 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Saito", "Kenji", ""], ["Shiseki", "Akimitsu", ""], ["Takada", "Mitsuyasu", ""], ["Yamamoto", "Hiroki", ""], ["Saitoh", "Masaaki", ""], ["Ohkawa", "Hiroaki", ""], ["Andou", "Hirofumi", ""], ["Miyamoto", "Naotake", ""], ["Yamakawa", "Kazuaki", ""], ["Kurakawa", "Kiyoshi", ""], ["Yabushita", "Tomohiro", ""], ["Yamada", "Yuji", ""], ["Masuda", "Go", ""], ["Masuda", "Kazuyuki", ""]]}, {"id": "2103.03227", "submitter": "E K", "authors": "E.Kurshan, H. Shen", "title": "Graph Computing for Financial Crime and Fraud Detection: Trends,\n  Challenges and Outlook", "comments": "arXiv admin note: substantial text overlap with arXiv:2103.01854", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of digital payments has caused consequential changes in the\nfinancial crime landscape. As a result, traditional fraud detection approaches\nsuch as rule-based systems have largely become ineffective. AI and machine\nlearning solutions using graph computing principles have gained significant\ninterest in recent years. Graph-based techniques provide unique solution\nopportunities for financial crime detection. However, implementing such\nsolutions at industrial-scale in real-time financial transaction processing\nsystems has brought numerous application challenges to light. In this paper, we\ndiscuss the implementation difficulties current and next-generation graph\nsolutions face. Furthermore, financial crime and digital payments trends\nindicate emerging challenges in the continued effectiveness of the detection\ntechniques. We analyze the threat landscape and argue that it provides key\ninsights for developing graph-based solutions.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 21:14:44 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Kurshan", "E.", ""], ["Shen", "H.", ""]]}, {"id": "2103.03287", "submitter": "Hampei Sasahara", "authors": "Hampei Sasahara and Henrik Sandberg", "title": "Epistemic Signaling Games for Cyber Deception with Asymmetric\n  Recognition", "comments": null, "journal-ref": null, "doi": "10.1109/LCSYS.2021.3087097", "report-no": null, "categories": "cs.CR cs.GT cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This study provides a model of cyber deception with asymmetric recognition\nrepresented by private beliefs. Signaling games, which are often used in\nexisting works, are built on the implicit premise that the receiver's belief is\npublic information. However, this assumption, which leads to symmetric\nrecognition, is unrealistic in adversarial decision making. For a precise\nevaluation of risks arising from cognitive gaps, this paper proposes epistemic\nsignaling games based on the Mertens-Zamir model, which explicitly quantifies\nplayers' asymmetric recognition. Equilibria of the games are analytically\ncharacterized with an interpretation.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 19:45:29 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 13:02:54 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Sasahara", "Hampei", ""], ["Sandberg", "Henrik", ""]]}, {"id": "2103.03344", "submitter": "Paarth Neekhara", "authors": "Shehzeen Hussain, Paarth Neekhara, Shlomo Dubnov, Julian McAuley,\n  Farinaz Koushanfar", "title": "WaveGuard: Understanding and Mitigating Audio Adversarial Examples", "comments": "Published as a conference paper at Usenix Security 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a recent surge in adversarial attacks on deep learning based\nautomatic speech recognition (ASR) systems. These attacks pose new challenges\nto deep learning security and have raised significant concerns in deploying ASR\nsystems in safety-critical applications. In this work, we introduce WaveGuard:\na framework for detecting adversarial inputs that are crafted to attack ASR\nsystems. Our framework incorporates audio transformation functions and analyses\nthe ASR transcriptions of the original and transformed audio to detect\nadversarial inputs. We demonstrate that our defense framework is able to\nreliably detect adversarial examples constructed by four recent audio\nadversarial attacks, with a variety of audio transformation functions. With\ncareful regard for best practices in defense evaluations, we analyze our\nproposed defense and its strength to withstand adaptive and robust attacks in\nthe audio domain. We empirically demonstrate that audio transformations that\nrecover audio from perceptually informed representations can lead to a strong\ndefense that is robust against an adaptive adversary even in a complete\nwhite-box setting. Furthermore, WaveGuard can be used out-of-the box and\nintegrated directly with any ASR model to efficiently detect audio adversarial\nexamples, without the need for model retraining.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 21:44:37 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Hussain", "Shehzeen", ""], ["Neekhara", "Paarth", ""], ["Dubnov", "Shlomo", ""], ["McAuley", "Julian", ""], ["Koushanfar", "Farinaz", ""]]}, {"id": "2103.03411", "submitter": "Kanthi Sarpatwar", "authors": "Kanthi Sarpatwar and Karthik Nandakumar and Nalini Ratha and James\n  Rayfield and Karthikeyan Shanmugam and Sharath Pankanti and Roman Vaculin", "title": "Efficient Encrypted Inference on Ensembles of Decision Trees", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data privacy concerns often prevent the use of cloud-based machine learning\nservices for sensitive personal data. While homomorphic encryption (HE) offers\na potential solution by enabling computations on encrypted data, the challenge\nis to obtain accurate machine learning models that work within the\nmultiplicative depth constraints of a leveled HE scheme. Existing approaches\nfor encrypted inference either make ad-hoc simplifications to a pre-trained\nmodel (e.g., replace hard comparisons in a decision tree with soft comparators)\nat the cost of accuracy or directly train a new depth-constrained model using\nthe original training set. In this work, we propose a framework to transfer\nknowledge extracted by complex decision tree ensembles to shallow neural\nnetworks (referred to as DTNets) that are highly conducive to encrypted\ninference. Our approach minimizes the accuracy loss by searching for the best\nDTNet architecture that operates within the given depth constraints and\ntraining this DTNet using only synthetic data sampled from the training data\ndistribution. Extensive experiments on real-world datasets demonstrate that\nthese characteristics are critical in ensuring that DTNet accuracy approaches\nthat of the original tree ensemble. Our system is highly scalable and can\nperform efficient inference on batched encrypted (134 bits of security) data\nwith amortized time in milliseconds. This is approximately three orders of\nmagnitude faster than the standard approach of applying soft comparison at the\ninternal nodes of the ensemble trees.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 01:06:30 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Sarpatwar", "Kanthi", ""], ["Nandakumar", "Karthik", ""], ["Ratha", "Nalini", ""], ["Rayfield", "James", ""], ["Shanmugam", "Karthikeyan", ""], ["Pankanti", "Sharath", ""], ["Vaculin", "Roman", ""]]}, {"id": "2103.03443", "submitter": "Riccardo Paccagnella", "authors": "Riccardo Paccagnella and Licheng Luo and Christopher W. Fletcher", "title": "Lord of the Ring(s): Side Channel Attacks on the CPU On-Chip Ring\n  Interconnect Are Practical", "comments": "This is the extended version of a paper that appears in USENIX\n  Security 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the first microarchitectural side channel attacks that leverage\ncontention on the CPU ring interconnect. There are two challenges that make it\nuniquely difficult to exploit this channel. First, little is known about the\nring interconnect's functioning and architecture. Second, information that can\nbe learned by an attacker through ring contention is noisy by nature and has\ncoarse spatial granularity. To address the first challenge, we perform a\nthorough reverse engineering of the sophisticated protocols that handle\ncommunication on the ring interconnect. With this knowledge, we build a\ncross-core covert channel over the ring interconnect with a capacity of over 4\nMbps from a single thread, the largest to date for a cross-core channel not\nrelying on shared memory. To address the second challenge, we leverage the\nfine-grained temporal patterns of ring contention to infer a victim program's\nsecrets. We demonstrate our attack by extracting key bits from vulnerable EdDSA\nand RSA implementations, as well as inferring the precise timing of keystrokes\ntyped by a victim user.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 02:44:20 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Paccagnella", "Riccardo", ""], ["Luo", "Licheng", ""], ["Fletcher", "Christopher W.", ""]]}, {"id": "2103.03472", "submitter": "Nur Imtiazul Haque", "authors": "Nur Imtiazul Haque, Mohammad Ashiqur Rahman, Md Hasan Shahriar, Alvi\n  Ataur Khalil and Selcuk Uluagac", "title": "A Novel Framework for Threat Analysis of Machine Learning-based Smart\n  Healthcare Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Smart healthcare systems (SHSs) are providing fast and efficient disease\ntreatment leveraging wireless body sensor networks (WBSNs) and implantable\nmedical devices (IMDs)-based internet of medical things (IoMT). In addition,\nIoMT-based SHSs are enabling automated medication, allowing communication among\nmyriad healthcare sensor devices. However, adversaries can launch various\nattacks on the communication network and the hardware/firmware to introduce\nfalse data or cause data unavailability to the automatic medication system\nendangering the patient's life. In this paper, we propose SHChecker, a novel\nthreat analysis framework that integrates machine learning and formal analysis\ncapabilities to identify potential attacks and corresponding effects on an\nIoMT-based SHS. Our framework can provide us with all potential attack vectors,\neach representing a set of sensor measurements to be altered, for an SHS given\na specific set of attack attributes, allowing us to realize the system's\nresiliency, thus the insight to enhance the robustness of the model. We\nimplement SHChecker on a synthetic and a real dataset, which affirms that our\nframework can reveal potential attack vectors in an IoMT system. This is a\nnovel effort to formally analyze supervised and unsupervised machine learning\nmodels for black-box SHS threat analysis.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 04:51:02 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Haque", "Nur Imtiazul", ""], ["Rahman", "Mohammad Ashiqur", ""], ["Shahriar", "Md Hasan", ""], ["Khalil", "Alvi Ataur", ""], ["Uluagac", "Selcuk", ""]]}, {"id": "2103.03500", "submitter": "Mark Zhao", "authors": "Mark Zhao, Mingyu Gao, and Christos Kozyrakis", "title": "ShEF: Shielded Enclaves for Cloud FPGAs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  FPGAs are now used in public clouds to accelerate a wide range of\napplications, including many that operate on sensitive data such as financial\nand medical records. We present ShEF, a trusted execution environment (TEE) for\ncloud-based reconfigurable accelerators. ShEF is independent from CPU-based\nTEEs and allows secure execution under a threat model where the adversary can\ncontrol all software running on the CPU connected to the FPGA, has physical\naccess to the FPGA, and can compromise the FPGA interface logic of the cloud\nprovider. ShEF provides a secure boot and remote attestation process that\nrelies solely on existing FPGA mechanisms for root of trust. It also includes a\nShield component that provides secure access to data while the accelerator is\nin use. The Shield is highly customizable and extensible, allowing users to\ncraft a bespoke security solution that fits their accelerator's memory access\npatterns, bandwidth, and security requirements at minimum performance and area\noverheads. We describe a prototype implementation of ShEF for existing cloud\nFPGAs and measure the performance benefits of customizable security using five\naccelerator designs.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 07:02:26 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Zhao", "Mark", ""], ["Gao", "Mingyu", ""], ["Kozyrakis", "Christos", ""]]}, {"id": "2103.03502", "submitter": "Jianming Huang", "authors": "Jianming Huang and Yu Hua", "title": "Update the Root of Integrity Tree in Secure Non-Volatile Memory Systems\n  with Low Overhead", "comments": "13 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data integrity is important for non-volatile memory (NVM) systems that\nmaintain data even without power. The data integrity in NVM is possibly\ncompromised by integrity attacks, which can be defended against by integrity\nverification via integrity trees. After NVM system failures and reboots, the\nintegrity tree root is responsible for providing a trusted execution\nenvironment. However, the root often becomes a performance bottleneck, since\nupdating the root requires high latency on the write critical path to propagate\nthe modifications from leaf nodes to the root. The root and leaf nodes have to\nensure the crash consistency between each other to avoid any update failures\nthat potentially result in misreporting the attacks after system reboots. In\nthis paper, we propose an efficient and low-latency scheme, called SCUE, to\ndirectly update the root on the SGX integrity tree (SIT) by overlooking the\nupdates upon the intermediate tree nodes. The idea behind SCUE explores and\nexploits the observation that only the persistent leaf nodes and root are\nuseful to ensure the integrity after system failures and reboots, due to the\nloss of the cached intermediate tree nodes. To achieve the crash consistency\nbetween root and leaf nodes, we accurately predict the updates upon the root\nand pre-update the root before the leaf nodes are modified. Moreover, the SIT\nroot is difficult to be reconstructed from the leaf nodes since updating one\ntree node needs its parent node as input. We use a counter-summing approach to\nreconstructing the SIT from leaf nodes. Our evaluation results show that\ncompared with the state-of-the-art integrity tree update schemes, our SCUE\nscheme delivers high performance while ensuring the system integrity.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 07:17:29 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Huang", "Jianming", ""], ["Hua", "Yu", ""]]}, {"id": "2103.03511", "submitter": "Wenna Song", "authors": "Wenna Song, Jiang Ming, Lin Jiang, Han Yan, Yi Xiang, Yuan Chen,\n  Jianming Fu and Guojun Peng", "title": "App's Auto-Login Function Security Testing via Android OS-Level\n  Virtualization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Limited by the small keyboard, most mobile apps support the automatic login\nfeature for better user experience. Therefore, users avoid the inconvenience of\nretyping their ID and password when an app runs in the foreground again.\nHowever, this auto-login function can be exploited to launch the so-called\n\"data-clone attack\": once the locally-stored, auto-login depended data are\ncloned by attackers and placed into their own smartphones, attackers can break\nthrough the login-device number limit and log in to the victim's account\nstealthily. A natural countermeasure is to check the consistency of\ndevicespecific attributes. As long as the new device shows different device\nfingerprints with the previous one, the app will disable the auto-login\nfunction and thus prevent data-clone attacks. In this paper, we develop\nVPDroid, a transparent Android OS-level virtualization platform tailored for\nsecurity testing. With VPDroid, security analysts can customize different\ndevice artifacts, such as CPU model, Android ID, and phone number, in a virtual\nphone without user-level API hooking. VPDroid's isolation mechanism ensures\nthat user-mode apps in the virtual phone cannot detect device-specific\ndiscrepancies. To assess Android apps' susceptibility to the data-clone attack,\nwe use VPDroid to simulate data-clone attacks with 234 most-downloaded apps.\nOur experiments on five different virtual phone environments show that\nVPDroid's device attribute customization can deceive all tested apps that\nperform device-consistency checks, such as Twitter, WeChat, and PayPal. 19\nvendors have confirmed our report as a zero-day vulnerability. Our findings\npaint a cautionary tale: only enforcing a device-consistency check at client\nside is still vulnerable to an advanced data-clone attack.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 07:46:54 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 10:00:09 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Song", "Wenna", ""], ["Ming", "Jiang", ""], ["Jiang", "Lin", ""], ["Yan", "Han", ""], ["Xiang", "Yi", ""], ["Chen", "Yuan", ""], ["Fu", "Jianming", ""], ["Peng", "Guojun", ""]]}, {"id": "2103.03530", "submitter": "Vasileios Mavroeidis Dr.", "authors": "Vasileios Mavroeidis, Siri Bromander", "title": "Cyber Threat Intelligence Model: An Evaluation of Taxonomies, Sharing\n  Standards, and Ontologies within Cyber Threat Intelligence", "comments": null, "journal-ref": null, "doi": "10.1109/EISIC.2017.20", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber threat intelligence is the provision of evidence-based knowledge about\nexisting or emerging threats. Benefits of threat intelligence include increased\nsituational awareness and efficiency in security operations and improved\nprevention, detection, and response capabilities. To process, analyze, and\ncorrelate vast amounts of threat information and derive highly contextual\nintelligence that can be shared and consumed in meaningful times requires\nutilizing machine-understandable knowledge representation formats that embed\nthe industry-required expressivity and are unambiguous. To a large extend, this\nis achieved by technologies like ontologies, interoperability schemas, and\ntaxonomies. This research evaluates existing cyber-threat-intelligence-relevant\nontologies, sharing standards, and taxonomies for the purpose of measuring\ntheir high-level conceptual expressivity with regards to the who, what, why,\nwhere, when, and how elements of an adversarial attack in addition to courses\nof action and technical indicators. The results confirmed that little emphasis\nhas been given to developing a comprehensive cyber threat intelligence ontology\nwith existing efforts not being thoroughly designed, non-interoperable and\nambiguous, and lacking semantic reasoning capability.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 08:15:50 GMT"}, {"version": "v2", "created": "Sun, 21 Mar 2021 09:35:50 GMT"}, {"version": "v3", "created": "Tue, 23 Mar 2021 07:32:36 GMT"}, {"version": "v4", "created": "Fri, 26 Mar 2021 14:43:01 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Mavroeidis", "Vasileios", ""], ["Bromander", "Siri", ""]]}, {"id": "2103.03558", "submitter": "Magali Bardet", "authors": "Magali Bardet (CA - LITIS, COSMIQ), Pierre Briaud (COSMIQ, SU)", "title": "An algebraic approach to the Rank Support Learning problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rank-metric code-based cryptography relies on the hardness of decoding a\nrandom linear code in the rank metric. The Rank Support Learning problem (RSL)\nis a variant where an attacker has access to N decoding instances whose errors\nhave the same support and wants to solve one of them. This problem is for\ninstance used in the Durandal signature scheme. In this paper, we propose an\nalgebraic attack on RSL which clearly outperforms the previous attacks to solve\nthis problem. We build upon Bardet et al., Asiacrypt 2020, where similar\ntechniques are used to solve MinRank and RD. However, our analysis is simpler\nand overall our attack relies on very elementary assumptions compared to\nstandard Gr{\\\"o}bner bases attacks. In particular, our results show that key\nrecovery attacks on Durandal are more efficient than was previously thought.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 09:35:48 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Bardet", "Magali", "", "CA - LITIS, COSMIQ"], ["Briaud", "Pierre", "", "COSMIQ, SU"]]}, {"id": "2103.03569", "submitter": "Pauline Puteaux", "authors": "Pauline Puteaux (UM, LIRMM), Vincent Itier (IMT Lille Douai, CRIStAL),\n  Patrick Bas (CNRS, CRIStAL)", "title": "Combining Forensics and Privacy Requirements for Digital Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes to study the impact of image selective encryption on both\nforensics and privacy preserving mechanisms. The proposed selective encryption\nscheme works independently on each bitplane by encrypting the s most\nsignificant bits of each pixel. We show that this mechanism can be used to\nincrease privacy by mitigating image recognition tasks. In order to guarantee a\ntrade-off between forensics analysis and privacy, the signal of interest used\nfor forensics purposes is extracted from the 8--s least significant bits of the\nprotected image. We show on the CASIA2 database that good tampering detection\ncapabilities can be achieved for s $\\in$ {3,. .. , 5} with an accuracy above\n80% using SRMQ1 features, while preventing class recognition tasks using CNN\nwith an accuracy smaller than 50%.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 09:54:00 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Puteaux", "Pauline", "", "UM, LIRMM"], ["Itier", "Vincent", "", "IMT Lille Douai, CRIStAL"], ["Bas", "Patrick", "", "CNRS, CRIStAL"]]}, {"id": "2103.03699", "submitter": "Yongge Wang", "authors": "Yongge Wang", "title": "Implementing Automated Market Makers with Constant Circle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describe the implementation details of constant ellipse based\nautomated market makers (CoinSwap). A CoinSwap prototype has been implemented\nat http://coinswapapp.io/ and the source codes are available at\nhttps://github.com/coinswapapp/\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 14:19:33 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Wang", "Yongge", ""]]}, {"id": "2103.03739", "submitter": "Karl Koch", "authors": "Karl Koch, Stephan Krenn, Donato Pellegrino, Sebastian Ramacher", "title": "Privacy-preserving Analytics for Data Markets using MPC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data markets have the potential to foster new data-driven applications and\nhelp growing data-driven businesses. When building and deploying such markets\nin practice, regulations such as the European Union's General Data Protection\nRegulation (GDPR) impose constraints and restrictions on these markets\nespecially when dealing with personal or privacy-sensitive data. In this paper,\nwe present a candidate architecture for a privacy-preserving personal data\nmarket, relying on cryptographic primitives such as multi-party computation\n(MPC) capable of performing privacy-preserving computations on the data.\nBesides specifying the architecture of such a data market, we also present a\nprivacy-risk analysis of the market following the LINDDUN methodology.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 15:11:44 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Koch", "Karl", ""], ["Krenn", "Stephan", ""], ["Pellegrino", "Donato", ""], ["Ramacher", "Sebastian", ""]]}, {"id": "2103.03806", "submitter": "Moulay Akhloufi", "authors": "Abir Rahali and Moulay A. Akhloufi", "title": "MalBERT: Using Transformers for Cybersecurity and Malicious Software\n  Detection", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years we have witnessed an increase in cyber threats and malicious\nsoftware attacks on different platforms with important consequences to persons\nand businesses. It has become critical to find automated machine learning\ntechniques to proactively defend against malware. Transformers, a category of\nattention-based deep learning techniques, have recently shown impressive\nresults in solving different tasks mainly related to the field of Natural\nLanguage Processing (NLP). In this paper, we propose the use of a Transformers'\narchitecture to automatically detect malicious software. We propose a model\nbased on BERT (Bidirectional Encoder Representations from Transformers) which\nperforms a static analysis on the source code of Android applications using\npreprocessed features to characterize existing malware and classify it into\ndifferent representative malware categories. The obtained results are promising\nand show the high performance obtained by Transformer-based models for\nmalicious software detection.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 17:09:46 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Rahali", "Abir", ""], ["Akhloufi", "Moulay A.", ""]]}, {"id": "2103.03831", "submitter": "George Kadianakis", "authors": "George Kadianakis, Theodoros Polyzos, Mike Perry, Kostas\n  Chatzikokolakis", "title": "PCP: Preemptive Circuit Padding against Tor circuit fingerprinting", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Online anonymity and privacy has been based on confusing the adversary by\ncreating indistinguishable network elements. Tor is the largest and most-used\ndeployed anonymity system, designed against realistic modern adversaries.\nRecently, researchers have managed to fingerprint Tor's circuits - and hence\nthe type of underlying traffic - simply by capturing and analyzing traffic\ntraces. In this work, we study the circuit fingerprinting problem, isolating it\nfrom website fingerprinting, and revisit previous findings in this model,\nshowing that accurate attacks are possible even when the application-layer\ntraffic is identical. We then proceed to incrementally create defenses against\ncircuit fingerprinting, using a generic adaptive padding framework for Tor\nbased on WTF-PAD. We present a simple but high-latency defense, as well as a\nmore advanced low-latency one which can effectively hide onion service circuits\nwith no additional delays. We thoroughly evaluate both defenses, both\nanalytically and experimentally, discovering new subtle fingerprints, but also\nshowing the effectiveness of our defenses.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 17:47:47 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Kadianakis", "George", ""], ["Polyzos", "Theodoros", ""], ["Perry", "Mike", ""], ["Chatzikokolakis", "Kostas", ""]]}, {"id": "2103.03851", "submitter": "Ege Tekiner", "authors": "Ege Tekiner, Abbas Acar, A. Selcuk Uluagac, Engin Kirda and Ali Aydin\n  Selcuk", "title": "SoK: Cryptojacking Malware", "comments": "EuroS&P 2021 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging blockchain and cryptocurrency-based technologies are redefining the\nway we conduct business in cyberspace. Today, a myriad of blockchain and\ncryptocurrency systems, applications, and technologies are widely available to\ncompanies, end-users, and even malicious actors who want to exploit the\ncomputational resources of regular users through \\textit{cryptojacking}\nmalware. Especially with ready-to-use mining scripts easily provided by service\nproviders (e.g., Coinhive) and untraceable cryptocurrencies (e.g., Monero),\ncryptojacking malware has become an indispensable tool for attackers. Indeed,\nthe banking industry, major commercial websites, government and military\nservers (e.g., US Dept. of Defense), online video sharing platforms (e.g.,\nYoutube), gaming platforms (e.g., Nintendo), critical infrastructure resources\n(e.g., routers), and even recently widely popular remote video\nconferencing/meeting programs (e.g., Zoom during the Covid-19 pandemic) have\nall been the victims of powerful cryptojacking malware campaigns. Nonetheless,\nexisting detection methods such as browser extensions that protect users with\nblacklist methods or antivirus programs with different analysis methods can\nonly provide a partial panacea to this emerging cryptojacking issue as the\nattackers can easily bypass them by using obfuscation techniques or changing\ntheir domains or scripts frequently. Therefore, many studies in the literature\nproposed cryptojacking malware detection methods using various\ndynamic/behavioral features.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 18:07:21 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 20:03:57 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Tekiner", "Ege", ""], ["Acar", "Abbas", ""], ["Uluagac", "A. Selcuk", ""], ["Kirda", "Engin", ""], ["Selcuk", "Ali Aydin", ""]]}, {"id": "2103.03918", "submitter": "Runhua Xu", "authors": "Runhua Xu, Nathalie Baracaldo, Yi Zhou, Ali Anwar, James Joshi, Heiko\n  Ludwig", "title": "FedV: Privacy-Preserving Federated Learning over Vertically Partitioned\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Federated learning (FL) has been proposed to allow collaborative training of\nmachine learning (ML) models among multiple parties where each party can keep\nits data private. In this paradigm, only model updates, such as model weights\nor gradients, are shared. Many existing approaches have focused on horizontal\nFL, where each party has the entire feature set and labels in the training data\nset. However, many real scenarios follow a vertically-partitioned FL setup,\nwhere a complete feature set is formed only when all the datasets from the\nparties are combined, and the labels are only available to a single party.\nPrivacy-preserving vertical FL is challenging because complete sets of labels\nand features are not owned by one entity. Existing approaches for vertical FL\nrequire multiple peer-to-peer communications among parties, leading to lengthy\ntraining times, and are restricted to (approximated) linear models and just two\nparties. To close this gap, we propose FedV, a framework for secure gradient\ncomputation in vertical settings for several widely used ML models such as\nlinear models, logistic regression, and support vector machines. FedV removes\nthe need for peer-to-peer communication among parties by using functional\nencryption schemes; this allows FedV to achieve faster training times. It also\nworks for larger and changing sets of parties. We empirically demonstrate the\napplicability for multiple types of ML models and show a reduction of 10%-70%\nof training time and 80% to 90% in data transfer with respect to the\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 19:59:29 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 20:31:33 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Xu", "Runhua", ""], ["Baracaldo", "Nathalie", ""], ["Zhou", "Yi", ""], ["Anwar", "Ali", ""], ["Joshi", "James", ""], ["Ludwig", "Heiko", ""]]}, {"id": "2103.03939", "submitter": "Julian Busch", "authors": "Julian Busch, Anton Kocheturov, Volker Tresp, Thomas Seidl", "title": "NF-GNN: Network Flow Graph Neural Networks for Malware Detection and\n  Classification", "comments": null, "journal-ref": "33rd International Conference on Scientific and Statistical\n  Database Management (SSDBM 2021)", "doi": "10.1145/3468791.3468814", "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malicious software (malware) poses an increasing threat to the security of\ncommunication systems as the number of interconnected mobile devices increases\nexponentially. While some existing malware detection and classification\napproaches successfully leverage network traffic data, they treat network flows\nbetween pairs of endpoints independently and thus fail to leverage rich\ncommunication patterns present in the complete network. Our approach first\nextracts flow graphs and subsequently classifies them using a novel edge\nfeature-based graph neural network model. We present three variants of our base\nmodel, which support malware detection and classification in supervised and\nunsupervised settings. We evaluate our approach on flow graphs that we extract\nfrom a recently published dataset for mobile malware detection that addresses\nseveral issues with previously available datasets. Experiments on four\ndifferent prediction tasks consistently demonstrate the advantages of our\napproach and show that our graph neural network model can boost detection\nperformance by a significant margin.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 20:54:38 GMT"}, {"version": "v2", "created": "Sun, 4 Apr 2021 21:24:11 GMT"}, {"version": "v3", "created": "Fri, 4 Jun 2021 13:28:04 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Busch", "Julian", ""], ["Kocheturov", "Anton", ""], ["Tresp", "Volker", ""], ["Seidl", "Thomas", ""]]}, {"id": "2103.04016", "submitter": "Yuanyu Zhang", "authors": "Ruka Nakanishi, Yuanyu Zhang, Masahiro Sasabe and Shoji Kasahara", "title": "Combining IOTA and Attribute-Based Encryption for Access Control in the\n  Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unauthorized resource access represents a typical security threat in the\nInternet of things (IoT), while distributed ledger technologies (e.g.,\nblockchain and IOTA) hold great promise to address this threat. Although\nblockchain-based IoT access control schemes have been the most popular ones,\nthey suffer from several significant limitations, such as high monetary cost\nand low throughput of processing access requests. To overcome these\nlimitations, this paper proposes a novel IoT access control scheme by combining\nthe fee-less IOTA technology and the Ciphertext-Policy Attribute-Based\nEncryption (CP-ABE) technology. To control the access to a resource, a token,\nwhich records access permissions to this resource, is encrypted by the CP-ABE\ntechnology and uploaded to the IOTA Tangle (i.e., the underlying database of\nIOTA). Any user can fetch the encrypted token from the Tangle, while only those\nwho can decrypt this token are authorized to access the resource. In this way,\nthe proposed scheme enables not only distributed, fee-less and scalable access\ncontrol thanks to the IOTA but also fine-grained attribute-based access control\nthanks to the CP-ABE. We show the feasibility of our scheme by implementing a\nproof-of-concept prototype system and evaluate its performance in terms of\naccess request processing throughput.\n", "versions": [{"version": "v1", "created": "Sat, 6 Mar 2021 03:19:23 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Nakanishi", "Ruka", ""], ["Zhang", "Yuanyu", ""], ["Sasabe", "Masahiro", ""], ["Kasahara", "Shoji", ""]]}, {"id": "2103.04028", "submitter": "Panagiotis Chatzigiannis", "authors": "Panagiotis Chatzigiannis, Foteini Baldimtsi, Constantinos Kolias,\n  Angelos Stavrou", "title": "Black-Box IoT: Authentication and Distributed Storage of IoT Data from\n  Constrained Sensors", "comments": "To appear in IoTDI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Black-Box IoT (BBox-IoT), a new ultra-lightweight black-box system\nfor authenticating and storing IoT data. BBox-IoT is tailored for deployment on\nIoT devices (including low-Size Weight and Power sensors) which are extremely\nconstrained in terms of computation, storage, and power. By utilizing core\nBlockchain principles, we ensure that the collected data is immutable and\ntamper-proof while preserving data provenance and non-repudiation. To realize\nBBox-IoT, we designed and implemented a novel chain-based hash signature scheme\nwhich only requires hashing operations and removes all synchronicity\ndependencies between signer and verifier. Our approach enables low-SWaP devices\nto authenticate removing reliance on clock synchronization. Our evaluation\nresults show that BBox-IoT is practical in Industrial Internet of Things (IIoT)\nenvironments: even devices equipped with 16MHz micro-controllers and 2KB memory\ncan broadcast their collected data without requiring heavy cryptographic\noperations or synchronicity assumptions. Finally, when compared to industry\nstandard ECDSA, our approach is two and three orders of magnitude faster for\nsigning and verification operations respectively. Thus, we are able to increase\nthe total number of signing operations by more than 5000% for the same amount\nof power.\n", "versions": [{"version": "v1", "created": "Sat, 6 Mar 2021 04:51:25 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Chatzigiannis", "Panagiotis", ""], ["Baldimtsi", "Foteini", ""], ["Kolias", "Constantinos", ""], ["Stavrou", "Angelos", ""]]}, {"id": "2103.04038", "submitter": "Yiming Li", "authors": "Yiming Li, Yanjie Li, Yalei Lv, Yong Jiang, Shu-Tao Xia", "title": "Hidden Backdoor Attack against Semantic Segmentation Models", "comments": "This is a 6-pages short version of our ongoing work. It is accepted\n  by the non-archival ICLR workshop on Security and Safety in Machine Learning\n  Systems, 2021. The first two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are vulnerable to the \\emph{backdoor attack},\nwhich intends to embed hidden backdoors in DNNs by poisoning training data. The\nattacked model behaves normally on benign samples, whereas its prediction will\nbe changed to a particular target label if hidden backdoors are activated. So\nfar, backdoor research has mostly been conducted towards classification tasks.\nIn this paper, we reveal that this threat could also happen in semantic\nsegmentation, which may further endanger many mission-critical applications\n($e.g.$, autonomous driving). Except for extending the existing attack paradigm\nto maliciously manipulate the segmentation models from the image-level, we\npropose a novel attack paradigm, the \\emph{fine-grained attack}, where we treat\nthe target label ($i.e.$, annotation) from the object-level instead of the\nimage-level to achieve more sophisticated manipulation. In the annotation of\npoisoned samples generated by the fine-grained attack, only pixels of specific\nobjects will be labeled with the attacker-specified target class while others\nare still with their ground-truth ones. Experiments show that the proposed\nmethods can successfully attack semantic segmentation models by poisoning only\na small proportion of training data. Our method not only provides a new\nperspective for designing novel attacks but also serves as a strong baseline\nfor improving the robustness of semantic segmentation methods.\n", "versions": [{"version": "v1", "created": "Sat, 6 Mar 2021 05:50:29 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 10:47:02 GMT"}, {"version": "v3", "created": "Sat, 3 Apr 2021 05:07:33 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Li", "Yiming", ""], ["Li", "Yanjie", ""], ["Lv", "Yalei", ""], ["Jiang", "Yong", ""], ["Xia", "Shu-Tao", ""]]}, {"id": "2103.04142", "submitter": "Ilias Politis Dr", "authors": "John C. Polley, Ilias Politis (Member, IEEE), Christos Xenakis\n  (Member, IEEE), Adarbad Master, and Micha{\\l} K\\k{e}pkowski", "title": "On an innovative architecture for digital immunity passports and\n  vaccination certificates", "comments": "This work has been funded in part with Federal funds from the\n  National Institutes of Health, Department of Health and Human Services, under\n  Contract No. 75N91020C00035 and in part by the European Union's Horizon 2020\n  Stimulating innovation by means of cross-fertilisation of knowledge program\n  under Grant 824015 (H2020-MSCA-RISE-2018-INCOGNITO) and the Grant 826404\n  (H2020-SC1-FA-DTS-2018-1-CUREX)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the COVID-19 pandemic entering a second phase and vaccination strategies\nbeing applied by countries and governments worldwide, there is an increasing\nexpectation by people to return to normal life. There is currently a debate\nabout immunity passports, privacy, and the enablement of individuals to safely\nenter everyday social life, workplace, and travel. Such digital immunity\npassports and vaccination certificates should meet people's expectations for\nprivacy while enabling them to present to 3rd party verifiers tamper-evident\ncredentials. This paper provides a comprehensive answer to the technological,\nethical and security challenges, by proposing an architecture that provides to\nindividuals, employers, and government agencies, a digital, decentralized,\nportable, immutable, and non-refutable health status cryptographic proof. It\ncan be used to evaluate the risk of allowing individuals to return to work,\ntravel, and public life activities.\n", "versions": [{"version": "v1", "created": "Sat, 6 Mar 2021 15:35:24 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 15:28:17 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 15:57:17 GMT"}, {"version": "v4", "created": "Wed, 12 May 2021 09:15:11 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Polley", "John C.", "", "Member, IEEE"], ["Politis", "Ilias", "", "Member, IEEE"], ["Xenakis", "Christos", "", "Member, IEEE"], ["Master", "Adarbad", ""], ["K\u0119pkowski", "Micha\u0142", ""]]}, {"id": "2103.04203", "submitter": "Wassim Hamidouche", "authors": "Guillaume Gautier, Mousa FarajAllah, Wassim Hamidouche, Olivier\n  D\\'eforges and Safwan El Assad", "title": "Selective Encryption of the Versatile Video Coding Standard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MM eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Versatile video coding (VVC) is the next generation video coding standard\ndeveloped by the joint video experts team (JVET) and released in July 2020. VVC\nintroduces several new coding tools providing a significant coding gain over\nthe high efficiency video coding (HEVC) standard. It is well known that\nincreasing the coding efficiency adds more dependencies in the video bitstream\nmaking format-compliant encryption with the standard more challenging. In this\npaper we tackle the problem of selective encryption of the VVC standard in\nformat-compliant and constant bitrate. These two constraints ensure that the\nencrypted bitstream can be decoded by any VVC decoder while the bitrate remains\nunchanged by the encryption. The selective encryption of all possible VVC\nsyntax elements is investigated. A new algorithm is proposed to encrypt in\nformat-compliant and constant bitrate the transform coefficients (TCs) together\nwith other syntax elements at the level of the entropy encoder. The proposed\nsolution was integrated and assessed under the VVC reference software model\nversion 6.0. Experimental results showed that the encryption drastically\ndecreases the video quality while the encryption is robust against several\ntypes of attacks. The encryption space is estimated in the range of 15% to 26%\nof the bitstream size resulting in a lightweight encryption process. The web\npage of this work is available at https://gugautie.github.io/sevvc/.\n", "versions": [{"version": "v1", "created": "Sat, 6 Mar 2021 22:27:30 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Gautier", "Guillaume", ""], ["FarajAllah", "Mousa", ""], ["Hamidouche", "Wassim", ""], ["D\u00e9forges", "Olivier", ""], ["Assad", "Safwan El", ""]]}, {"id": "2103.04208", "submitter": "Hanan Hindy", "authors": "Hanan Hindy, Robert Atkinson, Christos Tachtatzis, Ethan Bayne,\n  Miroslav Bures, Xavier Bellekens", "title": "Utilising Flow Aggregation to Classify Benign Imitating Attacks", "comments": "21 pages, 6 figures", "journal-ref": "MDPI Sensors 2021, 21, 1761. Special Issue: Security and Privacy\n  in the Internet of Things (IoT)", "doi": "10.3390/s21051761", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-attacks continue to grow, both in terms of volume and sophistication.\nThis is aided by an increase in available computational power, expanding attack\nsurfaces, and advancements in the human understanding of how to make attacks\nundetectable. Unsurprisingly, machine learning is utilised to defend against\nthese attacks. In many applications, the choice of features is more important\nthan the choice of model. A range of studies have, with varying degrees of\nsuccess, attempted to discriminate between benign traffic and well-known\ncyber-attacks. The features used in these studies are broadly similar and have\ndemonstrated their effectiveness in situations where cyber-attacks do not\nimitate benign behaviour. To overcome this barrier, in this manuscript, we\nintroduce new features based on a higher level of abstraction of network\ntraffic. Specifically, we perform flow aggregation by grouping flows with\nsimilarities. This additional level of feature abstraction benefits from\ncumulative information, thus qualifying the models to classify cyber-attacks\nthat mimic benign traffic. The performance of the new features is evaluated\nusing the benchmark CICIDS2017 dataset, and the results demonstrate their\nvalidity and effectiveness. This novel proposal will improve the detection\naccuracy of cyber-attacks and also build towards a new direction of feature\nextraction for complex ones.\n", "versions": [{"version": "v1", "created": "Sat, 6 Mar 2021 23:09:12 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Hindy", "Hanan", ""], ["Atkinson", "Robert", ""], ["Tachtatzis", "Christos", ""], ["Bayne", "Ethan", ""], ["Bures", "Miroslav", ""], ["Bellekens", "Xavier", ""]]}, {"id": "2103.04226", "submitter": "Lotfi ben Othmane", "authors": "Ameerah-Muhsinah Jamil and Lotfi ben Othmane and Altaz Valani", "title": "Threat Modeling of Cyber-Physical Systems in Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional Cyber-physical Systems(CPSs) were not built with cybersecurity in\nmind. They operated on separate Operational Technology (OT) networks. As these\nsystems now become more integrated with Information Technology (IT) networks\nbased on IP, they expose vulnerabilities that can be exploited by the attackers\nthrough these IT networks. The attackers can control such systems and cause\nbehavior that jeopardizes the performance and safety measures that were\noriginally designed into the system. In this paper, we explore the approaches\nto identify threats to CPSs and ensure the quality of the created threat\nmodels. The study involves interviews with eleven security experts working in\nsecurity consultation companies, software engineering companies, an Original\nEquipment Manufacturer (OEM),and ground and areal vehicles integrators. We\nfound through these interviews that the practitioners use a combination of\nvarious threat modeling methods, approaches, and standards together when they\nperform threat modeling of given CPSs. key challenges practitioners face are:\nthey cannot transfer the threat modeling knowledge that they acquire in a\ncyber-physical domain to other domains, threat models of modified systems are\noften not updated, and the reliance on mostly peer-evaluation and quality\nchecklists to ensure the quality of threat models. The study warns about the\ndifficulty to develop secure CPSs and calls for research on developing\npractical threat modeling methods for CPSs, techniques for continuous threat\nmodeling, and techniques to ensure the quality of threat models.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2021 01:29:57 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Jamil", "Ameerah-Muhsinah", ""], ["Othmane", "Lotfi ben", ""], ["Valani", "Altaz", ""]]}, {"id": "2103.04234", "submitter": "Salem Alqahtani", "authors": "Salem Alqahtani and Murat Demirbas", "title": "Bottlenecks in Blockchain Consensus Protocols", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most of the Blockchain permissioned systems employ Byzantine fault-tolerance\n(BFT) consensus protocols to ensure that honest validators agree on the order\nfor appending entries to their ledgers. In this paper, we study the performance\nand the scalability of prominent consensus protocols, namely PBFT, Tendermint,\nHotStuff, and Streamlet, both analytically via load formulas and practically\nvia implementation and evaluation. Under identical conditions, we identify the\nbottlenecks of these consensus protocols and show that these protocols do not\nscale well as the number of validators increases. Our investigation points to\nthe communication complexity as the culprit. Even when there is enough network\nbandwidth, the CPU cost of serialization and deserialization of the messages\nlimits the throughput and increases the latency of the protocols. To alleviate\nthe bottlenecks, the most useful techniques include reducing the communication\ncomplexity, rotating the hotspot of communications, and pipelining across\nconsensus instances.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2021 02:17:58 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 17:53:19 GMT"}, {"version": "v3", "created": "Sat, 17 Jul 2021 00:02:23 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Alqahtani", "Salem", ""], ["Demirbas", "Murat", ""]]}, {"id": "2103.04263", "submitter": "Jiameng Pu", "authors": "Jiameng Pu, Neal Mangaokar, Lauren Kelly, Parantapa Bhattacharya,\n  Kavya Sundaram, Mobin Javed, Bolun Wang, Bimal Viswanath", "title": "Deepfake Videos in the Wild: Analysis and Detection", "comments": "Accepted to The Web Conference 2021; First two authors contributed\n  equally to this work; 12 pages, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI-manipulated videos, commonly known as deepfakes, are an emerging problem.\nRecently, researchers in academia and industry have contributed several\n(self-created) benchmark deepfake datasets, and deepfake detection algorithms.\nHowever, little effort has gone towards understanding deepfake videos in the\nwild, leading to a limited understanding of the real-world applicability of\nresearch contributions in this space. Even if detection schemes are shown to\nperform well on existing datasets, it is unclear how well the methods\ngeneralize to real-world deepfakes. To bridge this gap in knowledge, we make\nthe following contributions: First, we collect and present the largest dataset\nof deepfake videos in the wild, containing 1,869 videos from YouTube and\nBilibili, and extract over 4.8M frames of content. Second, we present a\ncomprehensive analysis of the growth patterns, popularity, creators,\nmanipulation strategies, and production methods of deepfake content in the\nreal-world. Third, we systematically evaluate existing defenses using our new\ndataset, and observe that they are not ready for deployment in the real-world.\nFourth, we explore the potential for transfer learning schemes and\ncompetition-winning techniques to improve defenses.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2021 04:40:15 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 01:08:38 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Pu", "Jiameng", ""], ["Mangaokar", "Neal", ""], ["Kelly", "Lauren", ""], ["Bhattacharya", "Parantapa", ""], ["Sundaram", "Kavya", ""], ["Javed", "Mobin", ""], ["Wang", "Bolun", ""], ["Viswanath", "Bimal", ""]]}, {"id": "2103.04264", "submitter": "Jiameng Pu", "authors": "Ahmadreza Azizi, Ibrahim Asadullah Tahmid, Asim Waheed, Neal\n  Mangaokar, Jiameng Pu, Mobin Javed, Chandan K. Reddy, Bimal Viswanath", "title": "T-Miner: A Generative Approach to Defend Against Trojan Attacks on\n  DNN-based Text Classification", "comments": "Accepted to Usenix Security 2021; First two authors contributed\n  equally to this work; 18 pages, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network (DNN) classifiers are known to be vulnerable to Trojan or\nbackdoor attacks, where the classifier is manipulated such that it\nmisclassifies any input containing an attacker-determined Trojan trigger.\nBackdoors compromise a model's integrity, thereby posing a severe threat to the\nlandscape of DNN-based classification. While multiple defenses against such\nattacks exist for classifiers in the image domain, there have been limited\nefforts to protect classifiers in the text domain.\n  We present Trojan-Miner (T-Miner) -- a defense framework for Trojan attacks\non DNN-based text classifiers. T-Miner employs a sequence-to-sequence\n(seq-2-seq) generative model that probes the suspicious classifier and learns\nto produce text sequences that are likely to contain the Trojan trigger.\nT-Miner then analyzes the text produced by the generative model to determine if\nthey contain trigger phrases, and correspondingly, whether the tested\nclassifier has a backdoor. T-Miner requires no access to the training dataset\nor clean inputs of the suspicious classifier, and instead uses synthetically\ncrafted \"nonsensical\" text inputs to train the generative model. We extensively\nevaluate T-Miner on 1100 model instances spanning 3 ubiquitous DNN model\narchitectures, 5 different classification tasks, and a variety of trigger\nphrases. We show that T-Miner detects Trojan and clean models with a 98.75%\noverall accuracy, while achieving low false positives on clean models. We also\nshow that T-Miner is robust against a variety of targeted, advanced attacks\nfrom an adaptive attacker.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2021 04:43:24 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 01:02:24 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Azizi", "Ahmadreza", ""], ["Tahmid", "Ibrahim Asadullah", ""], ["Waheed", "Asim", ""], ["Mangaokar", "Neal", ""], ["Pu", "Jiameng", ""], ["Javed", "Mobin", ""], ["Reddy", "Chandan K.", ""], ["Viswanath", "Bimal", ""]]}, {"id": "2103.04302", "submitter": "Jinyu Tian", "authors": "Jinyu Tian, Jiantao Zhou, Yuanman Li, Jia Duan", "title": "Detecting Adversarial Examples from Sensitivity Inconsistency of\n  Spatial-Transform Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep neural networks (DNNs) have been shown to be vulnerable against\nadversarial examples (AEs), which are maliciously designed to cause dramatic\nmodel output errors. In this work, we reveal that normal examples (NEs) are\ninsensitive to the fluctuations occurring at the highly-curved region of the\ndecision boundary, while AEs typically designed over one single domain (mostly\nspatial domain) exhibit exorbitant sensitivity on such fluctuations. This\nphenomenon motivates us to design another classifier (called dual classifier)\nwith transformed decision boundary, which can be collaboratively used with the\noriginal classifier (called primal classifier) to detect AEs, by virtue of the\nsensitivity inconsistency. When comparing with the state-of-the-art algorithms\nbased on Local Intrinsic Dimensionality (LID), Mahalanobis Distance (MD), and\nFeature Squeezing (FS), our proposed Sensitivity Inconsistency Detector (SID)\nachieves improved AE detection performance and superior generalization\ncapabilities, especially in the challenging cases where the adversarial\nperturbation levels are small. Intensive experimental results on ResNet and VGG\nvalidate the superiority of the proposed SID.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2021 08:43:22 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Tian", "Jinyu", ""], ["Zhou", "Jiantao", ""], ["Li", "Yuanman", ""], ["Duan", "Jia", ""]]}, {"id": "2103.04330", "submitter": "\\.Ilker \\\"Oz\\c{c}elik", "authors": "Ilker Ozcelik, Sai Medury, Justin Broaddus and Anthony Skjellum", "title": "An Overview of Cryptographic Accumulators", "comments": "Note: This is an extended version of a paper published In Proceedings\n  of the 7th International Conference on Information Systems Security and\n  Privacy (ICISSP 2021), pages 661-669", "journal-ref": null, "doi": "10.5220/0010337806610669", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is a primer on cryptographic accumulators and how to apply them\npractically. A cryptographic accumulator is a space- and time-efficient data\nstructure used for set-membership tests. Since it is possible to represent any\ncomputational problem where the answer is yes or no as a set-membership\nproblem, cryptographic accumulators are invaluable data structures in computer\nscience and engineering. But, to the best of our knowledge, there is neither a\nconcise survey comparing and contrasting various types of accumulators nor a\nguide for how to apply the most appropriate one for a given application.\nTherefore, we address that gap by describing cryptographic accumulators while\npresenting their fundamental and so-called optional properties. We discuss the\neffects of each property on the given accumulator's performance in terms of\nspace and time complexity, as well as communication overhead.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2021 11:51:28 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Ozcelik", "Ilker", ""], ["Medury", "Sai", ""], ["Broaddus", "Justin", ""], ["Skjellum", "Anthony", ""]]}, {"id": "2103.04428", "submitter": "Christoph Capellaro", "authors": "Christoph Capellaro", "title": "Design of Ciphers based on the Geometric Structure of the Laguerre and\n  Minkowski Planes", "comments": "20 pages, 5 figures. arXiv admin note: text overlap with\n  arXiv:2102.10321", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Till now geometric structures don't play a major role in cryptography.\nGilbert, MacWilliams and Sloane introduced an authentication scheme in the\nprojective plane and showed its perfectness in the sense of Shannon. In\narXiv:2102.10321 we introduced an encryption scheme in the M\\\"obius plane and\nshowed that it fulfills Shannon's requirement of perfectness in first\napproximation and also the requirement of completeness according to Kam and\nDavida. In this paper we will apply a similar approach to define encryption\nschemes in the geometries of the Laguerre plande and the Minkowski plane. We\nwill show that the encryption scheme in the Laguerre geometry meets Shannon's\nrequirement of perfectness sharp and that the encryption scheme in the\nMinkowski geometry meets this requirement in first approximation. The Laguerre\ncipher also fulfills the requirement of completeness according to Kam and\nDavida.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2021 18:59:30 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Capellaro", "Christoph", ""]]}, {"id": "2103.04443", "submitter": "Oliver Hohlfeld", "authors": "Daniel Kopp and Christoph Dietzel and Oliver Hohlfeld", "title": "DDoS Never Dies? An IXP Perspective on DDoS Amplification Attacks", "comments": "To appear at PAM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DDoS attacks remain a major security threat to the continuous operation of\nInternet edge infrastructures, web services, and cloud platforms. While a large\nbody of research focuses on DDoS detection and protection, to date we\nultimately failed to eradicate DDoS altogether. Yet, the landscape of DDoS\nattack mechanisms is even evolving, demanding an updated perspective on DDoS\nattacks in the wild. In this paper, we identify up to 2608 DDoS amplification\nattacks at a single day by analyzing multiple Tbps of traffic flows at a major\nIXP with a rich ecosystem of different networks. We observe the prevalence of\nwell-known amplification attack protocols (e.g., NTP, CLDAP), which should no\nlonger exist given the established mitigation strategies. Nevertheless, they\npose the largest fraction on DDoS amplification attacks within our observation\nand we witness the emergence of DDoS attacks using recently discovered\namplification protocols (e.g., OpenVPN, ARMS, Ubiquity Discovery Protocol). By\nanalyzing the impact of DDoS on core Internet infrastructure, we show that DDoS\ncan overload backbone-capacity and that filtering approaches in prior work omit\n97% of the attack traffic.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2021 20:22:03 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Kopp", "Daniel", ""], ["Dietzel", "Christoph", ""], ["Hohlfeld", "Oliver", ""]]}, {"id": "2103.04456", "submitter": "Stefan Tauner", "authors": "Mario Telesklav and Stefan Tauner", "title": "Comparative Analysis and Enhancement of CFG-based Hardware-Assisted CFI\n  Schemes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Subverting the flow of instructions (e.g., by use of code-reuse attacks)\nstill poses a serious threat to the security of today's systems. Various\ncontrol flow integrity (CFI) schemes have been proposed as a powerful technique\nto detect and mitigate such attacks. In recent years, many hardware-assisted\nimplementations of CFI enforcement based on control flow graphs (CFGs) have\nbeen presented by academia. Such approaches check whether control flow\ntransfers follow the intended CFG by limiting the valid target addresses.\nHowever, these papers all target different platforms and were evaluated with\ndifferent sets of benchmark applications, which makes quantitative comparisons\nhardly possible.\n  For this paper, we have implemented multiple promising CFG-based CFI schemes\non a common platform comprising a RISC-V SoC within an FPGA. By porting almost\n40 benchmark applications to this system we can present a meaningful comparison\nof the various techniques in terms of run-time performance, hardware\nutilization, and binary size. In addition, we present an enhanced CFI approach\nthat is inspired by what we consider the best concepts and ideas of previously\nproposed mechanisms. We have made this approach more practical and\nfeature-complete by tackling some problems largely ignored previously. We show\nwith this fine-grained scheme that CFI can be achieved with even less overheads\nthan previously demonstrated.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2021 20:53:33 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Telesklav", "Mario", ""], ["Tauner", "Stefan", ""]]}, {"id": "2103.04475", "submitter": "Shuhan Yuan", "authors": "Haixuan Guo, Shuhan Yuan, Xintao Wu", "title": "LogBERT: Log Anomaly Detection via BERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Detecting anomalous events in online computer systems is crucial to protect\nthe systems from malicious attacks or malfunctions. System logs, which record\ndetailed information of computational events, are widely used for system status\nanalysis. In this paper, we propose LogBERT, a self-supervised framework for\nlog anomaly detection based on Bidirectional Encoder Representations from\nTransformers (BERT). LogBERT learns the patterns of normal log sequences by two\nnovel self-supervised training tasks and is able to detect anomalies where the\nunderlying patterns deviate from normal log sequences. The experimental results\non three log datasets show that LogBERT outperforms state-of-the-art approaches\nfor anomaly detection.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2021 22:56:01 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Guo", "Haixuan", ""], ["Yuan", "Shuhan", ""], ["Wu", "Xintao", ""]]}, {"id": "2103.04519", "submitter": "Mark Moir", "authors": "Victor Cacciari Miraldo and Harold Carr and Mark Moir and Lisandra\n  Silva and Guy L. Steele Jr", "title": "Formal Verification of Authenticated, Append-Only Skip Lists in Agda:\n  Extended Version", "comments": "This is an extended version of our paper published in the 10th ACM\n  SIGPLAN International Conference on Certified Programs and Proofs (CPP 2021).\n  This version (2021-02-23) presents a stronger version of the evocr property\n  than originally presented, and provides a link to our development in open\n  source", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Authenticated Append-Only Skiplists (AAOSLs) enable maintenance and querying\nof an authenticated log (such as a blockchain) without requiring any single\nparty to store or verify the entire log, or to trust another party regarding\nits contents. AAOSLs can help to enable efficient dynamic participation (e.g.,\nin consensus) and reduce storage overhead.\n  In this paper, we formalize an AAOSL originally described by Maniatis and\nBaker, and prove its key correctness properties. Our model and proofs are\nmachine checked in Agda. Our proofs apply to a generalization of the original\nconstruction and provide confidence that instances of this generalization can\nbe used in practice. Our formalization effort has also yielded some\nsimplifications and optimizations.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 02:43:46 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Miraldo", "Victor Cacciari", ""], ["Carr", "Harold", ""], ["Moir", "Mark", ""], ["Silva", "Lisandra", ""], ["Steele", "Guy L.", "Jr"]]}, {"id": "2103.04533", "submitter": "Zhe Zhou", "authors": "Junpeng Wan, Yanxiang Bi, Zhe Zhou, Zhou Li", "title": "Volcano: Stateless Cache Side-channel Attack by Exploiting Mesh\n  Interconnect", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cache side-channel attacks lead to severe security threats to the settings\nthat a CPU is shared across users, e.g., in the cloud. The existing attacks\nrely on sensing the micro-architectural state changes made by victims, and this\nassumption can be invalidated by combining spatial (\\eg, Intel CAT) and\ntemporal isolation (\\eg, time protection). In this work, we advance the state\nof cache side-channel attacks by showing stateless cache side-channel attacks\nthat cannot be defeated by both spatial and temporal isolation.\n  This side-channel exploits the timing difference resulted from interconnect\ncongestion. Specifically, to complete cache transactions, for Intel CPUs, cache\nlines would travel across cores via the CPU mesh interconnect. Nonetheless, the\nmesh links are shared by all cores, and cache isolation does not segregate the\ntraffic. An attacker can generate interconnect traffic to contend with the\nvictim's on a mesh link, hoping that extra delay will be measured. With the\nvariant delays, the attacker can deduce the memory access pattern of a victim\nprogram, and infer its sensitive data. Based on this idea, we implement Volcano\nand test it against the existing RSA implementations of JDK. We found the RSA\nprivate key used by a victim process can be partially recovered. In the end, we\npropose a few directions for defense and call for the attention of the security\ncommunity.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 03:52:42 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Wan", "Junpeng", ""], ["Bi", "Yanxiang", ""], ["Zhou", "Zhe", ""], ["Li", "Zhou", ""]]}, {"id": "2103.04606", "submitter": "Pascal Veron", "authors": "Yoann Marquer (IRISA), Tania Richmond (DGA.MI, IRISA), Pascal V\\'eron\n  (IMATH)", "title": "A Hole in the Ladder: Interleaved Variables in Iterative Conditional\n  Branching (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The iterative conditional branchings appear in various sensitive algorithms,\nlike the modular exponentiation in the RSA cryptosystem or the scalar\nmultiplication in ellipticcurve cryptography. In this paper, we abstract away\nthe desirable security properties achieved by the Montgomery ladder, and\nformalize systems of equations necessary to obtain what we call the\nsemi-interleaved and fully-interleaved ladder properties. This fruitful\napproach allows us to design novel fault-injection attacks, able to obtain\nsome/all bits of the secret against different ladders, including the common\nMontgomery ladder. We also demonstrate the generality of our approach by\napplying the ladder equations to the modular exponentiation and the scalar\nmultiplication, both in the semi-and fully-interleaved cases, thus proposing\nnovel and more secure algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 08:56:41 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Marquer", "Yoann", "", "IRISA"], ["Richmond", "Tania", "", "DGA.MI, IRISA"], ["V\u00e9ron", "Pascal", "", "IMATH"]]}, {"id": "2103.04673", "submitter": "Ahmed Alharbi", "authors": "Ahmed Alharbi, Hai Dong, Xun Yi, Zahir Tari and Ibrahim Khalil", "title": "Social Media Identity Deception Detection: A Survey", "comments": "Accepted for publication in ACM Computing Surveys", "journal-ref": "ACM Computing Surveys (CSUR), 54(3), 1-35 (2021)", "doi": "10.1145/3446372", "report-no": null, "categories": "cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media have been growing rapidly and become essential elements of many\npeople's lives. Meanwhile, social media have also come to be a popular source\nfor identity deception. Many social media identity deception cases have arisen\nover the past few years. Recent studies have been conducted to prevent and\ndetect identity deception. This survey analyses various identity deception\nattacks, which can be categorized into fake profile, identity theft and\nidentity cloning. This survey provides a detailed review of social media\nidentity deception detection techniques. It also identifies primary research\nchallenges and issues in the existing detection techniques. This article is\nexpected to benefit both researchers and social media providers.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 11:19:40 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 13:45:08 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Alharbi", "Ahmed", ""], ["Dong", "Hai", ""], ["Yi", "Xun", ""], ["Tari", "Zahir", ""], ["Khalil", "Ibrahim", ""]]}, {"id": "2103.04794", "submitter": "Qiumei Cheng", "authors": "Qiumei Cheng, Shiying Zhou, Yi Shen, Dezhang Kong, Chunming Wu", "title": "Packet-Level Adversarial Network Traffic Crafting using Sequence\n  Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The surge in the internet of things (IoT) devices seriously threatens the\ncurrent IoT security landscape, which requires a robust network intrusion\ndetection system (NIDS). Despite superior detection accuracy, existing machine\nlearning or deep learning based NIDS are vulnerable to adversarial examples.\nRecently, generative adversarial networks (GANs) have become a prevailing\nmethod in adversarial examples crafting. However, the nature of discrete\nnetwork traffic at the packet level makes it hard for GAN to craft adversarial\ntraffic as GAN is efficient in generating continuous data like image synthesis.\nUnlike previous methods that convert discrete network traffic into a grayscale\nimage, this paper gains inspiration from SeqGAN in sequence generation with\npolicy gradient. Based on the structure of SeqGAN, we propose Attack-GAN to\ngenerate adversarial network traffic at packet level that complies with domain\nconstraints. Specifically, the adversarial packet generation is formulated into\na sequential decision making process. In this case, each byte in a packet is\nregarded as a token in a sequence. The objective of the generator is to select\na token to maximize its expected end reward. To bypass the detection of NIDS,\nthe generated network traffic and benign traffic are classified by a black-box\nNIDS. The prediction results returned by the NIDS are fed into the\ndiscriminator to guide the update of the generator. We generate malicious\nadversarial traffic based on a real public available dataset with attack\nfunctionality unchanged. The experimental results validate that the generated\nadversarial samples are able to deceive many existing black-box NIDS.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 14:42:04 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Cheng", "Qiumei", ""], ["Zhou", "Shiying", ""], ["Shen", "Yi", ""], ["Kong", "Dezhang", ""], ["Wu", "Chunming", ""]]}, {"id": "2103.04816", "submitter": "Boel Nelson", "authors": "Boel Nelson", "title": "Efficient Accuracy Prediction for Differentially Private Algorithms", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Differential privacy is a strong mathematical notion of privacy. Still, a\nprominent challenge when using differential privacy in real data collection is\nunderstanding and counteracting the accuracy loss that differential privacy\nimposes. As such, the accuracy-privacy trade-off of differential privacy needs\nto be balanced on a case-by-case basis. Applications in the literature tend to\nfocus solely on analytical accuracy bounds, not include data in error\nprediction, or use arbitrary settings to measure error empirically.\n  To fill the gap in the literature, we propose a novel application of factor\nexperiments to create data aware error predictions. Basically, factor\nexperiments provide a systematic approach to conducting empirical experiments.\nTo demonstrate our methodology in action, we conduct a case study where error\nis dependent on arbitrarily complex tree structures. We first construct a tool\nto simulate poll data. Next, we use our simulated data to construct a least\nsquares model to predict error. Last, we show how to validate the model.\nConsequently, our contribution is a method for constructing error prediction\nmodels that are data aware.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 15:16:17 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Nelson", "Boel", ""]]}, {"id": "2103.04889", "submitter": "Radhika Rani Chintala", "authors": "Radhika Rani Chintala, Narasinga Rao M R, Somu Venkateswarlu", "title": "Design and implementation of Energy Efficient Lightweight Encryption\n  (EELWE) algorithm for medical applications", "comments": "11 pages", "journal-ref": null, "doi": "10.17762/itii.v9i1.152", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proportional to the growth in the usage of Human Sensor Networks (HSN), the\nvolume of the data exchange between Sensor devices is increasing at a rapid\npace. In this paper, we have proposed an Energy Efficient Lightweight\nEncryption (EELWE) algorithm for providing the confidentiality of data at the\nsensor level, particularly suitable for resource-constrained environments.\nResults obtained have proved that an EELWE consumes less energy relative to\npresent lightweight ciphers and it supports multiple block sizes of 32-bit,\n48-bit, and 64-bit.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 16:48:31 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Chintala", "Radhika Rani", ""], ["R", "Narasinga Rao M", ""], ["Venkateswarlu", "Somu", ""]]}, {"id": "2103.04901", "submitter": "Mazaher Kianpour", "authors": "Mazaher Kianpour", "title": "Socio-Technical Root Cause Analysis of Cyber-enabled Theft of the U.S.\n  Intellectual Property -- The Case of APT41", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Increased connectivity has made us all more vulnerable. Cyberspace, besides\nall its benefits, spawned more devices to hack and more opportunities to commit\ncybercrime. Criminals have found it lucrative to target both individuals and\nbusinesses, by holding or stealing their assets via different types of cyber\nattacks. The cyber-enabled theft of Intellectual Property (IP), as one of the\nmost important and critical intangible assets of nations, organizations and\nindividuals, by foreign countries has been a devastating challenge of the\nUnited States (U.S.) in the past decades. In this study, we conduct a\nsocio-technical root cause analysis to investigate one of the recent cases of\nIP theft by employing a holistic approach. It concludes with a list of root\ncauses and some corrective actions to stop the impact and prevent the\nrecurrence of the problem in the future. Building upon the findings of this\nstudy, the U.S. requires a detailed revision of IP strategies bringing the\nwhole socio-technical regulatory system into focus and strengthen IP rights\nprotection considering China's indigenous innovation policies. It is critical\nthat businesses and other organizations take steps to reduce their exposure to\ncyber attacks. It is particularly important to train employees on how to spot\npotential threats, and to institute policies that encourage workers to report\npotential security failures so that action can be taken quickly. Finally, we\ndiscuss how cyber ranges can provide an efficient and safe platform for dealing\nwith such challenges. The results of this study can be expanded to other\ncountries in order to protect their IP rights and deter or prevent and respond\nto future incidents.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 17:05:09 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Kianpour", "Mazaher", ""]]}, {"id": "2103.04904", "submitter": "Laszlo Csirmaz", "authors": "Laszlo Csirmaz, Franti\\v{s}ek Mat\\'u\\v{s} and Carles Padr\\'o", "title": "Bipartite secret sharing and staircases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bipartite secret sharing schemes have a bipartite access structure in which\nthe set of participants is divided into two parts and all participants in the\nsame part play an equivalent role. Such a bipartite scheme can be described by\na \"staircase\": the collection of its minimal points. The complexity of a scheme\nis the maximal share size relative to the secret size; and the\n$\\kappa$-complexity of a structure is the best lower bound provided by the\nentropy method. A structure is $\\kappa$-ideal if it has $\\kappa$-complexity 1.\nMotivated by the abundance of open problems in this area, the main results can\nbe summarized as follows. First, a new characterization of $\\kappa$-ideal\nmultipartite access structures is given which offers a straightforward and\nsimple approach to specify ideal bipartite and tripartite structures. Second,\n$\\kappa$-complexity is determined for a range of bipartite access structures,\nincluding those determined by two points, staircases with equal widths and\nheights, and staircases with all heights 1. Third, matching linear schemes are\npresented for some non-ideal cases, including staircases where all heights are\n1 and all widths are equal. Finally, finding the Shannon complexity of a\nbipartite access structure can be considered as a discrete submodular\noptimization problem. An interesting and intriguing continuous version is\ndefined which might give further insight to the large-scale behavior of these\noptimization problems.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 17:09:43 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Csirmaz", "Laszlo", ""], ["Mat\u00fa\u0161", "Franti\u0161ek", ""], ["Padr\u00f3", "Carles", ""]]}, {"id": "2103.04952", "submitter": "Anatoly Shusterman", "authors": "Anatoly Shusterman, Ayush Agarwal, Sioli O'Connell, Daniel Genkin,\n  Yossi Oren, Yuval Yarom", "title": "Prime+Probe 1, JavaScript 0: Overcoming Browser-based Side-Channel\n  Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \"eternal war in cache\" has reached browsers, with multiple cache-based\nside-channel attacks and countermeasures being suggested. A common approach for\ncountermeasures is to disable or restrict JavaScript features deemed essential\nfor carrying out attacks. To assess the effectiveness of this approach, in this\nwork we seek to identify those JavaScript features which are essential for\ncarrying out a cache-based attack. We develop a sequence of attacks with\nprogressively decreasing dependency on JavaScript features, culminating in the\nfirst browser-based side-channel attack which is constructed entirely from\nCascading Style Sheets (CSS) and HTML, and works even when script execution is\ncompletely blocked. We then show that avoiding JavaScript features makes our\ntechniques architecturally agnostic, resulting in microarchitectural website\nfingerprinting attacks that work across hardware platforms including Intel\nCore, AMD Ryzen, Samsung Exynos, and Apple M1 architectures. As a final\ncontribution, we evaluate our techniques in hardened browser environments\nincluding the Tor browser, Deter-Fox (Cao el al., CCS 2017), and Chrome Zero\n(Schwartz et al., NDSS 2018). We confirm that none of these approaches\ncompletely defend against our attacks. We further argue that the protections of\nChrome Zero need to be more comprehensively applied, and that the performance\nand user experience of Chrome Zero will be severely degraded if this approach\nis taken.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 18:16:10 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Shusterman", "Anatoly", ""], ["Agarwal", "Ayush", ""], ["O'Connell", "Sioli", ""], ["Genkin", "Daniel", ""], ["Oren", "Yossi", ""], ["Yarom", "Yuval", ""]]}, {"id": "2103.04980", "submitter": "Dongdong Chen", "authors": "Jie Zhang and Dongdong Chen and Jing Liao and Weiming Zhang and Huamin\n  Feng and Gang Hua and Nenghai Yu", "title": "Deep Model Intellectual Property Protection via Deep Watermarking", "comments": "To appear at TPAMI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the tremendous success, deep neural networks are exposed to serious\nIP infringement risks. Given a target deep model, if the attacker knows its\nfull information, it can be easily stolen by fine-tuning. Even if only its\noutput is accessible, a surrogate model can be trained through student-teacher\nlearning by generating many input-output training pairs. Therefore, deep model\nIP protection is important and necessary. However, it is still seriously\nunder-researched. In this work, we propose a new model watermarking framework\nfor protecting deep networks trained for low-level computer vision or image\nprocessing tasks. Specifically, a special task-agnostic barrier is added after\nthe target model, which embeds a unified and invisible watermark into its\noutputs. When the attacker trains one surrogate model by using the input-output\npairs of the barrier target model, the hidden watermark will be learned and\nextracted afterwards. To enable watermarks from binary bits to high-resolution\nimages, a deep invisible watermarking mechanism is designed. By jointly\ntraining the target model and watermark embedding, the extra barrier can even\nbe absorbed into the target model. Through extensive experiments, we\ndemonstrate the robustness of the proposed framework, which can resist attacks\nwith different network structures and objective functions.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 18:58:21 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Zhang", "Jie", ""], ["Chen", "Dongdong", ""], ["Liao", "Jing", ""], ["Zhang", "Weiming", ""], ["Feng", "Huamin", ""], ["Hua", "Gang", ""], ["Yu", "Nenghai", ""]]}, {"id": "2103.05072", "submitter": "Jaydeep Howlader Dr.", "authors": "Dhaneshwar Mardi, Surbhi Tanwar, Jaydeep Howlader", "title": "Multiparty Protocol that Usually Shuffles", "comments": "28 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multiparty computation is raising importance because it's primary objective\nis to replace any trusted third party in the distributed computation. This work\npresents two multiparty shuffling protocols where each party, possesses a\nprivate input, agrees on a random permutation while keeping the permutation\nsecret. The proposed shuffling protocols are based on permutation network,\nthereby data-oblivious. The first proposal is $n\\text{-}permute$ that permutes\n$n$ inputs in all $n!$ possible ways. $n$-permute network consists of\n$2\\log{n}-1$ layers, and in each layer there are $n/2$ gates. Our second\nprotocol is $n_{\\pi}$-permute shuffling that defines a permutation set\n$\\Pi=\\{\\pi_1,\\dots,\\pi_N\\}$ where $|\\Pi| < n!$, and the resultant shuffling is\na random permutation $\\pi_i \\in \\Pi$. The $n_{\\pi}$-permute network contains\nleases number of layers compare to $n$-permute network. Let $n=n_1n_2$, the\n$n_{\\pi}$-permute network would define $2\\log{n_1}-1+\\log{n_2}$ layers. \\par\nThe proposed shuffling protocols are unconditionally secure against malicious\nadversary who can corrupt at most $t<n/3$ parties. The probability that\nadversary can learn the outcome of $n$-permute is upper bound by\n$((n-t)!)^{-1}$. Whereas, the probability that adversary can learn the outcome\nof $n_{\\pi}$-permute is upper bounded by\n$\\big(f_{\\Pi}(n_1-\\theta_1)^{n_2}2^{\\theta_2}\\big)^{-1}$, for some positive\ninteger $\\theta_1, \\theta_2$, and a recursive definition of $f_{\\Pi}$. The\nprotocols allow the parties to build quorums, and distribute the load among the\nquorums.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 20:58:45 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Mardi", "Dhaneshwar", ""], ["Tanwar", "Surbhi", ""], ["Howlader", "Jaydeep", ""]]}, {"id": "2103.05088", "submitter": "Sarah Elder", "authors": "Sarah Elder, Nusrat Zahan, Val Kozarev, Rui Shu, Tim Menzies, Laurie\n  Williams", "title": "Structuring a Comprehensive Software Security Course Around the OWASP\n  Application Security Verification Standard", "comments": "10 pages, 5 figures, 1 table, submitted to International Conference\n  on Software Engineering: Joint Track on Software Engineering Education and\n  Training (ICSE-JSEET)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lack of security expertise among software practitioners is a problem with\nmany implications. First, there is a deficit of security professionals to meet\ncurrent needs. Additionally, even practitioners who do not plan to work in\nsecurity may benefit from increased understanding of security. The goal of this\npaper is to aid software engineering educators in designing a comprehensive\nsoftware security course by sharing an experience running a software security\ncourse for the eleventh time. Through all the eleven years of running the\nsoftware security course, the course objectives have been comprehensive -\nranging from security testing, to secure design and coding, to security\nrequirements to security risk management. For the first time in this eleventh\nyear, a theme of the course assignments was to map vulnerability discovery to\nthe security controls of the Open Web Application Security Project (OWASP)\nApplication Security Verification Standard (ASVS). Based upon student\nperformance on a final exploratory penetration testing project, this mapping\nmay have increased students' depth of understanding of a wider range of\nsecurity topics. The students efficiently detected 191 unique and verified\nvulnerabilities of 28 different Common Weakness Enumeration (CWE) types during\na three-hour period in the OpenMRS project, an electronic health record\napplication in active use.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 21:39:14 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Elder", "Sarah", ""], ["Zahan", "Nusrat", ""], ["Kozarev", "Val", ""], ["Shu", "Rui", ""], ["Menzies", "Tim", ""], ["Williams", "Laurie", ""]]}, {"id": "2103.05160", "submitter": "Sarah Elder", "authors": "Sarah Elder", "title": "Vulnerability Detection is Just the Beginning", "comments": "5 pages, 1 figure, submitted to International Conference on Software\n  Engineering: Doctoral Symposium (ICSE-DS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vulnerability detection plays a key role in secure software development.\nThere are many different vulnerability detection tools and techniques to choose\nfrom, and insufficient information on which vulnerability detection techniques\nto use and when. The goal of this research is to assist managers and other\ndecision-makers on software projects in making informed choices about the use\nof different software vulnerability detection techniques through empirical\nanalysis of the efficiency and effectiveness of each technique. We will examine\nthe relationships between the vulnerability detection technique used to find a\nvulnerability, the type of vulnerability found, the exploitability of the\nvulnerability, and the effort needed to fix a vulnerability on two projects\nwhere we ensure all vulnerabilities found have been fixed. We will then examine\nhow these relationships are seen in Open Source Software more broadly where\npractitioners may use different vulnerability detection techniques, or may not\nfix all vulnerabilities found due to resource constraints.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 01:03:03 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Elder", "Sarah", ""]]}, {"id": "2103.05173", "submitter": "Masoumeh Shafieinejad", "authors": "Masoumeh Shafieinejad (1) and Florian Kerschbaum (1) and Ihab F. Ilyas\n  (1) ((1) University of Waterloo)", "title": "PCOR: Private Contextual Outlier Release via Differentially Private\n  Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Outlier detection plays a significant role in various real world applications\nsuch as intrusion, malfunction, and fraud detection. Traditionally, outlier\ndetection techniques are applied to find outliers in the context of the whole\ndataset. However, this practice neglects contextual outliers, that are not\noutliers in the whole dataset but in some specific neighborhoods. Contextual\noutliers are particularly important in data exploration and targeted anomaly\nexplanation and diagnosis. In these scenarios, the data owner computes the\nfollowing information: i) The attributes that contribute to the abnormality of\nan outlier (metric), ii) Contextual description of the outlier's neighborhoods\n(context), and iii) The utility score of the context, e.g. its strength in\nshowing the outlier's significance, or in relation to a particular explanation\nfor the outlier. However, revealing the outlier's context leaks information\nabout the other individuals in the population as well, violating their privacy.\nWe address the issue of population privacy violations in this paper, and\npropose a solution for the two main challenges. In this setting, the data owner\nis required to release a valid context for the queried record, i.e. a context\nin which the record is an outlier. Hence, the first major challenge is that the\nprivacy technique must preserve the validity of the context for each record. We\npropose techniques to protect the privacy of individuals through a relaxed\nnotion of differential privacy to satisfy this requirement. The second major\nchallenge is applying the proposed techniques efficiently, as they impose\nintensive computation to the base algorithm. To overcome this challenge, we\npropose a graph structure to map the contexts to, and introduce differentially\nprivate graph search algorithms as efficient solutions for the computation\nproblem caused by differential privacy techniques.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 01:55:01 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Shafieinejad", "Masoumeh", "", "University of Waterloo"], ["Kerschbaum", "Florian", "", "University of Waterloo"], ["Ilyas", "Ihab F.", "", "University of Waterloo"]]}, {"id": "2103.05232", "submitter": "Lijun Gong", "authors": "Gege Qi, Lijun Gong, Yibing Song, Kai Ma, Yefeng Zheng", "title": "Stabilized Medical Image Attacks", "comments": "ICLR 2021 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convolutional Neural Networks (CNNs) have advanced existing medical systems\nfor automatic disease diagnosis. However, a threat to these systems arises that\nadversarial attacks make CNNs vulnerable. Inaccurate diagnosis results make a\nnegative influence on human healthcare. There is a need to investigate\npotential adversarial attacks to robustify deep medical diagnosis systems. On\nthe other side, there are several modalities of medical images (e.g., CT,\nfundus, and endoscopic image) of which each type is significantly different\nfrom others. It is more challenging to generate adversarial perturbations for\ndifferent types of medical images. In this paper, we propose an image-based\nmedical adversarial attack method to consistently produce adversarial\nperturbations on medical images. The objective function of our method consists\nof a loss deviation term and a loss stabilization term. The loss deviation term\nincreases the divergence between the CNN prediction of an adversarial example\nand its ground truth label. Meanwhile, the loss stabilization term ensures\nsimilar CNN predictions of this example and its smoothed input. From the\nperspective of the whole iterations for perturbation generation, the proposed\nloss stabilization term exhaustively searches the perturbation space to smooth\nthe single spot for local optimum escape. We further analyze the KL-divergence\nof the proposed loss function and find that the loss stabilization term makes\nthe perturbations updated towards a fixed objective spot while deviating from\nthe ground truth. This stabilization ensures the proposed medical attack\neffective for different types of medical images while producing perturbations\nin small variance. Experiments on several medical image analysis benchmarks\nincluding the recent COVID-19 dataset show the stability of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 05:40:30 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Qi", "Gege", ""], ["Gong", "Lijun", ""], ["Song", "Yibing", ""], ["Ma", "Kai", ""], ["Zheng", "Yefeng", ""]]}, {"id": "2103.05242", "submitter": "Fusen Wang", "authors": "Fusen Wang (1 and 2), Jun Sang (1 and 2), Qi Liu (1 and 2), Chunlin\n  Huang (1 and 2), Jinghan Tan (1 and 2) ((1) Key Laboratory of Dependable\n  Service Computing in Cyber Physical Society of Ministry of Education,\n  Chongqing University, Chongqing, China, (2) School of Big Data and Software\n  Engineering, Chongqing University, Chongqing, China)", "title": "A deep learning based known plaintext attack method for chaotic\n  cryptosystem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a known-plaintext attack (KPA) method based on deep\nlearning for traditional chaotic encryption scheme. We employ the convolutional\nneural network to learn the operation mechanism of chaotic cryptosystem, and\naccept the trained network as the final decryption system. To evaluate the\nattack performance of different networks on different chaotic cryptosystem, we\nadopt two neural networks to perform known-plaintext attacks on two distinct\nchaotic encryption schemes. The experimental results demonstrate the potential\nof deep learning-based method for known-plaintext attack against chaotic\ncryptosystem. Different from the previous known-plaintext attack methods, which\nwere usually limited to a specific chaotic cryptosystem, a neural network can\nbe applied to the cryptanalysis of various chaotic cryptosystems with deep\nlearning-based approach, while several different networks can be designed for\nthe cryptanalysis of chaotic cryptosystems. This paper provides a new idea for\nthe cryptanalysis of chaotic image encryption algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 06:24:56 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Wang", "Fusen", "", "1 and 2"], ["Sang", "Jun", "", "1 and 2"], ["Liu", "Qi", "", "1 and 2"], ["Huang", "Chunlin", "", "1 and 2"], ["Tan", "Jinghan", "", "1 and 2"]]}, {"id": "2103.05250", "submitter": "Pan Wang", "authors": "Pan Wang, Zixuan Wang, Feng Ye, Xuejiao Chen", "title": "ByteSGAN: A Semi-supervised Generative Adversarial Network for Encrypted\n  Traffic Classification of SDN Edge Gateway in Green Communication Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the rapid development of Green Communication Network, the types and\nquantity of network traffic data are accordingly increasing. Network traffic\nclassification become a non-trivial research task in the area of network\nmanagement and security, which not only help to improve the fine-grained\nnetwork resource allocation, but also enable policy-driven network management.\nMeanwhile, the combination of SDN and Edge Computing can leverage both SDN at\nits global visiability of network-wide and Edge Computing at its low latency\nand good privacy-preserving. However, capturing large labeled datasets is a\ncumbersome and time-consuming manual labor. Semi-Supervised learning is an\nappropriate technique to overcome this problem. With that in mind, we proposed\na Generative Adversarial Network (GAN)-based Semi-Supervised Learning Encrypted\nTraffic Classification method called \\emph{ByteSGAN} embedded in SDN Edge\nGateway to achieve the goal of traffic classification in a fine-grained manner\nto further improve network resource utilization. ByteSGAN can only use a small\nnumber of labeled traffic samples and a large number of unlabeled samples to\nachieve a good performance of traffic classification by modifying the structure\nand loss function of the regular GAN discriminator network in a semi-supervised\nlearning way. Based on public dataset 'ISCX2012 VPN-nonVPN', two experimental\nresults show that the ByteSGAN can efficiently improve the performance of\ntraffic classifier and outperform the other supervised learning method like\nCNN.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 06:45:14 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Wang", "Pan", ""], ["Wang", "Zixuan", ""], ["Ye", "Feng", ""], ["Chen", "Xuejiao", ""]]}, {"id": "2103.05292", "submitter": "Yue Liu", "authors": "Yue Liu, Chakkrit Tantithamthavorn, Li Li and Yepang Liu", "title": "Deep Learning for Android Malware Defenses: a Systematic Literature\n  Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malicious applications (especially in the Android platform) are a serious\nthreat to developers and end-users. Many research efforts have hence been\ndevoted to developing effective approaches to defend Android malware. However,\nwith the explosive growth of Android malware and the continuous advancement of\nmalicious evasion technologies like obfuscation and reflection, android malware\ndefenses based on manual rules or traditional machine learning may not be\neffective due to limited apriori knowledge. In recent years, a dominant\nresearch field of deep learning (DL) with the powerful feature abstraction\nability has demonstrated a compelling and promising performance in various\nfields, like Nature Language processing and image processing. To this end,\nemploying deep learning techniques to thwart the attack of Android malware has\nrecently gained considerable research attention. Yet, there exists no\nsystematic literature review that focuses on deep learning approaches for\nAndroid Malware defenses. In this paper, we conducted a systematic literature\nreview to search and analyze how deep learning approaches have been applied in\nthe context of malware defenses in the Android environment. As a result, a\ntotal of 104 studies were identified over the period 2014-2020. The results of\nour investigation show that even though most of these studies still mainly\nconsider DL-based on Android malware detection, 35 primary studies (33.7\\%)\ndesign the defenses approaches based on other scenarios. This review also\ndescribes research trends, research focuses, challenges, and future research\ndirections in DL-based Android malware defenses.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 08:33:08 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Liu", "Yue", ""], ["Tantithamthavorn", "Chakkrit", ""], ["Li", "Li", ""], ["Liu", "Yepang", ""]]}, {"id": "2103.05354", "submitter": "Ahmed Aldahdooh", "authors": "Ahmed Aldahdooh, Wassim Hamidouche, and Olivier D\\'eforges", "title": "Revisiting Model's Uncertainty and Confidences for Adversarial Example\n  Detection", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Security-sensitive applications that rely on Deep Neural Networks (DNNs) are\nvulnerable to small perturbations that are crafted to generate Adversarial\nExamples(AEs). The AEs are imperceptible to humans and cause DNN to misclassify\nthem. Many defense and detection techniques have been proposed. Model's\nconfidences and Dropout, as a popular way to estimate the model's uncertainty,\nhave been used for AE detection but they showed limited success against black-\nand gray-box attacks. Moreover, the state-of-the-art detection techniques have\nbeen designed for specific attacks or broken by others, need knowledge about\nthe attacks, are not consistent, increase model parameters overhead, are\ntime-consuming, or have latency in inference time. To trade off these factors,\nwe revisit the model's uncertainty and confidences and propose a novel\nunsupervised ensemble AE detection mechanism that 1) uses the uncertainty\nmethod called SelectiveNet, 2) processes model layers outputs, i.e.feature\nmaps, to generate new confidence probabilities. The detection method is called\nSelective and Feature based Adversarial Detection (SFAD). Experimental results\nshow that the proposed approach achieves better performance against black- and\ngray-box attacks than the state-of-the-art methods and achieves comparable\nperformance against white-box attacks. Moreover, results show that SFAD is\nfully robust against High Confidence Attacks (HCAs) for MNIST and partially\nrobust for CIFAR10 datasets.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 11:06:15 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 15:21:49 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Aldahdooh", "Ahmed", ""], ["Hamidouche", "Wassim", ""], ["D\u00e9forges", "Olivier", ""]]}, {"id": "2103.05469", "submitter": "Mark Stamp", "authors": "Andy Phung and Mark Stamp", "title": "Universal Adversarial Perturbations and Image Spam Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the name suggests, image spam is spam email that has been embedded in an\nimage. Image spam was developed in an effort to evade text-based filters.\nModern deep learning-based classifiers perform well in detecting typical image\nspam that is seen in the wild. In this chapter, we evaluate numerous\nadversarial techniques for the purpose of attacking deep learning-based image\nspam classifiers. Of the techniques tested, we find that universal perturbation\nperforms best. Using universal adversarial perturbations, we propose and\nanalyze a new transformation-based adversarial attack that enables us to create\ntailored \"natural perturbations\" in image spam. The resulting spam images\nbenefit from both the presence of concentrated natural features and a universal\nadversarial perturbation. We show that the proposed technique outperforms\nexisting adversarial attacks in terms of accuracy reduction, computation time\nper example, and perturbation distance. We apply our technique to create a\ndataset of adversarial spam images, which can serve as a challenge dataset for\nfuture research in image spam detection.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2021 14:36:02 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Phung", "Andy", ""], ["Stamp", "Mark", ""]]}, {"id": "2103.05472", "submitter": "Tao Li", "authors": "Tao Li, Chris Clifton", "title": "Differentially Private Imaging via Latent Space Manipulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing concern about image privacy due to the popularity of social\nmedia and photo devices, along with increasing use of face recognition systems.\nHowever, established image de-identification techniques are either too subject\nto re-identification, produce photos that are insufficiently realistic, or\nboth. To tackle this, we present a novel approach for image obfuscation by\nmanipulating latent spaces of an unconditionally trained generative model that\nis able to synthesize photo-realistic facial images of high resolution. This\nmanipulation is done in a way that satisfies the formal privacy standard of\nlocal differential privacy. To our knowledge, this is the first approach to\nimage privacy that satisfies $\\varepsilon$-differential privacy \\emph{for the\nperson.}\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 17:32:08 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 06:27:26 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Li", "Tao", ""], ["Clifton", "Chris", ""]]}, {"id": "2103.05476", "submitter": "Gianluca Stringhini", "authors": "Yun Shen and Gianluca Stringhini", "title": "ANDRUSPEX : Leveraging Graph Representation Learning to Predict Harmful\n  App Installations on Mobile Devices", "comments": "Accepted to appear in the Proceedings of the 2021 IEEE European\n  Symposium on Security and Privacy (EUROS&P)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android's security model severely limits the capabilities of anti-malware\nsoftware. Unlike commodity anti-malware solutions on desktop systems, their\nAndroid counterparts run as sandboxed applications without root privileges and\nare limited by Android's permission system. As such, PHAs on Android are\nusually willingly installed by victims, as they come disguised as useful\napplications with hidden malicious functionality, and are encountered on mobile\napp stores as suggestions based on the apps that a user previously installed.\nUsers with similar interests and app installation history are likely to be\nexposed and to decide to install the same PHA. This observation gives us the\nopportunity to develop predictive approaches that can warn the user about which\nPHAs they will encounter and potentially be tempted to install in the near\nfuture. These approaches could then be used to complement commodity\nanti-malware solutions, which are focused on post-fact detection, closing the\nwindow of opportunity that existing solutions suffer from. In this paper we\ndevelop Andruspex, a system based on graph representation learning, allowing us\nto learn latent relationships between user devices and PHAs and leverage them\nfor prediction. We test Andruspex on a real world dataset of PHA installations\ncollected by a security company, and show that our approach achieves very high\nprediction results (up to 0.994 TPR at 0.0001 FPR), while at the same time\noutperforming alternative baseline methods. We also demonstrate that Andruspex\nis robust and its runtime performance is acceptable for a real world\ndeployment.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 15:07:48 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 12:45:16 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Shen", "Yun", ""], ["Stringhini", "Gianluca", ""]]}, {"id": "2103.05544", "submitter": "Felix Engelmann", "authors": "Dominik Mei{\\ss}ner, Felix Engelmann, Frank Kargl, Benjamin Erb", "title": "PeQES: A Platform for Privacy-enhanced Quantitative Empirical Studies", "comments": "To be published in the 36th ACM/SIGAPP Symposium on Applied Computing\n  (SAC '21)", "journal-ref": null, "doi": "10.1145/3412841.3441997", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Empirical sciences and in particular psychology suffer a methodological\ncrisis due to the non-reproducibility of results, and in rare cases,\nquestionable research practices. Pre-registered studies and the publication of\nraw data sets have emerged as effective countermeasures. However, this approach\nrepresents only a conceptual procedure and may in some cases exacerbate privacy\nissues associated with data publications. We establish a novel,\nprivacy-enhanced workflow for pre-registered studies. We also introduce PeQES,\na corresponding platform that technically enforces the appropriate execution\nwhile at the same time protecting the participants' data from unauthorized use\nor data repurposing. Our PeQES prototype proves the overall feasibility of our\nprivacy-enhanced workflow while introducing only a negligible performance\noverhead for data acquisition and data analysis of an actual study. Using\ntrusted computing mechanisms, PeQES is the first platform to enable\nprivacy-enhanced studies, to ensure the integrity of study protocols, and to\nsafeguard the confidentiality of participants' data at the same time.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 16:46:25 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Mei\u00dfner", "Dominik", ""], ["Engelmann", "Felix", ""], ["Kargl", "Frank", ""], ["Erb", "Benjamin", ""]]}, {"id": "2103.05590", "submitter": "Mehdi Yadollahi", "authors": "Mohammad Mehdi Yadollahi, Farzaneh Shoeleh, Sajjad Dadkhah, Ali A.\n  Ghorbani", "title": "Robust Black-box Watermarking for Deep NeuralNetwork using Inverse\n  Document Frequency", "comments": "This manuscript is submitted to computer & security journal on Sep\n  26th. It has 13 pages, 8 figures and 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep learning techniques are one of the most significant elements of any\nArtificial Intelligence (AI) services. Recently, these Machine Learning (ML)\nmethods, such as Deep Neural Networks (DNNs), presented exceptional achievement\nin implementing human-level capabilities for various predicaments, such as\nNatural Processing Language (NLP), voice recognition, and image processing,\netc. Training these models are expensive in terms of computational power and\nthe existence of enough labelled data. Thus, ML-based models such as DNNs\nestablish genuine business value and intellectual property (IP) for their\nowners. Therefore the trained models need to be protected from any adversary\nattacks such as illegal redistribution, reproducing, and derivation.\nWatermarking can be considered as an effective technique for securing a DNN\nmodel. However, so far, most of the watermarking algorithm focuses on\nwatermarking the DNN by adding noise to an image. To this end, we propose a\nframework for watermarking a DNN model designed for a textual domain. The\nwatermark generation scheme provides a secure watermarking method by combining\nTerm Frequency (TF) and Inverse Document Frequency (IDF) of a particular word.\nThe proposed embedding procedure takes place in the model's training time,\nmaking the watermark verification stage straightforward by sending the\nwatermarked document to the trained model. The experimental results show that\nwatermarked models have the same accuracy as the original ones. The proposed\nframework accurately verifies the ownership of all surrogate models without\nimpairing the performance. The proposed algorithm is robust against well-known\nattacks such as parameter pruning and brute force attack.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 17:56:04 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Yadollahi", "Mohammad Mehdi", ""], ["Shoeleh", "Farzaneh", ""], ["Dadkhah", "Sajjad", ""], ["Ghorbani", "Ali A.", ""]]}, {"id": "2103.05633", "submitter": "Mohammad Yaghini", "authors": "Hengrui Jia, Mohammad Yaghini, Christopher A. Choquette-Choo, Natalie\n  Dullerud, Anvith Thudi, Varun Chandrasekaran, Nicolas Papernot", "title": "Proof-of-Learning: Definitions and Practice", "comments": "To appear in the 42nd IEEE Symposium on Security and Privacy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training machine learning (ML) models typically involves expensive iterative\noptimization. Once the model's final parameters are released, there is\ncurrently no mechanism for the entity which trained the model to prove that\nthese parameters were indeed the result of this optimization procedure. Such a\nmechanism would support security of ML applications in several ways. For\ninstance, it would simplify ownership resolution when multiple parties contest\nownership of a specific model. It would also facilitate the distributed\ntraining across untrusted workers where Byzantine workers might otherwise mount\na denial-of-service by returning incorrect model updates.\n  In this paper, we remediate this problem by introducing the concept of\nproof-of-learning in ML. Inspired by research on both proof-of-work and\nverified computations, we observe how a seminal training algorithm, stochastic\ngradient descent, accumulates secret information due to its stochasticity. This\nproduces a natural construction for a proof-of-learning which demonstrates that\na party has expended the compute require to obtain a set of model parameters\ncorrectly. In particular, our analyses and experiments show that an adversary\nseeking to illegitimately manufacture a proof-of-learning needs to perform *at\nleast* as much work than is needed for gradient descent itself.\n  We also instantiate a concrete proof-of-learning mechanism in both of the\nscenarios described above. In model ownership resolution, it protects the\nintellectual property of models released publicly. In distributed training, it\npreserves availability of the training procedure. Our empirical evaluation\nvalidates that our proof-of-learning mechanism is robust to variance induced by\nthe hardware (ML accelerators) and software stacks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 18:59:54 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Jia", "Hengrui", ""], ["Yaghini", "Mohammad", ""], ["Choquette-Choo", "Christopher A.", ""], ["Dullerud", "Natalie", ""], ["Thudi", "Anvith", ""], ["Chandrasekaran", "Varun", ""], ["Papernot", "Nicolas", ""]]}, {"id": "2103.05758", "submitter": "Siqi Ma", "authors": "Siqi Ma, Juanru Li, Hyoungshick Kim, Elisa Bertino, Surya Nepal,\n  Diethelm Ostry, Cong Sun", "title": "Fine with \"1234\"? An Analysis of SMS One-Time Password Randomness in\n  Android Apps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental premise of SMS One-Time Password (OTP) is that the used\npseudo-random numbers (PRNs) are uniquely unpredictable for each login session.\nHence, the process of generating PRNs is the most critical step in the OTP\nauthentication. An improper implementation of the pseudo-random number\ngenerator (PRNG) will result in predictable or even static OTP values, making\nthem vulnerable to potential attacks. In this paper, we present a vulnerability\nstudy against PRNGs implemented for Android apps. A key challenge is that PRNGs\nare typically implemented on the server-side, and thus the source code is not\naccessible. To resolve this issue, we build an analysis tool, \\sysname, to\nassess implementations of the PRNGs in an automated manner without the source\ncode requirement. Through reverse engineering, \\sysname identifies the apps\nusing SMS OTP and triggers each app's login functionality to retrieve OTP\nvalues. It further assesses the randomness of the OTP values to identify\nvulnerable PRNGs. By analyzing 6,431 commercially used Android apps downloaded\nfrom \\tool{Google Play} and \\tool{Tencent Myapp}, \\sysname identified 399\nvulnerable apps that generate predictable OTP values. Even worse, 194\nvulnerable apps use the OTP authentication alone without any additional\nsecurity mechanisms, leading to insecure authentication against guessing\nattacks and replay attacks.\n", "versions": [{"version": "v1", "created": "Sat, 6 Mar 2021 09:44:58 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Ma", "Siqi", ""], ["Li", "Juanru", ""], ["Kim", "Hyoungshick", ""], ["Bertino", "Elisa", ""], ["Nepal", "Surya", ""], ["Ostry", "Diethelm", ""], ["Sun", "Cong", ""]]}, {"id": "2103.05759", "submitter": "Mark Stamp", "authors": "Sunhera Paul and Mark Stamp", "title": "Word Embedding Techniques for Malware Evolution Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Malware detection is a critical aspect of information security. One\ndifficulty that arises is that malware often evolves over time. To maintain\neffective malware detection, it is necessary to determine when malware\nevolution has occurred so that appropriate countermeasures can be taken. We\nperform a variety of experiments aimed at detecting points in time where a\nmalware family has likely evolved, and we consider secondary tests designed to\nconfirm that evolution has actually occurred. Several malware families are\nanalyzed, each of which includes a number of samples collected over an extended\nperiod of time. Our experiments indicate that improved results are obtained\nusing feature engineering based on word embedding techniques. All of our\nexperiments are based on machine learning models, and hence our evolution\ndetection strategies require minimal human intervention and can easily be\nautomated.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2021 14:55:32 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Paul", "Sunhera", ""], ["Stamp", "Mark", ""]]}, {"id": "2103.05761", "submitter": "Mark Stamp", "authors": "Samanvitha Basole and Mark Stamp", "title": "Cluster Analysis of Malware Family Relationships", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we use $K$-means clustering to analyze various relationships\nbetween malware samples. We consider a dataset comprising~20 malware families\nwith~1000 samples per family. These families can be categorized into seven\ndifferent types of malware. We perform clustering based on pairs of families\nand use the results to determine relationships between families. We perform a\nsimilar cluster analysis based on malware type. Our results indicate that\n$K$-means clustering can be a powerful tool for data exploration of malware\nfamily relationships.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2021 14:51:01 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Basole", "Samanvitha", ""], ["Stamp", "Mark", ""]]}, {"id": "2103.05762", "submitter": "Anton Tkachenko", "authors": "P. Ellingsen, C. Riera, P. Stanica, A. Tkachenko", "title": "An extension of the avalanche criterion in the context of\n  c-differentials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.CO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The Strict Avalanche Criterion (SAC) is a property of vectorial Boolean\nfunctions that is used in the construction of strong S-boxes. We show in this\npaper how to generalize the concept of SAC to address possible c-differential\nattacks, in the realm of finite fields. We define the concepts of c-Strict\nAvalanche Criterion (c-SAC) and c-Strict Avalanche Criterion of order m\n(c-SAC(m)), and generalize results of (Li and Cusick, 2005). We also show\ncomputationally how the new definition is not equivalent to the existing\nconcepts of c-bent1-ness (Stanica et al., 2020), nor (for n = m) PcN-ness\n(Ellingsen et al., 2020)\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 14:25:28 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Ellingsen", "P.", ""], ["Riera", "C.", ""], ["Stanica", "P.", ""], ["Tkachenko", "A.", ""]]}, {"id": "2103.05763", "submitter": "Mark Stamp", "authors": "Aniket Chandak and Wendy Lee and Mark Stamp", "title": "A Comparison of Word2Vec, HMM2Vec, and PCA2Vec for Malware\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Word embeddings are often used in natural language processing as a means to\nquantify relationships between words. More generally, these same word embedding\ntechniques can be used to quantify relationships between features. In this\npaper, we first consider multiple different word embedding techniques within\nthe context of malware classification. We use hidden Markov models to obtain\nembedding vectors in an approach that we refer to as HMM2Vec, and we generate\nvector embeddings based on principal component analysis. We also consider the\npopular neural network based word embedding technique known as Word2Vec. In\neach case, we derive feature embeddings based on opcode sequences for malware\nsamples from a variety of different families. We show that we can obtain better\nclassification accuracy based on these feature embeddings, as compared to HMM\nexperiments that directly use the opcode sequences, and serve to establish a\nbaseline. These results show that word embeddings can be a useful feature\nengineering step in the field of malware analysis.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2021 14:41:18 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Chandak", "Aniket", ""], ["Lee", "Wendy", ""], ["Stamp", "Mark", ""]]}, {"id": "2103.05767", "submitter": "Shao-En Weng", "authors": "Lei Chen, Shao-En Weng, Chu-Jun Peng, Hong-Han Shuai, and Wen-Huang\n  Cheng", "title": "ZYELL-NCTU NetTraffic-1.0: A Large-Scale Dataset for Real-World Network\n  Anomaly Detection", "comments": "2 pages, 3 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network security has been an active research topic for long. One critical\nissue is improving the anomaly detection capability of intrusion detection\nsystems (IDSs), such as firewalls. However, existing network anomaly datasets\nare out of date (i.e., being collected many years ago) or IP-anonymized, making\nthe data characteristics differ from today's network. Therefore, this work\nintroduces a new, large-scale, and real-world dataset, ZYELL-NCTU\nNetTraffic-1.0, which is collected from the raw output of firewalls in a real\nnetwork, with the objective to advance the development of network security\nresearches.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 15:18:29 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Chen", "Lei", ""], ["Weng", "Shao-En", ""], ["Peng", "Chu-Jun", ""], ["Shuai", "Hong-Han", ""], ["Cheng", "Wen-Huang", ""]]}, {"id": "2103.05769", "submitter": "Gabriel Ferreira", "authors": "Gabriel Ferreira, Limin Jia, Joshua Sunshine, Christian K\\\"astner", "title": "Containing Malicious Package Updates in npm with a Lightweight\n  Permission System", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large amount of third-party packages available in fast-moving software\necosystems, such as Node.js/npm, enables attackers to compromise applications\nby pushing malicious updates to their package dependencies. Studying the npm\nrepository, we observed that many packages in the npm repository that are used\nin Node.js applications perform only simple computations and do not need access\nto filesystem or network APIs. This offers the opportunity to enforce\nleast-privilege design per package, protecting applications and package\ndependencies from malicious updates. We propose a lightweight permission system\nthat protects Node.js applications by enforcing package permissions at runtime.\nWe discuss the design space of solutions and show that our system makes a large\nnumber of packages much harder to be exploited, almost for free.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 01:49:30 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Ferreira", "Gabriel", ""], ["Jia", "Limin", ""], ["Sunshine", "Joshua", ""], ["K\u00e4stner", "Christian", ""]]}, {"id": "2103.05789", "submitter": "Quanyan Zhu", "authors": "Quanyan Zhu, Stefan Rass, Bernhard Dieber, Victor Mayoral Vilches", "title": "Cybersecurity in Robotics: Challenges, Quantitative Modeling, and\n  Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robotics is becoming more and more ubiquitous, but the pressure to bring\nsystems to market occasionally goes at the cost of neglecting security\nmechanisms during the development, deployment or while in production. As a\nresult, contemporary robotic systems are vulnerable to diverse attack patterns,\nand an a posteriori hardening is at least challenging, if not impossible at\nall. This book aims to stipulate the inclusion of security in robotics from the\nearliest design phases onward and with a special focus on the cost-benefit\ntradeoff that can otherwise be an inhibitor for the fast development of\naffordable systems. We advocate quantitative methods of security management and\ndesign, covering vulnerability scoring systems tailored to robotic systems, and\naccounting for the highly distributed nature of robots as an interplay of\npotentially very many components. A powerful quantitative approach to\nmodel-based security is offered by game theory, providing a rich spectrum of\ntechniques to optimize security against various kinds of attacks. Such a\nmulti-perspective view on security is necessary to address the heterogeneity\nand complexity of robotic systems. This book is intended as an accessible\nstarter for the theoretician and practitioner working in the field.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 23:54:44 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 03:22:50 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 19:07:31 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Zhu", "Quanyan", ""], ["Rass", "Stefan", ""], ["Dieber", "Bernhard", ""], ["Vilches", "Victor Mayoral", ""]]}, {"id": "2103.05792", "submitter": "Masoumeh Shafieinejad", "authors": "Masoumeh Shafieinejad (1) and Suraj Gupta (1) and Jin Yang Liu (1) and\n  Koray Karabina (2) and Florian Kerschbaum (1) ((1) University of Waterloo,\n  (2) National Research Council of Canada)", "title": "Equi-Joins Over Encrypted Data for Series of Queries", "comments": "13 pages, 4 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Encryption provides a method to protect data outsourced to a DBMS provider,\ne.g., in the cloud. However, performing database operations over encrypted data\nrequires specialized encryption schemes that carefully balance security and\nperformance. In this paper, we present a new encryption scheme that can\nefficiently perform equi-joins over encrypted data with better security than\nthe state-of-the-art. In particular, our encryption scheme reduces the leakage\nto equality of rows that match a selection criterion and only reveals the\ntransitive closure of the sum of the leakages of each query in a series of\nqueries. Our encryption scheme is provable secure. We implemented our\nencryption scheme and evaluated it over a dataset from the TPC-H benchmark.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 00:07:33 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Shafieinejad", "Masoumeh", ""], ["Gupta", "Suraj", ""], ["Liu", "Jin Yang", ""], ["Karabina", "Koray", ""], ["Kerschbaum", "Florian", ""]]}, {"id": "2103.05833", "submitter": "Mengce Zheng", "authors": "Zhimin Luo and Mengce Zheng and Ping Wang and Minhui Jin and Jiajia\n  Zhang and Honggang Hu", "title": "Towards Strengthening Deep Learning-based Side Channel Attacks with\n  Mixup", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, various deep learning techniques have been exploited in side\nchannel attacks, with the anticipation of obtaining more appreciable attack\nresults. Most of them concentrate on improving network architectures or putting\nforward novel algorithms, assuming that there are adequate profiling traces\navailable to train an appropriate neural network. However, in practical\nscenarios, profiling traces are probably insufficient, which makes the network\nlearn deficiently and compromises attack performance.\n  In this paper, we investigate a kind of data augmentation technique, called\nmixup, and first propose to exploit it in deep-learning based side channel\nattacks, for the purpose of expanding the profiling set and facilitating the\nchances of mounting a successful attack. We perform Correlation Power Analysis\nfor generated traces and original traces, and discover that there exists\nconsistency between them regarding leakage information. Our experiments show\nthat mixup is truly capable of enhancing attack performance especially for\ninsufficient profiling traces. Specifically, when the size of the training set\nis decreased to 30% of the original set, mixup can significantly reduce\nacquired attacking traces. We test three mixup parameter values and conclude\nthat generally all of them can bring about improvements. Besides, we compare\nthree leakage models and unexpectedly find that least significant bit model,\nwhich is less frequently used in previous works, actually surpasses prevalent\nidentity model and hamming weight model in terms of attack results.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 02:32:33 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 14:29:02 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Luo", "Zhimin", ""], ["Zheng", "Mengce", ""], ["Wang", "Ping", ""], ["Jin", "Minhui", ""], ["Zhang", "Jiajia", ""], ["Hu", "Honggang", ""]]}, {"id": "2103.05840", "submitter": "Habiba Farrukh", "authors": "Habiba Farrukh, Tinghan Yang, Hanwen Xu, Yuxuan Yin, He Wang, Z.\n  Berkay Celik", "title": "S3: Side-Channel Attack on Stylus Pencil through Sensors", "comments": "25 pages", "journal-ref": null, "doi": "10.1145/3448085", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With smart devices being an essential part of our everyday lives,\nunsupervised access to the mobile sensors' data can result in a multitude of\nside-channel attacks. In this paper, we study potential data leaks from Apple\nPencil (2nd generation) supported by the Apple iPad Pro, the latest stylus pen\nwhich attaches to the iPad body magnetically for charging. We observe that the\nPencil's body affects the magnetic readings sensed by the iPad's magnetometer\nwhen a user is using the Pencil. Therefore, we ask: Can we infer what a user is\nwriting on the iPad screen with the Apple Pencil, given access to only the\niPad's motion sensors' data? To answer this question, we present Side-channel\nattack on Stylus pencil through Sensors (S3), a system that identifies what a\nuser is writing from motion sensor readings. We first use the sharp\nfluctuations in the motion sensors' data to determine when a user is writing on\nthe iPad. We then introduce a high-dimensional particle filter to track the\nlocation and orientation of the Pencil during usage. Lastly, to guide\nparticles, we build the Pencil's magnetic map serving as a bridge between the\nmeasured magnetic data and the Pencil location and orientation. We evaluate S3\nwith 10 subjects and demonstrate that we correctly identify 93.9%, 96%, 97.9%,\nand 93.33% of the letters, numbers, shapes, and words by only having access to\nthe motion sensors' data.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 03:05:42 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Farrukh", "Habiba", ""], ["Yang", "Tinghan", ""], ["Xu", "Hanwen", ""], ["Yin", "Yuxuan", ""], ["Wang", "He", ""], ["Celik", "Z. Berkay", ""]]}, {"id": "2103.05854", "submitter": "Zhang Pingchuan", "authors": "Dongdong Zhao, Pingchuan Zhang, Jianwen Xiang, Jing Tian", "title": "NegDL: Privacy-Preserving Deep Learning Based on Negative Database", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of big data, deep learning has become an increasingly popular\ntopic. It has outstanding achievements in the fields of image recognition,\nobject detection, and natural language processing et al. The first priority of\ndeep learning is exploiting valuable information from a large amount of data,\nwhich will inevitably induce privacy issues that are worthy of attention.\nPresently, several privacy-preserving deep learning methods have been proposed,\nbut most of them suffer from a non-negligible degradation of either efficiency\nor accuracy. Negative database (\\textit{NDB}) is a new type of data\nrepresentation which can protect data privacy by storing and utilizing the\ncomplementary form of original data. In this paper, we propose a\nprivacy-preserving deep learning method named NegDL based on \\textit{NDB}.\nSpecifically, private data are first converted to \\textit{NDB} as the input of\ndeep learning models by a generation algorithm called \\textit{QK}-hidden\nalgorithm, and then the sketches of \\textit{NDB} are extracted for training and\ninference. We demonstrate that the computational complexity of NegDL is the\nsame as the original deep learning model without privacy protection.\nExperimental results on Breast Cancer, MNIST, and CIFAR-10 benchmark datasets\ndemonstrate that the accuracy of NegDL could be comparable to the original deep\nlearning model in most cases, and it performs better than the method based on\ndifferential privacy.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 03:34:03 GMT"}, {"version": "v2", "created": "Sun, 25 Apr 2021 03:05:46 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Zhao", "Dongdong", ""], ["Zhang", "Pingchuan", ""], ["Xiang", "Jianwen", ""], ["Tian", "Jing", ""]]}, {"id": "2103.05873", "submitter": "Regio Michelin", "authors": "Nadeem Ahmed, Regio A. Michelin, Wanli Xue, Guntur Dharma Putra,\n  Sushmita Ruj, Salil S. Kanhere, Sanjay Jha", "title": "DIMY: Enabling Privacy-preserving Contact Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The infection rate of COVID-19 and lack of an approved vaccine has forced\ngovernments and health authorities to adopt lockdowns, increased testing, and\ncontact tracing to reduce the spread of the virus. Digital contact tracing has\nbecome a supplement to the traditional manual contact tracing process. However,\nalthough there have been a number of digital contact tracing apps proposed and\ndeployed, these have not been widely adopted owing to apprehensions surrounding\nprivacy and security. In this paper, we propose a blockchain-based\nprivacy-preserving contact tracing protocol, \"Did I Meet You\" (DIMY), that\nprovides full-lifecycle data privacy protection on the devices themselves as\nwell as on the back-end servers, to address most of the privacy concerns\nassociated with existing protocols. We have employed Bloom filters to provide\nefficient privacy-preserving storage, and have used the Diffie-Hellman key\nexchange for secret sharing among the participants. We show that DIMY provides\nresilience against many well known attacks while introducing negligible\noverheads. DIMY's footprint on the storage space of clients' devices and\nback-end servers is also significantly lower than other similar state of the\nart apps.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 05:13:25 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Ahmed", "Nadeem", ""], ["Michelin", "Regio A.", ""], ["Xue", "Wanli", ""], ["Putra", "Guntur Dharma", ""], ["Ruj", "Sushmita", ""], ["Kanhere", "Salil S.", ""], ["Jha", "Sanjay", ""]]}, {"id": "2103.06039", "submitter": "Sandip Ghosal", "authors": "Sandip Ghosal and R. K. Shyamasundar", "title": "Pifthon: A Compile-Time Information Flow Analyzer For An Imperative\n  Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Compile-time information flow analysis has been a promising technique for\nprotecting confidentiality and integrity of private data. In the last couple of\ndecades, a large number of information flow security tools in the form of\nrun-time execution-monitors or static type systems have been developed for\nprogramming languages to analyze information flow security policies. However,\nexisting flow analysis tools lack in precision and usability, which is the\nprimary reason behind not being widely adopted in real application development.\nIn this paper, we propose a compile-time information flow analysis for an\nimperative program based on a hybrid (mutable + immutable) labelling approach\nthat enables a user to detect information flow-policy breaches and modify the\nprogram to overcome violations. We have developed an information flow security\nanalyzer for a dialect of Python language, PyX, called Pifthon using the said\napproach. The flow-analyzer aids in identifying possible misuse of the\ninformation in sequential PyX programs corresponding to a given information\nflow policy (IFP). Pifthon has distinct advantages like reduced labelling\noverhead that ameliorates usability, covers a wide range of PyX programs that\ninclude termination-and progress-sensitive channels, in contrast to other\napproaches in the literature. The proposed flow analysis is proved to be sound\nunder the classical non-interference property. Further, case study and\nexperience in the usage of Pifthon are provided.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 13:19:27 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Ghosal", "Sandip", ""], ["Shyamasundar", "R. K.", ""]]}, {"id": "2103.06091", "submitter": "Yuriy Brun", "authors": "Yuriy Brun, Tian Lin, Jessie Elise Somerville, Elisha Myers, Natalie\n  C. Ebner", "title": "Blindspots in Python and Java APIs Result in Vulnerable Code", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Blindspots in APIs can cause software engineers to introduce vulnerabilities,\nbut such blindspots are, unfortunately, common. We study the effect APIs with\nblindspots have on developers in two languages by replicating an 109-developer,\n24-Java-API controlled experiment. Our replication applies to Python and\ninvolves 129 new developers and 22 new APIs. We find that using APIs with\nblindspots statistically significantly reduces the developers' ability to\ncorrectly reason about the APIs in both languages, but that the effect is more\npronounced for Python. Interestingly, for Java, the effect increased with\ncomplexity of the code relying on the API, whereas for Python, the opposite was\ntrue. Whether the developers considered API uses to be more difficult, less\nclear, and less familiar did not have an effect on their ability to correctly\nreason about them. Developers with better long-term memory recall were more\nlikely to correctly reason about APIs with blindspots, but short-term memory,\nprocessing speed, episodic memory, and memory span had no effect. Surprisingly,\nprofessional experience and expertice did not improve the developers' ability\nto reason about APIs with blindspots across both languages, with long-term\nprofessionals with many years of experience making mistakes as often as\nrelative novices. Finally, personality traits did not significantly affect the\nPython developers' ability to reason about APIs with blindspots, but less\nextraverted and more open developers were better at reasoning about Java APIs\nwith blindspots. Overall, our findings suggest that blindspots in APIs are a\nserious problem across languages, and that experience and education alone do\nnot overcome that problem, suggesting that tools are needed to help developers\nrecognize blindspots in APIs as they write code that uses those APIs.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 14:44:19 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Brun", "Yuriy", ""], ["Lin", "Tian", ""], ["Somerville", "Jessie Elise", ""], ["Myers", "Elisha", ""], ["Ebner", "Natalie C.", ""]]}, {"id": "2103.06169", "submitter": "Riccardo Aragona", "authors": "Riccardo Aragona and Roberto Civino and Francesca Dalla Volta", "title": "On the primitivity of the AES key-schedule", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key-scheduling algorithm in the AES is the component responsible for\nselecting from the master key the sequence of round keys to be xor-ed to the\npartially encrypted state at each iteration. We consider here the group\n$\\Gamma$ generated by the action of the AES-128 key-scheduling operation, and\nwe prove that the smallest group containing $\\Gamma$ and all the translations\nof the message space is primitive. As a consequence, we obtain that no proper\nand non-trivial subspace can be invariant under its action.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 16:36:52 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Aragona", "Riccardo", ""], ["Civino", "Roberto", ""], ["Volta", "Francesca Dalla", ""]]}, {"id": "2103.06170", "submitter": "Majid Salimi", "authors": "Majid Salimi, Hamid Mala, Honorio Martin and Pedro Peris-Lopez", "title": "Full-Resilient Memory-Optimum Multi-Party Non-Interactive Key Exchange", "comments": "14 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-Party Non-Interactive Key Exchange (MP-NIKE) is a fundamental\ncryptographic primitive in which users register into a key generation centre\nand receive a public/private key pair each. After that, any subset of these\nusers can compute a shared key without any interaction. Nowadays, IoT devices\nsuffer from a high number and large size of messages exchanged in the Key\nManagement Protocol (KMP). To overcome this, an MP-NIKE scheme can eliminate\nthe airtime and latency of messages transferred between IoT devices. MP-NIKE\nschemes can be realized by using multilinear maps. There are several attempts\nfor constructing multilinear maps based on indistinguishable obfuscation,\nlattices and the Chinese Remainder Theorem (CRT). Nevertheless, these schemes\nare inefficient in terms of computation cost and memory overhead. Besides,\nseveral attacks have been recently reported against CRT-based and lattice-based\nmultilinear maps. There is only one modular exponentiation-based MP-NIKE scheme\nin the literature which has been claimed to be both secure and efficient. In\nthis article, we present an attack on this scheme based on the Euclidean\nalgorithm, in which two colluding users can obtain the shared key of any\narbitrary subgroup of users. We also propose an efficient and secure MP-NIKE\nscheme. We show how our proposal is secure in the random oracle model assuming\nthe hardness of the root extraction modulo a composite number.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 16:41:53 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Salimi", "Majid", ""], ["Mala", "Hamid", ""], ["Martin", "Honorio", ""], ["Peris-Lopez", "Pedro", ""]]}, {"id": "2103.06184", "submitter": "Shin Wang", "authors": "Shen Wang, Ehsan Toreini, Feng Hao", "title": "Anti-Counterfeiting for Polymer Banknotes Based on Polymer Substrate\n  Fingerprinting", "comments": "13 pages, 11 figures, 6 tables. This manuscript has been accepted for\n  publication in IEEE Transactions on Information Forensics & Security in 2021", "journal-ref": null, "doi": "10.1109/TIFS.2021.3067440", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polymer banknotes are the trend for printed currency and have been adopted by\nmore than fifty countries worldwide. However, over the past years, the quantity\nof polymer counterfeits has been increasing, so has the quality of\ncounterfeits. This shows that the initial advantage of bringing a new polymer\ntechnology to fight against counterfeiting is reducing. To maintain one step\nahead of counterfeiters, we propose a novel anti-counterfeiting technique\ncalled Polymer Substrate Fingerprinting (PSF). Our technique is built based on\nthe observation that the opacity coating, a critical step during the production\nof polymer notes, is a stochastic manufacturing process, leaving uneven\nthickness in the coating layer and the random dispersion of impurities from the\nink. The imperfections in the coating layer result in random translucent\npatterns when a polymer banknote is back-lit by a light source. We show these\npatterns can be reliably captured by a commodity negative-film scanner and\nprocessed into a compact fingerprint to uniquely identify each banknote. Using\nan extensive dataset of 6,200 sample images collected from 340 UK banknotes, we\nshow that our method can reliably authenticate banknotes, and is robust against\nrough daily handling of banknotes. Furthermore, we show the extracted\nfingerprints contain around 900 bits of entropy, which makes it extremely\nscalable to identify every polymer note circulated globally. As compared with\nprevious or existing anti-counterfeiting mechanisms for banknotes, our method\nhas a distinctive advantage: it ensures that even in the extreme case when\ncounterfeiters have procured the same printing equipment and ink as used by a\nlegitimate government, counterfeiting banknotes remains infeasible because of\nthe difficulty to replicate a stochastic manufacturing process.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 17:02:54 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 18:33:23 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Wang", "Shen", ""], ["Toreini", "Ehsan", ""], ["Hao", "Feng", ""]]}, {"id": "2103.06221", "submitter": "Pietro Tedeschi", "authors": "Pietro Tedeschi and Kang Eun Jeon and James She and Simon Wong and\n  Spiridon Bakiras and Roberto Di Pietro", "title": "Privacy-Preserving and Sustainable Contact Tracing Using Batteryless BLE\n  Beacons", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Contact tracing with mobile applications is an attractive approach for many\ngovernments and industry initiatives to address the Covid-19 pandemic. However,\nmany approaches today have severe privacy and security issues, and many of them\nalso fail to offer a sustainable contact tracing infrastructure due to the\ndemanding energy consumption. This work makes several contributions towards\novercoming these limitations. First, we propose a privacy-preserving\narchitecture for contact tracing that leverages a fixed infrastructure of BLE\nbeacon transmitters. Second, we evaluate the feasibility of adopting\nbatteryless or energy-harvesting BLE beacons to make this architecture more\nsustainable and green. Finally, we identify practical research challenges and\nopportunities for academia and industry to advance and realize the proposed\nprivacy-preserving and sustainable contact tracing architecture.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 17:45:20 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Tedeschi", "Pietro", ""], ["Jeon", "Kang Eun", ""], ["She", "James", ""], ["Wong", "Simon", ""], ["Bakiras", "Spiridon", ""], ["Di Pietro", "Roberto", ""]]}, {"id": "2103.06232", "submitter": "Samuel Yen-Chi Chen", "authors": "William M Watkins, Samuel Yen-Chi Chen, Shinjae Yoo", "title": "Quantum machine learning with differential privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum machine learning (QML) can complement the growing trend of using\nlearned models for a myriad of classification tasks, from image recognition to\nnatural speech processing. A quantum advantage arises due to the intractability\nof quantum operations on a classical computer. Many datasets used in machine\nlearning are crowd sourced or contain some private information. To the best of\nour knowledge, no current QML models are equipped with privacy-preserving\nfeatures, which raises concerns as it is paramount that models do not expose\nsensitive information. Thus, privacy-preserving algorithms need to be\nimplemented with QML. One solution is to make the machine learning algorithm\ndifferentially private, meaning the effect of a single data point on the\ntraining dataset is minimized. Differentially private machine learning models\nhave been investigated, but differential privacy has yet to be studied in the\ncontext of QML. In this study, we develop a hybrid quantum-classical model that\nis trained to preserve privacy using differentially private optimization\nalgorithm. This marks the first proof-of-principle demonstration of\nprivacy-preserving QML. The experiments demonstrate that differentially private\nQML can protect user-sensitive information without diminishing model accuracy.\nAlthough the quantum model is simulated and tested on a classical computer, it\ndemonstrates potential to be efficiently implemented on near-term quantum\ndevices (noisy intermediate-scale quantum [NISQ]). The approach's success is\nillustrated via the classification of spatially classed two-dimensional\ndatasets and a binary MNIST classification. This implementation of\nprivacy-preserving QML will ensure confidentiality and accurate learning on\nNISQ technology.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 18:06:15 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Watkins", "William M", ""], ["Chen", "Samuel Yen-Chi", ""], ["Yoo", "Shinjae", ""]]}, {"id": "2103.06271", "submitter": "Amir Khazraei", "authors": "Amir Khazraei, Spencer Hallyburton, Qitong Gao, Yu Wang and Miroslav\n  Pajic", "title": "Learning-Based Vulnerability Analysis of Cyber-Physical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work focuses on the use of deep learning for vulnerability analysis of\ncyber-physical systems (CPS). Specifically, we consider a control architecture\nwidely used in CPS (e.g., robotics), where the low-level control is based on\ne.g., the extended Kalman filter (EKF) and an anomaly detector. To facilitate\nanalyzing the impact potential sensing attacks could have, our objective is to\ndevelop learning-enabled attack generators capable of designing stealthy\nattacks that maximally degrade system operation. We show how such problem can\nbe cast within a learning-based grey-box framework where parts of the runtime\ninformation are known to the attacker, and introduce two models based on\nfeed-forward neural networks (FNN); both models are trained offline, using a\ncost function that combines the attack effects on the estimation error and the\nresidual signal used for anomaly detection, so that the trained models are\ncapable of recursively generating such effective sensor attacks in real-time.\nThe effectiveness of the proposed methods is illustrated on several case\nstudies.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 06:52:26 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 19:19:30 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Khazraei", "Amir", ""], ["Hallyburton", "Spencer", ""], ["Gao", "Qitong", ""], ["Wang", "Yu", ""], ["Pajic", "Miroslav", ""]]}, {"id": "2103.06297", "submitter": "Asaf Shabtai", "authors": "Yam Sharon and David Berend and Yang Liu and Asaf Shabtai and Yuval\n  Elovici", "title": "TANTRA: Timing-Based Adversarial Network Traffic Reshaping Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network intrusion attacks are a known threat. To detect such attacks, network\nintrusion detection systems (NIDSs) have been developed and deployed. These\nsystems apply machine learning models to high-dimensional vectors of features\nextracted from network traffic to detect intrusions. Advances in NIDSs have\nmade it challenging for attackers, who must execute attacks without being\ndetected by these systems. Prior research on bypassing NIDSs has mainly focused\non perturbing the features extracted from the attack traffic to fool the\ndetection system, however, this may jeopardize the attack's functionality. In\nthis work, we present TANTRA, a novel end-to-end Timing-based Adversarial\nNetwork Traffic Reshaping Attack that can bypass a variety of NIDSs. Our\nevasion attack utilizes a long short-term memory (LSTM) deep neural network\n(DNN) which is trained to learn the time differences between the target\nnetwork's benign packets. The trained LSTM is used to set the time differences\nbetween the malicious traffic packets (attack), without changing their content,\nsuch that they will \"behave\" like benign network traffic and will not be\ndetected as an intrusion. We evaluate TANTRA on eight common intrusion attacks\nand three state-of-the-art NIDS systems, achieving an average success rate of\n99.99\\% in network intrusion detection system evasion. We also propose a novel\nmitigation technique to address this new evasion attack.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 19:03:38 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Sharon", "Yam", ""], ["Berend", "David", ""], ["Liu", "Yang", ""], ["Shabtai", "Asaf", ""], ["Elovici", "Yuval", ""]]}, {"id": "2103.06400", "submitter": "Md Nazmul Islam", "authors": "Md Nazmul Islam, Yazhou Tu, Md Imran Hossen, Shengmin Guo, and Xiali\n  Hei", "title": "A Survey on Limitation, Security and Privacy Issues on Additive\n  Manufacturing", "comments": "10 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Additive manufacturing (AM) is growing as fast as anyone can imagine, and it\nis now a multi-billion-dollar industry. AM becomes popular in a variety of\nsectors, such as automotive, aerospace, biomedical, and pharmaceutical, for\nproducing parts/ components/ subsystems. However, current AM technologies can\nface vast risks of security issues and privacy loss. For the security of AM\nprocess, many researchers are working on the defense mechanism to\ncountermeasure such security concerns and finding efficient ways to eliminate\nthose risks. Researchers have also been conducting experiments to establish a\nsecure framework for the user's privacy and security components. This survey\nconsists of four sections. In the first section, we will explore the relevant\nlimitations of additive manufacturing in terms of printing capability,\nsecurity, and possible solutions. The second section will present different\nkinds of attacks on AM and their effects. The next part will analyze and\ndiscuss the mechanisms and frameworks for access control and authentication for\nAM devices. The final section examines the security issues in various\nindustrial sectors and provides the observations on the security of the\nadditive manufacturing process.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 01:03:46 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Islam", "Md Nazmul", ""], ["Tu", "Yazhou", ""], ["Hossen", "Md Imran", ""], ["Guo", "Shengmin", ""], ["Hei", "Xiali", ""]]}, {"id": "2103.06438", "submitter": "Tianxi Ji", "authors": "Tianxi Ji, Emre Yilmaz, Erman Ayday, Pan Li", "title": "The Curse of Correlations for Robust Fingerprinting of Relational\n  Databases", "comments": "To appear in 24th International Symposium on Research in Attacks,\n  Intrusions and Defenses (RAID'21)", "journal-ref": null, "doi": "10.1145/3471621.3471853", "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Database fingerprinting have been widely adopted to prevent unauthorized\nsharing of data and identify the source of data leakages. Although existing\nschemes are robust against common attacks, like random bit flipping and subset\nattack, their robustness degrades significantly if attackers utilize the\ninherent correlations among database entries. In this paper, we first\ndemonstrate the vulnerability of existing database fingerprinting schemes by\nidentifying different correlation attacks: column-wise correlation attack,\nrow-wise correlation attack, and the integration of them. To provide robust\nfingerprinting against the identified correlation attacks, we then develop\nmitigation techniques, which can work as post-processing steps for any\noff-the-shelf database fingerprinting schemes. The proposed mitigation\ntechniques also preserve the utility of the fingerprinted database considering\ndifferent utility metrics. We empirically investigate the impact of the\nidentified correlation attacks and the performance of mitigation techniques\nusing real-world relational databases. Our results show (i) high success rates\nof the identified correlation attacks against existing fingerprinting schemes\n(e.g., the integrated correlation attack can distort 64.8\\% fingerprint bits by\njust modifying 14.2\\% entries in a fingerprinted database), and (ii) high\nrobustness of the proposed mitigation techniques (e.g., with the mitigation\ntechniques, the integrated correlation attack can only distort $3\\%$\nfingerprint bits).\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 03:47:51 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 19:37:38 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Ji", "Tianxi", ""], ["Yilmaz", "Emre", ""], ["Ayday", "Erman", ""], ["Li", "Pan", ""]]}, {"id": "2103.06453", "submitter": "Guangyuan Hu", "authors": "Guangyuan Hu, Zecheng He, Ruby B. Lee", "title": "Smartphone Impostor Detection with Behavioral Data Privacy and\n  Minimalist Hardware Support", "comments": "Accepted by tinyML 2021 Research Symposium. arXiv admin note:\n  substantial text overlap with arXiv:2002.03914", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Impostors are attackers who take over a smartphone and gain access to the\nlegitimate user's confidential and private information. This paper proposes a\ndefense-in-depth mechanism to detect impostors quickly with simple Deep\nLearning algorithms, which can achieve better detection accuracy than the best\nprior work which used Machine Learning algorithms requiring computation of\nmultiple features. Different from previous work, we then consider protecting\nthe privacy of a user's behavioral (sensor) data by not exposing it outside the\nsmartphone. For this scenario, we propose a Recurrent Neural Network (RNN)\nbased Deep Learning algorithm that uses only the legitimate user's sensor data\nto learn his/her normal behavior. We propose to use Prediction Error\nDistribution (PED) to enhance the detection accuracy. We also show how a\nminimalist hardware module, dubbed SID for Smartphone Impostor Detector, can be\ndesigned and integrated into smartphones for self-contained impostor detection.\nExperimental results show that SID can support real-time impostor detection, at\na very low hardware cost and energy consumption, compared to other RNN\naccelerators.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 04:39:53 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 16:31:49 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Hu", "Guangyuan", ""], ["He", "Zecheng", ""], ["Lee", "Ruby B.", ""]]}, {"id": "2103.06487", "submitter": "Haowen Liu", "authors": "Haowen Liu, Ping Yi, Hsiao-Ying Lin, Jie Shi, Weidong Qiu", "title": "DAFAR: Defending against Adversaries by Feedback-Autoencoder\n  Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has shown impressive performance on challenging perceptual\ntasks and has been widely used in software to provide intelligent services.\nHowever, researchers found deep neural networks vulnerable to adversarial\nexamples. Since then, many methods are proposed to defend against adversaries\nin inputs, but they are either attack-dependent or shown to be ineffective with\nnew attacks. And most of existing techniques have complicated structures or\nmechanisms that cause prohibitively high overhead or latency, impractical to\napply on real software.\n  We propose DAFAR, a feedback framework that allows deep learning models to\ndetect/purify adversarial examples in high effectiveness and universality, with\nlow area and time overhead. DAFAR has a simple structure, containing a victim\nmodel, a plug-in feedback network, and a detector. The key idea is to import\nthe high-level features from the victim model's feature extraction layers into\nthe feedback network to reconstruct the input. This data stream forms a\nfeedback autoencoder. For strong attacks, it transforms the imperceptible\nattack on the victim model into the obvious reconstruction-error attack on the\nfeedback autoencoder directly, which is much easier to detect; for weak\nattacks, the reformation process destroys the structure of adversarial\nexamples. Experiments are conducted on MNIST and CIFAR-10 data-sets, showing\nthat DAFAR is effective against popular and arguably most advanced attacks\nwithout losing performance on legitimate samples, with high effectiveness and\nuniversality across attack methods and parameters.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 06:18:50 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 14:49:12 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Liu", "Haowen", ""], ["Yi", "Ping", ""], ["Lin", "Hsiao-Ying", ""], ["Shi", "Jie", ""], ["Qiu", "Weidong", ""]]}, {"id": "2103.06504", "submitter": "Ranjie Duan", "authors": "Ranjie Duan, Xiaofeng Mao, A. K. Qin, Yun Yang, Yuefeng Chen, Shaokai\n  Ye, Yuan He", "title": "Adversarial Laser Beam: Effective Physical-World Attack to DNNs in a\n  Blink", "comments": "Accepted to CVPR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Though it is well known that the performance of deep neural networks (DNNs)\ndegrades under certain light conditions, there exists no study on the threats\nof light beams emitted from some physical source as adversarial attacker on\nDNNs in a real-world scenario. In this work, we show by simply using a laser\nbeam that DNNs are easily fooled. To this end, we propose a novel attack method\ncalled Adversarial Laser Beam ($AdvLB$), which enables manipulation of laser\nbeam's physical parameters to perform adversarial attack. Experiments\ndemonstrate the effectiveness of our proposed approach in both digital- and\nphysical-settings. We further empirically analyze the evaluation results and\nreveal that the proposed laser beam attack may lead to some interesting\nprediction errors of the state-of-the-art DNNs. We envisage that the proposed\n$AdvLB$ method enriches the current family of adversarial attacks and builds\nthe foundation for future robustness studies for light.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 07:03:21 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Duan", "Ranjie", ""], ["Mao", "Xiaofeng", ""], ["Qin", "A. K.", ""], ["Yang", "Yun", ""], ["Chen", "Yuefeng", ""], ["Ye", "Shaokai", ""], ["He", "Yuan", ""]]}, {"id": "2103.06624", "submitter": "Huan Zhang", "authors": "Shiqi Wang, Huan Zhang, Kaidi Xu, Xue Lin, Suman Jana, Cho-Jui Hsieh,\n  J. Zico Kolter", "title": "Beta-CROWN: Efficient Bound Propagation with Per-neuron Split\n  Constraints for Complete and Incomplete Neural Network Verification", "comments": "Shiqi Wang, Huan Zhang and Kaidi Xu contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works in neural network verification show that cheap incomplete\nverifiers such as CROWN, based upon bound propagations, can effectively be used\nin Branch-and-Bound (BaB) methods to accelerate complete verification,\nachieving significant speedups compared to expensive linear programming (LP)\nbased techniques. However, they cannot fully handle the per-neuron split\nconstraints introduced by BaB like LP verifiers do, leading to looser bounds\nand hurting their verification efficiency. In this work, we develop\n$\\beta$-CROWN, a new bound propagation based method that can fully encode\nper-neuron splits via optimizable parameters $\\beta$. When the optimizable\nparameters are jointly optimized in intermediate layers, $\\beta$-CROWN has the\npotential of producing better bounds than typical LP verifiers with neuron\nsplit constraints, while being efficiently parallelizable on GPUs. Applied to\nthe complete verification setting, $\\beta$-CROWN is close to three orders of\nmagnitude faster than LP-based BaB methods for robustness verification, and\nalso over twice faster than state-of-the-art GPU-based complete verifiers with\nsimilar timeout rates. By terminating BaB early, our method can also be used\nfor incomplete verification. Compared to the state-of-the-art\nsemidefinite-programming (SDP) based verifier, we show a substantial leap\nforward by greatly reducing the gap between verified accuracy and empirical\nadversarial attack accuracy, from 35% (SDP) to 12% on an adversarially trained\nMNIST network ($\\epsilon=0.3$), while being 47 times faster. Our code is\navailable at https://github.com/KaidiXu/Beta-CROWN\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 11:56:54 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Wang", "Shiqi", ""], ["Zhang", "Huan", ""], ["Xu", "Kaidi", ""], ["Lin", "Xue", ""], ["Jana", "Suman", ""], ["Hsieh", "Cho-Jui", ""], ["Kolter", "J. Zico", ""]]}, {"id": "2103.06641", "submitter": "Aaron Roth", "authors": "Sergul Aydore, William Brown, Michael Kearns, Krishnaram Kenthapadi,\n  Luca Melis, Aaron Roth, Ankit Siva", "title": "Differentially Private Query Release Through Adaptive Projection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose, implement, and evaluate a new algorithm for releasing answers to\nvery large numbers of statistical queries like $k$-way marginals, subject to\ndifferential privacy. Our algorithm makes adaptive use of a continuous\nrelaxation of the Projection Mechanism, which answers queries on the private\ndataset using simple perturbation, and then attempts to find the synthetic\ndataset that most closely matches the noisy answers. We use a continuous\nrelaxation of the synthetic dataset domain which makes the projection loss\ndifferentiable, and allows us to use efficient ML optimization techniques and\ntooling. Rather than answering all queries up front, we make judicious use of\nour privacy budget by iteratively and adaptively finding queries for which our\n(relaxed) synthetic data has high error, and then repeating the projection. We\nperform extensive experimental evaluations across a range of parameters and\ndatasets, and find that our method outperforms existing algorithms in many\ncases, especially when the privacy budget is small or the query class is large.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 12:43:18 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 15:44:57 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Aydore", "Sergul", ""], ["Brown", "William", ""], ["Kearns", "Michael", ""], ["Kenthapadi", "Krishnaram", ""], ["Melis", "Luca", ""], ["Roth", "Aaron", ""], ["Siva", "Ankit", ""]]}, {"id": "2103.06701", "submitter": "Anna Kuzina", "authors": "Anna Kuzina, Max Welling, Jakub M. Tomczak", "title": "Diagnosing Vulnerability of Variational Auto-Encoders to Adversarial\n  Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we explore adversarial attacks on the Variational Autoencoders\n(VAE). We show how to modify data point to obtain a prescribed latent code\n(supervised attack) or just get a drastically different code (unsupervised\nattack). We examine the influence of model modifications ($\\beta$-VAE, NVAE) on\nthe robustness of VAEs and suggest metrics to quantify it.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 14:23:20 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 07:02:22 GMT"}, {"version": "v3", "created": "Thu, 6 May 2021 08:41:15 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Kuzina", "Anna", ""], ["Welling", "Max", ""], ["Tomczak", "Jakub M.", ""]]}, {"id": "2103.06743", "submitter": "McKenzie Van Der Hagen", "authors": "McKenzie van der Hagen, Brandon Lucia", "title": "Practical Encrypted Computing for IoT Clients", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy and energy are primary concerns for sensor devices that offload\ncompute to a potentially untrusted edge server or cloud. Homomorphic Encryption\n(HE) enables offload processing of encrypted data. HE offload processing\nretains data privacy, but is limited by the need for frequent communication\nbetween the client device and the offload server. Existing client-aided\nencrypted computing systems are optimized for performance on the offload\nserver, failing to sufficiently address client costs, and precluding HE offload\nfor low-resource (e.g., IoT) devices. We introduce Client-aided HE for Opaque\nCompute Offloading (CHOCO), a client-optimized system for encrypted offload\nprocessing. CHOCO introduces rotational redundancy, an algorithmic optimization\nto minimize computing and communication costs. We design Client-Aided HE for\nOpaque Compute Offloading Through Accelerated Cryptographic Operations\n(CHOCO-TACO), a comprehensive architectural accelerator for client-side\ncryptographic operations that eliminates most of their time and energy costs.\nOur evaluation shows that CHOCO makes client-aided HE offloading feasible for\nresource-constrained clients. Compared to existing encrypted computing\nsolutions, CHOCO reduces communication cost by up to 2948x. With hardware\nsupport, client-side encryption/decryption is faster by 1094x and uses 648x\nless energy. In our end-to-end implementation of a large-scale DNN (VGG16),\nCHOCO uses 37% less energy than local (unencrypted) computation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 15:44:54 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["van der Hagen", "McKenzie", ""], ["Lucia", "Brandon", ""]]}, {"id": "2103.06763", "submitter": "Khan Reaz", "authors": "Khan Reaz and Gerhard Wunder", "title": "ComPass: Proximity Aware Common Passphrase Agreement Protocol for Wi-Fi\n  devices Using Physical Layer Security", "comments": "Accepted in IMIS-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Secure and scalable device provisioning is a notorious challenge in Wi-Fi.\nWPA2/WPA3 solutions take user interaction and a strong passphrase for granted.\nHowever, the often weak passphrases are subject to guessing attacks. Notably,\nthere has been a significant rise of cyberattacks on Wi-Fi home or small office\nnetworks during the COVID-19 pandemic. This paper addresses the device\nprovisioning problem in Wi-Fi (personal mode) and proposes ComPass protocol to\nsupplement WPA2/WPA3. ComPass replaces the pre-installed or user-selected\npassphrases with automatically generated ones. For this, ComPass employs\nPhysical Layer Security and extracts credentials from common random physical\nlayer parameters between devices. Two major features make ComPass unique and\nsuperior compared to previous proposals: First, it employs phase information\n(rather than amplitude or signal strength) to generate the passphrase so that\nit is robust, scaleable, and impossible to guess. Our analysis showed that\nComPass generated passphrases have 3 times more entropy than human generated\npassphrases (113-bits vs. 34-bits). Second, ComPass selects parameters such\nthat two devices bind only within a certain proximity (less than 3m), hence\nproviding practically useful in-build PLS-based authentiation. ComPass is\navailable as a kernel module or as full firmware.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 16:20:41 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 13:54:48 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Reaz", "Khan", ""], ["Wunder", "Gerhard", ""]]}, {"id": "2103.06767", "submitter": "Kostiantyn Khabarlak", "authors": "Kostiantyn Khabarlak, Larysa Koriashkina", "title": "Mobile Access Control System Based on RFID Tags And Facial Information", "comments": null, "journal-ref": "In Bulletin of National Technical University \"KhPI\". Series:\n  System Analysis, Control and Information Technologies 2 (4) (2020): 69-74", "doi": "10.20998/2079-0023.2020.02.12", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RFID tags see a widespread use in modern security systems, including home\nintercoms, access control cards, etc. Here we focus on access control systems.\nCurrently they have either high cost or low security guarantees. Hence, the\ndevelopments focusing on improving access control security while lowering the\ncost is a rapidly developing field. The purpose of this work is to create an\nalternative access control scheme, where card scanners are replaced with\npassive RFID tags, and all the communications are done via user's smartphone\nWi-Fi. Based on the analysis of existing approaches, it was concluded that use\nof mobile systems is the most promising due to their expandability and presence\nof a large number of sensors, such as NFC, camera etc. In the proposed model\nRFID tags are mounted near a turnstile or a smart door. Tag reading and\nprogramming is done via NFC chip directly on an Android or iOS mobile device,\nwhich allows for a significant price cut for such a system implementation. A\ndetailed description of a tag writing procedure with the data required to\nperform it is provided. To enhance security, together with smartphone-based\nauthorization we require the user to provide his photograph while entering a\nsecure gate. The photograph is then displayed on a monitoring dashboard\nside-by-side with his registration picture, so that the two can then be matched\nagainst each other. The developed client-server application offers\nadministrative system used to configure gate access policies and monitor\nentrances with filters by access time, user and gate. Also, we propose a mobile\napplication that allows gate registration and serves as a door unlock key. The\nsuggested access control model reduces installation costs required, as it is\nfully wireless and uses cheap autonomous RFID-tags as its main component.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 16:23:45 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Khabarlak", "Kostiantyn", ""], ["Koriashkina", "Larysa", ""]]}, {"id": "2103.06797", "submitter": "Yuto Mori", "authors": "Yuto Mori, Atsushi Nitanda, Akiko Takeda", "title": "BODAME: Bilevel Optimization for Defense Against Model Extraction", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model extraction attacks have become serious issues for service providers\nusing machine learning. We consider an adversarial setting to prevent model\nextraction under the assumption that attackers will make their best guess on\nthe service provider's model using query accesses, and propose to build a\nsurrogate model that significantly keeps away the predictions of the attacker's\nmodel from those of the true model. We formulate the problem as a non-convex\nconstrained bilevel optimization problem and show that for kernel models, it\ncan be transformed into a non-convex 1-quadratically constrained quadratic\nprogram with a polynomial-time algorithm to find the global optimum. Moreover,\nwe give a tractable transformation and an algorithm for more complicated models\nthat are learned by using stochastic gradient descent-based algorithms.\nNumerical experiments show that the surrogate model performs well compared with\nexisting defense models when the difference between the attacker's and service\nprovider's distributions is large. We also empirically confirm the\ngeneralization ability of the surrogate model.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 17:08:31 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Mori", "Yuto", ""], ["Nitanda", "Atsushi", ""], ["Takeda", "Akiko", ""]]}, {"id": "2103.06809", "submitter": "Tuomas Granlund", "authors": "Tuomas Granlund, Juha Vedenp\\\"a\\\"a, Vlad Stirbu and Tommi Mikkonen", "title": "On Medical Device Cybersecurity Compliance in EU", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The medical device products at the European Union market must be safe and\neffective. To ensure this, medical device manufacturers must comply to the new\nregulatory requirements brought by the Medical Device Regulation (MDR) and the\nIn Vitro Diagnostic Medical Device Regulation (IVDR). In general, the new\nregulations increase regulatory requirements and oversight, especially for\nmedical software, and this is also true for requirements related to\ncybersecurity, which are now explicitly addressed in the legislation. The\nsignificant legislation changes currently underway, combined with increased\ncybersecurity requirements, create unique challenges for manufacturers to\ncomply with the regulatory framework. In this paper, we review the new\ncybersecurity requirements in the light of currently available guidance\ndocuments, and pinpoint four core concepts around which cybersecurity\ncompliance can be built. We argue that these core concepts form a foundations\nfor cybersecurity compliance in the European Union regulatory framework.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 17:26:06 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Granlund", "Tuomas", ""], ["Vedenp\u00e4\u00e4", "Juha", ""], ["Stirbu", "Vlad", ""], ["Mikkonen", "Tommi", ""]]}, {"id": "2103.06819", "submitter": "Jieren Deng", "authors": "Jieren Deng, Yijue Wang, Ji Li, Chao Shang, Hang Liu, Sanguthevar\n  Rajasekaran and Caiwen Ding", "title": "TAG: Transformer Attack from Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although federated learning has increasingly gained attention in terms of\neffectively utilizing local devices for data privacy enhancement, recent\nstudies show that publicly shared gradients in the training process can reveal\nthe private training images (gradient leakage) to a third-party in computer\nvision. We have, however, no systematic understanding of the gradient leakage\nmechanism on the Transformer based language models. In this paper, as the first\nattempt, we formulate the gradient attack problem on the Transformer-based\nlanguage models and propose a gradient attack algorithm, TAG, to reconstruct\nthe local training data. We develop a set of metrics to evaluate the\neffectiveness of the proposed attack algorithm quantitatively. Experimental\nresults on Transformer, TinyBERT$_{4}$, TinyBERT$_{6}$, BERT$_{BASE}$, and\nBERT$_{LARGE}$ using GLUE benchmark show that TAG works well on more weight\ndistributions in reconstructing training data and achieves 1.5$\\times$ recover\nrate and 2.5$\\times$ ROUGE-2 over prior methods without the need of ground\ntruth label. TAG can obtain up to 90$\\%$ data by attacking gradients in CoLA\ndataset. In addition, TAG has a stronger adversary on large models, small\ndictionary size, and small input length. We hope the proposed TAG will shed\nsome light on the privacy leakage problem in Transformer-based NLP models.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 17:41:32 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 03:08:57 GMT"}, {"version": "v3", "created": "Tue, 16 Mar 2021 20:51:19 GMT"}, {"version": "v4", "created": "Wed, 21 Apr 2021 04:04:18 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Deng", "Jieren", ""], ["Wang", "Yijue", ""], ["Li", "Ji", ""], ["Shang", "Chao", ""], ["Liu", "Hang", ""], ["Rajasekaran", "Sanguthevar", ""], ["Ding", "Caiwen", ""]]}, {"id": "2103.06936", "submitter": "Md Shohidul Islam", "authors": "Md Shohidul Islam, Ihsen Alouani, Khaled N. Khasawneh", "title": "Stochastic-HMDs: Adversarial Resilient Hardware Malware Detectors\n  through Voltage Over-scaling", "comments": "13 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning-based hardware malware detectors (HMDs) offer a potential\ngame changing advantage in defending systems against malware. However, HMDs\nsuffer from adversarial attacks, can be effectively reverse-engineered and\nsubsequently be evaded, allowing malware to hide from detection. We address\nthis issue by proposing a novel HMDs (Stochastic-HMDs) through approximate\ncomputing, which makes HMDs' inference computation-stochastic, thereby making\nHMDs resilient against adversarial evasion attacks. Specifically, we propose to\nleverage voltage overscaling to induce stochastic computation in the HMDs\nmodel. We show that such a technique makes HMDs more resilient to both\nblack-box adversarial attack scenarios, i.e., reverse-engineering and\ntransferability. Our experimental results demonstrate that Stochastic-HMDs\noffer effective defense against adversarial attacks along with by-product power\nsavings, without requiring any changes to the hardware/software nor to the\nHMDs' model, i.e., no retraining or fine tuning is needed. Moreover, based on\nrecent results in probably approximately correct (PAC) learnability theory, we\nshow that Stochastic-HMDs are provably more difficult to reverse engineer.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 20:18:40 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Islam", "Md Shohidul", ""], ["Alouani", "Ihsen", ""], ["Khasawneh", "Khaled N.", ""]]}, {"id": "2103.06990", "submitter": "Deepali Garg", "authors": "Joseph Sweeney, Deepali Garg, Lawrence Pileggi", "title": "Quantifying the Efficacy of Logic Locking Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The outsourced manufacturing of integrated circuits has increased the risk of\nintellectual property theft. In response, logic locking techniques have been\ndeveloped for protecting designs by adding programmable elements to the\ncircuit. These techniques differ significantly in both overhead and resistance\nto various attacks, leaving designers unable to discern their efficacy. To\novercome this critical impediment for the adoption of logic locking, we propose\ntwo metrics, key corruption and minimum corruption, that capture the goals of\nlocking under different attack scenarios. We develop a flow for approximating\nthese metrics on generic locked circuits and evaluate several locking\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 22:31:22 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Sweeney", "Joseph", ""], ["Garg", "Deepali", ""], ["Pileggi", "Lawrence", ""]]}, {"id": "2103.07012", "submitter": "Haoxi Tan", "authors": "Haoxi Tan, Mahin Chandramohan, Cristina Cifuentes, Guangdong Bai, Ryan\n  K. L. Ko", "title": "ColdPress: An Extensible Malware Analysis Platform for Threat\n  Intelligence", "comments": "The code is open source at https://github.com/uqcyber/ColdPress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware analysis is still largely a manual task. This slow and inefficient\napproach does not scale to the exponential rise in the rate of new unique\nmalware generated. Hence, automating the process as much as possible becomes\ndesirable.\n  In this paper, we present ColdPress - an extensible malware analysis platform\nthat automates the end-to-end process of malware threat intelligence gathering\nintegrated output modules to perform report generation of arbitrary file\nformats. ColdPress combines state-of-the-art tools and concepts into a modular\nsystem that aids the analyst to efficiently and effectively extract information\nfrom malware samples. It is designed as a user-friendly and extensible platform\nthat can be easily extended with user-defined modules.\n  We evaluated ColdPress with complex real-world malware samples (e.g.,\nWannaCry), demonstrating its efficiency, performance and usefulness to security\nanalysts.\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2021 00:08:02 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Tan", "Haoxi", ""], ["Chandramohan", "Mahin", ""], ["Cifuentes", "Cristina", ""], ["Bai", "Guangdong", ""], ["Ko", "Ryan K. L.", ""]]}, {"id": "2103.07073", "submitter": "Bo Liu Dr", "authors": "Bo Liu, Ming Ding, Hanyu Xue, Tianqing Zhu, Dayong Ye, Li Song, Wanlei\n  Zhou", "title": "DP-Image: Differential Privacy for Image Data in Feature Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The excessive use of images in social networks, government databases, and\nindustrial applications has posed great privacy risks and raised serious\nconcerns from the public. Even though differential privacy (DP) is a widely\naccepted criterion that can provide a provable privacy guarantee, the\napplication of DP on unstructured data such as images is not trivial due to the\nlack of a clear qualification on the meaningful difference between any two\nimages. In this paper, for the first time, we introduce a novel notion of\nimage-aware differential privacy, referred to as DP-image, that can protect\nuser's personal information in images, from both human and AI adversaries. The\nDP-Image definition is formulated as an extended version of traditional\ndifferential privacy, considering the distance measurements between feature\nspace vectors of images. Then we propose a mechanism to achieve DP-Image by\nadding noise to an image feature vector. Finally, we conduct experiments with a\ncase study on face image privacy. Our results show that the proposed DP-Image\nmethod provides excellent DP protection on images, with a controllable\ndistortion to faces.\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2021 04:02:23 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Liu", "Bo", ""], ["Ding", "Ming", ""], ["Xue", "Hanyu", ""], ["Zhu", "Tianqing", ""], ["Ye", "Dayong", ""], ["Song", "Li", ""], ["Zhou", "Wanlei", ""]]}, {"id": "2103.07101", "submitter": "Benjamin Zi Hao Zhao", "authors": "Benjamin Zi Hao Zhao, Aviral Agrawal, Catisha Coburn, Hassan Jameel\n  Asghar, Raghav Bhaskar, Mohamed Ali Kaafar, Darren Webb, and Peter Dickinson", "title": "On the (In)Feasibility of Attribute Inference Attacks on Machine\n  Learning Models", "comments": "20 pages, accepted at IEEE EuroS&P 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With an increase in low-cost machine learning APIs, advanced machine learning\nmodels may be trained on private datasets and monetized by providing them as a\nservice. However, privacy researchers have demonstrated that these models may\nleak information about records in the training dataset via membership inference\nattacks. In this paper, we take a closer look at another inference attack\nreported in literature, called attribute inference, whereby an attacker tries\nto infer missing attributes of a partially known record used in the training\ndataset by accessing the machine learning model as an API. We show that even if\na classification model succumbs to membership inference attacks, it is unlikely\nto be susceptible to attribute inference attacks. We demonstrate that this is\nbecause membership inference attacks fail to distinguish a member from a nearby\nnon-member. We call the ability of an attacker to distinguish the two (similar)\nvectors as strong membership inference. We show that membership inference\nattacks cannot infer membership in this strong setting, and hence inferring\nattributes is infeasible. However, under a relaxed notion of attribute\ninference, called approximate attribute inference, we show that it is possible\nto infer attributes close to the true attributes. We verify our results on\nthree publicly available datasets, five membership, and three attribute\ninference attacks reported in literature.\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2021 06:21:56 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Zhao", "Benjamin Zi Hao", ""], ["Agrawal", "Aviral", ""], ["Coburn", "Catisha", ""], ["Asghar", "Hassan Jameel", ""], ["Bhaskar", "Raghav", ""], ["Kaafar", "Mohamed Ali", ""], ["Webb", "Darren", ""], ["Dickinson", "Peter", ""]]}, {"id": "2103.07110", "submitter": "Dattaraj Rao", "authors": "Shraddha Mane, Dattaraj Rao", "title": "Explaining Network Intrusion Detection System Using Explainable AI\n  Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cybersecurity is a domain where the data distribution is constantly changing\nwith attackers exploring newer patterns to attack cyber infrastructure.\nIntrusion detection system is one of the important layers in cyber safety in\ntoday's world. Machine learning based network intrusion detection systems\nstarted showing effective results in recent years. With deep learning models,\ndetection rates of network intrusion detection system are improved. More\naccurate the model, more the complexity and hence less the interpretability.\nDeep neural networks are complex and hard to interpret which makes difficult to\nuse them in production as reasons behind their decisions are unknown. In this\npaper, we have used deep neural network for network intrusion detection and\nalso proposed explainable AI framework to add transparency at every stage of\nmachine learning pipeline. This is done by leveraging Explainable AI algorithms\nwhich focus on making ML models less of black boxes by providing explanations\nas to why a prediction is made. Explanations give us measurable factors as to\nwhat features influence the prediction of a cyberattack and to what degree.\nThese explanations are generated from SHAP, LIME, Contrastive Explanations\nMethod, ProtoDash and Boolean Decision Rules via Column Generation. We apply\nthese approaches to NSL KDD dataset for intrusion detection system and\ndemonstrate results.\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2021 07:15:09 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Mane", "Shraddha", ""], ["Rao", "Dattaraj", ""]]}, {"id": "2103.07118", "submitter": "Tsutomu Matsumoto", "authors": "Koichi Shimizu, Daisuke Suzuki, Ryo Muramatsu, Hisashi Mori, Tomoyuki\n  Nagatsuka, Tsutomu Matsumoto", "title": "Evaluation Framework for Performance Limitation of Autonomous Systems\n  under Sensor Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous systems such as self-driving cars rely on sensors to perceive the\nsurrounding world. Measures must be taken against attacks on sensors, which\nhave been a hot topic in the last few years. For that goal one must first\nevaluate how sensor attacks affect the system, i.e. which part or whole of the\nsystem will fail if some of the built-in sensors are compromised, or will keep\nsafe, etc. Among the relevant safety standards, ISO/PAS 21448 addresses the\nsafety of road vehicles taking into account the performance limitations of\nsensors, but leaves security aspects out of scope. On the other hand, ISO/SAE\n21434 addresses the security perspective during the development process of\nvehicular systems, but not specific threats such as sensor attacks. As a result\nthe safety of autonomous systems under sensor attack is yet to be addressed. In\nthis paper we propose a framework that combines safety analysis for scenario\nidentification, and scenario-based simulation with sensor attack models\nembedded. Given an autonomous system model, we identify hazard scenarios caused\nby sensor attacks, and evaluate the performance limitations in the scenarios.\nWe report on a prototype simulator for autonomous vehicles with radar, cameras\nand LiDAR along with attack models against the sensors. Our experiments show\nthat our framework can evaluate how the system safety changes as parameters of\nthe attacks and the sensors vary.\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2021 07:36:52 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Shimizu", "Koichi", ""], ["Suzuki", "Daisuke", ""], ["Muramatsu", "Ryo", ""], ["Mori", "Hisashi", ""], ["Nagatsuka", "Tomoyuki", ""], ["Matsumoto", "Tsutomu", ""]]}, {"id": "2103.07180", "submitter": "Enka Blanchard", "authors": "Enka Blanchard (LORIA), Ryan Robucci (UMBC), Ted Selker (UMBC), Alan\n  Sherman (UMBC)", "title": "Phrase-Verified Voting: Verifiable Low-Tech Remote Boardroom Voting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Phrase-Verified Voting, a voter-verifiable remote voting system\nassembled from commercial off-the-shelf software for small private elections.\nThe system is transparent and enables each voter to verify that the tally\nincludes their ballot selection without requiring any understanding of\ncryptography. This paper describes the system and its use in fall 2020, to vote\nremotely in promotion committees in a university. Each voter fills out a form\nin the cloud with their vote V (YES, NO, ABSTAIN) and a passphrase P-two words\nentered by the voter. The system generates a verification prompt of the (P,V)\npairs and a tally of the votes, organized to help visualize how the votes add\nup. After the polls close, each voter verifies that this table lists their\n(P,V) pair and that the tally is computed correctly. The system is especially\nappropriate for any small group making sensitive decisions. Because the system\nwould not prevent a coercer from demanding that their victim use a specified\npassphrase, it is not designed for applications where such malfeasance would be\nlikely or go undetected. Results from 43 voters show that the system was\nwell-accepted, performed effectively for its intended purpose, and introduced\nusers to the concept of voter-verified elections. Compared to the commonly-used\nalternatives of paper ballots or voting by email, voters found the system\neasier to use, and that it provided greater privacy and outcome integrity.\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2021 09:59:55 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Blanchard", "Enka", "", "LORIA"], ["Robucci", "Ryan", "", "UMBC"], ["Selker", "Ted", "", "UMBC"], ["Sherman", "Alan", "", "UMBC"]]}, {"id": "2103.07274", "submitter": "Muhammad E. H. Chowdhury", "authors": "Arafat Rahman, Muhammad E. H. Chowdhury, Amith Khandakar, Serkan\n  Kiranyaz, Kh Shahriya Zaman, Mamun Bin Ibne Reaz, Mohammad Tariqul Islam,\n  Muhammad Abdul Kadir", "title": "Multimodal EEG and Keystroke Dynamics Based Biometric System Using\n  Machine Learning Algorithms", "comments": "16 pages, 11 Figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid advancement of technology, different biometric user\nauthentication, and identification systems are emerging. Traditional biometric\nsystems like face, fingerprint, and iris recognition, keystroke dynamics, etc.\nare prone to cyber-attacks and suffer from different disadvantages.\nElectroencephalography (EEG) based authentication has shown promise in\novercoming these limitations. However, EEG-based authentication is less\naccurate due to signal variability at different psychological and physiological\nconditions. On the other hand, keystroke dynamics-based identification offers\nhigh accuracy but suffers from different spoofing attacks. To overcome these\nchallenges, we propose a novel multimodal biometric system combining EEG and\nkeystroke dynamics. Firstly, a dataset was created by acquiring both keystroke\ndynamics and EEG signals from 10 users with 500 trials per user at 10 different\nsessions. Different statistical, time, and frequency domain features were\nextracted and ranked from the EEG signals and key features were extracted from\nthe keystroke dynamics. Different classifiers were trained, validated, and\ntested for both individual and combined modalities for two different\nclassification strategies - personalized and generalized. Results show that\nvery high accuracy can be achieved both in generalized and personalized cases\nfor the combination of EEG and keystroke dynamics. The identification and\nauthentication accuracies were found to be 99.80% and 99.68% for Extreme\nGradient Boosting (XGBoost) and Random Forest classifiers, respectively which\noutperform the individual modalities with a significant margin (around 5\npercent). We also developed a binary template matching-based algorithm, which\ngives 93.64% accuracy 6X faster. The proposed method is secured and reliable\nfor any kind of biometric authentication.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 20:32:08 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 20:44:12 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Rahman", "Arafat", ""], ["Chowdhury", "Muhammad E. H.", ""], ["Khandakar", "Amith", ""], ["Kiranyaz", "Serkan", ""], ["Zaman", "Kh Shahriya", ""], ["Reaz", "Mamun Bin Ibne", ""], ["Islam", "Mohammad Tariqul", ""], ["Kadir", "Muhammad Abdul", ""]]}, {"id": "2103.07297", "submitter": "Xavier Ferrer Aran", "authors": "Danny S. Guam\\'an, Xavier Ferrer, Jose M. del Alamo, Jose Such", "title": "Automating the GDPR Compliance Assessment for Cross-border Personal Data\n  Transfers in Android Applications", "comments": "Author's copy of the submitted manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The General Data Protection Regulation (GDPR) aims to ensure that all\npersonal data processing activities are fair and transparent for the European\nUnion (EU) citizens, regardless of whether these are carried out within the EU\nor anywhere else. To this end, it sets strict requirements to transfer personal\ndata outside the EU. However, checking these requirements is a daunting task\nfor supervisory authorities, particularly in the mobile app domain due to the\nhuge number of apps available and their dynamic nature. In this paper, we\npropose a fully automated method to assess the compliance of mobile apps with\nthe GDPR requirements for cross-border personal data transfers. We have applied\nthe method to the top-free 10,080 apps from the Google Play Store. The results\nreveal that there is still a very significant gap between what app providers\nand third-party recipients do in practice and what is intended by the GDPR. A\nsubstantial 56% of analysed apps are potentially non-compliant with the GDPR\ncross-border transfer requirements.\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2021 14:13:26 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Guam\u00e1n", "Danny S.", ""], ["Ferrer", "Xavier", ""], ["del Alamo", "Jose M.", ""], ["Such", "Jose", ""]]}, {"id": "2103.07491", "submitter": "Pallika Kanani", "authors": "Pallika Kanani, Virendra J. Marathe, Daniel Peterson, Rave Harpaz,\n  Steve Bright", "title": "Private Cross-Silo Federated Learning for Extracting Vaccine Adverse\n  Event Mentions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is quickly becoming a goto distributed training\nparadigm for users to jointly train a global model without physically sharing\ntheir data. Users can indirectly contribute to, and directly benefit from a\nmuch larger aggregate data corpus used to train the global model. However,\nliterature on successful application of FL in real-world problem settings is\nsomewhat sparse. In this paper, we describe our experience applying a FL based\nsolution to the Named Entity Recognition (NER) task for an adverse event\ndetection application in the context of mass scale vaccination programs. We\npresent a comprehensive empirical analysis of various dimensions of benefits\ngained with FL based training. Furthermore, we investigate effects of tighter\nDifferential Privacy (DP) constraints in highly sensitive settings where\nfederation users must enforce Local DP to ensure strict privacy guarantees. We\nshow that local DP can severely cripple the global model's prediction accuracy,\nthus dis-incentivizing users from participating in the federation. In response,\nwe demonstrate how recent innovation on personalization methods can help\nsignificantly recover the lost accuracy. We focus our analysis on the Federated\nFine-Tuning algorithm, FedFT, and prove that it is not PAC Identifiable, thus\nmaking it even more attractive for FL-based training.\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2021 19:20:33 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Kanani", "Pallika", ""], ["Marathe", "Virendra J.", ""], ["Peterson", "Daniel", ""], ["Harpaz", "Rave", ""], ["Bright", "Steve", ""]]}, {"id": "2103.07567", "submitter": "Fatemehsadat Mireshghallah", "authors": "Fatemehsadat Mireshghallah, Huseyin A. Inan, Marcello Hasegawa, Victor\n  R\\\"uhle, Taylor Berg-Kirkpatrick, Robert Sim", "title": "Privacy Regularization: Joint Privacy-Utility Optimization in Language\n  Models", "comments": "NAACL-HLT 2021 Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural language models are known to have a high capacity for memorization of\ntraining samples. This may have serious privacy implications when training\nmodels on user content such as email correspondence. Differential privacy (DP),\na popular choice to train models with privacy guarantees, comes with\nsignificant costs in terms of utility degradation and disparate impact on\nsubgroups of users. In this work, we introduce two privacy-preserving\nregularization methods for training language models that enable joint\noptimization of utility and privacy through (1) the use of a discriminator and\n(2) the inclusion of a triplet-loss term. We compare our methods with DP\nthrough extensive evaluation. We show the advantages of our regularizers with\nfavorable utility-privacy trade-off, faster training with the ability to tap\ninto existing optimization approaches, and ensuring uniform treatment of\nunder-represented subgroups.\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2021 23:17:43 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 01:01:59 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Mireshghallah", "Fatemehsadat", ""], ["Inan", "Huseyin A.", ""], ["Hasegawa", "Marcello", ""], ["R\u00fchle", "Victor", ""], ["Berg-Kirkpatrick", "Taylor", ""], ["Sim", "Robert", ""]]}, {"id": "2103.07583", "submitter": "Andr\\'es Molina-Markham", "authors": "Andres Molina-Markham, Cory Miniter, Becky Powell, Ahmad Ridley", "title": "Network Environment Design for Autonomous Cyberdefense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has been demonstrated suitable to develop agents\nthat play complex games with human-level performance. However, it is not\nunderstood how to effectively use RL to perform cybersecurity tasks. To develop\nsuch understanding, it is necessary to develop RL agents using simulation and\nemulation systems allowing researchers to model a broad class of realistic\nthreats and network conditions. Demonstrating that a specific RL algorithm can\nbe effective for defending a network under certain conditions may not\nnecessarily give insight about the performance of the algorithm when the\nthreats, network conditions, and security goals change. This paper introduces a\nnovel approach for network environment design and a software framework to\naddress the fundamental problem that network defense cannot be defined as a\nsingle game with a simple set of fixed rules. We show how our approach is\nnecessary to facilitate the development of RL network defenders that are robust\nagainst attacks aimed at the agent's learning. Our framework enables the\ndevelopment and simulation of adversaries with sophisticated behavior that\nincludes poisoning and evasion attacks on RL network defenders.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 00:30:19 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Molina-Markham", "Andres", ""], ["Miniter", "Cory", ""], ["Powell", "Becky", ""], ["Ridley", "Ahmad", ""]]}, {"id": "2103.07595", "submitter": "Mingkui Tan", "authors": "Jincheng Li, Jiezhang Cao, Yifan Zhang, Jian Chen, Mingkui Tan", "title": "Learning Defense Transformers for Counterattacking Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are vulnerable to adversarial examples with small\nperturbations. Adversarial defense thus has been an important means which\nimproves the robustness of DNNs by defending against adversarial examples.\nExisting defense methods focus on some specific types of adversarial examples\nand may fail to defend well in real-world applications. In practice, we may\nface many types of attacks where the exact type of adversarial examples in\nreal-world applications can be even unknown. In this paper, motivated by that\nadversarial examples are more likely to appear near the classification\nboundary, we study adversarial examples from a new perspective that whether we\ncan defend against adversarial examples by pulling them back to the original\nclean distribution. We theoretically and empirically verify the existence of\ndefense affine transformations that restore adversarial examples. Relying on\nthis, we learn a defense transformer to counterattack the adversarial examples\nby parameterizing the affine transformations and exploiting the boundary\ninformation of DNNs. Extensive experiments on both toy and real-world datasets\ndemonstrate the effectiveness and generalization of our defense transformer.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 02:03:53 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Li", "Jincheng", ""], ["Cao", "Jiezhang", ""], ["Zhang", "Yifan", ""], ["Chen", "Jian", ""], ["Tan", "Mingkui", ""]]}, {"id": "2103.07598", "submitter": "Mingkui Tan", "authors": "Jincheng Li, Jiezhang Cao, Shuhai Zhang, Yanwu Xu, Jian Chen, Mingkui\n  Tan", "title": "Internal Wasserstein Distance for Adversarial Attack and Defense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are vulnerable to adversarial examples that can\ntrigger misclassification of DNNs but may be imperceptible to human perception.\nAdversarial attack has been an important way to evaluate the robustness of\nDNNs. Existing attack methods on the construction of adversarial examples use\nsuch $\\ell_p$ distance as a similarity metric to perturb samples. However, this\nkind of metric is incompatible with the underlying real-world image formation\nand human visual perception. In this paper, we first propose an internal\nWasserstein distance (IWD) to measure image similarity between a sample and its\nadversarial example. We apply IWD to perform adversarial attack and defense.\nSpecifically, we develop a novel attack method by capturing the distribution of\npatches in original samples. In this case, our approach is able to generate\nsemantically similar but diverse adversarial examples that are more difficult\nto defend by existing defense methods. Relying on IWD, we also build a new\ndefense method that seeks to learn robust models to defend against unseen\nadversarial examples. We provide both thorough theoretical and empirical\nevidence to support our methods.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 02:08:02 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Li", "Jincheng", ""], ["Cao", "Jiezhang", ""], ["Zhang", "Shuhai", ""], ["Xu", "Yanwu", ""], ["Chen", "Jian", ""], ["Tan", "Mingkui", ""]]}, {"id": "2103.07633", "submitter": "Fu Song", "authors": "Zhe Zhao, Guangke Chen, Jingyi Wang, Yiwei Yang, Fu Song, Jun Sun", "title": "Attack as Defense: Characterizing Adversarial Examples using Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a new programming paradigm, deep learning has expanded its application to\nmany real-world problems. At the same time, deep learning based software are\nfound to be vulnerable to adversarial attacks. Though various defense\nmechanisms have been proposed to improve robustness of deep learning software,\nmany of them are ineffective against adaptive attacks. In this work, we propose\na novel characterization to distinguish adversarial examples from benign ones\nbased on the observation that adversarial examples are significantly less\nrobust than benign ones. As existing robustness measurement does not scale to\nlarge networks, we propose a novel defense framework, named attack as defense\n(A2D), to detect adversarial examples by effectively evaluating an example's\nrobustness. A2D uses the cost of attacking an input for robustness evaluation\nand identifies those less robust examples as adversarial since less robust\nexamples are easier to attack. Extensive experiment results on MNIST, CIFAR10\nand ImageNet show that A2D is more effective than recent promising approaches.\nWe also evaluate our defence against potential adaptive attacks and show that\nA2D is effective in defending carefully designed adaptive attacks, e.g., the\nattack success rate drops to 0% on CIFAR10.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 06:29:13 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Zhao", "Zhe", ""], ["Chen", "Guangke", ""], ["Wang", "Jingyi", ""], ["Yang", "Yiwei", ""], ["Song", "Fu", ""], ["Sun", "Jun", ""]]}, {"id": "2103.07653", "submitter": "Feng Liu", "authors": "Feng Liu and Qi Wang", "title": "An Identity-based Batch Verification Scheme for VANETs Based on Ring\n  Signature with Efficient Revocation", "comments": "arXiv admin note: substantial text overlap with arXiv:1909.13223", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicular ad-hoc networks (VANETs) are one of the most important components\nin Intelligent Transportation System (ITS), which aims to provide secure and\nefficient communication between vehicles. Safety-critical vehicular\ncommunication requires security, privacy, and auditability. To satisfy these\nrequirements simultaneously, several conditional privacy-preserving\nauthentication schemes are proposed by employing ring signatures. However,\nthese methods have paid little attention to the issues like how to choose the\nvalid ring members or how to set up a ring. In this paper, we introduce an\nefficient conditional privacy-preserving scheme which provides an appropriate\napproach establishing the list of ring members with efficient revocation.\nMoreover, our proposed scheme also provides batch verification to significantly\nreduce the computational cost. According to the analysis of security, our\nscheme is sufficiently resistant against several common attacks in VANETs. The\nperformance results show that the proposed scheme is efficient and practical\nwith both low computation and communication cost.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 08:29:12 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Liu", "Feng", ""], ["Wang", "Qi", ""]]}, {"id": "2103.07655", "submitter": "Kenji Saito", "authors": "Kenji Saito, Satoki Watanabe", "title": "Lightweight Selective Disclosure for Verifiable Documents on Blockchain", "comments": "8 pages, 3 figures, 1 table. Submitted to ICT Express", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To achieve lightweight selective disclosure for protecting privacy of\ndocument holders, we propose an XML format for documents that can hide\narbitrary elements using a cryptographic hash function and salts, which allows\nto be partially digitally signed and efficiently verified, as well as a JSON\nformat that can be converted to such XML. The documents can be efficiently\nproven to exist by representing multiple such structures as a Merkle tree and\nstoring its root in blockchain.\n  We show that our proposal has advantages over known methods that represent\nthe document itself as a Merkle tree and partially hide it.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 08:32:45 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Saito", "Kenji", ""], ["Watanabe", "Satoki", ""]]}, {"id": "2103.07662", "submitter": "Jeremy Straub", "authors": "Jeremy Straub", "title": "Defining, Evaluating, Preparing for and Responding to a Cyber Pearl\n  Harbor", "comments": null, "journal-ref": "Technology in Society 65 (2021)", "doi": "10.1016/j.techsoc.2021.101599", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Despite not having a clear meaning, public perception and awareness makes the\nterm cyber Pearl Harbor an important part of the public discourse. This paper\nconsiders what the term has meant and proposes its decomposition based on three\ndifferent aspects of the historical Pearl Harbor attack, allowing the lessons\nfrom Pearl Harbor to be applied to threats and subjects that may not align with\nall aspects of the 1941 attack. Using these three definitions, prior attacks\nand current threats are assessed and preparation for and response to cyber\nPearl Harbor events is discussed.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 09:15:27 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Straub", "Jeremy", ""]]}, {"id": "2103.07669", "submitter": "Kenji Saito", "authors": "Kenji Saito, Mitsuru Iwamura", "title": "Privacy-Preserving Infection Exposure Notification without Trust in\n  Third Parties", "comments": "17 pages, 5 figures, 1 table. Submitted to Journal of Communications\n  and Networks (JCN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In response to the COVID-19 pandemic, Bluetooth-based contact tracing has\nbeen deployed in many countries with the help of the developers of smartphone\noperating systems that provide APIs for privacy-preserving exposure\nnotification. However, it has been assumed by the design that the OS\ndevelopers, smartphone vendors, or governments will not violate people's\nprivacy. We propose a privacy-preserving exposure notification under situations\nwhere none of the middle entities can be trusted. We believe that it can be\nachieved with small changes to the existing mechanism: random numbers are\ngenerated on the application side instead of the OS, and the positive test\nresults are reported to a public ledger (e.g. blockchain) rather than to a\ngovernment server, with endorsements from the medical institutes with blind\nsignatures. We also discuss how to incentivize the peer-to-peer maintenance of\nthe public ledger if it should be newly built. We show that the level of\nverifiability is much higher with our proposed design if a consumer group were\nto verify the privacy protections of the deployed systems. We believe that this\nwill allow for safer contact tracing, and contribute to healthier lifestyles\nfor citizens who may want to or have to go out under pandemic situations.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 09:47:45 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Saito", "Kenji", ""], ["Iwamura", "Mitsuru", ""]]}, {"id": "2103.07704", "submitter": "Hye Young Paik", "authors": "Nicholas Malecki and Hye-young Paik and Aleksandar Ignjatovic and Alan\n  Blair and Elisa Bertino", "title": "Simeon -- Secure Federated Machine Learning Through Iterative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning enables a global machine learning model to be trained\ncollaboratively by distributed, mutually non-trusting learning agents who\ndesire to maintain the privacy of their training data and their hardware. A\nglobal model is distributed to clients, who perform training, and submit their\nnewly-trained model to be aggregated into a superior model. However, federated\nlearning systems are vulnerable to interference from malicious learning agents\nwho may desire to prevent training or induce targeted misclassification in the\nresulting global model. A class of Byzantine-tolerant aggregation algorithms\nhas emerged, offering varying degrees of robustness against these attacks,\noften with the caveat that the number of attackers is bounded by some quantity\nknown prior to training. This paper presents Simeon: a novel approach to\naggregation that applies a reputation-based iterative filtering technique to\nachieve robustness even in the presence of attackers who can exhibit arbitrary\nbehaviour. We compare Simeon to state-of-the-art aggregation techniques and\nfind that Simeon achieves comparable or superior robustness to a variety of\nattacks. Notably, we show that Simeon is tolerant to sybil attacks, where other\nalgorithms are not, presenting a key advantage of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 12:17:47 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Malecki", "Nicholas", ""], ["Paik", "Hye-young", ""], ["Ignjatovic", "Aleksandar", ""], ["Blair", "Alan", ""], ["Bertino", "Elisa", ""]]}, {"id": "2103.07765", "submitter": "David Noever", "authors": "David A. Noever, Samantha E. Miller Noever", "title": "Image Classifiers for Network Intrusions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This research recasts the network attack dataset from UNSW-NB15 as an\nintrusion detection problem in image space. Using one-hot-encodings, the\nresulting grayscale thumbnails provide a quarter-million examples for deep\nlearning algorithms. Applying the MobileNetV2's convolutional neural network\narchitecture, the work demonstrates a 97% accuracy in distinguishing normal and\nattack traffic. Further class refinements to 9 individual attack families\n(exploits, worms, shellcodes) show an overall 56% accuracy. Using feature\nimportance rank, a random forest solution on subsets show the most important\nsource-destination factors and the least important ones as mainly obscure\nprotocols. The dataset is available on Kaggle.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 18:09:08 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Noever", "David A.", ""], ["Noever", "Samantha E. Miller", ""]]}, {"id": "2103.07769", "submitter": "Preslav Nakov", "authors": "Preslav Nakov, David Corney, Maram Hasanain, Firoj Alam, Tamer\n  Elsayed, Alberto Barr\\'on-Cede\\~no, Paolo Papotti, Shaden Shaar, Giovanni Da\n  San Martino", "title": "Automated Fact-Checking for Assisting Human Fact-Checkers", "comments": "fact-checking, fact-checkers, check-worthiness, detecting previously\n  fact-checked claims, evidence retrieval", "journal-ref": "IJCAI-2021", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CR cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reporting and the analysis of current events around the globe has\nexpanded from professional, editor-lead journalism all the way to citizen\njournalism. Nowadays, politicians and other key players enjoy direct access to\ntheir audiences through social media, bypassing the filters of official cables\nor traditional media. However, the multiple advantages of free speech and\ndirect communication are dimmed by the misuse of media to spread inaccurate or\nmisleading claims. These phenomena have led to the modern incarnation of the\nfact-checker -- a professional whose main aim is to examine claims using\navailable evidence and to assess their veracity. As in other text forensics\ntasks, the amount of information available makes the work of the fact-checker\nmore difficult. With this in mind, starting from the perspective of the\nprofessional fact-checker, we survey the available intelligent technologies\nthat can support the human expert in the different steps of her fact-checking\nendeavor. These include identifying claims worth fact-checking, detecting\nrelevant previously fact-checked claims, retrieving relevant evidence to\nfact-check a claim, and actually verifying a claim. In each case, we pay\nattention to the challenges in future work and the potential impact on\nreal-world fact-checking.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 18:29:14 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 12:27:05 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Nakov", "Preslav", ""], ["Corney", "David", ""], ["Hasanain", "Maram", ""], ["Alam", "Firoj", ""], ["Elsayed", "Tamer", ""], ["Barr\u00f3n-Cede\u00f1o", "Alberto", ""], ["Papotti", "Paolo", ""], ["Shaar", "Shaden", ""], ["Martino", "Giovanni Da San", ""]]}, {"id": "2103.07781", "submitter": "Khaled Alanezi", "authors": "Khaled Alanezi and Shivakant Mishra", "title": "Incorporating Individual and Group Privacy Preferences in the Internet\n  of Things", "comments": null, "journal-ref": null, "doi": "10.1007/s12652-021-02959-7", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a new privacy negotiation mechanism for an IoT\nenvironment that is both efficient and practical to cope with the IoT special\nneed of seamlessness. This mechanism allows IoT users to express and enforce\ntheir personal privacy preferences in a seamless manner while interacting with\nIoT deployments. A key contribution of the paper is that it addresses the\nprivacy concerns of individual users as well as a group of users where privacy\npreferences of all individual users are combined into a group privacy profile\nto be negotiated with the IoT owner. In addition, the proposed mechanism\nsatisfies the privacy requirements of the IoT deployment owner. Finally, the\nproposed privacy mechanism is agnostic to the actual IoT architecture and can\nbe used over a user-managed, edge-managed or a cloud-managed IoT architecture.\nPrototypes of the proposed mechanism have been implemented for each of these\nthree architectures, and the results show the capability of the protocol to\nnegotiate privacy while adding insignificant time overhead.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 20:05:02 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Alanezi", "Khaled", ""], ["Mishra", "Shivakant", ""]]}, {"id": "2103.07853", "submitter": "Hongsheng Hu", "authors": "Hongsheng Hu and Zoran Salcic and Gillian Dobbie and Xuyun Zhang", "title": "Membership Inference Attacks on Machine Learning: A Survey", "comments": "32 pages, 6 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Membership inference attack aims to identify whether a data sample was used\nto train a machine learning model or not. It can raise severe privacy risks as\nthe membership can reveal an individual's sensitive information. For example,\nidentifying an individual's participation in a hospital's health analytics\ntraining set reveals that this individual was once a patient in that hospital.\nMembership inference attacks have been shown to be effective on various machine\nlearning models, such as classification models, generative models, and\nsequence-to-sequence models. Meanwhile, many methods are proposed to defend\nsuch a privacy attack. Although membership inference attack is an emerging and\nrapidly growing research area, there is no comprehensive survey on this topic\nyet. In this paper, we bridge this important gap in membership inference attack\nliterature. We present the first comprehensive survey of membership inference\nattacks. We summarize and categorize existing membership inference attacks and\ndefenses and explicitly present how to implement attacks in various settings.\nBesides, we discuss why membership inference attacks work and summarize the\nbenchmark datasets to facilitate comparison and ensure fairness of future work.\nFinally, we propose several possible directions for future research and\npossible applications relying on reviewed works.\n", "versions": [{"version": "v1", "created": "Sun, 14 Mar 2021 06:10:47 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 03:21:35 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Hu", "Hongsheng", ""], ["Salcic", "Zoran", ""], ["Dobbie", "Gillian", ""], ["Zhang", "Xuyun", ""]]}, {"id": "2103.07934", "submitter": "Tharrmashastha Sapv", "authors": "Debajyoti Bera, Tharrmashastha Sapv", "title": "Quantum and Randomised Algorithms for Non-linearity Estimation", "comments": "Accepted in ACM Transactions on Quantum Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Non-linearity of a Boolean function indicates how far it is from any linear\nfunction. Despite there being several strong results about identifying a linear\nfunction and distinguishing one from a sufficiently non-linear function, we\nfound a surprising lack of work on computing the non-linearity of a function.\nThe non-linearity is related to the Walsh coefficient with the largest absolute\nvalue; however, the naive attempt of picking the maximum after constructing a\nWalsh spectrum requires $\\Theta(2^n)$ queries to an $n$-bit function. We\nimprove the scenario by designing highly efficient quantum and randomised\nalgorithms to approximate the non-linearity allowing additive error, denoted\n$\\lambda$, with query complexities that depend polynomially on $\\lambda$. We\nprove lower bounds to show that these are not very far from the optimal ones.\nThe number of queries made by our randomised algorithm is linear in $n$,\nalready an exponential improvement, and the number of queries made by our\nquantum algorithm is surprisingly independent of $n$. Our randomised algorithm\nuses a Goldreich-Levin style of navigating all Walsh coefficients and our\nquantum algorithm uses a clever combination of Deutsch-Jozsa, amplitude\namplification and amplitude estimation to improve upon the existing quantum\nversions of the Goldreich-Levin technique.\n", "versions": [{"version": "v1", "created": "Sun, 14 Mar 2021 14:13:50 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Bera", "Debajyoti", ""], ["Sapv", "Tharrmashastha", ""]]}, {"id": "2103.08007", "submitter": "Aron Laszka", "authors": "Yoko Shibuya, Go Yamamoto, Fuhito Kojima, Elaine Shi, Shin'ichiro\n  Matsuo, Aron Laszka", "title": "Selfish Mining Attacks Exacerbated by Elastic Hash Supply", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several attacks have been proposed against Proof-of-Work blockchains, which\nmay increase the attacker's share of mining rewards (e.g., selfish mining,\nblock withholding). A further impact of such attacks, which has not been\nconsidered in prior work, is that decreasing the profitability of mining for\nhonest nodes incentivizes them to stop mining or to leave the attacked chain\nfor a more profitable one. The departure of honest nodes exacerbates the attack\nand may further decrease profitability and incentivize more honest nodes to\nleave. In this paper, we first present an empirical analysis showing that there\nis a statistically significant correlation between the profitability of mining\nand the total hash rate, confirming that miners indeed respond to changing\nprofitability. Second, we present a theoretical analysis showing that selfish\nmining under such elastic hash supply leads either to the collapse of a chain,\ni.e., all honest nodes leaving, or to a stable equilibrium depending on the\nattacker's initial share.\n", "versions": [{"version": "v1", "created": "Sun, 14 Mar 2021 19:40:35 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Shibuya", "Yoko", ""], ["Yamamoto", "Go", ""], ["Kojima", "Fuhito", ""], ["Shi", "Elaine", ""], ["Matsuo", "Shin'ichiro", ""], ["Laszka", "Aron", ""]]}, {"id": "2103.08031", "submitter": "Manoj-Rohit Vemparala", "authors": "Manoj Rohit Vemparala, Alexander Frickenstein, Nael Fasfous, Lukas\n  Frickenstein, Qi Zhao, Sabine Kuhn, Daniel Ehrhardt, Yuankai Wu, Christian\n  Unger, Naveen Shankar Nagaraja, Walter Stechele", "title": "BreakingBED -- Breaking Binary and Efficient Deep Neural Networks by\n  Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deploying convolutional neural networks (CNNs) for embedded applications\npresents many challenges in balancing resource-efficiency and task-related\naccuracy. These two aspects have been well-researched in the field of CNN\ncompression. In real-world applications, a third important aspect comes into\nplay, namely the robustness of the CNN. In this paper, we thoroughly study the\nrobustness of uncompressed, distilled, pruned and binarized neural networks\nagainst white-box and black-box adversarial attacks (FGSM, PGD, C&W, DeepFool,\nLocalSearch and GenAttack). These new insights facilitate defensive training\nschemes or reactive filtering methods, where the attack is detected and the\ninput is discarded and/or cleaned. Experimental results are shown for distilled\nCNNs, agent-based state-of-the-art pruned models, and binarized neural networks\n(BNNs) such as XNOR-Net and ABC-Net, trained on CIFAR-10 and ImageNet datasets.\nWe present evaluation methods to simplify the comparison between CNNs under\ndifferent attack schemes using loss/accuracy levels, stress-strain graphs,\nbox-plots and class activation mapping (CAM). Our analysis reveals susceptible\nbehavior of uncompressed and pruned CNNs against all kinds of attacks. The\ndistilled models exhibit their strength against all white box attacks with an\nexception of C&W. Furthermore, binary neural networks exhibit resilient\nbehavior compared to their baselines and other compressed variants.\n", "versions": [{"version": "v1", "created": "Sun, 14 Mar 2021 20:43:19 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Vemparala", "Manoj Rohit", ""], ["Frickenstein", "Alexander", ""], ["Fasfous", "Nael", ""], ["Frickenstein", "Lukas", ""], ["Zhao", "Qi", ""], ["Kuhn", "Sabine", ""], ["Ehrhardt", "Daniel", ""], ["Wu", "Yuankai", ""], ["Unger", "Christian", ""], ["Nagaraja", "Naveen Shankar", ""], ["Stechele", "Walter", ""]]}, {"id": "2103.08128", "submitter": "Michael Zieve", "authors": "Zhiguo Ding and Michael E. Zieve", "title": "Tangent-Chebyshev rational maps and Redei functions", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently Lima and Campello de Souza introduced a new class of rational\nfunctions over odd-order finite fields, and explained their potential\nusefulness in cryptography. We show that these new functions are conjugate to\nthe classical family of Redei rational functions, so that the properties of the\nnew functions follow from properties of Redei functions. We also prove new\nproperties of these functions, and introduce analogous functions in\ncharacteristic 2, while also introducing a new version of trigonometry over\nfinite fields of even order, which is of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 04:12:09 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Ding", "Zhiguo", ""], ["Zieve", "Michael E.", ""]]}, {"id": "2103.08140", "submitter": "Nicholas Spooner", "authors": "Alessandro Chiesa, Fermi Ma, Nicholas Spooner, Mark Zhandry", "title": "Post-Quantum Succinct Arguments: Breaking the Quantum Rewinding Barrier", "comments": "50 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that Kilian's four-message succinct argument system is post-quantum\nsecure in the standard model when instantiated with any probabilistically\ncheckable proof and any collapsing hash function (which in turn exist based on\nthe post-quantum hardness of Learning with Errors). This yields the first\npost-quantum succinct argument system from any falsifiable assumption.\n  At the heart of our proof is a new quantum rewinding procedure that enables a\nreduction to repeatedly query a quantum adversary for accepting transcripts as\nmany times as desired. Prior techniques were limited to a constant number of\naccepting transcripts.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 05:09:17 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 20:34:34 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Chiesa", "Alessandro", ""], ["Ma", "Fermi", ""], ["Spooner", "Nicholas", ""], ["Zhandry", "Mark", ""]]}, {"id": "2103.08229", "submitter": "Georges-Axel Jaloyan", "authors": "Georges-Axel Jaloyan and Konstantinos Markantonakis and Raja Naeem\n  Akram and David Robin and Keith Mayes and David Naccache", "title": "Return-Oriented Programming on RISC-V", "comments": "27 pages, 8 figures, originally published at AsiaCCS 2020", "journal-ref": null, "doi": "10.1145/3320269.3384738", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides the first analysis on the feasibility of Return-Oriented\nProgramming (ROP) on RISC-V, a new instruction set architecture targeting\nembedded systems. We show the existence of a new class of gadgets, using\nseveral Linear Code Sequences And Jumps (LCSAJ), undetected by current\nGalileo-based ROP gadget searching tools. We argue that this class of gadgets\nis rich enough on RISC-V to mount complex ROP attacks, bypassing traditional\nmitigation like DEP, ASLR, stack canaries, G-Free, as well as some\ncompiler-based backward-edge CFI, by jumping over any guard inserted by a\ncompiler to protect indirect jump instructions. We provide examples of such\ngadgets, as well as a proof-of-concept ROP chain, using C code injection to\nleverage a privilege escalation attack on two standard Linux operating systems.\nAdditionally, we discuss some of the required mitigations to prevent such\nattacks and provide a new ROP gadget finder algorithm that handles this new\nclass of gadgets.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 09:26:19 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Jaloyan", "Georges-Axel", ""], ["Markantonakis", "Konstantinos", ""], ["Akram", "Raja Naeem", ""], ["Robin", "David", ""], ["Mayes", "Keith", ""], ["Naccache", "David", ""]]}, {"id": "2103.08304", "submitter": "Michael Kuperberg", "authors": "Michael Kuperberg", "title": "Scaling a Blockchain-based Railway Control System Prototype for Mainline\n  Railways: a Progress Report", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Railway operations require control systems to ensure safety and efficiency,\nand to coordinate infrastructure elements such as switches, signals and train\nprotection. To compete with the traditional approaches to these systems, a\nblockchain-based approach has been proposed, with the intent to build a more\nresilient, integrated and cost-efficient system. Additionally, the developed\nblockchain-based architecture enables to run safety-relevant and\nsecurity-focused business logic on off-the-shelf platforms such as cloud,\nrather than on specialized (and expensive) secure hardware. After implementing\na prototype of the blockchain-based railway control system, scaling the\napproach to real-world mainline and branch operations required a thorough\nvalidation of the design choices. In this technical report, we show how\nperformance calculations, long-term technology perspectives and law-mandated\nnorms have impacted the architecture, the technology choices, and the\nmake-buy-reuse decisions.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 12:33:35 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Kuperberg", "Michael", ""]]}, {"id": "2103.08361", "submitter": "Minghui Xu", "authors": "Minghui Xu, Feng Zhao, Yifei Zou, Chunchi Liu, Xiuzhen Cheng, Falko\n  Dressler", "title": "BLOWN: A Blockchain Protocol for Single-Hop Wireless Networks under\n  Adversarial SINR", "comments": "17 pages, 9 figures, journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Known as a distributed ledger technology (DLT), blockchain has attracted much\nattention due to its properties such as decentralization, security,\nimmutability and transparency, and its potential of servicing as an\ninfrastructure for various applications. Blockchain can empower wireless\nnetworks with identity management, data integrity, access control, and\nhigh-level security. However, previous studies on blockchain-enabled wireless\nnetworks mostly focus on proposing architectures or building systems with\npopular blockchain protocols. Nevertheless, such existing protocols have\nobvious shortcomings when adopted in wireless networks where nodes have limited\nphysical resources, fall short of well-established reliable channels, variable\nbandwidths impacted by environments or jamming attacks. In this paper, we\npropose a novel consensus protocol named Proof-of-Channel (PoC) leveraging the\nnatural properties of wireless communications, and a BLOWN protocol (BLOckchain\nprotocol for Wireless Networks) for wireless networks under an adversarial SINR\nmodel. We formalize BLOWN with the universal composition framework and prove\nits security properties, namely persistence and liveness, as well as its\nstrengths in countering against adversarial jamming, double-spending, and Sybil\nattacks, which are also demonstrated by extensive simulation studies.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 13:01:04 GMT"}, {"version": "v2", "created": "Sun, 11 Apr 2021 11:58:57 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Xu", "Minghui", ""], ["Zhao", "Feng", ""], ["Zou", "Yifei", ""], ["Liu", "Chunchi", ""], ["Cheng", "Xiuzhen", ""], ["Dressler", "Falko", ""]]}, {"id": "2103.08403", "submitter": "Weikang Li", "authors": "Weikang Li, Sirui Lu, Dong-Ling Deng", "title": "Quantum Private Distributed Learning Through Blind Quantum Computing", "comments": "6 pages (main text) + 3.5 pages (supplementary materials), 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Private distributed learning studies the problem of how multiple distributed\nentities collaboratively train a shared deep network with their private data\nunrevealed. With the security provided by the protocols of blind quantum\ncomputation, the cooperation between quantum physics and machine learning may\nlead to unparalleled prospect for solving private distributed learning tasks.\nIn this paper, we introduce a quantum protocol for distributed learning that is\nable to utilize the computational power of the remote quantum servers while\nkeeping the private data safe. For concreteness, we first introduce a protocol\nfor private single-party delegated training of variational quantum classifiers\nbased on blind quantum computing and then extend this protocol to multiparty\nprivate distributed learning incorporated with differential privacy. We carry\nout extensive numerical simulations with different real-life datasets and\nencoding strategies to benchmark the effectiveness of our protocol. We find\nthat our protocol is robust to experimental imperfections and is secure under\nthe gradient attack after the incorporation of differential privacy. Our\nresults show the potential for handling computationally expensive distributed\nlearning tasks with privacy guarantees, thus providing a valuable guide for\nexploring quantum advantages from the security perspective in the field of\nmachine learning with real-life applications.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 14:26:01 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Li", "Weikang", ""], ["Lu", "Sirui", ""], ["Deng", "Dong-Ling", ""]]}, {"id": "2103.08436", "submitter": "Paolo Modesti", "authors": "Paolo Modesti, Siamak F. Shahandashti, Patrick McCorry, Feng Hao", "title": "Formal Modelling and Security Analysis of Bitcoin's Payment Protocol", "comments": "30 pages, 6 figures. This is an accepted manuscript to appear in\n  Computers & Security. Please cite as: Modesti, Shahandashti, McCorry, and\n  Hao. \"Formal Modelling and Security Analysis of Bitcoin's Payment Protocol\".\n  To appear in Computer & Security, Elsevier, 2021", "journal-ref": null, "doi": "10.1016/j.cose.2021.102279", "report-no": null, "categories": "cs.CR cs.FL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The Payment Protocol standard BIP70, specifying how payments in Bitcoin are\nperformed by merchants and customers, is supported by the largest payment\nprocessors and most widely-used wallets. The protocol has been shown to be\nvulnerable to refund attacks due to lack of authentication of the refund\naddresses. In this paper, we give the first formal model of the protocol and\nformalise the refund address security goals for the protocol, namely refund\naddress authentication and secrecy. The formal model utilises communication\nchannels as abstractions conveying security goals on which the protocol\nmodeller and verifier can rely. We analyse the Payment Protocol confirming that\nit is vulnerable to an attack violating the refund address authentication\nsecurity goal. Moreover, we present a concrete protocol revision proposal\nsupporting the merchant with publicly verifiable evidence that can mitigate the\nattack. We verify that the revised protocol meets the security goals defined\nfor the refund address. Hence, we demonstrate that the revised protocol is\nsecure, not only against the existing attacks, but also against any further\nattacks violating the formalised security goals.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 15:05:01 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Modesti", "Paolo", ""], ["Shahandashti", "Siamak F.", ""], ["McCorry", "Patrick", ""], ["Hao", "Feng", ""]]}, {"id": "2103.08440", "submitter": "Johannes Krupp", "authors": "Johannes Krupp, Christian Rossow", "title": "BGPeek-a-Boo: Active BGP-based Traceback for Amplification DDoS Attacks", "comments": "6th IEEE European Symposium on Security and Privacy (EuroS&P) 2021 ;\n  \\copyright 2021 IEEE. Personal use of this material is permitted. Permission\n  from IEEE must be obtained for all other uses", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Amplification DDoS attacks inherently rely on IP spoofing to steer attack\ntraffic to the victim. At the same time, IP spoofing undermines prosecution, as\nthe originating attack infrastructure remains hidden. Researchers have\ntherefore proposed various mechanisms to trace back amplification attacks (or\nIP-spoofed attacks in general). However, existing traceback techniques require\neither the cooperation of external parties or a priori knowledge about the\nattacker. We propose BGPeek-a-Boo, a BGP-based approach to trace back\namplification attacks to their origin network. BGPeek-a-Boo monitors\namplification attacks with honeypots and uses BGP poisoning to temporarily shut\ndown ingress traffic from selected Autonomous Systems. By systematically\nprobing the entire AS space, we detect systems forwarding and originating\nspoofed traffic. We then show how a graph-based model of BGP route propagation\ncan reduce the search space, resulting in a 5x median speed-up and over 20x for\n1/4 of all cases. BGPeek-a-Boo achieves a unique traceback result 60% of the\ntime in a simulation-based evaluation supported by real-world experiments.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 15:10:19 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Krupp", "Johannes", ""], ["Rossow", "Christian", ""]]}, {"id": "2103.08442", "submitter": "Anca Jurcut Dr.", "authors": "Promise Agbedanu and Anca Delia Jurcut", "title": "BLOFF: A Blockchain based Forensic Model in IoT", "comments": null, "journal-ref": "Revolutionary Applications of Blockchain-Enabled Privacy and\n  Access Control, Editors Surjit Singh (Thapar Institute of Engineering and\n  Technology, India) and Anca Delia Jurcut (University College Dublin,\n  Ireland), IGI Global, April 2021", "doi": "10.4018/978-1-7998-7589-5.ch003", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this era of explosive growth in technology, the internet of things (IoT)\nhas become the game changer when we consider technologies like smart homes and\ncities, smart energy, security and surveillance, and healthcare. The numerous\nbenefits provided by IoT have become attractive technologies for users and\ncybercriminals. Cybercriminals of today have the tools and the technology to\ndeploy millions of sophisticated attacks. These attacks need to be\ninvestigated; this is where digital forensics comes into play. However, it is\nnot easy to conduct a forensic investigation in IoT systems because of the\nheterogeneous nature of the IoT environment. Additionally, forensic\ninvestigators mostly rely on evidence from service providers, a situation that\ncan lead to evidence contamination. To solve this problem, the authors proposed\na blockchain-based IoT forensic model that prevents the admissibility of\ntampered logs into evidence.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 15:11:07 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Agbedanu", "Promise", ""], ["Jurcut", "Anca Delia", ""]]}, {"id": "2103.08455", "submitter": "Fan Yin", "authors": "Fan Yin, Rongxing Lu, Yandong Zheng, Jun Shao, Xue Yang, Xiaohu Tang", "title": "Achieve Efficient Position-Heap-based Privacy-Preserving\n  Substring-of-Keyword Query over Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cloud computing technique, which was initially used to mitigate the\nexplosive growth of data, has been required to take both data privacy and\nusers' query functionality into consideration. Symmetric searchable encryption\n(SSE) is a popular solution to supporting efficient keyword queries over\nencrypted data in the cloud. However, most of the existing SSE schemes focus on\nthe exact keyword query and cannot work well when the user only remembers the\nsubstring of a keyword, i.e., substring-of-keyword query. This paper aims to\ninvestigate this issue by proposing an efficient and privacy-preserving\nsubstring-of-keyword query scheme over cloud. First, we employ the position\nheap technique to design a novel tree-based index to match substrings with\ncorresponding keywords. Based on the tree-based index, we introduce our\nsubstring-of-keyword query scheme, which contains two consecutive phases. The\nfirst phase queries the keywords that match a given substring, and the second\nphase queries the files that match a keyword in which people are really\ninterested. In addition, detailed security analysis and experimental results\ndemonstrate the security and efficiency of our proposed scheme.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 15:28:20 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Yin", "Fan", ""], ["Lu", "Rongxing", ""], ["Zheng", "Yandong", ""], ["Shao", "Jun", ""], ["Yang", "Xue", ""], ["Tang", "Xiaohu", ""]]}, {"id": "2103.08472", "submitter": "Ge Ren", "authors": "Ge Ren, Jun Wu, Gaolei Li, Shenghong Li", "title": "Automatically Lock Your Neural Networks When You're Away", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The smartphone and laptop can be unlocked by face or fingerprint recognition,\nwhile neural networks which confront numerous requests every day have little\ncapability to distinguish between untrustworthy and credible users. It makes\nmodel risky to be traded as a commodity. Existed research either focuses on the\nintellectual property rights ownership of the commercialized model, or traces\nthe source of the leak after pirated models appear. Nevertheless, active\nidentifying users legitimacy before predicting output has not been considered\nyet. In this paper, we propose Model-Lock (M-LOCK) to realize an end-to-end\nneural network with local dynamic access control, which is similar to the\nautomatic locking function of the smartphone to prevent malicious attackers\nfrom obtaining available performance actively when you are away. Three kinds of\nmodel training strategy are essential to achieve the tremendous performance\ndivergence between certified and suspect input in one neural network. Extensive\nexperiments based on MNIST, FashionMNIST, CIFAR10, CIFAR100, SVHN and GTSRB\ndatasets demonstrated the feasibility and effectiveness of the proposed scheme.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 15:47:54 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Ren", "Ge", ""], ["Wu", "Jun", ""], ["Li", "Gaolei", ""], ["Li", "Shenghong", ""]]}, {"id": "2103.08514", "submitter": "Sara Ramezanian", "authors": "Sara Ramezanian, Tommi Meskanen, and Valtteri Niemi", "title": "Multi-party Private Set Operations with an External Decider", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Private Set Operation (PSO) protocol involves at least two parties with\ntheir private input sets. The goal of the protocol is for the parties to learn\nthe output of a set operation, i.e. set intersection, on their input sets,\nwithout revealing any information about the items that are not in the output\nset. Commonly, the outcome of the set operation is revealed to parties and\nno-one else. However, in many application areas of PSO the result of the set\noperation should be learned by an external participant whom does not have an\ninput set. We call this participant the decider. In this paper, we present new\nvariants of multi-party PSO, where there is a decider who gets the result. All\nparties expect the decider have a private set. Other parties neither learn this\nresult, nor anything else about this protocol. Moreover, we present a generic\nsolution to the problem of PSO.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 16:36:33 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Ramezanian", "Sara", ""], ["Meskanen", "Tommi", ""], ["Niemi", "Valtteri", ""]]}, {"id": "2103.08560", "submitter": "Eric Wagner", "authors": "Eric Wagner, Jan Bauer, Martin Henze", "title": "Take a Bite of the Reality Sandwich: Revisiting the Security of\n  Progressive Message Authentication Codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Message authentication guarantees the integrity of messages exchanged over\nuntrusted channels. Yet, the required per-message authentication tags\nconsiderably expand packet sizes, which is especially problematic in\nconstrained environments. To address this issue, progressive message\nauthentication aggregates and distributes integrity protection over multiple\nmessages, promising to reduce overheads while upholding strong security of\ntraditional integrity protection. However, as we show in this paper, existing\nprogressive message authentication schemes are susceptible to packet drops: By\ninterfering with just two selected packets, an attacker can remove integrity\nprotection from a complete sequence of messages.\n  Revisiting the security of progressive message authentication, we consider it\nimperative to thwart such attacks by rethinking how authentication tags depend\non the successful reception of packets. To this end, we propose R2-D2, which\nrelies on randomized dependencies with parameterized security guarantees to\nmitigate network-level attacks inherent to current progressive authentication\nschemes. To deploy our approach to resource-constrained devices, we introduce\nSP-MAC, which implements R2-D2 using efficient XOR operations. Our evaluation\nshows that SP-MAC protects against sophisticated network-layer attacks, and\nstill operates as resources-conscious and fast as existing insecure schemes.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 17:24:37 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 11:23:41 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Wagner", "Eric", ""], ["Bauer", "Jan", ""], ["Henze", "Martin", ""]]}, {"id": "2103.08576", "submitter": "Rene Pickhardt", "authors": "Rene Pickhardt, Sergei Tikhomirov, Alex Biryukov, Mariusz Nowostawski", "title": "Security and Privacy of Lightning Network Payments with Uncertain\n  Channel Balances", "comments": "16 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The Lightning Network (LN) is a prominent payment channel network aimed at\naddressing Bitcoin's scalability issues. Due to the privacy of channel\nbalances, senders cannot reliably choose sufficiently liquid payment paths and\nresort to a trial-and-error approach, trying multiple paths until one succeeds.\nThis leaks private information and decreases payment reliability, which harms\nthe user experience. This work focuses on the reliability and privacy of LN\npayments. We create a probabilistic model of the payment process in the LN,\naccounting for the uncertainty of the channel balances. This enables us to\nexpress payment success probabilities for a given payment amount and a path.\nApplying negative Bernoulli trials for single- and multi-part payments allows\nus to compute the expected number of payment attempts for a given amount,\nsender, and receiver. As a consequence, we analytically derive the optimal\nnumber of parts into which one should split a payment to minimize the expected\nnumber of attempts. This methodology allows us to define service level\nobjectives and quantify how much private information leaks to the sender as a\nside effect of payment attempts. We propose an optimized path selection\nalgorithm that does not require a protocol upgrade. Namely, we suggest that\nnodes prioritize paths that are most likely to succeed while making payment\nattempts. A simulation based on the real-world LN topology shows that this\nmethod reduces the average number of payment attempts by 20% compared to a\nbaseline algorithm similar to the ones used in practice. This improvement will\nincrease to 48% if the LN protocol is upgraded to implement the channel\nrebalancing proposal described in BOLT14.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 17:43:55 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Pickhardt", "Rene", ""], ["Tikhomirov", "Sergei", ""], ["Biryukov", "Alex", ""], ["Nowostawski", "Mariusz", ""]]}, {"id": "2103.08577", "submitter": "Ethan Cecchetti", "authors": "Ethan Cecchetti, Siqiu Yao, Haobin Ni, Andrew C. Myers", "title": "Compositional Security for Reentrant Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The disastrous vulnerabilities in smart contracts sharply remind us of our\nignorance: we do not know how to write code that is secure in composition with\nmalicious code. Information flow control has long been proposed as a way to\nachieve compositional security, offering strong guarantees even when combining\nsoftware from different trust domains. Unfortunately, this appealing story\nbreaks down in the presence of reentrancy attacks. We formalize a general\ndefinition of reentrancy and introduce a security condition that allows\nsoftware modules like smart contracts to protect their key invariants while\nretaining the expressive power of safe forms of reentrancy. We present a\nsecurity type system that provably enforces secure information flow; in\nconjunction with run-time mechanisms, it enforces secure reentrancy even in the\npresence of unknown code; and it helps locate and correct recent high-profile\nvulnerabilities.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 17:45:04 GMT"}, {"version": "v2", "created": "Sat, 27 Mar 2021 21:06:41 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Cecchetti", "Ethan", ""], ["Yao", "Siqiu", ""], ["Ni", "Haobin", ""], ["Myers", "Andrew C.", ""]]}, {"id": "2103.08585", "submitter": "Islam Debicha", "authors": "Islam Debicha, Thibault Debatty, Wim Mees and Jean-Michel Dricot", "title": "Efficient Intrusion Detection Using Evidence Theory", "comments": "Already published in The Twelfth International Conference on Evolving\n  Internet (INTERNET 2020)", "journal-ref": "In The Twelfth International Conference on Evolving Internet\n  (INTERNET 2020), pp. 28-32, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrusion Detection Systems (IDS) are now an essential element when it comes\nto securing computers and networks. Despite the huge research efforts done in\nthe field, handling sources' reliability remains an open issue. To address this\nproblem, this paper proposes a novel contextual discounting method based on\nsources' reliability and their distinguishing ability between normal and\nabnormal behavior. Dempster-Shafer theory, a general framework for reasoning\nunder uncertainty, is used to construct an evidential classifier. The NSL-KDD\ndataset, a significantly revised and improved version of the existing KDDCUP'99\ndataset, provides the basis for assessing the performance of our new detection\napproach. While giving comparable results on the KDDTest+ dataset, our approach\noutperformed some other state-of-the-art methods on the KDDTest-21 dataset\nwhich is more challenging.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 17:54:16 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Debicha", "Islam", ""], ["Debatty", "Thibault", ""], ["Mees", "Wim", ""], ["Dricot", "Jean-Michel", ""]]}, {"id": "2103.08712", "submitter": "Cuneyt Gurcan Akcora", "authors": "Cuneyt Gurcan Akcora and Murat Kantarcioglu and Yulia R. Gel", "title": "Blockchain Networks: Data Structures of Bitcoin, Monero, Zcash,\n  Ethereum, Ripple and Iota", "comments": "27 figures, 8 tables, 40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain is an emerging technology that has already enabled a wide range of\napplications, from cryptocurrencies to digital asset management to supply\nchains. Due to this surge of popularity, analyzing the data stored on\nblockchains transpires as a new critical challenge in data science. To assist\ndata scientists in various analytic tasks on a blockchain, we provide a\nsystematic and comprehensive overview of the fundamental elements of blockchain\nnetwork models. We discuss how blockchain data can be abstracted as various\ntypes of networks, and how such associated network abstractions can be further\nused to reap important insights into the structure, organization, and\nfunctionality of blockchains.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 20:49:55 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Akcora", "Cuneyt Gurcan", ""], ["Kantarcioglu", "Murat", ""], ["Gel", "Yulia R.", ""]]}, {"id": "2103.08721", "submitter": "Jinshuo Dong", "authors": "Jinshuo Dong, Weijie J. Su, Linjun Zhang", "title": "A Central Limit Theorem for Differentially Private Query Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Perhaps the single most important use case for differential privacy is to\nprivately answer numerical queries, which is usually achieved by adding noise\nto the answer vector. The central question, therefore, is to understand which\nnoise distribution optimizes the privacy-accuracy trade-off, especially when\nthe dimension of the answer vector is high. Accordingly, extensive literature\nhas been dedicated to the question and the upper and lower bounds have been\nmatched up to constant factors [BUV18, SU17]. In this paper, we take a novel\napproach to address this important optimality question. We first demonstrate an\nintriguing central limit theorem phenomenon in the high-dimensional regime.\nMore precisely, we prove that a mechanism is approximately Gaussian\nDifferentially Private [DRS21] if the added noise satisfies certain conditions.\nIn particular, densities proportional to $\\mathrm{e}^{-\\|x\\|_p^\\alpha}$, where\n$\\|x\\|_p$ is the standard $\\ell_p$-norm, satisfies the conditions. Taking this\nperspective, we make use of the Cramer--Rao inequality and show an \"uncertainty\nprinciple\"-style result: the product of the privacy parameter and the\n$\\ell_2$-loss of the mechanism is lower bounded by the dimension. Furthermore,\nthe Gaussian mechanism achieves the constant-sharp optimal privacy-accuracy\ntrade-off among all such noises. Our findings are corroborated by numerical\nexperiments.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 21:06:25 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Dong", "Jinshuo", ""], ["Su", "Weijie J.", ""], ["Zhang", "Linjun", ""]]}, {"id": "2103.08747", "submitter": "Ya Xiao", "authors": "Ya Xiao, Salman Ahmed, Wenjia Song, Xinyang Ge, Bimal Viswanath,\n  Danfeng Yao", "title": "Embedding Code Contexts for Cryptographic API Suggestion:New\n  Methodologies and Comparisons", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent research efforts, the vision of automatic code generation\nthrough API recommendation has not been realized. Accuracy and expressiveness\nchallenges of API recommendation needs to be systematically addressed. We\npresent a new neural network-based approach, Multi-HyLSTM for API\nrecommendation --targeting cryptography-related code. Multi-HyLSTM leverages\nprogram analysis to guide the API embedding and recommendation. By analyzing\nthe data dependence paths of API methods, we train embedding and specialize a\nmulti-path neural network architecture for API recommendation tasks that\naccurately predict the next API method call. We address two previously\nunreported programming language-specific challenges, differentiating\nfunctionally similar APIs and capturing low-frequency long-range influences.\nOur results confirm the effectiveness of our design choices, including\nprogram-analysis-guided embedding, multi-path code suggestion architecture, and\nlow-frequency long-range-enhanced sequence learning, with high accuracy on\ntop-1 recommendations. We achieve a top-1 accuracy of 91.41% compared with\n77.44% from the state-of-the-art tool SLANG. In an analysis of 245 test cases,\ncompared with the commercial tool Codota, we achieve a top-1 recommendation\naccuracy of 88.98%, which is significantly better than Codota's accuracy of\n64.90%. We publish our data and code as a large Java cryptographic code\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 22:27:57 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 02:16:07 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Xiao", "Ya", ""], ["Ahmed", "Salman", ""], ["Song", "Wenjia", ""], ["Ge", "Xinyang", ""], ["Viswanath", "Bimal", ""], ["Yao", "Danfeng", ""]]}, {"id": "2103.08805", "submitter": "Chike Abuah", "authors": "Chike Abuah, Alex Silence, David Darais, Joe Near", "title": "DDUO: General-Purpose Dynamic Analysis for Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Differential privacy enables general statistical analysis of data with formal\nguarantees of privacy protection at the individual level. Tools that assist\ndata analysts with utilizing differential privacy have frequently taken the\nform of programming languages and libraries. However, many existing programming\nlanguages designed for compositional verification of differential privacy\nimpose significant burden on the programmer (in the form of complex type\nannotations). Supplementary library support for privacy analysis built on top\nof existing general-purpose languages has been more usable, but incapable of\npervasive end-to-end enforcement of sensitivity analysis and privacy\ncomposition. We introduce DDUO, a dynamic analysis for enforcing differential\nprivacy. DDUO is usable by non-experts: its analysis is automatic and it\nrequires no additional type annotations. DDUO can be implemented as a library\nfor existing programming languages; we present a reference implementation in\nPython which features moderate runtime overheads on realistic workloads. We\ninclude support for several data types, distance metrics and operations which\nare commonly used in modern machine learning programs. We also provide initial\nsupport for tracking the sensitivity of data transformations in popular Python\nlibraries for data analysis. We formalize the novel core of the DDUO system and\nprove it sound for sensitivity analysis via a logical relation for metric\npreservation. We also illustrate DDUO's usability and flexibility through\nvarious case studies which implement state-of-the-art machine learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 02:11:43 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Abuah", "Chike", ""], ["Silence", "Alex", ""], ["Darais", "David", ""], ["Near", "Joe", ""]]}, {"id": "2103.08820", "submitter": "Yingqi Liu", "authors": "Yingqi Liu, Guangyu Shen, Guanhong Tao, Zhenting Wang, Shiqing Ma,\n  Xiangyu Zhang", "title": "EX-RAY: Distinguishing Injected Backdoor from Natural Features in Neural\n  Networks by Examining Differential Feature Symmetry", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Backdoor attack injects malicious behavior to models such that inputs\nembedded with triggers are misclassified to a target label desired by the\nattacker. However, natural features may behave like triggers, causing\nmisclassification once embedded. While they are inevitable, mis-recognizing\nthem as injected triggers causes false warnings in backdoor scanning. A\nprominent challenge is hence to distinguish natural features and injected\nbackdoors. We develop a novel symmetric feature differencing method that\nidentifies a smallest set of features separating two classes. A backdoor is\nconsidered injected if the corresponding trigger consists of features different\nfrom the set of features distinguishing the victim and target classes. We\nevaluate the technique on thousands of models, including both clean and\ntrojaned models, from the TrojAI rounds 2-4 competitions and a number of models\non ImageNet. Existing backdoor scanning techniques may produce hundreds of\nfalse positives (i.e., clean models recognized as trojaned). Our technique\nremoves 78-100% of the false positives (by a state-of-the-art scanner ABS) with\na small increase of false negatives by 0-30%, achieving 17-41% overall accuracy\nimprovement, and facilitates achieving top performance on the leaderboard. It\nalso boosts performance of other scanners. It outperforms false positive\nremoval methods using L2 distance and attribution techniques. We also\ndemonstrate its potential in detecting a number of semantic backdoor attacks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 03:07:31 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 04:15:58 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Liu", "Yingqi", ""], ["Shen", "Guangyu", ""], ["Tao", "Guanhong", ""], ["Wang", "Zhenting", ""], ["Ma", "Shiqing", ""], ["Zhang", "Xiangyu", ""]]}, {"id": "2103.08908", "submitter": "Jingyu Feng", "authors": "Jingyu Feng, Yifei Shi, Neal N. Xiong, Feng Xiao", "title": "Blockchain-assisted Undisclosed IIoT Vulnerabilities Trusted Sharing\n  Protection with Dynamic Token", "comments": "10 pages,12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the large-scale deployment of industrial internet of things (IIoT)\ndevices, the number of vulnerabilities that threaten IIoT security is also\ngrowing dramatically, including a mass of undisclosed IIoT vulnerabilities that\nlack mitigation measures. Coordination Vulnerabilities Disclosure (CVD) is one\nof the most popular vulnerabilities sharing solutions, in which some security\nworkers (SWs) can develop undisclosed vulnerabilities patches together.\nHowever, CVD assumes that sharing participants (SWs) are all honest, and thus\noffering chances for dishonest SWs to leak undisclosed IIoT vulnerabilities. To\ncombat such threats, we propose an Undisclosed IIoT Vulnerabilities Trusted\nSharing Protection (UIV-TSP) scheme with dynamic token. In this article, a\ndynamic token is an implicit access credential for an SW to acquire an\nundisclosed vulnerability information, which is only held by the system and\nconstantly updated as the SW access. Meanwhile, the latest updated token can be\nstealthily sneaked into the acquired information as the traceability token.\nOnce the undisclosed vulnerability information leaves the SW host, the embedded\nself-destruct program will be automatically triggered to prevent leaks since\nthe destination MAC address in the traceability token has changed. To quickly\ndistinguish dishonest SWs, trust mechanism is adopted to evaluate the trust\nvalue of SWs. Moreover, we design a blockchain-assisted continuous logs storage\nmethod to achieve the tamper-proofing of dynamic token and the transparency of\nundisclosed IIoT vulnerabilities sharing. The simulation results indicate that\nour proposed scheme is resilient to suppress dishonest SWs and protect the IoT\nundisclosed vulnerabilities effectively.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 08:30:33 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Feng", "Jingyu", ""], ["Shi", "Yifei", ""], ["Xiong", "Neal N.", ""], ["Xiao", "Feng", ""]]}, {"id": "2103.08975", "submitter": "Ansis Rosmanis", "authors": "Ansis Rosmanis", "title": "Tight Bounds for Inverting Permutations via Compressed Oracle Arguments", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In his seminal work on recording quantum queries [Crypto 2019], Zhandry\nstudied interactions between quantum query algorithms and the quantum oracle\ncorresponding to random functions. Zhandry presented a framework for\ninterpreting various states in the quantum space of the oracle that can be used\nto provide security proofs in quantum cryptography.\n  In this paper, we introduce a similar interpretation for the case when the\noracle corresponds to random permutations instead of random functions. Because\nboth random functions and random permutations are highly significant in\nsecurity proofs, we hope that the present framework will find applications in\nquantum cryptography. Additionally, we show how this framework can be used to\nprove that the success probability for a k-query quantum algorithm that\nattempts to invert a random N-element permutation is at most O(k^2/N).\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 11:05:48 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Rosmanis", "Ansis", ""]]}, {"id": "2103.08987", "submitter": "Sylvain Chatel", "authors": "Sylvain Chatel, Apostolos Pyrgelis, Juan Ramon Troncoso-Pastoriza,\n  Jean-Pierre Hubaux", "title": "SoK: Privacy-Preserving Collaborative Tree-based Model Learning", "comments": null, "journal-ref": "Proceedings on Privacy Enhancing Technologies (PoPETs), Vol. 2021,\n  Issue 3", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree-based models are among the most efficient machine learning techniques\nfor data mining nowadays due to their accuracy, interpretability, and\nsimplicity. The recent orthogonal needs for more data and privacy protection\ncall for collaborative privacy-preserving solutions. In this work, we survey\nthe literature on distributed and privacy-preserving training of tree-based\nmodels and we systematize its knowledge based on four axes: the learning\nalgorithm, the collaborative model, the protection mechanism, and the threat\nmodel. We use this to identify the strengths and limitations of these works and\nprovide for the first time a framework analyzing the information leakage\noccurring in distributed tree-based model learning.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 11:24:15 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 09:38:10 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Chatel", "Sylvain", ""], ["Pyrgelis", "Apostolos", ""], ["Troncoso-Pastoriza", "Juan Ramon", ""], ["Hubaux", "Jean-Pierre", ""]]}, {"id": "2103.09008", "submitter": "Erick Galinkin", "authors": "Erick Galinkin", "title": "The Influence of Dropout on Membership Inference in Differentially\n  Private Models", "comments": "Additional work ongoing, revisions expected June 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Differentially private models seek to protect the privacy of data the model\nis trained on, making it an important component of model security and privacy.\nAt the same time, data scientists and machine learning engineers seek to use\nuncertainty quantification methods to ensure models are as useful and\nactionable as possible. We explore the tension between uncertainty\nquantification via dropout and privacy by conducting membership inference\nattacks against models with and without differential privacy. We find that\nmodels with large dropout slightly increases a model's risk to succumbing to\nmembership inference attacks in all cases including in differentially private\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 12:09:51 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Galinkin", "Erick", ""]]}, {"id": "2103.09113", "submitter": "Mariano Ceccato", "authors": "Filippo Contro, Marco Crosara, Mariano Ceccato, Mila Dalla Preda", "title": "EtherSolve: Computing an Accurate Control-Flow Graph from Ethereum\n  Bytecode", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the immutable nature of Ethereum smart contracts and of their\ntransactions, quite many approaches have been proposed to detect defects and\nsecurity problems before smart contracts become persistent in the blockchain\nand they are granted control on substantial financial value.\n  Because smart contracts source code might not be available, static analysis\napproaches mostly face the challenge of analysing compiled Ethereum bytecode,\nthat is available directly from the official blockchain. However, due to the\nintrinsic complexity of Ethereum bytecode (especially in jump resolution),\nstatic analysis encounters significant obstacles that reduce the accuracy of\nexiting automated tools.\n  This paper presents a novel static analysis algorithm based on the symbolic\nexecution of the Ethereum operand stack that allows us to resolve jumps in\nEthereum bytecode and to construct an accurate control-flow graph (CFG) of the\ncompiled smart contracts. EtherSolve is a prototype implementation of our\napproach. Experimental results on a significant set of real world Ethereum\nsmart contracts show that EtherSolve improves the accuracy of the execrated\nCFGs with respect to the state of the art available approaches.\n  Many static analysis techniques are based on the CFG representation of the\ncode and would therefore benefit from the accurate extraction of the CFG. For\nexample, we implemented a simple extension of EtherSolve that allows to detect\ninstances of the re-entrancy vulnerability.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 14:51:53 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Contro", "Filippo", ""], ["Crosara", "Marco", ""], ["Ceccato", "Mariano", ""], ["Preda", "Mila Dalla", ""]]}, {"id": "2103.09258", "submitter": "Alexandros Kornilakis", "authors": "Manolis Chalkiadakis, Alexandros Kornilakis, Panagiotis Papadopoulos,\n  Evangelos P. Markatos, Nicolas Kourtellis", "title": "The Rise and Fall of Fake News sites: A Traffic Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, we have witnessed the rise of misinformation on the\nInternet, with online users constantly falling victims of fake news. A\nmultitude of past studies have analyzed fake news diffusion mechanics and\ndetection and mitigation techniques. However, there are still open questions\nabout their operational behavior such as: How old are fake news websites? Do\nthey typically stay online for long periods of time? Do such websites\nsynchronize with each other their up and down time? Do they share similar\ncontent through time? Which third-parties support their operations? How much\nuser traffic do they attract, in comparison to mainstream or real news\nwebsites? In this paper, we perform a first of its kind investigation to answer\nsuch questions regarding the online presence of fake news websites and\ncharacterize their behavior in comparison to real news websites. Based on our\nfindings, we build a content-agnostic ML classifier for automatic detection of\nfake news websites (i.e. accuracy) that are not yet included in manually\ncurated blacklists.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 18:10:22 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Chalkiadakis", "Manolis", ""], ["Kornilakis", "Alexandros", ""], ["Papadopoulos", "Panagiotis", ""], ["Markatos", "Evangelos P.", ""], ["Kourtellis", "Nicolas", ""]]}, {"id": "2103.09262", "submitter": "Zachary Parish", "authors": "Zach Parish, Amirali Salehi-Abari, Julie Thorpe", "title": "A Study on Priming Methods for Graphical Passwords", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recent work suggests that a type of nudge or priming technique called the\npresentation effect may potentially improve the security of PassPoints-style\ngraphical passwords. These nudges attempt to prime or non-intrusively bias user\npassword choices (i.e., point selections) by gradually revealing a background\nimage from a particular edge to another edge at password creation time. We\nconduct a large-scale user study (n=710) to develop further insights into the\npresence of this effect and to perform the first evaluations of its security\nimpacts. We explore the usability impacts of this effect using the subset\n(n=100) of participants who returned for all three sessions. Our usability\nanalyses indicate that these priming techniques do not harm usability. Our\nsecurity analyses reveal that the priming techniques can measurably enhance the\nsecurity of graphical passwords; however, this effect is dependent on the\ncombination of both the image and priming techniques used.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 18:16:49 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 01:11:18 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Parish", "Zach", ""], ["Salehi-Abari", "Amirali", ""], ["Thorpe", "Julie", ""]]}, {"id": "2103.09274", "submitter": "Yue Li", "authors": "Yue Li and Hongxia Wang and Mauro Barni", "title": "A survey of deep neural network watermarking techniques", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protecting the Intellectual Property Rights (IPR) associated to Deep Neural\nNetworks (DNNs) is a pressing need pushed by the high costs required to train\nsuch networks and the importance that DNNs are gaining in our society.\nFollowing its use for Multimedia (MM) IPR protection, digital watermarking has\nrecently been considered as a mean to protect the IPR of DNNs. While DNN\nwatermarking inherits some basic concepts and methods from MM watermarking,\nthere are significant differences between the two application areas, calling\nfor the adaptation of media watermarking techniques to the DNN scenario and the\ndevelopment of completely new methods. In this paper, we overview the most\nrecent advances in DNN watermarking, by paying attention to cast it into the\nbulk of watermarking theory developed during the last two decades, while at the\nsame time highlighting the new challenges and opportunities characterizing DNN\nwatermarking. Rather than trying to present a comprehensive description of all\nthe methods proposed so far, we introduce a new taxonomy of DNN watermarking\nand present a few exemplary methods belonging to each class. We hope that this\npaper will inspire new research in this exciting area and will help researchers\nto focus on the most innovative and challenging problems in the field.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 18:35:07 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Li", "Yue", ""], ["Wang", "Hongxia", ""], ["Barni", "Mauro", ""]]}, {"id": "2103.09320", "submitter": "William Kretschmer", "authors": "William Kretschmer", "title": "Quantum Pseudorandomness and Classical Complexity", "comments": "20 pages. V2: added a new result about Haar random oracles (Corollary\n  5); various writing improvements", "journal-ref": "16th Conference on the Theory of Quantum Computation,\n  Communication and Cryptography (TQC 2021), Leibniz International Proceedings\n  in Informatics (LIPIcs) 197, pp. 2:1-2:20 (2021)", "doi": "10.4230/LIPIcs.TQC.2021.2", "report-no": null, "categories": "quant-ph cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a quantum oracle relative to which $\\mathsf{BQP} = \\mathsf{QMA}$\nbut cryptographic pseudorandom quantum states and pseudorandom unitary\ntransformations exist, a counterintuitive result in light of the fact that\npseudorandom states can be \"broken\" by quantum Merlin-Arthur adversaries. We\nexplain how this nuance arises as the result of a distinction between\nalgorithms that operate on quantum and classical inputs. On the other hand, we\nshow that some computational complexity assumption is needed to construct\npseudorandom states, by proving that pseudorandom states do not exist if\n$\\mathsf{BQP} = \\mathsf{PP}$. We discuss implications of these results for\ncryptography, complexity theory, and quantum tomography.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 20:54:12 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 20:29:06 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Kretschmer", "William", ""]]}, {"id": "2103.09327", "submitter": "Tolulope Odetola", "authors": "Tolulope A. Odetola and Syed Rafay Hasan", "title": "SoWaF: Shuffling of Weights and Feature Maps: A Novel Hardware Intrinsic\n  Attack (HIA) on Convolutional Neural Network (CNN)", "comments": "5 pages, 6 figures, 2 tables, ISCAS 2021 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Security of inference phase deployment of Convolutional neural network (CNN)\ninto resource constrained embedded systems (e.g. low end FPGAs) is a growing\nresearch area. Using secure practices, third party FPGA designers can be\nprovided with no knowledge of initial and final classification layers. In this\nwork, we demonstrate that hardware intrinsic attack (HIA) in such a \"secure\"\ndesign is still possible. Proposed HIA is inserted inside mathematical\noperations of individual layers of CNN, which propagates erroneous operations\nin all the subsequent CNN layers that lead to misclassification. The attack is\nnon-periodic and completely random, hence it becomes difficult to detect. Five\ndifferent attack scenarios with respect to each CNN layer are designed and\nevaluated based on the overhead resources and the rate of triggering in\ncomparison to the original implementation. Our results for two CNN\narchitectures show that in all the attack scenarios, additional latency is\nnegligible (<0.61%), increment in DSP, LUT, FF is also less than 2.36%. Three\nattack scenarios do not require any additional BRAM resources, while in two\nscenarios BRAM increases, which compensates with the corresponding decrease in\nFF and LUTs. To the authors' best knowledge this work is the first to address\nthe hardware intrinsic CNN attack with the attacker does not have knowledge of\nthe full CNN.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 21:12:07 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 15:28:05 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Odetola", "Tolulope A.", ""], ["Hasan", "Syed Rafay", ""]]}, {"id": "2103.09345", "submitter": "Rouzbeh Behnia", "authors": "Rouzbeh Behnia, Attila A. Yavuz, Muslum Ozgur Ozmen, Tsz Hon Yuen", "title": "Compatible Certificateless and Identity-Based Cryptosystems for\n  Heterogeneous IoT", "comments": null, "journal-ref": "In International Conference on Information Security (pp. 39-58).\n  Springer, Cham (2020)", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Certificates ensure the authenticity of users' public keys, however their\noverhead (e.g., certificate chains) might be too costly for some IoT systems\nlike aerial drones. Certificate-free cryptosystems, like identity-based and\ncertificateless systems, lift the burden of certificates and could be a\nsuitable alternative for such IoTs. However, despite their merits, there is a\nresearch gap in achieving compatible identity-based and certificateless systems\nto allow users from different domains (identity-based or certificateless) to\ncommunicate seamlessly. Moreover, more efficient constructions can enable their\nadoption in resource-limited IoTs.\n  In this work, we propose new identity-based and certificateless cryptosystems\nthat provide such compatibility and efficiency. This feature is beneficial for\nheterogeneous IoT settings (e.g., commercial aerial drones), where different\nlevels of trust/control is assumed on the trusted third party. Our schemes are\nmore communication efficient than their public key based counterparts, as they\ndo not need certificate processing. Our experimental analysis on both commodity\nand embedded IoT devices show that, only with the cost of having a larger\nsystem public key, our cryptosystems are more computation and communication\nefficient than their certificate-free counterparts. We prove the security of\nour schemes (in the random oracle model) and open-source our cryptographic\nframework for public testing/adoption.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 22:10:55 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Behnia", "Rouzbeh", ""], ["Yavuz", "Attila A.", ""], ["Ozmen", "Muslum Ozgur", ""], ["Yuen", "Tsz Hon", ""]]}, {"id": "2103.09380", "submitter": "Bruno Sousa Miguel", "authors": "Bruno Sousa and Tiago Cruz and Miguel Arieiro and Vasco Pereira", "title": "An ELEGANT dataset with Denial of Service and Man in The Middle attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This document describes a dataset with diverse types of Denial of Service\n(DoS) attacks and Man-in-the-Middle (MiTM) attacks. The data is available at\nthe following DOI 10.21227/mewp-g646. This document describes the data\ncollection process and provides useful information on how data can be employed\nto devise models for cybersecurity in critical infrastructures using\nProgrammable Logic Controllers (PLCs)\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2021 00:50:10 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 11:22:27 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Sousa", "Bruno", ""], ["Cruz", "Tiago", ""], ["Arieiro", "Miguel", ""], ["Pereira", "Vasco", ""]]}, {"id": "2103.09425", "submitter": "Zhenliang Lu", "authors": "Yuan Lu and Zhenliang Lu and Qiang Tang", "title": "Bolt-Dumbo Transformer: Asynchronous Consensus As Fast As Pipelined BFT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Optimistic asynchronous atomic broadcast was proposed to improve the\nperformance of asynchronous protocols while maintaining their liveness in\nunstable networks (Kursawe-Shoup, 2002; Ramasamy-Cachin, 2005). They used a\nfaster deterministic protocol in the optimistic case when the network condition\nremains good, and can safely fallback to a pessimistic path running\nasynchronous atomic broadcast once the fast path fails to proceed.\nUnfortunately, besides that the pessimistic path is slow, existing fallback\nmechanisms directly use a heavy tool of asynchronous multi-valued validated\nByzantine agreement (MVBA). When deployed on the open Internet, which could be\nfluctuating, the inefficient fallback may happen frequently thus the benefits\nof adding the optimistic path are eliminated.\n  We give a generic framework for practical optimistic asynchronous atomic\nbroadcast. A new abstraction of the optimistic case protocols, which can be\ninstantiated easily, is presented. More importantly, it enables us to design a\nhighly efficient fallback mechanism to handle the fast path failures. The\nresulting fallback replaces the cumbersome MVBA by a variant of simple binary\nagreement only. Besides a detailed security analysis, we also give concrete\ninstantiations of our framework and implement them. Extensive experiments show\nthat our new fallback mechanism adds minimal overhead, demonstrating that our\nframework can enjoy both the low latency of deterministic protocols and robust\nliveness of randomized asynchronous protocols in practice.\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2021 03:57:47 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 07:10:45 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Lu", "Yuan", ""], ["Lu", "Zhenliang", ""], ["Tang", "Qiang", ""]]}, {"id": "2103.09448", "submitter": "Mazen Abdelfattah Mr", "authors": "Mazen Abdelfattah, Kaiwen Yuan, Z. Jane Wang, and Rabab Ward", "title": "Adversarial Attacks on Camera-LiDAR Models for 3D Car Detection", "comments": "arXiv admin note: text overlap with arXiv:2101.10747", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.GR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most autonomous vehicles (AVs) rely on LiDAR and RGB camera sensors for\nperception. Using these point cloud and image data, perception models based on\ndeep neural nets (DNNs) have achieved state-of-the-art performance in 3D\ndetection. The vulnerability of DNNs to adversarial attacks have been heavily\ninvestigated in the RGB image domain and more recently in the point cloud\ndomain, but rarely in both domains simultaneously. Multi-modal perception\nsystems used in AVs can be divided into two broad types: cascaded models which\nuse each modality independently, and fusion models which learn from different\nmodalities simultaneously. We propose a universal and physically realizable\nadversarial attack for each type, and study and contrast their respective\nvulnerabilities to attacks. We place a single adversarial object with specific\nshape and texture on top of a car with the objective of making this car evade\ndetection. Evaluating on the popular KITTI benchmark, our adversarial object\nmade the host vehicle escape detection by each model type nearly 50% of the\ntime. The dense RGB input contributed more to the success of the adversarial\nattacks on both cascaded and fusion models. We found that the fusion model was\nrelatively more robust to adversarial attacks than the cascaded model.\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2021 05:24:48 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Abdelfattah", "Mazen", ""], ["Yuan", "Kaiwen", ""], ["Wang", "Z. Jane", ""], ["Ward", "Rabab", ""]]}, {"id": "2103.09459", "submitter": "Maurantonio Caprolu", "authors": "Maurantonio Caprolu and Matteo Pontecorvi and Matteo Signorini and\n  Carlos Segarra and Roberto Di Pietro", "title": "A Novel Framework for the Analysis of Unknown Transactions in Bitcoin:\n  Theory, Model, and Experimental Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin (BTC) is probably the most transparent payment network in the world,\nthanks to the full history of transactions available to the public. Though,\nBitcoin is not a fully anonymous environment, rather a pseudonymous one,\naccounting for a number of attempts to beat its pseudonimity using clustering\ntechniques. There is, however, a recurring assumption in all the cited\ndeanonymization techniques: that each transaction output has an address\nattached to it. That assumption is false. An evidence is that, as of block\nheight 591,872, there are several millions transactions with at least one\noutput for which the Bitcoin Core client cannot infer an address. In this\npaper, we present a novel approach based on sound graph theory for identifying\ntransaction inputs and outputs. Our solution implements two simple yet\ninnovative features: it does not rely on BTC addresses and explores all the\ntransactions stored in the blockchain. All the other existing solutions fail\nwith respect to one or both of the cited features. In detail, we first\nintroduce the concept of Unknown Transaction and provide a new framework to\nparse the Bitcoin blockchain by taking them into account. Then, we introduce a\ntheoretical model to detect, study, and classify -- for the first time in the\nliterature -- unknown transaction patterns in the user network. Further, in an\nextensive experimental campaign, we apply our model to the Bitcoin network to\nuncover hidden transaction patterns within the Bitcoin user network. Results\nare striking: we discovered more than 30,000 unknown transaction DAGs, with a\nfew of them exhibiting a complex yet ordered topology and potentially connected\nto automated payment services. To the best of our knowledge, the proposed\nframework is the only one that enables a complete study of the unknown\ntransaction patterns, hence enabling further research in the fields -- for\nwhich we provide some directions.\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2021 06:20:18 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Caprolu", "Maurantonio", ""], ["Pontecorvi", "Matteo", ""], ["Signorini", "Matteo", ""], ["Segarra", "Carlos", ""], ["Di Pietro", "Roberto", ""]]}, {"id": "2103.09477", "submitter": "Uttam Kumar Mondal", "authors": "Uttam Kr. Mondal, Shamayita Pal, AmitRanjan Dutta, J.K. Mandal", "title": "A New Approach to Enhance Security of Visual Cryptography Using\n  Steganography (VisUS)", "comments": "National Conference on Next Generation Computing & Information\n  Security (NCNGCIS-2011), 25-26 March,2011,IMS,Noida", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Steganography is a process that hides secrete message or secrete hologram or\nsecrete video or secrete image whose mere presence within the source data\nshould be undetectable and use for transmitting secret information over public\nmedia. Visual cryptography is a cryptographic technique in which no\ncryptographic computation is needed at the decryption end and the decryption is\nperformed by the human visual system (HVS). In this paper, both Steganography\nand visual cryptography have been selected to provide more secure data\ntransmission over the public media with less hazard of computation. This\ntechnique generates shares with less space overhead as well as without\nincreasing the computational complexity compared to existing techniques and may\nprovide better security. It is also easy to implement like other techniques of\nvisual cryptography. Finally, experimental results are given to establish the\nsecurity criteria.\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2021 07:15:27 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Mondal", "Uttam Kr.", ""], ["Pal", "Shamayita", ""], ["Dutta", "AmitRanjan", ""], ["Mandal", "J. K.", ""]]}, {"id": "2103.09506", "submitter": "Ying Cui", "authors": "Chencheng Ye, Ying Cui", "title": "Sample-based Federated Learning via Mini-batch SSCA", "comments": "to be published in ICC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate unconstrained and constrained sample-based\nfederated optimization, respectively. For each problem, we propose a privacy\npreserving algorithm using stochastic successive convex approximation (SSCA)\ntechniques, and show that it can converge to a Karush-Kuhn-Tucker (KKT) point.\nTo the best of our knowledge, SSCA has not been used for solving federated\noptimization, and federated optimization with nonconvex constraints has not\nbeen investigated. Next, we customize the two proposed SSCA-based algorithms to\ntwo application examples, and provide closed-form solutions for the respective\napproximate convex problems at each iteration of SSCA. Finally, numerical\nexperiments demonstrate inherent advantages of the proposed algorithms in terms\nof convergence speed, communication cost and model specification.\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2021 08:38:03 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Ye", "Chencheng", ""], ["Cui", "Ying", ""]]}, {"id": "2103.09595", "submitter": "Sabreen Ahmadjee", "authors": "Sabreen Ahmadjee, Carlos Mera-G\\'omez, Rami Bahsoon", "title": "Assessing Smart Contracts Security Technical Debts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart contracts are self-enforcing agreements that are employed to exchange\nassets without the approval of trusted third parties. This feature has\nencouraged various sectors to make use of smart contracts when transacting.\nExperience shows that many deployed contracts are vulnerable to exploitation\ndue to their poor design, which allows attackers to steal valuable assets from\nthe involved parties. Therefore, an assessment approach that allows developers\nto recognise the consequences of deploying vulnerable contracts is needed. In\nthis paper, we propose a debt-aware approach for assessing security design\nvulnerabilities in smart contracts. Our assessment approach involves two main\nsteps: (i) identification of design vulnerabilities using security analysis\ntechniques and (ii) an estimation of the ramifications of the identified\nvulnerabilities leveraging the technical debt metaphor, its principal and\ninterest. We use examples of vulnerable contracts to demonstrate the\napplicability of our approach. The results show that our assessment approach\nincreases the visibility of security design issues. It also allows developers\nto concentrate on resolving smart contract vulnerabilities through technical\ndebt impact analysis and prioritisation. Developers can use our approach to\ninform the design of more secure contracts and for reducing unintentional debts\ncaused by a lack of awareness of security issues.\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2021 12:23:21 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Ahmadjee", "Sabreen", ""], ["Mera-G\u00f3mez", "Carlos", ""], ["Bahsoon", "Rami", ""]]}, {"id": "2103.09668", "submitter": "Gagandeep Singh", "authors": "Gagandeep Singh and Akshar Kaul", "title": "Secure Hypersphere Range Query on Encrypted Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial queries like range queries, nearest neighbor, circular range queries\netc. are the most widely used queries in the location-based applications.\nBuilding secure and efficient solutions for these queries in the cloud\ncomputing framework is critical and has been an area of active research. This\npaper focuses on the problem of Secure Circular Range Queries (SCRQ), where\nclient submits an encrypted query (consisting of a center point and radius of\nthe circle) and the cloud (storing encrypted data points) has to return the\npoints lying inside the circle. The existing solutions for this problem suffer\nfrom various disadvantages such as high processing time which is proportional\nto square of the query radius, query generation phase which is directly\nproportional to the number of points covered by the query etc. This paper\npresents solution for the above problem which is much more efficient than the\nexisting solutions. Three protocols are proposed with varying characteristics.\nIt is shown that all the three protocols are secure. The proposed protocols can\nbe extended to multiple dimensions and thus are able to handle Secure\nHypersphere Range Queries (SHRQ) as well. Internally the proposed protocols use\npairing-based cryptography and a concept of lookup table. To enable the\nefficient use of limited size lookup table, a new storage scheme is presented.\nThe proposed storage scheme enables the protocols to handle query with much\nlarger radius values. Using the SHRQ protocols, we also propose a mechanism to\nanswer the Secure range Queries. Extensive performance evaluation has been done\nto evaluate the efficiency of the proposed protocols\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2021 14:06:35 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Singh", "Gagandeep", ""], ["Kaul", "Akshar", ""]]}, {"id": "2103.09705", "submitter": "Jingchen Hu", "authors": "Jingchen Hu, Joerg Drechsler, Hang J. Kim", "title": "Accuracy Gains from Privacy Amplification Through Sampling for\n  Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in differential privacy demonstrated that (sub)sampling can\namplify the level of protection. For example, for $\\epsilon$-differential\nprivacy and simple random sampling with sampling rate $r$, the actual privacy\nguarantee is approximately $r\\epsilon$, if a value of $\\epsilon$ is used to\nprotect the output from the sample. In this paper, we study whether this\namplification effect can be exploited systematically to improve the accuracy of\nthe privatized estimate. Specifically, assuming the agency has information for\nthe full population, we ask under which circumstances accuracy gains could be\nexpected, if the privatized estimate would be computed on a random sample\ninstead of the full population. We find that accuracy gains can be achieved for\ncertain regimes. However, gains can typically only be expected, if the\nsensitivity of the output with respect to small changes in the database does\nnot depend too strongly on the size of the database. We only focus on\nalgorithms that achieve differential privacy by adding noise to the final\noutput and illustrate the accuracy implications for two commonly used\nstatistics: the mean and the median. We see our research as a first step\ntowards understanding the conditions required for accuracy gains in practice\nand we hope that these findings will stimulate further research broadening the\nscope of differential privacy algorithms and outputs considered.\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2021 15:02:12 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Hu", "Jingchen", ""], ["Drechsler", "Joerg", ""], ["Kim", "Hang J.", ""]]}, {"id": "2103.09713", "submitter": "Boxiang Dong", "authors": "Boxiang Dong, Hui (Wendy) Wang, Aparna S. Varde, Dawei Li, Bharath K.\n  Samanthula, Weifeng Sun, Liang Zhao", "title": "Cyber Intrusion Detection by Using Deep Neural Networks with\n  Attack-sharing Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber attacks pose crucial threats to computer system security, and put\ndigital treasuries at excessive risks. This leads to an urgent call for an\neffective intrusion detection system that can identify the intrusion attacks\nwith high accuracy. It is challenging to classify the intrusion events due to\nthe wide variety of attacks. Furthermore, in a normal network environment, a\nmajority of the connections are initiated by benign behaviors. The class\nimbalance issue in intrusion detection forces the classifier to be biased\ntoward the majority/benign class, thus leave many attack incidents undetected.\nSpurred by the success of deep neural networks in computer vision and natural\nlanguage processing, in this paper, we design a new system named DeepIDEA that\ntakes full advantage of deep learning to enable intrusion detection and\nclassification. To achieve high detection accuracy on imbalanced data, we\ndesign a novel attack-sharing loss function that can effectively move the\ndecision boundary towards the attack classes and eliminates the bias towards\nthe majority/benign class. By using this loss function, DeepIDEA respects the\nfact that the intrusion mis-classification should receive higher penalty than\nthe attack mis-classification. Extensive experimental results on three\nbenchmark datasets demonstrate the high detection accuracy of DeepIDEA. In\nparticular, compared with eight state-of-the-art approaches, DeepIDEA always\nprovides the best class-balanced accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2021 15:15:12 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Dong", "Boxiang", "", "Wendy"], ["Hui", "", "", "Wendy"], ["Wang", "", ""], ["Varde", "Aparna S.", ""], ["Li", "Dawei", ""], ["Samanthula", "Bharath K.", ""], ["Sun", "Weifeng", ""], ["Zhao", "Liang", ""]]}, {"id": "2103.09905", "submitter": "Mohammad Tahaei", "authors": "Mohammad Tahaei, Adam Jenkins, Kami Vaniea, Maria Wolters", "title": "\"I Don't Know Too Much About It\": On the Security Mindsets of Computer\n  Science Students", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-55958-8", "report-no": null, "categories": "cs.CR cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The security attitudes and approaches of software developers have a large\nimpact on the software they produce, yet we know very little about how and when\nthese views are constructed. This paper investigates the security and privacy\n(S&P) perceptions, experiences, and practices of current Computer Science\nstudents at the graduate and undergraduate level using semi-structured\ninterviews. We find that the attitudes of students already match many of those\nthat have been observed in professional level developers. Students have a range\nof hacker and attack mindsets, lack of experience with security APIs, a mixed\nview of who is in charge of S&P in the software life cycle, and a tendency to\ntrust other peoples' code as a convenient approach to rapidly build software.\nWe discuss the impact of our results on both curriculum development and support\nfor professional developers.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 12:07:48 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Tahaei", "Mohammad", ""], ["Jenkins", "Adam", ""], ["Vaniea", "Kami", ""], ["Wolters", "Maria", ""]]}, {"id": "2103.10021", "submitter": "Fangqi Li", "authors": "Fangqi Li, Shilin Wang", "title": "Secure Watermark for Deep Neural Networks with Multi-task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep neural networks are playing an important role in many real-life\napplications. After being trained with abundant data and computing resources, a\ndeep neural network model providing service is endowed with economic value. An\nimportant prerequisite in commercializing and protecting deep neural networks\nis the reliable identification of their genuine author. To meet this goal,\nwatermarking schemes that embed the author's identity information into the\nnetworks have been proposed. However, current schemes can hardly meet all the\nnecessary requirements for securely proving the authorship and mostly focus on\nmodels for classification. To explicitly meet the formal definitions of the\nsecurity requirements and increase the applicability of deep neural network\nwatermarking schemes, we propose a new framework based on multi-task learning.\nBy treating the watermark embedding as an extra task, most of the security\nrequirements are explicitly formulated and met with well-designed regularizers,\nthe rest is guaranteed by using components from cryptography. Moreover, a\ndecentralized verification protocol is proposed to standardize the ownership\nverification. The experiment results show that the proposed scheme is flexible,\nsecure, and robust, hence a promising candidate in deep learning model\nprotection.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2021 04:56:34 GMT"}, {"version": "v2", "created": "Sat, 27 Mar 2021 20:00:50 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Li", "Fangqi", ""], ["Wang", "Shilin", ""]]}, {"id": "2103.10186", "submitter": "Dinh Nguyen", "authors": "Dinh C. Nguyen, Pubudu N. Pathirana, Ming Ding, Aruna Seneviratne", "title": "A Cooperative Architecture of Data Offloading and Sharing for Smart\n  Healthcare with Blockchain", "comments": "Accepted in the IEEE International Conference on Blockchain and\n  Cryptocurrency (IEEE ICBC 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The healthcare industry has witnessed significant transformations in e-health\nservices where Electronic Health Records (EHRs) are transferred to mobile edge\nclouds to facilitate healthcare. Many edge cloud-based system designs have been\nproposed, but some technical challenges still remain, such as low quality of\nservices (QoS), data privacy and system security due to centralized healthcare\narchitectures. In this paper, we propose a novel hybrid approach of data\noffloading and data sharing for healthcare using edge cloud and blockchain.\nFirst, an efficient data offloading scheme is proposed where IoT health data\ncan be offloaded to nearby edge servers for data processing with privacy\nawareness. Then, a data sharing scheme is integrated to enable data exchange\namong healthcare users via blockchain. Particularly, a trustworthy access\ncontrol mechanism is developed using smart contracts for access authentication\nto achieve secure EHRs sharing. Implementation results from extensive\nreal-world experiments show the superior advantages of the proposal over the\nexisting schemes in terms of improved QoS, enhanced data privacy and security,\nand low smart contract costs.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2021 11:50:36 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 10:39:21 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Nguyen", "Dinh C.", ""], ["Pathirana", "Pubudu N.", ""], ["Ding", "Ming", ""], ["Seneviratne", "Aruna", ""]]}, {"id": "2103.10212", "submitter": "Isaac Matthews", "authors": "Isaac Matthews, Sadegh Soudjani, Aad van Moorsel", "title": "Stochastic Simulation Techniques for Inference and Sensitivity Analysis\n  of Bayesian Attack Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A vulnerability scan combined with information about a computer network can\nbe used to create an attack graph, a model of how the elements of a network\ncould be used in an attack to reach specific states or goals in the network.\nThese graphs can be understood probabilistically by turning them into Bayesian\nattack graphs, making it possible to quantitatively analyse the security of\nlarge networks. In the event of an attack, probabilities on the graph change\ndepending on the evidence discovered (e.g., by an intrusion detection system or\nknowledge of a host's activity). Since such scenarios are difficult to solve\nthrough direct computation, we discuss and compare three stochastic simulation\ntechniques for updating the probabilities dynamically based on the evidence and\ncompare their speed and accuracy. From our experiments we conclude that\nlikelihood weighting is most efficient for most uses. We also consider\nsensitivity analysis of BAGs, to identify the most critical nodes for\nprotection of the network and solve the uncertainty problem in the assignment\nof priors to nodes. Since sensitivity analysis can easily become\ncomputationally expensive, we present and demonstrate an efficient sensitivity\nanalysis approach that exploits a quantitative relation with stochastic\ninference.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2021 12:33:27 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Matthews", "Isaac", ""], ["Soudjani", "Sadegh", ""], ["van Moorsel", "Aad", ""]]}, {"id": "2103.10498", "submitter": "Osvald Frisk", "authors": "Osvald Frisk, Friedrich D\\\"ormann, Christian Marius Lillelund,\n  Christian Fischer Pedersen", "title": "Super-convergence and Differential Privacy: Training faster with better\n  privacy guarantees", "comments": "(To be) Published and presented at the 55th Annual Conference on\n  Information Sciences and Systems (CISS), 7 pages, 4 figures", "journal-ref": "2021 55th Annual Conference on Information Sciences and Systems\n  (CISS)", "doi": "10.1109/CISS50987.2021.9400274", "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of deep neural networks and Differential Privacy has been of\nincreasing interest in recent years, as it offers important data protection\nguarantees to the individuals of the training datasets used. However, using\nDifferential Privacy in the training of neural networks comes with a set of\nshortcomings, like a decrease in validation accuracy and a significant increase\nin the use of resources and time in training. In this paper, we examine\nsuper-convergence as a way of greatly increasing training speed of\ndifferentially private neural networks, addressing the shortcoming of high\ntraining time and resource use. Super-convergence allows for acceleration in\nnetwork training using very high learning rates, and has been shown to achieve\nmodels with high utility in orders of magnitude less training iterations than\nconventional ways. Experiments in this paper show that this order-of-magnitude\nspeedup can also be seen when combining it with Differential Privacy, allowing\nfor higher validation accuracies in much fewer training iterations compared to\nnon-private, non-super convergent baseline models. Furthermore,\nsuper-convergence is shown to improve the privacy guarantees of private models.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2021 19:53:00 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Frisk", "Osvald", ""], ["D\u00f6rmann", "Friedrich", ""], ["Lillelund", "Christian Marius", ""], ["Pedersen", "Christian Fischer", ""]]}, {"id": "2103.10519", "submitter": "Bora Bugra Sezer", "authors": "Bora Bugra Sezer, Selcuk Topal and Urfat Nuriyev", "title": "An Auditability, Transparent, and Privacy-Preserving for Supply Chain\n  Traceability Based on Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traceability and auditability are key structures that are vital in supply\nchain management and construction. However, trust is the most important aspect\nof customers in these systems. Also, we have to rely on third parties to trade\nin centralized systems. Although current exist frameworks for these solutions\nin the supply chain, these have work poor traceability and lack of real-time\ninformation, and especially lack of privacy-preserving. In this paper, we\npropose a privacy-preserving framework for supply chain traceability that using\nsmart contracts. Development processes, model implementation, and smart\ncontracts are presented in detail and we show cryptographic techniques in these\ntechnologies to address the aforementioned. Finally, thanks to traceability and\nauditability, customers and other parties can view with a single product ID and\nalso verified with digital signature the claims of the actors in the system.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2021 20:57:00 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Sezer", "Bora Bugra", ""], ["Topal", "Selcuk", ""], ["Nuriyev", "Urfat", ""]]}, {"id": "2103.10533", "submitter": "Srivalli Boddupalli", "authors": "Srivalli Boddupalli, Akash Someshwar Rao, Sandip Ray", "title": "Resilient Cooperative Adaptive Cruise Control for Autonomous Vehicles\n  Using Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.RO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cooperative Adaptive Cruise Control (CACC) is a fundamental connected vehicle\napplication that extends Adaptive Cruise Control by exploiting\nvehicle-to-vehicle (V2V) communication. CACC is a crucial ingredient for\nnumerous autonomous vehicle functionalities including platooning, distributed\nroute management, etc. Unfortunately, malicious V2V communications can subvert\nCACC, leading to string instability and road accidents. In this paper, we\ndevelop a novel resiliency infrastructure, RACCON, for detecting and mitigating\nV2V attacks on CACC. RACCON uses machine learning to develop an on-board\nprediction model that captures anomalous vehicular responses and performs\nmitigation in real time. RACCON-enabled vehicles can exploit the high\nefficiency of CACC without compromising safety, even under potentially\nadversarial scenarios. We present extensive experimental evaluation to\ndemonstrate the efficacy of RACCON.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2021 21:28:28 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Boddupalli", "Srivalli", ""], ["Rao", "Akash Someshwar", ""], ["Ray", "Sandip", ""]]}, {"id": "2103.10579", "submitter": "Wanli Xue", "authors": "Cheng Shen and Wanli Xue", "title": "An Experiment Study on Federated LearningTestbed", "comments": "Accepted by SMARTCOM2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the Internet of Things (IoT) can benefit from machine learning by\noutsourcing model training on the cloud, user data exposure to an untrusted\ncloud service provider can pose threat to user privacy. Recently, federated\nlearning is proposed as an approach for privacy-preserving machine learning\n(PPML) for the IoT, while its practicability remains unclear. This work\npresents the evaluation on the efficiency and privacy performance of a readily\navailable federated learning framework based on PySyft, a Python library for\ndistributed deep learning. It is observed that the training speed of the\nframework is significantly slower than of the centralized approach due to\ncommunication overhead. Meanwhile, the framework bears some vulnerability to\npotential man-in-the-middle attacks at the network level. The report serves as\na starting point for PPML performance analysis and suggests the future\ndirection for PPML framework development.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2021 01:07:37 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Shen", "Cheng", ""], ["Xue", "Wanli", ""]]}, {"id": "2103.10585", "submitter": "Benjamin Levy", "authors": "Benjamin Levy and Matthew Stewart", "title": "The evolving ecosystem of COVID-19 contact tracing applications", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since the outbreak of the novel coronavirus, COVID-19, there has been\nincreased interest in the use of digital contact tracing as a means of stopping\nchains of viral transmission, provoking alarm from privacy advocates.\nConcerning the ethics of this technology, recent studies have predominantly\nfocused on (1) the formation of guidelines for ethical contact tracing, (2) the\nanalysis of specific implementations, or (3) the review of a select number of\ncontact tracing applications and their relevant privacy or ethical\nimplications. In this study, we provide a comprehensive survey of the evolving\necosystem of COVID-19 tracing applications, examining 152 contact tracing\napplications and assessing the extent to which they comply with existing\nguidelines for ethical contact tracing. The assessed criteria cover areas\nincluding data collection and storage, transparency and consent, and whether\nthe implementation is open source. We find that although many apps released\nearly in the pandemic fell short of best practices, apps released more\nrecently, following the publication of the Apple/Google exposure notification\nprotocol, have tended to be more closely aligned with ethical contact tracing\nprinciples. This dataset will be publicly available and may be updated as the\npandemic continues.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2021 01:38:19 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Levy", "Benjamin", ""], ["Stewart", "Matthew", ""]]}, {"id": "2103.10594", "submitter": "Haftu Reda", "authors": "Haftu Tasew Reda, Adnan Anwar, Abdun Mahmood", "title": "Comprehensive Survey and Taxonomies of False Injection Attacks in Smart\n  Grid: Attack Models, Targets, and Impacts", "comments": "Double-column of 24 pages, prepared based on IEEE Transaction article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Smart Grid has rapidly transformed the centrally controlled power system into\na massively interconnected cyber-physical system that benefits from the\nrevolutions happening in the communications (e.g. 5G) and the growing\nproliferation of the Internet of Things devices (such as smart metres and\nintelligent electronic devices). While the convergence of a significant number\nof cyber-physical elements has enabled the Smart Grid to be far more efficient\nand competitive in addressing the growing global energy challenges, it has also\nintroduced a large number of vulnerabilities culminating in violations of data\navailability, integrity, and confidentiality. Recently, false data injection\n(FDI) has become one of the most critical cyberattacks, and appears to be a\nfocal point of interest for both research and industry. To this end, this paper\npresents a comprehensive review in the recent advances of the FDI attacks, with\nparticular emphasis on 1) adversarial models, 2) attack targets, and 3) impacts\nin the Smart Grid infrastructure. This review paper aims to provide a thorough\nunderstanding of the incumbent threats affecting the entire spectrum of the\nSmart Grid. Related literature are analysed and compared in terms of their\ntheoretical and practical implications to the Smart Grid cybersecurity. In\nconclusion, a range of technical limitations of existing false data attack\nresearch is identified, and a number of future research directions is\nrecommended.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2021 02:15:11 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Reda", "Haftu Tasew", ""], ["Anwar", "Adnan", ""], ["Mahmood", "Abdun", ""]]}, {"id": "2103.10651", "submitter": "Yuxuan Chen", "authors": "Yuxuan Chen, Jiangshan Zhang, Xuejing Yuan, Shengzhi Zhang, Kai Chen,\n  Xiaofeng Wang and Shanqing Guo", "title": "SoK: A Modularized Approach to Study the Security of Automatic Speech\n  Recognition Systems", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the wide use of Automatic Speech Recognition (ASR) in applications such\nas human machine interaction, simultaneous interpretation, audio transcription,\netc., its security protection becomes increasingly important. Although recent\nstudies have brought to light the weaknesses of popular ASR systems that enable\nout-of-band signal attack, adversarial attack, etc., and further proposed\nvarious remedies (signal smoothing, adversarial training, etc.), a systematic\nunderstanding of ASR security (both attacks and defenses) is still missing,\nespecially on how realistic such threats are and how general existing\nprotection could be. In this paper, we present our systematization of knowledge\nfor ASR security and provide a comprehensive taxonomy for existing work based\non a modularized workflow. More importantly, we align the research in this\ndomain with that on security in Image Recognition System (IRS), which has been\nextensively studied, using the domain knowledge in the latter to help\nunderstand where we stand in the former. Generally, both IRS and ASR are\nperceptual systems. Their similarities allow us to systematically study\nexisting literature in ASR security based on the spectrum of attacks and\ndefense solutions proposed for IRS, and pinpoint the directions of more\nadvanced attacks and the directions potentially leading to more effective\nprotection in ASR. In contrast, their differences, especially the complexity of\nASR compared with IRS, help us learn unique challenges and opportunities in ASR\nsecurity. Particularly, our experimental study shows that transfer learning\nacross ASR models is feasible, even in the absence of knowledge about models\n(even their types) and training data.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2021 06:24:04 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Chen", "Yuxuan", ""], ["Zhang", "Jiangshan", ""], ["Yuan", "Xuejing", ""], ["Zhang", "Shengzhi", ""], ["Chen", "Kai", ""], ["Wang", "Xiaofeng", ""], ["Guo", "Shanqing", ""]]}, {"id": "2103.10671", "submitter": "Yang Su Mr.", "authors": "Yang Su, Michael Chesser, Yansong Gao, Alanson P. Sample and Damith C.\n  Ranasinghe", "title": "Wisecr: Secure Simultaneous Code Disseminationto Many Batteryless\n  Computational RFID Devices", "comments": "16 main pages, 4 Appendix. Under review at IEEE TDSC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging ultra-low-power tiny scale computing devices in Cyber-Physical\nSystems %and Internet of Things (IoT) run on harvested energy, are\nintermittently powered, have limited computational capability, and perform\nsensing and actuation functions under the control of a dedicated firmware\noperating without the supervisory control of an operating system. Wirelessly\nupdating or patching the firmware of such devices is inevitable. We consider\nthe challenging problem of simultaneous and secure firmware updates or patching\nfor a typical class of such devices -- Computational Radio Frequency\nIdentification (CRFID) devices. We propose Wisecr, the first secure and\nsimultaneous wireless code dissemination mechanism to multiple devices that\nprevent malicious code injection attacks and intellectual property (IP) theft,\nwhilst enabling remote attestation of code installation. Importantly, Wisecr is\nengineered to comply with existing ISO compliant communication protocol\nstandards employed by CRFID devices and systems. We comprehensively evaluate\nWisecr's overhead, demonstrate its implementation over standards-compliant\nprotocols, analyze its security and implement an end-to-end realization with\npopular CFRID devices -- the open-source code is released on GitHub.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2021 07:32:53 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 06:08:48 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Su", "Yang", ""], ["Chesser", "Michael", ""], ["Gao", "Yansong", ""], ["Sample", "Alanson P.", ""], ["Ranasinghe", "Damith C.", ""]]}, {"id": "2103.10687", "submitter": "WeiGuo Zhang", "authors": "Yan-Ping Wang and WeiGuo Zhang and Zhengbang Zha", "title": "Low differentially uniform permutations from Dobbertin APN function over\n  $\\mathbb{F}_{2^n}$", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Block ciphers use S-boxes to create confusion in the cryptosystems. Such\nS-boxes are functions over $\\mathbb{F}_{2^{n}}$. These functions should have\nlow differential uniformity, high nonlinearity, and high algebraic degree in\norder to resist differential attacks, linear attacks, and higher order\ndifferential attacks, respectively. In this paper, we construct new classes of\ndifferentially $4$ and $6$-uniform permutations by modifying the image of the\nDobbertin APN function $x^{d}$ with $d=2^{4k}+2^{3k}+2^{2k}+2^{k}-1$ over a\nsubfield of $\\mathbb{F}_{2^{n}}$. Furthermore, the algebraic degree and the\nlower bound of the nonlinearity of the constructed functions are given.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2021 08:38:45 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Wang", "Yan-Ping", ""], ["Zhang", "WeiGuo", ""], ["Zha", "Zhengbang", ""]]}, {"id": "2103.10692", "submitter": "Christos Sakalis", "authors": "Christos Sakalis, Stefanos Kaxiras and Magnus Sj\\\"alander", "title": "Selectively Delaying Instructions to Prevent Microarchitectural Replay\n  Attacks", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  MicroScope, and microarchitectural replay attacks in general, take advantage\nof the characteristics of speculative execution to trap the execution of the\nvictim application in an infinite loop, enabling the attacker to amplify a\nside-channel attack by executing it indefinitely. Due to the nature of the\nreplay, it can be used to effectively attack security critical trusted\nexecution environments (secure enclaves), even under conditions where a\nside-channel attack would not be possible. At the same time, unlike speculative\nside-channel attacks, MicroScope can be used to amplify the correct path of\nexecution, rendering many existing speculative side-channel defences\nineffective.\n  In this work, we generalize microarchitectural replay attacks beyond\nMicroScope and present an efficient defence against them. We make the\nobservation that such attacks rely on repeated squashes of so-called \"replay\nhandles\" and that the instructions causing the side-channel must reside in the\nsame reorder buffer window as the handles. We propose Delay-on-Squash, a\ntechnique for tracking squashed instructions and preventing them from being\nreplayed by speculative replay handles. Our evaluation shows that it is\npossible to achieve full security against microarchitectural replay attacks\nwith very modest hardware requirements, while still maintaining 97% of the\ninsecure baseline performance.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2021 08:53:02 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Sakalis", "Christos", ""], ["Kaxiras", "Stefanos", ""], ["Sj\u00e4lander", "Magnus", ""]]}, {"id": "2103.10756", "submitter": "Sina Rafati Niya", "authors": "Sina Rafati Niya, Julius Willems, Burkhard Stiller", "title": "On-Chain IoT Data Modification in Blockchains", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In recent years, the interest growth in the Blockchains (BC) and\nInternet-of-Things (IoT) integration -- termed as BIoT -- for more trust via\ndecentralization has led to great potentials in various use cases such as\nhealth care, supply chain tracking, and smart cities. A key element of BIoT\necosystems is the data transactions (TX) that include the data collected by IoT\ndevices. BIoT applications face many challenges to comply with the European\nGeneral Data Protection Regulation (GDPR) i.e., enabling users to hold on to\ntheir rights for deleting or modifying their data stored on publicly accessible\nand immutable BCs. In this regard, this paper identifies the requirements of\nBCs for being GDPR compliant in BIoT use cases. Accordingly, an on-chain\nsolution is proposed that allows fine-grained modification (update and erasure)\noperations on TXs' data fields within a BC. The proposed solution is based on a\ncryptographic primitive called Chameleon Hashing. The novelty of this approach\nis manifold. BC users have the authority to update their data, which are\naddressed at the TX level with no side-effects on the block or chain. By\nperforming and storing the data updates, all on-chain, traceability and\nverifiability of the BC are preserved. Moreover, the compatibility with TX\naggregation mechanisms that allow the compression of the BC size is maintained.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2021 11:53:10 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Niya", "Sina Rafati", ""], ["Willems", "Julius", ""], ["Stiller", "Burkhard", ""]]}, {"id": "2103.11002", "submitter": "Lakshmanan Nataraj", "authors": "Michael Goebel, Jason Bunk, Srinjoy Chattopadhyay, Lakshmanan Nataraj,\n  Shivkumar Chandrasekaran and B.S. Manjunath", "title": "Attribution of Gradient Based Adversarial Attacks for Reverse\n  Engineering of Deceptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) algorithms are susceptible to adversarial attacks and\ndeception both during training and deployment. Automatic reverse engineering of\nthe toolchains behind these adversarial machine learning attacks will aid in\nrecovering the tools and processes used in these attacks. In this paper, we\npresent two techniques that support automated identification and attribution of\nadversarial ML attack toolchains using Co-occurrence Pixel statistics and\nLaplacian Residuals. Our experiments show that the proposed techniques can\nidentify parameters used to generate adversarial samples. To the best of our\nknowledge, this is the first approach to attribute gradient based adversarial\nattacks and estimate their parameters. Source code and data is available at:\nhttps://github.com/michael-goebel/ei_red\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2021 19:55:00 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Goebel", "Michael", ""], ["Bunk", "Jason", ""], ["Chattopadhyay", "Srinjoy", ""], ["Nataraj", "Lakshmanan", ""], ["Chandrasekaran", "Shivkumar", ""], ["Manjunath", "B. S.", ""]]}, {"id": "2103.11003", "submitter": "Po-Ling Loh", "authors": "Marco Avella-Medina, Casey Bradshaw, Po-Ling Loh", "title": "Differentially private inference via noisy optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CR cs.LG stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a general optimization-based framework for computing\ndifferentially private M-estimators and a new method for constructing\ndifferentially private confidence regions. Firstly, we show that robust\nstatistics can be used in conjunction with noisy gradient descent or noisy\nNewton methods in order to obtain optimal private estimators with global linear\nor quadratic convergence, respectively. We establish local and global\nconvergence guarantees, under both local strong convexity and self-concordance,\nshowing that our private estimators converge with high probability to a nearly\noptimal neighborhood of the non-private M-estimators. Secondly, we tackle the\nproblem of parametric inference by constructing differentially private\nestimators of the asymptotic variance of our private M-estimators. This\nnaturally leads to approximate pivotal statistics for constructing confidence\nregions and conducting hypothesis testing. We demonstrate the effectiveness of\na bias correction that leads to enhanced small-sample empirical performance in\nsimulations. We illustrate the benefits of our methods in several numerical\nexamples.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2021 19:55:55 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Avella-Medina", "Marco", ""], ["Bradshaw", "Casey", ""], ["Loh", "Po-Ling", ""]]}, {"id": "2103.11014", "submitter": "Joshua Morris", "authors": "Joshua Morris, Dan Lin, Marcellus Smith", "title": "Fight Virus Like a Virus: A New Defense Method Against File-Encrypting\n  Ransomware", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nowadays ransomware has become a new profitable form of attack. This type of\nmalware acts as a form of extortion which encrypts the files in a victim's\ncomputer and forces the victim to pay the ransom to have the data recovered.\nEven companies and tech savvy people must use extensive resources to maintain\nbackups for recovery or else they will lose valuable data, not mentioning\naverage users. Unfortunately, not any recovery tool can effectively defend\nvarious types of ransomware. To address this challenge, we propose a novel\nransomware defense mechanism that can be easily deployed in modern Windows\nsystem to recover the data and mitigate a ransomware attack. The uniqueness of\nour approach is to fight the virus like a virus. We leverage Alternative Data\nStreams which are sometimes used by malicious applications, to develop a data\nprotection method that misleads the ransomware to attack only file 'shells'\ninstead of the actual file content. We evaluated different file encrypting\nransomware and demonstrate usability, efficiency and effectiveness of our\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2021 20:40:47 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Morris", "Joshua", ""], ["Lin", "Dan", ""], ["Smith", "Marcellus", ""]]}, {"id": "2103.11030", "submitter": "Luca Vigan\\`o", "authors": "Luca Vigan\\`o", "title": "Don't Tell Me The Cybersecurity Moon Is Shining... (Cybersecurity Show\n  And Tell)", "comments": "28 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  \"Show, don't tell\" has become the literary commandment for any writer. It\napplies to all forms of fiction, and to non-fiction, including scientific\nwriting, where it lies at the heart of many scientific communication and\nstorytelling approaches. In this paper, I discuss how \"show \\emph{and} tell\" is\nactually often the best approach when one wants to present, teach or explain\ncomplicated ideas such as those underlying notions and results in mathematics\nand science, and in particular in cybersecurity. I discuss how different kinds\nof artworks can be used to explain cybersecurity and I illustrate how telling\n(i.e., explaining notions in a formal, technical way) can be paired with\nshowing through visual storytelling or other forms of storytelling. I also\ndiscuss four categories of artworks and the explanations they help provide.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2021 21:27:27 GMT"}, {"version": "v2", "created": "Sun, 28 Mar 2021 18:54:51 GMT"}, {"version": "v3", "created": "Tue, 1 Jun 2021 07:57:20 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Vigan\u00f2", "Luca", ""]]}, {"id": "2103.11065", "submitter": "Jihoon Suh", "authors": "Jihoon Suh, Takashi Tanaka", "title": "Encrypted Value Iteration and Temporal Difference Learning over Leveled\n  Homomorphic Encryption", "comments": "8 pages, 7 figures, American Control Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an architecture of confidential cloud-based control synthesis\nbased on Homomorphic Encryption (HE). Our study is motivated by the recent\nsurge of data-driven control such as deep reinforcement learning, whose heavy\ncomputational requirements often necessitate an outsourcing to the third party\nserver. To achieve more flexibility than Partially Homomorphic Encryption (PHE)\nand less computational overhead than Fully Homomorphic Encryption (FHE), we\nconsider a Reinforcement Learning (RL) architecture over Leveled Homomorphic\nEncryption (LHE). We first show that the impact of the encryption noise under\nthe Cheon-Kim-Kim-Song (CKKS) encryption scheme on the convergence of the\nmodel-based tabular Value Iteration (VI) can be analytically bounded. We also\nconsider secure implementations of TD(0), SARSA(0) and Z-learning algorithms\nover the CKKS scheme, where we numerically demonstrate that the effects of the\nencryption noise on these algorithms are also minimal.\n", "versions": [{"version": "v1", "created": "Sat, 20 Mar 2021 00:34:27 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Suh", "Jihoon", ""], ["Tanaka", "Takashi", ""]]}, {"id": "2103.11109", "submitter": "Boxin Wang", "authors": "Boxin Wang, Fan Wu, Yunhui Long, Luka Rimanic, Ce Zhang, Bo Li", "title": "DataLens: Scalable Privacy Preserving Training via Gradient Compression\n  and Aggregation", "comments": "Accepted to ACM CCS 2021. 25 pages, 4 figures, 13 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent success of deep neural networks (DNNs) hinges on the availability of\nlarge-scale dataset; however, training on such dataset often poses privacy\nrisks for sensitive training information. In this paper, we aim to explore the\npower of generative models and gradient sparsity, and propose a scalable\nprivacy-preserving generative model DATALENS. Comparing with the standard PATE\nprivacy-preserving framework which allows teachers to vote on one-dimensional\npredictions, voting on the high dimensional gradient vectors is challenging in\nterms of privacy preservation. As dimension reduction techniques are required,\nwe need to navigate a delicate tradeoff space between (1) the improvement of\nprivacy preservation and (2) the slowdown of SGD convergence. To tackle this,\nwe take advantage of communication efficient learning and propose a novel noise\ncompression and aggregation approach TOPAGG by combining top-k compression for\ndimension reduction with a corresponding noise injection mechanism. We\ntheoretically prove that the DATALENS framework guarantees differential privacy\nfor its generated data, and provide analysis on its convergence. To demonstrate\nthe practical usage of DATALENS, we conduct extensive experiments on diverse\ndatasets including MNIST, Fashion-MNIST, and high dimensional CelebA, and we\nshow that, DATALENS significantly outperforms other baseline DP generative\nmodels. In addition, we adapt the proposed TOPAGG approach, which is one of the\nkey building blocks in DATALENS, to DP SGD training, and show that it is able\nto achieve higher utility than the state-of-the-art DP SGD approach in most\ncases.\n", "versions": [{"version": "v1", "created": "Sat, 20 Mar 2021 06:14:19 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 18:53:31 GMT"}, {"version": "v3", "created": "Fri, 7 May 2021 14:22:08 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Wang", "Boxin", ""], ["Wu", "Fan", ""], ["Long", "Yunhui", ""], ["Rimanic", "Luka", ""], ["Zhang", "Ce", ""], ["Li", "Bo", ""]]}, {"id": "2103.11206", "submitter": "Kartick Sutradhar", "authors": "Kartick Sutradhar, Hari Om", "title": "An Efficient Simulation of Quantum Secret Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In quantum cryptography, quantum secret sharing $(QSS)$ is a fundamental\nprimitive. $QSS$ can be used to create complex and secure multiparty quantum\nprotocols. Existing $QSS$ protocols are either at the $(n, n)$ threshold $2$\nlevel or at the $(t, n)$ threshold $d$ level with a trusted player, where $n$\ndenotes the number of players and $t$ denotes the threshold number of players.\nHere, we propose a secure $d$-level $QSS$ protocol for sharing a secret with\nefficient simulation. This protocol is more secure, flexible, and practical as\ncompared to the existing $QSS$ protocols: $(n, n)$ threshold $2$-level and\n$(t,n)$ threshold $d$-level with a trusted player. Further, it does not\ndisclose any information about the secret to players. Its security analysis\nshows that the intercept-resend, intercept, entangle-measure, forgery,\ncollision and collusion attacks are not possible in this protocol.\n", "versions": [{"version": "v1", "created": "Sat, 20 Mar 2021 16:42:02 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Sutradhar", "Kartick", ""], ["Om", "Hari", ""]]}, {"id": "2103.11240", "submitter": "Rafael Dowsley", "authors": "Rafael Dowsley and Caleb Horst and Anderson C. A. Nascimento", "title": "Round and Communication Balanced Protocols for Oblivious Evaluation of\n  Finite State Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose protocols for obliviously evaluating finite-state machines, i.e.,\nthe evaluation is shared between the provider of the finite-state machine and\nthe provider of the input string in such a manner that neither party learns the\nother's input, and the states being visited are hidden from both. For alphabet\nsize $|\\Sigma|$, number of states $|Q|$, and input length $n$, previous\nsolutions have either required a number of rounds linear in $n$ or\ncommunication $\\Omega(n|\\Sigma||Q|\\log|Q|)$. Our solutions require 2 rounds\nwith communication $O(n(|\\Sigma|+|Q|\\log|Q|))$. We present two different\nsolutions to this problem, a two-party one and a setting with an untrusted but\nnon-colluding helper.\n", "versions": [{"version": "v1", "created": "Sat, 20 Mar 2021 20:49:41 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Dowsley", "Rafael", ""], ["Horst", "Caleb", ""], ["Nascimento", "Anderson C. A.", ""]]}, {"id": "2103.11244", "submitter": "Takashi Yamakawa", "authors": "Nai-Hui Chia and Kai-Min Chung and Qipeng Liu and Takashi Yamakawa", "title": "On the Impossibility of Post-Quantum Black-Box Zero-Knowledge in\n  Constant Rounds", "comments": "46 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the existence of constant-round post-quantum black-box\nzero-knowledge protocols for $\\mathbf{NP}$. As a main result, we show that\nthere is no constant-round post-quantum black-box zero-knowledge argument for\n$\\mathbf{NP}$ unless $\\mathbf{NP}\\subseteq \\mathbf{BQP}$. As constant-round\nblack-box zero-knowledge arguments for $\\mathbf{NP}$ exist in the classical\nsetting, our main result points out a fundamental difference between\npost-quantum and classical zero-knowledge protocols. Combining previous\nresults, we conclude that unless $\\mathbf{NP}\\subseteq \\mathbf{BQP}$,\nconstant-round post-quantum zero-knowledge protocols for $\\mathbf{NP}$ exist if\nand only if we use non-black-box techniques or relax certain security\nrequirements such as relaxing standard zero-knowledge to\n$\\epsilon$-zero-knowledge. Additionally, we also prove that three-round and\npublic-coin constant-round post-quantum black-box $\\epsilon$-zero-knowledge\narguments for $\\mathbf{NP}$ do not exist unless $\\mathbf{NP}\\subseteq\n\\mathbf{BQP}$.\n", "versions": [{"version": "v1", "created": "Sat, 20 Mar 2021 21:00:13 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 13:40:45 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Chia", "Nai-Hui", ""], ["Chung", "Kai-Min", ""], ["Liu", "Qipeng", ""], ["Yamakawa", "Takashi", ""]]}, {"id": "2103.11308", "submitter": "Honglin Yuan", "authors": "Yan Yan, Hong-lin Yuan, Zhi-hua Bao, Guo-an Zhang", "title": "Nonlinear RF Fingerprints Authentication for OFDM Wireless Devices based\n  on Demodulated Symbols", "comments": "7 pages, 6 figures, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radio Frequency fingerprints (RFF) authentication is one of the methods for\nthe physical-layer information security, which uses the hardware\ncharacteristics of the transmitter to identify its real identity. In order to\nimprove the performance of RFF based on preamble with fixed duration, a\nnonlinear RFF authentication method based on payload symbols is proposed for\nthe wireless OFDM devices with the bit mapping scheme of QPSK. The\ncommunication system is modeled as a Hammerstein system containing the\nnonlinear transmitter and wireless multipath fading channel. A parameter\nseparation technique based on orthogonal polynomial is presented for the\nestimation of the parameters of the Hammerstein system. The Hammerstein system\nparameter separation technique is firstly used to estimate the linear parameter\nwith the training signal, which is used to compensate the adverse effect of the\nlinear channel for the demodulation of the successive payload symbols. The\ndemodulated payload symbols are further used to estimate the nonlinear\ncoefficients of the transmitter with the Hammerstein system parameter\nseparation technique again, which is used as the novel RFF for the\nauthentication of the QPSK-OFDM devices. Numerical experiments demonstrate that\nthe proposed method is feasible. The novel method can also be extended to the\nOFDM signals with other bit mapping schemes.\n", "versions": [{"version": "v1", "created": "Sun, 21 Mar 2021 05:30:00 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 07:32:42 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Yan", "Yan", ""], ["Yuan", "Hong-lin", ""], ["Bao", "Zhi-hua", ""], ["Zhang", "Guo-an", ""]]}, {"id": "2103.11316", "submitter": "Triet Le", "authors": "Triet H. M. Le, Bushra Sabir, M. Ali Babar", "title": "Automated Software Vulnerability Assessment with Concept Drift", "comments": "Published as a full paper at the 16th International Conference on\n  Mining Software Repositories 2019", "journal-ref": "Proceedings of the 16th International Conference on Mining\n  Software Repositories, 2019, pp. 371-382", "doi": "10.1109/MSR.2019.00063", "report-no": null, "categories": "cs.SE cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Software Engineering researchers are increasingly using Natural Language\nProcessing (NLP) techniques to automate Software Vulnerabilities (SVs)\nassessment using the descriptions in public repositories. However, the existing\nNLP-based approaches suffer from concept drift. This problem is caused by a\nlack of proper treatment of new (out-of-vocabulary) terms for the evaluation of\nunseen SVs over time. To perform automated SVs assessment with concept drift\nusing SVs' descriptions, we propose a systematic approach that combines both\ncharacter and word features. The proposed approach is used to predict seven\nVulnerability Characteristics (VCs). The optimal model of each VC is selected\nusing our customized time-based cross-validation method from a list of eight\nNLP representations and six well-known Machine Learning models. We have used\nthe proposed approach to conduct large-scale experiments on more than 100,000\nSVs in the National Vulnerability Database (NVD). The results show that our\napproach can effectively tackle the concept drift issue of the SVs'\ndescriptions reported from 2000 to 2018 in NVD even without retraining the\nmodel. In addition, our approach performs competitively compared to the\nexisting word-only method. We also investigate how to build compact\nconcept-drift-aware models with much fewer features and give some\nrecommendations on the choice of classifiers and NLP representations for SVs\nassessment.\n", "versions": [{"version": "v1", "created": "Sun, 21 Mar 2021 06:28:45 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Le", "Triet H. M.", ""], ["Sabir", "Bushra", ""], ["Babar", "M. Ali", ""]]}, {"id": "2103.11363", "submitter": "Fatimah Aljaafari F", "authors": "Fatimah Aljaafari and Rafael Menezes and Mustafa A. Mustafa and Lucas\n  C. Cordeiro", "title": "Finding Security Vulnerabilities in IoT Cryptographic Protocol and\n  Concurrent Implementations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) consists of a large number of devices connected\nthrough a network, which exchange a high volume of data, thereby posing new\nsecurity, privacy, and trust issues. One way to address these issues is\nensuring data confidentiality using lightweight encryption algorithms for IoT\nprotocols. However, the design and implementation of such protocols is an\nerror-prone task; flaws in the implementation can lead to devastating security\nvulnerabilities. Here we propose a new verification approach named\nEncryption-BMC and Fuzzing (EBF), which combines Bounded Model Checking (BMC)\nand Fuzzing techniques to check for security vulnerabilities that arise from\nconcurrent implementations of cyrptographic protocols, which include data race,\nthread leak, arithmetic overflow, and memory safety. EBF models IoT protocols\nas a client and server using POSIX threads, thereby simulating both entities'\ncommunication. It also employs static and dynamic verification to cover the\nsystem's state-space exhaustively. We evaluate EBF against three benchmarks.\nFirst, we use the concurrency benchmark from SV-COMP and show that it\noutperforms other state-of-the-art tools such as ESBMC, AFL, Lazy-CSeq, and\nTSAN with respect to bug finding. Second, we evaluate an open-source\nimplementation called WolfMQTT. It is an MQTT client implementation that uses\nthe WolfSSL library. We show that \\tool detects a data race bug, which other\napproaches are unable to find. Third, to show the effectiveness of EBF, we\nreplicate some known vulnerabilities in OpenSSL and CyaSSL (lately WolfSSL)\nlibraries. EBF can detect the bugs in minimum time.\n", "versions": [{"version": "v1", "created": "Sun, 21 Mar 2021 11:08:11 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 21:12:45 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Aljaafari", "Fatimah", ""], ["Menezes", "Rafael", ""], ["Mustafa", "Mustafa A.", ""], ["Cordeiro", "Lucas C.", ""]]}, {"id": "2103.11518", "submitter": "Zhen Yu Ding", "authors": "Zhen Yu Ding, Claire Le Goues", "title": "An Empirical Study of OSS-Fuzz Bugs", "comments": "12 pages; accepted at the 2021 IEEE/ACM 18th International Conference\n  on Mining Software Repositories (MSR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous fuzzing is an increasingly popular technique for automated quality\nand security assurance. Google maintains OSS-Fuzz: a continuous fuzzing service\nfor open source software. We conduct the first empirical study of OSS-Fuzz,\nanalyzing 23,907 bugs found in 316 projects. We examine the characteristics of\nfuzzer-found faults, the lifecycles of such faults, and the evolution of\nfuzzing campaigns over time. We find that OSS-Fuzz is often effective at\nquickly finding bugs, and developers are often quick to patch them. However,\nflaky bugs, timeouts, and out of memory errors are problematic, people rarely\nfile CVEs for security vulnerabilities, and fuzzing campaigns often exhibit\npunctuated equilibria, where developers might be surprised by large spikes in\nbugs found. Our findings have implications on future fuzzing research and\npractice.\n", "versions": [{"version": "v1", "created": "Sun, 21 Mar 2021 23:45:09 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Ding", "Zhen Yu", ""], ["Goues", "Claire Le", ""]]}, {"id": "2103.11519", "submitter": "Harshit Kumar", "authors": "Harshit Kumar, Nikhil Chawla, Saibal Mukhopadhyay", "title": "Towards Improving the Trustworthiness of Hardware based Malware Detector\n  using Online Uncertainty Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware-based Malware Detectors (HMDs) using Machine Learning (ML) models\nhave shown promise in detecting malicious workloads. However, the conventional\nblack-box based machine learning (ML) approach used in these HMDs fail to\naddress the uncertain predictions, including those made on zero-day malware.\nThe ML models used in HMDs are agnostic to the uncertainty that determines\nwhether the model \"knows what it knows,\" severely undermining its\ntrustworthiness. We propose an ensemble-based approach that quantifies\nuncertainty in predictions made by ML models of an HMD, when it encounters an\nunknown workload than the ones it was trained on. We test our approach on two\ndifferent HMDs that have been proposed in the literature. We show that the\nproposed uncertainty estimator can detect >90% of unknown workloads for the\nPower-management based HMD, and conclude that the overlapping benign and\nmalware classes undermine the trustworthiness of the Performance Counter-based\nHMD.\n", "versions": [{"version": "v1", "created": "Sun, 21 Mar 2021 23:55:35 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Kumar", "Harshit", ""], ["Chawla", "Nikhil", ""], ["Mukhopadhyay", "Saibal", ""]]}, {"id": "2103.11548", "submitter": "Masahito Hayashi", "authors": "Masahito Hayashi", "title": "Secure list decoding and its application to bit-string commitment", "comments": "This paper is a different paper from arXiv:1901.02590 as follows. (1)\n  The definition of secure list decoding of this paper contains the\n  equivocation rate while arXiv:1901.02590 does not consider it. (2) This paper\n  shows that our secure list decoding can be applied to bit-string commitment\n  while the paper arXiv:1901.02590 does not consider it", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new concept of secure list decoding, which is related to\nbit-string commitment. While the conventional list decoding requires that the\nlist contains the transmitted message, secure list decoding requires the\nfollowing additional security conditions to work as a modification of\nbit-string commitment. The first additional security condition is the\nreceiver's uncertainty for the transmitted message, which is stronger than the\nimpossibility of the correct decoding, even though the transmitted message is\ncontained in the list. The other additional security condition is the\nimpossibility for the sender to estimate another element of the decoded list\nexcept for the transmitted message. The first condition is evaluated by the\nequivocation rate. The asymptotic property is evaluated by three parameters,\nthe rates of the message and list sizes, and the equivocation rate. We derive\nthe capacity region of this problem. We show that the combination of hash\nfunction and secure list decoding yields the conventional bit-string\ncommitment. Our results hold even when the input and output systems are general\nprobability spaces including continuous systems. When the input system is a\ngeneral probability space, we formulate the abilities of the honest sender and\nthe dishonest sender in a different way.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2021 02:42:45 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Hayashi", "Masahito", ""]]}, {"id": "2103.11585", "submitter": "Sabah Suhail", "authors": "Sabah Suhail, Rasheed Hussain, Raja Jurdak, Alma Oracevic, Khaled\n  Salah, and Choong Seon Hong", "title": "Blockchain-based Digital Twins: Research Trends, Issues, and Future\n  Challenges", "comments": "32 pages, 9 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial processes rely on sensory data for decision-making processes, risk\nassessment, and performance evaluation. Extracting actionable insights from the\ncollected data calls for an infrastructure that can ensure the dissemination of\ntrustworthy data. For the physical data to be trustworthy, it needs to be\ncross-validated through multiple sensor sources with overlapping fields of\nview. Cross-validated data can then be stored on blockchain, to maintain its\nintegrity and trustworthiness. Once trustworthy data is recorded on the\nblockchain, product lifecycle events can be fed into data-driven systems for\nprocess monitoring, diagnostics, and optimized control. In this regard, Digital\nTwins (DTs) can be leveraged in industry to draw intelligent conclusions from\ndata by identifying the faults and recommending precautionary measures ahead of\ncritical events. Empowering DTs with blockchain in industrial use-cases targets\nkey challenges of disparate data repositories, untrustworthy data\ndissemination, and the need for predictive maintenance. In this survey, while\nhighlighting the key benefits of using blockchain-based DTs, we present a\ncomprehensive review of the state-of-the-art research results for\nblockchain-based DTs. Based on the current research trends, we discuss in\ndetail a framework for trustworthy blockchain-based DTs. Furthermore, we also\ndiscuss current and future research and deployment challenges along with\nessential measures that must be taken by the blockchain-based DTs.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2021 05:13:48 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Suhail", "Sabah", ""], ["Hussain", "Rasheed", ""], ["Jurdak", "Raja", ""], ["Oracevic", "Alma", ""], ["Salah", "Khaled", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2103.11648", "submitter": "Lukas Prediger", "authors": "Lukas Prediger, Niki Loppi, Samuel Kaski, Antti Honkela", "title": "d3p -- A Python Package for Differentially-Private Probabilistic\n  Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present d3p, a software package designed to help fielding runtime\nefficient widely-applicable Bayesian inference under differential privacy\nguarantees. d3p achieves general applicability to a wide range of probabilistic\nmodelling problems by implementing the differentially private variational\ninference algorithm, allowing users to fit any parametric probabilistic model\nwith a differentiable density function. d3p adopts the probabilistic\nprogramming paradigm as a powerful way for the user to flexibly define such\nmodels. We demonstrate the use of our software on a hierarchical logistic\nregression example, showing the expressiveness of the modelling approach as\nwell as the ease of running the parameter inference. We also perform an\nempirical evaluation of the runtime of the private inference on a complex model\nand find an $\\sim$10 fold speed-up compared to an implementation using\nTensorFlow Privacy.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2021 08:15:58 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Prediger", "Lukas", ""], ["Loppi", "Niki", ""], ["Kaski", "Samuel", ""], ["Honkela", "Antti", ""]]}, {"id": "2103.11739", "submitter": "Gamal Elkoumy", "authors": "Gamal Elkoumy (1), Alisa Pankova (2), Marlon Dumas (1) ((1) University\n  of Tartu, Tartu, Estonia, (2) Cybernetica, Tartu, Estonia)", "title": "Mine Me but Don't Single Me Out: Differentially Private Event Logs for\n  Process Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The applicability of process mining techniques hinges on the availability of\nevent logs capturing the execution of a business process. In some use cases,\nparticularly those involving customer-facing processes, these event logs may\ncontain private information. Data protection regulations restrict the use of\nsuch event logs for analysis purposes. One way of circumventing these\nrestrictions is to anonymize the event log to the extent that no individual can\nbe singled out using the anonymized log. This paper addresses the problem of\nanonymizing an event log in order to guarantee that, upon disclosure of the\nanonymized log, the probability that an attacker may single out any individual\nrepresented in the original log, does not increase by more than a threshold.\nThe paper proposes a differentially private disclosure mechanism, which\noversamples the cases in the log and adds noise to the timestamps to the extent\nrequired to achieve the above privacy guarantee. The paper reports on an\nempirical evaluation of the proposed approach using 14 real-life event logs in\nterms of data utility loss and computational efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2021 11:39:11 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Elkoumy", "Gamal", ""], ["Pankova", "Alisa", ""], ["Dumas", "Marlon", ""]]}, {"id": "2103.11740", "submitter": "Martin Kabierski", "authors": "Martin Kabierski, Stephan Fahrenkrog-Petersen, Matthias Weidlich", "title": "Privacy-aware Process Performance Indicators: Framework and Release\n  Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Process performance indicators (PPIs) are metrics to quantify the degree with\nwhich organizational goals defined based on business processes are fulfilled.\nThey exploit the event logs recorded by information systems during the\nexecution of business processes, thereby providing a basis for process\nmonitoring and subsequent optimization. However, PPIs are often evaluated on\nprocesses that involve individuals, which implies an inevitable risk of privacy\nintrusion. In this paper, we address the demand for privacy protection in the\ncomputation of PPIs. We first present a framework that enforces control over\nthe data exploited for process monitoring. We then show how PPIs defined based\non the established PPINOT meta-model are instantiated in this framework through\na set of data release mechanisms. These mechanisms are designed to provide\nprovable guarantees in terms of differential privacy. We evaluate our framework\nand the release mechanisms in a series of controlled experiments. We further\nuse a public event log to compare our framework with approaches based on\nprivatization of event logs. The results demonstrate feasibility and shed light\non the trade-offs between data utility and privacy guarantees in the\ncomputation of PPIs.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2021 11:41:21 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Kabierski", "Martin", ""], ["Fahrenkrog-Petersen", "Stephan", ""], ["Weidlich", "Matthias", ""]]}, {"id": "2103.11765", "submitter": "Andrea Merlina", "authors": "Andrea Merlina, Roman Vitenberg, Vinay Setty", "title": "A General and Configurable Framework for Blockchain-based Marketplaces", "comments": "27 pages, 2 figures, 7 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The first generation of blockchain focused on digital currencies and secure\nstorage, management and transfer of tokenized values. Thereafter, the focus has\nbeen shifting from currencies to a broader application space. In this paper, we\nsystematically explore marketplace types and properties, and consider the\nmechanisms required to support those properties through blockchain. We propose\na generic and configurable framework for blockchain-based marketplaces, and\ndescribe how popular marketplace types, price discovery policies, and other\nconfiguration parameters are implemented within the framework by presenting\nconcrete event-based algorithms. Finally, we consider three use cases with\nwidely diverging properties and show how the proposed framework supports them.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2021 12:28:53 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Merlina", "Andrea", ""], ["Vitenberg", "Roman", ""], ["Setty", "Vinay", ""]]}, {"id": "2103.11958", "submitter": "Wouter Lueks", "authors": "Theresa Stadler, Wouter Lueks, Katharina Kohls, Carmela Troncoso", "title": "Preliminary Analysis of Potential Harms in the Luca Tracing System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this document, we analyse the potential harms a large-scale deployment of\nthe Luca system might cause to individuals, venues, and communities. The Luca\nsystem is a digital presence tracing system designed to provide health\ndepartments with the contact information necessary to alert individuals who\nhave visited a location at the same time as a SARS-CoV-2-positive person.\nMultiple regional health departments in Germany have announced their plans to\ndeploy the Luca system for the purpose of presence tracing. The system's\ndevelopers suggest its use across various types of venues: from bars and\nrestaurants to public and private events, such religious or political\ngatherings, weddings, and birthday parties. Recently, an extension to include\nschools and other educational facilities was discussed in public. Our analysis\nof the potential harms of the system is based on the publicly available Luca\nSecurity Concept which describes the system's security architecture and its\nplanned protection mechanisms. The Security Concept furthermore provides a set\nof claims about the system's security and privacy properties. Besides an\nanalysis of harms, our analysis includes a validation of these claims.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2021 16:00:55 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Stadler", "Theresa", ""], ["Lueks", "Wouter", ""], ["Kohls", "Katharina", ""], ["Troncoso", "Carmela", ""]]}, {"id": "2103.12010", "submitter": "Samuel Yen-Chi Chen", "authors": "Samuel Yen-Chi Chen, Shinjae Yoo", "title": "Federated Quantum Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed training across several quantum computers could significantly\nimprove the training time and if we could share the learned model, not the\ndata, it could potentially improve the data privacy as the training would\nhappen where the data is located. However, to the best of our knowledge, no\nwork has been done in quantum machine learning (QML) in federation setting yet.\nIn this work, we present the federated training on hybrid quantum-classical\nmachine learning models although our framework could be generalized to pure\nquantum machine learning model. Specifically, we consider the quantum neural\nnetwork (QNN) coupled with classical pre-trained convolutional model. Our\ndistributed federated learning scheme demonstrated almost the same level of\ntrained model accuracies and yet significantly faster distributed training. It\ndemonstrates a promising future research direction for scaling and privacy\naspects.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2021 17:00:19 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Chen", "Samuel Yen-Chi", ""], ["Yoo", "Shinjae", ""]]}, {"id": "2103.12304", "submitter": "Kalvin Eng", "authors": "David Reid, Kalvin Eng, Chris Bogart, Adam Tutko", "title": "Tracing Vulnerable Code Lineage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents results from the MSR 2021 Hackathon. Our team\ninvestigates files/projects that contain known security vulnerabilities and how\nwidespread they are throughout repositories in open source software. These\nsecurity vulnerabilities can potentially be propagated through code reuse even\nwhen the vulnerability is fixed in different versions of the code. We utilize\nthe World of Code infrastructure to discover file-level duplication of code\nfrom a nearly complete collection of open source software. This paper describes\na method and set of tools to find all open source projects that use known\nvulnerable files and any previous revisions of those files.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 04:42:51 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Reid", "David", ""], ["Eng", "Kalvin", ""], ["Bogart", "Chris", ""], ["Tutko", "Adam", ""]]}, {"id": "2103.12323", "submitter": "Nassir Mohammad", "authors": "Nassir Mohammad", "title": "Anomaly detection using principles of human perception", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the fields of statistics and unsupervised machine learning a fundamental\nand well-studied problem is anomaly detection. Although anomalies are difficult\nto define, many algorithms have been proposed. Underlying the approaches is the\nnebulous understanding that anomalies are rare, unusual or inconsistent with\nthe majority of data. The present work gives a philosophical approach to\nclearly define anomalies and to develop an algorithm for their efficient\ndetection with minimal user intervention. Inspired by the Gestalt School of\nPsychology and the Helmholtz principle of human perception, the idea is to\nassume anomalies are observations that are unexpected to occur with respect to\ncertain groupings made by the majority of the data. Thus, under appropriate\nrandom variable modelling anomalies are directly found in a set of data under a\nuniform and independent random assumption of the distribution of constituent\nelements of the observations; anomalies correspond to those observations where\nthe expectation of occurrence of the elements in a given view is $<1$. Starting\nfrom fundamental principles of human perception an unsupervised anomaly\ndetection algorithm is developed that is simple, real-time and parameter-free.\nExperiments suggest it as the prime choice for univariate data and it shows\npromising performance on the detection of global anomalies in multivariate\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 05:46:27 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Mohammad", "Nassir", ""]]}, {"id": "2103.12326", "submitter": "Mayank Pandey", "authors": "Mayank Pandey, Rachit Agarwal, Sandeep K. Shukla, Nishchal K. Verma", "title": "Security of Healthcare Data Using Blockchains: A Survey", "comments": "Submitted as a book chapter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advancement in the healthcare sector is entering into a new era in the\nform of Health 4.0. The integration of innovative technologies like\nCyber-Physical Systems (CPS), Big Data, Cloud Computing, Machine Learning, and\nBlockchain with Healthcare services has led to improved performance and\nefficiency through data-based learning and interconnection of systems. On the\nother hand, it has also increased complexities and has brought its own share of\nvulnerabilities due to the heavy influx, sharing, and storage of healthcare\ndata. The protection of the same from cyber-attacks along with privacy\npreservation through authenticated access is one of the significant challenges\nfor the healthcare sector. For this purpose, the use of blockchain-based\nnetworks can lead to a considerable reduction in the vulnerabilities of the\nhealthcare systems and secure their data. This chapter explores blockchain's\nrole in strengthening healthcare data security by answering the questions\nrelated to what data use, when we need, why we need, who needs, and how\nstate-of-the-art techniques use blockchains to secure healthcare data. As a\ncase study, we also explore and analyze the state-of-the-art implementations\nfor blockchain in healthcare data security for the COVID-19 pandemic. In order\nto provide a path to future research directions, we identify and discuss the\ntechnical limitations and regulatory challenges associated with\nblockchain-based healthcare data security implementation.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 05:51:29 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Pandey", "Mayank", ""], ["Agarwal", "Rachit", ""], ["Shukla", "Sandeep K.", ""], ["Verma", "Nishchal K.", ""]]}, {"id": "2103.12365", "submitter": "Yuan Xu", "authors": "Yuan Xu and Tianwei Zhang and Yungang Bao", "title": "Risk Analysis and Policy Enforcement of Function Interactions in Robot\n  Apps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robot apps are becoming more automated, complex and diverse. An app usually\nconsists of many functions, interacting with each other and the environment.\nThis allows robots to conduct various tasks. However, it also opens a new door\nfor cyber attacks: adversaries can leverage these interactions to threaten the\nsafety of robot operations. Unfortunately, this issue is rarely explored in\npast works.\n  We present the first systematic investigation about the function interactions\nin common robot apps. First, we disclose the potential risks and damages caused\nby malicious interactions. We introduce a comprehensive graph to model the\nfunction interactions in robot apps by analyzing 3,100 packages from the Robot\nOperating System (ROS) platform. From this graph, we identify and categorize\nthree types of interaction risks. Second, we propose RTron, a novel system to\ndetect and mitigate these risks and protect the operations of robot apps. We\nintroduce security policies for each type of risks, and design coordination\nnodes to enforce the policies and regulate the interactions. We conduct\nextensive experiments on 110 robot apps from the ROS platform and two complex\napps (Baidu Apollo and Autoware) widely adopted in industry. Evaluation results\nindicated RTron can correctly identify and mitigate all potential risks with\nnegligible performance cost. To validate the practicality of the risks and\nsolutions, we implement and evaluate RTron on a physical UGV (Turtlebot) with\nreal-word apps and environments.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 07:57:28 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Xu", "Yuan", ""], ["Zhang", "Tianwei", ""], ["Bao", "Yungang", ""]]}, {"id": "2103.12399", "submitter": "Antonio Emanuele Cin\\`a", "authors": "Antonio Emanuele Cin\\`a, Sebastiano Vascon, Ambra Demontis, Battista\n  Biggio, Fabio Roli, Marcello Pelillo", "title": "The Hammer and the Nut: Is Bilevel Optimization Really Needed to Poison\n  Linear Classifiers?", "comments": "8 pages, 7 figures, Submitted to IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most concerning threats for modern AI systems is data poisoning,\nwhere the attacker injects maliciously crafted training data to corrupt the\nsystem's behavior at test time. Availability poisoning is a particularly\nworrisome subset of poisoning attacks where the attacker aims to cause a\nDenial-of-Service (DoS) attack. However, the state-of-the-art algorithms are\ncomputationally expensive because they try to solve a complex bi-level\noptimization problem (the \"hammer\"). We observed that in particular conditions,\nnamely, where the target model is linear (the \"nut\"), the usage of\ncomputationally costly procedures can be avoided. We propose a\ncounter-intuitive but efficient heuristic that allows contaminating the\ntraining set such that the target system's performance is highly compromised.\nWe further suggest a re-parameterization trick to decrease the number of\nvariables to be optimized. Finally, we demonstrate that, under the considered\nsettings, our framework achieves comparable, or even better, performances in\nterms of the attacker's objective while being significantly more\ncomputationally efficient.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 09:08:10 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Cin\u00e0", "Antonio Emanuele", ""], ["Vascon", "Sebastiano", ""], ["Demontis", "Ambra", ""], ["Biggio", "Battista", ""], ["Roli", "Fabio", ""], ["Pelillo", "Marcello", ""]]}, {"id": "2103.12433", "submitter": "Dmytro Petryk", "authors": "Dmytro Petryk and Zoya Dyka and Peter Langendoerfer", "title": "Sensitivity of Standard Library Cells to Optical Fault Injection Attacks\n  in IHP 250 nm Technology", "comments": null, "journal-ref": null, "doi": "10.1109/MECO49872.2020.9134146", "report-no": null, "categories": "cs.CR cs.AR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The IoT consists of a lot of devices such as embedded systems, wireless\nsensor nodes (WSNs), control systems, etc. It is essential for some of these\ndevices to protect information that they process and transmit. The issue is\nthat an adversary may steal these devices to gain a physical access to the\ndevice. There is a variety of ways that allows to reveal cryptographic keys.\nOne of them are optical Fault Injection attacks. We performed successful\noptical Fault Injections into different type of gates, in particular INV, NAND,\nNOR, FF. In our work we concentrate on the selection of the parameters\nconfigured by an attacker and their influence on the success of the Fault\nInjections.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 10:23:58 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Petryk", "Dmytro", ""], ["Dyka", "Zoya", ""], ["Langendoerfer", "Peter", ""]]}, {"id": "2103.12435", "submitter": "Dmytro Petryk", "authors": "Dmytro Petryk and Zoya Dyka and Eduardo Perez and Mamathamba\n  Kalishettyhalli Mahadevaiaha and Ievgen Kabin and Christian Wenger and Peter\n  Langendoerfer", "title": "Evaluation of the Sensitivity of RRAM Cells to Optical Fault Injection\n  Attacks", "comments": null, "journal-ref": null, "doi": "10.1109/DSD51259.2020.00047", "report-no": null, "categories": "cs.CR cs.AR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Resistive Random Access Memory (RRAM) is a type of Non-Volatile Memory (NVM).\nIn this paper we investigate the sensitivity of the TiN/Ti/Al:HfO2/TiN-based\n1T-1R RRAM cells implemented in a 250 nm CMOS IHP technology to the laser\nirradiation in detail. Experimental results show the feasibility to influence\nthe state of the cells under laser irradiation, i.e. successful optical Fault\nInjection. We focus on the selection of the parameters of the laser station and\ntheir influence on the success of optical Fault Injections.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 10:26:29 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Petryk", "Dmytro", ""], ["Dyka", "Zoya", ""], ["Perez", "Eduardo", ""], ["Mahadevaiaha", "Mamathamba Kalishettyhalli", ""], ["Kabin", "Ievgen", ""], ["Wenger", "Christian", ""], ["Langendoerfer", "Peter", ""]]}, {"id": "2103.12436", "submitter": "Dmytro Petryk", "authors": "Dmytro Petryk and Zoya Dyka and Jens Katzer and Peter Langendoerfer", "title": "Metal Fillers as Potential Low Cost Countermeasure against Optical Fault\n  Injection Attacks", "comments": null, "journal-ref": null, "doi": "10.1109/EWDTS50664.2020.9225092", "report-no": null, "categories": "cs.CR cs.AR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Physically accessible devices such as sensor nodes in Wireless Sensor\nNetworks or \"smart\" devices in the Internet of Things have to be resistant to a\nbroad spectrum of physical attacks, for example to Side Channel Analysis and to\nFault Injection attacks. In this work we concentrate on the vulnerability of\nASICs to precise optical Fault Injection attacks. Here we propose to use metal\nfillers as potential low-cost countermeasure that may be effective against a\nbroad spectrum of physical attacks. In our future work we plan to evaluate\ndifferent methods of metal fillers placement, to select an effective one and to\nintegrate it as additional design rules into automated design flows.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 10:28:25 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Petryk", "Dmytro", ""], ["Dyka", "Zoya", ""], ["Katzer", "Jens", ""], ["Langendoerfer", "Peter", ""]]}, {"id": "2103.12448", "submitter": "Christian Majenz", "authors": "Christian Majenz, Chanelle Matadah Manfouo, Maris Ozols", "title": "Quantum-access security of the Winternitz one-time signature scheme", "comments": "45 pages. v2: Full version accompanying published version, various\n  improvements", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum-access security, where an attacker is granted superposition access to\nsecret-keyed functionalities, is a fundamental security model and its study has\ninspired results in post-quantum security. We revisit, and fill a gap in, the\nquantum-access security analysis of the Lamport one-time signature scheme (OTS)\nin the quantum random oracle model (QROM) by Alagic et al.~(Eurocrypt 2020). We\nthen go on to generalize the technique to the Winternitz OTS. Along the way, we\ndevelop a tool for the analysis of hash chains in the QROM based on the\nsuperposition oracle technique by Zhandry (Crypto 2019) which might be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 10:55:00 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 07:44:11 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Majenz", "Christian", ""], ["Manfouo", "Chanelle Matadah", ""], ["Ozols", "Maris", ""]]}, {"id": "2103.12489", "submitter": "Chenguo Lin", "authors": "Ruowei Wang, Chenguo Lin, Qijun Zhao, Feiyu Zhu", "title": "Watermark Faker: Towards Forgery of Digital Image Watermarking", "comments": "6 pages; accepted by ICME2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital watermarking has been widely used to protect the copyright and\nintegrity of multimedia data. Previous studies mainly focus on designing\nwatermarking techniques that are robust to attacks of destroying the embedded\nwatermarks. However, the emerging deep learning based image generation\ntechnology raises new open issues that whether it is possible to generate fake\nwatermarked images for circumvention. In this paper, we make the first attempt\nto develop digital image watermark fakers by using generative adversarial\nlearning. Suppose that a set of paired images of original and watermarked\nimages generated by the targeted watermarker are available, we use them to\ntrain a watermark faker with U-Net as the backbone, whose input is an original\nimage, and after a domain-specific preprocessing, it outputs a fake watermarked\nimage. Our experiments show that the proposed watermark faker can effectively\ncrack digital image watermarkers in both spatial and frequency domains,\nsuggesting the risk of such forgery attacks.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 12:28:00 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Wang", "Ruowei", ""], ["Lin", "Chenguo", ""], ["Zhao", "Qijun", ""], ["Zhu", "Feiyu", ""]]}, {"id": "2103.12520", "submitter": "Erick Galinkin", "authors": "Erick Galinkin", "title": "Information Security Games: A Survey", "comments": "Drexel University PhD Candidacy Document", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce some preliminaries about game theory and information security.\nThen surveying a subset of the literature, we identify opportunities for future\nresearch.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 13:38:47 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Galinkin", "Erick", ""]]}, {"id": "2103.12521", "submitter": "Mark Stamp", "authors": "Mark Stamp and Aniket Chandak and Gavin Wong and Allen Ye", "title": "On Ensemble Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we consider ensemble classifiers, that is, machine learning\nbased classifiers that utilize a combination of scoring functions. We provide a\nframework for categorizing such classifiers, and we outline several ensemble\ntechniques, discussing how each fits into our framework. From this general\nintroduction, we then pivot to the topic of ensemble learning within the\ncontext of malware analysis. We present a brief survey of some of the ensemble\ntechniques that have been used in malware (and related) research. We conclude\nwith an extensive set of experiments, where we apply ensemble techniques to a\nlarge and challenging malware dataset. While many of these ensemble techniques\nhave appeared in the malware literature, previously there has been no way to\ndirectly compare results such as these, as different datasets and different\nmeasures of success are typically used. Our common framework and empirical\nresults are an effort to bring some sense of order to the chaos that is evident\nin the evolving field of ensemble learning -- both within the narrow confines\nof the malware analysis problem, and in the larger realm of machine learning in\ngeneral.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2021 14:47:11 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Stamp", "Mark", ""], ["Chandak", "Aniket", ""], ["Wong", "Gavin", ""], ["Ye", "Allen", ""]]}, {"id": "2103.12541", "submitter": "Preslav Nakov", "authors": "Firoj Alam, Stefano Cresci, Tanmoy Chakraborty, Fabrizio Silvestri,\n  Dimiter Dimitrov, Giovanni Da San Martino, Shaden Shaar, Hamed Firooz,\n  Preslav Nakov", "title": "A Survey on Multimodal Disinformation Detection", "comments": "disinformation, misinformation, factuality, harmfulness, fake news,\n  propaganda, multimodality, text, images, videos, network structure,\n  temporality", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.AI cs.CL cs.CR cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the proliferation of fake news, propaganda,\nmisinformation, and disinformation online. While initially this was mostly\nabout textual content, over time images and videos gained popularity, as they\nare much easier to consume, attract much more attention, and spread further\nthan simple text. As a result, researchers started targeting different\nmodalities and combinations thereof. As different modalities are studied in\ndifferent research communities, with insufficient interaction, here we offer a\nsurvey that explores the state-of-the-art on multimodal disinformation\ndetection covering various combinations of modalities: text, images, audio,\nvideo, network structure, and temporal information. Moreover, while some\nstudies focused on factuality, others investigated how harmful the content is.\nWhile these two components in the definition of disinformation -- (i)\nfactuality and (ii) harmfulness, are equally important, they are typically\nstudied in isolation. Thus, we argue for the need to tackle disinformation\ndetection by taking into account multiple modalities as well as both factuality\nand harmfulness, in the same framework. Finally, we discuss current challenges\nand future research directions.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 18:04:17 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Alam", "Firoj", ""], ["Cresci", "Stefano", ""], ["Chakraborty", "Tanmoy", ""], ["Silvestri", "Fabrizio", ""], ["Dimitrov", "Dimiter", ""], ["Martino", "Giovanni Da San", ""], ["Shaar", "Shaden", ""], ["Firooz", "Hamed", ""], ["Nakov", "Preslav", ""]]}, {"id": "2103.12542", "submitter": "Boyu Fan", "authors": "Boyu Fan, Xiang Su, Jianwei Niu and Pan Hui", "title": "EmgAuth: Unlocking Smartphones with EMG Signals", "comments": "13 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Screen lock is a critical security feature for smartphones to prevent\nunauthorized access. Although various screen unlocking technologies, including\nfingerprint and facial recognition, have been widely adopted, they still have\nsome limitations. For example, fingerprints can be stolen by special material\nstickers and facial recognition systems can be cheated by 3D-printed head\nmodels. In this paper, we propose EmgAuth, a novel electromyography(EMG)-based\nsmartphone unlocking system based on the Siamese network. EmgAuth enables users\nto unlock their smartphones by leveraging the EMG data of the smartphone users\ncollected from Myo armbands. When training the Siamese network, we design a\nspecial data augmentation technique to make the system resilient to the\nrotation of the armband, which makes EmgAuth free of calibration. We conduct\nextensive experiments including 53 participants and the evaluation results\nverify that EmgAuth can effectively authenticate users with an average true\nacceptance rate of 91.81% while keeping the average false acceptance rate of\n7.43%. In addition, we also demonstrate that EmgAuth can work well for\nsmartphones with different screen sizes and for different scenarios when users\nare placing smartphones at different locations and with different orientations.\nEmgAuth shows great promise to serve as a good supplement for existing screen\nunlocking systems to improve the safety of smartphones.\n", "versions": [{"version": "v1", "created": "Sun, 21 Mar 2021 07:17:54 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Fan", "Boyu", ""], ["Su", "Xiang", ""], ["Niu", "Jianwei", ""], ["Hui", "Pan", ""]]}, {"id": "2103.12544", "submitter": "Ripon Patgiri", "authors": "Ripon Patgiri, Anupam Biswas and Sabuzima Nayak", "title": "deepBF: Malicious URL detection using Learned Bloom Filter and\n  Evolutionary Deep Learning", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Malicious URL detection is an emerging research area due to continuous\nmodernization of various systems, for instance, Edge Computing. In this\narticle, we present a novel malicious URL detection technique, called deepBF\n(deep learning and Bloom Filter). deepBF is presented in two-fold. Firstly, we\npropose a learned Bloom Filter using 2-dimensional Bloom Filter. We\nexperimentally decide the best non-cryptography string hash function. Then, we\nderive a modified non-cryptography string hash function from the selected hash\nfunction for deepBF by introducing biases in the hashing method and compared\namong the string hash functions. The modified string hash function is compared\nto other variants of diverse non-cryptography string hash functions. It is also\ncompared with various filters, particularly, counting Bloom Filter, Kirsch\n\\textit{et al.}, and Cuckoo Filter using various use cases. The use cases\nunearth weakness and strength of the filters. Secondly, we propose a malicious\nURL detection mechanism using deepBF. We apply the evolutionary convolutional\nneural network to identify the malicious URLs. The evolutionary convolutional\nneural network is trained and tested with malicious URL datasets. The output is\ntested in deepBF for accuracy. We have achieved many conclusions from our\nexperimental evaluation and results and are able to reach various conclusive\ndecisions which are presented in the article.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2021 21:53:22 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Patgiri", "Ripon", ""], ["Biswas", "Anupam", ""], ["Nayak", "Sabuzima", ""]]}, {"id": "2103.12575", "submitter": "Shunji Itani", "authors": "S. Itani, S. Kita and Y. Kajikawa", "title": "Multimodal Personal Ear Authentication Using Smartphones", "comments": "9 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, biometric authentication technology for smartphones has\nbecome widespread, with the mainstream methods being fingerprint authentication\nand face recognition. However, fingerprint authentication cannot be used when\nhands are wet, and face recognition cannot be used when a person is wearing a\nmask. Therefore, we examine a personal authentication system using the pinna as\na new approach for biometric authentication on smartphones. Authentication\nsystems based on the acoustic transfer function of the pinna (PRTF: Pinna\nRelated Transfer Function) have been investigated. However, the authentication\naccuracy decreases due to the positional fluctuation across each measurement.\nIn this paper, we propose multimodal personal authentication on smartphones\nusing PRTF. The pinna image and positional sensor information are used with the\nPRTF, and the effectiveness of the authentication method is examined. We\ndemonstrate that the proposed authentication system can compensate for the\npositional changes in each measurement and improve robustness.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 14:19:15 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Itani", "S.", ""], ["Kita", "S.", ""], ["Kajikawa", "Y.", ""]]}, {"id": "2103.12607", "submitter": "Christoph Sendner", "authors": "Oliver Lutz and Huili Chen and Hossein Fereidooni and Christoph\n  Sendner and Alexandra Dmitrienko and Ahmad Reza Sadeghi and Farinaz\n  Koushanfar", "title": "ESCORT: Ethereum Smart COntRacTs Vulnerability Detection using Deep\n  Neural Network and Transfer Learning", "comments": "17 pages, 10 figures, 5 tables, 5 equations, 2 listings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ethereum smart contracts are automated decentralized applications on the\nblockchain that describe the terms of the agreement between buyers and sellers,\nreducing the need for trusted intermediaries and arbitration. However, the\ndeployment of smart contracts introduces new attack vectors into the\ncryptocurrency systems. In particular, programming flaws in smart contracts can\nbe and have already been exploited to gain enormous financial profits. It is\nthus an emerging yet crucial issue to detect vulnerabilities of different\nclasses in contracts in an efficient manner. Existing machine learning-based\nvulnerability detection methods are limited and only inspect whether the smart\ncontract is vulnerable, or train individual classifiers for each specific\nvulnerability, or demonstrate multi-class vulnerability detection without\nextensibility consideration. To overcome the scalability and generalization\nlimitations of existing works, we propose ESCORT, the first Deep Neural Network\n(DNN)-based vulnerability detection framework for Ethereum smart contracts that\nsupport lightweight transfer learning on unseen security vulnerabilities, thus\nis extensible and generalizable. ESCORT leverages a multi-output NN\narchitecture that consists of two parts: (i) A common feature extractor that\nlearns the semantics of the input contract; (ii) Multiple branch structures\nwhere each branch learns a specific vulnerability type based on features\nobtained from the feature extractor. Experimental results show that ESCORT\nachieves an average F1-score of 95% on six vulnerability types and the\ndetection time is 0.02 seconds per contract. When extended to new vulnerability\ntypes, ESCORT yields an average F1-score of 93%. To the best of our knowledge,\nESCORT is the first framework that enables transfer learning on new\nvulnerability types with minimal modification of the DNN model architecture and\nre-training overhead.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 15:04:44 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Lutz", "Oliver", ""], ["Chen", "Huili", ""], ["Fereidooni", "Hossein", ""], ["Sendner", "Christoph", ""], ["Dmitrienko", "Alexandra", ""], ["Sadeghi", "Ahmad Reza", ""], ["Koushanfar", "Farinaz", ""]]}, {"id": "2103.12616", "submitter": "Majid Salimi", "authors": "Majid Salimi", "title": "Efficient Multilinear Map from Graded Encoding Scheme", "comments": "15 pagess", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Though the multilinear maps have many cryptographic applications, secure and\nefficient construction of such maps is an open problem. Many multilinear maps\nlike GGH, GGH15, CLT, and CLT15 have been and are being proposed, while none of\nthem is both secure and efficient. The construction of some multilinear maps is\nbased on the Graded Encoding Scheme (GES), where, the necessity of announcing\nzero-testing parameter and encoding of zero has destroyed the security of the\nmultilinear map.\n  Attempt is made to propose a new GES, where, instead of encoding an element,\nthe users can obtain the encoding of an associated but unknown random element.\nIn this new setting, there is no need to publish the encodings of zero and one.\nThis new GES provides the actual functionality of the usual GES and can be\napplied in constructing a secure and efficient multilinear map and a\nmulti-party non-interactive key exchange (MP-NIKE) scheme. We also improve the\nMP-NIKE scheme of \\cite{Access20} and turn it into an ID-based MP-NIKE scheme.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 15:15:23 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Salimi", "Majid", ""]]}, {"id": "2103.12739", "submitter": "Pagadala Kalaharsha", "authors": "P.Kalaharsha (1, 2), B.M.Mehtre (1) ((1) Center of excellence in cyber\n  security, Institute for Development and Research in Banking Technology\n  (IDRBT), Hyderabad, India, (2) School of Computer Science and Information\n  Sciences (SCIS), University of Hyderabad, Hyderabad, India)", "title": "Detecting Phishing Sites -- An Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Phishing is one of the most severe cyber-attacks where researchers are\ninterested to find a solution. In phishing, attackers lure end-users and steal\ntheir personal in-formation. To minimize the damage caused by phishing must be\ndetected as early as possible. There are various phishing attacks like spear\nphishing, whaling, vishing, smishing, pharming and so on. There are various\nphishing detection techniques based on white-list, black-list, content-based,\nURL-based, visual-similarity and machine-learning. In this paper, we discuss\nvarious kinds of phishing attacks, attack vectors and detection techniques for\ndetecting the phishing sites. Performance comparison of 18 different models\nalong with nine different sources of datasets are given. Challenges in phishing\ndetection techniques are also given.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 19:16:03 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 09:02:51 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Kalaharsha", "P.", ""], ["Mehtre", "B. M.", ""]]}, {"id": "2103.12801", "submitter": "Pratyay Banerjee", "authors": "Pratyay Banerjee, Kuntal Kumar Pal, Fish Wang, Chitta Baral", "title": "Variable Name Recovery in Decompiled Binary Code using Constrained\n  Masked Language Modeling", "comments": "Work In Progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Decompilation is the procedure of transforming binary programs into a\nhigh-level representation, such as source code, for human analysts to examine.\nWhile modern decompilers can reconstruct and recover much information that is\ndiscarded during compilation, inferring variable names is still extremely\ndifficult. Inspired by recent advances in natural language processing, we\npropose a novel solution to infer variable names in decompiled code based on\nMasked Language Modeling, Byte-Pair Encoding, and neural architectures such as\nTransformers and BERT. Our solution takes \\textit{raw} decompiler output, the\nless semantically meaningful code, as input, and enriches it using our proposed\n\\textit{finetuning} technique, Constrained Masked Language Modeling. Using\nConstrained Masked Language Modeling introduces the challenge of predicting the\nnumber of masked tokens for the original variable name. We address this\n\\textit{count of token prediction} challenge with our post-processing\nalgorithm. Compared to the state-of-the-art approaches, our trained VarBERT\nmodel is simpler and of much better performance. We evaluated our model on an\nexisting large-scale data set with 164,632 binaries and showed that it can\npredict variable names identical to the ones present in the original source\ncode up to 84.15\\% of the time.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 19:09:22 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Banerjee", "Pratyay", ""], ["Pal", "Kuntal Kumar", ""], ["Wang", "Fish", ""], ["Baral", "Chitta", ""]]}, {"id": "2103.12843", "submitter": "Marzieh Bitaab", "authors": "Marzieh Bitaab, Haehyun Cho, Adam Oest, Penghui Zhang, Zhibo Sun, Rana\n  Pourmohamad, Doowon Kim, Tiffany Bao, Ruoyu Wang, Yan Shoshitaishvili, Adam\n  Doup\\'e, Gail-Joon Ahn", "title": "Scam Pandemic: How Attackers Exploit Public Fear through Phishing", "comments": "10 pages, Accepted to eCrime 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the COVID-19 pandemic started triggering widespread lockdowns across the\nglobe, cybercriminals did not hesitate to take advantage of users' increased\nusage of the Internet and their reliance on it. In this paper, we carry out a\ncomprehensive measurement study of online social engineering attacks in the\nearly months of the pandemic. By collecting, synthesizing, and analyzing DNS\nrecords, TLS certificates, phishing URLs, phishing website source code,\nphishing emails, web traffic to phishing websites, news articles, and\ngovernment announcements, we track trends of phishing activity between January\nand May 2020 and seek to understand the key implications of the underlying\ntrends.\n  We find that phishing attack traffic in March and April 2020 skyrocketed up\nto 220\\% of its pre-COVID-19 rate, far exceeding typical seasonal spikes.\nAttackers exploited victims' uncertainty and fear related to the pandemic\nthrough a variety of highly targeted scams, including emerging scam types\nagainst which current defenses are not sufficient as well as traditional\nphishing which outpaced the ecosystem's collective response.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 21:08:04 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Bitaab", "Marzieh", ""], ["Cho", "Haehyun", ""], ["Oest", "Adam", ""], ["Zhang", "Penghui", ""], ["Sun", "Zhibo", ""], ["Pourmohamad", "Rana", ""], ["Kim", "Doowon", ""], ["Bao", "Tiffany", ""], ["Wang", "Ruoyu", ""], ["Shoshitaishvili", "Yan", ""], ["Doup\u00e9", "Adam", ""], ["Ahn", "Gail-Joon", ""]]}, {"id": "2103.12865", "submitter": "Vladimir Dyo", "authors": "Jahangir Ali and Vladimir Dyo", "title": "Privacy-preserving Identity Broadcast for Contact Tracing Applications", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wireless Contact tracing has emerged as an important tool for managing the\nCOVID-19 pandemic and relies on continuous broadcasting of a person's presence\nusing Bluetooth Low Energy beacons. The limitation of current contact tracing\nsystems in that a reception of a single beacon is sufficient to reveal the user\nidentity, potentially exposing users to malicious trackers installed along the\nroads, passageways, and other infrastructure. In this paper, we propose a\nmethod based on Shamir secret sharing algorithm, which lets mobile nodes reveal\ntheir identity only after a certain predefined contact duration, remaining\ninvisible to trackers with short or fleeting encounters. Through data-driven\nevaluation, using a dataset containing 18 million BLE sightings, we show that\nthe method drastically reduces the privacy exposure. Finally, we implemented\nthe approach on Android phones to demonstrate its feasibility and measure\nperformance for various network densities.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 21:56:58 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Ali", "Jahangir", ""], ["Dyo", "Vladimir", ""]]}, {"id": "2103.12905", "submitter": "Qin Wang", "authors": "Rujia Li and Qin Wang and Xinrui Zhang and Qi Wang and David Galindo\n  and Yang Xiang", "title": "An Offline Delegatable Cryptocurrency System", "comments": "ICBC21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain-based cryptocurrencies, facilitating the convenience of payment by\nproviding a decentralized online solution, have not been widely adopted so far\ndue to slow confirmation of transactions. Offline delegation offers an\nefficient way to exchange coins. However, in such an approach, the coins that\nhave been delegated confront the risk of being spent twice since the\ndelegator's behaviour cannot be restricted easily on account of the absence of\neffective supervision. Even if a third party can be regarded as a judge between\nthe delegator and delegatee to secure transactions, she still faces the threat\nof being compromised or providing misleading assure. Moreover, the approach\nequipped with a third party contradicts the real intention of decentralized\ncryptocurrency systems. In this paper, we propose \\textit{DelegaCoin}, an\noffline delegatable cryptocurrency system to mitigate such an issue. We exploit\ntrusted execution environments (TEEs) as decentralized \"virtual agents\" to\nprevent malicious delegation. In DelegaCoin, an owner can delegate his coins\nthrough offline-transactions without interacting with the blockchain network. A\nformal model and analysis, prototype implementation, and further evaluation\ndemonstrate that our scheme is provably secure and practically feasible.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2021 00:59:42 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Li", "Rujia", ""], ["Wang", "Qin", ""], ["Zhang", "Xinrui", ""], ["Wang", "Qi", ""], ["Galindo", "David", ""], ["Xiang", "Yang", ""]]}, {"id": "2103.12928", "submitter": "Sashidhar Jakkamsetti", "authors": "Ivan De Oliveira Nunes and Sashidhar Jakkamsetti and Gene Tsudik", "title": "DIALED: Data Integrity Attestation for Low-end Embedded Devices", "comments": "6 pages, to be published in DAC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verifying integrity of software execution in low-end micro-controller units\n(MCUs) is a well-known open problem. The central challenge is how to securely\ndetect software exploits with minimal overhead, since these MCUs are designed\nfor low cost, low energy and small size. Some recent work yielded inexpensive\nhardware/software co-designs for remotely verifying code and execution\nintegrity. In particular, a means of detecting unauthorized code modifications\nand control-flow attacks were proposed, referred to as Remote Attestation (RA)\nand Control-Flow Attestation (CFA), respectively. Despite this progress,\ndetection of data-only attacks remains elusive. Such attacks exploit software\nvulnerabilities to corrupt intermediate computation results stored in data\nmemory, changing neither the program code nor its control flow. Motivated by\nlack of any current techniques (for low-end MCUs) that detect these attacks, in\nthis paper we propose, implement and evaluate DIALED, the first Data-Flow\nAttestation (DFA) technique applicable to the most resource-constrained\nembedded devices (e.g., TI MSP430). DIALED works in tandem with a companion CFA\nscheme to detect all (currently known) types of runtime software exploits at\nfairly low cost.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2021 01:56:08 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Nunes", "Ivan De Oliveira", ""], ["Jakkamsetti", "Sashidhar", ""], ["Tsudik", "Gene", ""]]}, {"id": "2103.12935", "submitter": "Khalid Mursi", "authors": "Yu Zhuang, Khalid T. Mursi, Li Gaoxiang", "title": "A Challenge Obfuscating Interface for Arbiter PUF Variants against\n  Machine Learning Attacks", "comments": "7 Pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Security is of critical importance for the Internet of Things (IoT). Many IoT\ndevices are resource-constrained, calling for lightweight security protocols.\nPhysical unclonable functions (PUFs) leverage integrated circuits' variations\nto produce responses unique for individual devices, and hence are not\nreproducible even by the manufacturers. Implementable with simplistic circuits\nof thousands of transistors and operable with low energy, Physical unclonable\nfunctions are promising candidates as security primitives for\nresource-constrained IoT devices. Arbiter PUFs (APUFs) are a group of\ndelay-based PUFs which are highly lightweight in resource requirements but\nsuffer from high susceptibility to machine learning attacks. To defend APUF\nvariants against machine learning attacks, we introduce challenge input\ninterface, which incurs low resource overhead. With the interface, experimental\nattack study shows that all tested PUFs have substantially improved their\nresistance against machine learning attacks, rendering interfaced APUF variants\npromising candidates for security critical applications.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2021 02:20:47 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Zhuang", "Yu", ""], ["Mursi", "Khalid T.", ""], ["Gaoxiang", "Li", ""]]}, {"id": "2103.13121", "submitter": "Hampei Sasahara", "authors": "Hampei Sasahara and Henrik Sandberg", "title": "Asymptotic Security by Model-based Incident Handlers for Markov Decision\n  Processes", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.GT cs.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This study investigates general model-based incident handler's asymptotic\nbehaviors in time against cyber attacks to control systems. The attacker's and\nthe defender's dynamic decision making is modeled as an equilibrium of a\ndynamic signaling game. It is shown that the defender's belief on existence of\nan attacker converges over time for any attacker's strategy provided that the\nstochastic dynamics of the control system is known to the defender. This fact\nimplies that the rational behavior of the attacker converges to a harmless\naction as long as the defender possesses an effective counteraction. The\nobtained result supports the powerful protection capability achieved by\nmodel-based defense mechanisms.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2021 11:57:03 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Sasahara", "Hampei", ""], ["Sandberg", "Henrik", ""]]}, {"id": "2103.13127", "submitter": "Yinpeng Dong", "authors": "Yinpeng Dong, Xiao Yang, Zhijie Deng, Tianyu Pang, Zihao Xiao, Hang\n  Su, Jun Zhu", "title": "Black-box Detection of Backdoor Attacks with Limited Information and\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Although deep neural networks (DNNs) have made rapid progress in recent\nyears, they are vulnerable in adversarial environments. A malicious backdoor\ncould be embedded in a model by poisoning the training dataset, whose intention\nis to make the infected model give wrong predictions during inference when the\nspecific trigger appears. To mitigate the potential threats of backdoor\nattacks, various backdoor detection and defense methods have been proposed.\nHowever, the existing techniques usually require the poisoned training data or\naccess to the white-box model, which is commonly unavailable in practice. In\nthis paper, we propose a black-box backdoor detection (B3D) method to identify\nbackdoor attacks with only query access to the model. We introduce a\ngradient-free optimization algorithm to reverse-engineer the potential trigger\nfor each class, which helps to reveal the existence of backdoor attacks. In\naddition to backdoor detection, we also propose a simple strategy for reliable\npredictions using the identified backdoored models. Extensive experiments on\nhundreds of DNN models trained on several datasets corroborate the\neffectiveness of our method under the black-box setting against various\nbackdoor attacks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2021 12:06:40 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Dong", "Yinpeng", ""], ["Yang", "Xiao", ""], ["Deng", "Zhijie", ""], ["Pang", "Tianyu", ""], ["Xiao", "Zihao", ""], ["Su", "Hang", ""], ["Zhu", "Jun", ""]]}, {"id": "2103.13158", "submitter": "Asaf Shabtai", "authors": "Yair Allouche, Nachiket Tapas, Francesco Longo, Asaf Shabtai, Yaron\n  Wolfsthal", "title": "TRADE: TRusted Anonymous Data Exchange: Threat Sharing Using Blockchain\n  Technology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber attacks are becoming more frequent and sophisticated, introducing\nsignificant challenges for organizations to protect their systems and data from\nthreat actors. Today, threat actors are highly motivated, persistent, and\nwell-founded and operate in a coordinated manner to commit a diversity of\nattacks using various sophisticated tactics, techniques, and procedures. Given\nthe risks these threats present, it has become clear that organizations need to\ncollaborate and share cyber threat information (CTI) and use it to improve\ntheir security posture. In this paper, we present TRADE -- TRusted Anonymous\nData Exchange -- a collaborative, distributed, trusted, and anonymized CTI\nsharing platform based on blockchain technology. TRADE uses a blockchain-based\naccess control framework designed to provide essential features and\nrequirements to incentivize and encourage organizations to share threat\nintelligence information. In TRADE, organizations can fully control their data\nby defining sharing policies enforced by smart contracts used to control and\nmanage CTI sharing in the network. TRADE allows organizations to preserve their\nanonymity while keeping organizations fully accountable for their action in the\nnetwork. Finally, TRADE can be easily integrated within existing threat\nintelligence exchange protocols - such as trusted automated exchange of\nintelligence information (TAXII) and OpenDXL, thereby allowing a fast and\nsmooth technology adaptation.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2021 13:03:01 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Allouche", "Yair", ""], ["Tapas", "Nachiket", ""], ["Longo", "Francesco", ""], ["Shabtai", "Asaf", ""], ["Wolfsthal", "Yaron", ""]]}, {"id": "2103.13217", "submitter": "Qinghe Gao", "authors": "Qinghe Gao, Yan Huo, Tao Jing, Liran Ma, Jin Qian", "title": "Cross-layer based intermittent jamming schemes for securing\n  energy-constraint networks", "comments": "11 pages,33 subfigures and figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet-of-Things (IoT) emerges as a paradigm to achieve ubiquitous\nconnectivity via wireless communications between kinds of physical objects. Due\nto the wireless broadcasting nature and the energy constraint of physical\nobjects, concerns on IoT security have triggered research on cooperative\njamming based physical layer security. With the help of a cooperative jammer,\nexisting solutions can effectively fight against eavesdroppers. However, these\nschemes are of high energy cost due to continuously transmitting jamming\nsignals. To reduce the energy consumption, we propose a new idea of\nintermittent jamming and design five specific intermittent jamming schemes\n(IJSs). By taking the transmit frame formate into account, we optimize these\nIJSs from three aspects, including the jamming power, the jamming method, and\nthe jamming positions. Then we analyze the applicability of the proposed IJSs\naccording to different requirements on the synchronization, the available\njamming energy and the jamming power constraints. Extensive MATLAB experiments\nare conducted on the basis of the WLAN Toolbox, which demonstrate the proposed\nIJSs can effectively degrade the reception of the eavesdropper and outperform\nthe widespread continuous jamming scheme (CJS) when the available jamming\nenergy is limited.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2021 14:25:16 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Gao", "Qinghe", ""], ["Huo", "Yan", ""], ["Jing", "Tao", ""], ["Ma", "Liran", ""], ["Qian", "Jin", ""]]}, {"id": "2103.13287", "submitter": "Tobias Fiebig", "authors": "Mannat Kaur, Michel van Eeten, Marijn Janssen, Kevin Borgolte, and\n  Tobias Fiebig", "title": "Human Factors in Security Research: Lessons Learned from 2008-2018", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instead of only considering technology, computer security research now\nstrives to also take into account the human factor by studying regular users\nand, to a lesser extent, experts like operators and developers of systems. We\nfocus our analysis on the research on the crucial population of experts, whose\nhuman errors can impact many systems at once, and compare it to research on\nregular users. To understand how far we advanced in the area of human factors,\nhow the field can further mature, and to provide a point of reference for\nresearchers new to this field, we analyzed the past decade of human factors\nresearch in security and privacy, identifying 557 relevant publications. Of\nthese, we found 48 publications focused on expert users and analyzed all in\ndepth. For additional insights, we compare them to a stratified sample of 48\nend-user studies.\n  In this paper we investigate:\n  (i) The perspective on human factors, and how we can learn from safety\nscience (ii) How and who are the participants recruited, and how this -- as we\nfind -- creates a western-centric perspective (iii) Research objectives, and\nhow to align these with the chosen research methods (iv) How theories can be\nused to increase rigor in the communities scientific work, including\nlimitations to the use of Grounded Theory, which is often incompletely applied\n(v) How researchers handle ethical implications, and what we can do to account\nfor them more consistently\n  Although our literature review has limitations, new insights were revealed\nand avenues for further research identified.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2021 15:58:05 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Kaur", "Mannat", ""], ["van Eeten", "Michel", ""], ["Janssen", "Marijn", ""], ["Borgolte", "Kevin", ""], ["Fiebig", "Tobias", ""]]}, {"id": "2103.13375", "submitter": "Antonino Sabetta", "authors": "Daan Hommersom, Antonino Sabetta, Bonaventura Coppola, Damian A.\n  Tamburri", "title": "Automated Mapping of Vulnerability Advisories onto their Fix Commits in\n  Open Source Repositories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of comprehensive sources of accurate vulnerability data represents a\ncritical obstacle to studying and understanding software vulnerabilities (and\ntheir corrections). In this paper, we present an approach that combines\nheuristics stemming from practical experience and machine-learning (ML) -\nspecifically, natural language processing (NLP) - to address this problem. Our\nmethod consists of three phases. First, an advisory record containing key\ninformation about a vulnerability is extracted from an advisory (expressed in\nnatural language). Second, using heuristics, a subset of candidate fix commits\nis obtained from the source code repository of the affected project by\nfiltering out commits that are known to be irrelevant for the task at hand.\nFinally, for each such candidate commit, our method builds a numerical feature\nvector reflecting the characteristics of the commit that are relevant to\npredicting its match with the advisory at hand. The feature vectors are then\nexploited for building a final ranked list of candidate fixing commits. The\nscore attributed by the ML model to each feature is kept visible to the users,\nallowing them to interpret of the predictions.\n  We evaluated our approach using a prototype implementation named Prospector\non a manually curated data set that comprises 2,391 known fix commits\ncorresponding to 1,248 public vulnerability advisories. When considering the\ntop-10 commits in the ranked results, our implementation could successfully\nidentify at least one fix commit for up to 84.03% of the vulnerabilities (with\na fix commit on the first position for 65.06% of the vulnerabilities). In\nconclusion, our method reduces considerably the effort needed to search OSS\nrepositories for the commits that fix known vulnerabilities.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2021 17:50:35 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Hommersom", "Daan", ""], ["Sabetta", "Antonino", ""], ["Coppola", "Bonaventura", ""], ["Tamburri", "Damian A.", ""]]}, {"id": "2103.13567", "submitter": "Yiwen Guo", "authors": "Zhi Wang, Yiwen Guo, Wangmeng Zuo", "title": "Deepfake Forensics via An Adversarial Game", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the progress in AI-based facial forgery (i.e., deepfake), people are\nincreasingly concerned about its abuse. Albeit effort has been made for\ntraining classification (also known as deepfake detection) models to recognize\nsuch forgeries, existing models suffer from poor generalization to unseen\nforgery technologies and high sensitivity to changes in image/video quality. In\nthis paper, we advocate adversarial training for improving the generalization\nability to both unseen facial forgeries and unseen image/video qualities. We\nbelieve training with samples that are adversarially crafted to attack the\nclassification models improves the generalization ability considerably.\nConsidering that AI-based face manipulation often leads to high-frequency\nartifacts that can be easily spotted by models yet difficult to generalize, we\nfurther propose a new adversarial training method that attempts to blur out\nthese specific artifacts, by introducing pixel-wise Gaussian blurring models.\nWith adversarial training, the classification models are forced to learn more\ndiscriminative and generalizable features, and the effectiveness of our method\ncan be verified by plenty of empirical evidence. Our code will be made publicly\navailable.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 02:20:08 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Wang", "Zhi", ""], ["Guo", "Yiwen", ""], ["Zuo", "Wangmeng", ""]]}, {"id": "2103.13568", "submitter": "Charalambos Konstantinou", "authors": "Xiaorui Liu, Yaodan Hu, Charalambos Konstantinou, Yier Jin", "title": "CHIMERA: A Hybrid Estimation Approach to Limit the Effects of False Data\n  Injection Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reliable operation of the electric power systems is supported by energy\nmanagement systems (EMS) that provide monitoring and control functionalities.\nContingency analysis is a critical application of EMS to evaluate the impacts\nof outage events based on the grid state variables, and allow system operators\nto prepare for potential system failures. However, false data injection attacks\n(FDIAs) against state estimation have demonstrated the possibility of\ncompromising sensor measurements and consequently falsifying the estimated\npower system states. As a result, FDIAs may mislead the system operations and\nother EMS applications including contingency analysis and optimal power flow\nroutines. In this paper, we assess the effect of FDIAs on contingency analysis\nand demonstrate that such attacks can affect the resulted number of\ncontingencies in power systems. In order to mitigate the FDIA impact on\ncontingency analysis algorithms, we propose CHIMERA, a hybrid attack-resilient\nstate estimation approach that integrates model-based and data-driven methods.\nCHIMERA combines the physical grid information with a Long Short Term Memory\n(LSTM)-based deep learning model by considering a static loss of weighted least\nsquare errors and a dynamic loss of the difference between the temporal\nvariations of the actual and the estimated active power. Our simulation\nexperiments based on the load data from New York state demonstrate that CHIMERA\ncan effectively mitigate 91.74% of the attack cases in which FDIAs can\nmaliciously modify the contingency results.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 02:28:02 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Liu", "Xiaorui", ""], ["Hu", "Yaodan", ""], ["Konstantinou", "Charalambos", ""], ["Jin", "Yier", ""]]}, {"id": "2103.13598", "submitter": "Yiwen Guo", "authors": "Yiwen Guo, Changshui Zhang", "title": "Recent Advances in Large Margin Learning", "comments": "Accepted by TPAMI, 8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper serves as a survey of recent advances in large margin training and\nits theoretical foundations, mostly for (nonlinear) deep neural networks (DNNs)\nthat are probably the most prominent machine learning models for large-scale\ndata in the community over the past decade. We generalize the formulation of\nclassification margins from classical research to latest DNNs, summarize\ntheoretical connections between the margin, network generalization, and\nrobustness, and introduce recent efforts in enlarging the margins for DNNs\ncomprehensively. Since the viewpoint of different methods is discrepant, we\ncategorize them into groups for ease of comparison and discussion in the paper.\nHopefully, our discussions and overview inspire new research work in the\ncommunity that aim to improve the performance of DNNs, and we also point to\ndirections where the large margin principle can be verified to provide\ntheoretical evidence why certain regularizations for DNNs function well in\npractice. We managed to shorten the paper such that the crucial spirit of large\nmargin learning and related methods are better emphasized.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 04:12:00 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 05:41:45 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Guo", "Yiwen", ""], ["Zhang", "Changshui", ""]]}, {"id": "2103.13628", "submitter": "Peizhuo Lv", "authors": "Peizhuo Lv, Pan Li, Shengzhi Zhang, Kai Chen, Ruigang Liang, Yue Zhao,\n  Yingjiu Li", "title": "HufuNet: Embedding the Left Piece as Watermark and Keeping the Right\n  Piece for Ownership Verification in Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the wide use of highly-valuable and large-scale deep neural networks\n(DNNs), it becomes crucial to protect the intellectual property of DNNs so that\nthe ownership of disputed or stolen DNNs can be verified. Most existing\nsolutions embed backdoors in DNN model training such that DNN ownership can be\nverified by triggering distinguishable model behaviors with a set of secret\ninputs. However, such solutions are vulnerable to model fine-tuning and\npruning. They also suffer from fraudulent ownership claim as attackers can\ndiscover adversarial samples and use them as secret inputs to trigger\ndistinguishable behaviors from stolen models. To address these problems, we\npropose a novel DNN watermarking solution, named HufuNet, for protecting the\nownership of DNN models. We evaluate HufuNet rigorously on four benchmark\ndatasets with five popular DNN models, including convolutional neural network\n(CNN) and recurrent neural network (RNN). The experiments demonstrate HufuNet\nis highly robust against model fine-tuning/pruning, kernels cutoff/supplement,\nfunctionality-equivalent attack, and fraudulent ownership claims, thus highly\npromising to protect large-scale DNN models in the real-world.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 06:55:22 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Lv", "Peizhuo", ""], ["Li", "Pan", ""], ["Zhang", "Shengzhi", ""], ["Chen", "Kai", ""], ["Liang", "Ruigang", ""], ["Zhao", "Yue", ""], ["Li", "Yingjiu", ""]]}, {"id": "2103.13667", "submitter": "Maximilian Algehed", "authors": "Maximilian Algehed and Cormac Flanagan", "title": "Multi-Execution Lattices Fast and Slow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for automatically, soundly, and precisely guaranteeing the\nnoninterference security policy are predominantly based on multi-execution. All\nother methods are either based on undecidable theorem proving or suffer from\nfalse alarms. The multi-execution mechanisms, meanwhile, work by isolating\nsecurity levels during program execution and running multiple copies of the\ntarget program, once for each security level with carefully tailored inputs\nthat ensure both soundness and precision. When security levels are\nhierarchically organised in a lattice, this may lead to an exponential number\nof executions of the target program as the number of possible ways of combining\nsecurity levels grows. In this paper we study how the lattice structure for\nsecurity levels influences the runtime overhead of multi-execution. We\nadditionally show how to use Galois connections to gain speedups in\nmulti-execution by switching from lattices with high overhead to lattices with\nlow overhead. Additionally, we give an empirical evaluation that corroborates\nour analysis and shows how Galois connections have potential to speed up\nmulti-execution.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 08:35:56 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Algehed", "Maximilian", ""], ["Flanagan", "Cormac", ""]]}, {"id": "2103.13754", "submitter": "Alberto Garoffolo", "authors": "Alberto Garoffolo, Dmytro Kaidalov, Roman Oliynykov", "title": "Latus Incentive Scheme: Enabling Decentralization in Blockchains based\n  on Recursive SNARKs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Zendoo whitepaper we introduced a novel SNARK-based construction that\nallows Bitcoin-like blockchains to create and communicate with sidechains of\ndifferent types without knowing their internal structure. We also introduced a\nspecific construction, called Latus, allowing creation of fully verifiable\nsidechains. In the paper we omitted a detailed description of an incentive\nscheme for Latus that is an essential element of a real decentralized system.\nThis paper fills the gap by introducing details of the incentive scheme for the\nLatus sidechain. The represented ideas can also be adopted by other SNARK-based\nblockchains to incentivize decentralized proofs creation.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 11:08:54 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Garoffolo", "Alberto", ""], ["Kaidalov", "Dmytro", ""], ["Oliynykov", "Roman", ""]]}, {"id": "2103.13809", "submitter": "Ying Lan", "authors": "Ying Lan, Jianbo Gao, Ke Wang, Jiashuo Zhang, Zhenhao Wu, Yuesheng\n  Zhu, Zhong Chen", "title": "TrustCross: Enabling Confidential Interoperability across Blockchains\n  Using Trusted Hardware", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the rapid development of blockchain technology, different types of\nblockchains are adopted and interoperability across blockchains has received\nwidespread attention. There have been many cross-chain solutions proposed in\nrecent years, including notary scheme, sidechain, and relay chain. However,\nmost of the existing platforms do not take confidentiality into account,\nalthough privacy has become an important concern for blockchain. In this paper,\nwe present TrustCross, a privacy-preserving cross-chain platform to enable\nconfidential interoperability across blockchains. The key insight behind\nTrustCross is to encrypt cross-chain communication data on the relay chain with\nthe assistance of trusted execution environment and employ fine-grained access\ncontrol to protect user privacy. Our experimental results show that TrustCross\nachieves reasonable latency and high scalability on the contract calls across\nheterogeneous blockchains.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 07:56:44 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Lan", "Ying", ""], ["Gao", "Jianbo", ""], ["Wang", "Ke", ""], ["Zhang", "Jiashuo", ""], ["Wu", "Zhenhao", ""], ["Zhu", "Yuesheng", ""], ["Chen", "Zhong", ""]]}, {"id": "2103.13813", "submitter": "Adnan Siraj Rakin", "authors": "Adnan Siraj Rakin, Li Yang, Jingtao Li, Fan Yao, Chaitali Chakrabarti,\n  Yu Cao, Jae-sun Seo, and Deliang Fan", "title": "RA-BNN: Constructing Robust & Accurate Binary Neural Network to\n  Simultaneously Defend Adversarial Bit-Flip Attack and Improve Accuracy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently developed adversarial weight attack, a.k.a. bit-flip attack (BFA),\nhas shown enormous success in compromising Deep Neural Network (DNN)\nperformance with an extremely small amount of model parameter perturbation. To\ndefend against this threat, we propose RA-BNN that adopts a complete binary\n(i.e., for both weights and activation) neural network (BNN) to significantly\nimprove DNN model robustness (defined as the number of bit-flips required to\ndegrade the accuracy to as low as a random guess). However, such an aggressive\nlow bit-width model suffers from poor clean (i.e., no attack) inference\naccuracy. To counter this, we propose a novel and efficient two-stage network\ngrowing method, named Early-Growth. It selectively grows the channel size of\neach BNN layer based on channel-wise binary masks training with Gumbel-Sigmoid\nfunction. Apart from recovering the inference accuracy, our RA-BNN after\ngrowing also shows significantly higher resistance to BFA. Our evaluation of\nthe CIFAR-10 dataset shows that the proposed RA-BNN can improve the clean model\naccuracy by ~2-8 %, compared with a baseline BNN, while simultaneously\nimproving the resistance to BFA by more than 125 x. Moreover, on ImageNet, with\na sufficiently large (e.g., 5,000) amount of bit-flips, the baseline BNN\naccuracy drops to 4.3 % from 51.9 %, while our RA-BNN accuracy only drops to\n37.1 % from 60.9 % (9 % clean accuracy improvement).\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2021 20:50:30 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Rakin", "Adnan Siraj", ""], ["Yang", "Li", ""], ["Li", "Jingtao", ""], ["Yao", "Fan", ""], ["Chakrabarti", "Chaitali", ""], ["Cao", "Yu", ""], ["Seo", "Jae-sun", ""], ["Fan", "Deliang", ""]]}, {"id": "2103.13820", "submitter": "Mark Stamp", "authors": "Mugdha Jain and William Andreopoulos and Mark Stamp", "title": "CNN vs ELM for Image-Based Malware Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research in the field of malware classification often relies on machine\nlearning models that are trained on high-level features, such as opcodes,\nfunction calls, and control flow graphs. Extracting such features is costly,\nsince disassembly or code execution is generally required. In this paper, we\nconduct experiments to train and evaluate machine learning models for malware\nclassification, based on features that can be obtained without disassembly or\nexecution of code. Specifically, we visualize malware samples as images and\nemploy image analysis techniques. In this context, we focus on two machine\nlearning models, namely, Convolutional Neural Networks (CNN) and Extreme\nLearning Machines (ELM). Surprisingly, we find that ELMs can achieve accuracies\non par with CNNs, yet ELM training requires less than~2\\%\\ of the time needed\nto train a comparable CNN.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2021 00:51:06 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Jain", "Mugdha", ""], ["Andreopoulos", "William", ""], ["Stamp", "Mark", ""]]}, {"id": "2103.13827", "submitter": "Pratikkumar Prajapati", "authors": "Pratikkumar Prajapati and Mark Stamp", "title": "An Empirical Analysis of Image-Based Learning Techniques for Malware\n  Classification", "comments": "20 pages, 8 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we consider malware classification using deep learning\ntechniques and image-based features. We employ a wide variety of deep learning\ntechniques, including multilayer perceptrons (MLP), convolutional neural\nnetworks (CNN), long short-term memory (LSTM), and gated recurrent units (GRU).\nAmongst our CNN experiments, transfer learning plays a prominent role\nspecifically, we test the VGG-19 and ResNet152 models. As compared to previous\nwork, the results presented in this paper are based on a larger and more\ndiverse malware dataset, we consider a wider array of features, and we\nexperiment with a much greater variety of learning techniques. Consequently,\nour results are the most comprehensive and complete that have yet been\npublished.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2021 16:10:05 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Prajapati", "Pratikkumar", ""], ["Stamp", "Mark", ""]]}, {"id": "2103.13832", "submitter": "Stefan Hristozov", "authors": "Stefan Hristozov, Manuel Huber, Lei Xu, Jaro Fietz, Marco Liess, Georg\n  Sigl", "title": "The Cost of OSCORE and EDHOC for Constrained Devices", "comments": "A short version of this paper will appear on CODASPY 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern IoT applications rely on the Constrained Application Protocol\n(CoAP) because of its efficiency and seamless integrability in the existing\nInternet infrastructure. One of the strategies that CoAP leverages to achieve\nthese characteristics is the usage of proxies. Unfortunately, in order for a\nproxy to operate, it needs to terminate the (D)TLS channels between clients and\nservers. Therefore, end-to-end confidentiality, integrity and authenticity of\nthe exchanged data cannot be achieved. In order to overcome this problem, an\nalternative to (D)TLS was recently proposed by the Internet Engineering Task\nForce (IETF). This alternative consists of two novel protocols: 1) Object\nSecurity for Constrained RESTful Environments (OSCORE) providing authenticated\nencryption for the payload data and 2) Ephemeral Diffie-Hellman Over COSE\n(EDHOC) providing the symmetric session keys required for OSCORE. In this\npaper, we present the design of four firmware libraries for these protocols\nespecially targeted for constrained microcontrollers and their detailed\nevaluation. More precisely, we present the design of uOSCORE and uEDHOC\nlibraries for regular microcontrollers and uOSCORE-TEE and uEDHOC-TEE libraries\nfor microcontrollers with a Trusted Execution Environment (TEE), such as\nmicrocontrollers featuring ARM TrustZone-M. Our firmware design for the later\nclass of devices concerns the fact that attackers may exploit common software\nvulnerabilities, e.g., buffer overflows in the protocol logic, OS or\napplication to compromise the protocol security. uOSCORE-TEE and uEDHOC-TEE\nachieve separation of the cryptographic operations and keys from the remainder\nof the firmware, which could be vulnerable. We present an evaluation of our\nimplementations in terms of RAM/FLASH requirements, execution speed and energy\non a broad range of microcontrollers.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 13:21:43 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Hristozov", "Stefan", ""], ["Huber", "Manuel", ""], ["Xu", "Lei", ""], ["Fietz", "Jaro", ""], ["Liess", "Marco", ""], ["Sigl", "Georg", ""]]}, {"id": "2103.13902", "submitter": "Ahmet Okutan Ph.D.", "authors": "Shanchieh Jay Yang, Ahmet Okutan, Gordon Werner, Shao-Hsuan Su, Ayush\n  Goel, Nathan D. Cahill", "title": "Near Real-time Learning and Extraction of Attack Models from Intrusion\n  Alerts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Critical and sophisticated cyberattacks often take multitudes of\nreconnaissance, exploitations, and obfuscation techniques to penetrate through\nwell protected enterprise networks. The discovery and detection of attacks,\nthough needing continuous efforts, is no longer sufficient. Security Operation\nCenter (SOC) analysts are overwhelmed by the significant volume of intrusion\nalerts without being able to extract actionable intelligence. Recognizing this\nchallenge, this paper describes the advances and findings through deploying\nASSERT to process intrusion alerts from OmniSOC in collaboration with the\nCenter for Applied Cybersecurity Research (CACR) at Indiana University. ASSERT\nutilizes information theoretic unsupervised learning to extract and update\n`attack models' in near real-time without expert knowledge. It consumes\nstreaming intrusion alerts and generates a small number of statistical models\nfor SOC analysts to comprehend ongoing and emerging attacks in a timely manner.\nThis paper presents the architecture and key processes of ASSERT and discusses\na few real-world attack models to highlight the use-cases that benefit SOC\noperations. The research team is developing a light-weight containerized ASSERT\nthat will be shared through a public repository to help the community combat\nthe overwhelming intrusion alerts.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 15:12:03 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Yang", "Shanchieh Jay", ""], ["Okutan", "Ahmet", ""], ["Werner", "Gordon", ""], ["Su", "Shao-Hsuan", ""], ["Goel", "Ayush", ""], ["Cahill", "Nathan D.", ""]]}, {"id": "2103.13937", "submitter": "Miroslav Dimitrov", "authors": "Miroslav Dimitrov, Bernhard Esslinger", "title": "CUDA Tutorial -- Cryptanalysis of Classical Ciphers Using Modern GPUs\n  and CUDA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  CUDA (formerly an abbreviation of Compute Unified Device Architecture) is a\nparallel computing platform and API model created by Nvidia allowing software\ndevelopers to use a CUDA-enabled graphics processing unit (GPU) for general\npurpose processing. This 90-pages tutorial introduces the CUDA concepts in an\neasy-to-grasp and interactive way with ready-to-run code samples tested on\nWindows and Linux. Starting from scratch, a complete stand-alone GPU tool is\nimplemented which automatically performs a ciphertext-only attack on\nciphertexts encrypted by monoalphabetic substitution and columnar\ntransposition. Throughout this process, you will learn how to architect the\ntool, what optimizations could significantly accelerate the routines, why the\nchoice of an adequate metaheuristic is critical, and how to draw sketches to\nenlighten the design process. This tutorial will be incorporated in the\nCrypTool book as chapter 13.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 15:58:00 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 17:43:33 GMT"}, {"version": "v3", "created": "Fri, 2 Apr 2021 17:06:15 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Dimitrov", "Miroslav", ""], ["Esslinger", "Bernhard", ""]]}, {"id": "2103.13994", "submitter": "Mina Doosti", "authors": "Mina Doosti, Mahshid Delavar, Elham Kashefi, and Myrto Arapinis", "title": "A Unified Framework For Quantum Unforgeability", "comments": "47 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we continue the line of work initiated by Boneh and Zhandry at\nCRYPTO 2013 and EUROCRYPT 2013 in which they formally define the notion of\nunforgeability against quantum adversaries specifically, for classical message\nauthentication codes and classical digital signatures schemes. We develop a\ngeneral and parameterised quantum game-based security model unifying\nunforgeability for both classical and quantum constructions allowing us for the\nfirst time to present a complete quantum cryptanalysis framework for\nunforgeability. In particular, we prove how our definitions subsume previous\nones while considering more fine-grained adversarial models, capturing the full\nspectrum of superposition attacks. The subtlety here resides in the\ncharacterisation of a forgery. We show that the strongest level of\nunforgeability, namely existential unforgeability, can only be achieved if only\northogonal to previously queried messages are considered to be forgeries. In\nparticular, we present a non-trivial attack if any overlap between the forged\nmessage and previously queried ones is allowed. We further show that\ndeterministic constructions can only achieve the weaker notion of\nunforgeability, that is selective unforgeability, against such restricted\nadversaries, but that selective unforgeability breaks if general quantum\nadversaries (capable of general superposition attacks) are considered. On the\nother hand, we show that PRF is sufficient for constructing a selective\nunforgeable classical primitive against full quantum adversaries. Moreover, we\nshow similar positive results relying on Pseudorandom Unitaries (PRU) for\nquantum primitives. These results demonstrate the generality of our framework\nthat could be applicable to other primitives beyond the cases analysed in this\npaper.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 17:31:59 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Doosti", "Mina", ""], ["Delavar", "Mahshid", ""], ["Kashefi", "Elham", ""], ["Arapinis", "Myrto", ""]]}, {"id": "2103.14035", "submitter": "Mayana Pereira", "authors": "Mayana Pereira, Allen Kim, Joshua Allen, Kevin White, Juan Lavista\n  Ferres and Rahul Dodhia", "title": "U.S. Broadband Coverage Data Set: A Differentially Private Data Release", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Broadband connectivity is a key metric in today's economy. In an era of rapid\nexpansion of the digital economy, it directly impacts GDP. Furthermore, with\nthe COVID-19 guidelines of social distancing, internet connectivity became\nnecessary to everyday activities such as work, learning, and staying in touch\nwith family and friends. This paper introduces a publicly available U.S.\nBroadband Coverage data set that reports broadband coverage percentages at a\nzip code-level. We also explain how we used differential privacy to guarantee\nthat the privacy of individual households is preserved. Our data set also\ncontains error ranges estimates, providing information on the expected error\nintroduced by differential privacy per zip code. We describe our error range\ncalculation method and show that this additional data metric does not induce\nany privacy losses.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2021 21:32:04 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 17:46:26 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Pereira", "Mayana", ""], ["Kim", "Allen", ""], ["Allen", "Joshua", ""], ["White", "Kevin", ""], ["Ferres", "Juan Lavista", ""], ["Dodhia", "Rahul", ""]]}, {"id": "2103.14036", "submitter": "David Smith", "authors": "David Smith, Frederik Geth, Elliott Vercoe, Andrew Feutrill, Ming\n  Ding, Jonathan Chan, James Foster and Thierry Rakotoarivelo", "title": "Realistic Differentially-Private Transmission Power Flow Data Release", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the modeling, design and planning of future energy transmission networks,\nit is vital for stakeholders to access faithful and useful power flow data,\nwhile provably maintaining the privacy of business confidentiality of service\nproviders. This critical challenge has recently been somewhat addressed in [1].\nThis paper significantly extends this existing work. First, we reduce the\npotential leakage information by proposing a fundamentally different\npost-processing method, using public information of grid losses rather than\npower dispatch, which achieve a higher level of privacy protection. Second, we\nprotect more sensitive parameters, i.e., branch shunt susceptance in addition\nto series impedance (complete pi-model). This protects power flow data for the\ntransmission high-voltage networks, using differentially private\ntransformations that maintain the optimal power flow consistent with, and\nfaithful to, expected model behaviour. Third, we tested our approach at a\nlarger scale than previous work, using the PGLib-OPF test cases [10]. This\nresulted in the successful obfuscation of up to a 4700-bus system, which can be\nsuccessfully solved with faithfulness of parameters and good utility to data\nanalysts. Our approach addresses a more feasible and realistic scenario, and\nprovides higher than state-of-the-art privacy guarantees, while maintaining\nsolvability, fidelity and feasibility of the system.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 04:04:12 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Smith", "David", ""], ["Geth", "Frederik", ""], ["Vercoe", "Elliott", ""], ["Feutrill", "Andrew", ""], ["Ding", "Ming", ""], ["Chan", "Jonathan", ""], ["Foster", "James", ""], ["Rakotoarivelo", "Thierry", ""]]}, {"id": "2103.14056", "submitter": "Ali Pourranjbar", "authors": "Ali Pourranjbar, Georges Kaddoum, Aidin Ferdowsi, and Walid Saad", "title": "Reinforcement Learning for Deceiving Reactive Jammers in Wireless\n  Networks", "comments": "in IEEE Transactions on Communications", "journal-ref": null, "doi": "10.1109/TCOMM.2021.3062854", "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional anti-jamming method mostly rely on frequency hopping to hide or\nescape from jammer. These approaches are not efficient in terms of bandwidth\nusage and can also result in a high probability of jamming. Different from\nexisting works, in this paper, a novel anti-jamming strategy is proposed based\non the idea of deceiving the jammer into attacking a victim channel while\nmaintaining the communications of legitimate users in safe channels. Since the\njammer's channel information is not known to the users, an optimal channel\nselection scheme and a sub optimal power allocation are proposed using\nreinforcement learning (RL). The performance of the proposed anti-jamming\ntechnique is evaluated by deriving the statistical lower bound of the total\nreceived power (TRP). Analytical results show that, for a given access point,\nover 50 % of the highest achievable TRP, i.e. in the absence of jammers, is\nachieved for the case of a single user and three frequency channels. Moreover,\nthis value increases with the number of users and available channels. The\nobtained results are compared with two existing RL based anti-jamming\ntechniques, and random channel allocation strategy without any jamming attacks.\nSimulation results show that the proposed anti-jamming method outperforms the\ncompared RL based anti-jamming methods and random search method, and yields\nnear optimal achievable TRP.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 18:12:41 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Pourranjbar", "Ali", ""], ["Kaddoum", "Georges", ""], ["Ferdowsi", "Aidin", ""], ["Saad", "Walid", ""]]}, {"id": "2103.14068", "submitter": "Rachel Cummings", "authors": "Chris Waites and Rachel Cummings", "title": "Differentially Private Normalizing Flows for Privacy-Preserving Density\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flow models have risen as a popular solution to the problem of\ndensity estimation, enabling high-quality synthetic data generation as well as\nexact probability density evaluation. However, in contexts where individuals\nare directly associated with the training data, releasing such a model raises\nprivacy concerns. In this work, we propose the use of normalizing flow models\nthat provide explicit differential privacy guarantees as a novel approach to\nthe problem of privacy-preserving density estimation. We evaluate the efficacy\nof our approach empirically using benchmark datasets, and we demonstrate that\nour method substantially outperforms previous state-of-the-art approaches. We\nadditionally show how our algorithm can be applied to the task of\ndifferentially private anomaly detection.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 18:39:51 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Waites", "Chris", ""], ["Cummings", "Rachel", ""]]}, {"id": "2103.14122", "submitter": "Alexander Block", "authors": "Alexander R. Block (Purdue University) and Jeremiah Blocki (Purdue\n  University)", "title": "Private and Resource-Bounded Locally Decodable Codes for Insertions and\n  Deletions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct locally decodable codes (LDCs) to correct insertion-deletion\nerrors in the setting where the sender and receiver share a secret key or where\nthe channel is resource-bounded. Our constructions rely on a so-called\n\"Hamming-to-InsDel\" compiler (Ostrovsky and Paskin-Cherniavsky, ITS '15 & Block\net al., FSTTCS '20), which compiles any locally decodable Hamming code into a\nlocally decodable code resilient to insertion-deletion (InsDel) errors. While\nthe compilers were designed for the classical coding setting, we show that the\ncompilers still work in a secret key or resource-bounded setting. Applying our\nresults to the private key Hamming LDC of Ostrovsky, Pandey, and Sahai (ICALP\n'07), we obtain a private key InsDel LDC with constant rate and polylogarithmic\nlocality. Applying our results to the construction of Blocki, Kulkarni, and\nZhou (ITC '20), we obtain similar results for resource-bounded channels; i.e.,\na channel where computation is constrained by resources such as space or time.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 20:29:40 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 00:45:52 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 18:32:23 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Block", "Alexander R.", "", "Purdue University"], ["Blocki", "Jeremiah", "", "Purdue\n  University"]]}, {"id": "2103.14144", "submitter": "Matheus Venturyne Xavier Ferreira", "authors": "Matheus V. X. Ferreira and Daniel J. Moroz and David C. Parkes and\n  Mitchell Stern", "title": "Dynamic Posted-Price Mechanisms for the Blockchain Transaction-Fee\n  Market", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR econ.TH math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, prominent blockchain systems such as Bitcoin and Ethereum\nhave experienced explosive growth in transaction volume, leading to frequent\nsurges in demand for limited block space, causing transaction fees to fluctuate\nby orders of magnitude. Under the standard first-price auction approach, users\nfind it difficult to estimate how much they need to bid to get their\ntransactions accepted (balancing the risk of delay with a preference to avoid\npaying more than is necessary).\n  In light of these issues, new transaction fee mechanisms have been proposed,\nmost notably EIP-1559. A problem with EIP-1559 is that under market\ninstability, it again reduces to a first-price auction. Here, we propose\ndynamic posted-price mechanisms, which are ex post Nash incentive compatible\nfor myopic bidders and dominant strategy incentive compatible for myopic\nminers. We give sufficient conditions for which our mechanisms are stable and\napproximately welfare optimal in the probabilistic setting where each time\nstep, bidders are drawn i.i.d. from a static (but unknown) distribution. Under\nthis setting, we show instances where our dynamic mechanisms are stable, but\nEIP-1559 is unstable. Our main technical contribution is an iterative algorithm\nthat, given oracle access to a Lipschitz continuous and concave function $f$,\nconverges to a fixed point of $f$.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 21:41:13 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Ferreira", "Matheus V. X.", ""], ["Moroz", "Daniel J.", ""], ["Parkes", "David C.", ""], ["Stern", "Mitchell", ""]]}, {"id": "2103.14154", "submitter": "Sohini Roy", "authors": "Sohini Roy, Arunabha Sen", "title": "Identification and Mitigation of False Data Injection using Multi State\n  Implicative Interdependency Model (MSIIM) for Smart Grid", "comments": "6 pages, Accepted for publication in The IEEE International workshop\n  on Communication, Computing, and Networking in Cyber Physical Systems (CCNCPS\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart grid monitoring, automation and control will completely rely on PMU\nbased sensor data soon. Accordingly, a high throughput, low latency Information\nand Communication Technology (ICT) infrastructure should be opted in this\nregard. Due to the low cost, low power profile, dynamic nature, improved\naccuracy and scalability, wireless sensor networks (WSNs) can be a good choice.\nYet, the efficiency of a WSN depends a lot on the network design and the\nrouting technique. In this paper a new design of the ICT network for smart grid\nusing WSN is proposed. In order to understand the interactions between\ndifferent entities, detect their operational levels, design the routing scheme\nand identify false data injection by particular ICT entities, a new model of\ninterdependency called the Multi State Implicative Interdependency Model\n(MSIIM) is proposed in this paper, which is an updated version of the Modified\nImplicative Interdependency Model (MIIM) [1]. MSIIM considers the data\ndependency and operational accuracy of entities together with structural and\nfunctional dependencies between them. A multi-path secure routing technique is\nalso proposed in this paper which relies on the MSIIM model for its\nfunctioning. Simulation results prove that MSIIM based False Data Injection\n(FDI) detection and mitigation works better and faster than existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 22:11:45 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 18:45:11 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Roy", "Sohini", ""], ["Sen", "Arunabha", ""]]}, {"id": "2103.14155", "submitter": "Sanchari Das", "authors": "Callie Monroe, Faiza Tazi, and Sanchari Das", "title": "Location Data and COVID-19 Contact Tracing: How Data Privacy Regulations\n  and Cell Service Providers Work In Tandem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Governments, Healthcare, and Private Organizations in the global scale have\nbeen using digital tracking to keep COVID-19 outbreaks under control. Although\nthis method could limit pandemic contagion, it raises significant concerns\nabout user privacy. Known as ~\"Contact Tracing Apps\", these mobile applications\nare facilitated by Cellphone Service Providers (CSPs), who enable the spatial\nand temporal real-time user tracking. Accordingly, it might be speculated that\nCSPs collect information violating the privacy policies such as GDPR, CCPA, and\nothers. To further clarify, we conducted an in-depth analysis comparing privacy\nlegislations with the real-world practices adapted by CSPs. We found that three\nof the regulations (GDPR, COPPA, and CCPA) analyzed defined mobile location\ndata as private information, and two (T-Mobile US, Boost Mobile) of the five\nCSPs that were analyzed did not comply with the COPPA regulation. Our results\nare crucial in view of the threat these violations represent, especially when\nit comes to children's data. As such proper security and privacy auditing is\nnecessary to curtail such violations. We conclude by providing actionable\nrecommendations to address concerns and provide privacy-preserving monitoring\nof the COVID-19 spread through the contact tracing applications.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 22:13:50 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 17:57:51 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Monroe", "Callie", ""], ["Tazi", "Faiza", ""], ["Das", "Sanchari", ""]]}, {"id": "2103.14217", "submitter": "Afsah Anwar", "authors": "Afsah Anwar, Jinchun Choi, Abdulrahman Alabduljabbar, Hisham Alasmary,\n  Jeffrey Spaulding, An Wang, Songqing Chen, DaeHun Nyang, Amro Awad, and David\n  Mohaisen", "title": "Understanding Internet of Things Malware by Analyzing Endpoints in their\n  Static Artifacts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The lack of security measures among the Internet of Things (IoT) devices and\ntheir persistent online connection gives adversaries a prime opportunity to\ntarget them or even abuse them as intermediary targets in larger attacks such\nas distributed denial-of-service (DDoS) campaigns. In this paper, we analyze\nIoT malware and focus on the endpoints reachable on the public Internet, that\nplay an essential part in the IoT malware ecosystem. Namely, we analyze\nendpoints acting as dropzones and their targets to gain insights into the\nunderlying dynamics in this ecosystem, such as the affinity between the\ndropzones and their target IP addresses, and the different patterns among\nendpoints. Towards this goal, we reverse-engineer 2,423 IoT malware samples and\nextract strings from them to obtain IP addresses. We further gather information\nabout these endpoints from public Internet-wide scanners, such as Shodan and\nCensys. For the masked IP addresses, we examine the Classless Inter-Domain\nRouting (CIDR) networks accumulating to more than 100 million (78.2% of total\nactive public IPv4 addresses) endpoints. Our investigation from four different\nperspectives provides profound insights into the role of endpoints in IoT\nmalware attacks, which deepens our understanding of IoT malware ecosystems and\ncan assist future defenses.\n", "versions": [{"version": "v1", "created": "Fri, 26 Mar 2021 02:14:40 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Anwar", "Afsah", ""], ["Choi", "Jinchun", ""], ["Alabduljabbar", "Abdulrahman", ""], ["Alasmary", "Hisham", ""], ["Spaulding", "Jeffrey", ""], ["Wang", "An", ""], ["Chen", "Songqing", ""], ["Nyang", "DaeHun", ""], ["Awad", "Amro", ""], ["Mohaisen", "David", ""]]}, {"id": "2103.14221", "submitter": "Afsah Anwar", "authors": "Hisham Alasmary, Afsah Anwar, Ahmed Abusnaina, Abdulrahman\n  Alabduljabbar, Mohammad Abuhamad, An Wang, DaeHun Nyang, Amro Awad, David\n  Mohaisen", "title": "ShellCore: Automating Malicious IoT Software Detection by Using Shell\n  Commands Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The Linux shell is a command-line interpreter that provides users with a\ncommand interface to the operating system, allowing them to perform a variety\nof functions. Although very useful in building capabilities at the edge, the\nLinux shell can be exploited, giving adversaries a prime opportunity to use\nthem for malicious activities. With access to IoT devices, malware authors can\nabuse the Linux shell of those devices to propagate infections and launch\nlarge-scale attacks, e.g., DDoS. In this work, we provide a first look at shell\ncommands used in Linux-based IoT malware towards detection. We analyze\nmalicious shell commands found in IoT malware and build a neural network-based\nmodel, ShellCore, to detect malicious shell commands. Namely, we collected a\nlarge dataset of shell commands, including malicious commands extracted from\n2,891 IoT malware samples and benign commands collected from real-world network\ntraffic analysis and volunteered data from Linux users. Using conventional\nmachine and deep learning-based approaches trained with term- and\ncharacter-level features, ShellCore is shown to achieve an accuracy of more\nthan 99% in detecting malicious shell commands and files (i.e., binaries).\n", "versions": [{"version": "v1", "created": "Fri, 26 Mar 2021 02:20:03 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Alasmary", "Hisham", ""], ["Anwar", "Afsah", ""], ["Abusnaina", "Ahmed", ""], ["Alabduljabbar", "Abdulrahman", ""], ["Abuhamad", "Mohammad", ""], ["Wang", "An", ""], ["Nyang", "DaeHun", ""], ["Awad", "Amro", ""], ["Mohaisen", "David", ""]]}, {"id": "2103.14222", "submitter": "Chengzhi Mao", "authors": "Chengzhi Mao, Mia Chiquier, Hao Wang, Junfeng Yang, Carl Vondrick", "title": "Adversarial Attacks are Reversible with Natural Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We find that images contain intrinsic structure that enables the reversal of\nmany adversarial attacks. Attack vectors cause not only image classifiers to\nfail, but also collaterally disrupt incidental structure in the image. We\ndemonstrate that modifying the attacked image to restore the natural structure\nwill reverse many types of attacks, providing a defense. Experiments\ndemonstrate significantly improved robustness for several state-of-the-art\nmodels across the CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets. Our results\nshow that our defense is still effective even if the attacker is aware of the\ndefense mechanism. Since our defense is deployed during inference instead of\ntraining, it is compatible with pre-trained networks as well as most other\ndefenses. Our results suggest deep networks are vulnerable to adversarial\nexamples partly because their representations do not enforce the natural\nstructure of images.\n", "versions": [{"version": "v1", "created": "Fri, 26 Mar 2021 02:21:40 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 02:34:39 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Mao", "Chengzhi", ""], ["Chiquier", "Mia", ""], ["Wang", "Hao", ""], ["Yang", "Junfeng", ""], ["Vondrick", "Carl", ""]]}, {"id": "2103.14244", "submitter": "Xiaoxuan Lou", "authors": "Xiaoxuan Lou, Tianwei Zhang, Jun Jiang, Yinqian Zhang", "title": "A Survey of Microarchitectural Side-channel Vulnerabilities, Attacks and\n  Defenses in Cryptography", "comments": "In processings of the ACM Computing Surveys. arXiv admin note:\n  substantial text overlap with arXiv:1911.09312", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Side-channel attacks have become a severe threat to the confidentiality of\ncomputer applications and systems. One popular type of such attacks is the\nmicroarchitectural attack, where the adversary exploits the hardware features\nto break the protection enforced by the operating system and steal the secrets\nfrom the program. In this paper, we systematize microarchitectural side\nchannels with a focus on attacks and defenses in cryptographic applications. We\nmake three contributions. (1) We survey past research literature to categorize\nmicroarchitectural side-channel attacks. Since these are hardware attacks\ntargeting software, we summarize the vulnerable implementations in software, as\nwell as flawed designs in hardware. (2) We identify common strategies to\nmitigate microarchitectural attacks, from the application, OS and hardware\nlevels. (3) We conduct a large-scale evaluation on popular cryptographic\napplications in the real world, and analyze the severity, practicality and\nimpact of side-channel vulnerabilities. This survey is expected to inspire\nside-channel research community to discover new attacks, and more importantly,\npropose new defense solutions against them.\n", "versions": [{"version": "v1", "created": "Fri, 26 Mar 2021 03:30:29 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Lou", "Xiaoxuan", ""], ["Zhang", "Tianwei", ""], ["Jiang", "Jun", ""], ["Zhang", "Yinqian", ""]]}, {"id": "2103.14414", "submitter": "Benedikt Putz", "authors": "Benedikt Putz, Fabian B\\\"ohm and G\\\"unther Pernul", "title": "HyperSec: Visual Analytics for blockchain security monitoring", "comments": "Accepted at the IFIP TC 11 36th International Information Security\n  Conference (SEC 2021), June 22-24 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Today, permissioned blockchains are being adopted by large organizations for\nbusiness critical operations. Consequently, they are subject to attacks by\nmalicious actors. Researchers have discovered and enumerated a number of\nattacks that could threaten availability, integrity and confidentiality of\nblockchain data. However, currently it remains difficult to detect these\nattacks. We argue that security experts need appropriate visualizations to\nassist them in detecting attacks on blockchain networks. To achieve this, we\ndevelop HyperSec, a visual analytics monitoring tool that provides relevant\ninformation at a glance to detect ongoing attacks on Hyperledger Fabric. For\nevaluation, we connect the HyperSec prototype to a Hyperledger Fabric test\nnetwork. The results show that common attacks on Fabric can be detected by a\nsecurity expert using HyperSec's visualizations.\n", "versions": [{"version": "v1", "created": "Fri, 26 Mar 2021 11:51:55 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Putz", "Benedikt", ""], ["B\u00f6hm", "Fabian", ""], ["Pernul", "G\u00fcnther", ""]]}, {"id": "2103.14510", "submitter": "Christian Majenz", "authors": "Christian Majenz, Christian Schaffner and Mehrdad Tahmasbi", "title": "Limitations on Uncloneable Encryption and Simultaneous One-Way-to-Hiding", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study uncloneable quantum encryption schemes for classical messages as\nrecently proposed by Broadbent and Lord. We focus on the information-theoretic\nsetting and give several limitations on the structure and security of these\nschemes: Concretely, 1) We give an explicit cloning-indistinguishable attack\nthat succeeds with probability $\\frac12 + \\mu/16$ where $\\mu$ is related to the\nlargest eigenvalue of the resulting quantum ciphertexts. 2) For a uniform\nmessage distribution, we partially characterize the scheme with the minimal\nsuccess probability for cloning attacks. 3) Under natural symmetry conditions,\nwe prove that the rank of the ciphertext density operators has to grow at least\nlogarithmically in the number of messages to ensure uncloneable security. 4)\nThe \\emph{simultaneous} one-way-to-hiding (O2H) lemma is an important technique\nin recent works on uncloneable encryption and quantum copy protection. We give\nan explicit example which shatters the hope of reducing the multiplicative\n\"security loss\" constant in this lemma to below 9/8.\n", "versions": [{"version": "v1", "created": "Fri, 26 Mar 2021 15:12:10 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Majenz", "Christian", ""], ["Schaffner", "Christian", ""], ["Tahmasbi", "Mehrdad", ""]]}, {"id": "2103.14628", "submitter": "Florian Wilkens", "authors": "Florian Wilkens, Felix Ortmann, Steffen Haas, Matthias Vallentin,\n  Mathias Fischer", "title": "Multi-Stage Attack Detection via Kill Chain State Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, human security analysts collapse under the sheer volume of alerts they\nhave to triage during investigations. The inability to cope with this load,\ncoupled with a high false positive rate of alerts, creates alert fatigue. This\nresults in failure to detect complex attacks, such as advanced persistent\nthreats (APTs), because they manifest over long time frames and attackers tread\ncarefully to evade detection mechanisms. In this paper, we contribute a new\nmethod to synthesize attack graphs from state machines. We use the network\ndirection to derive potential attack stages from single and meta-alerts and\nmodel resulting attack scenarios in a kill chain state machine (KCSM). Our\nalgorithm yields a graphical summary of the attack, APT scenario graphs, where\nnodes represent involved hosts and edges infection activity. We evaluate the\nfeasibility of our approach in multiple experiments based on the\nCSE-CIC-IDS2018 data set. We obtain up to 446 458 singleton alerts that our\nalgorithm condenses into 700 APT scenario graphs resulting in a reduction of up\nto three orders of magnitude. This reduction makes it feasible for human\nanalysts to effectively triage potential incidents. An evaluation on the same\ndata set, in which we embedded a synthetic yet realistic APT campaign, supports\nthe applicability of our approach of detecting and contextualizing complex\nattacks. The APT scenario graphs constructed by our algorithm correctly link\nlarge parts of the APT campaign and present a coherent view to support the\nhuman analyst in further analyses.\n", "versions": [{"version": "v1", "created": "Fri, 26 Mar 2021 17:42:57 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Wilkens", "Florian", ""], ["Ortmann", "Felix", ""], ["Haas", "Steffen", ""], ["Vallentin", "Matthias", ""], ["Fischer", "Mathias", ""]]}, {"id": "2103.14679", "submitter": "Tom Emery", "authors": "Michel Scheerman, Narges Zarrabi, Martijn Kruiten, Maxime Mog\\'e,\n  Lykle Voort, Annette Langedijk, Ruurd Schoonhoven, Tom Emery", "title": "Secure Platform for Processing Sensitive Data on Shared HPC Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High performance computing clusters operating in shared and batch mode pose\nchallenges for processing sensitive data. In the meantime, the need for secure\nprocessing of sensitive data on HPC system is growing. In this work we present\na novel method for creating secure computing environments on traditional\nmulti-tenant high-performance computing clusters. Our platform as a service\nprovides a customizable, virtualized solution using PCOCC and SLURM to meet\nstrict security requirements without modifying the exist-ing HPC\ninfrastructure. We show how this platform has been used in real-world research\napplications from different research domains. The solution is scalable by\ndesign with low performance overhead and can be generalized for processing\nsensitive data on shared HPC systems imposing high security criteria\n", "versions": [{"version": "v1", "created": "Fri, 26 Mar 2021 18:30:33 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Scheerman", "Michel", ""], ["Zarrabi", "Narges", ""], ["Kruiten", "Martijn", ""], ["Mog\u00e9", "Maxime", ""], ["Voort", "Lykle", ""], ["Langedijk", "Annette", ""], ["Schoonhoven", "Ruurd", ""], ["Emery", "Tom", ""]]}, {"id": "2103.14697", "submitter": "Clemens Seibold", "authors": "Clemens Seibold, Anna Hilsmann, Peter Eisert", "title": "Focused LRP: Explainable AI for Face Morphing Attack Detection", "comments": "Published at WACVW 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of detecting morphed face images has become highly relevant in\nrecent years to ensure the security of automatic verification systems based on\nfacial images, e.g. automated border control gates. Detection methods based on\nDeep Neural Networks (DNN) have been shown to be very suitable to this end.\nHowever, they do not provide transparency in the decision making and it is not\nclear how they distinguish between genuine and morphed face images. This is\nparticularly relevant for systems intended to assist a human operator, who\nshould be able to understand the reasoning. In this paper, we tackle this\nproblem and present Focused Layer-wise Relevance Propagation (FLRP). This\nframework explains to a human inspector on a precise pixel level, which image\nregions are used by a Deep Neural Network to distinguish between a genuine and\na morphed face image. Additionally, we propose another framework to objectively\nanalyze the quality of our method and compare FLRP to other DNN\ninterpretability methods. This evaluation framework is based on removing\ndetected artifacts and analyzing the influence of these changes on the decision\nof the DNN. Especially, if the DNN is uncertain in its decision or even\nincorrect, FLRP performs much better in highlighting visible artifacts compared\nto other methods.\n", "versions": [{"version": "v1", "created": "Fri, 26 Mar 2021 19:05:01 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Seibold", "Clemens", ""], ["Hilsmann", "Anna", ""], ["Eisert", "Peter", ""]]}, {"id": "2103.14713", "submitter": "Jing Tang", "authors": "Yuming Huang and Jing Tang and Qianhao Cong and Andrew Lim and\n  Jianliang Xu", "title": "Do the Rich Get Richer? Fairness Analysis for Blockchain Incentives", "comments": "A short version of the paper will appear in 2021 International\n  Conference on Management of Data (SIGMOD '21)", "journal-ref": null, "doi": "10.1145/3448016.3457285", "report-no": null, "categories": "cs.CR cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Proof-of-Work (PoW) is the most widely adopted incentive model in current\nblockchain systems, which unfortunately is energy inefficient. Proof-of-Stake\n(PoS) is then proposed to tackle the energy issue. The rich-get-richer concern\nof PoS has been heavily debated in the blockchain community. The debate is\ncentered around the argument that whether rich miners possessing more stakes\nwill obtain higher staking rewards and further increase their potential income\nin the future. In this paper, we define two types of fairness, i.e.,\nexpectational fairness and robust fairness, that are useful for answering this\nquestion. In particular, expectational fairness illustrates that the expected\nincome of a miner is proportional to her initial investment, indicating that\nthe expected return on investment is a constant. To better capture the\nuncertainty of mining outcomes, robust fairness is proposed to characterize\nwhether the return on investment concentrates to a constant with high\nprobability as time evolves. Our analysis shows that the classical PoW\nmechanism can always preserve both types of fairness as long as the mining game\nruns for a sufficiently long time. Furthermore, we observe that current PoS\nblockchains implement various incentive models and discuss three\nrepresentatives, namely ML-PoS, SL-PoS and C-PoS. We find that (i) ML-PoS\n(e.g., Qtum and Blackcoin) preserves expectational fairness but may not achieve\nrobust fairness, (ii) SL-PoS (e.g., NXT) does not protect any type of fairness,\nand (iii) C-PoS (e.g., Ethereum 2.0) outperforms ML-PoS in terms of robust\nfairness while still maintaining expectational fairness. Finally, massive\nexperiments on real blockchain systems and extensive numerical simulations are\nperformed to validate our analysis.\n", "versions": [{"version": "v1", "created": "Fri, 26 Mar 2021 19:53:15 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 07:02:15 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Huang", "Yuming", ""], ["Tang", "Jing", ""], ["Cong", "Qianhao", ""], ["Lim", "Andrew", ""], ["Xu", "Jianliang", ""]]}, {"id": "2103.14717", "submitter": "Alessandro Lameiras Koerich", "authors": "Mohammad Esmaeilpour, Patrick Cardinal, Alessandro Lameiras Koerich", "title": "Cyclic Defense GAN Against Speech Adversarial Attacks", "comments": "5", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CR eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new defense approach for counteracting with\nstate-of-the-art white and black-box adversarial attack algorithms. Our\napproach fits in the category of implicit reactive defense algorithms since it\ndoes not directly manipulate the potentially malicious input signals. Instead,\nit reconstructs a similar signal with a synthesized spectrogram using a cyclic\ngenerative adversarial network. This cyclic framework helps to yield a stable\ngenerative model. Finally, we feed the reconstructed signal into the\nspeech-to-text model for transcription. The conducted experiments on targeted\nand non-targeted adversarial attacks developed for attacking DeepSpeech, Kaldi,\nand Lingvo models demonstrate the proposed defense's effectiveness in adverse\nscenarios.\n", "versions": [{"version": "v1", "created": "Fri, 26 Mar 2021 20:09:46 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Esmaeilpour", "Mohammad", ""], ["Cardinal", "Patrick", ""], ["Koerich", "Alessandro Lameiras", ""]]}, {"id": "2103.14739", "submitter": "Saurav Maji", "authors": "Saurav Maji, Utsav Banerjee, and Anantha P. Chandrakasan", "title": "Leaky Nets: Recovering Embedded Neural Network Models and Inputs through\n  Simple Power and Timing Side-Channels -- Attacks and Defenses", "comments": null, "journal-ref": "IEEE Internet of Things Journal, 2021", "doi": "10.1109/JIOT.2021.3061314.", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent advancements in machine learning theory, many commercial\nembedded micro-processors use neural network models for a variety of signal\nprocessing applications. However, their associated side-channel security\nvulnerabilities pose a major concern. There have been several proof-of-concept\nattacks demonstrating the extraction of their model parameters and input data.\nBut, many of these attacks involve specific assumptions, have limited\napplicability, or pose huge overheads to the attacker. In this work, we study\nthe side-channel vulnerabilities of embedded neural network implementations by\nrecovering their parameters using timing-based information leakage and simple\npower analysis side-channel attacks. We demonstrate our attacks on popular\nmicro-controller platforms over networks of different precisions such as\nfloating point, fixed point, binary networks. We are able to successfully\nrecover not only the model parameters but also the inputs for the above\nnetworks. Countermeasures against timing-based attacks are implemented and\ntheir overheads are analyzed.\n", "versions": [{"version": "v1", "created": "Fri, 26 Mar 2021 21:28:13 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Maji", "Saurav", ""], ["Banerjee", "Utsav", ""], ["Chandrakasan", "Anantha P.", ""]]}, {"id": "2103.14741", "submitter": "Geoffrey Siwo", "authors": "Taeho Jung, Ryan Karl, Geoffrey H. Siwo", "title": "Genomic Encryption of Biometric Information for Privacy-Preserving\n  Forensics", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DNA fingerprinting is a cornerstone for human identification in forensics,\nwhere the sequence of highly polymorphic short tandem repeats (STRs) from an\nindividual is compared against a DNA database. This presents significant\nprivacy risks to individuals with DNA profiles in the database due to hacking\nby malicious attackers who may access the data and misuse it for secondary\npurposes. In this paper, we propose a novel cryptographic framework for jointly\nencrypting DNA-based fingerprints (STRs) with other biometric data, for\nexample, facial images, such that the STRs and biometrics information of an\nindividual are revealed only when a positive match is found, i.e. the STRs act\nas decryption keys. Specifically, when a search is performed on the encrypted\ndatabase using STR sequences of an individual in the database, a perfect match\ngenerates the facial image and/ or other biometrics of the individual while the\nlack of a match returns a null result. By jointly encrypting DNA fingerprints\nand other biometrics using the unique STRs generated keys, our approach ensures\nperfect privacy of the encrypted information with decryption of only the record\nwith STRs matching the query. This safeguards the information of other\nindividuals in the same database. The proposed approach can also be used to\nsecurely authenticate the identity of individuals or biological material in\nscenarios beyond forensics including tracking the identity of samples for\nclinical genetics and cell therapies.\n", "versions": [{"version": "v1", "created": "Fri, 26 Mar 2021 21:33:53 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Jung", "Taeho", ""], ["Karl", "Ryan", ""], ["Siwo", "Geoffrey H.", ""]]}, {"id": "2103.14783", "submitter": "Christopher Gorog", "authors": "Christopher Gorog", "title": "A Synergistic Approach to Digital Privacy", "comments": "This paper has been produced at the request of the IEEE Future\n  Directions Committee as a response to a call for expertise on evolving\n  privacy empowering technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper outlines an approach for IEEE to take leadership for digital\nprivacy to align many existing IEEE Societies and efforts in the areas of\ncomputer systems & applications security, organizational & global\narchitectures, policy-supporting legislation, originating new standards,\nintegrating compliance into technologies, and helping design decision-board\ninfrastructures for governance bodies. Much of the current emphasis on evolving\nprivacy technologies centers on big corporate enterprises and institutions,\ncausing the industry to support corporate assets protection mainly. Fostering\ntechnology to empower individual privacy-enabling tools has lagged, and\npersonal privacy has diminished because corporate big data applications have\nmade sizable investments into exploiting private data. As one of the largest\nindividual-member-based organizations, IEEE is urged to develop a collaborative\napproach for digital privacy with privacy-enabling technologies to benefit its\nmembers. The recommendations outlined define a prospective course that could\nresult in future global individualized privacy capabilities which employ a\ncombination of synergistic technologies such as distributed ledgers,\ndifferential privacy, homomorphic encryption, secure distributed multi-party\ncomputation, zero-trust architectures, proof-of-origin of data, software, or\nother techniques. Such an effort would involve community engagement and\noutreach, academic peer-review events, the establishment of governance bodies,\ncoordination & expansion of existing standards, and the development of\npublicly-accessible prototypes. Collaboration with other IEEE-sponsored efforts\nfor transactive energy systems, confidentiality and security of healthcare\nrecords and devices, and other IEEE-funded projects will help magnify digital\nprivacy investments already in progress in these applications of emerging\ntechnologies.\n", "versions": [{"version": "v1", "created": "Sat, 27 Mar 2021 01:40:19 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Gorog", "Christopher", ""]]}, {"id": "2103.14795", "submitter": "Yi Cai", "authors": "Yi Cai, Xuefei Ning, Huazhong Yang, Yu Wang", "title": "Ensemble-in-One: Learning Ensemble within Random Gated Networks for\n  Enhanced Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks have rendered high security risks on modern deep learning\nsystems. Adversarial training can significantly enhance the robustness of\nneural network models by suppressing the non-robust features. However, the\nmodels often suffer from significant accuracy loss on clean data. Ensemble\ntraining methods have emerged as promising solutions for defending against\nadversarial attacks by diversifying the vulnerabilities among the sub-models,\nsimultaneously maintaining comparable accuracy as standard training. However,\nexisting ensemble methods are with poor scalability, owing to the rapid\ncomplexity increase when including more sub-models in the ensemble. Moreover,\nin real-world applications, it is difficult to deploy an ensemble with multiple\nsub-models, owing to the tight hardware resource budget and latency\nrequirement. In this work, we propose ensemble-in-one (EIO), a simple but\nefficient way to train an ensemble within one random gated network (RGN). EIO\naugments the original model by replacing the parameterized layers with\nmulti-path random gated blocks (RGBs) to construct a RGN. By diversifying the\nvulnerability of the numerous paths within the RGN, better robustness can be\nachieved. It provides high scalability because the paths within an EIO network\nexponentially increase with the network depth. Our experiments demonstrate that\nEIO consistently outperforms previous ensemble training methods with even less\ncomputational overhead.\n", "versions": [{"version": "v1", "created": "Sat, 27 Mar 2021 03:13:03 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Cai", "Yi", ""], ["Ning", "Xuefei", ""], ["Yang", "Huazhong", ""], ["Wang", "Yu", ""]]}, {"id": "2103.14835", "submitter": "Zhijie Deng", "authors": "Zhijie Deng, Xiao Yang, Shizhen Xu, Hang Su, Jun Zhu", "title": "LiBRe: A Practical Bayesian Approach to Adversarial Detection", "comments": "IEEE/ CVF International Conference on Computer Vision and Pattern\n  Recognition (CVPR), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite their appealing flexibility, deep neural networks (DNNs) are\nvulnerable against adversarial examples. Various adversarial defense strategies\nhave been proposed to resolve this problem, but they typically demonstrate\nrestricted practicability owing to unsurmountable compromise on universality,\neffectiveness, or efficiency. In this work, we propose a more practical\napproach, Lightweight Bayesian Refinement (LiBRe), in the spirit of leveraging\nBayesian neural networks (BNNs) for adversarial detection. Empowered by the\ntask and attack agnostic modeling under Bayes principle, LiBRe can endow a\nvariety of pre-trained task-dependent DNNs with the ability of defending\nheterogeneous adversarial attacks at a low cost. We develop and integrate\nadvanced learning techniques to make LiBRe appropriate for adversarial\ndetection. Concretely, we build the few-layer deep ensemble variational and\nadopt the pre-training & fine-tuning workflow to boost the effectiveness and\nefficiency of LiBRe. We further provide a novel insight to realise adversarial\ndetection-oriented uncertainty quantification without inefficiently crafting\nadversarial examples during training. Extensive empirical studies covering a\nwide range of scenarios verify the practicability of LiBRe. We also conduct\nthorough ablation studies to evidence the superiority of our modeling and\nlearning strategies.\n", "versions": [{"version": "v1", "created": "Sat, 27 Mar 2021 07:48:58 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 06:42:21 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Deng", "Zhijie", ""], ["Yang", "Xiao", ""], ["Xu", "Shizhen", ""], ["Su", "Hang", ""], ["Zhu", "Jun", ""]]}, {"id": "2103.14838", "submitter": "Atif Ahmad", "authors": "Atif Ahmad, Sean B. Maynard, Sameen Motahhir, Moneer Alshaikh", "title": "Teaching Information Security Management Using an Incident of\n  Intellectual Property Leakage", "comments": "11 pages", "journal-ref": "Australasian Conference on Information Systems, Wellington, 2020,\n  pp. 1-11", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Case-based learning is a powerful pedagogical method of creating dialogue\nbetween theory and practice. CBL is particularly suited to executive learning\nas it instigates critical discussion and draws out relevant experiences. In\nthis paper we used a real-world case to teach Information Security Management\nto students in Management Information Systems. The real-world case is described\nin a legal indictment, T-mobile USA Inc v Huawei Device USA Inc. and Huawei\nTechnologies Co. LTD, alleging theft of intellectual property and breaches of\ncontract concerning confidentiality and disclosure of sensitive information.\nThe incident scenario is interesting as it relates to a business asset that has\nboth digital and physical components that has been compromised through an\nunconventional cyber-physical attack facilitated by insiders. The scenario\nsparked an interesting debate among students about the scope and definition of\nsecurity incidents, the role and structure of the security unit, the utility of\ncompliance-based approaches to security, and the inadequate use of threat\nintelligence in modern security strategies.\n", "versions": [{"version": "v1", "created": "Sat, 27 Mar 2021 08:07:17 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Ahmad", "Atif", ""], ["Maynard", "Sean B.", ""], ["Motahhir", "Sameen", ""], ["Alshaikh", "Moneer", ""]]}, {"id": "2103.14839", "submitter": "Atif Ahmad", "authors": "Atif Ahmad, Sean B. Maynard, Sameen Motahhir", "title": "Teaching Information Security Management in Postgraduate Tertiary\n  Education: The Case of Horizon Automotive Industries", "comments": null, "journal-ref": "Australasian Conference on Information Systems, Wellington, 2020,\n  pp. 1-12", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Teaching cases based on stories about real organizations are a powerful means\nof storytelling. These cases closely parallel real-world situations and can\ndeliver on pedagogical objectives as writers can use their creative license to\ncraft a storyline that better focuses on the specific principles, concepts, and\nchallenges they want to address in their teaching. The method instigates\ncritical discussion, draws out relevant experiences from students, encourages\nquestioning of accepted practices, and creates dialogue between theory and\npractice. We present Horizon, a case study of a firm that suffers a\ncatastrophic incident of Intellectual Property (IP) theft. The case study was\ndeveloped to teach information security management (ISM) principles in key\nareas such as strategy, risk, policy and training to postgraduate Information\nSystems and Information Technology students at the University of Melbourne,\nAustralia.\n", "versions": [{"version": "v1", "created": "Sat, 27 Mar 2021 08:12:56 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Ahmad", "Atif", ""], ["Maynard", "Sean B.", ""], ["Motahhir", "Sameen", ""]]}, {"id": "2103.14991", "submitter": "Min Chen", "authors": "Min Chen and Zhikun Zhang and Tianhao Wang and Michael Backes and\n  Mathias Humbert and Yang Zhang", "title": "Graph Unlearning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The right to be forgotten states that a data subject has the right to erase\ntheir data from an entity storing it. In the context of machine learning (ML),\nit requires the ML model provider to remove the data subject's data from the\ntraining set used to build the ML model, a process known as \\textit{machine\nunlearning}. While straightforward and legitimate, retraining the ML model from\nscratch upon receiving unlearning requests incurs high computational overhead\nwhen the training set is large. To address this issue, a number of approximate\nalgorithms have been proposed in the domain of image and text data, among which\nSISA is the state-of-the-art solution. It randomly partitions the training set\ninto multiple shards and trains a constituent model for each shard. However,\ndirectly applying SISA to the graph data can severely damage the graph\nstructural information, and thereby the resulting ML model utility.\n  In this paper, we propose GraphEraser, a novel machine unlearning method\ntailored to graph data. Its contributions include two novel graph partition\nalgorithms, and a learning-based aggregation method. We conduct extensive\nexperiments on five real-world datasets to illustrate the unlearning efficiency\nand model utility of GraphEraser. We observe that GraphEraser achieves\n2.06$\\times$ (small dataset) to 35.94$\\times$ (large dataset) unlearning time\nimprovement compared to retraining from scratch. On the other hand, GraphEraser\nachieves up to $62.5\\%$ higher F1 score than that of random partitioning. In\naddition, our proposed learning-based aggregation method achieves up to $112\\%$\nhigher F1 score than that of the majority vote aggregation.\n", "versions": [{"version": "v1", "created": "Sat, 27 Mar 2021 20:38:25 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Chen", "Min", ""], ["Zhang", "Zhikun", ""], ["Wang", "Tianhao", ""], ["Backes", "Michael", ""], ["Humbert", "Mathias", ""], ["Zhang", "Yang", ""]]}, {"id": "2103.15005", "submitter": "Atif Ahmad", "authors": "Atif Ahmad, Jeb Webb, Kevin C. Desouza, James Boorman", "title": "Strategically-Motivated Advanced Persistent Threat: Definition, Process,\n  Tactics and a Disinformation Model of Counterattack", "comments": null, "journal-ref": "Computers & Security, 2019, Vol 86, pp. 402-418", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Advanced persistent threat (APT) is widely acknowledged to be the most\nsophisticated and potent class of security threat. APT refers to knowledgeable\nhuman attackers that are organized, highly sophisticated and motivated to\nachieve their objectives against a targeted organization(s) over a prolonged\nperiod. Strategically-motivated APTs or S-APTs are distinct in that they draw\ntheir objectives from the broader strategic agenda of third parties such as\ncriminal syndicates, nation-states, and rival corporations. In this paper we\nreview the use of the term - Advanced Persistent Threat - and present a formal\ndefinition. We then draw on military science, the science of organized\nconflict, for a theoretical basis to develop a rigorous and holistic model of\nthe stages of an APT operation which we subsequently use to explain how S-APTs\nexecute their strategically motivated operations using tactics, techniques and\nprocedures. Finally, we present a general disinformation model, derived from\nsituation awareness theory, and explain how disinformation can be used to\nattack the situation awareness and decision making of not only S-APT operators,\nbut also the entities that back them.\n", "versions": [{"version": "v1", "created": "Sat, 27 Mar 2021 22:18:20 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Ahmad", "Atif", ""], ["Webb", "Jeb", ""], ["Desouza", "Kevin C.", ""], ["Boorman", "James", ""]]}, {"id": "2103.15009", "submitter": "Prabhanjan Ananth", "authors": "Prabhanjan Ananth, Fatih Kaleoglu", "title": "Uncloneable Encryption, Revisited", "comments": "Submitted to TQC'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Uncloneable encryption, introduced by Broadbent and Lord (TQC'20), is an\nencryption scheme with the following attractive feature: an adversary cannot\ncreate multiple ciphertexts which encrypt to the same message as the original\nciphertext. The constructions proposed by Broadbent and Lord have the\ndisadvantage that they only guarantee one-time security; that is, the\nencryption key can only be used once to encrypt the message. In this work, we\nstudy uncloneable encryption schemes, where the encryption key can be re-used\nto encrypt multiple messages. We present two constructions from minimal\ncryptographic assumptions: (i) a private-key uncloneable encryption scheme\nassuming post-quantum one-way functions and, (ii) a public-key uncloneable\nencryption scheme assuming a post-quantum public-key encryption scheme.\n", "versions": [{"version": "v1", "created": "Sat, 27 Mar 2021 22:37:59 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Ananth", "Prabhanjan", ""], ["Kaleoglu", "Fatih", ""]]}, {"id": "2103.15072", "submitter": "Hassan Noura", "authors": "Jean-Paul A. Yaacoub, Hassan N. Noura, Ola Salman, Ali Chehab", "title": "A Survey on Ethical Hacking: Issues and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Security attacks are growing in an exponential manner and their impact on\nexisting systems is seriously high and can lead to dangerous consequences.\nHowever, in order to reduce the effect of these attacks, penetration tests are\nhighly required, and can be considered as a suitable solution for this task.\nTherefore, the main focus of this paper is to explain the technical and\nnon-technical steps of penetration tests. The objective of penetration tests is\nto make existing systems and their corresponding data more secure, efficient\nand resilient. In other terms, pen testing is a simulated attack with the goal\nof identifying any exploitable vulnerability or/and a security gap. In fact,\nany identified exploitable vulnerability will be used to conduct attacks on\nsystems, devices, or personnel. This growing problem should be solved and\nmitigated to reach better resistance against these attacks. Moreover, the\nadvantages and limitations of penetration tests are also listed. The main issue\nof penetration tests that it is efficient to detect known vulnerabilities.\nTherefore, in order to resist unknown vulnerabilities, a new kind of modern\npenetration tests is required, in addition to reinforcing the use of shadows\nhoneypots. This can also be done by reinforcing the anomaly detection of\nintrusion detection/prevention system. In fact, security is increased by\ndesigning an efficient cooperation between the different security elements and\npenetration tests.\n", "versions": [{"version": "v1", "created": "Sun, 28 Mar 2021 07:33:03 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Yaacoub", "Jean-Paul A.", ""], ["Noura", "Hassan N.", ""], ["Salman", "Ola", ""], ["Chehab", "Ali", ""]]}, {"id": "2103.15164", "submitter": "Ping Wang", "authors": "Ping Wang", "title": "Privacy-Assured Outsourcing of Compressed Sensing Reconstruction Service\n  in Cloud", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Compressed sensing (CS), breaking the constriction of Shannon-Nyquist\nsampling theorem, is a very promising data acquisition technique in the era of\nmultimedia big data. However, the high complexity of CS reconstruction\nalgorithm is a big trouble for endusers who are hardly provided with great\ncomputing power. The combination of CS and cloud has the potential of freeing\nendusers from the resource constraint by cleverly transforming computational\nworkload from the local cilent to the cloud platform. As a result, the\nlow-complexity encoding virtue of CS is fully leveraged in the\nresource-constrained sensing devices but its highcomplexity decoding problem is\neffectively addressed in cloud. It seems to be perfect but privacy and security\nconcerns are ignored. In this paper, a secure outsourcing scheme for CS\nreconstruction service is proposed. Experimental results and security analyses\ndemonstrate that the proposed scheme can restrict malicious access, verify the\nintegrity of the recovered data, and resist brute-force attack, ciphertext-only\nattack, and plaintext attack.\n", "versions": [{"version": "v1", "created": "Sun, 28 Mar 2021 16:18:05 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Wang", "Ping", ""]]}, {"id": "2103.15194", "submitter": "Vasileios Mavroeidis Dr.", "authors": "Vasileios Mavroeidis and Audun J{\\o}sang", "title": "Data-Driven Threat Hunting Using Sysmon", "comments": null, "journal-ref": null, "doi": "10.1145/3199478.3199490", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Threat actors can be persistent, motivated and agile, and leverage a\ndiversified and extensive set of tactics and techniques to attain their goals.\nIn response to that, defenders establish threat intelligence programs to stay\nthreat-informed and lower risk. Actionable threat intelligence is integrated\ninto security information and event management systems (SIEM) or is accessed\nvia more dedicated tools like threat intelligence platforms. A threat\nintelligence platform gives access to contextual threat information by\naggregating, processing, correlating, and analyzing real-time data and\ninformation from multiple sources, and in many cases, it provides centralized\nanalysis and reporting of an organization's security events. Sysmon logs is a\ndata source that has received considerable attention for endpoint visibility.\nApproaches for threat detection using Sysmon have been proposed, mainly\nfocusing on search engine technologies like NoSQL database systems. This paper\ndemonstrates one of the many use cases of Sysmon and cyber threat intelligence.\nIn particular, we present a threat assessment system that relies on a cyber\nthreat intelligence ontology to automatically classify executed software into\ndifferent threat levels by analyzing Sysmon log streams. The presented system\nand approach augments cyber defensive capabilities through situational\nawareness, prediction, and automated courses of action.\n", "versions": [{"version": "v1", "created": "Sun, 28 Mar 2021 18:20:16 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Mavroeidis", "Vasileios", ""], ["J\u00f8sang", "Audun", ""]]}, {"id": "2103.15202", "submitter": "Ateeq Sharfuddin", "authors": "Ateeq Sharfuddin, Brian Chapman, Chris Balles", "title": "An In-memory Embedding of CPython for Offensive Use", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We offer an embedding of CPython that runs entirely in memory without\n\"touching\" the disk. This in-memory embedding can load Python scripts directly\nfrom memory instead these scripts having to be loaded from files on disk.\nMalware that resides only in memory is harder to detect or mitigate against. We\nintend for our work to be used by security researchers to rapidly develop and\ndeploy offensive techniques that is difficult for security products to analyze\ngiven these instructions are in bytecode and only translated to machine-code by\nthe interpreter immediately prior to execution. Our work helps security\nresearchers and enterprise Red Teams who play offense. Red Teams want to\nrapidly prototype malware for their periodic campaigns and do not want their\nmalware to be detected by the Incident Response (IR) teams prior to\naccomplishing objectives. Red Teams also have difficulty running malware in\nproduction from files on disk as modern enterprise security products emulate,\ninspect, or quarantine such executables given these files have no reputation.\nOur work also helps enterprise Hunt and IR teams by making them aware of the\nviability of this type of attack. Our approach has been in use in production\nfor over a year and meets our customers' needs to quickly emulate\nthreat-actors' tasks, techniques, and procedures (TTPs).\n", "versions": [{"version": "v1", "created": "Sun, 28 Mar 2021 19:10:36 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 23:15:38 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Sharfuddin", "Ateeq", ""], ["Chapman", "Brian", ""], ["Balles", "Chris", ""]]}, {"id": "2103.15245", "submitter": "Deepti Gupta", "authors": "Deepti Gupta, Smriti Bhatt, Paras Bhatt, Maanak Gupta, and Ali Saman\n  Tosun", "title": "Game Theory Based Privacy Preserving Approach for Collaborative Deep\n  Learning in IoT", "comments": "arXiv admin note: text overlap with arXiv:2007.15215", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The exponential growth of Internet of Things (IoT) has become a transcending\nforce in creating innovative smart devices and connected domains including\nsmart homes, healthcare, transportation and manufacturing. With billions of IoT\ndevices, there is a huge amount of data continuously being generated,\ntransmitted, and stored at various points in the IoT architecture. Deep\nlearning is widely being used in IoT applications to extract useful insights\nfrom IoT data. However, IoT users have security and privacy concerns and prefer\nnot to share their personal data with third party applications or stakeholders.\nIn order to address user privacy concerns, Collaborative Deep Learning (CDL)\nhas been largely employed in data-driven applications which enables multiple\nIoT devices to train their models locally on edge gateways. In this chapter, we\nfirst discuss different types of deep learning approaches and how these\napproaches can be employed in the IoT domain. We present a privacy-preserving\ncollaborative deep learning approach for IoT devices which can achieve benefits\nfrom other devices in the system. This learning approach is analyzed from the\nbehavioral perspective of mobile edge devices using a game-theoretic model. We\nanalyze the Nash Equilibrium in N-player static game model. We further present\na novel fair collaboration strategy among edge IoT devices using cluster based\napproach to solve the CDL game, which enforces mobile edge devices for\ncooperation. We also present implementation details and evaluation analysis in\na real-world smart home deployment.\n", "versions": [{"version": "v1", "created": "Sun, 28 Mar 2021 23:36:56 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 01:31:05 GMT"}, {"version": "v3", "created": "Sat, 3 Apr 2021 14:55:20 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Gupta", "Deepti", ""], ["Bhatt", "Smriti", ""], ["Bhatt", "Paras", ""], ["Gupta", "Maanak", ""], ["Tosun", "Ali Saman", ""]]}, {"id": "2103.15289", "submitter": "Jinhua Cui", "authors": "Jinhua Cui, Shweta Shinde, Satyaki Sen, Prateek Saxena, Pinghai Yuan", "title": "Dynamic Binary Translation for SGX Enclaves", "comments": "24 pages, 11 figures, 10 tables. arXiv admin note: substantial text\n  overlap with arXiv:2009.01144", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enclaves, such as those enabled by Intel SGX, offer a hardware primitive for\nshielding user-level applications from the OS. While enclaves are a useful\nstarting point, code running in the enclave requires additional checks whenever\ncontrol or data is transferred to/from the untrusted OS. The enclave-OS\ninterface on SGX, however, can be extremely large if we wish to run existing\nunmodified binaries inside enclaves. This paper presents Ratel, a dynamic\nbinary translation engine running inside SGX enclaves on Linux. Ratel offers\ncomplete interposition, the ability to interpose on all executed instructions\nin the enclave and monitor all interactions with the OS. Instruction-level\ninterposition offers a general foundation for implementing a large variety of\ninline security monitors in the future.\n  We take a principled approach in explaining why complete interposition on SGX\nis challenging. We draw attention to 5 design decisions in SGX that create\nfundamental trade-offs between performance and ensuring complete interposition,\nand we explain how to resolve them in the favor of complete interposition. To\nillustrate the utility of the Ratel framework, we present the first attempt to\noffer binary compatibility with existing software on SGX. We report that Ratel\noffers binary compatibility with over 200 programs we tested, including\nmicro-benchmarks and real applications such as Linux shell utilities. Runtimes\nfor two programming languages, namely Python and R, tested with standard\nbenchmarks work out-of-the-box on Ratel without any specialized handling.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 02:45:41 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Cui", "Jinhua", ""], ["Shinde", "Shweta", ""], ["Sen", "Satyaki", ""], ["Saxena", "Prateek", ""], ["Yuan", "Pinghai", ""]]}, {"id": "2103.15352", "submitter": "Daogao Liu", "authors": "Janardhan Kulkarni, Yin Tat Lee, Daogao Liu", "title": "Private Non-smooth Empirical Risk Minimization and Stochastic Convex\n  Optimization in Subquadratic Steps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the differentially private Empirical Risk Minimization (ERM) and\nStochastic Convex Optimization (SCO) problems for non-smooth convex functions.\nWe get a (nearly) optimal bound on the excess empirical risk and excess\npopulation loss with subquadratic gradient complexity. More precisely, our\ndifferentially private algorithm requires $O(\\frac{N^{3/2}}{d^{1/8}}+\n\\frac{N^2}{d})$ gradient queries for optimal excess empirical risk, which is\nachieved with the help of subsampling and smoothing the function via\nconvolution. This is the first subquadratic algorithm for the non-smooth case\nwhen $d$ is super constant. As a direct application, using the iterative\nlocalization approach of Feldman et al. \\cite{fkt20}, we achieve the optimal\nexcess population loss for stochastic convex optimization problem, with\n$O(\\min\\{N^{5/4}d^{1/8},\\frac{ N^{3/2}}{d^{1/8}}\\})$ gradient queries. Our work\nmakes progress towards resolving a question raised by Bassily et al.\n\\cite{bfgt20}, giving first algorithms for private ERM and SCO with\nsubquadratic steps.\n  We note that independently Asi et al. \\cite{afkt21} gave other algorithms for\nprivate ERM and SCO with subquadratic steps.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 05:58:56 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 02:45:26 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Kulkarni", "Janardhan", ""], ["Lee", "Yin Tat", ""], ["Liu", "Daogao", ""]]}, {"id": "2103.15620", "submitter": "Olivier Rioul", "authors": "Andrei T\\u{a}n\\u{a}sescu, Marios O. Choudary, Olivier Rioul, and\n  Pantelimon George Popescu", "title": "Asymptotically Optimal Massey-Like Inequality on Guessing Entropy With\n  Application to Side-Channel Attack Evaluations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Massey-like inequality is any useful lower bound on guessing entropy in\nterms of the computationally scalable Shannon entropy. The asymptotically\noptimal Massey-like inequality is determined and further refined for\nfinite-support distributions. The impact of these results are highlighted for\nside-channel attack evaluation where guessing entropy is a key metric. In this\ncontext, the obtained bounds are compared to the state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 14:02:08 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["T\u0103n\u0103sescu", "Andrei", ""], ["Choudary", "Marios O.", ""], ["Rioul", "Olivier", ""], ["Popescu", "Pantelimon George", ""]]}, {"id": "2103.15690", "submitter": "Kobbi Nissim", "authors": "Kobbi Nissim and Chao Yan", "title": "The Sample Complexity of Distribution-Free Parity Learning in the Robust\n  Shuffle Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We provide a lowerbound on the sample complexity of distribution-free parity\nlearning in the realizable case in the shuffle model of differential privacy.\nNamely, we show that the sample complexity of learning $d$-bit parity functions\nis $\\Omega(2^{d/2})$. Our result extends a recent similar lowerbound on the\nsample complexity of private agnostic learning of parity functions in the\nshuffle model by Cheu and Ullman. We also sketch a simple shuffle model\nprotocol demonstrating that our results are tight up to $poly(d)$ factors.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 15:26:02 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Nissim", "Kobbi", ""], ["Yan", "Chao", ""]]}, {"id": "2103.15708", "submitter": "Johan Mazel", "authors": "Corentin Larroche, Johan Mazel, Stephan Cl\\'emen\\c{c}on", "title": "Dynamically Modelling Heterogeneous Higher-Order Interactions for\n  Malicious Behavior Detection in Event Logs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Anomaly detection in event logs is a promising approach for intrusion\ndetection in enterprise networks. By building a statistical model of usual\nactivity, it aims to detect multiple kinds of malicious behavior, including\nstealthy tactics, techniques and procedures (TTPs) designed to evade\nsignature-based detection systems. However, finding suitable anomaly detection\nmethods for event logs remains an important challenge. This results from the\nvery complex, multi-faceted nature of the data: event logs are not only\ncombinatorial, but also temporal and heterogeneous data, thus they fit poorly\nin most theoretical frameworks for anomaly detection. Most previous research\nfocuses on either one of these three aspects, building a simplified\nrepresentation of the data that can be fed to standard anomaly detection\nalgorithms. In contrast, we propose to simultaneously address all three of\nthese characteristics through a specifically tailored statistical model. We\nintroduce \\textsc{Decades}, a \\underline{d}ynamic, h\\underline{e}terogeneous\nand \\underline{c}ombinatorial model for \\underline{a}nomaly\n\\underline{d}etection in \\underline{e}vent \\underline{s}treams, and we\ndemonstrate its effectiveness at detecting malicious behavior through\nexperiments on a real dataset containing labelled red team activity. In\nparticular, we empirically highlight the importance of handling the multiple\ncharacteristics of the data by comparing our model with state-of-the-art\nbaselines relying on various data representations.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 15:45:38 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Larroche", "Corentin", ""], ["Mazel", "Johan", ""], ["Cl\u00e9men\u00e7on", "Stephan", ""]]}, {"id": "2103.15753", "submitter": "Pavlos Papadopoulos", "authors": "Pavlos Papadopoulos, Will Abramson, Adam J. Hall, Nikolaos Pitropakis\n  and William J. Buchanan", "title": "Privacy and Trust Redefined in Federated Machine Learning", "comments": "MDPI Mach. Learn. Knowl. Extr. 2021, 3(2), 333-356;\n  https://doi.org/10.3390/make3020017", "journal-ref": "Mach. Learn. Knowl. Extr. 2021, 3(2), 333-356", "doi": "10.3390/make3020017", "report-no": null, "categories": "cs.CR cs.CY cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A common privacy issue in traditional machine learning is that data needs to\nbe disclosed for the training procedures. In situations with highly sensitive\ndata such as healthcare records, accessing this information is challenging and\noften prohibited. Luckily, privacy-preserving technologies have been developed\nto overcome this hurdle by distributing the computation of the training and\nensuring the data privacy to their owners. The distribution of the computation\nto multiple participating entities introduces new privacy complications and\nrisks. In this paper, we present a privacy-preserving decentralised workflow\nthat facilitates trusted federated learning among participants. Our\nproof-of-concept defines a trust framework instantiated using decentralised\nidentity technologies being developed under Hyperledger projects\nAries/Indy/Ursa. Only entities in possession of Verifiable Credentials issued\nfrom the appropriate authorities are able to establish secure, authenticated\ncommunication channels authorised to participate in a federated learning\nworkflow related to mental health data.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 16:47:01 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 15:07:01 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Papadopoulos", "Pavlos", ""], ["Abramson", "Will", ""], ["Hall", "Adam J.", ""], ["Pitropakis", "Nikolaos", ""], ["Buchanan", "William J.", ""]]}, {"id": "2103.15860", "submitter": "J\\\"ames M\\'en\\'etrey", "authors": "J\\\"ames M\\'en\\'etrey, Marcelo Pasin, Pascal Felber, Valerio Schiavoni", "title": "Twine: An Embedded Trusted Runtime for WebAssembly", "comments": "12 pages. This is the author's version of the work. The definitive\n  version will be published in the proceedings of the 37th IEEE International\n  Conference on Data Engineering (ICDE'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  WebAssembly is an increasingly popular lightweight binary instruction format,\nwhich can be efficiently embedded and sandboxed. Languages like C, C++, Rust,\nGo, and many others can be compiled into WebAssembly. This paper describes\nTwine, a WebAssembly trusted runtime designed to execute unmodified,\nlanguage-independent applications. We leverage Intel SGX to build the runtime\nenvironment without dealing with language-specific, complex APIs. While SGX\nhardware provides secure execution within the processor, Twine provides a\nsecure, sandboxed software runtime nested within an SGX enclave, featuring a\nWebAssembly system interface (WASI) for compatibility with unmodified\nWebAssembly applications. We evaluate Twine with a large set of general-purpose\nbenchmarks and real-world applications. In particular, we used Twine to\nimplement a secure, trusted version of SQLite, a well-known full-fledged\nembeddable database. We believe that such a trusted database would be a\nreasonable component to build many larger application services. Our evaluation\nshows that SQLite can be fully executed inside an SGX enclave via WebAssembly\nand existing system interface, with similar average performance overheads. We\nestimate that the performance penalties measured are largely compensated by the\nadditional security guarantees and its full compatibility with standard\nWebAssembly. An in-depth analysis of our results indicates that performance can\nbe greatly improved by modifying some of the underlying libraries. We describe\nand implement one such modification in the paper, showing up to $4.1\\times$\nspeedup. Twine is open-source, available at GitHub along with instructions to\nreproduce our experiments.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 18:10:51 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["M\u00e9n\u00e9trey", "J\u00e4mes", ""], ["Pasin", "Marcelo", ""], ["Felber", "Pascal", ""], ["Schiavoni", "Valerio", ""]]}, {"id": "2103.15896", "submitter": "Petros Spachos", "authors": "Marc Jayson Baucas, Stephen Andrew Gadsden, and Petros Spachos", "title": "IoT-based Smart Home Device Monitor Using Private Blockchain Technology\n  and Localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Internet of Things (IoT)-based smart home applications are rising in\npopularity. However, this trend attracts malicious activity, which causes\ncost-efficient security to be in high demand. This paper proposes a low-end\ndesign that reinforces the security of a home network. It uses private\nblockchain technology and localization via RSSI-based trilateration. We\ninvestigated the benefits of private blockchains over their public counterpart,\nand we improve the precision of the localization algorithm by testing it\nagainst different wireless technologies. The results conclude that using a\nprivate blockchain with a WiFi-based communication system produces the most\nefficient iteration of the proposed design.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 19:07:10 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Baucas", "Marc Jayson", ""], ["Gadsden", "Stephen Andrew", ""], ["Spachos", "Petros", ""]]}, {"id": "2103.15897", "submitter": "Matthew Ciolino", "authors": "Josh Kalin, David Noever, Matthew Ciolino, Dominick Hambrick, Gerry\n  Dozier", "title": "Automating Defense Against Adversarial Attacks: Discovery of\n  Vulnerabilities and Application of Multi-INT Imagery to Protect Deployed\n  Models", "comments": "SPIE 2021, 8 Pages, 6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Image classification is a common step in image recognition for machine\nlearning in overhead applications. When applying popular model architectures\nlike MobileNetV2, known vulnerabilities expose the model to counter-attacks,\neither mislabeling a known class or altering box location. This work proposes\nan automated approach to defend these models. We evaluate the use of\nmulti-spectral image arrays and ensemble learners to combat adversarial\nattacks. The original contribution demonstrates the attack, proposes a remedy,\nand automates some key outcomes for protecting the model's predictions against\nadversaries. In rough analogy to defending cyber-networks, we combine\ntechniques from both offensive (\"red team\") and defensive (\"blue team\")\napproaches, thus generating a hybrid protective outcome (\"green team\"). For\nmachine learning, we demonstrate these methods with 3-color channels plus\ninfrared for vehicles. The outcome uncovers vulnerabilities and corrects them\nwith supplemental data inputs commonly found in overhead cases particularly.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 19:07:55 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Kalin", "Josh", ""], ["Noever", "David", ""], ["Ciolino", "Matthew", ""], ["Hambrick", "Dominick", ""], ["Dozier", "Gerry", ""]]}, {"id": "2103.15918", "submitter": "Panagiota Kiourti", "authors": "Panagiota Kiourti, Wenchao Li, Anirban Roy, Karan Sikka, and Susmit\n  Jha", "title": "Online Defense of Trojaned Models using Misattributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new approach to detecting neural Trojans on Deep Neural\nNetworks during inference. This approach is based on monitoring the inference\nof a machine learning model, computing the attribution of the model's decision\non different features of the input, and then statistically analyzing these\nattributions to detect whether an input sample contains the Trojan trigger. The\nanomalous attributions, aka misattributions, are then accompanied by\nreverse-engineering of the trigger to evaluate whether the input sample is\ntruly poisoned with a Trojan trigger. We evaluate our approach on several\nbenchmarks, including models trained on MNIST, Fashion MNIST, and German\nTraffic Sign Recognition Benchmark, and demonstrate the state of the art\ndetection accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 19:53:44 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Kiourti", "Panagiota", ""], ["Li", "Wenchao", ""], ["Roy", "Anirban", ""], ["Sikka", "Karan", ""], ["Jha", "Susmit", ""]]}, {"id": "2103.15942", "submitter": "Chenghong Wang", "authors": "Chenghong Wang, Johes Bater, Kartik Nayak, Ashwin Machanavajjhala", "title": "DP-Sync: Hiding Update Patterns in Secure Outsourced Databases with\n  Differential Privacy", "comments": null, "journal-ref": null, "doi": "10.1145/3448016.3457306", "report-no": null, "categories": "cs.CR cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we have introduced a new type of leakage associated with\nmodern encrypted databases called update pattern leakage. We formalize the\ndefinition and security model of DP-Sync with DP update patterns. We also\nproposed the framework DP-Sync, which extends existing encrypted database\nschemes to DP-Sync with DP update patterns. DP-Sync guarantees that the entire\ndata update history over the outsourced data structure is protected by\ndifferential privacy. This is achieved by imposing differentially-private\nstrategies that dictate the data owner's synchronization of local~data.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 20:36:59 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 01:56:15 GMT"}, {"version": "v3", "created": "Wed, 7 Apr 2021 02:45:27 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Wang", "Chenghong", ""], ["Bater", "Johes", ""], ["Nayak", "Kartik", ""], ["Machanavajjhala", "Ashwin", ""]]}, {"id": "2103.16029", "submitter": "Dorel Yaffe", "authors": "Dorel Yaffe and Danny Hendler", "title": "Early Detection of In-Memory Malicious Activity based on Run-time\n  Environmental Features", "comments": "26 pages, 12 figures, LNCS format, CSCML 2021 to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years malware has become increasingly sophisticated and difficult\nto detect prior to exploitation. While there are plenty of approaches to\nmalware detection, they all have shortcomings when it comes to identifying\nmalware correctly prior to exploitation. The trade-off is usually between false\npositives, causing overhead, preventing normal usage and the risk of letting\nthe malware execute and cause damage to the target. We present a novel\nend-to-end solution for in-memory malicious activity detection done prior to\nexploitation by leveraging machine learning capabilities based on data from\nunique run-time logs, which are carefully curated in order to detect malicious\nactivity in the memory of protected processes. This solution achieves reduced\noverhead and false positives as well as deployment simplicity. We implemented\nour solution for Windows-based systems, employing multi disciplinary knowledge\nfrom malware research, machine learning, and operating system internals. Our\nexperimental evaluation yielded promising results. As we expect future\nsophisticated malware may try to bypass it, we also discuss how our solution\ncan be extended to thwart such bypassing attempts.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 02:19:00 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Yaffe", "Dorel", ""], ["Hendler", "Danny", ""]]}, {"id": "2103.16085", "submitter": "Haftu Reda", "authors": "Haftu Tasew Reda, Adnan Anwar, Abdun Naser Mahmood, and Zahir Tari", "title": "A Taxonomy of Cyber Defence Strategies Against False Data Attacks in\n  Smart Grid", "comments": "35 pages, prepared using the 'acmsmall' document class. arXiv admin\n  note: substantial text overlap with arXiv:2103.10594", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Modern electric power grid, known as the Smart Grid, has fast transformed the\nisolated and centrally controlled power system to a fast and massively\nconnected cyber-physical system that benefits from the revolutions happening in\nthe communications and the fast adoption of Internet of Things devices. While\nthe synergy of a vast number of cyber-physical entities has allowed the Smart\nGrid to be much more effective and sustainable in meeting the growing global\nenergy challenges, it has also brought with it a large number of\nvulnerabilities resulting in breaches of data integrity, confidentiality and\navailability. False data injection (FDI) appears to be among the most critical\ncyberattacks and has been a focal point interest for both research and\nindustry. To this end, this paper presents a comprehensive review in the recent\nadvances of the defence countermeasures of the FDI attacks in the Smart Grid\ninfrastructure. Relevant existing literature are evaluated and compared in\nterms of their theoretical and practical significance to the Smart Grid\ncybersecurity. In conclusion, a range of technical limitations of existing\nfalse data attack detection researches are identified, and a number of future\nresearch directions are recommended.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 05:36:09 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Reda", "Haftu Tasew", ""], ["Anwar", "Adnan", ""], ["Mahmood", "Abdun Naser", ""], ["Tari", "Zahir", ""]]}, {"id": "2103.16139", "submitter": "Antonio J. Pe\\v{n}a", "authors": "Guillermo Lloret-Talavera, Marc Jorda, Harald Servat, Fabian Boemer,\n  Chetan Chauhan, Shigeki Tomishima, Nilesh N. Shah, Antonio J. Pe\\~na", "title": "Enabling Homomorphically Encrypted Inference for Large DNN Models", "comments": "Manuscript accepted for publication in IEEE Transactions on Computers", "journal-ref": null, "doi": "10.1109/TC.2021.3076123", "report-no": null, "categories": "cs.CR cs.LG cs.PF", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The proliferation of machine learning services in the last few years has\nraised data privacy concerns. Homomorphic encryption (HE) enables inference\nusing encrypted data but it incurs 100x-10,000x memory and runtime overheads.\nSecure deep neural network (DNN) inference using HE is currently limited by\ncomputing and memory resources, with frameworks requiring hundreds of gigabytes\nof DRAM to evaluate small models. To overcome these limitations, in this paper\nwe explore the feasibility of leveraging hybrid memory systems comprised of\nDRAM and persistent memory. In particular, we explore the recently-released\nIntel Optane PMem technology and the Intel HE-Transformer nGraph to run large\nneural networks such as MobileNetV2 (in its largest variant) and ResNet-50 for\nthe first time in the literature. We present an in-depth analysis of the\nefficiency of the executions with different hardware and software\nconfigurations. Our results conclude that DNN inference using HE incurs on\nfriendly access patterns for this memory configuration, yielding efficient\nexecutions.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 07:53:34 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 08:36:39 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Lloret-Talavera", "Guillermo", ""], ["Jorda", "Marc", ""], ["Servat", "Harald", ""], ["Boemer", "Fabian", ""], ["Chauhan", "Chetan", ""], ["Tomishima", "Shigeki", ""], ["Shah", "Nilesh N.", ""], ["Pe\u00f1a", "Antonio J.", ""]]}, {"id": "2103.16143", "submitter": "Constantinos Patsakis", "authors": "Fran Casino, Nikolaos Totosis, Theodoros Apostolopoulos, Nikolaos\n  Lykousas, and Constantinos Patsakis", "title": "Analysis and Correlation of Visual Evidence in Campaigns of Malicious\n  Office Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many malware campaigns use Microsoft (MS) Office documents as droppers to\ndownload and execute their malicious payload. Such campaigns often use these\ndocuments because MS Office is installed in billions of devices and that these\nfiles allow the execution of arbitrary VBA code. Recent versions of MS Office\nprevent the automatic execution of VBA macros, so malware authors try to\nconvince users into enabling the content via images that, e.g. forge system or\ntechnical errors. In this work, we leverage these visual elements to construct\nlightweight malware signatures that can be applied with minimal effort. We test\nand validate our approach using an extensive database of malware samples and\nidentify correlations between different campaigns that illustrate that some\ncampaigns are either using the same tools or that there is some collaboration\nbetween them.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 07:56:38 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Casino", "Fran", ""], ["Totosis", "Nikolaos", ""], ["Apostolopoulos", "Theodoros", ""], ["Lykousas", "Nikolaos", ""], ["Patsakis", "Constantinos", ""]]}, {"id": "2103.16216", "submitter": "Aditya Ahuja", "authors": "Aditya Ahuja, Vinay J. Ribeiro, Ranjan Pal", "title": "A Regulatory System for Optimal Legal Transaction Throughput in\n  Cryptocurrency Blockchains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Permissionless blockchain consensus protocols have been designed primarily\nfor defining decentralized economies for the commercial trade of assets, both\nvirtual and physical, using cryptocurrencies. In most instances, the assets\nbeing traded are regulated, which mandates that the legal right to their trade\nand their trade value are determined by the governmental regulator of the\njurisdiction in which the trade occurs. Unfortunately, existing blockchains do\nnot formally recognise proposal of legal cryptocurrency transactions, as part\nof the execution of their respective consensus protocols, resulting in rampant\nillegal activities in the associated crypto-economies. In this contribution, we\nmotivate the need for regulated blockchain consensus protocols with a case\nstudy of the illegal, cryptocurrency based, Silk Road darknet market. We\npresent a novel regulatory framework for blockchain protocols, for ensuring\nlegal transaction confirmation as part of the blockchain distributed consensus.\nAs per our regulatory framework, we derive conditions under which legal\ntransaction throughput supersedes throughput of traditional transactions, which\nare, in the worst case, an indifferentiable mix of legal and illegal\ntransactions. Finally, we show that with a small change to the standard\nblockchain consensus execution policy (appropriately introduced through\nregulation), the legal transaction throughput in the blockchain network can be\nmaximized.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 09:59:59 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Ahuja", "Aditya", ""], ["Ribeiro", "Vinay J.", ""], ["Pal", "Ranjan", ""]]}, {"id": "2103.16235", "submitter": "Husrev Taha Sencar", "authors": "Muhammed Ali Yurdagul and Husrev Taha Sencar", "title": "BLEKeeper: Response Time Behavior Based Man-In-The-Middle Attack\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bluetooth Low Energy (BLE) has become one of the most popular wireless\ncommunication protocols and is used in billions of smart devices. Despite\nseveral security features, the hardware and software limitations of these\ndevices makes them vulnerable to man-in-the-middle (MITM) attacks. Due to the\nuse of these devices in increasingly diverse and safety-critical applications,\nthe capability to detect MITM attacks has become more critical. To address this\nchallenge, we propose the use of the response time behavior of a BLE device\nobserved in relation to select read and write operations and introduce an\nactiveMITM attack detection system that identifies changes in response time.\nOur measurements on several BLE devices show that theirresponse time behavior\nexhibits very high regularity, making it a very reliable attack indicator that\ncannot be concealed by an attacker. Test results show that our system can very\naccurately and quickly detect MITM attacks while requiring a simple learning\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 10:35:57 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Yurdagul", "Muhammed Ali", ""], ["Sencar", "Husrev Taha", ""]]}, {"id": "2103.16295", "submitter": "Siamak Layeghy", "authors": "Seyedehfaezeh Hosseininoorbin, Siamak Layeghy, Mohanad Sarhan, Raja\n  Jurdak, Marius Portmann", "title": "Exploring Edge TPU for Network Intrusion Detection in IoT", "comments": "22 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper explores Google's Edge TPU for implementing a practical network\nintrusion detection system (NIDS) at the edge of IoT, based on a deep learning\napproach. While there are a significant number of related works that explore\nmachine learning based NIDS for the IoT edge, they generally do not consider\nthe issue of the required computational and energy resources. The focus of this\npaper is the exploration of deep learning-based NIDS at the edge of IoT, and in\nparticular the computational and energy efficiency. In particular, the paper\nstudies Google's Edge TPU as a hardware platform, and considers the following\nthree key metrics: computation (inference) time, energy efficiency and the\ntraffic classification performance. Various scaled model sizes of two major\ndeep neural network architectures are used to investigate these three metrics.\nThe performance of the Edge TPU-based implementation is compared with that of\nan energy efficient embedded CPU (ARM Cortex A53). Our experimental evaluation\nshows some unexpected results, such as the fact that the CPU significantly\noutperforms the Edge TPU for small model sizes.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 12:43:57 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Hosseininoorbin", "Seyedehfaezeh", ""], ["Layeghy", "Siamak", ""], ["Sarhan", "Mohanad", ""], ["Jurdak", "Raja", ""], ["Portmann", "Marius", ""]]}, {"id": "2103.16329", "submitter": "Siamak Layeghy", "authors": "Wai Weng Lo, Siamak Layeghy, Mohanad Sarhan, Marcus Gallagher, Marius\n  Portmann", "title": "E-GraphSAGE: A Graph Neural Network based Intrusion Detection System", "comments": "13 pages, 7 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a new network intrusion detection system (NIDS) based on\nGraph Neural Networks (GNNs). GNNs are a relatively new sub-field of deep\nneural networks, which have the unique ability to leverage the inherent\nstructure of graph-based data. Training and evaluation data for NIDSs are\ntypically represented as flow records, which can naturally be represented in a\ngraph format. This establishes the potential and motivation for exploring GNNs\nfor the purpose of network intrusion detection, which is the focus of this\npaper. E-GraphSAGE, our proposed new approach is based on the established\nGraphSAGE model, but provides the necessary modifications in order to support\nedge features for edge classification, and hence the classification of network\nflows into benign and attack classes. An extensive experimental evaluation\nbased on six recent NIDS benchmark datasets shows the excellent performance of\nour E-GraphSAGE based NIDS in comparison with the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 13:21:31 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 07:43:02 GMT"}, {"version": "v3", "created": "Thu, 13 May 2021 10:01:00 GMT"}, {"version": "v4", "created": "Fri, 14 May 2021 01:03:35 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Lo", "Wai Weng", ""], ["Layeghy", "Siamak", ""], ["Sarhan", "Mohanad", ""], ["Gallagher", "Marcus", ""], ["Portmann", "Marius", ""]]}, {"id": "2103.16335", "submitter": "Sebastian Schlor", "authors": "Sebastian Schlor, Michael Hertneck, Stefan Wildhagen and Frank\n  Allg\\\"ower", "title": "Multi-party computation for secure polynomial control", "comments": "7 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encrypted control systems allow to evaluate feedback laws on external servers\nwithout revealing private information about state and input data, the control\nlaw, or the plant. While there are a number of encrypted control schemes\navailable for linear feedback laws, only few results exist for the evaluation\nof more general control laws. Recently, an approach to encrypted polynomial\ncontrol was presented, relying on two-party secret sharing and an inter-server\ncommunication protocol using homomorphic encryption. As homomorphic encryptions\nare much more computationally demanding than secret sharing, they make up for a\ntremendous amount of the overall computational demand of this scheme. For this\nreason, in this paper, we investigate schemes for secure polynomial control\nbased solely on secret sharing. We introduce a novel secure three-party control\nscheme based on three-party computation. Further, we propose a novel $n$-party\ncontrol scheme to securely evaluate polynomial feedback laws of arbitrary\ndegree without inter-server communication. The latter property makes it easier\nto realize the necessary requirement regarding non-collusion of the servers,\nwith which perfect security can be guaranteed. Simulations suggest that the\npresented control schemes are many times less computationally demanding than\nthe two-party scheme mentioned above.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 13:30:38 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Schlor", "Sebastian", ""], ["Hertneck", "Michael", ""], ["Wildhagen", "Stefan", ""], ["Allg\u00f6wer", "Frank", ""]]}, {"id": "2103.16360", "submitter": "Ahaan Dabholkar", "authors": "Ahaan Dabholkar, Sourya Kakarla, Dhiman Saha", "title": "Looney Tunes: Exposing the Lack of DRM Protection in Indian Music\n  Streaming Services", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Numerous studies have shown that streaming is now the most preferred way of\nconsuming multimedia content and this is evidenced by the proliferation in the\nnumber of streaming service providers as well as the exponential growth in\ntheir subscriber base. Riding on the advancements in low cost electronics, high\nspeed communication and extremely cheap data, Over-The-Top (OTT) music\nstreaming is now the norm in the music industry and is worth millions of\ndollars. This is especially true in India where major players offer the so\ncalled freemium models which have active monthly user bases running in to the\nmillions. These services namely, Gaana, Airtel Wynk and JioSaavn attract a\nsignificantly bigger audience than their 100% subscription based peers like\nAmazon Prime Music, Apple Music etc. Given their ubiquity and market dominance,\nit is pertinent to do a systematic analysis of these platforms so as to\nascertain their potential as hotbeds of piracy. This work investigates the\nresilience of the content protection systems of the four biggest music\nstreaming services (by subscriber base) from India, namely Airtel Wynk, Ganna,\nJioSaavn and Hungama. By considering the Digital Rights Management (DRM) system\nemployed by Spotify as a benchmark, we analyse the security of these platforms\nby attempting to steal the streamed content efficiently. Finally, we present a\nholistic overview of the flaws in their security mechanisms and discuss\npossible mitigation strategies. To the best of our knowledge, this work\nconstitutes the first attempt to analyze security of OTT music services from\nIndia. Our results further confirm the time tested belief that security through\nobscurity is not a long term solution and leaves such platforms open to piracy\nand a subsequent loss of revenue for all the stakeholders.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 14:01:45 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Dabholkar", "Ahaan", ""], ["Kakarla", "Sourya", ""], ["Saha", "Dhiman", ""]]}, {"id": "2103.16400", "submitter": "Fabian Boemer", "authors": "Fabian Boemer, Sejun Kim, Gelila Seifu, Fillipe D. M. de Souza, Vinodh\n  Gopal", "title": "Intel HEXL: Accelerating Homomorphic Encryption with Intel AVX512-IFMA52", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern implementations of homomorphic encryption (HE) rely heavily on\npolynomial arithmetic over a finite field. This is particularly true of the\nCKKS, BFV, and BGV HE schemes. Two of the biggest performance bottlenecks in HE\nprimitives and applications are polynomial modular multiplication and the\nforward and inverse number-theoretic transform (NTT). Here, we introduce Intel\nHomomorphic Encryption Acceleration Library (Intel HEXL), a C++ library which\nprovides optimized implementations of polynomial arithmetic for Intel\nprocessors. Intel HEXL takes advantage of the recent Intel Advanced Vector\nExtensions 512 (Intel AVX512) instruction set to provide state-of-the-art\nimplementations of the NTT and modular multiplication. On the forward and\ninverse NTT, Intel HEXL provides up to 7.2x and 6.7x speedup, respectively,\nover a native C++ implementation. Intel HEXL also provides up to 6.0x speedup\non the element-wise vector-vector modular multiplication, and 1.7x speedup on\nthe element-wise vector-scalar modular multiplication. Intel HEXL is available\nopen-source at https://github.com/intel/hexl under the Apache 2.0 license and\nhas been adopted by the Microsoft SEAL and PALISADE homomorphic encryption\nlibraries.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 14:49:44 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 20:07:39 GMT"}, {"version": "v3", "created": "Fri, 9 Jul 2021 20:28:31 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Boemer", "Fabian", ""], ["Kim", "Sejun", ""], ["Seifu", "Gelila", ""], ["de Souza", "Fillipe D. M.", ""], ["Gopal", "Vinodh", ""]]}, {"id": "2103.16437", "submitter": "Simon Kassing", "authors": "Simon Kassing, Hussain Abbas, Laurent Vanbever, Ankit Singla", "title": "Order P4-66: Characterizing and mitigating surreptitious programmable\n  network device exploitation", "comments": "14 pages, 13 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Substantial efforts are invested in improving network security, but the\nthreat landscape is rapidly evolving, particularly with the recent interest in\nprogrammable network hardware. We explore a new security threat, from an\nattacker who has gained control of such devices. While it should be obvious\nthat such attackers can trivially cause substantial damage, the challenge and\nnovelty are in doing so while preventing quick diagnosis by the operator.\n  We find that compromised programmable devices can easily degrade networked\napplications by orders of magnitude, while evading diagnosis by even the most\nsophisticated network diagnosis methods in deployment. Two key observations\nyield this result: (a) targeting a small number of packets is often enough to\ncause disproportionate performance degradation; and (b) new programmable\nhardware is an effective enabler of careful, selective targeting of packets.\nOur results also point to recommendations for minimizing the damage from such\nattacks, ranging from known, easy to implement techniques like encryption and\nredundant requests, to more complex considerations that would potentially limit\nsome intended uses of programmable hardware. For data center contexts, we also\ndiscuss application-aware monitoring and response as a potential mitigation.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 15:34:37 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 09:51:53 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Kassing", "Simon", ""], ["Abbas", "Hussain", ""], ["Vanbever", "Laurent", ""], ["Singla", "Ankit", ""]]}, {"id": "2103.16443", "submitter": "Frances Cleary Ms", "authors": "Frances Cleary, David Henshall, Sasitharan Balasubramaniam", "title": "On-body Edge Computing through E-Textile Programmable Logic Array", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR cs.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  E-textiles has received tremendous attention in recent years due to the\ncapability of integrating sensors into a garment to provide high precision\nsensing of the human body. Besides sensing, a number of solutions for e-textile\ngarments have also integrated wireless interfaces allowing these sensing data\nto be transmitted and also sensors that allow users to provide instructions\nthrough touching. While this has provided a new level of sensing that can\nresult in unprecedented applications, there has been little attention placed on\non-body computing for e-textiles. Facilitating computing on e-textiles can\nresult in a new form of On-body Edge Computing, where sensor information are\nprocessed very close to the body before being transmitted to an external device\nor wireless access point. This form of computing can provide new security and\ndata privacy capabilities and at the same time provide opportunities for new\nenergy harvesting mechanisms to process the data through the garment. This\npaper proposes this concept through embroidered Programmable Logic Array (PLA)\nintegrated into e-textiles. In the way that PLAs have programmable logic\ncircuits by interconnecting different AND, NOT and OR gates, we propose\ne-textile based gates that are sewn into a garment and connected through\nconductive thread stitching. Two designs are proposed and this includes Single\nand Multi-Layered PLA. Experimental validations have been conducted at the\nindividual gates as well as the entire PLA circuits to determine the voltage\nutilization as well as logic computing reliability. Our proposed approach can\nusher in a new form of On-Body Edge Computing for e-textile garments for future\nwearable technologies\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 15:42:54 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Cleary", "Frances", ""], ["Henshall", "David", ""], ["Balasubramaniam", "Sasitharan", ""]]}, {"id": "2103.16640", "submitter": "Samuel Maddock", "authors": "Graham Cormode, Samuel Maddock, Carsten Maple", "title": "Frequency Estimation under Local Differential Privacy [Experiments,\n  Analysis and Benchmarks]", "comments": "13 pages; Updated figures (7,8,10) and minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Private collection of statistics from a large distributed population is an\nimportant problem, and has led to large scale deployments from several leading\ntechnology companies. The dominant approach requires each user to randomly\nperturb their input, leading to guarantees in the local differential privacy\nmodel. In this paper, we place the various approaches that have been suggested\ninto a common framework, and perform an extensive series of experiments to\nunderstand the tradeoffs between different implementation choices. Our\nconclusion is that for the core problems of frequency estimation and heavy\nhitter identification, careful choice of algorithms can lead to very effective\nsolutions that scale to millions of users\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 19:23:20 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 16:09:31 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Cormode", "Graham", ""], ["Maddock", "Samuel", ""], ["Maple", "Carsten", ""]]}, {"id": "2103.16696", "submitter": "Shihao Yan", "authors": "Shihao Yan, Xiaobo Zhou, Derrick Wing Kwan Ng, Jinhong Yuan, and\n  Naofal Al-Dhahir", "title": "Intelligent Reflecting Surface for Wireless Communication Security and\n  Privacy", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.ET math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent reflection surface (IRS) is emerging as a promising technique for\nfuture wireless communications. Considering its excellent capability in\ncustomizing the channel conditions via energy-focusing and energy-nulling, it\nis an ideal technique for enhancing wireless communication security and\nprivacy, through the theories of physical layer security and covert\ncommunications, respectively. In this article, we first present some results on\napplying IRS to improve the average secrecy rate in wiretap channels, to enable\nperfect communication covertness, and to deliberately create extra randomness\nin wireless propagations for hiding active wireless transmissions. Then, we\nidentify multiple challenges for future research to fully unlock the benefits\noffered by IRS in the context of physical layer security and covert\ncommunications. With the aid of extensive numerical studies, we demonstrate the\nnecessity of designing the amplitudes of the IRS elements in wireless\ncommunications with the consideration of security and privacy, where the\noptimal values are not always $1$ as commonly adopted in the literature.\nFurthermore, we reveal the tradeoff between the achievable secrecy performance\nand the estimation accuracy of the IRS's channel state information (CSI) at\nboth the legitimate and malicious users, which presents the fundamental\nresource allocation challenge in the context of IRS-aided physical layer\nsecurity. Finally, a passive channel estimation methodology exploiting deep\nneural networks and scene images is discussed as a potential solution to\nenabling CSI availability without utilizing resource-hungry pilots. This\nmethodology serves as a visible pathway to significantly improving the covert\ncommunication rate in IRS-aided wireless networks.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 21:42:50 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Yan", "Shihao", ""], ["Zhou", "Xiaobo", ""], ["Ng", "Derrick Wing Kwan", ""], ["Yuan", "Jinhong", ""], ["Al-Dhahir", "Naofal", ""]]}, {"id": "2103.16787", "submitter": "Ryan Rogers", "authors": "Adrian Rivera Cardoso, Ryan Rogers", "title": "Differentially Private Histograms under Continual Observation: Streaming\n  Selection into the Unknown", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the continuous observation privacy setting from Dwork et al.\n'10 and Chan et al. '11 by allowing each event in a stream to be a subset of\nsome (possibly unknown) universe of items. We design differentially private\n(DP) algorithms for histograms in several settings, including top-$k$\nselection, with privacy loss that scales with polylog$(T)$, where $T$ is the\nmaximum length of the input stream. We present a meta-algorithm that can use\nexisting one-shot top-$k$ DP algorithms as a subroutine to continuously release\nprivate histograms from a stream. Further, we present more practical DP\nalgorithms for two settings: 1) continuously releasing the top-$k$ counts from\na histogram over a known domain when an event can consist of an arbitrary\nnumber of items, and 2) continuously releasing histograms over an unknown\ndomain when an event has a limited number of items.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 03:13:15 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Cardoso", "Adrian Rivera", ""], ["Rogers", "Ryan", ""]]}, {"id": "2103.16898", "submitter": "Wojciech Ozga", "authors": "Wojciech Ozga, Do Le Quoc, Christof Fetzer", "title": "Perun: Secure Multi-Stakeholder Machine Learning Framework with GPU\n  Support", "comments": null, "journal-ref": "The 35th Annual IFIP Conference on Data and Applications Security\n  and Privacy (DBSec 2021)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Confidential multi-stakeholder machine learning (ML) allows multiple parties\nto perform collaborative data analytics while not revealing their intellectual\nproperty, such as ML source code, model, or datasets. State-of-the-art\nsolutions based on homomorphic encryption incur a large performance overhead.\nHardware-based solutions, such as trusted execution environments (TEEs),\nsignificantly improve the performance in inference computations but still\nsuffer from low performance in training computations, e.g., deep neural\nnetworks model training, because of limited availability of protected memory\nand lack of GPU support.\n  To address this problem, we designed and implemented Perun, a framework for\nconfidential multi-stakeholder machine learning that allows users to make a\ntrade-off between security and performance. Perun executes ML training on\nhardware accelerators (e.g., GPU) while providing security guarantees using\ntrusted computing technologies, such as trusted platform module and integrity\nmeasurement architecture. Less compute-intensive workloads, such as inference,\nexecute only inside TEE, thus at a lower trusted computing base. The evaluation\nshows that during the ML training on CIFAR-10 and real-world medical datasets,\nPerun achieved a 161x to 1560x speedup compared to a pure TEE-based approach.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 08:31:07 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Ozga", "Wojciech", ""], ["Quoc", "Do Le", ""], ["Fetzer", "Christof", ""]]}, {"id": "2103.16920", "submitter": "Hossein Pakdel", "authors": "Reza Fotohi and Hossein Pakdel", "title": "A Lightweight and Scalable Physical Layer Attack Detection Mechanism for\n  the Internet of Things (IoT) Using Hybrid Security Schema", "comments": "20 pages, 6 Figures, 8 Tables, Wireless Pers Commun (2021)", "journal-ref": null, "doi": "10.1007/s11277-021-08388-1", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Internet of Things, also known as the IoT, refers to the billions of\ndevices around the world that are now connected to the Internet, collecting and\nsharing data. The amount of data collected through IoT sensors must be\ncompletely securely controlled. To protect the information collected by IoT\nsensors, a lightweight method called Discover the Flooding Attack-RPL (DFA-RPL)\nhas been proposed. The proposed DFA-RPL method identifies intrusive nodes in\nseveral steps to exclude them from continuing routing operations. Thus, in the\nDFA-RPL method, it first builds a cluster and selects the most appropriate node\nas a cluster head in DODAG, then, due to the vulnerability of the RPL protocol\nto Flooding attacks, it uses an ant colony algorithm (ACO) using five steps to\ndetect attacks. Use Flooding to prevent malicious activity on the IoT network.\nIn other words, if it detects a node as malicious, it puts that node on the\ndetention list and quarantines it for a certain period of time. The results\nobtained from the simulation show the superiority of the proposed method in\nterms of Packet Delivery Rate, Detection Rate, False Positive Rate, and False\nNegative Rate compared to IRAD and REATO methods.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 09:18:06 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Fotohi", "Reza", ""], ["Pakdel", "Hossein", ""]]}, {"id": "2103.16930", "submitter": "Cengiz Acart\\\"urk", "authors": "Emrah Tufan, Cihangir Tezcan, Cengiz Acart\\\"urk", "title": "Anomaly-Based Intrusion Detection by Machine Learning: A Case Study on\n  Probing Attacks to an Institutional Network", "comments": "15 pages, published in IEEE Access 2021,\n  https://ieeexplore.ieee.org/document/9387304", "journal-ref": "IEEE Access 2021", "doi": "10.1109/ACCESS.2021.3068961", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cyber attacks constitute a significant threat to organizations with\nimplications ranging from economic, reputational, and legal consequences. As\ncybercriminals' techniques get sophisticated, information security\nprofessionals face a more significant challenge to protecting information\nsystems. In today's interconnected realm of computer systems, each attack\nvector has a network dimension. The present study investigates network\nintrusion attempts with anomaly-based machine learning models to provide better\nprotection than the conventional misuse-based models. Two models, namely an\nensemble learning model and a convolutional neural network model, were built\nand implemented on a data set gathered from a real-life, institutional\nproduction environment. To demonstrate the models' reliability and validity,\nthey were applied to the UNSW-NB15 benchmarking data set. The type of attack\nwas limited to probing attacks to keep the scope of the study manageable. The\nfindings revealed high accuracy rates, the CNN model being slightly more\naccurate.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 09:27:34 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Tufan", "Emrah", ""], ["Tezcan", "Cihangir", ""], ["Acart\u00fcrk", "Cengiz", ""]]}, {"id": "2103.17028", "submitter": "Hassan Noura", "authors": "Jean-Paul A. Yaacoub, Hassan N. Noura, Ola Salman and Ali Chehab", "title": "Digital Forensics vs. Anti-Digital Forensics: Techniques, Limitations\n  and Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The number of cyber attacks has increased tremendously in the last few years.\nThis resulted into both human and financial losses at the individual and\norganization levels. Recently, cyber-criminals are leveraging new skills and\ncapabilities by employing anti-forensics activities, techniques and tools to\ncover their tracks and evade any possible detection. Consequently,\ncyber-attacks are becoming more efficient and more sophisticated. Therefore,\ntraditional cryptographic and non-cryptographic solutions and access control\nsystems are no longer enough to prevent such cyber attacks, especially in terms\nof acquiring evidence for attack investigation. Hence, the need for\nwell-defined, sophisticated, and advanced forensics investigation tools are\nhighly required to track down cyber criminals and to reduce the number of cyber\ncrimes. This paper reviews the different forensics and anti-forensics methods,\ntools, techniques, types, and challenges, while also discussing the rise of the\nanti-anti-forensics as a new forensics protection mechanism against\nanti-forensics activities. This would help forensics investigators to better\nunderstand the different anti-forensics tools, methods and techniques that\ncyber criminals employ while launching their attacks. Moreover, the limitations\nof the current forensics techniques are discussed, especially in terms of\nissues and challenges. Finally, this paper presents a holistic view from a\nliterature point of view over the forensics domain and also helps other fellow\ncolleagues in their quest to further understand the digital forensics domain.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 12:27:08 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Yaacoub", "Jean-Paul A.", ""], ["Noura", "Hassan N.", ""], ["Salman", "Ola", ""], ["Chehab", "Ali", ""]]}, {"id": "2103.17059", "submitter": "Fabio De Gaspari", "authors": "Fabio De Gaspari, Dorjan Hitaj, Giulio Pagnotta, Lorenzo De Carli,\n  Luigi V. Mancini", "title": "Reliable Detection of Compressed and Encrypted Data", "comments": "12 pages, 8 figures. arXiv admin note: substantial text overlap with\n  arXiv:2010.07754", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Several cybersecurity domains, such as ransomware detection, forensics and\ndata analysis, require methods to reliably identify encrypted data fragments.\nTypically, current approaches employ statistics derived from byte-level\ndistribution, such as entropy estimation, to identify encrypted fragments.\nHowever, modern content types use compression techniques which alter data\ndistribution pushing it closer to the uniform distribution. The result is that\ncurrent approaches exhibit unreliable encryption detection performance when\ncompressed data appears in the dataset. Furthermore, proposed approaches are\ntypically evaluated over few data types and fragment sizes, making it hard to\nassess their practical applicability. This paper compares existing statistical\ntests on a large, standardized dataset and shows that current approaches\nconsistently fail to distinguish encrypted and compressed data on both small\nand large fragment sizes. We address these shortcomings and design EnCoD, a\nlearning-based classifier which can reliably distinguish compressed and\nencrypted data. We evaluate EnCoD on a dataset of 16 different file types and\nfragment sizes ranging from 512B to 8KB. Our results highlight that EnCoD\noutperforms current approaches by a wide margin, with accuracy ranging from ~82\nfor 512B fragments up to ~92 for 8KB data fragments. Moreover, EnCoD can\npinpoint the exact format of a given data fragment, rather than performing only\nbinary classification like previous approaches.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 13:27:28 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["De Gaspari", "Fabio", ""], ["Hitaj", "Dorjan", ""], ["Pagnotta", "Giulio", ""], ["De Carli", "Lorenzo", ""], ["Mancini", "Luigi V.", ""]]}, {"id": "2103.17091", "submitter": "David M\\\"odinger", "authors": "David M\\\"odinger and Alexander He{\\ss} and Franz J. Hauck", "title": "Arbitrary Length k-Anonymous Dining-Cryptographers Communication", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dining-cryptographers networks (DCN) can achieve information-theoretical\nprivacy. Unfortunately, they are not well suited for peer-to-peer networks as\nthey are used in blockchain applications to disseminate transactions and blocks\namong participants. In previous but preliminary work, we proposed a threephase\napproach with an initial phase based on a DCN with a group size of k while\nlater phases take care of the actual broadcast within a peer-to-peer network.\nThis paper describes our DCN protocol in detail and adds a performance\nevaluation powered by our proof-of-concept implementation. Our contributions\nare (i) an extension of the DCN protocol by von Ahn for fair delivery of\narbitrarily long messages sent by potentially multiple senders, (ii) a privacy\nand security analysis of this extension, (iii) various performance optimisation\nespecially for best-case operation, and (iv) a performance evaluation. The\nlatter uses a latency of 100 ms and a bandwidth limit of 50 Mbit/s between\nparticipants. The interquartile range of the largest test of the highly secured\nversion took 35s+-1.25s for a full run. All tests of the optimized common-case\nmode show the dissemination of a message within 0.5s+-0.1s. These results\ncompare favourably to previously established protocols for k-anonymous\ntransmission of fixed size messages, outperforming the original protocol for\nmessages as small as 2 KiB.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 14:03:15 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["M\u00f6dinger", "David", ""], ["He\u00df", "Alexander", ""], ["Hauck", "Franz J.", ""]]}, {"id": "2103.17096", "submitter": "Axel Oehmichen PhD", "authors": "Axel Oehmichen, Florian Guitton, Cedric Wahl, Bertrand Foing, Damian\n  Tziamtzis, Yike Guo", "title": "MOAI: A methodology for evaluating the impact of indoor airflow in the\n  transmission of COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Epidemiology models play a key role in understanding and responding to the\nCOVID-19 pandemic. In order to build those models, scientists need to\nunderstand contributing factors and their relative importance. A large strand\nof literature has identified the importance of airflow to mitigate droplets and\nfar-field aerosol transmission risks. However, the specific factors\ncontributing to higher or lower contamination in various settings have not been\nclearly defined and quantified. As part of the MOAI project\n(https://moaiapp.com), we are developing a privacy-preserving test and trace\napp to enable infection cluster investigators to get in touch with patients\nwithout having to know their identity. This approach allows involving users in\nthe fight against the pandemic by contributing additional information in the\nform of anonymous research questionnaires. We first describe how the\nquestionnaire was designed, and the synthetic data was generated based on a\nreview we carried out on the latest available literature. We then present a\nmodel to evaluate the risk exposition of a user for a given setting. We finally\npropose a temporal addition to the model to evaluate the risk exposure over\ntime for a given user.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 14:06:09 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Oehmichen", "Axel", ""], ["Guitton", "Florian", ""], ["Wahl", "Cedric", ""], ["Foing", "Bertrand", ""], ["Tziamtzis", "Damian", ""], ["Guo", "Yike", ""]]}, {"id": "2103.17122", "submitter": "Piotr \\.Zelasko", "authors": "Piotr \\.Zelasko, Sonal Joshi, Yiwen Shao, Jesus Villalba, Jan Trmal,\n  Najim Dehak, Sanjeev Khudanpur", "title": "Adversarial Attacks and Defenses for Speech Recognition Systems", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CR cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ubiquitous presence of machine learning systems in our lives necessitates\nresearch into their vulnerabilities and appropriate countermeasures. In\nparticular, we investigate the effectiveness of adversarial attacks and\ndefenses against automatic speech recognition (ASR) systems. We select two ASR\nmodels - a thoroughly studied DeepSpeech model and a more recent Espresso\nframework Transformer encoder-decoder model. We investigate two threat models:\na denial-of-service scenario where fast gradient-sign method (FGSM) or weak\nprojected gradient descent (PGD) attacks are used to degrade the model's word\nerror rate (WER); and a targeted scenario where a more potent imperceptible\nattack forces the system to recognize a specific phrase. We find that the\nattack transferability across the investigated ASR systems is limited. To\ndefend the model, we use two preprocessing defenses: randomized smoothing and\nWaveGAN-based vocoder, and find that they significantly improve the model's\nadversarial robustness. We show that a WaveGAN vocoder can be a useful\ncountermeasure to adversarial attacks on ASR systems - even when it is jointly\nattacked with the ASR, the target phrases' word error rate is high.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 14:44:58 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["\u017belasko", "Piotr", ""], ["Joshi", "Sonal", ""], ["Shao", "Yiwen", ""], ["Villalba", "Jesus", ""], ["Trmal", "Jan", ""], ["Dehak", "Najim", ""], ["Khudanpur", "Sanjeev", ""]]}]