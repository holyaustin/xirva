[{"id": "1504.00065", "submitter": "Fragkiskos Koufogiannis", "authors": "Fragkiskos Koufogiannis, Shuo Han, George J. Pappas", "title": "Optimality of the Laplace Mechanism in Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the highly interconnected realm of Internet of Things, exchange of\nsensitive information raises severe privacy concerns. The Laplace mechanism --\nadding Laplace-distributed artificial noise to sensitive data -- is one of the\nwidely used methods of providing privacy guarantees within the framework of\ndifferential privacy. In this work, we present Lipschitz privacy, a slightly\ntighter version of differential privacy. We prove that the Laplace mechanism is\noptimal in the sense that it minimizes the mean-squared error for identity\nqueries which provide privacy with respect to the $\\ell_{1}$-norm. In addition\nto the $\\ell_{1}$-norm which respects individuals' participation, we focus on\nthe use of the $\\ell_{2}$-norm which provides privacy of high-dimensional data.\nA variation of the Laplace mechanism is proven to have the optimal mean-squared\nerror from the identity query. Finally, the optimal mechanism for the scenario\nin which individuals submit their high-dimensional sensitive data is derived.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2015 23:28:16 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2015 20:49:32 GMT"}], "update_date": "2015-04-09", "authors_parsed": [["Koufogiannis", "Fragkiskos", ""], ["Han", "Shuo", ""], ["Pappas", "George J.", ""]]}, {"id": "1504.00429", "submitter": "Fragkiskos Koufogiannis", "authors": "Fragkiskos Koufogiannis, Shuo Han, George J. Pappas", "title": "Gradual Release of Sensitive Data under Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the problem of releasing sensitive data under differential\nprivacy when the privacy level is subject to change over time. Existing work\nassumes that privacy level is determined by the system designer as a fixed\nvalue before sensitive data is released. For certain applications, however,\nusers may wish to relax the privacy level for subsequent releases of the same\ndata after either a re-evaluation of the privacy concerns or the need for\nbetter accuracy. Specifically, given a database containing sensitive data, we\nassume that a response $y_1$ that preserves $\\epsilon_{1}$-differential privacy\nhas already been published. Then, the privacy level is relaxed to $\\epsilon_2$,\nwith $\\epsilon_2 > \\epsilon_1$, and we wish to publish a more accurate response\n$y_2$ while the joint response $(y_1, y_2)$ preserves $\\epsilon_2$-differential\nprivacy. How much accuracy is lost in the scenario of gradually releasing two\nresponses $y_1$ and $y_2$ compared to the scenario of releasing a single\nresponse that is $\\epsilon_{2}$-differentially private? Our results show that\nthere exists a composite mechanism that achieves \\textit{no loss} in accuracy.\nWe consider the case in which the private data lies within $\\mathbb{R}^{n}$\nwith an adjacency relation induced by the $\\ell_{1}$-norm, and we focus on\nmechanisms that approximate identity queries. We show that the same accuracy\ncan be achieved in the case of gradual release through a mechanism whose\noutputs can be described by a \\textit{lazy Markov stochastic process}. This\nstochastic process has a closed form expression and can be efficiently sampled.\nOur results are applicable beyond identity queries. To this end, we demonstrate\nthat our results can be applied in several cases, including Google's RAPPOR\nproject, trading of sensitive data, and controlled transmission of private data\nin a social network.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2015 02:03:20 GMT"}], "update_date": "2015-04-06", "authors_parsed": [["Koufogiannis", "Fragkiskos", ""], ["Han", "Shuo", ""], ["Pappas", "George J.", ""]]}, {"id": "1504.00601", "submitter": "Subhash Kak", "authors": "Subhash Kak", "title": "Oblivious Transfer Protocol with Verification", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although random sequences can be used to generate probability events, they\ncome with the risk of cheating in an unsupervised situation. In such cases, the\noblivious transfer protocol may be used and this paper presents a variation to\nthe DH key-exchange to serve as this protocol. A method to verify the\ncorrectness of the procedure, without revealing the random numbers used by the\ntwo parties, is also proposed.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2015 16:05:22 GMT"}], "update_date": "2015-04-03", "authors_parsed": [["Kak", "Subhash", ""]]}, {"id": "1504.00619", "submitter": "Moreno Ambrosin", "authors": "Moreno Ambrosin and Mauro Conti and Tooska Dargahi", "title": "On the Feasibility of Attribute-Based Encryption on Smartphone Devices", "comments": "Accepted at the 1st International Workshop on IoT challenges in\n  Mobile and Industrial Systems (IoT-Sys 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribute-Based Encryption (ABE) is a powerful cryptographic tool that allows\nfine-grained access control over data. Due to its features, ABE has been\nadopted in several applications, such as encrypted storage or access control\nsystems. Recently, researchers argued about the non acceptable performance of\nABE when implemented on mobile devices. Indeed, the non feasibility of ABE on\nmobile devices would hinder the deployment of novel protocols and\nservices--that could instead exploit the full potential of such devices.\nHowever, we believe the conclusion of non usability was driven by a not-very\nefficient implementation.\n  In this paper, we want to shine a light on this concern by studying the\nfeasibility of applying ABE on smartphone devices. In particular, we\nimplemented AndrABEn, an ABE library for Android operating system. Our library\nis written in the C language and implements two main ABE schemes:\nCiphertext-Policy Attribute-Based Encryption, and Key- Policy Attribute-Based\nEncryption. We also run a thorough set of experimental evaluation for AndrABEn,\nand compare it with the current state-of-the-art (considering the same\nexperimental setting). The results confirm the possibility to effectively use\nABE on smartphone devices, requiring an acceptable amount of resources in terms\nof computations and energy consumption. Since the current state-of-the-art\nclaims the non feasibility of ABE on mobile devices, we believe that our study\n(together with the AndrABEn library that we made available online) is a key\nresult that will pave the way for researchers and developers to design and\nimplement novel protocols and applications for mobile devices.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2015 17:14:37 GMT"}], "update_date": "2015-04-03", "authors_parsed": [["Ambrosin", "Moreno", ""], ["Conti", "Mauro", ""], ["Dargahi", "Tooska", ""]]}, {"id": "1504.00943", "submitter": "Adrian Kent", "authors": "Emily Adlam and Adrian Kent", "title": "Deterministic Relativistic Quantum Bit Commitment", "comments": null, "journal-ref": "Int. J. Quantum Inform. 13, 1550029 (2015)", "doi": "10.1142/S021974991550029X", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe new unconditionally secure bit commitment schemes whose security\nis based on Minkowski causality and the monogamy of quantum entanglement. We\nfirst describe an ideal scheme that is purely deterministic, in the sense that\nneither party needs to generate any secret randomness at any stage. We also\ndescribe a variant that allows the committer to proceed deterministically,\nrequires only local randomness generation from the receiver, and allows the\ncommitment to be verified in the neighbourhood of the unveiling point. We show\nthat these schemes still offer near-perfect security in the presence of losses\nand errors, which can be made perfect if the committer uses an extra single\nrandom secret bit. We discuss scenarios where these advantages are significant.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2015 21:38:24 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Adlam", "Emily", ""], ["Kent", "Adrian", ""]]}, {"id": "1504.00944", "submitter": "Adrian Kent", "authors": "Emily Adlam and Adrian Kent", "title": "Device-Independent Relativistic Quantum Bit Commitment", "comments": null, "journal-ref": "Phys. Rev. A 92, 022315 (2015)", "doi": "10.1103/PhysRevA.92.022315", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the possibility of device-independent relativistic quantum bit\ncommitment. We note the potential threat of {\\it location attacks}, in which\nthe behaviour of untrusted devices used in relativistic quantum cryptography\ndepends on their space-time location. We describe relativistic quantum bit\ncommitment schemes that are immune to these attacks, and show that these\nschemes offer device-independent security against hypothetical post-quantum\nadversaries subject only to the no-signalling principle. We compare a\nrelativistic classical bit commitment scheme with similar features, and note\nsome possible advantages of the quantum schemes.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2015 21:40:43 GMT"}], "update_date": "2015-08-10", "authors_parsed": [["Adlam", "Emily", ""], ["Kent", "Adrian", ""]]}, {"id": "1504.01042", "submitter": "Xianghui Cao", "authors": "Wenlong Shen, Bo Yin, Xianghui Cao, and Yu Cheng", "title": "A Distributed Secure Outsourcing Scheme for Solving Linear Algebraic\n  Equations in Ad Hoc Clouds", "comments": "This paper has been withdrawn by the authors due to incompleteness of\n  the security analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging ad hoc clouds form a new cloud computing paradigm by leveraging\nuntapped local computation and storage resources. An important application\napplication over ad hoc clouds is outsourcing computationally intensive\nproblems to nearby cloud agents to solve in a distributed manner.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2015 19:32:14 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2015 02:48:53 GMT"}, {"version": "v3", "created": "Tue, 16 Aug 2016 15:17:48 GMT"}, {"version": "v4", "created": "Mon, 29 Aug 2016 03:19:25 GMT"}], "update_date": "2016-08-30", "authors_parsed": [["Shen", "Wenlong", ""], ["Yin", "Bo", ""], ["Cao", "Xianghui", ""], ["Cheng", "Yu", ""]]}, {"id": "1504.01099", "submitter": "Muhammad Asad", "authors": "Muhammad Asad Khan, Amir Ali Khan, Fauzan Mirza", "title": "CRT and Fixed Patterns in Combinatorial Sequences", "comments": "New results on finite fields theory of combinatorial sequences and\n  their CRT based analysis. arXiv admin note: substantial text overlap with\n  arXiv:1503.00943", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, new context of Chinese Remainder Theorem (CRT) based analysis\nof combinatorial sequence generators has been presented. CRT is exploited to\nestablish fixed patterns in LFSR sequences and underlying cyclic structures of\nfinite fields. New methodology of direct computations of DFT spectral points in\nhigher finite fields from known DFT spectra points of smaller constituent\nfields is also introduced. Novel approach of CRT based structural analysis of\nLFSR based combinatorial sequence is given both in time and frequency domain.\nThe proposed approach is demonstrated on some examples of combiner generators\nand is scalable to general configuration of combiner generators.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2015 09:05:03 GMT"}], "update_date": "2015-04-07", "authors_parsed": [["Khan", "Muhammad Asad", ""], ["Khan", "Amir Ali", ""], ["Mirza", "Fauzan", ""]]}, {"id": "1504.01101", "submitter": "Manoj Mishra", "authors": "Manoj Mishra, Tanmay Sharma, Bikash K. Dey, Vinod M. Prabhakaran", "title": "Private Data Transfer over a Broadcast Channel", "comments": "To be presented at IEEE International Symposium on Information Theory\n  (ISIT 2015), Hong Kong", "journal-ref": null, "doi": "10.1109/ISIT.2015.7282676", "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the following private data transfer problem: Alice has a database of\nfiles. Bob and Cathy want to access a file each from this database (which may\nor may not be the same file), but each of them wants to ensure that their\nchoices of file do not get revealed even if Alice colludes with the other user.\nAlice, on the other hand, wants to make sure that each of Bob and Cathy does\nnot learn any more information from the database than the files they demand\n(the identities of which will be unknown to her). Moreover, they should not\nlearn any information about the other files even if they collude.\n  It turns out that it is impossible to accomplish this if Alice, Bob, and\nCathy have access only to private randomness and noiseless communication links.\nWe consider this problem when a binary erasure broadcast channel with\nindependent erasures is available from Alice to Bob and Cathy in addition to a\nnoiseless public discussion channel. We study the\nfile-length-per-broadcast-channel-use rate in the honest-but-curious model. We\nfocus on the case when the database consists of two files, and obtain the\noptimal rate. We then extend to the case of larger databases, and give upper\nand lower bounds on the optimal rate.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2015 09:12:40 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2015 11:52:07 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Mishra", "Manoj", ""], ["Sharma", "Tanmay", ""], ["Dey", "Bikash K.", ""], ["Prabhakaran", "Vinod M.", ""]]}, {"id": "1504.01175", "submitter": "Igor Semaev", "authors": "Igor Semaev", "title": "New algorithm for the discrete logarithm problem on elliptic curves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC math.AC math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new algorithms for computing discrete logarithms on elliptic curves defined\nover finite fields is suggested. It is based on a new method to find zeroes of\nsummation polynomials. In binary elliptic curves one is to solve a cubic system\nof Boolean equations. Under a first fall degree assumption the regularity\ndegree of the system is at most $4$. Extensive experimental data which supports\nthe assumption is provided. An heuristic analysis suggests a new asymptotical\ncomplexity bound $2^{c\\sqrt{n\\ln n}}, c\\approx 1.69$ for computing discrete\nlogarithms on an elliptic curve over a field of size $2^n$. For several binary\nelliptic curves recommended by FIPS the new method performs better than\nPollard's.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2015 00:19:59 GMT"}], "update_date": "2015-04-07", "authors_parsed": [["Semaev", "Igor", ""]]}, {"id": "1504.01185", "submitter": "Guoru Ding", "authors": "Linyuan Zhang, Guoru Ding, Qihui Wu, Yulong Zou, Zhu Han, and Jinlong\n  Wang", "title": "Byzantine Attack and Defense in Cognitive Radio Networks: A Survey", "comments": "Accepted by IEEE Communications Surveys and Tutoirals", "journal-ref": null, "doi": "10.1109/COMST.2015.2422735", "report-no": null, "categories": "cs.NI cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Byzantine attack in cooperative spectrum sensing (CSS), also known as the\nspectrum sensing data falsification (SSDF) attack in the literature, is one of\nthe key adversaries to the success of cognitive radio networks (CRNs). In the\npast couple of years, the research on the Byzantine attack and defense\nstrategies has gained worldwide increasing attention. In this paper, we provide\na comprehensive survey and tutorial on the recent advances in the Byzantine\nattack and defense for CSS in CRNs. Specifically, we first briefly present the\npreliminaries of CSS for general readers, including signal detection\ntechniques, hypothesis testing, and data fusion. Second, we analyze the spear\nand shield relation between Byzantine attack and defense from three aspects:\nthe vulnerability of CSS to attack, the obstacles in CSS to defense, and the\ngames between attack and defense. Then, we propose a taxonomy of the existing\nByzantine attack behaviors and elaborate on the corresponding attack\nparameters, which determine where, who, how, and when to launch attacks. Next,\nfrom the perspectives of homogeneous or heterogeneous scenarios, we classify\nthe existing defense algorithms, and provide an in-depth tutorial on the\nstate-of-the-art Byzantine defense schemes, commonly known as robust or secure\nCSS in the literature. Furthermore, we highlight the unsolved research\nchallenges and depict the future research directions.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2015 02:04:30 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Zhang", "Linyuan", ""], ["Ding", "Guoru", ""], ["Wu", "Qihui", ""], ["Zou", "Yulong", ""], ["Han", "Zhu", ""], ["Wang", "Jinlong", ""]]}, {"id": "1504.01287", "submitter": "Vijay Gadepally", "authors": "Vijay Gadepally, Braden Hancock and Benjamin Kaiser, Jeremy Kepner,\n  Pete Michaleas, Mayank Varia, Arkady Yerukhimovich", "title": "Computing on Masked Data to improve the Security of Big Data", "comments": "6 pages, Accepted to IEEE HST Conference", "journal-ref": null, "doi": "10.1109/THS.2015.7225312", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organizations that make use of large quantities of information require the\nability to store and process data from central locations so that the product\ncan be shared or distributed across a heterogeneous group of users. However,\nrecent events underscore the need for improving the security of data stored in\nsuch untrusted servers or databases. Advances in cryptographic techniques and\ndatabase technologies provide the necessary security functionality but rely on\na computational model in which the cloud is used solely for storage and\nretrieval. Much of big data computation and analytics make use of signal\nprocessing fundamentals for computation. As the trend of moving data storage\nand computation to the cloud increases, homeland security missions should\nunderstand the impact of security on key signal processing kernels such as\ncorrelation or thresholding. In this article, we propose a tool called\nComputing on Masked Data (CMD), which combines advances in database\ntechnologies and cryptographic tools to provide a low overhead mechanism to\noffload certain mathematical operations securely to the cloud. This article\ndescribes the design and development of the CMD tool.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2015 14:21:49 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Gadepally", "Vijay", ""], ["Hancock", "Braden", ""], ["Kaiser", "Benjamin", ""], ["Kepner", "Jeremy", ""], ["Michaleas", "Pete", ""], ["Varia", "Mayank", ""], ["Yerukhimovich", "Arkady", ""]]}, {"id": "1504.01358", "submitter": "Logan Washbourne", "authors": "Logan Washbourne", "title": "A Survey of P2P Network Security", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a review of peer-to-peer network security. Popular for\nsharing of multimedia files, these networks carry risks and vulnerabilities\nrelating to data integrity, spyware, adware, and unwanted files. Further\nattacks include those of forgery, pollution, repudiation, membership and\nEclipse attacks, neighbor selection attacks, Sybil, DoS, and omission attacks.\nWe review some protection mechanisms that have been devised.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2015 19:10:03 GMT"}], "update_date": "2015-04-07", "authors_parsed": [["Washbourne", "Logan", ""]]}, {"id": "1504.01614", "submitter": "Kittipong Kittichokechai", "authors": "Kittipong Kittichokechai and Giuseppe Caire", "title": "Secret key-based Authentication with a Privacy Constraint", "comments": "8 pages, 2 figures, to be presented at ISIT 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider problems of authentication using secret key generation under a\nprivacy constraint on the enrolled source data. An adversary who has access to\nthe stored description and correlated side information tries to deceive the\nauthentication as well as learn about the source. We characterize the optimal\ntradeoff between the compression rate of the stored description, the leakage\nrate of the source data, and the exponent of the adversary's maximum false\nacceptance probability. The related problem of secret key generation with a\nprivacy constraint is also studied where the optimal tradeoff between the\ncompression rate, leakage rate, and secret key rate is characterized. It\nreveals a connection between the optimal secret key rate and security of the\nauthentication system.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2015 14:25:47 GMT"}], "update_date": "2015-04-08", "authors_parsed": [["Kittichokechai", "Kittipong", ""], ["Caire", "Giuseppe", ""]]}, {"id": "1504.01693", "submitter": "Benjamin Holland", "authors": "Benjamin Holland, Tom Deering, Suresh Kothari, Jon Mathews, Nikhil\n  Ranade", "title": "Security Toolbox for Detecting Novel and Sophisticated Android Malware", "comments": "4 pages, 1 listing, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a demo of our Security Toolbox to detect novel malware in\nAndroid apps. This Toolbox is developed through our recent research project\nfunded by the DARPA Automated Program Analysis for Cybersecurity (APAC)\nproject. The adversarial challenge (\"Red\") teams in the DARPA APAC program are\ntasked with designing sophisticated malware to test the bounds of malware\ndetection technology being developed by the research and development (\"Blue\")\nteams. Our research group, a Blue team in the DARPA APAC program, proposed a\n\"human-in-the-loop program analysis\" approach to detect malware given the\nsource or Java bytecode for an Android app. Our malware detection apparatus\nconsists of two components: a general-purpose program analysis platform called\nAtlas, and a Security Toolbox built on the Atlas platform. This paper describes\nthe major design goals, the Toolbox components to achieve the goals, and the\nworkflow for auditing Android apps. The accompanying video\n(http://youtu.be/WhcoAX3HiNU) illustrates features of the Toolbox through a\nlive audit.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2015 18:09:11 GMT"}], "update_date": "2015-04-08", "authors_parsed": [["Holland", "Benjamin", ""], ["Deering", "Tom", ""], ["Kothari", "Suresh", ""], ["Mathews", "Jon", ""], ["Ranade", "Nikhil", ""]]}, {"id": "1504.01974", "submitter": "Goutam Paul", "authors": "Arpita Maitra, Goutam Paul and Asim K. Pal", "title": "Secure two-party quantum computation for non-rational and rational\n  settings", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the negative result of Lo (Physical Review A, 1997), it has been left\nopen whether there exist some functions that can be securely computed in\ntwo-party setting in quantum domain when one of the parties is malicious. In\nthis paper, we for the first time, show that there are some functions for which\nsecure two-party quantum computation is indeed possible for non-simultaneous\nchannel model. This is in sharp contrast with the impossibility result of Ben\n-Or et al. (FOCS, 2006) in broadcast channel model. The functions we study are\nof two types - one is any function without an embedded XOR, and the other one\nis a particular function containing an embedded XOR. Contrary to classical\nsolutions, security against adversaries with unbounded power of computation is\nachieved by the quantum protocols due to entanglement. Further, in the context\nof secure multi-party quantum computation, for the first time we introduce\nrational parties, each of whom tries to maximize its utility by obtaining the\nfunction output alone. We adapt our quantum protocols for both the above types\nof functions in rational setting to achieve fairness and strict Nash\nequilibrium.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2015 14:06:50 GMT"}, {"version": "v2", "created": "Sat, 30 May 2015 00:19:36 GMT"}, {"version": "v3", "created": "Wed, 10 Jun 2015 21:16:40 GMT"}, {"version": "v4", "created": "Mon, 13 Jul 2015 20:36:33 GMT"}, {"version": "v5", "created": "Sun, 1 May 2016 10:39:32 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Maitra", "Arpita", ""], ["Paul", "Goutam", ""], ["Pal", "Asim K.", ""]]}, {"id": "1504.02115", "submitter": "Subodh Gangan", "authors": "Subodh Gangan", "title": "A Review of Man-in-the-Middle Attacks", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a survey of man-in-the-middle (MIM) attacks in\ncommunication networks and methods of protection against them. In real time\ncommunication, the attack can in many situations be discovered by the use of\ntiming information. The most common attacks occur due to Address Resolution\nProtocol (ARP) cache poisoning, DNS spoofing, session hijacking, and SSL\nhijacking.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2015 20:19:24 GMT"}], "update_date": "2015-04-10", "authors_parsed": [["Gangan", "Subodh", ""]]}, {"id": "1504.02288", "submitter": "Follner Andreas", "authors": "Andreas Follner, Eric Bodden", "title": "ROPocop - Dynamic Mitigation of Code-Reuse Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Control-flow attacks, usually achieved by exploiting a buffer-overflow\nvulnerability, have been a serious threat to system security for over fifteen\nyears. Researchers have answered the threat with various mitigation techniques,\nbut nevertheless, new exploits that successfully bypass these technologies\nstill appear on a regular basis.\n  In this paper, we propose ROPocop, a novel approach for detecting and\npreventing the execution of injected code and for mitigating code-reuse attacks\nsuch as return-oriented programming (RoP). ROPocop uses dynamic binary\ninstrumentation, requiring neither access to source code nor debug symbols or\nchanges to the operating system. It mitigates attacks by both monitoring the\nprogram counter at potentially dangerous points and by detecting suspicious\nprogram flows.\n  We have implemented ROPocop for Windows x86 using PIN, a dynamic program\ninstrumentation framework from Intel. Benchmarks using the SPEC CPU2006 suite\nshow an average overhead of 2.4x, which is comparable to similar approaches,\nwhich give weaker guarantees. Real-world applications show only an initially\nnoticeable input lag and no stutter. In our evaluation our tool successfully\ndetected all 11 of the latest real-world code-reuse exploits, with no false\nalarms. Therefore, despite the overhead, it is a viable, temporary solution to\nsecure critical systems against exploits if a vendor patch is not yet\navailable.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2015 13:03:28 GMT"}], "update_date": "2015-04-10", "authors_parsed": [["Follner", "Andreas", ""], ["Bodden", "Eric", ""]]}, {"id": "1504.02333", "submitter": "Maciej  Skorski", "authors": "Maciej Skorski", "title": "Lower bounds on $q$-wise independence tails and applications to\n  min-entropy condensers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present novel and sharp lower bounds for higher load moments in the\nclassical problem of mapping $M$ balls into $N$ bins by $q$-universal hashing,\nspecialized to the case when $M=N$. As a corollary we prove a tight counterpart\nfor the result about min-entropy condensers due to Dodis, Pietrzak and Wichs\n(CRYPTO'14), which has found important applications in key derivation. It\nstates that condensing $k$ bits of min-entropy into a $k$-bit string\n$\\epsilon$-close to almost full min-entropy (precisely $\nk-\\log\\log(1/\\epsilon)$ bits of entropy) can be achieved by the use of\n$q$-independent hashing with $q= \\log(1/\\epsilon)$. We prove that when given a\nsource of min-entropy $k$ and aiming at entropy loss $\\ell = \\log\\log\n(1/\\epsilon) - 3$, the independence level $q=(1-o(1))\\log(1/\\epsilon)$ is\nnecessary (for small values of $\\epsilon$), which almost matches the positive\nresult. Besides these asymptotic bounds, we provide clear hard bounds in terms\nof Bell numbers and some numerical examples. Our technique is based on an\nexplicit representation of the load moments in terms of Stirling numbers, some\nasymptotic estimates on Stirling numbers and a tricky application of the\nPaley-Zygmund inequality. \\keywords{ min-entropy condensers, key derivation,\nballs and bins hashing, anti-concentration inequalities }\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2015 14:36:37 GMT"}], "update_date": "2015-04-10", "authors_parsed": [["Skorski", "Maciej", ""]]}, {"id": "1504.02347", "submitter": "Koray Karabina", "authors": "Koray Karabina", "title": "Point Decomposition Problem in Binary Elliptic Curves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the point decomposition problem (PDP) in binary elliptic curves.\nIt is known that PDP in an elliptic curve group can be reduced to solving a\nparticular system of multivariate non-linear system of equations derived from\nthe so called Semaev summation polynomials. We modify the underlying system of\nequations by introducing some auxiliary variables. We argue that the trade-off\nbetween lowering the degree of Semaev polynomials and increasing the number of\nvariables is worth.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2015 15:12:13 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2015 04:53:03 GMT"}], "update_date": "2015-04-21", "authors_parsed": [["Karabina", "Koray", ""]]}, {"id": "1504.02395", "submitter": "Giulio Chiribella", "authors": "Giulio Chiribella and Xiao Yuan", "title": "Bridging the gap between general probabilistic theories and the\n  device-independent framework for nonlocality and contextuality", "comments": "61 pages, no figures, published version", "journal-ref": "Information and Computation, 250, 15-49 (2016)", "doi": "10.1016/j.ic.2016.02.006", "report-no": null, "categories": "quant-ph cs.CR cs.GT cs.LO math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing quantum correlations in terms of information-theoretic\nprinciples is a popular chapter of quantum foundations. Traditionally, the\nprinciples adopted for this scope have been expressed in terms of conditional\nprobability distributions, specifying the probability that a black box produces\na certain output upon receiving a certain input. This framework is known as\n\"device-independent\". Another major chapter of quantum foundations is the\ninformation-theoretic characterization of quantum theory, with its sets of\nstates and measurements, and with its allowed dynamics. The different\nframeworks adopted for this scope are known under the umbrella term \"general\nprobabilistic theories\". With only a few exceptions, the two programmes on\ncharacterizing quantum correlations and characterizing quantum theory have so\nfar proceeded on separate tracks, each one developing its own methods and its\nown agenda. This paper aims at bridging the gap, by comparing the two\nframeworks and illustrating how the two programmes can benefit each other.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2015 17:19:17 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2015 15:18:17 GMT"}, {"version": "v3", "created": "Thu, 30 Apr 2015 02:43:43 GMT"}, {"version": "v4", "created": "Fri, 11 Mar 2016 16:47:43 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Chiribella", "Giulio", ""], ["Yuan", "Xiao", ""]]}, {"id": "1504.02420", "submitter": "Gregory Gutin", "authors": "D. Cohen, J. Crampton, A. Gagarin, G. Gutin and M. Jones", "title": "Algorithms for the workflow satisfiability problem engineered for\n  counting constraints", "comments": null, "journal-ref": null, "doi": "10.1007/s10878-015-9877-7", "report-no": null, "categories": "cs.DS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The workflow satisfiability problem (WSP) asks whether there exists an\nassignment of authorized users to the steps in a workflow specification that\nsatisfies the constraints in the specification. The problem is NP-hard in\ngeneral, but several subclasses of the problem are known to be fixed-parameter\ntractable (FPT) when parameterized by the number of steps in the specification.\nIn this paper, we consider the WSP with user-independent counting constraints,\na large class of constraints for which the WSP is known to be FPT. We describe\nan efficient implementation of an FPT algorithm for solving this subclass of\nthe WSP and an experimental evaluation of this algorithm. The algorithm\niteratively generates all equivalence classes of possible partial solutions\nuntil, whenever possible, it finds a complete solution to the problem. We also\nprovide a reduction from a WSP instance to a pseudo-Boolean SAT instance. We\napply this reduction to the instances used in our experiments and solve the\nresulting PB SAT problems using SAT4J, a PB SAT solver. We compare the\nperformance of our algorithm with that of SAT4J and discuss which of the two\napproaches would be more effective in practice.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2015 18:54:57 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Cohen", "D.", ""], ["Crampton", "J.", ""], ["Gagarin", "A.", ""], ["Gutin", "G.", ""], ["Jones", "M.", ""]]}, {"id": "1504.02536", "submitter": "Vincent Tan", "authors": "Masahito Hayashi and Vincent Y. F. Tan", "title": "Equivocations, Exponents and Second-Order Coding Rates under Various\n  R\\'enyi Information Measures", "comments": "47 pages, 9 figures; Presented at the 2015 International Symposium on\n  Information Theory (Hong Kong); Submitted to the IEEE Transactions on\n  Information Theory; v3: fixed typos and added some clarifications to the\n  proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate the asymptotics of equivocations, their exponents as well as\ntheir second-order coding rates under various R\\'{e}nyi information measures.\nSpecifically, we consider the effect of applying a hash function on a source\nand we quantify the level of non-uniformity and dependence of the compressed\nsource from another correlated source when the number of copies of the sources\nis large. Unlike previous works that use Shannon information measures to\nquantify randomness, information or uniformity, we define our security measures\nin terms of a more general class of information measures--the R\\'{e}nyi\ninformation measures and their Gallager-type counterparts. A special case of\nthese R\\'{e}nyi information measure is the class of Shannon information\nmeasures. We prove tight asymptotic results for the security measures and their\nexponential rates of decay. We also prove bounds on the second-order\nasymptotics and show that these bounds match when the magnitudes of the\nsecond-order coding rates are large. We do so by establishing new classes\nnon-asymptotic bounds on the equivocation and evaluating these bounds using\nvarious probabilistic limit theorems asymptotically.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2015 02:24:05 GMT"}, {"version": "v2", "created": "Thu, 7 May 2015 02:58:58 GMT"}, {"version": "v3", "created": "Tue, 5 Jul 2016 04:22:45 GMT"}], "update_date": "2016-07-06", "authors_parsed": [["Hayashi", "Masahito", ""], ["Tan", "Vincent Y. F.", ""]]}, {"id": "1504.02549", "submitter": "Odemir Bruno PhD", "authors": "Jeaneth Machicao, Jan M. Baetens, Anderson G. Marco, Bernard De Baets,\n  Odemir M. Bruno", "title": "A dynamical systems approach to the discrimination of the modes of\n  operation of cryptographic systems", "comments": "14 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evidence of signatures associated with cryptographic modes of operation is\nestablished. Motivated by some analogies between cryptographic and dynamical\nsystems, in particular with chaos theory, we propose an algorithm based on\nLyapunov exponents of discrete dynamical systems to estimate the divergence\namong ciphertexts as the encryption algorithm is applied iteratively. The\nresults allow to distinguish among six modes of operation, namely ECB, CBC,\nOFB, CFB, CTR and PCBC using DES, IDEA, TEA and XTEA block ciphers of 64 bits,\nas well as AES, RC6, Twofish, Seed, Serpent and Camellia block ciphers of 128\nbits. Furthermore, the proposed methodology enables a classification of modes\nof operation of cryptographic systems according to their strength.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2015 04:44:39 GMT"}], "update_date": "2015-04-13", "authors_parsed": [["Machicao", "Jeaneth", ""], ["Baetens", "Jan M.", ""], ["Marco", "Anderson G.", ""], ["De Baets", "Bernard", ""], ["Bruno", "Odemir M.", ""]]}, {"id": "1504.02615", "submitter": "EPTCS", "authors": "Marwan Radwan (University of Leicester), Reiko Heckel (University of\n  Leicester)", "title": "Detecting and Refactoring Operational Smells within the Domain Name\n  System", "comments": "In Proceedings GaM 2015, arXiv:1504.02448", "journal-ref": "EPTCS 181, 2015, pp. 113-128", "doi": "10.4204/EPTCS.181.8", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Domain Name System (DNS) is one of the most important components of the\nInternet infrastructure. DNS relies on a delegation-based architecture, where\nresolution of names to their IP addresses requires resolving the names of the\nservers responsible for those names. The recursive structures of the inter\ndependencies that exist between name servers associated with each zone are\ncalled dependency graphs. System administrators' operational decisions have far\nreaching effects on the DNSs qualities. They need to be soundly made to create\na balance between the availability, security and resilience of the system. We\nutilize dependency graphs to identify, detect and catalogue operational bad\nsmells. Our method deals with smells on a high-level of abstraction using a\nconsistent taxonomy and reusable vocabulary, defined by a DNS Operational\nModel. The method will be used to build a diagnostic advisory tool that will\ndetect configuration changes that might decrease the robustness or security\nposture of domain names before they become into production.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2015 09:41:30 GMT"}], "update_date": "2015-04-13", "authors_parsed": [["Radwan", "Marwan", "", "University of Leicester"], ["Heckel", "Reiko", "", "University of\n  Leicester"]]}, {"id": "1504.02796", "submitter": "Quoc-Sang Phan", "authors": "Quoc-Sang Phan", "title": "Model Counting Modulo Theories", "comments": "PhD thesis (2015); Queen Mary University of London\n  (http://theory.eecs.qmul.ac.uk/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis is concerned with the quantitative assessment of security in\nsoftware. More specifically, it tackles the problem of efficient computation of\nchannel capacity, the maximum amount of confidential information leaked by\nsoftware, measured in Shannon entropy or R\\'{e}nyi's min-entropy.\n  Most approaches to computing channel capacity are either efficient and return\nonly (possibly very loose) upper bounds, or alternatively are inefficient but\nprecise; few target realistic programs. In this thesis, we present a novel\napproach to the problem by reducing it to a model counting problem on\nfirst-order logic, which we name Model Counting Modulo Theories or #SMT for\nbrevity.\n  For quantitative security, our contribution is twofold. First, on the\ntheoretical side we establish the connections between measuring confidentiality\nleaks and fundamental verification algorithms like Symbolic Execution, SMT\nsolvers and DPLL. Second, exploiting these connections, we develop novel\n#SMT-based techniques to compute channel capacity, which achieve both accuracy\nand efficiency. These techniques are scalable to real-world programs, and\nillustrative case studies include C programs from Linux kernel, a Java program\nfrom a European project and anonymity protocols.\n  For formal verification, our contribution is also twofold. First, we\nintroduce and study a new research problem, namely #SMT, which has other\npotential applications beyond computing channel capacity, such as returning\nmultiple-counterexamples for Bounded Model Checking or automated test\ngeneration. Second, we propose an alternative approach for Bounded Model\nChecking using classical Symbolic Execution, which can be parallelised to\nleverage modern multi-core and distributed architecture.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2015 21:16:03 GMT"}], "update_date": "2015-04-14", "authors_parsed": [["Phan", "Quoc-Sang", ""]]}, {"id": "1504.03161", "submitter": "Jun Zhao", "authors": "Jun Zhao, Osman Ya\\u{g}an, Virgil Gligor", "title": "Random intersection graphs and their applications in security, wireless\n  communication, and social networks", "comments": "This is an invited paper in Information Theory and Applications\n  Workshop (ITA) 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CR cs.SI math.CO physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random intersection graphs have received much interest and been used in\ndiverse applications. They are naturally induced in modeling secure sensor\nnetworks under random key predistribution schemes, as well as in modeling the\ntopologies of social networks including common-interest networks, collaboration\nnetworks, and actor networks. Simply put, a random intersection graph is\nconstructed by assigning each node a set of items in some random manner and\nthen putting an edge between any two nodes that share a certain number of\nitems.\n  Broadly speaking, our work is about analyzing random intersection graphs, and\nmodels generated by composing it with other random graph models including\nrandom geometric graphs and Erd\\H{o}s-R\\'enyi graphs. These compositional\nmodels are introduced to capture the characteristics of various complex natural\nor man-made networks more accurately than the existing models in the\nliterature. For random intersection graphs and their compositions with other\nrandom graphs, we study properties such as ($k$-)connectivity,\n($k$-)robustness, and containment of perfect matchings and Hamilton cycles. Our\nresults are typically given in the form of asymptotically exact probabilities\nor zero-one laws specifying critical scalings, and provide key insights into\nthe design and analysis of various real-world networks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Feb 2015 09:37:09 GMT"}], "update_date": "2015-04-14", "authors_parsed": [["Zhao", "Jun", ""], ["Ya\u011fan", "Osman", ""], ["Gligor", "Virgil", ""]]}, {"id": "1504.03287", "submitter": "Mohammed Shafiul Alam Khan", "authors": "Mohammed Shafiul Alam Khan, Chris J Mitchell", "title": "Improving Air Interface User Privacy in Mobile Telephony", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the security properties of 3G and 4G mobile networks have\nsignificantly improved by comparison with 2G (GSM), significant shortcomings\nremain with respect to user privacy. A number of possible modifications to 2G,\n3G and 4G protocols have been proposed designed to provide greater user\nprivacy; however, they all require significant modifications to existing\ndeployed infrastructures, which are almost certainly impractical to achieve in\npractice. In this article we propose an approach which does not require any\nchanges to the existing deployed network infrastructures or mobile devices, but\noffers improved user identity protection over the air interface. The proposed\nscheme makes use of multiple IMSIs for an individual USIM to offer a degree of\npseudonymity for a user. The only changes required are to the operation of the\nauthentication centre in the home network and to the USIM, and the scheme could\nbe deployed immediately since it is completely transparent to the existing\nmobile telephony infrastructure. We present two different approaches to the use\nand management of multiple IMSIs.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2015 18:23:53 GMT"}], "update_date": "2015-04-14", "authors_parsed": [["Khan", "Mohammed Shafiul Alam", ""], ["Mitchell", "Chris J", ""]]}, {"id": "1504.03340", "submitter": "Amirhosein Bodaghi", "authors": "Amir Hosein Bodaghi", "title": "A Novel Model for Integration of Information Security Management against\n  Replication Attack Based on Biological Structures of the Body", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By developing communications and increase of access points, computer networks\nhave been vulnerable considerably against wide range of information attacks,\nspecially new and complicated attacks. Every day, replication attacks attack\nmillions of network and mobile users. Increase in amount of replication attack\nmay be a potential danger for income of SMS or network and causes losing\ncustomers of these services provider. Humans or software can be used to\nencounter these replication attacks. It is obvious that lonely absolute use of\neach method will not result in a proper answer to encounter replication\nattack`s problem. Since replication attack is one of the important problems of\ninformation protection and security in organizations for computer and mobile\nphone users, while reviewing types of replication attacks and methods of\nencountering, this paper uses similarities between pathologies in body and\ninvader factors in replication attacks, a model is provided based on biological\nsimulation methods existing in body`s adapted immune system to encounter these\nthreats.\n", "versions": [{"version": "v1", "created": "Sun, 23 Nov 2014 16:20:49 GMT"}], "update_date": "2015-04-15", "authors_parsed": [["Bodaghi", "Amir Hosein", ""]]}, {"id": "1504.03342", "submitter": "Imrul Kayes", "authors": "Imrul Kayes, Adriana Iamnitchi", "title": "A Survey on Privacy and Security in Online Social Networks", "comments": null, "journal-ref": "Online Social Networks and Media Journal October 2017", "doi": "10.1016/j.osnem.2017.09.001", "report-no": null, "categories": "cs.SI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online Social Networks (OSN) are a permanent presence in today's personal and\nprofessional lives of a huge segment of the population, with direct\nconsequences to offline activities. Built on a foundation of trust-users\nconnect to other users with common interests or overlapping personal\ntrajectories-online social networks and the associated applications extract an\nunprecedented volume of personal information. Unsurprisingly, serious privacy\nand security risks emerged, positioning themselves along two main types of\nattacks: attacks that exploit the implicit trust embedded in declared social\nrelationships; and attacks that harvest user's personal information for\nill-intended use. This article provides an overview of the privacy and security\nissues that emerged so far in OSNs. We introduce a taxonomy of privacy and\nsecurity attacks in OSNs, we overview existing solutions to mitigate those\nattacks, and outline challenges still to overcome.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2015 18:09:10 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Kayes", "Imrul", ""], ["Iamnitchi", "Adriana", ""]]}, {"id": "1504.03385", "submitter": "Chen-Yu Lee", "authors": "Chen-Yu Lee, Deng-Jyi Chen", "title": "A Content Creation and Protection Scheme for Medical Images", "comments": "15 pages, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical images contain metadata information on where, when, and how an image\nwas acquired, and the majority of this information is stored as pixel data.\nImage feature descriptions are often captured only as free text stored in the\nimage file or in the hospital information system. Correlations between the free\ntext and the location of the feature are often inaccurate, making it difficult\nto link image observations to their corresponding image locations. This limits\nthe interpretation of image data from a clinical, research, and academic\nstandpoint. An efficient medical image protection design should allow for\ncompatibility, usability, and privacy. This paper proposes a medical-content\ncreation and protection scheme that contains a) a DICOM-compatible multimedia\nannotation scheme for medical content creation; b) a DICOM-compatible partial\nDRM scheme for medical record transmission under this scheme, authorized users\ncan view only information to which they have been granted to access.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2015 22:43:45 GMT"}], "update_date": "2015-04-15", "authors_parsed": [["Lee", "Chen-Yu", ""], ["Chen", "Deng-Jyi", ""]]}, {"id": "1504.03406", "submitter": "Omer K. Jasim", "authors": "Omer K. Jasim Mohammad, Safia Abbas, El-Sayed M. El-Horbaty and\n  Abdel-Badeeh M. Salem", "title": "Innovative Method for enhancing Key generation and management in the\n  AES-algorithm", "comments": "7 pages, 10 figures. arXiv admin note: text overlap with\n  arXiv:1503.04796", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the extraordinary maturity of data exchange in network environments and\nincreasing the attackers capabilities, information security has become the most\nimportant process for data storage and communication. In order to provide such\ninformation security the confidentiality, data integrity, and data origin\nauthentication must be verified based on cryptographic encryption algorithms.\nThis paper presents a development of the advanced encryption standard (AES)\nalgorithm, which is considered as the most eminent symmetric encryption\nalgorithm. The development focuses on the generation of the integration between\nthe developed AES based S-Boxes, and the specific selected secret key generated\nfrom the quantum key distribution.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2015 02:36:06 GMT"}], "update_date": "2015-04-15", "authors_parsed": [["Mohammad", "Omer K. Jasim", ""], ["Abbas", "Safia", ""], ["El-Horbaty", "El-Sayed M.", ""], ["Salem", "Abdel-Badeeh M.", ""]]}, {"id": "1504.03539", "submitter": "Mansaf Alam Dr", "authors": "Mansaf Alam, Shuchi Sethi", "title": "Detection of Information leakage in cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research shows that colluded malware in different VMs sharing a single\nphysical host may use a resource as a channel to leak critical information.\nCovert channels employ time or storage characteristics to transmit confidential\ninformation to attackers leaving no trail.These channels were not meant for\ncommunication and hence control mechanisms do not exist. This means these\nremain undetected by traditional security measures employed in firewalls etc in\na network. The comprehensive survey to address the issue highlights that\naccurate methods for fast detection in cloud are very expensive in terms of\nstorage and processing. The proposed framework builds signature by extracting\nfeatures which accurately classify the regular from covert traffic in cloud and\nestimates difference in distribution of data under analysis by means of scores.\nIt then adds context to the signature and finally using machine learning\n(Support Vector Machines),a model is built and trained for deploying in cloud.\nThe results show that the framework proposed is high in accuracy while being\nlow cost and robust as it is tested after adding noise which is likely to exist\nin public cloud environments.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2015 13:35:32 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2015 09:26:35 GMT"}], "update_date": "2015-11-09", "authors_parsed": [["Alam", "Mansaf", ""], ["Sethi", "Shuchi", ""]]}, {"id": "1504.03561", "submitter": "Gregory Gutin", "authors": "Jason Crampton, Andrei Gagarin, Gregory Gutin, Mark Jones and Magnus\n  Wahlstrom", "title": "On the Workflow Satisfiability Problem with Class-Independent\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A workflow specification defines sets of steps and users. An authorization\npolicy determines for each user a subset of steps the user is allowed to\nperform. Other security requirements, such as separation-of-duty, impose\nconstraints on which subsets of users may perform certain subsets of steps. The\n\\emph{workflow satisfiability problem} (WSP) is the problem of determining\nwhether there exists an assignment of users to workflow steps that satisfies\nall such authorizations and constraints. An algorithm for solving WSP is\nimportant, both as a static analysis tool for workflow specifications, and for\nthe construction of run-time reference monitors for workflow management\nsystems. Given the computational difficulty of WSP, it is important,\nparticularly for the second application, that such algorithms are as efficient\nas possible.\n  We introduce class-independent constraints, enabling us to model scenarios\nwhere the set of users is partitioned into groups, and the identities of the\nuser groups are irrelevant to the satisfaction of the constraint. We prove that\nsolving WSP is fixed-parameter tractable (FPT) for this class of constraints\nand develop an FPT algorithm that is useful in practice. We compare the\nperformance of the FPT algorithm with that of SAT4J (a pseudo-Boolean SAT\nsolver) in computational experiments, which show that our algorithm\nsignificantly outperforms SAT4J for many instances of WSP. User-independent\nconstraints, a large class of constraints including many practical ones, are a\nspecial case of class-independent constraints for which WSP was proved to be\nFPT (Cohen {\\em et al.}, J. Artif. Intel. Res. 2014). Thus our results\nconsiderably extend our knowledge of the fixed-parameter tractability of WSP.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2015 14:25:22 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2015 15:21:23 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Crampton", "Jason", ""], ["Gagarin", "Andrei", ""], ["Gutin", "Gregory", ""], ["Jones", "Mark", ""], ["Wahlstrom", "Magnus", ""]]}, {"id": "1504.03711", "submitter": "Kristopher Micinski", "authors": "Kristopher Micinski, Jonathan Fetter-Degges, Jinseong Jeon, Jeffrey S.\n  Foster, Michael R. Clarkson", "title": "Checking Interaction-Based Declassification Policies for Android Using\n  Symbolic Execution", "comments": "This research was supported in part by NSF grants CNS-1064997 and\n  1421373, AFOSR grants FA9550-12-1-0334 and FA9550-14-1-0334, a partnership\n  between UMIACS and the Laboratory for Telecommunication Sciences, and the\n  National Security Agency", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile apps can access a wide variety of secure information, such as contacts\nand location. However, current mobile platforms include only coarse access\ncontrol mechanisms to protect such data. In this paper, we introduce\ninteraction-based declassification policies, in which the user's interactions\nwith the app constrain the release of sensitive information. Our policies are\ndefined extensionally, so as to be independent of the app's implementation,\nbased on sequences of security-relevant events that occur in app runs. Policies\nuse LTL formulae to precisely specify which secret inputs, read at which times,\nmay be released. We formalize a semantic security condition, interaction-based\nnoninterference, to define our policies precisely. Finally, we describe a\nprototype tool that uses symbolic execution to check interaction-based\ndeclassification policies for Android, and we show that it enforces policies\ncorrectly on a set of apps.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2015 20:33:46 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2015 14:14:24 GMT"}], "update_date": "2015-07-30", "authors_parsed": [["Micinski", "Kristopher", ""], ["Fetter-Degges", "Jonathan", ""], ["Jeon", "Jinseong", ""], ["Foster", "Jeffrey S.", ""], ["Clarkson", "Michael R.", ""]]}, {"id": "1504.03744", "submitter": "Mohammad Reza Khalili Shoja", "authors": "Mohammad Reza Khalili Shoja, George Traian Amariucai, Shuangqing Wei,\n  Jing Deng", "title": "KERMAN: A Key Establishment Algorithm based on Harvesting Randomness in\n  MANETs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Establishing secret common randomness between two or multiple devices in a\nnetwork resides at the root of communication security. The problem is\ntraditionally decomposed into a randomness generation stage (randomness purity\nis subject to employing often costly true random number generators) and a\nkey-agreement information exchange stage, which can rely on public-key\ninfrastructure or on key wrapping. In this paper, we propose KERMAN, an\nalternative key establishment algorithm for ad-hoc networks which works by\nharvesting randomness directly from the network routing metadata, thus\nachieving both pure randomness generation and (implicitly) secret-key\nagreement. Our algorithm relies on the route discovery phase of an ad-hoc\nnetwork employing the Dynamic Source Routing protocol, is lightweight, and\nrequires minimal communication overhead.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2015 23:45:12 GMT"}], "update_date": "2015-04-16", "authors_parsed": [["Shoja", "Mohammad Reza Khalili", ""], ["Amariucai", "George Traian", ""], ["Wei", "Shuangqing", ""], ["Deng", "Jing", ""]]}, {"id": "1504.03747", "submitter": "Serge Egelman", "authors": "Primal Wijesekera, Arjun Baokar, Ashkan Hosseini, Serge Egelman, David\n  Wagner, Konstantin Beznosov", "title": "Android Permissions Remystified: A Field Study on Contextual Integrity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the amount of data that smartphone applications can potentially\naccess, platforms enforce permission systems that allow users to regulate how\napplications access protected resources. If users are asked to make security\ndecisions too frequently and in benign situations, they may become habituated\nand approve all future requests without regard for the consequences. If they\nare asked to make too few security decisions, they may become concerned that\nthe platform is revealing too much sensitive information. To explore this\ntradeoff, we instrumented the Android platform to collect data regarding how\noften and under what circumstances smartphone applications are accessing\nprotected resources regulated by permissions. We performed a 36-person field\nstudy to explore the notion of \"contextual integrity,\" that is, how often are\napplications accessing protected resources when users are not expecting it?\nBased on our collection of 27 million data points and exit interviews with\nparticipants, we examine the situations in which users would like the ability\nto deny applications access to protected resources. We found out that at least\n80% of our participants would have preferred to prevent at least one permission\nrequest, and overall, they thought that over a third of requests were invasive\nand desired a mechanism to block them.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2015 00:07:17 GMT"}], "update_date": "2015-04-16", "authors_parsed": [["Wijesekera", "Primal", ""], ["Baokar", "Arjun", ""], ["Hosseini", "Ashkan", ""], ["Egelman", "Serge", ""], ["Wagner", "David", ""], ["Beznosov", "Konstantin", ""]]}, {"id": "1504.03778", "submitter": "Vanessa Teague", "authors": "Josh Benaloh (Microsoft Research), Ronald Rivest (Massachusetts\n  Institute of Technology), Peter Y. A. Ryan (University of Luxembourg), Philip\n  Stark (University of California, Berkeley), Vanessa Teague (University of\n  Melbourne), Poorvi Vora (George Washington University)", "title": "End-to-end verifiability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This pamphlet describes end-to-end election verifiability (E2E-V) for a\nnontechnical audience: election officials, public policymakers, and anyone else\ninterested in secure, transparent, evidence-based electronic elections.\n  This work is part of the Overseas Vote Foundation's End-to-End Verifiable\nInternet Voting: Specification and Feasibility Assessment Study (E2E VIV\nProject), funded by the Democracy Fund.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2015 03:52:45 GMT"}], "update_date": "2015-04-16", "authors_parsed": [["Benaloh", "Josh", "", "Microsoft Research"], ["Rivest", "Ronald", "", "Massachusetts\n  Institute of Technology"], ["Ryan", "Peter Y. A.", "", "University of Luxembourg"], ["Stark", "Philip", "", "University of California, Berkeley"], ["Teague", "Vanessa", "", "University of\n  Melbourne"], ["Vora", "Poorvi", "", "George Washington University"]]}, {"id": "1504.04217", "submitter": "Jamie Sikora", "authors": "Ashwin Nayak, Jamie Sikora, Levent Tun\\c{c}el", "title": "Quantum and classical coin-flipping protocols based on bit-commitment\n  and their point games", "comments": "41 pages (plus a 17 page appendix). Comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on a family of quantum coin-flipping protocols based on\nbit-commitment. We discuss how the semidefinite programming formulations of\ncheating strategies can be reduced to optimizing a linear combination of\nfidelity functions over a polytope. These turn out to be much simpler\nsemidefinite programs which can be modelled using second-order cone programming\nproblems. We then use these simplifications to construct their point games as\ndeveloped by Kitaev. We also study the classical version of these protocols and\nuse linear optimization to formulate optimal cheating strategies. We then\nconstruct the point games for the classical protocols as well using the\nanalysis for the quantum case.\n  We discuss the philosophical connections between the classical and quantum\nprotocols and their point games as viewed from optimization theory. In\nparticular, we observe an analogy between a spectrum of physical theories (from\nclassical to quantum) and a spectrum of convex optimization problems (from\nlinear programming to semidefinite programming, through second-order cone\nprogramming). In this analogy, classical systems correspond to linear\nprogramming problems and the level of quantum features in the system is\ncorrelated to the level of sophistication of the semidefinite programming\nmodels on the optimization side.\n  Concerning security analysis, we use the classical point games to prove that\nevery classical protocol of this type allows exactly one of the parties to\nentirely determine the coin-flip. Using the relationships between the quantum\nand classical protocols, we show that only \"classical\" protocols can saturate\nKitaev's lower bound for strong coin-flipping. Moreover, if the product of\nAlice and Bob's optimal cheating probabilities is 1/2, then one party can cheat\nwith probability 1. This rules out quantum protocols of this type from\nattaining the optimal level of security.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2015 13:07:23 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Nayak", "Ashwin", ""], ["Sikora", "Jamie", ""], ["Tun\u00e7el", "Levent", ""]]}, {"id": "1504.04306", "submitter": "Sugata Sanyal", "authors": "Uday Kumar, Tuhin Borgohain, Sugata Sanyal", "title": "Comparative Analysis of Cryptography Library in IoT", "comments": "5 pages, 14 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper aims to do a survey along with a comparative analysis of the\nvarious cryptography libraries that are applicable in the field of Internet of\nThings (IoT). The first half of the paper briefly introduces the various\ncryptography libraries available in the field of cryptography along with a list\nof all the algorithms contained within the libraries. The second half of the\npaper deals with cryptography libraries specifically aimed for application in\nthe field of Internet of Things. The various libraries and their performance\nanalysis listed down in this paper are consolidated from various sources with\nthe aim of providing a single comprehensive repository for reference to the\nvarious cryptography libraries and the comparative analysis of their features\nin IoT.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2015 17:05:52 GMT"}], "update_date": "2015-04-17", "authors_parsed": [["Kumar", "Uday", ""], ["Borgohain", "Tuhin", ""], ["Sanyal", "Sugata", ""]]}, {"id": "1504.04317", "submitter": "Robert Bridges", "authors": "Corinne L. Jones, Robert A. Bridges, Kelly Huffer, John Goodall", "title": "Towards a relation extraction framework for cyber-security concepts", "comments": "4 pages in Cyber & Information Security Research Conference 2015, ACM", "journal-ref": null, "doi": "10.1145/2746266.2746277", "report-no": null, "categories": "cs.IR cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to assist security analysts in obtaining information pertaining to\ntheir network, such as novel vulnerabilities, exploits, or patches, information\nretrieval methods tailored to the security domain are needed. As labeled text\ndata is scarce and expensive, we follow developments in semi-supervised Natural\nLanguage Processing and implement a bootstrapping algorithm for extracting\nsecurity entities and their relationships from text. The algorithm requires\nlittle input data, specifically, a few relations or patterns (heuristics for\nidentifying relations), and incorporates an active learning component which\nqueries the user on the most important decisions to prevent drifting from the\ndesired relations. Preliminary testing on a small corpus shows promising\nresults, obtaining precision of .82.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2015 17:26:24 GMT"}], "update_date": "2015-04-17", "authors_parsed": [["Jones", "Corinne L.", ""], ["Bridges", "Robert A.", ""], ["Huffer", "Kelly", ""], ["Goodall", "John", ""]]}, {"id": "1504.04339", "submitter": "Tamara Bonaci", "authors": "Tamara Bonaci, Jeffrey Herron, Tariq Yusuf, Junjie Yan, Tadayoshi\n  Kohno and Howard Jay Chizeck", "title": "To Make a Robot Secure: An Experimental Analysis of Cyber Security\n  Threats Against Teleoperated Surgical Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teleoperated robots are playing an increasingly important role in military\nactions and medical services. In the future, remotely operated surgical robots\nwill likely be used in more scenarios such as battlefields and emergency\nresponse. But rapidly growing applications of teleoperated surgery raise the\nquestion; what if the computer systems for these robots are attacked, taken\nover and even turned into weapons? Our work seeks to answer this question by\nsystematically analyzing possible cyber security attacks against Raven II, an\nadvanced teleoperated robotic surgery system. We identify a slew of possible\ncyber security threats, and experimentally evaluate their scopes and impacts.\nWe demonstrate the ability to maliciously control a wide range of robots\nfunctions, and even to completely ignore or override command inputs from the\nsurgeon. We further find that it is possible to abuse the robot's existing\nemergency stop (E-stop) mechanism to execute efficient (single packet) attacks.\nWe then consider steps to mitigate these identified attacks, and experimentally\nevaluate the feasibility of applying the existing security solutions against\nthese threats. The broader goal of our paper, however, is to raise awareness\nand increase understanding of these emerging threats. We anticipate that the\nmajority of attacks against telerobotic surgery will also be relevant to other\nteleoperated robotic and co-robotic systems.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2015 19:01:28 GMT"}, {"version": "v2", "created": "Tue, 12 May 2015 17:55:38 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Bonaci", "Tamara", ""], ["Herron", "Jeffrey", ""], ["Yusuf", "Tariq", ""], ["Yan", "Junjie", ""], ["Kohno", "Tadayoshi", ""], ["Chizeck", "Howard Jay", ""]]}, {"id": "1504.04499", "submitter": "Manoj Mishra", "authors": "Manoj Mishra, Bikash Kumar Dey, Vinod M. Prabhakaran, Suhas Diggavi", "title": "On the Oblivious Transfer Capacity of the Degraded Wiretapped Binary\n  Erasure Channel", "comments": "To be presented at the IEEE International Symposium on Information\n  Theory (ISIT 2015), Hong Kong", "journal-ref": null, "doi": "10.1109/ISIT.2015.7282639", "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study oblivious transfer (OT) between Alice and Bob in the presence of an\neavesdropper Eve over a degraded wiretapped binary erasure channel from Alice\nto Bob and Eve. In addition to the privacy goals of oblivious transfer between\nAlice and Bob, we require privacy of Alice and Bob's private data from Eve. In\nprevious work we derived the OT capacity (in the honest-but-curious model) of\nthe wiretapped binary independent erasure channel where the erasure processes\nof Bob and Eve are independent. Here we derive a lower bound on the OT capacity\nin the same secrecy model when the wiretapped binary erasure channel is\ndegraded in favour of Bob.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2015 13:00:47 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Mishra", "Manoj", ""], ["Dey", "Bikash Kumar", ""], ["Prabhakaran", "Vinod M.", ""], ["Diggavi", "Suhas", ""]]}, {"id": "1504.04686", "submitter": "Raef Bassily", "authors": "Raef Bassily and Adam Smith", "title": "Local, Private, Efficient Protocols for Succinct Histograms", "comments": null, "journal-ref": null, "doi": "10.1145/2746539.2746632", "report-no": null, "categories": "cs.CR cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give efficient protocols and matching accuracy lower bounds for frequency\nestimation in the local model for differential privacy. In this model,\nindividual users randomize their data themselves, sending differentially\nprivate reports to an untrusted server that aggregates them.\n  We study protocols that produce a succinct histogram representation of the\ndata. A succinct histogram is a list of the most frequent items in the data\n(often called \"heavy hitters\") along with estimates of their frequencies; the\nfrequency of all other items is implicitly estimated as 0.\n  If there are $n$ users whose items come from a universe of size $d$, our\nprotocols run in time polynomial in $n$ and $\\log(d)$. With high probability,\nthey estimate the accuracy of every item up to error\n$O\\left(\\sqrt{\\log(d)/(\\epsilon^2n)}\\right)$ where $\\epsilon$ is the privacy\nparameter. Moreover, we show that this much error is necessary, regardless of\ncomputational efficiency, and even for the simple setting where only one item\nappears with significant frequency in the data set.\n  Previous protocols (Mishra and Sandler, 2006; Hsu, Khanna and Roth, 2012) for\nthis task either ran in time $\\Omega(d)$ or had much worse error (about\n$\\sqrt[6]{\\log(d)/(\\epsilon^2n)}$), and the only known lower bound on error was\n$\\Omega(1/\\sqrt{n})$.\n  We also adapt a result of McGregor et al (2010) to the local setting. In a\nmodel with public coins, we show that each user need only send 1 bit to the\nserver. For all known local protocols (including ours), the transformation\npreserves computational efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2015 06:23:34 GMT"}], "update_date": "2015-04-21", "authors_parsed": [["Bassily", "Raef", ""], ["Smith", "Adam", ""]]}, {"id": "1504.04730", "submitter": "Sourav Bhattacharya", "authors": "Sourav Bhattacharya and Otto Huhta and N. Asokan", "title": "LookAhead: Augmenting Crowdsourced Website Reputation Systems With\n  Predictive Modeling", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsafe websites consist of malicious as well as inappropriate sites, such as\nthose hosting questionable or offensive content. Website reputation systems are\nintended to help ordinary users steer away from these unsafe sites. However,\nthe process of assigning safety ratings for websites typically involves humans.\nConsequently it is time consuming, costly and not scalable. This has resulted\nin two major problems: (i) a significant proportion of the web space remains\nunrated and (ii) there is an unacceptable time lag before new websites are\nrated.\n  In this paper, we show that by leveraging structural and content-based\nproperties of websites, it is possible to reliably and efficiently predict\ntheir safety ratings, thereby mitigating both problems. We demonstrate the\neffectiveness of our approach using four datasets of up to 90,000 websites. We\nuse ratings from Web of Trust (WOT), a popular crowdsourced web reputation\nsystem, as ground truth. We propose a novel ensemble classification technique\nthat makes opportunistic use of available structural and content properties of\nwebpages to predict their eventual ratings in two dimensions used by WOT:\ntrustworthiness and child safety. Ours is the first classification system to\npredict such subjective ratings and the same approach works equally well in\nidentifying malicious websites. Across all datasets, our classification\nperforms well with average F$_1$-score in the 74--90\\% range.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2015 15:13:13 GMT"}], "update_date": "2015-04-21", "authors_parsed": [["Bhattacharya", "Sourav", ""], ["Huhta", "Otto", ""], ["Asokan", "N.", ""]]}, {"id": "1504.04768", "submitter": "David Baelde", "authors": "David Baelde, St\\'ephanie Delaune, Lucca Hirschi", "title": "Partial Order Reduction for Security Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Security protocols are concurrent processes that communicate using\ncryptography with the aim of achieving various security properties. Recent work\non their formal verification has brought procedures and tools for deciding\ntrace equivalence properties (e.g., anonymity, unlinkability, vote secrecy) for\na bounded number of sessions. However, these procedures are based on a naive\nsymbolic exploration of all traces of the considered processes which,\nunsurprisingly, greatly limits the scalability and practical impact of the\nverification tools.\n  In this paper, we overcome this difficulty by developing partial order\nreduction techniques for the verification of security protocols. We provide\nreduced transition systems that optimally eliminate redundant traces, and which\nare adequate for model-checking trace equivalence properties of protocols by\nmeans of symbolic execution. We have implemented our reductions in the tool\nApte, and demonstrated that it achieves the expected speedup on various\nprotocols.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2015 21:58:38 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2015 08:32:17 GMT"}, {"version": "v3", "created": "Mon, 7 Sep 2015 16:13:29 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Baelde", "David", ""], ["Delaune", "St\u00e9phanie", ""], ["Hirschi", "Lucca", ""]]}, {"id": "1504.04773", "submitter": "Danila Gorodecky", "authors": "Danila Gorodecky", "title": "Reed-Muller Realization of X (mod P)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article provides a novel technique of X (mod P) realization. It is based\non the Reed-Muller polynomial expansion. The advantage of the approach\nconcludes in the capability to realize X (mod P) for an arbitrary P. The\napproach is competitive with the known realizations on the speed processing.\nAdvantages and results of comparison with the known approaches for X [9:1] and\nP=7 is demonstrated.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2015 22:52:05 GMT"}], "update_date": "2015-04-21", "authors_parsed": [["Gorodecky", "Danila", ""]]}, {"id": "1504.04867", "submitter": "Wojciech Mazurczyk", "authors": "Wojciech Mazurczyk and Luca Caviglione", "title": "Information Hiding as a Challenge for Malware Detection", "comments": "9 pages, 1 table", "journal-ref": "IEEE Security & Privacy magazine, March/April, 2015, Volume:13,\n  Issue: 2, pp. 89-93", "doi": "10.1109/MSP.2015.33", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information hiding techniques are increasingly utilized by the current\nmalware to hide its existence and communication attempts. In this paper we\nhighlight this new trend by reviewing the most notable examples of malicious\nsoftware that shows this capability.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2015 18:39:35 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Mazurczyk", "Wojciech", ""], ["Caviglione", "Luca", ""]]}, {"id": "1504.04971", "submitter": "Serena Elisa Ponta", "authors": "Henrik Plate and Serena Elisa Ponta and Antonino Sabetta", "title": "Impact assessment for vulnerabilities in open-source software libraries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software applications integrate more and more open-source software (OSS) to\nbenefit from code reuse. As a drawback, each vulnerability discovered in\nbundled OSS potentially affects the application. Upon the disclosure of every\nnew vulnerability, the application vendor has to decide whether it is\nexploitable in his particular usage context, hence, whether users require an\nurgent application patch containing a non-vulnerable version of the OSS.\nCurrent decision making is mostly based on high-level vulnerability\ndescriptions and expert knowledge, thus, effort intense and error prone. This\npaper proposes a pragmatic approach to facilitate the impact assessment,\ndescribes a proof-of-concept for Java, and examines one example vulnerability\nas case study. The approach is independent from specific kinds of\nvulnerabilities or programming languages and can deliver immediate results.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2015 08:47:29 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2015 11:35:07 GMT"}], "update_date": "2015-04-22", "authors_parsed": [["Plate", "Henrik", ""], ["Ponta", "Serena Elisa", ""], ["Sabetta", "Antonino", ""]]}, {"id": "1504.05226", "submitter": "Daniel Caragata", "authors": "Daniel Caragata", "title": "On the Security of a Revised Fragile Watermarking Scheme", "comments": "To be submitted to AEU INT J ELECTRON C", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes a revised fragile watermarking scheme proposed by Botta\net al. which was developed as a revision of the watermarking scheme previously\nproposed by Rawat et al. A new attack is presented that allows an attacker to\napply a valid watermark on tampered images, therefore circumventing the\nprotection that the watermarking scheme under study was supposed to offer.\nFurthermore, the presented attack has very low computational and memory\nrequirements.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2015 20:53:29 GMT"}], "update_date": "2015-04-22", "authors_parsed": [["Caragata", "Daniel", ""]]}, {"id": "1504.05255", "submitter": "Tommaso Gagliardoni", "authors": "Tommaso Gagliardoni, Andreas H\\\"ulsing, Christian Schaffner", "title": "Semantic Security and Indistinguishability in the Quantum World", "comments": "37 pages, 2 figures", "journal-ref": null, "doi": "10.1007/978-3-662-53015-3_3", "report-no": null, "categories": "cs.CR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At CRYPTO 2013, Boneh and Zhandry initiated the study of quantum-secure\nencryption. They proposed first indistinguishability definitions for the\nquantum world where the actual indistinguishability only holds for classical\nmessages, and they provide arguments why it might be hard to achieve a stronger\nnotion. In this work, we show that stronger notions are achievable, where the\nindistinguishability holds for quantum superpositions of messages. We\ninvestigate exhaustively the possibilities and subtle differences in defining\nsuch a quantum indistinguishability notion for symmetric-key encryption\nschemes. We justify our stronger definition by showing its equivalence to novel\nquantum semantic-security notions that we introduce. Furthermore, we show that\nour new security definitions cannot be achieved by a large class of ciphers --\nthose which are quasi-preserving the message length. On the other hand, we\nprovide a secure construction based on quantum-resistant pseudorandom\npermutations; this construction can be used as a generic transformation for\nturning a large class of encryption schemes into quantum indistinguishable and\nhence quantum semantically secure ones. Moreover, our construction is the first\ncompletely classical encryption scheme shown to be secure against an even\nstronger notion of indistinguishability, which was previously known to be\nachievable only by using quantum messages and arbitrary quantum encryption\ncircuits.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2015 22:50:02 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2015 14:22:50 GMT"}, {"version": "v3", "created": "Tue, 31 May 2016 16:21:58 GMT"}, {"version": "v4", "created": "Wed, 1 Jun 2016 13:58:10 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Gagliardoni", "Tommaso", ""], ["H\u00fclsing", "Andreas", ""], ["Schaffner", "Christian", ""]]}, {"id": "1504.05276", "submitter": "Rasheed Hussain", "authors": "Rasheed Hussain, Donghyun Kim, Michele Nogueira, Junggab Son, Alade O.\n  Tokuta, and Heekuck Oh", "title": "PBF: A New Privacy-Aware Billing Framework for Online Electric Vehicles\n  with Bidirectional Auditability", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently an online electric vehicle (OLEV) concept has been introduced, where\nvehicles are propelled through the wirelessly transmitted electrical power from\nthe infrastructure installed under the road while moving. The absence of\nsecure-and-fair billing is one main hurdle to widely adopt this promising\ntechnology. This paper introduces a secure and privacy-aware fair billing\nframework for OLEV on the move through the charging plates installed under the\nroad. We first propose two extreme lightweight mutual authentication\nmechanisms, a direct authentication and a hash chain-based authentication\nbetween vehicles and the charging plates that can be used for different\nvehicular speeds on the road. Second we propose a secure and privacy-aware\nwireless power transfer on move for the vehicles with bidirectional\nauditability guarantee by leveraging game-theoretic approach. Each charging\nplate transfers a fixed amount of energy to the vehicle and bills the vehicle\nin a privacy-aware way accordingly. Our protocol guarantees secure,\nprivacy-aware, and fair billing mechanism for the OLEVs while receiving\nelectric power from the road. Moreover our proposed framework can play a vital\nrole in eliminating the security and privacy challenges in the deployment of\npower transfer technology to the OLEVs.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2015 02:13:04 GMT"}], "update_date": "2015-04-22", "authors_parsed": [["Hussain", "Rasheed", ""], ["Kim", "Donghyun", ""], ["Nogueira", "Michele", ""], ["Son", "Junggab", ""], ["Tokuta", "Alade O.", ""], ["Oh", "Heekuck", ""]]}, {"id": "1504.05353", "submitter": "Ryo Kikuchi", "authors": "Dai Ikarashi, Ryo Kikuchi, Koji Chida, Katsumi Takahashi", "title": "k-anonymous Microdata Release via Post Randomisation Method", "comments": "22 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of the release of anonymized microdata is an important topic in\nthe fields of statistical disclosure control (SDC) and privacy preserving data\npublishing (PPDP), and yet it remains sufficiently unsolved. In these research\nfields, k-anonymity has been widely studied as an anonymity notion for mainly\ndeterministic anonymization algorithms, and some probabilistic relaxations have\nbeen developed. However, they are not sufficient due to their limitations,\ni.e., being weaker than the original k-anonymity or requiring strong parametric\nassumptions. First we propose Pk-anonymity, a new probabilistic k-anonymity,\nand prove that Pk-anonymity is a mathematical extension of k-anonymity rather\nthan a relaxation. Furthermore, Pk-anonymity requires no parametric\nassumptions. This property has a significant meaning in the viewpoint that it\nenables us to compare privacy levels of probabilistic microdata release\nalgorithms with deterministic ones. Second, we apply Pk-anonymity to the post\nrandomization method (PRAM), which is an SDC algorithm based on randomization.\nPRAM is proven to satisfy Pk-anonymity in a controlled way, i.e, one can\ncontrol PRAM's parameter so that Pk-anonymity is satisfied. On the other hand,\nPRAM is also known to satisfy ${\\varepsilon}$-differential privacy, a recent\npopular and strong privacy notion. This fact means that our results\nsignificantly enhance PRAM since it implies the satisfaction of both important\nnotions: k-anonymity and ${\\varepsilon}$-differential privacy.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2015 09:34:07 GMT"}], "update_date": "2015-04-22", "authors_parsed": [["Ikarashi", "Dai", ""], ["Kikuchi", "Ryo", ""], ["Chida", "Koji", ""], ["Takahashi", "Katsumi", ""]]}, {"id": "1504.05431", "submitter": "Jean-Pierre  Tillich", "authors": "Adrien Hauteville and Jean-Pierre Tillich", "title": "New algorithms for decoding in the rank metric and an attack on the LRPC\n  cryptosystem", "comments": "A shortened version of this paper will be published in the\n  proceedings of the IEEE International Symposium on Information Theory 2015\n  (ISIT 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the decoding problem or the problem of finding low weight\ncodewords for rank metric codes. We show how additional information about the\ncodeword we want to find under the form of certain linear combinations of the\nentries of the codeword leads to algorithms with a better complexity. This is\nthen used together with a folding technique for attacking a McEliece scheme\nbased on LRPC codes. It leads to a feasible attack on one of the parameters\nsuggested in \\cite{GMRZ13}.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2015 13:37:04 GMT"}], "update_date": "2015-04-22", "authors_parsed": [["Hauteville", "Adrien", ""], ["Tillich", "Jean-Pierre", ""]]}, {"id": "1504.05522", "submitter": "Rupesh Gunturu", "authors": "Rupesh Gunturu", "title": "Survey of Sybil Attacks in Social Networks", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviews the Sybil attack in social networks, which has the\npotential to compromise the whole distributed network. In the Sybil attack, the\nmalicious user claims multiple identities to compromise the network. Sybil\nattacks can be used to change the overall ranking in voting applications,\nbad-mouth an opinion, access resources or to break the trust mechanism behind a\nP2P network. In this paper, different defense mechanisms used to mitigate Sybil\nattacks are also reviewed.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2015 17:43:30 GMT"}], "update_date": "2015-04-22", "authors_parsed": [["Gunturu", "Rupesh", ""]]}, {"id": "1504.05566", "submitter": "Shaunak Mishra", "authors": "Shaunak Mishra, Yasser Shoukry, Nikhil Karamchandani, Suhas Diggavi\n  and Paulo Tabuada", "title": "Secure State Estimation: Optimal Guarantees against Sensor Attacks in\n  the Presence of Noise", "comments": "A shorter version of this work will appear in the proceedings of ISIT\n  2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CR cs.IT cs.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the need to secure cyber-physical systems against attacks, we\nconsider the problem of estimating the state of a noisy linear dynamical system\nwhen a subset of sensors is arbitrarily corrupted by an adversary. We propose a\nsecure state estimation algorithm and derive (optimal) bounds on the achievable\nstate estimation error. In addition, as a result of independent interest, we\ngive a coding theoretic interpretation for prior work on secure state\nestimation against sensor attacks in a noiseless dynamical system.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2015 19:52:18 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2015 00:43:38 GMT"}], "update_date": "2015-04-24", "authors_parsed": [["Mishra", "Shaunak", ""], ["Shoukry", "Yasser", ""], ["Karamchandani", "Nikhil", ""], ["Diggavi", "Suhas", ""], ["Tabuada", "Paulo", ""]]}, {"id": "1504.05646", "submitter": "Vanessa Teague", "authors": "J. Alex Halderman (University of Michigan) and Vanessa Teague\n  (University of Melbourne)", "title": "The New South Wales iVote System: Security Failures and Verification\n  Flaws in a Live Online Election", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the world's largest-ever deployment of online voting, the iVote Internet\nvoting system was trusted for the return of 280,000 ballots in the 2015 state\nelection in New South Wales, Australia. During the election, we performed an\nindependent security analysis of parts of the live iVote system and uncovered\nsevere vulnerabilities that could be leveraged to manipulate votes, violate\nballot privacy, and subvert the verification mechanism. These vulnerabilities\ndo not seem to have been detected by the election authorities before we\ndisclosed them, despite a pre-election security review and despite the system\nhaving run in a live state election for five days. One vulnerability, the\nresult of including analytics software from an insecure external server,\nexposed some votes to complete compromise of privacy and integrity. At least\none parliamentary seat was decided by a margin much smaller than the number of\nvotes taken while the system was vulnerable. We also found protocol flaws,\nincluding vote verification that was itself susceptible to manipulation. This\nincident underscores the difficulty of conducting secure elections online and\ncarries lessons for voters, election officials, and the e-voting research\ncommunity.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2015 03:42:36 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2015 19:17:31 GMT"}], "update_date": "2015-06-08", "authors_parsed": [["Halderman", "J. Alex", "", "University of Michigan"], ["Teague", "Vanessa", "", "University of Melbourne"]]}, {"id": "1504.05647", "submitter": "Bushra Aloraini", "authors": "Bushra Aloraini, Daryl Johnson, Bill Stackpole, and Sumita Mishra", "title": "A New Covert Channel over Cellular Voice Channel in Smartphones", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Investigating network covert channels in smartphones has become increasingly\nimportant as smartphones have recently replaced the role of traditional\ncomputers. Smartphones are subject to traditional computer network covert\nchannel techniques. Smartphones also introduce new sets of covert channel\ntechniques as they add more capabilities and multiple network connections. This\nwork presents a new network covert channel in smartphones. The research studies\nthe ability to leak information from the smartphones applications by reaching\nthe cellular voice stream, and it examines the ability to employ the cellular\nvoice channel to be a potential medium of information leakage through carrying\nmodulated speech-like data covertly. To validate the theory, an Android\nsoftware audio modem has been developed and it was able to leak data\nsuccessfully through the cellular voice channel stream by carrying modulated\ndata with a throughput of 13 bps with 0.018% BER. Moreover, Android security\npolicies are investigated and broken in order to implement a user-mode rootkit\nthat opens the voice channels by stealthily answering an incoming voice call.\nMultiple scenarios are conducted to verify the effectiveness of the proposed\ncovert channel. This study identifies a new potential smartphone covert\nchannel, and discusses some security vulnerabilities in Android OS that allow\nthe use of this channel demonstrating the need to set countermeasures against\nthis kind of breach.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2015 03:49:23 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2015 05:49:10 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Aloraini", "Bushra", ""], ["Johnson", "Daryl", ""], ["Stackpole", "Bill", ""], ["Mishra", "Sumita", ""]]}, {"id": "1504.05800", "submitter": "Uri Stemmer", "authors": "Kobbi Nissim, Uri Stemmer", "title": "On the Generalization Properties of Differential Privacy", "comments": "This paper was merged with another manuscript and is now subsumed by\n  arXiv:1511.02513", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new line of work, started with Dwork et al., studies the task of answering\nstatistical queries using a sample and relates the problem to the concept of\ndifferential privacy. By the Hoeffding bound, a sample of size $O(\\log\nk/\\alpha^2)$ suffices to answer $k$ non-adaptive queries within error $\\alpha$,\nwhere the answers are computed by evaluating the statistical queries on the\nsample. This argument fails when the queries are chosen adaptively (and can\nhence depend on the sample). Dwork et al. showed that if the answers are\ncomputed with $(\\epsilon,\\delta)$-differential privacy then $O(\\epsilon)$\naccuracy is guaranteed with probability $1-O(\\delta^\\epsilon)$. Using the\nPrivate Multiplicative Weights mechanism, they concluded that the sample size\ncan still grow polylogarithmically with the $k$.\n  Very recently, Bassily et al. presented an improved bound and showed that (a\nvariant of) the private multiplicative weights algorithm can answer $k$\nadaptively chosen statistical queries using sample complexity that grows\nlogarithmically in $k$. However, their results no longer hold for every\ndifferentially private algorithm, and require modifying the private\nmultiplicative weights algorithm in order to obtain their high probability\nbounds.\n  We greatly simplify the results of Dwork et al. and improve on the bound by\nshowing that differential privacy guarantees $O(\\epsilon)$ accuracy with\nprobability $1-O(\\delta\\log(1/\\epsilon)/\\epsilon)$. It would be tempting to\nguess that an $(\\epsilon,\\delta)$-differentially private computation should\nguarantee $O(\\epsilon)$ accuracy with probability $1-O(\\delta)$. However, we\nshow that this is not the case, and that our bound is tight (up to logarithmic\nfactors).\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2015 13:40:04 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2015 03:08:34 GMT"}], "update_date": "2015-11-11", "authors_parsed": [["Nissim", "Kobbi", ""], ["Stemmer", "Uri", ""]]}, {"id": "1504.05862", "submitter": "Parisa Babaheidarian", "authors": "Parisa Babaheidarian and Somayeh Salimi", "title": "Compute-and-Forward Can Buy Secrecy Cheap", "comments": "Accepted to ISIT 2015, 5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a Gaussian multiple access channel with $K$ transmitters, a\n(intended) receiver and an external eavesdropper. The transmitters wish to\nreliably communicate with the receiver while concealing their messages from the\neavesdropper. This scenario has been investigated in prior works using two\ndifferent coding techniques; the random i.i.d. Gaussian coding and the signal\nalignment coding. Although, the latter offers promising results in a very high\nSNR regime, extending these results to the finite SNR regime is a challenging\ntask. In this paper, we propose a new lattice alignment scheme based on the\ncompute-and-forward framework which works at any finite SNR. We show that our\nachievable secure sum rate scales with $\\log(\\mathrm{SNR})$ and hence, in most\nSNR regimes, our scheme outperforms the random coding scheme in which the\nsecure sum rate does not grow with power. Furthermore, we show that our result\nmatches the prior work in the infinite SNR regime. Additionally, we analyze our\nresult numerically.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2015 16:25:54 GMT"}], "update_date": "2015-04-23", "authors_parsed": [["Babaheidarian", "Parisa", ""], ["Salimi", "Somayeh", ""]]}, {"id": "1504.05880", "submitter": "Shiva Kasiviswanathan", "authors": "Shiva Prasad Kasiviswanathan and Mark Rudelson", "title": "Spectral Norm of Random Kernel Matrices with Applications to Privacy", "comments": "16 pages, 1 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods are an extremely popular set of techniques used for many\nimportant machine learning and data analysis applications. In addition to\nhaving good practical performances, these methods are supported by a\nwell-developed theory. Kernel methods use an implicit mapping of the input data\ninto a high dimensional feature space defined by a kernel function, i.e., a\nfunction returning the inner product between the images of two data points in\nthe feature space. Central to any kernel method is the kernel matrix, which is\nbuilt by evaluating the kernel function on a given sample dataset.\n  In this paper, we initiate the study of non-asymptotic spectral theory of\nrandom kernel matrices. These are n x n random matrices whose (i,j)th entry is\nobtained by evaluating the kernel function on $x_i$ and $x_j$, where\n$x_1,...,x_n$ are a set of n independent random high-dimensional vectors. Our\nmain contribution is to obtain tight upper bounds on the spectral norm (largest\neigenvalue) of random kernel matrices constructed by commonly used kernel\nfunctions based on polynomials and Gaussian radial basis.\n  As an application of these results, we provide lower bounds on the distortion\nneeded for releasing the coefficients of kernel ridge regression under\nattribute privacy, a general privacy notion which captures a large class of\nprivacy definitions. Kernel ridge regression is standard method for performing\nnon-parametric regression that regularly outperforms traditional regression\napproaches in various domains. Our privacy distortion lower bounds are the\nfirst for any kernel technique, and our analysis assumes realistic scenarios\nfor the input, unlike all previous lower bounds for other release problems\nwhich only hold under very restrictive input settings.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2015 16:54:48 GMT"}], "update_date": "2015-04-23", "authors_parsed": [["Kasiviswanathan", "Shiva Prasad", ""], ["Rudelson", "Mark", ""]]}, {"id": "1504.05967", "submitter": "Dragos Sbirlea", "authors": "Daniel Song, Jisheng Zhao, Michael Burke, Drago\\c{s} Sb\\^irlea, Dan\n  Wallach, and Vivek Sarkar", "title": "Finding Tizen security bugs through whole-system static analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tizen is a new Linux-based open source platform for consumer devices\nincluding smartphones, televisions, vehicles, and wearables. While Tizen\nprovides kernel-level mandatory policy enforcement, it has a large collection\nof libraries, implemented in a mix of C and C++, which make their own security\nchecks. In this research, we describe the design and engineering of a static\nanalysis engine which drives a full information flow analysis for apps and a\ncontrol flow analysis for the full library stack. We implemented these static\nanalyses as extensions to LLVM, requiring us to improve LLVM's native analysis\nfeatures to get greater precision and scalability, including knotty issues like\nthe coexistence of C++ inheritance with C function pointer use. With our tools,\nwe found several unexpected behaviors in the Tizen system, including paths\nthrough the system libraries that did not have inline security checks. We show\nhow our tools can help the Tizen app store to verify important app properties\nas well as helping the Tizen development process avoid the accidental\nintroduction of subtle vulnerabilities.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2015 20:02:04 GMT"}], "update_date": "2015-04-24", "authors_parsed": [["Song", "Daniel", ""], ["Zhao", "Jisheng", ""], ["Burke", "Michael", ""], ["Sb\u00eerlea", "Drago\u015f", ""], ["Wallach", "Dan", ""], ["Sarkar", "Vivek", ""]]}, {"id": "1504.05997", "submitter": "Dong Su", "authors": "Dong Su, Jianneng Cao, Ninghui Li", "title": "Differentially Private Projected Histograms of Multi-Attribute Data for\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this paper, we tackle the problem of constructing a differentially private\nsynopsis for the classification analyses. Several the state-of-the-art methods\nfollow the structure of existing classification algorithms and are all\niterative, which is suboptimal due to the locally optimal choices and the\nover-divided privacy budget among many sequentially composed steps. Instead, we\npropose a new approach, PrivPfC, a new differentially private method for\nreleasing data for classification. The key idea is to privately select an\noptimal partition of the underlying dataset using the given privacy budget in\none step. Given one dataset and the privacy budget, PrivPfC constructs a pool\nof candidate grids where the number of cells of each grid is under a data-aware\nand privacy-budget-aware threshold. After that, PrivPfC selects an optimal grid\nvia the exponential mechanism by using a novel quality function which minimizes\nthe expected number of misclassified records on which a histogram classifier is\nconstructed using the published grid. Finally, PrivPfC injects noise into each\ncell of the selected grid and releases the noisy grid as the private synopsis\nof the data. If the size of the candidate grid pool is larger than the\nprocessing capability threshold set by the data curator, we add a step in the\nbeginning of PrivPfC to prune the set of attributes privately. We introduce a\nmodified $\\chi^2$ quality function with low sensitivity and use it to evaluate\nan attribute's relevance to the classification label variable. Through\nextensive experiments on real datasets, we demonstrate PrivPfC's superiority\nover the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2015 22:20:26 GMT"}], "update_date": "2015-04-24", "authors_parsed": [["Su", "Dong", ""], ["Cao", "Jianneng", ""], ["Li", "Ninghui", ""]]}, {"id": "1504.05998", "submitter": "Dong Su", "authors": "Dong Su, Jianneng Cao, Ninghui Li, Elisa Bertino, Hongxia Jin", "title": "Differentially Private $k$-Means Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  There are two broad approaches for differentially private data analysis. The\ninteractive approach aims at developing customized differentially private\nalgorithms for various data mining tasks. The non-interactive approach aims at\ndeveloping differentially private algorithms that can output a synopsis of the\ninput dataset, which can then be used to support various data mining tasks. In\nthis paper we study the tradeoff of interactive vs. non-interactive approaches\nand propose a hybrid approach that combines interactive and non-interactive,\nusing $k$-means clustering as an example. In the hybrid approach to\ndifferentially private $k$-means clustering, one first uses a non-interactive\nmechanism to publish a synopsis of the input dataset, then applies the standard\n$k$-means clustering algorithm to learn $k$ cluster centroids, and finally uses\nan interactive approach to further improve these cluster centroids. We analyze\nthe error behavior of both non-interactive and interactive approaches and use\nsuch analysis to decide how to allocate privacy budget between the\nnon-interactive step and the interactive step. Results from extensive\nexperiments support our analysis and demonstrate the effectiveness of our\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2015 22:21:30 GMT"}], "update_date": "2015-04-24", "authors_parsed": [["Su", "Dong", ""], ["Cao", "Jianneng", ""], ["Li", "Ninghui", ""], ["Bertino", "Elisa", ""], ["Jin", "Hongxia", ""]]}, {"id": "1504.06541", "submitter": "Elias Gonzalez", "authors": "Elias Gonzalez, Robert S. Balog, Laszlo B. Kish", "title": "Resource requirements and speed versus geometry of unconditionally\n  secure physical key exchanges", "comments": "13 pages, 7 figures, MDPI Entropy", "journal-ref": "Entropy 2015, 17(4), pp. 2010-2024", "doi": "10.3390/e17042010", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The imperative need for unconditional secure key exchange is expounded by the\nincreasing connectivity of networks and by the increasing number and level of\nsophistication of cyberattacks. Two concepts that are information theoretically\nsecure are quantum key distribution (QKD) and Kirchoff-law-Johnson-noise\n(KLJN). However, these concepts require a dedicated connection between hosts in\npeer-to-peer (P2P) networks which can be impractical and or cost prohibitive. A\npractical and cost effective method is to have each host share their respective\ncable(s) with other hosts such that two remote hosts can realize a secure key\nexchange without the need of an additional cable or key exchanger. In this\narticle we analyze the cost complexities of cable, key exchangers, and time\nrequired in the star network. We mentioned the reliability of the star network\nand compare it with other network geometries. We also conceived a protocol and\nequation for the number of secure bit exchange periods needed in a star\nnetwork. We then outline other network geometries and trade-off possibilities\nthat seem interesting to explore.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2015 15:32:03 GMT"}], "update_date": "2015-04-27", "authors_parsed": [["Gonzalez", "Elias", ""], ["Balog", "Robert S.", ""], ["Kish", "Laszlo B.", ""]]}, {"id": "1504.06893", "submitter": "Emre Erturk", "authors": "Emre Erturk", "title": "Two Trends in Mobile Security: Financial Motives and Transitioning from\n  Static to Dynamic Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to analyze the behavior and intent of recent types\nof privacy invasive Android adware. There are two recent trends in this area:\nmore financial motives instead of ego motives, and the development of more\ndynamic analysis tools. This paper starts with a review of Android mobile\noperating system security, and also addresses the pros and cons of open source\noperating system security. Static analysis of malware provides high quality\nresults and leads to a good understanding as shown in this paper. However, as\nmalware grows in number and complexity, there have been recent efforts to\nautomate the detection mechanisms and many of the static tasks. As Android's\nmarket share is rapidly growing around the world. Android security will be a\ncrucial area of research for IT security professionals and their academic\ncounterparts. The upside of the current situation is that malware is being\nquickly exposed, thanks to open source software development tools. This\ncooperation is important in curbing the widespread theft of personal\ninformation with monetary value.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2015 23:26:27 GMT"}], "update_date": "2015-04-28", "authors_parsed": [["Erturk", "Emre", ""]]}, {"id": "1504.06920", "submitter": "Swapnil Kharche Mr", "authors": "Swapnil Kharche, Jagdish patil, Kanchan Gohad, Bharti Ambetkar", "title": "Preventing SQL Injection attack using pattern matching algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SQL injection attacks, a class of injection flaw in which specially crafted\ninput strings leads to illegal queries to databases, are one of the topmost\nthreats to web applications. A Number of research prototypes and commercial\nproducts that maintain the queries structure in web applications have been\ndeveloped. But these techniques either fail to address the full scope of the\nproblem or have limitations. Based on our observation that the injected string\nin a SQL injection attack is interpreted differently on different\ndatabases.Injection attack is a method that can inject any kind of malicious\nstring or anomaly string on the original string. Pattern matching is a\ntechnique that can be used to identify or detect any anomaly packet from a\nsequential action. Most of the pattern based techniques are used static\nanalysis and patterns are generated from the attacked statements. In this\npaper, we proposed a detection and prevention technique for preventing SQL\nInjection Attack using AhoCorasick pattern matching algorithm. In this paper,\nwe proposed an overview of the architecture. In the initial stage evaluation,\nwe consider some sample of standard attack patterns and it shows that the\nproposed algorithm is works well against the SQL Injection Attack.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2015 03:42:47 GMT"}], "update_date": "2015-04-28", "authors_parsed": [["Kharche", "Swapnil", ""], ["patil", "Jagdish", ""], ["Gohad", "Kanchan", ""], ["Ambetkar", "Bharti", ""]]}, {"id": "1504.06998", "submitter": "Mohammad Alaggan", "authors": "Mohammad Alaggan, S\\'ebastien Gambs, Anne-Marie Kermarrec", "title": "Heterogeneous Differential Privacy", "comments": "27 pages, 3 figures, presented at the first workshop on theory and\n  practice of differential privacy (TPDP 2015) at London, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The massive collection of personal data by personalization systems has\nrendered the preservation of privacy of individuals more and more difficult.\nMost of the proposed approaches to preserve privacy in personalization systems\nusually address this issue uniformly across users, thus ignoring the fact that\nusers have different privacy attitudes and expectations (even among their own\npersonal data). In this paper, we propose to account for this non-uniformity of\nprivacy expectations by introducing the concept of heterogeneous differential\nprivacy. This notion captures both the variation of privacy expectations among\nusers as well as across different pieces of information related to the same\nuser. We also describe an explicit mechanism achieving heterogeneous\ndifferential privacy, which is a modification of the Laplacian mechanism by\nDwork, McSherry, Nissim, and Smith. In a nutshell, this mechanism achieves\nheterogeneous differential privacy by manipulating the sensitivity of the\nfunction using a linear transformation on the input domain. Finally, we\nevaluate on real datasets the impact of the proposed mechanism with respect to\na semantic clustering task. The results of our experiments demonstrate that\nheterogeneous differential privacy can account for different privacy attitudes\nwhile sustaining a good level of utility as measured by the recall for the\nsemantic clustering task.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2015 09:35:46 GMT"}], "update_date": "2015-04-28", "authors_parsed": [["Alaggan", "Mohammad", ""], ["Gambs", "S\u00e9bastien", ""], ["Kermarrec", "Anne-Marie", ""]]}, {"id": "1504.07098", "submitter": "Steve Schneider", "authors": "Craig Burton, Chris Culnane and Steve Schneider", "title": "Secure and Verifiable Electronic Voting in Practice: the use of vVote in\n  the Victorian State Election", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The November 2014 Australian State of Victoria election was the first\nstatutory political election worldwide at State level which deployed an\nend-to-end verifiable electronic voting system in polling places. This was the\nfirst time blind voters have been able to cast a fully secret ballot in a\nverifiable way, and the first time a verifiable voting system has been used to\ncollect remote votes in a political election. The code is open source, and the\noutput from the election is verifiable. The system took 1121 votes from these\nparticular groups, an increase on 2010 and with fewer polling places.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2015 14:08:24 GMT"}], "update_date": "2015-04-28", "authors_parsed": [["Burton", "Craig", ""], ["Culnane", "Chris", ""], ["Schneider", "Steve", ""]]}, {"id": "1504.07135", "submitter": "Homa Alemzadeh", "authors": "Homa Alemzadeh, Daniel Chen, Andrew Lewis, Zbigniew Kalbarczyk,\n  Jaishankar Raman, Nancy Leveson, and Ravishankar K. Iyer", "title": "Systems-theoretic Safety Assessment of Robotic Telesurgical Systems", "comments": "Revise based on reviewers feedback. To appear in the the\n  International Conference on Computer Safety, Reliability, and Security\n  (SAFECOMP) 2015", "journal-ref": null, "doi": "10.1007/978-3-319-24255-2_16", "report-no": null, "categories": "cs.RO cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic telesurgical systems are one of the most complex medical\ncyber-physical systems on the market, and have been used in over 1.75 million\nprocedures during the last decade. Despite significant improvements in design\nof robotic surgical systems through the years, there have been ongoing\noccurrences of safety incidents during procedures that negatively impact\npatients. This paper presents an approach for systems-theoretic safety\nassessment of robotic telesurgical systems using software-implemented\nfault-injection. We used a systemstheoretic hazard analysis technique (STPA) to\nidentify the potential safety hazard scenarios and their contributing causes in\nRAVEN II robot, an open-source robotic surgical platform. We integrated the\nrobot control software with a softwareimplemented fault-injection engine which\nmeasures the resilience of the system to the identified safety hazard scenarios\nby automatically inserting faults into different parts of the robot control\nsoftware. Representative hazard scenarios from real robotic surgery incidents\nreported to the U.S. Food and Drug Administration (FDA) MAUDE database were\nused to demonstrate the feasibility of the proposed approach for safety-based\ndesign of robotic telesurgical systems.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2015 15:39:17 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2015 23:09:20 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Alemzadeh", "Homa", ""], ["Chen", "Daniel", ""], ["Lewis", "Andrew", ""], ["Kalbarczyk", "Zbigniew", ""], ["Raman", "Jaishankar", ""], ["Leveson", "Nancy", ""], ["Iyer", "Ravishankar K.", ""]]}, {"id": "1504.07192", "submitter": "Marcos Portnoi", "authors": "Marcos Portnoi, Chien-Chung Shen", "title": "Location-aware sign-on and key exchange using attribute-based encryption\n  and Bluetooth beacons", "comments": "Communications and Network Security (CNS), 2013 IEEE Conference on.\n  arXiv admin note: text overlap with arXiv:1410.0983", "journal-ref": null, "doi": "10.1109/CNS.2013.6682750", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a mobile sign-on scheme, which utilizes Bluetooth Low\nEnergy beacons for location awareness and Attribute-Based Encryption for\nexpressive, broadcast-style key exchange. Bluetooth Low Energy beacons\nbroadcast encrypted messages with encoded access policies. Within range of the\nbeacons, a user with appropriate attributes is able to decrypt the broadcast\nmessage and obtain parameters that allow the user to perform a short or\nsimplified login. The effect is a \"traveling\" sign-on that accompanies the user\nthroughout different locations.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2015 18:11:24 GMT"}], "update_date": "2015-04-28", "authors_parsed": [["Portnoi", "Marcos", ""], ["Shen", "Chien-Chung", ""]]}, {"id": "1504.07193", "submitter": "Marcos Portnoi", "authors": "Marcos Portnoi, Chien-Chung Shen", "title": "Secure Zones: An Attribute-Based Encryption advisory system for safe\n  firearms", "comments": "Communications and Network Security (CNS), 2013 IEEE Conference on.\n  arXiv admin note: substantial text overlap with arXiv:1411.1733", "journal-ref": null, "doi": "10.1109/CNS.2013.6682746", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents an application of the highly expressive Attribute-Based\nEncryption to implement Secure Zones for firearms. Within these zones,\nradio-transmitted local policies based on attributes of the user and the\nfirearm are received by embedded hardware in the firearms, which then advises\nthe user about safe operations. The Secure Zones utilize Attribute-Based\nEncryption to encode the policies and user attributes, and providing privacy\nand security through it cryptography. We describe a holistic approach to\nevolving the firearm to a cyber-physical system to aid in augmenting safety. We\nintroduce a conceptual model for a firearm equipped with sensors and a\ncontext-aware software agent. Based on the information from the sensors, the\nagent can access the context and inform the user of potential unsafe\noperations. To support Secure Zones and the cyber-physical firearm model, we\npropose a Key Infrastructure Scheme for key generation, distribution, and\nmanagement, and a Context-Aware Software Agent Framework for Firearms.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2015 18:11:54 GMT"}], "update_date": "2015-04-28", "authors_parsed": [["Portnoi", "Marcos", ""], ["Shen", "Chien-Chung", ""]]}, {"id": "1504.07313", "submitter": "Daniel Aranki", "authors": "Daniel Aranki and Ruzena Bajcsy", "title": "Private Disclosure of Information in Health Tele-monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel framework, called Private Disclosure of Information (PDI),\nwhich is aimed to prevent an adversary from inferring certain sensitive\ninformation about subjects using the data that they disclosed during\ncommunication with an intended recipient. We show cases where it is possible to\nachieve perfect privacy regardless of the adversary's auxiliary knowledge while\npreserving full utility of the information to the intended recipient and\nprovide sufficient conditions for such cases. We also demonstrate the\napplicability of PDI on a real-world data set that simulates a health\ntele-monitoring scenario.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2015 00:20:50 GMT"}], "update_date": "2015-04-29", "authors_parsed": [["Aranki", "Daniel", ""], ["Bajcsy", "Ruzena", ""]]}, {"id": "1504.07553", "submitter": "Mark Bun", "authors": "Mark Bun and Kobbi Nissim and Uri Stemmer and Salil Vadhan", "title": "Differentially Private Release and Learning of Threshold Functions", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove new upper and lower bounds on the sample complexity of $(\\epsilon,\n\\delta)$ differentially private algorithms for releasing approximate answers to\nthreshold functions. A threshold function $c_x$ over a totally ordered domain\n$X$ evaluates to $c_x(y) = 1$ if $y \\le x$, and evaluates to $0$ otherwise. We\ngive the first nontrivial lower bound for releasing thresholds with\n$(\\epsilon,\\delta)$ differential privacy, showing that the task is impossible\nover an infinite domain $X$, and moreover requires sample complexity $n \\ge\n\\Omega(\\log^*|X|)$, which grows with the size of the domain. Inspired by the\ntechniques used to prove this lower bound, we give an algorithm for releasing\nthresholds with $n \\le 2^{(1+ o(1))\\log^*|X|}$ samples. This improves the\nprevious best upper bound of $8^{(1 + o(1))\\log^*|X|}$ (Beimel et al., RANDOM\n'13).\n  Our sample complexity upper and lower bounds also apply to the tasks of\nlearning distributions with respect to Kolmogorov distance and of properly PAC\nlearning thresholds with differential privacy. The lower bound gives the first\nseparation between the sample complexity of properly learning a concept class\nwith $(\\epsilon,\\delta)$ differential privacy and learning without privacy. For\nproperly learning thresholds in $\\ell$ dimensions, this lower bound extends to\n$n \\ge \\Omega(\\ell \\cdot \\log^*|X|)$.\n  To obtain our results, we give reductions in both directions from releasing\nand properly learning thresholds and the simpler interior point problem. Given\na database $D$ of elements from $X$, the interior point problem asks for an\nelement between the smallest and largest elements in $D$. We introduce new\nrecursive constructions for bounding the sample complexity of the interior\npoint problem, as well as further reductions and techniques for proving\nimpossibility results for other basic problems in differential privacy.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2015 16:15:01 GMT"}], "update_date": "2015-04-29", "authors_parsed": [["Bun", "Mark", ""], ["Nissim", "Kobbi", ""], ["Stemmer", "Uri", ""], ["Vadhan", "Salil", ""]]}, {"id": "1504.07621", "submitter": "Maciej  Skorski", "authors": "Maciej Skorski, Alexander Golovnev, Krzysztof Pietrzak", "title": "Condensed Unpredictability", "comments": "This is the full version of the paper published at ICALP 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of deriving a key with high HILL entropy from an\nunpredictable source. Previous to this work, the only known way to transform\nunpredictability into a key that was $\\eps$ indistinguishable from having\nmin-entropy was via pseudorandomness, for example by Goldreich-Levin (GL)\nhardcore bits. This approach has the inherent limitation that from a source\nwith $k$ bits of unpredictability entropy one can derive a key of length (and\nthus HILL entropy) at most $k-2\\log(1/\\epsilon)$ bits. In many settings, e.g.\nwhen dealing with biometric data, such a $2\\log(1/\\epsilon)$ bit entropy loss\nin not an option. Our main technical contribution is a theorem that states that\nin the high entropy regime, unpredictability implies HILL entropy. The loss in\ncircuit size in this argument is exponential in the entropy gap $d$. To\novercome the above restriction, we investigate if it's possible to first\n\"condense\" unpredictability entropy and make the entropy gap small. We show\nthat any source with $k$ bits of unpredictability can be condensed into a\nsource of length $k$ with $k-3$ bits of unpredictability entropy. Our condenser\nsimply \"abuses\" the GL construction and derives a $k$ bit key from a source\nwith $k$ bits of unpredicatibily. The original GL theorem implies nothing when\nextracting that many bits, but we show that in this regime, GL still behaves\nlike a \"condenser\" for unpredictability. This result comes with two caveats (1)\nthe loss in circuit size is exponential in $k$ and (2) we require that the\nsource we start with has \\emph{no} HILL entropy (equivalently, one can\nefficiently check if a guess is correct). We leave it as an intriguing open\nproblem to overcome these restrictions or to prove they're inherent.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2015 19:59:54 GMT"}], "update_date": "2015-04-29", "authors_parsed": [["Skorski", "Maciej", ""], ["Golovnev", "Alexander", ""], ["Pietrzak", "Krzysztof", ""]]}, {"id": "1504.07912", "submitter": "Adam Smith", "authors": "Sofya Raskhodnikova, Adam Smith", "title": "Efficient Lipschitz Extensions for High-Dimensional Graph Statistics and\n  Node Private Degree Distributions", "comments": "23 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lipschitz extensions were recently proposed as a tool for designing node\ndifferentially private algorithms. However, efficiently computable Lipschitz\nextensions were known only for 1-dimensional functions (that is, functions that\noutput a single real value). In this paper, we study efficiently computable\nLipschitz extensions for multi-dimensional (that is, vector-valued) functions\non graphs. We show that, unlike for 1-dimensional functions, Lipschitz\nextensions of higher-dimensional functions on graphs do not always exist, even\nwith a non-unit stretch. We design Lipschitz extensions with small stretch for\nthe sorted degree list and for the degree distribution of a graph. Crucially,\nour extensions are efficiently computable.\n  We also develop new tools for employing Lipschitz extensions in the design of\ndifferentially private algorithms. Specifically, we generalize the exponential\nmechanism, a widely used tool in data privacy. The exponential mechanism is\ngiven a collection of score functions that map datasets to real values. It\nattempts to return the name of the function with nearly minimum value on the\ndata set. Our generalized exponential mechanism provides better accuracy when\nthe sensitivity of an optimal score function is much smaller than the maximum\nsensitivity of score functions.\n  We use our Lipschitz extension and the generalized exponential mechanism to\ndesign a node-differentially private algorithm for releasing an approximation\nto the degree distribution of a graph. Our algorithm is much more accurate than\nalgorithms from previous work.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2015 16:08:57 GMT"}], "update_date": "2015-04-30", "authors_parsed": [["Raskhodnikova", "Sofya", ""], ["Smith", "Adam", ""]]}, {"id": "1504.07948", "submitter": "William Garrison III", "authors": "William C. Garrison III and Adam J. Lee", "title": "Decomposing, Comparing, and Synthesizing Access Control Expressiveness\n  Simulations (Extended Version)", "comments": "24-page extended version of \"Decomposing, Comparing, and Synthesizing\n  Access Control Expressiveness Simulations\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Access control is fundamental to computer security, and has thus been the\nsubject of extensive formal study. In particular, *relative expressiveness\nanalysis* techniques have used formal mappings called *simulations* to explore\nwhether one access control system is capable of emulating another, thereby\ncomparing the expressive power of these systems. Unfortunately, the notions of\nexpressiveness simulation that have been explored vary widely, which makes it\ndifficult to compare results in the literature, and even leads to apparent\ncontradictions between results. Furthermore, some notions of expressiveness\nsimulation make use of non-determinism, and thus cannot be used to define\nmappings between access control systems that are useful in practical scenarios.\nIn this work, we define the minimum set of properties for an *implementable*\naccess control simulation; i.e., a deterministic \"recipe\" for using one system\nin place of another. We then define a wide range of properties spread across\nseveral dimensions that can be enforced on top of this minimum definition.\nThese properties define a taxonomy that can be used to separate and compare\nexisting notions of access control simulation, many of which were previously\nincomparable. We position existing notions of simulation within our properties\nlattice by formally proving each simulation's equivalence to a corresponding\nset of properties. Lastly, we take steps towards bridging the gap between\ntheory and practice by exploring the systems implications of points within our\nproperties lattice. This shows that relative expressive analysis is more than\njust a theoretical tool, and can also guide the choice of the most suitable\naccess control system for a specific application or scenario.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2015 18:16:35 GMT"}, {"version": "v2", "created": "Fri, 1 May 2015 22:08:09 GMT"}], "update_date": "2015-05-05", "authors_parsed": [["Garrison", "William C.", "III"], ["Lee", "Adam J.", ""]]}, {"id": "1504.08043", "submitter": "Pol Mac Aonghusa", "authors": "P\\'ol Mac Aonghusa and Douglas J. Leith", "title": "Don't let Google know I'm lonely!", "comments": "26 pages, 7 figures in ACM Transactions on Privacy and Security\n  (TOPS), Volume 19 Issue 1, August 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From buying books to finding the perfect partner, we share our most intimate\nwants and needs with our favourite online systems. But how far should we accept\npromises of privacy in the face of personal profiling? In particular we ask how\ncan we improve detection of sensitive topic profiling by online systems? We\npropose a definition of privacy disclosure we call\n{\\epsilon}-indistinguishability from which we construct scalable, practical\ntools to assess an adversaries learning potential. We demonstrate our results\nusing openly available resources, detecting a learning rate in excess of 98%\nfor a range of sensitive topics during our experiments.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2015 22:58:26 GMT"}, {"version": "v2", "created": "Fri, 19 Aug 2016 13:53:39 GMT"}], "update_date": "2016-08-22", "authors_parsed": [["Mac Aonghusa", "P\u00f3l", ""], ["Leith", "Douglas J.", ""]]}]