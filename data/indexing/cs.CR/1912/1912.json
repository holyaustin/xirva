[{"id": "1912.00007", "submitter": "Oleksii Konashevych", "authors": "Oleksii Konashevych and Oleg Khovayko", "title": "Randpay: The Technology for Blockchain Micropayments and Transactions\n  Which Require Recipient's Consent", "comments": "This document needs major revision and is not going to be updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randpay is a technology developed in Emercoin for blockchain micropayments\nthat can be more effective in some scenarios than the Lightning Network as we\nshow in the paper. The protocol is based on the concept of Ronald L. Rivest and\npublished in the paper \"Electronic Lottery Tickets as Micropayments\" (1997).\nThe \"lottery ticket\" was designed for centralized systems where a trusted third\nparty is required to provide payments, and in some scenarios is also a lottery\nfacilitator. The existing blockchain protocol cannot accommodate peer-to-peer\n\"lottery\" micropayments at least without the need to create payment channels,\nwhich is analysed in the paper. Therefore, the implementation required the\ndevelopment of an update to the blockchain core. In the result, RandpayUTXO was\nintroduced - infinitely spendable zero output that requires the payee's\nsignature to be published in the blockchain. Randpay is considered to be the\nfirst blockchain protocol to require the payee to sign the transaction by their\nprivate key. This is a significant feature to improve not only\nmicrotransactions but also extend the use of the blockchain for legal deeds\nthat require a payee's consent to be recognised in legal applications. The\nsecond important innovation of this research is the implementation of Blum's\n\"coin flipping by telephone\" problem to design a \"lottery ticket\" that does not\nrequire any third party to facilitate the lottery. The paper offers an API\ndescription, an analysis of the mathematical model, and proof of how \"lottery\"\ncan be beneficial. There is also an attack analysis and overview of existing\nsolutions.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 23:07:27 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 04:23:25 GMT"}, {"version": "v3", "created": "Fri, 24 Apr 2020 02:33:33 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Konashevych", "Oleksii", ""], ["Khovayko", "Oleg", ""]]}, {"id": "1912.00049", "submitter": "Maksym Andriushchenko", "authors": "Maksym Andriushchenko, Francesco Croce, Nicolas Flammarion, Matthias\n  Hein", "title": "Square Attack: a query-efficient black-box adversarial attack via random\n  search", "comments": "Accepted at ECCV 2020; added imperceptible perturbations, analysis of\n  examples that require more queries, results on dilated CNNs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Square Attack, a score-based black-box $l_2$- and\n$l_\\infty$-adversarial attack that does not rely on local gradient information\nand thus is not affected by gradient masking. Square Attack is based on a\nrandomized search scheme which selects localized square-shaped updates at\nrandom positions so that at each iteration the perturbation is situated\napproximately at the boundary of the feasible set. Our method is significantly\nmore query efficient and achieves a higher success rate compared to the\nstate-of-the-art methods, especially in the untargeted setting. In particular,\non ImageNet we improve the average query efficiency in the untargeted setting\nfor various deep networks by a factor of at least $1.8$ and up to $3$ compared\nto the recent state-of-the-art $l_\\infty$-attack of Al-Dujaili & O'Reilly.\nMoreover, although our attack is black-box, it can also outperform\ngradient-based white-box attacks on the standard benchmarks achieving a new\nstate-of-the-art in terms of the success rate. The code of our attack is\navailable at https://github.com/max-andr/square-attack.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 19:29:32 GMT"}, {"version": "v2", "created": "Sat, 14 Mar 2020 22:30:48 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2020 07:53:10 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Andriushchenko", "Maksym", ""], ["Croce", "Francesco", ""], ["Flammarion", "Nicolas", ""], ["Hein", "Matthias", ""]]}, {"id": "1912.00055", "submitter": "Grigorios Loukides", "authors": "Grigorios Loukides and George Theodorakopoulos", "title": "Location histogram privacy by sensitive location hiding and target\n  histogram avoidance/resemblance (extended version)", "comments": "A shorter version is to appear in Knowledge and Information Systems\n  journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A location histogram is comprised of the number of times a user has visited\nlocations as they move in an area of interest, and it is often obtained from\nthe user in applications such as recommendation and advertising. However, a\nlocation histogram that leaves a user's computer or device may threaten privacy\nwhen it contains visits to locations that the user does not want to disclose\n(sensitive locations), or when it can be used to profile the user in a way that\nleads to price discrimination and unsolicited advertising. Our work introduces\ntwo privacy notions to protect a location histogram from these threats:\nsensitive location hiding, which aims at concealing all visits to sensitive\nlocations, and target avoidance/resemblance, which aims at concealing the\nsimilarity/dissimilarity of the user's histogram to a target histogram that\ncorresponds to an undesired/desired profile. We formulate an optimization\nproblem around each notion: Sensitive Location Hiding (SLH), which seeks to\nconstruct a histogram that is as similar as possible to the user's histogram\nbut associates all visits with nonsensitive locations, and Target\nAvoidance/Resemblance (TA/TR), which seeks to construct a histogram that is as\ndissimilar/similar as possible to a given target histogram but remains useful\nfor getting a good response from the application that analyzes the histogram.\nWe develop an optimal algorithm for each notion and also develop a greedy\nheuristic for the TA/TR problem. Our experiments demonstrate that all\nalgorithms are effective at preserving the distribution of locations in a\nhistogram and the quality of location recommendation. They also demonstrate\nthat the heuristic produces near-optimal solutions while being orders of\nmagnitude faster than the optimal algorithm for TA/TR.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 19:59:52 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Loukides", "Grigorios", ""], ["Theodorakopoulos", "George", ""]]}, {"id": "1912.00131", "submitter": "Keith Bonawitz", "authors": "Keith Bonawitz, Fariborz Salehi, Jakub Kone\\v{c}n\\'y, Brendan McMahan,\n  Marco Gruteser", "title": "Federated Learning with Autotuned Communication-Efficient Secure\n  Aggregation", "comments": "5 pages, 3 figures. To appear at the IEEE Asilomar Conference on\n  Signals, Systems, and Computers 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated Learning enables mobile devices to collaboratively learn a shared\ninference model while keeping all the training data on a user's device,\ndecoupling the ability to do machine learning from the need to store the data\nin the cloud. Existing work on federated learning with limited communication\ndemonstrates how random rotation can enable users' model updates to be\nquantized much more efficiently, reducing the communication cost between users\nand the server. Meanwhile, secure aggregation enables the server to learn an\naggregate of at least a threshold number of device's model contributions\nwithout observing any individual device's contribution in unaggregated form. In\nthis paper, we highlight some of the challenges of setting the parameters for\nsecure aggregation to achieve communication efficiency, especially in the\ncontext of the aggressively quantized inputs enabled by random rotation. We\nthen develop a recipe for auto-tuning communication-efficient secure\naggregation, based on specific properties of random rotation and secure\naggregation -- namely, the predictable distribution of vector entries\npost-rotation and the modular wrapping inherent in secure aggregation. We\npresent both theoretical results and initial experiments.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 04:27:27 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Bonawitz", "Keith", ""], ["Salehi", "Fariborz", ""], ["Kone\u010dn\u00fd", "Jakub", ""], ["McMahan", "Brendan", ""], ["Gruteser", "Marco", ""]]}, {"id": "1912.00234", "submitter": "Emil Pricop", "authors": "Emil Pricop, Sanda Florentina Mihalache", "title": "Fuzzy approach on modelling cyber attacks patterns on data transfer in\n  industrial control systems", "comments": "6 pages; Paper accepted and presented at ECAI 2015 - 7th\n  International Conference Electronics, Computers and Artificial Intelligence,\n  25 June -27 June, 2015, Bucharest, ROM\\^ANIA", "journal-ref": null, "doi": "10.1109/ECAI.2015.7301200", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybersecurity of industrial control system is a very complex and challenging\nresearch topic, due to the integration of these systems in national critical\ninfrastructures. The control systems are now interconnected in industrial\nnetworks and frequently to the Internet. In this context they are becoming\ntargets of various cyber attacks conducted by malicious people such as hackers,\nscript kiddies, industrial spies and even foreign armies and intelligence\nagencies. In this paper the authors propose a way to model the most frequent\nattacker profiles and to estimate the success rate of an attack conducted in\ngiven conditions. The authors use a fuzzy approach for generating attacker\nprofiles based on attacker attributes such as knowledge, technical resources\nand motivation. The attack success rate is obtained by using another fuzzy\ninference system that analyzes the attacker profile and system intrinsic\ncharacteristics.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 17:04:45 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Pricop", "Emil", ""], ["Mihalache", "Sanda Florentina", ""]]}, {"id": "1912.00264", "submitter": "Chenglong Fu", "authors": "Chenglong Fu, Qiang Zeng, Xiaojiang Du", "title": "Towards Efficient Integration of Blockchain for IoT Security: The Case\n  Study of IoT Remote Access", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The booming Internet of Things (IoT) market has drawn tremendous interest\nfrom cyber attackers. The centralized cloud-based IoT service architecture has\nserious limitations in terms of security, availability, and scalability, and is\nsubject to single points of failure (SPOF). Recently, accommodating IoT\nservices on blockchains has become a trend for better security, privacy, and\nreliability. However, blockchain's shortcomings of high cost, low throughput,\nand long latency make it unsuitable for IoT applications. In this paper, we\ntake a retrospection of existing blockchain-based IoT solutions and propose a\nframework for efficient blockchain and IoT integration. Following the\nframework, we design a novel blockchain-assisted decentralized IoT remote\naccessing system, RS-IoT, which has the advantage of defending IoT devices\nagainst zero-day attacks without relying on any trusted third-party. By\nintroducing incentives and penalties enforced by smart contracts, our work\nenables \"an economic approach\" to thwarting the majority of attackers who aim\nto achieve monetary gains. Our work presents an example of how blockchain can\nbe used to ensure the fairness of service trading in a decentralized\nenvironment and punish misbehaviors objectively. We show the security of RS-IoT\nvia detailed security analyses. Finally, we demonstrate its scalability,\nefficiency, and usability through a proof-of-concept implementation on the\nEthereum testnet blockchain.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 21:13:58 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Fu", "Chenglong", ""], ["Zeng", "Qiang", ""], ["Du", "Xiaojiang", ""]]}, {"id": "1912.00288", "submitter": "Steve Schneider", "authors": "Muntadher Sallal and Steve Schneider and Matthew Casey and Catalin\n  Dragan and Francois Dupressoir and Luke Riley and Helen Treharne and Joe\n  Wadsworth and Phil Wright", "title": "VMV: Augmenting an Internet Voting System with Selene Verifiability", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online voting in the UK generally takes place without verifiability\nmechanisms, with providers that are trusted to provide ballot privacy and\ncorrectness of the result. However, replacing existing systems with verifiable\nvoting systems with brand new algorithms and code presents a business risk to\nelection providers. We present an approach for incremental change: adding a\nSelene-based verifiability layer to an existing online voting system. Selene is\na verifiable e-voting protocol that publishes votes in plaintext alongside\ntracking numbers that enable voters to confirm that their votes have been\ncaptured correctly by the system. This results in a system where even the\nelection authority running the system cannot change the result in an\nundetectable way. This gives stronger guarantees on the integrity of the\nelection than were previously present. This gives an end-to-end verifiable\nsystem we call Verify My Vote (VMV). In addition, we outline how this approach\nsupports further incremental changes towards the deployment of fully\ntrustworthy online voting systems. The paper also describes the use of\ndistributed ledger technology as a component of VMV to manage the verifiability\ndata in a decentralised way for resilience and trust.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 00:06:51 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Sallal", "Muntadher", ""], ["Schneider", "Steve", ""], ["Casey", "Matthew", ""], ["Dragan", "Catalin", ""], ["Dupressoir", "Francois", ""], ["Riley", "Luke", ""], ["Treharne", "Helen", ""], ["Wadsworth", "Joe", ""], ["Wright", "Phil", ""]]}, {"id": "1912.00314", "submitter": "Xiao Zhang", "authors": "Xiao Zhang and Manish Marwah and I-ta Lee and Martin Arlitt and Dan\n  Goldwasser", "title": "ACE -- An Anomaly Contribution Explainer for Cyber-Security Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Anomaly Contribution Explainer or ACE, a tool to\nexplain security anomaly detection models in terms of the model features\nthrough a regression framework, and its variant, ACE-KL, which highlights the\nimportant anomaly contributors. ACE and ACE-KL provide insights in diagnosing\nwhich attributes significantly contribute to an anomaly by building a\nspecialized linear model to locally approximate the anomaly score that a\nblack-box model generates. We conducted experiments with these anomaly\ndetection models to detect security anomalies on both synthetic data and real\ndata. In particular, we evaluate performance on three public data sets: CERT\ninsider threat, netflow logs, and Android malware. The experimental results are\nencouraging: our methods consistently identify the correct contributing feature\nin the synthetic data where ground truth is available; similarly, for real data\nsets, our methods point a security analyst in the direction of the underlying\ncauses of an anomaly, including in one case leading to the discovery of\npreviously overlooked network scanning activity. We have made our source code\npublicly available.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 04:16:12 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 21:26:15 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Zhang", "Xiao", ""], ["Marwah", "Manish", ""], ["Lee", "I-ta", ""], ["Arlitt", "Martin", ""], ["Goldwasser", "Dan", ""]]}, {"id": "1912.00317", "submitter": "Daniel Votipka", "authors": "Daniel Votipka and Seth M. Rabin and Kristopher Micinski and Jeffrey\n  S. Foster and Michelle L. Mazurek", "title": "An Observational Investigation of Reverse Engineers' Processes", "comments": "22 pages, 6 figures, to appear at the 2020 USENIX Security Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reverse engineering is a complex process essential to software-security tasks\nsuch as vulnerability discovery and malware analysis. Significant research and\nengineering effort has gone into developing tools to support reverse engineers.\nHowever, little work has been done to understand the way reverse engineers\nthink when analyzing programs, leaving tool developers to make interface design\ndecisions based only on intuition.\n  This paper takes a first step toward a better understanding of reverse\nengineers' processes, with the goal of producing insights for improving\ninteraction design for reverse engineering tools. We present the results of a\nsemi-structured, observational interview study of reverse engineers (N=16).\nEach observation investigated the questions reverse engineers ask as they probe\na program, how they answer these questions, and the decisions they make\nthroughout the reverse engineering process. From the interview responses, we\ndistill a model of the reverse engineering process, divided into three phases:\noverview, sub-component scanning, and focused experimentation. Each analysis\nphase's results feed the next as reverse engineers' mental representations\nbecome more concrete. We find that reverse engineers typically use static\nmethods in the first two phases, but dynamic methods in the final phase, with\nexperience playing large, but varying, roles in each phase. % and the role of\nexperience varies between phases. Based on these results, we provide five\ninteraction design guidelines for reverse engineering tools.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 04:41:37 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Votipka", "Daniel", ""], ["Rabin", "Seth M.", ""], ["Micinski", "Kristopher", ""], ["Foster", "Jeffrey S.", ""], ["Mazurek", "Michelle L.", ""]]}, {"id": "1912.00329", "submitter": "Yuan Xiao", "authors": "Yuan Xiao, Yinqian Zhang, Radu Teodorescu", "title": "SPEECHMINER: A Framework for Investigating and Measuring Speculative\n  Execution Vulnerabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SPEculative Execution side Channel Hardware (SPEECH) Vulnerabilities have\nenabled the notorious Meltdown, Spectre, and L1 terminal fault (L1TF) attacks.\nWhile a number of studies have reported different variants of SPEECH\nvulnerabilities, they are still not well understood. This is primarily due to\nthe lack of information about microprocessor implementation details that impact\nthe timing and order of various micro-architectural events. Moreover, to date,\nthere is no systematic approach to quantitatively measure SPEECH\nvulnerabilities on commodity processors. This paper introduces SPEECHMINER, a\nsoftware framework for exploring and measuring SPEECH vulnerabilities in an\nautomated manner. SPEECHMINER empirically establishes the link between a novel\ntwo-phase fault handling model and the exploitability and speculation windows\nof SPEECH vulnerabilities. It enables testing of a comprehensive list of\nexception-triggering instructions under the same software framework, which\nleverages covert-channel techniques and differential tests to gain visibility\ninto the micro-architectural state changes. We evaluated SPEECHMINER on 9\ndifferent processor types, examined 21 potential vulnerability variants,\nconfirmed various known attacks, and identified several new variants.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 06:25:51 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 21:13:00 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Xiao", "Yuan", ""], ["Zhang", "Yinqian", ""], ["Teodorescu", "Radu", ""]]}, {"id": "1912.00354", "submitter": "Farah Shamout", "authors": "Pulkit Sharma, Farah E Shamout, David A Clifton", "title": "Preserving Patient Privacy while Training a Predictive Model of\n  In-hospital Mortality", "comments": "AI for Social Good Workshop, Neurips 2019, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models can be used for pattern recognition in medical data\nin order to improve patient outcomes, such as the prediction of in-hospital\nmortality. Deep learning models, in particular, require large amounts of data\nfor model training. However, the data is often collected at different hospitals\nand sharing is restricted due to patient privacy concerns. In this paper, we\naimed to demonstrate the potential of distributed training in achieving\nstate-of-the-art performance while maintaining data privacy. Our results show\nthat training the model in the federated learning framework leads to comparable\nperformance to the traditional centralised setting. We also suggest several\nconsiderations for the success of such frameworks in future work.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 08:26:13 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Sharma", "Pulkit", ""], ["Shamout", "Farah E", ""], ["Clifton", "David A", ""]]}, {"id": "1912.00442", "submitter": "Xinyu Fan", "authors": "Xinyu Fan, Faen Zhang, Jianfei Song, Jingming Guo, Fujie Gao", "title": "PACLP: a fine-grained partition-based access control policy language for\n  provenance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even though the idea of partitioning provenance graphs for access control was\npreviously proposed, employing segments of the provenance DAG for fine-grained\naccess control to provenance data has not been thoroughly explored. Hence, we\ntake segments of a provenance graph, based on the extended OPM, and defined use\na variant of regular expressions, and utilize them in our fine-grained access\ncontrol language. It can not only return partial graphs to answer access\nrequests but also introduce segments as restrictions in order to screen\ntargeted data.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 17:05:13 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 09:48:38 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Fan", "Xinyu", ""], ["Zhang", "Faen", ""], ["Song", "Jianfei", ""], ["Guo", "Jingming", ""], ["Gao", "Fujie", ""]]}, {"id": "1912.00445", "submitter": "Xinyu Fan", "authors": "Faen Zhang, Xinyu Fan, Wenfeng Zhou, Pengcheng Zhou", "title": "Purpose-based access policy on provenance and data algebra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a crucial mechanism of access control to determine that data can only\nbe accessed for allowed purposes. To achieve this mechanism, we propose\npurpose-based access policies in this paper. Different from provenance-based\npolicies that determine if a piece of data can be accessed or not,\npurpose-based access policies determines for what purposes can data be\naccessed. Particularly, the purposes can be classified as different sensitivity\nlevels. For the first time, We tailor policy algebras to include internal and\nexternal policy operators for hierarchical purposes, in order to merge purpose\nsets generated by individual policies. We also created external policy algebras\nto merge policies from multi-parties. With different types' testing\nexperiments, our model is proved to be feasible and practical.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 17:09:29 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Zhang", "Faen", ""], ["Fan", "Xinyu", ""], ["Zhou", "Wenfeng", ""], ["Zhou", "Pengcheng", ""]]}, {"id": "1912.00446", "submitter": "Xinyu Fan", "authors": "Faen Zhang, Xinyu Fan, Pengcheng Zhou, Wenfeng Zhou", "title": "Zero knowledge proofs for cloud storage integrity checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the wide application of cloud storage, cloud security has become a\ncrucial concern. Related works have addressed security issues such as data\nconfidentiality and integrity, which ensure that the remotely stored data are\nwell maintained by the cloud. However, how to define zero-knowledge proof\nalgorithms for stored data integrity check has not been formally defined and\ninvestigated. We believe that it is important that the cloud server is unable\nto reveal any useful information about the stored data. In this paper, we\nintroduce a novel definition of data privacy for integrity checks, which\ndescribes very high security of a zero-knowledge proof. We found that all other\nexisting remote integrity proofs do not capture this feature. We provide a\ncomprehensive study of data privacy and an integrity check algorithm that\ncaptures data integrity, confidentiality, privacy, and soundness.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 17:12:43 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Zhang", "Faen", ""], ["Fan", "Xinyu", ""], ["Zhou", "Pengcheng", ""], ["Zhou", "Wenfeng", ""]]}, {"id": "1912.00461", "submitter": "Abdullah Hamdi", "authors": "Abdullah Hamdi, Sara Rojas, Ali Thabet, Bernard Ghanem", "title": "AdvPC: Transferable Adversarial Perturbations on 3D Point Clouds", "comments": "Presented at European conference on computer vision (ECCV), 2020. The\n  code is available at https://github.com/ajhamdi/AdvPC", "journal-ref": "ECCV 2020", "doi": "10.1007/978-3-030-58610-2_15", "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to adversarial attacks, in which\nimperceptible perturbations to their input lead to erroneous network\npredictions. This phenomenon has been extensively studied in the image domain,\nand has only recently been extended to 3D point clouds. In this work, we\npresent novel data-driven adversarial attacks against 3D point cloud networks.\nWe aim to address the following problems in current 3D point cloud adversarial\nattacks: they do not transfer well between different networks, and they are\neasy to defend against via simple statistical methods. To this extent, we\ndevelop a new point cloud attack (dubbed AdvPC) that exploits the input data\ndistribution by adding an adversarial loss, after Auto-Encoder reconstruction,\nto the objective it optimizes. AdvPC leads to perturbations that are resilient\nagainst current defenses, while remaining highly transferable compared to\nstate-of-the-art attacks. We test AdvPC using four popular point cloud\nnetworks: PointNet, PointNet++ (MSG and SSG), and DGCNN. Our proposed attack\nincreases the attack success rate by up to 40% for those transferred to unseen\nnetworks (transferability), while maintaining a high success rate on the\nattacked network. AdvPC also increases the ability to break defenses by up to\n38% as compared to other baselines on the ModelNet40 dataset.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 18:13:23 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 12:16:06 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Hamdi", "Abdullah", ""], ["Rojas", "Sara", ""], ["Thabet", "Ali", ""], ["Ghanem", "Bernard", ""]]}, {"id": "1912.00466", "submitter": "Nupur Kumari", "authors": "Tejus Gupta, Abhishek Sinha, Nupur Kumari, Mayank Singh, Balaji\n  Krishnamurthy", "title": "A Method for Computing Class-wise Universal Adversarial Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for computing class-specific universal adversarial\nperturbations for deep neural networks. Such perturbations can induce\nmisclassification in a large fraction of images of a specific class. Unlike\nprevious methods that use iterative optimization for computing a universal\nperturbation, the proposed method employs a perturbation that is a linear\nfunction of weights of the neural network and hence can be computed much\nfaster. The method does not require any training data and has no\nhyper-parameters. The attack obtains 34% to 51% fooling rate on\nstate-of-the-art deep neural networks on ImageNet and transfers across models.\nWe also study the characteristics of the decision boundaries learned by\nstandard and adversarially trained models to understand the universal\nadversarial perturbations.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 18:22:14 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Gupta", "Tejus", ""], ["Sinha", "Abhishek", ""], ["Kumari", "Nupur", ""], ["Singh", "Mayank", ""], ["Krishnamurthy", "Balaji", ""]]}, {"id": "1912.00533", "submitter": "Leonardo Babun", "authors": "Leonardo Babun, Hidayet Aksu, and A. Selcuk Uluagac", "title": "A System-level Behavioral Detection Framework for Compromised CPS\n  Devices: Smart-Grid Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-Physical Systems (CPS) play a significant role in our critical\ninfrastructure networks from power-distribution to utility networks. The\nemerging smart-grid concept is a compelling critical CPS infrastructure that\nrelies on two-way communications between smart devices to increase efficiency,\nenhance reliability, and reduce costs. However, compromised devices in the\nsmart grid poses several security challenges. Consequences of propagating fake\ndata or stealing sensitive smart grid information via compromised devices are\ncostly. Hence, early behavioral detection of compromised devices is critical\nfor protecting the smart grid's components and data. To address these concerns,\nin this paper, we introduce a novel and configurable system-level framework to\nidentify compromised smart grid devices. The framework combines system and\nfunction call tracing techniques with signal processing and statistical\nanalysis to detect compromised devices based on their behavioral\ncharacteristics. We measure the efficacy of our framework with a realistic\nsmart grid substation testbed that includes both resource-limited and\nresource-rich devices. In total, using our framework, we analyze six different\ntypes of compromised device scenarios with different resources and attack\npayloads. To the best of our knowledge, the proposed framework is the first in\ndetecting compromised CPS smart grid devices with system and function-level\ncall tracing techniques. The experimental results reveal an excellent rate for\nthe detection of compromised devices. Specifically, performance metrics include\naccuracy values between 95% and 99% for the different attack scenarios.\nFinally, the performance analysis demonstrates that the use of the proposed\nframework has minimal overhead on the smart grid devices' computing resources.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 01:00:54 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Babun", "Leonardo", ""], ["Aksu", "Hidayet", ""], ["Uluagac", "A. Selcuk", ""]]}, {"id": "1912.00574", "submitter": "Zhaoyang Lyu", "authors": "Zhaoyang Lyu, Ching-Yun Ko, Zhifeng Kong, Ngai Wong, Dahua Lin, Luca\n  Daniel", "title": "Fastened CROWN: Tightened Neural Network Robustness Certificates", "comments": "Zhaoyang Lyu and Ching-Yun Ko contributed equally, accepted to AAAI\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of deep learning applications in real life is accompanied by\nsevere safety concerns. To mitigate this uneasy phenomenon, much research has\nbeen done providing reliable evaluations of the fragility level in different\ndeep neural networks. Apart from devising adversarial attacks, quantifiers that\ncertify safeguarded regions have also been designed in the past five years. The\nsummarizing work of Salman et al. unifies a family of existing verifiers under\na convex relaxation framework. We draw inspiration from such work and further\ndemonstrate the optimality of deterministic CROWN (Zhang et al. 2018) solutions\nin a given linear programming problem under mild constraints. Given this\ntheoretical result, the computationally expensive linear programming based\nmethod is shown to be unnecessary. We then propose an optimization-based\napproach \\textit{FROWN} (\\textbf{F}astened C\\textbf{ROWN}): a general algorithm\nto tighten robustness certificates for neural networks. Extensive experiments\non various networks trained individually verify the effectiveness of FROWN in\nsafeguarding larger robust regions.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 03:54:20 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Lyu", "Zhaoyang", ""], ["Ko", "Ching-Yun", ""], ["Kong", "Zhifeng", ""], ["Wong", "Ngai", ""], ["Lin", "Dahua", ""], ["Daniel", "Luca", ""]]}, {"id": "1912.00696", "submitter": "Stefano Di Carlo", "authors": "Alberto Carelli, Cataldo Basile, Alessandro Savino, Alessandro\n  Vallero, Stefano Di Carlo", "title": "Securing Soft IP Cores in FPGA based Reconfigurable Mobile Heterogeneous\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mobile application market is rapidly growing and changing, offering\nalways brand new software to install in increasingly powerful devices. Mobile\ndevices become pervasive and more heterogeneous, embedding latest technologies\nsuch as multicore architectures, special-purpose circuits and reconfigurable\nlogic. In a future mobile market scenario reconfigurable systems are employed\nto provide high-speed functionalities to assist execution of applications.\nHowever, new security concerns are introduced. In particular, protecting the\nIntellectual Property of the exchanged soft IP cores is a serious concern. The\navailable techniques for preserving integrity, confidentiality and authenticity\nsuffer from the limitation of heavily relying onto the system designer. In this\npaper we propose two different protocols suitable for the secure deployment of\nsoft IP cores in FPGA-based mobile heterogeneous systems where multiple\nindependent actors are involved: a simple scenario requiring trust relationship\nbetween entities, and a more complex scenario where no trust relationship\nexists through adoption of the Direct Anonymous Attestation protocol. Finally,\nwe provide a prototype implementation of the proposed architectures.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 11:47:52 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Carelli", "Alberto", ""], ["Basile", "Cataldo", ""], ["Savino", "Alessandro", ""], ["Vallero", "Alessandro", ""], ["Di Carlo", "Stefano", ""]]}, {"id": "1912.00701", "submitter": "Benjamin Smith", "authors": "Craig Costello, Benjamin Smith (GRACE)", "title": "The supersingular isogeny problem in genus 2 and beyond", "comments": null, "journal-ref": "Post-Quantum Cryptography, Apr 2020, Paris, France", "doi": null, "report-no": null, "categories": "cs.CR math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $A/\\overline{\\mathbb{F}}\\_p$ and $A'/\\overline{\\mathbb{F}}\\_p$ be\nsupersingular principally polarized abelian varieties of dimension $g>1$. For\nany prime $\\ell \\ne p$, we give an algorithm that finds a path $\\phi \\colon A\n\\rightarrow A'$ in the $(\\ell, \\dots , \\ell)$-isogeny graph in\n$\\widetilde{O}(p^{g-1})$ group operations on a classical computer, and\n$\\widetilde{O}(\\sqrt{p^{g-1}})$ calls to the Grover oracle on a quantum\ncomputer. The idea is to find paths from $A$ and $A'$ to nodes that correspond\nto products of lower dimensional abelian varieties, and to recurse down in\ndimension until an elliptic path-finding algorithm (such as Delfs--Galbraith)\ncan be invoked to connect the paths in dimension $g=1$. In the general case\nwhere $A$ and $A'$ are any two nodes in the graph, this algorithm presents an\nasymptotic improvement over all of the algorithms in the current literature. In\nthe special case where $A$ and $A'$ are a known and relatively small number of\nsteps away from each other (as is the case in higher dimensional analogues of\nSIDH), it gives an asymptotic improvement over the quantum claw finding\nalgorithms and an asymptotic improvement over the classical van\nOorschot--Wiener algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 11:56:09 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 10:14:04 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Costello", "Craig", "", "GRACE"], ["Smith", "Benjamin", "", "GRACE"]]}, {"id": "1912.00731", "submitter": "James Pavur", "authors": "James Pavur and Casey Knerr", "title": "GDPArrrrr: Using Privacy Laws to Steal Identities", "comments": "Associated With the Black Hat USA 2019 Briefing \"GDPArrrrr: Using\n  Privacy Laws to Steal Identities\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The General Data Protection Regulation (GDPR) has become a touchstone model\nfor modern privacy law, in part because it empowers consumers with\nunprecedented control over the use of their personal information. However, this\nsame power may be susceptible to abuse by malicious attackers. In this paper,\nwe consider how legal ambiguity surrounding the \"Right of Access\" process may\nbe abused by social engineers. This hypothesis is tested through an adversarial\ncase study of more than 150 businesses. We find that many organizations fail to\nemploy adequate safeguards against Right of Access abuse and thus risk exposing\nsensitive information to unauthorized third parties. This information varied in\nsensitivity from simple public records to Social Security Numbers and account\npasswords. These findings suggest a critical need to improve the implementation\nof the subject access request process. To this end, we propose possible\nremediations which may be appropriate for further consideration by government,\nindustry and individuals.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 12:58:06 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Pavur", "James", ""], ["Knerr", "Casey", ""]]}, {"id": "1912.00888", "submitter": "Nils Lukas", "authors": "Nils Lukas, Yuxuan Zhang, Florian Kerschbaum", "title": "Deep Neural Network Fingerprinting by Conferrable Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Machine Learning as a Service, a provider trains a deep neural network and\ngives many users access. The hosted (source) model is susceptible to model\nstealing attacks, where an adversary derives a surrogate model from API access\nto the source model. For post hoc detection of such attacks, the provider needs\na robust method to determine whether a suspect model is a surrogate of their\nmodel. We propose a fingerprinting method for deep neural network classifiers\nthat extracts a set of inputs from the source model so that only surrogates\nagree with the source model on the classification of such inputs. These inputs\nare a subclass of transferable adversarial examples which we call conferrable\nadversarial examples that exclusively transfer with a target label from a\nsource model to its surrogates. We propose a new method to generate these\nconferrable adversarial examples. We present an extensive study on the\nirremovability of our fingerprint against fine-tuning, weight pruning,\nretraining, retraining with different architectures, three model extraction\nattacks from related work, transfer learning, adversarial training, and two new\nadaptive attacks. Our fingerprint is robust against distillation, related model\nextraction attacks, and even transfer learning when the attacker has no access\nto the model provider's dataset. Our fingerprint is the first method that\nreaches a ROC AUC of 1.0 in verifying surrogates, compared to a ROC AUC of 0.63\nby previous fingerprints.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 16:11:56 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 01:09:43 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 00:00:56 GMT"}, {"version": "v4", "created": "Wed, 20 Jan 2021 18:19:24 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Lukas", "Nils", ""], ["Zhang", "Yuxuan", ""], ["Kerschbaum", "Florian", ""]]}, {"id": "1912.00916", "submitter": "Markku-Juhani Saarinen", "authors": "Markku-Juhani O. Saarinen", "title": "Mobile Energy Requirements of the Upcoming NIST Post-Quantum\n  Cryptography Standards", "comments": "Related to a presentation given at the 7th ETSI/IQC Quantum Safe\n  Cryptography Workshop, 7 November 2019, Seattle USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standardization of Post-Quantum Cryptography (PQC) was started by NIST in\n2016 and has proceeded to its second elimination round. The upcoming standards\nare intended to replace (or supplement) current RSA and Elliptic Curve\nCryptography (ECC) on all targets, including lightweight, embedded, and mobile\nsystems. We present an energy requirement analysis based on extensive\nmeasurements of PQC candidate algorithms on a Cortex M4 - based reference\nplatform. We relate computational (energy) costs of PQC algorithms to their\ndata transmission costs which are expected to increase with new types of public\nkeys and ciphertext messages. The energy, bandwidth, and latency needs of PQC\nalgorithms span several orders of magnitude, which is substantial enough to\nimpact battery life, user experience, and application protocol design. We\npropose metrics and guidelines for PQC algorithm usage in IoT and mobile\nsystems based on our findings. Our evidence supports the view that fast\nstructured-lattice PQC schemes are the preferred choice for cloud-connected\nmobile devices in most use cases, even when per-bit data transmission energy\ncost is relatively high.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 16:45:48 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 14:22:46 GMT"}, {"version": "v3", "created": "Tue, 7 Jan 2020 14:51:30 GMT"}, {"version": "v4", "created": "Tue, 14 Apr 2020 23:54:12 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Saarinen", "Markku-Juhani O.", ""]]}, {"id": "1912.00981", "submitter": "Samuel Drews", "authors": "Samuel Drews and Aws Albarghouthi and Loris D'Antoni", "title": "Proving Data-Poisoning Robustness in Decision Trees", "comments": "Changes: revisions to main text for clarity of presentation, and\n  corrections to proofs in the appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are brittle, and small changes in the training data\ncan result in different predictions. We study the problem of proving that a\nprediction is robust to data poisoning, where an attacker can inject a number\nof malicious elements into the training set to influence the learned model. We\ntarget decision-tree models, a popular and simple class of machine learning\nmodels that underlies many complex learning techniques. We present a sound\nverification technique based on abstract interpretation and implement it in a\ntool called Antidote. Antidote abstractly trains decision trees for an\nintractably large space of possible poisoned datasets. Due to the soundness of\nour abstraction, Antidote can produce proofs that, for a given input, the\ncorresponding prediction would not have changed had the training set been\ntampered with or not. We demonstrate the effectiveness of Antidote on a number\nof popular datasets.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 18:20:54 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 22:40:42 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Drews", "Samuel", ""], ["Albarghouthi", "Aws", ""], ["D'Antoni", "Loris", ""]]}, {"id": "1912.00990", "submitter": "Nai-Hui Chia", "authors": "Nai-Hui Chia and Kai-Min Chung and Takashi Yamakawa", "title": "Classical Verification of Quantum Computations with Efficient Verifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we extend the protocol of classical verification of quantum\ncomputations (CVQC) recently proposed by Mahadev to make the verification\nefficient. Our result is obtained in the following three steps:\n  $\\bullet$ We show that parallel repetition of Mahadev's protocol has\nnegligible soundness error. This gives the first constant round CVQC protocol\nwith negligible soundness error. In this part, we only assume the quantum\nhardness of the learning with error (LWE) problem similar to the Mahadev's\nwork.\n  $\\bullet$ We construct a two-round CVQC protocol in the quantum random oracle\nmodel (QROM) where a cryptographic hash function is idealized to be a random\nfunction. This is obtained by applying the Fiat-Shamir transform to the\nparallel repetition version of the Mahadev's protocol.\n  $\\bullet$ We construct a two-round CVQC protocol with the efficient verifier\nin the CRS+QRO model where both prover and verifier can access to a (classical)\ncommon reference string generated by a trusted third party in addition to\nquantum access to QRO. Specifically, the verifier can verify a $QTIME(T)$\ncomputation in time $poly(n,log T)$ where $n$ is the security parameter. For\nproving soundness, we assume that a standard model instantiation of our\ntwo-round protocol with a concrete hash function (say, SHA-3) is sound and the\nexistence of post-quantum indistinguishability obfuscation and post-quantum\nfully homomorphic encryption in addition to the quantum hardness of the LWE\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 18:45:19 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 00:59:57 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Chia", "Nai-Hui", ""], ["Chung", "Kai-Min", ""], ["Yamakawa", "Takashi", ""]]}, {"id": "1912.01051", "submitter": "Zitao Li", "authors": "Zitao Li, Tianhao Wang, Milan Lopuha\\\"a-Zwakenberg, Boris Skoric,\n  Ninghui Li", "title": "Estimating Numerical Distributions under Local Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When collecting information, local differential privacy (LDP) relieves the\nconcern of privacy leakage from users' perspective, as user's private\ninformation is randomized before sent to the aggregator. We study the problem\nof recovering the distribution over a numerical domain while satisfying LDP.\nWhile one can discretize a numerical domain and then apply the protocols\ndeveloped for categorical domains, we show that taking advantage of the\nnumerical nature of the domain results in better trade-off of privacy and\nutility. We introduce a new reporting mechanism, called the square wave SW\nmechanism, which exploits the numerical nature in reporting. We also develop an\nExpectation Maximization with Smoothing (EMS) algorithm, which is applied to\naggregated histograms from the SW mechanism to estimate the original\ndistributions. Extensive experiments demonstrate that our proposed approach, SW\nwith EMS, consistently outperforms other methods in a variety of utility\nmetrics.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 19:26:11 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Li", "Zitao", ""], ["Wang", "Tianhao", ""], ["Lopuha\u00e4-Zwakenberg", "Milan", ""], ["Skoric", "Boris", ""], ["Li", "Ninghui", ""]]}, {"id": "1912.01149", "submitter": "Yizheng Chen", "authors": "Yizheng Chen, Shiqi Wang, Weifan Jiang, Asaf Cidon, Suman Jana", "title": "Cost-Aware Robust Tree Ensembles for Security Applications", "comments": "USENIX Security 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are various costs for attackers to manipulate the features of security\nclassifiers. The costs are asymmetric across features and to the directions of\nchanges, which cannot be precisely captured by existing cost models based on\n$L_p$-norm robustness. In this paper, we utilize such domain knowledge to\nincrease the attack cost of evading classifiers, specifically, tree ensemble\nmodels that are widely used by security tasks. We propose a new cost modeling\nmethod to capture the feature manipulation cost as constraint, and then we\nintegrate the cost-driven constraint into the node construction process to\ntrain robust tree ensembles. During the training process, we use the constraint\nto find data points that are likely to be perturbed given the feature\nmanipulation cost, and we use a new robust training algorithm to optimize the\nquality of the trees. Our cost-aware training method can be applied to\ndifferent types of tree ensembles, including gradient boosted decision trees\nand random forest models. Using Twitter spam detection as the case study, our\nevaluation results show that we can increase the attack cost by 10.6X compared\nto the baseline. Moreover, our robust training method using cost-driven\nconstraint can achieve higher accuracy, lower false positive rate, and stronger\ncost-aware robustness than the state-of-the-art training method using\n$L_\\infty$-norm cost model. Our code is available at\nhttps://github.com/surrealyz/growtrees.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 02:02:59 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 22:06:14 GMT"}, {"version": "v3", "created": "Sat, 30 May 2020 18:04:40 GMT"}, {"version": "v4", "created": "Tue, 8 Dec 2020 15:38:15 GMT"}, {"version": "v5", "created": "Tue, 23 Feb 2021 02:07:27 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Chen", "Yizheng", ""], ["Wang", "Shiqi", ""], ["Jiang", "Weifan", ""], ["Cidon", "Asaf", ""], ["Jana", "Suman", ""]]}, {"id": "1912.01209", "submitter": "Sheikh Ariful Islam", "authors": "Sheikh Ariful Islam", "title": "On the (In)security of Approximate Computing Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The broad landscape of new applications requires minimal hardware resources\nwithout any sacrifice in Quality-of-Results. Approximate Computing (AC) has\nemerged to meet the demands of data-rich applications. Although AC applies\ntechniques to improve the energy efficiency of error-tolerant applications at\nthe cost of computational accuracy, new challenges in security threats of AC\nshould be simultaneously addressed. In this paper, we introduce the security\nvulnerability of the concurrent AC synthesis. We analyze the threat landscape\nand provide a broader view of the attack and defense strategy. As a case study,\nwe utilize AC synthesis technique to perform malicious modifications in the\nsynthesized approximate netlist. Similarly, we provide a scalable defense\nframework for trustworthy AC synthesis.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 06:11:31 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Islam", "Sheikh Ariful", ""]]}, {"id": "1912.01215", "submitter": "Jack Peterson", "authors": "Austin K. Williams, Jack Peterson", "title": "Decentralized Common Knowledge Oracles", "comments": "22 pages, 11 figures", "journal-ref": "Ledger 4 (2019) 157-190", "doi": "10.5195/ledger.2019.166", "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define and analyze three mechanisms for getting common knowledge, a\nposteriori truths about the world onto a blockchain in a decentralized setting.\nWe show that, when a reasonable economic condition is met, these mechanisms are\nindividually rational, incentive compatible, and decide the true outcome of\nvalid oracle queries in both the non-cooperative and cooperative settings.\nThese mechanisms are based upon repeated games with two classes of players:\nqueriers who desire to get common knowledge truths onto the blockchain and a\npool of reporters who posses such common knowledge. Presented with a new oracle\nquery, reporters have an opportunity to report the truth in return for a fee\nprovided by the querier. During subsequent oracle queries, the querier has an\nopportunity to punish any reporters who did not report truthfully during\nprevious rounds. While the set of reporters has the power to cause the oracle\nto lie, they are incentivized not to do so.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 06:41:16 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Williams", "Austin K.", ""], ["Peterson", "Jack", ""]]}, {"id": "1912.01487", "submitter": "Salah Ghamizi", "authors": "Salah Ghamizi, Maxime Cordy, Mike Papadakis and Yves Le Traon", "title": "Adversarial Embedding: A robust and elusive Steganography and\n  Watermarking technique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose adversarial embedding, a new steganography and watermarking\ntechnique that embeds secret information within images. The key idea of our\nmethod is to use deep neural networks for image classification and adversarial\nattacks to embed secret information within images. Thus, we use the attacks to\nembed an encoding of the message within images and the related deep neural\nnetwork outputs to extract it. The key properties of adversarial attacks\n(invisible perturbations, nontransferability, resilience to tampering) offer\nguarantees regarding the confidentiality and the integrity of the hidden\nmessages. We empirically evaluate adversarial embedding using more than 100\nmodels and 1,000 messages. Our results confirm that our embedding passes\nunnoticed by both humans and steganalysis methods, while at the same time\nimpedes illicit retrieval of the message (less than 13% recovery rate when the\ninterceptor has some knowledge about our model), and is resilient to soft and\n(to some extent) aggressive image tampering (up to 100% recovery rate under\njpeg compression). We further develop our method by proposing a new type of\nadversarial attack which improves the embedding density (amount of hidden\ninformation) of our method to up to 10 bits per pixel.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 17:05:13 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Ghamizi", "Salah", ""], ["Cordy", "Maxime", ""], ["Papadakis", "Mike", ""], ["Traon", "Yves Le", ""]]}, {"id": "1912.01493", "submitter": "Eli (Omid) David", "authors": "Ishai Rosenberg, Guillaume Sicard, Eli David", "title": "End-to-End Deep Neural Networks and Transfer Learning for Automatic\n  Analysis of Nation-State Malware", "comments": "arXiv admin note: substantial text overlap with arXiv:1711.09666", "journal-ref": "Entropy, Vol. 20, No. 5, pp. 390-401, May 2018", "doi": "10.3390/e20050390", "report-no": null, "categories": "cs.CR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware allegedly developed by nation-states, also known as advanced\npersistent threats (APT), are becoming more common. The task of attributing an\nAPT to a specific nation-state or classifying it to the correct APT family is\nchallenging for several reasons. First, each nation-state has more than a\nsingle cyber unit that develops such malware, rendering traditional authorship\nattribution algorithms useless. Furthermore, the dataset of such available APTs\nis still extremely small. Finally, those APTs use state-of-the-art evasion\ntechniques, making feature extraction challenging. In this paper, we use a deep\nneural network (DNN) as a classifier for nation-state APT attribution. We\nrecord the dynamic behavior of the APT when run in a sandbox and use it as raw\ninput for the neural network, allowing the DNN to learn high level feature\nabstractions of the APTs itself. We also use the same raw features for APT\nfamily classification. Finally, we use the feature abstractions learned by the\nAPT family classifier to solve the attribution problem. Using a test set of\n1000 Chinese and Russian developed APTs, we achieved an accuracy rate of 98.6%.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 01:21:26 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Rosenberg", "Ishai", ""], ["Sicard", "Guillaume", ""], ["David", "Eli", ""]]}, {"id": "1912.01560", "submitter": "Michel Kinsy", "authors": "Novak Boskov, Mihailo Isakov, Michel A. Kinsy", "title": "Drndalo: Lightweight Control Flow Obfuscation Through Minimal\n  Processor/Compiler Co-Design", "comments": null, "journal-ref": null, "doi": null, "report-no": "BU - ECE - ASCS Laboratory 2019 Report v5", "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary analysis is traditionally used in the realm of malware detection.\nHowever, the same technique may be employed by an attacker to analyze the\noriginal binaries in order to reverse engineer them and extract exploitable\nweaknesses. When a binary is distributed to end users, it becomes a common\nremotely exploitable attack point. Code obfuscation is used to hinder reverse\nengineering of executable programs. In this paper, we focus on securing binary\ndistribution, where attackers gain access to binaries distributed to end\ndevices, in order to reverse engineer them and find potential vulnerabilities.\nAttackers do not however have means to monitor the execution of said devices.\nIn particular, we focus on the control flow obfuscation --- a technique that\nprevents an attacker from restoring the correct reachability conditions for the\nbasic blocks of a program. By doing so, we thwart attackers in their effort to\ninfer the inputs that cause the program to enter a vulnerable state (e.g.,\nbuffer overrun). We propose a compiler extension for obfuscation and a minimal\nhardware modification for dynamic deobfuscation that takes advantage of a\nsecret key stored in hardware. We evaluate our experiments on the LLVM compiler\ntoolchain and the BRISC-V open source processor. On PARSEC benchmarks, our\ndeobfuscation technique incurs only a 5\\% runtime overhead. We evaluate the\nsecurity of Drndalo by training classifiers on pairs of obfuscated and\nunobfuscated binaries. Our results shine light on the difficulty of producing\nobfuscated binaries of arbitrary programs in such a way that they are\nstatistically indistinguishable from plain binaries.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 05:22:47 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Boskov", "Novak", ""], ["Isakov", "Mihailo", ""], ["Kinsy", "Michel A.", ""]]}, {"id": "1912.01561", "submitter": "Maksim Jenihhin", "authors": "Maksim Jenihhin, Said Hamdioui, Matteo Sonza Reorda, Milos Krstic,\n  Peter Langendoerfer, Christian Sauer, Anton Klotz, Michael Huebner, Joerg\n  Nolte, Heinrich Theodor Vierhaus, Georgios Selimis, Dan Alexandrescu,\n  Mottaqiallah Taouil, Geert-Jan Schrijen, Jaan Raik, Luca Sterpone, Giovanni\n  Squillero and Zoya Dyka", "title": "RESCUE: Interdependent Challenges of Reliability, Security and Quality\n  in Nanoelectronic Systems", "comments": "2020 Design, Automation & Test in Europe Conference & Exhibition\n  (DATE), Grenoble, France, 09 - 13 March 2020 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.SE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent trends for nanoelectronic computing systems include\nmachine-to-machine communication in the era of Internet-of-Things (IoT) and\nautonomous systems, complex safety-critical applications, extreme\nminiaturization of implementation technologies and intensive interaction with\nthe physical world. These set tough requirements on mutually dependent\nextra-functional design aspects. The H2020 MSCA ITN project RESCUE is focused\non key challenges for reliability, security and quality, as well as related\nelectronic design automation tools and methodologies. The objectives include\nboth research advancements and cross-sectoral training of a new generation of\ninterdisciplinary researchers. Notable interdisciplinary collaborative research\nresults for the first half-period include novel approaches for test generation,\nsoft-error and transient faults vulnerability analysis, cross-layer\nfault-tolerance and error-resilience, functional safety validation, reliability\nassessment and run-time management, HW security enhancement and initial\nimplementation of these into holistic EDA tools.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 09:04:27 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Jenihhin", "Maksim", ""], ["Hamdioui", "Said", ""], ["Reorda", "Matteo Sonza", ""], ["Krstic", "Milos", ""], ["Langendoerfer", "Peter", ""], ["Sauer", "Christian", ""], ["Klotz", "Anton", ""], ["Huebner", "Michael", ""], ["Nolte", "Joerg", ""], ["Vierhaus", "Heinrich Theodor", ""], ["Selimis", "Georgios", ""], ["Alexandrescu", "Dan", ""], ["Taouil", "Mottaqiallah", ""], ["Schrijen", "Geert-Jan", ""], ["Raik", "Jaan", ""], ["Sterpone", "Luca", ""], ["Squillero", "Giovanni", ""], ["Dyka", "Zoya", ""]]}, {"id": "1912.01606", "submitter": "Volkan Dedeoglu", "authors": "Volkan Dedeoglu, Ali Dorri, Raja Jurdak, Regio A. Michelin, Roben C.\n  Lunardi, Salil S. Kanhere, and Avelino F. Zorzo", "title": "A journey in applying blockchain for cyberphysical systems", "comments": "COMSNET 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyberphysical Systems (CPS) are transforming the way we interact with the\nphysical world around us. However, centralised approaches for CPS systems are\nnot capable of addressing the unique challenges of CPS due to the complexity,\nconstraints, and dynamic nature of the interactions. To realize the true\npotential of CPS, a decentralized approach that takes into account these unique\nfeatures is required. Recently, blockchain-based solutions have been proposed\nto address CPS challenges.Yet, applying blockchain for diverse CPS domains is\nnot straight-forward and has its own challenges. In this paper, we share our\nexperiences in applying blockchain technology for CPS to provide insights and\nhighlight the challenges and future opportunities.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 07:14:30 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Dedeoglu", "Volkan", ""], ["Dorri", "Ali", ""], ["Jurdak", "Raja", ""], ["Michelin", "Regio A.", ""], ["Lunardi", "Roben C.", ""], ["Kanhere", "Salil S.", ""], ["Zorzo", "Avelino F.", ""]]}, {"id": "1912.01667", "submitter": "Siddhant Bhambri", "authors": "Siddhant Bhambri, Sumanyu Muku, Avinash Tulasi, Arun Balaji Buduru", "title": "A Survey of Black-Box Adversarial Attacks on Computer Vision Models", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has seen tremendous advances in the past few years, which\nhas lead to deep learning models being deployed in varied applications of\nday-to-day life. Attacks on such models using perturbations, particularly in\nreal-life scenarios, pose a severe challenge to their applicability, pushing\nresearch into the direction which aims to enhance the robustness of these\nmodels. After the introduction of these perturbations by Szegedy et al. [1],\nsignificant amount of research has focused on the reliability of such models,\nprimarily in two aspects - white-box, where the adversary has access to the\ntargeted model and related parameters; and the black-box, which resembles a\nreal-life scenario with the adversary having almost no knowledge of the model\nto be attacked. To provide a comprehensive security cover, it is essential to\nidentify, study, and build defenses against such attacks. Hence, in this paper,\nwe propose to present a comprehensive comparative study of various black-box\nadversarial attacks and defense techniques.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 20:06:49 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 07:33:59 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2020 09:17:38 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Bhambri", "Siddhant", ""], ["Muku", "Sumanyu", ""], ["Tulasi", "Avinash", ""], ["Buduru", "Arun Balaji", ""]]}, {"id": "1912.01701", "submitter": "Dayeol Lee", "authors": "Dayeol Lee, Dongha Jung, Ian T. Fang, Chia-Che Tsai, Raluca Ada Popa", "title": "An Off-Chip Attack on Hardware Enclaves via the Memory Bus", "comments": "In proceedings of the 29th USENIX Security Symposium, 2020, 18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows how an attacker can break the confidentiality of a hardware\nenclave with Membuster, an off-chip attack based on snooping the memory bus. An\nattacker with physical access can observe an unencrypted address bus and\nextract fine-grained memory access patterns of the victim. Membuster is\nqualitatively different from prior on-chip attacks to enclaves and is more\ndifficult to thwart.\n  We highlight several challenges for Membuster. First, DRAM requests are only\nvisible on the memory bus at last-level cache misses. Second, the attack needs\nto incur minimal interference or overhead to the victim to prevent the\ndetection of the attack. Lastly, the attacker needs to reverse-engineer the\ntranslation between virtual, physical, and DRAM addresses to perform a robust\nattack. We introduce three techniques, critical page whitelisting, cache\nsqueezing, and oracle-based fuzzy matching algorithm to increase cache misses\nfor memory accesses that are useful for the attack, with no detectable\ninterference to the victim, and to convert memory accesses to sensitive data.\nWe demonstrate Membuster on an Intel SGX CPU to leak confidential data from two\napplications: Hunspell and Memcached. We show that a single uninterrupted run\nof the victim can leak most of the sensitive data with high accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 22:02:57 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Lee", "Dayeol", ""], ["Jung", "Dongha", ""], ["Fang", "Ian T.", ""], ["Tsai", "Chia-Che", ""], ["Popa", "Raluca Ada", ""]]}, {"id": "1912.01709", "submitter": "Abhishek Kesarwani", "authors": "Abhishek Kesarwani and Pabitra Mohan Khilar", "title": "Development of trust based access control models using fuzzy logic in\n  cloud computing", "comments": null, "journal-ref": null, "doi": "10.1016/j.jksuci.2019.11.001", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cloud computing is the technology that provides different types of services\nas a useful resource on the Internet. Resource trust value will help the cloud\nusers to select the services of a cloud provider for processing and storing\ntheir essential information. Also, service providers can give access to users\nbased on trust value to secure cloud resources from malicious users. In this\npaper, trust models are proposed, which comes under the subjective trust model\nbased on the behavior of user and service provider to calculate the trust\nvalues. The trust is fuzzy, which motivated us to apply fuzzy logic for\ncalculating the trust values of the cloud users and service providers in the\ncloud environment. We use a Mamdani fuzzy method with gauss membership function\nfor fuzzification and triangular membership function for defuzzification.\nParameters such as performance and elasticity are taken for trust evaluation of\nthe resource. The attributes for calculating performance are workload and\nresponse time. And for calculating elasticity, we have taken scalability,\navailability, security, and usability. The fuzzy C-means clustering is applied\nto parameters for evaluating the trust value of users such as bad requests,\nbogus requests, unauthorized requests, and total requests.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 06:10:53 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Kesarwani", "Abhishek", ""], ["Khilar", "Pabitra Mohan", ""]]}, {"id": "1912.01710", "submitter": "Miriam Leeser", "authors": "Xin Fang, Stratis Ioannidis and Miriam Leeser", "title": "SIFO: Secure Computational Infrastructure using FPGA Overlays", "comments": "International Journal of Reconfigurable Computing, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure Function Evaluation (SFE) has received recent attention due to the\nmassive collection and mining of personal data, but remains impractical due to\nits large computational cost. Garbled Circuits (GC) is a protocol for\nimplementing SFE which can evaluate any function that can be expressed as a\nBoolean circuit and obtain the result while keeping each party's input private.\nRecent advances have led to a surge of garbled circuit implementations in\nsoftware for a variety of different tasks. However, these implementations are\ninefficient and therefore GC is not widely used, especially for large problems.\nThis research investigates, implements and evaluates secure computation\ngeneration using a heterogeneous computing platform featuring FPGAs. We have\ndesigned and implemented SIFO: Secure computational Infrastructure using FPGA\nOverlays. Unlike traditional FPGA design, a coarse grained overlay architecture\nis adopted which supports mapping SFE problems that are too large to map to a\nsingle FPGA. Host tools provided include SFE problem generator, parser and\nautomatic host code generation. Our design allows re-purposing an FPGA to\nevaluate different SFE tasks without the need for reprogramming, and fully\nexplores the parallelism for any GC problem. Our system demonstrates an order\nof magnitude speedup compared with an existing software platform.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 14:46:50 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Fang", "Xin", ""], ["Ioannidis", "Stratis", ""], ["Leeser", "Miriam", ""]]}, {"id": "1912.01711", "submitter": "Jorge Pe\\~na Queralta", "authors": "Jorge Pe\\~na Queralta and Tomi Westerlund", "title": "Blockchain-Powered Collaboration in Heterogeneous Swarms of Robots", "comments": "2019 Symposium on Blockchain for Robotics and AI Systems, 16 pages, 2\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key challenges in the collaboration within heterogeneous\nmulti-robot systems is the optimization of the amount and type of data to be\nshared between robots with different sensing capabilities and computational\nresources. In this paper, we present a novel approach to managing collaboration\nterms in heterogeneous multi-robot systems with blockchain technology.\nLeveraging the extensive research of consensus algorithms in the blockchain\ndomain, we exploit key technologies in this field to be integrated for\nconsensus in robotic systems. We propose the utilization of proof of work\nsystems to have an online estimation of the available computational resources\nat different robots. Furthermore, we define smart contracts that integrate\ninformation about the environment from different robots in order to evaluate\nand rank the quality and accuracy of each of the robots' sensor data. This\nmeans that the key parameters involved in heterogeneous robotic collaboration\nare integrated within the Blockchain and estimated at all robots equally\nwithout explicitly sharing information about the robots' hardware or sensors.\nTrustability is based on the verification of data samples that are submitted to\nthe blockchain within each data exchange transaction and validated by other\nrobots operating in the same environment. Initial results are reported which\nshow the viability of the concepts presented in this paper.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 09:28:06 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 12:19:49 GMT"}, {"version": "v3", "created": "Sun, 5 Jul 2020 18:00:07 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Queralta", "Jorge Pe\u00f1a", ""], ["Westerlund", "Tomi", ""]]}, {"id": "1912.01712", "submitter": "Aliya Tabassum", "authors": "Aliya Tabassum and Wadha Lebda", "title": "Security Framework for IoT Devices against Cyber-Attacks", "comments": "18 Pages, 3 figures, 4 tables, International Conference on Internet\n  of Things (CIoT 2019)on November 23 ~ 24, 2019, Zurich, Switzerland", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) is the interconnection of heterogeneous smart\ndevices through the Internet with diverse application areas. The huge number of\nsmart devices and the complexity of networks has made it impossible to secure\nthe data and communication between devices. Various conventional security\ncontrols are insufficient to prevent numerous attacks against these\ninformation-rich devices. Along with enhancing existing approaches, a\nperipheral defence, Intrusion Detection System (IDS), proved efficient in most\nscenarios. However, conventional IDS approaches are unsuitable to mitigate\ncontinuously emerging zero-day attacks. Intelligent mechanisms that can detect\nunfamiliar intrusions seems a prospective solution. This article explores\npopular attacks against IoT architecture and its relevant defence mechanisms to\nidentify an appropriate protective measure for different networking practices\nand attack categories. Besides, a security framework for IoT architecture is\nprovided with a list of security enhancement techniques.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 13:43:07 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Tabassum", "Aliya", ""], ["Lebda", "Wadha", ""]]}, {"id": "1912.01713", "submitter": "Oleksii Konashevych", "authors": "Oleksii Konashevych", "title": "Cross-Blockchain Databases for Governments: The Technology for Public\n  Registries and Smart Laws", "comments": "This document needs major revision and is not going to be updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an ongoing competition among blockchain technologies and the\nexistence of one ultimate blockchain is impossible for many reasons. On the\nother hand, such variety can create difficulties in adoption, especially for\nthe governments and corporations. The proposed technology ensures a blockchain\nagnostic approach and aimed to create a unified ecosystem of multiple networks.\nThe cross-blockchain protocol can be used to develop services where end-users\ndecide for themselves their most preferred blockchain. The invention solves\nproblems of duplication of tokens in the result of hardforks, issues with\nscalability, digital identity and even the \"problem\" of immutability\n(enforceability). A cross-blockchain DB means a consistent non-conflicting\nkey-value database across a bunch of defined blockchains. It is not a new\nblockchain, but a protocol for developing databases on existing blockchains.\nThe protocol is also a basis for a \"smart law\" which is a framework for public\nregistries and their governance.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 00:10:09 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 02:32:40 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Konashevych", "Oleksii", ""]]}, {"id": "1912.01781", "submitter": "Mithilesh Kumar", "authors": "Mithilesh Kumar", "title": "Faster Lattice Enumeration", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A lattice reduction is an algorithm that transforms the given basis of the\nlattice to another lattice basis such that problems like finding a shortest\nvector and closest vector become easier to solve. Some of the famous lattice\nreduction algorithms are LLL and BKZ reductions. We define a class of bases\ncalled \\emph{obtuse bases} and show that any lattice basis can be transformed\nto an obtuse basis in $\\mathcal{O}(n^4)$ time. A shortest vector s can be\nwritten as $v_1b_1+\\cdots+v_nb_n$ where $b_1,\\dots,b_n$ are the input basis\nvectors and $v_1,\\dots,v_n$ are integers. When the input basis is obtuse, all\nthese integers can be chosen to be positive for a shortest vector. This\nproperty of the obtuse basis makes lattice enumeration algorithm for finding a\nshortest vector exponentially faster. Moreover, extreme pruning, the current\nfastest algorithm for lattice enumeration, can be run on an obtuse basis.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 11:23:03 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Kumar", "Mithilesh", ""]]}, {"id": "1912.01798", "submitter": "Charlie Hou", "authors": "Charlie Hou and Mingxun Zhou and Yan Ji and Phil Daian and Florian\n  Tramer and Giulia Fanti and Ari Juels", "title": "SquirRL: Automating Attack Analysis on Blockchain Incentive Mechanisms\n  with Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incentive mechanisms are central to the functionality of permissionless\nblockchains: they incentivize participants to run and secure the underlying\nconsensus protocol. Designing incentive-compatible incentive mechanisms is\nnotoriously challenging, however. As a result, most public blockchains today\nuse incentive mechanisms whose security properties are poorly understood and\nlargely untested. In this work, we propose SquirRL, a framework for using deep\nreinforcement learning to analyze attacks on blockchain incentive mechanisms.\nWe demonstrate SquirRL's power by first recovering known attacks: (1) the\noptimal selfish mining attack in Bitcoin [52], and (2) the Nash equilibrium in\nblock withholding attacks [16]. We also use SquirRL to obtain several novel\nempirical results. First, we discover a counterintuitive flaw in the widely\nused rushing adversary model when applied to multi-agent Markov games with\nincomplete information. Second, we demonstrate that the optimal selfish mining\nstrategy identified in [52] is actually not a Nash equilibrium in the\nmulti-agent selfish mining setting. In fact, our results suggest (but do not\nprove) that when more than two competing agents engage in selfish mining, there\nis no profitable Nash equilibrium. This is consistent with the lack of observed\nselfish mining in the wild. Third, we find a novel attack on a simplified\nversion of Ethereum's finalization mechanism, Casper the Friendly Finality\nGadget (FFG) that allows a strategic agent to amplify her rewards by up to 30%.\nNotably, [10] show that honest voting is a Nash equilibrium in Casper FFG: our\nattack shows that when Casper FFG is composed with selfish mining, this is no\nlonger the case. Altogether, our experiments demonstrate SquirRL's flexibility\nand promise as a framework for studying attack settings that have thus far\neluded theoretical and empirical understanding.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 04:48:21 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 19:02:57 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Hou", "Charlie", ""], ["Zhou", "Mingxun", ""], ["Ji", "Yan", ""], ["Daian", "Phil", ""], ["Tramer", "Florian", ""], ["Fanti", "Giulia", ""], ["Juels", "Ari", ""]]}, {"id": "1912.01855", "submitter": "Gamal Elkoumy", "authors": "Gamal Elkoumy, Stephan A. Fahrenkrog-Petersen, Marlon Dumas, Peeter\n  Laud, Alisa Pankova, Matthias Weildich", "title": "Secure Multi-Party Computation for Inter-Organizational Process Mining", "comments": "15 pages ,5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process mining is a family of techniques for analysing business processes\nbased on event logs extracted from information systems. Mainstream process\nmining tools are designed for intra-organizational settings, insofar as they\nassume that an event log is available for processing as a whole. The use of\nsuch tools for inter-organizational process analysis is hampered by the fact\nthat such processes involve independent parties who are unwilling to, or\nsometimes legally prevented from, sharing detailed event logs with each other.\nIn this setting, this paper proposes an approach for constructing and querying\na common type of artifact used for process mining, namely the frequency and\ntime-annotated Directly-Follows Graph (DFG), over multiple event logs belonging\nto different parties, in such a way that the parties do not share the event\nlogs with each other. The proposal leverages an existing platform for secure\nmulti-party computation, namely Sharemind. Since a direct implementation of DFG\nconstruction in Sharemind suffers from scalability issues, the paper proposes\nto rely on vectorization of event logs and to employ a divide-and-conquer\nscheme for parallel processing of sub-logs. The paper reports on an\nexperimental evaluation that tests the scalability of the approach on real-life\nlogs.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 09:08:38 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 08:00:21 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Elkoumy", "Gamal", ""], ["Fahrenkrog-Petersen", "Stephan A.", ""], ["Dumas", "Marlon", ""], ["Laud", "Peeter", ""], ["Pankova", "Alisa", ""], ["Weildich", "Matthias", ""]]}, {"id": "1912.01959", "submitter": "Alexander Kott", "authors": "Paul Th\\'eron, Alexander Kott", "title": "When Autonomous Intelligent Goodware will Fight Autonomous Intelligent\n  Malware: A Possible Future of Cyber Defense", "comments": "MILCOM-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the coming years, the future of military combat will include, on one hand,\nartificial intelligence-optimized complex command, control, communications,\ncomputers, intelligence, surveillance and reconnaissance (C4ISR) and networks\nand, on the other hand, autonomous intelligent Things fighting autonomous\nintelligent Things at a fast pace. Under this perspective, enemy forces will\nseek to disable or disturb our autonomous Things and our complex\ninfrastructures and systems. Autonomy, scale and complexity in our defense\nsystems will trigger new cyber-attack strategies, and autonomous intelligent\nmalware (AIM) will be part of the picture. Should these cyber-attacks succeed\nwhile human operators remain unaware or unable to react fast enough due to the\nspeed, scale or complexity of the mission, systems or attacks, missions would\nfail, our networks and C4ISR would be heavily disrupted, and command and\ncontrol would be disabled. New cyber-defense doctrines and technologies are\ntherefore required. Autonomous cyber defense (ACyD) is a new field of research\nand technology driven by the defense sector in anticipation of such threats to\nfuture military infrastructures, systems and operations. It will be implemented\nvia swarms of autonomous intelligent cyber-defense agents (AICAs) that will\nfight AIM within our networks and systems. This paper presents this\ncyber-defense technology of the future, the current state of the art in this\nfield and its main challenges. First, we review the rationale of the ACyD\nconcept and its associated AICA technology. Then, we present the current\nresearch results from NATO's IST-152 Research Task Group on the AICA Reference\nArchitecture. We then develop the 12 main technological challenges that must be\nresolved in the coming years, besides ethical and political issues.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 20:36:48 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Th\u00e9ron", "Paul", ""], ["Kott", "Alexander", ""]]}, {"id": "1912.02015", "submitter": "Zimin Chen", "authors": "Zimin Chen, Steve Kommrusch, Martin Monperrus", "title": "Using Sequence-to-Sequence Learning for Repairing C Vulnerabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software vulnerabilities affect all businesses and research is being done to\navoid, detect or repair them. In this article, we contribute a new technique\nfor automatic vulnerability fixing. We present a system that uses the rich\nsoftware development history that can be found on GitHub to train an AI system\nthat generates patches. We apply sequence-to-sequence learning on a big dataset\nof code changes and we evaluate the trained system on real world\nvulnerabilities from the CVE database. The result shows the feasibility of\nusing sequence-to-sequence learning for fixing software vulnerabilities.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 14:27:34 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Chen", "Zimin", ""], ["Kommrusch", "Steve", ""], ["Monperrus", "Martin", ""]]}, {"id": "1912.02036", "submitter": "Son Nguyen Hong", "authors": "Nguyen Hong Son, Ha Thanh Dung", "title": "The method of detecting online password attacks based on high-level\n  protocol analysis and clustering techniques", "comments": "13 pages, 7 figures", "journal-ref": "International Journal of Computer Networks & Communications\n  (IJCNC) Vol.11, No.6, November 2019", "doi": "10.5121/ijcnc.2019.11605", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although there have been many solutions applied, the safety challenges\nrelated to the password security mechanism are not reduced. The reason for this\nis that while the means and tools to support password attacks are becoming more\nand more abundant, the number of transaction systems through the Internet is\nincreasing, and new services systems appear. For example, IoT also uses\npassword-based authentication. In this context, consolidating password-based\nauthentication mechanisms is critical, but monitoring measures for timely\ndetection of attacks also play an important role in this battle. The password\nattack detection solutions being used need to be supplemented and improved to\nmeet the new situation. In this paper we propose a solution that automatically\ndetects online password attacks in a way that is based solely on the network,\nusing unsupervised learning techniques and protected application orientation.\nOur solution, therefore, minimizes dependence on the factors encountered by\nhost-based or supervised learning solutions. The certainty of the solution\ncomes from using the results of an in-depth analysis of attack characteristics\nto build the detection capacity of the mechanism. The solution was implemented\nexperimentally on the real system and gave positive results.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 15:01:17 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Son", "Nguyen Hong", ""], ["Dung", "Ha Thanh", ""]]}, {"id": "1912.02045", "submitter": "Xiaojie Zhu", "authors": "Xiaojie Zhu (1), Erman Ayday (2), Roman Vitenberg (1), Narasimha\n  Raghavan Veeraragavan (1) ((1) University of Oslo, (2) Case Western Reserve\n  University)", "title": "Privacy-Preserving Search for a Similar Genomic Makeup in the Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we attempt to provide a privacy-preserving and efficient\nsolution for the \"similar patient search\" problem among several parties (e.g.,\nhospitals) by addressing the shortcomings of previous attempts. We consider a\nscenario in which each hospital has its own genomic dataset and the goal of a\nphysician (or researcher) is to search for a patient similar to a given one\n(based on a genomic makeup) among all the hospitals in the system. To enable\nthis search, we let each hospital encrypt its dataset with its own key and\noutsource the storage of its dataset to a public cloud. The physician can get\nauthorization from multiple hospitals and send a query to the cloud, which\nefficiently performs the search across authorized hospitals using a\nprivacy-preserving index structure. We propose a hierarchical index structure\nto index each hospital's dataset with low memory requirements. Furthermore, we\ndevelop a novel privacy-preserving index merging mechanism that generates a\ncommon search index from individual indices of each hospital to significantly\nimprove the search efficiency. We also consider the storage of medical\ninformation associated with genomic data of a patient (e.g., diagnosis and\ntreatment). We allow access to this information via a fine-grained access\ncontrol policy that we develop through the combination of standard symmetric\nencryption and ciphertext policy attribute-based encryption. Using this\nmechanism, a physician can search for similar patients and obtain medical\ninformation about the matching records if the access policy holds. We conduct\nexperiments on large-scale genomic data and show the efficiency of the proposed\nscheme. Notably, we show that under our experimental settings, the proposed\nscheme is more than $60$ times faster than Wang et al.'s protocol and $95$\ntimes faster than Asharov et al.'s solution.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 15:11:11 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 17:39:19 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Zhu", "Xiaojie", ""], ["Ayday", "Erman", ""], ["Vitenberg", "Roman", ""], ["Veeraragavan", "Narasimha Raghavan", ""]]}, {"id": "1912.02089", "submitter": "Xinyu Fan", "authors": "Faen Zhang, Xinyu Fan, Pengcheng Zhou, Wenfeng Zhou", "title": "On the Security of A Remote Cloud Storage Integrity Checking Protocol", "comments": "arXiv admin note: text overlap with arXiv:1912.00446", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data security and privacy is an important but challenging problem in cloud\ncomputing. One of the security concerns from cloud users is how to efficiently\nverify the integrity of their data stored on the cloud server. Third Party\nAuditing (TPA) is a new technique proposed in recent years to achieve this\ngoal. In a recent paper (IEEE Transactions on Computers 62(2): 362-375 (2013)),\nWang et al. proposed a highly efficient and scalable TPA protocol and also a\nZero Knowledge Public Auditing protocol which can prevent offline guessing\nattacks. However, in this paper, we point out several security weaknesses in\nWang et al's protocols: first, we show that an attacker can arbitrarily modify\nthe cloud data without being detected by the auditor in the integrity checking\nprocess, and the attacker can achieve this goal even without knowing the\ncontent of the cloud data or any verification metadata maintained by the cloud\nserver; secondly, we show that the Zero Knowledge Public Auditing protocol\ncannot achieve its design goal, that is to prevent offline guessing attacks.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 17:16:35 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Zhang", "Faen", ""], ["Fan", "Xinyu", ""], ["Zhou", "Pengcheng", ""], ["Zhou", "Wenfeng", ""]]}, {"id": "1912.02153", "submitter": "Hanwei Zhang", "authors": "Hanwei Zhang, Yannis Avrithis, Teddy Furon, Laurent Amsaleg", "title": "Walking on the Edge: Fast, Low-Distortion Adversarial Examples", "comments": "13 pages, 9 figures", "journal-ref": null, "doi": "10.1109/TIFS.2020.3021899", "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples of deep neural networks are receiving ever increasing\nattention because they help in understanding and reducing the sensitivity to\ntheir input. This is natural given the increasing applications of deep neural\nnetworks in our everyday lives. When white-box attacks are almost always\nsuccessful, it is typically only the distortion of the perturbations that\nmatters in their evaluation.\n  In this work, we argue that speed is important as well, especially when\nconsidering that fast attacks are required by adversarial training. Given more\ntime, iterative methods can always find better solutions. We investigate this\nspeed-distortion trade-off in some depth and introduce a new attack called\nboundary projection (BP) that improves upon existing methods by a large margin.\nOur key idea is that the classification boundary is a manifold in the image\nspace: we therefore quickly reach the boundary and then optimize distortion on\nthis manifold.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 18:04:53 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 12:07:15 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Zhang", "Hanwei", ""], ["Avrithis", "Yannis", ""], ["Furon", "Teddy", ""], ["Amsaleg", "Laurent", ""]]}, {"id": "1912.02258", "submitter": "Raj Dasgupta", "authors": "Prithviraj Dasgupta and Joseph B. Collins", "title": "A Survey of Game Theoretic Approaches for Adversarial Machine Learning\n  in Cybersecurity Tasks", "comments": "13 pages, 2 figures, 1 table", "journal-ref": "AI Magazine, 40(2), 31-43 (2019)", "doi": "10.1609/aimag.v40i2.2847", "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques are currently used extensively for automating\nvarious cybersecurity tasks. Most of these techniques utilize supervised\nlearning algorithms that rely on training the algorithm to classify incoming\ndata into different categories, using data encountered in the relevant domain.\nA critical vulnerability of these algorithms is that they are susceptible to\nadversarial attacks where a malicious entity called an adversary deliberately\nalters the training data to misguide the learning algorithm into making\nclassification errors. Adversarial attacks could render the learning algorithm\nunsuitable to use and leave critical systems vulnerable to cybersecurity\nattacks. Our paper provides a detailed survey of the state-of-the-art\ntechniques that are used to make a machine learning algorithm robust against\nadversarial attacks using the computational framework of game theory. We also\ndiscuss open problems and challenges and possible directions for further\nresearch that would make deep machine learning-based systems more robust and\nreliable for cybersecurity tasks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 21:42:15 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Dasgupta", "Prithviraj", ""], ["Collins", "Joseph B.", ""]]}, {"id": "1912.02285", "submitter": "Shravan Ravi Narayan", "authors": "Shravan Narayan, Tal Garfinkel, Sorin Lerner, Hovav Shacham, Deian\n  Stefan", "title": "Gobi: WebAssembly as a Practical Path to Library Sandboxing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software based fault isolation (SFI) is a powerful approach to reduce the\nimpact of security vulnerabilities in large C/C++ applications like Firefox and\nApache. Unfortunately, practical SFI tools have not been broadly available.\n  Developing SFI toolchains are a significant engineering challenge. Only in\nrecent years have browser vendors invested in building production quality SFI\ntools like Native Client (NaCl) to sandbox code. Further, without committed\nsupport, these tools are not viable, e.g. NaCl has been discontinued, orphaning\nprojects that relied on it.\n  WebAssembly (Wasm) offers a promising solution---it can support high\nperformance sandboxing and has been embraced by all major browser\nvendors---thus seems to have a viable future. However, Wasm presently only\noffers a solution for sandboxing mobile code. Providing SFI for native\napplication, such as C/C++ libraries requires additional steps.\n  To reconcile the different worlds of Wasm on the browser and native\nplatforms, we present Gobi. Gobi is a system of compiler changes and runtime\nsupport that can sandbox normal C/C++ libraries with Wasm---allowing them to be\ncompiled and linked into native applications. Gobi has been tested on libjpeg,\nlibpng, and zlib.\n  Based on our experience developing Gobi, we conclude with a call to arms to\nthe Wasm community and SFI research community to make Wasm based module\nsandboxing a first class use case and describe how this can significantly\nbenefit both communities.\n  Addendum: This short paper was originally written in January of 2019. Since\nthen, the implementation and design of Gobi has evolved substantially as some\nof the issues raised in this paper have been addressed by the Wasm community.\nNevertheless, several challenges still remain. We have thus left the paper\nlargely intact and only provide a brief update on the state of Wasm tooling as\nof November 2019 in the last section.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 22:28:03 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Narayan", "Shravan", ""], ["Garfinkel", "Tal", ""], ["Lerner", "Sorin", ""], ["Shacham", "Hovav", ""], ["Stefan", "Deian", ""]]}, {"id": "1912.02480", "submitter": "Mario Dagrada", "authors": "Daniel Ricardo dos Santos, Mario Dagrada, Elisa Costante", "title": "Leveraging Operational Technology and the Internet of Things to Attack\n  Smart Buildings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the buildings where we spend most part of our life are\nrapidly evolving. They are becoming fully automated environments where energy\nconsumption, access control, heating and many other subsystems are all\nintegrated within a single system commonly referred to as smart building (SB).\nTo support the growing complexity of building operations, building automation\nsystems (BAS) powering SBs are integrating consumer range Internet of Things\n(IoT) devices such as IP cameras alongside with operational technology (OT)\ncontrollers and actuators. However, these changes pose important cybersecurity\nconcerns since the attack surface is larger, attack vectors are increasing and\nattacks can potentially harm building occupants. In this paper, we analyze the\nthreat landscape of BASs by focusing on subsystems which are strongly affected\nby the advent of IoT devices such as video surveillance systems and smart\nlightning. We demonstrate how BAS operation can be disrupted by simple attacks\nto widely used network protocols. Furthermore, using both known and 0-day\nvulnerabilities reported in the paper and previously disclosed, we present the\nfirst (at our knowledge) BAS-specific malware which is able to persist within\nthe BAS network by leveraging both OT and IoT devices connected to the BAS. Our\nresearch highlights how BAS networks can be considered as critical as\nindustrial control systems and security concerns in BASs deserve more attention\nfrom both industrial and scientific communities. Even within a simulated\nenvironment, our proof-of-concept attacks were carried out with relative ease\nand a limited amount of budget and resources. Therefore, we believe that\nwell-funded attack groups will increasingly shift their focus towards BASs with\nthe potential of impacting the live of thousands of people.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 10:24:12 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Santos", "Daniel Ricardo dos", ""], ["Dagrada", "Mario", ""], ["Costante", "Elisa", ""]]}, {"id": "1912.02520", "submitter": "Simon Bell", "authors": "Simon Bell, Kenny Paterson, Lorenzo Cavallaro", "title": "Catch Me (On Time) If You Can: Understanding the Effectiveness of\n  Twitter URL Blacklists", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With more than 500 million daily tweets from over 330 million active users,\nTwitter constantly attracts malicious users aiming to carry out phishing and\nmalware-related attacks against its user base. It therefore becomes of\nparamount importance to assess the effectiveness of Twitter's use of blacklists\nin protecting its users from such threats. We collected more than 182 million\npublic tweets containing URLs from Twitter's Stream API over a 2-month period\nand compared these URLs against 3 popular phishing, social engineering, and\nmalware blacklists, including Google Safe Browsing (GSB). We focus on the delay\nperiod between an attack URL first being tweeted to appearing on a blacklist,\nas this is the timeframe in which blacklists do not warn users, leaving them\nvulnerable. Experiments show that, whilst GSB is effective at blocking a number\nof social engineering and malicious URLs within 6 hours of being tweeted, a\nsignificant number of URLs go undetected for at least 20 days. For instance,\nduring one month, we discovered 4,930 tweets containing URLs leading to social\nengineering websites that had been tweeted to over 131 million Twitter users.\nWe also discovered 1,126 tweets containing 376 blacklisted Bitly URLs that had\na combined total of 991,012 clicks, posing serious security and privacy\nthreats. In addition, an equally large number of URLs contained within public\ntweets remain in GSB for at least 150 days, raising questions about potential\nfalse positives in the blacklist. We also provide evidence to suggest that\nTwitter may no longer be using GSB to protect its users.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 11:59:06 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Bell", "Simon", ""], ["Paterson", "Kenny", ""], ["Cavallaro", "Lorenzo", ""]]}, {"id": "1912.02551", "submitter": "Liron David", "authors": "Liron David and Avishai Wool", "title": "Online Password Guessability via Multi-Dimensional Rank Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-chosen passwords are the a dominant form of authentication systems.\nPasswords strength estimators are used to help users avoid picking weak\npasswords by predicting how many attempts a password cracker would need until\nit finds a given password.\n  In this paper we propose a novel password strength estimator, called PESrank,\nwhich accurately models the behavior of a powerful password cracker. PESrank\ncalculates the rank of a given password in an optimal descending order of\nlikelihood. PESrank estimates a given password's rank in fractions of a\nsecond---without actually enumerating the passwords---so it is practical for\nonline use. It also has a training time that is drastically shorter than\nprevious methods. Moreover, PESrank is efficiently tweakable to allow model\npersonalization in fractions of a second, without the need to retrain the\nmodel; and it is explainable: it is able to provide information on why the\npassword has its calculated rank, and gives the user insight on how to pick a\nbetter password.\n  Our idea is to cast the question of password rank estimation in a\nprobabilistic framework used in side-channel cryptanalysis. We view each\npassword as a point in a $d$-dimensional search space, and learn the\nprobability distribution of each dimension separately. The dimensions represent\nthe base word, plus a dimension for each possible transformation such as adding\na suffix or using a capitalization pattern. Using this model, password strength\nestimation is analogous to side-channel rank estimation.\n  We implemented PERrank in Python and conducted an extensive evaluation study\nof it. We also integrated it into the registration page of a course at our\nuniversity. Even with a model based on 905 million passwords, the response time\nwas well under 1 second, with up to a 1-bit accuracy margin between the upper\nbound and the lower bound on the rank.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 13:05:26 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 20:42:47 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["David", "Liron", ""], ["Wool", "Avishai", ""]]}, {"id": "1912.02583", "submitter": "Alberto Sonnino", "authors": "Alberto Sonnino", "title": "FMPC: Secure Multiparty Computation from Fourier Series and Parseval's\n  Identity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FMPC is a novel multiparty computation protocol of arithmetic circuits based\non secret-sharing, capable of computing multiplication of secrets with no\nonline communication; it thus enjoys constant online communication latency in\nthe size of the circuit. FMPC is based on the application of Fourier series to\nParseval's identity, and introduces the first generalization of Parseval's\nidentity for Fourier series applicable to an arbitrary number of inputs. FMPC\noperates in a setting where users wish to compute a function over some secret\ninputs by submitting the computation to a set of nodes, but is only suitable\nfor the evaluation of low-depth arithmetic circuits. FMPC relies on an offline\nphase consisting of traditional preprocessing as introduced by established\nprotocols like SPDZ, and innovates on the online phase that mainly consists of\neach node locally evaluating specific functions. FMPC paves the way for a new\nkind of multiparty computation protocols capable of computing multiplication of\nsecrets as an alternative to circuit garbling and the traditional algebra\nintroduced by Donald Beaver in 1991.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 14:11:35 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Sonnino", "Alberto", ""]]}, {"id": "1912.02592", "submitter": "Ajith Suresh", "authors": "Harsh Chaudhari, Ashish Choudhury, Arpita Patra, Ajith Suresh", "title": "ASTRA: High Throughput 3PC over Rings with Application to Secure\n  Prediction", "comments": "This article is the full and extended version of an article appeared\n  in ACM CCSW 2019", "journal-ref": null, "doi": "10.1145/3338466.3358922", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The concrete efficiency of secure computation has been the focus of many\nrecent works. In this work, we present concretely-efficient protocols for\nsecure $3$-party computation (3PC) over a ring of integers modulo $2^{\\ell}$\ntolerating one corruption, both with semi-honest and malicious security. Owing\nto the fact that computation over ring emulates computation over the real-world\nsystem architectures, secure computation over ring has gained momentum of late.\n  Cast in the offline-online paradigm, our constructions present the most\nefficient online phase in concrete terms. In the semi-honest setting, our\nprotocol requires communication of $2$ ring elements per multiplication gate\nduring the {\\it online} phase, attaining a per-party cost of {\\em less than one\nelement}. This is achieved for the first time in the regime of 3PC. In the {\\it\nmalicious} setting, our protocol requires communication of $4$ elements per\nmultiplication gate during the online phase, beating the state-of-the-art\nprotocol by $5$ elements. Realized with both the security notions of selective\nabort and fairness, the malicious protocol with fairness involves slightly more\ncommunication than its counterpart with abort security for the output gates\n{\\em alone}.\n  We apply our techniques from $3$PC in the regime of secure server-aided\nmachine-learning (ML) inference for a range of prediction functions-- linear\nregression, linear SVM regression, logistic regression, and linear SVM\nclassification. Our setting considers a model-owner with trained model\nparameters and a client with a query, with the latter willing to learn the\nprediction of her query based on the model parameters of the former. The inputs\nand computation are outsourced to a set of three non-colluding servers. Our\nconstructions catering to both semi-honest and the malicious world, invariably\nperform better than the existing constructions.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 14:30:39 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Chaudhari", "Harsh", ""], ["Choudhury", "Ashish", ""], ["Patra", "Arpita", ""], ["Suresh", "Ajith", ""]]}, {"id": "1912.02611", "submitter": "Hossein Mohammadi Rouzbahani", "authors": "Hossein Mohammadi Rouzbahani, Hadis Karimipour, Ali Dehghantanha, Reza\n  M. Parizi", "title": "Blockchain Applications in Power Systems: A Bibliometric Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power systems are growing rapidly, due to the ever-increasing demand for\nelectrical power. These systems require novel methodologies and modern tools\nand technologies, to better perform, particularly for communication among\ndifferent parts. Therefore, power systems are facing new challenges such as\nenergy trading and marketing and cyber threats. Using blockchain in power\nsystems, as a solution, is one of the newest methods. Most studies aim to\ninvestigate innovative approach-es of blockchain application in power systems.\nEven though, many articles published to support the research activities, there\nhas not been any bibliometric analysis which specifies the research trends.\nThis paper aims to present a bibliographic analysis of the blockchain\napplication in power systems related literature, in the Web of Science (WoS)\ndatabase between January 2009 and July 2019. This paper discusses the research\nactivities and performed a detailed analysis by looking at the number of\narticles published, citations, institutions, research areas, and authors. From\nthe analysis, it was concluded that there are several significant impacts of\nresearch activities in China and the USA, in comparison to other countries.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 14:47:04 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Rouzbahani", "Hossein Mohammadi", ""], ["Karimipour", "Hadis", ""], ["Dehghantanha", "Ali", ""], ["Parizi", "Reza M.", ""]]}, {"id": "1912.02629", "submitter": "Marieh Alaghband", "authors": "Niloofar Yousefi, Marie Alaghband, Ivan Garibay", "title": "A Comprehensive Survey on Machine Learning Techniques and User\n  Authentication Approaches for Credit Card Fraud Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increase of credit card usage, the volume of credit card misuse also\nhas significantly increased. As a result, financial organizations are working\nhard on developing and deploying credit card fraud detection methods, in order\nto adapt to ever-evolving, increasingly sophisticated defrauding strategies and\nidentifying illicit transactions as quickly as possible to protect themselves\nand their customers. Compounding on the complex nature of such adverse\nstrategies, credit card fraudulent activities are rare events compared to the\nnumber of legitimate transactions. Hence, the challenge to develop fraud\ndetection that are accurate and efficient is substantially intensified and, as\na consequence, credit card fraud detection has lately become a very active area\nof research. In this work, we provide a survey of current techniques most\nrelevant to the problem of credit card fraud detection. We carry out our survey\nin two main parts. In the first part,we focus on studies utilizing classical\nmachine learning models, which mostly employ traditional transnational features\nto make fraud predictions. These models typically rely on some static physical\ncharacteristics, such as what the user knows (knowledge-based method), or what\nhe/she has access to (object-based method). In the second part of our survey,\nwe review more advanced techniques of user authentication, which use behavioral\nbiometrics to identify an individual based on his/her unique behavior while\nhe/she is interacting with his/her electronic devices. These approaches rely on\nhow people behave (instead of what they do), which cannot be easily forged. By\nproviding an overview of current approaches and the results reported in the\nliterature, this survey aims to drive the future research agenda for the\ncommunity in order to develop more accurate, reliable and scalable models of\ncredit card fraud detection.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 21:40:39 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Yousefi", "Niloofar", ""], ["Alaghband", "Marie", ""], ["Garibay", "Ivan", ""]]}, {"id": "1912.02631", "submitter": "Ajith Suresh", "authors": "Harsh Chaudhari, Rahul Rachuri, Ajith Suresh", "title": "Trident: Efficient 4PC Framework for Privacy Preserving Machine Learning", "comments": "This work appeared at the 26th Annual Network and Distributed System\n  Security Symposium (NDSS) 2020. Update: An improved version of this framework\n  is available at arXiv:2106.02850", "journal-ref": null, "doi": "10.14722/ndss.2020.23005", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning has started to be deployed in fields such as healthcare and\nfinance, which propelled the need for and growth of privacy-preserving machine\nlearning (PPML). We propose an actively secure four-party protocol (4PC), and a\nframework for PPML, showcasing its applications on four of the most\nwidely-known machine learning algorithms -- Linear Regression, Logistic\nRegression, Neural Networks, and Convolutional Neural Networks. Our 4PC\nprotocol tolerating at most one malicious corruption is practically efficient\nas compared to the existing works. We use the protocol to build an efficient\nmixed-world framework (Trident) to switch between the Arithmetic, Boolean, and\nGarbled worlds. Our framework operates in the offline-online paradigm over\nrings and is instantiated in an outsourced setting for machine learning. Also,\nwe propose conversions especially relevant to privacy-preserving machine\nlearning. The highlights of our framework include using a minimal number of\nexpensive circuits overall as compared to ABY3. This can be seen in our\ntechnique for truncation, which does not affect the online cost of\nmultiplication and removes the need for any circuits in the offline phase. Our\nB2A conversion has an improvement of $\\mathbf{7} \\times$ in rounds and\n$\\mathbf{18} \\times$ in the communication complexity. The practicality of our\nframework is argued through improvements in the benchmarking of the\naforementioned algorithms when compared with ABY3. All the protocols are\nimplemented over a 64-bit ring in both LAN and WAN settings. Our improvements\ngo up to $\\mathbf{187} \\times$ for the training phase and $\\mathbf{158} \\times$\nfor the prediction phase when observed over LAN and WAN.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 15:06:39 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 09:08:04 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Chaudhari", "Harsh", ""], ["Rachuri", "Rahul", ""], ["Suresh", "Ajith", ""]]}, {"id": "1912.02651", "submitter": "Maede Zolanvari", "authors": "Maede Zolanvari, Marcio A. Teixeira, Raj Jain", "title": "Effect of Imbalanced Datasets on Security of Industrial IoT Using\n  Machine Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1911.05771", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms have been shown to be suitable for securing\nplatforms for IT systems. However, due to the fundamental differences between\nthe industrial internet of things (IIoT) and regular IT networks, a special\nperformance review needs to be considered. The vulnerabilities and security\nrequirements of IIoT systems demand different considerations. In this paper, we\nstudy the reasons why machine learning must be integrated into the security\nmechanisms of the IIoT, and where it currently falls short in having a\nsatisfactory performance. The challenges and real-world considerations\nassociated with this matter are studied in our experimental design. We use an\nIIoT testbed resembling a real industrial plant to show our proof of concept.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 20:16:47 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Zolanvari", "Maede", ""], ["Teixeira", "Marcio A.", ""], ["Jain", "Raj", ""]]}, {"id": "1912.02771", "submitter": "Dimitris Tsipras", "authors": "Alexander Turner, Dimitris Tsipras, Aleksander Madry", "title": "Label-Consistent Backdoor Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been demonstrated to be vulnerable to backdoor\nattacks. Specifically, by injecting a small number of maliciously constructed\ninputs into the training set, an adversary is able to plant a backdoor into the\ntrained model. This backdoor can then be activated during inference by a\nbackdoor trigger to fully control the model's behavior. While such attacks are\nvery effective, they crucially rely on the adversary injecting arbitrary inputs\nthat are---often blatantly---mislabeled. Such samples would raise suspicion\nupon human inspection, potentially revealing the attack. Thus, for backdoor\nattacks to remain undetected, it is crucial that they maintain\nlabel-consistency---the condition that injected inputs are consistent with\ntheir labels. In this work, we leverage adversarial perturbations and\ngenerative models to execute efficient, yet label-consistent, backdoor attacks.\nOur approach is based on injecting inputs that appear plausible, yet are hard\nto classify, hence causing the model to rely on the (easier-to-learn) backdoor\ntrigger.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 18:05:59 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 23:16:45 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Turner", "Alexander", ""], ["Tsipras", "Dimitris", ""], ["Madry", "Aleksander", ""]]}, {"id": "1912.02919", "submitter": "Stephanie L. Hyland", "authors": "Stephanie L. Hyland and Shruti Tople", "title": "An Empirical Study on the Intrinsic Privacy of SGD", "comments": "17 pages, 11 figures, 7 tables; v3 edits: emphasised empirical nature\n  of work, added more analyses, fixed some errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We take the first step towards understanding whether the intrinsic randomness\nof stochastic gradient descent (SGD) can be leveraged for privacy, for any\ngiven dataset and model. In doing so, we hope to mitigate the trade-off between\nprivacy and performance for models trained with differential-privacy (DP)\nguarantees. Our main contribution is a large-scale empirical analysis of SGD on\nconvex and non-convex objectives, on four datasets. We evaluate the inherent\nvariability in SGD and calculate the intrinsic data-dependent\n$\\epsilon_i(\\mathcal{D})$ values due to the inherent noise. We show that the\nvariability in model parameters due to random sampling almost always exceeds\nthat due to changes in the data. We show that the existing theoretical bound on\nthe sensitivity of SGD with convex objectives is not tight. For logistic\nregression, we observe that SGD provides intrinsic $\\epsilon_i(\\mathcal{D})$\nvalues between 3.95 and 23.10 across four datasets, dropping to between 1.25\nand 4.22 using the tight empirical sensitivity bound. For neural networks, we\nreport high $\\epsilon_i(\\mathcal{D})$ values (>40) owing to their larger\nparameter count. Next, we propose a method to augment the intrinsic noise of\nSGD to achieve the desired target $\\epsilon$. Our augmented SGD produces models\nthat outperform existing approaches with the same privacy target, closing the\ngap to noiseless utility between 0.03% and 36.31% for logistic regression. We\nfurther explore the role of the number of steps of SGD, and demonstrate that\nour estimates are stable. Our experiments provide concrete evidence that\nchanging the seed in SGD has a far greater impact on the model's weights than\nexcluding any given training example. By accounting for this intrinsic\nrandomness - subject to necessary assumptions, we can achieve a consistent and\nstatistically significant improvement in utility, without sacrificing further\nprivacy.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 23:28:05 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 16:08:31 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 11:46:04 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Hyland", "Stephanie L.", ""], ["Tople", "Shruti", ""]]}, {"id": "1912.02924", "submitter": "Allison Irvin", "authors": "Allison Irvin, Isabell Kiral", "title": "Designing for Privacy and Confidentiality on Distributed Ledgers for\n  Enterprise (Industry Track)", "comments": "Middleware 2019", "journal-ref": "In Proceedings of Middleware 2019: 20th ACM/IFIP International\n  Middleware Conference (Middleware 2019). ACM, New York, NY, USA", "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed ledger technology offers numerous desirable attributes to\napplications in the enterprise context. However, with distributed data and\ndecentralized computation on a shared platform, privacy and confidentiality\nchallenges arise. Any design for an enterprise system needs to carefully cater\nfor use case specific privacy and confidentiality needs. With the goal to\nfacilitate the design of enterprise solutions, this paper aims to provide a\nguide to navigate and aid in decisions around common requirements and\nmechanisms that prevent the leakage of private and confidential information. To\nfurther contextualize key concepts, the design guide is then applied to three\nenterprise DLT protocols: Hyperledger Fabric, Corda, and Quorum.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 23:51:58 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Irvin", "Allison", ""], ["Kiral", "Isabell", ""]]}, {"id": "1912.02954", "submitter": "Michael Neuder", "authors": "Michael Neuder, Daniel J. Moroz, Rithvik Rao, David C. Parkes", "title": "Selfish Behavior in the Tezos Proof-of-Stake Protocol", "comments": "Presented at Cryptoeconomic Systems Conference 2020. To appear in\n  Cryptoeconomic Systems Journal Issue 0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proof-of-Stake consensus protocols give rise to complex modeling challenges.\nWe analyze the recently-updated Tezos Proof-of-Stake protocol and demonstrate\nthat, under certain conditions, rational participants are incentivized to\nbehave dishonestly. In doing so, we provide a theoretical analysis of the\nfeasibility and profitability of a block stealing attack that we call selfish\nendorsing, a concrete instance of an attack previously only theoretically\nconsidered. We propose and analyze a simple change to the Tezos protocol which\nsignificantly reduces the (already small) profitability of this dishonest\nbehavior, and introduce a new delay and reward scheme that is provably secure\nagainst length-1 and length-2 selfish endorsing attacks. Our framework provides\na template for analyzing other Proof-of-Stake implementations for selfish\nbehavior.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 02:47:37 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 17:02:13 GMT"}, {"version": "v3", "created": "Mon, 23 Mar 2020 14:45:43 GMT"}, {"version": "v4", "created": "Wed, 8 Apr 2020 01:01:28 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Neuder", "Michael", ""], ["Moroz", "Daniel J.", ""], ["Rao", "Rithvik", ""], ["Parkes", "David C.", ""]]}, {"id": "1912.03009", "submitter": "Aleksey Fedorov", "authors": "M.A. Kudinov, A.A. Chilikov, E.O. Kiktenko, A.K. Fedorov", "title": "Advanced attribute-based protocol based on the modified secret sharing\n  scheme", "comments": "15 pages", "journal-ref": "J. Comput. Virol. Hacking Tech. 16, 333 (2020)", "doi": "10.1007/s11416-020-00366-8", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a new protocol for attribute-based encryption with the use of\nthe modification of the standard secret sharing scheme. In the suggested\nmodification of the secret sharing scheme, only one master key for each user is\nrequired that is achieved by linearly enlarging public parameters in the access\nformula. We then use this scheme for designing an attribute-based encryption\nprotocol related to some access structure in terms of attributes. We\ndemonstrate that the universe of possible attributes does not affect the\nresulting efficiency of the scheme. The security proofs for both constructions\nare provided.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 07:47:33 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 07:26:37 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 13:18:02 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Kudinov", "M. A.", ""], ["Chilikov", "A. A.", ""], ["Kiktenko", "E. O.", ""], ["Fedorov", "A. K.", ""]]}, {"id": "1912.03076", "submitter": "Zhi Zhang", "authors": "Zhi Zhang, Yueqiang Cheng, Dongxi Liu, Surya Nepal, and Zhi Wang", "title": "TeleHammer: A Formal Model of Implicit Rowhammer", "comments": "We use a formal model to present a class of implicit rowhammer,\n  called TeleHammer, showing that it might have more than one instance.\n  PThammer in arXiv:2007.08707 was the first concrete example of implicit\n  rowhammer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rowhammer bug allows an attacker to gain privilege escalation or steal\nprivate data. A key requirement of all existing rowhammer attacks is that an\nattacker must have access to at least part of an exploitable hammer row. We\nrefer to such rowhammer attacks as PeriHammer. The state-of-the-art\nsoftware-only defenses against PeriHammer attacks is to make the exploitable\nhammer rows beyond the attacker's access permission. In this paper, we question\nthe necessity of the above requirement and propose a new class of rowhammer\nattacks, termed as TeleHammer. It is a paradigm shift in rowhammer attacks\nsince it crosses privilege boundary to stealthily rowhammer an inaccessible row\nby implicit DRAM accesses. Such accesses are achieved by abusing inherent\nfeatures of modern hardware and or software. We propose a generic model to\nrigorously formalize the necessary conditions to initiate TeleHammer and\nPeriHammer, respectively. Compared to PeriHammer, TeleHammer can defeat the\nadvanced software-only defenses, stealthy in hiding itself and hard to be\nmitigated. To demonstrate the practicality of TeleHammer and its advantages, we\nhave created a TeleHammer's instance, called PThammer, which leverages the\naddress-translation feature of modern processors. We observe that a memory\naccess from user space can induce a load of a Level-1 page-table entry (L1PTE)\nfrom memory and thus hammer the L1PTE once, although L1PTE is not accessible to\nus. To achieve a high enough hammering frequency, we flush relevant TLB and\ncache effectively and efficiently. To this end, we demonstrate PThammer on\nthree different test machines and show that it can cross user-kernel boundary\nand induce the first bit flips in L1PTEs within 15 minutes of double-sided\nPThammering. We have exploited PThammer to defeat advanced software-only\nrowhammer defenses in default system setting.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 11:56:42 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 05:21:55 GMT"}, {"version": "v3", "created": "Thu, 30 Jul 2020 13:56:56 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Zhang", "Zhi", ""], ["Cheng", "Yueqiang", ""], ["Liu", "Dongxi", ""], ["Nepal", "Surya", ""], ["Wang", "Zhi", ""]]}, {"id": "1912.03250", "submitter": "Rachel Cummings", "authors": "Uthaipon Tantipongpipat, Chris Waites, Digvijay Boob, Amaresh Ankit\n  Siva, Rachel Cummings", "title": "Differentially Private Synthetic Mixed-Type Data Generation For\n  Unsupervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the DP-auto-GAN framework for synthetic data generation, which\ncombines the low dimensional representation of autoencoders with the\nflexibility of Generative Adversarial Networks (GANs). This framework can be\nused to take in raw sensitive data and privately train a model for generating\nsynthetic data that will satisfy similar statistical properties as the original\ndata. This learned model can generate an arbitrary amount of synthetic data,\nwhich can then be freely shared due to the post-processing guarantee of\ndifferential privacy. Our framework is applicable to unlabeled mixed-type data,\nthat may include binary, categorical, and real-valued data. We implement this\nframework on both binary data (MIMIC-III) and mixed-type data (ADULT), and\ncompare its performance with existing private algorithms on metrics in\nunsupervised settings. We also introduce a new quantitative metric able to\ndetect diversity, or lack thereof, of synthetic data.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 17:46:07 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 00:46:37 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Tantipongpipat", "Uthaipon", ""], ["Waites", "Chris", ""], ["Boob", "Digvijay", ""], ["Siva", "Amaresh Ankit", ""], ["Cummings", "Rachel", ""]]}, {"id": "1912.03356", "submitter": "Khondokar Fida Hasan", "authors": "Khondokar Fida Hasan, Tarandeep Kaur, Md. Mhedi Hasan, Yanming Feng", "title": "Cognitive Internet of Vehicles: Motivation, Layered Architecture and\n  Security Issues", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, we have experienced great technological advancements\nin the information and communication field, which has significantly contributed\nto reshaping the Intelligent Transportation System (ITS) concept. Evolving from\nthe platform of a collection of sensors aiming to collect data, the data\nexchanged paradigm among vehicles is shifted from the local network to the\ncloud. With the introduction of cloud and edge computing along with ubiquitous\n5G mobile network, it is expected to see the role of Artificial Intelligence\n(AI) in data processing and smart decision imminent. So as to fully understand\nthe future automobile scenario in this verge of industrial revolution 4.0, it\nis necessary first of all to get a clear understanding of the cutting-edge\ntechnologies that going to take place in the automotive ecosystem so that the\ncyber-physical impact on transportation system can be measured. CIoV, which is\nabbreviated from Cognitive Internet of Vehicle, is one of the recently proposed\narchitectures of the technological evolution in transportation, and it has\namassed great attention. It introduces cloud-based artificial intelligence and\nmachine learning into transportation system. What are the future expectations\nof CIoV. To fully contemplate this architectures future potentials, and\nmilestones set to achieve, it is crucial to understand all the technologies\nthat leaned into it. Also, the security issues to meet the security\nrequirements of its practical implementation. Aiming to that, this paper\npresents the evolution of CIoV along with the layer abstractions to outline the\ndistinctive functional parts of the proposed architecture. It also gives an\ninvestigation of the prime security and privacy issues associated with\ntechnological evolution to take measures.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 05:38:25 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Hasan", "Khondokar Fida", ""], ["Kaur", "Tarandeep", ""], ["Hasan", "Md. Mhedi", ""], ["Feng", "Yanming", ""]]}, {"id": "1912.03388", "submitter": "Nuno Santos", "authors": "Jo\\~ao Santos, Nuno Santos, David Dias", "title": "DClaims: A Censorship Resistant Web Annotations System using IPFS and\n  Ethereum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of unreliable and biased information is a significant\nproblem on the Internet. To assess the credibility of the information retrieved\nfrom news websites and other sources, users often resort to social platforms\nlooking for confirmation with trustworthy parties. However, users may be faced\nwith considerable obstacles posed by the platform provider, who can prevent\naccess to certain content. This paper presents DClaims, a system that provides\na censorship-resistant distributed service for the exchange of information over\nthe Internet using web annotations. DClaims' fully decentralized architecture\nrelies on Inter-Planetary File System (IPFS) and Ethereum blockchain, both of\nwhich offer desirable censorship resistant properties. DClaims is implemented\nas a web annotations browser extension which allows for the classification of\nnews articles, on news websites. From our evaluation of the system, we conclude\nthat a large scale implementation of the system is practical and economically\nviable.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 23:28:49 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Santos", "Jo\u00e3o", ""], ["Santos", "Nuno", ""], ["Dias", "David", ""]]}, {"id": "1912.03485", "submitter": "Hema Venkata Krishna Giri Narra", "authors": "Krishna Giri Narra, Zhifeng Lin, Yongqin Wang, Keshav Balasubramaniam,\n  Murali Annavaram", "title": "Privacy-Preserving Inference in Machine Learning Services Using Trusted\n  Execution Environments", "comments": "13 pages, Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents Origami, which provides privacy-preserving inference for\nlarge deep neural network (DNN) models through a combination of enclave\nexecution, cryptographic blinding, interspersed with accelerator-based\ncomputation. Origami partitions the ML model into multiple partitions. The\nfirst partition receives the encrypted user input within an SGX enclave. The\nenclave decrypts the input and then applies cryptographic blinding to the input\ndata and the model parameters. Cryptographic blinding is a technique that adds\nnoise to obfuscate data. Origami sends the obfuscated data for computation to\nan untrusted GPU/CPU. The blinding and de-blinding factors are kept private by\nthe SGX enclave, thereby preventing any adversary from denoising the data, when\nthe computation is offloaded to a GPU/CPU. The computed output is returned to\nthe enclave, which decodes the computation on noisy data using the unblinding\nfactors privately stored within SGX. This process may be repeated for each DNN\nlayer, as has been done in prior work Slalom.\n  However, the overhead of blinding and unblinding the data is a limiting\nfactor to scalability. Origami relies on the empirical observation that the\nfeature maps after the first several layers can not be used, even by a powerful\nconditional GAN adversary to reconstruct input. Hence, Origami dynamically\nswitches to executing the rest of the DNN layers directly on an accelerator\nwithout needing any further cryptographic blinding intervention to preserve\nprivacy. We empirically demonstrate that using Origami, a conditional GAN\nadversary, even with an unlimited inference budget, cannot reconstruct the\ninput. We implement and demonstrate the performance gains of Origami using the\nVGG-16 and VGG-19 models. Compared to running the entire VGG-19 model within\nSGX, Origami inference improves the performance of private inference from 11x\nwhile using Slalom to 15.1x.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 10:27:33 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Narra", "Krishna Giri", ""], ["Lin", "Zhifeng", ""], ["Wang", "Yongqin", ""], ["Balasubramaniam", "Keshav", ""], ["Annavaram", "Murali", ""]]}, {"id": "1912.03498", "submitter": "Sujan Vijayaraj", "authors": "Sujan Vijayaraj, S. Balakrishnan, K. Senthilnathan", "title": "Quasi-deterministic secure quantum communication using non-maximally\n  entangled states", "comments": null, "journal-ref": "Int J Theor Phys, 60, 164 (2021)", "doi": "10.1007/s10773-020-04672-1", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Quantum communication in general helps deter potential eavesdropping in the\ncourse of transmission of bits to enable secure communication between two or\nmore parties. In this paper, we propose a novel quasi-deterministic secure\nquantum communication scheme using non-maximally entangled states. The proposed\nscheme follows a simple procedure, and cases where the entanglement required\ncan be significantly reduced to carry out the protocol successfully are\ndiscussed. Long sequences or the whole sequence of data can be sent after error\nchecking for a potential eavesdropper. The maximum qubit efficiency of the\nproposed protocol is found to be 33.333%.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 13:08:45 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 15:17:39 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2020 19:01:34 GMT"}, {"version": "v4", "created": "Fri, 5 Mar 2021 16:36:20 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Vijayaraj", "Sujan", ""], ["Balakrishnan", "S.", ""], ["Senthilnathan", "K.", ""]]}, {"id": "1912.03552", "submitter": "Constantinos Patsakis", "authors": "Constantinos Patsakis, Fran Casino, Nikolaos Lykousas, Vasilios Katos", "title": "Unravelling Ariadne's Thread: Exploring the Threats of Decentalised DNS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current landscape of the core Internet technologies shows considerable\ncentralisation with the big tech companies controlling the vast majority of\ntraffic and services. This has sparked a wide range of decentralisation\ninitiatives with perhaps the most profound and successful being the blockchain\ntechnology. In the past years, a core Internet infrastructure, domain name\nsystem (DNS), is being revised mainly due to its inherent security and privacy\nissues. One of the proposed panaceas is Blockchain-based DNS, which claims to\nsolve many issues of traditional DNS. However, this does not come without\nsecurity concerns and issues, as any introduction and adoption of a new\ntechnology does - let alone a disruptive one such as blockchain. In this work,\nwe discuss a number of associated threats, including emerging ones, and we\nvalidate many of them with real-world data. In this regard, we explore a part\nof the blockchain DNS ecosystem in terms of the browser extensions using such\ntechnologies, the chain itself (Namecoin and Emercoin), the domains, and users\nwhich have been registered in both platforms. Finally, we provide some\ncountermeasures to address the identified threats, and we propose a fertile\ncommon ground for further research.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 20:05:46 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Patsakis", "Constantinos", ""], ["Casino", "Fran", ""], ["Lykousas", "Nikolaos", ""], ["Katos", "Vasilios", ""]]}, {"id": "1912.03732", "submitter": "Behrooz Khadem", "authors": "Behrooz Khadem and Reza Ghasemi", "title": "Improved Algoritms in Parallel Evaluation of Large Cryptographic S-Box", "comments": "14 pages, 3 figures, 6 algorithms , 4 tables. International Journal\n  of Parallel, Emergent and Distributed Systems (2020)", "journal-ref": "International Journal of Parallel, Emergent and Distributed\n  Systems (2020)", "doi": "10.1080/17445760.2020.1760863", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays computational complexity of fast walsh hadamard transform and\nnonlinearity for Boolean functions and large substitution boxes is a major\nchallenge of modern cryptography research on strengthening encryption schemes\nagainst linear and differential attacks. Time and memory complexities of the\nbest existing algorithm for computing fast walsh hadamard transform and non\nlinearity for n x m substitution boxes (n >= 16;m >= 16) is O(2^(n+m)). This\npaper proposes three new acceleration methods that improve the computation time\nfor parallelized walsh matrix up to 39 folds and the computation time for non\nlinearity degree up to 563 folds, defining and accessing walsh matrix\ntranspose, and incorporating an important part of computation process of non\nlinearity in the computation algorithm of walsh matrix. The validity of the\nproposed algorithms is verified by means of simulation and experimentation and\nthe overall analysis of resource consumption of proposed algorithms was\ncompared with previous ones.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 18:09:35 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Khadem", "Behrooz", ""], ["Ghasemi", "Reza", ""]]}, {"id": "1912.03735", "submitter": "Shahbaz Rezaei", "authors": "Shahbaz Rezaei and Xin Liu", "title": "Security of Deep Learning Methodologies: Challenges and Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the plethora of studies about security vulnerabilities and defenses\nof deep learning models, security aspects of deep learning methodologies, such\nas transfer learning, have been rarely studied. In this article, we highlight\nthe security challenges and research opportunities of these methodologies,\nfocusing on vulnerabilities and attacks unique to them.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 18:23:23 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Rezaei", "Shahbaz", ""], ["Liu", "Xin", ""]]}, {"id": "1912.03790", "submitter": "Giovanni Apruzzese", "authors": "Giovanni Apruzzese, Mauro Andreolini, Michele Colajanni, Mirco\n  Marchetti", "title": "Hardening Random Forest Cyber Detectors Against Adversarial Attacks", "comments": null, "journal-ref": null, "doi": "10.1109/TETCI.2019.2961157", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms are effective in several applications, but they\nare not as much successful when applied to intrusion detection in cyber\nsecurity. Due to the high sensitivity to their training data, cyber detectors\nbased on machine learning are vulnerable to targeted adversarial attacks that\ninvolve the perturbation of initial samples. Existing defenses assume\nunrealistic scenarios; their results are underwhelming in non-adversarial\nsettings; or they can be applied only to machine learning algorithms that\nperform poorly for cyber security. We present an original methodology for\ncountering adversarial perturbations targeting intrusion detection systems\nbased on random forests. As a practical application, we integrate the proposed\ndefense method in a cyber detector analyzing network traffic. The experimental\nresults on millions of labelled network flows show that the new detector has a\ntwofold value: it outperforms state-of-the-art detectors that are subject to\nadversarial attacks; it exhibits robust results both in adversarial and\nnon-adversarial scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 00:02:19 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Apruzzese", "Giovanni", ""], ["Andreolini", "Mauro", ""], ["Colajanni", "Michele", ""], ["Marchetti", "Mirco", ""]]}, {"id": "1912.03817", "submitter": "Varun Chandrasekaran", "authors": "Lucas Bourtoule, Varun Chandrasekaran, Christopher A. Choquette-Choo,\n  Hengrui Jia, Adelin Travers, Baiwu Zhang, David Lie and Nicolas Papernot", "title": "Machine Unlearning", "comments": "Published in IEEE S&P 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Once users have shared their data online, it is generally difficult for them\nto revoke access and ask for the data to be deleted. Machine learning (ML)\nexacerbates this problem because any model trained with said data may have\nmemorized it, putting users at risk of a successful privacy attack exposing\ntheir information. Yet, having models unlearn is notoriously difficult. We\nintroduce SISA training, a framework that expedites the unlearning process by\nstrategically limiting the influence of a data point in the training procedure.\nWhile our framework is applicable to any learning algorithm, it is designed to\nachieve the largest improvements for stateful algorithms like stochastic\ngradient descent for deep neural networks. SISA training reduces the\ncomputational overhead associated with unlearning, even in the worst-case\nsetting where unlearning requests are made uniformly across the training set.\nIn some cases, the service provider may have a prior on the distribution of\nunlearning requests that will be issued by users. We may take this prior into\naccount to partition and order data accordingly, and further decrease overhead\nfrom unlearning. Our evaluation spans several datasets from different domains,\nwith corresponding motivations for unlearning. Under no distributional\nassumptions, for simple learning tasks, we observe that SISA training improves\ntime to unlearn points from the Purchase dataset by 4.63x, and 2.45x for the\nSVHN dataset, over retraining from scratch. SISA training also provides a\nspeed-up of 1.36x in retraining for complex learning tasks such as ImageNet\nclassification; aided by transfer learning, this results in a small degradation\nin accuracy. Our work contributes to practical data governance in machine\nunlearning.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 02:16:53 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 20:09:45 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 05:39:28 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Bourtoule", "Lucas", ""], ["Chandrasekaran", "Varun", ""], ["Choquette-Choo", "Christopher A.", ""], ["Jia", "Hengrui", ""], ["Travers", "Adelin", ""], ["Zhang", "Baiwu", ""], ["Lie", "David", ""], ["Papernot", "Nicolas", ""]]}, {"id": "1912.03829", "submitter": "Run Wang", "authors": "Run Wang, Felix Juefei-Xu, Qing Guo, Yihao Huang, Xiaofei Xie, Lei Ma,\n  Yang Liu", "title": "Amora: Black-box Adversarial Morphing Attack", "comments": "Accepted by ACM MM'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, digital facial content manipulation has become ubiquitous and\nrealistic with the success of generative adversarial networks (GANs), making\nface recognition (FR) systems suffer from unprecedented security concerns. In\nthis paper, we investigate and introduce a new type of adversarial attack to\nevade FR systems by manipulating facial content, called\n\\textbf{\\underline{a}dversarial \\underline{mor}phing \\underline{a}ttack}\n(a.k.a. Amora). In contrast to adversarial noise attack that perturbs pixel\nintensity values by adding human-imperceptible noise, our proposed adversarial\nmorphing attack works at the semantic level that perturbs pixels spatially in a\ncoherent manner. To tackle the black-box attack problem, we devise a simple yet\neffective joint dictionary learning pipeline to obtain a proprietary optical\nflow field for each attack. Our extensive evaluation on two popular FR systems\ndemonstrates the effectiveness of our adversarial morphing attack at various\nlevels of morphing intensity with smiling facial expression manipulations. Both\nopen-set and closed-set experimental results indicate that a novel black-box\nadversarial attack based on local deformation is possible, and is vastly\ndifferent from additive noise attacks. The findings of this work potentially\npave a new research direction towards a more thorough understanding and\ninvestigation of image-based adversarial attacks and defenses.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 03:23:36 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 05:26:41 GMT"}, {"version": "v3", "created": "Thu, 28 May 2020 06:57:08 GMT"}, {"version": "v4", "created": "Mon, 1 Jun 2020 03:58:29 GMT"}, {"version": "v5", "created": "Sat, 15 Aug 2020 13:29:53 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wang", "Run", ""], ["Juefei-Xu", "Felix", ""], ["Guo", "Qing", ""], ["Huang", "Yihao", ""], ["Xie", "Xiaofei", ""], ["Ma", "Lei", ""], ["Liu", "Yang", ""]]}, {"id": "1912.03848", "submitter": "Behnam Kiani Kalejahi", "authors": "Behnam Kiani Kalejahi, Saeed Meshgini, Ayshan Yariyeva, Dawda Ndure,\n  Uzeyir Maharramov, Ali Farzamnia", "title": "Big Data Security Issues and Challenges in Healthcare", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper embodies the usage of Big Data in Healthcare. It is important to\nnote that big data in terms of Architecture and implementation might be or has\nalready or will continue to assist the continuous growth in the field of\nhealthcare. The main important aspects of this study are the general importance\nof big data in healthcare, the positives big data will help tackle and enhance\nin this field and not to also forget to mention the tremendous downside big\ndata has on healthcare that is still needed to improve or putting extensive\nresearch on. We believe there is still a long way in which institutions and\nindividuals understand the hidden truth about big data. We have highlighted the\nvarious ways one could be confidently relied on big data and on the other hand\nhighlighted the weighted importance of big problem big data and expected\nsolutions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 04:51:53 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Kalejahi", "Behnam Kiani", ""], ["Meshgini", "Saeed", ""], ["Yariyeva", "Ayshan", ""], ["Ndure", "Dawda", ""], ["Maharramov", "Uzeyir", ""], ["Farzamnia", "Ali", ""]]}, {"id": "1912.03959", "submitter": "Eli (Omid) David", "authors": "Itay Mosafi, Eli David, Nathan S. Netanyahu", "title": "Stealing Knowledge from Protected Deep Neural Networks Using Composite\n  Unlabeled Data", "comments": null, "journal-ref": "International Joint Conference on Neural Networks (IJCNN), pages\n  1-8, Budapest, Hungary, July 2019", "doi": "10.1109/IJCNN.2019.8851798", "report-no": null, "categories": "cs.LG cs.CR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As state-of-the-art deep neural networks are deployed at the core of more\nadvanced Al-based products and services, the incentive for copying them (i.e.,\ntheir intellectual properties) by rival adversaries is expected to increase\nconsiderably over time. The best way to extract or steal knowledge from such\nnetworks is by querying them using a large dataset of random samples and\nrecording their output, followed by training a student network to mimic these\noutputs, without making any assumption about the original networks. The most\neffective way to protect against such a mimicking attack is to provide only the\nclassification result, without confidence values associated with the softmax\nlayer.In this paper, we present a novel method for generating composite images\nfor attacking a mentor neural network using a student model. Our method assumes\nno information regarding the mentor's training dataset, architecture, or\nweights. Further assuming no information regarding the mentor's softmax output\nvalues, our method successfully mimics the given neural network and steals all\nof its knowledge. We also demonstrate that our student network (which copies\nthe mentor) is impervious to watermarking protection methods, and thus would\nnot be detected as a stolen model.Our results imply, essentially, that all\ncurrent neural networks are vulnerable to mimicking attacks, even if they do\nnot divulge anything but the most basic required output, and that the student\nmodel which mimics them cannot be easily detected and singled out as a stolen\ncopy using currently available techniques.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 10:57:51 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Mosafi", "Itay", ""], ["David", "Eli", ""], ["Netanyahu", "Nathan S.", ""]]}, {"id": "1912.04042", "submitter": "John Duchi", "authors": "Hilal Asi and John Duchi and Omid Javidbakht", "title": "Element Level Differential Privacy: The Right Granularity of Privacy", "comments": "34 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential Privacy (DP) provides strong guarantees on the risk of\ncompromising a user's data in statistical learning applications, though these\nstrong protections make learning challenging and may be too stringent for some\nuse cases. To address this, we propose element level differential privacy,\nwhich extends differential privacy to provide protection against leaking\ninformation about any particular \"element\" a user has, allowing better utility\nand more robust results than classical DP. By carefully choosing these\n\"elements,\" it is possible to provide privacy protections at a desired\ngranularity. We provide definitions, associated privacy guarantees, and\nanalysis to identify the tradeoffs with the new definition; we also develop\nseveral private estimation and learning methodologies, providing careful\nexamples for item frequency and M-estimation (empirical risk minimization) with\nconcomitant privacy and utility analysis. We complement our theoretical and\nmethodological advances with several real-world applications, estimating\nhistograms and fitting several large-scale prediction models, including deep\nnetworks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 23:05:54 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Asi", "Hilal", ""], ["Duchi", "John", ""], ["Javidbakht", "Omid", ""]]}, {"id": "1912.04065", "submitter": "Thuat Do", "authors": "Thuat Do, Thao Nguyen, Hung Pham", "title": "Delegated Proof of Reputation: a novel Blockchain consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consensus mechanism is the heart of any blockchain network. Many projects\nhave proposed alternative protocols to improve restricted scalability of Proof\nof Work originated since Bitcoin. As an improvement of Delegated Proof of\nStake, in this paper, we introduce a novel consensus, namely, Delegated Proof\nof Reputation, which is scalable, secure with an acceptable decentralization.\nOur innovative idea is replacing pure coinstaking by a reputation ranking\nsystem essentially based on ranking theories (PageRank, NCDawareRank and\nHodgeRank).\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 09:30:18 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Do", "Thuat", ""], ["Nguyen", "Thao", ""], ["Pham", "Hung", ""]]}, {"id": "1912.04109", "submitter": "Yangjun Xu", "authors": "Liang Chen and Yangjun Xu and Fenfang Xie and Min Huang and Zibin\n  Zheng", "title": "Data Poisoning Attacks on Neighborhood-based Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, collaborative filtering recommender systems have been widely\ndeployed in many commercial companies to make profit. Neighbourhood-based\ncollaborative filtering is common and effective. To date, despite its\neffectiveness, there has been little effort to explore their robustness and the\nimpact of data poisoning attacks on their performance. Can the\nneighbourhood-based recommender systems be easily fooled? To this end, we shed\nlight on the robustness of neighbourhood-based recommender systems and propose\na novel data poisoning attack framework encoding the purpose of attack and\nconstraint against them. We firstly illustrate how to calculate the optimal\ndata poisoning attack, namely UNAttack. We inject a few well-designed fake\nusers into the recommender systems such that target items will be recommended\nto as many normal users as possible. Extensive experiments are conducted on\nthree real-world datasets to validate the effectiveness and the transferability\nof our proposed method. Besides, some interesting phenomenons can be found. For\nexample, 1) neighbourhood-based recommender systems with Euclidean\nDistance-based similarity have strong robustness. 2) the fake users can be\ntransferred to attack the state-of-the-art collaborative filtering recommender\nsystems such as Neural Collaborative Filtering and Bayesian Personalized\nRanking Matrix Factorization.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 15:34:58 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Chen", "Liang", ""], ["Xu", "Yangjun", ""], ["Xie", "Fenfang", ""], ["Huang", "Min", ""], ["Zheng", "Zibin", ""]]}, {"id": "1912.04143", "submitter": "Ansgar Kellner", "authors": "Ansgar Kellner, Lisa Rangosch, Christian Wressnegger, and Konrad Rieck", "title": "Political Elections Under (Social) Fire? Analysis and Detection of\n  Propaganda on Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many, social networks have become the primary source of news, although\nthe correctness of the provided information and its trustworthiness are often\nunclear. The investigations of the 2016 US presidential elections have brought\nthe existence of external campaigns to light aiming at affecting the general\npolitical public opinion. In this paper, we investigate whether a similar\ninfluence on political elections can be observed in Europe as well. To this\nend, we use the past German federal election as an indicator and inspect the\npropaganda on Twitter, based on data from a period of 268 days. We find that 79\ntrolls from the US campaign have also acted upon the German federal election\nspreading right-wing views. Moreover, we develop a detector for finding\nautomated behavior that enables us to identify 2,414 previously unknown bots.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 16:02:50 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Kellner", "Ansgar", ""], ["Rangosch", "Lisa", ""], ["Wressnegger", "Christian", ""], ["Rieck", "Konrad", ""]]}, {"id": "1912.04145", "submitter": "Hans Liljestrand", "authors": "R\\'emi Denis-Courmont, Hans Liljestrand, Carlos Chinea, Jan-Erik\n  Ekberg", "title": "Camouflage: Hardware-assisted CFI for the ARM Linux kernel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software control flow integrity (CFI) solutions have been applied to the\nLinux kernel for memory protection. Due to performance costs, deployed software\nCFI solutions are coarse grained. In this work, we demonstrate a precise\nhardware-assisted kernel CFI running on widely-used off-the-shelf processors.\nSpecifically, we use the ARMv8.3 pointer authentication (PAuth) extension and\npresent a design that uses it to achieve strong security guarantees with\nminimal performance penalties. Furthermore, we show how deployment of such\nsecurity primitives in the kernel can significantly differ from their user\nspace application.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 16:03:52 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Denis-Courmont", "R\u00e9mi", ""], ["Liljestrand", "Hans", ""], ["Chinea", "Carlos", ""], ["Ekberg", "Jan-Erik", ""]]}, {"id": "1912.04222", "submitter": "Christina Ilvento", "authors": "Christina Ilvento", "title": "Implementing the Exponential Mechanism with Base-2 Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite excellent theoretical support, Differential Privacy (DP) can still be\na challenge to implement in practice. In part, this challenge is due to the\nconcerns associated with translating arbitrary- or infinite-precision\ntheoretical mechanisms to the reality of floating point or fixed-precision.\nBeginning with the troubling result of Mironov demonstrating the security\nissues of using floating point for implementing the Laplace mechanism, there\nhave been many reasonable questions raised concerning the vulnerabilities of\nreal-world implementations of DP.\n  In this work, we examine the practicalities of implementing the exponential\nmechanism of McSherry and Talwar. We demonstrate that naive or malicious\nimplementations can result in catastrophic privacy failures. To address these\nproblems, we show that the mechanism can be implemented exactly for a rich set\nof values of the privacy parameter $\\varepsilon$ and utility functions with\nlimited practical overhead in running time and minimal code complexity.\n  How do we achieve this result? We employ a simple trick of switching from\nbase $e$ to base $2$, allowing us to perform precise base $2$ arithmetic. A\nshort, precise expression is always available for $\\varepsilon$, and the only\napproximation error we incur is the conversion of the base-2 privacy parameter\nback to base $e$ for reporting purposes. The core base $2$ arithmetic of the\nmechanism can be simply and efficiently implemented using open-source high\nprecision arithmetic libraries. Furthermore, the exact nature of the\nimplementation lends itself to simple monitoring of correctness and proofs of\nprivacy.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 17:58:13 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 17:42:38 GMT"}, {"version": "v3", "created": "Thu, 6 Aug 2020 18:12:36 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Ilvento", "Christina", ""]]}, {"id": "1912.04231", "submitter": "Harshal Tupsamudre", "authors": "Harshal Tupsamudre, Sukanya Vaddepalli, Vijayanand Banahatti, Sachin\n  Lodha", "title": "Extended- Force vs Nudge : Comparing Users' Pattern Choices on SysPal\n  and TinPal", "comments": "Our paper is an extended version of ACM CCS 2019 poster by the same\n  name. The paper is 32 pages long in ACM reference format. The paper has not\n  been submitted to any journal or conference for the peer review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Android's 3X3 graphical pattern lock scheme is one of the widely used\nauthentication method on smartphone devices. However, users choose 3X3 patterns\nfrom a small subspace of all possible 389,112 patterns. The two recently\nproposed interfaces, SysPal by Cho et al. and TinPal by the authors,\ndemonstrate that it is possible to influence users 3X3 pattern choices by\nmaking small modifications in the existing interface. While SysPal forces users\nto include one, two or three system-assigned random dots in their pattern,\nTinPal employs a highlighting mechanism to inform users about the set of\nreachable dots from the current selected dot. Both interfaces improved the\nsecurity of 3X3 patterns without affecting usability, but no comparison between\nSysPal and TinPal was presented.\n  To address this gap, we conduct a new user study with 147 participants and\ncollect patterns on three SysPal interfaces, 1-dot, 2-dot and 3-dot. We also\nconsider original and TinPal patterns collected in our previous user study\ninvolving 99 participants. We compare patterns created on five different\ninterfaces, original, TinPal, 1-dot, 2-dot and 3-dot using a range of security\nand usability metrics including pattern length, stroke length, guessability,\nrecall time and login attempts. Our study results show that participants in the\nTinPal group created significantly longer and complex patterns than\nparticipants in the other four groups. Consequently, the guessing resistance of\nTinPal patterns was the highest among all groups. Further, we did not find any\nsignificant difference in memorability of patterns created in the TinPal group\nand the other groups.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 18:18:46 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 04:34:33 GMT"}, {"version": "v3", "created": "Fri, 27 Dec 2019 04:17:38 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Tupsamudre", "Harshal", ""], ["Vaddepalli", "Sukanya", ""], ["Banahatti", "Vijayanand", ""], ["Lodha", "Sachin", ""]]}, {"id": "1912.04439", "submitter": "Joonas J\\\"alk\\\"o", "authors": "Joonas J\\\"alk\\\"o, Eemil Lagerspetz, Jari Haukka, Sasu Tarkoma, Antti\n  Honkela, Samuel Kaski", "title": "Privacy-preserving data sharing via probabilistic modelling", "comments": null, "journal-ref": null, "doi": "10.1016/j.patter.2021.100271", "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Differential privacy allows quantifying privacy loss resulting from accessing\nsensitive personal data. Repeated accesses to underlying data incur increasing\nloss. Releasing data as privacy-preserving synthetic data would avoid this\nlimitation, but would leave open the problem of designing what kind of\nsynthetic data. We propose formulating the problem of private data release\nthrough probabilistic modelling. This approach transforms the problem of\ndesigning the synthetic data into choosing a model for the data, allowing also\nincluding prior knowledge, which improves the quality of the synthetic data. We\ndemonstrate empirically, in an epidemiological study, that statistical\ndiscoveries can be reliably reproduced from the synthetic data. We expect the\nmethod to have broad use in creating high-quality anonymized data twins of key\ndata sets for research.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 01:21:32 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 10:09:43 GMT"}, {"version": "v3", "created": "Fri, 2 Oct 2020 07:39:45 GMT"}, {"version": "v4", "created": "Mon, 1 Mar 2021 09:26:54 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["J\u00e4lk\u00f6", "Joonas", ""], ["Lagerspetz", "Eemil", ""], ["Haukka", "Jari", ""], ["Tarkoma", "Sasu", ""], ["Honkela", "Antti", ""], ["Kaski", "Samuel", ""]]}, {"id": "1912.04466", "submitter": "Jiaming Ye", "authors": "Yinxing Xue (1), Jiaming Ye (1), Mingliang Ma (1), Lei Ma (2), Yi Li\n  (3), Haijun Wang (3), Yun Lin (4), Tianyong Peng (1), Yang Liu (3) ((1)\n  University of Science and Technology of China, (2) Kyushu University, (3)\n  Nanyang Technological University, (4) National University of Singapore)", "title": "Doublade: Unknown Vulnerability Detection in Smart Contracts Via\n  Abstract Signature Matching and Refined Detection Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the prosperity of smart contracts and the blockchain technology, various\nsecurity analyzers have been proposed from both the academia and industry to\naddress the associated risks. Yet, there does not exist a high-quality\nbenchmark of smart contract vulnerability for security research. In this study,\nwe propose an approach towards building a high-quality vulnerability benchmark.\nOur approach consists of two parts. First, to improve recall, we propose to\nsearch for similar vulnerabilities in an automated way by leveraging the\nabstract vulnerability signature (AVS). Second, to remove the false positives\n(FPs) due to AVS-based matching, we summarize the detection rules of existing\ntools and apply the refined rules by considering various defense mechanisms\n(DMs). By integrating AVS-based code matching and the refined detection rules\n(RDR), our approach achieves higher precision and recall. On the collected\n76,354 contracts, we build a benchmark consisting of 1,219 vulnerabilities\ncovering five different vulnerability types identified together by our tool\n(DOUBLADE) and other three scanners. Additionally, we conduct a comparison\nbetween DOUBLADE and the others, on an additional 17,770 contracts. Results\nshow that DOUBLADE can yield a better detection accuracy with similar execution\ntime.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 03:09:57 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Xue", "Yinxing", ""], ["Ye", "Jiaming", ""], ["Ma", "Mingliang", ""], ["Ma", "Lei", ""], ["Li", "Yi", ""], ["Wang", "Haijun", ""], ["Lin", "Yun", ""], ["Peng", "Tianyong", ""], ["Liu", "Yang", ""]]}, {"id": "1912.04497", "submitter": "Kirthi Shankar Sivamani", "authors": "Kirthi Shankar Sivamani", "title": "Feature Losses for Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has made tremendous advances in computer vision tasks such as\nimage classification. However, recent studies have shown that deep learning\nmodels are vulnerable to specifically crafted adversarial inputs that are\nquasi-imperceptible to humans. In this work, we propose a novel approach to\ndefending adversarial attacks. We employ an input processing technique based on\ndenoising autoencoders as a defense. It has been shown that the input\nperturbations grow and accumulate as noise in feature maps while propagating\nthrough a convolutional neural network (CNN). We exploit the noisy feature maps\nby using an additional subnetwork to extract image feature maps and train an\nauto-encoder on perceptual losses of these feature maps. This technique\nachieves close to state-of-the-art results on defending MNIST and CIFAR10\ndatasets, but more importantly, shows a new way of employing a defense that\ncannot be trivially trained end-to-end by the attacker. Empirical results\ndemonstrate the effectiveness of this approach on the MNIST and CIFAR10\ndatasets on simple as well as iterative LP attacks. Our method can be applied\nas a preprocessing technique to any off the shelf CNN.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 04:58:45 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Sivamani", "Kirthi Shankar", ""]]}, {"id": "1912.04519", "submitter": "Arip Solehudin", "authors": "April Lia Hananto, Arip Solehudin, Agung Susilo Yuda Irawan, Bayu\n  Priyatna", "title": "Analyzing the Kasiski Method Against Vigenere Cipher", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The weakness of the vigenere cipher lies in its short key and is repeated, so\nthere is a key loop in encrypting messages, this is used by cryptanalysts using\nthe Kasiski method to know the key length so it can solve this algorithm. The\nKasiski method uses repetitive cryptograms found in the ciphertext to determine\nthe key length. Modification of the vigenere cipher solves strengthen the\ncipher by using arranged keys to make it difficult to crack the keys against\nthe Kasiski method attacks. This study analyzes the strength of the vigenere\ncipher ciphertext and the modification of the vigenere cipher from the\nencryption results composed of plaintexts that use different keys. Against the\nKasiski method attack. The method used in this study is a quantitative method\nwith a descriptive approach through nonparametric statistical tests on the sign\ntest. The results showed a difference in the ciphertext's strength from the\nencryption process even though using the same key. The kaiseki method if can\nknow not all key lengths the ciphertext in the compilation does not occur\nrepetitive cryptograms. Modification of the vigenere cipher has a positive\neffect on the strength of the cipher and can influence the strength of the\nciphertext that is built against the Kasiski method attacks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 06:06:49 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Hananto", "April Lia", ""], ["Solehudin", "Arip", ""], ["Irawan", "Agung Susilo Yuda", ""], ["Priyatna", "Bayu", ""]]}, {"id": "1912.04613", "submitter": "Wei Wang Dr.", "authors": "Yong Huang, Wei Wang, Yiyuan Wang, Tao Jiang and Qian Zhang", "title": "Lightweight Sybil-Resilient Multi-Robot Networks by Multipath\n  Manipulation", "comments": "To appear at IEEE INFOCOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless networking opens up many opportunities to facilitate miniaturized\nrobots in collaborative tasks, while the openness of wireless medium exposes\nrobots to the threats of Sybil attackers, who can break the fundamental trust\nassumption in robotic collaboration by forging a large number of fictitious\nrobots. Recent advances advocate the adoption of bulky multi-antenna systems to\npassively obtain fine-grained physical layer signatures, rendering them\nunaffordable to miniaturized robots. To overcome this conundrum, this paper\npresents ScatterID, a lightweight system that attaches featherlight and\nbatteryless backscatter tags to single-antenna robots to defend against Sybil\nattacks. Instead of passively \"observing\" signatures, ScatterID actively\n\"manipulates\" multipath propagation by using backscatter tags to intentionally\ncreate rich multipath features obtainable to a single-antenna robot. These\nfeatures are used to construct a distinct profile to detect the real signal\nsource, even when the attacker is mobile and power-scaling. We implement\nScatterID on the iRobot Create platform and evaluate it in typical indoor and\noutdoor environments. The experimental results show that our system achieves a\nhigh AUROC of 0.988 and an overall accuracy of 96.4% for identity verification.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 10:13:57 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 01:26:16 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Huang", "Yong", ""], ["Wang", "Wei", ""], ["Wang", "Yiyuan", ""], ["Jiang", "Tao", ""], ["Zhang", "Qian", ""]]}, {"id": "1912.04669", "submitter": "Siddharth Prakash Rao", "authors": "Thanh Bui, Siddharth Prakash Rao, Markku Antikainen, Tuomas Aura", "title": "Client-side Vulnerabilities in Commercial VPNs", "comments": "A refined version of this draft, with the same title, has been\n  published in the 24th Nordic Conference on Secure IT Systems (NordSec 19). It\n  is accessible here:\n  https://link.springer.com/chapter/10.1007/978-3-030-35055-0_7", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Internet users increasingly rely on commercial virtual private network (VPN)\nservices to protect their security and privacy. The VPN services route the\nclient's traffic over an encrypted tunnel to a VPN gateway in the cloud. Thus,\nthey hide the client's real IP address from online services, and they also\nshield the user's connections from perceived threats in the access networks. In\nthis paper, we study the security of such commercial VPN services. The focus is\non how the client applications set up VPN tunnels, and how the service\nproviders instruct users to configure generic client software. We analyze\ncommon VPN protocols and implementations on Windows, macOS and Ubuntu. We find\nthat the VPN clients have various configuration flaws, which an attacker can\nexploit to strip off traffic encryption or to bypass authentication of the VPN\ngateway. In some cases, the attacker can also steal the VPN user's username and\npassword. We suggest ways to mitigate each of the discovered vulnerabilities.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 12:50:57 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Bui", "Thanh", ""], ["Rao", "Siddharth Prakash", ""], ["Antikainen", "Markku", ""], ["Aura", "Tuomas", ""]]}, {"id": "1912.04726", "submitter": "Jianming Huang", "authors": "Jianming Huang and Yu Hua", "title": "A Write-Friendly and Fast-Recovery Scheme for Security Metadata in NVM", "comments": "12 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-Volatile Memories (NVMs) have attracted the attentions of academia and\nindustry, which is expected to become the next-generation memory. However, due\nto the nonvolatile property, NVMs become vulnerable to attacks and require\nsecurity mechanisms, e.g., counter mode encryption and integrity tree, which\nintroduce the security metadata. NVMs promise to recover these security\nmetadata after a system crash, including the counter and integrity tree.\nHowever, unlike merkle tree reconstructed from user data, recovering SGX\nintegrity tree (SIT) has to address the challenges from unique top-down\nhierarchical dependency. Moreover, writing overhead and recovery time are\nimportant metrics for evaluating persistent memory system due to the high costs\nof NVM writes and IT downtime. How to recover the security metadata, i.e.,\ncounter blocks and integrity tree nodes, with low write overhead and short\nrecovery time, becomes much important.\n  To provide a fast recovery scheme with low write overhead, we propose STAR, a\ncost-efficient scheme for recovering counter blocks and SGX integrity tree\nnodes after crashes. For fast recovery and verification, STAR synergizes the\nMAC and correct data, uses bitmap lines in ADR to indicate the location of\nstale node and constructs a cached merkle tree to verify the correctness of the\nrecovery process. Moreover, STAR uses a multi-layer index to speed up the\nrecovery process. STAR also allows different configurations to meet adaptive\nrequirements for write overhead and recovery time. Our evaluation results show\nthat the proposed STAR reduces the number of memory writes by up to 87\\%\ncompared with state-of-the-art work, Anubis, which needs extra 1x memory\nwrites. For a 4MB security metadata cache, STAR needs 0.039s/0.023s/0.004s in\nthree different configurations to recover the metadata cache while Anubis needs\n0.020s.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 14:50:33 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Huang", "Jianming", ""], ["Hua", "Yu", ""]]}, {"id": "1912.04735", "submitter": "Xuhang Ying", "authors": "Xuhang Ying, Giuseppe Bernieri, Mauro Conti, Linda Bushnell, Radha\n  Poovendran", "title": "Covert Channel-Based Transmitter Authentication in Controller Area\n  Networks", "comments": "Submitted to TDSC (Transactions on Dependable and Secure Computing).\n  arXiv admin note: text overlap with arXiv:1903.05231", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the security of automotive Cyber-Physical Systems (CPSs) is\nfacing urgent threats due to the widespread use of legacy in-vehicle\ncommunication systems. As a representative legacy bus system, the Controller\nArea Network (CAN) hosts Electronic Control Units (ECUs) that are crucial\nvehicle functioning. In this scenario, malicious actors can exploit CAN\nvulnerabilities, such as the lack of built-in authentication and encryption\nschemes, to launch CAN bus attacks with life-threatening consequences (e.g.,\ndisabling brakes). In this paper, we present TACAN (Transmitter Authentication\nin CAN), which provides secure authentication of ECUs on the legacy CAN bus by\nexploiting the covert channels, without introducing CAN protocol modifications\nor traffic overheads. TACAN turns upside-down the originally malicious concept\nof covert channels and exploits it to build an effective defensive technique\nthat facilitates transmitter authentication via a centralized, trusted Monitor\nNode. TACAN consists of three different covert channels for ECU authentication:\n1) the Inter-Arrival Time (IAT)-based; 2) the Least Significant Bit\n(LSB)-based; and 3) a hybrid covert channel, exploiting the combination of the\nfirst two. In order to validate TACAN, we implement the covert channels on the\nUniversity of Washington (UW) EcoCAR (Chevrolet Camaro 2016) testbed. We\nfurther evaluate the bit error, throughput, and detection performance of TACAN\nthrough extensive experiments using the EcoCAR testbed and a publicly available\ndataset collected from Toyota Camry 2010. We demonstrate the feasibility of\nTACAN and the effectiveness of detecting CAN bus attacks, highlighting no\ntraffic overheads and attesting the regular functionality of ECUs.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 00:52:45 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Ying", "Xuhang", ""], ["Bernieri", "Giuseppe", ""], ["Conti", "Mauro", ""], ["Bushnell", "Linda", ""], ["Poovendran", "Radha", ""]]}, {"id": "1912.04746", "submitter": "Warit Sirichotedumrong", "authors": "Warit Sirichotedumrong, Yuma Kinoshita, Hitoshi Kiya", "title": "On the Security of Pixel-Based Image Encryption for Privacy-Preserving\n  Deep Neural Networks", "comments": "Accepted in 2019 IEEE 8th Global Conference on Consumer Electronics\n  (GCCE 2019). arXiv admin note: substantial text overlap with arXiv:1905.01827", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to evaluate the safety of a pixel-based image encryption\nmethod, which has been proposed to apply images with no visual information to\ndeep neural networks (DNN), in terms of robustness against ciphertext-only\nattacks (COA). In addition, we propose a novel DNN-based COA that aims to\nreconstruct the visual information of encrypted images. The effectiveness of\nthe proposed attack is evaluated under two encryption key conditions: same\nencryption key, and different encryption keys. The results show that the\nproposed attack can recover the visual information of the encrypted images if\nimages are encrypted under same encryption key. Otherwise, the pixel-based\nimage encryption method has robustness against COA.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 07:30:03 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Sirichotedumrong", "Warit", ""], ["Kinoshita", "Yuma", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "1912.04769", "submitter": "Omri Shmueli", "authors": "Nir Bitansky, Omri Shmueli", "title": "Post-quantum Zero Knowledge in Constant Rounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a constant-round zero-knowledge classical argument for NP secure\nagainst quantum attacks. We assume the existence of Quantum Fully-Homomorphic\nEncryption and other standard primitives, known based on the Learning with\nErrors Assumption for quantum algorithms. As a corollary, we also obtain a\nconstant-round zero-knowledge quantum argument for QMA.\n  At the heart of our protocol is a new no-cloning non-black-box simulation\ntechnique.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 15:32:58 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 21:48:19 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Bitansky", "Nir", ""], ["Shmueli", "Omri", ""]]}, {"id": "1912.04836", "submitter": "Chris Xiaoxuan Lu", "authors": "Chris Xiaoxuan Lu, Bowen Du, Hongkai Wen, Sen Wang, Andrew Markham,\n  Ivan Martinovic, Yiran Shen and Niki Trigoni", "title": "Snoopy: Sniffing Your Smartwatch Passwords via Deep Sequence Learning", "comments": "27 pages. Originally published at ACM UbiComp 2018. This version\n  corrects some errors in the original version and add the pointer to released\n  code & dataset", "journal-ref": null, "doi": "10.1145/3161196", "report-no": null, "categories": "cs.HC cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Demand for smartwatches has taken off in recent years with new models which\ncan run independently from smartphones and provide more useful features,\nbecoming first-class mobile platforms. One can access online banking or even\nmake payments on a smartwatch without a paired phone. This makes smartwatches\nmore attractive and vulnerable to malicious attacks, which to date have been\nlargely overlooked. In this paper, we demonstrate Snoopy, a password extraction\nand inference system which is able to accurately infer passwords entered on\nAndroid/Apple watches within 20 attempts, just by eavesdropping on motion\nsensors. Snoopy uses a uniform framework to extract the segments of motion data\nwhen passwords are entered, and uses novel deep neural networks to infer the\nactual passwords. We evaluate the proposed Snoopy system in the real-world with\ndata from 362 participants and show that our system offers a 3-fold improvement\nin the accuracy of inferring passwords compared to the state-of-the-art,\nwithout consuming excessive energy or computational resources. We also show\nthat Snoopy is very resilient to user and device heterogeneity: it can be\ntrained on crowd-sourced motion data (e.g. via Amazon Mechanical Turk), and\nthen used to attack passwords from a new user, even if they are wearing a\ndifferent model. This paper shows that, in the wrong hands, Snoopy can\npotentially cause serious leaks of sensitive information. By raising awareness,\nwe invite the community and manufacturers to revisit the risks of continuous\nmotion sensing on smart wearable devices.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 17:25:40 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 10:24:33 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Lu", "Chris Xiaoxuan", ""], ["Du", "Bowen", ""], ["Wen", "Hongkai", ""], ["Wang", "Sen", ""], ["Markham", "Andrew", ""], ["Martinovic", "Ivan", ""], ["Shen", "Yiran", ""], ["Trigoni", "Niki", ""]]}, {"id": "1912.04859", "submitter": "Anudit Nagar", "authors": "Anudit Nagar", "title": "Privacy-Preserving Blockchain Based Federated Learning with Differential\n  Data Sharing", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the modern world where data is becoming one of the most valuable assets,\nrobust data privacy policies rooted in the fundamental infrastructure of\nnetworks and applications are becoming an even bigger necessity to secure\nsensitive user data. In due course with the ever-evolving nature of newer\nstatistical techniques infringing user privacy, machine learning models with\nalgorithms built with respect for user privacy can offer a dynamically adaptive\nsolution to preserve user privacy against the exponentially increasing\nmultidimensional relationships that datasets create. Using these privacy aware\nML Models at the core of a Federated Learning Ecosystem can enable the entire\nnetwork to learn from data in a decentralized manner. By harnessing the\never-increasing computational power of mobile devices, increasing network\nreliability and IoT devices revolutionizing the smart devices industry, and\ncombining it with a secure and scalable, global learning session backed by a\nblockchain network with the ability to ensure on-device privacy, we allow any\nInternet enabled device to participate and contribute data to a global privacy\npreserving, data sharing network with blockchain technology even allowing the\nnetwork to reward quality work. This network architecture can also be built on\ntop of existing blockchain networks like Ethereum and Hyperledger, this lets\neven small startups build enterprise ready decentralized solutions allowing\nanyone to learn from data across different departments of a company, all the\nway to thousands of devices participating in a global synchronized learning\nnetwork.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 17:58:10 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Nagar", "Anudit", ""]]}, {"id": "1912.04865", "submitter": "Anna-Pia Lohfink", "authors": "Anna-Pia Lohfink, Simon D. Duque Anton, Hans Dieter Schotten, Heike\n  Leitte, Christoph Garth", "title": "Security in Process: Visually Supported Triage Analysis in Industrial\n  Process Data", "comments": "VizSec 2019 Best Paper Award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operation technology networks, i.e. hard- and software used for monitoring\nand controlling physical/industrial processes, have been considered immune to\ncyber attacks for a long time. A recent increase of attacks in these networks\nproves this assumption wrong. Several technical constraints lead to approaches\nto detect attacks on industrial processes using available sensor data. This\nsetting differs fundamentally from anomaly detection in IT-network traffic and\nrequires new visualization approaches adapted to the common periodical behavior\nin OT-network data. We present a tailored visualization system that utilizes\ninherent features of measurements from industrial processes to full capacity to\nprovide insight into the data and support triage analysis by laymen and\nexperts. The novel combination of spiral plots with results from anomaly\ndetection was implemented in an interactive system. The capabilities of our\nsystem are demonstrated using sensor and actuator data from a real-world water\ntreatment process with introduced attacks. Exemplary analysis strategies are\npresented. Finally, we evaluate effectiveness and usability of our system and\nperform an expert evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 18:14:21 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 10:35:38 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Lohfink", "Anna-Pia", ""], ["Anton", "Simon D. Duque", ""], ["Schotten", "Hans Dieter", ""], ["Leitte", "Heike", ""], ["Garth", "Christoph", ""]]}, {"id": "1912.04870", "submitter": "David Gens", "authors": "Zijo Kenjar, Tommaso Frassetto, David Gens, Michael Franz, and\n  Ahmad-Reza Sadeghi", "title": "V0LTpwn: Attacking x86 Processor Integrity from Software", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fault-injection attacks have been proven in the past to be a reliable way of\nbypassing hardware-based security measures, such as cryptographic hashes,\nprivilege and access permission enforcement, and trusted execution\nenvironments. However, traditional fault-injection attacks require physical\npresence, and hence, were often considered out of scope in many real-world\nadversary settings.\n  In this paper we show this assumption may no longer be justified. We present\nV0LTpwn, a novel hardware-oriented but software-controlled attack that affects\nthe integrity of computation in virtually any execution mode on modern x86\nprocessors. To the best of our knowledge, this represents the first attack on\nx86 integrity from software. The key idea behind our attack is to undervolt a\nphysical core to force non-recoverable hardware faults. Under a V0LTpwn attack,\nCPU instructions will continue to execute with erroneous results and without\ncrashes, allowing for exploitation. In contrast to recently presented\nside-channel attacks that leverage vulnerable speculative execution, V0LTpwn is\nnot limited to information disclosure, but allows adversaries to affect\nexecution, and hence, effectively breaks the integrity goals of modern x86\nplatforms. In our detailed evaluation we successfully launch software-based\nattacks against Intel SGX enclaves from a privileged process to demonstrate\nthat a V0LTpwn attack can successfully change the results of computations\nwithin enclave execution across multiple CPU revisions.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 18:24:58 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Kenjar", "Zijo", ""], ["Frassetto", "Tommaso", ""], ["Gens", "David", ""], ["Franz", "Michael", ""], ["Sadeghi", "Ahmad-Reza", ""]]}, {"id": "1912.04977", "submitter": "Peter Kairouz", "authors": "Peter Kairouz, H. Brendan McMahan, Brendan Avent, Aur\\'elien Bellet,\n  Mehdi Bennis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham\n  Cormode, Rachel Cummings, Rafael G.L. D'Oliveira, Hubert Eichner, Salim El\n  Rouayheb, David Evans, Josh Gardner, Zachary Garrett, Adri\\`a Gasc\\'on, Badih\n  Ghazi, Phillip B. Gibbons, Marco Gruteser, Zaid Harchaoui, Chaoyang He, Lie\n  He, Zhouyuan Huo, Ben Hutchinson, Justin Hsu, Martin Jaggi, Tara Javidi,\n  Gauri Joshi, Mikhail Khodak, Jakub Kone\\v{c}n\\'y, Aleksandra Korolova,\n  Farinaz Koushanfar, Sanmi Koyejo, Tancr\\`ede Lepoint, Yang Liu, Prateek\n  Mittal, Mehryar Mohri, Richard Nock, Ayfer \\\"Ozg\\\"ur, Rasmus Pagh, Mariana\n  Raykova, Hang Qi, Daniel Ramage, Ramesh Raskar, Dawn Song, Weikang Song,\n  Sebastian U. Stich, Ziteng Sun, Ananda Theertha Suresh, Florian Tram\\`er,\n  Praneeth Vepakomma, Jianyu Wang, Li Xiong, Zheng Xu, Qiang Yang, Felix X. Yu,\n  Han Yu, Sen Zhao", "title": "Advances and Open Problems in Federated Learning", "comments": "Published in Foundations and Trends in Machine Learning Vol 4 Issue\n  1. See: https://www.nowpublishers.com/article/Details/MAL-083", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a machine learning setting where many clients\n(e.g. mobile devices or whole organizations) collaboratively train a model\nunder the orchestration of a central server (e.g. service provider), while\nkeeping the training data decentralized. FL embodies the principles of focused\ndata collection and minimization, and can mitigate many of the systemic privacy\nrisks and costs resulting from traditional, centralized machine learning and\ndata science approaches. Motivated by the explosive growth in FL research, this\npaper discusses recent advances and presents an extensive collection of open\nproblems and challenges.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 20:55:41 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 06:20:24 GMT"}, {"version": "v3", "created": "Tue, 9 Mar 2021 03:03:49 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Kairouz", "Peter", ""], ["McMahan", "H. Brendan", ""], ["Avent", "Brendan", ""], ["Bellet", "Aur\u00e9lien", ""], ["Bennis", "Mehdi", ""], ["Bhagoji", "Arjun Nitin", ""], ["Bonawitz", "Kallista", ""], ["Charles", "Zachary", ""], ["Cormode", "Graham", ""], ["Cummings", "Rachel", ""], ["D'Oliveira", "Rafael G. L.", ""], ["Eichner", "Hubert", ""], ["Rouayheb", "Salim El", ""], ["Evans", "David", ""], ["Gardner", "Josh", ""], ["Garrett", "Zachary", ""], ["Gasc\u00f3n", "Adri\u00e0", ""], ["Ghazi", "Badih", ""], ["Gibbons", "Phillip B.", ""], ["Gruteser", "Marco", ""], ["Harchaoui", "Zaid", ""], ["He", "Chaoyang", ""], ["He", "Lie", ""], ["Huo", "Zhouyuan", ""], ["Hutchinson", "Ben", ""], ["Hsu", "Justin", ""], ["Jaggi", "Martin", ""], ["Javidi", "Tara", ""], ["Joshi", "Gauri", ""], ["Khodak", "Mikhail", ""], ["Kone\u010dn\u00fd", "Jakub", ""], ["Korolova", "Aleksandra", ""], ["Koushanfar", "Farinaz", ""], ["Koyejo", "Sanmi", ""], ["Lepoint", "Tancr\u00e8de", ""], ["Liu", "Yang", ""], ["Mittal", "Prateek", ""], ["Mohri", "Mehryar", ""], ["Nock", "Richard", ""], ["\u00d6zg\u00fcr", "Ayfer", ""], ["Pagh", "Rasmus", ""], ["Raykova", "Mariana", ""], ["Qi", "Hang", ""], ["Ramage", "Daniel", ""], ["Raskar", "Ramesh", ""], ["Song", "Dawn", ""], ["Song", "Weikang", ""], ["Stich", "Sebastian U.", ""], ["Sun", "Ziteng", ""], ["Suresh", "Ananda Theertha", ""], ["Tram\u00e8r", "Florian", ""], ["Vepakomma", "Praneeth", ""], ["Wang", "Jianyu", ""], ["Xiong", "Li", ""], ["Xu", "Zheng", ""], ["Yang", "Qiang", ""], ["Yu", "Felix X.", ""], ["Yu", "Han", ""], ["Zhao", "Sen", ""]]}, {"id": "1912.05021", "submitter": "Xiao Yang", "authors": "Xiao Yang, Fangyun Wei, Hongyang Zhang, Jun Zhu", "title": "Design and Interpretation of Universal Adversarial Patches in Face\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider universal adversarial patches for faces -- small visual elements\nwhose addition to a face image reliably destroys the performance of face\ndetectors. Unlike previous work that mostly focused on the algorithmic design\nof adversarial examples in terms of improving the success rate as an attacker,\nin this work we show an interpretation of such patches that can prevent the\nstate-of-the-art face detectors from detecting the real faces. We investigate a\nphenomenon: patches designed to suppress real face detection appear face-like.\nThis phenomenon holds generally across different initialization, locations,\nscales of patches, backbones, and state-of-the-art face detection frameworks.\nWe propose new optimization-based approaches to automatic design of universal\nadversarial patches for varying goals of the attack, including scenarios in\nwhich true positives are suppressed without introducing false positives. Our\nproposed algorithms perform well on real-world datasets, deceiving\nstate-of-the-art face detectors in terms of multiple precision/recall metrics\nand transferability.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 12:43:56 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 15:00:41 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 09:37:37 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Yang", "Xiao", ""], ["Wei", "Fangyun", ""], ["Zhang", "Hongyang", ""], ["Zhu", "Jun", ""]]}, {"id": "1912.05064", "submitter": "Nick Frymann", "authors": "Nick Frymann, Mark Manulis", "title": "Securing Fleets of Consumer Drones at Low Cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the use and suitability of drones for many applications,\nincluding surveillance, search and rescue, research, agriculture and civil\nengineering, has greatly increased due to their improved affordability and\nimproved functionality. However, low-cost consumer drones are rarely designed\nto work in fleets, which limits the applications for which business, research\nand individuals may deploy such drones. Proprietary, commercial and bespoke\noptions are available at higher cost and existing solutions providing fleet\nfunctionality have limited security, if any, which excludes their use for\nsensitive applications. In this paper, we discuss the repurposing of consumer\noff-the-shelf (COTS) drones for use in secured fleets and provide the design,\nimplementation and evaluation of a complete approach for creating end-to-end\nsecured fleets of consumer drones (SFCD).\n  We present a protocol for securing communications within fleets whilst\nemploying more efficient symmetric key cryptography throughout to reduce the\nimpact of our security on the limited and resource-constrained COTS drones,\nexploiting the characteristics of a fleet with an online and central ground\ncontrol station, which may act as a key distribution centre. The protocol\nallows an arbitrary number of channels to be established to authenticate and\noptionally encrypt real-time data transmitted on these channels. We also\ndiscuss routing in fleets, as well as the control and monitoring of them, to\nallow SFCD to be fully deployed; providing an extensive and thorough solution.\nOur experimental evaluation confirms the suitability of low-cost consumer\ndrones for use in SFCD, with flight time impacted by only 9.9% and worst-case\nbandwidth of 4.7Mibit/s.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 00:29:33 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Frymann", "Nick", ""], ["Manulis", "Mark", ""]]}, {"id": "1912.05182", "submitter": "Alessandro Barenghi", "authors": "Paolo Santini and Alessandro Barenghi and Gerardo Pelosi and Marco\n  Baldi and Franco Chiaraluce", "title": "A Code-specific Conservative Model for the Failure Rate of Bit-flipping\n  Decoding of LDPC Codes with Cryptographic Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing the decoding failure rate of iteratively decoded Low- and\nModerate-Density Parity Check (LDPC/MDPC) codes is paramount to build\ncryptosystems based on them, able to achieve indistinguishability under\nadaptive chosen ciphertext attacks. In this paper, we provide a statistical\nworst-case analysis of our proposed iterative decoder obtained through a simple\nmodification of the classic in-place bit-flipping decoder. This worst case\nanalysis allows both to derive the worst-case behaviour of an LDPC/MDPC code\npicked among the family with the same length, rate and number of parity checks,\nand a code-specific bound on the decoding failure rate. The former result\nallows us to build a code-based cryptosystem enjoying the $\\delta$-correctness\nproperty required by IND-CCA2 constructions, while the latter result allows us\nto discard code instances which may have a decoding failure rate significantly\ndifferent from the average one (i.e., representing weak keys), should they be\npicked during the key generation procedure.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 08:56:34 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Santini", "Paolo", ""], ["Barenghi", "Alessandro", ""], ["Pelosi", "Gerardo", ""], ["Baldi", "Marco", ""], ["Chiaraluce", "Franco", ""]]}, {"id": "1912.05183", "submitter": "Madura Shelton", "authors": "Madura A Shelton, Niels Samwel, Lejla Batina, Francesco Regazzoni,\n  Markus Wagner, Yuval Yarom", "title": "Rosita: Towards Automatic Elimination of Power-Analysis Leakage in\n  Ciphers", "comments": "17 pages, 16 figures. Accepted in Network and Distributed Systems\n  Security (NDSS) Symposium 2021", "journal-ref": null, "doi": "10.14722/ndss.2021.23137", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since their introduction over two decades ago, side-channel attacks have\npresented a serious security threat. While many ciphers' implementations employ\nmasking techniques to protect against such attacks, they often leak secret\ninformation due to unintended interactions in the hardware. We present Rosita,\na code rewrite engine that uses a leakage emulator which we amend to correctly\nemulate the micro-architecture of a target system. We use Rosita to\nautomatically protect masked implementations of AES, ChaCha, and Xoodoo. For\nAES and Xoodoo, we show the absence of observable leakage at 1,000,000 traces\nwith less than 21% penalty to the performance. For ChaCha, which has\nsignificantly more leakage, Rosita eliminates over 99% of the leakage, at a\nperformance cost of 64%.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 08:58:02 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 02:32:51 GMT"}, {"version": "v3", "created": "Mon, 25 May 2020 12:15:20 GMT"}, {"version": "v4", "created": "Thu, 19 Nov 2020 14:58:40 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Shelton", "Madura A", ""], ["Samwel", "Niels", ""], ["Batina", "Lejla", ""], ["Regazzoni", "Francesco", ""], ["Wagner", "Markus", ""], ["Yarom", "Yuval", ""]]}, {"id": "1912.05547", "submitter": "Gregory D. Kahanamoku-Meyer", "authors": "Gregory D. Kahanamoku-Meyer (University of California at Berkeley)", "title": "Forging quantum data: classically defeating an IQP-based quantum test", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2009, Shepherd and Bremner proposed a \"test of quantum capability\"\narXiv:0809.0847 that is attractive because the quantum machine's output can be\nverified efficiently by classical means. While follow-up papers gave evidence\nthat directly simulating the quantum prover is classically hard, the security\nof the protocol against other (non-simulating) classical attacks has remained\nan open question. In this paper, I demonstrate that the protocol is not secure\nagainst classical provers. I describe a classical algorithm that can not only\nconvince the verifier that the (classical) prover is quantum, but can in fact\ncan extract the secret key underlying a given protocol instance. Furthermore, I\nshow that the algorithm is efficient in practice for problem sizes of hundreds\nof qubits. Finally, I provide an implementation of the algorithm, and give the\nsecret vector underlying the \"$25 challenge\" posted online by the authors of\nthe original paper.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 19:00:00 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Kahanamoku-Meyer", "Gregory D.", "", "University of California at Berkeley"]]}, {"id": "1912.05620", "submitter": "Sacha Servan-Schreiber", "authors": "Sacha Servan-Schreiber and Archer Wheeler", "title": "Judge, Jury & Encryptioner: Exceptional Device Access with a Social Cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Judge, Jury and Encryptioner (JJE) an exceptional access scheme\nfor unlocking devices that does not give unilateral power to any single\nauthority. JJE achieves this by placing final approval to unlock a device in\nthe hands of peer devices. JJE distributes maintenance of the protocol across a\nnetwork of \"custodians\" such as courts, government agencies, civil rights\nwatchdogs, and academic institutions. Unlock requests, however, can only be\napproved by a randomly selected set of recently active peer devices that must\nbe physically located by law enforcement in order to gain access to the locked\ndevice. This requires that law enforcement expend both human and monetary\nresources and pay a \"social cost\" in order to find and request the\nparticipation of random device owners in the unlock process. Compared to other\nproposed exceptional access schemes, we believe that JJE mitigates the risk of\nmass surveillance, law enforcement abuse, and vulnerability to unlawful\nattackers. While we propose a concrete construction, our primary goal with JJE\nis to spur discussion on ethical exceptional access schemes that balance\nprivacy of individuals and the desires for law enforcement. JJE transparently\nreveals the use of exceptional access to the public and enforces a fixed social\ncost that, we believe, can be an effective deterrent to mass surveillance and\nabuse.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 20:57:25 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 19:01:41 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 15:44:54 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Servan-Schreiber", "Sacha", ""], ["Wheeler", "Archer", ""]]}, {"id": "1912.05721", "submitter": "Zhilong Wang", "authors": "Yoon-Ho Choi, Peng Liu, Zitong Shang, Haizhou Wang, Zhilong Wang, Lan\n  Zhang, Junwei Zhou and Qingtian Zou", "title": "Using Deep Learning to Solve Computer Security Challenges: A Survey", "comments": "43 pages with 7 figures and two tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although using machine learning techniques to solve computer security\nchallenges is not a new idea, the rapidly emerging Deep Learning technology has\nrecently triggered a substantial amount of interests in the computer security\ncommunity. This paper seeks to provide a dedicated review of the very recent\nresearch works on using Deep Learning techniques to solve computer security\nchallenges. In particular, the review covers eight computer security problems\nbeing solved by applications of Deep Learning: security-oriented program\nanalysis, defending return-oriented programming (ROP) attacks, achieving\ncontrol-flow integrity (CFI), defending network attacks, malware\nclassification, system-event-based anomaly detection, memory forensics, and\nfuzzing for software security.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 01:42:09 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 21:46:33 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Choi", "Yoon-Ho", ""], ["Liu", "Peng", ""], ["Shang", "Zitong", ""], ["Wang", "Haizhou", ""], ["Wang", "Zhilong", ""], ["Zhang", "Lan", ""], ["Zhou", "Junwei", ""], ["Zou", "Qingtian", ""]]}, {"id": "1912.05823", "submitter": "Abhik Roychoudhury", "authors": "Xiao Liang Yu, Omar Al-Bataineh, David Lo, Abhik Roychoudhury", "title": "Smart Contract Repair", "comments": "32 pages. ACM Transactions on Software Engineering and Methodology\n  (TOSEM), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart contracts are automated or self-enforcing contracts that can be used to\nexchange assets without having to place trust in third parties. Many commercial\ntransactions use smart contracts due to their potential benefits in terms of\nsecure peer-to-peer transactions independent of external parties. Experience\nshows that many commonly used smart contracts are vulnerable to serious\nmalicious attacks which may enable attackers to steal valuable assets of\ninvolving parties. There is therefore a need to apply analysis and automated\nrepair techniques to detect and repair bugs in smart contracts before being\ndeployed. In this work, we present the first general-purpose automated smart\ncontract repair approach that is also gas-aware. Our repair method is\nsearch-based and searches among mutations of the buggy contract. Our method\nalso considers the gas usage of the candidate patches by leveraging our novel\nnotion of gas dominance relationship. We have made our smart contract repair\ntool SCRepair available open-source, for investigation by the wider community.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 08:11:00 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 14:13:43 GMT"}, {"version": "v3", "created": "Wed, 20 May 2020 13:52:13 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Yu", "Xiao Liang", ""], ["Al-Bataineh", "Omar", ""], ["Lo", "David", ""], ["Roychoudhury", "Abhik", ""]]}, {"id": "1912.05849", "submitter": "Constantinos Patsakis", "authors": "Constantinos Patsakis and Fran Casino", "title": "Exploiting Statistical and Structural Features for the Detection of\n  Domain Generation Algorithms", "comments": null, "journal-ref": "Journal of Information Security and Applications, Volume 58, 2021", "doi": "10.1016/j.jisa.2020.102725", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, malware campaigns have reached a high level of sophistication,\nthanks to the use of cryptography and covert communication channels over\ntraditional protocols and services. In this regard, a typical approach to evade\nbotnet identification and takedown mechanisms is the use of domain fluxing\nthrough the use of Domain Generation Algorithms (DGAs). These algorithms\nproduce an overwhelming amount of domain names that the infected device tries\nto communicate with to find the Command and Control server, yet only a small\nfragment of them is actually registered. Due to the high number of domain\nnames, the blacklisting approach is rendered useless. Therefore, the botmaster\nmay pivot the control dynamically and hinder botnet detection mechanisms. To\ncounter this problem, many security mechanisms result in solutions that try to\nidentify domains from a DGA based on the randomness of their name.\n  In this work, we explore hard to detect families of DGAs, as they are\nconstructed to bypass these mechanisms. More precisely, they are based on the\nuse of dictionaries so the domains seem to be user-generated. Therefore, the\ncorresponding generated domains pass many filters that look for, e.g. high\nentropy strings. To address this challenge, we propose an accurate and\nefficient probabilistic approach to detect them. We test and validate the\nproposed solution through extensive experiments with a sound dataset containing\nall the wordlist-based DGA families that exhibit this behaviour and compare it\nwith other state-of-the-art methods, practically showing the efficacy and\nprevalence of our proposal.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 09:42:17 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 18:03:27 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Patsakis", "Constantinos", ""], ["Casino", "Fran", ""]]}, {"id": "1912.05861", "submitter": "Ephraim Zimmer", "authors": "Ephraim Zimmer, Christian Burkert, Tom Petersen, Hannes Federrath", "title": "PEEPLL: Privacy-Enhanced Event Pseudonymisation with Limited Linkability", "comments": "10 pages. Extended version, Dec. 2019. A shortened version has been\n  accepted for publication in the proceedings of the 35th ACM/SIGAPP Symposium\n  On Applied Computing 2020", "journal-ref": null, "doi": "10.1145/3341105.3375781", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pseudonymisation provides the means to reduce the privacy impact of\nmonitoring, auditing, intrusion detection, and data collection in general on\nindividual subjects. Its application on data records, especially in an\nenvironment with additional constraints, like re-identification in the course\nof incident response, implies assumptions and privacy issues, which contradict\nthe achievement of the desirable privacy level. Proceeding from two real-world\nscenarios, where personal and identifying data needs to be processed, we\nidentify requirements as well as a system model for pseudonymisation and\nexplicitly state the sustained privacy threats, even when pseudonymisation is\napplied. With this system and threat model, we derive privacy protection goals\ntogether with possible technical realisations, which are implemented and\nintegrated into our event pseudonymisation framework PEEPLL for the context of\nevent processing, like monitoring and auditing of user, process, and network\nactivities. Our framework provides privacy-friendly linkability in order to\nmaintain the possibility for automatic event correlation and evaluation, while\nat the same time reduces the privacy impact on individuals. Additionally, the\npseudonymisation framework is evaluated in order to provide some restrained\ninsights on the impact of assigned paradigms and all necessary new mechanisms\non the performance of monitoring and auditing. With this framework, privacy\nprovided by event pseudonymisation can be enhanced by a more rigorous\ncommitment to the concept of personal data minimisation, especially in the\ncontext of regulatory requirements like the European General Data Protection\nRegulation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 10:11:18 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Zimmer", "Ephraim", ""], ["Burkert", "Christian", ""], ["Petersen", "Tom", ""], ["Federrath", "Hannes", ""]]}, {"id": "1912.05897", "submitter": "Runhua Xu", "authors": "Runhua Xu, Nathalie Baracaldo, Yi Zhou, Ali Anwar and Heiko Ludwig", "title": "HybridAlpha: An Efficient Approach for Privacy-Preserving Federated\n  Learning", "comments": "12 pages, AISec 2019", "journal-ref": null, "doi": "10.1145/3338501.3357371", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning has emerged as a promising approach for collaborative and\nprivacy-preserving learning. Participants in a federated learning process\ncooperatively train a model by exchanging model parameters instead of the\nactual training data, which they might want to keep private. However, parameter\ninteraction and the resulting model still might disclose information about the\ntraining data used. To address these privacy concerns, several approaches have\nbeen proposed based on differential privacy and secure multiparty computation\n(SMC), among others. They often result in large communication overhead and slow\ntraining time. In this paper, we propose HybridAlpha, an approach for\nprivacy-preserving federated learning employing an SMC protocol based on\nfunctional encryption. This protocol is simple, efficient and resilient to\nparticipants dropping out. We evaluate our approach regarding the training time\nand data volume exchanged using a federated learning process to train a CNN on\nthe MNIST data set. Evaluation against existing crypto-based SMC solutions\nshows that HybridAlpha can reduce the training time by 68% and data transfer\nvolume by 92% on average while providing the same model performance and privacy\nguarantees as the existing solutions.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 12:37:39 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Xu", "Runhua", ""], ["Baracaldo", "Nathalie", ""], ["Zhou", "Yi", ""], ["Anwar", "Ali", ""], ["Ludwig", "Heiko", ""]]}, {"id": "1912.06134", "submitter": "Tongjiang Yan", "authors": "Ming Yan, Tongjiang Yan, Yu Li", "title": "Computing the 2-adic complexity of two classes of Ding-Helleseth\n  generalized cyclotomic sequences of period of twin prime products", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper contributes to compute 2-adic complexity of two classes of\nDing-Helleseth generalized cyclotomic sequences. Results show that 2-adic\ncomplexity of these sequences is good enough to resist the attack by the\nrational approximation algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 07:03:27 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Yan", "Ming", ""], ["Yan", "Tongjiang", ""], ["Li", "Yu", ""]]}, {"id": "1912.06176", "submitter": "Dan Wallach", "authors": "Clayton Drazner and Nikola {\\DJ}uza and Hugo Jonker and Dan S. Wallach", "title": "Investigating the effectiveness of web adblockers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate adblocking filters and the extent to which websites and\nadvertisers react when their content is impacted by these filters. We collected\ndata daily from the Alexa Top-5000 web sites for 120 days, and from specific\nsites that newly appeared in filter lists for 140 days. By evaluating how long\na filter rule triggers on a website, we can gauge how long it remains\neffective. We matched websites with both a regular adblocking filter list\n(EasyList) and with a specialized filter list that targets anti-adblocking\nlogic (Nano Defender).\n  From our data, we observe that the effectiveness of the EasyList adblocking\nfilter decays a modest 0.13\\% per day, and after around 80 days seems to\nstabilize. We found no evidence for any significant decay in effectiveness of\nthe more specialized, but less widely used, anti-adblocking removal filters.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 19:34:48 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Drazner", "Clayton", ""], ["\u0110uza", "Nikola", ""], ["Jonker", "Hugo", ""], ["Wallach", "Dan S.", ""]]}, {"id": "1912.06362", "submitter": "Bodhibrata Mukhopadhyay", "authors": "Bodhibrata Mukhopadhyay, Seshan Srirangarajan, and Subrat Kar", "title": "RSSI-based Secure Localization in the Presence of Malicious Nodes in\n  Sensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of a sensor node to determine its location in a sensor network is\nimportant in many applications. The infrastructure for the location-based\nservices is an easy target for malicious attacks. We address scenarios where\nmalicious node(s) attempt to disrupt, in an uncoordinated or coordinated\nmanner, the localization process of a target node. We propose four techniques\nfor secure localization: weighted least square (WLS), secure weighted least\nsquare (SWLS), and $\\ell_1$-norm based techniques LN-1 and LN-1E, in a network\nthat includes one or more compromised anchor nodes. WLS and SWLS techniques are\nshown to offer significant advantage over existing techniques by assigning\nlarger weights to the anchor nodes that are closer to the target node, and by\ndetecting the malicious nodes and eliminating their measurements from the\nlocalization process. In a coordinated attack, the localization problem can be\nposed as a plane fitting problem where the measurements from non-malicious and\nmalicious anchor nodes lie on two different planes. LN-1E technique estimates\nthese two planes and prevents disruption of the localization process. The\nCramer-Rao lower bound (CRLB) for the position estimate is also derived. The\nproposed techniques are shown to provide better localization accuracy than the\nexisting algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 08:48:26 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Mukhopadhyay", "Bodhibrata", ""], ["Srirangarajan", "Seshan", ""], ["Kar", "Subrat", ""]]}, {"id": "1912.06412", "submitter": "Ricardo P\\'erez-Marco", "authors": "Cyril Grunspan, Ricardo P\\'erez-Marco", "title": "On Profitability of Nakamoto double spend", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": "10.1017/S026996482100005X", "report-no": null, "categories": "cs.CR math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nakamoto double spend strategy, described in Bitcoin foundational article,\nleads to total ruin with positive probability and does not make sense from the\nprofitability point of view. The simplest strategy that can be profitable\nincorporates a stopping threshold when success is unlikely. We solve and\ncompute the exact profitability for this strategy. We compute the minimal\namount of the double spend that is profitable. For a given amount of the\ntransaction, we determine the minimal number of confirmations to be requested\nby the recipient such that this double spend strategy is non-profitable. We\nfind that this number of confirmations is only 1 or 2 for average transactions\nand a small hashrate of the attacker. This is substantially lower than the\noriginal Nakamoto numbers that are widely used and are only based on the\nsuccess probability instead of the profitability.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 17:00:17 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Grunspan", "Cyril", ""], ["P\u00e9rez-Marco", "Ricardo", ""]]}, {"id": "1912.06485", "submitter": "Hong-Ning Dai Prof.", "authors": "Zibin Zheng and Hong-Ning Dai and Jiajing Wu", "title": "Blockchain Intelligence: When Blockchain Meets Artificial Intelligence", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.DC cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain is gaining extensive attention due to its provision of secure and\ndecentralized resource sharing manner. However, the incumbent blockchain\nsystems also suffer from a number of challenges in operational maintenance,\nquality assurance of smart contracts and malicious behaviour detection of\nblockchain data. The recent advances in artificial intelligence bring the\nopportunities in overcoming the above challenges. The integration of blockchain\nwith artificial intelligence can be beneficial to enhance current blockchain\nsystems. This article presents an introduction of the convergence of blockchain\nand artificial intelligence (namely blockchain intelligence). This article also\ngives a case study to further demonstrate the feasibility of blockchain\nintelligence and point out the future directions.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 02:56:45 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 03:57:05 GMT"}, {"version": "v3", "created": "Fri, 3 Apr 2020 22:41:18 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Zheng", "Zibin", ""], ["Dai", "Hong-Ning", ""], ["Wu", "Jiajing", ""]]}, {"id": "1912.06487", "submitter": "Peter Mell", "authors": "Peter Mell", "title": "Augmenting Fiat Currency with an Integrated Managed Cryptocurrency", "comments": "Published in The Fourteenth International Conference on Software\n  Engineering Advances (ICSEA) 2019, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate how the governance features of a managed\ncurrency (e.g., a fiat currency) can be built into a cryptocurrency in order to\nleverage potential benefits found in the use of blockchain technology and smart\ncontracts. The resulting managed cryptocurrency can increase transparency and\nintegrity, while potentially enabling the emergence of novel monetary\ninstruments. It has similarities to cash in that it enables the general public\nto immediately transfer funds to a recipient without intermediary systems being\ninvolved. However, our system is account-based, unlike circulating bank notes\nthat are self-contained. Our design would allow one to satisfy know your\ncustomer laws and be subject to law enforcement actions following legal due\nprocess (e.g., account freezing and fund seizure), while mitigating\ncounterparty risk with checks and balances. Funds can thus be transferred only\nbetween approved and authenticated users. Our system has on-chain governance\ncapabilities using smart contracts deployed on a dedicated, permissioned\nblockchain that has different sets of control mechanisms for who can read data,\nwrite data, and publish blocks. To enable the governance features, only\nauthorized identity proofed entities can submit transactions. To enable\nprivacy, only the block publishers can read the blockchain; the publishers\nmaintain dedicated nodes that provide access controlled partial visibility of\nthe blockchain data. Being permissioned, we can use a simple consensus protocol\nwith no transaction fees. A separate security layer prevents denial of service\nand a balance of power mechanism prevents any small group of entities from\nhaving undue control. While permissioned, we ensure that no one entity controls\nthe blockchain data or block publishing capability through a voting system with\npublicly visible election outcomes.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 13:51:41 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Mell", "Peter", ""]]}, {"id": "1912.06491", "submitter": "Peter Mell", "authors": "Peter Mell, Aurelien Delaitre, Frederic de Vaulx, Philippe Dessauw", "title": "Implementing a Protocol Native Managed Cryptocurrency", "comments": "Published in The Fourteenth International Conference on Software\n  Engineering Advances (ICSEA) 2019, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work presented a theoretical model based on the implicit Bitcoin\nspecification for how an entity might issue a protocol native cryptocurrency\nthat mimics features of fiat currencies. Protocol native means that it is built\ninto the blockchain platform itself and is not simply a token running on\nanother platform. Novel to this work were mechanisms by which the issuing\nentity could manage the cryptocurrency but where their power was limited and\ntransparency was enforced by the cryptocurrency being implemented using a\npublicly mined blockchain. In this work we demonstrate the feasibility of this\ntheoretical model by implementing such a managed cryptocurrency architecture\nthrough forking the Bitcoin code base. We discovered that the theoretical model\ncontains several vulnerabilities and security issues that needed to be\nmitigated. It also contains architectural features that presented significant\nimplementation challenges; some aspects of the proposed changes to the Bitcoin\nspecification were not practical or even workable. In this work we describe how\nwe mitigated the security vulnerabilities and overcame the architectural\nhurdles to build a working prototype.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 13:54:48 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Mell", "Peter", ""], ["Delaitre", "Aurelien", ""], ["de Vaulx", "Frederic", ""], ["Dessauw", "Philippe", ""]]}, {"id": "1912.06497", "submitter": "Vahid Behzadan", "authors": "Ibrahim Baggili and Vahid Behzadan", "title": "Founding The Domain of AI Forensics", "comments": "Accepted for presentation at SafeAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread integration of AI in everyday and critical technologies,\nit seems inevitable to witness increasing instances of failure in AI systems.\nIn such cases, there arises a need for technical investigations that produce\nlegally acceptable and scientifically indisputable findings and conclusions on\nthe causes of such failures. Inspired by the domain of cyber forensics, this\npaper introduces the need for the establishment of AI Forensics as a new\ndiscipline under AI safety. Furthermore, we propose a taxonomy of the subfields\nunder this discipline, and present a discussion on the foundational challenges\nthat lay ahead of this new research area.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 23:39:57 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Baggili", "Ibrahim", ""], ["Behzadan", "Vahid", ""]]}, {"id": "1912.06510", "submitter": "Nikolai Gladychev", "authors": "Nikolai Gladychev", "title": "Computer Viruses: The Abstract Theory Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying new viral threats, and developing long term defences against\ncurrent and future computer viruses, requires an understanding of their\nbehaviour, structure and capabilities. This paper aims to advance this\nunderstanding by further developing the abstract theory of computer viruses. A\nmethod of providing abstract definitions for classes of viruses is presented in\nthis paper, which addresses inadequacies of previous techniques. Formal\ndefinitions for some classes of viruses are then provided, which correspond to\nexisting informal definitions. To relate the abstract theory to the real world,\nthe connection between the abstract definitions and concrete virus\nimplementations is examined. The use of the proposed method in studying the\nfundamental properties of computer viruses is discussed.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 14:14:38 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Gladychev", "Nikolai", ""]]}, {"id": "1912.06542", "submitter": "Boris Ryabko", "authors": "Boris Ryabko", "title": "On asymptotically optimal tests for random number generators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of constructing effective statistical tests for random number\ngenerators (RNG) is considered. Currently, statistical tests for RNGs are a\nmandatory part of cryptographic information protection systems, but their\neffectiveness is mainly estimated based on experiments with various RNGs.\n  We find an asymptotic estimate for the p-value of an optimal test in the case\nwhere the alternative hypothesis is a known stationary ergodic source, and then\ndescribe a family of tests each of which has the same asymptotic estimate of\nthe p-value for any (unknown) stationary ergodic source.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 15:00:40 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Ryabko", "Boris", ""]]}, {"id": "1912.06733", "submitter": "Daniel Peterson", "authors": "Daniel Peterson, Pallika Kanani, Virendra J. Marathe", "title": "Private Federated Learning with Domain Adaptation", "comments": "Presented at the Workshop on Federated Learning for Data Privacy and\n  Confidentiality (in Conjunction with NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is a distributed machine learning (ML) paradigm that\nenables multiple parties to jointly re-train a shared model without sharing\ntheir data with any other parties, offering advantages in both scale and\nprivacy. We propose a framework to augment this collaborative model-building\nwith per-user domain adaptation. We show that this technique improves model\naccuracy for all users, using both real and synthetic data, and that this\nimprovement is much more pronounced when differential privacy bounds are\nimposed on the FL model.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 22:48:43 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Peterson", "Daniel", ""], ["Kanani", "Pallika", ""], ["Marathe", "Virendra J.", ""]]}, {"id": "1912.06751", "submitter": "Riccardo Aragona", "authors": "Riccardo Aragona and Marco Calderini and Roberto Civino", "title": "Some group-theoretical results on Feistel Networks in a long-key\n  scenario", "comments": "Accepted for publication in Advances in Mathematics of Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of the trapdoors that can be hidden in a block cipher is and has\nalways been a high-interest topic in symmetric cryptography. In this paper we\nfocus on Feistel-network-like ciphers in a classical long-key scenario and we\ninvestigate some conditions which make such a construction immune to the\npartition-based attack introduced recently by Bannier et al.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 00:10:03 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 13:18:46 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Aragona", "Riccardo", ""], ["Calderini", "Marco", ""], ["Civino", "Roberto", ""]]}, {"id": "1912.06796", "submitter": "Steven Kommrusch", "authors": "Steve Kommrusch", "title": "Artificial Intelligence Techniques for Security Vulnerability Prevention", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer security has been a concern for decades and artificial intelligence\ntechniques have been applied to the area for nearly as long. Most of the\ntechniques are being applied to the detection of attacks to running systems,\nbut recent improvements in machine learning (for example, in natural language\nprocessing) have enabled the opportunity to process software and specifications\nto detect vulnerabilities in a system before it is deployed. This paper\npresents a survey of artificial intelligence techniques (including machine\nlearning) to detect or repair security vulnerabilities before product\nintroduction. In the surveyed papers, techniques are presented for using NLP to\nanalyze requirements documents for security standard completeness, performing\nneural fuzz testing of software, generating exploits to detect risk, and more.\nWe categorize current techniques into 3 groups: vulnerability detection,\nvulnerability repair, and specification analysis. Generally, while AI\ntechniques have become quite useful in this area, we show that AI techniques\nstill tend to be limited in scope, providing a collection of tools which can\naugment but not replace careful system development to reduce vulnerability\nrisks.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 07:01:44 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Kommrusch", "Steve", ""]]}, {"id": "1912.06812", "submitter": "Hina Binte Haq", "authors": "Aamna Tariq, Hina Binte Haq, Syed Taha Ali", "title": "Cerberus: A Blockchain-Based Accreditation and Degree Verification\n  System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credential fraud is a widespread practice that undermines investment and\nconfidence in higher education systems and bears significant economic and\nsocial costs. Legacy credential verification systems are typically\ntime-consuming, costly, and bureaucratic, and struggle against certain classes\nof credential fraud. In this paper, we propose a comprehensive blockchain-based\ncredential verification solution, Cerberus, which is considerably more\nefficient, easy and intuitive to use, and effectively mitigates widespread\nmanifestations of credential fraud. Cerberus also improves significantly upon\nother blockchain-based solutions in the research literature: it adheres closely\nto the existing credential verification ecosystem, it addresses a threat model\ninformed by real-world fraud scenarios. Moreover, Cerberus uses on-chain smart\ncontracts for credential revocation, and it does not entail students or\nemployers to manage digital identities or cryptographic credentials to use the\nsystem. We prototype our solution and describe our attempt to design an online\nverification service with a rich feature set, including data privacy,\ntranscript verification, and selective disclosure of data. We hope this effort\ncontributes positively to towards alleviating the problem of fake credentials.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 09:29:41 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Tariq", "Aamna", ""], ["Haq", "Hina Binte", ""], ["Ali", "Syed Taha", ""]]}, {"id": "1912.06817", "submitter": "Ricardo Morla", "authors": "Ricardo Morla", "title": "Ten AI Stepping Stones for Cybersecurity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the turmoil in cybersecurity and the mind-blowing advances in AI, it is\nonly natural that cybersecurity practitioners consider further employing\nlearning techniques to help secure their organizations and improve the\nefficiency of their security operation centers. But with great fears come great\nopportunities for both the good and the evil, and a myriad of bad deals. This\npaper discusses ten issues in cybersecurity that hopefully will make it easier\nfor practitioners to ask detailed questions about what they want from an AI\nsystem in their cybersecurity operations. We draw on the state of the art to\nprovide factual arguments for a discussion on well-established AI in\ncybersecurity issues, including the current scope of AI and its application to\ncybersecurity, the impact of privacy concerns on the cybersecurity data that\ncan be collected and shared externally to the organization, how an AI decision\ncan be explained to the person running the operations center, and the\nimplications of the adversarial nature of cybersecurity in the learning\ntechniques. We then discuss the use of AI by attackers on a level playing field\nincluding several issues in an AI battlefield, and an AI perspective on the old\ncat-and-mouse game including how the adversary may assess your AI power.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 09:54:36 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Morla", "Ricardo", ""]]}, {"id": "1912.06863", "submitter": "Ronny Chevalier", "authors": "Ronny Chevalier, David Plaquin, Chris Dalton, Guillaume Hiet", "title": "Survivor: A Fine-Grained Intrusion Response and Recovery Approach for\n  Commodity Operating Systems", "comments": "The final version of this paper has been published in the Proceedings\n  of the 35th Annual Computer Security Applications Conference (ACSAC), 2019.\n  14 pages, 5 figures, 6 tables", "journal-ref": "Proceedings of the 35th Annual Computer Security Applications\n  Conference. ACM, 2019. p. 762-775", "doi": "10.1145/3359789.3359792", "report-no": null, "categories": "cs.CR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the deployment of preventive security mechanisms to protect the\nassets and computing platforms of users, intrusions eventually occur. We\npropose a novel intrusion survivability approach to withstand ongoing\nintrusions. Our approach relies on an orchestration of fine-grained recovery\nand per-service responses (e.g., privileges removal). Such an approach may put\nthe system into a degraded mode. This degraded mode prevents attackers to\nreinfect the system or to achieve their goals if they managed to reinfect it.\nIt maintains the availability of core functions while waiting for patches to be\ndeployed. We devised a cost-sensitive response selection process to ensure that\nwhile the service is in a degraded mode, its core functions are still\noperating. We built a Linux-based prototype and evaluated the effectiveness of\nour approach against different types of intrusions. The results show that our\nsolution removes the effects of the intrusions, that it can select appropriate\nresponses, and that it allows services to survive when reinfected. In terms of\nperformance overhead, in most cases, we observed a small overhead, except in\nthe rare case of services that write many small files asynchronously in a\nburst, where we observed a higher but acceptable overhead.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 15:17:00 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Chevalier", "Ronny", ""], ["Plaquin", "David", ""], ["Dalton", "Chris", ""], ["Hiet", "Guillaume", ""]]}, {"id": "1912.06871", "submitter": "Thomas Hardjono", "authors": "Thomas Hardjono, Alexander Lipton, Alex Pentland", "title": "Privacy-Preserving Claims Exchange Networks for Virtual Asset Service\n  Providers", "comments": "4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In order for VASPs to fulfill the regulatory requirements from the FATF and\nthe Travel Rule, VASPs need access to truthful information regarding\noriginators, beneficiaries and other VASPs involved in a virtual asset transfer\ninstance. Additionally, in seeking data regarding subjects (individuals or\norganizations) VASPs are faced with privacy regulations such as the GDPR and\nCCPA. In this paper we a propose privacy-preserving claims issuance model that\ncarries indicators of the provenance of the data and the algorithms used to\nderive the claim or assertion. This allows VASPs to obtain originator and\nbeneficiary information without necessarily having access to the private data\nabout these entities. Secondly we propose the use of a consortium trust network\narrangement for VASPs to exchange signed claims about subjects and their\npublic-key information or certificate.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 16:03:14 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 18:40:42 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Hardjono", "Thomas", ""], ["Lipton", "Alexander", ""], ["Pentland", "Alex", ""]]}, {"id": "1912.06895", "submitter": "Cristian Canton Ferrer", "authors": "Hao Guo, Brian Dolhansky, Eric Hsin, Phong Dinh, Cristian Canton\n  Ferrer, Song Wang", "title": "Deep Poisoning: Towards Robust Image Data Sharing against Visual\n  Disclosure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to respectively limited training data, different entities addressing the\nsame vision task based on certain sensitive images may not train a robust deep\nnetwork. This paper introduces a new vision task where various entities share\ntask-specific image data to enlarge each other's training data volume without\nvisually disclosing sensitive contents (e.g. illegal images). Then, we present\na new structure-based training regime to enable different entities learn\ntask-specific and reconstruction-proof image representations for image data\nsharing. Specifically, each entity learns a private Deep Poisoning Module (DPM)\nand insert it to a pre-trained deep network, which is designed to perform the\nspecific vision task. The DPM deliberately poisons convolutional image features\nto prevent image reconstructions, while ensuring that the altered image data is\nfunctionally equivalent to the non-poisoned data for the specific vision task.\nGiven this equivalence, the poisoned features shared from one entity could be\nused by another entity for further model refinement. Experimental results on\nimage classification prove the efficacy of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 18:02:53 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 02:56:26 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Guo", "Hao", ""], ["Dolhansky", "Brian", ""], ["Hsin", "Eric", ""], ["Dinh", "Phong", ""], ["Ferrer", "Cristian Canton", ""], ["Wang", "Song", ""]]}, {"id": "1912.07005", "submitter": "Han Li", "authors": "Han Li", "title": "A Statistical Explanation of the Timing Attack on QC-MDPC Code\n  Crypto-system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The McEliece cryptosystem based on quasi-cyclic moderate-density parity-check\n(QC-MDPC) codes is first purposed in 2013\\cite{QCMDPC} and is considered a\npromising contender in the post-quantum era. Understanding its security is\nhence essential. Till now, the most effective attacks are the reaction\nattack\\cite{Reaction} and the timing attack\\cite{Timing}. Both of these attacks\nrely on the decoding performance to recover the private key. The reaction\nattack relies on the decoding failure rate and the timing attack relies on the\niterations during decoding. However, the mechanics behind these attacks remain\nelusive. In this paper, a mathematical model is proposed to explain both\nattacks by connecting the spectrum of private key and first-layer performance\nof the decoder.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 08:49:10 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Li", "Han", ""]]}, {"id": "1912.07144", "submitter": "Cristiana Santos", "authors": "Cristiana Santos, Nataliia Bielova and C\\'elestin Matte", "title": "Are cookie banners indeed compliant with the law? Deciphering EU legal\n  requirements on consent and technical means to verify compliance of cookie\n  banners", "comments": "75 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work, we analyze the legal requirements on how cookie banners are\nsupposed to be implemented to be fully compliant with the e-Privacy Directive\nand the General Data Protection Regulation. Our contribution resides in the\ndefinition of seventeen operational and fine-grained requirements on cookie\nbanner design that are legally compliant, and moreover, we define whether and\nwhen the verification of compliance of each requirement is technically\nfeasible. The definition of requirements emerges from a joint interdisciplinary\nanalysis composed of lawyers and computer scientists in the domain of web\ntracking technologies. As such, while some requirements are provided by\nexplicitly codified legal sources, others result from the domain-expertise of\ncomputer scientists. In our work, we match each requirement against existing\ncookie banners design of websites. For each requirement, we exemplify with\ncompliant and non-compliant cookie banners. As an outcome of a technical\nassessment, we verify per requirement if technical (with computer science\ntools) or manual (with any human operator) verification is needed to assess\ncompliance of consent and we also show which requirements are impossible to\nverify with certainty in the current architecture of the Web. For example, we\nexplain how the requirement for revocable consent could be implemented in\npractice: when consent is revoked, the publisher should delete the consent\ncookie and communicate the withdrawal to all third parties who have previously\nreceived consent. With this approach we aim to support practically-minded\nparties (compliance officers, regulators, researchers, and computer scientists)\nto assess compliance and detect violations in cookie banner design and\nimplementation, specially under the current revision of the European Union\ne-Privacy framework.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 00:47:45 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 00:09:07 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Santos", "Cristiana", ""], ["Bielova", "Nataliia", ""], ["Matte", "C\u00e9lestin", ""]]}, {"id": "1912.07250", "submitter": "Yi-Ting Huang", "authors": "Yi-Ting Huang, Ting-Yi Chen, Yeali S. Sun, and Meng Chang Chen", "title": "Learning Malware Representation based on Execution Sequences", "comments": "Incorrect experiment data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware analysis has been extensively investigated as the number and types of\nmalware has increased dramatically. However, most previous studies use\nend-to-end systems to detect whether a sample is malicious, or to identify its\nmalware family. In this paper, we propose a neural network framework composed\nof an embedder, an encoder, and a filter to learn malware representations from\ncharacteristic execution sequences for malware family classification. The\nembedder uses BERT and Sent2Vec, state-of-the-art embedding modules, to capture\nrelations within a single API call and among consecutive API calls in an\nexecution trace. The encoder comprises gated recurrent units (GRU) to preserve\nthe ordinal position of API calls and a self-attention mechanism for comparing\nintra-relations among different positions of API calls. The filter identifies\nrepresentative API calls to build the malware representation. We conduct broad\nexperiments to determine the influence of individual framework components. The\nresults show that the proposed framework outperforms the baselines, and also\ndemonstrates that considering Sent2Vec to learn complete API call embeddings\nand GRU to explicitly preserve ordinal information yields more information and\nthus significant improvements. Also, the proposed approach effectively\nclassifies new malicious execution traces on the basis of similarities with\npreviously collected families.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 08:52:40 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 02:22:17 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Huang", "Yi-Ting", ""], ["Chen", "Ting-Yi", ""], ["Sun", "Yeali S.", ""], ["Chen", "Meng Chang", ""]]}, {"id": "1912.07283", "submitter": "Joaquin Garcia-Alfaro", "authors": "Fr\\'ed\\'eric Cuppens, Nora Cuppens-Boulahia, Joaquin Garcia-Alfaro", "title": "Misconfiguration Management of Network Security Components", "comments": "9 pages, 4 figures, 10 references, 7th International Symposium on\n  System and Information Security (SSI), Sao Paulo, Brazil", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many companies and organizations use firewalls to control the access to their\nnetwork infrastructure. Firewalls are network security components which provide\nmeans to filter traffic within corporate networks, as well as to police\nincoming and outcoming interaction with the Internet. For this purpose, it is\nnecessary to configure firewalls with a set of filtering rules. Nevertheless,\nthe existence of errors in a set of filtering rules is very likely to degrade\nthe network security policy. The discovering and removal of these configuration\nerrors is a serious and complex problem to solve. In this paper, we present a\nset of algorithms for such a management. Our approach is based on the analysis\nof relationships between the set of filtering rules. Then, a subsequent\nrewriting of rules will derive from an initial firewall setup -- potentially\nmisconfigured -- to an equivalent one completely free of errors. At the same\ntime, the algorithms will detect useless rules in the initial firewall\nconfiguration.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 10:29:20 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Cuppens", "Fr\u00e9d\u00e9ric", ""], ["Cuppens-Boulahia", "Nora", ""], ["Garcia-Alfaro", "Joaquin", ""]]}, {"id": "1912.07331", "submitter": "Ufuk Altun", "authors": "Ufuk Altun, Semiha T. Basaran, Gunes K. Kurt, Enver Ozdemir", "title": "Scalable Group Secret Key Generation over Wireless Channels", "comments": "7 pages, 3 figure, transactions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of secret key generation for multiple\nparties. Multi-user networks usually require a trusted party to efficiently\ndistribute keys to the legitimate users and this process is a weakness against\neavesdroppers. With the help of the physical layer security techniques, users\ncan securely decide on a secret key without a trusted party by exploiting the\nunique properties of the channel. In this context, we develop a physical layer\ngroup key generation scheme that is also based on the ideas of the analog\nfunction computation studies. We firstly consider the key generation as a\nfunction to be computed over the wireless channel and propose two novel methods\ndepending on the users transmission capability (i.e. half-duplex and\nfull-duplex transmissions). Secondly, we exploit the uniqueness of the prime\nintegers in order to enable the simultaneous transmission of the users for key\ngeneration. As a result, our approach contributes to the scalability of the\nexisting physical layer key generation algorithms since all users transmit\nsimultaneously rather than using pairwise communications. We prove that our\nhalf-duplex network model reduces the required number of communications for\ngroup key generation down to a linear scale. Furthermore, the full-duplex\nnetwork model reduces to a constant scale.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 13:07:50 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Altun", "Ufuk", ""], ["Basaran", "Semiha T.", ""], ["Kurt", "Gunes K.", ""], ["Ozdemir", "Enver", ""]]}, {"id": "1912.07497", "submitter": "Michael Mirkin", "authors": "Michael Mirkin, Yan Ji, Jonathan Pang, Ariah Klages-Mundt, Ittay Eyal\n  and Ari Juels", "title": "BDoS: Blockchain Denial of Service", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proof-of-work (PoW) cryptocurrency blockchains like Bitcoin secure vast\namounts of money. Their operators, called miners, expend resources to generate\nblocks and receive monetary rewards for their effort. Blockchains are, in\nprinciple, attractive targets for Denial-of-Service (DoS) attacks: There is\nfierce competition among coins, as well as potential gains from short selling.\nClassical DoS attacks, however, typically target a few servers and cannot scale\nto systems with many nodes. There have been no successful DoS attacks to date\nagainst prominent cryptocurrencies. We present Blockchain DoS (BDoS), the first\nincentive-based DoS attack that targets PoW cryptocurrencies. Unlike classical\nDoS, BDoS targets the system's mechanism design: It exploits the reward\nmechanism to discourage miner participation. Previous DoS attacks against PoW\nblockchains require an adversary's mining power to match that of all other\nminers. In contrast, BDoS can cause a blockchain to grind to a halt with\nsignificantly fewer resources, e.g., 21% as of March 2020 in Bitcoin, according\nto our empirical study. We find that Bitcoin's vulnerability to BDoS increases\nrapidly as the mining industry matures and profitability drops. BDoS differs\nfrom known attacks like Selfish Mining in its aim not to increase an\nadversary's revenue, but to disrupt the system. Although it bears some\nalgorithmic similarity to those attacks, it introduces a new adversarial model,\ngoals, algorithm, and game-theoretic analysis. Beyond its direct implications\nfor operational blockchains, BDoS introduces the novel idea that an adversary\ncan manipulate miners' incentives by proving the existence of blocks without\nactually publishing them.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 16:55:14 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 21:23:34 GMT"}, {"version": "v3", "created": "Thu, 30 Jan 2020 14:05:32 GMT"}, {"version": "v4", "created": "Wed, 4 Nov 2020 21:48:52 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Mirkin", "Michael", ""], ["Ji", "Yan", ""], ["Pang", "Jonathan", ""], ["Klages-Mundt", "Ariah", ""], ["Eyal", "Ittay", ""], ["Juels", "Ari", ""]]}, {"id": "1912.07641", "submitter": "Yang Lu", "authors": "Yang Lu and Minghui Zhu", "title": "On privacy preserving data release of linear dynamic networks", "comments": "18 pages, 5 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed data sharing in dynamic networks is ubiquitous. It raises the\nconcern that the private information of dynamic networks could be leaked when\ndata receivers are malicious or communication channels are insecure. In this\npaper, we propose to intentionally perturb the inputs and outputs of a linear\ndynamic system to protect the privacy of target initial states and inputs from\nreleased outputs. We formulate the problem of perturbation design as an\noptimization problem which minimizes the cost caused by the added perturbations\nwhile maintaining system controllability and ensuring the privacy. We analyze\nthe computational complexity of the formulated optimization problem. To\nminimize the $\\ell_0$ and $\\ell_2$ norms of the added perturbations, we derive\ntheir convex relaxations which can be efficiently solved. The efficacy of the\nproposed techniques is verified by a case study on a heating, ventilation, and\nair conditioning system.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 19:11:20 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Lu", "Yang", ""], ["Zhu", "Minghui", ""]]}, {"id": "1912.07714", "submitter": "V\\'ictor Mayoral Vilches", "authors": "V\\'ictor Mayoral-Vilches, Lander Usategui San Juan, Unai Ayucar\n  Carbajo, Rub\\'en Campo, Xabier S\\'aez de C\\'amara, Oxel Urzelai, Nuria\n  Garc\\'ia and Endika Gil-Uriarte", "title": "Industrial robot ransomware: Akerbeltz", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybersecurity lessons have not been learnt from the dawn of other\ntechnological industries. In robotics, the existing insecurity landscape needs\nto be addressed immediately. Several manufacturers profiting from the lack of\ngeneral awareness are systematically ignoring their responsibilities by\nclaiming their insecure (open) systems facilitate system integration,\ndisregarding the safety, privacy and ethical consequences that their (lack of)\nactions have. In an attempt to raise awareness and illustrate the \"insecurity\nby design in robotics\" we have created Akerbeltz, the first known instance of\nindustrial robot ransomware. Our malware is demonstrated using a leading brand\nfor industrial collaborative robots, Universal Robots. We describe the\nrationale behind our target and discuss the general flow of the attack\nincluding the initial cyber-intrusion, lateral movement and later control\nphase. We urge security researchers to adopt some sort of disclosure policy\nthat forces manufacturers to react promptly. We advocate against security by\nobscurity and encourage the release of similar actions once vulnerability\nreports fall into a dead-end. Actions are now to be taken to abide a future\nfree of zero-days for robotics.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 21:39:16 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Mayoral-Vilches", "V\u00edctor", ""], ["Juan", "Lander Usategui San", ""], ["Carbajo", "Unai Ayucar", ""], ["Campo", "Rub\u00e9n", ""], ["de C\u00e1mara", "Xabier S\u00e1ez", ""], ["Urzelai", "Oxel", ""], ["Garc\u00eda", "Nuria", ""], ["Gil-Uriarte", "Endika", ""]]}, {"id": "1912.07742", "submitter": "Huy Phan", "authors": "Huy Phan, Yi Xie, Siyu Liao, Jie Chen, Bo Yuan", "title": "CAG: A Real-time Low-cost Enhanced-robustness High-transferability\n  Content-aware Adversarial Attack Generator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks (DNNs) are vulnerable to adversarial attack despite\ntheir tremendous success in many AI fields. Adversarial attack is a method that\ncauses the intended misclassfication by adding imperceptible perturbations to\nlegitimate inputs. Researchers have developed numerous types of adversarial\nattack methods. However, from the perspective of practical deployment, these\nmethods suffer from several drawbacks such as long attack generating time, high\nmemory cost, insufficient robustness and low transferability. We propose a\nContent-aware Adversarial Attack Generator (CAG) to achieve real-time,\nlow-cost, enhanced-robustness and high-transferability adversarial attack.\nFirst, as a type of generative model-based attack, CAG shows significant\nspeedup (at least 500 times) in generating adversarial examples compared to the\nstate-of-the-art attacks such as PGD and C\\&W. CAG only needs a single\ngenerative model to perform targeted attack to any targeted class. Because CAG\nencodes the label information into a trainable embedding layer, it differs from\nprior generative model-based adversarial attacks that use $n$ different copies\nof generative models for $n$ different targeted classes. As a result, CAG\nsignificantly reduces the required memory cost for generating adversarial\nexamples. CAG can generate adversarial perturbations that focus on the critical\nareas of input by integrating the class activation maps information in the\ntraining process, and hence improve the robustness of CAG attack against the\nstate-of-art adversarial defenses. In addition, CAG exhibits high\ntransferability across different DNN classifier models in black-box attack\nscenario by introducing random dropout in the process of generating\nperturbations. Extensive experiments on different datasets and DNN models have\nverified the real-time, low-cost, enhanced-robustness, and high-transferability\nbenefits of CAG.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 22:48:38 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Phan", "Huy", ""], ["Xie", "Yi", ""], ["Liao", "Siyu", ""], ["Chen", "Jie", ""], ["Yuan", "Bo", ""]]}, {"id": "1912.07824", "submitter": "Chao Li", "authors": "Chao Li and Balaji Palanisamy", "title": "SilentDelivery: Practical Timed-delivery of Private Information using\n  Smart Contracts", "comments": "This paper has been accepted by IEEE Transactions on Services\n  Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes SilentDelivery, a secure, scalable and cost-efficient\nprotocol for implementing timed information delivery service in a decentralized\nblockchain network. SilentDelivery employs a novel combination of threshold\nsecret sharing and decentralized smart contracts. The protocol maintains shares\nof the decryption key of the private information of an information sender using\na group of mailmen recruited in a blockchain network before the specified\nfuture time-frame and restores the information to the information recipient at\nthe required time-frame. To tackle the key challenges that limit the security\nand scalability of the protocol, SilentDelivery incorporates two novel\ncountermeasure strategies. The first strategy, namely silent recruitment,\nenables a mailman to get recruited by a sender silently without the knowledge\nof any third party. The second strategy, namely dual-mode execution, makes the\nprotocol run in a lightweight mode by default, where the cost of running smart\ncontracts is significantly reduced. We rigorously analyze the security of\nSilentDelivery and implement the protocol over the Ethereum official test\nnetwork. The results demonstrate that SilentDelivery is more secure and\nscalable compared to the state of the art and reduces the cost of running smart\ncontracts by 85%.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 05:22:16 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 07:53:00 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Li", "Chao", ""], ["Palanisamy", "Balaji", ""]]}, {"id": "1912.07860", "submitter": "Sicong Zhou", "authors": "Sicong Zhou, Huawei Huang, Wuhui Chen, Zibin Zheng, and Song Guo", "title": "PIRATE: A Blockchain-based Secure Framework of Distributed Machine\n  Learning in 5G Networks", "comments": "8 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the fifth-generation (5G) networks and the beyond, communication latency\nand network bandwidth will be no more bottleneck to mobile users. Thus, almost\nevery mobile device can participate in the distributed learning. That is, the\navailability issue of distributed learning can be eliminated. However, the\nmodel safety will become a challenge. This is because the distributed learning\nsystem is prone to suffering from byzantine attacks during the stages of\nupdating model parameters and aggregating gradients amongst multiple learning\nparticipants. Therefore, to provide the byzantine-resilience for distributed\nlearning in 5G era, this article proposes a secure computing framework based on\nthe sharding-technique of blockchain, namely PIRATE. A case-study shows how the\nproposed PIRATE contributes to the distributed learning. Finally, we also\nenvision some open issues and challenges based on the proposed\nbyzantine-resilient learning framework.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 08:01:36 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Zhou", "Sicong", ""], ["Huang", "Huawei", ""], ["Chen", "Wuhui", ""], ["Zheng", "Zibin", ""], ["Guo", "Song", ""]]}, {"id": "1912.07908", "submitter": "Micah Altman", "authors": "Micah Altman and Richard Landau", "title": "Selecting efficient and reliable preservation strategies: modeling\n  long-term information integrity using large-scale hierarchical discrete event\n  simulation", "comments": "Fortcoming IDCC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article addresses the problem of formulating efficient and reliable\noperational preservation policies that ensure bit-level information integrity\nover long periods, and in the presence of a diverse range of real-world\ntechnical, legal, organizational, and economic threats. We develop a\nsystematic, quantitative prediction framework that combines formal modeling,\ndiscrete-event-based simulation, hierarchical modeling, and then use\nempirically calibrated sensitivity analysis to identify effective strategies.\nThe framework offers flexibility for the modeling of a wide range of\npreservation policies and threats. Since this framework is open source and\neasily deployed in a cloud computing environment, it can be used to produce\nanalysis based on independent estimates of scenario-specific costs,\nreliability, and risks.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 10:05:50 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Altman", "Micah", ""], ["Landau", "Richard", ""]]}, {"id": "1912.07942", "submitter": "Santiago Zanella-Beguelin", "authors": "Marc Brockschmidt, Boris K\\\"opf, Olga Ohrimenko, Andrew Paverd, Victor\n  R\\\"uhle, Shruti Tople, Lukas Wutschitz, Santiago Zanella-B\\'eguelin", "title": "Analyzing Information Leakage of Updates to Natural Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To continuously improve quality and reflect changes in data, machine learning\napplications have to regularly retrain and update their core models. We show\nthat a differential analysis of language model snapshots before and after an\nupdate can reveal a surprising amount of detailed information about changes in\nthe training data. We propose two new metrics---differential score and\ndifferential rank---for analyzing the leakage due to updates of natural\nlanguage models. We perform leakage analysis using these metrics across models\ntrained on several different datasets using different methods and\nconfigurations. We discuss the privacy implications of our findings, propose\nmitigation strategies and evaluate their effect.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 11:46:08 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 13:28:16 GMT"}, {"version": "v3", "created": "Mon, 18 May 2020 21:41:35 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Brockschmidt", "Marc", ""], ["K\u00f6pf", "Boris", ""], ["Ohrimenko", "Olga", ""], ["Paverd", "Andrew", ""], ["R\u00fchle", "Victor", ""], ["Tople", "Shruti", ""], ["Wutschitz", "Lukas", ""], ["Zanella-B\u00e9guelin", "Santiago", ""]]}, {"id": "1912.08094", "submitter": "Uwe Roth", "authors": "Uwe Roth", "title": "Proof of file access in a private P2P network using blockchain", "comments": "16 pages, 7 figures, 1 listing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While sharing files in a peer-to-peer (P2P) system significantly increases\nboth the speed of retrieving the contents and the robustness of the system,\ntracing the access of files is not straightforward, even in the case of private\nP2P networks. In fact, a participant that has uploaded a file to a P2P network\nis not necessarily involved in its download. Additionally, due to the nature of\nthe P2P network it is possible for a participant to already have all the\nfragments of a file, even before requesting it.\n  This work tries to address the problem of tracing file access in a private\nP2P file sharing network through the use of blockchains to improve quality of\nservice and auditability. To this end, the proposed solution combines three\nelements: (1) A distributed hash table network that is used to distribute\nencrypted files with redundancy amongst the partner peers; (2) Shamir's secret\nsharing scheme to split the secret keys of each file; (3) A blockchain network\nto distribute and manage the secret shares amongst the partner peers. In fact,\nthe latter makes access to a file undeniable to every node of the network.\n  The solution is relevant for consortia that manage a shared data pool on base\nof P2P technology with unrestricted access to files but where access to a file\nhas to be recorded due to legal or billing reasons.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 15:57:34 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Roth", "Uwe", ""]]}, {"id": "1912.08191", "submitter": "Shakir Almasaari", "authors": "Shakir A. Almasaari", "title": "Securing Big Data systems, A cybersecurity management discussion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper explores the essential areas of cybersecurity management for big\ndata systems. Big data platform stems its complexity from being a collection of\ninterrelated non-standardized systems that interact with each other to process\nlarge data-sets. This complexity increases the chances of overlooking critical\ncybersecurity management practices. The paper discusses various security\nmanagement for each part of big data systems. This includes security measures,\nstandards, and methodologies. The primary objective is to highlight the\nessential segments of security management that are expected to be implemented\nflawlessly in big data systems.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 18:53:54 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Almasaari", "Shakir A.", ""]]}, {"id": "1912.08454", "submitter": "Yaxing Chen", "authors": "Yaxing Chen, Qinghua Zheng, Dan Liu, Zheng Yan, Wenhai Sun, Ning\n  Zhang, Wenjing Lou, Y. Thomas Hou", "title": "Enjoy the Untrusted Cloud: A Secure, Scalable and Efficient SQL-like\n  Query Framework for Outsourcing Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the security of the cloud remains a concern, a common practice is to\nencrypt data before outsourcing them for utilization. One key challenging issue\nis how to efficiently perform queries over the ciphertext. Conventional\ncrypto-based solutions, e.g. partially/fully homomorphic encryption and\nsearchable encryption, suffer from low performance, poor expressiveness and\nweak compatibility. An alternative method that utilizes hardware-assisted\ntrusted execution environment, i.e., Intel SGX, has emerged recently. On one\nhand, such work lacks of supporting scalable access control over multiple data\nusers. On the other hand, existing solutions are subjected to the key\nrevocation problem and knowledge extractor vulnerability. In this work, we\nleverage the newly hardware-assisted methodology and propose a secure, scalable\nand efficient SQL-like query framework named QShield. Building upon Intel SGX,\nQShield can guarantee the confidentiality and integrity of sensitive data when\nbeing processed on an untrusted cloud platform. Moreover, we present a novel\nlightweight secret sharing method to enable multi-user access control in\nQShield, while tackling the key revocation problem. Furthermore, with an\nadditional trust proof mechanism, QShield guarantees the correctness of queries\nand significantly alleviates the possibility to build a knowledge extractor. We\nimplemented a prototype for QShield and show that QShield incurs minimum\nperformance cost.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 08:54:51 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Chen", "Yaxing", ""], ["Zheng", "Qinghua", ""], ["Liu", "Dan", ""], ["Yan", "Zheng", ""], ["Sun", "Wenhai", ""], ["Zhang", "Ning", ""], ["Lou", "Wenjing", ""], ["Hou", "Y. Thomas", ""]]}, {"id": "1912.08573", "submitter": "Katharina Bogad", "authors": "Katharina Bogad and Manuel Huber", "title": "Harzer Roller: Linker-Based Instrumentation for Enhanced Embedded\n  Security Testing", "comments": "9 Pages, 7 Figures, ROOTS'19", "journal-ref": null, "doi": "10.1145/3375894.3375897", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the rise of the Internet of Things, there are many new chips and\nplatforms available for hobbyists and industry alike to build smart devices.\nThe SDKs for these new platforms usually include closed-source binaries\ncontaining wireless protocol implementations, cryptographic implementations, or\nother library functions, which are shared among all user code across the\nplatform. Leveraging such a library vulnerability has a high impact on a given\nplatform. However, as these platforms are often shipped ready-to-use, classic\ndebug infrastructure like JTAG is often times not available.\n  In this paper, we present a method, called Harzer Roller, to enhance embedded\nfirmware security testing on resource-constrained devices. With the Harzer\nRoller, we hook instrumentation code into function call and return. The hooking\nnot only applies to the user application code but to the SDK used to build\nfirmware as well. While we keep the design of the Harzer Rollergenerally\narchitecture independent, we provide an implementation for the ESP8266 Wi-Fi\nIoT chip based on the xtensa architecture.\n  We show that the Harzer Roller can be leveraged to trace execution flow\nthrough libraries without available source code and to detect stack-based\nbuffer-overflows. Additionally, we showcase how the overflow detection can be\nused to dump debugging information for later analysis. This enables better\nusage of a variety of software security testing methods like fuzzing of\nwireless protocol implementations or proof-of-concept attack development.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 12:55:15 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Bogad", "Katharina", ""], ["Huber", "Manuel", ""]]}, {"id": "1912.08590", "submitter": "Kushagra Singh", "authors": "Kushagra Singh, Gurshabad Grover, and Varun Bansal", "title": "How India Censors the Web", "comments": null, "journal-ref": null, "doi": "10.1145/3394231.3397891", "report-no": null, "categories": "cs.NI cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the primary ways in which India engages in online censorship is by\nordering Internet Service Providers (ISPs) operating in its jurisdiction to\nblock access to certain websites for its users. This paper reports the\ndifferent techniques Indian ISPs are using to censor websites, and investigates\nwhether website blocklists are consistent across ISPs. We propose a suite of\ntests that prove more robust than previous work in detecting DNS and HTTP based\ncensorship. Our tests also discern the use of SNI inspection for blocking\nwebsites, which is previously undocumented in the Indian context. Using\ninformation from court orders, user reports, and public and leaked government\norders, we compile the largest known list of potentially blocked websites in\nIndia. We pass this list to our tests and run them from connections of six\ndifferent ISPs, which together serve more than 98% of Internet users in India.\nOur findings not only confirm that ISPs are using different techniques to block\nwebsites, but also demonstrate that different ISPs are not blocking the same\nwebsites.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 13:32:53 GMT"}, {"version": "v2", "created": "Sat, 30 May 2020 12:31:39 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Singh", "Kushagra", ""], ["Grover", "Gurshabad", ""], ["Bansal", "Varun", ""]]}, {"id": "1912.08677", "submitter": "Nicholas Bornman Mr", "authors": "Nicholas Bornman, Andrew Forbes and Achim Kempf", "title": "Random number generation & distribution out of thin (or thick) air", "comments": "18 pages, 9 figures", "journal-ref": "J. Opt. 22 075705 (2020)", "doi": "10.1088/2040-8986/ab9513", "report-no": null, "categories": "physics.class-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much scientific work has focused on the generation of random numbers as well\nas the distribution of said random numbers for use as a cryptographic key.\nHowever, emphasis is often placed on one of the two to the exclusion of the\nother, but both are often simultaneously important. Here we present a simple\nhybrid free-space link scheme for both the generation and secure distribution\nof (pseudo-)random numbers between two remote parties, drawing the randomness\nfrom the stochastic nature of atmospheric turbulence. The atmosphere is\nsimulated using digital micro-mirror devices for efficient, all-digital\ncontrol. After outlining one potential algorithm for extracting random numbers\nbased on finding the centre-of-mass (COM) of turbulent beam intensity profiles,\nthe statistics of our experimental COM measurements is studied and found to\nagree well with the literature. After implementing the scheme in the\nlaboratory, Alice and Bob are able to establish a string of correlated random\nbits with an 84% fidelity. Finally, we make a simple modification to the\noriginal setup in an attempt to thwart the hacking attempts of an eavesdropper,\nEve, who has access to the free-space portion of the link. We find that the\nfidelity between Eve's key and that of Alice/Bob is 54%, only slightly above\nthe theoretical minimum. Atmospheric turbulence could hence be leveraged as an\nadded security measure, rather than being seen as a drawback.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 09:11:12 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 12:13:31 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Bornman", "Nicholas", ""], ["Forbes", "Andrew", ""], ["Kempf", "Achim", ""]]}, {"id": "1912.08788", "submitter": "Lesly-Ann Daniel", "authors": "Lesly-Ann Daniel, S\\'ebastien Bardin, Tamara Rezk", "title": "Binsec/Rel: Efficient Relational Symbolic Execution for Constant-Time at\n  Binary-Level", "comments": "18 pages, 7 figures, accepted at IEEE Symposium on Security and\n  Privacy 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The constant-time programming discipline (CT) is an efficient countermeasure\nagainst timing side-channel attacks, requiring the control flow and the memory\naccesses to be independent from the secrets. Yet, writing CT code is\nchallenging as it demands to reason about pairs of execution traces (2-\nhypersafety property) and it is generally not preserved by the compiler,\nrequiring binary-level analysis. Unfortunately, current verification tools for\nCT either reason at higher level (C or LLVM), or sacrifice bug-finding or\nbounded-verification, or do not scale. We tackle the problem of designing an\nefficient binary-level verification tool for CT providing both bug-finding and\nbounded-verification. The technique builds on relational symbolic execution\nenhanced with new optimizations dedicated to information flow and binary-level\nanalysis, yielding a dramatic improvement over prior work based on symbolic\nexecution. We implement a prototype, Binsec/Rel, and perform extensive\nexperiments on a set of 338 cryptographic implementations, demonstrating the\nbenefits of our approach in both bug-finding and bounded-verification. Using\nBinsec/Rel, we also automate a previous manual study of CT preservation by\ncompilers. Interestingly, we discovered that gcc -O0 and backend passes of\nclang introduce violations of CT in implementations that were previously deemed\nsecure by a state-of-the-art CT verification tool operating at LLVM level,\nshowing the importance of reasoning at binary-level.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 18:41:34 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 21:20:29 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Daniel", "Lesly-Ann", ""], ["Bardin", "S\u00e9bastien", ""], ["Rezk", "Tamara", ""]]}, {"id": "1912.08939", "submitter": "Claude Cr\\'epeau", "authors": "Claude Cr\\'epeau, Arnaud Massenet, Louis Salvail, Lucas Stinchcombe\n  and Nan Yang", "title": "Practical Relativistic Zero-Knowledge for NP", "comments": "Submitted to ITC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we consider the following problem: in a Multi-Prover\nenvironment, how close can we get to prove the validity of an NP statement in\nZero-Knowledge ? We exhibit a set of two novel Zero-Knowledge protocols for the\n3-COLorability problem that use two (local) provers or three (entangled)\nprovers and only require them to reply two trits each. This greatly improves\nthe ability to prove Zero-Knowledge statements on very short distances with\nvery minimal equipment.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 23:13:27 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Cr\u00e9peau", "Claude", ""], ["Massenet", "Arnaud", ""], ["Salvail", "Louis", ""], ["Stinchcombe", "Lucas", ""], ["Yang", "Nan", ""]]}, {"id": "1912.08951", "submitter": "Amos Beimel", "authors": "Amos Beimel, Aleksandra Korolova, Kobbi Nissim, Or Sheffet, Uri\n  Stemmer", "title": "The power of synergy in differential privacy: Combining a small curator\n  with local randomizers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the desire to bridge the utility gap between local and trusted\ncurator models of differential privacy for practical applications, we initiate\nthe theoretical study of a hybrid model introduced by \"Blender\" [Avent et al.,\\\nUSENIX Security '17], in which differentially private protocols of n agents\nthat work in the local-model are assisted by a differentially private curator\nthat has access to the data of m additional users. We focus on the regime where\nm << n and study the new capabilities of this (m,n)-hybrid model. We show that,\ndespite the fact that the hybrid model adds no significant new capabilities for\nthe basic task of simple hypothesis-testing, there are many other tasks (under\na wide range of parameters) that can be solved in the hybrid model yet cannot\nbe solved either by the curator or by the local-users separately. Moreover, we\nexhibit additional tasks where at least one round of interaction between the\ncurator and the local-users is necessary -- namely, no hybrid model protocol\nwithout such interaction can solve these tasks. Taken together, our results\nshow that the combination of the local model with a small curator can become\npart of a promising toolkit for designing and implementing differential\nprivacy.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 23:49:11 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 17:49:55 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Beimel", "Amos", ""], ["Korolova", "Aleksandra", ""], ["Nissim", "Kobbi", ""], ["Sheffet", "Or", ""], ["Stemmer", "Uri", ""]]}, {"id": "1912.08987", "submitter": "Nicholas Roberts", "authors": "Nicholas Roberts, Vinay Uday Prabhu, Matthew McAteer", "title": "Model Weight Theft With Just Noise Inputs: The Curious Case of the\n  Petulant Attacker", "comments": "Presented at the Security and Privacy of Machine Learning Workshop,\n  36th International Conference on Machine Learning (ICML 2019), Long Beach,\n  California, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the scenarios under which an attacker can claim that\n'Noise and access to the softmax layer of the model is all you need' to steal\nthe weights of a convolutional neural network whose architecture is already\nknown. We were able to achieve 96% test accuracy using the stolen MNIST model\nand 82% accuracy using the stolen KMNIST model learned using only i.i.d.\nBernoulli noise inputs. We posit that this theft-susceptibility of the weights\nis indicative of the complexity of the dataset and propose a new metric that\ncaptures the same. The goal of this dissemination is to not just showcase how\nfar knowing the architecture can take you in terms of model stealing, but to\nalso draw attention to this rather idiosyncratic weight learnability aspects of\nCNNs spurred by i.i.d. noise input. We also disseminate some initial results\nobtained with using the Ising probability distribution in lieu of the i.i.d.\nBernoulli distribution.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 01:59:59 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Roberts", "Nicholas", ""], ["Prabhu", "Vinay Uday", ""], ["McAteer", "Matthew", ""]]}, {"id": "1912.09034", "submitter": "Xiaojuan Dong", "authors": "Xiaojuan Dong, Weiming Zhang, Mohsin Shah, Bei Wang, Nenghai Yu", "title": "A Restrained Paillier Cryptosystem and Its Applications for Access\n  Control of Common Secret", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The modified Paillier cryptosystem has become extremely popular and applied\nin many fields, owning to its additive homomorphism. This cryptosystem provides\nweak private keys and a strong private key. A weak private key only can decrypt\nciphertexts under the corresponding public key. The strong private key can\ndecrypt all ciphertexts even under different public keys. When the modified\nPaillier cryptosystem is applied in a system, the member, often the system\nadministrator, has the strong private key and can decrypt all ciphertexts. If\nthis system administrator is attacked or compromised, the security of the\napplication system absolutely break down. Thus, it is important to stop the\ndecryption of the strong private key. To address this issue, we propose an\nrestrained version of the modified Paillier cryptosystem (Restrained-Paillier),\nby endowing the multiplicative homomorphism. We perform the additive encryption\non the multiplicative ciphertext and generate the mixed ciphertext, which can\nnot be decrypted by the strong private key. Based on this Restrained-Paillier,\nwe develop two applications. Firstly, we realize access control of common\nsecret of two owners. In our scheme, only one owner cannot access secret.\nSecondly, we present three protocols for identity distribution and key\nmanagement, identity authentication and private key recovery. Security analysis\nshows that the Restrained-Paillier cryptosystem can resist the chosen plaintext\nattack. The experimental results illustrate the utility and efficiency of the\nproposed protocols.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 06:50:53 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Dong", "Xiaojuan", ""], ["Zhang", "Weiming", ""], ["Shah", "Mohsin", ""], ["Wang", "Bei", ""], ["Yu", "Nenghai", ""]]}, {"id": "1912.09059", "submitter": "Mahmood Sharif", "authors": "Mahmood Sharif, Lujo Bauer, Michael K. Reiter", "title": "$n$-ML: Mitigating Adversarial Examples via Ensembles of Topologically\n  Manipulated Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes a new defense called $n$-ML against adversarial examples,\ni.e., inputs crafted by perturbing benign inputs by small amounts to induce\nmisclassifications by classifiers. Inspired by $n$-version programming, $n$-ML\ntrains an ensemble of $n$ classifiers, and inputs are classified by a vote of\nthe classifiers in the ensemble. Unlike prior such approaches, however, the\nclassifiers in the ensemble are trained specifically to classify adversarial\nexamples differently, rendering it very difficult for an adversarial example to\nobtain enough votes to be misclassified. We show that $n$-ML roughly retains\nthe benign classification accuracies of state-of-the-art models on the MNIST,\nCIFAR10, and GTSRB datasets, while simultaneously defending against adversarial\nexamples with better resilience than the best defenses known to date and, in\nmost cases, with lower classification-time overhead.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 08:24:07 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Sharif", "Mahmood", ""], ["Bauer", "Lujo", ""], ["Reiter", "Michael K.", ""]]}, {"id": "1912.09064", "submitter": "Mahmood Sharif", "authors": "Mahmood Sharif, Keane Lucas, Lujo Bauer, Michael K. Reiter, Saurabh\n  Shintre", "title": "Optimization-Guided Binary Diversification to Mislead Neural Networks\n  for Malware Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Motivated by the transformative impact of deep neural networks (DNNs) on\ndifferent areas (e.g., image and speech recognition), researchers and\nanti-virus vendors are proposing end-to-end DNNs for malware detection from raw\nbytes that do not require manual feature engineering. Given the security\nsensitivity of the task that these DNNs aim to solve, it is important to assess\ntheir susceptibility to evasion.\n  In this work, we propose an attack that guides binary-diversification tools\nvia optimization to mislead DNNs for malware detection while preserving the\nfunctionality of binaries. Unlike previous attacks on such DNNs, ours\nmanipulates instructions that are a functional part of the binary, which makes\nit particularly challenging to defend against. We evaluated our attack against\nthree DNNs in white-box and black-box settings, and found that it can often\nachieve success rates near 100%. Moreover, we found that our attack can fool\nsome commercial anti-viruses, in certain cases with a success rate of 85%. We\nexplored several defenses, both new and old, and identified some that can\nsuccessfully prevent over 80% of our evasion attempts. However, these defenses\nmay still be susceptible to evasion by adaptive attackers, and so we advocate\nfor augmenting malware-detection systems with methods that do not rely on\nmachine learning.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 08:41:16 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Sharif", "Mahmood", ""], ["Lucas", "Keane", ""], ["Bauer", "Lujo", ""], ["Reiter", "Michael K.", ""], ["Shintre", "Saurabh", ""]]}, {"id": "1912.09150", "submitter": "Jun Zhao", "authors": "Zhiying Xu, Shuyu Shi, Alex X. Liu, Jun Zhao, Lin Chen", "title": "An Adaptive and Fast Convergent Approach to Differentially Private Deep\n  Learning", "comments": "This full paper appears in the Proceedings of IEEE International\n  Conference on Computer Communications (INFOCOM), held in April 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of the era of big data, deep learning has become a prevalent\nbuilding block in a variety of machine learning or data mining tasks, such as\nsignal processing, network modeling and traffic analysis, to name a few. The\nmassive user data crowdsourced plays a crucial role in the success of deep\nlearning models. However, it has been shown that user data may be inferred from\ntrained neural models and thereby exposed to potential adversaries, which\nraises information security and privacy concerns. To address this issue, recent\nstudies leverage the technique of differential privacy to design\nprivate-preserving deep learning algorithms. Albeit successful at privacy\nprotection, differential privacy degrades the performance of neural models. In\nthis paper, we develop ADADP, an adaptive and fast convergent learning\nalgorithm with a provable privacy guarantee. ADADP significantly reduces the\nprivacy cost by improving the convergence speed with an adaptive learning rate\nand mitigates the negative effect of differential privacy upon the model\naccuracy by introducing adaptive noise. The performance of ADADP is evaluated\non real-world datasets. Experiment results show that it outperforms\nstate-of-the-art differentially private approaches in terms of both privacy\ncost and model accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 12:02:58 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Xu", "Zhiying", ""], ["Shi", "Shuyu", ""], ["Liu", "Alex X.", ""], ["Zhao", "Jun", ""], ["Chen", "Lin", ""]]}, {"id": "1912.09264", "submitter": "Yang Li", "authors": "Yang Li and Hongbo Li", "title": "Improved quantum algorithm for the random subset sum problem", "comments": "arXiv admin note: text overlap with arXiv:1907.04295 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving random subset sum instances plays an important role in constructing\ncryptographic systems. For the random subset sum problem, in 2013 Bernstein et\nal. proposed a quantum algorithm with heuristic time complexity\n$\\widetilde{O}(2^{0.241n})$, where the \"$\\widetilde{O}$\" symbol is used to omit\npoly($\\log n$) factors. In 2018, Helm and May proposed another quantum\nalgorithm that reduces the heuristic time and memory complexity to\n$\\widetilde{O}(2^{0.226n})$. In this paper, a new quantum algorithm is\nproposed, with heuristic time and memory complexity\n$\\widetilde{O}(2^{0.209n})$.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 05:51:03 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 18:17:30 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Li", "Yang", ""], ["Li", "Hongbo", ""]]}, {"id": "1912.09280", "submitter": "Marcus Edwards", "authors": "Marcus Edwards (1), Atefeh Mashatan (2), Shohini Ghose (3, 1) ((1)\n  Institute for Quantum Computing, University of Waterloo, Canada, (2) School\n  of Information Technology Management, Ryerson University, Toronto, Canada,\n  (3) Department of Physics and Computer Science, Wilfrid Laurier University,\n  Waterloo, Canada)", "title": "A Review of Quantum and Hybrid Quantum / Classical Blockchain Protocols", "comments": "27 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain technology is facing critical issues of scalability, efficiency\nand sustainability. These problems are necessary to solve if blockchain is to\nbecome a technology that can be used responsibly. Useful quantum computers\ncould potentially be developed by the time that blockchain will be widely\nimplemented for mission-critical work at financial and other institutions.\nQuantum computing will not only cause challenges for blockchain, but can also\nbe harnessed to better implement parts of blockchain technologies including\ncryptocurrencies. We review the work that has been done in the area of quantum\nblockchain and hybrid quantum-classical blockchain technology and discuss open\nquestions that remain.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 21:38:43 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Edwards", "Marcus", ""], ["Mashatan", "Atefeh", ""], ["Ghose", "Shohini", ""]]}, {"id": "1912.09303", "submitter": "Simon Msika", "authors": "Simon Msika, Alejandro Quintero, Foutse Khomh", "title": "SIGMA : Strengthening IDS with GAN and Metaheuristics Attacks", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An Intrusion Detection System (IDS) is a key cybersecurity tool for network\nadministrators as it identifies malicious traffic and cyberattacks. With the\nrecent successes of machine learning techniques such as deep learning, more and\nmore IDS are now using machine learning algorithms to detect attacks faster.\nHowever, these systems lack robustness when facing previously unseen types of\nattacks. With the increasing number of new attacks, especially against Internet\nof Things devices, having a robust IDS able to spot unusual and new attacks\nbecomes necessary.\n  This work explores the possibility of leveraging generative adversarial\nmodels to improve the robustness of machine learning based IDS. More\nspecifically, we propose a new method named SIGMA, that leverages adversarial\nexamples to strengthen IDS against new types of attacks. Using Generative\nAdversarial Networks (GAN) and metaheuristics, SIGMA %Our method consists in\ngenerates adversarial examples, iteratively, and uses it to retrain a machine\nlearning-based IDS, until a convergence of the detection rate (i.e. until the\ndetection system is not improving anymore). A round of improvement consists of\na generative phase, in which we use GANs and metaheuristics to generate\ninstances ; an evaluation phase in which we calculate the detection rate of\nthose newly generated attacks ; and a training phase, in which we train the IDS\nwith those attacks. We have evaluated the SIGMA method for four standard\nmachine learning classification algorithms acting as IDS, with a combination of\nGAN and a hybrid local-search and genetic algorithm, to generate new datasets\nof attacks. Our results show that SIGMA can successfully generate adversarial\nattacks against different machine learning based IDS. Also, using SIGMA, we can\nimprove the performance of an IDS to up to 100\\% after as little as two rounds\nof improvement.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 15:35:38 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Msika", "Simon", ""], ["Quintero", "Alejandro", ""], ["Khomh", "Foutse", ""]]}, {"id": "1912.09555", "submitter": "Rene Pickhardt", "authors": "Rene Pickhardt, Mariusz Nowostawski", "title": "Imbalance measure and proactive channel rebalancing algorithm for the\n  Lightning Network", "comments": "8 Pages + references. 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Making a payment in a privacy-aware payment channel network is achieved by\ntrying several payment paths until one succeeds. With a large network, such as\nthe Lightning Network, a completion of a single payment can take up to several\nminutes. We introduce a network imbalance measure and formulate the\noptimization problem of improving the balance of the network as a sequence of\nrebalancing operations of the funds within the channels along circular paths\nwithin the network. As the funds and balances of channels are not globally\nknown, we introduce a greedy heuristic with which every node despite the\nuncertainty can improve its own local balance. In an empirical simulation on a\nrecent snapshot of the Lightning Network we demonstrate that the imbalance\ndistribution of the network has a Kolmogorov-Smirnoff distance of 0.74 in\ncomparison to the imbalance distribution after the heuristic is applied. We\nfurther show that the success rate of a single unit payment increases from\n11.2% on the imbalanced network to 98.3% in the balanced network. Similarly,\nthe median possible payment size across all pairs of participants increases\nfrom 0 to 0.5 mBTC for initial routing attempts on the cheapest possible path.\nWe provide an empirical evidence that routing fees should be dropped for\nproactive rebalancing operations. Executing 4 different strategies for\nselecting rebalancing cycles lead to similar results indicating that a\ncollaborative approach within the friend of a friend network might be\npreferable from a practical point of view\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 21:42:55 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Pickhardt", "Rene", ""], ["Nowostawski", "Mariusz", ""]]}, {"id": "1912.09556", "submitter": "Mubashar Iqbal", "authors": "Mubashar Iqbal, Raimundas Matulevicius", "title": "Blockchain-based Application Security Risks: A Systematic Literature\n  Review", "comments": "12 pages, 7 tables, 0 figures", "journal-ref": null, "doi": "10.1007/978-3-030-20948-3_16", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the blockchain-based applications are considered to be less\nvulnerable due to the nature of the distributed ledger, they did not become the\nsilver bullet with respect to securing the information against different\nsecurity risks. In this paper, we present a literature review on the security\nrisks that can be mitigated by introducing the blockchain technology, and on\nthe security risks that are identified in the blockchain-based applications. In\naddition, we highlight the application and technology domains where these\nsecurity risks are observed. The results of this study could be seen as a\npreliminary checklist of security risks when implementing blockchain-based\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 21:43:15 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Iqbal", "Mubashar", ""], ["Matulevicius", "Raimundas", ""]]}, {"id": "1912.09734", "submitter": "Christian Gorke", "authors": "Christian A. Gorke, Frederik Armknecht", "title": "Reverse Fingerprinting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software connected to the Internet is an attractive target for attackers: as\nsoon as a security flaw is known, services may be taken under attack. In\ncontrast, software developers release updates to add further features and fix\nflaws in order to increase its security. Consequently, a user of the software\nwants to have the latest secure version running. However, if the software is\nprovided as a service, e.g., as part of the cloud, the user relies on the\nservice provider (SP) to perform such updates. But when asking for the software\nversion, the user has to trust the output of SP or his software. Latter may be\nmalformed, since updating software costs time and money, i.e., in comparison to\nchanging a (false) version string. Now the question rises how a software\nservice's client can provably determine the real software version of the\nrunning service at the SP, also known as Remote Software Identification (RSI).\nWhile existing tools provide an answer, they can be tricked by the service to\noutput any forged string because they rely on the information handed directly\nby the SP. We solve the problem of RSI by introducing Reverse Fingerprinting\n(RFP), a novel challenge-response scheme which employs the evaluation of\ninherit functions of software versions depending on certain inputs. That is,\nRFP does not rely on version number APIs but employs a database consisting of\nfunction inputs and according outputs and combines them with a strategy and a\nrandomness source to provably determine the version number. We also provide a\ntheoretical framework for RSI and RFP, and describe how to create databases and\nstrategies. Additionally, RFP can be securely outsourced to a third party,\ncalled the auditor, to take away the burden of the user while respecting\nliability. We also provide an implementation and API to perform RFP in\npractice, showing that most of the providers have installed the latest\nversions.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 10:13:35 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Gorke", "Christian A.", ""], ["Armknecht", "Frederik", ""]]}, {"id": "1912.09773", "submitter": "Roben Castagna Lunardi", "authors": "Roben Castagna Lunardi and Henry Cabral Nunes and Vinicius da Silva\n  Branco and Bruno Hugentobler Lipper and Charles Varlei Neu and Avelino\n  Francisco Zorzo", "title": "Performance and Cost Evaluation of Smart Contracts in Collaborative\n  Health Care Environments", "comments": "Presented at ICITST 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain emerged as a solution for data integrity, non-repudiation, and\navailability in different applications. Data sensitive scenarios, such as\nHealth Care, can also benefit from these blockchain properties. Consequently,\ndifferent research proposed the adoption of blockchain in Health Care\napplications. However, few are discussed about incentive methods to attract new\nusers, as well as to motivate the system or application usage by existing\nend-users. Also, little is discussed about performance during code execution in\nblockchains. In order to tackle these issues, this work presents the\npreliminary evaluation of TokenHealth, an application for collaborative health\npractice monitoring with gamification and token-based incentives. The proposed\nsolution is implemented through smart contracts using Solidity in the Ethereum\nblockchain. We evaluated the performance of both in Ropsten test network and in\na Private instance. The preliminary results show that the execution of smart\ncontracts takes less than a minute for a full cycle of different smart\ncontracts. Also, we present a discussion about costs for using a Private\ninstance and the public Ethereum main network.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 11:34:47 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Lunardi", "Roben Castagna", ""], ["Nunes", "Henry Cabral", ""], ["Branco", "Vinicius da Silva", ""], ["Lipper", "Bruno Hugentobler", ""], ["Neu", "Charles Varlei", ""], ["Zorzo", "Avelino Francisco", ""]]}, {"id": "1912.09779", "submitter": "Roben Castagna Lunardi", "authors": "Daniel Dalalana Bertoglio and Guilherme Girotto and Charles Varlei Neu\n  and Roben Castagna Lunardi and and Avelino Francisco Zorzo", "title": "Pentest on an Internet Mobile App: A Case Study using Tramonto", "comments": "ICITST 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile applications are used to handle different types of data. Commonly,\nthere is a set of personal identifiable information present in the data stored,\nshared and used by these applications. From that, attackers can try to exploit\nthe mobile application in order to obtain or to cause private data leakage.\nTherefore, performing security assessments is an important practice to find\nvulnerabilities in the applications and systems before the application is\ndeployed, or even during their use. Regarding security assessments, Penetration\nTest (Pentest) is one of the security test types that can be used to detect\nvulnerabilities through simulated attacks. Additionally, Pentest can be\nperformed using different methodologies and best practices, through several\nframeworks to: organize the test execution, execute tools, provide estimations,\nprovide reports and document a Pentest. One such framework is Tramonto, which\naims to assist a cybersecurity expert during the Pentest execution by providing\norganization, standardization and flexibility to the whole Pentest process.\nThis paper presents a Pentest case study applied to a Brazilian university\nMobile App using the Tramonto framework. The main goal of this case study is to\npresent how Tramonto can be applied during a Pentest execution, assisting\ncybersecurity experts in the tasks included in the Pentest process. Our results\nshow details on how to perform a Pentest using Tramonto and the found\nvulnerabilities in the Mobile App. Besides that, there is a discussion about\nthe main contributions obtained from our results, and we were able to verify\nthat Tramonto managed, organized and optimized the whole Pentest process.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 11:51:22 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Bertoglio", "Daniel Dalalana", ""], ["Girotto", "Guilherme", ""], ["Neu", "Charles Varlei", ""], ["Lunardi", "Roben Castagna", ""], ["Zorzo", "and Avelino Francisco", ""]]}, {"id": "1912.09855", "submitter": "Maximilian Bachl", "authors": "Alexander Hartl, Maximilian Bachl, Joachim Fabini, Tanja Zseby", "title": "Explainability and Adversarial Robustness for RNNs", "comments": "Accepted at IEEE BigDataService 2020", "journal-ref": "2020 IEEE Sixth International Conference on Big Data Computing\n  Service and Applications (BigDataService)", "doi": "10.1109/BigDataService49289.2020.00030", "report-no": null, "categories": "cs.LG cs.CR cs.NI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recurrent Neural Networks (RNNs) yield attractive properties for constructing\nIntrusion Detection Systems (IDSs) for network data. With the rise of\nubiquitous Machine Learning (ML) systems, malicious actors have been catching\nup quickly to find new ways to exploit ML vulnerabilities for profit. Recently\ndeveloped adversarial ML techniques focus on computer vision and their\napplicability to network traffic is not straightforward: Network packets expose\nfewer features than an image, are sequential and impose several constraints on\ntheir features.\n  We show that despite these completely different characteristics, adversarial\nsamples can be generated reliably for RNNs. To understand a classifier's\npotential for misclassification, we extend existing explainability techniques\nand propose new ones, suitable particularly for sequential data. Applying them\nshows that already the first packets of a communication flow are of crucial\nimportance and are likely to be targeted by attackers. Feature importance\nmethods show that even relatively unimportant features can be effectively\nabused to generate adversarial samples. Since traditional evaluation metrics\nsuch as accuracy are not sufficient for quantifying the adversarial threat, we\npropose the Adversarial Robustness Score (ARS) for comparing IDSs, capturing a\ncommon notion of adversarial robustness, and show that an adversarial training\nprocedure can significantly and successfully reduce the attack surface.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 14:47:09 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 13:23:07 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Hartl", "Alexander", ""], ["Bachl", "Maximilian", ""], ["Fabini", "Joachim", ""], ["Zseby", "Tanja", ""]]}, {"id": "1912.09882", "submitter": "Qusay Mahmoud", "authors": "Nathaniel Aldred, Luke Baal, Graeham Broda, Steven Trumble, Qusay H.\n  Mahmoud", "title": "Design and Implementation of a Blockchain-based Consent Management\n  System", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A blockchain is a distributed ledger forming a distributed consensus on a\nhistory of transactions. It is the underlying technology for the Bitcoin\ncryptocurrency, but there are many applications beyond the financial sector.\nWith built-in security and removal of the need for third party trust,\nblockchain has started to see some use within contract applications among other\nthings. In this paper, we present the design and implementation of a\npermissioned-based blockchain third party consent management system, whose\npolicy can be decided by a government agency. We have constructed a proof of\nconcept implementation using Hyperledger Fabric to provide a service that\nallows end-users to control and consent to who manages their private\ninformation. We believe our solution meets the guiding principles of EU General\nData Protection Regulation or GDPR. While our performance and usability\nevaluation are limited, our solution design and its implementation meet the 7\nfoundational principles of privacy by design.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 15:29:23 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Aldred", "Nathaniel", ""], ["Baal", "Luke", ""], ["Broda", "Graeham", ""], ["Trumble", "Steven", ""], ["Mahmoud", "Qusay H.", ""]]}, {"id": "1912.09899", "submitter": "Jinyuan Jia", "authors": "Jinyuan Jia, Xiaoyu Cao, Binghui Wang, Neil Zhenqiang Gong", "title": "Certified Robustness for Top-k Predictions against Adversarial\n  Perturbations via Randomized Smoothing", "comments": "ICLR 2020, code is available at this:\n  https://github.com/jjy1994/Certify_Topk", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that classifiers are vulnerable to adversarial\nperturbations. To defend against adversarial perturbations, various certified\nrobustness results have been derived. However, existing certified robustnesses\nare limited to top-1 predictions. In many real-world applications, top-$k$\npredictions are more relevant. In this work, we aim to derive certified\nrobustness for top-$k$ predictions. In particular, our certified robustness is\nbased on randomized smoothing, which turns any classifier to a new classifier\nvia adding noise to an input example. We adopt randomized smoothing because it\nis scalable to large-scale neural networks and applicable to any classifier. We\nderive a tight robustness in $\\ell_2$ norm for top-$k$ predictions when using\nrandomized smoothing with Gaussian noise. We find that generalizing the\ncertified robustness from top-1 to top-$k$ predictions faces significant\ntechnical challenges. We also empirically evaluate our method on CIFAR10 and\nImageNet. For example, our method can obtain an ImageNet classifier with a\ncertified top-5 accuracy of 62.8\\% when the $\\ell_2$-norms of the adversarial\nperturbations are less than 0.5 (=127/255). Our code is publicly available at:\n\\url{https://github.com/jjy1994/Certify_Topk}.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 15:54:51 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Jia", "Jinyuan", ""], ["Cao", "Xiaoyu", ""], ["Wang", "Binghui", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "1912.10013", "submitter": "Battista Biggio", "authors": "Marco Melis and Ambra Demontis and Maura Pintor and Angelo Sotgiu and\n  Battista Biggio", "title": "secml: A Python Library for Secure and Explainable Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present secml, an open-source Python library for secure and explainable\nmachine learning. It implements the most popular attacks against machine\nlearning, including not only test-time evasion attacks to generate adversarial\nexamples against deep neural networks, but also training-time poisoning attacks\nagainst support vector machines and many other algorithms. These attacks enable\nevaluating the security of learning algorithms and of the corresponding\ndefenses under both white-box and black-box threat models. To this end, secml\nprovides built-in functions to compute security evaluation curves, showing how\nquickly classification performance decreases against increasing adversarial\nperturbations of the input data. secml also includes explainability methods to\nhelp understand why adversarial attacks succeed against a given model, by\nvisualizing the most influential features and training prototypes contributing\nto each decision. It is distributed under the Apache License 2.0, and hosted at\nhttps://gitlab.com/secml/secml.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 18:41:37 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Melis", "Marco", ""], ["Demontis", "Ambra", ""], ["Pintor", "Maura", ""], ["Sotgiu", "Angelo", ""], ["Biggio", "Battista", ""]]}, {"id": "1912.10070", "submitter": "Jonathan Lwowski", "authors": "Isaac Corley, Jonathan Lwowski, and Justin Hoffman", "title": "Destruction of Image Steganography using Generative Adversarial Networks", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR cs.LG eess.IV eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Digital image steganalysis, or the detection of image steganography, has been\nstudied in depth for years and is driven by Advanced Persistent Threat (APT)\ngroups', such as APT37 Reaper, utilization of steganographic techniques to\ntransmit additional malware to perform further post-exploitation activity on a\ncompromised host. However, many steganalysis algorithms are constrained to work\nwith only a subset of all possible images in the wild or are known to produce a\nhigh false positive rate. This results in blocking any suspected image being an\nunreasonable policy. A more feasible policy is to filter suspicious images\nprior to reception by the host machine. However, how does one optimally filter\nspecifically to obfuscate or remove image steganography while avoiding\ndegradation of visual image quality in the case that detection of the image was\na false positive? We propose the Deep Digital Steganography Purifier (DDSP), a\nGenerative Adversarial Network (GAN) which is optimized to destroy\nsteganographic content without compromising the perceptual quality of the\noriginal image. As verified by experimental results, our model is capable of\nproviding a high rate of destruction of steganographic image content while\nmaintaining a high visual quality in comparison to other state-of-the-art\nfiltering methods. Additionally, we test the transfer learning capability of\ngeneralizing to to obfuscate real malware payloads embedded into different\nimage file formats and types using an unseen steganographic algorithm and prove\nthat our model can in fact be deployed to provide adequate results.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 19:23:32 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Corley", "Isaac", ""], ["Lwowski", "Jonathan", ""], ["Hoffman", "Justin", ""]]}, {"id": "1912.10185", "submitter": "Alvin Chan", "authors": "Alvin Chan, Yi Tay, Yew Soon Ong, Jie Fu", "title": "Jacobian Adversarially Regularized Networks for Robustness", "comments": "ICLR 2020 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial examples are crafted with imperceptible perturbations with the\nintent to fool neural networks. Against such attacks, adversarial training and\nits variants stand as the strongest defense to date. Previous studies have\npointed out that robust models that have undergone adversarial training tend to\nproduce more salient and interpretable Jacobian matrices than their non-robust\ncounterparts. A natural question is whether a model trained with an objective\nto produce salient Jacobian can result in better robustness. This paper answers\nthis question with affirmative empirical results. We propose Jacobian\nAdversarially Regularized Networks (JARN) as a method to optimize the saliency\nof a classifier's Jacobian by adversarially regularizing the model's Jacobian\nto resemble natural training images. Image classifiers trained with JARN show\nimproved robust accuracy compared to standard models on the MNIST, SVHN and\nCIFAR-10 datasets, uncovering a new angle to boost robustness without using\nadversarial training examples.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 02:46:50 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 08:06:12 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Chan", "Alvin", ""], ["Tay", "Yi", ""], ["Ong", "Yew Soon", ""], ["Fu", "Jie", ""]]}, {"id": "1912.10190", "submitter": "Sajjad Arshad", "authors": "Seyed Ali Mirheidari, Sajjad Arshad, Kaan Onarlioglu, Bruno Crispo,\n  Engin Kirda, William Robertson", "title": "Cached and Confused: Web Cache Deception in the Wild", "comments": "USENIX Security Symposium, Boston, MA, USA, August 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web cache deception (WCD) is an attack proposed in 2017, where an attacker\ntricks a caching proxy into erroneously storing private information transmitted\nover the Internet and subsequently gains unauthorized access to that cached\ndata. Due to the widespread use of web caches and, in particular, the use of\nmassive networks of caching proxies deployed by content distribution network\n(CDN) providers as a critical component of the Internet, WCD puts a substantial\npopulation of Internet users at risk. We present the first large-scale study\nthat quantifies the prevalence of WCD in 340 high-profile sites among the Alexa\nTop 5K. Our analysis reveals WCD vulnerabilities that leak private user data as\nwell as secret authentication and authorization tokens that can be leveraged by\nan attacker to mount damaging web application attacks. Furthermore, we explore\nWCD in a scientific framework as an instance of the path confusion class of\nattacks, and demonstrate that variations on the path confusion technique used\nmake it possible to exploit sites that are otherwise not impacted by the\noriginal attack. Our findings show that many popular sites remain vulnerable\ntwo years after the public disclosure of WCD. Our empirical experiments with\npopular CDN providers underline the fact that web caches are not plug & play\ntechnologies. In order to mitigate WCD, site operators must adopt a holistic\nview of their web infrastructure and carefully configure cache settings\nappropriate for their applications.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 03:54:40 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 00:22:59 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Mirheidari", "Seyed Ali", ""], ["Arshad", "Sajjad", ""], ["Onarlioglu", "Kaan", ""], ["Crispo", "Bruno", ""], ["Kirda", "Engin", ""], ["Robertson", "William", ""]]}, {"id": "1912.10247", "submitter": "Guntur Dharma Putra", "authors": "Guntur Dharma Putra, Volkan Dedeoglu, Salil S. Kanhere, Raja Jurdak", "title": "Trust Management in Decentralized IoT Access Control System", "comments": "Accepted to IEEE ICBC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous and dynamic IoT environments require a lightweight, scalable,\nand trustworthy access control system for protection from unauthorized access\nand for automated detection of compromised nodes. Recent proposals in IoT\naccess control systems have incorporated blockchain to overcome inherent issues\nin conventional access control schemes. However, the dynamic interaction of IoT\nnetworks remains uncaptured. Here, we develop a blockchain based Trust and\nReputation System (TRS) for IoT access control, which progressively evaluates\nand calculates the trust and reputation score of each participating node to\nachieve a self-adaptive and trustworthy access control system. Trust and\nreputation are explicitly incorporated in the attribute-based access control\npolicy, so that different nodes can be assigned to different access right\nlevels, resulting in dynamic access control policies. We implement our proposed\narchitecture in a private Ethereum blockchain comprised of a Docker container\nnetwork. We benchmark our solution using various performance metrics to\nhighlight its applicability for IoT contexts.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 11:06:24 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 10:39:58 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Putra", "Guntur Dharma", ""], ["Dedeoglu", "Volkan", ""], ["Kanhere", "Salil S.", ""], ["Jurdak", "Raja", ""]]}, {"id": "1912.10298", "submitter": "Chaitanya Rahalkar", "authors": "Chaitanya Rahalkar and Dhaval Gujar", "title": "Content Addressed P2P File System for the Web with Blockchain-Based\n  Meta-Data Integrity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the exponentially scaled World Wide Web, the standard HTTP protocol has\nstarted showing its limitations. With the increased amount of data duplication\n& accidental deletion of files on the Internet, the P2P file system called IPFS\ncompletely changes the way files are stored. IPFS is a file storage protocol\nallowing files to be stored on decentralized systems. In the HTTP client-server\nprotocol, files are downloaded from a single source. With files stored on a\ndecentralized network, IPFS allows packet retrieval from multiple sources,\nsimultaneously saving considerable bandwidth. IPFS uses a content-addressed\nblock storage model with content-addressed hyperlinks. Large amounts of data is\naddressable with IPFS with the immutable and permanent IPFS links with\nmeta-data stored as Blockchain transactions. This timestamps and secures the\ndata, instead of having to put it on the chain itself. Our paper proposes a\nmodel that uses the decentralized file storage system of IPFS, and the\nintegrity preservation properties of the Blockchain, to store and distribute\ndata on the Web.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 17:11:31 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 03:00:40 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Rahalkar", "Chaitanya", ""], ["Gujar", "Dhaval", ""]]}, {"id": "1912.10312", "submitter": "Sheikh Ariful Islam", "authors": "Sheikh Ariful Islam, Farha Islam Mime, S M Asaduzzaman, Farzana Islam", "title": "Socio-network Analysis of RTL Designs for Hardware Trojan Localization", "comments": "Accepted to be Published in: Proceedings of the 2019 22nd\n  International Conference on Computer and Information Technology (ICCIT),\n  18-20 December 2019, Dhaka, Bangladesh", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent surge in hardware security is significant due to offshoring the\nproprietary Intellectual property (IP). One distinct dimension of the\ndisruptive threat is malicious logic insertion, also known as Hardware Trojan\n(HT). HT subverts the normal operations of a device stealthily. The diversity\nin HTs activation mechanisms and their location in design brings no catch-all\ndetection techniques. In this paper, we propose to leverage principle features\nof social network analysis to security analysis of Register Transfer Level\n(RTL) designs against HT. The approach is based on investigating design\nproperties, and it extends the current detection techniques. In particular, we\nperform both node- and graph-level analysis to determine the direct and\nindirect interactions between nets in a design. This technique helps not only\nin finding vulnerable nets that can act as HT triggering signals but also their\ninteractions to influence a particular net to act as HT payload signal. We\nexperiment the technique on 420 combinational HT instances, and on average, we\ncan detect both triggering and payload signals with accuracy up to 97.37%.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 18:31:55 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Islam", "Sheikh Ariful", ""], ["Mime", "Farha Islam", ""], ["Asaduzzaman", "S M", ""], ["Islam", "Farzana", ""]]}, {"id": "1912.10367", "submitter": "Vincent Gramoli", "authors": "Gauthier Voron and Vincent Gramoli", "title": "Dispel: Byzantine SMR with Distributed Pipelining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.OS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Byzantine State Machine Replication (SMR) is a long studied topic that\nreceived increasing attention recently with the advent of blockchains as\ncompanies are trying to scale them to hundreds of nodes. Byzantine SMRs try to\nincrease throughput by either reducing the latency of consensus instances that\nthey run sequentially or by reducing the number of replicas that send messages\nto others in order to reduce the network usage. Unfortunately, the former\napproach makes use of resources in burst whereas the latter requires\nCPU-intensive authentication mechanisms.\n  In this paper, we propose a new Byzantine SMR called Dispel (Distributed\nPipeline) that allows any node to distributively start new consensus instances\nwhenever they detect sufficient resources locally. We evaluate the performance\nof Dispel within a single datacenter and across up to 380 machines over 3\ncontinents by comparing it against four other SMRs. On 128 nodes, Dispel speeds\nup HotStuff, the Byzantine fault tolerant SMR being integrated within\nFacebook's blockchain, by more than 12 times. In addition, we also test Dispel\nunder isolated and correlated failures and show that the Dispel distributed\ndesign is more robust than HotStuff. Finally, we evaluate Dispel in a\ncryptocurrency application with Bitcoin transactions and show that this SMR is\nnot the bottleneck.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 00:58:54 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 09:57:12 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Voron", "Gauthier", ""], ["Gramoli", "Vincent", ""]]}, {"id": "1912.10413", "submitter": "Tanay Singhania", "authors": "Kartik Sharma, Ashutosh Aggarwal, Tanay Singhania, Deepak Gupta,\n  Ashish Khanna", "title": "Hiding Data in Images Using Cryptography and Deep Neural Network", "comments": "20 pages, 9 figures, 5 tables", "journal-ref": null, "doi": "10.33969/AIS.2019.11009", "report-no": null, "categories": "cs.MM cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Steganography is an art of obscuring data inside another quotidian file of\nsimilar or varying types. Hiding data has always been of significant importance\nto digital forensics. Previously, steganography has been combined with\ncryptography and neural networks separately. Whereas, this research combines\nsteganography, cryptography with the neural networks all together to hide an\nimage inside another container image of the larger or same size. Although the\ncryptographic technique used is quite simple, but is effective when convoluted\nwith deep neural nets. Other steganography techniques involve hiding data\nefficiently, but in a uniform pattern which makes it less secure. This method\ntargets both the challenges and make data hiding secure and non-uniform.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 10:19:44 GMT"}, {"version": "v2", "created": "Wed, 1 Jan 2020 18:51:59 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Sharma", "Kartik", ""], ["Aggarwal", "Ashutosh", ""], ["Singhania", "Tanay", ""], ["Gupta", "Deepak", ""], ["Khanna", "Ashish", ""]]}, {"id": "1912.10602", "submitter": "Hiroshi Haramoto", "authors": "Hiroshi Haramoto", "title": "Study on upper limit of sample sizes for a two-level test in NIST\n  SP800-22", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NIST SP800-22 is one of the most widely used statistical testing tools for\npseudorandom number generators (PRNGs). This tool consists of 15 tests\n(one-level tests) and two additional tests (two-level tests). Each one-level\ntest provides one or more $p$-values. The two-level tests measure the\nuniformity of the obtained $p$-values for a fixed one-level test. One of the\ntwo-level tests categorizes the $p$-values into ten intervals of equal length,\nand apply a chi-squared goodness-of-fit test. This two-level test is often more\npowerful than one-level tests, but sometimes it rejects even good PRNGs when\nthe sample size at the second level is too large, since it detects\napproximation errors in the computation of $p$-values. In this paper, we\npropose a practical upper limit of the sample size in this two-level test, for\neach of six tests appeared in SP800-22. These upper limits are derived by the\nchi-squared discrepancy between the distribution of the approximated $p$-values\nand the uniform distribution $U(0, 1)$. We also computed a \"risky\" sample size\nat the second level for each one-level test. Our experiments show that the\ntwo-level test with the proposed upper limit gives appropriate results, while\nusing the risky size often rejects even good PRNGs. We also propose another\nimprovement: to use the exact probability for the ten categories in the\ncomputation of goodness-of-fit at the two-level test. This allows us to\nincrease the sample size at the second level, and would make the test more\nsensitive than the NIST's recommending usage.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 03:33:06 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2019 14:10:44 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2020 15:07:23 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Haramoto", "Hiroshi", ""]]}, {"id": "1912.10617", "submitter": "Ahmet Kurt", "authors": "Ahmet Kurt, Enes Erdin, Mumin Cebe, Kemal Akkaya, A. Selcuk Uluagac", "title": "LNBot: A Covert Hybrid Botnet on Bitcoin Lightning Network for Fun and\n  Profit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While various covert botnets were proposed in the past, they still lack\ncomplete anonymization for their servers/botmasters or suffer from slow\ncommunication between the botmaster and the bots. In this paper, we propose a\nnew generation hybrid botnet that covertly and efficiently communicates over\nBitcoin Lightning Network (LN), called LNBot. LN is a payment channel network\noperating on top of Bitcoin network for faster Bitcoin transactions with\nnegligible fees. Exploiting various anonymity features of LN, we designed a\nscalable two-layer botnet which completely anonymize the identity of the\nbotmaster. In the first layer, the botmaster sends commands anonymously to the\nC&C servers through LN transactions. Specifically, LNBot allows botmaster's\ncommands to be sent in the form of surreptitious multihop LN payments, where\nthe commands are encoded with ASCII or Huffman encoding to provide covert\ncommunications. In the second layer, C&C servers further relay those commands\nto the bots they control in their mini-botnets to launch any type of attacks to\nvictim machines. We implemented a proof-of-concept on the actual LN and\nextensively analyzed the delay and cost performance of LNBot. Our analysis show\nthat LNBot achieves better scalibility compared to the other similar blockchain\nbotnets with negligible costs. Finally, we also provide and discuss a list of\npotential countermeasures to detect LNBot activities and minimize its impacts.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 04:57:01 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 14:33:47 GMT"}, {"version": "v3", "created": "Sat, 25 Apr 2020 07:47:06 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Kurt", "Ahmet", ""], ["Erdin", "Enes", ""], ["Cebe", "Mumin", ""], ["Akkaya", "Kemal", ""], ["Uluagac", "A. Selcuk", ""]]}, {"id": "1912.10666", "submitter": "Yutian Yang", "authors": "Yutian Yang, Songbo Zhu, Wenbo Shen, Yajin Zhou, Jiadong Sun, and Kui\n  Ren", "title": "ARM Pointer Authentication based Forward-Edge and Backward-Edge Control\n  Flow Integrity for Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code reuse attacks are still big threats to software and system security.\nControl flow integrity is a promising technique to defend against such attacks.\nHowever, its effectiveness has been weakened due to the inaccurate control flow\ngraph and practical strategy to trade security for performance. In recent\nyears, CPU vendors have integrated hardware features as countermeasures. For\ninstance, ARM Pointer Authentication (PA in short) was introduced in ARMV8-A\narchitecture. It can efficiently generate an authentication code for an\naddress, which is encoded in the unused bits of the address. When the address\nis de-referenced, the authentication code is checked to ensure its integrity.\nThough there exist systems that adopt PA to harden user programs, how to\neffectively use PA to protect OS kernels is still an open research question.\n  In this paper, we shed lights on how to leverage PA to protect control flows,\nincluding function pointers and return addresses, of Linux kernel.\nSpecifically, to protect function pointers, we embed authentication code into\nthem, track their propagation and verify their values when loading from memory\nor branching to targets. To further defend against the pointer substitution\nattack, we use the function pointer address as its context, and take a clean\ndesign to propagate the address by piggybacking it into the pointer value. We\nhave implemented a prototype system with LLVM to identify function pointers,\nadd authentication code and verify function pointers by emitting new machine\ninstructions. We applied this system to Linux kernel, and solved numerous\npractical issues, e.g., function pointer comparison and arithmetic operations.\nThe security analysis shows that our system can protect all function pointers\nand return addresses in Linux kernel.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 07:58:04 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 06:33:43 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Yang", "Yutian", ""], ["Zhu", "Songbo", ""], ["Shen", "Wenbo", ""], ["Zhou", "Yajin", ""], ["Sun", "Jiadong", ""], ["Ren", "Kui", ""]]}, {"id": "1912.10757", "submitter": "Shipra Kumari", "authors": "Shipra Kumari and Hrishikesh Mahato", "title": "Encryption based on Conference Matrix", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article, an encryption scheme based on (-1, 1) conference matrix has\nbeen developed. The decryption key comprising of fixed number of positive\nintegers with prime power yields the high level security of message. Some\npopular attacks has been discussed in the context of cryptoanalysis and\nobserved that it is robust against the popular cipher attack and the security\nof the information does not compromise.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 12:14:22 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Kumari", "Shipra", ""], ["Mahato", "Hrishikesh", ""]]}, {"id": "1912.10833", "submitter": "Ziwen He", "authors": "Ziwen He, Wei Wang, Xinsheng Xuan, Jing Dong, Tieniu Tan", "title": "A New Ensemble Method for Concessively Targeted Multi-model Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that deep learning models are vulnerable to adversarial\nexamples crafted by maliciously adding perturbations to original inputs. There\nare two types of attacks: targeted attack and non-targeted attack, and most\nresearchers often pay more attention to the targeted adversarial examples.\nHowever, targeted attack has a low success rate, especially when aiming at a\nrobust model or under a black-box attack protocol. In this case, non-targeted\nattack is the last chance to disable AI systems. Thus, in this paper, we\npropose a new attack mechanism which performs the non-targeted attack when the\ntargeted attack fails. Besides, we aim to generate a single adversarial sample\nfor different deployed models of the same task, e.g. image classification\nmodels. Hence, for this practical application, we focus on attacking ensemble\nmodels by dividing them into two groups: easy-to-attack and robust models. We\nalternately attack these two groups of models in the non-targeted or targeted\nmanner. We name it a bagging and stacking ensemble (BAST) attack. The BAST\nattack can generate an adversarial sample that fails multiple models\nsimultaneously. Some of the models classify the adversarial sample as a target\nlabel, and other models which are not attacked successfully may give wrong\nlabels at least. The experimental results show that the proposed BAST attack\noutperforms the state-of-the-art attack methods on the new defined criterion\nthat considers both targeted and non-targeted attack performance.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 10:56:36 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["He", "Ziwen", ""], ["Wang", "Wei", ""], ["Xuan", "Xinsheng", ""], ["Dong", "Jing", ""], ["Tan", "Tieniu", ""]]}, {"id": "1912.10836", "submitter": "Aykut \\c{C}ay{\\i}r", "authors": "Aykut \\c{C}ay{\\i}r, U\\u{g}ur \\\"Unal and Hasan Da\\u{g}", "title": "Random CapsNet Forest Model for Imbalanced Malware Type Classification\n  Task", "comments": "30 pages, 10 figures, typos are corrected, references are added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Behavior of a malware varies with respect to malware types. Therefore,knowing\ntype of a malware affects strategies of system protection softwares. Many\nmalware type classification models empowered by machine and deep learning\nachieve superior accuracies to predict malware types.Machine learning based\nmodels need to do heavy feature engineering and feature engineering is\ndominantly effecting performance of models.On the other hand, deep learning\nbased models require less feature engineering than machine learning based\nmodels. However, traditional deep learning architectures and components cause\nvery complex and data sensitive models. Capsule network architecture minimizes\nthis complexity and data sensitivity unlike classical convolutional neural\nnetwork architectures. This paper proposes an ensemble capsule network model\nbased on bootstrap aggregating technique. The proposed method are tested on two\nmalware datasets, whose the-state-of-the-art results are well-known.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 06:40:40 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 13:51:31 GMT"}, {"version": "v3", "created": "Mon, 30 Mar 2020 19:56:53 GMT"}, {"version": "v4", "created": "Sun, 23 Aug 2020 20:21:04 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["\u00c7ay\u0131r", "Aykut", ""], ["\u00dcnal", "U\u011fur", ""], ["Da\u011f", "Hasan", ""]]}, {"id": "1912.10979", "submitter": "Florian Lemmerich", "authors": "Michael Ellers, Michael Cochez, Tobias Schumacher, Markus Strohmaier,\n  Florian Lemmerich", "title": "Privacy Attacks on Network Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data ownership and data protection are increasingly important topics with\nethical and legal implications, e.g., with the right to erasure established in\nthe European General Data Protection Regulation (GDPR). In this light, we\ninvestigate network embeddings, i.e., the representation of network nodes as\nlow-dimensional vectors. We consider a typical social network scenario with\nnodes representing users and edges relationships between them. We assume that a\nnetwork embedding of the nodes has been trained. After that, a user demands the\nremoval of his data, requiring the full deletion of the corresponding network\ninformation, in particular the corresponding node and incident edges. In that\nsetting, we analyze whether after the removal of the node from the network and\nthe deletion of the vector representation of the respective node in the\nembedding significant information about the link structure of the removed node\nis still encoded in the embedding vectors of the remaining nodes. This would\nrequire a (potentially computationally expensive) retraining of the embedding.\nFor that purpose, we deploy an attack that leverages information from the\nremaining network and embedding to recover information about the neighbors of\nthe removed node. The attack is based on (i) measuring distance changes in\nnetwork embeddings and (ii) a machine learning classifier that is trained on\nnetworks that are constructed by removing additional nodes. Our experiments\ndemonstrate that substantial information about the edges of a removed node/user\ncan be retrieved across many different datasets. This implies that to fully\nprotect the privacy of users, node deletion requires complete retraining - or\nat least a significant modification - of original network embeddings. Our\nresults suggest that deleting the corresponding vector representation from\nnetwork embeddings alone is not sufficient from a privacy perspective.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 17:10:20 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Ellers", "Michael", ""], ["Cochez", "Michael", ""], ["Schumacher", "Tobias", ""], ["Strohmaier", "Markus", ""], ["Lemmerich", "Florian", ""]]}, {"id": "1912.11043", "submitter": "Regio Michelin", "authors": "Roben C. Lunardi, Regio A. Michelin, Charles V. Neu, Avelino F. Zorzo,\n  Salil S. Kanhere", "title": "Impact of consensus on appendable-block blockchain for IoT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) is transforming our physical world into a\ncomplex and dynamic system of connected devices on an unprecedented scale.\nConnecting everyday physical objects is creating new business models, improving\nprocesses and reducing costs and risks. Recently, blockchain technology has\nreceived a lot of attention from the community as a possible solution to\novercome security issues in IoT. However, traditional blockchains (such as the\nones used in Bitcoin and Ethereum) are not well suited to the\nresource-constrained nature of IoT devices and also with the large volume of\ninformation that is expected to be generated from typical IoT deployments. To\novercome these issues, several researchers have presented lightweight instances\nof blockchains tailored for IoT. For example, proposing novel data structures\nbased on blocks with decoupled and appendable data. However, these researchers\ndid not discuss how the consensus algorithm would impact their solutions, i.e.,\nthe decision of which consensus algorithm would be better suited was left as an\nopen issue. In this paper, we improved an appendable-block blockchain framework\nto support different consensus algorithms through a modular design. We\nevaluated the performance of this improved version in different emulated\nscenarios and studied the impact of varying the number of devices and\ntransactions and employing different consensus algorithms. Even adopting\ndifferent consensus algorithms, results indicate that the latency to append a\nnew block is less than 161ms (in the more demanding scenario) and the delay for\nprocessing a new transaction is less than 7ms, suggesting that our improved\nversion of the appendable-block blockchain is efficient and scalable, and thus\nwell suited for IoT scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 00:37:41 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Lunardi", "Roben C.", ""], ["Michelin", "Regio A.", ""], ["Neu", "Charles V.", ""], ["Zorzo", "Avelino F.", ""], ["Kanhere", "Salil S.", ""]]}, {"id": "1912.11044", "submitter": "Regio Michelin", "authors": "Regio A. Michelin, Nadeem Ahmed, Salil S. Kanhere, Aruna Seneviratne,\n  Sanjay Jha", "title": "Leveraging lightweight blockchain to establish data integrity for\n  surveillance cameras", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The video footage produced by the surveillance cameras is an important\nevidence to support criminal investigations. Video evidence can be sourced from\npublic (trusted) as well as private (untrusted) surveillance systems. This\nraises the issue of establishing integrity and auditability for information\nprovided by the untrusted video sources. In this paper, we focus on a airport\necosystem, where multiple entities with varying levels of trust are involved in\nproducing and exchanging video surveillance information. We present a framework\nto ensure the data integrity of the stored videos, allowing authorities to\nvalidate whether video footage has not been tampered. Our proposal uses a\nlightweight blockchain technology to store the video metadata as blockchain\ntransactions to support the validation of video integrity. The proposed\nframework also ensures video auditability and non-repudiation. Our evaluations\nshow that the overhead introduced by employing the blockchain to create and\nquery the transactions introduces a very minor latency of a few milliseconds.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 00:47:28 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 02:52:11 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Michelin", "Regio A.", ""], ["Ahmed", "Nadeem", ""], ["Kanhere", "Salil S.", ""], ["Seneviratne", "Aruna", ""], ["Jha", "Sanjay", ""]]}, {"id": "1912.11118", "submitter": "Ke Coby Wang", "authors": "Ke Coby Wang and Michael K. Reiter", "title": "Detecting stuffing of a user's credentials at her own accounts", "comments": null, "journal-ref": "Proceedings of the 29th USENIX Security Symposium (USENIX Security\n  2020)", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework by which websites can coordinate to detect credential\nstuffing on individual user accounts. Our detection algorithm teases apart\nnormal login behavior (involving password reuse, entering correct passwords\ninto the wrong sites, etc.) from credential stuffing, by leveraging modern\nanomaly detection and carefully tracking suspicious logins. Websites coordinate\nusing a novel private membership-test protocol, thereby ensuring that\ninformation about passwords is not leaked; this protocol is highly scalable,\npartly due to its use of cuckoo filters, and is more secure than similarly\nscalable alternatives in an important measure that we define. We use\nprobabilistic model checking to estimate our credential-stuffing detection\naccuracy across a range of operating points. These methods might be of\nindependent interest for their novel application of formal methods to estimate\nthe usability impacts of our design. We show that even a minimal-infrastructure\ndeployment of our framework should already support the combined login load\nexperienced by the airline, hotel, retail, and consumer banking industries in\nthe U.S.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 21:38:21 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 15:47:18 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Wang", "Ke Coby", ""], ["Reiter", "Michael K.", ""]]}, {"id": "1912.11153", "submitter": "Luca Piccolboni", "authors": "Luca Piccolboni, Giuseppe Di Guglielmo, Luca P. Carloni", "title": "PAGURUS: Low-Overhead Dynamic Information Flow Tracking on Loosely\n  Coupled Accelerators", "comments": "Published in IEEE Transactions on Computer-Aided Design of Integrated\n  Circuits and Systems (TCAD)", "journal-ref": null, "doi": "10.1109/TCAD.2018.2857321", "report-no": "IEEE Trans. Comput.-Aided Des. Integr. Circuits Syst. Volume 37\n  Number 11 (November 2018)", "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software-based attacks exploit bugs or vulnerabilities to get unauthorized\naccess or leak confidential information. Dynamic information flow tracking\n(DIFT) is a security technique to track spurious information flows and provide\nstrong security guarantees against such attacks. To secure heterogeneous\nsystems, the spurious information flows must be tracked through all their\ncomponents, including processors, accelerators (i.e., application-specific\nhardware components) and memories. We present PAGURUS, a flexible methodology\nto design a low-overhead shell circuit that adds DIFT support to accelerators.\nThe shell uses a coarse-grain DIFT approach, thus not requiring to make\nmodifications to the accelerator's implementation. We analyze the performance\nand area overhead of the DIFT shell on FPGAs and we propose a metric, called\ninformation leakage, to measure its security guarantees. We perform a\ndesign-space exploration to show that we can synthesize accelerators with\ndifferent characteristics in terms of performance, cost and security\nguarantees. We also present a case study where we use the DIFT shell to secure\nan accelerator running on a embedded platform with a DIFT-enhanced RISC-V core.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 20:28:15 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Piccolboni", "Luca", ""], ["Di Guglielmo", "Giuseppe", ""], ["Carloni", "Luca P.", ""]]}, {"id": "1912.11249", "submitter": "Sam Yen", "authors": "Yao Saint Yen, Zhe Wei Chen, Ying Ren Guo, Meng Chang Chen", "title": "Integration of Static and Dynamic Analysis for Malware Family\n  Classification with Composite Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been used in the research of malware analysis. Most\nclassification methods use either static analysis features or dynamic analysis\nfeatures for malware family classification, and rarely combine them as\nclassification features and also no extra effort is spent integrating the two\ntypes of features. In this paper, we combine static and dynamic analysis\nfeatures with deep neural networks for Windows malware classification. We\ndevelop several methods to generate static and dynamic analysis features to\nclassify malware in different ways. Given these features, we conduct\nexperiments with composite neural network, showing that the proposed approach\nperforms best with an accuracy of 83.17% on a total of 80 malware families with\n4519 malware samples. Additionally, we show that using integrated features for\nmalware family classification outperforms using static features or dynamic\nfeatures alone. We show how static and dynamic features complement each other\nfor malware classification.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 08:50:00 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Yen", "Yao Saint", ""], ["Chen", "Zhe Wei", ""], ["Guo", "Ying Ren", ""], ["Chen", "Meng Chang", ""]]}, {"id": "1912.11279", "submitter": "Reza Shokri", "authors": "Hongyan Chang, Virat Shejwalkar, Reza Shokri, Amir Houmansadr", "title": "Cronus: Robust and Heterogeneous Collaborative Learning with Black-Box\n  Knowledge Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative (federated) learning enables multiple parties to train a model\nwithout sharing their private data, but through repeated sharing of the\nparameters of their local models. Despite its advantages, this approach has\nmany known privacy and security weaknesses and performance overhead, in\naddition to being limited only to models with homogeneous architectures. Shared\nparameters leak a significant amount of information about the local (and\nsupposedly private) datasets. Besides, federated learning is severely\nvulnerable to poisoning attacks, where some participants can adversarially\ninfluence the aggregate parameters. Large models, with high dimensional\nparameter vectors, are in particular highly susceptible to privacy and security\nattacks: curse of dimensionality in federated learning. We argue that sharing\nparameters is the most naive way of information exchange in collaborative\nlearning, as they open all the internal state of the model to inference\nattacks, and maximize the model's malleability by stealthy poisoning attacks.\nWe propose Cronus, a robust collaborative machine learning framework. The\nsimple yet effective idea behind designing Cronus is to control, unify, and\nsignificantly reduce the dimensions of the exchanged information between\nparties, through robust knowledge transfer between their black-box local\nmodels. We evaluate all existing federated learning algorithms against\npoisoning attacks, and we show that Cronus is the only secure method, due to\nits tight robustness guarantee. Treating local models as black-box, reduces the\ninformation leakage through models, and enables us using existing\nprivacy-preserving algorithms that mitigate the risk of information leakage\nthrough the model's output (predictions). Cronus also has a significantly lower\nsample complexity, compared to federated learning, which does not bind its\nsecurity to the number of participants.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 10:20:38 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Chang", "Hongyan", ""], ["Shejwalkar", "Virat", ""], ["Shokri", "Reza", ""], ["Houmansadr", "Amir", ""]]}, {"id": "1912.11283", "submitter": "Roberto Bruzzese", "authors": "Roberto Bruzzese", "title": "An Analisys of Application Logs with Splunk : developing an App for the\n  synthetic analysis of data and security incidents", "comments": "32 pages, 32 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present work aims to enhance the application logs of an hypothetical\ninfrastructure platform, and to build an App that displays the synthetic data\nabout performance, anomalies and security incidents synthesized in the form of\na Dashboard. The reference architecture, with multiple applications and\nmultiple HW distribution, implementing a Service Oriented Architecture, is a\nreal case of which the details have been abstracted because we want to extend\nthe concept to all architectures with similar characteristics.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 10:42:42 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Bruzzese", "Roberto", ""]]}, {"id": "1912.11299", "submitter": "V\\'ictor Mayoral Vilches", "authors": "V\\'ictor Mayoral Vilches, Lander Usategui San Juan, Bernhard Dieber,\n  Unai Ayucar Carbajo and Endika Gil-Uriarte", "title": "Introducing the Robot Vulnerability Database (RVD)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybersecurity in robotics is an emerging topic that has gained significant\ntraction. Researchers have demonstrated some of the potentials and effects of\ncyber attacks on robots lately. This implies safety related adverse\nconsequences causing human harm, death or lead to significant integrity loss\nclearly overcoming the privacy concerns in classical IT world. In cybersecurity\nresearch, the use of vulnerability databases is a very reliable tool to\nresponsibly disclose vulnerabilities in software products and raise willingness\nof vendors to address these issues. In this paper we argue, that existing\nvulnerability databases are of insufficient information density and show some\nbiased content with respect to vulnerabilities in robots. This paper presents\nthe Robot Vulnerability Database (RVD), a directory for responsible disclosure\nof bugs, weaknesses and vulnerabilities in robots. This article aims to\ndescribe the design and process as well as the associated disclosure policy\nbehind RVD. Furthermore the authors present preliminary selected\nvulnerabilities already contained in RVD and call to the robotics and security\ncommunities for contribution to the endeavour of eliminating zero-day\nvulnerabilities in robotics.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 11:38:52 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 11:59:43 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Vilches", "V\u00edctor Mayoral", ""], ["Juan", "Lander Usategui San", ""], ["Dieber", "Bernhard", ""], ["Carbajo", "Unai Ayucar", ""], ["Gil-Uriarte", "Endika", ""]]}, {"id": "1912.11328", "submitter": "Jonas Robl", "authors": "Daniel Bernau, Philip-William Grassal, Jonas Robl, Florian Kerschbaum", "title": "Assessing differentially private deep learning with Membership Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attacks that aim to identify the training data of public neural networks\nrepresent a severe threat to the privacy of individuals participating in the\ntraining data set. A possible protection is offered by anonymization of the\ntraining data or training function with differential privacy. However, data\nscientists can choose between local and central differential privacy and need\nto select meaningful privacy parameters $\\epsilon$ which is challenging for\nnon-privacy experts. We empirically compare local and central differential\nprivacy mechanisms under white- and black-box membership inference to evaluate\ntheir relative privacy-accuracy trade-offs. We experiment with several datasets\nand show that this trade-off is similar for both types of mechanisms. This\nsuggests that local differential privacy is a sound alternative to central\ndifferential privacy for differentially private deep learning, since small\n$\\epsilon$ in central differential privacy and large $\\epsilon$ in local\ndifferential privacy result in similar membership inference attack risk.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 13:00:24 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 11:19:08 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2020 16:43:11 GMT"}, {"version": "v4", "created": "Tue, 26 May 2020 14:27:16 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Bernau", "Daniel", ""], ["Grassal", "Philip-William", ""], ["Robl", "Jonas", ""], ["Kerschbaum", "Florian", ""]]}, {"id": "1912.11401", "submitter": "Vidal Attias", "authors": "Vidal Attias, Luigi Vigneri, Vassil Dimitrov", "title": "On the Decentralized Generation of theRSA Moduli in Multi-Party Settings", "comments": "The submission contains 14 pages and 12 figures. The conference to\n  submit is not determined yet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RSA cryptography is still widely used. Some of its applications (e.g.,\ndistributed signature schemes, cryptosystems) do not allow the RSA modulus to\nbe generated by a centralized trusted entity. Instead, the factorization must\nremain unknown to all the network participants. To this date, the existing\nalgorithms are either computationally expensive, or limited to two-party\nsettings. In this work, we design a decentralized multi-party computation\nalgorithm able to generate efficiently the RSA modulus.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 14:57:43 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Attias", "Vidal", ""], ["Vigneri", "Luigi", ""], ["Dimitrov", "Vassil", ""]]}, {"id": "1912.11523", "submitter": "Zane Weissman", "authors": "Zane Weissman, Thore Tiemann, Daniel Moghimi, Evan Custodio, Thomas\n  Eisenbarth and Berk Sunar", "title": "JackHammer: Efficient Rowhammer on Heterogeneous FPGA-CPU Platforms", "comments": "Accepted to IACR Transactions on Cryptographic Hardware and Embedded\n  Systems (TCHES), Volume 2020, Issue 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After years of development, FPGAs are finally making an appearance on\nmulti-tenant cloud servers. These heterogeneous FPGA-CPU architectures break\ncommon assumptions about isolation and security boundaries. Since the FPGA and\nCPU architectures share hardware resources, a new class of vulnerabilities\nrequires us to reassess the security and dependability of these platforms.\n  In this work, we analyze the memory and cache subsystem and study Rowhammer\nand cache attacks enabled on two proposed heterogeneous FPGA-CPU platforms by\nIntel: the Arria 10 GX with an integrated FPGA-CPU platform, and the Arria 10\nGX PAC expansion card which connects the FPGA to the CPU via the PCIe\ninterface. We show that while Intel PACs currently are immune to cache attacks\nfrom FPGA to CPU, the integrated platform is indeed vulnerable to Prime and\nProbe style attacks from the FPGA to the CPU's last level cache. Further, we\ndemonstrate JackHammer, a novel and efficient Rowhammer from the FPGA to the\nhost's main memory. Our results indicate that a malicious FPGA can perform\ntwice as fast as a typical Rowhammer attack from the CPU on the same system and\ncauses around four times as many bit flips as the CPU attack. We demonstrate\nthe efficacy of JackHammer from the FPGA through a realistic fault attack on\nthe WolfSSL RSA signing implementation that reliably causes a fault after an\naverage of fifty-eight RSA signatures, 25% faster than a CPU rowhammer attack.\nIn some scenarios our JackHammer attack produces faulty signatures more than\nthree times more often and almost three times faster than a conventional CPU\nrowhammer attack.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 20:37:36 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2019 00:26:57 GMT"}, {"version": "v3", "created": "Sat, 4 Apr 2020 21:09:14 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Weissman", "Zane", ""], ["Tiemann", "Thore", ""], ["Moghimi", "Daniel", ""], ["Custodio", "Evan", ""], ["Eisenbarth", "Thomas", ""], ["Sunar", "Berk", ""]]}, {"id": "1912.11531", "submitter": "Luca Pasqualini", "authors": "Luca Pasqualini, Maurizio Parton", "title": "Pseudo Random Number Generation: a Reinforcement Learning approach", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pseudo-Random Numbers Generators (PRNGs) are algorithms produced to generate\nlong sequences of statistically uncorrelated numbers, i.e. Pseudo-Random\nNumbers (PRNs). These numbers are widely employed in mid-level cryptography and\nin software applications. Test suites are used to evaluate PRNGs quality by\nchecking statistical properties of the generated sequences. Machine learning\ntechniques are often used to break these generators, for instance approximating\na certain generator or a certain sequence using a neural network. But what\nabout using machine learning to generate PRNs generators? This paper proposes a\nReinforcement Learning (RL) approach to the task of generating PRNGs from\nscratch by learning a policy to solve an N-dimensional navigation problem. In\nthis context, N is the length of the period of the generated sequence, and the\npolicy is iteratively improved using the average value of an appropriate test\nsuite run over that period. Aim of this work is to demonstrate the feasibility\nof the proposed approach, to compare it with classical methods, and to lay the\nfoundation of a research path which combines RL and PRNGs.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 13:32:07 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Pasqualini", "Luca", ""], ["Parton", "Maurizio", ""]]}, {"id": "1912.11541", "submitter": "Muhammad Anas Imtiaz", "authors": "Muhammad Anas Imtiaz, David Starobinski, Ari Trachtenberg", "title": "Characterizing Orphan Transactions in the Bitcoin Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Orphan transactions are those whose parental income-sources are missing at\nthe time that they are processed. These transactions are not propagated to\nother nodes until all of their missing parents are received, and they thus end\nup languishing in a local buffer until evicted or their parents are found.\nAlthough there has been little work in the literature on characterizing the\nnature and impact of such orphans, it is intuitive that they may affect\nthroughput on the Bitcoin network. This work thus seeks to methodically\nresearch such effects through a measurement campaign of orphan transactions on\nlive Bitcoin nodes. Our data show that, surprisingly, orphan transactions tend\nto have fewer parents on average than non-orphan transactions. Moreover, the\nsalient features of their missing parents are a lower fee and larger size than\ntheir non-orphan counterparts, resulting in a lower transaction fee per byte.\nFinally, we note that the network overhead incurred by these orphan\ntransactions can be significant, exceeding 17% when using the default orphan\nmemory pool size (100 transactions). However, this overhead can be made\nnegligible, without significant computational or memory demands, if the pool\nsize is merely increased to 1000 transactions.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 16:03:28 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 07:51:45 GMT"}, {"version": "v3", "created": "Wed, 11 Mar 2020 18:47:14 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Imtiaz", "Muhammad Anas", ""], ["Starobinski", "David", ""], ["Trachtenberg", "Ari", ""]]}, {"id": "1912.11546", "submitter": "Luigi Vigneri", "authors": "Vassil Dimitrov, Luigi Vigneri, Vidal Attias", "title": "Fast Generation of RSA Keys using Smooth Integers", "comments": "This paper contains 11 pages and 8 tables, in IEEE Transactions on\n  Computers", "journal-ref": null, "doi": "10.1109/TC.2021.3095669", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Primality generation is the cornerstone of several essential cryptographic\nsystems. The problem has been a subject of deep investigations, but there is\nstill a substantial room for improvements. Typically, the algorithms used have\ntwo parts trial divisions aimed at eliminating numbers with small prime factors\nand primality tests based on an easy-to-compute statement that is valid for\nprimes and invalid for composites. In this paper, we will showcase a technique\nthat will eliminate the first phase of the primality testing algorithms. The\ncomputational simulations show a reduction of the primality generation time by\nabout 30% in the case of 1024-bit RSA key pairs. This can be particularly\nbeneficial in the case of decentralized environments for shared RSA keys as the\ninitial trial division part of the key generation algorithms can be avoided at\nno cost. This also significantly reduces the communication complexity. Another\nessential contribution of the paper is the introduction of a new one-way\nfunction that is computationally simpler than the existing ones used in\npublic-key cryptography. This function can be used to create new random number\ngenerators, and it also could be potentially used for designing entirely new\npublic-key encryption systems.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 21:38:00 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 10:34:19 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Dimitrov", "Vassil", ""], ["Vigneri", "Luigi", ""], ["Attias", "Vidal", ""]]}, {"id": "1912.11588", "submitter": "Maanak Gupta", "authors": "Feras M. Awaysheh, Mamoun Alazab, Maanak Gupta, Tom\\'as F. Pena,\n  Jos\\'e C. Cabaleiro", "title": "Next-Generation Big Data Federation Access Control: A Reference Model", "comments": null, "journal-ref": null, "doi": "10.1016/j.future.2020.02.052", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses one of the most significant challenges of\nnext-generation big data (BD) federation platforms, namely, Hadoop access\ncontrol. Privacy and security on a federation scale remain significant concerns\namong practitioners. Hadoop's current primitive access control presents\nsecurity concerns and limitations, such as the complexity of deployment and the\nconsumption of resources. However, this major concern has not been a subject of\nintensive study in the literature. This paper critically reviews and\ninvestigates these security limitations and provides a framework called BD\nfederation access broker to address 8 main security limitations. This paper\nproposes the federated access control reference model (FACRM) to formalize the\ndesign of secure BD solutions within the Apache Hadoop stack. Furthermore, this\npaper discusses the implementation of the access broker and its usefulness for\nsecurity breach detection and digital forensics investigations. The efficiency\nof the proposed access broker has not sustainably affected the performance\noverhead. The experimental results show only 1\\% of each 100 MB read/write\noperation in a WebHDFS. Overall, the findings of the paper pave the way for a\nwide range of revolutionary and state-of-the-art enhancements and future trends\nwithin Hadoop stack security and privacy.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 04:13:04 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Awaysheh", "Feras M.", ""], ["Alazab", "Mamoun", ""], ["Gupta", "Maanak", ""], ["Pena", "Tom\u00e1s F.", ""], ["Cabaleiro", "Jos\u00e9 C.", ""]]}, {"id": "1912.11598", "submitter": "Saurabh Bagchi", "authors": "Saurabh Bagchi, Vaneet Aggarwal, Somali Chaterji, Fred Douglis, Aly El\n  Gamal, Jiawei Han, Brian J. Henz, Hank Hoffmann, Suman Jana, Milind Kulkarni,\n  Felix Xiaozhu Lin, Karen Marais, Prateek Mittal, Shaoshuai Mou, Xiaokang Qiu,\n  and Gesualdo Scutari", "title": "Grand Challenges in Resilience: Autonomous System Resilience through\n  Design and Runtime Measures", "comments": null, "journal-ref": "IEEE Open Journal of the Computer Society, 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A set of about 80 researchers, practitioners, and federal agency program\nmanagers participated in the NSF-sponsored Grand Challenges in Resilience\nWorkshop held on Purdue campus on March 19-21, 2019. The workshop was divided\ninto three themes: resilience in cyber, cyber-physical, and socio-technical\nsystems. About 30 attendees in all participated in the discussions of cyber\nresilience. This article brings out the substantive parts of the challenges and\nsolution approaches that were identified in the cyber resilience theme. In this\narticle, we put forward the substantial challenges in cyber resilience in a few\nrepresentative application domains and outline foundational solutions to\naddress these challenges. These solutions fall into two broad themes:\nresilience-by-design and resilience-by-reaction. We use examples of autonomous\nsystems as the application drivers motivating cyber resilience. We focus on\nsome autonomous systems in the near horizon (autonomous ground and aerial\nvehicles) and also a little more distant (autonomous rescue and relief).\n  For resilience-by-design, we focus on design methods in software that are\nneeded for our cyber systems to be resilient. In contrast, for\nresilience-by-reaction, we discuss how to make systems resilient by responding,\nreconfiguring, or recovering at runtime when failures happen. We also discuss\nthe notion of adaptive execution to improve resilience, execution transparently\nand adaptively among available execution platforms (mobile/embedded, edge, and\ncloud). For each of the two themes, we survey the current state, and the\ndesired state and ways to get there. We conclude the paper by looking at the\nresearch challenges we will have to solve in the short and the mid-term to make\nthe vision of resilient autonomous systems a reality.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 05:46:43 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 04:27:53 GMT"}, {"version": "v3", "created": "Sat, 9 May 2020 15:32:57 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Bagchi", "Saurabh", ""], ["Aggarwal", "Vaneet", ""], ["Chaterji", "Somali", ""], ["Douglis", "Fred", ""], ["Gamal", "Aly El", ""], ["Han", "Jiawei", ""], ["Henz", "Brian J.", ""], ["Hoffmann", "Hank", ""], ["Jana", "Suman", ""], ["Kulkarni", "Milind", ""], ["Lin", "Felix Xiaozhu", ""], ["Marais", "Karen", ""], ["Mittal", "Prateek", ""], ["Mou", "Shaoshuai", ""], ["Qiu", "Xiaokang", ""], ["Scutari", "Gesualdo", ""]]}, {"id": "1912.11617", "submitter": "Tuvi Etzion", "authors": "Yeow Meng Chee, Johan Chrisnata, Tuvi Etzion, Han Mao Kiah", "title": "Efficient Algorithm for the Linear Complexity of Sequences and Some\n  Related Consequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The linear complexity of a sequence $s$ is one of the measures of its\npredictability. It represents the smallest degree of a linear recursion which\nthe sequence satisfies. There are several algorithms to find the linear\ncomplexity of a periodic sequence $s$ of length $N$ (where $N$ is of some given\nform) over a finite field $F_q$ in $O(N)$ symbol field operations. The first\nsuch algorithm is The Games-Chan Algorithm which considers binary sequences of\nperiod $2^n$, and is known for its extreme simplicity. We generalize this\nalgorithm and apply it efficiently for several families of binary sequences.\nOur algorithm is very simple, it requires $\\beta N$ bit operations for a small\nconstant $\\beta$, where $N$ is the period of the sequence. We make an analysis\non the number of bit operations required by the algorithm and compare it with\nprevious algorithms. In the process, the algorithm also finds the recursion for\nthe shortest linear feedback shift-register which generates the sequence. Some\nother interesting properties related to shift-register sequences, which might\nnot be too surprising but generally unnoted, are also consequences of our\nexposition.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 08:07:55 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Chee", "Yeow Meng", ""], ["Chrisnata", "Johan", ""], ["Etzion", "Tuvi", ""], ["Kiah", "Han Mao", ""]]}, {"id": "1912.11721", "submitter": "Tempestt Neal", "authors": "Md A. Noor, G. Kaptan, V. Cherukupally, P. Gera, T. Neal", "title": "A Closer Look at Mobile App Usage as a Persistent Biometric: A Small\n  Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore mobile app use as a behavioral biometric\nidentifier. While several efforts have also taken on this challenge, many have\nalluded to the inconsistency in human behavior, resulting in updating the\nbiometric template frequently and periodically. Here, we represent app usage as\nsimple images wherein each pixel value provides some information about the\nuser's app usage. Then, we feed use these images to train a deep learning\nnetwork (convolutional neural net) to classify the user's identity. Our\ncontribution lies in the random order in which the images are fed to the\nclassifier, thereby presenting novel evidence that there are some aspects of\napp usage that are indeed persistent. Our results yield a 96.8% $F$-score\nwithout any updates to the template data.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 22:11:24 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Noor", "Md A.", ""], ["Kaptan", "G.", ""], ["Cherukupally", "V.", ""], ["Gera", "P.", ""], ["Neal", "T.", ""]]}, {"id": "1912.11745", "submitter": "Shengling Wang", "authors": "Xidi Qu, Shengling Wang, Qin Hu, Xiuzhen Cheng", "title": "Proof of Federated Learning: A Novel Energy-recycling Consensus\n  Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proof of work (PoW), the most popular consensus mechanism for Blockchain,\nrequires ridiculously large amounts of energy but without any useful outcome\nbeyond determining accounting rights among miners. To tackle the drawback of\nPoW, we propose a novel energy-recycling consensus algorithm, namely proof of\nfederated learning (PoFL), where the energy originally wasted to solve\ndifficult but meaningless puzzles in PoW is reinvested to federated learning.\nFederated learning and pooled-ming, a trend of PoW, have a natural fit in terms\nof organization structure. However, the separation between the data usufruct\nand ownership in Blockchain lead to data privacy leakage in model training and\nverification, deviating from the original intention of federal learning. To\naddress the challenge, a reverse game-based data trading mechanism and a\nprivacy-preserving model verification mechanism are proposed. The former can\nguard against training data leakage while the latter verifies the accuracy of a\ntrained model with privacy preservation of the task requester's test data as\nwell as the pool's submitted model. To the best of our knowledge, our paper is\nthe first work to employ federal learning as the proof of work for Blockchain.\nExtensive simulations based on synthetic and real-world data demonstrate the\neffectiveness and efficiency of our proposed mechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 01:35:45 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Qu", "Xidi", ""], ["Wang", "Shengling", ""], ["Hu", "Qin", ""], ["Cheng", "Xiuzhen", ""]]}, {"id": "1912.11831", "submitter": "Mustafizur Rahman Shahid", "authors": "Mustafizur Rahman Shahid (SAMOVAR), Gregory Blanc (SAMOVAR), Zonghua\n  Zhang (SAMOVAR), Herv\\'e Debar (SAMOVAR)", "title": "Anomalous Communications Detection in IoT Networks Using Sparse\n  Autoencoders", "comments": null, "journal-ref": "2019 IEEE 18th International Symposium on Network Computing and\n  Applications (NCA), Sep 2019, Cambridge, United States. pp.1-5", "doi": "10.1109/NCA.2019.8935007", "report-no": null, "categories": "cs.CR cs.LG cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, IoT devices have been widely deployed for enabling various smart\nservices, such as, smart home or e-healthcare. However, security remains as one\nof the paramount concern as many IoT devices are vulnerable. Moreover, IoT\nmalware are constantly evolving and getting more sophisticated. IoT devices are\nintended to perform very specific tasks, so their networking behavior is\nexpected to be reasonably stable and predictable. Any significant behavioral\ndeviation from the normal patterns would indicate anomalous events. In this\npaper, we present a method to detect anomalous network communications in IoT\nnetworks using a set of sparse autoencoders. The proposed approach allows us to\ndifferentiate malicious communications from legitimate ones. So that, if a\ndevice is compromised only malicious communications can be dropped while the\nservice provided by the device is not totally interrupted. To characterize\nnetwork behavior, bidirectional TCP flows are extracted and described using\nstatistics on the size of the first N packets sent and received, along with\nstatistics on the corresponding inter-arrival times between packets. A set of\nsparse autoencoders is then trained to learn the profile of the legitimate\ncommunications generated by an experimental smart home network. Depending on\nthe value of N, the developed model achieves attack detection rates ranging\nfrom 86.9% to 91.2%, and false positive rates ranging from 0.1% to 0.5%.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 10:47:35 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Shahid", "Mustafizur Rahman", "", "SAMOVAR"], ["Blanc", "Gregory", "", "SAMOVAR"], ["Zhang", "Zonghua", "", "SAMOVAR"], ["Debar", "Herv\u00e9", "", "SAMOVAR"]]}, {"id": "1912.11852", "submitter": "Yinpeng Dong", "authors": "Yinpeng Dong, Qi-An Fu, Xiao Yang, Tianyu Pang, Hang Su, Zihao Xiao,\n  Jun Zhu", "title": "Benchmarking Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to adversarial examples, which becomes\none of the most important research problems in the development of deep\nlearning. While a lot of efforts have been made in recent years, it is of great\nsignificance to perform correct and complete evaluations of the adversarial\nattack and defense algorithms. In this paper, we establish a comprehensive,\nrigorous, and coherent benchmark to evaluate adversarial robustness on image\nclassification tasks. After briefly reviewing plenty of representative attack\nand defense methods, we perform large-scale experiments with two robustness\ncurves as the fair-minded evaluation criteria to fully understand the\nperformance of these methods. Based on the evaluation results, we draw several\nimportant findings and provide insights for future research.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 12:37:01 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Dong", "Yinpeng", ""], ["Fu", "Qi-An", ""], ["Yang", "Xiao", ""], ["Pang", "Tianyu", ""], ["Su", "Hang", ""], ["Xiao", "Zihao", ""], ["Zhu", "Jun", ""]]}, {"id": "1912.11951", "submitter": "Roshan Dathathri", "authors": "Roshan Dathathri, Blagovesta Kostova, Olli Saarikivi, Wei Dai, Kim\n  Laine, Madanlal Musuvathi", "title": "EVA: An Encrypted Vector Arithmetic Language and Compiler for Efficient\n  Homomorphic Computation", "comments": null, "journal-ref": "Programming Language Design and Implementation (PLDI 2020) 546-561", "doi": "10.1145/3385412.3386023", "report-no": null, "categories": "cs.CR cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully-Homomorphic Encryption (FHE) offers powerful capabilities by enabling\nsecure offloading of both storage and computation, and recent innovations in\nschemes and implementations have made it all the more attractive. At the same\ntime, FHE is notoriously hard to use with a very constrained programming model,\na very unusual performance profile, and many cryptographic constraints.\nExisting compilers for FHE either target simpler but less efficient FHE schemes\nor only support specific domains where they can rely on expert-provided\nhigh-level runtimes to hide complications.\n  This paper presents a new FHE language called Encrypted Vector Arithmetic\n(EVA), which includes an optimizing compiler that generates correct and secure\nFHE programs, while hiding all the complexities of the target FHE scheme.\nBolstered by our optimizing compiler, programmers can develop efficient\ngeneral-purpose FHE applications directly in EVA. For example, we have\ndeveloped image processing applications using EVA, with a very few lines of\ncode.\n  EVA is designed to also work as an intermediate representation that can be a\ntarget for compiling higher-level domain-specific languages. To demonstrate\nthis, we have re-targeted CHET, an existing domain-specific compiler for neural\nnetwork inference, onto EVA. Due to the novel optimizations in EVA, its\nprograms are on average 5.3x faster than those generated by CHET. We believe\nthat EVA would enable a wider adoption of FHE by making it easier to develop\nFHE applications and domain-specific FHE compilers.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 00:24:26 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 16:15:19 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Dathathri", "Roshan", ""], ["Kostova", "Blagovesta", ""], ["Saarikivi", "Olli", ""], ["Dai", "Wei", ""], ["Laine", "Kim", ""], ["Musuvathi", "Madanlal", ""]]}, {"id": "1912.12043", "submitter": "Volodymyr Sokolov", "authors": "Davyd Kurbanmuradov, Volodymyr Sokolov, Volodymyr Astapenya", "title": "Implementation of XTEA Encryption Protocol based on IEEE 802.15.4\n  Wireless Systems", "comments": "in Ukrainian", "journal-ref": "Cybersecurity: Education, Science, Technique (ISSN: 2663-4023),\n  no. 6(2), 2019", "doi": "10.28925/2663-4023.2019.6.3245", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The problem of data security in IEEE 802.15.4 systems on Pololu Wixel devices\nis solved, examples of hardware and software implementation of encryption and\ndecryption of different devices on the same platform are given. The proposed\napproaches can be used in the development, implementation and operation of\nwireless enterprise, industrial, and personal systems. Possible areas of\ndevelopment for this work are related to research on improving encryption\nalgorithms (increasing key length, using asymmetric ciphers, etc.), comparing\ntheir performance, and implementing a complete data exchange protocol. During\nthe work there were problems in the implementation of encryption algorithms on\nlow-power processors. During the work, a number of issues were resolved\nregarding type reduction, addressing, memory space, buffer overflow, and more.\nIssues resolved with reconciliation of receiver and transmitter operation.\nExamples of hardware and software implementation of encryption and decryption\nof different devices based on Pololu Wixel are given in the paper. The basic\ntask of building a secure communication channel by encrypting data in the\nchannel was solved and firmware and application software were obtained to fully\nvalidate the devices. In addition, this work has great application potential,\nsince the implementation of encryption in existing systems will have a small\nimpact on implementation and will not affect the project budget, but will\ndramatically improve the security of data transmission in these networks. The\nproposed approaches can be used in the development, implementation and\noperation of wireless enterprise, industrial, and personal systems. Continuing\nthis work may be to test the performance of other protocols on this and similar\nhardware for systems that may be embedded in short-range wireless communication\nprojects of short-range standards.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 10:05:01 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Kurbanmuradov", "Davyd", ""], ["Sokolov", "Volodymyr", ""], ["Astapenya", "Volodymyr", ""]]}, {"id": "1912.12060", "submitter": "Yining Hu", "authors": "Yining Hu, Suranga Seneviratne, Kanchana Thilakarathna, Kensuke\n  Fukuda, Aruna Seneviratne", "title": "Characterizing and Detecting Money Laundering Activities on the Bitcoin\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin is by far the most popular crypto-currency solution enabling\npeer-to-peer payments. Despite some studies highlighting the network does not\nprovide full anonymity, it is still being heavily used for a wide variety of\ndubious financial activities such as money laundering, ponzi schemes, and\nransom-ware payments. In this paper, we explore the landscape of potential\nmoney laundering activities occurring across the Bitcoin network. Using data\ncollected over three years, we create transaction graphs and provide an\nin-depth analysis on various graph characteristics to differentiate money\nlaundering transactions from regular transactions. We found that the main\ndifference between laundering and regular transactions lies in their output\nvalues and neighbourhood information. Then, we propose and evaluate a set of\nclassifiers based on four types of graph features: immediate neighbours,\ncurated features, deepwalk embeddings, and node2vec embeddings to classify\nmoney laundering and regular transactions. Results show that the node2vec-based\nclassifier outperforms other classifiers in binary classification reaching an\naverage accuracy of 92.29% and an F1-measure of 0.93 and high robustness over a\n2.5-year time span. Finally, we demonstrate how effective our classifiers are\nin discovering unknown laundering services. The classifier performance dropped\ncompared to binary classification, however, the prediction can be improved with\nsimple ensemble techniques for some services.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 11:34:41 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Hu", "Yining", ""], ["Seneviratne", "Suranga", ""], ["Thilakarathna", "Kanchana", ""], ["Fukuda", "Kensuke", ""], ["Seneviratne", "Aruna", ""]]}, {"id": "1912.12122", "submitter": "Devashish Khulbe", "authors": "Soumya Sourav, Devashish Khulbe, Naman Kapoor", "title": "Deep Learning Based Android Malware Detection Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development in the field of smartphones and ever growing base of\nInternet, various softwares are left prone to many malicious activities like\npharming, phishing, ransomware, spam, spoofing, spyware, eavesdropping, etc.\nThese threats have not spared the smartphones which are equally prone to them.\nIn this work, we aim to detect these malwares with accuracy and efficiency.\nThis being essentially a classification problem, we use various machine\nlearning methods for this task. We observe that across models, Attention based\nArtificial Neural Networks (ANN), or broadly speaking, Deep Learning, are most\nsuitable for this problem. Attention based ANNs are an amalgamation of accuracy\nand efficiency, the crux of our work. The accuracy achieved by our model is\naround 96.75\\%. Our model runs the test on Android Package Files (APKs) to\ndetermine whether a particular application is malicious or not by doing\nbehavior analysis on android application under consideration.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 16:13:04 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Sourav", "Soumya", ""], ["Khulbe", "Devashish", ""], ["Kapoor", "Naman", ""]]}, {"id": "1912.12141", "submitter": "Alain Brenzikofer", "authors": "Alain Brenzikofer", "title": "encointer -- Local Community Cryptocurrencies with Universal Basic\n  Income", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Encointer proposes a blockchain platform for local community\ncryptocurrencies. Individuals can claim a universal basic income through\nissuance of fresh money. Money supply is kept in proportion to population size\nthrough the use of demurrage. Sybil attacks are prevented by regular,\nconcurrent and randomized pseudonym key signing parties to obtain a\nproof-of-personhood. Encointer features privacy by design and purchasing-power\nadjusted transaction fees.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 14:27:55 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 20:01:03 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Brenzikofer", "Alain", ""]]}, {"id": "1912.12143", "submitter": "Ahmed A. Mawgoud", "authors": "Ahmed A. Mawgoud, Ahmed I. Karadawy, Benbella S. Tawfik", "title": "A Secure Authentication Technique in Internet of Medical Things through\n  Machine Learning", "comments": null, "journal-ref": null, "doi": "10.6084/m9.figshare.13311479.v2", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rapid growth of the Internet of Things technology in healthcare domain\nled to the appearance of many security threats and risks. It became very\nchallenging to provide full protection with the expansion in using sensor\nobjects in medical field, this led to the Internet of Medical Things\ndefinition, the security part in IoMT poses a perilous problem that keeps\ngrowing, because of the data sensitivity and critical information. The lack of\nproviding a secure environment in IoMT may lead to patients privacy issues, not\nonly leaving the data privacy of the patients at risk but also their lives can\nbe in danger. In this paper, we provide a discussion on both definition and\narchitecture of the Internet of Medical Things and Propose a new authentication\napproach through machine learning, to enhance the security level.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 16:05:51 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 05:20:10 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2020 06:25:35 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Mawgoud", "Ahmed A.", ""], ["Karadawy", "Ahmed I.", ""], ["Tawfik", "Benbella S.", ""]]}, {"id": "1912.12170", "submitter": "Woohyung Chun", "authors": "Woohyung Chun, Sung-Min Hong, Junho Huh, Inyup Kang", "title": "Mitigating large adversarial perturbations on X-MAS (X minus Moving\n  Averaged Samples)", "comments": "X-MAS is the essential condition for the proposed mitigation as well\n  as human beings. The codes and data for evaluation are available in\n  https://github.com/stonylinux/mitigating_large_adversarial_perturbations_on_X-MAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the scheme that mitigates the adversarial perturbation $\\epsilon$\non the adversarial example $X_{adv}$ ($=$ $X$ $\\pm$ $\\epsilon$, $X$ is a benign\nsample) by subtracting the estimated perturbation $\\hat{\\epsilon}$ from $X$ $+$\n$\\epsilon$ and adding $\\hat{\\epsilon}$ to $X$ $-$ $\\epsilon$. The estimated\nperturbation $\\hat{\\epsilon}$ comes from the difference between $X_{adv}$ and\nits moving-averaged outcome $W_{avg}*X_{adv}$ where $W_{avg}$ is $N \\times N$\nmoving average kernel that all the coefficients are one. Usually, the adjacent\nsamples of an image are close to each other such that we can let $X$ $\\approx$\n$W_{avg}*X$ (naming this relation after X-MAS[X minus Moving Averaged\nSamples]). By doing that, we can make the estimated perturbation\n$\\hat{\\epsilon}$ falls within the range of $\\epsilon$. The scheme is also\nextended to do the multi-level mitigation by configuring the mitigated\nadversarial example $X_{adv}$ $\\pm$ $\\hat{\\epsilon}$ as a new adversarial\nexample to be mitigated. The multi-level mitigation gets $X_{adv}$ closer to\n$X$ with a smaller (i.e. mitigated) perturbation than original unmitigated\nperturbation by setting the moving averaged adversarial sample $W_{avg} *\nX_{adv}$ (which has the smaller perturbation than $X_{adv}$ if $X$ $\\approx$\n$W_{avg}*X$) as the boundary condition that the multi-level mitigation cannot\ncross over (i.e. decreasing $\\epsilon$ cannot go below and increasing\n$\\epsilon$ cannot go beyond). With the multi-level mitigation, we can get high\nprediction accuracies even in the adversarial example having a large\nperturbation (i.e. $\\epsilon$ $>$ $16$). The proposed scheme is evaluated with\nadversarial examples crafted by the FGSM (Fast Gradient Sign Method) based\nattacks on ResNet-50 trained with ImageNet dataset.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 22:37:12 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2019 13:52:44 GMT"}, {"version": "v3", "created": "Mon, 13 Jan 2020 11:23:15 GMT"}, {"version": "v4", "created": "Thu, 23 Jan 2020 14:16:36 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Chun", "Woohyung", ""], ["Hong", "Sung-Min", ""], ["Huh", "Junho", ""], ["Kang", "Inyup", ""]]}, {"id": "1912.12172", "submitter": "Ehsan Meamari", "authors": "Khadijeh Afhamisisi, Hadi Shahriar Shahhoseini, Ehsan Meamari", "title": "Defense against Lion Attack in Cognitive Radio Systems using the Markov\n  Decision Process Approach", "comments": null, "journal-ref": "Frequenz, 2014", "doi": "10.1515/freq-2013-0048", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive Radio (CR) technology is a solution to solve the lack of spectrum\nby allowing the secondary user to use licensed bands. There are several\npotential security challenges for cognitive radio like Jamming, PUE and Lion\nattack. Lion attack is multi layer attacks that has effected on two layers. The\nLion attack uses PUE or jamming attack in physical layer to disrupt TCP\nprotocol in transport layer. Since transport layer is unaware of physical layer\nsituation, when it occurs to an unacknowledged packet, there is no way to\ndistinguish between congestion and disconnection in the physical layer. So the\nwindows size of TCP would be decrease because of a wrong decision caused by\nunawareness. To Mitigate the Lion attack the cross layer design is usually used\nto freeze its windows size during frequency handoff. The main issue in this\nsolution is finding the best strategy for freezing. In this paper, we propose a\ndynamic method for freezing and performing frequency handoff to counter Lion\nattack. Also a learning model based on Markov decision process (MDP) is\napplied. By using the proposed method, the secondary user can choose an optimal\nstrategy in both physical and transport layers to reduce the effect of Lion\nattack.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 05:29:52 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Afhamisisi", "Khadijeh", ""], ["Shahhoseini", "Hadi Shahriar", ""], ["Meamari", "Ehsan", ""]]}, {"id": "1912.12173", "submitter": "Ehsan Meamari", "authors": "Ehsan Meamari, Khadijeh Afhamisisi, Hadi Shahriar Shahhoseini", "title": "Game-theory-based analysis on interactions among secondary and malicious\n  users in coordinated jamming attack in cognitive radio systems", "comments": null, "journal-ref": "Journal of Circuits, Systems and Computers, 2016", "doi": "10.1142/S0218126616500973", "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IEEE 802.22 standard utilizes cognitive radio (CR) techniques to allow\nsharing unused spectrum band. The cognitive radio is vulnerable to various\nattacks such as jamming attacks. This paper has focused on coordinated jamming\nattacks. A simple strategy for secondary users is to change their bands and\nswitch to other appropriate bands when the jamming attack is occurred. Also,\nthe malicious users should switch to other bands in order to jam the secondary\nusers. To address this problem, a game theoretical method is proposed to\nanalyze coordinated jamming attacks in CR. Then, using Nash equilibrium on the\nproposed game, the most appropriate bands have been found to switch as well as\nthe optimal switching probabilities for both secondary and malicious users.\nMeanwhile, effects of different parameters like the number of malicious users\nare investigated in changing the optimal switching probabilities by analysis on\nthe model.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 04:56:47 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Meamari", "Ehsan", ""], ["Afhamisisi", "Khadijeh", ""], ["Shahhoseini", "Hadi Shahriar", ""]]}, {"id": "1912.12174", "submitter": "Ehsan Meamari", "authors": "Ehsan Meamari, Khadijeh Afhamisisi, Hadi Shahriar Shahhoseini", "title": "An Analysis on Interactions among Secondary User and Unknown Jammer in\n  Cognitive Radio Systems by Fictitious Play", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": "10.1109/ISCISC.2013.6767327", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancement of communication, the spectrum shortage problem becomes\na serious problem for future generations. The cognitive radio technology is\nproposed to address this concern. In cognitive radio networks, the secondary\nusers can access spectrum that allocated to the primary users without\ninterference to the operation of primary users. Using cognitive radio network\nraises security issues such as jamming attack. A straightforward strategy to\ncounter the jamming attack is to switch other bands. Finding the best strategy\nfor switching is complicated when the malicious user is unknown to the primary\nusers. This paper uses fictitious game for analysis the defense against such an\nunknown jammer.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 04:01:21 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Meamari", "Ehsan", ""], ["Afhamisisi", "Khadijeh", ""], ["Shahhoseini", "Hadi Shahriar", ""]]}, {"id": "1912.12221", "submitter": "Sarwan Ali", "authors": "Sarwan Ali, Maria Khalid Alvi, Safi Faizullah, Muhammad Asad Khan,\n  Abdullah Alshanqiti, Imdadullah Khan", "title": "Detecting DDoS Attack on SDN Due to Vulnerabilities in OpenFlow", "comments": "Accepted to International Conference on Advances in the Emerging\n  Computing Technologies (AECT) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software Defined Networking (SDN) is a network paradigm shift that\nfacilitates comprehensive network programmability to cope with emerging new\ntechnologies such as cloud computing and big data. SDN facilitates simplified\nand centralized network management enabling it to operate in dynamic scenarios.\nFurther, SDN uses the OpenFlow protocol for communication between the\ncontroller and its switches. The OpenFlow creates vulnerabilities for network\nattacks especially Distributed Denial of Service (DDoS). DDoS attacks are\nlaunched from the compromised hosts connected to the SDN switches. In this\npaper, we introduce a time- and space-efficient solution for the identification\nof these compromised hosts. Our solution consumes less computational resources\nand space and does not require any special equipment.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 16:26:39 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 12:42:07 GMT"}, {"version": "v3", "created": "Wed, 8 Jan 2020 20:45:55 GMT"}, {"version": "v4", "created": "Sun, 2 Feb 2020 19:06:33 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Ali", "Sarwan", ""], ["Alvi", "Maria Khalid", ""], ["Faizullah", "Safi", ""], ["Khan", "Muhammad Asad", ""], ["Alshanqiti", "Abdullah", ""], ["Khan", "Imdadullah", ""]]}, {"id": "1912.12225", "submitter": "Mohammadreza Darabi", "authors": "Mohammadreza Darabi", "title": "Securing Cluster-heads in Wireless Sensor Networks by a Hybrid Intrusion\n  Detection System Based on Data Mining", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Cluster-based Wireless Sensor Network (CWSN) is a kind of WSNs that because\nof avoiding long distance communications, preserve the energy of nodes and so\nis attractive for related applications. The criticality of most applications of\nWSNs and also their unattended nature, makes sensor nodes often susceptible to\nmany types of attacks. Based on this fact, it is clear that cluster heads (CHs)\nare the most attacked targets by attackers, and also according to their\ncritical operations in CWSNs, their compromise and control by an attacker will\ndisrupt the entire cluster and sometimes the entire network, so their security\nneeds more attentiveness and must be ensured. In this paper, we introduce a\nhybrid Intrusion Detection System (HIDS) for securing CHs, to take advantages\nof both anomaly-based and misuse-based detection methods, that is high\ndetection and low false alarm rate. Also by using a novel preprocessing model,\nsignificantly reduces the computational and memory complexities of the proposed\nIDS, and finally allows the use of the clustering algorithms for it. The\nsimulation results show that the proposed IDS in comparison to existing works,\nwhich often have high computational and memory complexities, can be as an\neffective and lightweight IDS for securing CHs.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 05:15:25 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Darabi", "Mohammadreza", ""]]}, {"id": "1912.12257", "submitter": "William Buchanan Prof", "authors": "Jon Barton, William J Buchanan, Will Abramson, Nikolaos Pitropakis", "title": "Performance Analysis of TLS for Quantum Robust Cryptography on a\n  Constrained Device", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in quantum computing make Shor's algorithm for factorising numbers\never more tractable. This threatens the security of any cryptographic system\nwhich often relies on the difficulty of factorisation. It also threatens\nmethods based on discrete logarithms, such as with the Diffie-Hellman key\nexchange method. For a cryptographic system to remain secure against a quantum\nadversary, we need to build methods based on a hard mathematical problem, which\nare not susceptible to Shor's algorithm and which create Post Quantum\nCryptography (PQC). While high-powered computing devices may be able to run\nthese new methods, we need to investigate how well these methods run on limited\npowered devices. This paper outlines an evaluation framework for PQC within\nconstrained devices, and contributes to the area by providing benchmarks of the\nfront-running algorithms on a popular single-board low-power device.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 08:33:19 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Barton", "Jon", ""], ["Buchanan", "William J", ""], ["Abramson", "Will", ""], ["Pitropakis", "Nikolaos", ""]]}, {"id": "1912.12363", "submitter": "Michael Reiter", "authors": "Adam Humphries (University of North Carolina at Chapel Hill), Kartik\n  Cating-Subramanian (University of Colorado -- Boulder), Michael K. Reiter\n  (University of North Carolina at Chapel Hill)", "title": "TASE: Reducing latency of symbolic execution with transactional memory", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the design and implementation of a tool called TASE that uses\ntransactional memory to reduce the latency of symbolic-execution applications\nwith small amounts of symbolic state. Execution paths are executed natively\nwhile operating on concrete values, and only when execution encounters symbolic\nvalues (or modeled functions) is native execution suspended and interpretation\nbegun. Execution then returns to its native mode when symbolic values are no\nlonger encountered. The key innovations in the design of TASE are a technique\nfor amortizing the cost of checking whether values are symbolic over few\ninstructions, and the use of hardware-supported transactional memory (TSX) to\nimplement native execution that rolls back with no effect when use of a\nsymbolic value is detected (perhaps belatedly). We show that TASE has the\npotential to dramatically improve some latency-sensitive applications of\nsymbolic execution, such as methods to verify the behavior of a client in a\nclient-server application.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 23:18:55 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Humphries", "Adam", "", "University of North Carolina at Chapel Hill"], ["Cating-Subramanian", "Kartik", "", "University of Colorado -- Boulder"], ["Reiter", "Michael K.", "", "University of North Carolina at Chapel Hill"]]}, {"id": "1912.12370", "submitter": "Josh Payne", "authors": "Josh Payne and Ashish Kundu", "title": "Towards Deep Federated Defenses Against Malware in Cloud Ecosystems", "comments": "IEEE International Conference on Trust, Privacy and Security in\n  Intelligent Systems, and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cloud computing environments with many virtual machines, containers, and\nother systems, an epidemic of malware can be highly threatening to business\nprocesses. In this vision paper, we introduce a hierarchical approach to\nperforming malware detection and analysis using several recent advances in\nmachine learning on graphs, hypergraphs, and natural language. We analyze\nindividual systems and their logs, inspecting and understanding their behavior\nwith attentional sequence models. Given a feature representation of each\nsystem's logs using this procedure, we construct an attributed network of the\ncloud with systems and other components as vertices and propose an analysis of\nmalware with inductive graph and hypergraph learning models. With this\nfoundation, we consider the multicloud case, in which multiple clouds with\ndiffering privacy requirements cooperate against the spread of malware,\nproposing the use of federated learning to perform inference and training while\npreserving privacy. Finally, we discuss several open problems that remain in\ndefending cloud computing environments against malware related to designing\nrobust ecosystems, identifying cloud-specific optimization problems for\nresponse strategy, action spaces for malware containment and eradication, and\ndeveloping priors and transfer learning tasks for machine learning models in\nthis area.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 23:46:06 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Payne", "Josh", ""], ["Kundu", "Ashish", ""]]}, {"id": "1912.12373", "submitter": "Josh Payne", "authors": "Josh Payne, Karan K. Budhraja, Ashish Kundu", "title": "How Secure Is Your IoT Network?", "comments": "IEEE International Congress on Internet of Things", "journal-ref": null, "doi": "10.1109/ICIOT.2019.00038", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of IoT devices in smart homes, hospitals, and enterprise\nnetworks is widespread and continuing to increase in a superlinear manner. With\nthis unprecedented growth, how can one assess the security of an IoT network\nholistically? In this article, we explore two dimensions of security\nassessment, using vulnerability information of IoT devices and their underlying\ncomponents ($\\textit{compositional security scores}$) and SIEM logs captured\nfrom the communications and operations of such devices in a network\n($\\textit{dynamic activity metrics}$) to propose the notion of an\n$\\textit{attack circuit}$. These measures are used to evaluate the security of\nIoT devices and the overall IoT network, demonstrating the effectiveness of\nattack circuits as practical tools for computing security metrics\n(exploitability, impact, and risk to confidentiality, integrity, and\navailability) of heterogeneous networks. We propose methods for generating\nattack circuits with input/output pairs constructed from CVEs using natural\nlanguage processing (NLP) and with weights computed using standard security\nscoring procedures, as well as efficient optimization methods for evaluating\nattack circuits. Our system provides insight into possible attack paths an\nadversary may utilize based on their exploitability, impact, or overall risk.\nWe have performed experiments on IoT networks to demonstrate the efficacy of\nthe proposed techniques.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 00:07:13 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Payne", "Josh", ""], ["Budhraja", "Karan K.", ""], ["Kundu", "Ashish", ""]]}, {"id": "1912.12576", "submitter": "Farhad Farokhi", "authors": "Farhad Farokhi", "title": "Privacy-Preserving Public Release of Datasets for Support Vector Machine\n  Classification", "comments": null, "journal-ref": "IEEE Transactions on Big Data, 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of publicly releasing a dataset for support vector\nmachine classification while not infringing on the privacy of data subjects\n(i.e., individuals whose private information is stored in the dataset). The\ndataset is systematically obfuscated using an additive noise for privacy\nprotection. Motivated by the Cramer-Rao bound, inverse of the trace of the\nFisher information matrix is used as a measure of the privacy. Conditions are\nestablished for ensuring that the classifier extracted from the original\ndataset and the obfuscated one are close to each other (capturing the utility).\nThe optimal noise distribution is determined by maximizing a weighted sum of\nthe measures of privacy and utility. The optimal privacy-preserving noise is\nproved to achieve local differential privacy. The results are generalized to a\nbroader class of optimization-based supervised machine learning algorithms.\nApplicability of the methodology is demonstrated on multiple datasets.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 03:32:38 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Farokhi", "Farhad", ""]]}, {"id": "1912.12640", "submitter": "Benedetta Tondi", "authors": "Mauro Barni, Quoc-Tin Phan, Benedetta Tondi", "title": "Copy Move Source-Target Disambiguation through Multi-Branch CNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to identify the source and target regions of a copy-move\nforgery so allow a correct localisation of the tampered area. First, we cast\nthe problem into a hypothesis testing framework whose goal is to decide which\nregion between the two nearly-duplicate regions detected by a generic copy-move\ndetector is the original one. Then we design a multi-branch CNN architecture\nthat solves the hypothesis testing problem by learning a set of features\ncapable to reveal the presence of interpolation artefacts and boundary\ninconsistencies in the copy-moved area. The proposed architecture, trained on a\nsynthetic dataset explicitly built for this purpose, achieves good results on\ncopy-move forgeries from both synthetic and realistic datasets. Based on our\ntests, the proposed disambiguation method can reliably reveal the target region\neven in realistic cases where an approximate version of the copy-move\nlocalization mask is provided by a state-of-the-art copy-move detection\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 11:56:33 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 10:24:36 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Barni", "Mauro", ""], ["Phan", "Quoc-Tin", ""], ["Tondi", "Benedetta", ""]]}, {"id": "1912.12673", "submitter": "Steven McElwee", "authors": "Steven McElwee and James Cannady", "title": "Cyber Situation Awareness with Active Learning for Intrusion Detection", "comments": "McElwee, S. & Cannady, J. (2019). Cyber situation awareness with\n  active learning for intrusion detection. SoutheastCon 2019. IEEE. Pre-print", "journal-ref": "IEEE SoutheastCon (2019) 1-7", "doi": "10.1109/SoutheastCon42311.2019.9020599", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrusion detection has focused primarily on detecting cyberattacks at the\nevent-level. Since there is such a large volume of network data and attacks are\nminimal, machine learning approaches have focused on improving accuracy and\nreducing false positives, but this has frequently resulted in overfitting. In\naddition, the volume of intrusion detection alerts is large and creates fatigue\nin the human analyst who must review them. This research addresses the problems\nassociated with event-level intrusion detection and the large volumes of\nintrusion alerts by applying active learning and cyber situation awareness.\nThis paper includes the results of two experiments using the UNSW-NB15 dataset.\nThe first experiment evaluated sampling approaches for querying the oracle, as\npart of active learning. It then trained a Random Forest classifier using the\nsamples and evaluated its results. The second experiment applied cyber\nsituation awareness by aggregating the detection results of the first\nexperiment and calculating the probability that a computer system was part of a\ncyberattack. This research showed that moving the perspective of event-level\nalerts to the probability that a computer system was part of an attack improved\nthe accuracy of detection and reduced the volume of alerts that a human analyst\nwould need to review.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 15:25:22 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["McElwee", "Steven", ""], ["Cannady", "James", ""]]}, {"id": "1912.12716", "submitter": "Zhaoxian Wu", "authors": "Zhaoxian Wu, Qing Ling, Tianyi Chen, and Georgios B. Giannakis", "title": "Federated Variance-Reduced Stochastic Gradient Descent with Robustness\n  to Byzantine Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with distributed finite-sum optimization for learning over\nnetworks in the presence of malicious Byzantine attacks. To cope with such\nattacks, most resilient approaches so far combine stochastic gradient descent\n(SGD) with different robust aggregation rules. However, the sizeable\nSGD-induced stochastic gradient noise makes it challenging to distinguish\nmalicious messages sent by the Byzantine attackers from noisy stochastic\ngradients sent by the 'honest' workers. This motivates us to reduce the\nvariance of stochastic gradients as a means of robustifying SGD in the presence\nof Byzantine attacks. To this end, the present work puts forth a Byzantine\nattack resilient distributed (Byrd-) SAGA approach for learning tasks involving\nfinite-sum optimization over networks. Rather than the mean employed by\ndistributed SAGA, the novel Byrd- SAGA relies on the geometric median to\naggregate the corrected stochastic gradients sent by the workers. When less\nthan half of the workers are Byzantine attackers, the robustness of geometric\nmedian to outliers enables Byrd-SAGA to attain provably linear convergence to a\nneighborhood of the optimal solution, with the asymptotic learning error\ndetermined by the number of Byzantine workers. Numerical tests corroborate the\nrobustness to various Byzantine attacks, as well as the merits of Byrd- SAGA\nover Byzantine attack resilient distributed SGD.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 19:46:03 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 07:34:10 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Wu", "Zhaoxian", ""], ["Ling", "Qing", ""], ["Chen", "Tianyi", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1912.12828", "submitter": "Feng Xiao", "authors": "Feng Xiao and Qiang Xu", "title": "ICSTrace: A Malicious IP Traceback Model for Attacking Data of\n  Industrial Control System", "comments": "14 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering the attacks against industrial control system are mostly\norganized and premeditated actions, IP traceback is significant for the\nsecurity of industrial control system. Based on the infrastructure of the\nInternet, we have developed a novel malicious IP traceback model-ICSTrace,\nwithout deploying any new services. The model extracts the function codes and\ntheir parameters from the attack data according to the format of industrial\ncontrol protocol, and employs a short sequence probability method to transform\nthe function codes and their parameter into a vector, which characterizes the\nattack pattern of malicious IP addresses. Furthermore, a Partial Seeded K-Means\nalgorithm is proposed for the pattern's clustering, which helps in tracing the\nattacks back to an organization. ICSTrace is evaluated basing on the attack\ndata captured by the large-scale deployed honeypots for industrial control\nsystem, and the results demonstrate that ICSTrace is effective on malicious IP\ntraceback in industrial control system.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 07:00:32 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Xiao", "Feng", ""], ["Xu", "Qiang", ""]]}, {"id": "1912.12884", "submitter": "Sanjay Sahay", "authors": "Trupil Limbasiya, Debasis Das and Sanjay K. Sahay", "title": "Secure Communication Protocol for Smart Transportation Based on\n  Vehicular Cloud", "comments": "10 Pages, 1 figure, Conference", "journal-ref": "ACM Proceedings of the 2019 ACM International Joint Conference on\n  Pervasive and Ubiquitous Computing and Proceedings of the 2019 ACM\n  International Symposium on Wearable Computers, pp. 372-376", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pioneering concept of connected vehicles has transformed the way of\nthinking for researchers and entrepreneurs by collecting relevant data from\nnearby objects. However, this data is useful for a specific vehicle only.\nMoreover, vehicles get a high amount of data (e.g., traffic, safety, and\nmultimedia infotainment) on the road. Thus, vehicles expect adequate storage\ndevices for this data, but it is infeasible to have a large memory in each\nvehicle. Hence, the vehicular cloud computing (VCC) framework came into the\npicture to provide a storage facility by connecting a road-side-unit (RSU) with\nthe vehicular cloud (VC). In this, data should be saved in an encrypted form to\npreserve security, but there is a challenge to search for information over\nencrypted data. Next, we understand that many of vehicular communication\nschemes are inefficient for data transmissions due to its poor performance\nresults and vulnerable to different fundamental security attacks. Accordingly,\non-device performance is critical, but data damages and secure on-time\nconnectivity are also significant challenges in a public environment.\nTherefore, we propose reliable data transmission protocols for cutting-edge\narchitecture to search data from the storage, to resist against various\nsecurity attacks, and provide better performance results. Thus, the proposed\ndata transmission protocol is useful in diverse smart city applications\n(business, safety, and entertainment) for the benefits of society.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 11:15:14 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 15:17:11 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Limbasiya", "Trupil", ""], ["Das", "Debasis", ""], ["Sahay", "Sanjay K.", ""]]}, {"id": "1912.12915", "submitter": "Chengqing Li", "authors": "Yunling Ma, Chengqing Li, Bo Ou", "title": "Cryptanalysis of an Image Block Encryption Algorithm Based on Chaotic\n  Maps", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, an image block encryption algorithm was proposed based on some\nwell-known chaotic maps. The authors claim that the encryption algorithm\nachieves enough security level and high encryption speed at the same time. In\nthis paper, we give a thorough security analysis on the algorithm from the\nperspective of modern cryptology and report some critical security defects on\nthe algorithm. Given five chosen plain-images and the corresponding\ncipher-images, the attacker can obtain an equivalent secret key to successfully\ndecrypt the other cipher-images encrypted with the same secret key. In\naddition, each security metric adopted in the security evaluation on the\nalgorithm is questioned. The drawn lessons are generally applicable to many\nother image encryption algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 13:08:31 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 05:18:58 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Ma", "Yunling", ""], ["Li", "Chengqing", ""], ["Ou", "Bo", ""]]}, {"id": "1912.12982", "submitter": "Daoyuan Wu", "authors": "Daoyuan Wu and Debin Gao and David Lo", "title": "Scalable Online Vetting of Android Apps for Measuring Declared SDK\n  Versions and Their Consistency with API Calls", "comments": "This article extends our preliminary conference version at WASA'17,\n  see https://link.springer.com/chapter/10.1007/978-3-319-60033-8_58 and\n  arXiv:1702.04872", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android has been the most popular smartphone system with multiple platform\nversions active in the market. To manage the application's compatibility with\none or more platform versions, Android allows apps to declare the supported\nplatform SDK versions in their manifest files. In this paper, we conduct a\nsystematic study of this modern software mechanism. Our objective is to measure\nthe current practice of declared SDK versions (which we term as DSDK versions\nafterwards) in real apps, and the (in)consistency between DSDK versions and\ntheir host apps' API calls. To successfully analyze a modern dataset of 22,687\npopular apps (with an average app size of 25MB), we design a scalable approach\nthat operates on the Android bytecode level and employs a lightweight bytecode\nsearch for app analysis. This approach achieves a good performance suitable for\nonline vetting in app markets, requiring only around 5 seconds to process an\napp on average. Besides shedding light on the characteristics of DSDK in the\nwild, our study quantitatively measures two side effects of inappropriate DSDK\nversions: (i) around 35% apps under-set the minimum DSDK versions and could\nincur runtime crashes, but fortunately, only 11.3% apps could crash on Android\n6.0 and above; (ii) around 2% apps, due to under-claiming the targeted DSDK\nversions, are potentially exploitable by remote code execution, and half of\nthem invoke the vulnerable API via embedded third-party libraries. These\nresults indicate the importance and difficulty of declaring correct DSDK, and\nour work can help developers fulfill this goal.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 16:20:57 GMT"}, {"version": "v2", "created": "Sun, 31 May 2020 09:13:52 GMT"}, {"version": "v3", "created": "Mon, 31 Aug 2020 09:29:22 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Wu", "Daoyuan", ""], ["Gao", "Debin", ""], ["Lo", "David", ""]]}, {"id": "1912.13046", "submitter": "Edward Raff", "authors": "Edward Raff, Charles Nicholas, Mark McLean", "title": "A New Burrows Wheeler Transform Markov Distance", "comments": "To appear in: The Thirty-Fourth AAAI Conference on Artificial\n  Intelligence (AAAI-20), AICS-2020 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work inspired by compression algorithms has described how the Burrows\nWheeler Transform can be used to create a distance measure for bioinformatics\nproblems. We describe issues with this approach that were not widely known, and\nintroduce our new Burrows Wheeler Markov Distance (BWMD) as an alternative. The\nBWMD avoids the shortcomings of earlier efforts, and allows us to tackle\nproblems in variable length DNA sequence clustering. BWMD is also more\nadaptable to other domains, which we demonstrate on malware classification\ntasks. Unlike other compression-based distance metrics known to us, BWMD works\nby embedding sequences into a fixed-length feature vector. This allows us to\nprovide significantly improved clustering performance on larger malware\ncorpora, a weakness of prior methods.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 18:33:32 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Raff", "Edward", ""], ["Nicholas", "Charles", ""], ["McLean", "Mark", ""]]}, {"id": "1912.13120", "submitter": "Masahito Hayashi", "authors": "Masahito Hayashi and Angeles Vazquez-Castro", "title": "Physical Layer Security Protocol for Poisson Channels for Passive\n  Man-in-the-middle Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we focus on the classical optical channel having Poissonian\nstatistical behavior and propose a novel secrecy coding-based physical layer\nprotocol. Our protocol is different but complementary to both (computationally\nsecure) quantum immune cryptographic protocols and (information theoretically\nsecure) quantum cryptographic protocols. Specifically, our (information\ntheoretical) secrecy coding protocol secures classical digital information bits\nat photonic level exploiting the random nature of the Poisson channel.\n  It is known that secrecy coding techniques for the Poisson channel based on\nthe classical one-way wiretap channel (introduced by Wyner in 1975) ensure\nsecret communication only if the mutual information to the eavesdropper is\nsmaller than that to the legitimate receiver. In order to overcome such a\nstrong limitation, we introduce a two-way protocol that always ensures secret\ncommunication independently of the conditions of legitimate and eavesdropper\nchannels. We prove this claim showing rigorous comparative derivation and\nanalysis of the information theoretical secrecy capacity of the classical\none-way and of the proposed two-way protocols. We also show numerical\ncalculations that prove drastic gains and strong practical potential of our\nproposed two-way protocol to secure information transmission over optical\nchannels.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 00:02:53 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Hayashi", "Masahito", ""], ["Vazquez-Castro", "Angeles", ""]]}, {"id": "1912.13156", "submitter": "Dingju Zhu", "authors": "Dingju Zhu", "title": "Hiding Information in Big Data based on Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current approach of information hiding based on deep learning model can\nnot directly use the original data as carriers, which means the approach can\nnot make use of the existing data in big data to hiding information. We\nproposed a novel method of information hiding in big data based on deep\nlearning. Our method uses the existing data in big data as carriers and uses\ndeep learning models to hide and extract secret messages in big data. The data\namount of big data is unlimited and thus the data amount of secret messages\nhided in big data can also be unlimited. Before opponents want to extract\nsecret messages from carriers, they need to find the carriers, however finding\nout the carriers from big data is just like finding out a box from the sea.\nDeep learning models are well known as deep black boxes in which the process\nfrom the input to the output is very complex, and thus the deep learning model\nfor information hiding is almost impossible for opponents to reconstruct. The\nresults also show that our method can hide secret messages safely,\nconveniently, quickly and with no limitation on the data amount.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 03:23:54 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 10:32:24 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Zhu", "Dingju", ""]]}, {"id": "1912.13204", "submitter": "Suchet Sapre", "authors": "Suchet Sapre, Pouyan Ahmadi and Khondkar Islam", "title": "A Robust Comparison of the KDDCup99 and NSL-KDD IoT Network Intrusion\n  Detection Datasets Through Various Machine Learning Algorithms", "comments": "8 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, as intrusion attacks on IoT networks have grown\nexponentially, there is an immediate need for sophisticated intrusion detection\nsystems (IDSs). A vast majority of current IDSs are data-driven, which means\nthat one of the most important aspects of this area of research is the quality\nof the data acquired from IoT network traffic. Two of the most cited intrusion\ndetection datasets are the KDDCup99 and the NSL-KDD. The main goal of our\nproject was to conduct a robust comparison of both datasets by evaluating the\nperformance of various Machine Learning (ML) classifiers trained on them with a\nlarger set of classification metrics than previous researchers. From our\nresearch, we were able to conclude that the NSL-KDD dataset is of a higher\nquality than the KDDCup99 dataset as the classifiers trained on it were on\naverage 20.18% less accurate. This is because the classifiers trained on the\nKDDCup99 dataset exhibited a bias towards the redundancies within it, allowing\nthem to achieve higher accuracies.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 07:36:33 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Sapre", "Suchet", ""], ["Ahmadi", "Pouyan", ""], ["Islam", "Khondkar", ""]]}, {"id": "1912.13410", "submitter": "Wei Zhou", "authors": "Wei Zhou, Chen Cao, Dongdong Huo, Kai Cheng, Lan Zhang, Le Guan, Tao\n  Liu, Yaowen Zheng, Yuqing Zhang, Limin Sun, Yazhe Wang, Peng Liu", "title": "Logic Bugs in IoT Platforms and Systems: A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, IoT platforms and systems have been rapidly emerging.\nAlthough IoT is a new technology, new does not mean simpler (than existing\nnetworked systems). Contrarily, the complexity (of IoT platforms and systems)\nis actually being increased in terms of the interactions between the physical\nworld and cyberspace. The increased complexity indeed results in new\nvulnerabilities. This paper seeks to provide a review of the recently\ndiscovered logic bugs that are specific to IoT platforms and systems. In\nparticular, 17 logic bugs and one weakness falling into seven categories of\nvulnerabilities are reviewed in this survey.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 16:50:24 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 22:27:33 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Zhou", "Wei", ""], ["Cao", "Chen", ""], ["Huo", "Dongdong", ""], ["Cheng", "Kai", ""], ["Zhang", "Lan", ""], ["Guan", "Le", ""], ["Liu", "Tao", ""], ["Zheng", "Yaowen", ""], ["Zhang", "Yuqing", ""], ["Sun", "Limin", ""], ["Wang", "Yazhe", ""], ["Liu", "Peng", ""]]}, {"id": "1912.13445", "submitter": "Krishna Pillutla", "authors": "Krishna Pillutla, Sham M. Kakade, Zaid Harchaoui", "title": "Robust Aggregation for Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a robust aggregation approach to make federated learning robust to\nsettings when a fraction of the devices may be sending corrupted updates to the\nserver. The proposed approach relies on a robust secure aggregation oracle\nbased on the geometric median, which returns a robust aggregate using a\nconstant number of calls to a regular non-robust secure average oracle. The\nrobust aggregation oracle is privacy-preserving, similar to the secure average\noracle it builds upon. We provide experimental results of the proposed approach\nwith linear models and deep networks for two tasks in computer vision and\nnatural language processing. The robust aggregation approach is agnostic to the\nlevel of corruption; it outperforms the classical aggregation approach in terms\nof robustness when the level of corruption is high, while being competitive in\nthe regime of low corruption.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 17:24:41 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Pillutla", "Krishna", ""], ["Kakade", "Sham M.", ""], ["Harchaoui", "Zaid", ""]]}, {"id": "1912.13501", "submitter": "Karim Banawan", "authors": "Zhusheng Wang and Karim Banawan and Sennur Ulukus", "title": "Private Set Intersection: A Multi-Message Symmetric Private Information\n  Retrieval Perspective", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.DB eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of private set intersection (PSI). In this problem,\nthere are two entities $E_i$, for $i=1, 2$, each storing a set $\\mathcal{P}_i$,\nwhose elements are picked from a finite field $\\mathbb{F}_K$, on $N_i$\nreplicated and non-colluding databases. It is required to determine the set\nintersection $\\mathcal{P}_1 \\cap \\mathcal{P}_2$ without leaking any information\nabout the remaining elements to the other entity with the least amount of\ndownloaded bits. We first show that the PSI problem can be recast as a\nmulti-message symmetric private information retrieval (MM-SPIR) problem. Next,\nas a stand-alone result, we derive the information-theoretic sum capacity of\nMM-SPIR, $C_{MM-SPIR}$. We show that with $K$ messages, $N$ databases, and the\nsize of the desired message set $P$, the exact capacity of MM-SPIR is\n$C_{MM-SPIR} = 1 - \\frac{1}{N}$ when $P \\leq K-1$, provided that the entropy of\nthe common randomness $S$ satisfies $H(S) \\geq \\frac{P}{N-1}$ per desired\nsymbol. This result implies that there is no gain for MM-SPIR over successive\nsingle-message SPIR (SM-SPIR). For the MM-SPIR problem, we present a novel\ncapacity-achieving scheme that builds on the near-optimal scheme of\nBanawan-Ulukus originally proposed for the multi-message PIR (MM-PIR) problem\nwithout database privacy constraints. Surprisingly, our scheme here is exactly\noptimal for the MM-SPIR problem for any $P$, in contrast to the scheme for the\nMM-PIR problem, which was proved only to be near-optimal. Our scheme is an\nalternative to the SM-SPIR scheme of Sun-Jafar. Based on this capacity result\nfor MM-SPIR, and after addressing the added requirements in its conversion to\nthe PSI problem, we show that the optimal download cost for the PSI problem is\n$\\min\\left\\{\\left\\lceil\\frac{P_1 N_2}{N_2-1}\\right\\rceil, \\left\\lceil\\frac{P_2\nN_1}{N_1-1}\\right\\rceil\\right\\}$, where $P_i$ is the cardinality of set\n$\\mathcal{P}_i$\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 18:51:02 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 17:17:04 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Wang", "Zhusheng", ""], ["Banawan", "Karim", ""], ["Ulukus", "Sennur", ""]]}]