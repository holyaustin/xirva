[{"id": "1606.00161", "submitter": "Hadi Farahani", "authors": "Hadi Farahani", "title": "An Alternating Qubit Protocol and Its Correctness Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a quantum version of classical alternating bit protocol is\nproposed. This protocol provides a reliable method to transmit the secret\nquantum data via a noisy quantum channel while the entanglement between\nparticles is not broken. Our protocol is based on quantum teleportation and\nsuperdense coding. By assuming that the participants can distinguish the\nalternating qubit from other messages and also the assumption that data can be\nresent unlimited times, an abstraction of this protocol can be derived. Using\nthe quantum process algebra \\textit{full} $qACP$, we show that the proposed\nprotocol is correct, so the desired external behaviour of the protocol is\nguaranteed.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 08:21:23 GMT"}], "update_date": "2016-06-02", "authors_parsed": [["Farahani", "Hadi", ""]]}, {"id": "1606.00410", "submitter": "Prashanth Reddy Busi Reddy Gari", "authors": "B. Prashanth Reddy and Subhash Kak", "title": "The binary primes sequence for computational hardening of pseudorandom\n  sequences", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the use of the binary primes sequence to strengthen\npseudorandom (PN) decimal sequences for cryptography applications. The binary\nprimes sequence is added to the PN decimal sequence (where one can choose from\nmany arbitrary shift values) and it is shown that the sum sequence has improved\nautocorrelation properties besides being computationally hard. Also, an\nanalysis on the computational complexity is performed and it is shown that the\ncomplexity for the eavesdropper is of exponential complexity and therefore, the\nproposed method is an attractive procedure for cryptographic applications.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 19:29:59 GMT"}], "update_date": "2016-06-02", "authors_parsed": [["Reddy", "B. Prashanth", ""], ["Kak", "Subhash", ""]]}, {"id": "1606.00629", "submitter": "Philippe Gaborit", "authors": "Philippe Gaborit, Olivier Ruatta, Julien Schrek, and Gilles Z\\'emor", "title": "RankSign: an efficient signature algorithm based on the rank metric", "comments": "extended version of PQCrypto conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new approach to code-based signatures that makes\nuse in particular of rank metric codes. When the classical approach consists in\nfinding the unique preimage of a syndrome through a decoding algorithm, we\npropose to introduce the notion of mixed decoding of erasures and errors for\nbuilding signature schemes. In that case the difficult problem becomes, as is\nthe case in lattice-based cryptography, finding a preimage of weight above the\nGilbert-Varshamov bound (case where many solutions occur) rather than finding a\nunique preimage of weight below the Gilbert-Varshamov bound. The paper\ndescribes RankSign: a new signature algorithm for the rank metric based on a\nnew mixed algorithm for decoding erasures and errors for the recently\nintroduced Low Rank Parity Check (LRPC) codes. We explain how it is possible\n(depending on choices of parameters) to obtain a full decoding algorithm which\nis able to find a preimage of reasonable rank weight for any random syndrome\nwith a very strong probability. We study the semantic security of our signature\nalgorithm and show how it is possible to reduce the unforgeability to direct\nattacks on the public matrix, so that no information leaks through signatures.\nFinally, we give several examples of parameters for our scheme, some of which\nwith public key of size $11,520$ bits and signature of size $1728$ bits.\nMoreover the scheme can be very fast for small base fields.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 11:26:59 GMT"}, {"version": "v2", "created": "Fri, 26 May 2017 10:42:20 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["Gaborit", "Philippe", ""], ["Ruatta", "Olivier", ""], ["Schrek", "Julien", ""], ["Z\u00e9mor", "Gilles", ""]]}, {"id": "1606.00884", "submitter": "Duy Dang-Pham", "authors": "Duy Dang-Pham, Siddhi Pittayachawan and Vince Bruno", "title": "Factors of people-centric security climate: conceptual model and\n  exploratory study in Vietnam", "comments": "Research-in-Progress ISBN# 978-0-646-95337-3 Presented at the\n  Australasian Conference on Information Systems 2015 (arXiv:1605.01032)", "journal-ref": null, "doi": null, "report-no": "ACIS/2015/65", "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There is an increasing focus on the persuasive approach to develop a\npeople-centric security climate where employees are aware of the priority of\nsecurity and perform conscious security behaviour proactively. Employees can\nevaluate the priority of security as they observe and interact with the\nsecurity features that constitute the security climate of the workplace. We\nexamined the fundamental challenge that not every employee could recognise\nthose features. In this multi-stage research, we adopted the theoretical lens\nof symbolic interactionism to advance a conceptual model which explains the\nrelationship between organisation's social networks and the formation of\ninformation security climate. A descriptive case study in Vietnam was then\nconducted to refine the proposed model. The findings validated and extended the\ndimensions of information security climate, as well as identified the relevant\norganisation's social networks (i.e. information, affect, and power) that lead\nto its formation.\n", "versions": [{"version": "v1", "created": "Sat, 28 May 2016 04:21:12 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Dang-Pham", "Duy", ""], ["Pittayachawan", "Siddhi", ""], ["Bruno", "Vince", ""]]}, {"id": "1606.00887", "submitter": "Marcus Butavicius", "authors": "Marcus Butavicius, Kathryn Parsons, Malcolm Pattinson and Agata\n  McCormac", "title": "Breaching the Human Firewall: Social engineering in Phishing and\n  Spear-Phishing Emails", "comments": "ISBN# 978-0-646-95337-3 Presented at the Australasian Conference on\n  Information Systems 2015 (arXiv:1605.01032)", "journal-ref": null, "doi": null, "report-no": "ACIS/2015/57", "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We examined the influence of three social engineering strategies on users'\njudgments of how safe it is to click on a link in an email. The three\nstrategies examined were authority, scarcity and social proof, and the emails\nwere either genuine, phishing or spear-phishing. Of the three strategies, the\nuse of authority was the most effective strategy in convincing users that a\nlink in an email was safe. When detecting phishing and spear-phishing emails,\nusers performed the worst when the emails used the authority principle and\nperformed best when social proof was present. Overall, users struggled to\ndistinguish between genuine and spear-phishing emails. Finally, users who were\nless impulsive in making decisions generally were less likely to judge a link\nas safe in the fraudulent emails. Implications for education and training are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Sat, 28 May 2016 04:01:02 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Butavicius", "Marcus", ""], ["Parsons", "Kathryn", ""], ["Pattinson", "Malcolm", ""], ["McCormac", "Agata", ""]]}, {"id": "1606.00888", "submitter": "Christian Fernando Libaque-Saenz", "authors": "Christian Fernando Libaque-Saenz, Younghoon Chang, Siew Fan Wong and\n  Hwansoo Lee", "title": "The Power of Fair Information Practices - A Control Agency Approach", "comments": "Research-in-progress ISBN# 978-0-646-95337-3 Presented at the\n  Australasian Conference on Information Systems 2015 (arXiv:1605.01032)", "journal-ref": null, "doi": null, "report-no": "ACIS/2015/56", "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Most companies' new business practices are based on customer data. These\npractices have raised privacy concerns because of the associated risks. Privacy\nlaws require companies to gain customer consent before using their information,\nwhich stands as the biggest roadblock to monetise this asset. Privacy\nliterature suggests that reducing privacy concerns and building trust may\nincrease individuals' intention to authorise the use of personal information.\nFair information practices (FIPs) are potential means to achieve this goal.\nHowever, there is lack of empirical evidence on the mechanisms through which\nthe FIPs affect privacy concerns and trust. This research argues that FIPs load\nindividuals with control, which has been found to influence privacy concerns\nand trust level. We will use an experimental design methodology to conduct the\nstudy. The results are expected to have both theoretical and managerial\nimplications.\n", "versions": [{"version": "v1", "created": "Sat, 28 May 2016 03:57:07 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Libaque-Saenz", "Christian Fernando", ""], ["Chang", "Younghoon", ""], ["Wong", "Siew Fan", ""], ["Lee", "Hwansoo", ""]]}, {"id": "1606.00890", "submitter": "Moneer Alshaikh", "authors": "Moneer Alshaikh, Sean B. Maynard, Atif Ahmad and Shanton Chang", "title": "Information Security Policy: A Management Practice Perspective", "comments": "ISBN# 978-0-646-95337-3 Presented at the Australasian Conference on\n  Information Systems 2015 (arXiv:1605.01032)", "journal-ref": null, "doi": null, "report-no": "ACIS/2015/49", "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Considerable research effort has been devoted to the study of Policy in the\ndomain of Information Security Management (ISM). However, our review of ISM\nliterature identified four key deficiencies that reduce the utility of the\nguidance to organisations implementing policy management practices. This paper\nprovides a comprehensive overview of the management practices of information\nsecurity policy and develops a practice-based model that addresses the four\naforementioned deficiencies. The model provides comprehensive guidance to\npractitioners on the activities security managers must undertake for security\npolicy development and allows practitioners to benchmark their current practice\nwith the models suggested best practice. The model contributes to theory by\nmapping existing information security policy research in terms of the defined\nmanagement practices.\n", "versions": [{"version": "v1", "created": "Sat, 28 May 2016 03:47:11 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Alshaikh", "Moneer", ""], ["Maynard", "Sean B.", ""], ["Ahmad", "Atif", ""], ["Chang", "Shanton", ""]]}, {"id": "1606.01010", "submitter": "Vinh Thong Ta", "authors": "Vinh Thong Ta", "title": "Automated Road Traffic Congestion Detection and Alarm Systems:\n  Incorporating V2I communications into ATCSs", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this position paper, we address the problems of automated road congestion\ndetection and alerting systems and their security properties. We review\ndifferent theoretical adaptive road traffic control approaches, and three\nwidely deployed adaptive traffic control systems (ATCSs), namely, SCATS, SCOOT\nand InSync. We then discuss some related research questions, and the\ncorresponding possible approaches, as well as the adversary model and potential\nattack scenarios. Two theoretical concepts of automated road congestion alarm\nsystems (including system architecture, communication protocol, and algorithms)\nare proposed on top of ATCSs, such as SCATS, SCOOT and InSync, by incorporating\nsecure wireless vehicle-to-infrastructure (V2I) communications. Finally, the\nsecurity properties of the proposed system have been discussed and analysed\nusing the ProVerif protocol verification tool.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 09:07:40 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Ta", "Vinh Thong", ""]]}, {"id": "1606.01040", "submitter": "Marco Baldi", "authors": "Marco Baldi, Paolo Santini, Franco Chiaraluce", "title": "Soft McEliece: MDPC code-based McEliece cryptosystems with very compact\n  keys through real-valued intentional errors", "comments": "5 pages, 1 figure, to be presented at IEEE ISIT 2016", "journal-ref": "Proc. IEEE International Symposium on Information Theory (ISIT\n  2016)", "doi": "10.1109/ISIT.2016.7541408", "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to use real-valued errors instead of classical bit flipping\nintentional errors in the McEliece cryptosystem based on moderate-density\nparity-check (MDPC) codes. This allows to exploit the error correcting\ncapability of these codes to the utmost, by using soft-decision iterative\ndecoding algorithms instead of hard-decision bit flipping decoders. However,\nsoft reliability values resulting from the use of real-valued noise can also be\nexploited by attackers. We devise new attack procedures aimed at this, and\ncompute the relevant work factors and security levels. We show that, for a\nfixed security level, these new systems achieve the shortest public key sizes\never reached, with a reduction up to 25% with respect to previous proposals.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 10:50:56 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Baldi", "Marco", ""], ["Santini", "Paolo", ""], ["Chiaraluce", "Franco", ""]]}, {"id": "1606.01042", "submitter": "Alexy Bhowmick Mr", "authors": "Alexy Bhowmick, Shyamanta M. Hazarika", "title": "Machine Learning for E-mail Spam Filtering: Review,Techniques and Trends", "comments": "Journal. 27 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a comprehensive review of the most effective content-based e-mail\nspam filtering techniques. We focus primarily on Machine Learning-based spam\nfilters and their variants, and report on a broad review ranging from surveying\nthe relevant ideas, efforts, effectiveness, and the current progress. The\ninitial exposition of the background examines the basics of e-mail spam\nfiltering, the evolving nature of spam, spammers playing cat-and-mouse with\ne-mail service providers (ESPs), and the Machine Learning front in fighting\nspam. We conclude by measuring the impact of Machine Learning-based filters and\nexplore the promising offshoots of latest developments.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 10:58:37 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Bhowmick", "Alexy", ""], ["Hazarika", "Shyamanta M.", ""]]}, {"id": "1606.01045", "submitter": "Jean-Guillaume Dumas", "authors": "Xavier Bultel (LIMOS), Jannik Dreier (CASSIS), Jean-Guillaume Dumas\n  (CASYS), Pascal Lafourcade (LIMOS)", "title": "Physical Zero-Knowledge Proofs for Akari, Takuzu, Kakuro and KenKen", "comments": "FUN with algorithms 2016, Jun 2016, La Maddalena, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Akari, Takuzu, Kakuro and KenKen are logic games similar to Sudoku. In Akari,\na labyrinth on a grid has to be lit by placing lanterns, respecting various\nconstraints. In Takuzu a grid has to be filled with 0's and 1's, while\nrespecting certain constraints. In Kakuro a grid has to be filled with numbers\nsuch that the sums per row and column match given values; similarly in KenKen a\ngrid has to be filled with numbers such that in given areas the product, sum,\ndifference or quotient equals a given value. We give physical algorithms to\nrealize zero-knowledge proofs for these games which allow a player to show that\nhe knows a solution without revealing it. These interactive proofs can be\nrealized with simple office material as they only rely on cards and envelopes.\nMoreover, we formalize our algorithms and prove their security.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 11:09:14 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Bultel", "Xavier", "", "LIMOS"], ["Dreier", "Jannik", "", "CASSIS"], ["Dumas", "Jean-Guillaume", "", "CASYS"], ["Lafourcade", "Pascal", "", "LIMOS"]]}, {"id": "1606.01356", "submitter": "Alan Litchfield", "authors": "Alan Litchfield and Abid Shahzad", "title": "Virtualization Technology: Cross-VM Cache Side Channel Attacks make it\n  Vulnerable", "comments": "ISBN# 978-0-646-95337-3 Presented at the Australasian Conference on\n  Information Systems 2015 (arXiv:1605.01032)", "journal-ref": null, "doi": null, "report-no": "ACIS/2015/111", "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cloud computing provides an effective business model for the deployment of IT\ninfrastructure, platform, and software services. Often, facilities are\noutsourced to cloud providers and this offers the service consumer\nvirtualization technologies without the added cost burden of development.\nHowever, virtualization introduces serious threats to service delivery such as\nDenial of Service (DoS) attacks, Cross-VM Cache Side Channel attacks,\nHypervisor Escape and Hyper-jacking. One of the most sophisticated forms of\nattack is the cross-VM cache side channel attack that exploits shared cache\nmemory between VMs. A cache side channel attack results in side channel data\nleakage, such as cryptographic keys. Various techniques used by the attackers\nto launch cache side channel attack are presented, as is a critical analysis of\ncountermeasures against cache side channel attacks.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jun 2016 09:31:29 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Litchfield", "Alan", ""], ["Shahzad", "Abid", ""]]}, {"id": "1606.01403", "submitter": "Aziz Mohaisen", "authors": "Jae-wook Jang and Jaesung Yun and Aziz Mohaisen and Jiyoung Woo and\n  Huy Kang Kim", "title": "Andro-profiler: Detecting and Classifying Android Malware based on\n  Behavioral Profiles", "comments": "13 pages", "journal-ref": "SpringerPlus (2016) 5:273", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mass-market mobile security threats have increased recently due to the growth\nof mobile technologies and the popularity of mobile devices. Accordingly,\ntechniques have been introduced for identifying, classifying, and defending\nagainst mobile threats utilizing static, dynamic, on-device, off-device, and\nhybrid approaches. In this paper, we contribute to the mobile security defense\nposture by introducing Andro-profiler, a hybrid behavior based analysis and\nclassification system for mobile malware. Andro-profiler classifies malware by\nexploiting the behavior profiling extracted from the integrated system logs\nincluding system calls, which are implicitly equivalent to distinct behavior\ncharacteristics. Andro-profiler executes a malicious application on an emulator\nin order to generate the integrated system logs, and creates human-readable\nbehavior profiles by analyzing the integrated system logs. By comparing the\nbehavior profile of malicious application with representative behavior profile\nfor each malware family, Andro-profiler detects and classifies it into malware\nfamilies. The experiment results demonstrate that Andro-profiler is scalable,\nperforms well in detecting and classifying malware with accuracy greater than\n$98\\%$, outperforms the existing state-of-the-art work, and is capable of\nidentifying zero-day mobile malware samples.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jun 2016 18:15:01 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Jang", "Jae-wook", ""], ["Yun", "Jaesung", ""], ["Mohaisen", "Aziz", ""], ["Woo", "Jiyoung", ""], ["Kim", "Huy Kang", ""]]}, {"id": "1606.01426", "submitter": "Aziz Mohaisen", "authors": "Ah Reum Kang and Seong Hoon Jeong and Aziz Mohaisen and Huy Kang Kim", "title": "Multimodal Game Bot Detection using User Behavioral Characteristics", "comments": null, "journal-ref": "Springerplus. 2016; 5: 523", "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the online service industry has continued to grow, illegal activities in\nthe online world have drastically increased and become more diverse. Most\nillegal activities occur continuously because cyber assets, such as game items\nand cyber money in online games, can be monetized into real currency. The aim\nof this study is to detect game bots in a Massively Multiplayer Online Role\nPlaying Game (MMORPG). We observed the behavioral characteristics of game bots\nand found that they execute repetitive tasks associated with gold farming and\nreal money trading. We propose a game bot detection methodology based on user\nbehavioral characteristics. The methodology of this paper was applied to real\ndata provided by a major MMORPG company. Detection accuracy rate increased to\n96.06% on the banned account list.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jun 2016 22:47:16 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Kang", "Ah Reum", ""], ["Jeong", "Seong Hoon", ""], ["Mohaisen", "Aziz", ""], ["Kim", "Huy Kang", ""]]}, {"id": "1606.01428", "submitter": "Bede Amarasekara", "authors": "Bede Amarasekara and Anuradha Mathrani", "title": "Exploring Risk and Fraud Scenarios in Affiliate Marketing Technologies\n  from the Advertisers perspective", "comments": "Research-in-progress ISBN# 978-0-646-95337-3 Presented at the\n  Australasian Conference on Information Systems 2015 (arXiv:1605.01032)", "journal-ref": null, "doi": null, "report-no": "ACIS/2015/128", "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Affiliate Marketing (AM) has become an important and cost effective tool for\ne-commerce. There are numerous risks and vulnerabilities that are typically\nassociated with AM. Though a well-planned AM model can greatly benefit the\ne-commerce strategies of an enterprise, a haphazardly implemented system can\nexpose a business enterprise to major risks and vulnerabilities, which can lead\nto great financial losses through fraudulent activities. This\nresearch-in-progress has identified some of the risks and the technical\nbackground of those scenarios. The research will now move on to build a\nfunctional prototype of an AM network to design and test solutions to control\nthe identified risks.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jun 2016 22:55:35 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Amarasekara", "Bede", ""], ["Mathrani", "Anuradha", ""]]}, {"id": "1606.01448", "submitter": "Sean B. Maynard", "authors": "Harry Zurita, Sean B. Maynard and Atif Ahmad", "title": "Evaluating the Utility of Research Articles for Teaching Information\n  Security Management", "comments": "ISBN# 978-0-646-95337-3 Presented at the Australasian Conference on\n  Information Systems 2015 (arXiv:1605.01032)", "journal-ref": null, "doi": null, "report-no": "ACIS/2015/143", "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Research articles can support teaching by introducing the latest expert\nthinking on relevant topics and trends and describing practical real-world case\nstudies to encourage discussion and analysis. However, from the point of view\nof the instructor, a common challenge is identifying the most suitable papers\nfor classroom teaching amongst a very large pool of potential candidates that\nare not typically written for teaching purposes. Further, even in\npractice-oriented disciplines such as Information Security Management (ISM),\nhigh-quality journals emphasise theoretical contribution and research method\nrather than relevance to practice. Our review of the relevant literature did\nnot find a comprehensive set of criteria to assist instructors in evaluating\nthe suitability of research articles to teaching. Therefore, this\nresearch-in-progress paper presents a framework to support academics in the\nprocess of evaluating the suitability of research articles for their teaching\nprograms.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jun 2016 02:18:17 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Zurita", "Harry", ""], ["Maynard", "Sean B.", ""], ["Ahmad", "Atif", ""]]}, {"id": "1606.01584", "submitter": "Ricky Laishram", "authors": "Ricky Laishram, Vir Virander Phoha", "title": "Curie: A method for protecting SVM Classifier from Poisoning Attack", "comments": "19 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is used in a number of security related applications such as\nbiometric user authentication, speaker identification etc. A type of causative\nintegrity attack against machine learning called Poisoning attack works by\ninjecting specially crafted data points in the training data so as to increase\nthe false positive rate of the classifier. In the context of the biometric\nauthentication, this means that more intruders will be classified as valid\nuser, and in case of speaker identification system, user A will be classified\nuser B. In this paper, we examine poisoning attack against SVM and introduce -\nCurie - a method to protect the SVM classifier from the poisoning attack. The\nbasic idea of our method is to identify the poisoned data points injected by\nthe adversary and filter them out. Our method is light weight and can be easily\nintegrated into existing systems. Experimental results show that it works very\nwell in filtering out the poisoned data.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jun 2016 23:42:56 GMT"}, {"version": "v2", "created": "Tue, 7 Jun 2016 00:41:08 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Laishram", "Ricky", ""], ["Phoha", "Vir Virander", ""]]}, {"id": "1606.01655", "submitter": "Andrew Paverd", "authors": "Sandeep Tamrakar, Jian Liu, Andrew Paverd, Jan-Erik Ekberg, Benny\n  Pinkas, N. Asokan", "title": "The Circle Game: Scalable Private Membership Test Using Trusted Hardware", "comments": "Extended version of a paper published at ACM ASIACCS 2017", "journal-ref": null, "doi": "10.1145/3052973.3053006", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware checking is changing from being a local service to a cloud-assisted\none where users' devices query a cloud server, which hosts a dictionary of\nmalware signatures, to check if particular applications are potentially\nmalware. Whilst such an architecture gains all the benefits of cloud-based\nservices, it opens up a major privacy concern since the cloud service can infer\npersonal traits of the users based on the lists of applications queried by\ntheir devices. Private membership test (PMT) schemes can remove this privacy\nconcern. However, known PMT schemes do not scale well to a large number of\nsimultaneous users and high query arrival rates. We propose a simple PMT\napproach using a carousel: circling the entire dictionary through trusted\nhardware on the cloud server. Users communicate with the trusted hardware via\nsecure channels. We show how the carousel approach, using different data\nstructures to represent the dictionary, can be realized on two different\ncommercial hardware security architectures (ARM TrustZone and Intel SGX). We\nhighlight subtle aspects of securely implementing seemingly simple PMT schemes\non these architectures. Through extensive experimental analysis, we show that\nfor the malware checking scenario our carousel approach surprisingly\noutperforms Path ORAM on the same hardware by supporting a much higher query\narrival rate while guaranteeing acceptable response latency for individual\nqueries.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 08:29:22 GMT"}, {"version": "v2", "created": "Mon, 27 Jun 2016 08:20:13 GMT"}, {"version": "v3", "created": "Wed, 24 Aug 2016 08:44:52 GMT"}, {"version": "v4", "created": "Fri, 17 Feb 2017 15:32:40 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Tamrakar", "Sandeep", ""], ["Liu", "Jian", ""], ["Paverd", "Andrew", ""], ["Ekberg", "Jan-Erik", ""], ["Pinkas", "Benny", ""], ["Asokan", "N.", ""]]}, {"id": "1606.01671", "submitter": "Atamli-Ahmad Reineh", "authors": "Ahmad-Atamli Reineh, Andrew J. Paverd, Andrew P. Martin", "title": "Trustworthy and Secure Service-Oriented Architecture for the Internet of\n  Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Internet of Things (IoT), heterogeneous devices connect to each other\nand to external systems to exchange data and provide services. Given the\ndiversity of devices, it is becoming increasingly common to establish\ncollaborative relationships between devices to provide composite services.\nHowever, due to the high degree of heterogeneity in the IoT context, one of the\nmost significant challenges is to develop software applications that can run on\na wide variety of devices and can communicate and collaborate with an even\nwider array of systems. A common middleware infrastructure for these devices\nwill therefore have a significant impact on the design, deployment, and use of\nservices in IoT systems by allowing developers to focus on the applications\nrather than the low-level implementation details each device.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 09:33:56 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Reineh", "Ahmad-Atamli", ""], ["Paverd", "Andrew J.", ""], ["Martin", "Andrew P.", ""]]}, {"id": "1606.01708", "submitter": "Vincent Taylor", "authors": "Vincent F. Taylor and Ivan Martinovic", "title": "Quantifying Permission-Creep in the Google Play Store", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although there are over 1,600,000 third-party Android apps in the Google Play\nStore, little has been conclusively shown about how their individual (and\ncollective) permission usage has evolved over time. Recently, Android 6\noverhauled the way permissions are granted by users, by switching to run-time\npermission requests instead of install-time permission requests. This is a\nwelcome change, but recent research has shown that many users continue to\naccept run-time permissions blindly, leaving them at the mercy of third-party\napp developers and adversaries. Beyond intentionally invading privacy, highly\nprivileged apps increase the attack surface of smartphones and are more\nattractive targets for adversaries. This work focuses exclusively on dangerous\npermissions, i.e., those permissions identified by Android as guarding access\nto sensitive user data. By taking snapshots of the Google Play Store over a\n20-month period, we characterise changes in the number and type of dangerous\npermissions used by Android apps when they are updated, to gain a greater\nunderstanding of the evolution of permission usage. We found that approximately\n25,000 apps asked for additional permissions every three months. Worryingly, we\nmade statistically significant observations that free apps and highly popular\napps were more likely to ask for additional permissions when they were updated.\nBy looking at patterns in dangerous permission usage, we find evidence that\nsuggests developers may still be failing to correctly specify the permissions\ntheir apps need.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 12:11:08 GMT"}, {"version": "v2", "created": "Wed, 10 Aug 2016 13:19:21 GMT"}], "update_date": "2016-08-11", "authors_parsed": [["Taylor", "Vincent F.", ""], ["Martinovic", "Ivan", ""]]}, {"id": "1606.01881", "submitter": "Andrew Ruef", "authors": "Andrew Ruef, Michael Hicks, James Parker, Dave Levin, Michelle L.\n  Mazurek, Piotr Mardziel", "title": "Build It, Break It, Fix It: Contesting Secure Development", "comments": null, "journal-ref": null, "doi": "10.1145/2976749.2978382", "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical security contests focus on breaking or mitigating the impact of buggy\nsystems. We present the Build-it Break-it Fix-it BIBIFI contest which aims to\nassess the ability to securely build software not just break it. In BIBIFI\nteams build specified software with the goal of maximizing correctness\nperformance and security. The latter is tested when teams attempt to break\nother teams submissions. Winners are chosen from among the best builders and\nthe best breakers. BIBIFI was designed to be open-ended - teams can use any\nlanguage tool process etc. that they like. As such contest outcomes shed light\non factors that correlate with successfully building secure software and\nbreaking insecure software. During we ran three contests involving a total of\nteams and two different programming problems. Quantitative analysis from these\ncontests found that the most efficient build-it submissions used CC but\nsubmissions coded in a statically-typed language were less likely to have a\nsecurity flaw build-it teams with diverse programming-language knowledge also\nproduced more secure code. Shorter programs correlated with better scores.\nBreak-it teams that were also build-it teams were significantly better at\nfinding security bugs.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 19:41:42 GMT"}, {"version": "v2", "created": "Fri, 19 Aug 2016 04:55:57 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Ruef", "Andrew", ""], ["Hicks", "Michael", ""], ["Parker", "James", ""], ["Levin", "Dave", ""], ["Mazurek", "Michelle L.", ""], ["Mardziel", "Piotr", ""]]}, {"id": "1606.01971", "submitter": "Aziz Mohaisen", "authors": "Jae-wook Jang and Jiyoung Woo and Aziz Mohaisen and Jaesung Yun and\n  Huy Kang Kim", "title": "Mal-Netminer: Malware Classification Approach based on Social Network\n  Analysis of System Call Graph", "comments": "Mathematical Problems in Engineering, Vol 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the security landscape evolves over time, where thousands of species of\nmalicious codes are seen every day, antivirus vendors strive to detect and\nclassify malware families for efficient and effective responses against malware\ncampaigns. To enrich this effort, and by capitalizing on ideas from the social\nnetwork analysis domain, we build a tool that can help classify malware\nfamilies using features driven from the graph structure of their system calls.\nTo achieve that, we first construct a system call graph that consists of system\ncalls found in the execution of the individual malware families. To explore\ndistinguishing features of various malware species, we study social network\nproperties as applied to the call graph, including the degree distribution,\ndegree centrality, average distance, clustering coefficient, network density,\nand component ratio. We utilize features driven from those properties to build\na classifier for malware families. Our experimental results show that\ninfluence-based graph metrics such as the degree centrality are effective for\nclassifying malware, whereas the general structural metrics of malware are less\neffective for classifying malware. Our experiments demonstrate that the\nproposed system performs well in detecting and classifying malware families\nwithin each malware class with accuracy greater than 96%.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 23:09:27 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Jang", "Jae-wook", ""], ["Woo", "Jiyoung", ""], ["Mohaisen", "Aziz", ""], ["Yun", "Jaesung", ""], ["Kim", "Huy Kang", ""]]}, {"id": "1606.02108", "submitter": "Jaros{\\l}aw Miszczak", "authors": "Piotr Zawadzki, Jaros{\\l}aw Adam Miszczak", "title": "A general scheme for information interception in the ping pong protocol", "comments": "10 pages, 4 figures", "journal-ref": "Advances in Mathematical Physics, vol. 2016, 3162012 (2016)", "doi": "10.1155/2016/3162012", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existence of an undetectable eavesdropping of dense coded information has\nbeen already demonstrated by Pavi\\v{c}i\\'c for the quantum direct communication\nbased on the ping-pong paradigm. However, a) the explicit scheme of the circuit\nis only given and no design rules are provided, b) the existence of losses is\nimplicitly assumed, c) the attack has been formulated against qubit based\nprotocol only and it is not clear whether it can be adapted to higher\ndimensional systems. These deficiencies are removed in the presented\ncontribution. A new generic eavesdropping scheme built on a firm theoretical\nbackground is proposed. In contrast to the previous approach, it does not refer\nto the properties of the vacuum state, so it is fully consistent with the\nabsence of losses assumption. Moreover, the scheme applies to the communication\nparadigm based on signal particles of any dimensionality. It is also shown that\nsome well known attacks are special cases of the proposed scheme.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 11:49:56 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Zawadzki", "Piotr", ""], ["Miszczak", "Jaros\u0142aw Adam", ""]]}, {"id": "1606.02109", "submitter": "Onur Dikmen", "authors": "Antti Honkela, Mrinal Das, Arttu Nieminen, Onur Dikmen and Samuel\n  Kaski", "title": "Efficient differentially private learning improves drug sensitivity\n  prediction", "comments": "14 pages + 13 pages supplementary information, 3 + 3 figures", "journal-ref": "Biology Direct (2018) 13:1", "doi": "10.1186/s13062-017-0203-4", "report-no": null, "categories": "stat.ML cs.CR cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users of a personalised recommendation system face a dilemma: recommendations\ncan be improved by learning from data, but only if the other users are willing\nto share their private information. Good personalised predictions are vitally\nimportant in precision medicine, but genomic information on which the\npredictions are based is also particularly sensitive, as it directly identifies\nthe patients and hence cannot easily be anonymised. Differential privacy has\nemerged as a potentially promising solution: privacy is considered sufficient\nif presence of individual patients cannot be distinguished. However,\ndifferentially private learning with current methods does not improve\npredictions with feasible data sizes and dimensionalities. Here we show that\nuseful predictors can be learned under powerful differential privacy\nguarantees, and even from moderately-sized data sets, by demonstrating\nsignificant improvements with a new robust private regression method in the\naccuracy of private drug sensitivity prediction. The method combines two key\nproperties not present even in recent proposals, which can be generalised to\nother predictors: we prove it is asymptotically consistently and efficiently\nprivate, and demonstrate that it performs well on finite data. Good finite data\nperformance is achieved by limiting the sharing of private information by\ndecreasing the dimensionality and by projecting outliers to fit tighter bounds,\ntherefore needing to add less noise for equal privacy. As already the\nsimple-to-implement method shows promise on the challenging genomic data, we\nanticipate rapid progress towards practical applications in many fields, such\nas mobile sensing and social media, in addition to the badly needed precision\nmedicine solutions.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 11:52:28 GMT"}, {"version": "v2", "created": "Wed, 5 Jul 2017 11:38:00 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Honkela", "Antti", ""], ["Das", "Mrinal", ""], ["Nieminen", "Arttu", ""], ["Dikmen", "Onur", ""], ["Kaski", "Samuel", ""]]}, {"id": "1606.02239", "submitter": "Mohd Anuar Mat Isa Dr.", "authors": "Mohd Anuar Mat Isa, Ramlan Mahmod, Nur Izura Udzir, Jamalul-lail Ab\n  Manan, Audun J{\\o}sang, Ali Dehghan Tanha", "title": "A Formal Calculus for International Relations Computation and Evaluation", "comments": "keywords: Relation Algebra, International Relations, Defense,\n  Relation Calculus, Foreign Policy, Politics Economy, Dempster-Shafer,\n  Subjective Logic, Common Criteria. arXiv admin note: text overlap with\n  arXiv:1604.00980", "journal-ref": "Journal of Current Research in Science, Issn 2322-5009, 4(2),\n  2016: 177-194", "doi": "10.13140/RG.2.1.3796.6321", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This publication presents a relation computation or calculus for\ninternational relations using a mathematical modeling. It examined trust for\ninternational relations and its calculus, which related to Bayesian inference,\nDempster-Shafer theory and subjective logic. Based on an observation in the\nliterature, we found no literature discussing the calculus method for the\ninternational relations. To bridge this research gap, we propose a relation\nalgebra method for international relations computation. The proposed method\nwill allow a relation computation which is previously subjective and\nincomputable. We also present three international relations as case studies to\ndemonstrate the proposed method is a real-world scenario. The method will\ndeliver the relation computation for the international relations that to\nsupport decision makers in a government such as foreign ministry, defense\nministry, presidential or prime minister office. The Department of Defense\n(DoD) may use our method to determine a nation that can be identified as a\nfriendly, neutral or hostile nation.\n", "versions": [{"version": "v1", "created": "Sat, 2 Apr 2016 10:13:26 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["Isa", "Mohd Anuar Mat", ""], ["Mahmod", "Ramlan", ""], ["Udzir", "Nur Izura", ""], ["Manan", "Jamalul-lail Ab", ""], ["J\u00f8sang", "Audun", ""], ["Tanha", "Ali Dehghan", ""]]}, {"id": "1606.02312", "submitter": "James Collins", "authors": "James Collins, Sos Agaian", "title": "High Capacity Image Steganography using Adjunctive Numerical\n  Representations with Multiple Bit-Plane Decomposition Methods", "comments": "20 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LSB steganography is a one of the most widely used methods for implementing\ncovert data channels in image file exchanges [1][2]. The low computational\ncomplexity and implementation simplicity of the algorithm are significant\nfactors for its popularity with the primary reason being low image distortion.\nMany attempts have been made to increase the embedding capacity of LSB\nalgorithms by expanding into the second or third binary layers of the image\nwhile maintaining a low probability of detection with minimal distortive\neffects [2][3][4]. In this paper, we introduce an advanced technique for\ncovertly embedding data within images using redundant number system\ndecomposition over non-standard digital bit planes. Both grayscale and\nbit-mapped images are equally effective as cover files. It will be shown that\nthis unique steganography method has minimal visual distortive affects while\nalso preserving the cover file statistics, making it less susceptible to most\ngeneral steganography detection algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 20:00:41 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Collins", "James", ""], ["Agaian", "Sos", ""]]}, {"id": "1606.02373", "submitter": "Meysam Ghaffari", "authors": "Meysam Ghaffari, Nasser Ghadiri, Mohammad Hossein Manshaei, Mehran\n  Sadeghi Lahijani", "title": "P4QS: A Peer to Peer Privacy Preserving Query Service for Location-Based\n  Mobile Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The location-based services provide an interesting combination of cyber and\nphysical worlds. However, they can also threaten the users' privacy. Existing\nprivacy preserving protocols require trusted nodes, with serious security and\ncomputational bottlenecks. In this paper, we propose a novel distributed\nanonymizing protocol based on peer-to-peer architecture. Each mobile node is\nresponsible for anonymizing a specific zone. The mobile nodes collaborate in\nanonymizing their queries, without the need not get access to any information\nabout each other. In the proposed protocol, each request will be sent with a\nrandomly chosen ticket. The encrypted response produced by the server is sent\nto a particular mobile node (called broker node) over the network, based on the\nhash value of this ticket. The user will query the broker to get the response.\nAll parts of the messages are encrypted except the fields required for the\nanonymizer and the broker. This will secure the packet exchange over the P2P\nnetwork. The proposed protocol was implemented and tested successfully, and the\nexperimental results showed that it could be deployed efficiently to achieve\nuser privacy in location-based services.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 02:09:15 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Ghaffari", "Meysam", ""], ["Ghadiri", "Nasser", ""], ["Manshaei", "Mohammad Hossein", ""], ["Lahijani", "Mehran Sadeghi", ""]]}, {"id": "1606.02385", "submitter": "John Geddes", "authors": "John Geddes, Mike Schliep, Nicholas Hopper", "title": "Anarchy in Tor: Performance Cost of Decentralization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Like many routing protocols, the Tor anonymity network has decentralized path\nselection, in clients locally and independently choose paths. As a result,\nnetwork resources may be left idle, leaving the system in a suboptimal state.\nThis is referred to as the price of anarchy, where agents acting in their own\nself interest can make poor decisions when viewed in a global context. In this\npaper we explore the cost of anarchy in Tor by examining the potential\nperformance increases that can be gained by centrally optimizing circuit and\nrelay selection using global knowledge. In experiments with both offline and\nonline algorithms, we show that centrally coordinated clients can achieve up to\n75% higher bandwidth compared to traditional Tor. Drawing on these findings, we\ndesign and evaluate a decentralized version of our online algorithm, in which\nrelays locally distribute information enabling clients to make smarter\ndecisions locally and perform downloads 10-60% faster. Finally, we perform a\nprivacy analysis of the decentralized algorithm against a passive and active\nadversary trying to reduce anonymity of clients and increase their view of the\nTor network. We conclude that this decentralized algorithm does not enable new\nattacks, while providing significantly higher performance.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 03:19:24 GMT"}, {"version": "v2", "created": "Mon, 13 Jun 2016 16:43:50 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Geddes", "John", ""], ["Schliep", "Mike", ""], ["Hopper", "Nicholas", ""]]}, {"id": "1606.02508", "submitter": "Brian Cusack", "authors": "Brian Cusack and Reza Khaleghparast", "title": "Using Design Science to build a Watermark System for Righful Ownership\n  Protection in the Cloud", "comments": "ISBN# 978-0-646-95337-3 Presented at the Australasian Conference on\n  Information Systems 2015 (arXiv:1605.01032)", "journal-ref": null, "doi": null, "report-no": "ACIS/2015/180", "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cloud computing opportunities have presented service options for users that\nare both economical and flexible to use requirements. However, the risk\nanalysis for the user identifies vulnerabilities for intellectual property\nownership and vulnerabilities for the identification of rightful property\nowners when cloud services are used. It is common for image owners to embed\nwatermarks and other security mechanisms into their property so that the\nrightful ownership may be identified. In this paper we present a design that\novercomes many of the current limitations in cloud watermarking uses and\npropose a schema that places responsibility on the cloud provider to have a\nrobust information protection program. Such a design solution lays out an\ninformation security architecture that enhances utility for cloud services and\ngives better options for users to securely place properties in the cloud. The\nDesign Science methodology is used to build the artefact.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 11:04:39 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Cusack", "Brian", ""], ["Khaleghparast", "Reza", ""]]}, {"id": "1606.02509", "submitter": "Deborah Bunker", "authors": "Deborah Bunker, Catherine Hardy, Abdul Babar and Ken Stevens", "title": "Exploring Practitioner Perspectives of Sourcing Risks: Towards the\n  Development of an Integrated Risk and Control Framework", "comments": "ISBN# 978-0-646-95337-3 Presented at the Australasian Conference on\n  Information Systems 2015 (arXiv:1605.01032)", "journal-ref": null, "doi": null, "report-no": "ACIS/2015/185", "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Outsourcing of information and communication technologies (ICT) and related\nservices is an established and growing industry. Recent trends, such as the\nmove toward multi-sourcing have increased the complexity and risk of these\noutsourcing arrangements. There is a critical research need to identify the\nrisks faced by both the organisations that outsource ICT and the vendors that\nprovide it in this changing landscape. To address growing concerns regarding\nthe best way to deal with risk and control in this environment, our research\nfocuses on establishing a Sourcing Risk and Control Framework to assist\norganisations identify these risks and develop effective mitigation strategies.\nIn this paper we report on the first stage of our research that sought to\ndocument how sourcing risk is represented and considered in practice. To date,\nlimited empirical research has been conducted in an Australian context. Using a\nseries of workshops involving client and vendor representatives, we identified\na broad range of risks and developed a cohesive categorisation scheme that\nincorporates functional and multi-stakeholder perspectives.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 11:08:51 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Bunker", "Deborah", ""], ["Hardy", "Catherine", ""], ["Babar", "Abdul", ""], ["Stevens", "Ken", ""]]}, {"id": "1606.02534", "submitter": "Sara Boujaada", "authors": "S. Boujaada, Y. Qaraai, S. Agoujil and M. Hajar", "title": "Protector Control PC-AODV-BH in The Ad Hoc Networks", "comments": "submit 15 pages, 19 figures, 1 table, Journal Indexing team, AIRCC\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we deal with the protector control that which we used to secure\nAODV routing protocol in Ad Hoc networks. The considered system can be\nvulnerable to several attacks because of mobility and absence of\ninfrastructure. While the disturbance is assumed to be of the black hole type,\nwe purpose a control named \"PC-AODV-BH\" in order to neutralize the effects of\nmalicious nodes. Such a protocol is obtained by coupling hash functions,\ndigital signatures and fidelity concept. An implementation under NS2 simulator\nwill be given to compare our proposed approach with SAODV protocol, basing on\nthree performance metrics and taking into account the number of black hole\nmalicious nodes\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 12:54:22 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Boujaada", "S.", ""], ["Qaraai", "Y.", ""], ["Agoujil", "S.", ""], ["Hajar", "M.", ""]]}, {"id": "1606.02697", "submitter": "Laszlo Kish", "authors": "Laszlo Bela Kish, Claes Goran Granqvist", "title": "Comments On \"A New Transient Attack On The Kish Key Distribution System\"", "comments": "Accepted for publication in the journal Metrology and Measurement\n  Systems (May 2016)", "journal-ref": "Metrology and Measurement Systems, Vol. 23 (2016), No. 3, pp.\n  321-331", "doi": "10.1515/mms-2016-0039", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A recent IEEE Access Paper by Gunn, Allison and Abbott (GAA) proposed a new\ntransient attack against the Kirchhoff-law-Johnson-noise (KLJN) secure key\nexchange system. The attack is valid, but it is easy to build a defense for the\nKLJN system. Here we note that GAA's paper contains several invalid statements\nregarding security measures and the continuity of functions in classical\nphysics. These deficiencies are clarified in our present paper, wherein we also\nemphasize that a new version of the KLJN system is immune against all existing\nattacks, including the one by GAA.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 22:14:00 GMT"}], "update_date": "2018-08-19", "authors_parsed": [["Kish", "Laszlo Bela", ""], ["Granqvist", "Claes Goran", ""]]}, {"id": "1606.02995", "submitter": "Atamli-Ahmad Reineh", "authors": "Ahmad-Atamli Reineh, Giuseppe Petracca, Janne Uusilehto, Andrew Martin", "title": "Enabling Secure and Usable Mobile Application: Revealing the Nuts and\n  Bolts of software TPM in todays Mobile Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of mobile applications to execute sensitive operations has\nbrought a myriad of security threats to both enterprises and users. In order to\nbenefit from the large potential in smartphones there is a need to manage the\nrisks arising from threats, while maintaining an easy interface for the users.\nIn this paper we investigate the use of Trusted Platform Model (TPM) 2.0 to\ndevelop a secure application for smartphones using Windows Phone 8.1. In\nparticular, we suggest a framework based on remote attestation as a proxy to\nauthenticate remote services, where the device is associated to the user and\nreplaces the users credentials. In addition, we use the TPM 2.0 to enable\nsecured information and data storage within the device itself. We present an\nimplementation and performance evaluation of the suggested architecture that\nuses our novel attestation and authentication scheme and reveal the caveats of\nusing software TPM in todays mobile devices.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2016 15:23:31 GMT"}], "update_date": "2016-06-10", "authors_parsed": [["Reineh", "Ahmad-Atamli", ""], ["Petracca", "Giuseppe", ""], ["Uusilehto", "Janne", ""], ["Martin", "Andrew", ""]]}, {"id": "1606.03147", "submitter": "Tetsufumi Tanamoto", "authors": "Tetsufumi Tanamoto, Naoharu Shimomura, Sumio Ikegawa, Mari Matsumoto,\n  Shinobu Fujita, and Hiroaki Yoda", "title": "High-Speed Magnetoresistive Random-Access Memory Random Number Generator\n  Using Error-Correcting Code", "comments": "5 pages, 11 figures", "journal-ref": "Jpn. J. Appl. Phys. 50, 04DM01 (2011)", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A high-speed random number generator (RNG) circuit based on magnetoresistive\nrandom-access memory (MRAM) using an error-correcting code (ECC) post\nprocessing circuit is presented. ECC post processing increases the quality of\nrandomness by increasing the entropy of random number. { We experimentally show\nthat a small error-correcting capability circuit is sufficient for this post\nprocessing. It is shown that the ECC post processing circuit powerfully\nimproves the quality of randomness with minimum overhead, ending up with\nhigh-speed random number generation. We also show that coupling with a linear\nfeedback shift resistor is effective for improving randomness\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 00:29:19 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["Tanamoto", "Tetsufumi", ""], ["Shimomura", "Naoharu", ""], ["Ikegawa", "Sumio", ""], ["Matsumoto", "Mari", ""], ["Fujita", "Shinobu", ""], ["Yoda", "Hiroaki", ""]]}, {"id": "1606.03182", "submitter": "Tarun Yadav", "authors": "Koustav Sadhukhan, Rao Arvind Mallari, Tarun Yadav", "title": "Cyber Attack Thread: A Control-flow Based Approach to Deconstruct and\n  Mitigate Cyber Threats", "comments": "9 Pages, 1 Figure, 2015 International Conference on Computing and\n  Network Communications (CoCoNet), The final publication is available at IEEE\n  Xplore via http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7411183", "journal-ref": null, "doi": "10.1109/CoCoNet.2015.7411183", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attacks in cyberspace have got attention due to risk at privacy, breach of\ntrust and financial losses for individuals as well as organizations. In recent\nyears, these attacks have become more complex to analyze technically, as well\nas to detect and prevent from accessing confidential data. Although there are\nmany methodologies and mechanisms which have been suggested for cyber-attack\ndetection and prevention, but not from the perspective of an attacker. This\npaper presents the cyber-defence as hindrances, faced by the attacker, by\nunderstanding attack thread and defence possibilities with existing security\nmechanisms. Seven phases of Cyber Attack Thread are introduced and technical\naspects are discussed with reference to APT attacks. The paper aims for\nsecurity practitioner and administrators as well as for the general audience to\nunderstand the attack scenario and defensive security measures.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 05:22:08 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["Sadhukhan", "Koustav", ""], ["Mallari", "Rao Arvind", ""], ["Yadav", "Tarun", ""]]}, {"id": "1606.03184", "submitter": "Tarun Yadav", "authors": "Tarun Yadav, Rao Arvind Mallari", "title": "Technical Aspects of Cyber Kill Chain", "comments": "7 pages, 1 figure, 4 tables, The final publication is available at\n  Springer via http://dx.doi.org/10.1007/978-3-319-22915-7_40", "journal-ref": null, "doi": "10.1007/978-3-319-22915-7_40", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent trends in targeted cyber-attacks has increased the interest of\nresearch in the field of cyber security. Such attacks have massive disruptive\neffects on rganizations, enterprises and governments. Cyber kill chain is a\nmodel to describe cyber-attacks so as to develop incident response and analysis\ncapabilities. Cyber kill chain in simple terms is an attack chain, the path\nthat an intruder takes to penetrate information systems over time to execute an\nattack on the target. This paper broadly categories the methodologies,\ntechniques and tools involved in cyber-attacks. This paper intends to help a\ncyber security researcher to realize the options available to an attacker at\nevery stage of a cyber-attack.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 05:30:57 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["Yadav", "Tarun", ""], ["Mallari", "Rao Arvind", ""]]}, {"id": "1606.03304", "submitter": "Hamid Usefi", "authors": "Sudharaka Palamakumbura and Hamid Usefi", "title": "Homomorphic Evaluation of Database Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Homomorphic encryption is an encryption method that enables computing over\nencrypted data. This has a wide range of real world ramifications such as being\nable to blindly compute a search result sent to a remote server without\nrevealing its content. This paper discusses how database search queries can be\nmade secure using a homomorphic encryption scheme. We propose a new database\nsearch technique that can be used with the ring-based fully homomorphic\nencryption scheme proposed by Braserski.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 13:03:36 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["Palamakumbura", "Sudharaka", ""], ["Usefi", "Hamid", ""]]}, {"id": "1606.03368", "submitter": "Dominik Leibenger", "authors": "Dominik Leibenger, Christoph Sorge", "title": "sec-cs: Getting the Most out of Untrusted Cloud Storage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present sec-cs, a hash-table-like data structure for file contents on\nuntrusted storage that is both secure and storage-efficient. We achieve\nauthenticity and confidentiality with zero storage overhead using deterministic\nauthenticated encryption. State-of-the-art data deduplication approaches\nprevent redundant storage of shared parts of different contents irrespective of\nwhether relationships between contents are known a priori or not.\n  Instead of just adapting existing approaches, we introduce novel\n(multi-level) chunking strategies, ML-SC and ML-CDC, which are significantly\nmore storage-efficient than existing approaches in presence of high redundancy.\n  We prove sec-cs's security, publish a ready-to-use implementation, and\npresent results of an extensive analytical and empirical evaluation that show\nits suitability for, e.g., future backup systems that should preserve many\nversions of files on little available cloud storage.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 15:29:47 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["Leibenger", "Dominik", ""], ["Sorge", "Christoph", ""]]}, {"id": "1606.03527", "submitter": "Sameera Mubarak", "authors": "Sameera Mubarak and Mubarak Ali Rahamathulla", "title": "Online self-disclosure and wellbeing of adolescents: A systematic\n  literature review", "comments": "Research-in-progress ISBN# 978-0-646-95337-3 Presented at the\n  Australasian Conference on Information Systems 2015 (arXiv:1605.01032)", "journal-ref": null, "doi": null, "report-no": "ACIS/2015/207", "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The present research investigated the extent of online self-disclosure (SD)\nof adolescents through a systematic decadal literature review. This review\nidentified three major areas of research focus, with studies categorized mainly\nas: (1) factors contributing to online SD of adolescents; (2) risks and\nconsequences of online SD; and (3) future directions of research and practical\ninterventions to address the problems. A detailed examination of the variables\ncovered by the studies indicated that only a few aspects related to\nadolescents' online SD were addressed and these variables did not receive\nin-depth analysis. Some aspects of online SD received too much attention while\nothers received none. Based on these findings, the present research argues that\nfurther research using sophisticated scientific research designs is needed to\nunderstand adolescents' online SD.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jun 2016 02:46:47 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Mubarak", "Sameera", ""], ["Rahamathulla", "Mubarak Ali", ""]]}, {"id": "1606.03528", "submitter": "Craig A. Horne", "authors": "Craig A. Horne, Atif Ahmad and Sean B. Maynard", "title": "Information Security Strategy in Organisations: Review, Discussion and\n  Future Research Directions", "comments": "ISBN# 978-0-646-95337-3 Presented at the Australasian Conference on\n  Information Systems 2015 (arXiv:1605.01032)", "journal-ref": null, "doi": null, "report-no": "ACIS/2015/209", "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Dependence on information, including for some of the world's largest\norganisations such as governments and multi-national corporations, has grown\nrapidly in recent years. However, reports of information security breaches and\ntheir associated consequences continue to indicate that attacks are still\nescalating on organisations when conducting these information-based activities.\nClearly, more research is needed to better understand how organisations should\nformulate strategy to secure their information. Through a thematic review of\nacademic security literature, we (1) analyse the antecedent conditions that\nmotivate the potential adoption of a comprehensive information security\nstrategy, (2) the current perspectives of strategy and (3) the yields and\nbenefits that could be enjoyed post-adoption. Our contributions include a\ndefinition of information security strategy. We argue for a paradigm shift to\nextend from internally-focussed protection of organisation-wide information\ntowards a strategic view that considers the inter-organisational level. Our\nfindings are then used to suggest future research directions.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jun 2016 02:53:06 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Horne", "Craig A.", ""], ["Ahmad", "Atif", ""], ["Maynard", "Sean B.", ""]]}, {"id": "1606.03540", "submitter": "Zahir Al Rashdi", "authors": "Zahir Al Rashdi, Martin Dick and Ian Storey", "title": "A Conceptual Framework for Accountability in Cloud Computing Service\n  Provision", "comments": "ISBN# 978-0-646-95337-3 Presented at the Australasian Conference on\n  Information Systems 2015 (arXiv:1605.01032)", "journal-ref": null, "doi": null, "report-no": "ACIS/2015/221", "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper uses a comprehensive review of the academic and professional\nliterature in relation to accountability in the area of cloud computing service\nprovision. It identifies four key conceptual factors that are necessary for an\norganisation to be considered as accountable. The four factors were found to\nbe: responsibility, assurance, transparency and remediation. A key finding of\nthe paper is that in order to be considered as an accountable cloud service\nprovider, all four factors need to be implemented and be demonstrable by the\norganisation.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jun 2016 03:27:35 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Rashdi", "Zahir Al", ""], ["Dick", "Martin", ""], ["Storey", "Ian", ""]]}, {"id": "1606.03572", "submitter": "Sam Fletcher", "authors": "Sam Fletcher and Md Zahidul Islam", "title": "Differentially Private Random Decision Forests using Smooth Sensitivity", "comments": "Pre-print of accepted journal article to Expert Systems with\n  Applications. 47 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new differentially-private decision forest algorithm that\nminimizes both the number of queries required, and the sensitivity of those\nqueries. To do so, we build an ensemble of random decision trees that avoids\nquerying the private data except to find the majority class label in the leaf\nnodes. Rather than using a count query to return the class counts like the\ncurrent state-of-the-art, we use the Exponential Mechanism to only output the\nclass label itself. This drastically reduces the sensitivity of the query --\noften by several orders of magnitude -- which in turn reduces the amount of\nnoise that must be added to preserve privacy. Our improved sensitivity is\nachieved by using \"smooth sensitivity\", which takes into account the specific\ndata used in the query rather than assuming the worst-case scenario. We also\nextend work done on the optimal depth of random decision trees to handle\ncontinuous features, not just discrete features. This, along with several other\nimprovements, allows us to create a differentially private decision forest with\nsubstantially higher predictive power than the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jun 2016 09:47:05 GMT"}, {"version": "v2", "created": "Wed, 28 Sep 2016 07:14:18 GMT"}, {"version": "v3", "created": "Wed, 25 Jan 2017 05:19:56 GMT"}], "update_date": "2017-01-26", "authors_parsed": [["Fletcher", "Sam", ""], ["Islam", "Md Zahidul", ""]]}, {"id": "1606.03588", "submitter": "Dmitry Khovratovich", "authors": "Alex Biryukov and Dmitry Khovratovich", "title": "Egalitarian computing", "comments": "USENIX 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore several contexts where an adversary has an upper\nhand over the defender by using special hardware in an attack. These include\npassword processing, hard-drive protection, cryptocurrency mining, resource\nsharing, code obfuscation, etc. We suggest memory-hard computing as a generic\nparadigm, where every task is amalgamated with a certain procedure requiring\nintensive access to RAM both in terms of size and (very importantly) bandwidth,\nso that transferring the computation to GPU, FPGA, and even ASIC brings little\nor no cost reduction. Cryptographic schemes that run in this framework become\negalitarian in the sense that both users and attackers are equal in the\nprice-performance ratio conditions. Based on existing schemes like {Argon2} and\nthe recent generalized-birthday proof-of-work, we suggest a generic framework\nand two new schemes: MTP, a memory-hard Proof-of-Work based on the memory-hard\nfunction with fast verification and short proofs. It can be also used for\nmemory-hard time-lock puzzles. {MHE}, the concept of memory-hard encryption,\nwhich utilizes available RAM to strengthen the encryption for the low-entropy\nkeys (allowing to bring back 6 letter passwords).\n", "versions": [{"version": "v1", "created": "Sat, 11 Jun 2016 13:11:51 GMT"}, {"version": "v2", "created": "Mon, 29 Jan 2018 21:06:50 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Biryukov", "Alex", ""], ["Khovratovich", "Dmitry", ""]]}, {"id": "1606.03986", "submitter": "Vincenzo Matta", "authors": "Vincenzo Matta, Mario Di Mauro, Maurizio Longo", "title": "DDoS Attacks with Randomized Traffic Innovation: Botnet Identification\n  Challenges and Strategies", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Denial-of-Service (DDoS) attacks are usually launched through the\n$botnet$, an \"army\" of compromised nodes hidden in the network. Inferential\ntools for DDoS mitigation should accordingly enable an early and reliable\ndiscrimination of the normal users from the compromised ones. Unfortunately,\nthe recent emergence of attacks performed at the application layer has\nmultiplied the number of possibilities that a botnet can exploit to conceal its\nmalicious activities. New challenges arise, which cannot be addressed by simply\nborrowing the tools that have been successfully applied so far to earlier DDoS\nparadigms. In this work, we offer basically three contributions: $i)$ we\nintroduce an abstract model for the aforementioned class of attacks, where the\nbotnet emulates normal traffic by continually learning admissible patterns from\nthe environment; $ii)$ we devise an inference algorithm that is shown to\nprovide a consistent (i.e., converging to the true solution as time progresses)\nestimate of the botnet possibly hidden in the network; and $iii)$ we verify the\nvalidity of the proposed inferential strategy over $real$ network traces.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 15:03:10 GMT"}, {"version": "v2", "created": "Fri, 9 Sep 2016 07:10:08 GMT"}], "update_date": "2016-09-12", "authors_parsed": [["Matta", "Vincenzo", ""], ["Di Mauro", "Mario", ""], ["Longo", "Maurizio", ""]]}, {"id": "1606.04435", "submitter": "Kathrin Grosse", "authors": "Kathrin Grosse, Nicolas Papernot, Praveen Manoharan, Michael Backes,\n  Patrick McDaniel", "title": "Adversarial Perturbations Against Deep Neural Networks for Malware\n  Classification", "comments": "version update: correcting typos, incorporating external feedback", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks, like many other machine learning models, have recently\nbeen shown to lack robustness against adversarially crafted inputs. These\ninputs are derived from regular inputs by minor yet carefully selected\nperturbations that deceive machine learning models into desired\nmisclassifications. Existing work in this emerging field was largely specific\nto the domain of image classification, since the high-entropy of images can be\nconveniently manipulated without changing the images' overall visual\nappearance. Yet, it remains unclear how such attacks translate to more\nsecurity-sensitive applications such as malware detection - which may pose\nsignificant challenges in sample generation and arguably grave consequences for\nfailure.\n  In this paper, we show how to construct highly-effective adversarial sample\ncrafting attacks for neural networks used as malware classifiers. The\napplication domain of malware classification introduces additional constraints\nin the adversarial sample crafting problem when compared to the computer vision\ndomain: (i) continuous, differentiable input domains are replaced by discrete,\noften binary inputs; and (ii) the loose condition of leaving visual appearance\nunchanged is replaced by requiring equivalent functional behavior. We\ndemonstrate the feasibility of these attacks on many different instances of\nmalware classifiers that we trained using the DREBIN Android malware data set.\nWe furthermore evaluate to which extent potential defensive mechanisms against\nadversarial crafting can be leveraged to the setting of malware classification.\nWhile feature reduction did not prove to have a positive impact, distillation\nand re-training on adversarially crafted samples show promising results.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 16:01:52 GMT"}, {"version": "v2", "created": "Thu, 16 Jun 2016 08:14:12 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Grosse", "Kathrin", ""], ["Papernot", "Nicolas", ""], ["Manoharan", "Praveen", ""], ["Backes", "Michael", ""], ["McDaniel", "Patrick", ""]]}, {"id": "1606.04552", "submitter": "Harish Sethu", "authors": "Tingshan Huang, Harish Sethu and Nagarajan Kandasamy", "title": "A New Approach to Dimensionality Reduction for Anomaly Detection in Data\n  Traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The monitoring and management of high-volume feature-rich traffic in large\nnetworks offers significant challenges in storage, transmission and\ncomputational costs. The predominant approach to reducing these costs is based\non performing a linear mapping of the data to a low-dimensional subspace such\nthat a certain large percentage of the variance in the data is preserved in the\nlow-dimensional representation. This variance-based subspace approach to\ndimensionality reduction forces a fixed choice of the number of dimensions, is\nnot responsive to real-time shifts in observed traffic patterns, and is\nvulnerable to normal traffic spoofing. Based on theoretical insights proved in\nthis paper, we propose a new distance-based approach to dimensionality\nreduction motivated by the fact that the real-time structural differences\nbetween the covariance matrices of the observed and the normal traffic is more\nrelevant to anomaly detection than the structure of the training data alone.\nOur approach, called the distance-based subspace method, allows a different\nnumber of reduced dimensions in different time windows and arrives at only the\nnumber of dimensions necessary for effective anomaly detection. We present\ncentralized and distributed versions of our algorithm and, using simulation on\nreal traffic traces, demonstrate the qualitative and quantitative advantages of\nthe distance-based subspace approach.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 20:29:50 GMT"}], "update_date": "2016-06-16", "authors_parsed": [["Huang", "Tingshan", ""], ["Sethu", "Harish", ""], ["Kandasamy", "Nagarajan", ""]]}, {"id": "1606.04593", "submitter": "Guy Kloss", "authors": "Guy Kloss", "title": "Strongvelope Multi-Party Encrypted Messaging Protocol design document", "comments": "design whitepaper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this document we describe the design of a multi-party messaging encryption\nprotocol \"Strongvelope\". We hope that it will prove useful to people interested\nin understanding the inner workings of this protocol as well as cryptography\nand security experts to review the underlying concepts and assumptions.\n  In this design paper we are outlining the perspective of chat message\nprotection through the Strongvelope module. This is different from the product\n(the Mega chat) and the transport means which it will be used with. Aspects of\nthe chat product and transport are only referred to where appropriate, but are\nnot subject to discussion in this document.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 23:38:41 GMT"}], "update_date": "2016-06-16", "authors_parsed": [["Kloss", "Guy", ""]]}, {"id": "1606.04598", "submitter": "Guy Kloss", "authors": "Ximin Luo, Guy Kloss", "title": "mpENC Multi-Party Encrypted Messaging Protocol design document", "comments": "technical whitepaper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This document is a technical overview and discussion of our work, a protocol\nfor secure group messaging. By secure we mean for the actual users i.e.\nend-to-end security, as opposed to \"secure\" for irrelevant third parties.\n  Our work provides everything needed to run a messaging session between real\nusers on top of a real transport protocol. That is, we specify not just a key\nexchange, but when and how to run these relative to transport-layer events; how\nto achieve liveness properties such as reliability and consistency, that are\ntime-sensitive and lie outside of the send-receive logic that cryptography-only\nprotocols often restrict themselves to; and offer suggestions for displaying\naccurate (i.e. secure) but not overwhelming information in user interfaces.\n  We aim towards a general-purpose unified protocol. In other words, we'd\nprefer to avoid creating a completely new protocol merely to support\nautomation, or asynchronity, or a different transport protocol. This would add\ncomplexity to the overall ecosystem of communications protocols. It is simply\nunnecessary if the original protocol is designed well, as we have tried to do.\n  That aim is not complete -- our full protocol system, as currently\nimplemented, is suitable only for use with certain instant messaging protocols.\nHowever, we have tried to separate out conceptually-independent concerns, and\nsolve these individually using minimal assumptions even if other components\nmake extra assumptions. This means that many components of our full system can\nbe reused in future protocol extensions, and we know exactly which components\nmust be replaced in order to lift the existing constraints on our full system.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 00:40:17 GMT"}], "update_date": "2016-06-16", "authors_parsed": [["Luo", "Ximin", ""], ["Kloss", "Guy", ""]]}, {"id": "1606.04599", "submitter": "Guy Kloss", "authors": "Guy Kloss", "title": "Mega Key Authentication Mechanism", "comments": "technical whitepaper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  For secure communication it is not just sufficient to use strong cryptography\nwith good and strong keys, but to actually have the assurance, that the keys in\nuse for it are authentic and from the contact one is expecting to communicate\nwith. Without that, it is possible to be subject to impersonation or\nman-in-the-middle (MitM) attacks.\n  Mega meets this problem by providing a hierarchical authentication mechanism\nfor contacts and their keys. To avoid any hassle when using multiple types of\nkeys and key pairs for different purposes, the whole authentication mechanism\nis brought down to a single \"identity key\".\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 00:40:31 GMT"}], "update_date": "2016-06-16", "authors_parsed": [["Kloss", "Guy", ""]]}, {"id": "1606.04662", "submitter": "Igor Korkin", "authors": "Igor Korkin and Iwan Nesterow", "title": "Acceleration of Statistical Detection of Zero-day Malware in the Memory\n  Dump Using CUDA-enabled GPU Hardware", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the anticipatory enhancement of methods of detecting\nstealth software. Cyber security detection tools are insufficiently powerful to\nreveal the most recent cyber-attacks which use malware. In this paper, we will\npresent first an idea of the highest stealth malware, as this is the most\ncomplicated scenario for detection because it combines both existing\nanti-forensic techniques together with their potential improvements. Second, we\npresent new detection methods, which are resilient to this hidden prototype. To\nhelp solve this detection challenge, we have analyzed Windows memory content\nusing a new method of Shannon Entropy calculation; methods of digital\nphotogrammetry; the Zipf Mandelbrot law, as well as by disassembling the memory\ncontent and analyzing the output. Finally, we present an idea and architecture\nof the software tool, which uses CUDA enabled GPU hardware to speed-up memory\nforensics. All three ideas are currently a work in progress.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 07:33:38 GMT"}], "update_date": "2016-06-16", "authors_parsed": [["Korkin", "Igor", ""], ["Nesterow", "Iwan", ""]]}, {"id": "1606.04705", "submitter": "Davut Deniz Yavuz", "authors": "Kemal Bicakci, Davut Deniz Yavuz, Sezin Gurkan", "title": "TwinCloud: Secure Cloud Sharing Without Explicit Key Management", "comments": "9 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of cloud technologies, there is a growing number of\neasy-to-use services to store files and share them with other cloud users. By\nproviding security features, cloud service providers try to encourage users to\nstore personal files or corporate documents on their servers. However, their\nserver-side encryption solutions are not satisfactory when the server itself is\nnot trusted. Although, there are several client-side solutions to provide\nsecurity for cloud sharing, they are not used extensively because of usability\nissues in key management.\n  In this paper, we propose TwinCloud which is an innovative solution with the\ngoal of providing a secure system to users without compromising the usability\nof cloud sharing. TwinCloud achieves this by bringing a novel solution to the\ncomplex key exchange problem and by providing a simple and practical approach\nto store and share files by hiding all the cryptographic and key-distribution\noperations from users. Serving as a gateway, TwinCloud uses two or more cloud\nproviders to store the encryption keys and encrypted files in separate clouds\nwhich ease the secure sharing without a need for trust to either of the cloud\nservice providers with the assumption that they do not collude with each other.\nWe implemented TwinCloud as a lightweight application and make it available as\nopen-source. The results of our usability study show the prospect of the secure\nsharing solution of TwinCloud.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 10:11:54 GMT"}, {"version": "v2", "created": "Wed, 13 Jul 2016 05:40:31 GMT"}], "update_date": "2016-07-14", "authors_parsed": [["Bicakci", "Kemal", ""], ["Yavuz", "Davut Deniz", ""], ["Gurkan", "Sezin", ""]]}, {"id": "1606.04722", "submitter": "Xi Wu", "authors": "Xi Wu, Fengan Li, Arun Kumar, Kamalika Chaudhuri, Somesh Jha, Jeffrey\n  F. Naughton", "title": "Bolt-on Differential Privacy for Scalable Stochastic Gradient\n  Descent-based Analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While significant progress has been made separately on analytics systems for\nscalable stochastic gradient descent (SGD) and private SGD, none of the major\nscalable analytics frameworks have incorporated differentially private SGD.\nThere are two inter-related issues for this disconnect between research and\npractice: (1) low model accuracy due to added noise to guarantee privacy, and\n(2) high development and runtime overhead of the private algorithms. This paper\ntakes a first step to remedy this disconnect and proposes a private SGD\nalgorithm to address \\emph{both} issues in an integrated manner. In contrast to\nthe white-box approach adopted by previous work, we revisit and use the\nclassical technique of {\\em output perturbation} to devise a novel \"bolt-on\"\napproach to private SGD. While our approach trivially addresses (2), it makes\n(1) even more challenging. We address this challenge by providing a novel\nanalysis of the $L_2$-sensitivity of SGD, which allows, under the same privacy\nguarantees, better convergence of SGD when only a constant number of passes can\nbe made over the data. We integrate our algorithm, as well as other\nstate-of-the-art differentially private SGD, into Bismarck, a popular scalable\nSGD-based analytics system on top of an RDBMS. Extensive experiments show that\nour algorithm can be easily integrated, incurs virtually no overhead, scales\nwell, and most importantly, yields substantially better (up to 4X) test\naccuracy than the state-of-the-art algorithms on many real datasets.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 11:14:29 GMT"}, {"version": "v2", "created": "Sun, 26 Feb 2017 16:26:59 GMT"}, {"version": "v3", "created": "Thu, 23 Mar 2017 17:35:09 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Wu", "Xi", ""], ["Li", "Fengan", ""], ["Kumar", "Arun", ""], ["Chaudhuri", "Kamalika", ""], ["Jha", "Somesh", ""], ["Naughton", "Jeffrey F.", ""]]}, {"id": "1606.05374", "submitter": "Jacob Steinhardt", "authors": "Jacob Steinhardt and Gregory Valiant and Moses Charikar", "title": "Avoiding Imposters and Delinquents: Adversarial Crowdsourcing and Peer\n  Prediction", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR cs.DS cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a crowdsourcing model in which $n$ workers are asked to rate the\nquality of $n$ items previously generated by other workers. An unknown set of\n$\\alpha n$ workers generate reliable ratings, while the remaining workers may\nbehave arbitrarily and possibly adversarially. The manager of the experiment\ncan also manually evaluate the quality of a small number of items, and wishes\nto curate together almost all of the high-quality items with at most an\n$\\epsilon$ fraction of low-quality items. Perhaps surprisingly, we show that\nthis is possible with an amount of work required of the manager, and each\nworker, that does not scale with $n$: the dataset can be curated with\n$\\tilde{O}\\Big(\\frac{1}{\\beta\\alpha^3\\epsilon^4}\\Big)$ ratings per worker, and\n$\\tilde{O}\\Big(\\frac{1}{\\beta\\epsilon^2}\\Big)$ ratings by the manager, where\n$\\beta$ is the fraction of high-quality items. Our results extend to the more\ngeneral setting of peer prediction, including peer grading in online\nclassrooms.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2016 21:45:14 GMT"}], "update_date": "2016-06-20", "authors_parsed": [["Steinhardt", "Jacob", ""], ["Valiant", "Gregory", ""], ["Charikar", "Moses", ""]]}, {"id": "1606.05457", "submitter": "Juan Antonio Lopez-Ramos", "authors": "Joan-Josep Climent and Juan Antonio Lopez-Ramos", "title": "Public Key Protocols over the Ring E_p(m)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we use the nonrepresentable ring E_p(m)to introduce public key\ncryptosystems in noncommutative settings and based on the Semigrouop Action\nProblem and the Decomposition Problem respectively.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 09:08:05 GMT"}], "update_date": "2016-06-20", "authors_parsed": [["Climent", "Joan-Josep", ""], ["Lopez-Ramos", "Juan Antonio", ""]]}, {"id": "1606.05915", "submitter": "Mordechai Guri", "authors": "Mordechai Guri, Yosef Solewicz, Andrey Daidakulov, Yuval Elovici", "title": "Fansmitter: Acoustic Data Exfiltration from (Speakerless) Air-Gapped\n  Computers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because computers may contain or interact with sensitive information, they\nare often air-gapped and in this way kept isolated and disconnected from the\nInternet. In recent years the ability of malware to communicate over an air-gap\nby transmitting sonic and ultrasonic signals from a computer speaker to a\nnearby receiver has been shown. In order to eliminate such acoustic channels,\ncurrent best practice recommends the elimination of speakers (internal or\nexternal) in secure computers, thereby creating a so-called 'audio-gap'. In\nthis paper, we present Fansmitter, a malware that can acoustically exfiltrate\ndata from air-gapped computers, even when audio hardware and speakers are not\npresent. Our method utilizes the noise emitted from the CPU and chassis fans\nwhich are present in virtually every computer today. We show that a software\ncan regulate the internal fans' speed in order to control the acoustic waveform\nemitted from a computer. Binary data can be modulated and transmitted over\nthese audio signals to a remote microphone (e.g., on a nearby mobile phone). We\npresent Fansmitter's design considerations, including acoustic signature\nanalysis, data modulation, and data transmission. We also evaluate the acoustic\nchannel, present our results, and discuss countermeasures. Using our method we\nsuccessfully transmitted data from air-gapped computer without audio hardware,\nto a smartphone receiver in the same room. We demonstrated the effective\ntransmission of encryption keys and passwords from a distance of zero to eight\nmeters, with bit rate of up to 900 bits/hour. We show that our method can also\nbe used to leak data from different types of IT equipment, embedded systems,\nand IoT devices that have no audio hardware, but contain fans of various types\nand sizes.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jun 2016 22:05:44 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Guri", "Mordechai", ""], ["Solewicz", "Yosef", ""], ["Daidakulov", "Andrey", ""], ["Elovici", "Yuval", ""]]}, {"id": "1606.05917", "submitter": "Jason Teutsch", "authors": "Sanjay Jain, Prateek Saxena, Frank Stephan, and Jason Teutsch", "title": "How to verify computation with a rational network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper introduces a practical protocol for provably secure,\noutsourced computation. Our protocol minimizes overhead for verification by\nrequiring solutions to withstand an interactive game between a prover and\nchallenger. For optimization problems, the best or nearly best of all submitted\nsolutions is expected to be accepted by this approach. Financial incentives and\ndeposits are used in order to overcome the problem of fake participants.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jun 2016 22:11:28 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Jain", "Sanjay", ""], ["Saxena", "Prateek", ""], ["Stephan", "Frank", ""], ["Teutsch", "Jason", ""]]}, {"id": "1606.06047", "submitter": "Harmeet Singh", "authors": "Harmeet Singh", "title": "Contravening Esotery: Cryptanalysis of Knapsack Cipher using Genetic\n  Algorithms", "comments": "http://www.ijcaonline.org/archives/volume140/number6/24599-2016909333, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptanalysis of knapsack cipher is a fascinating problem which has eluded\nthe computing fraternity for decades. However, in most of the cases either the\ntime complexity of the proposed algorithm is colossal or an insufficient number\nof samples have been taken for verification. The present work proposes a\nGenetic Algorithm based technique for cryptanalysis of knapsack cipher. The\nexperiments conducted prove the validity of the technique. The results prove\nthat the technique is better than the existing techniques. An extensive review\nhas been carried out in order to find the gaps in the existing techniques. The\nwork paves the way of the application of computational intelligence techniques\nto the discipline of cryptanalysis.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 10:04:05 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Singh", "Harmeet", ""]]}, {"id": "1606.06369", "submitter": "Annamalai Narayanan", "authors": "Annamalai Narayanan, Guozhu Meng, Liu Yang, Jinliang Liu and Lihui\n  Chen", "title": "Contextual Weisfeiler-Lehman Graph Kernel For Malware Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel graph kernel specifically to address a\nchallenging problem in the field of cyber-security, namely, malware detection.\nPrevious research has revealed the following: (1) Graph representations of\nprograms are ideally suited for malware detection as they are robust against\nseveral attacks, (2) Besides capturing topological neighbourhoods (i.e.,\nstructural information) from these graphs it is important to capture the\ncontext under which the neighbourhoods are reachable to accurately detect\nmalicious neighbourhoods.\n  We observe that state-of-the-art graph kernels, such as Weisfeiler-Lehman\nkernel (WLK) capture the structural information well but fail to capture\ncontextual information. To address this, we develop the Contextual\nWeisfeiler-Lehman kernel (CWLK) which is capable of capturing both these types\nof information. We show that for the malware detection problem, CWLK is more\nexpressive and hence more accurate than WLK while maintaining comparable\nefficiency. Through our large-scale experiments with more than 50,000\nreal-world Android apps, we demonstrate that CWLK outperforms two\nstate-of-the-art graph kernels (including WLK) and three malware detection\ntechniques by more than 5.27% and 4.87% F-measure, respectively, while\nmaintaining high efficiency. This high accuracy and efficiency make CWLK\nsuitable for large-scale real-world malware detection.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 00:02:45 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Narayanan", "Annamalai", ""], ["Meng", "Guozhu", ""], ["Yang", "Liu", ""], ["Liu", "Jinliang", ""], ["Chen", "Lihui", ""]]}, {"id": "1606.06530", "submitter": "Ralph Holz", "authors": "Luke Anderson, Ralph Holz, Alexander Ponomarev, Paul Rimba, Ingo Weber", "title": "New kids on the block: an analysis of modern blockchains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Half a decade after Bitcoin became the first widely used cryptocurrency,\nblockchains are receiving considerable interest from industry and the research\ncommunity. Modern blockchains feature services such as name registration and\nsmart contracts. Some employ new forms of consensus, such as proof-of-stake\ninstead of proof-of-work. However, these blockchains are so far relatively\npoorly investigated, despite the fact that they move considerable assets. In\nthis paper, we explore three representative, modern blockchains---Ethereum,\nNamecoin, and Peercoin. Our focus is on the features that set them apart from\nthe pure currency use case of Bitcoin. We investigate the blockchains' activity\nin terms of transactions and usage patterns, identifying some curiosities in\nthe process. For Ethereum, we are mostly interested in the smart contract\nfunctionality it offers. We also carry out a brief analysis of issues that are\nintroduced by negligent design of smart contracts. In the case of Namecoin, our\nfocus is how the name registration is used and has developed over time. For\nPeercoin, we are interested in the use of proof-of-stake, as this consensus\nalgorithm is poorly understood yet used to move considerable value. Finally, we\nrelate the above to the fundamental characteristics of the underlying\npeer-to-peer networks. We present a crawler for Ethereum and give statistics on\nthe network size. For Peercoin and Namecoin, we identify the relatively small\nsize of the networks and the weak bootstrapping process.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 12:11:44 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Anderson", "Luke", ""], ["Holz", "Ralph", ""], ["Ponomarev", "Alexander", ""], ["Rimba", "Paul", ""], ["Weber", "Ingo", ""]]}, {"id": "1606.06644", "submitter": "Amadou Kane", "authors": "Amadou Moctar Kane", "title": "How DNA Cryptography can help whistleblowers and refugees", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent progress in DNA sequencing will probably revolutionize the world\nof electronic. Hence, we went from DNA sequencing that only research centers\ncould realize, to portable, tiny and inexpensive tools. So, it is likely that\nin a few years these DNA sequencers will be included in our smartphones.\n  The purpose of this paper is to support this revolution, by using the DNA\ncryptography, hash functions and social networks. The first application will\nintroduce a mutual entity authentication protocol in order to help waifs,\nrefugees, and victims of human trafficking to find their biological parents\nonline.\n  The second application will also use the DNA cryptography and the social\nnetworks to protect whistleblowers' actions. For example, this method will\nallow whistleblowers to securely broadcast on social networks, their\ninformation with one grape.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2016 16:12:09 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Kane", "Amadou Moctar", ""]]}, {"id": "1606.06698", "submitter": "Amin Ghafouri", "authors": "Amin Ghafouri, Waseem Abbas, Yevgeniy Vorobeychik, and Xenofon\n  Koutsoukos", "title": "Vulnerability of Fixed-Time Control of Signalized Intersections to\n  Cyber-Tampering", "comments": null, "journal-ref": "9th International Symposium on Resilient Control Systems (ISRCS),\n  Chicago, IL, pp. 130-135 (2016)", "doi": null, "report-no": null, "categories": "cs.SY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent experimental studies have shown that traffic management systems are\nvulnerable to cyber-attacks on sensor data. This paper studies the\nvulnerability of fixed-time control of signalized intersections when sensors\nmeasuring traffic flow information are compromised and perturbed by an\nadversary. The problems are formulated by considering three malicious\nobjectives: 1) worst-case network accumulation, which aims to destabilize the\noverall network as much as possible; 2) worst-case lane accumulation, which\naims to cause worst-case accumulation on some target lanes; and 3) risk-averse\ntarget accumulation, which aims to reach a target accumulation by making the\nminimum perturbation to sensor data. The problems are solved using bilevel\nprogramming optimization methods. Finally, a case study of a real network is\nused to illustrate the results.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 18:41:46 GMT"}, {"version": "v2", "created": "Mon, 11 Jul 2016 18:43:11 GMT"}, {"version": "v3", "created": "Wed, 8 Feb 2017 22:15:31 GMT"}], "update_date": "2017-02-10", "authors_parsed": [["Ghafouri", "Amin", ""], ["Abbas", "Waseem", ""], ["Vorobeychik", "Yevgeniy", ""], ["Koutsoukos", "Xenofon", ""]]}, {"id": "1606.06699", "submitter": "Amin Ghafouri", "authors": "Amin Ghafouri and Xenofon D. Koutsoukos", "title": "Resilient Supervisory Control of Autonomous Intersections in the\n  Presence of Sensor Attacks", "comments": "8 pages, submitted to 55th IEEE Conference on Decision and Control\n  (CDC 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical systems (CPS), such as autonomous vehicles crossing an\nintersection, are vulnerable to cyber-attacks and their safety-critical nature\nmakes them a target for malicious adversaries. This paper studies the problem\nof supervisory control of autonomous intersections in the presence of sensor\nattacks. Sensor attacks are performed when an adversary gains access to the\ntransmission channel and corrupts the measurements before they are received by\nthe decision-making unit. We show that the supervisory control system is\nvulnerable to sensor attacks that can cause collision or deadlock among\nvehicles. To improve the system resilience, we introduce a detector in the\ncontrol architecture and focus on stealthy attacks that cannot be detected but\nare capable of compromising safety. We then present a resilient supervisory\ncontrol system that is safe, non-deadlocking, and maximally permissive, despite\nthe presence of disturbances, uncontrolled vehicles, and sensor attacks.\nFinally, we demonstrate how the resilient supervisor works by considering\nillustrative examples.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 18:43:04 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Ghafouri", "Amin", ""], ["Koutsoukos", "Xenofon D.", ""]]}, {"id": "1606.06707", "submitter": "Amin Ghafouri", "authors": "Amin Ghafouri, Waseem Abbas, Aron Laszka, Yevgeniy Vorobeychik, and\n  Xenofon Koutsoukos", "title": "Optimal Thresholds for Anomaly-Based Intrusion Detection in Dynamical\n  Environments", "comments": "Decision and Game Theory for Security: 7th International Conference,\n  GameSec 2016, New York, NY, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cyber-physical systems, malicious and resourceful attackers could\npenetrate the system through cyber means and cause significant physical damage.\nConsequently, detection of such attacks becomes integral towards making these\nsystems resilient to attacks. To achieve this objective, intrusion detection\nsystems (IDS) that are able to detect malicious behavior can be deployed.\nHowever, practical IDS are imperfect and sometimes they may produce false\nalarms for a normal system behavior. Since alarms need to be investigated for\nany potential damage, a large number of false alarms may increase the\noperational costs significantly. Thus, IDS need to be configured properly, as\noversensitive IDS could detect attacks early but at the cost of a higher number\nof false alarms. Similarly, IDS with low sensitivity could reduce the false\nalarms while increasing the time to detect the attacks. The configuration of\nIDS to strike the right balance between time to detecting attacks and the rate\nof false positives is a challenging task, especially in dynamic environments,\nin which the damage incurred by a successful attack is time-varying.\n  In this paper, we study the problem of finding optimal detection thresholds\nfor anomaly-based detectors implemented in dynamical systems in the face of\nstrategic attacks. We formulate the problem as an attacker-defender security\ngame, and determine thresholds for the detector to achieve an optimal trade-off\nbetween the detection delay and the false positive rates. In this direction,\nfirst, we provide an algorithm that computes optimal fixed threshold that\nremains fixed throughout. Second, we allow detector's threshold to change with\ntime to further minimize the defender's loss and provide an algorithm to\ncompute time-varying thresholds, which we call adaptive thresholds. Finally, we\nnumerically evaluate our results using a water distribution network as a\ncase-study.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 18:59:55 GMT"}, {"version": "v2", "created": "Wed, 8 Feb 2017 22:04:20 GMT"}], "update_date": "2017-02-10", "authors_parsed": [["Ghafouri", "Amin", ""], ["Abbas", "Waseem", ""], ["Laszka", "Aron", ""], ["Vorobeychik", "Yevgeniy", ""], ["Koutsoukos", "Xenofon", ""]]}, {"id": "1606.06771", "submitter": "Jeffrey Pawlick", "authors": "Jeffrey Pawlick and Quanyan Zhu", "title": "A Stackelberg Game Perspective on the Conflict Between Machine Learning\n  and Data Obfuscation", "comments": "This conference paper was not accepted. It has been withdrawn because\n  it was subsequently revised and appears here arXiv:1608.02546", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data is the new oil; this refrain is repeated extensively in the age of\ninternet tracking, machine learning, and data analytics. Social network\nanalysis, cookie-based advertising, and government surveillance are all\nevidence of the use of data for commercial and national interests. Public\npressure, however, is mounting for the protection of privacy. Frameworks such\nas differential privacy offer machine learning algorithms methods to guarantee\nlimits to information disclosure, but they are seldom implemented. Recently,\nhowever, developers have made significant efforts to undermine tracking through\nobfuscation tools that hide user characteristics in a sea of noise. These\nservices highlight an emerging clash between tracking and data obfuscation. In\nthis paper, we conceptualize this conflict through a dynamic game between users\nand a machine learning algorithm that uses empirical risk minimization. First,\na machine learner declares a privacy protection level, and then users respond\nby choosing their own perturbation amounts. We study the interaction between\nthe users and the learner using a Stackelberg game. The utility functions\nquantify accuracy using expected loss and privacy in terms of the bounds of\ndifferential privacy. In equilibrium, we find selfish users tend to cause\nsignificant utility loss to trackers by perturbing heavily, in a phenomenon\nreminiscent of public good games. Trackers, however, can improve the balance by\nproactively perturbing the data themselves. While other work in this area has\nstudied privacy markets and mechanism design for truthful reporting of user\ninformation, we take a different viewpoint by considering both user and learner\nperturbation.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 21:14:48 GMT"}, {"version": "v2", "created": "Wed, 10 Aug 2016 17:11:49 GMT"}], "update_date": "2016-08-11", "authors_parsed": [["Pawlick", "Jeffrey", ""], ["Zhu", "Quanyan", ""]]}, {"id": "1606.06808", "submitter": "Johes Bater", "authors": "Johes Bater, Gregory Elliott, Craig Eggen, Satyender Goel, Abel Kho,\n  Jennie Rogers", "title": "SMCQL: Secure Querying for Federated Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People and machines are collecting data at an unprecedented rate. Despite\nthis newfound abundance of data, progress has been slow in sharing it for open\nscience, business, and other data-intensive endeavors. Many such efforts are\nstymied by privacy concerns and regulatory compliance issues. For example, many\nhospitals are interested in pooling their medical records for research, but\nnone may disclose arbitrary patient records to researchers or other healthcare\nproviders. In this context we propose the Private Data Network (PDN), a\nfederated database for querying over the collective data of mutually\ndistrustful parties. In a PDN, each member database does not reveal its tuples\nto its peers nor to the query writer. Instead, the user submits a query to an\nhonest broker that plans and coordinates its execution over multiple private\ndatabases using secure multiparty computation (SMC). Here, each database's\nquery execution is oblivious, and its program counters and memory traces are\nagnostic to the inputs of others. We introduce a framework for executing PDN\nqueries named SMCQL. This system translates SQL statements into SMC primitives\nto compute query results over the union of its source databases without\nrevealing sensitive information about individual tuples to peer data providers\nor the honest broker. Only the honest broker and the querier receive the\nresults of a PDN query. For fast, secure query evaluation, we explore a\nheuristics-driven optimizer that minimizes the PDN's use of secure computation\nand partitions its query evaluation into scalable slices.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 02:45:39 GMT"}, {"version": "v2", "created": "Tue, 28 Jun 2016 20:15:00 GMT"}, {"version": "v3", "created": "Thu, 30 Jun 2016 18:44:51 GMT"}, {"version": "v4", "created": "Thu, 17 Nov 2016 07:37:41 GMT"}, {"version": "v5", "created": "Mon, 6 Mar 2017 21:42:17 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Bater", "Johes", ""], ["Elliott", "Gregory", ""], ["Eggen", "Craig", ""], ["Goel", "Satyender", ""], ["Kho", "Abel", ""], ["Rogers", "Jennie", ""]]}, {"id": "1606.06872", "submitter": "Adi Rosen", "authors": "Iordanis Kerenidis, Adi Ros\\'en, Florent Urrutia", "title": "Multi-Party Protocols, Information Complexity and Privacy", "comments": "32 pages ; MFCS2016 ; ACM Transactions on Computation Theory, to\n  appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new information theoretic measure that we call Public\nInformation Complexity (PIC), as a tool for the study of multi-party\ncomputation protocols, and of quantities such as their communication\ncomplexity, or the amount of randomness they require in the context of\ninformation-theoretic private computations. We are able to use this measure\ndirectly in the natural asynchronous message-passing peer-to-peer model and\nshow a number of interesting properties and applications of our new notion: the\nPublic Information Complexity is a lower bound on the Communication Complexity\nand an upper bound on the Information Complexity; the difference between the\nPublic Information Complexity and the Information Complexity provides a lower\nbound on the amount of randomness used in a protocol; any communication\nprotocol can be compressed to its Public Information Cost; an explicit\ncalculation of the zero-error Public Information Complexity of the $k$-party,\n$n$-bit Parity function, where a player outputs the bit-wise parity of the\ninputs. The latter result also establishes that the amount of randomness needed\nby a private protocol that computes this function is $\\Omega(n)$.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 10:00:41 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 19:59:18 GMT"}, {"version": "v3", "created": "Mon, 17 Dec 2018 17:55:10 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Kerenidis", "Iordanis", ""], ["Ros\u00e9n", "Adi", ""], ["Urrutia", "Florent", ""]]}, {"id": "1606.06897", "submitter": "Sanjay Sahay", "authors": "Ashu Sharma and Sanjay K. Sahay", "title": "An effective approach for classification of advanced malware with high\n  accuracy", "comments": "15 Pages, 14 figures", "journal-ref": "International Journal of Security and Its Applications, Vol. 10,\n  No. 4, pp.249-266, 2016", "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combating malware is very important for software/systems security, but to\nprevent the software/systems from the advanced malware, viz. metamorphic\nmalware is a challenging task, as it changes the structure/code after each\ninfection. Therefore in this paper, we present a novel approach to detect the\nadvanced malware with high accuracy by analyzing the occurrence of opcodes\n(features) by grouping the executables. These groups are made on the basis of\nour earlier studies [1] that the difference between the sizes of any two\nmalware generated by popular advanced malware kits viz. PS-MPC, G2 and NGVCK\nare within 5 KB. On the basis of obtained promising features, we studied the\nperformance of thirteen classifiers using N-fold cross-validation available in\nmachine learning tool WEKA. Among these thirteen classifiers we studied\nin-depth top five classifiers (Random forest, LMT, NBT, J48 and FT) and obtain\nmore than 96.28% accuracy for the detection of unknown malware, which is better\nthan the maximum detection accuracy (95.9%) reported by Santos et al (2013). In\nthese top five classifiers, our approach obtained a detection accuracy of\n97.95% by the Random forest.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 11:00:48 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Sharma", "Ashu", ""], ["Sahay", "Sanjay K.", ""]]}, {"id": "1606.06908", "submitter": "Sanjay Sahay", "authors": "Sanjay K. Sahay and Ashu Sharma", "title": "Grouping the executables to detect malware with high accuracy", "comments": "8 Pages, 13 Figures. arXiv admin note: text overlap with\n  arXiv:1606.06897", "journal-ref": "Elsevier, Procedia Computer Science, Vol. 78, pp. 667 - 674, 2016", "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The metamorphic malware variants with the same malicious behavior (family),\ncan obfuscate themselves to look different from each other. This variation in\nstructure leads to a huge signature database for traditional signature matching\ntechniques to detect them. In order to effective and efficient detection of\nmalware in large amounts of executables, we need to partition these files into\ngroups which can identify their respective families. In addition, the grouping\ncriteria should be chosen such a way that, it can also be applied to unknown\nfiles encounter on computers for classification. This paper discusses the study\nof malware and benign executables in groups to detect unknown malware with high\naccuracy. We studied sizes of malware generated by three popular second\ngeneration malware (metamorphic malware) creator kits viz. G2, PS-MPC and\nNGVCK, and observed that the size variation in any two generated malware from\nsame kit is not much. Hence, we grouped the executables on the basis of malware\nsizes by using Optimal k-Means Clustering algorithm and used these obtained\ngroups to select promising features for training (Random forest, J48, LMT, FT\nand NBT) classifiers to detect variants of malware or unknown malware. We find\nthat detection of malware on the basis of their respected file sizes gives\naccuracy up to 99.11% from the classifiers.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 11:45:13 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Sahay", "Sanjay K.", ""], ["Sharma", "Ashu", ""]]}, {"id": "1606.06909", "submitter": "Sanjay Sahay", "authors": "Ashu Sharma, Sanjay K. Sahay and Abhishek Kumar", "title": "Improving the detection accuracy of unknown malware by partitioning the\n  executables in groups", "comments": "Proceedings 9th ICACCT, 2015, 8 Pages, 7 Figures", "journal-ref": "Springer, Advances in Intelligent System and Computing, Vol. 452,\n  pp. 421 - 431, 2016", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detection of unknown malware with high accuracy is always a challenging task.\nTherefore, in this paper, we study the classification of unknown malware by two\nmethods. In the first/regular method, similar to other authors [17][16][20]\napproaches we select the features by taking all dataset in one group and in the\nsecond method, we select the features by partitioning the dataset in the range\nof file 5 KB size. We find that the second method to detect the malware with\n~8.7% more accurate than the first/regular method.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 11:46:10 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Sharma", "Ashu", ""], ["Sahay", "Sanjay K.", ""], ["Kumar", "Abhishek", ""]]}, {"id": "1606.06931", "submitter": "Petros Wallden Dr", "authors": "Elham Kashefi and Petros Wallden", "title": "Garbled Quantum Computation", "comments": "23 pages, 3 figures. v2 change in title, extended appendix on the\n  definition of specious adversaries and few other minor changes", "journal-ref": "Cryptography 1, 6 (2017)", "doi": "10.3390/cryptography1010006", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The universal blind quantum computation protocol (UBQC) (Broadbent,\nFitzsimons, Kashefi 2009) enables an almost classical client to delegate a\nquantum computation to an untrusted quantum server (in form of a garbled\nquantum computation) while the security for the client is unconditional. In\nthis contribution we explore the possibility of extending the verifiable UBQC\n(Fitzsimons, Kashefi 2012), to achieve further functionalities as was done for\nclassical garbled computation. First, exploring the asymmetric nature of UBQC\n(client preparing only single qubits, while the server runs the entire quantum\ncomputation), we present a \"Yao\" type protocol for secure two party quantum\ncomputation. Similar to the classical setting (Yao 1986) our quantum Yao\nprotocol is secure against a specious (quantum honest-but-curious) garbler, but\nin our case, against a (fully) malicious evaluator. Unlike the protocol in\n(Dupuis, Nielsen, Salvail 2010), we do not require any online-quantum\ncommunication between the garbler and the evaluator and thus no extra\ncryptographic primitive. This feature will allow us to construct a simple\nuniversal one-time compiler for any quantum computation using one-time memory,\nin a similar way with the classical work of (Goldwasser, Kalai, Rothblum 2008)\nwhile more efficiently than the previous work of (Broadbent, Gutoski, Stebila\n2013).\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 12:57:26 GMT"}, {"version": "v2", "created": "Fri, 3 Mar 2017 11:48:41 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Kashefi", "Elham", ""], ["Wallden", "Petros", ""]]}, {"id": "1606.07025", "submitter": "Luis Mu\\~noz-Gonz\\'alez", "authors": "Luis Mu\\~noz-Gonz\\'alez, Daniele Sgandurra, Andrea Paudice, Emil C.\n  Lupu", "title": "Efficient Attack Graph Analysis through Approximate Inference", "comments": "30 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attack graphs provide compact representations of the attack paths that an\nattacker can follow to compromise network resources by analysing network\nvulnerabilities and topology. These representations are a powerful tool for\nsecurity risk assessment. Bayesian inference on attack graphs enables the\nestimation of the risk of compromise to the system's components given their\nvulnerabilities and interconnections, and accounts for multi-step attacks\nspreading through the system. Whilst static analysis considers the risk posture\nat rest, dynamic analysis also accounts for evidence of compromise, e.g. from\nSIEM software or forensic investigation. However, in this context, exact\nBayesian inference techniques do not scale well. In this paper we show how\nLoopy Belief Propagation - an approximate inference technique - can be applied\nto attack graphs, and that it scales linearly in the number of nodes for both\nstatic and dynamic analysis, making such analyses viable for larger networks.\nWe experiment with different topologies and network clustering on synthetic\nBayesian attack graphs with thousands of nodes to show that the algorithm's\naccuracy is acceptable and converge to a stable solution. We compare sequential\nand parallel versions of Loopy Belief Propagation with exact inference\ntechniques for both static and dynamic analysis, showing the advantages of\napproximate inference techniques to scale to larger attack graphs.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 17:48:17 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["Sgandurra", "Daniele", ""], ["Paudice", "Andrea", ""], ["Lupu", "Emil C.", ""]]}, {"id": "1606.07080", "submitter": "Ah Reum Kang", "authors": "Ah Reum Kang and Jeffrey Spaulding and Aziz Mohaisen", "title": "Domain Name System Security and Privacy: Old Problems and New Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The domain name system (DNS) is an important protocol in today's Internet\noperation, and is the standard naming convention between domain names, names\nthat are easy to read, understand, and remember by humans, to IP address of\nInternet resources. The wealth of research activities on DNS in general and\nsecurity and privacy in particular suggest that all problems in this domain are\nsolved. Reality however is that despite the large body of literature on various\naspects of DNS, there are still many challenges that need to be addressed. In\nthis paper, we review the various activities in the research community on DNS\noperation, security, and privacy, and outline various challenges and open\nresearch directions that need to be tackled.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 20:04:16 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Kang", "Ah Reum", ""], ["Spaulding", "Jeffrey", ""], ["Mohaisen", "Aziz", ""]]}, {"id": "1606.07150", "submitter": "Annamalai Narayanan", "authors": "Annamalai Narayanan, Liu Yang, Lihui Chen and Liu Jinliang", "title": "Adaptive and Scalable Android Malware Detection through Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that malware constantly evolves so as to evade detection and\nthis causes the entire malware population to be non-stationary. Contrary to\nthis fact, prior works on machine learning based Android malware detection have\nassumed that the distribution of the observed malware characteristics (i.e.,\nfeatures) do not change over time. In this work, we address the problem of\nmalware population drift and propose a novel online machine learning based\nframework, named DroidOL to handle it and effectively detect malware. In order\nto perform accurate detection, security-sensitive behaviors are captured from\napps in the form of inter-procedural control-flow sub-graph features using a\nstate-of-the-art graph kernel. In order to perform scalable detection and to\nadapt to the drift and evolution in malware population, an online\npassive-aggressive classifier is used.\n  In a large-scale comparative analysis with more than 87,000 apps, DroidOL\nachieves 84.29% accuracy outperforming two state-of-the-art malware techniques\nby more than 20% in their typical batch learning setting and more than 3% when\nthey are continuously re-trained. Our experimental findings strongly indicate\nthat online learning based approaches are highly suitable for real-world\nmalware detection.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 01:08:10 GMT"}, {"version": "v2", "created": "Mon, 26 Sep 2016 10:07:11 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Narayanan", "Annamalai", ""], ["Yang", "Liu", ""], ["Chen", "Lihui", ""], ["Jinliang", "Liu", ""]]}, {"id": "1606.07490", "submitter": "Mark Moir", "authors": "Maurice Herlihy and Mark Moir", "title": "Enhancing Accountability and Trust in Distributed Ledgers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Permisionless decentralized ledgers (\"blockchains\") such as the one\nunderlying the cryptocurrency Bitcoin allow anonymous participants to maintain\nthe ledger, while avoiding control or \"censorship\" by any single entity. In\ncontrast, permissioned decentralized ledgers exploit real-world trust and\naccountability, allowing only explicitly authorized parties to maintain the\nledger. Permissioned ledgers support more flexible governance and a wider\nchoice of consensus mechanisms. Both kinds of decentralized ledgers may be\nsusceptible to manipulation by participants who favor some transactions over\nothers. The real-world accountability underlying permissioned ledgers provides\nan opportunity to impose fairness constraints that can be enforced by\npenalizing violators after-the- fact. To date, however, this opportunity has\nnot been fully exploited, unnecessarily leaving participants latitude to\nmanipulate outcomes undetectably. This paper draws attention to this issue, and\nproposes design principles to make such manipulation more difficult, as well as\nspecific mechanisms to make it easier to detect when violations occur.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 21:47:10 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Herlihy", "Maurice", ""], ["Moir", "Mark", ""]]}, {"id": "1606.07760", "submitter": "Ayoub Otmani", "authors": "Philippe Gaborit and Ayoub Otmani and Herv\\'e Tal\\'e Kalachi", "title": "Polynomial-Time Key Recovery Attack on the Faure-Loidreau Scheme based\n  on Gabidulin Codes", "comments": "To appear in Designs, Codes and Cryptography Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encryption schemes based on the rank metric lead to small public key sizes of\norder of few thousands bytes which represents a very attractive feature\ncompared to Hamming metric-based encryption schemes where public key sizes are\nof order of hundreds of thousands bytes even with additional structures like\nthe cyclicity. The main tool for building public key encryption schemes in rank\nmetric is the McEliece encryption setting used with the family of Gabidulin\ncodes. Since the original scheme proposed in 1991 by Gabidulin, Paramonov and\nTretjakov, many systems have been proposed based on different masking\ntechniques for Gabidulin codes. Nevertheless, over the years all these systems\nwere attacked essentially by the use of an attack proposed by Overbeck.\n  In 2005 Faure and Loidreau designed a rank-metric encryption scheme which was\nnot in the McEliece setting. The scheme is very efficient, with small public\nkeys of size a few kiloBytes and with security closely related to the\nlinearized polynomial reconstruction problem which corresponds to the decoding\nproblem of Gabidulin codes. The structure of the scheme differs considerably\nfrom the classical McEliece setting and until our work, the scheme had never\nbeen attacked. We show in this article that this scheme like other schemes\nbased on Gabidulin codes, is also vulnerable to a polynomial-time attack that\nrecovers the private key by applying Overbeck's attack on an appropriate public\ncode. As an example we break concrete proposed $80$ bits security parameters in\na few seconds.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 16:45:08 GMT"}, {"version": "v2", "created": "Fri, 14 Apr 2017 08:44:44 GMT"}], "update_date": "2017-04-17", "authors_parsed": [["Gaborit", "Philippe", ""], ["Otmani", "Ayoub", ""], ["Kalachi", "Herv\u00e9 Tal\u00e9", ""]]}, {"id": "1606.08378", "submitter": "Duane Wilson", "authors": "Duane Wilson, Jeff Avery", "title": "Mitigating Data Exfiltration in Storage-as-a-Service Clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing processes and methods for incident handling are geared towards\ninfrastructures and operational models that will be increasingly outdated by\ncloud computing. Research has shown that to adapt incident handling to cloud\ncomputing environments, cloud customers must establish clarity about their\nrequirements on Cloud Service Providers (CSPs) for successful handling of\nincidents and contract CSPs accordingly. Secondly, CSPs must strive to support\nthese requirements and mirror them in their Service Level Agreements. Intrusion\nDetection Systems (IDS) have been used widely to detect malicious behaviors in\nnetwork communication and hosts. Facing new application scenarios in Cloud\nComputing, the IDS approaches yield several problems since the operator of the\nIDS should be the user, not the administrator of the Cloud infrastructure.\nCloud providers need to enable possibilities to deploy and configure IDS for\nthe user - which poses its own challenges. Current research and commercial\nsolutions primarily focus on protecting against Denial of Service attacks and\nattacks against the Cloud's virtual infrastructure. To counter these\nchallenges, we propose a capability that aims to both detect and prevent the\npotential of data exfiltration by using a novel deception-based methodology. We\nalso introduce a method of increasing the data protection level based on\nvarious threat conditions.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2016 17:34:02 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Wilson", "Duane", ""], ["Avery", "Jeff", ""]]}, {"id": "1606.08480", "submitter": "Charith Perera", "authors": "Charith Perera, Chang Liu, Rajiv Ranjan, Lizhe Wang, Albert Y. Zomaya", "title": "Privacy Knowledge Modelling for Internet of Things: A Look Back", "comments": "IEEE Computer Magazine 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) and cloud computing together give us the ability to\nsense, collect, process, and analyse data so we can use them to better\nunderstand behaviours, habits, preferences and life patterns of users and lead\nthem to consume resources more efficiently. In such knowledge discovery\nactivities, privacy becomes a significant challenge due to the extremely\npersonal nature of the knowledge that can be derived from the data and the\npotential risks involved. Therefore, understanding the privacy expectations and\npreferences of stakeholders is an important task in the IoT domain. In this\npaper, we review how privacy knowledge has been modelled and used in the past\nin different domains. Our goal is not only to analyse, compare and consolidate\npast research work but also to appreciate their findings and discuss their\napplicability towards the IoT. Finally, we discuss major research challenges\nand opportunities.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2016 20:34:35 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Perera", "Charith", ""], ["Liu", "Chang", ""], ["Ranjan", "Rajiv", ""], ["Wang", "Lizhe", ""], ["Zomaya", "Albert Y.", ""]]}, {"id": "1606.08536", "submitter": "Nicholas Hopper", "authors": "Max Schuchard and Nicholas Hopper", "title": "E-Embargoes: Discouraging the Deployment of Traffic Manipulating Boxes\n  With Economic Incentives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of systems have been proposed or deployed to the transit\ncore of the Internet with the goal of observing and manipulating traffic in\nflight, systems we term Traffic Manipulating Boxes. Examples of these include:\ndecoy routing systems, surveillance infrastructure like the NSA's alleged\nQUANTUM project, and traffic shaping middleboxes. In this work, we examine a\nnew approach that a routing capable adversary might take to resisting these\nsystems: the use of economic pressure to incentivize ISPs to remove them.\nRather than directly attacking the availability of these systems, our attack\ninflicts economic losses, in the form of reduced transit revenue, on ISPs that\ndeploy them, while at the same time incentivizing ISPs that do not.\n  We alter and expand upon previous routing around decoys attack of Schuchard\net al., by adjusting the priority given to avoiding TMBs. This reduces or\neliminates the key costs faced by routing capable adversary while maintaining\nthe effectiveness of the attack. Additionally, we show that since the flow of\ntraffic on the Internet is directly related to the flow of cash between ISPs, a\nrouting capable adversary is actually a powerful economic adversary. Our\nfindings show that by preferentially using routes which are free of TMBs, some\nrouting capable adversaries can inflict in excess of a billion dollars in\nannual revenue losses.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 02:00:50 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Schuchard", "Max", ""], ["Hopper", "Nicholas", ""]]}, {"id": "1606.08654", "submitter": "Dylan Clarke", "authors": "Dylan Clarke and Tarvi Martens", "title": "E-voting in Estonia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estonia has one of the most established e-voting systems in the world.\nInternet voting - remote e-voting using the voter's own equipment - was piloted\nin 2005 with the first real elections using e-voting being conducted the same\nyear and has been in use ever since. We detail this internet voting system and\ndiscuss how it was developed.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 11:21:20 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Clarke", "Dylan", ""], ["Martens", "Tarvi", ""]]}, {"id": "1606.08828", "submitter": "Hua Sun", "authors": "Hua Sun and Syed A. Jafar", "title": "The Capacity of Symmetric Private Information Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.IR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Private information retrieval (PIR) is the problem of retrieving as\nefficiently as possible, one out of $K$ messages from $N$ non-communicating\nreplicated databases (each holds all $K$ messages) while keeping the identity\nof the desired message index a secret from each individual database. Symmetric\nPIR (SPIR) is a generalization of PIR to include the requirement that beyond\nthe desired message, the user learns nothing about the other $K-1$ messages.\nThe information theoretic capacity of SPIR (equivalently, the reciprocal of\nminimum download cost) is the maximum number of bits of desired information\nthat can be privately retrieved per bit of downloaded information. We show that\nthe capacity of SPIR is $1-1/N$ regardless of the number of messages $K$, if\nthe databases have access to common randomness (not available to the user) that\nis independent of the messages, in the amount that is at least $1/(N-1)$ bits\nper desired message bit, and zero otherwise. Extensions to the capacity region\nof SPIR and the capacity of finite length SPIR are provided.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 19:19:13 GMT"}, {"version": "v2", "created": "Sat, 15 Jul 2017 04:07:25 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Sun", "Hua", ""], ["Jafar", "Syed A.", ""]]}, {"id": "1606.08928", "submitter": "Annamalai Narayanan", "authors": "Annamalai Narayanan, Mahinthan Chandramohan, Lihui Chen, Yang Liu and\n  Santhoshkumar Saminathan", "title": "subgraph2vec: Learning Distributed Representations of Rooted Sub-graphs\n  from Large Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present subgraph2vec, a novel approach for learning latent\nrepresentations of rooted subgraphs from large graphs inspired by recent\nadvancements in Deep Learning and Graph Kernels. These latent representations\nencode semantic substructure dependencies in a continuous vector space, which\nis easily exploited by statistical models for tasks such as graph\nclassification, clustering, link prediction and community detection.\nsubgraph2vec leverages on local information obtained from neighbourhoods of\nnodes to learn their latent representations in an unsupervised fashion. We\ndemonstrate that subgraph vectors learnt by our approach could be used in\nconjunction with classifiers such as CNNs, SVMs and relational data clustering\nalgorithms to achieve significantly superior accuracies. Also, we show that the\nsubgraph vectors could be used for building a deep learning variant of\nWeisfeiler-Lehman graph kernel. Our experiments on several benchmark and\nlarge-scale real-world datasets reveal that subgraph2vec achieves significant\nimprovements in accuracies over existing graph kernels on both supervised and\nunsupervised learning tasks. Specifically, on two realworld program analysis\ntasks, namely, code clone and malware detection, subgraph2vec outperforms\nstate-of-the-art kernels by more than 17% and 4%, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 01:05:36 GMT"}], "update_date": "2016-06-30", "authors_parsed": [["Narayanan", "Annamalai", ""], ["Chandramohan", "Mahinthan", ""], ["Chen", "Lihui", ""], ["Liu", "Yang", ""], ["Saminathan", "Santhoshkumar", ""]]}, {"id": "1606.09042", "submitter": "Francois-Xavier Aguessy", "authors": "Aguessy Fran\\c{c}ois-Xavier, Bettan Olivier, Blanc Gr\\'egory, Conan\n  Vania, Debar Herv\\'e", "title": "Bayesian Attack Model for Dynamic Risk Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because of the threat of advanced multi-step attacks, it is often difficult\nfor security operators to completely cover all vulnerabilities when deploying\nremediations. Deploying sensors to monitor attacks exploiting residual\nvulnerabilities is not sufficient and new tools are needed to assess the risk\nassociated to the security events produced by these sensors. Although attack\ngraphs were proposed to represent known multi-step attacks occurring in an\ninformation system, they are not directly suited for dynamic risk assessment.\nIn this paper, we present the Bayesian Attack Model (BAM), a Bayesian\nnetwork-based extension to topological attack graphs, capable of handling\ntopological cycles, making it fit for any information system. Evaluation is\nperformed on realistic topologies to study the sensitivity of its probabilistic\nparameters.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 11:01:21 GMT"}], "update_date": "2016-06-30", "authors_parsed": [["Fran\u00e7ois-Xavier", "Aguessy", ""], ["Olivier", "Bettan", ""], ["Gr\u00e9gory", "Blanc", ""], ["Vania", "Conan", ""], ["Herv\u00e9", "Debar", ""]]}, {"id": "1606.09075", "submitter": "John V Monaco", "authors": "John V. Monaco", "title": "Robust Keystroke Biometric Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Keystroke Biometrics Ongoing Competition (KBOC) presented an anomaly\ndetection challenge with a public keystroke dataset containing a large number\nof subjects and real-world aspects. Over 300 subjects typed case-insensitive\nrepetitions of their first and last name, and as a result, keystroke sequences\ncould vary in length and order depending on the usage of modifier keys. To deal\nwith this, a keystroke alignment preprocessing algorithm was developed to\nestablish a semantic correspondence between keystrokes in mismatched sequences.\nThe method is robust in the sense that query keystroke sequences need only\napproximately match a target sequence, and alignment is agnostic to the\nparticular anomaly detector used. This paper describes the fifteen\nbest-performing anomaly detection systems submitted to the KBOC, which ranged\nfrom auto-encoding neural networks to ensemble methods. Manhattan distance\nachieved the lowest equal error rate of 5.32%, while all fifteen systems\nperformed better than any other submission. Performance gains are shown to be\ndue in large part not to the particular anomaly detector, but to preprocessing\nand score normalization techniques.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 13:09:29 GMT"}, {"version": "v2", "created": "Wed, 18 Jan 2017 19:19:00 GMT"}], "update_date": "2017-01-20", "authors_parsed": [["Monaco", "John V.", ""]]}, {"id": "1606.09344", "submitter": "Jun Zhang", "authors": "Xiao-Guang Zhang, You-Qi Nie, Hongyi Zhou, Hao Liang, Xiongfeng Ma,\n  Jun Zhang, and Jian-Wei Pan", "title": "Fully integrated 3.2 Gbps quantum random number generator with real-time\n  extraction", "comments": "3 pages, 3 figures. Accepted for publication in Review of Scientific\n  Instrument", "journal-ref": "Rev. Sci. Instrum. 87, 076102 (2016)", "doi": "10.1063/1.4958663", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a real-time and fully integrated quantum random number generator\n(QRNG) by measuring laser phase fluctuations. The QRNG scheme based on laser\nphase fluctuations is featured for its capability of generating ultra\nhigh-speed random numbers. However, the speed bottleneck of a practical QRNG\nlies on the limited speed of randomness extraction. To close the gap between\nthe fast randomness generation and the slow post-processing, we propose a\npipeline extraction algorithm based on Toeplitz matrix hashing and implement it\nin a high-speed field-programmable gate array. Further, all the QRNG components\nare integrated into a module, including a compact and actively stabilized\ninterferometer, high-speed data acquisition, and real-time data post-processing\nand transmission. The final generation rate of the QRNG module with real-time\nextraction can reach 3.2 Gbps.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2016 04:50:15 GMT"}], "update_date": "2016-07-13", "authors_parsed": [["Zhang", "Xiao-Guang", ""], ["Nie", "You-Qi", ""], ["Zhou", "Hongyi", ""], ["Liang", "Hao", ""], ["Ma", "Xiongfeng", ""], ["Zhang", "Jun", ""], ["Pan", "Jian-Wei", ""]]}, {"id": "1606.09605", "submitter": "Joshua Joy", "authors": "Joshua Joy, Minh Le, Mario Gerla", "title": "LocationSafe: Granular Location Privacy for IoT Devices", "comments": "arXiv admin note: text overlap with arXiv:1604.04892", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, mobile data owners lack consent and control over the release and\nutilization of their location data. Third party applications continuously\nprocess and access location data without data owners granular control and\nwithout knowledge of how location data is being used. The proliferation of IoT\ndevices will lead to larger scale abuses of trust.\n  In this paper we present the first design and implementation of a privacy\nmodule built into the GPSD daemon. The GPSD daemon is a low-level GPS interface\nthat runs on GPS enabled devices. The integration of the privacy module ensures\nthat data owners have granular control over the release of their GPS location.\nWe describe the design of our privacy module and then evaluate the performance\nof private GPS release and demonstrate that strong privacy guarantees can be\nbuilt into the GPSD daemon itself with minimal to no overhead.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2016 18:28:43 GMT"}], "update_date": "2016-07-01", "authors_parsed": [["Joy", "Joshua", ""], ["Le", "Minh", ""], ["Gerla", "Mario", ""]]}]