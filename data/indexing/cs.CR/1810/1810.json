[{"id": "1810.00022", "submitter": "Salim Ali Altug", "authors": "Salim Ali Altug and Yilei Chen", "title": "Hard isogeny problems over RSA moduli and groups with infeasible\n  inversion", "comments": "Significant revision of the article previously titled \"A Candidate\n  Group with Infeasible Inversion\" (arXiv:1810.00022v1). Cleared up the\n  constructions by giving toy examples, added \"The Parallelogram Attack\" (Sec\n  5.3.2). 54 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CR math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of computational problems on elliptic curve isogeny\ngraphs defined over RSA moduli. We conjecture that several variants of the\nneighbor-search problem over these graphs are hard, and provide a comprehensive\nlist of cryptanalytic attempts on these problems. Moreover, based on the\nhardness of these problems, we provide a construction of groups with infeasible\ninversion, where the underlying groups are the ideal class groups of imaginary\nquadratic orders.\n  Recall that in a group with infeasible inversion, computing the inverse of a\ngroup element is required to be hard, while performing the group operation is\neasy. Motivated by the potential cryptographic application of building a\ndirected transitive signature scheme, the search for a group with infeasible\ninversion was initiated in the theses of Hohenberger and Molnar (2003). Later\nit was also shown to provide a broadcast encryption scheme by Irrer et al.\n(2004). However, to date the only case of a group with infeasible inversion is\nimplied by the much stronger primitive of self-bilinear map constructed by\nYamakawa et al. (2014) based on the hardness of factoring and\nindistinguishability obfuscation (iO). Our construction gives a candidate\nwithout using iO.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 18:09:21 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 16:44:39 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Altug", "Salim Ali", ""], ["Chen", "Yilei", ""]]}, {"id": "1810.00024", "submitter": "Washington Garcia", "authors": "Washington Garcia, Joseph I. Choi, Suman K. Adari, Somesh Jha, Kevin\n  R. B. Butler", "title": "Explainable Black-Box Attacks Against Model-based Authentication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Establishing unique identities for both humans and end systems has been an\nactive research problem in the security community, giving rise to innovative\nmachine learning-based authentication techniques. Although such techniques\noffer an automated method to establish identity, they have not been vetted\nagainst sophisticated attacks that target their core machine learning\ntechnique. This paper demonstrates that mimicking the unique signatures\ngenerated by host fingerprinting and biometric authentication systems is\npossible. We expose the ineffectiveness of underlying machine learning\nclassification models by constructing a blind attack based around the query\nsynthesis framework and utilizing Explainable-AI (XAI) techniques. We launch an\nattack in under 130 queries on a state-of-the-art face authentication system,\nand under 100 queries on a host authentication system. We examine how these\nattacks can be defended against and explore their limitations. XAI provides an\neffective means for adversaries to infer decision boundaries and provides a new\nway forward in constructing attacks against systems using machine learning\nmodels for authentication.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 18:13:26 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Garcia", "Washington", ""], ["Choi", "Joseph I.", ""], ["Adari", "Suman K.", ""], ["Jha", "Somesh", ""], ["Butler", "Kevin R. B.", ""]]}, {"id": "1810.00069", "submitter": "Manaar Alam", "authors": "Anirban Chakraborty and Manaar Alam and Vishal Dey and Anupam\n  Chattopadhyay and Debdeep Mukhopadhyay", "title": "Adversarial Attacks and Defences: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has emerged as a strong and efficient framework that can be\napplied to a broad spectrum of complex learning problems which were difficult\nto solve using the traditional machine learning techniques in the past. In the\nlast few years, deep learning has advanced radically in such a way that it can\nsurpass human-level performance on a number of tasks. As a consequence, deep\nlearning is being extensively used in most of the recent day-to-day\napplications. However, security of deep learning systems are vulnerable to\ncrafted adversarial examples, which may be imperceptible to the human eye, but\ncan lead the model to misclassify the output. In recent times, different types\nof adversaries based on their threat model leverage these vulnerabilities to\ncompromise a deep learning system where adversaries have high incentives.\nHence, it is extremely important to provide robustness to deep learning\nalgorithms against these adversaries. However, there are only a few strong\ncountermeasures which can be used in all types of attack scenarios to design a\nrobust deep learning system. In this paper, we attempt to provide a detailed\ndiscussion on different types of adversarial attacks with various threat models\nand also elaborate the efficiency and challenges of recent countermeasures\nagainst them.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 20:09:04 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Chakraborty", "Anirban", ""], ["Alam", "Manaar", ""], ["Dey", "Vishal", ""], ["Chattopadhyay", "Anupam", ""], ["Mukhopadhyay", "Debdeep", ""]]}, {"id": "1810.00106", "submitter": "Peter Michael Reichstein Rasmussen Mr", "authors": "Peter M. R. Rasmussen and Amit Sahai", "title": "Expander Graphs are Non-Malleable Codes", "comments": "10 pages Resubmitted with revised introduction and acknowledgement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Any $d$-regular graph on $n$ vertices with spectral expansion $\\lambda$\nsatisfying $n = \\Omega(d^3\\log(d)/\\lambda)$ yields a\n$O\\left(\\frac{\\lambda^{3/2}}{d}\\right)$-non-malleable code for single-bit\nmessages in the split-state model.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 22:19:23 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 10:09:29 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Rasmussen", "Peter M. R.", ""], ["Sahai", "Amit", ""]]}, {"id": "1810.00181", "submitter": "Vinod Pankajakshan Prof.", "authors": "Ravi Tej Akella, Raviteja Rekula, Vinod Pankajakshan", "title": "A Randomized Kernel-Based Secret Image Sharing Scheme", "comments": "Accepted in IEEE International Workshop on Information Forensics and\n  Security (WIFS) 2018", "journal-ref": null, "doi": "10.1109/WIFS.2018.8630770", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a ($k,n$)-threshold secret image sharing scheme that\noffers flexibility in terms of meeting contrasting demands such as information\nsecurity and storage efficiency with the help of a randomized kernel (binary\nmatrix) operation. A secret image is split into $n$ shares such that any $k$ or\nmore shares ($k\\leq n$) can be used to reconstruct the image. Each share has a\nsize less than or at most equal to the size of the secret image. Security and\nshare sizes are solely determined by the kernel of the scheme. The kernel\noperation is optimized in terms of the security and computational requirements.\nThe storage overhead of the kernel can further be made independent of its size\nby efficiently storing it as a sparse matrix. Moreover, the scheme is free from\nany kind of single point of failure (SPOF).\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 09:54:03 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Akella", "Ravi Tej", ""], ["Rekula", "Raviteja", ""], ["Pankajakshan", "Vinod", ""]]}, {"id": "1810.00200", "submitter": "Rui Zhu", "authors": "Rui Zhu, Tao Shu, and Huirong Fu", "title": "Statistical Inference Attack Against PHY-layer Key Extraction and\n  Countermeasures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The formal theoretical analysis on channel correlations in both real indoor\nand outdoor environments are provided in this paper. Moreover, this paper\nstudies empirical statistical inference attacks (SIA) against LSB key\nextraction, whereby an adversary infers the signature of a target link.\nConsequently, the secret key extracted from that signature has been recovered\nby observing the surrounding links. Prior work assumes theoretical\nlink-correlation models for the inference, in contrast, our study does not make\nany assumption on link correlation. Instead, we take machine learning (ML)\nmethods for link inference based on empirically measured link signatures. ML\nalgorithms have been developed to launch SIAs under various realistic\nscenarios. Our experimental results have shown that the proposed inference\nalgorithms are still quite effective even without making assumptions on link\ncorrelation. In addition, our inference algorithms can reduce the key search\nspace by many orders of magnitudes compared to brute force search. We further\npropose a countermeasure against the statistical inference attacks, FBCH\n(forward-backward cooperative key extraction protocol with helpers). In the\nFBCH, helpers (other trusted wireless nodes) are introduced to provide more\nrandomness in the key extraction. Our experiment results verify the\neffectiveness of the proposed protocol.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 12:20:18 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Zhu", "Rui", ""], ["Shu", "Tao", ""], ["Fu", "Huirong", ""]]}, {"id": "1810.00208", "submitter": "Ilia Shumailov", "authors": "Yiren Zhao, Ilia Shumailov, Robert Mullins, Ross Anderson", "title": "To compress or not to compress: Understanding the Interactions between\n  Adversarial Attacks and Neural Network Compression", "comments": "Presented at SysML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As deep neural networks (DNNs) become widely used, pruned and quantised\nmodels are becoming ubiquitous on edge devices; such compressed DNNs are\npopular for lowering computational requirements. Meanwhile, recent studies show\nthat adversarial samples can be effective at making DNNs misclassify. We,\ntherefore, investigate the extent to which adversarial samples are transferable\nbetween uncompressed and compressed DNNs. We find that adversarial samples\nremain transferable for both pruned and quantised models. For pruning, the\nadversarial samples generated from heavily pruned models remain effective on\nuncompressed models. For quantisation, we find the transferability of\nadversarial samples is highly sensitive to integer precision.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 13:08:34 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 17:27:31 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Zhao", "Yiren", ""], ["Shumailov", "Ilia", ""], ["Mullins", "Robert", ""], ["Anderson", "Ross", ""]]}, {"id": "1810.00279", "submitter": "Ruben Recabarren", "authors": "Ruben Recabarren and Bogdan Carbunar", "title": "Tithonus: A Bitcoin Based Censorship Resilient System", "comments": "19 pages, 10 figures, to appear in PETS 2019, issue 1, volume 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing reliable and surreptitious communications is difficult in the\npresence of adaptive and resourceful state level censors. In this paper we\nintroduce Tithonus, a framework that builds on the Bitcoin blockchain and\nnetwork to provide censorship-resistant communication mechanisms. In contrast\nto previous approaches, we do not rely solely on the slow and expensive\nblockchain consensus mechanism but instead fully exploit Bitcoin's peer-to-peer\ngossip protocol. We develop adaptive, fast and cost effective data\ncommunication solutions that camouflage client requests into inconspicuous\nBitcoin transactions. We propose solutions to securely request and transfer\ncontent, with unobservability and censorship resistance, and free,\npay-per-access and subscription based payment options. When compared to\nstate-of-the-art Bitcoin writing solutions, Tithonus reduces the cost of\ntransferring data to censored clients by 2 orders of magnitude and increases\nthe goodput by 3 to 5 orders of magnitude. We show that Tithonus client\ninitiated transactions are hard to detect, while server initiated transactions\ncannot be censored without creating split world problems to the Bitcoin\nblockchain.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 23:58:37 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Recabarren", "Ruben", ""], ["Carbunar", "Bogdan", ""]]}, {"id": "1810.00281", "submitter": "Quanyan Zhu", "authors": "Quanyan Zhu, Stefan Rass, Peter Schartner", "title": "Community-Based Security for the Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With more and more devices becoming connectable to the internet, the number\nof services but also a lot of threats increases dramatically. Security is often\na secondary matter behind functionality and comfort, but the problem has\nalready been recognized. Still, with many IoT devices being deployed already,\nsecurity will come step-by-step and through updates, patches and new versions\nof apps and IoT software. While these updates can be safely retrieved from app\nstores, the problems kick in via jailbroken devices and with the variety of\nuntrusted sources arising on the internet. Since hacking is typically a\ncommunity effort? these days, security could be a community goal too. The\nchallenges are manifold, and one reason for weak or absent security on IoT\ndevices is their weak computational power. In this chapter, we discuss a\ncommunity based security mechanism in which devices mutually aid each other in\nsecure software management. We discuss game-theoretic methods of community\nformation and light-weight cryptographic means to accomplish authentic software\ndeployment inside the IoT device community.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 00:24:22 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Zhu", "Quanyan", ""], ["Rass", "Stefan", ""], ["Schartner", "Peter", ""]]}, {"id": "1810.00282", "submitter": "Quanyan Zhu", "authors": "Quanyan Zhu", "title": "Multi-Layer Cyber-Physical Security and Resilience for Smart Grid", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The smart grid is a large-scale complex system that integrates communication\ntechnologies with the physical layer operation of the energy systems. Security\nand resilience mechanisms by design are important to provide guarantee\noperations for the system. This chapter provides a layered perspective of the\nsmart grid security and discusses game and decision theory as a tool to model\nthe interactions among system components and the interaction between attackers\nand the system. We discuss game-theoretic applications and challenges in the\ndesign of cross-layer robust and resilient controller, secure network routing\nprotocol at the data communication and networking layers, and the challenges of\nthe information security at the management layer of the grid. The chapter will\ndiscuss the future directions of using game-theoretic tools in addressing\nmulti-layer security issues in the smart grid.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 00:29:00 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Zhu", "Quanyan", ""]]}, {"id": "1810.00290", "submitter": "Quanyan Zhu", "authors": "Quanyan Zhu", "title": "Cyber Insurance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This chapter will first present a principal-agent game-theoretic model to\ncapture the interactions between one insurer and one user. The insurer is\ndeemed as the principal who does not have incomplete information about user's\nsecurity policies. The user, which refers to the infrastructure operator or the\ncustomer, implements his local protection and pays a premium to the insurer.\nThe insurer designs an incentive compatible insurance mechanism that includes\nthe premium and the coverage policy, while the user determines whether to\nparticipate in the insurance and his effort to defend against attacks. The\nchapter will also focus on an attack-aware cyber insurance model by introducing\nthe adversarial behaviors into the framework. The behavior of an attacker\ndetermines the type of cyber threats, e.g. denial of service (DoS) attacks,\ndata breaches, phishing and spoofing. The distinction of threat types plays a\nrole in determining the type of losses and the coverage policies. The data\nbreaches can lead to not only financial losses but also damage of the\nreputations. The coverage may only cover certain agreed percentage of the\nfinancial losses.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 01:31:33 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 20:29:25 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Zhu", "Quanyan", ""]]}, {"id": "1810.00329", "submitter": "Lu\\'is Alexandre", "authors": "Vasco Lopes and Lu\\'is A. Alexandre", "title": "An Overview of Blockchain Integration with Robotics and Artificial\n  Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain technology is growing everyday at a fast-passed rhythm and it's\npossible to integrate it with many systems, namely Robotics with AI services.\nHowever, this is still a recent field and there isn't yet a clear understanding\nof what it could potentially become. In this paper, we conduct an overview of\nmany different methods and platforms that try to leverage the power of\nblockchain into robotic systems, to improve AI services or to solve problems\nthat are present in the major blockchains, which can lead to the ability of\ncreating robotic systems with increased capabilities and security. We present\nan overview, discuss the methods and conclude the paper with our view on the\nfuture of the integration of these technologies.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 07:34:20 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Lopes", "Vasco", ""], ["Alexandre", "Lu\u00eds A.", ""]]}, {"id": "1810.00349", "submitter": "Kaz{\\i}m R{\\i}fat \\\"Ozy{\\i}lmaz", "authors": "Kaz{\\i}m R{\\i}fat \\\"Ozy{\\i}lmaz, Mehmet Do\\u{g}an, Arda Yurdakul", "title": "IDMoB: IoT Data Marketplace on Blockchain", "comments": "Presented at Crypto Valley Conference on Blockchain Technology (CVCBT\n  2018), 20-22 June 2018 - published version may differ", "journal-ref": null, "doi": "10.1109/CVCBT.2018.00007", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, Internet of Things (IoT) devices are the powerhouse of data generation\nwith their ever-increasing numbers and widespread penetration. Similarly,\nartificial intelligence (AI) and machine learning (ML) solutions are getting\nintegrated to all kinds of services, making products significantly more\n\"smarter\". The centerpiece of these technologies is \"data\". IoT device vendors\nshould be able keep up with the increased throughput and come up with new\nbusiness models. On the other hand, AI/ML solutions will produce better results\nif training data is diverse and plentiful.\n  In this paper, we propose a blockchain-based, decentralized and trustless\ndata marketplace where IoT device vendors and AI/ML solution providers may\ninteract and collaborate. By facilitating a transparent data exchange platform,\naccess to consented data will be democratized and the variety of services\ntargeting end-users will increase. Proposed data marketplace is implemented as\na smart contract on Ethereum blockchain and Swarm is used as the distributed\nstorage platform.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 09:42:11 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["\u00d6zy\u0131lmaz", "Kaz\u0131m R\u0131fat", ""], ["Do\u011fan", "Mehmet", ""], ["Yurdakul", "Arda", ""]]}, {"id": "1810.00383", "submitter": "Bo Han", "authors": "Bo Han, Ivor W. Tsang, Xiaokui Xiao, Ling Chen, Sai-fu Fung, Celina P.\n  Yu", "title": "Privacy-preserving Stochastic Gradual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is challenging for stochastic optimizations to handle large-scale\nsensitive data safely. Recently, Duchi et al. proposed private sampling\nstrategy to solve privacy leakage in stochastic optimizations. However, this\nstrategy leads to robustness degeneration, since this strategy is equal to the\nnoise injection on each gradient, which adversely affects updates of the primal\nvariable. To address this challenge, we introduce a robust stochastic\noptimization under the framework of local privacy, which is called\nPrivacy-pREserving StochasTIc Gradual lEarning (PRESTIGE). PRESTIGE bridges\nprivate updates of the primal variable (by private sampling) with the gradual\ncurriculum learning (CL). Specifically, the noise injection leads to the issue\nof label noise, but the robust learning process of CL can combat with label\nnoise. Thus, PRESTIGE yields \"private but robust\" updates of the primal\nvariable on the private curriculum, namely an reordered label sequence provided\nby CL. In theory, we reveal the convergence rate and maximum complexity of\nPRESTIGE. Empirical results on six datasets show that, PRESTIGE achieves a good\ntradeoff between privacy preservation and robustness over baselines.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 14:10:11 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Han", "Bo", ""], ["Tsang", "Ivor W.", ""], ["Xiao", "Xiaokui", ""], ["Chen", "Ling", ""], ["Fung", "Sai-fu", ""], ["Yu", "Celina P.", ""]]}, {"id": "1810.00464", "submitter": "Panagiotis Papadopoulos", "authors": "Panagiotis Papadopoulos, Panagiotis Ilia, Michalis Polychronakis,\n  Evangelos P. Markatos, Sotiris Ioannidis, Giorgos Vasiliadis", "title": "Master of Web Puppets: Abusing Web Browsers for Persistent and Stealthy\n  Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of web applications has essentially transformed modern\nbrowsers into small but powerful operating systems. Upon visiting a website,\nuser devices run implicitly trusted script code, the execution of which is\nconfined within the browser to prevent any interference with the user's system.\nRecent JavaScript APIs, however, provide advanced capabilities that not only\nenable feature-rich web applications, but also allow attackers to perform\nmalicious operations despite the confined nature of JavaScript code execution.\nIn this paper, we demonstrate the powerful capabilities that modern browser\nAPIs provide to attackers by presenting MarioNet: a framework that allows a\nremote malicious entity to control a visitor's browser and abuse its resources\nfor unwanted computation or harmful operations, such as cryptocurrency mining,\npassword-cracking, and DDoS. MarioNet relies solely on already available HTML5\nAPIs, without requiring the installation of any additional software. In\ncontrast to previous browser-based botnets, the persistence and stealthiness\ncharacteristics of MarioNet allow the malicious computations to continue in the\nbackground of the browser even after the user closes the window or tab of the\ninitial malicious website. We present the design, implementation, and\nevaluation of a prototype system, MarioNet, that is compatible with all major\nbrowsers, and discuss potential defense strategies to counter the threat of\nsuch persistent in-browser attacks. Our main goal is to raise awareness\nregarding this new class of attacks, and inform the design of future browser\nAPIs so that they provide a more secure client-side environment for web\napplications.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 20:47:22 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Papadopoulos", "Panagiotis", ""], ["Ilia", "Panagiotis", ""], ["Polychronakis", "Michalis", ""], ["Markatos", "Evangelos P.", ""], ["Ioannidis", "Sotiris", ""], ["Vasiliadis", "Giorgos", ""]]}, {"id": "1810.00470", "submitter": "Kenneth Co", "authors": "Kenneth T. Co, Luis Mu\\~noz-Gonz\\'alez, Sixte de Maupeou, Emil C. Lupu", "title": "Procedural Noise Adversarial Examples for Black-Box Attacks on Deep\n  Convolutional Networks", "comments": "16 pages, 10 figures. In Proceedings of the 2019 ACM SIGSAC\n  Conference on Computer and Communications Security (CCS '19)", "journal-ref": null, "doi": "10.1145/3319535.3345660", "report-no": null, "categories": "cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Convolutional Networks (DCNs) have been shown to be vulnerable to\nadversarial examples---perturbed inputs specifically designed to produce\nintentional errors in the learning algorithms at test time. Existing\ninput-agnostic adversarial perturbations exhibit interesting visual patterns\nthat are currently unexplained. In this paper, we introduce a structured\napproach for generating Universal Adversarial Perturbations (UAPs) with\nprocedural noise functions. Our approach unveils the systemic vulnerability of\npopular DCN models like Inception v3 and YOLO v3, with single noise patterns\nable to fool a model on up to 90% of the dataset. Procedural noise allows us to\ngenerate a distribution of UAPs with high universal evasion rates using only a\nfew parameters. Additionally, we propose Bayesian optimization to efficiently\nlearn procedural noise parameters to construct inexpensive untargeted black-box\nattacks. We demonstrate that it can achieve an average of less than 10 queries\nper successful attack, a 100-fold improvement on existing methods. We further\nmotivate the use of input-agnostic defences to increase the stability of models\nto adversarial perturbations. The universality of our attacks suggests that DCN\nmodels may be sensitive to aggregations of low-level class-agnostic features.\nThese findings give insight on the nature of some universal adversarial\nperturbations and how they could be generated in other applications.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 21:45:39 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 17:01:58 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 12:09:48 GMT"}, {"version": "v4", "created": "Sat, 23 Nov 2019 13:02:08 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Co", "Kenneth T.", ""], ["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["de Maupeou", "Sixte", ""], ["Lupu", "Emil C.", ""]]}, {"id": "1810.00545", "submitter": "Anupam Chattopadhyay", "authors": "Anupam Chattopadhyay and Kwok-Yan Lam", "title": "Autonomous Vehicle: Security by Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security of (semi)-autonomous vehicles is a growing concern, first, due to\nthe increased exposure of the functionality to the potential attackers; second,\ndue to the reliance of car functionalities on diverse (semi)-autonomous\nsystems; third, due to the interaction of a single vehicle with myriads of\nother smart systems in an urban traffic infrastructure. Beyond these technical\nissues, we argue that the security-by-design principle for smart and complex\nautonomous systems, such as an Autonomous Vehicle (AV) is poorly understood and\nrarely practiced. Unlike traditional IT systems, where the risk mitigation\ntechniques and adversarial models are well studied and developed with security\ndesign principles such as security perimeter and defence-in-depth, the lack of\nsuch a framework for connected autonomous systems is plaguing the design and\nimplementation of a secure AV. We attempt to identify the core issues of\nsecuring an AV. This is done methodically by developing a security-by-design\nframework for AV from the first principle. Subsequently, the technical\nchallenges for AV security are identified.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 06:29:16 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Chattopadhyay", "Anupam", ""], ["Lam", "Kwok-Yan", ""]]}, {"id": "1810.00567", "submitter": "Jesus Vicente Roig", "authors": "JV Roig", "title": "Stronger Cryptography For Every Device, Everywhere", "comments": "Presented and won the Best Conference Paper Award at the National\n  University of Singapore (ICIRSTM2018, Sep 29-30, 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating secure random numbers is a central problem in cryptography that\nneeds a reliable source of enough computing entropy. Without enough entropy\navailable - meaning no good source of secure random numbers - a device is\nsusceptible to cryptographic protocol failures such as weak, factorable, or\npredictable keys, which lead to various security and privacy vulnerabilities.\nIn this paper, the author presents a significant improvement: a reliable way\nfor any CPU-powered device - from the small, simple CPUs in embedded devices,\nto larger, more complex CPUs in modern servers - to collect virtually unlimited\nentropy through side channel measurements of trivial CPU operations, making the\ngeneration of secure random numbers an easy, safe, and reliable operation.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 08:00:22 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Roig", "JV", ""]]}, {"id": "1810.00602", "submitter": "Shruti Tople", "authors": "Karan Grover, Shruti Tople, Shweta Shinde, Ranjita Bhagwan and\n  Ramachandran Ramjee", "title": "Privado: Practical and Secure DNN Inference with Enclaves", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud providers are extending support for trusted hardware primitives such as\nIntel SGX. Simultaneously, the field of deep learning is seeing enormous\ninnovation as well as an increase in adoption. In this paper, we ask a timely\nquestion: \"Can third-party cloud services use Intel SGX enclaves to provide\npractical, yet secure DNN Inference-as-a-service?\" We first demonstrate that\nDNN models executing inside enclaves are vulnerable to access pattern based\nattacks. We show that by simply observing access patterns, an attacker can\nclassify encrypted inputs with 97% and 71% attack accuracy for MNIST and\nCIFAR10 datasets on models trained to achieve 99% and 79% original accuracy\nrespectively. This motivates the need for PRIVADO, a system we have designed\nfor secure, easy-to-use, and performance efficient inference-as-a-service.\nPRIVADO is input-oblivious: it transforms any deep learning framework that is\nwritten in C/C++ to be free of input-dependent access patterns thus eliminating\nthe leakage. PRIVADO is fully-automated and has a low TCB: with zero developer\neffort, given an ONNX description of a model, it generates compact and\nenclave-compatible code which can be deployed on an SGX cloud platform. PRIVADO\nincurs low performance overhead: we use PRIVADO with Torch framework and show\nits overhead to be 17.18% on average on 11 different contemporary neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 10:13:42 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 15:03:14 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Grover", "Karan", ""], ["Tople", "Shruti", ""], ["Shinde", "Shweta", ""], ["Bhagwan", "Ranjita", ""], ["Ramjee", "Ramachandran", ""]]}, {"id": "1810.00752", "submitter": "Tao Zhang", "authors": "Tao Zhang and Quanyan zhu", "title": "A Game-Theoretic Foundation of Deception: Knowledge Acquisition and\n  Fundamental Limits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deception is a technique to mislead human or computer systems by manipulating\nbeliefs and information. Successful deception is characterized by the\ninformation-asymmetric, dynamic, and strategic behaviors of the deceiver and\nthe deceivee. This paper proposes a game-theoretic framework of a deception\ngame to model the strategic behaviors of the deceiver and deceivee and\nconstruct strategies for both attacks and defenses over a continuous\none-dimensional information space. We use the signaling game model to capture\nthe information-asymmetric, dynamic, and strategic behaviors of deceptions by\nmodeling the deceiver as a privately-informed player called sender and the\ndeceivee as an uninformed player called receiver. We characterize perfect\nBayesian Nash equilibrium (PBNE) solution of the game and study the\ndeceivability. We highlight the condition of deceivee's knowledge enhancement\nthrough evidences to maintain the equilibrium and analyze the impacts of direct\ndeception costs and players' conflict of interest on the deceivability.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 15:12:13 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Zhang", "Tao", ""], ["zhu", "Quanyan", ""]]}, {"id": "1810.00769", "submitter": "Suthee Ruangwises", "authors": "Suthee Ruangwises, Toshiya Itoh", "title": "AND Protocols Using Only Uniform Shuffles", "comments": "This paper has appeared at CSR 2019", "journal-ref": null, "doi": "10.1007/978-3-030-19955-5_30", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure multi-party computation using a deck of playing cards has been a\nsubject of research since the \"five-card trick\" introduced by den Boer in 1989.\nOne of the main problems in card-based cryptography is to design\ncommitted-format protocols to compute a Boolean AND operation subject to\ndifferent runtime and shuffle restrictions by using as few cards as possible.\nIn this paper, we introduce two AND protocols that use only uniform shuffles.\nThe first one requires four cards and is a restart-free Las Vegas protocol with\nfinite expected runtime. The second one requires five cards and always\nterminates in finite time.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 15:46:43 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 09:29:19 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Ruangwises", "Suthee", ""], ["Itoh", "Toshiya", ""]]}, {"id": "1810.00845", "submitter": "Olli Saarikivi", "authors": "Roshan Dathathri, Olli Saarikivi, Hao Chen, Kim Laine, Kristin Lauter,\n  Saeed Maleki, Madanlal Musuvathi, Todd Mytkowicz", "title": "CHET: Compiler and Runtime for Homomorphic Evaluation of Tensor Programs", "comments": "Submitted to ASPLOS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully Homomorphic Encryption (FHE) refers to a set of encryption schemes that\nallow computations to be applied directly on encrypted data without requiring a\nsecret key. This enables novel application scenarios where a client can safely\noffload storage and computation to a third-party cloud provider without having\nto trust the software and the hardware vendors with the decryption keys. Recent\nadvances in both FHE schemes and implementations have moved such applications\nfrom theoretical possibilities into the realm of practicalities.\n  This paper proposes a compact and well-reasoned interface called the\nHomomorphic Instruction Set Architecture (HISA) for developing FHE\napplications. Just as the hardware ISA interface enabled hardware advances to\nproceed independent of software advances in the compiler and language runtimes,\nHISA decouples compiler optimizations and runtimes for supporting FHE\napplications from advancements in the underlying FHE schemes.\n  This paper demonstrates the capabilities of HISA by building an end-to-end\nsoftware stack for evaluating neural network models on encrypted data. Our\nstack includes an end-to-end compiler, runtime, and a set of optimizations. Our\napproach shows generated code, on a set of popular neural network\narchitectures, is faster than hand-optimized implementations.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 17:38:53 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Dathathri", "Roshan", ""], ["Saarikivi", "Olli", ""], ["Chen", "Hao", ""], ["Laine", "Kim", ""], ["Lauter", "Kristin", ""], ["Maleki", "Saeed", ""], ["Musuvathi", "Madanlal", ""], ["Mytkowicz", "Todd", ""]]}, {"id": "1810.00877", "submitter": "Quan Geng", "authors": "Quan Geng, Wei Ding, Ruiqi Guo, and Sanjiv Kumar", "title": "Privacy and Utility Tradeoff in Approximate Differential Privacy", "comments": "15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize the minimum noise amplitude and power for noise-adding\nmechanisms in $(\\epsilon, \\delta)$-differential privacy for single real-valued\nquery function. We derive new lower bounds using the duality of linear\nprogramming, and new upper bounds by proposing a new class of\n$(\\epsilon,\\delta)$-differentially private mechanisms, the \\emph{truncated\nLaplacian} mechanisms. We show that the multiplicative gap of the lower bounds\nand upper bounds goes to zero in various high privacy regimes, proving the\ntightness of the lower and upper bounds and thus establishing the optimality of\nthe truncated Laplacian mechanism. In particular, our results close the\nprevious constant multiplicative gap in the discrete setting. Numeric\nexperiments show the improvement of the truncated Laplacian mechanism over the\noptimal Gaussian mechanism in all privacy regimes.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 17:54:17 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 16:41:34 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Geng", "Quan", ""], ["Ding", "Wei", ""], ["Guo", "Ruiqi", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "1810.00953", "submitter": "Adam Oberman", "authors": "Chris Finlay, Adam Oberman, Bilal Abbasi", "title": "Improved robustness to adversarial examples using Lipschitz\n  regularization of the loss", "comments": "Merged with arXiv:1808.09540", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We augment adversarial training (AT) with worst case adversarial training\n(WCAT) which improves adversarial robustness by 11% over the current\nstate-of-the-art result in the $\\ell_2$ norm on CIFAR-10. We obtain verifiable\naverage case and worst case robustness guarantees, based on the expected and\nmaximum values of the norm of the gradient of the loss. We interpret\nadversarial training as Total Variation Regularization, which is a fundamental\ntool in mathematical image processing, and WCAT as Lipschitz regularization.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 20:02:00 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 16:08:46 GMT"}, {"version": "v3", "created": "Mon, 7 Jan 2019 16:01:04 GMT"}, {"version": "v4", "created": "Fri, 13 Sep 2019 14:56:57 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Finlay", "Chris", ""], ["Oberman", "Adam", ""], ["Abbasi", "Bilal", ""]]}, {"id": "1810.00957", "submitter": "Marcin Niemiec", "authors": "Marcin Niemiec", "title": "Error correction in quantum cryptography based on artificial neural\n  networks", "comments": null, "journal-ref": "Quantum Inf Process (2019) 18: 174", "doi": "10.1007/s11128-019-2296-4", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intensive work on quantum computing has increased interest in quantum\ncryptography in recent years. Although this technique is characterized by a\nvery high level of security, there are still challenges that limit the\nwidespread use of quantum key distribution. One of the most important problem\nremains secure and effective mechanisms for the key distillation process. This\narticle presents a new idea for a key reconciliation method in quantum\ncryptography. This proposal assumes the use of mutual synchronization of\nartificial neural networks to correct errors occurring during transmission in\nthe quantum channel. Users can build neural networks based on their own string\nof bits. The typical value of the quantum bit error rate does not exceed a few\npercent, therefore the strings are similar and also users' neural networks are\nvery similar at the beginning of the learning process. It has been shown that\nthe synchronization process in the new solution is much faster than in the\nanalogous scenario used in neural cryptography. This feature significantly\nincreases the level of security because a potential eavesdropper cannot\neffectively synchronize their own artificial neural networks in order to obtain\ninformation about the key. Therefore, the key reconciliation based on the new\nidea can be a secure and efficient solution.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 20:12:31 GMT"}, {"version": "v2", "created": "Sun, 28 Apr 2019 19:44:11 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Niemiec", "Marcin", ""]]}, {"id": "1810.01017", "submitter": "Nalin Asanka Gamagedara Arachchilage", "authors": "Chamila Wijayarathna and Nalin Asanka Gamagedara Arachchilage", "title": "Fighting Against XSS Attacks: A Usability Evaluation of OWASP ESAPI\n  Output Encoding", "comments": "10", "journal-ref": "The 52nd Hawaii International Conference on System Sciences\n  (HICSS), 2019", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross Site Scripting (XSS) is one of the most critical vulnerabilities exist\nin web applications. XSS can be prevented by encoding untrusted data that are\nloaded into browser content of web applications. Security Application\nProgramming Interfaces (APIs) such as OWASP ESAPI provide output encoding\nfunctionalities for programmers to use to protect their applications from XSS\nattacks. However, XSS still being ranked as one of the most critical\nvulnerabilities in web applications suggests that programmers are not\neffectively using those APIs to encode untrusted data. Therefore, we conducted\nan experimental study with 10 programmers where they attempted to fix XSS\nvulnerabilities of a web application using the output encoding functionality of\nOWASP ESAPI. Results revealed 3 types of mistakes that programmers made which\nresulted in them failing to fix the application by removing XSS\nvulnerabilities. We also identified 16 usability issues of OWASP ESAPI. We\nidentified that some of these usability issues as the reason for mistakes that\nprogrammers made. Based on these results, we provided suggestions on how the\nusability of output encoding APIs should be improved to give a better\nexperience to programmers.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 23:57:58 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Wijayarathna", "Chamila", ""], ["Arachchilage", "Nalin Asanka Gamagedara", ""]]}, {"id": "1810.01032", "submitter": "Jingkang Wang", "authors": "Jingkang Wang, Yang Liu, Bo Li", "title": "Reinforcement Learning with Perturbed Rewards", "comments": "AAAI 2020 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that reinforcement learning (RL) models are\nvulnerable in various noisy scenarios. For instance, the observed reward\nchannel is often subject to noise in practice (e.g., when rewards are collected\nthrough sensors), and is therefore not credible. In addition, for applications\nsuch as robotics, a deep reinforcement learning (DRL) algorithm can be\nmanipulated to produce arbitrary errors by receiving corrupted rewards. In this\npaper, we consider noisy RL problems with perturbed rewards, which can be\napproximated with a confusion matrix. We develop a robust RL framework that\nenables agents to learn in noisy environments where only perturbed rewards are\nobserved. Our solution framework builds on existing RL/DRL algorithms and\nfirstly addresses the biased noisy reward setting without any assumptions on\nthe true distribution (e.g., zero-mean Gaussian noise as made in previous\nworks). The core ideas of our solution include estimating a reward confusion\nmatrix and defining a set of unbiased surrogate rewards. We prove the\nconvergence and sample complexity of our approach. Extensive experiments on\ndifferent DRL platforms show that trained policies based on our estimated\nsurrogate reward can achieve higher expected rewards, and converge faster than\nexisting baselines. For instance, the state-of-the-art PPO algorithm is able to\nobtain 84.6% and 80.8% improvements on average score for five Atari games, with\nerror rates as 10% and 30% respectively.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 01:43:45 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 15:47:23 GMT"}, {"version": "v3", "created": "Mon, 13 Jan 2020 22:19:26 GMT"}, {"version": "v4", "created": "Sat, 1 Feb 2020 21:15:52 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Wang", "Jingkang", ""], ["Liu", "Yang", ""], ["Li", "Bo", ""]]}, {"id": "1810.01046", "submitter": "Ang Li", "authors": "Ang Li, David Darling, Qinghua Li", "title": "PhotoSafer: Content-Based and Context-Aware Private Photo Protection for\n  Smartphones", "comments": "2018 IEEE Symposium on Privacy-Aware Computing (PAC)", "journal-ref": null, "doi": "10.1109/PAC.2018.00008", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays many people store photos in smartphones. Many of the photos contain\nsensitive, private information, such as a photocopy of driver's license and\ncredit card. An arising privacy concern is with the unauthorized accesses to\nsuch private photos by installed apps. Coarse-grained access control systems\nsuch as the Android permission system offer all-or-nothing access to photos\nstored on smartphones, and users are unaware of the exact behavior of installed\napps. Our analysis finds that 82% of the top 200 free apps in a popular Android\napp store have complete access to stored photos and network on a user's\nsmartphone, which indicates possible private photo leakage. In addition, our\nuser survey reveals that 87.5% of the 112 respondents are not aware that\ncertain apps can access their photos without informing users, and all the\nrespondents believe that the stored photos on their smartphones contain\ndifferent types of private information. Hence, we propose PhotoSafer, a\ncontent-based, context-aware private photo protection system for Android\nphones. PhotoSafer can detect private photos based on photo content with a\nwell-trained deep convolutional neural network, and control access to photos\nbased on system status (e.g., screen locked or not) and app-running status\n(e.g., app in the background). Evaluations demonstrate that PhotoSafer can\naccurately identify private photos in real time. The efficacy and efficiency of\nthe implemented prototype system show the potential for practical use.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 03:03:26 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Li", "Ang", ""], ["Darling", "David", ""], ["Li", "Qinghua", ""]]}, {"id": "1810.01048", "submitter": "Ang Li", "authors": "Ang Li, Wei Du, Qinghua Li", "title": "Privacy-Preserving Outsourcing of Large-Scale Nonlinear Programming to\n  the Cloud", "comments": "Ang Li and Wei Du equally contributed to this work. This work was\n  done when Wei Du was at the University of Arkansas. 2018 EAI International\n  Conference on Security and Privacy in Communication Networks (SecureComm)", "journal-ref": null, "doi": "10.1007/978-3-030-01701-9_31", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing massive data generated by various sources has given birth to\nbig data analytics. Solving large-scale nonlinear programming problems (NLPs)\nis one important big data analytics task that has applications in many domains\nsuch as transport and logistics. However, NLPs are usually too computationally\nexpensive for resource-constrained users. Fortunately, cloud computing provides\nan alternative and economical service for resource-constrained users to\noutsource their computation tasks to the cloud. However, one major concern with\noutsourcing NLPs is the leakage of user's private information contained in NLP\nformulations and results. Although much work has been done on\nprivacy-preserving outsourcing of computation tasks, little attention has been\npaid to NLPs. In this paper, we for the first time investigate secure\noutsourcing of general large-scale NLPs with nonlinear constraints. A secure\nand efficient transformation scheme at the user side is proposed to protect\nuser's private information; at the cloud side, generalized reduced gradient\nmethod is applied to effectively solve the transformed large-scale NLPs. The\nproposed protocol is implemented on a cloud computing testbed. Experimental\nevaluations demonstrate that significant time can be saved for users and the\nproposed mechanism has the potential for practical use.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 03:11:55 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Li", "Ang", ""], ["Du", "Wei", ""], ["Li", "Qinghua", ""]]}, {"id": "1810.01107", "submitter": "Gabriele Spini", "authors": "Thomas Attema and Emiliano Mancini and Gabriele Spini and Mark Abspoel\n  and Jan de Gier and Serge Fehr and Thijs Veugen and Maran van Heesch and\n  Dani\\\"el Worm and Andrea De Luca and Ronald Cramer and Peter M.A. Sloot", "title": "A New Approach to Privacy-Preserving Clinical Decision Support Systems", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Clinical decision support systems (CDSS) are a category of health\ninformation technologies that can assist clinicians to choose optimal\ntreatments. These support systems are based on clinical trials and expert\nknowledge; however, the amount of data available to these systems is limited.\nFor this reason, CDSSs could be significantly improved by using the knowledge\nobtained by treating patients. This knowledge is mainly contained in patient\nrecords, whose usage is restricted due to privacy and confidentiality\nconstraints.\n  Methods: A treatment effectiveness measure, containing valuable information\nfor treatment prescription, was defined and a method to extract this measure\nfrom patient records was developed. This method uses an advanced cryptographic\ntechnology, known as secure Multiparty Computation (henceforth referred to as\nMPC), to preserve the privacy of the patient records and the confidentiality of\nthe clinicians' decisions.\n  Results: Our solution enables to compute the effectiveness measure of a\ntreatment based on patient records, while preserving privacy. Moreover,\nclinicians are not burdened with the computational and communication costs\nintroduced by the privacy-preserving techniques that are used. Our system is\nable to compute the effectiveness of 100 treatments for a specific patient in\nless than 24 minutes, querying a database containing 20,000 patient records.\n  Conclusion: This paper presents a novel and efficient clinical decision\nsupport system, that harnesses the potential and insights acquired from\ntreatment data, while preserving the privacy of patient records and the\nconfidentiality of clinician decisions.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 08:13:20 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 11:41:11 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Attema", "Thomas", ""], ["Mancini", "Emiliano", ""], ["Spini", "Gabriele", ""], ["Abspoel", "Mark", ""], ["de Gier", "Jan", ""], ["Fehr", "Serge", ""], ["Veugen", "Thijs", ""], ["van Heesch", "Maran", ""], ["Worm", "Dani\u00ebl", ""], ["De Luca", "Andrea", ""], ["Cramer", "Ronald", ""], ["Sloot", "Peter M. A.", ""]]}, {"id": "1810.01152", "submitter": "Pingbo Pan", "authors": "Pingbo Pan, Yan Yan, Tianbao Yang, Yi Yang", "title": "Learning Discriminators as Energy Networks in Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework for structured prediction via adversarial\nlearning. Existing adversarial learning methods involve two separate networks,\ni.e., the structured prediction models and the discriminative models, in the\ntraining. The information captured by discriminative models complements that in\nthe structured prediction models, but few existing researches have studied on\nutilizing such information to improve structured prediction models at the\ninference stage. In this work, we propose to refine the predictions of\nstructured prediction models by effectively integrating discriminative models\ninto the prediction. Discriminative models are treated as energy-based models.\nSimilar to the adversarial learning, discriminative models are trained to\nestimate scores which measure the quality of predicted outputs, while\nstructured prediction models are trained to predict contrastive outputs with\nmaximal energy scores. In this way, the gradient vanishing problem is\nameliorated, and thus we are able to perform inference by following the ascent\ngradient directions of discriminative models to refine structured prediction\nmodels. The proposed method is able to handle a range of tasks, e.g.,\nmulti-label classification and image segmentation. Empirical results on these\ntwo tasks validate the effectiveness of our learning method.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 10:06:32 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Pan", "Pingbo", ""], ["Yan", "Yan", ""], ["Yang", "Tianbao", ""], ["Yang", "Yi", ""]]}, {"id": "1810.01166", "submitter": "Li Yu", "authors": "Li Yu", "title": "A quantum homomorphic encryption scheme for polynomial-sized circuits", "comments": "29 pages, 2 figures. Revised Section VIII, among other minor fixes", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum homomorphic encryption (QHE) is an encryption method that allows\nquantum computation to be performed on one party's private data with the\nprogram provided by another party, without revealing much information about the\ndata nor about the program to the opposite party. It is known that\ninformation-theoretically-secure QHE for circuits of unrestricted size would\nrequire exponential resources, and efficient computationally-secure QHE schemes\nfor polynomial-sized quantum circuits have been constructed. In this paper we\nfirst propose a QHE scheme for a type of circuits of polynomial depth, based on\nthe rebit quantum computation formalism. The scheme keeps the restricted type\nof data perfectly secure. We then propose a QHE scheme for a larger class of\npolynomial-depth quantum circuits, which has partial data privacy. Both schemes\nhave good circuit privacy. We also propose an interactive QHE scheme with\nasymptotic data privacy, however, the circuit privacy is not good, in the sense\nthat the party who provides the data could cheat and learn about the circuit.\nWe show that such cheating would generally affect the correctness of the\nevaluation or cause deviation from the protocol. Hence the cheating can be\ncaught by the opposite party in an interactive scheme with embedded\nverifications. Such scheme with verification has a minor drawback in data\nprivacy. Finally, we show some methods which achieve some nontrivial level of\ndata privacy and circuit privacy without resorting to allowing early\nterminations, in both the QHE problem and in secure evaluation of classical\nfunctions. The entanglement and classical communication costs in these schemes\nare polynomial in the circuit size and the security parameter (if any).\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 10:38:32 GMT"}, {"version": "v10", "created": "Mon, 26 Nov 2018 10:44:40 GMT"}, {"version": "v11", "created": "Tue, 11 Dec 2018 15:11:28 GMT"}, {"version": "v12", "created": "Thu, 13 Dec 2018 18:44:45 GMT"}, {"version": "v13", "created": "Wed, 26 Dec 2018 12:10:55 GMT"}, {"version": "v14", "created": "Tue, 5 Feb 2019 15:54:01 GMT"}, {"version": "v15", "created": "Mon, 4 Mar 2019 02:43:27 GMT"}, {"version": "v16", "created": "Thu, 4 Apr 2019 16:21:48 GMT"}, {"version": "v17", "created": "Sun, 5 May 2019 16:20:57 GMT"}, {"version": "v18", "created": "Mon, 3 Jun 2019 14:44:46 GMT"}, {"version": "v19", "created": "Tue, 9 Jul 2019 14:09:19 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 17:48:37 GMT"}, {"version": "v20", "created": "Thu, 1 Aug 2019 17:55:11 GMT"}, {"version": "v3", "created": "Mon, 8 Oct 2018 16:09:20 GMT"}, {"version": "v4", "created": "Wed, 17 Oct 2018 16:44:17 GMT"}, {"version": "v5", "created": "Mon, 29 Oct 2018 16:23:18 GMT"}, {"version": "v6", "created": "Thu, 1 Nov 2018 11:46:07 GMT"}, {"version": "v7", "created": "Mon, 5 Nov 2018 15:45:04 GMT"}, {"version": "v8", "created": "Mon, 12 Nov 2018 16:40:08 GMT"}, {"version": "v9", "created": "Mon, 19 Nov 2018 17:57:19 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Yu", "Li", ""]]}, {"id": "1810.01185", "submitter": "Alexandru Constantin Serban", "authors": "Alexandru Constantin Serban, Erik Poll, Joost Visser", "title": "Adversarial Examples - A Complete Characterisation of the Phenomenon", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a complete characterisation of the phenomenon of adversarial\nexamples - inputs intentionally crafted to fool machine learning models. We aim\nto cover all the important concerns in this field of study: (1) the conjectures\non the existence of adversarial examples, (2) the security, safety and\nrobustness implications, (3) the methods used to generate and (4) protect\nagainst adversarial examples and (5) the ability of adversarial examples to\ntransfer between different machine learning models. We provide ample background\ninformation in an effort to make this document self-contained. Therefore, this\ndocument can be used as survey, tutorial or as a catalog of attacks and\ndefences using adversarial examples.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 11:54:51 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 21:48:42 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Serban", "Alexandru Constantin", ""], ["Poll", "Erik", ""], ["Visser", "Joost", ""]]}, {"id": "1810.01268", "submitter": "Yash Sharma", "authors": "Yash Sharma, Tien-Dung Le, Moustafa Alzantot", "title": "CAAD 2018: Generating Transferable Adversarial Examples", "comments": "1st place attack solutions and 3rd place defense in CAAD 2018\n  Competition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are vulnerable to adversarial examples,\nperturbations carefully crafted to fool the targeted DNN, in both the\nnon-targeted and targeted case. In the non-targeted case, the attacker simply\naims to induce misclassification. In the targeted case, the attacker aims to\ninduce classification to a specified target class. In addition, it has been\nobserved that strong adversarial examples can transfer to unknown models,\nyielding a serious security concern. The NIPS 2017 competition was organized to\naccelerate research in adversarial attacks and defenses, taking place in the\nrealistic setting where submitted adversarial attacks attempt to transfer to\nsubmitted defenses. The CAAD 2018 competition took place with nearly identical\nrules to the NIPS 2017 one. Given the requirement that the NIPS 2017\nsubmissions were to be open-sourced, participants in the CAAD 2018 competition\nwere able to directly build upon previous solutions, and thus improve the\nstate-of-the-art in this setting. Our team participated in the CAAD 2018\ncompetition, and won 1st place in both attack subtracks, non-targeted and\ntargeted adversarial attacks, and 3rd place in defense. We outline our\nsolutions and development results in this article. We hope our results can\ninform researchers in both generating and defending against adversarial\nexamples.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 17:57:24 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 08:32:51 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Sharma", "Yash", ""], ["Le", "Tien-Dung", ""], ["Alzantot", "Moustafa", ""]]}, {"id": "1810.01279", "submitter": "Xuanqing Liu", "authors": "Xuanqing Liu, Yao Li, Chongruo Wu, Cho-Jui Hsieh", "title": "Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural\n  Network", "comments": "Code will be made available at\n  https://github.com/xuanqing94/BayesianDefense", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm to train a robust neural network against\nadversarial attacks. Our algorithm is motivated by the following two ideas.\nFirst, although recent work has demonstrated that fusing randomness can improve\nthe robustness of neural networks (Liu 2017), we noticed that adding noise\nblindly to all the layers is not the optimal way to incorporate randomness.\nInstead, we model randomness under the framework of Bayesian Neural Network\n(BNN) to formally learn the posterior distribution of models in a scalable way.\nSecond, we formulate the mini-max problem in BNN to learn the best model\ndistribution under adversarial attacks, leading to an adversarial-trained\nBayesian neural net. Experiment results demonstrate that the proposed algorithm\nachieves state-of-the-art performance under strong attacks. On CIFAR-10 with\nVGG network, our model leads to 14\\% accuracy improvement compared with\nadversarial training (Madry 2017) and random self-ensemble (Liu 2017) under PGD\nattack with $0.035$ distortion, and the gap becomes even larger on a subset of\nImageNet.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 05:23:15 GMT"}, {"version": "v2", "created": "Sat, 4 May 2019 06:39:11 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Liu", "Xuanqing", ""], ["Li", "Yao", ""], ["Wu", "Chongruo", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1810.01291", "submitter": "Yu Chen", "authors": "Ronghua Xu, Yu Chen, Erik Blasch, Genshe Chen", "title": "An Exploration of Blockchain Enabled Decentralized Capability based\n  Access Control Strategy for Space Situation Awareness", "comments": "Submitted to SPIE Optical Engineering, Special Section on Sensors and\n  Systems for Space Applications. arXiv admin note: substantial text overlap\n  with arXiv:1804.09267", "journal-ref": null, "doi": "10.1117/1.OE.58.4.041609", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Space situation awareness (SSA) includes tracking of active and inactive\nresident space objects (RSOs) and assessing the space environment through\nsensor data collection and processing. To enhance SSA, the dynamic data-driven\napplications systems (DDDAS) framework couples on-line data with off-line\nmodels to enhance system performance. Using feedback control, sensor\nmanagement, and communications reliability. For information management, there\nis a need for identity authentication and access control to ensure the\nintegrity of exchanged data as well as to grant authorized entities access\nright to data and services. Due to decentralization and heterogeneity of SSA\nsystems, it is challenging to build an efficient centralized access control\nsystem, which could either be a performance bottleneck or the single point of\nfailure. Inspired by the blockchain and smart contract technology, this paper\nintroduces BlendCAC, a decentralized authentication and capability-based access\ncontrol mechanism to enable effective protection for devices, services and\ninformation in SSA networks. To achieve secure identity authentication, the\nBlendCAC leverages the blockchain to create virtual trust zones and a robust\nidentity-based capability token management strategy is proposed. A\nproof-of-concept prototype has been implemented on both resources-constrained\ndevices and more powerful computing devices, and is tested on a private\nEthereum blockchain network. The experimental results demonstrate the\nfeasibility of the BlendCAC scheme to offer a decentralized, scalable,\nlightweight and fine-grained access control solution for space system towards\nSSA.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 13:20:11 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 16:24:36 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Xu", "Ronghua", ""], ["Chen", "Yu", ""], ["Blasch", "Erik", ""], ["Chen", "Genshe", ""]]}, {"id": "1810.01407", "submitter": "Mohammad Mahmoody", "authors": "Saeed Mahloujifar and Mohammad Mahmoody", "title": "Can Adversarially Robust Learning Leverage Computational Hardness?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making learners robust to adversarial perturbation at test time (i.e.,\nevasion attacks) or training time (i.e., poisoning attacks) has emerged as a\nchallenging task. It is known that for some natural settings, sublinear\nperturbations in the training phase or the testing phase can drastically\ndecrease the quality of the predictions. These negative results, however, are\ninformation theoretic and only prove the existence of such successful\nadversarial perturbations. A natural question for these settings is whether or\nnot we can make classifiers computationally robust to polynomial-time attacks.\n  In this work, we prove strong barriers against achieving such envisioned\ncomputational robustness both for evasion and poisoning attacks. In particular,\nwe show that if the test instances come from a product distribution (e.g.,\nuniform over $\\{0,1\\}^n$ or $[0,1]^n$, or isotropic $n$-variate Gaussian) and\nthat there is an initial constant error, then there exists a polynomial-time\nattack that finds adversarial examples of Hamming distance $O(\\sqrt n)$. For\npoisoning attacks, we prove that for any learning algorithm with sample\ncomplexity $m$ and any efficiently computable \"predicate\" defining some \"bad\"\nproperty $B$ for the produced hypothesis (e.g., failing on a particular test)\nthat happens with an initial constant probability, there exist polynomial-time\nonline poisoning attacks that tamper with $O (\\sqrt m)$ many examples, replace\nthem with other correctly labeled examples, and increases the probability of\nthe bad event $B$ to $\\approx 1$.\n  Both of our poisoning and evasion attacks are black-box in how they access\ntheir corresponding components of the system (i.e., the hypothesis, the\nconcept, and the learning algorithm) and make no further assumptions about the\nclassifier or the learning algorithm producing the classifier.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:58:23 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 04:53:12 GMT"}, {"version": "v3", "created": "Tue, 6 Nov 2018 04:19:41 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Mahloujifar", "Saeed", ""], ["Mahmoody", "Mohammad", ""]]}, {"id": "1810.01497", "submitter": "Boris K\\\"opf", "authors": "Pepe Vila, Boris K\\\"opf, Jos\\'e Francisco Morales", "title": "Theory and Practice of Finding Eviction Sets", "comments": "To appear at IEEE Symposium on Security and Privacy, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many micro-architectural attacks rely on the capability of an attacker to\nefficiently find small eviction sets: groups of virtual addresses that map to\nthe same cache set. This capability has become a decisive primitive for cache\nside-channel, rowhammer, and speculative execution attacks. Despite their\nimportance, algorithms for finding small eviction sets have not been\nsystematically studied in the literature.\n  In this paper, we perform such a systematic study. We begin by formalizing\nthe problem and analyzing the probability that a set of random virtual\naddresses is an eviction set. We then present novel algorithms, based on ideas\nfrom threshold group testing, that reduce random eviction sets to their minimal\ncore in linear time, improving over the quadratic state-of-the-art.\n  We complement the theoretical analysis of our algorithms with a rigorous\nempirical evaluation in which we identify and isolate factors that affect their\nreliability in practice, such as adaptive cache replacement strategies and TLB\nthrashing. Our results indicate that our algorithms enable finding small\neviction sets much faster than before, and under conditions where this was\npreviously deemed impractical.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 20:25:17 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 17:18:26 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Vila", "Pepe", ""], ["K\u00f6pf", "Boris", ""], ["Morales", "Jos\u00e9 Francisco", ""]]}, {"id": "1810.01571", "submitter": "Ken Goss", "authors": "Ken Goss and Wei Jiang", "title": "Distributing and Obfuscating Firewalls via Oblivious Bloom Filter\n  Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Firewalls have long been in use to protect local networks from threats of the\nlarger Internet. Although firewalls are effective in preventing attacks\ninitiated from outside, they are vulnerable to insider threats, e.g., malicious\ninsiders may access and alter firewall configurations, and disable firewall\nservices. In this paper, we develop an innovative distributed architecture to\nobliviously manage and evaluate firewalls to prevent both insider and external\nattacks oriented to the firewalls. Our proposed structure alleviates these\nissues by obfuscating the firewall rules or policies themselves, then\ndistributing the function of evaluating these rules across multiple servers.\nThus, both accessing and altering the rules are considerably more difficult\nthereby providing better protection to the local network as well as greater\nsecurity for the firewall itself. We achieve this by integrating multiple areas\nof research such as secret sharing schemes and multi-party computation, as well\nas Bloom filters and Byzantine agreement protocols. Our resulting solution is\nan efficient and secure means by which a firewall may be distributed, and\nobfuscated while maintaining the ability for multiple servers to obliviously\nevaluate its functionality.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 02:59:39 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Goss", "Ken", ""], ["Jiang", "Wei", ""]]}, {"id": "1810.01594", "submitter": "Sadegh Momeni Milajerdi", "authors": "Sadegh M. Milajerdi, Rigel Gjomemo, Birhanu Eshete, R. Sekar, V.N.\n  Venkatakrishnan", "title": "HOLMES: Real-time APT Detection through Correlation of Suspicious\n  Information Flows", "comments": "The final version of this paper will appear in the proceedings of the\n  40th IEEE Symposium on Security and Privacy in May 2019\n  (https://www.ieee-security.org/TC/SP2019/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present HOLMES, a system that implements a new approach to\nthe detection of Advanced and Persistent Threats (APTs). HOLMES is inspired by\nseveral case studies of real-world APTs that highlight some common goals of APT\nactors. In a nutshell, HOLMES aims to produce a detection signal that indicates\nthe presence of a coordinated set of activities that are part of an APT\ncampaign. One of the main challenges addressed by our approach involves\ndeveloping a suite of techniques that make the detection signal robust and\nreliable. At a high-level, the techniques we develop effectively leverage the\ncorrelation between suspicious information flows that arise during an attacker\ncampaign. In addition to its detection capability, HOLMES is also able to\ngenerate a high-level graph that summarizes the attacker's actions in\nreal-time. This graph can be used by an analyst for an effective cyber\nresponse. An evaluation of our approach against some real-world APTs indicates\nthat HOLMES can detect APT campaigns with high precision and low false alarm\nrate. The compact high-level graphs produced by HOLMES effectively summarizes\nan ongoing attack campaign and can assist real-time cyber-response operations.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 06:10:33 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2019 23:08:35 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Milajerdi", "Sadegh M.", ""], ["Gjomemo", "Rigel", ""], ["Eshete", "Birhanu", ""], ["Sekar", "R.", ""], ["Venkatakrishnan", "V. N.", ""]]}, {"id": "1810.01651", "submitter": "Shaohua Li", "authors": "Shaohua Li, Kaiping Xue", "title": "SecGrid: A Secure and Efficient SGX-enabled Smart Grid System with Rich\n  Functionalities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart grid adopts two-way communication and rich functionalities to gain a\npositive impact on the sustainability and efficiency of power usage, but on the\nother hand, also poses serious challenges to customers' privacy. Existing\nsolutions in smart grid usually use cryptographic tools, such as homomorphic\nencryption, to protect individual privacy, which, however, can only support\nlimited and simple functionalities. Moreover, the resource-constrained smart\nmeters need to perform heavy asymmetric cryptography in these solutions, which\nis not applied to smart grid. In this paper, we present a practical and secure\nSGX-enabled smart grid system, named SecGrid. Our system leverage trusted\nhardware SGX to ensure that grid utilities can efficiently execute rich\nfunctionalities on customers' private data, while guaranteeing their privacy.\nWith the designed security protocols, the SecGrid only require the smart meters\nto perform AES encryption. Security analysis shows that SecGrid can thwart\nvarious attacks from malicious adversaries. Experimental results show that\nSecGrid is much faster than the existing privacy-preserving schemes in smart\ngrid.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 09:21:32 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Li", "Shaohua", ""], ["Xue", "Kaiping", ""]]}, {"id": "1810.01662", "submitter": "Vasilios Mavroudis Mr", "authors": "Vasilios Mavroudis, Petr Svenda", "title": "Towards Low-level Cryptographic Primitives for JavaCards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  JavaCard is a multi-application security platform deployed to over twenty\nbillion smartcards, used in applications ranging from secure payments to\ntelecommunications. While the platform is a popular choice for established\ncommercial use cases (e.g., SIM cards in telecommunication networks), it has\nnotably low adoption rates in: 1) application scenarios requiring\nrecently-standardized cryptographic algorithms, 2) research projects, and 3)\nopen source initiatives. We attribute this to the restricted access to\nlow-level cryptographic primitives (e.g., elliptic curve operations) and the\nlack of essential data types (e.g., Integers). While the underlying hardware\nhas those capabilities, the JavaCard API does not provide calls for the\ncorresponding functionality. Until now, the only available workaround was\nmanufacturer-specific proprietary APIs that come with very restrictive\nnon-disclosure agreements.\n  In this paper, we introduce a methodology to efficiently derive essential\ndata types and low-level cryptographic primitives from high-level operations.\nOur techniques are ideal for resource-constrained platforms, and make optimal\nuse of the underlying hardware, while having a small memory footprint. We also\nintroduce JCMathLib, which, to the best of our knowledge, is the first generic\nlibrary for low-level cryptographic operations in JavaCards that does not rely\non a proprietary API. Without any disclosure limitations, JCMathLib enables\nopen code sharing, release of research prototypes and public and third-party\ncode audits.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 09:52:48 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Mavroudis", "Vasilios", ""], ["Svenda", "Petr", ""]]}, {"id": "1810.01851", "submitter": "Mahmoud Nabil", "authors": "Ahmad Alsharif, Mahmoud Nabil, Samet Tonyali, Hawzhin Mohammed,\n  Mohamed Mahmoud, and Kemal Akkaya", "title": "EPIC: Efficient Privacy-Preserving Scheme with E2E Data Integrity and\n  Authenticity for AMI Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Advanced Metering Infrastructure (AMI) networks, smart meters should send\nfine-grained power consumption readings to electric utilities to perform\nreal-time monitoring and energy management. However, these readings can leak\nsensitive information about consumers' activities. Various privacy-preserving\nschemes for collecting fine-grained readings have been proposed for AMI\nnetworks. These schemes aggregate individual readings and send an aggregated\nreading to the utility, but they extensively use asymmetric-key cryptography\nwhich involves large computation/communication overhead. Furthermore, they do\nnot address End-to-End (E2E) data integrity, authenticity, and computing\nelectricity bills based on dynamic prices. In this paper, we propose EPIC, an\nefficient and privacy-preserving data collection scheme with E2E data integrity\nverification for AMI networks. Using efficient cryptographic operations, each\nmeter should send a masked reading to the utility such that all the masks are\ncanceled after aggregating all meters' masked readings, and thus the utility\ncan only obtain an aggregated reading to preserve consumers' privacy. The\nutility can verify the aggregated reading integrity without accessing the\nindividual readings to preserve privacy. It can also identify the attackers and\ncompute electricity bills efficiently by using the fine-grained readings\nwithout violating privacy. Furthermore, EPIC can resist collusion attacks in\nwhich the utility colludes with a relay node to extract the meters' readings. A\nformal proof, probabilistic analysis are used to evaluate the security of EPIC,\nand ns-3 is used to implement EPIC and evaluate the network performance. In\naddition, we compare EPIC to existing data collection schemes in terms of\noverhead and security/privacy features.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 17:35:23 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Alsharif", "Ahmad", ""], ["Nabil", "Mahmoud", ""], ["Tonyali", "Samet", ""], ["Mohammed", "Hawzhin", ""], ["Mahmoud", "Mohamed", ""], ["Akkaya", "Kemal", ""]]}, {"id": "1810.01945", "submitter": "Jinoh Kim", "authors": "Jinoh Kim, Caitlin Sim, Jinhwan Choi", "title": "Generating Labeled Flow Data from MAWILab Traces for Network Intrusion\n  Detection", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing issue in the modern cyberspace world is the direct identification\nof malicious activity over network connections. The boom of the machine\nlearning industry in the past few years has led to the increasing usage of\nmachine learning technologies, which are especially prevalent in the network\nintrusion detection research community. When utilizing these fairly\ncontemporary techniques, the community has realized that datasets are pivotal\nfor identifying malicious packets and connections, particularly ones associated\nwith information concerning labeling in order to construct learning models.\nHowever, there exists a shortage of publicly available, relevant datasets to\nresearchers in the network intrusion detection community. Thus, in this paper,\nwe introduce a method to construct labeled flow data by combining the packet\nmeta-information with IDS logs to infer labels for intrusion detection\nresearch. Specifically, we designed a NetFlow-compatible format due to the\ncapability of a a large body of network devices, such as routers and switches,\nto export NetFlow records from raw traffic. In doing so, the introduced method\nat hand would aid researchers to access relevant network flow datasets along\nwith label information.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 20:19:10 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Kim", "Jinoh", ""], ["Sim", "Caitlin", ""], ["Choi", "Jinhwan", ""]]}, {"id": "1810.02023", "submitter": "Ryan Curtin", "authors": "Ryan R. Curtin, Andrew B. Gardner, Slawomir Grzonkowski, Alexey\n  Kleymenov, Alejandro Mosquera", "title": "Detecting DGA domains with recurrent neural networks and side\n  information", "comments": "Accepted to ARES 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern malware typically makes use of a domain generation algorithm (DGA) to\navoid command and control domains or IPs being seized or sinkholed. This means\nthat an infected system may attempt to access many domains in an attempt to\ncontact the command and control server. Therefore, the automatic detection of\nDGA domains is an important task, both for the sake of blocking malicious\ndomains and identifying compromised hosts. However, many DGAs use English\nwordlists to generate plausibly clean-looking domain names; this makes\nautomatic detection difficult. In this work, we devise a notion of difficulty\nfor DGA families called the smashword score; this measures how much a DGA\nfamily looks like English words. We find that this measure accurately reflects\nhow much a DGA family's domains look like they are made from natural English\nwords. We then describe our new modeling approach, which is a combination of a\nnovel recurrent neural network architecture with domain registration side\ninformation. Our experiments show the model is capable of effectively\nidentifying domains generated by difficult DGA families. Our experiments also\nshow that our model outperforms existing approaches, and is able to reliably\ndetect difficult DGA families such as matsnu, suppobox, rovnix, and others. The\nmodel's performance compared to the state of the art is best for DGA families\nthat resemble English words. We believe that this model could either be used in\na standalone DGA domain detector---such as an endpoint security\napplication---or alternately the model could be used as a part of a larger\nmalware detection system.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 02:02:38 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 15:02:46 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Curtin", "Ryan R.", ""], ["Gardner", "Andrew B.", ""], ["Grzonkowski", "Slawomir", ""], ["Kleymenov", "Alexey", ""], ["Mosquera", "Alejandro", ""]]}, {"id": "1810.02061", "submitter": "Muhamad Felemban", "authors": "Muhamad Felemban, Yahya Javeed, Jason Kobes, Thamir Qadah, Arif\n  Ghafoor, and Walid Aref", "title": "Design and Evaluation of A Data Partitioning-Based Intrusion Management\n  Architecture for Database Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-intensive applications exhibit increasing reliance on Database\nManagement Systems (DBMSs, for short). With the growing cyber-security threats\nto government and commercial infrastructures, the need to develop high\nresilient cyber systems is becoming increasingly important. Cyber-attacks on\nDBMSs include intrusion attacks that may result in severe degradation in\nperformance. Several efforts have been directed towards designing an integrated\nmanagement system to detect, respond, and recover from malicious attacks. In\nthis paper, we propose a data Partitioning-based Intrusion Management System\n(PIMS, for short) that can endure intense malicious intrusion attacks on DBMS.\nThe novelty in PIMS is the ability to contain the damage into data partitions,\ntermed Intrusion Boundaries (IBs, for short). The IB Demarcation Problem (IBDP,\nfor short) is formulated as a mixed integer nonlinear programming. We prove\nthat IBDP is NP-hard. Accordingly, two heuristic solutions for IBDP are\nintroduced. The proposed architecture for PIMS includes novel IB-centric\nresponse and recovery mechanisms, which executes compensating transactions.\nPIMS is prototyped within PostgreSQL, an open-source DBMS. Finally, empirical\nand experimental performance evaluation of PIMS are conducted to demonstrate\nthat intelligent partitioning of data tuples improves the overall availability\nof the DBMS under intrusion attacks.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 05:08:35 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 22:21:28 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Felemban", "Muhamad", ""], ["Javeed", "Yahya", ""], ["Kobes", "Jason", ""], ["Qadah", "Thamir", ""], ["Ghafoor", "Arif", ""], ["Aref", "Walid", ""]]}, {"id": "1810.02062", "submitter": "Warit Sirichotedumrong", "authors": "Tatsuya Chuman, Kenta Iida, Warit Sirichotedumrong, Hitoshi Kiya", "title": "Image Manipulation Specifications on Social Networking Services for\n  Encryption-then-Compression Systems", "comments": "To be appeared in IEICE Transactions on Information and Systems,\n  January 2019", "journal-ref": null, "doi": "10.1587/transinf.2018MUP0001", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encryption-then-Compression (EtC) systems have been proposed to securely\ntransmit images through an untrusted channel provider. In this study, EtC\nsystems were applied to social media like Twitter that carry out image\nmanipulations. The block scrambling-based encryption schemes used in EtC\nsystems were evaluated in terms of their robustness against image manipulation\non social media. The aim was to investigate how five social networking service\n(SNS) providers, Facebook, Twitter, Google+, Tumblr and Flickr, manipulate\nimages and to determine whether the encrypted images uploaded to SNS providers\ncan avoid being distorted by such manipulations. In an experiment, encrypted\nand non-encrypted JPEG images were uploaded to various SNS providers. The\nresults show that EtC systems are applicable to the five SNS providers.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 05:25:05 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Chuman", "Tatsuya", ""], ["Iida", "Kenta", ""], ["Sirichotedumrong", "Warit", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "1810.02066", "submitter": "Ran Gilad-Bachrach", "authors": "Stav Buchsbaum and Ran Gilad-Bachrach and Yehuda Lindell", "title": "Turning Lemons into Peaches using Secure Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many cases, assessing the quality of goods is hard. For example, when\npurchasing a car, it is hard to measure how pollutant the car is since there\nare infinitely many driving conditions to be tested. Typically, these\nsituations are considered under the umbrella of information asymmetry and as\nAkelrof showed may lead to a market of lemons. However, we argue that in many\nof these situations, the problem is not the missing information but the\ncomputational challenge of obtaining it. In a nut-shell, if verifying the value\nof goods requires a large amount of computation or even infinite amounts of\ncomputation, the buyer is forced to use a finite test that samples, in some\nsense, the quality of the goods. However, if the seller knows the test, then\nthe seller can over-fit the test and create goods that pass the quality test\ndespite not having the desired quality. We show different solutions to this\nsituation including a novel approach that uses secure computation to hide the\ntest from the seller to prevent over-fitting.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 06:09:03 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Buchsbaum", "Stav", ""], ["Gilad-Bachrach", "Ran", ""], ["Lindell", "Yehuda", ""]]}, {"id": "1810.02090", "submitter": "Dov Murik", "authors": "Fady Copty (1), Francisco Hernandez (2), Dov Murik (1), Olmo Ray\\'on\n  (2) ((1) IBM Research, (2) Worldsensing)", "title": "Shakedown: compiler-based moving target protection for Return Oriented\n  Programing attacks on an industrial IoT device", "comments": "1st SMESEC Workshop - Heraklion, Greece (2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybercriminals use Return Oriented Programming techniques to attack systems\nand IoT devices. While defenses have been developed, not all of them are\napplicable to constrained devices. We present Shakedown, which is a\ncompile-time randomizing build tool which creates several versions of the\nbinary, each with a distinct memory layout. An attack developed against one\ndevice will not work on another device which has a different memory layout. We\ntested Shakedown on an industrial IoT device and shown that its normal\nfunctionality remained intact while an exploit was blocked.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 08:12:31 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 09:28:47 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Copty", "Fady", "", "IBM Research"], ["Hernandez", "Francisco", "", "Worldsensing"], ["Murik", "Dov", "", "IBM Research"], ["Ray\u00f3n", "Olmo", "", "Worldsensing"]]}, {"id": "1810.02183", "submitter": "Ilias Zadik", "authors": "Christian Borgs, Jennifer Chayes, Adam Smith, Ilias Zadik", "title": "Revealing Network Structure, Confidentially: Improved Rates for\n  Node-Private Graphon Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CR cs.DS math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by growing concerns over ensuring privacy on social networks, we\ndevelop new algorithms and impossibility results for fitting complex\nstatistical models to network data subject to rigorous privacy guarantees. We\nconsider the so-called node-differentially private algorithms, which compute\ninformation about a graph or network while provably revealing almost no\ninformation about the presence or absence of a particular node in the graph.\n  We provide new algorithms for node-differentially private estimation for a\npopular and expressive family of network models: stochastic block models and\ntheir generalization, graphons. Our algorithms improve on prior work, reducing\ntheir error quadratically and matching, in many regimes, the optimal nonprivate\nalgorithm. We also show that for the simplest random graph models ($G(n,p)$ and\n$G(n,m)$), node-private algorithms can be qualitatively more accurate than for\nmore complex models---converging at a rate of $\\frac{1}{\\epsilon^2 n^{3}}$\ninstead of $\\frac{1}{\\epsilon^2 n^2}$. This result uses a new extension lemma\nfor differentially private algorithms that we hope will be broadly useful.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 13:00:27 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Borgs", "Christian", ""], ["Chayes", "Jennifer", ""], ["Smith", "Adam", ""], ["Zadik", "Ilias", ""]]}, {"id": "1810.02227", "submitter": "Jan Wassenberg", "authors": "Jan Wassenberg, Robert Obryk, Jyrki Alakuijala, Emmanuel Mogenet", "title": "Randen - fast backtracking-resistant random generator with\n  AES+Feistel+Reverie", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms that rely on a pseudorandom number generator often lose their\nperformance guarantees when adversaries can predict the behavior of the\ngenerator. To protect non-cryptographic applications against such attacks, we\npropose 'strong' pseudorandom generators characterized by two properties:\ncomputationally indistinguishable from random and backtracking-resistant. Some\nexisting cryptographically secure generators also meet these criteria, but they\nare too slow to be accepted for general-purpose use. We introduce a new\nopen-sourced generator called 'Randen' and show that it is 'strong' in addition\nto outperforming Mersenne Twister, PCG, ChaCha8, ISAAC and Philox in real-world\nbenchmarks. This is made possible by hardware acceleration. Randen is an\ninstantiation of Reverie, a recently published robust sponge-like random\ngenerator, with a new permutation built from an improved generalized Feistel\nstructure with 16 branches. We provide new bounds on active s-boxes for up to\n24 rounds of this construction, made possible by a memory-efficient search\nalgorithm. Replacing existing generators with Randen can protect randomized\nalgorithms such as reservoir sampling from attack. The permutation may also be\nuseful for wide-block ciphers and hashing functions.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 14:08:57 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Wassenberg", "Jan", ""], ["Obryk", "Robert", ""], ["Alakuijala", "Jyrki", ""], ["Mogenet", "Emmanuel", ""]]}, {"id": "1810.02396", "submitter": "Jevg\\=enijs Vihrovs", "authors": "Balthazar Bauer, Jevg\\=enijs Vihrovs, Hoeteck Wee", "title": "On the Inner Product Predicate and a Generalization of Matching Vector\n  Families", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by cryptographic applications such as predicate encryption, we\nconsider the problem of representing an arbitrary predicate as the inner\nproduct predicate on two vectors. Concretely, fix a Boolean function $P$ and\nsome modulus $q$. We are interested in encoding $x$ to $\\vec x$ and $y$ to\n$\\vec y$ so that $$P(x,y) = 1 \\Longleftrightarrow \\langle\\vec x,\\vec y\\rangle=\n0 \\bmod q,$$ where the vectors should be as short as possible. This problem can\nalso be viewed as a generalization of matching vector families, which\ncorresponds to the equality predicate. Matching vector families have been used\nin the constructions of Ramsey graphs, private information retrieval (PIR)\nprotocols, and more recently, secret sharing.\n  Our main result is a simple lower bound that allows us to show that known\nencodings for many predicates considered in the cryptographic literature such\nas greater than and threshold are essentially optimal for prime modulus $q$.\nUsing this approach, we also prove lower bounds on encodings for composite $q$,\nand then show tight upper bounds for such predicates as greater than, index and\ndisjointness.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 19:14:37 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Bauer", "Balthazar", ""], ["Vihrovs", "Jevg\u0113nijs", ""], ["Wee", "Hoeteck", ""]]}, {"id": "1810.02400", "submitter": "Ang Li", "authors": "Wei Du, Ang Li, Qinghua Li", "title": "Privacy-Preserving Multiparty Learning For Logistic Regression", "comments": "This work was done when Wei Du was at the University of Arkansas", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, machine learning techniques are widely used in numerous\napplications, such as weather forecast, financial data analysis, spam\nfiltering, and medical prediction. In the meantime, massive data generated from\nmultiple sources further improve the performance of machine learning tools.\nHowever, data sharing from multiple sources brings privacy issues for those\nsources since sensitive information may be leaked in this process. In this\npaper, we propose a framework enabling multiple parties to collaboratively and\naccurately train a learning model over distributed datasets while guaranteeing\nthe privacy of data sources. Specifically, we consider logistic regression\nmodel for data training and propose two approaches for perturbing the objective\nfunction to preserve {\\epsilon}-differential privacy. The proposed solutions\nare tested on real datasets, including Bank Marketing and Credit Card Default\nprediction. Experimental results demonstrate that the proposed multiparty\nlearning framework is highly efficient and accurate.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 19:34:33 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Du", "Wei", ""], ["Li", "Ang", ""], ["Li", "Qinghua", ""]]}, {"id": "1810.02466", "submitter": "Benjamin Kaiser", "authors": "Ben Kaiser, Mireya Jurado, Alex Ledger", "title": "The Looming Threat of China: An Analysis of Chinese Influence on Bitcoin", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As Bitcoin's popularity has grown over the decade since its creation, it has\nbecome an increasingly attractive target for adversaries of all kinds. One of\nthe most powerful potential adversaries is the country of China, which has\nexpressed adversarial positions regarding the cryptocurrency and demonstrated\npowerful capabilities to influence it. In this paper, we explore how China\nthreatens the security, stability, and viability of Bitcoin through its\ndominant position in the Bitcoin ecosystem, political and economic control over\ndomestic activity, and control over its domestic Internet infrastructure. We\nexplore the relationship between China and Bitcoin, document China's motivation\nto undermine Bitcoin, and present a case study to demonstrate the strong\ninfluence that China has over Bitcoin. Finally, we systematize the class of\nattacks that China can deploy against Bitcoin to better understand the threat\nChina poses. We conclude that China has mature capabilities and strong motives\nfor performing a variety of attacks against Bitcoin.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 00:19:50 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Kaiser", "Ben", ""], ["Jurado", "Mireya", ""], ["Ledger", "Alex", ""]]}, {"id": "1810.02496", "submitter": "Georgios Portokalidis", "authors": "Dimitrios Damopoulos and Georgios Portokalidis", "title": "Hands-Free One-Time and Continuous Authentication Using Glass Wearable\n  Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users with limited use of their hands, such as people suffering from\ndisabilities of the arm, shoulder, and hand (DASH), face challenges when\nauthenticating with computer terminals, specially with publicly accessible\nterminals such as ATMs. A new glass wearable device was recently introduced by\nGoogle and it was immediately welcomed by groups of users, such as the ones\ndescribed above, as Google Glass allows them to perform actions, like taking a\nphoto, using only verbal commands. This paper investigates whether glass\nwearable devices can be used to authenticate users, both to grant access\n(one-time) and to maintain access (continuous), in similar hands-free fashion.\nWe do so by designing and implementing Gauth, a system that enables users to\nauthenticate with a service simply by issuing a voice command, while facing the\ncomputer terminal they are going to use to access the service. To achieve this\ngoal, we create a physical communication channel from the terminal to the\ndevice using machine readable visual codes, like QR codes, and utilize the\ndevice's network adapter to communicate directly with a service. More\nimportantly, we continuously authenticate the user accessing the terminal,\nexploiting the fact that a user operating a terminal is most likely facing it\nmost of the time. We periodically issue authentication challenges, which are\ndisplayed as a QR code on the terminal, that cause the glass device to\nre-authenticate the user with an appropriate response. We evaluate our system\nto determine the technical limits of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 02:39:43 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Damopoulos", "Dimitrios", ""], ["Portokalidis", "Georgios", ""]]}, {"id": "1810.02599", "submitter": "Minglong Qi", "authors": "Minglong Qi and Shenwu Xiong", "title": "On a Theorem of Kyureghyan and Pott", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In the paper of Gohar M. Kyureghyan and Alexander Pott (Designs, Codes and\nCryptography, 29, 149-164, 2003), the linear feedback polynomials of the\nSidel'nikov-Lempel-Cohn-Eastman sequences were determined for some special\ncases. When referring to that paper, we found that Corollary 4 and Theorem 2 of\nthat paper are wrong because there exist many counterexamples for these two\nresults. In this note, we give some counterexamples of Corollary 4 and Theorem\n2 of that paper.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 10:24:01 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Qi", "Minglong", ""], ["Xiong", "Shenwu", ""]]}, {"id": "1810.02649", "submitter": "Emiliano De Cristofaro", "authors": "Luca Melis, Apostolos Pyrgelis, Emiliano De Cristofaro", "title": "On Collaborative Predictive Blacklisting", "comments": "A preliminary version of this paper appears in ACM SIGCOMM's Computer\n  Communication Review (Volume 48 Issue 5, October 2018). This is the full\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative predictive blacklisting (CPB) allows to forecast future attack\nsources based on logs and alerts contributed by multiple organizations.\nUnfortunately, however, research on CPB has only focused on increasing the\nnumber of predicted attacks but has not considered the impact on false\npositives and false negatives. Moreover, sharing alerts is often hindered by\nconfidentiality, trust, and liability issues, which motivates the need for\nprivacy-preserving approaches to the problem. In this paper, we present a\nmeasurement study of state-of-the-art CPB techniques, aiming to shed light on\nthe actual impact of collaboration. To this end, we reproduce and measure two\nsystems: a non privacy-friendly one that uses a trusted coordinating party with\naccess to all alerts (Soldo et al., 2010) and a peer-to-peer one using\nprivacy-preserving data sharing (Freudiger et al., 2015). We show that, while\ncollaboration boosts the number of predicted attacks, it also yields high false\npositives, ultimately leading to poor accuracy. This motivates us to present a\nhybrid approach, using a semi-trusted central entity, aiming to increase\nutility from collaboration while, at the same time, limiting information\ndisclosure and false positives. This leads to a better trade-off of true and\nfalse positive rates, while at the same time addressing privacy concerns.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 12:41:25 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Melis", "Luca", ""], ["Pyrgelis", "Apostolos", ""], ["De Cristofaro", "Emiliano", ""]]}, {"id": "1810.02713", "submitter": "Giovanni Iacca Dr.", "authors": "D. Bucur, G. Iacca, M. Gaudesi, G. Squillero, A. Tonda", "title": "Optimizing groups of colluding strong attackers in mobile urban\n  communication networks with evolutionary algorithms", "comments": null, "journal-ref": "Applied Soft Computing, Volume 40, pp 416-426, 2016", "doi": "10.1016/j.asoc.2015.11.024", "report-no": null, "categories": "cs.NE cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In novel forms of the Social Internet of Things, any mobile user within\ncommunication range may help routing messages for another user in the network.\nThe resulting message delivery rate depends both on the users' mobility\npatterns and the message load in the network. This new type of configuration,\nhowever, poses new challenges to security, amongst them, assessing the effect\nthat a group of colluding malicious participants can have on the global message\ndelivery rate in such a network is far from trivial. In this work, after\nmodeling such a question as an optimization problem, we are able to find quite\ninteresting results by coupling a network simulator with an evolutionary\nalgorithm. The chosen algorithm is specifically designed to solve problems\nwhose solutions can be decomposed into parts sharing the same structure. We\ndemonstrate the effectiveness of the proposed approach on two medium-sized\nDelay-Tolerant Networks, realistically simulated in the urban contexts of two\ncities with very different route topology: Venice and San Francisco. In all\nexperiments, our methodology produces attack patterns that greatly lower\nnetwork performance with respect to previous studies on the subject, as the\nevolutionary core is able to exploit the specific weaknesses of each target\nconfiguration.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 14:25:50 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Bucur", "D.", ""], ["Iacca", "G.", ""], ["Gaudesi", "M.", ""], ["Squillero", "G.", ""], ["Tonda", "A.", ""]]}, {"id": "1810.02895", "submitter": "Peter Ney", "authors": "Peter M. Ney, Luis Ceze, Tadayoshi Kohno", "title": "Computer Security Risks of Distant Relative Matching in Consumer Genetic\n  Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Consumer genetic testing has become immensely popular in recent years and has\nlead to the creation of large scale genetic databases containing millions of\ndense autosomal genotype profiles. One of the most used features offered by\ngenetic databases is the ability to find distant relatives using a technique\ncalled relative matching (or DNA matching). Recently, novel uses of relative\nmatching were discovered that combined matching results with genealogical\ninformation to solve criminal cold cases. New estimates suggest that relative\nmatching, combined with simple demographic information, could be used to\nre-identify a significant percentage of US Caucasian individuals. In this work\nwe attempt to systematize computer security and privacy risks from relative\nmatching and describe new security problems that can occur if an attacker\nuploads manipulated or forged genetic profiles. For example, forged profiles\ncan be used by criminals to misdirect investigations, con-artists to defraud\nvictims, or political operatives to blackmail opponents. We discuss solutions\nto mitigate these threats, including existing proposals to use digital\nsignatures, and encourage the consumer genetics community to consider the\nbroader security implications of relative matching now that it is becoming so\nprominent.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 21:42:59 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Ney", "Peter M.", ""], ["Ceze", "Luis", ""], ["Kohno", "Tadayoshi", ""]]}, {"id": "1810.02937", "submitter": "Shumo Chu", "authors": "Shumo Chu, Sophia Wang", "title": "The Curses of Blockchain Decentralization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Decentralization, which has backed the hyper growth of many blockchains,\ncomes at the cost of scalability. To understand this fundamental limitation,\nthis paper proposes a quantitative measure of blockchain decentralization, and\ndiscusses its implications to various trust models and consensus algorithms.\nFurther, we identify the major challenges in blockchain decentralization. Our\nkey findings are that true decentralization is hard to achieve due to the\nskewed mining power and that a fully decentralized blockchain inherently limits\nscalability as it incurs a throughput upper bound and prevents scaling smart\ncontract execution. To address these challenges, we outline three research\ndirections to explore the trade-offs between decentralization and scalability.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 05:22:32 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Chu", "Shumo", ""], ["Wang", "Sophia", ""]]}, {"id": "1810.02964", "submitter": "Giacomo Micheli", "authors": "Karan Khathuria and Giacomo Micheli and Violetta Weger", "title": "On the algebraic structure of $E_p^{(m)}$ and applications to\n  cryptography", "comments": "To appear in Applicable Algebra in Engineering, Communication and\n  Computing", "journal-ref": null, "doi": "10.1007/s00200-019-00410-1", "report-no": null, "categories": "cs.CR math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show that the $\\mathbb Z/p^{m}\\mathbb Z$-module structure of\nthe ring $E_p^{(m)}$ is isomorphic to a $\\mathbb Z/p^{m}\\mathbb Z$-submodule of\nthe matrix ring over $\\mathbb Z/p^{m}\\mathbb Z$. Using this intrinsic structure\nof $E_p^{(m)}$, solving a linear system over $E_p^{(m)}$ becomes\ncomputationally equivalent to solving a linear system over $\\mathbb\nZ/p^{m}\\mathbb Z$. As an application we break the protocol based on the\nDiffie-Hellman Decomposition problem and ElGamal Decomposition problem over\n$E_p^{(m)}$. Our algorithm terminates in a provable running time of $O(m^{6})$\n$\\mathbb Z/p^{m}\\mathbb Z$-operations.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 09:06:21 GMT"}, {"version": "v2", "created": "Sat, 14 Dec 2019 19:16:56 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Khathuria", "Karan", ""], ["Micheli", "Giacomo", ""], ["Weger", "Violetta", ""]]}, {"id": "1810.02974", "submitter": "Vero Estrada-Galinanes", "authors": "Vero Estrada-Gali\\~nanes (1 and 2), Ethan Miller (2), Pascal Felber\n  (1), and Jehan-Fran\\c{c}ois P\\^aris (3) ((1) University of Neuch\\^atel, 2000\n  Neuch\\^atel, Switzerland, (2) University of California, Santa Cruz, CA 95064,\n  USA, (3) University of Houston, Houston, TX 77204-3010, USA)", "title": "Alpha Entanglement Codes: Practical Erasure Codes to Archive Data in\n  Unreliable Environments", "comments": "The publication has 12 pages and 13 figures. This work was partially\n  supported by Swiss National Science Foundation SNSF Doc.Mobility 162014, 2018\n  48th Annual IEEE/IFIP International Conference on Dependable Systems and\n  Networks (DSN)", "journal-ref": null, "doi": "10.1109/DSN.2018.00030", "report-no": null, "categories": "cs.DC cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data centres that use consumer-grade disks drives and distributed\npeer-to-peer systems are unreliable environments to archive data without enough\nredundancy. Most redundancy schemes are not completely effective for providing\nhigh availability, durability and integrity in the long-term. We propose alpha\nentanglement codes, a mechanism that creates a virtual layer of highly\ninterconnected storage devices to propagate redundant information across a\nlarge scale storage system. Our motivation is to design flexible and practical\nerasure codes with high fault-tolerance to improve data durability and\navailability even in catastrophic scenarios. By flexible and practical, we mean\ncode settings that can be adapted to future requirements and practical\nimplementations with reasonable trade-offs between security, resource usage and\nperformance. The codes have three parameters. Alpha increases storage overhead\nlinearly but increases the possible paths to recover data exponentially. Two\nother parameters increase fault-tolerance even further without the need of\nadditional storage. As a result, an entangled storage system can provide high\navailability, durability and offer additional integrity: it is more difficult\nto modify data undetectably. We evaluate how several redundancy schemes perform\nin unreliable environments and show that alpha entanglement codes are flexible\nand practical codes. Remarkably, they excel at code locality, hence, they\nreduce repair costs and become less dependent on storage locations with poor\navailability. Our solution outperforms Reed-Solomon codes in many disaster\nrecovery scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 10:32:33 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Estrada-Gali\u00f1anes", "Vero", "", "1 and 2"], ["Miller", "Ethan", ""], ["Felber", "Pascal", ""], ["P\u00e2ris", "Jehan-Fran\u00e7ois", ""]]}, {"id": "1810.03010", "submitter": "Mark Yampolskiy", "authors": "Bikash Ranabhat, Joseph Clements, Jacob Gatlin, Kuang-Ting Hsiao, Mark\n  Yampolskiy", "title": "Optimal Sabotage Attack on Composite Material Parts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industry 4.0 envisions a fully automated manufacturing environment, in which\ncomputerized manufacturing equipment--Cyber-Physical Systems (CPS)--performs\nall tasks. These machines are open to a variety of cyber and cyber-physical\nattacks, including sabotage. In the manufacturing context, sabotage attacks aim\nto damage equipment or degrade a manufactured part's mechanical properties. In\nthis paper, we focus on the latter, specifically for composite materials.\nComposite material parts are predominantly used in safety-critical systems,\ne.g., as load-bearing parts of aircraft. Further, we distinguish between the\nmethods to compromise various manufacturing equipment, and the malicious\nmanipulations that will sabotage a part. As the research literature has\nnumerous examples of the former, in this paper we assume that the equipment is\nalready compromised, our discussion is solely on manipulations.\n  We develop a simulation approach to designing sabotage attacks against\ncomposite material parts. The attack can be optimized by two criteria,\nminimizing the \"footprint\" of manipulations. We simulate two optimal attacks\nagainst the design of a spar, a load bearing component of an airplane wing. Our\nsimulation identifies the minimal manipulations needed to degrade its strength\nto three desired levels, as well as the resulting failure characteristics. Last\nbut not least, we outline an approach to identifying sabotaged parts.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 15:33:03 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Ranabhat", "Bikash", ""], ["Clements", "Joseph", ""], ["Gatlin", "Jacob", ""], ["Hsiao", "Kuang-Ting", ""], ["Yampolskiy", "Mark", ""]]}, {"id": "1810.03197", "submitter": "Xueru Zhang", "authors": "Xueru Zhang, Mohammad Mahdi Khalili, Mingyan Liu", "title": "Recycled ADMM: Improve Privacy and Accuracy with Less Computation in\n  Distributed Algorithms", "comments": "Accepted to 56th Annual Allerton Conference on Communication,\n  Control, and Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alternating direction method of multiplier (ADMM) is a powerful method to\nsolve decentralized convex optimization problems. In distributed settings, each\nnode performs computation with its local data and the local results are\nexchanged among neighboring nodes in an iterative fashion. During this\niterative process the leakage of data privacy arises and can accumulate\nsignificantly over many iterations, making it difficult to balance the\nprivacy-utility tradeoff. In this study we propose Recycled ADMM (R-ADMM),\nwhere a linear approximation is applied to every even iteration, its solution\ndirectly calculated using only results from the previous, odd iteration. It\nturns out that under such a scheme, half of the updates incur no privacy loss\nand require much less computation compared to the conventional ADMM. We obtain\na sufficient condition for the convergence of R-ADMM and provide the privacy\nanalysis based on objective perturbation.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 18:39:41 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Zhang", "Xueru", ""], ["Khalili", "Mohammad Mahdi", ""], ["Liu", "Mingyan", ""]]}, {"id": "1810.03249", "submitter": "Daniel Inge", "authors": "William Fu, Raymond Lin, Daniel Inge", "title": "Fully Homomorphic Image Processing", "comments": "12 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully homomorphic encryption has allowed devices to outsource computation to\nthird parties while preserving the secrecy of the data being computed on. Many\nimages contain sensitive information and are commonly sent to cloud services to\nencode images for different devices. We implement image processing\nhomomorphically that ensures secrecy of the image while also providing\nreasonable overhead. We first present some previous related work, as well as\nthe fully homomorphic encryption scheme we use. Then, we introduce our schemes\nfor JPEG encoding and decoding, as well as schemes for bilinear and bicubic\nimage resizing, as well as some data and analysis of our homomorphic schemes.\nFinally, we outline several issues with the homomorphic evaluation of\nproprietary algorithms, and how a third party can gain information on the\nalgorithm through noise.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 02:32:38 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Fu", "William", ""], ["Lin", "Raymond", ""], ["Inge", "Daniel", ""]]}, {"id": "1810.03323", "submitter": "Meng Shen", "authors": "Meng Shen, Zelin Liao, Liehuang Zhu, Rashid Mijumbi, Xiaojiang Du, and\n  Jiankun Hu", "title": "IriTrack: Liveness Detection Using Irises Tracking for Preventing Face\n  Spoofing Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face liveness detection has become a widely used technique with a growing\nimportance in various authentication scenarios to withstand spoofing attacks.\nExisting methods that perform liveness detection generally focus on designing\nintelligent classifiers or customized hardware to differentiate between the\nimage or video samples of a real legitimate user and the imitated ones.\nAlthough effective, they can be resource-consuming and detection results may be\nsensitive to environmental changes. In this paper, we take iris movement as a\nsignificant liveness sign and propose a simple and efficient liveness detection\nsystem named IriTrack. Users are required to move their eyes along with a\nrandomly generated poly-line, and trajectories of irises are then used as\nevidences for liveness detection. IriTrack allows checking liveness by using\ndata collected during user-device interactions. We implemented a prototype and\nconducted extensive experiments to evaluate the performance of the proposed\nsystem. The results show that IriTrack can fend against spoofing attacks with a\nmoderate and adjustable time overhead.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 08:45:53 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Shen", "Meng", ""], ["Liao", "Zelin", ""], ["Zhu", "Liehuang", ""], ["Mijumbi", "Rashid", ""], ["Du", "Xiaojiang", ""], ["Hu", "Jiankun", ""]]}, {"id": "1810.03357", "submitter": "Abdul Wahab Mr", "authors": "Abdul Wahab and Waqas Mehmood", "title": "Survey of Consensus Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed ledger technology has gained wide popularity and adoption since\nthe emergence of bitcoin in 2008 which is based on proof of work (PoW). It is a\ndistributed, transparent and immutable database of records of all the\ntransactions or events that have been shared and executed among the\nparticipants. All the transactions are verified and maintained by multiple\nnodes across a network without a central authority through a distributed\ncryptographic mechanism, a consensus protocol. It forms the core of this\ntechnology that not only validates the information appended to the ledger but\nalso ensures the order in which it is appended across all the nodes. It is the\nfoundation of its security, accountability and trust. While many researchers\nare working on improving the current protocol to be quantum resistant,\nfault-tolerant, and energy-efficient. Others are focused on developing\ndifferent variants of the protocol, best suited for specific use cases. In this\npaper, we shall review different consensus protocols of distributed ledger\ntechnologies and their implementations. We shall also review their properties,\nconcept and similar-work followed by a brief analysis.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 10:04:39 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 05:14:58 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Wahab", "Abdul", ""], ["Mehmood", "Waqas", ""]]}, {"id": "1810.03464", "submitter": "Peng Gao", "authors": "Peng Gao, Xusheng Xiao, Zhichun Li, Kangkook Jee, Fengyuan Xu, Sanjeev\n  R. Kulkarni, Prateek Mittal", "title": "A Query System for Efficiently Investigating Complex Attack Behaviors\n  for Enterprise Security", "comments": "demo paper, 4 pages. arXiv admin note: text overlap with\n  arXiv:1806.02290", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for countering Advanced Persistent Threat (APT) attacks has led to\nthe solutions that ubiquitously monitor system activities in each enterprise\nhost, and perform timely attack investigation over the monitoring data for\nuncovering the attack sequence. However, existing general-purpose query systems\nlack explicit language constructs for expressing key properties of major attack\nbehaviors, and their semantics-agnostic design often produces inefficient\nexecution plans for queries. To address these limitations, we build AIQL, a\nnovel query system that is designed with novel types of domain-specific\noptimizations to enable efficient attack investigation. AIQL provides (1)\ndomain-specific data model and storage for storing the massive system\nmonitoring data, (2) a domain-specific query language, Attack Investigation\nQuery Language (AIQL) that integrates critical primitives for expressing major\nattack behaviors, and (3) an optimized query engine based on the\ncharacteristics of the data and the semantics of the query to efficiently\nschedule the execution. We have deployed AIQL in NEC Labs America comprising\n150 hosts. In our demo, we aim to show the complete usage scenario of AIQL by\n(1) performing an APT attack in a controlled environment, and (2) using AIQL to\ninvestigate such attack by querying the collected system monitoring data that\ncontains the attack traces. The audience will have the option to perform the\nAPT attack themselves under our guidance, and interact with the system and\ninvestigate the attack via issuing queries and checking the query results\nthrough our web UI.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 22:27:07 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 03:38:24 GMT"}, {"version": "v3", "created": "Tue, 19 Mar 2019 15:20:19 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Gao", "Peng", ""], ["Xiao", "Xusheng", ""], ["Li", "Zhichun", ""], ["Jee", "Kangkook", ""], ["Xu", "Fengyuan", ""], ["Kulkarni", "Sanjeev R.", ""], ["Mittal", "Prateek", ""]]}, {"id": "1810.03487", "submitter": "Sanghyun Hong", "authors": "Sanghyun Hong, Michael Davinroy, Yi\\v{g}itcan Kaya, Stuart Nevans\n  Locke, Ian Rackow, Kevin Kulda, Dana Dachman-Soled, Tudor Dumitra\\c{s}", "title": "Security Analysis of Deep Neural Networks Operating in the Presence of\n  Cache Side-Channel Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has introduced attacks that extract the architecture information\nof deep neural networks (DNN), as this knowledge enhances an adversary's\ncapability to conduct black-box attacks against the model. This paper presents\nthe first in-depth security analysis of DNN fingerprinting attacks that exploit\ncache side-channels. First, we define the threat model for these attacks: our\nadversary does not need the ability to query the victim model; instead, she\nruns a co-located process on the host machine victim's deep learning (DL)\nsystem is running and passively monitors the accesses of the target functions\nin the shared framework. Second, we introduce DeepRecon, an attack that\nreconstructs the architecture of the victim network by using the internal\ninformation extracted via Flush+Reload, a cache side-channel technique. Once\nthe attacker observes function invocations that map directly to architecture\nattributes of the victim network, the attacker can reconstruct the victim's\nentire network architecture. In our evaluation, we demonstrate that an attacker\ncan accurately reconstruct two complex networks (VGG19 and ResNet50) having\nobserved only one forward propagation. Based on the extracted architecture\nattributes, we also demonstrate that an attacker can build a meta-model that\naccurately fingerprints the architecture and family of the pre-trained model in\na transfer learning setting. From this meta-model, we evaluate the importance\nof the observed attributes in the fingerprinting process. Third, we propose and\nevaluate new framework-level defense techniques that obfuscate our attacker's\nobservations. Our empirical security analysis represents a step toward\nunderstanding the DNNs' vulnerability to cache side-channel attacks.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 14:21:46 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 05:13:52 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 02:13:40 GMT"}, {"version": "v4", "created": "Fri, 31 Jan 2020 17:12:52 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Hong", "Sanghyun", ""], ["Davinroy", "Michael", ""], ["Kaya", "Yi\u01e7itcan", ""], ["Locke", "Stuart Nevans", ""], ["Rackow", "Ian", ""], ["Kulda", "Kevin", ""], ["Dachman-Soled", "Dana", ""], ["Dumitra\u015f", "Tudor", ""]]}, {"id": "1810.03510", "submitter": "Ramin Soltani", "authors": "Ramin Soltani, Dennis Goeckel, Don Towsley, Amir Houmansadr", "title": "Fundamental Limits of Covert Bit Insertion in Packets", "comments": "This work has been presented at the 56th Annual Allerton Conference\n  on Communication, Control, and Computing, October 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covert communication is necessary when revealing the mere existence of a\nmessage leaks sensitive information to an attacker. Consider a network link\nwhere an authorized transmitter Jack sends packets to an authorized receiver\nSteve, and the packets visit Alice, Willie, and Bob, respectively, before they\nreach Steve. Covert transmitter Alice wishes to alter the packet stream in some\nway to send information to covert receiver Bob without watchful and capable\nadversary Willie being able to detect the presence of the message. In our\nprevious works, we addressed two techniques for such covert transmission from\nAlice to Bob: packet insertion and packet timing. In this paper, we consider\ncovert communication via bit insertion in packets with available space (e.g.,\nwith size less than the maximum transmission unit). We consider three\nscenarios: 1) packet sizes are independent and identically distributed (i.i.d.)\nwith a probability mass function (pmf) whose support is a set of one bit spaced\nvalues; 2) packet sizes are i.i.d. with a pmf whose support is arbitrary; 3)\npacket sizes may be dependent. For the first and second assumptions, we show\nthat Alice can covertly insert $\\mathcal{O}(\\sqrt{n})$ bits of information in a\nflow of $n$ packets; conversely, if she inserts $\\omega(\\sqrt{n})$ bits of\ninformation, Willie can detect her with arbitrarily small error probability.\nFor the third assumption, we prove Alice can covertly insert on average\n$\\mathcal{O}(c(n)/\\sqrt{n})$ bits in a sequence of $n$ packets, where $c(n)$ is\nthe average number of conditional pmf of packet sizes given the history, with a\nsupport of at least size two.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 14:57:32 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Soltani", "Ramin", ""], ["Goeckel", "Dennis", ""], ["Towsley", "Don", ""], ["Houmansadr", "Amir", ""]]}, {"id": "1810.03568", "submitter": "Vincent Primault", "authors": "Primault Vincent, Boutet Antoine, Ben Mokhtar Sonia and Brunie Lionel", "title": "The Long Road to Computational Location Privacy: A Survey", "comments": "IEEE Communications Surveys & Tutorials", "journal-ref": null, "doi": "10.1109/COMST.2018.2873950", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread adoption of continuously connected smartphones and tablets\ndeveloped the usage of mobile applications, among which many use location to\nprovide geolocated services. These services provide new prospects for users:\ngetting directions to work in the morning, leaving a check-in at a restaurant\nat noon and checking next day's weather in the evening are possible right from\nany mobile device embedding a GPS chip. In these location-based applications,\nthe user's location is sent to a server, which uses them to provide contextual\nand personalised answers. However, nothing prevents the latter from gathering,\nanalysing and possibly sharing the collected information, which opens the door\nto many privacy threats. Indeed, mobility data can reveal sensitive information\nabout users, among which one's home, work place or even religious and political\npreferences. For this reason, many privacy-preserving mechanisms have been\nproposed these last years to enhance location privacy while using geolocated\nservices. This article surveys and organises contributions in this area from\nclassical building blocks to the most recent developments of privacy threats\nand location privacy-preserving mechanisms. We divide the protection mechanisms\nbetween online and offline use cases, and organise them into six categories\ndepending on the nature of their algorithm. Moreover, this article surveys the\nevaluation metrics used to assess protection mechanisms in terms of privacy,\nutility and performance. Finally, open challenges and new directions to address\nthe problem of computational location privacy are pointed out and discussed.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 16:39:51 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Vincent", "Primault", ""], ["Antoine", "Boutet", ""], ["Sonia", "Ben Mokhtar", ""], ["Lionel", "Brunie", ""]]}, {"id": "1810.03646", "submitter": "Ming-Deh Huang", "authors": "Ming-Deh A. Huang", "title": "Trilinear maps for cryptography II", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We continue to study the construction of cryptographic trilinear maps\ninvolving abelian varieties over finite fields. We introduce Weil descent as a\ntool to strengthen the security of a trilinear map. We form the trilinear map\non the descent variety of an abelian variety of small dimension defined over a\nfinite field of a large extension degree over a ground field. The descent\nbases, with respect to which the descents are performed, are trapdoor secrets\nfor efficient construction of the trilinear map which pairs three trapdoor\nDDH-groups. The trilinear map also provides efficient public identity testing\nfor the third group. We present a concrete construction involving the jacobian\nvarieties of hyperelliptic curves.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 18:21:15 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 06:53:29 GMT"}, {"version": "v3", "created": "Thu, 18 Oct 2018 04:00:14 GMT"}, {"version": "v4", "created": "Fri, 19 Oct 2018 03:01:01 GMT"}, {"version": "v5", "created": "Wed, 24 Oct 2018 17:54:27 GMT"}, {"version": "v6", "created": "Wed, 6 Feb 2019 01:06:38 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Huang", "Ming-Deh A.", ""]]}, {"id": "1810.03808", "submitter": "Nicola Paoletti", "authors": "Nicola Paoletti, Zhihao Jiang, Md Ariful Islam, Houssam Abbas, Rahul\n  Mangharam, Shan Lin, Zachary Gruber, Scott A. Smolka", "title": "Synthesizing Stealthy Reprogramming Attacks on Cardiac Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An Implantable Cardioverter Defibrillator (ICD) is a medical device used for\nthe detection of potentially fatal cardiac arrhythmia and their treatment\nthrough the delivery of electrical shocks intended to restore normal heart\nrhythm. An ICD reprogramming attack seeks to alter the device's parameters to\ninduce unnecessary shocks and, even more egregious, prevent required therapy.\nIn this paper, we present a formal approach for the synthesis of ICD\nreprogramming attacks that are both effective, i.e., lead to fundamental\nchanges in the required therapy, and stealthy, i.e., involve minimal changes to\nthe nominal ICD parameters. We focus on the discrimination algorithm underlying\nBoston Scientific devices (one of the principal ICD manufacturers) and\nformulate the synthesis problem as one of multi-objective optimization. Our\nsolution technique is based on an Optimization Modulo Theories encoding of the\nproblem and allows us to derive device parameters that are optimal with respect\nto the effectiveness-stealthiness tradeoff (i.e., lie along the corresponding\nPareto front). To the best of our knowledge, our work is the first to derive\nsystematic ICD reprogramming attacks designed to maximize therapy disruption\nwhile minimizing detection. To evaluate our technique, we employ an extensive\ndataset of synthetic EGMs (cardiac signals), each generated with a prescribed\narrhythmia, allowing us to synthesize attacks tailored to the victim's cardiac\ncondition. Our approach readily generalizes to unseen signals, representing the\nunknown EGM of the victim patient.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 04:27:00 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Paoletti", "Nicola", ""], ["Jiang", "Zhihao", ""], ["Islam", "Md Ariful", ""], ["Abbas", "Houssam", ""], ["Mangharam", "Rahul", ""], ["Lin", "Shan", ""], ["Gruber", "Zachary", ""], ["Smolka", "Scott A.", ""]]}, {"id": "1810.03977", "submitter": "Dinesh Kumar Amara", "authors": "Amara Dinesh Kumar, Vinayakumar R, Soman KP", "title": "DeepImageSpam: Deep Learning based Image Spam Detection", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hackers and spammers are employing innovative and novel techniques to deceive\nnovice and even knowledgeable internet users. Image spam is one of such\ntechnique where the spammer varies and changes some portion of the image such\nthat it is indistinguishable from the original image fooling the users. This\npaper proposes a deep learning based approach for image spam detection using\nthe convolutional neural networks which uses a dataset with 810 natural images\nand 928 spam images for classification achieving an accuracy of 91.7%\noutperforming the existing image processing and machine learning techniques\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 09:35:01 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Kumar", "Amara Dinesh", ""], ["R", "Vinayakumar", ""], ["KP", "Soman", ""]]}, {"id": "1810.04538", "submitter": "Lei Ma", "authors": "Lei Ma, Felix Juefei-Xu, Minhui Xue, Qiang Hu, Sen Chen, Bo Li, Yang\n  Liu, Jianjun Zhao, Jianxiong Yin, and Simon See", "title": "Secure Deep Learning Engineering: A Software Quality Assurance\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decades, deep learning (DL) systems have achieved tremendous\nsuccess and gained great popularity in various applications, such as\nintelligent machines, image processing, speech processing, and medical\ndiagnostics. Deep neural networks are the key driving force behind its recent\nsuccess, but still seem to be a magic black box lacking interpretability and\nunderstanding. This brings up many open safety and security issues with\nenormous and urgent demands on rigorous methodologies and engineering practice\nfor quality enhancement. A plethora of studies have shown that the\nstate-of-the-art DL systems suffer from defects and vulnerabilities that can\nlead to severe loss and tragedies, especially when applied to real-world\nsafety-critical applications. In this paper, we perform a large-scale study and\nconstruct a paper repository of 223 relevant works to the quality assurance,\nsecurity, and interpretation of deep learning. We, from a software quality\nassurance perspective, pinpoint challenges and future opportunities towards\nuniversal secure deep learning engineering. We hope this work and the\naccompanied paper repository can pave the path for the software engineering\ncommunity towards addressing the pressing industrial demand of secure\nintelligent applications.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 14:04:08 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Ma", "Lei", ""], ["Juefei-Xu", "Felix", ""], ["Xue", "Minhui", ""], ["Hu", "Qiang", ""], ["Chen", "Sen", ""], ["Li", "Bo", ""], ["Liu", "Yang", ""], ["Zhao", "Jianjun", ""], ["Yin", "Jianxiong", ""], ["See", "Simon", ""]]}, {"id": "1810.04607", "submitter": "Sara Hosseinzadeh Kassani", "authors": "Uchi Ugobame Uchibeke, Sara Hosseinzadeh Kassani, Kevin A. Schneider,\n  Ralph Deters", "title": "Blockchain access control Ecosystem for Big Data security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the advancement in modern technologies has experienced an\nexplosion of huge data sets being captured and recorded in different fields,\nbut also given rise to concerns the security and protection of data storage,\ntransmission, processing, and access to data. The blockchain is a distributed\nledger that records transactions in a secure, flexible, verifiable and\npermanent way. Transactions in a blockchain can be an exchange of an asset, the\nexecution of the terms of a smart contract, or an update to a record. In this\npaper, we have developed a blockchain access control ecosystem that gives asset\nowners the sovereign right to effectively manage access control of large data\nsets and protect against data breaches. The Linux Foundation's Hyperledger\nFabric blockchain is used to run the business network while the Hyperledger\ncomposer tool is used to implement the smart contracts or transaction\nprocessing functions that run on the blockchain network.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 16:09:41 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 03:34:51 GMT"}, {"version": "v3", "created": "Sun, 22 Dec 2019 22:09:10 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Uchibeke", "Uchi Ugobame", ""], ["Kassani", "Sara Hosseinzadeh", ""], ["Schneider", "Kevin A.", ""], ["Deters", "Ralph", ""]]}, {"id": "1810.04654", "submitter": "Yung-Wen Liu", "authors": "Huiying Mao, Yung-wen Liu, Yuting Jia, Jay Nanduri", "title": "Adaptive Fraud Detection System Using Dynamic Risk Features", "comments": "19 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  eCommerce transaction frauds keep changing rapidly. This is the major issue\nthat prevents eCommerce merchants having a robust machine learning model for\nfraudulent transactions detection. The root cause of this problem is that rapid\nchanging fraud patterns alters underlying data generating system and causes the\nperformance deterioration for machine learning models. This phenomenon in\nstatistical modeling is called \"Concept Drift\". To overcome this issue, we\npropose an approach which adds dynamic risk features as model inputs. Dynamic\nrisk features are a set of features built on entity profile with fraud\nfeedback. They are introduced to quantify the fluctuation of probability\ndistribution of risk features from certain entity profile caused by concept\ndrift. In this paper, we also illustrate why this strategy can successfully\nhandle the effect of concept drift under statistical learning framework. We\nalso validate our approach on multiple businesses in production and have\nverified that the proposed dynamic model has a superior ROC curve than a static\nmodel built on the same data and training parameters.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 17:31:16 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Mao", "Huiying", ""], ["Liu", "Yung-wen", ""], ["Jia", "Yuting", ""], ["Nanduri", "Jay", ""]]}, {"id": "1810.04660", "submitter": "Emma Dauterman", "authors": "Emma Dauterman, Henry Corrigan-Gibbs, David Mazi\\`eres, Dan Boneh,\n  Dominic Rizzo", "title": "True2F: Backdoor-resistant authentication tokens", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present True2F, a system for second-factor authentication that provides\nthe benefits of conventional authentication tokens in the face of phishing and\nsoftware compromise, while also providing strong protection against token\nfaults and backdoors. To do so, we develop new lightweight two-party protocols\nfor generating cryptographic keys and ECDSA signatures, and we implement new\nprivacy defenses to prevent cross-origin token-fingerprinting attacks. To\nfacilitate real-world deployment, our system is backwards-compatible with\ntoday's U2F-enabled web services and runs on commodity hardware tokens after a\nfirmware modification. A True2F-protected authentication takes just 57ms to\ncomplete on the token, compared with 23ms for unprotected U2F.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 17:43:53 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2019 07:58:26 GMT"}, {"version": "v3", "created": "Tue, 6 Aug 2019 23:54:09 GMT"}, {"version": "v4", "created": "Sun, 11 Aug 2019 17:44:40 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Dauterman", "Emma", ""], ["Corrigan-Gibbs", "Henry", ""], ["Mazi\u00e8res", "David", ""], ["Boneh", "Dan", ""], ["Rizzo", "Dominic", ""]]}, {"id": "1810.04668", "submitter": "Margit Antal", "authors": "Margit Antal and Elod Egyed-Zsigmond", "title": "Intrusion Detection Using Mouse Dynamics", "comments": "Submitted to IET Biometrics on 23 May 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared to other behavioural biometrics, mouse dynamics is a less explored\narea. General purpose data sets containing unrestricted mouse usage data are\nusually not available. The Balabit data set was released in 2016 for a data\nscience competition, which against the few subjects, can be considered the\nfirst adequate publicly available one. This paper presents a performance\nevaluation study on this data set for impostor detection. The existence of very\nshort test sessions makes this data set challenging. Raw data were segmented\ninto mouse move, point and click and drag and drop types of mouse actions, then\nseveral features were extracted. In contrast to keystroke dynamics, mouse data\nis not sensitive, therefore it is possible to collect negative mouse dynamics\ndata and to use two-class classifiers for impostor detection. Both action- and\nset of actions-based evaluations were performed. Set of actions-based\nevaluation achieves 0.92 AUC on the test part of the data set. However, the\nsame type of evaluation conducted on the training part of the data set resulted\nin maximal AUC (1) using only 13 actions. Drag and drop mouse actions proved to\nbe the best actions for impostor detection.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 18:25:02 GMT"}], "update_date": "2018-10-14", "authors_parsed": [["Antal", "Margit", ""], ["Egyed-Zsigmond", "Elod", ""]]}, {"id": "1810.04755", "submitter": "Maria Leonor Pacheco", "authors": "Samuel Jero, Maria Leonor Pacheco, Dan Goldwasser and Cristina\n  Nita-Rotaru", "title": "Leveraging Textual Specifications for Grammar-based Fuzzing of Network\n  Protocols", "comments": null, "journal-ref": "The Thirty-First AAAI Conference on Innovative Applications of\n  Artificial Intelligence, IAAI 2019", "doi": "10.1609/aaai.v33i01.33019478", "report-no": null, "categories": "cs.CR cs.CL cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grammar-based fuzzing is a technique used to find software vulnerabilities by\ninjecting well-formed inputs generated following rules that encode application\nsemantics. Most grammar-based fuzzers for network protocols rely on human\nexperts to manually specify these rules. In this work we study automated\nlearning of protocol rules from textual specifications (i.e. RFCs). We evaluate\nthe automatically extracted protocol rules by applying them to a\nstate-of-the-art fuzzer for transport protocols and show that it leads to a\nsmaller number of test cases while finding the same attacks as the system that\nuses manually specified rules.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 21:42:29 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Jero", "Samuel", ""], ["Pacheco", "Maria Leonor", ""], ["Goldwasser", "Dan", ""], ["Nita-Rotaru", "Cristina", ""]]}, {"id": "1810.04760", "submitter": "Yaliang Li", "authors": "Yaliang Li, Houping Xiao, Zhan Qin, Chenglin Miao, Lu Su, Jing Gao,\n  Kui Ren, Bolin Ding", "title": "Towards Differentially Private Truth Discovery for Crowd Sensing Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, crowd sensing becomes increasingly more popular due to the\nubiquitous usage of mobile devices. However, the quality of such\nhuman-generated sensory data varies significantly among different users. To\nbetter utilize sensory data, the problem of truth discovery, whose goal is to\nestimate user quality and infer reliable aggregated results through\nquality-aware data aggregation, has emerged as a hot topic. Although the\nexisting truth discovery approaches can provide reliable aggregated results,\nthey fail to protect the private information of individual users. Moreover,\ncrowd sensing systems typically involve a large number of participants, making\nencryption or secure multi-party computation based solutions difficult to\ndeploy. To address these challenges, in this paper, we propose an efficient\nprivacy-preserving truth discovery mechanism with theoretical guarantees of\nboth utility and privacy. The key idea of the proposed mechanism is to perturb\ndata from each user independently and then conduct weighted aggregation among\nusers' perturbed data. The proposed approach is able to assign user weights\nbased on information quality, and thus the aggregated results will not deviate\nmuch from the true results even when large noise is added. We adapt local\ndifferential privacy definition to this privacy-preserving task and demonstrate\nthe proposed mechanism can satisfy local differential privacy while preserving\nhigh aggregation accuracy. We formally quantify utility and privacy trade-off\nand further verify the claim by experiments on both synthetic data and a\nreal-world crowd sensing system.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 22:02:11 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Li", "Yaliang", ""], ["Xiao", "Houping", ""], ["Qin", "Zhan", ""], ["Miao", "Chenglin", ""], ["Su", "Lu", ""], ["Gao", "Jing", ""], ["Ren", "Kui", ""], ["Ding", "Bolin", ""]]}, {"id": "1810.04779", "submitter": "Georgios Portokalidis", "authors": "Georgios Kontaxis and Angelos D. Keromytis and Georgios Portokalidis", "title": "Redirect2Own: Protecting the Intellectual Property of User-uploaded\n  Content through Off-site Indirect Access", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social networking services have attracted millions of users, including\nindividuals, professionals, and companies, that upload massive amounts of\ncontent, such as text, pictures, and video, every day. Content creators retain\nthe intellectual property (IP) rights on the content they share with these\nnetworks, however, very frequently they implicitly grant them, a sometimes,\noverly broad license to use that content, which enables the services to use it\nin possibly undesirable ways. For instance, Facebook claims a transferable,\nsub-licensable, royalty-free, worldwide license on all user-provided content.\nProfessional content creators, like photographers, are particularly affected.\nIn this paper we propose a design for decoupling user data from social\nnetworking services without any loss of functionality for the users. Our design\nsuggests that user data are kept off the social networking service, in third\nparties that enable the hosting of user-generated content under terms of\nservice and overall environment (e.g., a different location) that better suit\nthe user's needs and wishes. At the same time, indirection schemata are\nseamlessly integrated in the social networking service, without any cooperation\nfrom the server side necessary, so that users can transparently access the\noff-site data just as they would if hosted in-site. We have implemented our\ndesign as an extension for the Chrome Web browser, called Redirect2Own, and\nshow that it incurs negligible overhead on accessing 'redirected' content. We\noffer the extension as free software and its code as an open-source project.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 23:34:54 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Kontaxis", "Georgios", ""], ["Keromytis", "Angelos D.", ""], ["Portokalidis", "Georgios", ""]]}, {"id": "1810.04971", "submitter": "Kilian Becher", "authors": "Kilian Becher and Martin Beck and Thorsten Strufe", "title": "An Enhanced Approach to Cloud-based Privacy-preserving Benchmarking\n  (Long Version)", "comments": "Long version with appendix containing correctness and security proofs\n  as well as details regarding the computational and communication complexity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benchmarking is an important measure for companies to investigate their\nperformance and to increase efficiency. As companies usually are reluctant to\nprovide their key performance indicators (KPIs) for public benchmarks,\nprivacy-preserving benchmarking systems are required. In this paper, we present\nan enhanced privacy-preserving benchmarking protocol that is based on\nhomomorphic encryption. It enables cloud-based KPI comparison including the\nstatistical measures mean, variance, median, maximum, best-in-class, bottom\nquartile, and top quartile. The theoretical and empirical evaluation of our\nbenchmarking system underlines its practicability. Even under worst-case\nassumptions regarding connection quality and asymmetric encryption\nkey-security, it fulfils the performance requirements of typical KPI\nbenchmarking systems.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 12:11:06 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 19:03:58 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Becher", "Kilian", ""], ["Beck", "Martin", ""], ["Strufe", "Thorsten", ""]]}, {"id": "1810.05005", "submitter": "Maurizio Pizzonia", "authors": "Federico Griscioli and Maurizio Pizzonia", "title": "USBCaptchaIn: Preventing (Un)Conventional Attacks from Promiscuously\n  Used USB Devices in Industrial Control Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial Control Systems (ICS) are sensible targets for high profile\nattackers and advanced persistent threats, which are known to exploit USB thumb\ndrives as an effective spreading vector. In ICSes, thumb drives are widely used\nto transfer files among disconnected systems and represent a serious security\nrisks, since, they may be promiscuously used in both critical and regular\nsystems. The threats come both from malware hidden in files stored in the thumb\ndrives and from BadUSB attacks [16]. BadUSB leverages the modification of\nfirmware of USB devices in order to mimic the behaviour of a keyboard and send\nmalicious commands to the host. We present a solution that allows a promiscuous\nuse of USB thumbs drives while protecting critical machines from malware, that\nspread by regular file infection or by firmware infection. The main component\nof the architecture we propose is an hardware, called USBCaptchaIn, intended to\nbe in the middle between a critical machine and all USB devices. We do not\nrequire users to change the way they use thumb drives. To avoid human-errors,\nwe do not require users to take any decision. The proposed approach is highly\ncompatible with already deployed products of a ICS environment and proactively\nblocks malware before they reach their targets. We describe our solution,\nprovide a thorough analysis of the security of our approach in the ICS context,\nand report the informal feedback of some experts regarding our first\nprototypes.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 13:24:42 GMT"}, {"version": "v2", "created": "Sat, 16 Mar 2019 17:47:46 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Griscioli", "Federico", ""], ["Pizzonia", "Maurizio", ""]]}, {"id": "1810.05083", "submitter": "Anna Pappa Dr", "authors": "Myrto Arapinis, Elham Kashefi, Nikolaos Lamprou, Anna Pappa", "title": "Definitions and Analysis of Quantum E-voting Protocols", "comments": "Changes from previous version: introduced security definitions for\n  voting properties. 31 pages main text, 8 pages appendix", "journal-ref": "ACM Transactions on Quantum Computing 2, 1, Article 4 (2021)", "doi": "10.1145/3450144", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances indicate that quantum computers will soon be reality.\nMotivated by this ever more realistic threat for existing classical\ncryptographic protocols, researchers have developed several schemes to resist\n\"quantum attacks\". In particular, for electronic voting, several e-voting\nschemes relying on properties of quantum mechanics have been proposed. However,\neach of these proposals comes with a different and often not well-articulated\ncorruption model, has different objectives, and is accompanied by security\nclaims which are never formalized and are at best justified only against\nspecific attacks. To address this, we propose the first formal security\ndefinitions for quantum e-voting protocols. With these at hand, we systematize\nand evaluate the security of previously-proposed quantum e-voting protocols; we\nexamine the claims of these works concerning privacy, correctness and\nverifiability, and if they are correctly attributed to the proposed protocols.\nIn all non-trivial cases, we identify specific quantum attacks that violate\nthese properties. We argue that the cause of these failures lies in the absence\nof formal security models and references to the existing cryptographic\nliterature.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 15:32:42 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 16:59:07 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 10:48:10 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Arapinis", "Myrto", ""], ["Kashefi", "Elham", ""], ["Lamprou", "Nikolaos", ""], ["Pappa", "Anna", ""]]}, {"id": "1810.05100", "submitter": "Nalin Asanka Gamagedara Arachchilage", "authors": "Chamila Wijayarathna and Nalin Asanka Gamagedara Arachchilage", "title": "A methodology to Evaluate the Usability of Security APIs", "comments": "6", "journal-ref": "IEEE International Conference on Information and Automation for\n  Sustainability (ICIAfS), 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing number of cyber-attacks demotivate people to use Information and\nCommunication Technology (ICT) for industrial as well as day to day work. A\nmain reason for the increasing number of cyber-attacks is mistakes that\nprogrammers make while developing software applications that are caused by\nusability issues exist in security Application Programming Interfaces (APIs).\nThese mistakes make software vulnerable to cyber-attacks. In this paper, we\nattempt to take a step closer to solve this problem by proposing a methodology\nto evaluate the usability and identify usability issues exist in security APIs.\nBy conducting a review of previous research, we identified 5 usability\nevaluation methodologies that have been proposed to evaluate the usability of\ngeneral APIs and characteristics of those methodologies that would affect when\nusing these methodologies to evaluate security APIs. Based on the findings, we\npropose a methodology to evaluate the usability of security APIs.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 16:04:51 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Wijayarathna", "Chamila", ""], ["Arachchilage", "Nalin Asanka Gamagedara", ""]]}, {"id": "1810.05162", "submitter": "Ruizhi Deng", "authors": "Chaowei Xiao, Ruizhi Deng, Bo Li, Fisher Yu, Mingyan Liu, and Dawn\n  Song", "title": "Characterizing Adversarial Examples Based on Spatial Consistency\n  Information for Semantic Segmentation", "comments": "Accepted to ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have been widely applied in various recognition\ntasks. However, recently DNNs have been shown to be vulnerable against\nadversarial examples, which can mislead DNNs to make arbitrary incorrect\npredictions. While adversarial examples are well studied in classification\ntasks, other learning problems may have different properties. For instance,\nsemantic segmentation requires additional components such as dilated\nconvolutions and multiscale processing. In this paper, we aim to characterize\nadversarial examples based on spatial context information in semantic\nsegmentation. We observe that spatial consistency information can be\npotentially leveraged to detect adversarial examples robustly even when a\nstrong adaptive attacker has access to the model and detection strategies. We\nalso show that adversarial examples based on attacks considered within the\npaper barely transfer among models, even though transferability is common in\nclassification. Our observations shed new light on developing adversarial\nattacks and defenses to better understand the vulnerabilities of DNNs.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 17:03:44 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Xiao", "Chaowei", ""], ["Deng", "Ruizhi", ""], ["Li", "Bo", ""], ["Yu", "Fisher", ""], ["Liu", "Mingyan", ""], ["Song", "Dawn", ""]]}, {"id": "1810.05206", "submitter": "Dawei Yang", "authors": "Chaowei Xiao, Dawei Yang, Bo Li, Jia Deng, Mingyan Liu", "title": "MeshAdv: Adversarial Meshes for Visual Recognition", "comments": "Published in IEEE CVPR2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly expressive models such as deep neural networks (DNNs) have been widely\napplied to various applications. However, recent studies show that DNNs are\nvulnerable to adversarial examples, which are carefully crafted inputs aiming\nto mislead the predictions. Currently, the majority of these studies have\nfocused on perturbation added to image pixels, while such manipulation is not\nphysically realistic. Some works have tried to overcome this limitation by\nattaching printable 2D patches or painting patterns onto surfaces, but can be\npotentially defended because 3D shape features are intact. In this paper, we\npropose meshAdv to generate \"adversarial 3D meshes\" from objects that have rich\nshape features but minimal textural variation. To manipulate the shape or\ntexture of the objects, we make use of a differentiable renderer to compute\naccurate shading on the shape and propagate the gradient. Extensive experiments\nshow that the generated 3D meshes are effective in attacking both classifiers\nand object detectors. We evaluate the attack under different viewpoints. In\naddition, we design a pipeline to perform black-box attack on a photorealistic\nrenderer with unknown rendering parameters.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 19:01:10 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 19:43:54 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Xiao", "Chaowei", ""], ["Yang", "Dawei", ""], ["Li", "Bo", ""], ["Deng", "Jia", ""], ["Liu", "Mingyan", ""]]}, {"id": "1810.05234", "submitter": "Jiayu Zhang", "authors": "Jiayu Zhang", "title": "Delegating Quantum Computation in the Quantum Random Oracle Model", "comments": "41 pages, 1 figures. Update to be consistent with the proceeding\n  version", "journal-ref": "Theory of Cryptography, Part II, 2019, page 30-60", "doi": "10.1007/978-3-030-36033-7_2", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A delegation scheme allows a computationally weak client to use a server's\nresources to help it evaluate a complex circuit without leaking any information\nabout the input (other than its length) to the server. In this paper, we\nconsider delegation schemes for quantum circuits, where we try to minimize the\nquantum operations needed by the client. We construct a new scheme for\ndelegating a large circuit family, which we call \"C+P circuits\". \"C+P\" circuits\nare the circuits composed of Toffoli gates and diagonal gates. Our scheme is\nnon-interactive, requires very little quantum computation from the client\n(proportional to input length but independent of the circuit size), and can be\nproved secure in the quantum random oracle model, without relying on additional\nassumptions, such as the existence of fully homomorphic encryption. In practice\nthe random oracle can be replaced by an appropriate hash function or block\ncipher, for example, SHA-3, AES.\n  This protocol allows a client to delegate the most expensive part of some\nquantum algorithms, for example, Shor's algorithm. The previous protocols that\nare powerful enough to delegate Shor's algorithm require either many rounds of\ninteractions or the existence of FHE. The protocol requires asymptotically\nfewer quantum gates on the client side compared to running Shor's algorithm\nlocally.\n  To hide the inputs, our scheme uses an encoding that maps one input qubit to\nmultiple qubits. We then provide a novel generalization of classical garbled\ncircuits (\"reversible garbled circuits\") to allow the computation of Toffoli\ncircuits on this encoding. We also give a technique that can support the\ncomputation of phase gates on this encoding.\n  To prove the security of this protocol, we study key dependent message(KDM)\nsecurity in the quantum random oracle model. KDM security was not previously\nstudied in quantum settings.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 20:18:13 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 21:36:06 GMT"}, {"version": "v3", "created": "Wed, 28 Nov 2018 22:50:29 GMT"}, {"version": "v4", "created": "Fri, 7 Dec 2018 08:13:11 GMT"}, {"version": "v5", "created": "Thu, 18 Jul 2019 14:56:25 GMT"}, {"version": "v6", "created": "Wed, 4 Sep 2019 14:54:03 GMT"}, {"version": "v7", "created": "Tue, 28 Apr 2020 10:54:03 GMT"}, {"version": "v8", "created": "Thu, 30 Apr 2020 04:30:39 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Zhang", "Jiayu", ""]]}, {"id": "1810.05292", "submitter": "Sara Hosseinzadeh Kassani", "authors": "Sara Hosseinzadeh Kassani, Ralph Deters", "title": "Leveraging protection and efficiency of query answering in heterogenous\n  RDF data using blockchain", "comments": "arXiv admin note: text overlap with arXiv:1810.04606", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Semantic Web, an extension of the current web, provides a common\nframework that makes data machine understandable and also allows data to be\nshared and reused across various applications. Resource Description Framework\n(RDF), a graph-based data model for describing things (entities), facilitates\ndata integration. Due to the explosion of the amount of RDF data, developing\ntools to support processing and answering of complex queries over the\nintegrated data has become challenging. To overcome this challenge in query\nprocessing in semantic data integration frameworks, we provide a view layer\ninserted between the heterogeneous data sources and user interface layer while\nensuring only authorized users are allowed access to the information. The view\nlayer must provide a support in terms of access, integration, querying,\nmanagement of data sources in a multi-user environment.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 00:03:14 GMT"}, {"version": "v2", "created": "Sun, 22 Dec 2019 22:18:52 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Kassani", "Sara Hosseinzadeh", ""], ["Deters", "Ralph", ""]]}, {"id": "1810.05365", "submitter": "Wei Cai", "authors": "Wei Cai, Zehua Wang, Jason B. Ernst, Zhen Hong, Chen Feng, Victor C.M.\n  Leung", "title": "Decentralized Applications: The Blockchain-Empowered Software System", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": "10.1109/ACCESS.2018.2870644", "report-no": null, "categories": "cs.DC cs.CR cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Blockchain technology has attracted tremendous attention in both academia and\ncapital market. However, overwhelming speculations on thousands of available\ncryptocurrencies and numerous initial coin offering (ICO) scams have also\nbrought notorious debates on this emerging technology. This paper traces the\ndevelopment of blockchain systems to reveal the importance of decentralized\napplications (dApps) and the future value of blockchain. We survey the\nstate-of-the-art dApps and discuss the direction of blockchain development to\nfulfill the desirable characteristics of dApps. The readers will gain an\noverview of dApp research and get familiar with recent developments in the\nblockchain.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 05:41:31 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Cai", "Wei", ""], ["Wang", "Zehua", ""], ["Ernst", "Jason B.", ""], ["Hong", "Zhen", ""], ["Feng", "Chen", ""], ["Leung", "Victor C. M.", ""]]}, {"id": "1810.05447", "submitter": "Saar Tochner", "authors": "Saar Tochner and Aviv Zohar", "title": "How to Pick Your Friends - A Game Theoretic Approach to P2P Overlay\n  Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major limitation of open P2P networks is the lack of strong identities.\nThis allows any agent to attack the system by creating multiple false personas,\nthereby disrupting the overlay network's connectivity and sabotaging its\noperation. In this paper, we explore practical ways to defend P2P networks from\nsuch attacks. To do so, we employ a game theoretic approach to the management\nof each peer's list of known nodes and to the overlay construction mechanisms\nthat utilize this list. We consider the interaction between defender and\nattacker agents as a zero-sum game. We show that the cost of attacks can be\ndriven up substantially if the defender utilizes available information about\npeers it chooses to connect to, such as their IP address. In addition to\ntheoretical analysis of the underlying game, we apply our approach to the\nBitcoin P2P network and derive effective strategies that guarantee a high\nsafety level against attacks.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 10:58:33 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Tochner", "Saar", ""], ["Zohar", "Aviv", ""]]}, {"id": "1810.05602", "submitter": "Stefan Rass", "authors": "Stefan Rass", "title": "Perfectly Secure Communication, based on Graph-Topological Addressing in\n  Unique-Neighborhood Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider network graphs $G=(V,E)$ in which adjacent nodes share common\nsecrets. In this setting, certain techniques for perfect end-to-end security\n(in the sense of confidentiality, authenticity (implying integrity) and\navailability, i.e., CIA+) can be made applicable without end-to-end shared\nsecrets and without computational intractability assumptions. To this end, we\nintroduce and study the concept of a unique-neighborhood network, in which\nnodes are uniquely identifiable upon their graph-topological neighborhood.\nWhile the concept is motivated by authentication, it may enjoy wider\napplicability as being a technology-agnostic (yet topology aware) form of\naddressing nodes in a network.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 16:46:07 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 12:36:24 GMT"}, {"version": "v3", "created": "Mon, 20 Apr 2020 17:03:30 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Rass", "Stefan", ""]]}, {"id": "1810.05692", "submitter": "Aloni Cohen", "authors": "Aloni Cohen, Kobbi Nissim", "title": "Linear Program Reconstruction in Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We briefly report on a successful linear program reconstruction attack\nperformed on a production statistical queries system and using a real dataset.\nThe attack was deployed in test environment in the course of the Aircloak\nChallenge bug bounty program and is based on the reconstruction algorithm of\nDwork, McSherry, and Talwar. We empirically evaluate the effectiveness of the\nalgorithm and a related algorithm by Dinur and Nissim with various dataset\nsizes, error rates, and numbers of queries in a Gaussian noise setting.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 19:27:25 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 18:49:37 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Cohen", "Aloni", ""], ["Nissim", "Kobbi", ""]]}, {"id": "1810.05711", "submitter": "Sadegh Momeni Milajerdi", "authors": "Sadegh M. Milajerdi, Birhanu Eshete, Rigel Gjomemo, V.N.\n  Venkatakrishnan", "title": "ProPatrol: Attack Investigation via Extracted High-Level Tasks", "comments": "The published version of this article will appear in proceedings of\n  the 14th International Conference on Information Systems Security in Dec 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel audit logs are an invaluable source of information in the forensic\ninvestigation of a cyber-attack. However, the coarse granularity of dependency\ninformation in audit logs leads to the construction of huge attack graphs which\ncontain false or inaccurate dependencies. To overcome this problem, we propose\na system, called ProPatrol, which leverages the open compartmentalized design\nin families of enterprise applications used in security-sensitive contexts\n(e.g., browser, chat client, email client). To achieve its goal, ProPatrol\ninfers a model for an application's high-level tasks as input-processing\ncompartments using purely the audit log events generated by that application.\nThe main benefit of this approach is that it does not rely on source code or\nbinary instrumentation, but only on a preliminary and general knowledge of an\napplication's architecture to bootstrap the analysis. Our experiments with\nenterprise-level attacks demonstrate that ProPatrol significantly cuts down the\nforensic investigation effort and quickly pinpoints the root- cause of attacks.\nProPatrol incurs less than 2% runtime overhead on a commodity operating system.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 20:25:11 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Milajerdi", "Sadegh M.", ""], ["Eshete", "Birhanu", ""], ["Gjomemo", "Rigel", ""], ["Venkatakrishnan", "V. N.", ""]]}, {"id": "1810.05725", "submitter": "Dhinaharan Nagamalai", "authors": "Marija Prokopijevi\\'c, Aleksandar Stan\\v{c}i\\'c, Jelena Vasiljevi\\'c,\n  \\v{Z}eljko Stojkovi\\'c, Goran Dimi\\'c, Jelena Sopta, Dalibor Risti\\'c and\n  Dhinaharan Nagamalai", "title": "Neural Network based classification of bone metastasis by primary\n  cacinoma", "comments": "13 pages, 9 figures", "journal-ref": "Computer Science & Information Technology (CS & IT), 7th\n  International Conference on Information Technology Convergence and Services\n  (ITCSE 2018), Vienna, Austria, May 26~27, 2018", "doi": "10.5121/csit.2018.80707", "report-no": null, "categories": "cs.CV cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks have been known for a long time as a tool for different types\nof classification, but only just in the last decade they have showed their\nentire power. Along with appearing of hardware that is capable to support\ndemanding matrix operations and parallel algorithms, the neural network, as a\nuniversal function approximation framework, turns out to be the most successful\nclassification method widely used in all fields of science. On the other side,\nmultifractal (MF) approach is an efficient way for quantitative description of\ncomplex structures [1] such as metastatic carcinoma, which recommends this\nmethod as an accurate tool for medical diagnostics. The only part that is\nmissing is classification method. The goal of this research is to describe and\napply a feed-forward neural network as an auxiliary diagnostic method for\nclassification of multifractal parameters in order to determine primary cancer.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 23:44:59 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Prokopijevi\u0107", "Marija", ""], ["Stan\u010di\u0107", "Aleksandar", ""], ["Vasiljevi\u0107", "Jelena", ""], ["Stojkovi\u0107", "\u017deljko", ""], ["Dimi\u0107", "Goran", ""], ["Sopta", "Jelena", ""], ["Risti\u0107", "Dalibor", ""], ["Nagamalai", "Dhinaharan", ""]]}, {"id": "1810.05864", "submitter": "Mohammad Ali", "authors": "Mohammad Ali, Javad Mohajeri, Mohammad-Reza Sadeghi", "title": "On the security of the hierarchical attribute based encryption scheme\n  proposed by Wang et al", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ciphertext-policy hierarchical attribute-based encryption (CP-HABE) is a\npromising cryptographic primitive for enforcing the fine-grained access control\nwith scalable key delegation and user revocation mechanisms on the outsourced\nencrypted data in a cloud. Wang et al. (2011) proposed the first CP-HABE scheme\nand showed that the scheme is semantically secure in the random oracle model\n[4, 5]. Due to some weakness in its key delegation mechanism, by presenting two\nattacks, we demonstrate the scheme does not offer any confidentiality and\nfine-grained access control. In this way, anyone who has just one attribute can\nrecover any outsourced encrypted data in the cloud.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 13:52:11 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Ali", "Mohammad", ""], ["Mohajeri", "Javad", ""], ["Sadeghi", "Mohammad-Reza", ""]]}, {"id": "1810.05921", "submitter": "Arunesh Sinha", "authors": "Ankit Shah, Arunesh Sinha, Rajesh Ganesan, Sushil Jajodia, Hasan Cam", "title": "Two Can Play That Game: An Adversarial Evaluation of a Cyber-alert\n  Inspection System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-security is an important societal concern. Cyber-attacks have increased\nin numbers as well as in the extent of damage caused in every attack. Large\norganizations operate a Cyber Security Operation Center (CSOC), which form the\nfirst line of cyber-defense. The inspection of cyber-alerts is a critical part\nof CSOC operations. A recent work, in collaboration with Army Research Lab, USA\nproposed a reinforcement learning (RL) based approach to prevent the\ncyber-alert queue length from growing large and overwhelming the defender.\nGiven the potential deployment of this approach to CSOCs run by US defense\nagencies, we perform a red team (adversarial) evaluation of this approach.\nFurther, with the recent attacks on learning systems, it is even more important\nto test the limits of this RL approach. Towards that end, we learn an\nadversarial alert generation policy that is a best response to the defender\ninspection policy. Surprisingly, we find the defender policy to be quite robust\nto the best response of the attacker. In order to explain this observation, we\nextend the earlier RL model to a game model and show that there exists defender\npolicies that can be robust against any adversarial policy. We also derive a\ncompetitive baseline from the game theory model and compare it to the RL\napproach. However, we go further to exploit assumptions made in the MDP in the\nRL model and discover an attacker policy that overwhelms the defender. We use a\ndouble oracle approach to retrain the defender with episodes from this\ndiscovered attacker policy. This made the defender robust to the discovered\nattacker policy and no further harmful attacker policies were discovered.\nOverall, the adversarial RL and double oracle approach in RL are general\ntechniques that are applicable to other RL usage in adversarial environments.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 20:01:54 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Shah", "Ankit", ""], ["Sinha", "Arunesh", ""], ["Ganesan", "Rajesh", ""], ["Jajodia", "Sushil", ""], ["Cam", "Hasan", ""]]}, {"id": "1810.05939", "submitter": "Xingpeng Li", "authors": "Xingpeng Li and Kory W. Hedman", "title": "Enhancing Power System Cyber-Security with Systematic Two-Stage\n  Detection Strategy", "comments": "11 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State estimation estimates the system condition in real-time and provides a\nbase case for other energy management system (EMS) applications including\nreal-time contingency analysis and security-constrained economic dispatch.\nRecent work in the literature shows malicious cyber-attack can inject false\nmeasurements that bypass traditional bad data detection in state estimation and\ncause actual overloads. Thus, it is very important to detect such cyber-attack.\nIn this paper, multiple metrics are proposed to monitor abnormal load\ndeviations and suspicious branch flow changes. A systematic two-stage approach\nis proposed to detect false data injection (FDI) cyber-attack. The first stage\ndetermines whether the system is under attack while the second stage identifies\nthe target branch. Numerical simulations verify that FDI can cause severe\nsystem violations and demonstrate the effectiveness of the proposed two-stage\nFDI detection (FDID) method. It is concluded that the proposed FDID approach\ncan efficiently detect FDI cyber-attack and identify the target branch, which\nwill substantially improve operators situation awareness in real-time.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 23:26:45 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 20:25:45 GMT"}, {"version": "v3", "created": "Wed, 24 Jul 2019 01:21:53 GMT"}, {"version": "v4", "created": "Fri, 29 Nov 2019 05:50:18 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Li", "Xingpeng", ""], ["Hedman", "Kory W.", ""]]}, {"id": "1810.06080", "submitter": "Andrew Paverd", "authors": "Fritz Alder, N. Asokan, Arseny Kurnikov, Andrew Paverd, Michael\n  Steiner", "title": "S-FaaS: Trustworthy and Accountable Function-as-a-Service using Intel\n  SGX", "comments": null, "journal-ref": null, "doi": "10.1145/3338466.3358916", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Function-as-a-Service (FaaS) is a recent and already very popular paradigm in\ncloud computing. The function provider need only specify the function to be\nrun, usually in a high-level language like JavaScript, and the service provider\norchestrates all the necessary infrastructure and software stacks. The function\nprovider is only billed for the actual computational resources used by the\nfunction invocation. Compared to previous cloud paradigms, FaaS requires\nsignificantly more fine-grained resource measurement mechanisms, e.g. to\nmeasure compute time and memory usage of a single function invocation with\nsub-second accuracy. Thanks to the short duration and stateless nature of\nfunctions, and the availability of multiple open-source frameworks, FaaS\nenables non-traditional service providers e.g. individuals or data centers with\nspare capacity. However, this exacerbates the challenge of ensuring that\nresource consumption is measured accurately and reported reliably. It also\nraises the issues of ensuring computation is done correctly and minimizing the\namount of information leaked to service providers.\n  To address these challenges, we introduce S-FaaS, the first architecture and\nimplementation of FaaS to provide strong security and accountability guarantees\nbacked by Intel SGX. To match the dynamic event-driven nature of FaaS, our\ndesign introduces a new key distribution enclave and a novel transitive\nattestation protocol. A core contribution of S-FaaS is our set of resource\nmeasurement mechanisms that securely measure compute time inside an enclave,\nand actual memory allocations. We have integrated S-FaaS into the popular\nOpenWhisk FaaS framework. We evaluate the security of our architecture, the\naccuracy of our resource measurement mechanisms, and the performance of our\nimplementation, showing that our resource measurement mechanisms add less than\n6.3% latency on standardized benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 19:08:05 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Alder", "Fritz", ""], ["Asokan", "N.", ""], ["Kurnikov", "Arseny", ""], ["Paverd", "Andrew", ""], ["Steiner", "Michael", ""]]}, {"id": "1810.06130", "submitter": "Alan Sherman", "authors": "Alan T. Sherman, Farid Javani, Haibin Zhang, and Enis Golaszewski", "title": "On the Origins and Variations of Blockchain Technologies", "comments": "14 pages, 3 tables, includes all references. A short version with ten\n  references will be submitted to IEEE Security & Privacy in October 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the origins of blockchain technologies to better understand the\nenduring needs they address. We identify the five key elements of a blockchain,\nshow embodiments of these elements, and examine how these elements come\ntogether to yield important properties in selected systems. To facilitate\ncomparing the many variations of blockchains, we also describe the four crucial\nroles of blockchain participants common to all blockchains. Our historical\nexploration highlights the 1979 work of David Chaum whose vault system embodies\nmany of the elements of blockchains.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 00:00:33 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Sherman", "Alan T.", ""], ["Javani", "Farid", ""], ["Zhang", "Haibin", ""], ["Golaszewski", "Enis", ""]]}, {"id": "1810.06230", "submitter": "Yikun Ban", "authors": "Yikun Ban, Xin Liu, Yitao Duan, Xue Liu, Wei Xu", "title": "No Place to Hide: Catching Fraudulent Entities in Tensors", "comments": "Proceedings of the 2019 World Wide Web Conference (WWW '19), May\n  13--17, 2019, San Francisco, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many approaches focus on detecting dense blocks in the tensor of multimodal\ndata to prevent fraudulent entities (e.g., accounts, links) from retweet\nboosting, hashtag hijacking, link advertising, etc. However, no existing method\nis effective to find the dense block if it only possesses high density on a\nsubset of all dimensions in tensors. In this paper, we novelly identify\ndense-block detection with dense-subgraph mining, by modeling a tensor into a\nweighted graph without any density information lost. Based on the weighted\ngraph, which we call information sharing graph (ISG), we propose an algorithm\nfor finding multiple densest subgraphs, D-Spot, that is faster (up to 11x\nfaster than the state-of-the-art algorithm) and can be computed in parallel. In\nan N-dimensional tensor, the entity group found by the ISG+D-Spot is at least\n1/2 of the optimum with respect to density, compared with the 1/N guarantee\nensured by competing methods. We use nine datasets to demonstrate that\nISG+D-Spot becomes new state-of-the-art dense-block detection method in terms\nof accuracy specifically for fraud detection.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 08:58:37 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 06:42:45 GMT"}, {"version": "v3", "created": "Wed, 17 Oct 2018 01:38:25 GMT"}, {"version": "v4", "created": "Sun, 21 Oct 2018 03:12:48 GMT"}, {"version": "v5", "created": "Sat, 23 Feb 2019 09:41:06 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Ban", "Yikun", ""], ["Liu", "Xin", ""], ["Duan", "Yitao", ""], ["Liu", "Xue", ""], ["Xu", "Wei", ""]]}, {"id": "1810.06333", "submitter": "Reza Parvaz", "authors": "Y. Khedmati, R. Parvaz, Y. Behroo", "title": "2D Hybrid chaos map for image security transform based on framelet and\n  cellular automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide some safe ways to transfer images securely by using\ncryptography and steganography methods. In order to enhance the security of the\nimage transmission, we introduce a new type of uniformly distributed 2D-hybrid\nchaos map based on Logistic, Sine and Tent maps, and use the cellular automata\nand discrete framelet transform in the proposed algorithms and also mix the\nposition of the image pixels by apply kinds of shifts. To show that the\nproposed algorithms are able to resist various attacks, different types of\nsimulation results and security analysis are used.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 09:04:02 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Khedmati", "Y.", ""], ["Parvaz", "R.", ""], ["Behroo", "Y.", ""]]}, {"id": "1810.06689", "submitter": "Ripon Patgiri", "authors": "Ripon Patgiri, Sabuzima Nayak, Samir Kumar Borgohain", "title": "Preventing DDoS using Bloom Filter: A Survey", "comments": "9 pages, 1 figure. This article is accepted for publication in EAI\n  Endorsed Transactions on Scalable Information Systems", "journal-ref": "EAI Endorsed Transactions on Scalable Information Systems, 5(19),\n  2018", "doi": "10.4108/eai.19-6-2018.155865", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Denial-of-Service (DDoS) is a menace for service provider and\nprominent issue in network security. Defeating or defending the DDoS is a prime\nchallenge. DDoS make a service unavailable for a certain time. This phenomenon\nharms the service providers, and hence, loss of business revenue. Therefore,\nDDoS is a grand challenge to defeat. There are numerous mechanism to defend\nDDoS, however, this paper surveys the deployment of Bloom Filter in defending a\nDDoS attack. The Bloom Filter is a probabilistic data structure for membership\nquery that returns either true or false. Bloom Filter uses tiny memory to store\ninformation of large data. Therefore, packet information is stored in Bloom\nFilter to defend and defeat DDoS. This paper presents a survey on DDoS\ndefending technique using Bloom Filter.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 21:00:12 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Patgiri", "Ripon", ""], ["Nayak", "Sabuzima", ""], ["Borgohain", "Samir Kumar", ""]]}, {"id": "1810.07058", "submitter": "Wei Wang Dr.", "authors": "Zhiqing Luo, Wei Wang, Jun Qu, Tao Jiang and Qian Zhang", "title": "ShieldScatter: Improving IoT Security with Backscatter Assistance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lightweight protocols and low-power radio technologies open up many\nopportunities to facilitate Internet-of-Things (IoT) into our daily life, while\ntheir minimalist design also makes IoT devices vulnerable to many active\nattacks due to the lack of sophisticated security protocols. Recent advances\nadvocate the use of an antenna array to extract fine-grained physical-layer\nsignatures to mitigate these active attacks. However, it adds burdens in terms\nof energy consumption and hardware cost that IoT devices cannot afford. To\novercome this predicament, we present ShieldScatter, a lightweight system that\nattaches battery-free backscatter tags to single-antenna devices to shield the\nsystem from active attacks. The key insight of ShieldScatter is to\nintentionally create multi-path propagation signatures with the careful\ndeployment of backscatter tags. These signatures can be used to construct a\nsensitive profile to identify the location of the signals' arrival, and thus\ndetect the threat. We prototype ShieldScatter with USRPs and ambient\nbackscatter tags to evaluate our system in various environments. The\nexperimental results show that even when the attacker is located only 15 cm\naway from the legitimate device, ShieldScatter with merely three backscatter\ntags can mitigate 97% of spoofing attack attempts while at the same time\ntrigger false alarms on just 7% of legitimate traffic.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 14:59:55 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Luo", "Zhiqing", ""], ["Wang", "Wei", ""], ["Qu", "Jun", ""], ["Jiang", "Tao", ""], ["Zhang", "Qian", ""]]}, {"id": "1810.07177", "submitter": "Debesh Choudhury", "authors": "Debesh Choudhury", "title": "Fourier domain asymmetric cryptosystem for privacy protected multimodal\n  biometric security", "comments": "SPIE Conference Optical Pattern Recognition XXVII, part of SPIE\n  Defense + Commercial Sensing, Baltimore, 20-21 April 2016", "journal-ref": null, "doi": "10.1117/12.2223927", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Fourier domain asymmetric cryptosystem for multimodal biometric\nsecurity. One modality of biometrics (such as face) is used as the plaintext,\nwhich is encrypted by another modality of biometrics (such as fingerprint). A\nprivate key is synthesized from the encrypted biometric signature by complex\nspatial Fourier processing. The encrypted biometric signature is further\nencrypted by other biometric modalities, and the corresponding private keys are\nsynthesized. The resulting biometric signature is privacy protected since the\nencryption keys are provided by the human, and hence those are private keys.\nMoreover, the decryption keys are synthesized using those private encryption\nkeys. The encrypted signatures are decrypted using the synthesized private keys\nand inverse complex spatial Fourier processing. Computer simulations\ndemonstrate the feasibility of the technique proposed.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 08:35:28 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Choudhury", "Debesh", ""]]}, {"id": "1810.07242", "submitter": "Muhammad Usama", "authors": "Muhammad Usama, Junaid Qadir, Ala Al-Fuqaha", "title": "Adversarial Attacks on Cognitive Self-Organizing Networks: The Challenge\n  and the Way Forward", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future communications and data networks are expected to be largely cognitive\nself-organizing networks (CSON). Such networks will have the essential property\nof cognitive self-organization, which can be achieved using machine learning\ntechniques (e.g., deep learning). Despite the potential of these techniques,\nthese techniques in their current form are vulnerable to adversarial attacks\nthat can cause cascaded damages with detrimental consequences for the whole\nnetwork. In this paper, we explore the effect of adversarial attacks on CSON.\nOur experiments highlight the level of threat that CSON have to deal with in\norder to meet the challenges of next-generation networks and point out\npromising directions for future work.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 10:25:17 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Usama", "Muhammad", ""], ["Qadir", "Junaid", ""], ["Al-Fuqaha", "Ala", ""]]}, {"id": "1810.07248", "submitter": "Ali Emami", "authors": "Mahdi Ahmadi, Alireza Norouzi, S.M.Reza Soroushmehr, Nader Karimi,\n  Kayvan Najarian, Shadrokh Samavi and Ali Emami", "title": "ReDMark: Framework for Residual Diffusion Watermarking on Deep Networks", "comments": "33 pages (Single column), 10 figures, 5 tables, one appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the rapid growth of machine learning tools and specifically deep\nnetworks in various computer vision and image processing areas, application of\nConvolutional Neural Networks for watermarking have recently emerged. In this\npaper, we propose a deep end-to-end diffusion watermarking framework (ReDMark)\nwhich can be adapted for any desired transform space. The framework is composed\nof two Fully Convolutional Neural Networks with the residual structure for\nembedding and extraction. The whole deep network is trained end-to-end to\nconduct a blind secure watermarking. The framework is customizable for the\nlevel of robustness vs. imperceptibility. It is also adjustable for the\ntrade-off between capacity and robustness. The proposed framework simulates\nvarious attacks as a differentiable network layer to facilitate end-to-end\ntraining. For JPEG attack, a differentiable approximation is utilized, which\ndrastically improves the watermarking robustness to this attack. Another\nimportant characteristic of the proposed framework, which leads to improved\nsecurity and robustness, is its capability to diffuse watermark information\namong a relatively wide area of the image. Comparative results versus recent\nstate-of-the-art researches highlight the superiority of the proposed framework\nin terms of imperceptibility and robustness.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 23:07:15 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 09:53:39 GMT"}, {"version": "v3", "created": "Tue, 11 Dec 2018 09:32:01 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Ahmadi", "Mahdi", ""], ["Norouzi", "Alireza", ""], ["Soroushmehr", "S. M. Reza", ""], ["Karimi", "Nader", ""], ["Najarian", "Kayvan", ""], ["Samavi", "Shadrokh", ""], ["Emami", "Ali", ""]]}, {"id": "1810.07250", "submitter": "Weize Yu", "authors": "Weize Yu and Jia Chen", "title": "PUF-AES-PUF: a novel PUF architecture against non-invasive attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, a physical unclonable function (PUF)-advanced encryption\nstandard (AES)-PUF is proposed as a new PUF architecture by embedding an AES\ncryptographic circuit between two conventional PUF circuits to conceal their\nchallenge-to-response pairs (CRPs) against machine learning attacks. Moreover,\nan internal confidential data is added to the secret key of the AES\ncryptographic circuit in the new PUF architecture to update the secret key in\nreal-time against side-channel attacks. As shown in the results, even if 1\nmillion number of data are enabled by the adversary to implement machine\nlearning or side-channel attacks, the proposed PUF can not be cracked. By\ncontrast, only 5,000 (1,000) number of data are sufficient to leak the\nconfidential information of a conventional PUF via machine learning\n(side-channel) attacks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 18:28:18 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Yu", "Weize", ""], ["Chen", "Jia", ""]]}, {"id": "1810.07252", "submitter": "Mouhammd Alkasassbeh", "authors": "Mouhammd Alkasassbeh, Samail Al-Daleen", "title": "Classification of malware based on file content and characteristics", "comments": "12", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In general, the industry of malware has come to be a market which brings on\nloads of money by investing and implementing high end technology to escape\ntraditional detection while vendors of anti-malware spend thousands if not\nmillions of dollars to stop the malware breach since it not only causes\nfinancial losses but also emotional ones. This paper study the classification\nof malware based on file content and characteristics, this was done through use\nof Clamp Integrated dataset that includes 5210 instances. There are different\nalgorithms were applied using Weka software, which are; ZeroR, bayesNet, SMO,\nKNN, J48, as well as Random Forest. The obtained results showed that Random\nForest that achieved the highest overall accuracy of (99.0979%). This means\nthat Random Forest algorithm is efficient to be used in malware classification\nbased on file content and characteristics.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 07:57:23 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Alkasassbeh", "Mouhammd", ""], ["Al-Daleen", "Samail", ""]]}, {"id": "1810.07260", "submitter": "Shouhuai Xu", "authors": "Pang Du and Zheyuan Sun and Huashan Chen and Jin-Hee Cho and Shouhuai\n  Xu", "title": "Statistical Estimation of Malware Detection Metrics in the Absence of\n  Ground Truth", "comments": null, "journal-ref": "IEEE T-IFS (2018)", "doi": null, "report-no": null, "categories": "stat.AP cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accurate measurement of security metrics is a critical research problem\nbecause an improper or inaccurate measurement process can ruin the usefulness\nof the metrics, no matter how well they are defined. This is a highly\nchallenging problem particularly when the ground truth is unknown or noisy. In\ncontrast to the well perceived importance of defining security metrics, the\nmeasurement of security metrics has been little understood in the literature.\nIn this paper, we measure five malware detection metrics in the {\\em absence}\nof ground truth, which is a realistic setting that imposes many technical\nchallenges. The ultimate goal is to develop principled, automated methods for\nmeasuring these metrics at the maximum accuracy possible. The problem naturally\ncalls for investigations into statistical estimators by casting the measurement\nproblem as a {\\em statistical estimation} problem. We propose statistical\nestimators for these five malware detection metrics. By investigating the\nstatistical properties of these estimators, we are able to characterize when\nthe estimators are accurate, and what adjustments can be made to improve them\nunder what circumstances. We use synthetic data with known ground truth to\nvalidate these statistical estimators. Then, we employ these estimators to\nmeasure five metrics with respect to a large dataset collected from VirusTotal.\nWe believe our study touches upon a vital problem that has not been paid due\nattention and will inspire many future investigations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 02:40:31 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Du", "Pang", ""], ["Sun", "Zheyuan", ""], ["Chen", "Huashan", ""], ["Cho", "Jin-Hee", ""], ["Xu", "Shouhuai", ""]]}, {"id": "1810.07274", "submitter": "Ahsan Humayun Mr.", "authors": "Zafar Iqbal, Tahreem Saeed, Tariq Rafiq, Ahsan Humayun", "title": "Mathematical Modeling of Routes Maintenance and Recovery Procedure for\n  MANETs", "comments": "8 pages", "journal-ref": "IJCSNS International Journal of Computer Science and Network\n  Security, VOL.18 No.8, August 2018", "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Routing is one of the most mysterious issues from the birth of networks up\ntill now. Designing routing protocols for Mobile Ad hoc Networks (MANETs) is a\ncomplicated task because unpredictable mobility patterns of mobile nodes\ngreatly effect routing decisions. Various routing protocols are designed to\nimprove this very problem. Different simulator based routing protocols are\ndesigned but these protocols might fail during deployment because of the\ntesting procedures of simulators. In this study, a novel formal model for\nroutes management is proposed for MANETs. Formal methods are the most novel\ntechniques based purely on mathematics and are used for the verification,\nvalidation of critical systems/models and guarantee the correctness and\ncompleteness of hardware/software systems. The proposed routing model is a\ncomplete and detailed graph based logical model defined in VDM-SL (formal\nlanguage) and then verified and validated by using VDM-SL toolbox.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 03:57:11 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Iqbal", "Zafar", ""], ["Saeed", "Tahreem", ""], ["Rafiq", "Tariq", ""], ["Humayun", "Ahsan", ""]]}, {"id": "1810.07304", "submitter": "Erik Sy", "authors": "Erik Sy, Christian Burkert, Hannes Federrath, Mathias Fischer", "title": "Tracking Users across the Web via TLS Session Resumption", "comments": "11 pages", "journal-ref": "Published in 2018 Annual Computer Security Applications Conference\n  (ACSAC '18), December 3-7, 2018, San Juan, PR, USA", "doi": "10.1145/3274694.3274708", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User tracking on the Internet can come in various forms, e.g., via cookies or\nby fingerprinting web browsers. A technique that got less attention so far is\nuser tracking based on TLS and specifically based on the TLS session resumption\nmechanism. To the best of our knowledge, we are the first that investigate the\napplicability of TLS session resumption for user tracking. For that, we\nevaluated the configuration of 48 popular browsers and one million of the most\npopular websites. Moreover, we present a so-called prolongation attack, which\nallows extending the tracking period beyond the lifetime of the session\nresumption mechanism. To show that under the observed browser configurations\ntracking via TLS session resumptions is feasible, we also looked into DNS data\nto understand the longest consecutive tracking period for a user by a\nparticular website. Our results indicate that with the standard setting of the\nsession resumption lifetime in many current browsers, the average user can be\ntracked for up to eight days. With a session resumption lifetime of seven days,\nas recommended upper limit in the draft for TLS version 1.3, 65% of all users\nin our dataset can be tracked permanently.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 22:58:44 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Sy", "Erik", ""], ["Burkert", "Christian", ""], ["Federrath", "Hannes", ""], ["Fischer", "Mathias", ""]]}, {"id": "1810.07305", "submitter": "Shalabh Jain", "authors": "Shalabh Jain, Qian Wang, Md Tanvir Arafin and Jorge Guajardo", "title": "Probing Attacks on Physical Layer Key Agreement for Automotive\n  Controller Area Networks (Extended Version)", "comments": "Presented at ESCAR Europe 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient key management for automotive networks (CAN) is a critical element,\ngoverning the adoption of security in the next generation of vehicles. A recent\npromising approach for dynamic key agreement between groups of nodes,\nPlug-and-Secure for CAN, has been demonstrated to be information theoretically\nsecure based on the physical properties of the CAN bus. In this paper, we\nillustrate side-channel attacks, leading to nearly-complete leakage of the\nsecret key bits, by an adversary that is capable of probing the CAN bus. We\nidentify the fundamental characteristics that lead to such attacks and propose\ntechniques to minimize the information leakage at the hardware, controller and\nsystem levels.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 23:00:16 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Jain", "Shalabh", ""], ["Wang", "Qian", ""], ["Arafin", "Md Tanvir", ""], ["Guajardo", "Jorge", ""]]}, {"id": "1810.07315", "submitter": "Somya Mohanty", "authors": "Franklin Wei, Mahalingam Ramkumar and Somya D Mohanty", "title": "A Scalable, Trustworthy Infrastructure for Collaborative Container\n  Repositories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a scalable \"Trustworthy Container Repository\" (TCR) infrastructure\nfor the storage of software container images, such as those used by Docker.\nUsing an authenticated data structure based on index-ordered Merkle trees\n(IOMTs), TCR aims to provide assurances of 1) Integrity, 2) Availability, and\n3) Confidentiality to its users, whose containers are stored in an untrusted\nenvironment. Trust within the TCR architecture is rooted in a low-complexity,\ntamper-resistant trusted module. The use of IOMTs allows such a module to\nefficiently track a virtually unlimited number of container images, and thus\nprovide the desired assurances for the system's users. Using a simulated\nversion of the proposed system, we demonstrate the scalability of platform by\nshowing logarithmic time complexity up to $2^{25}$ (32 million) container\nimages. This paper presents both algorithmic and proof-of-concept software\nimplementations of the proposed TCR infrastructure.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 23:48:06 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Wei", "Franklin", ""], ["Ramkumar", "Mahalingam", ""], ["Mohanty", "Somya D", ""]]}, {"id": "1810.07321", "submitter": "Giuseppe Laurenza", "authors": "Giuseppe Laurenza, Riccardo Lazzeretti and Luca Mazzotti", "title": "Malware triage for early identification of Advanced Persistent Threat\n  activities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, a new class of cyber-threats has emerged. This new\ncybersecurity adversary is known with the name of \"Advanced Persistent Threat\"\n(APT) and is referred to different organizations that in the last years have\nbeen \"in the center of the eye\" due to multiple dangerous and effective attacks\ntargeting financial and politic, news headlines, embassies, critical\ninfrastructures, TV programs, etc. In order to early identify APT related\nmalware, a semi-automatic approach for malware samples analysis is needed. In\nour previous work we introduced a \"malware triage\" step for a semi-automatic\nmalware analysis architecture. This step has the duty to analyze as fast as\npossible new incoming samples and to immediately dispatch the ones that deserve\na deeper analysis, among all the malware delivered per day in the cyber-space,\nthe ones that really worth to be further examined by analysts. Our paper\nfocuses on malware developed by APTs, and we build our knowledge base, used in\nthe triage, on known APTs obtained from publicly available reports. In order to\nhave the triage as fast as possible, we only rely on static malware features,\nthat can be extracted with negligible delay, and use machine learning\ntechniques for the identification. In this work we move from multiclass\nclassification to a group of oneclass classifier, which simplify the training\nand allows higher modularity. The results of the proposed framework highlight\nhigh performances, reaching a precision of 100% and an accuracy over 95%\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 12:28:55 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Laurenza", "Giuseppe", ""], ["Lazzeretti", "Riccardo", ""], ["Mazzotti", "Luca", ""]]}, {"id": "1810.07339", "submitter": "Guofu Li", "authors": "Guofu Li, Pengjia Zhu, Jin Li, Zhemin Yang, Ning Cao, and Zhiyi Chen", "title": "Security Matters: A Survey on Adversarial Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial machine learning is a fast growing research area, which considers\nthe scenarios when machine learning systems may face potential adversarial\nattackers, who intentionally synthesize input data to make a well-trained model\nto make mistake. It always involves a defending side, usually a classifier, and\nan attacking side that aims to cause incorrect output. The earliest studies on\nthe adversarial examples for machine learning algorithms start from the\ninformation security area, which considers a much wider varieties of attacking\nmethods. But recent research focus that popularized by the deep learning\ncommunity places strong emphasis on how the \"imperceivable\" perturbations on\nthe normal inputs may cause dramatic mistakes by the deep learning with\nsupposed super-human accuracy. This paper serves to give a comprehensive\nintroduction to a range of aspects of the adversarial deep learning topic,\nincluding its foundations, typical attacking and defending strategies, and some\nextended studies.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 09:06:26 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 03:13:05 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Li", "Guofu", ""], ["Zhu", "Pengjia", ""], ["Li", "Jin", ""], ["Yang", "Zhemin", ""], ["Cao", "Ning", ""], ["Chen", "Zhiyi", ""]]}, {"id": "1810.07428", "submitter": "Chun Guo", "authors": "Chun Guo", "title": "Understanding the Related-Key Security of Feistel Ciphers from a\n  Provable Perspective", "comments": "The technical part is the same as the submission (only modify to fit\n  into the double column). In \"Related Work\" comparison with [72] is added: in\n  short, these two works focus on very different goals, and their general\n  results aren't comparable", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the provable related-key security treatment for models of\npractical Feistel ciphers. In detail, we consider Feistel networks with four\nwhitening keys $w_i(k)$ ($i=0,1,2,3$) and round-functions of the form\n$f(\\gamma_i(k)\\oplus X)$, where $k$ is the main-key, $w_i$ and $\\gamma_i$ are\nefficient transformations, and $f$ is a public ideal function or permutation\nthat the adversary is allowed to query. We investigate conditions on the\nkey-schedules that are sufficient for security against XOR-induced related-key\nattacks up to $2^{n/2}$ adversarial queries. When the key-schedules are\nnon-linear, we prove security for 4 rounds. When only affine key-schedules are\nused, we prove security for 6 rounds. These also imply secure tweakable Feistel\nciphers in the Random Oracle model.\n  By shuffling the key-schedules, our model unifies both the DES-like structure\n(known as Feistel-2 scheme in the cryptanalytic community, a.k.a.\nkey-alternating Feistel due to Lampe and Seurin, FSE 2014) and the Lucifer-like\nmodel (previously analyzed by Guo and Lin, TCC 2015). This allows us to derive\nconcrete implications on these two (more common) models, and helps\nunderstanding their differences---and further understanding the related-key\nsecurity of Feistel ciphers.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 08:33:55 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 06:36:16 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 16:50:53 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Guo", "Chun", ""]]}, {"id": "1810.07554", "submitter": "Thomas Debris-Alazard", "authors": "Thomas Debris-Alazard and Nicolas Sendrier and Jean-Pierre Tillich", "title": "Wave: A New Family of Trapdoor One-Way Preimage Sampleable Functions\n  Based on Codes", "comments": "arXiv admin note: text overlap with arXiv:1706.08065", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present here a new family of trapdoor one-way Preimage Sampleable\nFunctions (PSF) based on codes, the Wave-PSF family. The trapdoor function is\none-way under two computational assumptions: the hardness of generic decoding\nfor high weights and the indistinguishability of generalized $(U,U+V)$-codes.\nOur proof follows the GPV strategy [GPV08]. By including rejection sampling, we\nensure the proper distribution for the trapdoor inverse output. The domain\nsampling property of our family is ensured by using and proving a variant of\nthe left-over hash lemma. We instantiate the new Wave-PSF family with ternary\ngeneralized $(U,U+V)$-codes to design a \"hash-and-sign\" signature scheme which\nachieves existential unforgeability under adaptive chosen message attacks\n(EUF-CMA) in the random oracle model. For 128 bits of classical security,\nsignature sizes are in the order of 15 thousand bits, the public key size in\nthe order of 4 megabytes, and the rejection rate is limited to one rejection\nevery 10 to 12 signatures.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 12:54:53 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 11:37:00 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Debris-Alazard", "Thomas", ""], ["Sendrier", "Nicolas", ""], ["Tillich", "Jean-Pierre", ""]]}, {"id": "1810.07665", "submitter": "Shujun Li", "authors": "Ximing Liu, Yingjiu Li, Robert H. Deng, Bing Chang and Shujun Li", "title": "When Human cognitive modeling meets PINs: User-independent\n  inter-keystroke timing attacks", "comments": "16 pages, 9 figures", "journal-ref": "Computers & Security, vol. 80, pp. 90-107, 2018", "doi": "10.1016/j.cose.2018.09.003", "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the first user-independent inter-keystroke timing attacks\non PINs. Our attack method is based on an inter-keystroke timing dictionary\nbuilt from a human cognitive model whose parameters can be determined by a\nsmall amount of training data on any users (not necessarily the target\nvictims). Our attacks can thus be potentially launched on a large scale in\nreal-world settings. We investigate inter-keystroke timing attacks in different\nonline attack settings and evaluate their performance on PINs at different\nstrength levels. Our experimental results show that the proposed attack\nperforms significantly better than random guessing attacks. We further\ndemonstrate that our attacks pose a serious threat to real-world applications\nand propose various ways to mitigate the threat.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 16:54:39 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Liu", "Ximing", ""], ["Li", "Yingjiu", ""], ["Deng", "Robert H.", ""], ["Chang", "Bing", ""], ["Li", "Shujun", ""]]}, {"id": "1810.07670", "submitter": "Matthias Pilz", "authors": "Matthias Pilz, Fariborz Baghaei Naeini, Ketil Grammont, Coline\n  Smagghe, Mastaneh Davis, Jean-Christophe Nebel, Luluwah Al-Fagih, Eckhard\n  Pfluegel", "title": "Security Attacks on Smart Grid Scheduling and Their Defences: A\n  Game-Theoretic Approach", "comments": "13 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The introduction of advanced communication infrastructure into the power grid\nraises a plethora of new opportunities to tackle climate change. This paper is\nconcerned with the security of energy management systems which are expected to\nbe implemented in the future smart grid. The existence of a novel class of\nfalse data injection attacks that are based on modifying forecasted demand data\nis demonstrated, and the impact of the attacks on a typical system's parameters\nis identified, using a simulated scenario. Monitoring strategies that the\nutility company may employ in order to detect the attacks are proposed and a\ngame--theoretic approach is used to support the utility company's\ndecision--making process for the allocation of their defence resources.\nInformed by these findings, a generic security game is devised and solved,\nrevealing the existence of several Nash Equilibrium strategies. The practical\noutcomes of these results for the utility company are discussed in detail and a\nproposal is made, suggesting how the generic model may be applied to other\nscenarios.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 17:05:45 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Pilz", "Matthias", ""], ["Naeini", "Fariborz Baghaei", ""], ["Grammont", "Ketil", ""], ["Smagghe", "Coline", ""], ["Davis", "Mastaneh", ""], ["Nebel", "Jean-Christophe", ""], ["Al-Fagih", "Luluwah", ""], ["Pfluegel", "Eckhard", ""]]}, {"id": "1810.07780", "submitter": "Juan Tapiador", "authors": "Haoyu Wang, Zhe Liu, Jingyue Liang, Narseo Vallina-Rodriguez, Yao Guo,\n  Li Li, Juan Tapiador, Jingcun Cao, Guoai Xu", "title": "Beyond Google Play: A Large-Scale Comparative Study of Chinese Android\n  App Markets", "comments": "To appear in the Proceedings of the 2018 Internet Measurement\n  Conference (IMC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  China is one of the largest Android markets in the world. As Chinese users\ncannot access Google Play to buy and install Android apps, a number of\nindependent app stores have emerged and compete in the Chinese app market. Some\nof the Chinese app stores are pre-installed vendor-specific app markets (e.g.,\nHuawei, Xiaomi and OPPO), whereas others are maintained by large tech companies\n(e.g., Baidu, Qihoo 360 and Tencent). The nature of these app stores and the\ncontent available through them vary greatly, including their trustworthiness\nand security guarantees.\n  As of today, the research community has not studied the Chinese Android\necosystem in depth. To fill this gap, we present the first large-scale\ncomparative study that covers more than 6 million Android apps downloaded from\n16 Chinese app markets and Google Play. We focus our study on catalog\nsimilarity across app stores, their features, publishing dynamics, and the\nprevalence of various forms of misbehavior (including the presence of fake,\ncloned and malicious apps). Our findings also suggest heterogeneous developer\nbehavior across app stores, in terms of code maintenance, use of third-party\nservices, and so forth. Overall, Chinese app markets perform substantially\nworse when taking active measures to protect mobile users and legit developers\nfrom deceptive and abusive actors, showing a significantly higher prevalence of\nmalware, fake, and cloned apps than Google Play.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 11:20:03 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Wang", "Haoyu", ""], ["Liu", "Zhe", ""], ["Liang", "Jingyue", ""], ["Vallina-Rodriguez", "Narseo", ""], ["Guo", "Yao", ""], ["Li", "Li", ""], ["Tapiador", "Juan", ""], ["Cao", "Jingcun", ""], ["Xu", "Guoai", ""]]}, {"id": "1810.07873", "submitter": "Zhili Chen Prof.", "authors": "Zhili Chen, Tianjiao Ni, Hong Zhong, Shun Zhang, Jie Cui", "title": "Differentially Private Double Spectrum Auction with Approximate Social\n  Welfare Maximization", "comments": "12 pages, 7figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectrum auction is an effective approach to improving spectrum utilization,\nby leasing idle spectrum from primary users to secondary users. Recently, a few\ndifferentially private spectrum auction mechanisms have been proposed, but, as\nfar as we know, none of them addressed the differential privacy in the setting\nof double spectrum auctions. In this paper, we combine the concept of\ndifferential privacy with double spectrum auction design, and present a\nDifferentially private Double spectrum auction mechanism with approximate\nSocial welfare Maximization (DDSM). Specifically, we design the mechanism by\nemploying the exponential mechanism to select clearing prices for the double\nspectrum auction with probabilities exponentially proportional to the related\nsocial welfare values, and then improve the mechanism in several aspects like\nthe designs of the auction algorithm, the utility function and the buyer\ngrouping algorithm. Through theoretical analysis, we prove that DDSM achieves\ndifferential privacy, approximate truthfulness, approximate social welfare\nmaximization. Extensive experimental evaluations show that DDSM achieves a good\nperformance in term of social welfare.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 02:20:07 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Chen", "Zhili", ""], ["Ni", "Tianjiao", ""], ["Zhong", "Hong", ""], ["Zhang", "Shun", ""], ["Cui", "Jie", ""]]}, {"id": "1810.07880", "submitter": "Zhili Chen Dr.", "authors": "Zhili Chen, Xuemei Wei, Hong Zhong, Jie Cui, Yan Xu, Shun Zhang", "title": "Making Double Spectrum Auction Practical: Both Privacy and Efficiency\n  Matter", "comments": "11 pages, 6figures", "journal-ref": "IWQoS 2017", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Truthful spectrum auction is believed to be an effective method for spectrum\nredistribution. However, privacy concerns have largely hampered the practical\napplications of truthful spectrum auctions. In this paper, to make the\napplications of double spectrum auctions practical, we present a\nprivacy-preserving and socially efficient double spectrum auction design, SDSA.\nSpecifically, by combining three security techniques: homomorphic encryption,\nsecret sharing and garbled circuits, we design a secure two-party protocol\ncomputing a socially efficient double spectrum auction, TDSA, without leaking\nany information about sellers' requests or buyers' bids beyond the auction\noutcome. We give the formal security definition in our context, and\ntheoretically prove the security that our design achieves. Experimental results\nshow that our design is also efficient in performance, even for large-scale\ndouble spectrum auctions.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 02:42:46 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Chen", "Zhili", ""], ["Wei", "Xuemei", ""], ["Zhong", "Hong", ""], ["Cui", "Jie", ""], ["Xu", "Yan", ""], ["Zhang", "Shun", ""]]}, {"id": "1810.07886", "submitter": "Nagender Aneja", "authors": "Nagender Aneja and Sapna Gambhir", "title": "Profile-Based Ad Hoc Social Networking Using Wi-Fi Direct on the Top of\n  Android", "comments": null, "journal-ref": "Nagender Aneja and Sapna Gambhir, \"Profile-Based Ad Hoc Social\n  Networking Using Wi-Fi Direct on the Top of Android,\" Mobile Information\n  Systems, vol 2018, Article ID 9469536, 7 pages, 2018.\n  https://doi.org/10.1155/2018/9469536", "doi": "10.1155/2018/9469536", "report-no": null, "categories": "cs.SI cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ad-hoc Social Networks have become popular to support novel applications\nrelated to location-based mobile services that are of great importance to users\nand businesses. Unlike traditional social services using a centralized server\nto fetch location, ad-hoc social network services support infrastructure less\nreal-time social networking. It allows users to collaborate and share views\nanytime anywhere. However, current ad-hoc social network applications are\neither not available without rooting the mobile phones or don't filter the\nnearby users based on common interests without a centralized server. This paper\npresents an architecture and implementation of social networks on commercially\navailable mobile devices that allow broadcasting name and a limited number of\nkeywords representing users' interests without any connection in a nearby\nregion to facilitate matching of interests. The broadcasting region creates a\ndigital aura and is limited by WiFi region that is around 200 meters. The\napplication connects users to form a group based on their profile or interests\nusing peer-to-peer communication mode without using any centralized networking\nor profile matching infrastructure. The peer-to-peer group can be used for\nprivate communication when the network is not available.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 03:17:26 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Aneja", "Nagender", ""], ["Gambhir", "Sapna", ""]]}, {"id": "1810.08031", "submitter": "Junqing Zhang", "authors": "Junqing Zhang, Alan Marshall, and Lajos Hanzo", "title": "Channel-Envelope Differencing Eliminates Secret Key Correlation:\n  LoRa-Based Key Generation in Low Power Wide Area Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents automatic key generation for long-range wireless\ncommunications in low power wide area networks (LPWANs), employing LoRa as a\ncase study. Differential quantization is adopted to extract a high level of\nrandomness. Experiments conducted both in an outdoor urban environment and in\nan indoor environment demonstrate that this key generation technique is\napplicable for LPWANs, and shows that it is able to reliably generate secure\nkeys.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 13:09:28 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Zhang", "Junqing", ""], ["Marshall", "Alan", ""], ["Hanzo", "Lajos", ""]]}, {"id": "1810.08070", "submitter": "Yingdi Wang", "authors": "Yingdi Wang, Wenjia Niu, Tong Chen, Yingxiao Xiang, Jingjing Liu, Gang\n  Li, and Jiqiang Liu", "title": "A Training-based Identification Approach to VIN Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of Artificial Intelligence (AI), the problem of AI\nsecurity has gradually emerged. Most existing machine learning algorithms may\nbe attacked by adversarial examples. An adversarial example is a slightly\nmodified input sample that can lead to a false result of machine learning\nalgorithms. The adversarial examples pose a potential security threat for many\nAI application areas, especially in the domain of robot path planning. In this\nfield, the adversarial examples obstruct the algorithm by adding obstacles to\nthe normal maps, resulting in multiple effects on the predicted path. However,\nthere is no suitable approach to automatically identify them. To our knowledge,\nall previous work uses manual observation method to estimate the attack results\nof adversarial maps, which is time-consuming. Aiming at the existing problem,\nthis paper explores a method to automatically identify the adversarial examples\nin Value Iteration Networks (VIN), which has a strong generalization ability.\nWe analyze the possible scenarios caused by the adversarial maps. We propose a\ntraining-based identification approach to VIN adversarial examples by combing\nthe path feature comparison and path image classification. We evaluate our\nmethod using the adversarial maps dataset, show that our method can achieve a\nhigh-accuracy and faster identification than manual observation method.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 14:17:12 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Wang", "Yingdi", ""], ["Niu", "Wenjia", ""], ["Chen", "Tong", ""], ["Xiang", "Yingxiao", ""], ["Liu", "Jingjing", ""], ["Li", "Gang", ""], ["Liu", "Jiqiang", ""]]}, {"id": "1810.08092", "submitter": "Vivek Bagaria", "authors": "Vivek Bagaria, Sreeram Kannan, David Tse, Giulia Fanti, Pramod\n  Viswanath", "title": "Deconstructing the Blockchain to Approach Physical Limits", "comments": "Computer and Communications Security, 2019", "journal-ref": "Computer and Communications Security, 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transaction throughput, confirmation latency and confirmation reliability are\nfundamental performance measures of any blockchain system in addition to its\nsecurity. In a decentralized setting, these measures are limited by two\nunderlying physical network attributes: communication capacity and\nspeed-of-light propagation delay. Existing systems operate far away from these\nphysical limits. In this work we introduce Prism, a new proof-of-work\nblockchain protocol, which can achieve 1) security against up to 50%\nadversarial hashing power; 2) optimal throughput up to the capacity C of the\nnetwork; 3) confirmation latency for honest transactions proportional to the\npropagation delay D, with confirmation error probability exponentially small in\nCD ; 4) eventual total ordering of all transactions. Our approach to the design\nof this protocol is based on deconstructing the blockchain into its basic\nfunctionalities and systematically scaling up these functionalities to approach\ntheir physical limits.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 14:55:40 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 17:40:56 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 19:40:17 GMT"}, {"version": "v4", "created": "Wed, 2 Oct 2019 00:47:25 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Bagaria", "Vivek", ""], ["Kannan", "Sreeram", ""], ["Tse", "David", ""], ["Fanti", "Giulia", ""], ["Viswanath", "Pramod", ""]]}, {"id": "1810.08125", "submitter": "Ruffin White", "authors": "Ruffin White, Gianluca Caiazza, Henrik I. Christensen, Agostino\n  Cortesi", "title": "Procedurally Provisioned Access Control for Robotic Systems", "comments": null, "journal-ref": "2018 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS)", "doi": null, "report-no": null, "categories": "cs.RO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security of robotics systems, as well as of the related middleware\ninfrastructures, is a critical issue for industrial and domestic IoT, and it\nneeds to be continuously assessed throughout the whole development lifecycle.\nThe next generation open source robotic software stack, ROS2, is now targeting\nsupport for Secure DDS, providing the community with valuable tools for secure\nreal world robotic deployments. In this work, we introduce a framework for\nprocedural provisioning access control policies for robotic software, as well\nas for verifying the compliance of generated transport artifacts and decision\npoint implementations.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 15:55:54 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["White", "Ruffin", ""], ["Caiazza", "Gianluca", ""], ["Christensen", "Henrik I.", ""], ["Cortesi", "Agostino", ""]]}, {"id": "1810.08130", "submitter": "Morten Dahl", "authors": "Morten Dahl, Jason Mancuso, Yann Dupis, Ben Decoste, Morgan Giraud,\n  Ian Livingstone, Justin Patriquin, Gavin Uhma", "title": "Private Machine Learning in TensorFlow using Secure Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for experimenting with secure multi-party computation\ndirectly in TensorFlow. By doing so we benefit from several properties valuable\nto both researchers and practitioners, including tight integration with\nordinary machine learning processes, existing optimizations for distributed\ncomputation in TensorFlow, high-level abstractions for expressing complex\nalgorithms and protocols, and an expanded set of familiar tooling. We give an\nopen source implementation of a state-of-the-art protocol and report on\nconcrete benchmarks using typical models from private machine learning.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 16:10:12 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 08:13:06 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Dahl", "Morten", ""], ["Mancuso", "Jason", ""], ["Dupis", "Yann", ""], ["Decoste", "Ben", ""], ["Giraud", "Morgan", ""], ["Livingstone", "Ian", ""], ["Patriquin", "Justin", ""], ["Uhma", "Gavin", ""]]}, {"id": "1810.08136", "submitter": "Zhongliang Yang", "authors": "Zhongliang Yang, Nan Wei, Junyi Sheng, Yongfeng Huang, Yu-Jin Zhang", "title": "TS-CNN: Text Steganalysis from Semantic Space Based on Convolutional\n  Neural Network", "comments": "Submitted to AAAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Steganalysis has been an important research topic in cybersecurity that helps\nto identify covert attacks in public network. With the rapid development of\nnatural language processing technology in the past two years, coverless\nsteganography has been greatly developed. Previous text steganalysis methods\nhave shown unsatisfactory results on this new steganography technique and\nremain an unsolved challenge. Different from all previous text steganalysis\nmethods, in this paper, we propose a text steganalysis method(TS-CNN) based on\nsemantic analysis, which uses convolutional neural network(CNN) to extract\nhigh-level semantic features of texts, and finds the subtle distribution\ndifferences in the semantic space before and after embedding the secret\ninformation. To train and test the proposed model, we collected and released a\nlarge text steganalysis(CT-Steg) dataset, which contains a total number of\n216,000 texts with various lengths and various embedding rates. Experimental\nresults show that the proposed model can achieve nearly 100\\% precision and\nrecall, outperforms all the previous methods. Furthermore, the proposed model\ncan even estimate the capacity of the hidden information inside. These results\nstrongly support that using the subtle changes in the semantic space before and\nafter embedding the secret information to conduct text steganalysis is feasible\nand effective.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 16:20:05 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Yang", "Zhongliang", ""], ["Wei", "Nan", ""], ["Sheng", "Junyi", ""], ["Huang", "Yongfeng", ""], ["Zhang", "Yu-Jin", ""]]}, {"id": "1810.08280", "submitter": "Octavian Suciu", "authors": "Octavian Suciu, Scott E. Coull, Jeffrey Johns", "title": "Exploring Adversarial Examples in Malware Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The convolutional neural network (CNN) architecture is increasingly being\napplied to new domains, such as malware detection, where it is able to learn\nmalicious behavior from raw bytes extracted from executables. These\narchitectures reach impressive performance with no feature engineering effort\ninvolved, but their robustness against active attackers is yet to be\nunderstood. Such malware detectors could face a new attack vector in the form\nof adversarial interference with the classification model. Existing evasion\nattacks intended to cause misclassification on test-time instances, which have\nbeen extensively studied for image classifiers, are not applicable because of\nthe input semantics that prevents arbitrary changes to the binaries. This paper\nexplores the area of adversarial examples for malware detection. By training an\nexisting model on a production-scale dataset, we show that some previous\nattacks are less effective than initially reported, while simultaneously\nhighlighting architectural weaknesses that facilitate new attack strategies for\nmalware classification. Finally, we explore how generalizable different attack\nstrategies are, the trade-offs when aiming to increase their effectiveness, and\nthe transferability of single-step attacks.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 21:26:27 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 14:23:22 GMT"}, {"version": "v3", "created": "Sat, 13 Apr 2019 23:21:45 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Suciu", "Octavian", ""], ["Coull", "Scott E.", ""], ["Johns", "Jeffrey", ""]]}, {"id": "1810.08359", "submitter": "Zhongyi Hu", "authors": "Zhongyi Hu, Raymond Chiong, Ilung Pranata, Yukun Bao, Yuqing Lin", "title": "Malicious Web Domain Identification using Online Credibility and\n  Performance Data by Considering the Class Imbalance Issue", "comments": "20 pages", "journal-ref": "Industrial Management & Data Systems, 2018", "doi": "10.1108/IMDS-02-2018-0072", "report-no": null, "categories": "cs.LG cs.CR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: Malicious web domain identification is of significant importance to\nthe security protection of Internet users. With online credibility and\nperformance data, this paper aims to investigate the use of machine learning\ntech-niques for malicious web domain identification by considering the class\nimbalance issue (i.e., there are more benign web domains than malicious ones).\nDesign/methodology/approach: We propose an integrated resampling approach to\nhandle class imbalance by combining the Synthetic Minority Over-sampling\nTEchnique (SMOTE) and Particle Swarm Optimisation (PSO), a population-based\nmeta-heuristic algorithm. We use the SMOTE for over-sampling and PSO for\nunder-sampling. Findings: By applying eight well-known machine learning\nclassifiers, the proposed integrated resampling approach is comprehensively\nexamined using several imbalanced web domain datasets with different imbalance\nratios. Com-pared to five other well-known resampling approaches, experimental\nresults confirm that the proposed approach is highly effective. Practical\nimplications: This study not only inspires the practical use of online\ncredibility and performance data for identifying malicious web domains, but\nalso provides an effective resampling approach for handling the class\nimbal-ance issue in the area of malicious web domain identification.\nOriginality/value: Online credibility and performance data is applied to build\nmalicious web domain identification models using machine learning techniques.\nAn integrated resampling approach is proposed to address the class im-balance\nissue. The performance of the proposed approach is confirmed based on\nreal-world datasets with different imbalance ratios.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 05:54:40 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Hu", "Zhongyi", ""], ["Chiong", "Raymond", ""], ["Pranata", "Ilung", ""], ["Bao", "Yukun", ""], ["Lin", "Yuqing", ""]]}, {"id": "1810.08415", "submitter": "Ibbad Hafeez", "authors": "Ibbad Hafeez, Markku Antikainen, Aaron Yi Ding, Sasu Tarkoma", "title": "IoT-KEEPER: Securing IoT Communications in Edge Networks", "comments": "20 pages, 9 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increased popularity of IoT devices have made them lucrative targets for\nattackers. Due to insecure product development practices, these devices are\noften vulnerable even to very trivial attacks and can be easily compromised.\nDue to the sheer number and heterogeneity of IoT devices, it is not possible to\nsecure the IoT ecosystem using traditional endpoint and network security\nsolutions. To address the challenges and requirements of securing IoT devices\nin edge networks, we present IoT-Keeper, which is a novel system capable of\nsecuring the network against any malicious activity, in real time. The proposed\nsystem uses a lightweight anomaly detection technique, to secure both\ndevice-to-device and device-to-infrastructure communications, while using\nlimited resources available on the gateway. It uses unlabeled network data to\ndistinguish between benign and malicious traffic patterns observed in the\nnetwork. A detailed evaluation, done with real world testbed, shows that\nIoT-Keeper detects any device generating malicious traffic with high accuracy\n(0.982) and low false positive rate (0.01). The results demonstrate that\nIoT-Keeper is lightweight, responsive and can effectively handle complex D2D\ninteractions without requiring explicit attack signatures or sophisticated\nhardware.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 09:14:27 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Hafeez", "Ibbad", ""], ["Antikainen", "Markku", ""], ["Ding", "Aaron Yi", ""], ["Tarkoma", "Sasu", ""]]}, {"id": "1810.08420", "submitter": "Sarah Meiklejohn", "authors": "Pierre Reibel, Haaroon Yousaf, Sarah Meiklejohn", "title": "Why is a Ravencoin Like a TokenDesk? An Exploration of Code Diversity in\n  the Cryptocurrency Landscape", "comments": "19 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interest in cryptocurrencies has skyrocketed since their introduction a\ndecade ago, with hundreds of billions of dollars now invested across a\nlandscape of thousands of different cryptocurrencies. While there is\nsignificant diversity, there is also a significant number of scams as people\nseek to exploit the current popularity. In this paper, we seek to identify the\nextent of innovation in the cryptocurrency landscape using the open-source\nrepositories associated with each one. Among other findings, we observe that\nwhile many cryptocurrencies are largely unchanged copies of Bitcoin, the use of\nEthereum as a platform has enabled the deployment of cryptocurrencies with more\ndiverse functionalities.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 09:43:48 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Reibel", "Pierre", ""], ["Yousaf", "Haaroon", ""], ["Meiklejohn", "Sarah", ""]]}, {"id": "1810.08451", "submitter": "Zhili Chen Prof.", "authors": "Zhili Chen, Sheng Chen, Hong Zhong, Lin Chen, Miaomiao Tian", "title": "PP-MCSA: Privacy Preserving Multi-Channel Double Spectrum Auction", "comments": "Accepted by ICICS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auction is widely regarded as an effective way in dynamic spectrum\nredistribution. Recently, considerable research efforts have been devoted to\ndesigning privacy-preserving spectrum auctions in a variety of auction\nsettings. However, none of existing work has addressed the privacy issue in the\nmost generic scenario, double spectrum auctions where each seller sells\nmultiple channels and each buyer buys multiple channels. To fill this gap, in\nthis paper we propose PP-MCSA, a Privacy Preserving mechanism for Multi-Channel\ndouble Spectrum Auctions. Technically, by leveraging garbled circuits, we\nmanage to protect the privacy of both sellers' requests and buyers' bids in\nmulti-channel double spectrum auctions. As far as we know, PP-MCSA is the first\nprivacy-preserving solution for multi-channel double spectrum auctions. We\nfurther theoretically demonstrate the privacy guarantee of PP-MCSA, and\nextensively evaluate its performance via experiments. Experimental results show\nthat PP-MCSA incurs only moderate communication and computation overhead.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 11:47:29 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Chen", "Zhili", ""], ["Chen", "Sheng", ""], ["Zhong", "Hong", ""], ["Chen", "Lin", ""], ["Tian", "Miaomiao", ""]]}, {"id": "1810.08464", "submitter": "Manik Lal Das", "authors": "Atrayee Deb, Saloni Dalal, Manik Lal Das", "title": "DigiLock: User-controlled and Server-aware Digital Locker System", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing popularity of digital systems have paved the way for digital\nlocker that ensures security and safety of the digital documents in store.\nWhile facilitating this system to user and availing its services offered by\nservice provider, non-repudiation of service offered and service consumed is an\nimportant security requirement in the digital locker system. In this paper, we\npresent a digital locker system that addresses the aspect of confidentiality,\nintegrity, and non-repudiation along with other security properties. The\nproposed protocol ensures the confirmed participation of the user as well as\nthe service provider while accessing the digital locker. The protocol is\nanalyzed against potential threats in the context of safety and security of the\ndigital locker system.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 12:33:09 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Deb", "Atrayee", ""], ["Dalal", "Saloni", ""], ["Das", "Manik Lal", ""]]}, {"id": "1810.08509", "submitter": "Shun Zhang", "authors": "Shun Zhang, Laixiang Liu, Zhili Chen, Hong Zhong", "title": "Probabilistic Matrix Factorization with Personalized Differential\n  Privacy", "comments": "24 pages, 12 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic matrix factorization (PMF) plays a crucial role in\nrecommendation systems. It requires a large amount of user data (such as user\nshopping records and movie ratings) to predict personal preferences, and\nthereby provides users high-quality recommendation services, which expose the\nrisk of leakage of user privacy. Differential privacy, as a provable privacy\nprotection framework, has been applied widely to recommendation systems. It is\ncommon that different individuals have different levels of privacy requirements\non items. However, traditional differential privacy can only provide a uniform\nlevel of privacy protection for all users.\n  In this paper, we mainly propose a probabilistic matrix factorization\nrecommendation scheme with personalized differential privacy (PDP-PMF). It aims\nto meet users' privacy requirements specified at the item-level instead of\ngiving the same level of privacy guarantees for all. We then develop a modified\nsampling mechanism (with bounded differential privacy) for achieving PDP. We\nalso perform a theoretical analysis of the PDP-PMF scheme and demonstrate the\nprivacy of the PDP-PMF scheme. In addition, we implement the probabilistic\nmatrix factorization schemes both with traditional and with personalized\ndifferential privacy (DP-PMF, PDP-PMF) and compare them through a series of\nexperiments. The results show that the PDP-PMF scheme performs well on\nprotecting the privacy of each user and its recommendation quality is much\nbetter than the DP-PMF scheme.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 14:03:03 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Zhang", "Shun", ""], ["Liu", "Laixiang", ""], ["Chen", "Zhili", ""], ["Zhong", "Hong", ""]]}, {"id": "1810.08598", "submitter": "Md Sadek Ferdous", "authors": "Md Sadek Ferdous, Mohammad Jabed Morshed Chowdhury, Kamanashis Biswas,\n  Niaz Chowdhury", "title": "Immutable Autobiography of Smart Cars", "comments": "To be presented at the 3rd Symposium on Distributed Ledger Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of smart cars is increasing around the world as they offer a\nwide range of services and conveniences.These smart cars are equipped with a\nvariety of sensors generating a large amount of data, many of which are\nsensitive. Besides, there are multiple parties involved in a lifespan of a\nsmart car ,such as manufacturers, car owners, government agencies, and\nthird-party service providers who also produce data about the vehicle. In\naddition to managing and sharing data amongst these entities in a secure and\nprivacy-friendly way which is a great challenge itself, there exists a trust\ndeficit about some types of data as they remain under the custody of the car\nowner(e.g. satellite navigation and mileage data) and can easily be\nmanipulated. In this paper, we propose a blockchain supported architecture\nenabling the owner of a smart car to create an immutable record of every data,\ncalled the auto biography of a car, generated within its lifespan. We also\nexplain how the trust about this record is guaranteed by the immutability\ncharacteristic of the blockchain. Furthermore, the paper describes how the\nproposed architecture enables a secure and privacy-friendly sharing of smart\ncar data between different parties in a secure yet privacy-friendly manner.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 17:42:44 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Ferdous", "Md Sadek", ""], ["Chowdhury", "Mohammad Jabed Morshed", ""], ["Biswas", "Kamanashis", ""], ["Chowdhury", "Niaz", ""]]}, {"id": "1810.08640", "submitter": "Tsui-Wei Weng", "authors": "Tsui-Wei Weng, Huan Zhang, Pin-Yu Chen, Aurelie Lozano, Cho-Jui Hsieh,\n  Luca Daniel", "title": "On Extensions of CLEVER: A Neural Network Robustness Evaluation\n  Algorithm", "comments": "Accepted by GlobalSIP 2018. Tsui-Wei Weng and Huan Zhang contributed\n  equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CLEVER (Cross-Lipschitz Extreme Value for nEtwork Robustness) is an Extreme\nValue Theory (EVT) based robustness score for large-scale deep neural networks\n(DNNs). In this paper, we propose two extensions on this robustness score.\nFirst, we provide a new formal robustness guarantee for classifier functions\nthat are twice differentiable. We apply extreme value theory on the new formal\nrobustness guarantee and the estimated robustness is called second-order CLEVER\nscore. Second, we discuss how to handle gradient masking, a common defensive\ntechnique, using CLEVER with Backward Pass Differentiable Approximation (BPDA).\nWith BPDA applied, CLEVER can evaluate the intrinsic robustness of neural\nnetworks of a broader class -- networks with non-differentiable input\ntransformations. We demonstrate the effectiveness of CLEVER with BPDA in\nexperiments on a 121-layer Densenet model trained on the ImageNet dataset.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 18:44:58 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Weng", "Tsui-Wei", ""], ["Zhang", "Huan", ""], ["Chen", "Pin-Yu", ""], ["Lozano", "Aurelie", ""], ["Hsieh", "Cho-Jui", ""], ["Daniel", "Luca", ""]]}, {"id": "1810.08735", "submitter": "Tara Salman", "authors": "Tara Salman, Maede Zolanvari, Aiman Erbad, Raj Jain, and Mohammed\n  Samaka", "title": "Security Services Using Blockchains: A State of the Art Survey", "comments": "COMST 2018 accepted paper", "journal-ref": "IEEE Communications Surveys & Tutorials 2018", "doi": "10.1109/COMST.2018.2863956", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article surveys blockchain-based approaches for several security\nservices. These services include authentication, confidentiality, privacy, and\naccess control list (ACL), data and resource provenance, and integrity\nassurance. All these services are critical for the current distributed\napplications, especially due to the large amount of data being processed over\nthe networks and the use of cloud computing. Authentication ensures that the\nuser is who he/she claims to be. Confidentiality guarantees that data cannot be\nread by unauthorized users. Privacy provides the users the ability to control\nwho can access their data. Provenance allows an efficient tracking of the data\nand resources along with their ownership and utilization over the network.\nIntegrity helps in verifying that the data has not been modified or altered.\nThese services are currently managed by centralized controllers, for example, a\ncertificate authority. Therefore, the services are prone to attacks on the\ncentralized controller. On the other hand, blockchain is a secured and\ndistributed ledger that can help resolve many of the problems with\ncentralization. The objectives of this paper are to give insights on the use of\nsecurity services for current applications, to highlight the state of the art\ntechniques that are currently used to provide these services, to describe their\nchallenges, and to discuss how the blockchain technology can resolve these\nchallenges. Further, several blockchain-based approaches providing such\nsecurity services are compared thoroughly. Challenges associated with using\nblockchain-based security services are also discussed to spur further research\nin this area.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 02:28:11 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Salman", "Tara", ""], ["Zolanvari", "Maede", ""], ["Erbad", "Aiman", ""], ["Jain", "Raj", ""], ["Samaka", "Mohammed", ""]]}, {"id": "1810.08821", "submitter": "Durba Chatterjee", "authors": "Durba Chatterjee, Aritra Hazra, Debdeep Mukhopadhyay", "title": "Testability Analysis of PUFs Leveraging Correlation-Spectra in Boolean\n  Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testability of digital ICs rely on the principle of controllability and\nobservability. Adopting conventional techniques like scan-chains open up\navenues for attacks, and hence cannot be adopted in a straight-forward manner\nfor security chips. Furthermore, testing becomes incredibly challenging for the\npromising class of hardware security primitives, called PUFs, which offer\nunique properties like unclonability, unpredictibility, uniformity, uniqueness,\nand yet easily computable. However, the definition of PUF itself poses a\nchallenge on test engineers, simply because it has no golden response for a\ngiven input, often called challenge. In this paper, we develop a novel test\nstrategy considering that the fabrication of a batch of $N>1$ PUFs is\nequivalent to drawing random instances of Boolean mappings. We hence model the\nPUFs as black-box Boolean functions of dimension $m\\times1$, and show\ncombinatorially that random designs of such functions exhibit\ncorrelation-spectra which can be used to characterize random and thus {\\em\ngood} designs of PUFs. We first develop theoretical results to quantize the\ncorrelation values, and subsequently the expected number of pairs of such\nBoolean functions which should belong to a given spectra. In addition to this,\nwe show through extensive experimental results that a randomly chosen sample of\nsuch PUFs also resemble the correlation-spectra property of the overall PUF\npopulation. Interestingly, we show through experimental results on $50$ FPGAs\nthat when the PUFs are infected by faults the usual randomness tests for the\nPUF outputs such as uniformity, fail to detect any aberration. However, the\nspectral-pattern is clearly shown to get affected, which we demonstrate by\nstandard statistical tools. We finally propose a systematic testing framework\nfor the evaluation of PUFs by observing the correlation-spectra of the PUF\ninstances under test.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 15:40:56 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Chatterjee", "Durba", ""], ["Hazra", "Aritra", ""], ["Mukhopadhyay", "Debdeep", ""]]}, {"id": "1810.08885", "submitter": "Yikun Ban", "authors": "Yikun Ban, Jiao Sun, Xin Liu", "title": "Catching Loosely Synchronized Behavior in Face of Camouflage", "comments": "Submitted to WWW 2019, Oct.2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fraud has severely detrimental impacts on the business of social networks and\nother online applications. A user can become a fake celebrity by purchasing\n\"zombie followers\" on Twitter. A merchant can boost his reputation through fake\nreviews on Amazon. This phenomenon also conspicuously exists on Facebook, Yelp\nand TripAdvisor, etc. In all the cases, fraudsters try to manipulate the\nplatform's ranking mechanism by faking interactions between the fake accounts\nthey control and the target customers.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 03:08:01 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 13:23:00 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Ban", "Yikun", ""], ["Sun", "Jiao", ""], ["Liu", "Xin", ""]]}, {"id": "1810.08983", "submitter": "Pedro Hecht", "authors": "Pedro Hecht", "title": "PQC: Triple Decomposition Problem Applied To GL(d, Fp) - A Secure\n  Framework For Canonical Non-Commutative Cryptography", "comments": "9 pages, 1 Appendix included, 8 Tables", "journal-ref": null, "doi": "10.13140/RG.2.2.23240.78082", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-Quantum Cryptography (PQC) attempts to find cryptographic protocols\nresistant to attacks using Shor polynomial time algorithm for numerical field\nproblems or Grover search algorithm. A mostly overlooked but valuable line of\nsolutions is provided by non-commutative algebraic structures, specifically\ncanonical protocols that rely on one-way trapdoor functions (OWTF). Here we\ndevelop an algebraic framework who could be applied to different asymmetric\nprotocols like D-H KE (Diffie-Hellman key exchange), Public Key Encryption,\nDigital Signature, ZKP (zero-knowledge proof) authentication, Oblivious\nTransfer, Multi-Party Computing, and so on. The trapdoor one-way functions\nselected are (a) Triple decomposition Problem (TDP) developed by Kurt, where a\nknown element is factored into a product of three unknown factors and (b) a new\nversion of conjugacy search that we refer from now on as Blind Conjugacy Search\nProblem (BCSP). Our platform structure is the general linear group GL(d,F_p)\nd-square non-singular matrices of prime field values. We give support to the\nfact that this framework is cryptographically secure against classical attacks\nlike linear algebra attacks, length-based attacks, side-channel attacks against\nsquare (or duplicate) and multiply (or sum) algorithm, high sensitivity to\npseudo random deterministic generators, etc. At same time it is immune against\nquantum attacks (using Grover and Shor), if the size parameters are carefully\nselected. Semantic security and IND-CCA2 compliance for this framework is\ndiscussed.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 15:57:22 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 10:42:56 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Hecht", "Pedro", ""]]}, {"id": "1810.09065", "submitter": "Scott Stoller", "authors": "Christopher Kane, Bo Lin, Saksham Chand, Scott D. Stoller, Yanhong A.\n  Liu", "title": "High-level Cryptographic Abstractions", "comments": null, "journal-ref": "PLAS 2019: Proceedings of the 14th ACM SIGSAC Workshop on\n  Programming Languages and Analysis for Security. November 2019. Pages 31-43", "doi": "10.1145/3338504.3357343", "report-no": null, "categories": "cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interfaces exposed by commonly used cryptographic libraries are clumsy,\ncomplicated, and assume an understanding of cryptographic algorithms. The\nchallenge is to design high-level abstractions that require minimum knowledge\nand effort to use while also allowing maximum control when needed.\n  This paper proposes such high-level abstractions consisting of simple\ncryptographic primitives and full declarative configuration. These abstractions\ncan be implemented on top of any cryptographic library in any language. We have\nimplemented these abstractions in Python, and used them to write a wide variety\nof well-known security protocols, including Signal, Kerberos, and TLS.\n  We show that programs using our abstractions are much smaller and easier to\nwrite than using low-level libraries, where size of security protocols\nimplemented is reduced by about a third on average. We show our implementation\nincurs a small overhead, less than 5 microseconds for shared key operations and\nless than 341 microseconds (< 1%) for public key operations. We also show our\nabstractions are safe against main types of cryptographic misuse reported in\nthe literature.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 02:59:56 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 19:03:37 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Kane", "Christopher", ""], ["Lin", "Bo", ""], ["Chand", "Saksham", ""], ["Stoller", "Scott D.", ""], ["Liu", "Yanhong A.", ""]]}, {"id": "1810.09076", "submitter": "Stjepan Picek", "authors": "Lejla Batina and Shivam Bhasin and Dirmanto Jap and Stjepan Picek", "title": "CSI Neural Network: Using Side-channels to Recover Your Artificial\n  Neural Network Information", "comments": "15 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has become mainstream across industries. Numerous examples\nproved the validity of it for security applications. In this work, we\ninvestigate how to reverse engineer a neural network by using only power\nside-channel information. To this end, we consider a multilayer perceptron as\nthe machine learning architecture of choice and assume a non-invasive and\neavesdropping attacker capable of measuring only passive side-channel leakages\nlike power consumption, electromagnetic radiation, and reaction time.\n  We conduct all experiments on real data and common neural net architectures\nin order to properly assess the applicability and extendability of those\nattacks. Practical results are shown on an ARM CORTEX-M3 microcontroller. Our\nexperiments show that the side-channel attacker is capable of obtaining the\nfollowing information: the activation functions used in the architecture, the\nnumber of layers and neurons in the layers, the number of output classes, and\nweights in the neural network. Thus, the attacker can effectively reverse\nengineer the network using side-channel information.\n  Next, we show that once the attacker has the knowledge about the neural\nnetwork architecture, he/she could also recover the inputs to the network with\nonly a single-shot measurement. Finally, we discuss several mitigations one\ncould use to thwart such attacks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 04:13:17 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Batina", "Lejla", ""], ["Bhasin", "Shivam", ""], ["Jap", "Dirmanto", ""], ["Picek", "Stjepan", ""]]}, {"id": "1810.09160", "submitter": "Peter Snyder", "authors": "Peter Snyder, Antoine Vastel, Benjamin Livshits", "title": "Who Filters the Filters: Understanding the Growth, Usefulness and\n  Efficiency of Crowdsourced Ad Blocking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ad and tracking blocking extensions are popular tools for improving web\nperformance, privacy and aesthetics. Content blocking extensions typically rely\non filter lists to decide whether a web request is associated with tracking or\nadvertising, and so should be blocked. Millions of web users rely on filter\nlists to protect their privacy and improve their browsing experience.\n  Despite their importance, the growth and health of filter lists are poorly\nunderstood. Filter lists are maintained by a small number of contributors, who\nuse a variety of undocumented heuristics to determine what rules should be\nincluded. Lists quickly accumulate rules, and rules are rarely removed. As a\nresult, users' browsing experiences are degraded as the number of stale, dead\nor otherwise not useful rules increasingly dwarf the number of useful rules,\nwith no attenuating benefit. An accumulation of \"dead weight\" rules also makes\nit difficult to apply filter lists on resource-limited mobile devices.\n  This paper improves the understanding of crowdsourced filter lists by\nstudying EasyList, the most popular filter list. We find that EasyList has\ngrown from several hundred rules, to well over 60,000 rules, during its 9-year\nhistory. We measure how EasyList affects web browsing by applying EasyList to a\nsample of 10,000 websites. We find that 90.16% of the resource blocking rules\nin EasyList provide no benefit to users in common browsing scenarios. We\nfurther use our changes in EasyList application rates to provide a taxonomy of\nthe ways advertisers evade EasyList rules. Finally, we propose optimizations\nfor popular ad-blocking tools, that allow EasyList to be applied on performance\nconstrained mobile devices, and improve desktop performance by 62.5%, while\npreserving over 99% of blocking coverage.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 10:05:29 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 22:27:11 GMT"}, {"version": "v3", "created": "Thu, 21 May 2020 03:18:37 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Snyder", "Peter", ""], ["Vastel", "Antoine", ""], ["Livshits", "Benjamin", ""]]}, {"id": "1810.09203", "submitter": "Thomas Semrpinis", "authors": "Thomas Sermpinis, Christos Sermpinis", "title": "Traceability Decentralization in Supply Chain Management Using\n  Blockchain Technologies", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increase of web users and applications with real time requests, the\nability to identify, track and trace elements of a product as it moves in the\nsupply chain is deemed necessary, and for many industries is even mandated by\nnational or international regulations. Traceability presupposes the integrity\nand transparency of data that is saved and shared. This is a problem for\ncurrent technologies, as there are many examples with tampered data and\ndatabase vulnerabilities that resulted in serious implications and data loss. A\nsolution to this problem can be the decentralization of the system, which will\nremove the central point of failure. To that effect, blockchain or DLT\ntechnologies, an emergent technology that enables the decentralization of a\nnetwork can be used, by implementing a trustless model to achieve it.\nBlockchains are tamperproof and transparent, which means that by exploiting\nblockchain characteristics, traceability can be improved. A model that\ndescribes the decentralization process of the supply chain traceability part\nhas been developed for this paper and is later evaluated and compared with the\ntraditional system.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 12:18:56 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Sermpinis", "Thomas", ""], ["Sermpinis", "Christos", ""]]}, {"id": "1810.09225", "submitter": "Xiao Zhang", "authors": "Xiao Zhang, David Evans", "title": "Cost-Sensitive Robustness against Adversarial Examples", "comments": "ICLR final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent works have developed methods for training classifiers that are\ncertifiably robust against norm-bounded adversarial perturbations. These\nmethods assume that all the adversarial transformations are equally important,\nwhich is seldom the case in real-world applications. We advocate for\ncost-sensitive robustness as the criteria for measuring the classifier's\nperformance for tasks where some adversarial transformation are more important\nthan others. We encode the potential harm of each adversarial transformation in\na cost matrix, and propose a general objective function to adapt the robust\ntraining method of Wong & Kolter (2018) to optimize for cost-sensitive\nrobustness. Our experiments on simple MNIST and CIFAR10 models with a variety\nof cost matrices show that the proposed approach can produce models with\nsubstantially reduced cost-sensitive robust error, while maintaining\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 12:55:48 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 15:43:25 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Zhang", "Xiao", ""], ["Evans", "David", ""]]}, {"id": "1810.09438", "submitter": "Amro Awad", "authors": "Amro Awad, Laurent Njilla and Mao Ye", "title": "Triad-NVM: Persistent-Security for Integrity-Protected and Encrypted\n  Non-Volatile Memories (NVMs)", "comments": "This paper is currently under submission. We arXiv our paper to\n  establish credit for inventing this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging Non-Volatile Memories (NVMs) are promising contenders for building\nfuture memory systems. On the other side, unlike DRAM systems, NVMs can retain\ndata even after power loss and thus enlarge the attack surface. While data\nencryption and integrity verification have been proposed earlier for DRAM\nsystems, protecting and recovering secure memories becomes more challenging\nwith persistent memory. Specifically, security metadata, e.g., encryption\ncounters and Merkle Tree data, should be securely persisted and recovered\nacross system reboots and during recovery from crashes. Not persisting updates\nto security metadata can lead to data inconsistency, in addition to serious\nsecurity vulnerabilities.\n  In this paper, we pioneer a new direction that explores persistency of both\nMerkle Tree and encryption counters to enable secure recovery of\ndata-verifiable and encrypted memory systems. To this end, we coin a new\nconcept that we call Persistent-Security. We discuss the requirements for such\npersistently secure systems, propose novel optimizations, and evaluate the\nimpact of the proposed relaxation schemes and optimizations on performance,\nresilience and recovery time. To the best of our knowledge, our paper is the\nfirst to discuss the persistence of security metadata in integrity-protected\nNVM systems and provide corresponding optimizations. We define a set of\nrelaxation schemes that bring trade-offs between performance and recovery time\nfor large capacity NVM systems. Our results show that our proposed design,\nTriad-NVM, can improve the throughput by an average of ~2x (relative to strict\npersistence). Moreover, Triad-NVM maintains a recovery time of less than 4\nseconds for an 8TB NVM system (30.6 seconds for 64TB), which is ~3648x faster\nthan a system without security metadata persistence.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 21:21:28 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Awad", "Amro", ""], ["Njilla", "Laurent", ""], ["Ye", "Mao", ""]]}, {"id": "1810.09551", "submitter": "Dang Tu Nguyen", "authors": "Dang Tu Nguyen, Chengyu Song, Zhiyun Qian, Srikanth V. Krishnamurthy,\n  Edward J. M. Colbert, Patrick McDaniel", "title": "IoTSan: Fortifying the Safety of IoT Systems", "comments": "Proc. of the 14th ACM CoNEXT, 2018", "journal-ref": null, "doi": "10.1145/3281411.3281440", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's IoT systems include event-driven smart applications (apps) that\ninteract with sensors and actuators. A problem specific to IoT systems is that\nbuggy apps, unforeseen bad app interactions, or device/communication failures,\ncan cause unsafe and dangerous physical states. Detecting flaws that lead to\nsuch states, requires a holistic view of installed apps, component devices,\ntheir configurations, and more importantly, how they interact. In this paper,\nwe design IoTSan, a novel practical system that uses model checking as a\nbuilding block to reveal \"interaction-level\" flaws by identifying events that\ncan lead the system to unsafe states. In building IoTSan, we design novel\ntechniques tailored to IoT systems, to alleviate the state explosion associated\nwith model checking. IoTSan also automatically translates IoT apps into a\nformat amenable to model checking. Finally, to understand the root cause of a\ndetected vulnerability, we design an attribution mechanism to identify\nproblematic and potentially malicious apps. We evaluate IoTSan on the Samsung\nSmartThings platform. From 76 manually configured systems, IoTSan detects 147\nvulnerabilities. We also evaluate IoTSan with malicious SmartThings apps from a\nprevious effort. IoTSan detects the potential safety violations and also\neffectively attributes these apps as malicious.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 21:02:15 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 14:27:57 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Nguyen", "Dang Tu", ""], ["Song", "Chengyu", ""], ["Qian", "Zhiyun", ""], ["Krishnamurthy", "Srikanth V.", ""], ["Colbert", "Edward J. M.", ""], ["McDaniel", "Patrick", ""]]}, {"id": "1810.09619", "submitter": "Yiwen Guo", "authors": "Yiwen Guo, Chao Zhang, Changshui Zhang and Yurong Chen", "title": "Sparse DNNs with Improved Adversarial Robustness", "comments": "l1 regularization on weights --> l1 regularization on activations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are computationally/memory-intensive and\nvulnerable to adversarial attacks, making them prohibitive in some real-world\napplications. By converting dense models into sparse ones, pruning appears to\nbe a promising solution to reducing the computation/memory cost. This paper\nstudies classification models, especially DNN-based ones, to demonstrate that\nthere exists intrinsic relationships between their sparsity and adversarial\nrobustness. Our analyses reveal, both theoretically and empirically, that\nnonlinear DNN-based classifiers behave differently under $l_2$ attacks from\nsome linear ones. We further demonstrate that an appropriately higher model\nsparsity implies better robustness of nonlinear DNNs, whereas over-sparsified\nmodels can be more difficult to resist adversarial examples.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 01:05:41 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 01:32:50 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Guo", "Yiwen", ""], ["Zhang", "Chao", ""], ["Zhang", "Changshui", ""], ["Chen", "Yurong", ""]]}, {"id": "1810.09650", "submitter": "Jingkang Wang", "authors": "Jingkang Wang, Ruoxi Jia, Gerald Friedland, Bo Li, Costas Spanos", "title": "One Bit Matters: Understanding Adversarial Examples as the Abuse of\n  Redundancy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the great success achieved in machine learning (ML), adversarial\nexamples have caused concerns with regards to its trustworthiness: A small\nperturbation of an input results in an arbitrary failure of an otherwise\nseemingly well-trained ML model. While studies are being conducted to discover\nthe intrinsic properties of adversarial examples, such as their transferability\nand universality, there is insufficient theoretic analysis to help understand\nthe phenomenon in a way that can influence the design process of ML\nexperiments. In this paper, we deduce an information-theoretic model which\nexplains adversarial attacks as the abuse of feature redundancies in ML\nalgorithms. We prove that feature redundancy is a necessary condition for the\nexistence of adversarial examples. Our model helps to explain some major\nquestions raised in many anecdotal studies on adversarial examples. Our theory\nis backed up by empirical measurements of the information content of benign and\nadversarial examples on both image and text datasets. Our measurements show\nthat typical adversarial examples introduce just enough redundancy to overflow\nthe decision making of an ML model trained on corresponding benign examples. We\nconclude with actionable recommendations to improve the robustness of machine\nlearners against adversarial examples.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 04:23:25 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Wang", "Jingkang", ""], ["Jia", "Ruoxi", ""], ["Friedland", "Gerald", ""], ["Li", "Bo", ""], ["Spanos", "Costas", ""]]}, {"id": "1810.09752", "submitter": "Mara Sorella", "authors": "Florin Dragos Tanasache, Mara Sorella, Silvia Bonomi, Raniero Rapone,\n  Davide Meacci", "title": "Building an Emulation Environment for Cyber Security Analyses of Complex\n  Networked Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer networks are undergoing a phenomenal growth, driven by the rapidly\nincreasing number of nodes constituting the networks. At the same time, the\nnumber of security threats on Internet and intranet networks is constantly\ngrowing, and the testing and experimentation of cyber defense solutions\nrequires the availability of separate, test environments that best emulate the\ncomplexity of a real system. Such environments support the deployment and\nmonitoring of complex mission-driven network scenarios, thus enabling the study\nof cyber defense strategies under real and controllable traffic and attack\nscenarios. In this paper, we propose a methodology that makes use of a\ncombination of techniques of network and security assessment, and the use of\ncloud technologies to build an emulation environment with adjustable degree of\naffinity with respect to actual reference networks or planned systems. As a\nbyproduct, starting from a specific study case, we collected a dataset\nconsisting of complete network traces comprising benign and malicious traffic,\nwhich is feature-rich and publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 10:03:06 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Tanasache", "Florin Dragos", ""], ["Sorella", "Mara", ""], ["Bonomi", "Silvia", ""], ["Rapone", "Raniero", ""], ["Meacci", "Davide", ""]]}, {"id": "1810.10031", "submitter": "Mohammad Hashemi", "authors": "Mohammad Hashemi, Greg Cusack, Eric Keller", "title": "Stochastic Substitute Training: A Gray-box Approach to Craft Adversarial\n  Examples Against Gradient Obfuscation Defenses", "comments": "Accepted by AISec '18: 11th ACM Workshop on Artificial Intelligence\n  and Security. Source code at https://github.com/S-Mohammad-Hashemi/SST", "journal-ref": null, "doi": "10.1145/3270101.3270111", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that adversaries can craft example inputs to neural\nnetworks which are similar to legitimate inputs but have been created to\npurposely cause the neural network to misclassify the input. These adversarial\nexamples are crafted, for example, by calculating gradients of a carefully\ndefined loss function with respect to the input. As a countermeasure, some\nresearchers have tried to design robust models by blocking or obfuscating\ngradients, even in white-box settings. Another line of research proposes\nintroducing a separate detector to attempt to detect adversarial examples. This\napproach also makes use of gradient obfuscation techniques, for example, to\nprevent the adversary from trying to fool the detector. In this paper, we\nintroduce stochastic substitute training, a gray-box approach that can craft\nadversarial examples for defenses which obfuscate gradients. For those defenses\nthat have tried to make models more robust, with our technique, an adversary\ncan craft adversarial examples with no knowledge of the defense. For defenses\nthat attempt to detect the adversarial examples, with our technique, an\nadversary only needs very limited information about the defense to craft\nadversarial examples. We demonstrate our technique by applying it against two\ndefenses which make models more robust and two defenses which detect\nadversarial examples.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 18:14:47 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Hashemi", "Mohammad", ""], ["Cusack", "Greg", ""], ["Keller", "Eric", ""]]}, {"id": "1810.10109", "submitter": "Yanzi Zhu", "authors": "Yanzi Zhu, Zhujun Xiao, Yuxin Chen, Zhijing Li, Max Liu, Ben Y. Zhao,\n  Haitao Zheng", "title": "Et Tu Alexa? When Commodity WiFi Devices Turn into Adversarial Motion\n  Sensors", "comments": "NDSS'20", "journal-ref": null, "doi": "10.14722/ndss.2020.23053", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our work demonstrates a new set of silent reconnaissance attacks, which\nleverages the presence of commodity WiFi devices to track users inside private\nhomes and offices, without compromising any WiFi network, data packets, or\ndevices. We show that just by sniffing existing WiFi signals, an adversary can\naccurately detect and track movements of users inside a building. This is made\npossible by our new signal model that links together human motion near WiFi\ntransmitters and variance of multipath signal propagation seen by the attacker\nsniffer outside of the property. The resulting attacks are cheap, highly\neffective, and yet difficult to detect. We implement the attack using a single\ncommodity smartphone, deploy it in 11 real-world offices and residential\napartments, and show it is highly effective. Finally, we evaluate potential\ndefenses, and propose a practical and effective defense based on AP signal\nobfuscation.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 22:12:08 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 17:13:21 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 03:25:58 GMT"}, {"version": "v4", "created": "Sat, 11 Jan 2020 20:22:08 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Zhu", "Yanzi", ""], ["Xiao", "Zhujun", ""], ["Chen", "Yuxin", ""], ["Li", "Zhijing", ""], ["Liu", "Max", ""], ["Zhao", "Ben Y.", ""], ["Zheng", "Haitao", ""]]}, {"id": "1810.10121", "submitter": "Fabian Boemer", "authors": "Fabian Boemer, Yixing Lao, Rosario Cammarota, Casimir Wierzynski", "title": "nGraph-HE: A Graph Compiler for Deep Learning on Homomorphically\n  Encrypted Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Homomorphic encryption (HE)---the ability to perform computation on encrypted\ndata---is an attractive remedy to increasing concerns about data privacy in\ndeep learning (DL). However, building DL models that operate on ciphertext is\ncurrently labor-intensive and requires simultaneous expertise in DL,\ncryptography, and software engineering. DL frameworks and recent advances in\ngraph compilers have greatly accelerated the training and deployment of DL\nmodels to various computing platforms. We introduce nGraph-HE, an extension of\nnGraph, Intel's DL graph compiler, which enables deployment of trained models\nwith popular frameworks such as TensorFlow while simply treating HE as another\nhardware target. Our graph-compiler approach enables HE-aware optimizations--\nimplemented at compile-time, such as constant folding and HE-SIMD packing, and\nat run-time, such as special value plaintext bypass. Furthermore, nGraph-HE\nintegrates with DL frameworks such as TensorFlow, enabling data scientists to\nbenchmark DL models with minimal overhead.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 23:01:38 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 21:49:04 GMT"}, {"version": "v3", "created": "Tue, 2 Apr 2019 16:39:44 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Boemer", "Fabian", ""], ["Lao", "Yixing", ""], ["Cammarota", "Rosario", ""], ["Wierzynski", "Casimir", ""]]}, {"id": "1810.10123", "submitter": "Venkat Arun", "authors": "Venkat Arun, Aniket Kate, Deepak Garg, Peter Druschel, Bobby\n  Bhattacharjee", "title": "Finding Safety in Numbers with Secure Allegation Escrows", "comments": "To appear in NDSS 2020. New version includes improvements to writing\n  and proof. The protocol is unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For fear of retribution, the victim of a crime may be willing to report it\nonly if other victims of the same perpetrator also step forward. Common\nexamples include 1) identifying oneself as the victim of sexual harassment,\nespecially by a person in a position of authority or 2) accusing an influential\npolitician, an authoritarian government, or ones own employer of corruption. To\nhandle such situations, legal literature has proposed the concept of an\nallegation escrow: a neutral third-party that collects allegations anonymously,\nmatches them against each other, and de-anonymizes allegers only after\nde-anonymity thresholds (in terms of number of co-allegers), pre-specified by\nthe allegers, are reached.\n  An allegation escrow can be realized as a single trusted third party;\nhowever, this party must be trusted to keep the identity of the alleger and\ncontent of the allegation private. To address this problem, this paper\nintroduces Secure Allegation Escrows (SAE, pronounced \"say\"). A SAE is a group\nof parties with independent interests and motives, acting jointly as an escrow\nfor collecting allegations from individuals, matching the allegations, and\nde-anonymizing the allegations when designated thresholds are reached. By\ndesign, SAEs provide a very strong property: No less than a majority of parties\nconstituting a SAE can de-anonymize or disclose the content of an allegation\nwithout a sufficient number of matching allegations (even in collusion with any\nnumber of other allegers). Once a sufficient number of matching allegations\nexist, the join escrow discloses the allegation with the allegers' identities.\nWe describe how SAEs can be constructed using a novel authentication protocol\nand a novel allegation matching and bucketing algorithm, provide formal proofs\nof the security of our constructions, and evaluate a prototype implementation,\ndemonstrating feasibility in practice.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 23:08:14 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 00:34:34 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Arun", "Venkat", ""], ["Kate", "Aniket", ""], ["Garg", "Deepak", ""], ["Druschel", "Peter", ""], ["Bhattacharjee", "Bobby", ""]]}, {"id": "1810.10156", "submitter": "Zi Long", "authors": "Shengping Zhou and Zi Long and Lianzhi Tan and Hao Guo", "title": "Automatic Identification of Indicators of Compromise using Neural-Based\n  Sequence Labelling", "comments": "accepted by PACLIC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Indicators of Compromise (IOCs) are artifacts observed on a network or in an\noperating system that can be utilized to indicate a computer intrusion and\ndetect cyber-attacks in an early stage. Thus, they exert an important role in\nthe field of cybersecurity. However, state-of-the-art IOCs detection systems\nrely heavily on hand-crafted features with expert knowledge of cybersecurity,\nand require a large amount of supervised training corpora to train an IOC\nclassifier. In this paper, we propose using a neural-based sequence labelling\nmodel to identify IOCs automatically from reports on cybersecurity without\nexpert knowledge of cybersecurity. Our work is the first to apply an end-to-end\nsequence labelling to the task in IOCs identification. By using an attention\nmechanism and several token spelling features, we find that the proposed model\nis capable of identifying the low frequency IOCs from long sentences contained\nin cybersecurity reports. Experiments show that the proposed model outperforms\nother sequence labelling models, achieving over 88% average F1-score.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 02:40:14 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Zhou", "Shengping", ""], ["Long", "Zi", ""], ["Tan", "Lianzhi", ""], ["Guo", "Hao", ""]]}, {"id": "1810.10157", "submitter": "Yanzi Zhu", "authors": "Yanzi Zhu, Ying Ju, Bolun Wang, Jenna Cryan, Ben Y. Zhao, Haitao Zheng", "title": "Wireless Side-Lobe Eavesdropping Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millimeter-wave wireless networks offer high throughput and can (ideally)\nprevent eavesdropping attacks using narrow, directional beams. Unfortunately,\nimperfections in physical hardware mean today's antenna arrays all exhibit side\nlobes, signals that carry the same sensitive data as the main lobe. Our work\npresents results of the first experimental study of the security properties of\nmmWave transmissions against side-lobe eavesdropping attacks. We show that\nthese attacks on mmWave links are highly effective in both indoor and outdoor\nsettings, and they cannot be eliminated by improved hardware or currently\nproposed defenses.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 02:42:22 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Zhu", "Yanzi", ""], ["Ju", "Ying", ""], ["Wang", "Bolun", ""], ["Cryan", "Jenna", ""], ["Zhao", "Ben Y.", ""], ["Zheng", "Haitao", ""]]}, {"id": "1810.10369", "submitter": "Vahid Behzadan", "authors": "Vahid Behzadan and Arslan Munir", "title": "The Faults in Our Pi Stars: Security Issues and Open Challenges in Deep\n  Reinforcement Learning", "comments": "arXiv admin note: text overlap with arXiv:1807.06064,\n  arXiv:1712.03632, arXiv:1803.02811, arXiv:1710.00814 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the inception of Deep Reinforcement Learning (DRL) algorithms, there\nhas been a growing interest in both research and industrial communities in the\npromising potentials of this paradigm. The list of current and envisioned\napplications of deep RL ranges from autonomous navigation and robotics to\ncontrol applications in the critical infrastructure, air traffic control,\ndefense technologies, and cybersecurity. While the landscape of opportunities\nand the advantages of deep RL algorithms are justifiably vast, the security\nrisks and issues in such algorithms remain largely unexplored. To facilitate\nand motivate further research on these critical challenges, this paper presents\na foundational treatment of the security problem in DRL. We formulate the\nsecurity requirements of DRL, and provide a high-level threat model through the\nclassification and identification of vulnerabilities, attack vectors, and\nadversarial capabilities. Furthermore, we present a review of current\nliterature on security of deep RL from both offensive and defensive\nperspectives. Lastly, we enumerate critical research venues and open problems\nin mitigation and prevention of intentional attacks against deep RL as a\nroadmap for further research in this area.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 07:05:17 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Behzadan", "Vahid", ""], ["Munir", "Arslan", ""]]}, {"id": "1810.10436", "submitter": "Christian Majenz", "authors": "Christian Majenz", "title": "Entropy in Quantum Information Theory -- Communication and Cryptography", "comments": "PhD Thesis, University of Copenhagen, 144 pages. The abstract is\n  shortened to meet ArXiv requirements, please see the pdf for a more\n  informative abstract. Contains results from 1809.10751, 1610.04214 and\n  1605.00514", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this Thesis, several results in quantum information theory are collected,\nmost of which use entropy as the main mathematical tool. *While a direct\ngeneralization of the Shannon entropy to density matrices, the von Neumann\nentropy behaves differently. A long-standing open question is, whether there\nare quantum analogues of unconstrained non-Shannon type inequalities. Here, a\nnew constrained non-von-Neumann type inequality is proven, a step towards a\nconjectured unconstrained inequality by Linden and Winter. *IID quantum state\nmerging can be optimally achieved using the decoupling technique. The one-shot\nresults by Berta et al. and Anshu at al., however, had to bring in additional\nmathematical machinery. We introduce a natural generalized decoupling paradigm,\ncatalytic decoupling, that can reproduce the aforementioned results when used\nanalogously to the application of standard decoupling in the asymptotic case.\n*Port based teleportation, a variant of standard quantum teleportation\nprotocol, cannot be implemented perfectly. We prove several lower bounds on the\nnecessary number of output ports N to achieve port based teleportation for\ngiven error and input dimension, showing that N diverges uniformly in the\ndimension of the teleported quantum system, for vanishing error. As a\nbyproduct, a new lower bound for the size of the program register for an\napproximate universal programmable quantum processor is derived. *In the last\npart, we give a new definition for information-theoretic quantum\nnon-malleability, strengthening the previous definition by Ambainis et al. We\nshow that quantum non-malleability implies secrecy, analogous to quantum\nauthentication. Furthermore, non-malleable encryption schemes can be used as a\nprimitive to build authenticating encryption schemes. We also show that the\nstrong notion of authentication recently proposed by Garg et al. can be\nfulfilled using 2-designs.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 15:07:16 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Majenz", "Christian", ""]]}, {"id": "1810.10464", "submitter": "Meisam Mohammady memoh", "authors": "Meisam Mohammady, Lingyu Wang, Yuan Hong, Habib Louafi, Makan\n  Pourzandi, Mourad Debbabi", "title": "Preserving Both Privacy and Utility in Network Trace Anonymization", "comments": null, "journal-ref": null, "doi": "10.1145/3243734.3243809", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As network security monitoring grows more sophisticated, there is an\nincreasing need for outsourcing such tasks to third-party analysts. However,\norganizations are usually reluctant to share their network traces due to\nprivacy concerns over sensitive information, e.g., network and system\nconfiguration, which may potentially be exploited for attacks. In cases where\ndata owners are convinced to share their network traces, the data are typically\nsubjected to certain anonymization techniques, e.g., CryptoPAn, which replaces\nreal IP addresses with prefix-preserving pseudonyms. However, most such\ntechniques either are vulnerable to adversaries with prior knowledge about some\nnetwork flows in the traces, or require heavy data sanitization or\nperturbation, both of which may result in a significant loss of data utility.\nIn this paper, we aim to preserve both privacy and utility through shifting the\ntrade-off from between privacy and utility to between privacy and computational\ncost. The key idea is for the analysts to generate and analyze multiple\nanonymized views of the original network traces; those views are designed to be\nsufficiently indistinguishable even to adversaries armed with prior knowledge,\nwhich preserves the privacy, whereas one of the views will yield true analysis\nresults privately retrieved by the data owner, which preserves the utility. We\npresent the general approach and instantiate it based on CryptoPAn. We formally\nanalyze the privacy of our solution and experimentally evaluate it using real\nnetwork traces provided by a major ISP. The results show that our approach can\nsignificantly reduce the level of information leakage (e.g., less than 1\\% of\nthe information leaked by CryptoPAn) with comparable utility.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 15:54:26 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Mohammady", "Meisam", ""], ["Wang", "Lingyu", ""], ["Hong", "Yuan", ""], ["Louafi", "Habib", ""], ["Pourzandi", "Makan", ""], ["Debbabi", "Mourad", ""]]}, {"id": "1810.10635", "submitter": "Kasper Green Larsen", "authors": "Riko Jacob, Kasper Green Larsen, Jesper Buus Nielsen", "title": "Lower Bounds for Oblivious Data Structures", "comments": "To appear at SODA'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An oblivious data structure is a data structure where the memory access\npatterns reveals no information about the operations performed on it. Such data\nstructures were introduced by Wang et al. [ACM SIGSAC'14] and are intended for\nsituations where one wishes to store the data structure at an untrusted server.\nOne way to obtain an oblivious data structure is simply to run a classic data\nstructure on an oblivious RAM (ORAM). Until very recently, this resulted in an\noverhead of $\\omega(\\lg n)$ for the most natural setting of parameters.\nMoreover, a recent lower bound for ORAMs by Larsen and Nielsen [CRYPTO'18] show\nthat they always incur an overhead of at least $\\Omega(\\lg n)$ if used in a\nblack box manner. To circumvent the $\\omega(\\lg n)$ overhead, researchers have\ninstead studied classic data structure problems more directly and have obtained\nefficient solutions for many such problems such as stacks, queues, deques,\npriority queues and search trees. However, none of these data structures\nprocess operations faster than $\\Theta(\\lg n)$, leaving open the question of\nwhether even faster solutions exist. In this paper, we rule out this\npossibility by proving $\\Omega(\\lg n)$ lower bounds for oblivious stacks,\nqueues, deques, priority queues and search trees.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 21:43:32 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Jacob", "Riko", ""], ["Larsen", "Kasper Green", ""], ["Nielsen", "Jesper Buus", ""]]}, {"id": "1810.10649", "submitter": "Sajjad Arshad", "authors": "Reza Mirzazade Farkhani, Saman Jafari, Sajjad Arshad, William\n  Robertson, Engin Kirda, Hamed Okhravi", "title": "On the Effectiveness of Type-based Control Flow Integrity", "comments": "Annual Computer Security Applications Conference (ACSAC), San Juan,\n  Puerto Rico, USA, December 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Control flow integrity (CFI) has received significant attention in the\ncommunity to combat control hijacking attacks in the presence of memory\ncorruption vulnerabilities. The challenges in creating a practical CFI has\nresulted in the development of a new type of CFI based on runtime type checking\n(RTC). RTC-based CFI has been implemented in a number of recent practical\nefforts such as GRSecurity Reuse Attack Protector (RAP) and LLVM-CFI. While\nthere has been a number of previous efforts that studied the strengths and\nlimitations of other types of CFI techniques, little has been done to evaluate\nthe RTC-based CFI. In this work, we study the effectiveness of RTC from the\nsecurity and practicality aspects. From the security perspective, we observe\nthat type collisions are abundant in sufficiently large code bases but\nexploiting them to build a functional attack is not straightforward. Then we\nshow how an attacker can successfully bypass RTC techniques using a variant of\nROP attacks that respect type checking (called TROP) and also built two\nproof-of-concept exploits, one against Nginx web server and the other against\nExim mail server. We also discuss practical challenges of implementing RTC. Our\nfindings suggest that while RTC is more practical for applying CFI to large\ncode bases, its policy is not strong enough when facing a motivated attacker.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 22:59:19 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 00:28:24 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Farkhani", "Reza Mirzazade", ""], ["Jafari", "Saman", ""], ["Arshad", "Sajjad", ""], ["Robertson", "William", ""], ["Kirda", "Engin", ""], ["Okhravi", "Hamed", ""]]}, {"id": "1810.10731", "submitter": "Ram Shankar Siva Kumar", "authors": "Ram Shankar Siva Kumar, David R. O'Brien, Kendra Albert, Salome\n  Vilojen", "title": "Law and Adversarial Machine Learning", "comments": "Minor edits. Corrected typos, Added references. 4 pages, submitted to\n  NIPS 2018 Workshop on Security in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When machine learning systems fail because of adversarial manipulation, how\nshould society expect the law to respond? Through scenarios grounded in\nadversarial ML literature, we explore how some aspects of computer crime,\ncopyright, and tort law interface with perturbation, poisoning, model stealing\nand model inversion attacks to show how some attacks are more likely to result\nin liability than others. We end with a call for action to ML researchers to\ninvest in transparent benchmarks of attacks and defenses; architect ML systems\nwith forensics in mind and finally, think more about adversarial machine\nlearning in the context of civil liberties. The paper is targeted towards ML\nresearchers who have no legal background.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 06:17:34 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 02:45:10 GMT"}, {"version": "v3", "created": "Wed, 5 Dec 2018 02:02:46 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Kumar", "Ram Shankar Siva", ""], ["O'Brien", "David R.", ""], ["Albert", "Kendra", ""], ["Vilojen", "Salome", ""]]}, {"id": "1810.10746", "submitter": "Zhitao Guan", "authors": "Zhitao Guan, Jing Li, Longfei Wu, Yue Zhang, Jun Wu, Xiaojiang Du", "title": "Achieving Efficient and Secure Data Acquisition for Cloud-supported\n  Internet of Things in Smart Grid", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud-supported Internet of Things (Cloud-IoT) has been broadly deployed in\nsmart grid systems. The IoT front-ends are responsible for data acquisition and\nstatus supervision, while the substantial amount of data is stored and managed\nin the cloud server. Achieving data security and system efficiency in the data\nacquisition and transmission process are of great significance and challenging,\nbecause the power grid-related data is sensitive and in huge amount. In this\npaper, we present an efficient and secure data acquisition scheme based on\nCP-ABE (Ciphertext Policy Attribute Based Encryption). Data acquired from the\nterminals will be partitioned into blocks and encrypted with its corresponding\naccess sub-tree in sequence, thereby the data encryption and data transmission\ncan be processed in parallel. Furthermore, we protect the information about the\naccess tree with threshold secret sharing method, which can preserve the data\nprivacy and integrity from users with the unauthorized sets of attributes. The\nformal analysis demonstrates that the proposed scheme can fulfill the security\nrequirements of the Cloud-supported IoT in smart grid. The numerical analysis\nand experimental results indicate that our scheme can effectively reduce the\ntime cost compared with other popular approaches.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 07:33:58 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Guan", "Zhitao", ""], ["Li", "Jing", ""], ["Wu", "Longfei", ""], ["Zhang", "Yue", ""], ["Wu", "Jun", ""], ["Du", "Xiaojiang", ""]]}, {"id": "1810.10748", "submitter": "Zhitao Guan", "authors": "Zhitao Guan, Jing Li, Liehuang Zhu, Zijian Zhang, Xiaojiang Du, Mohsen\n  Guizani", "title": "Towards Delay-Tolerant Flexible Data Access Control for Smart Grid with\n  Renewable Energy Resources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Smart Grid with Renewable Energy Resources (RERs), the Residential\nUnits (RUs) with Distributed Energy Resources (DERs) are considered to be both\npower consumers and suppliers. Specifically, RUs with excessive renewable\ngenerations can trade with the utility in deficit of power supplies for mutual\nbenefits. It causes two challenging issues. First, the trading data of RUs is\nquite sensitive, which should be only accessed by authorized users with\nfine-grained policies. Second, the behaviors of the RUs to generate trading\ndata are spontaneous and unpredictable, then the problem is how to guarantee\nsystem efficiency and delay tolerance simultaneously. In this paper, we propose\na delay-tolerant flexible data access control scheme based on Key Policy\nAttribute Based Encryption (KP-ABE) for Smart Grid with Renewable Energy\nResources (RERs). We adopt the secret sharing scheme (SSS) to realize a\nflexible access control with encryption delay tolerance. Furthermore, there is\nno central trusted server to perform the encryption/decryption. We reduce the\ncomputation cost on RUs and operators via a semi-trusted model. The analysis\nshows that the proposed scheme can meet the data security requirement of the\nSmart Grid with RERs, and it also has less cost compared with other popular\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 07:35:59 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Guan", "Zhitao", ""], ["Li", "Jing", ""], ["Zhu", "Liehuang", ""], ["Zhang", "Zijian", ""], ["Du", "Xiaojiang", ""], ["Guizani", "Mohsen", ""]]}, {"id": "1810.10750", "submitter": "Zhitao Guan", "authors": "Jing Li, Zhitao Guan, Xiaojiang Du, Zijian Zhang, Jun Wu", "title": "An Efficient Encryption Scheme with Verifiable Outsourced Decryption in\n  Mobile Cloud Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing number of mobile applications and the popularity of cloud\ncomputing, the combination of these two techniques that named mobile cloud\ncomputing (MCC) attracts great attention in recent years. A promising public\nkey encryption scheme, Attribute-Based Encryption (ABE), especially the\nCiphertext Policy Attribute-Based Encryption (CP-ABE), has been used for\nrealizing fine-grained access control on encrypted data stored in MCC. However,\nthe computational overhead of encryption and decryption grow with the\ncomplexity of the access policy. Thus, maintaining data security as well as\nefficiency of data processing in MCC are important and challenging issues. In\nthis paper, we propose an efficient encryption method based on CP-ABE, which\ncan lower the overhead on data owners. To further reduce the decryption\noverhead on data receivers, we additionally propose a verifiable outsourced\ndecryption scheme. By security analysis and performance evaluation, the\nproposed scheme is proved to be secure as well as efficient.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 07:46:27 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Li", "Jing", ""], ["Guan", "Zhitao", ""], ["Du", "Xiaojiang", ""], ["Zhang", "Zijian", ""], ["Wu", "Jun", ""]]}, {"id": "1810.10751", "submitter": "Xiaoyun Wang", "authors": "Xiaoyun Wang, Minhao Cheng, Joe Eaton, Cho-Jui Hsieh, Felix Wu", "title": "Attack Graph Convolutional Networks by Adding Fake Nodes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the robustness of graph convolutional networks\n(GCNs). Previous work have shown that GCNs are vulnerable to adversarial\nperturbation on adjacency or feature matrices of existing nodes; however, such\nattacks are usually unrealistic in real applications. For instance, in social\nnetwork applications, the attacker will need to hack into either the client or\nserver to change existing links or features. In this paper, we propose a new\ntype of \"fake node attacks\" to attack GCNs by adding malicious fake nodes. This\nis much more realistic than previous attacks; in social network applications,\nthe attacker only needs to register a set of fake accounts and link to existing\nones. To conduct fake node attacks, a greedy algorithm is proposed to generate\nedges of malicious nodes and their corresponding features aiming to minimize\nthe classification accuracy on the target nodes. In addition, we introduce a\ndiscriminator to classify malicious nodes from real nodes, and propose a\nGreedy-GAN attack to simultaneously update the discriminator and the attacker,\nto make malicious nodes indistinguishable from the real ones. Our non-targeted\nattack decreases the accuracy of GCN down to 0.03, and our targeted attack\nreaches a success rate of 78% on a group of 100 nodes, and 90% on average for\nattacking a single target node.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 07:49:09 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 06:59:12 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 17:16:47 GMT"}, {"version": "v4", "created": "Thu, 3 Sep 2020 20:31:16 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Wang", "Xiaoyun", ""], ["Cheng", "Minhao", ""], ["Eaton", "Joe", ""], ["Hsieh", "Cho-Jui", ""], ["Wu", "Felix", ""]]}, {"id": "1810.10939", "submitter": "Bogdan Kulynych", "authors": "Bogdan Kulynych, Jamie Hayes, Nikita Samarin, Carmela Troncoso", "title": "Evading classifiers in discrete domains with provable optimality\n  guarantees", "comments": "NeurIPS 2018 Workshop on Security in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learning models for security-critical applications such as bot,\nmalware, or spam detection, operate in constrained discrete domains. These\napplications would benefit from having provable guarantees against adversarial\nexamples. The existing literature on provable adversarial robustness of models,\nhowever, exclusively focuses on robustness to gradient-based attacks in domains\nsuch as images. These attacks model the adversarial cost, e.g., amount of\ndistortion applied to an image, as a $p$-norm. We argue that this approach is\nnot well-suited to model adversarial costs in constrained domains where not all\nexamples are feasible.\n  We introduce a graphical framework that (1) generalizes existing attacks in\ndiscrete domains, (2) can accommodate complex cost functions beyond $p$-norms,\nincluding financial cost incurred when attacking a classifier, and (3)\nefficiently produces valid adversarial examples with guarantees of minimal\nadversarial cost. These guarantees directly translate into a notion of\nadversarial robustness that takes into account domain constraints and the\nadversary's capabilities. We show how our framework can be used to evaluate\nsecurity by crafting adversarial examples that evade a Twitter-bot detection\nclassifier with provably minimal number of changes; and to build privacy\ndefenses by crafting adversarial examples that evade a privacy-invasive\nwebsite-fingerprinting classifier.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 15:53:19 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 14:26:22 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2019 15:10:25 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Kulynych", "Bogdan", ""], ["Hayes", "Jamie", ""], ["Samarin", "Nikita", ""], ["Troncoso", "Carmela", ""]]}, {"id": "1810.11063", "submitter": "Filipo Sharevski", "authors": "Adam Trowbridge, Jessica Westbrook, Filipo Sharevski", "title": "Sorry: Ambient Tactical Deception Via Malware-Based Social Engineering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we argue, drawing from the perspectives of cybersecurity and\nsocial psychology, that Internet-based manipulation of an individual or group\nreality using ambient tactical deception is possible using only software and\nchanging words in a web browser. We call this attack Ambient Tactical Deception\n(ATD). Ambient, in artificial intelligence, describes software that is\n\"unobtrusive,\" and completely integrated into a user's life. Tactical deception\nis an information warfare term for the use of deception on an opposing force.\nWe suggest that an ATD attack could change the sentiment of text in a web\nbrowser. This could alter the victim's perception of reality by providing\ndisinformation. Within the limit of online communication, even a pause in\nreplying to a text can affect how people perceive each other. The outcomes of\nan ATD attack could include alienation, upsetting a victim, and influencing\ntheir feelings about an election, a spouse, or a corporation.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 18:42:01 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Trowbridge", "Adam", ""], ["Westbrook", "Jessica", ""], ["Sharevski", "Filipo", ""]]}, {"id": "1810.11153", "submitter": "Farhad Farokhi", "authors": "Farhad Farokhi", "title": "Development and Analysis of Deterministic Privacy-Preserving Policies\n  Using Non-Stochastic Information Theory", "comments": "improved introduction and numerical example", "journal-ref": "IEEE Transactions on Information Forensics and Security, 2019", "doi": "10.1109/TIFS.2019.2903660", "report-no": null, "categories": "cs.IT cs.CR cs.SY math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deterministic privacy metric using non-stochastic information theory is\ndeveloped. Particularly, minimax information is used to construct a measure of\ninformation leakage, which is inversely proportional to the measure of privacy.\nAnyone can submit a query to a trusted agent with access to a non-stochastic\nuncertain private dataset. Optimal deterministic privacy-preserving policies\nfor responding to the submitted query are computed by maximizing the measure of\nprivacy subject to a constraint on the worst-case quality of the response\n(i.e., the worst-case difference between the response by the agent and the\noutput of the query computed on the private dataset). The optimal\nprivacy-preserving policy is proved to be a piecewise constant function in the\nform of a quantization operator applied on the output of the submitted query.\nThe measure of privacy is also used to analyze the performance of $k$-anonymity\nmethodology (a popular deterministic mechanism for privacy-preserving release\nof datasets using suppression and generalization techniques), proving that it\nis in fact not privacy-preserving.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 00:42:11 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 23:00:24 GMT"}, {"version": "v3", "created": "Wed, 7 Nov 2018 22:44:24 GMT"}, {"version": "v4", "created": "Wed, 23 Jan 2019 01:56:16 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Farokhi", "Farhad", ""]]}, {"id": "1810.11175", "submitter": "Yong Yu", "authors": "Yong Yu, Yujie Ding, Yanqi Zhao, Yannan Li, Xiaojiang Du and Mohsen\n  Guizani", "title": "LRCoin: Leakage-resilient Cryptocurrency Based on Bitcoin for Data\n  Trading in IoT", "comments": "9 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, the number of Internet of Thing (IoT) devices making up the IoT is\nmore than 11 billion and this number has been continuously increasing. The\nprevalence of these devices leads to an emerging IoT business model called\nDevice-as-a-service(DaaS), which enables sensor devices to collect data\ndisseminated to all interested devices. The devices sharing data with other\ndevices could receive some financial reward such as Bitcoin. However,\nside-channel attacks, which aim to exploit some information leaked from the IoT\ndevices during data trade execution, are possible since most of the IoT devices\nare vulnerable to be hacked or compromised. Thus, it is challenging to securely\nrealize data trading in IoT environment due to the information leakage such as\nleaking the private key for signing a Bitcoin transaction in Bitcoin system. In\nthis paper, we propose LRCoin, a kind of leakage-resilient cryptocurrency based\non bitcoin in which the signature algorithm used for authenticating bitcoin\ntransactions is leakage-resilient. LRCoin is suitable for the scenarios where\ninformation leakage is inevitable such as IoT applications. Our core\ncontribution is proposing an efficient bilinear-based\ncontinual-leakage-resilient ECDSA signature. We prove the proposed signature\nalgorithm is unforgeable against adaptively chosen messages attack in the\ngeneric bilinear group model under the continual leakage setting. Both the\ntheoretical analysis and the implementation demonstrate the practicability of\nthe proposed scheme.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 03:37:27 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Yu", "Yong", ""], ["Ding", "Yujie", ""], ["Zhao", "Yanqi", ""], ["Li", "Yannan", ""], ["Du", "Xiaojiang", ""], ["Guizani", "Mohsen", ""]]}, {"id": "1810.11179", "submitter": "Yong Yu", "authors": "Yong Yu, Yannan Li, Xiaojiang Du, Ruonan Chen and Bo Yang", "title": "Content Protection in Named Data Networking: Challenges and Potential\n  Solutions", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information-Centric Networks (ICN) are promising alternatives to current\nInternet architecture since the Internet struggles with a number of issues such\nas scalability, mobility and security. ICN offers a number of potential\nbenefits including reduced congestion and enhanced delivery performance by\nemploying content caching, simpler network configurations and stronger security\nfor the content. Named Data Networking (NDN), an instance of the ICN, enables\ncontent delivery instead of host-centric approaches by naming data rather than\nthe host. In order to make NDN practical in the real world, the challenging\nissues of content security need to be addressed. In this article, we examine\nthe architecture, content security as well as possible solutions to these\nissues of NDN, with a special focus on content integrity and provenance. We\npropose a variety of digital signature schemes to achieve the data integrity\nand origin authentication in NDN for various applications, which include\ncost-effective signatures, privacy-preserving signatures, network coding\nsignatures, and post-quantum signatures. We also present the speed-up\ntechniques in generating signatures and verifying signatures such as\npre-computation, batch verification and server-aided verification to reduce the\ncomputational cost of the producers and receivers in NDN. A number of\ncertificate-free trust management approaches and possible adoptions in NDN are\ninvestigated.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 03:54:47 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Yu", "Yong", ""], ["Li", "Yannan", ""], ["Du", "Xiaojiang", ""], ["Chen", "Ruonan", ""], ["Yang", "Bo", ""]]}, {"id": "1810.11580", "submitter": "Guanhong Tao", "authors": "Guanhong Tao, Shiqing Ma, Yingqi Liu, Xiangyu Zhang", "title": "Attacks Meet Interpretability: Attribute-steered Detection of\n  Adversarial Samples", "comments": "Accepted to NIPS 2018 Spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial sample attacks perturb benign inputs to induce DNN misbehaviors.\nRecent research has demonstrated the widespread presence and the devastating\nconsequences of such attacks. Existing defense techniques either assume prior\nknowledge of specific attacks or may not work well on complex models due to\ntheir underlying assumptions. We argue that adversarial sample attacks are\ndeeply entangled with interpretability of DNN models: while classification\nresults on benign inputs can be reasoned based on the human perceptible\nfeatures/attributes, results on adversarial samples can hardly be explained.\nTherefore, we propose a novel adversarial sample detection technique for face\nrecognition models, based on interpretability. It features a novel\nbi-directional correspondence inference between attributes and internal neurons\nto identify neurons critical for individual attributes. The activation values\nof critical neurons are enhanced to amplify the reasoning part of the\ncomputation and the values of other neurons are weakened to suppress the\nuninterpretable part. The classification results after such transformation are\ncompared with those of the original model to detect adversaries. Results show\nthat our technique can achieve 94% detection accuracy for 7 different kinds of\nattacks with 9.91% false positives on benign inputs. In contrast, a\nstate-of-the-art feature squeezing technique can only achieve 55% accuracy with\n23.3% false positives.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 02:32:32 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Tao", "Guanhong", ""], ["Ma", "Shiqing", ""], ["Liu", "Yingqi", ""], ["Zhang", "Xiangyu", ""]]}, {"id": "1810.11605", "submitter": "Aashish Kolluri", "authors": "Aashish Kolluri, Ivica Nikolic, Ilya Sergey, Aquinas Hobor, Prateek\n  Saxena", "title": "Exploiting The Laws of Order in Smart Contracts", "comments": "18 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a family of bugs in blockchain-based smart contracts, which we\ncall event-ordering (or EO) bugs. These bugs are intimately related to the\ndynamic ordering of contract events, i.e., calls of its functions on the\nblockchain, and enable potential exploits of millions of USD worth of Ether.\nKnown examples of such bugs and prior techniques to detect them have been\nrestricted to a small number of event orderings, typicall 1 or 2. Our work\nprovides a new formulation of this general class of EO bugs as finding\nconcurrency properties arising in long permutations of such events. The\ntechnical challenge in detecting our formulation of EO bugs is the inherent\ncombinatorial blowup in path and state space analysis, even for simple\ncontracts. We propose the first use of partial-order reduction techniques,\nusing happen-before relations extracted automatically for contracts, along with\nseveral other optimizations built on a dynamic symbolic execution technique. We\nbuild an automatic tool called ETHRACER that requires no hints from users and\nruns directly on Ethereum bytecode. It flags 7-11% of over ten thousand\ncontracts analyzed in roughly 18.5 minutes per contract, providing compact\nevent traces that human analysts can run as witnesses. These witnesses are so\ncompact that confirmations require only a few minutes of human effort. Half of\nthe flagged contracts have subtle EO bugs, including in ERC-20 contracts that\ncarry hundreds of millions of dollars worth of Ether. Thus, ETHRACER is\neffective at detecting a subtle yet dangerous class of bugs which existing\ntools miss.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 06:41:38 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Kolluri", "Aashish", ""], ["Nikolic", "Ivica", ""], ["Sergey", "Ilya", ""], ["Hobor", "Aquinas", ""], ["Saxena", "Prateek", ""]]}, {"id": "1810.11622", "submitter": "Myoung Jin Nam", "authors": "Myoung Jin Nam, Periklis Akritidis, David J Greaves", "title": "FRAMER: A Software-based Capability Model", "comments": "15 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-grained memory protection for C and C++ programs must track individual\nobjects (or pointers), and store bounds information per object (pointer). Its\ncost is dominated by metadata updates and lookups, making efficient metadata\nmanagement the key for minimizing performance impact. Existing approaches\nreduce metadata management overheads by sacrificing precision, breaking binary\ncompatibility by changing object memory layout, or wasting space by excessive\nalignment or large shadow memory spaces. We propose FRAMER, a software\ncapability model for object-granularity memory protection. Its efficient\nper-object metadata management mechanism enables direct access to metadata by\ncalculating their location from a tagged pointer to the object and, for large\nobjects, a compact supplementary table. The number of bits in this tag and the\nsize of the supplementary table are balanced to minimize both using a novel\ntechnique. FRAMER is a general proposal for object metadata management with\npotential applications in memory safety, type safety, thread safety and garbage\ncollection that improves over previous solutions by (1) increasing locality of\nreference by having objects carry their metadata, (2) streamlining expensive\nmetadata lookups, (3) saving space by avoiding superfluous alignment and\npadding, (4) avoiding internal object memory layout changes.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 09:21:56 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 23:31:32 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Nam", "Myoung Jin", ""], ["Akritidis", "Periklis", ""], ["Greaves", "David J", ""]]}, {"id": "1810.11644", "submitter": "Ricardo Monge", "authors": "Osvaldo Skliar, Sherry Gapper, Ricardo E. Monge", "title": "A New Cryptographic Approach: Iterated Random Encryption (IRE)", "comments": "15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new cryptographic approach -- Iterated Random Encryption (IRE) -- is\npresented here. Although it is very simple, and easy to implement, it provides\na very high level of security. According to this approach, a sequence of\noperations applied to a message ($M$) yields the encrypted message ($M_E$). In\nthat series of operations, the one with the most important role is operation 6,\nwhich involves a random binary sequence (RBS) generated by using the Hybrid\nRandom Number Generator (HRNG) or the Mathematical Random Number Generator\n(MRNG). A sequence of anti-operations applied to $M_E$ makes it possible to\nrecover $M$.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 13:44:43 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Skliar", "Osvaldo", ""], ["Gapper", "Sherry", ""], ["Monge", "Ricardo E.", ""]]}, {"id": "1810.11655", "submitter": "Sabine Bertram", "authors": "Sabine Bertram and Co-Pierre Georg", "title": "A privacy-preserving system for data ownership using blockchain and\n  distributed databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain has the potential to revolutionize the way we store, use, and\nprocess data. Information on most blockchains can be viewed by every node\nhosting the blockchain, which means that most blockchains cannot handle private\ndata. Decentralized databases exist that guarantee privacy by encrypting user\ndata with the user's private key, but this prevents easy data sharing. However,\nin many real world applications, from student data to medical records, it is\ndesirable that user data is anonymously searchable. In this paper we present a\nnovel system that gives users ownership over their data while at the same time\nenabling them to make their data searchable within previously agreed upon\nlimits. Our system implements a strong notion of ownership using a\nself-sovereign identity system and a weak notion of ownership using multiple\ncentralized databases together with a blockchain and a tumbling process. We\ndiscuss applications of our methods to university's student records and medical\ndata.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 14:44:52 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Bertram", "Sabine", ""], ["Georg", "Co-Pierre", ""]]}, {"id": "1810.11793", "submitter": "Hiromu Yakura", "authors": "Hiromu Yakura, Jun Sakuma", "title": "Robust Audio Adversarial Example for a Physical Attack", "comments": "Accepted to IJCAI 2019", "journal-ref": null, "doi": "10.24963/ijcai.2019/741", "report-no": null, "categories": "cs.LG cs.CR cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to generate audio adversarial examples that can attack a\nstate-of-the-art speech recognition model in the physical world. Previous work\nassumes that generated adversarial examples are directly fed to the recognition\nmodel, and is not able to perform such a physical attack because of\nreverberation and noise from playback environments. In contrast, our method\nobtains robust adversarial examples by simulating transformations caused by\nplayback or recording in the physical world and incorporating the\ntransformations into the generation process. Evaluation and a listening\nexperiment demonstrated that our adversarial examples are able to attack\nwithout being noticed by humans. This result suggests that audio adversarial\nexamples generated by the proposed method may become a real threat.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 10:50:24 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 23:18:45 GMT"}, {"version": "v3", "created": "Mon, 4 Mar 2019 08:40:25 GMT"}, {"version": "v4", "created": "Mon, 19 Aug 2019 02:22:51 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Yakura", "Hiromu", ""], ["Sakuma", "Jun", ""]]}, {"id": "1810.11871", "submitter": "Jinwook Lee Ph.D.", "authors": "Jinwook Lee, Paul Moon Sub Choi", "title": "Chain of Antichains: An Efficient and Secure Distributed Ledger\n  Technology and Its Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the inception of blockchain and Bitcoin (Nakamoto (2008)), a\ndecentralized-distributed ledger system and its associated cryptocurrency,\nrespectively, the world has witnessed a slew of newer adaptations and\napplications. Although the original distributed ledger technology (DLT) of\nblockchain is deemed secure and decentralized, the confirmation of transactions\nis inefficient by design. Recently adopted, directed acyclic graph (DAG)-based\ndistributed ledgers validate transactions efficiently without the physically\nand environmentally costly building process of blocks (Lerner (2015)). However,\ncentrally-controlled confirmation against the odds of multiple validation\ndisqualifies the DAG as a decentralized-distributed ledger. In this regard, we\nintroduce an innovative DLT by reconstructing a chain of antichains based on a\ngiven DAG-pool of transactions. Each antichain (box) contains distinct nodes\nwhose approved transactions are recursively validated by subsequently\naugmenting nodes. The boxer node closes the box and keeps the hash of all\ntransactions confirmed by the box-genesis node. Designation of boxers and\nbox-geneses is conditionally randomized for decentralization. The boxes are\nserially concatenated with recursive confirmation (boxchain) without incurring\nthe cost of box generation. Rewards (boxcoin) are paid to the contributing\nnodes of the ecosystem whose trust is built on the doubly-secure protocol of\nconfirmation. A value-preserving medium of payment (boxdollar) is among\nnumerous practical applications discussed herein.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 19:52:02 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 00:51:18 GMT"}, {"version": "v3", "created": "Tue, 1 Jan 2019 23:24:56 GMT"}, {"version": "v4", "created": "Fri, 11 Jan 2019 15:00:02 GMT"}, {"version": "v5", "created": "Mon, 14 Jan 2019 18:47:26 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Lee", "Jinwook", ""], ["Choi", "Paul Moon Sub", ""]]}, {"id": "1810.11888", "submitter": "Matthias Geihs", "authors": "Matthias Geihs, Johannes Buchmann", "title": "ELSA: Efficient Long-Term Secure Storage of Large Datasets", "comments": "ICISC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing amount of information today is generated, exchanged, and stored\ndigitally. This also includes long-lived and highly sensitive information\n(e.g., electronic health records, governmental documents) whose integrity and\nconfidentiality must be protected over decades or even centuries. While there\nis a vast amount of cryptography-based data protection schemes, only few are\ndesigned for long-term protection. Recently, Braun et al. (AsiaCCS'17) proposed\nthe first long-term protection scheme that provides renewable integrity\nprotection and information-theoretic confidentiality protection. However,\ncomputation and storage costs of their scheme increase significantly with the\nnumber of stored data items. As a result, their scheme appears suitable only\nfor protecting databases with a small number of relatively large data items,\nbut unsuitable for databases that hold a large number of relatively small data\nitems (e.g., medical record databases). In this work, we present a solution for\nefficient long-term integrity and confidentiality protection of large datasets\nconsisting of relatively small data items. First, we construct a renewable\nvector commitment scheme that is information-theoretically hiding under\nselective decommitment. We then combine this scheme with renewable timestamps\nand information-theoretically secure secret sharing. The resulting solution\nrequires only a single timestamp for protecting a dataset while the state of\nthe art requires a number of timestamps linear in the number of data items. We\nimplemented our solution and measured its performance in a scenario where 12\n000 data items are aggregated, stored, protected, and verified over a time span\nof 100 years. Our measurements show that our new solution completes this\nevaluation scenario an order of magnitude faster than the state of the art.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 21:31:28 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Geihs", "Matthias", ""], ["Buchmann", "Johannes", ""]]}, {"id": "1810.11914", "submitter": "Dong Yin", "authors": "Dong Yin and Kannan Ramchandran and Peter Bartlett", "title": "Rademacher Complexity for Adversarially Robust Generalization", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning models are vulnerable to adversarial attacks; for\nexample, adding adversarial perturbations that are imperceptible to humans can\noften make machine learning models produce wrong predictions with high\nconfidence. Moreover, although we may obtain robust models on the training\ndataset via adversarial training, in some problems the learned models cannot\ngeneralize well to the test data. In this paper, we focus on $\\ell_\\infty$\nattacks, and study the adversarially robust generalization problem through the\nlens of Rademacher complexity. For binary linear classifiers, we prove tight\nbounds for the adversarial Rademacher complexity, and show that the adversarial\nRademacher complexity is never smaller than its natural counterpart, and it has\nan unavoidable dimension dependence, unless the weight vector has bounded\n$\\ell_1$ norm. The results also extend to multi-class linear classifiers. For\n(nonlinear) neural networks, we show that the dimension dependence in the\nadversarial Rademacher complexity also exists. We further consider a surrogate\nadversarial loss for one-hidden layer ReLU network and prove margin bounds for\nthis setting. Our results indicate that having $\\ell_1$ norm constraints on the\nweight matrices might be a potential way to improve generalization in the\nadversarial setting. We demonstrate experimental results that validate our\ntheoretical findings.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 00:51:08 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 06:40:59 GMT"}, {"version": "v3", "created": "Fri, 25 Jan 2019 07:03:12 GMT"}, {"version": "v4", "created": "Wed, 29 Jul 2020 04:23:34 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Yin", "Dong", ""], ["Ramchandran", "Kannan", ""], ["Bartlett", "Peter", ""]]}, {"id": "1810.11956", "submitter": "Sebastien Blandin", "authors": "Marc Jourdan, Sebastien Blandin, Laura Wynter, Pralhad Deshpande", "title": "Characterizing Entities in the Bitcoin Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin has created a new exchange paradigm within which financial\ntransactions can be trusted without an intermediary. This premise of a free\ndecentralized transactional network however requires, in its current\nimplementation, unrestricted access to the ledger for peer-based transaction\nverification. A number of studies have shown that, in this pseudonymous\ncontext, identities can be leaked based on transaction features or off-network\ninformation. In this work, we analyze the information revealed by the pattern\nof transactions in the neighborhood of a given entity transaction. By\ndefinition, these features which pertain to an extended network are not\ndirectly controllable by the entity, but might enable leakage of information\nabout transacting entities. We define a number of new features relevant to\nentity characterization on the Bitcoin Blockchain and study their efficacy in\npractice. We show that even a weak attacker with shallow data mining knowledge\nis able to leverage these features to characterize the entity properties.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 05:05:00 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Jourdan", "Marc", ""], ["Blandin", "Sebastien", ""], ["Wynter", "Laura", ""], ["Deshpande", "Pralhad", ""]]}, {"id": "1810.12035", "submitter": "Philipp Morgner", "authors": "Philipp Morgner and Zinaida Benenson", "title": "Exploring Security Economics in IoT Standardization Efforts", "comments": "NDSS Workshop on Decentralized IoT Security and Standards (DISS)\n  2018, 18 February 2018, San Diego, CA, USA", "journal-ref": null, "doi": "10.14722/diss.2018.23009", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) propagates the paradigm of interconnecting\nbillions of heterogeneous devices by various manufacturers. To enable IoT\napplications, the communication between IoT devices follows specifications\ndefined by standard developing organizations. In this paper, we present a case\nstudy that investigates disclosed insecurities of the popular IoT standard\nZigBee, and derive general lessons about security economics in IoT\nstandardization efforts. We discuss the motivation of IoT standardization\nefforts that are primarily driven from an economic perspective, in which large\ninvestments in security are not considered necessary since the consumers do not\nreward them. Success at the market is achieved by being quick-to-market,\nproviding functional features and offering easy integration for complementors.\nNevertheless, manufacturers should not only consider economic reasons but also\nsee their responsibility to protect humans and technological infrastructures\nfrom being threatened by insecure IoT products. In this context, we propose a\nnumber of recommendations to strengthen the security design in future IoT\nstandardization efforts, ranging from the definition of a precise security\nmodel to the enforcement of an update policy.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 10:07:17 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Morgner", "Philipp", ""], ["Benenson", "Zinaida", ""]]}, {"id": "1810.12042", "submitter": "Marius Mosbach", "authors": "Marius Mosbach, Maksym Andriushchenko, Thomas Trost, Matthias Hein,\n  Dietrich Klakow", "title": "Logit Pairing Methods Can Fool Gradient-Based Attacks", "comments": "Accepted to NeurIPS 2018 Workshop on Security in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Kannan et al. [2018] proposed several logit regularization methods\nto improve the adversarial robustness of classifiers. We show that the\ncomputationally fast methods they propose - Clean Logit Pairing (CLP) and Logit\nSqueezing (LSQ) - just make the gradient-based optimization problem of crafting\nadversarial examples harder without providing actual robustness. We find that\nAdversarial Logit Pairing (ALP) may indeed provide robustness against\nadversarial examples, especially when combined with adversarial training, and\nwe examine it in a variety of settings. However, the increase in adversarial\naccuracy is much smaller than previously claimed. Finally, our results suggest\nthat the evaluation against an iterative PGD attack relies heavily on the\nparameters used and may result in false conclusions regarding robustness of a\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 10:30:20 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 16:08:33 GMT"}, {"version": "v3", "created": "Tue, 12 Mar 2019 08:13:30 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Mosbach", "Marius", ""], ["Andriushchenko", "Maksym", ""], ["Trost", "Thomas", ""], ["Hein", "Matthias", ""], ["Klakow", "Dietrich", ""]]}, {"id": "1810.12188", "submitter": "Kwang-Sung Jun", "authors": "Kwang-Sung Jun, Lihong Li, Yuzhe Ma, Xiaojin Zhu", "title": "Adversarial Attacks on Stochastic Bandits", "comments": "accepted to NIPS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study adversarial attacks that manipulate the reward signals to control\nthe actions chosen by a stochastic multi-armed bandit algorithm. We propose the\nfirst attack against two popular bandit algorithms: $\\epsilon$-greedy and UCB,\n\\emph{without} knowledge of the mean rewards. The attacker is able to spend\nonly logarithmic effort, multiplied by a problem-specific parameter that\nbecomes smaller as the bandit problem gets easier to attack. The result means\nthe attacker can easily hijack the behavior of the bandit algorithm to promote\nor obstruct certain actions, say, a particular medical treatment. As bandits\nare seeing increasingly wide use in practice, our study exposes a significant\nsecurity threat.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 15:28:20 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Jun", "Kwang-Sung", ""], ["Li", "Lihong", ""], ["Ma", "Yuzhe", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "1810.12272", "submitter": "Dimitrios Diochnos", "authors": "Dimitrios I. Diochnos, Saeed Mahloujifar, Mohammad Mahmoody", "title": "Adversarial Risk and Robustness: General Definitions and Implications\n  for the Uniform Distribution", "comments": "Full version of a work with the same title that will appear in NIPS\n  2018, 31 pages containing 5 figures, 1 table, 2 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study adversarial perturbations when the instances are uniformly\ndistributed over $\\{0,1\\}^n$. We study both \"inherent\" bounds that apply to any\nproblem and any classifier for such a problem as well as bounds that apply to\nspecific problems and specific hypothesis classes.\n  As the current literature contains multiple definitions of adversarial risk\nand robustness, we start by giving a taxonomy for these definitions based on\ntheir goals, we identify one of them as the one guaranteeing misclassification\nby pushing the instances to the error region. We then study some classic\nalgorithms for learning monotone conjunctions and compare their adversarial\nrisk and robustness under different definitions by attacking the hypotheses\nusing instances drawn from the uniform distribution. We observe that sometimes\nthese definitions lead to significantly different bounds. Thus, this study\nadvocates for the use of the error-region definition, even though other\ndefinitions, in other contexts, may coincide with the error-region definition.\n  Using the error-region definition of adversarial perturbations, we then study\ninherent bounds on risk and robustness of any classifier for any classification\nproblem whose instances are uniformly distributed over $\\{0,1\\}^n$. Using the\nisoperimetric inequality for the Boolean hypercube, we show that for initial\nerror $0.01$, there always exists an adversarial perturbation that changes\n$O(\\sqrt{n})$ bits of the instances to increase the risk to $0.5$, making\nclassifier's decisions meaningless. Furthermore, by also using the central\nlimit theorem we show that when $n\\to \\infty$, at most $c \\cdot \\sqrt{n}$ bits\nof perturbations, for a universal constant $c< 1.17$, suffice for increasing\nthe risk to $0.5$, and the same $c \\cdot \\sqrt{n} $ bits of perturbations on\naverage suffice to increase the risk to $1$, hence bounding the robustness by\n$c \\cdot \\sqrt{n}$.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 17:41:29 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Diochnos", "Dimitrios I.", ""], ["Mahloujifar", "Saeed", ""], ["Mahmoody", "Mohammad", ""]]}, {"id": "1810.12380", "submitter": "Diego Chialva", "authors": "Diego Chialva and Ann Dooms", "title": "Conditionals in Homomorphic Encryption and Machine Learning Applications", "comments": "14 pages, 1 figure, corrected typos, added introductory pedagogical\n  section on polynomial approximation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Homomorphic encryption aims at allowing computations on encrypted data\nwithout decryption other than that of the final result. This could provide an\nelegant solution to the issue of privacy preservation in data-based\napplications, such as those using machine learning, but several open issues\nhamper this plan. In this work we assess the possibility for homomorphic\nencryption to fully implement its program without relying on other techniques,\nsuch as multiparty computation (SMPC), which may be impossible in many use\ncases (for instance due to the high level of communication required). We\nproceed in two steps: i) on the basis of the structured program theorem\n(Bohm-Jacopini theorem) we identify the relevant minimal set of operations\nhomomorphic encryption must be able to perform to implement any algorithm; and\nii) we analyse the possibility to solve -- and propose an implementation for --\nthe most fundamentally relevant issue as it emerges from our analysis, that is,\nthe implementation of conditionals (requiring comparison and selection/jump\noperations). We show how this issue clashes with the fundamental requirements\nof homomorphic encryption and could represent a drawback for its use as a\ncomplete solution for privacy preservation in data-based applications, in\nparticular machine learning ones. Our approach for comparisons is novel and\nentirely embedded in homomorphic encryption, while previous studies relied on\nother techniques, such as SMPC, demanding high level of communication among\nparties, and decryption of intermediate results from data-owners. Our protocol\nis also provably safe (sharing the same safety as the homomorphic encryption\nschemes), differently from other techniques such as\nOrder-Preserving/Revealing-Encryption (OPE/ORE).\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 19:44:23 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 19:02:20 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Chialva", "Diego", ""], ["Dooms", "Ann", ""]]}, {"id": "1810.12490", "submitter": "Fran\\c{c}ois Gauthier", "authors": "Alexander Jordan and Fran\\c{c}ois Gauthier and Behnaz Hassanshahi and\n  David Zhao", "title": "SAFE-PDF: Robust Detection of JavaScript PDF Malware Using Abstract\n  Interpretation", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of the PDF format and the rich JavaScript environment that PDF\nviewers offer make PDF documents an attractive attack vector for malware\ndevelopers. PDF documents present a serious threat to the security of\norganizations because most users are unsuspecting of them and thus likely to\nopen documents from untrusted sources. We propose to identify malicious PDFs by\nusing conservative abstract interpretation to statically reason about the\nbehavior of the embedded JavaScript code. Currently, state-of-the-art tools\neither: (1) statically identify PDF malware based on structural similarity to\nknown malicious samples; or (2) dynamically execute the code to detect\nmalicious behavior. These two approaches are subject to evasion attacks that\nmimic the structure of benign documents or do not exhibit their malicious\nbehavior when being analyzed dynamically. In contrast, abstract interpretation\nis oblivious to both types of evasions. A comparison with two state-of-the-art\nPDF malware detection tools shows that our conservative abstract interpretation\napproach achieves similar accuracy, while being more resilient to evasion\nattacks.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 02:17:48 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Jordan", "Alexander", ""], ["Gauthier", "Fran\u00e7ois", ""], ["Hassanshahi", "Behnaz", ""], ["Zhao", "David", ""]]}, {"id": "1810.12492", "submitter": "Mohammed Almukaynizi", "authors": "Mohammed Almukaynizi, Ericsson Marin, Eric Nunes, Paulo Shakarian,\n  Gerardo I. Simari, Dipsy Kapoor and Timothy Siedlecki", "title": "DARKMENTION: A Deployed System to Predict Enterprise-Targeted External\n  Cyberattacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent incidents of data breaches call for organizations to proactively\nidentify cyber attacks on their systems. Darkweb/Deepweb (D2web) forums and\nmarketplaces provide environments where hackers anonymously discuss existing\nvulnerabilities and commercialize malicious software to exploit those\nvulnerabilities. These platforms offer security practitioners a threat\nintelligence environment that allows to mine for patterns related to\norganization-targeted cyber attacks. In this paper, we describe a system\n(called DARKMENTION) that learns association rules correlating indicators of\nattacks from D2web to real-world cyber incidents. Using the learned rules,\nDARKMENTION generates and submits warnings to a Security Operations Center\n(SOC) prior to attacks. Our goal was to design a system that automatically\ngenerates enterprise-targeted warnings that are timely, actionable, accurate,\nand transparent. We show that DARKMENTION meets our goal. In particular, we\nshow that it outperforms baseline systems that attempt to generate warnings of\ncyber attacks related to two enterprises with an average increase in F1 score\nof about 45% and 57%. Additionally, DARKMENTION was deployed as part of a\nlarger system that is built under a contract with the IARPA Cyber-attack\nAutomated Unconventional Sensor Environment (CAUSE) program. It is actively\nproducing warnings that precede attacks by an average of 3 days.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 02:21:46 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Almukaynizi", "Mohammed", ""], ["Marin", "Ericsson", ""], ["Nunes", "Eric", ""], ["Shakarian", "Paulo", ""], ["Simari", "Gerardo I.", ""], ["Kapoor", "Dipsy", ""], ["Siedlecki", "Timothy", ""]]}, {"id": "1810.12518", "submitter": "Ilias Zadik", "authors": "Christian Borgs, Jennifer Chayes, Adam Smith, Ilias Zadik", "title": "Private Algorithms Can Always Be Extended", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CR cs.DS stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following fundamental question on $\\epsilon$-differential\nprivacy. Consider an arbitrary $\\epsilon$-differentially private algorithm\ndefined on a subset of the input space. Is it possible to extend it to an\n$\\epsilon'$-differentially private algorithm on the whole input space for some\n$\\epsilon'$ comparable with $\\epsilon$? In this note we answer affirmatively\nthis question for $\\epsilon'=2\\epsilon$. Our result applies to every input\nmetric space and space of possible outputs. This result originally appeared in\na recent paper by the authors [BCSZ18]. We present a self-contained version in\nthis note, in the hopes that it will be broadly useful.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 04:12:13 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 15:37:29 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Borgs", "Christian", ""], ["Chayes", "Jennifer", ""], ["Smith", "Adam", ""], ["Zadik", "Ilias", ""]]}, {"id": "1810.12715", "submitter": "Sven Gowal", "authors": "Sven Gowal, Krishnamurthy Dvijotham, Robert Stanforth, Rudy Bunel,\n  Chongli Qin, Jonathan Uesato, Relja Arandjelovic, Timothy Mann, Pushmeet\n  Kohli", "title": "On the Effectiveness of Interval Bound Propagation for Training\n  Verifiably Robust Models", "comments": "[v2] Best paper at NeurIPS SECML 2018 Workshop [v4] Accepted at ICCV\n  2019 under the title \"Scalable Verified Training for Provably Robust Image\n  Classification\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that it is possible to train deep neural networks that\nare provably robust to norm-bounded adversarial perturbations. Most of these\nmethods are based on minimizing an upper bound on the worst-case loss over all\npossible adversarial perturbations. While these techniques show promise, they\noften result in difficult optimization procedures that remain hard to scale to\nlarger networks. Through a comprehensive analysis, we show how a simple\nbounding technique, interval bound propagation (IBP), can be exploited to train\nlarge provably robust neural networks that beat the state-of-the-art in\nverified accuracy. While the upper bound computed by IBP can be quite weak for\ngeneral networks, we demonstrate that an appropriate loss and clever\nhyper-parameter schedule allow the network to adapt such that the IBP bound is\ntight. This results in a fast and stable learning algorithm that outperforms\nmore sophisticated methods and achieves state-of-the-art results on MNIST,\nCIFAR-10 and SVHN. It also allows us to train the largest model to be verified\nbeyond vacuous bounds on a downscaled version of ImageNet.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 13:12:47 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 11:48:21 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2019 16:53:04 GMT"}, {"version": "v4", "created": "Thu, 29 Aug 2019 12:23:52 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Gowal", "Sven", ""], ["Dvijotham", "Krishnamurthy", ""], ["Stanforth", "Robert", ""], ["Bunel", "Rudy", ""], ["Qin", "Chongli", ""], ["Uesato", "Jonathan", ""], ["Arandjelovic", "Relja", ""], ["Mann", "Timothy", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1810.12751", "submitter": "Yuqi Yu", "authors": "Yuqi Yu, Hanbing Yan, Hongchao Guan and Hao Zhou", "title": "DeepHTTP: Semantics-Structure Model with Attention for Anomalous HTTP\n  Traffic Detection and Pattern Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Internet age, cyber-attacks occur frequently with complex types.\nTraffic generated by access activities can record website status and user\nrequest information, which brings a great opportunity for network attack\ndetection. Among diverse network protocols, Hypertext Transfer Protocol (HTTP)\nis widely used in government, organizations and enterprises. In this work, we\npropose DeepHTTP, a semantics structure integration model utilizing\nBidirectional Long Short-Term Memory (Bi-LSTM) with attention mechanism to\nmodel HTTP traffic as a natural language sequence. In addition to extracting\ntraffic content information, we integrate structural information to enhance the\ngeneralization capabilities of the model. Moreover, the application of\nattention mechanism can assist in discovering critical parts of anomalous\ntraffic and further mining attack patterns. Additionally, we demonstrate how to\nincrementally update the data set and retrain model so that it can be adapted\nto new anomalous traffic. Extensive experimental evaluations over large traffic\ndata have illustrated that DeepHTTP has outstanding performance in traffic\ndetection and pattern discovery.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 14:07:48 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Yu", "Yuqi", ""], ["Yan", "Hanbing", ""], ["Guan", "Hongchao", ""], ["Zhou", "Hao", ""]]}, {"id": "1810.12786", "submitter": "Haaroon Yousaf", "authors": "Haaroon Yousaf, George Kappos, Sarah Meiklejohn", "title": "Tracing Transactions Across Cryptocurrency Ledgers", "comments": "14 pages, 13 tables, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the defining features of a cryptocurrency is that its ledger,\ncontaining all transactions that have evertaken place, is globally visible. As\none consequenceof this degree of transparency, a long line of recent re-search\nhas demonstrated that even in cryptocurrenciesthat are specifically designed to\nimprove anonymity it is often possible to track money as it changes hands,and\nin some cases to de-anonymize users entirely. With the recent proliferation of\nalternative cryptocurrencies, however, it becomes relevant to ask not only\nwhether ornot money can be traced as it moves within the ledgerof a single\ncryptocurrency, but if it can in fact be tracedas it moves across ledgers. This\nis especially pertinent given the rise in popularity of automated trading\nplatforms such as ShapeShift, which make it effortless to carry out such\ncross-currency trades. In this paper, weuse data scraped from ShapeShift over a\nthirteen-monthperiod and the data from eight different blockchains to explore\nthis question. Beyond developing new heuristics and creating new types of links\nacross cryptocurrency ledgers, we also identify various patterns of\ncross-currency trades and of the general usage of these platforms, with the\nultimate goal of understanding whetherthey serve a criminal or a profit-driven\nagenda.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 14:54:01 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 22:10:23 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Yousaf", "Haaroon", ""], ["Kappos", "George", ""], ["Meiklejohn", "Sarah", ""]]}, {"id": "1810.12881", "submitter": "Mingjie Sun", "authors": "Mingjie Sun, Jian Tang, Huichen Li, Bo Li, Chaowei Xiao, Yao Chen,\n  Dawn Song", "title": "Data Poisoning Attack against Unsupervised Node Embedding Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised node embedding methods (e.g., DeepWalk, LINE, and node2vec) have\nattracted growing interests given their simplicity and effectiveness. However,\nalthough these methods have been proved effective in a variety of applications,\nnone of the existing work has analyzed the robustness of them. This could be\nvery risky if these methods are attacked by an adversarial party. In this\npaper, we take the task of link prediction as an example, which is one of the\nmost fundamental problems for graph analysis, and introduce a data positioning\nattack to node embedding methods. We give a complete characterization of\nattacker's utilities and present efficient solutions to adversarial attacks for\ntwo popular node embedding methods: DeepWalk and LINE. We evaluate our proposed\nattack model on multiple real-world graphs. Experimental results show that our\nproposed model can significantly affect the results of link prediction by\nslightly changing the graph structures (e.g., adding or removing a few edges).\nWe also show that our proposed model is very general and can be transferable\nacross different embedding methods. Finally, we conduct a case study on a\ncoauthor network to better understand our attack method.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 17:25:30 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 04:09:57 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Sun", "Mingjie", ""], ["Tang", "Jian", ""], ["Li", "Huichen", ""], ["Li", "Bo", ""], ["Xiao", "Chaowei", ""], ["Chen", "Yao", ""], ["Song", "Dawn", ""]]}, {"id": "1810.12906", "submitter": "Mohammed Almukaynizi", "authors": "Mohammed Almukaynizi, Vivin Paliath, Malay Shah, Malav Shah, Paulo\n  Shakarian", "title": "Finding Cryptocurrency Attack Indicators Using Temporal Logic and\n  Darkweb Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent prevalence of darkweb/deepweb (D2web) sites specializing in\nthe trade of exploit kits and malware, malicious actors have easy-access to a\nwide-range of tools that can empower their offensive capability. In this study,\nwe apply concepts from causal reasoning, itemset mining, and logic programming\non historical cryptocurrency-related cyber incidents with intelligence\ncollected from over 400 D2web hacker forums. Our goal was to find indicators of\ncyber threats targeting cryptocurrency traders and exchange platforms from\nhacker activity. Our approach found interesting activities that, when observed\ntogether in the D2web, subsequent cryptocurrency-related incidents are at least\ntwice as likely to occur than they would if no activity was observed. We also\npresent an algorithmic extension to a previously-introduced algorithm called\nAPT-Extract that allows to model new semantic structures that are specific to\nour application.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 02:35:54 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Almukaynizi", "Mohammed", ""], ["Paliath", "Vivin", ""], ["Shah", "Malay", ""], ["Shah", "Malav", ""], ["Shakarian", "Paulo", ""]]}, {"id": "1810.13067", "submitter": "Warit Sirichotedumrong", "authors": "Warit Sirichotedumrong, Tatsuya Chuman, Hitoshi Kiya", "title": "Compression Performance of Grayscale-based Image Encryption for\n  Encryption-then-Compression Systems", "comments": "Accepted in International Technical Conference on Circuits/Systems,\n  Computers and Communications (ITC-CSCC) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a new grayscale-based image encryption for\nEncryption-then-Compression (EtC) systems with JPEG compression. Firstly,\ngeneration methods of grayscale-based images are discussed in terms of the\nselection of color space. In addition, a new JPEG quantization table for the\ngrayscale-based images is proposed to provide a better compression performance.\nMoreover, the quality of both images uploaded to Social Network Services (SNS)\nand downloaded from SNS, are discussed and evaluated. In the experiments,\nencrypted images are compressed using various compression parameters and\nquantization tables, and uploaded to Twitter and Facebook. The results proved\nthat the selection of color space and the proposed quantization table can\nimprove the compression performances of not only uploaded images but also\ndownloaded ones.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 01:50:27 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Sirichotedumrong", "Warit", ""], ["Chuman", "Tatsuya", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "1810.13310", "submitter": "Jukka Ruohonen", "authors": "Jukka Ruohonen", "title": "An Empirical Analysis of Vulnerabilities in Python Packages for Web\n  Applications", "comments": "Forthcoming in: Proceedings of the 9th International Workshop on\n  Empirical Software Engineering in Practice (IWESEP 2018), Nara, IEEE", "journal-ref": null, "doi": "10.1109/IWESEP.2018.00013", "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines software vulnerabilities in common Python packages used\nparticularly for web development. The empirical dataset is based on the PyPI\npackage repository and the so-called Safety DB used to track vulnerabilities in\nselected packages within the repository. The methodological approach builds on\na release-based time series analysis of the conditional probabilities for the\nreleases of the packages to be vulnerable. According to the results, many of\nthe Python vulnerabilities observed seem to be only modestly severe; input\nvalidation and cross-site scripting have been the most typical vulnerabilities.\nIn terms of the time series analysis based on the release histories, only the\nrecent past is observed to be relevant for statistical predictions; the\nclassical Markov property holds.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 14:41:12 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 05:25:54 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Ruohonen", "Jukka", ""]]}, {"id": "1810.13347", "submitter": "Farhad Shirani Chaharsooghi", "authors": "F. Shirani, S. Garg, E. Erkip", "title": "Matching Graphs with Community Structure: A Concentration of Measure\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, matching pairs of random graphs under the community structure\nmodel is considered. The problem emerges naturally in various applications such\nas privacy, image processing and DNA sequencing. A pair of randomly generated\nlabeled graphs with pairwise correlated edges are considered. It is assumed\nthat the graph edges are generated based on the community structure model.\nGiven the labeling of the edges of the first graph, the objective is to recover\nthe labels in the second graph. The problem is considered under two scenarios:\ni) with side-information where the community membership of the nodes in both\ngraphs are known, and ii) without side-information where the community\nmemberships are not known. A matching scheme is proposed which operates based\non typicality of the adjacency matrices of the graphs. Achievability results\nare derived which provide theoretical guarantees for successful matching under\nspecific assumptions on graph parameters. It is observed that for the proposed\nmatching scheme, the conditions for successful matching do not change in the\npresence of side-information. Furthermore, a converse result is derived which\ncharacterizes a set of graph parameters for which matching is not possible.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 15:36:50 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Shirani", "F.", ""], ["Garg", "S.", ""], ["Erkip", "E.", ""]]}, {"id": "1810.13367", "submitter": "Davino Mauro Junior", "authors": "Davino Mauro Junior, Kiev Gama and Atul Prakash", "title": "Securing IoT Apps with Fine-grained Control of Information Flows", "comments": "Paper accepted for publication in the XVIII Brazilian Symposium On\n  Information and Computational Systems Security", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things is growing rapidly, with many connected devices now\navailable to consumers. With this growth, the IoT apps that manage the devices\nfrom smartphones raise significant security concerns. Typically, these apps are\nsecured via sensitive credentials such as email and password that need to be\nvalidated through specific servers, thus requiring permissions to access the\nInternet. Unfortunately, even when developers are well-intentioned, such apps\ncan be non-trivial to secure so as to guarantee that user's credentials do not\nleak to unauthorized servers on the Internet. For example, if the app relies on\nthird-party libraries, as many do, those libraries can potentially capture and\nleak sensitive credentials. Bugs in the applications can also result in\nexploitable vulnerabilities that leak credentials. This paper presents our work\nin-progress on a prototype that enables developers to control how information\nflows within the app from sensitive UI data to specific servers. We extend\nFlowFence to enforce fine-grained information flow policies on sensitive UI\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 16:04:56 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 17:16:49 GMT"}, {"version": "v3", "created": "Sat, 3 Nov 2018 00:34:06 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Junior", "Davino Mauro", ""], ["Gama", "Kiev", ""], ["Prakash", "Atul", ""]]}]