[{"id": "0904.0109", "submitter": "Michael Huber", "authors": "Michael Huber", "title": "Authentication and Secrecy Codes for Equiprobable Source Probability\n  Distributions", "comments": "5 pages (double-column); to appear in Proc. IEEE International\n  Symposium on Information Theory (ISIT 2009, Seoul, South Korea)", "journal-ref": null, "doi": "10.1109/ISIT.2009.5206028", "report-no": null, "categories": "cs.CR cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give new combinatorial constructions for codes providing authentication\nand secrecy for equiprobable source probability distributions. In particular,\nwe construct an infinite class of optimal authentication codes which are\nmultiple-fold secure against spoofing and simultaneously achieve perfect\nsecrecy. Several further new optimal codes satisfying these properties will\nalso be constructed and presented in general tables. Almost all of these appear\nto be the first authentication codes with these properties.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2009 09:29:34 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Huber", "Michael", ""]]}, {"id": "0904.0308", "submitter": "Masahito Hayashi", "authors": "Masahito Hayashi", "title": "Exponential decreasing rate of leaked information in universal random\n  privacy amplification", "comments": "The organization is a little changed. This version is the same as the\n  published version", "journal-ref": "IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 57, NO. 6, JUNE\n  2011, 3989-4001", "doi": "10.1109/TIT.2011.2110950", "report-no": null, "categories": "cs.IT cs.CR math.AC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a new upper bound for Eve's information in secret key generation\nfrom a common random number without communication. This bound improves on\nBennett et al(1995)'s bound based on the R\\'enyi entropy of order 2 because the\nbound obtained here uses the R\\'enyi entropy of order $1+s$ for $s \\in [0,1]$.\nThis bound is applied to a wire-tap channel. Then, we derive an exponential\nupper bound for Eve's information. Our exponent is compared with\nHayashi(2006)'s exponent. For the additive case, the bound obtained here is\nbetter. The result is applied to secret key agreement by public discussion.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2009 05:38:27 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2010 10:50:41 GMT"}, {"version": "v3", "created": "Mon, 17 May 2010 02:34:12 GMT"}, {"version": "v4", "created": "Thu, 16 Sep 2010 03:33:07 GMT"}, {"version": "v5", "created": "Wed, 22 Jun 2011 23:48:20 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Hayashi", "Masahito", ""]]}, {"id": "0904.0525", "submitter": "Fang-Wei Fu", "authors": "Zhi-Han Gao and Fang-Wei Fu", "title": "The Minimal Polynomial over F_q of Linear Recurring Sequence over\n  F_{q^m}", "comments": "Submitted to the journal Finite Fields and Their Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, motivated by the study of vectorized stream cipher systems, the\njoint linear complexity and joint minimal polynomial of multisequences have\nbeen investigated. Let S be a linear recurring sequence over finite field\nF_{q^m} with minimal polynomial h(x) over F_{q^m}. Since F_{q^m} and F_{q}^m\nare isomorphic vector spaces over the finite field F_q, S is identified with an\nm-fold multisequence S^{(m)} over the finite field F_q. The joint minimal\npolynomial and joint linear complexity of the m-fold multisequence S^{(m)} are\nthe minimal polynomial and linear complexity over F_q of S respectively. In\nthis paper, we study the minimal polynomial and linear complexity over F_q of a\nlinear recurring sequence S over F_{q^m} with minimal polynomial h(x) over\nF_{q^m}. If the canonical factorization of h(x) in F_{q^m}[x] is known, we\ndetermine the minimal polynomial and linear complexity over F_q of the linear\nrecurring sequence S over F_{q^m}.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2009 07:49:57 GMT"}], "update_date": "2009-04-06", "authors_parsed": [["Gao", "Zhi-Han", ""], ["Fu", "Fang-Wei", ""]]}, {"id": "0904.0942", "submitter": "Michael Hay", "authors": "Michael Hay, Vibhor Rastogi, Gerome Miklau, and Dan Suciu", "title": "Boosting the Accuracy of Differentially-Private Histograms Through\n  Consistency", "comments": "15 pages, 7 figures, minor revisions to previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that it is possible to significantly improve the accuracy of a\ngeneral class of histogram queries while satisfying differential privacy. Our\napproach carefully chooses a set of queries to evaluate, and then exploits\nconsistency constraints that should hold over the noisy output. In a\npost-processing phase, we compute the consistent input most likely to have\nproduced the noisy output. The final output is differentially-private and\nconsistent, but in addition, it is often much more accurate. We show, both\ntheoretically and experimentally, that these techniques can be used for\nestimating the degree sequence of a graph very precisely, and for computing a\nhistogram that can support arbitrary range queries accurately.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2009 14:58:20 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2009 20:45:13 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2009 14:07:04 GMT"}, {"version": "v4", "created": "Thu, 4 Feb 2010 20:34:17 GMT"}, {"version": "v5", "created": "Fri, 9 Jul 2010 01:34:32 GMT"}], "update_date": "2010-07-12", "authors_parsed": [["Hay", "Michael", ""], ["Rastogi", "Vibhor", ""], ["Miklau", "Gerome", ""], ["Suciu", "Dan", ""]]}, {"id": "0904.1110", "submitter": "David Nowak", "authors": "David Nowak", "title": "On formal verification of arithmetic-based cryptographic primitives", "comments": "13 pages", "journal-ref": "In Information Security and Cryptology - ICISC 2008, 11th\n  International Conference, Seoul, Korea, December 3-5, 2008, Proceedings,\n  volume 5461 of Lecture Notes in Computer Science, pages 368-382, Springer", "doi": "10.1007/978-3-642-00730-9_23", "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptographic primitives are fundamental for information security: they are\nused as basic components for cryptographic protocols or public-key\ncryptosystems. In many cases, their security proofs consist in showing that\nthey are reducible to computationally hard problems. Those reductions can be\nsubtle and tedious, and thus not easily checkable. On top of the proof\nassistant Coq, we had implemented in previous work a toolbox for writing and\nchecking game-based security proofs of cryptographic primitives. In this paper\nwe describe its extension with number-theoretic capabilities so that it is now\npossible to write and check arithmetic-based cryptographic primitives in our\ntoolbox. We illustrate our work by machine checking the game-based proofs of\nunpredictability of the pseudo-random bit generator of Blum, Blum and Shub, and\nsemantic security of the public-key cryptographic scheme of Goldwasser and\nMicali.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2009 11:04:39 GMT"}], "update_date": "2009-04-08", "authors_parsed": [["Nowak", "David", ""]]}, {"id": "0904.1186", "submitter": "Bjoern Grohmann", "authors": "Bjoern Grohmann", "title": "A New Key-Agreement-Protocol", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new 4-pass Key-Agreement Protocol is presented. The security of the\nprotocol mainly relies on the existence of a (polynomial-computable)\nOne-Way-Function and the supposed computational hardness of solving a specific\nsystem of equations.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2009 17:45:52 GMT"}], "update_date": "2009-04-08", "authors_parsed": [["Grohmann", "Bjoern", ""]]}, {"id": "0904.1284", "submitter": "Manabu Inuma", "authors": "Manabu Inuma, Akira Otsuka, Hideki Imai", "title": "Theoretical framework for constructing matching algorithms in biometric\n  authentication systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a theoretical framework to construct matching\nalgorithms for any biometric authentication systems. Conventional matching\nalgorithms are not necessarily secure against strong intentional impersonation\nattacks such as wolf attacks. The wolf attack is an attempt to impersonate a\ngenuine user by presenting a \"wolf\" to a biometric authentication system\nwithout the knowledge of a genuine user's biometric sample. A wolf is a sample\nwhich can be accepted as a match with multiple templates. The wolf attack\nprobability (WAP) is the maximum success probability of the wolf attack, which\nwas proposed by Une, Otsuka, Imai as a measure for evaluating security of\nbiometric authentication systems. We present a principle for construction of\nsecure matching algorithms against the wolf attack for any biometric\nauthentication systems. The ideal matching algorithm determines a threshold for\neach input value depending on the entropy of the probability distribution of\nthe (Hamming) distances. Then we show that if the information about the\nprobability distribution for each input value is perfectly given, then our\nmatching algorithm is secure against the wolf attack. Our generalized matching\nalgorithm gives a theoretical framework to construct secure matching\nalgorithms. How lower WAP is achievable depends on how accurately the entropy\nis estimated. Then there is a trade-off between the efficiency and the\nachievable WAP. Almost every conventional matching algorithm employs a fixed\nthreshold and hence it can be regarded as an efficient but insecure instance of\nour theoretical framework. Daugman's IrisCode recognition algorithm proposed\ncan also be regarded as a non-optimal instance of our framework.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2009 08:48:30 GMT"}], "update_date": "2009-04-09", "authors_parsed": [["Inuma", "Manabu", ""], ["Otsuka", "Akira", ""], ["Imai", "Hideki", ""]]}, {"id": "0904.1616", "submitter": "Juan Meza", "authors": "Juan Meza, Scott Campbell, and David Bailey", "title": "Mathematical and Statistical Opportunities in Cyber Security", "comments": null, "journal-ref": null, "doi": null, "report-no": "LBNL-1667E", "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The role of mathematics in a complex system such as the Internet has yet to\nbe deeply explored. In this paper, we summarize some of the important and\npressing problems in cyber security from the viewpoint of open science\nenvironments. We start by posing the question \"What fundamental problems exist\nwithin cyber security research that can be helped by advanced mathematics and\nstatistics?\" Our first and most important assumption is that access to\nreal-world data is necessary to understand large and complex systems like the\nInternet. Our second assumption is that many proposed cyber security solutions\ncould critically damage both the openness and the productivity of scientific\nresearch. After examining a range of cyber security problems, we come to the\nconclusion that the field of cyber security poses a rich set of new and\nexciting research opportunities for the mathematical and statistical sciences.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2009 22:30:03 GMT"}], "update_date": "2009-04-13", "authors_parsed": [["Meza", "Juan", ""], ["Campbell", "Scott", ""], ["Bailey", "David", ""]]}, {"id": "0904.2023", "submitter": "Bjoern Grohmann", "authors": "Bjoern Grohmann", "title": "A new Protocol for 1-2 Oblivious Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new protocol for 1-2 (String) Oblivious Transfer is proposed. The protocol\nuses 5 rounds of message exchange.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2009 22:30:53 GMT"}], "update_date": "2009-04-15", "authors_parsed": [["Grohmann", "Bjoern", ""]]}, {"id": "0904.2722", "submitter": "MinJi Kim", "authors": "MinJi Kim, Lu\\'isa Lima, Fang Zhao, Joao Barros, Muriel Medard, Ralf\n  Koetter, Ton Kalker, Keesook Han", "title": "On Counteracting Byzantine Attacks in Network Coded Peer-to-Peer\n  Networks", "comments": "26 pages, 9 figures, Submitted to IEEE Journal on Selected Areas in\n  Communications (JSAC) \"Mission Critical Networking\"", "journal-ref": null, "doi": "10.1109/JSAC.2010.100607", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random linear network coding can be used in peer-to-peer networks to increase\nthe efficiency of content distribution and distributed storage. However, these\nsystems are particularly susceptible to Byzantine attacks. We quantify the\nimpact of Byzantine attacks on the coded system by evaluating the probability\nthat a receiver node fails to correctly recover a file. We show that even for a\nsmall probability of attack, the system fails with overwhelming probability. We\nthen propose a novel signature scheme that allows packet-level Byzantine\ndetection. This scheme allows one-hop containment of the contamination, and\nsaves bandwidth by allowing nodes to detect and drop the contaminated packets.\nWe compare the net cost of our signature scheme with various other Byzantine\nschemes, and show that when the probability of Byzantine attacks is high, our\nscheme is the most bandwidth efficient.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2009 15:31:46 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Kim", "MinJi", ""], ["Lima", "Lu\u00edsa", ""], ["Zhao", "Fang", ""], ["Barros", "Joao", ""], ["Medard", "Muriel", ""], ["Koetter", "Ralf", ""], ["Kalker", "Ton", ""], ["Han", "Keesook", ""]]}, {"id": "0904.3420", "submitter": "Vandani Verma", "authors": "Sunder Lal and Vandani Verma", "title": "Identity Based Strong Designated Verifier Parallel Multi-Proxy Signature\n  Scheme", "comments": "6 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new identity based strong designated verifier parallel\nmulti-proxy signature scheme. Multi-Proxy signatures allow the original signer\nto delegate his signing power to a group of proxy signers. In our scheme, the\ndesignated verifier can only validate proxy signatures created by a group of\nproxy signer.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2009 10:07:16 GMT"}], "update_date": "2009-09-30", "authors_parsed": [["Lal", "Sunder", ""], ["Verma", "Vandani", ""]]}, {"id": "0904.3422", "submitter": "Vandani Verma", "authors": "Sunder Lal and Vandani Verma", "title": "Some Proxy Signature and Designated verifier Signature Schemes over\n  Braid Groups", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Braids groups provide an alternative to number theoretic public cryptography\nand can be implemented quite efficiently. The paper proposes five signature\nschemes: Proxy Signature, Designated Verifier, Bi-Designated Verifier,\nDesignated Verifier Proxy Signature And Bi-Designated Verifier Proxy Signature\nscheme based on braid groups. We also discuss the security aspects of each of\nthe proposed schemes.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2009 10:14:06 GMT"}], "update_date": "2009-09-30", "authors_parsed": [["Lal", "Sunder", ""], ["Verma", "Vandani", ""]]}, {"id": "0904.3458", "submitter": "Praveen Sivadasan", "authors": "Praveen Sivadasan, P Sojan Lal", "title": "JConstHide: A Framework for Java Source Code Constant Hiding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software obfuscation or obscuring a software is an approach to defeat the\npractice of reverse engineering a software for using its functionality\nillegally in the development of another software. Java applications are more\namenable to reverse engineering and re-engineering attacks through methods such\nas decompilation because Java class files store the program in a semi complied\nform called byte codes. The existing obfuscation systems obfuscate the Java\nclass files. Obfuscated source code produce obfuscated byte codes and hence two\nlevel obfuscation (source code and byte code level) of the program makes it\nmore resilient to reverse engineering attacks . But source code obfuscation is\nmuch more difficult due to richer set of programming constructs and the scope\nof the different variables used in the program and only very little progress\nhas been made on this front. We in this paper are proposing a framework named\nJConstHide for hiding constants, especially integers in the java source codes,\nto defeat reverse engineering through decompilation. To the best of our\nknowledge, no data hiding software are available for java source code constant\nhiding.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2009 13:15:31 GMT"}], "update_date": "2009-04-23", "authors_parsed": [["Sivadasan", "Praveen", ""], ["Lal", "P Sojan", ""]]}, {"id": "0904.3789", "submitter": "Serguei Mokhov", "authors": "Serguei A. Mokhov and Joey Paquet", "title": "Formally Specifying and Proving Operational Aspects of Forensic Lucid in\n  Isabelle", "comments": "23 pages, 3 listings, 3 figures, 1 table, 1 Appendix with theorems,\n  pp. 76--98. TPHOLs 2008 Emerging Trends Proceedings, August 18-21, Montreal,\n  Canada. Editors: Otmane Ait Mohamed and Cesar Munoz and Sofiene Tahar. The\n  individual paper's PDF is at\n  http://users.encs.concordia.ca/~tphols08/TPHOLs2008/ET/76-98.pdf", "journal-ref": null, "doi": null, "report-no": "2008-1-Ait Mohamed", "categories": "cs.LO cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Forensic Lucid intensional programming language has been proposed for\nintensional cyberforensic analysis. In large part, the language is based on\nvarious predecessor and codecessor Lucid dialects bound by the higher-order\nintensional logic (HOIL) that is behind them. This work formally specifies the\noperational aspects of the Forensic Lucid language and compiles a theory of its\nconstructs using Isabelle, a proof assistant system.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2009 03:30:20 GMT"}], "update_date": "2009-05-08", "authors_parsed": [["Mokhov", "Serguei A.", ""], ["Paquet", "Joey", ""]]}, {"id": "0904.4058", "submitter": "Gregory Price", "authors": "Jeff Arnold, Tim Abbott, Waseem Daher, Gregory Price, Nelson Elhage,\n  Geoffrey Thomas, Anders Kaseorg", "title": "Security impact ratings considered harmful", "comments": "HotOS 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we question the common practice of assigning security impact\nratings to OS updates. Specifically, we present evidence that ranking updates\nby their perceived security importance, in order to defer applying some\nupdates, exposes systems to significant risk.\n  We argue that OS vendors and security groups should not focus on security\nupdates to the detriment of other updates, but should instead seek update\ntechnologies that make it feasible to distribute updates for all disclosed OS\nbugs in a timely manner.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2009 20:57:42 GMT"}], "update_date": "2009-04-28", "authors_parsed": [["Arnold", "Jeff", ""], ["Abbott", "Tim", ""], ["Daher", "Waseem", ""], ["Price", "Gregory", ""], ["Elhage", "Nelson", ""], ["Thomas", "Geoffrey", ""], ["Kaseorg", "Anders", ""]]}, {"id": "0904.4073", "submitter": "Momtchil Peev", "authors": "Solange Ghernaouti-Helie, Igli Tashi, Thomas Laenger, Christian Monyk", "title": "SECOQC Business White Paper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In contemporary cryptographic systems, secret keys are usually exchanged by\nmeans of methods, which suffer from mathematical and technology inherent\ndrawbacks. That could lead to unnoticed complete compromise of cryptographic\nsystems, without a chance of control by its legitimate owners. Therefore a need\nfor innovative solutions exists when truly and reliably secure transmission of\nsecrets is required for dealing with critical data and applications. Quantum\nCryptography (QC), in particular Quantum Key Distribution (QKD) can answer that\nneed.\n  The business white paper (BWP) summarizes how secret key establishment and\ndistribution problems can be solved by quantum cryptography. It deals with\nseveral considerations related to how the quantum cryptography innovation could\ncontribute to provide business effectiveness. It addresses advantages and also\nlimitations of quantum cryptography, proposes a scenario case study, and\ninvokes standardization related issues. In addition, it answers most frequently\nasked questions about quantum cryptography.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2009 01:49:40 GMT"}], "update_date": "2009-04-28", "authors_parsed": [["Ghernaouti-Helie", "Solange", ""], ["Tashi", "Igli", ""], ["Laenger", "Thomas", ""], ["Monyk", "Christian", ""]]}, {"id": "0904.4412", "submitter": "Anne Canteaut", "authors": "Anne Canteaut (INRIA Rocquencourt), Maria Naya-Plasencia (INRIA\n  Rocquencourt)", "title": "Computing the biases of parity-check relations", "comments": null, "journal-ref": "2009 IEEE International Symposium on Information Theory\n  (ISIT2009), Seoul : Cor\\'ee, R\\'epublique de (2009)", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A divide-and-conquer cryptanalysis can often be mounted against some\nkeystream generators composed of several (nonlinear) independent devices\ncombined by a Boolean function. In particular, any parity-check relation\nderived from the periods of some constituent sequences usually leads to a\ndistinguishing attack whose complexity is determined by the bias of the\nrelation. However, estimating this bias is a difficult problem since the\npiling-up lemma cannot be used. Here, we give two exact expressions for this\nbias. Most notably, these expressions lead to a new algorithm for computing the\nbias of a parity-check relation, and they also provide some simple formulae for\nthis bias in some particular cases which are commonly used in cryptography.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2009 14:25:48 GMT"}], "update_date": "2009-04-29", "authors_parsed": [["Canteaut", "Anne", "", "INRIA Rocquencourt"], ["Naya-Plasencia", "Maria", "", "INRIA\n  Rocquencourt"]]}, {"id": "0904.4449", "submitter": "Martin Loebl", "authors": "Lukas Kencl, Martin Loebl", "title": "DNA-Inspired Information Concealing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protection of the sensitive content is crucial for extensive information\nsharing. We present a technique of information concealing, based on\nintroduction and maintenance of families of repeats. Repeats in DNA constitute\na basic obstacle for its reconstruction by hybridization.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2009 17:27:54 GMT"}], "update_date": "2009-04-29", "authors_parsed": [["Kencl", "Lukas", ""], ["Loebl", "Martin", ""]]}, {"id": "0904.4458", "submitter": "Michael Goodrich", "authors": "Michael T. Goodrich", "title": "Learning Character Strings via Mastermind Queries, with a Case Study\n  Involving mtDNA", "comments": "Full version of related paper appearing in IEEE Symposium on Security\n  and Privacy 2009, \"The Mastermind Attack on Genomic Data.\" This version\n  corrects the proofs of what are now Theorems 2 and 4.", "journal-ref": null, "doi": "10.1109/TIT.2012.2208581", "report-no": null, "categories": "cs.DS cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the degree to which a character string, $Q$, leaks details about\nitself any time it engages in comparison protocols with a strings provided by a\nquerier, Bob, even if those protocols are cryptographically guaranteed to\nproduce no additional information other than the scores that assess the degree\nto which $Q$ matches strings offered by Bob. We show that such scenarios allow\nBob to play variants of the game of Mastermind with $Q$ so as to learn the\ncomplete identity of $Q$. We show that there are a number of efficient\nimplementations for Bob to employ in these Mastermind attacks, depending on\nknowledge he has about the structure of $Q$, which show how quickly he can\ndetermine $Q$. Indeed, we show that Bob can discover $Q$ using a number of\nrounds of test comparisons that is much smaller than the length of $Q$, under\nreasonable assumptions regarding the types of scores that are returned by the\ncryptographic protocols and whether he can use knowledge about the distribution\nthat $Q$ comes from. We also provide the results of a case study we performed\non a database of mitochondrial DNA, showing the vulnerability of existing\nreal-world DNA data to the Mastermind attack.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2009 18:12:24 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2010 05:31:22 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Goodrich", "Michael T.", ""]]}]