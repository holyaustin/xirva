[{"id": "1501.00100", "submitter": "Marco Gramaglia", "authors": "Marco Gramaglia and Marco Fiore", "title": "On the anonymizability of mobile traffic datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Preserving user privacy is paramount when it comes to publicly disclosed\ndatasets that contain fine-grained data about large populations. The problem is\nespecially critical in the case of mobile traffic datasets collected by\ncellular operators, as they feature elevate subscriber trajectory uniqueness\nand they are resistant to anonymization through spatiotemporal generalization.\nIn this work, we investigate the $k$-anonymizability of trajectories in two\nlarge-scale mobile traffic datasets, by means of a novel dedicated measure. Our\nresults are in agreement with those of previous analyses, however they also\nprovide additional insights on the reasons behind the poor anonimizability of\nmobile traffic datasets. As such, our study is a step forward in the direction\nof a more robust dataset anonymization.\n", "versions": [{"version": "v1", "created": "Wed, 31 Dec 2014 09:53:31 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2015 09:35:41 GMT"}], "update_date": "2015-04-15", "authors_parsed": [["Gramaglia", "Marco", ""], ["Fiore", "Marco", ""]]}, {"id": "1501.00166", "submitter": "Yaser Sadra", "authors": "Sodeif Ahadpour, Yaser Sadra", "title": "Chaotic trigonometric Haar wavelet with focus on image encryption", "comments": "Accepted in Journal of Discrete Mathematical Sciences and\n  Cryptography, 10pages, 9 figures,2 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, after reviewing the main points of Haar wavelet transform and\nchaotic trigonometric maps, we introduce a new perspective of Haar wavelet\ntransform. The essential idea of the paper is given linearity properties of the\nscaling function of the Haar wavelet. With regard to applications of Haar\nwavelet transform in image processing, we introduce chaotic trigonometric Haar\nwavelet transform to encrypt the plain images. In addition, the encrypted\nimages based on a proposed algorithm were made. To evaluate the security of the\nencrypted images, the key space analysis, the correlation coefficient analysis\nand differential attack were performed. Here, the chaotic trigonometric Haar\nwavelet transform tries to improve the problem of failure of encryption such as\nsmall key space and level of security.\n", "versions": [{"version": "v1", "created": "Wed, 31 Dec 2014 16:28:28 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2015 06:46:29 GMT"}, {"version": "v3", "created": "Fri, 8 Apr 2016 05:12:25 GMT"}], "update_date": "2016-04-11", "authors_parsed": [["Ahadpour", "Sodeif", ""], ["Sadra", "Yaser", ""]]}, {"id": "1501.00178", "submitter": "Alice Silverberg", "authors": "H. W. Lenstra Jr. and A. Silverberg", "title": "Lattices with Symmetry", "comments": "Published in Journal of Cryptology. Minor typos corrected", "journal-ref": null, "doi": "10.1007/s00145-016-9235-7", "report-no": null, "categories": "math.NT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For large ranks, there is no good algorithm that decides whether a given\nlattice has an orthonormal basis. But when the lattice is given with enough\nsymmetry, we can construct a provably deterministic polynomial-time algorithm\nto accomplish this, based on the work of Gentry and Szydlo. The techniques\ninvolve algorithmic algebraic number theory, analytic number theory,\ncommutative algebra, and lattice basis reduction.\n", "versions": [{"version": "v1", "created": "Wed, 31 Dec 2014 17:32:08 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2015 23:07:09 GMT"}, {"version": "v3", "created": "Tue, 4 Oct 2016 02:06:02 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Lenstra", "H. W.", "Jr."], ["Silverberg", "A.", ""]]}, {"id": "1501.00180", "submitter": "Rajdeep Borgohain", "authors": "Tuhin Borgohain, Amardeep Borgohain, Rajdeep Borgohain, Sugata Sanyal", "title": "Multipath Routing of Fragmented Data Transfer in a Smart Grid\n  Environment", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": "10.5120/19528-1165", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is to do a general survey on the existing\ncommunication modes inside a smart grid, the existing security loopholes and\ntheir countermeasures. Then we suggest a detailed countermeasure, building upon\nthe Jigsaw based secure data transfer [8] for enhanced security of the data\nflow inside the communication system of a smart grid. The paper has been\nwritten without the consideration of any factor of inoperability between the\nvarious security techniques inside a smart grid\n", "versions": [{"version": "v1", "created": "Wed, 31 Dec 2014 17:36:58 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Borgohain", "Tuhin", ""], ["Borgohain", "Amardeep", ""], ["Borgohain", "Rajdeep", ""], ["Sanyal", "Sugata", ""]]}, {"id": "1501.00354", "submitter": "Sang-Pil Kim", "authors": "Sang-Pil Kim, Myeong-Sun Gil, Yang-Sae Moon, and Hee-Sun Won", "title": "Efficient 2-Step Protocol and Its Discriminative Feature Selections in\n  Secure Similar Document Detection", "comments": "25 pages, 12 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure similar document detection (SSDD) identifies similar documents of two\nparties while each party does not disclose its own sensitive documents to\nanother party. In this paper, we propose an efficient 2-step protocol that\nexploits a feature selection as the lower-dimensional transformation and\npresents discriminative feature selections to maximize the performance of the\nprotocol. For this, we first analyze that the existing 1-step protocol causes\nserious computation and communication overhead for high dimensional document\nvectors. To alleviate the overhead, we next present the feature selection-based\n2-step protocol and formally prove its correctness. The proposed 2-step\nprotocol works as follows: (1) in the filtering step, it uses low dimensional\nvectors obtained by the feature selection to filter out non-similar documents;\n(2) in the post-processing step, it identifies similar documents only from the\nnon-filtered documents by using the 1-step protocol. As the feature selection,\nwe first consider the simplest one, random projection (RP), and propose its\n2-step solution SSDD-RP. We then present two discriminative feature selections\nand their solutions: SSDD-LF (local frequency) which selects a few dimensions\nlocally frequent in the current querying vector and SSDD-GF (global frequency)\nwhich selects ones globally frequent in the set of all document vectors. We\nfinally propose a hybrid one, SSDD-HF (hybrid frequency), that takes advantage\nof both SSDD-LF and SSDD-GF. We empirically show that the proposed 2-step\nprotocol outperforms the 1-step protocol by three or four orders of magnitude.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jan 2015 07:32:06 GMT"}], "update_date": "2015-01-05", "authors_parsed": [["Kim", "Sang-Pil", ""], ["Gil", "Myeong-Sun", ""], ["Moon", "Yang-Sae", ""], ["Won", "Hee-Sun", ""]]}, {"id": "1501.00447", "submitter": "Stephan Verb\\\"ucheln", "authors": "Stephan Verb\\\"ucheln", "title": "How Perfect Offline Wallets Can Still Leak Bitcoin Private Keys", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ECDSA has become a popular choice as lightweight alternative to RSA and\nclassic DL based signature algorithms in recent years. As standardized, the\nsignature produced by ECDSA for a pair of a message and a key is not\ndeterministic. This work shows how this non-deterministic choice can be\nexploited by an attacker to leak private information through the signature\nwithout any side channels, an attack first discovered by Young and Yung for\nclassic DL-based cryptosystems in 1997, and how this attack affects the\napplication of ECDSA in the Bitcoin protocol.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jan 2015 17:56:36 GMT"}], "update_date": "2015-01-05", "authors_parsed": [["Verb\u00fccheln", "Stephan", ""]]}, {"id": "1501.00747", "submitter": "Divya Sharma", "authors": "Anupam Datta, Deepak Garg, Dilsun Kaynar, Divya Sharma, Arunesh Sinha", "title": "Programs as Actual Causes: A Building Block for Accountability", "comments": "This submission has been updated and is available at\n  http://arxiv.org/abs/1505.01131", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An updated version of this paper is available at\nhttp://arxiv.org/abs/1505.01131\n", "versions": [{"version": "v1", "created": "Mon, 5 Jan 2015 02:11:05 GMT"}, {"version": "v2", "created": "Wed, 6 May 2015 18:32:43 GMT"}], "update_date": "2015-05-07", "authors_parsed": [["Datta", "Anupam", ""], ["Garg", "Deepak", ""], ["Kaynar", "Dilsun", ""], ["Sharma", "Divya", ""], ["Sinha", "Arunesh", ""]]}, {"id": "1501.01039", "submitter": "Jack Peterson", "authors": "Joseph Krug and Jack Peterson", "title": "Sidecoin: a snapshot mechanism for bootstrapping a blockchain", "comments": "3 pages", "journal-ref": null, "doi": "10.13140/2.1.4577.1841", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sidecoin is a mechanism that allows a snapshot to be taken of Bitcoin's\nblockchain. We compile a list of Bitcoin's unspent transaction outputs, then\nuse these outputs and their corresponding balances to bootstrap a new\nblockchain. This allows the preservation of Bitcoin's economic state in the\ncontext of a new blockchain, which may provide new features and technical\ninnovations.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jan 2015 23:48:06 GMT"}], "update_date": "2015-01-07", "authors_parsed": [["Krug", "Joseph", ""], ["Peterson", "Jack", ""]]}, {"id": "1501.01042", "submitter": "Jack Peterson", "authors": "Jack Peterson, Joseph Krug, Micah Zoltu, Austin K. Williams, Stephanie\n  Alexander", "title": "Augur: a decentralized oracle and prediction market platform", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": "10.13140/2.1.1431.4563", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Augur is a trustless, decentralized oracle and platform for prediction\nmarkets. The outcomes of Augur's prediction markets are chosen by users that\nhold Augur's native Reputation token, who stake their tokens on the actual\nobserved outcome and, in return, receive settlement fees from the markets.\nAugur's incentive structure is designed to ensure that honest, accurate\nreporting of outcomes is always the most profitable option for Reputation token\nholders. Token holders can post progressively-larger Reputation bonds to\ndispute proposed market outcomes. If the size of these bonds reaches a certain\nthreshold, Reputation splits into multiple versions, one for each possible\noutcome of the disputed market; token holders must then exchange their\nReputation tokens for one of these versions. Versions of Reputation which do\nnot correspond to the real-world outcome will become worthless, as no one will\nparticipate in prediction markets unless they are confident that the markets\nwill resolve correctly. Therefore, token holders will select the only version\nof Reputation which they know will continue to have value: the version that\ncorresponds to reality.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jan 2015 23:56:17 GMT"}, {"version": "v2", "created": "Sat, 3 Feb 2018 06:00:30 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2020 22:13:15 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Peterson", "Jack", ""], ["Krug", "Joseph", ""], ["Zoltu", "Micah", ""], ["Williams", "Austin K.", ""], ["Alexander", "Stephanie", ""]]}, {"id": "1501.01152", "submitter": "Vitaly Roman'kov", "authors": "Vitali\\u{i} Roman'kov", "title": "Linear decomposition attack on public key exchange protocols using\n  semidirect products of (semi)groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a linear decomposition attack based on the decomposition method\nintroduced by the author works by finding the exchanged secret keys in all main\nprotocols using semidirect products of (semi)grops proposed by Kahrobaei,\nShpilrain, Habeeb, Koupparis and Lam.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jan 2015 11:35:55 GMT"}], "update_date": "2015-01-07", "authors_parsed": [["Roman'kov", "Vitali\u012d", ""]]}, {"id": "1501.01199", "submitter": "Paolo Gasti", "authors": "Zdenka Sitova and Jaroslav Sedenka and Qing Yang and Ge Peng and Gang\n  Zhou and Paolo Gasti and Kiran Balagani", "title": "HMOG: New Behavioral Biometric Features for Continuous Authentication of\n  Smartphone Users", "comments": null, "journal-ref": "IEEE Transactions on Information Forensics and Security, PP(99):\n  1-1,2016", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Hand Movement, Orientation, and Grasp (HMOG), a set of\nbehavioral features to continuously authenticate smartphone users. HMOG\nfeatures unobtrusively capture subtle micro-movement and orientation dynamics\nresulting from how a user grasps, holds, and taps on the smartphone. We\nevaluated authentication and biometric key generation (BKG) performance of HMOG\nfeatures on data collected from 100 subjects typing on a virtual keyboard. Data\nwas collected under two conditions: sitting and walking. We achieved\nauthentication EERs as low as 7.16% (walking) and 10.05% (sitting) when we\ncombined HMOG, tap, and keystroke features. We performed experiments to\ninvestigate why HMOG features perform well during walking. Our results suggest\nthat this is due to the ability of HMOG features to capture distinctive body\nmovements caused by walking, in addition to the hand-movement dynamics from\ntaps. With BKG, we achieved EERs of 15.1% using HMOG combined with taps. In\ncomparison, BKG using tap, key hold, and swipe features had EERs between 25.7%\nand 34.2%. We also analyzed the energy consumption of HMOG feature extraction\nand computation. Our analysis shows that HMOG features extracted at 16Hz sensor\nsampling rate incurred a minor overhead of 7.9% without sacrificing\nauthentication accuracy. Two points distinguish our work from current\nliterature: 1) we present the results of a comprehensive evaluation of three\ntypes of features (HMOG, keystroke, and tap) and their combinations under the\nsame experimental conditions, and 2) we analyze the features from three\nperspectives (authentication, BKG, and energy consumption on smartphones).\n", "versions": [{"version": "v1", "created": "Tue, 6 Jan 2015 15:25:08 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2015 16:31:42 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2016 16:32:43 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Sitova", "Zdenka", ""], ["Sedenka", "Jaroslav", ""], ["Yang", "Qing", ""], ["Peng", "Ge", ""], ["Zhou", "Gang", ""], ["Gasti", "Paolo", ""], ["Balagani", "Kiran", ""]]}, {"id": "1501.01376", "submitter": "Bambang Harjito -", "authors": "Bambang Harjito and Vidyasagar Potdar", "title": "Secure Transmission in Wireless Sensor Networks Data Using Linear\n  Kolmogorov Watermarking Technique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Wireless sensor networks (WSNs), All communications between different\nnodes are sent out in a broadcast fashion. These networks are used in a variety\nof applications including military, environmental, and smart spaces. Sensors\nare susceptible to various types of attack, such as data modification, data\ninsertion and deletion, or even physical capture and sensor replacement. Hence\nsecurity becomes important issue in WSNs. However given the fact that sensors\nare resources constrained, hence the traditional intensive security algorithms\nare not well suited for WSNs. This makes traditional security techniques, based\non data encryption, not very suitable for WSNs. This paper proposes Linear\nKolmogorov watermarking technique for secure data communication in WSNs. We\nprovide a security analysis to show the robustness of the proposed techniques\nagainst various types of attacks. This technique is robust against data\ndeletion, packet replication and Sybil attacks\n", "versions": [{"version": "v1", "created": "Wed, 7 Jan 2015 07:11:24 GMT"}], "update_date": "2015-01-08", "authors_parsed": [["Harjito", "Bambang", ""], ["Potdar", "Vidyasagar", ""]]}, {"id": "1501.01427", "submitter": "Ghada Elkabbany ghada elkabbany", "authors": "Ghada F. Elkabbany, Heba K. Aslan, Mohamed N. Rasslan", "title": "A Design of a Fast Parallel-Pipelined Implementation of AES: Advanced\n  Encryption Standard", "comments": null, "journal-ref": "International Journal of Computer Science & Information Technology\n  (IJCSIT), Vol. 6, No. 6, Dec. 2014", "doi": "10.5121/ijcsit", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Advanced Encryption Standard (AES) algorithm is a symmetric block cipher\nwhich operates on a sequence of blocks each consists of 128, 192 or 256 bits.\nMoreover, the cipher key for the AES algorithm is a sequence of 128, 192 or 256\nbits. AES algorithm has many sources of parallelism. In this paper, a design of\nparallel AES on the multiprocessor platform is presented. While most of the\nprevious designs either use pipelined parallelization or take advantage of the\nMix_Column parallelization, our design is based on combining pipelining of\nrounds and parallelization of Mix_Column and Add_Round_Key transformations.\nThis model is divided into two levels: the first is pipelining different\nrounds, while the second is through parallelization of both the Add_Round_Key\nand the Mix_Column transformations. Previous work proposed for pipelining AES\nalgorithm was based on using nine stages, while, we propose the use of eleven\nstages in order to exploit the sources of parallelism in both initial and final\nround. This enhances the system performance compared to previous designs. Using\ntwo-levels of parallelization benefits from the highly independency of\nAdd_Round_Key and Mix_Column/ Inv_Mix_Colum transformations. The analysis shows\nthat the parallel implementation of the AES achieves a better performance. The\nanalysis shows that using pipeline increases significantly the degree of\nimprovement for both encryption and decryption by approximately 95%. Moreover,\nparallelizing Add_Round_Key and Mix_Column/ Inv_Mix_Column transformations\nincreases the degree of improvement by approximately 98%. This leads to the\nconclusion that the proposed design is scalable and is suitable for real-time\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jan 2015 10:21:31 GMT"}], "update_date": "2015-01-08", "authors_parsed": [["Elkabbany", "Ghada F.", ""], ["Aslan", "Heba K.", ""], ["Rasslan", "Mohamed N.", ""]]}, {"id": "1501.01463", "submitter": "Ricardo Francisco Martinez-Gonzalez PhD", "authors": "Ricardo Francisco Martinez-Gonzalez and Jose Alejandro Diaz-Mendez", "title": "Implementation of a Stream Cipher Based on Bernoulli's Map", "comments": "9 Pages, 6 Figures and 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A stream cipher was implemented on a FPGA. The keystream, for some authors\nthe most important element, was developed using an algorithm based on\nBernoullis chaotic map. When dynamic systems are digitally implemented, a\nnormal degradation appears and disturbs their behavior; for such reason, a\nmechanism was needed. The proposed mechanism gives a solution for degradation\nissue and its implementation is not complicated. Finally, the implemented\ncipher includes 8 stages and 2 pseudo-random number generators (PRNG), such\ncipher was tested using NIST testes. Once its designing stage, it was\nimplemented using a developing FPGA board.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jan 2015 12:19:26 GMT"}], "update_date": "2015-01-08", "authors_parsed": [["Martinez-Gonzalez", "Ricardo Francisco", ""], ["Diaz-Mendez", "Jose Alejandro", ""]]}, {"id": "1501.01549", "submitter": "Christian Schaffner", "authors": "Louis Salvail and Christian Schaffner and Miroslava Sotakova", "title": "Quantifying the Leakage of Quantum Protocols for Classical Two-Party\n  Cryptography", "comments": "38 pages, completely supersedes arXiv:0902.4036", "journal-ref": "Int. J. Quantum Inform. 12, 1450041 (2014)", "doi": "10.1142/S0219749914500415", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study quantum protocols among two distrustful parties. By adopting a\nrather strict definition of correctness - guaranteeing that honest players\nobtain their correct outcomes only - we can show that every strictly correct\nquantum protocol implementing a non-trivial classical primitive necessarily\nleaks information to a dishonest player. This extends known impossibility\nresults to all non-trivial primitives. We provide a framework for quantifying\nthis leakage and argue that leakage is a good measure for the privacy provided\nto the players by a given protocol. Our framework also covers the case where\nthe two players are helped by a trusted third party. We show that despite the\nhelp of a trusted third party, the players cannot amplify the cryptographic\npower of any primitive. All our results hold even against quantum\nhonest-but-curious adversaries who honestly follow the protocol but purify\ntheir actions and apply a different measurement at the end of the protocol. As\nconcrete examples, we establish lower bounds on the leakage of standard\nuniversal two-party primitives such as oblivious transfer.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jan 2015 16:40:57 GMT"}], "update_date": "2015-01-08", "authors_parsed": [["Salvail", "Louis", ""], ["Schaffner", "Christian", ""], ["Sotakova", "Miroslava", ""]]}, {"id": "1501.01721", "submitter": "Ethan  Zou", "authors": "Nathan Wolfe, Ethan Zou, Ling Ren, Xiangyao Yu", "title": "Optimizing Path ORAM for Cloud Storage Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We live in a world where our personal data are both valuable and vulnerable\nto misappropriation through exploitation of security vulnerabilities in online\nservices. For instance, Dropbox, a popular cloud storage tool, has certain\nsecurity flaws that can be exploited to compromise a user's data, one of which\nbeing that a user's access pattern is unprotected. We have thus created an\nimplementation of Path Oblivious RAM (Path ORAM) for Dropbox users to obfuscate\npath access information to patch this vulnerability. This implementation\ndiffers significantly from the standard usage of Path ORAM, in that we\nintroduce several innovations, including a dynamically growing and shrinking\ntree architecture, multi-block fetching, block packing and the possibility for\nmulti-client use. Our optimizations together produce about a 77% throughput\nincrease and a 60% reduction in necessary tree size; these numbers vary with\nfile size distribution.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jan 2015 03:56:54 GMT"}], "update_date": "2015-01-09", "authors_parsed": [["Wolfe", "Nathan", ""], ["Zou", "Ethan", ""], ["Ren", "Ling", ""], ["Yu", "Xiangyao", ""]]}, {"id": "1501.01755", "submitter": "Hossein Bakhshi Golestani", "authors": "Hossein Bakhshi Golestani, Mohammed Ghanbari", "title": "Minimization of image watermarking side effects through subjective\n  optimization", "comments": "17 pages,11 figures, IET Image Processing Journal", "journal-ref": "IET Image Processing, vol. 7, no. 8, pp. 733-741, 2013", "doi": "10.1049/iet-ipr.2013.0086", "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the use of Structural Similaritys (SSIM) index on the\nminimized side effect to image watermarking. For fast implementation and more\ncompatibility with the standard DCT based codecs, watermark insertion is\ncarried out on the DCT coefficients and hence a SSIM model for DCT based\nwatermarking is developed. For faster implementation, the SSIM index is\nmaximized over independent 4x4 non-overlapped blocks but the disparity between\nthe adjacent blocks reduces the overall image quality. This problem is resolved\nthrough optimization of overlapped blocks, but, the higher image quality is\nachieved at a cost of high computational complexity. To reduce the\ncomputational complexity while preserving the good quality, optimization of\nsemi-overlapped blocks is introduced. We show that while SSIM-based\noptimization over overlapped blocks has as high as 64 times the complexity of\nthe 4x4 non-overlapped method, with semi-overlapped optimization the high\nquality of overlapped method is preserved only at a cost of less than 8 times\nthe non-overlapped method.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jan 2015 08:02:01 GMT"}], "update_date": "2015-01-09", "authors_parsed": [["Golestani", "Hossein Bakhshi", ""], ["Ghanbari", "Mohammed", ""]]}, {"id": "1501.01758", "submitter": "Hossein Bakhshi Golestani", "authors": "Hossein Bakhshi Golestani, Shahrokh Ghaemmaghami", "title": "Enhance Robustness of Image-in-Image Watermarking through Data\n  Partitioning", "comments": "5 pages, 7 figures, IEEE TENCON2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vulnerability of watermarking schemes against intense signal processing\nattacks is generally a major concern, particularly when there are techniques to\nreproduce an acceptable copy of the original signal with no chance for\ndetecting the watermark. In this paper, we propose a two-layer, data\npartitioning (DP) based, image in image watermarking method in the DCT domain\nto improve the watermark detection performance. Truncated singular value\ndecomposition, binary wavelet decomposition and spatial scalability idea in\nH.264/SVC are analyzed and employed as partitioning methods. It is shown that\nthe proposed scheme outperforms its two recent competitors in terms of both\ndata payload and robustness to intense attacks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jan 2015 08:08:50 GMT"}], "update_date": "2015-01-09", "authors_parsed": [["Golestani", "Hossein Bakhshi", ""], ["Ghaemmaghami", "Shahrokh", ""]]}, {"id": "1501.01826", "submitter": "Jun Zhao", "authors": "Jun Zhao, Osman Ya\\u{g}an, Virgil Gligor", "title": "Designing Securely and Reliably Connected Wireless Sensor Networks", "comments": "A critical error is found in the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DM cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In wireless sensor networks, the $q$-composite key predistribution scheme is\na widely recognized way to secure communications. Although connectivity\nproperties of secure sensor networks with the $q$-composite scheme have been\nstudied in the literature, few results address physical transmission\nconstraints since it is challenging to analyze the network connectivity in\nconsideration of both the $q$-composite scheme and transmission constraints\ntogether. These transmission constraints reflect real-world implementations of\nsensor networks in which two sensors have to be within a certain distance from\neach other to communicate. In this paper, we rigorously derive conditions for\nconnectivity in sensor networks employing the $q$-composite scheme under\ntransmission constraints. Furthermore, we extend the analysis to consider the\nunreliability of wireless links by modeling each link being independently\nactive with some probability. Our results provide useful guidelines for\ndesigning securely and reliably connected sensor networks. We also present\nnumerical experiments to confirm the analytical results.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jan 2015 13:11:10 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2015 21:01:45 GMT"}], "update_date": "2015-08-07", "authors_parsed": [["Zhao", "Jun", ""], ["Ya\u011fan", "Osman", ""], ["Gligor", "Virgil", ""]]}, {"id": "1501.01901", "submitter": "Subil Abraham", "authors": "Subil Abraham, Suku Nair", "title": "Predictive Cyber-security Analytics Framework: A non-homogenous Markov\n  model for Security Quantification", "comments": "16 pages, 6 Figures in International Conference of Security, Privacy\n  and Trust Management 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous security metrics have been proposed in the past for protecting\ncomputer networks. However we still lack effective techniques to accurately\nmeasure the predictive security risk of an enterprise taking into account the\ndynamic attributes associated with vulnerabilities that can change over time.\nIn this paper we present a stochastic security framework for obtaining\nquantitative measures of security using attack graphs. Our model is novel as\nexisting research in attack graph analysis do not consider the temporal aspects\nassociated with the vulnerabilities, such as the availability of exploits and\npatches which can affect the overall network security based on how the\nvulnerabilities are interconnected and leveraged to compromise the system.\nGaining a better understanding of the relationship between vulnerabilities and\ntheir lifecycle events can provide security practitioners a better\nunderstanding of their state of security. In order to have a more realistic\nrepresentation of how the security state of the network would vary over time, a\nnonhomogeneous model is developed which incorporates a time dependent\ncovariate, namely the vulnerability age. The daily transition-probability\nmatrices are estimated using Frei's Vulnerability Lifecycle model. We also\nleverage the trusted CVSS metric domain to analyze how the total exploitability\nand impact measures evolve over a time period for a given network.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jan 2015 16:56:03 GMT"}], "update_date": "2015-01-09", "authors_parsed": [["Abraham", "Subil", ""], ["Nair", "Suku", ""]]}, {"id": "1501.02062", "submitter": "Sankalp Bagaria", "authors": "Sankalp Bagaria", "title": "New Hashing Algorithm for Use in TCP Reassembly Module of IPS", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since last decade, IDS/ IPS has gained popularity in protecting large\nnetworks. They can employ signature based techniques and/or flow-based\ntechniques to prevent intrusion from outside/ inside the network they are\ntrying to protect. Signature based IDS/ IPS can be stateless or stateful.\nStateful IDS can store the state of the protocol and use it for better\ndetection of malware. In the case of TCP/IP networks, an attacker can also\nlaunch an attack such that the malicious code is distributed over many packets.\nThese packets pass through the traditional IDS/ IPS and reassemble inside the\nnetwork. Once re-assembled inside the network by the TCP/IP layer, the\nmalicious code launches an attack.\n  The TCP state and a copy of last few packets for each active connection has\nto be maintained in IDS/IPS. In TCP re-assembly, packets are re-assembled at\nIDS/IPS and searched for signature matches. A connection table has to be\nmaintained for active connections and their list of last few (atmost 11)\npackets that have already arrived. We need data structures for searching the\nconnection that the latest incoming packet belongs to. Popular hashing\nalgorithms like CRC, XOR, summing tuple, taking modulus are inefficient as hash\nkeys are not evenly distributed in hash-key space. Thus we show how an\nalgorithm based on cryptography concepts can be used for efficient hashing in\nnetwork connection management. We also show how to use full four tuple for\ncalculating hash key instead of simply summing the tuple and taking the modulus\nof the sum.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 07:58:08 GMT"}], "update_date": "2015-01-12", "authors_parsed": [["Bagaria", "Sankalp", ""]]}, {"id": "1501.02211", "submitter": "Sugata Sanyal", "authors": "Tuhin Borgohain, Uday Kumar, Sugata Sanyal", "title": "Survey of Security and Privacy Issues of Internet of Things", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a general survey of all the security issues existing in the\nInternet of Things (IoT) along with an analysis of the privacy issues that an\nend-user may face as a consequence of the spread of IoT. The majority of the\nsurvey is focused on the security loopholes arising out of the information\nexchange technologies used in Internet of Things. No countermeasure to the\nsecurity drawbacks has been analyzed in the paper.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 17:58:18 GMT"}], "update_date": "2015-01-12", "authors_parsed": [["Borgohain", "Tuhin", ""], ["Kumar", "Uday", ""], ["Sanyal", "Sugata", ""]]}, {"id": "1501.02365", "submitter": "Nidhi Lal", "authors": "Nidhi Lal, Anurag Prakash Singh, Shishupal Kumar", "title": "Modified Trial Division Algorithm Using KNJ-Factorization Method To\n  Factorize RSA Public Key Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The security of RSA algorithm depends upon the positive integer N, which is\nthe multiple of two precise large prime numbers. Factorization of such great\nnumbers is a problematic process. There are many algorithms has been\nimplemented in the past years. The offered KNJ -Factorization algorithm\ncontributes a deterministic way to factorize RSA. The algorithm limits the\nsearch by only considering the prime values. Subsequently prime numbers are odd\nnumbers accordingly it also requires smaller number steps to factorize RSA. In\nthis paper, the anticipated algorithm is very simple besides it is very easy to\nunderstand and implement. The main concept of this KNJ factorization algorithm\nis, to check only those factors which are odd and prime. The proposed KNJ-\nFactorization algorithm works very efficiently on those factors; which are\nadjoining and close to N. The proposed factorization method can speed up if we\ncan reduce the time for primality testing. It fundamentally decreases the time\ncomplexity.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jan 2015 16:00:41 GMT"}], "update_date": "2015-01-13", "authors_parsed": [["Lal", "Nidhi", ""], ["Singh", "Anurag Prakash", ""], ["Kumar", "Shishupal", ""]]}, {"id": "1501.02484", "submitter": "Jihun Hamm", "authors": "Jihun Hamm, Adam Champion, Guoxing Chen, Mikhail Belkin, Dong Xuan", "title": "Crowd-ML: A Privacy-Preserving Learning Framework for a Crowd of Smart\n  Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart devices with built-in sensors, computational capabilities, and network\nconnectivity have become increasingly pervasive. The crowds of smart devices\noffer opportunities to collectively sense and perform computing tasks in an\nunprecedented scale. This paper presents Crowd-ML, a privacy-preserving machine\nlearning framework for a crowd of smart devices, which can solve a wide range\nof learning problems for crowdsensing data with differential privacy\nguarantees. Crowd-ML endows a crowdsensing system with an ability to learn\nclassifiers or predictors online from crowdsensing data privately with minimal\ncomputational overheads on devices and servers, suitable for a practical and\nlarge-scale employment of the framework. We analyze the performance and the\nscalability of Crowd-ML, and implement the system with off-the-shelf\nsmartphones as a proof of concept. We demonstrate the advantages of Crowd-ML\nwith real and simulated experiments under various conditions.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jan 2015 18:57:28 GMT"}], "update_date": "2015-01-13", "authors_parsed": [["Hamm", "Jihun", ""], ["Champion", "Adam", ""], ["Chen", "Guoxing", ""], ["Belkin", "Mikhail", ""], ["Xuan", "Dong", ""]]}, {"id": "1501.02601", "submitter": "Mohsen Toorani", "authors": "Mohsen Toorani", "title": "On Vulnerabilities of the Security Association in the IEEE 802.15.6\n  Standard", "comments": null, "journal-ref": "Financial Cryptography and Data Security, LNCS 8976, pp. 245-260,\n  2015", "doi": "10.1007/978-3-662-48051-9_18", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless Body Area Networks (WBAN) support a variety of real-time health\nmonitoring and consumer electronics applications. The latest international\nstandard for WBAN is the IEEE 802.15.6. The security association in this\nstandard includes four elliptic curve-based key agreement protocols that are\nused for generating a master key. In this paper, we challenge the security of\nthe IEEE 802.15.6 standard by showing vulnerabilities of those four protocols\nto several attacks. We perform a security analysis on the protocols, and show\nthat they all have security problems, and are vulnerable to different attacks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jan 2015 11:11:10 GMT"}], "update_date": "2016-06-03", "authors_parsed": [["Toorani", "Mohsen", ""]]}, {"id": "1501.02633", "submitter": "Bart van Delft", "authors": "Bart van Delft, Sebastian Hunt, David Sands", "title": "Very Static Enforcement of Dynamic Policies", "comments": "Technical Report of publication under the same name in Principles of\n  Security and Trust (POST) 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security policies are naturally dynamic. Reflecting this, there has been a\ngrowing interest in studying information-flow properties which change during\nprogram execution, including concepts such as declassification, revocation, and\nrole-change.\n  A static verification of a dynamic information flow policy, from a semantic\nperspective, should only need to concern itself with two things: 1) the\ndependencies between data in a program, and 2) whether those dependencies are\nconsistent with the intended flow policies as they change over time. In this\npaper we provide a formal ground for this intuition. We present a\nstraightforward extension to the principal flow-sensitive type system\nintroduced by Hunt and Sands (POPL '06, ESOP '11) to infer both end-to-end\ndependencies and dependencies at intermediate points in a program. This allows\ntypings to be applied to verification of both static and dynamic policies. Our\nextension preserves the principal type system's distinguishing feature, that\ntype inference is independent of the policy to be enforced: a single, generic\ndependency analysis (typing) can be used to verify many different dynamic\npolicies of a given program, thus achieving a clean separation between (1) and\n(2).\n  We also make contributions to the foundations of dynamic information flow.\nArguably, the most compelling semantic definitions for dynamic security\nconditions in the literature are phrased in the so-called knowledge-based\nstyle. We contribute a new definition of knowledge-based termination\ninsensitive security for dynamic policies. We show that the new definition\navoids anomalies of previous definitions and enjoys a simple and useful\ncharacterisation as a two-run style property.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jan 2015 13:03:28 GMT"}], "update_date": "2015-01-13", "authors_parsed": [["van Delft", "Bart", ""], ["Hunt", "Sebastian", ""], ["Sands", "David", ""]]}, {"id": "1501.02885", "submitter": "Clark Thomborson", "authors": "Clark Thomborson", "title": "Benchmarking Obfuscators of Functionality", "comments": "8 pp., submitted to SPRO 2015 (https://aspire-fp7.eu/spro)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a set of benchmarks for evaluating the practicality of software\nobfuscators which rely on provably-secure methods for functional obfuscation.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jan 2015 04:28:03 GMT"}], "update_date": "2015-01-14", "authors_parsed": [["Thomborson", "Clark", ""]]}, {"id": "1501.02892", "submitter": "V.P. Binu", "authors": "V.P. Binu and A. Sreekumar", "title": "Lossless Secret Image Sharing Schemes", "comments": "International Journal of Computational Intelligence and Information\n  Security Vol. 4 April 2013, ISSN: 1837-7823", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secret image sharing deals with splitting confidential images into several\nshares and the original image can be reconstructed from the qualified subset of\nthe shares. Secret sharing schemes are used in transmission and storage of\nprivate medical images and military secrets. Increased confidentiality and\navailability are the major achievements. We propose an efficient (2, 2) scheme\nand (2, 3) scheme for secret image sharing. The scheme is lossless and also the\nshare size is same as the secret size. The sharing and revealing phase uses\nsimple modular arithmetic which can be very easily implemented. Experimental\nresults on Binary and Gray scale images show that the proposed scheme is secure\nand efficient.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jan 2015 07:06:40 GMT"}], "update_date": "2015-01-14", "authors_parsed": [["Binu", "V. P.", ""], ["Sreekumar", "A.", ""]]}, {"id": "1501.02967", "submitter": "Thanh Bui", "authors": "Thanh Bui", "title": "Analysis of Docker Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few years, the use of virtualization technologies has increased\ndramatically. This makes the demand for efficient and secure virtualization\nsolutions become more obvious. Container-based virtualization and\nhypervisor-based virtualization are two main types of virtualization\ntechnologies that have emerged to the market. Of these two classes,\ncontainer-based virtualization is able to provide a more lightweight and\nefficient virtual environment, but not without security concerns. In this\npaper, we analyze the security level of Docker, a well-known representative of\ncontainer-based approaches. The analysis considers two areas: (1) the internal\nsecurity of Docker, and (2) how Docker interacts with the security features of\nthe Linux kernel, such as SELinux and AppArmor, in order to harden the host\nsystem. Furthermore, the paper also discusses and identifies what could be done\nwhen using Docker to increase its level of security.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jan 2015 11:44:02 GMT"}], "update_date": "2015-01-14", "authors_parsed": [["Bui", "Thanh", ""]]}, {"id": "1501.03056", "submitter": "Stephen D. Miller", "authors": "Evgeni Begelfor, Stephen D. Miller, and Ramarathnam Venkatesan", "title": "Non-Abelian Analogs of Lattice Rounding", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.CR math.CO math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lattice rounding in Euclidean space can be viewed as finding the nearest\npoint in the orbit of an action by a discrete group, relative to the norm\ninherited from the ambient space. Using this point of view, we initiate the\nstudy of non-abelian analogs of lattice rounding involving matrix groups. In\none direction, we give an algorithm for solving a normed word problem when the\ninputs are random products over a basis set, and give theoretical justification\nfor its success. In another direction, we prove a general inapproximability\nresult which essentially rules out strong approximation algorithms (i.e., whose\napproximation factors depend only on dimension) analogous to LLL in the general\ncase.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jan 2015 15:54:05 GMT"}], "update_date": "2015-01-14", "authors_parsed": [["Begelfor", "Evgeni", ""], ["Miller", "Stephen D.", ""], ["Venkatesan", "Ramarathnam", ""]]}, {"id": "1501.03139", "submitter": "Eduardo Duarte", "authors": "Eduardo Duarte, Filipe Pinheiro, Andr\\'e Z\\'uquete, H\\'elder Gomes", "title": "Secure and trustworthy file sharing over cloud storage using eID tokens", "comments": "12 pages, 1 figure, submitted and presented at OID conference 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper presents a multi-platform, open-source application that aims to\nprotect data stored and shared in existing cloud storage services. The access\nto the cryptographic material used to protect data is implemented using the\nidentification and authentication functionalities of national electronic\nidentity (eID) tokens. All peer to peer dialogs to exchange cryptographic\nmaterial is implemented using the cloud storage facilities. Furthermore, we\nhave included a set of mechanisms to prevent files from being permanently lost\nor damaged due to concurrent modification, deletion and malicious tampering. We\nhave implemented a prototype in Java that is agnostic relatively to cloud\nstorage providers; it only manages local folders, one of them being the local\nimage of a cloud folder. We have successfully tested our prototype in Windows,\nMac OS X and Linux, with Dropbox, OneDrive, Google Drive and SugarSync.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jan 2015 20:29:45 GMT"}], "update_date": "2015-01-14", "authors_parsed": [["Duarte", "Eduardo", ""], ["Pinheiro", "Filipe", ""], ["Z\u00faquete", "Andr\u00e9", ""], ["Gomes", "H\u00e9lder", ""]]}, {"id": "1501.03188", "submitter": "Ross Sowell", "authors": "Alexander Hubers, Emily Andrulis, Levi Scott, Tanner Stirrat, Duc\n  Tran, Ruonan Zhang, Ross Sowell, Cindy Grimm, William D. Smart", "title": "Video Manipulation Techniques for the Protection of Privacy in Remote\n  Presence Systems", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems that give control of a mobile robot to a remote user raise privacy\nconcerns about what the remote user can see and do through the robot. We aim to\npreserve some of that privacy by manipulating the video data that the remote\nuser sees. Through two user studies, we explore the effectiveness of different\nvideo manipulation techniques at providing different types of privacy. We\nsimultaneously examine task performance in the presence of privacy protection.\nIn the first study, participants were asked to watch a video captured by a\nrobot exploring an office environment and to complete a series of observational\ntasks under differing video manipulation conditions. Our results show that\nusing manipulations of the video stream can lead to fewer privacy violations\nfor different privacy types. Through a second user study, it was demonstrated\nthat these privacy-protecting techniques were effective without diminishing the\ntask performance of the remote user.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jan 2015 21:58:16 GMT"}], "update_date": "2015-01-15", "authors_parsed": [["Hubers", "Alexander", ""], ["Andrulis", "Emily", ""], ["Scott", "Levi", ""], ["Stirrat", "Tanner", ""], ["Tran", "Duc", ""], ["Zhang", "Ruonan", ""], ["Sowell", "Ross", ""], ["Grimm", "Cindy", ""], ["Smart", "William D.", ""]]}, {"id": "1501.03241", "submitter": "Aymen Alawady aa", "authors": "Aymen Hasan Rashid Al Awadi and Bahari Belaton", "title": "Multi-phase IRC Botnet and Botnet Behavior Detection Model", "comments": "10 pages, Journal paper", "journal-ref": "International Journal of Computer Applications 66(15):41-51, March\n  2013", "doi": "10.5120/11164-6289", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  Botnets are considered one of the most dangerous and serious security threats\nfacing the networks and the Internet. Comparing with the other security\nthreats, botnet members have the ability to be directed and controlled via C&C\nmessages from the botmaster over common protocols such as IRC and HTTP, or even\nover covert and unknown applications. As for IRC botnets, general security\ninstances like firewalls and IDSes do not provide by themselves a viable\nsolution to prevent them completely. These devices could not differentiate well\nbetween the legitimate and malicious traffic of the IRC protocol. So, this\npaper is proposing an IDS-based and multi-phase IRC botnet and botnet behavior\ndetection model based on C&C responses messages and malicious behaviors of the\nIRC bots inside the network environment. The proposed model has been evaluated\non five network traffic traces from two different network environments (Virtual\nnetwork and DARPA 2000 Windows NT Attack Data Set). The results show that the\nproposed model could detect all the infected IRC botnet member(s), state their\ncurrent status of attack, filter their malicious IRC messages, pass the other\nnormal IRC messages and detect the botnet behavior regardless of the botnet\ncommunication protocol with very low false positive rate. The proposed model\nhas been compared with some of the existing and well-known approaches,\nincluding BotHunter, BotSniffer and Rishi regarding botnet characteristics\ntaken in each approach. The comparison showed that the proposed model has made\na progress on the comparative models by not to rely on a certain time window or\nspecific bot signatures.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jan 2015 11:31:02 GMT"}], "update_date": "2015-01-15", "authors_parsed": [["Awadi", "Aymen Hasan Rashid Al", ""], ["Belaton", "Bahari", ""]]}, {"id": "1501.03353", "submitter": "Fabian Bendun", "authors": "Michael Backes, Fabian Bendun, Joerg Hoffmann, Ninja Marnau", "title": "PriCL: Creating a Precedent A Framework for Reasoning about Privacy Case\n  Law", "comments": "Extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce PriCL: the first framework for expressing and automatically\nreasoning about privacy case law by means of precedent. PriCL is parametric in\nan underlying logic for expressing world properties, and provides support for\ncourt decisions, their justification, the circumstances in which the\njustification applies as well as court hierarchies. Moreover, the framework\noffers a tight connection between privacy case law and the notion of norms that\nunderlies existing rule-based privacy research. In terms of automation, we\nidentify the major reasoning tasks for privacy cases such as deducing legal\npermissions or extracting norms. For solving these tasks, we provide generic\nalgorithms that have particularly efficient realizations within an expressive\nunderlying logic. Finally, we derive a definition of deducibility based on\nlegal concepts and subsequently propose an equivalent characterization in terms\nof logic satisfiability.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jan 2015 14:05:18 GMT"}], "update_date": "2015-01-15", "authors_parsed": [["Backes", "Michael", ""], ["Bendun", "Fabian", ""], ["Hoffmann", "Joerg", ""], ["Marnau", "Ninja", ""]]}, {"id": "1501.03378", "submitter": "Amirali Sanatinia", "authors": "Amirali Sanatinia, Guevara Noubir", "title": "OnionBots: Subverting Privacy Infrastructure for Cyber Attacks", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decade botnets survived by adopting a sequence of increasingly\nsophisticated strategies to evade detection and take overs, and to monetize\ntheir infrastructure. At the same time, the success of privacy infrastructures\nsuch as Tor opened the door to illegal activities, including botnets,\nransomware, and a marketplace for drugs and contraband. We contend that the\nnext waves of botnets will extensively subvert privacy infrastructure and\ncryptographic mechanisms. In this work we propose to preemptively investigate\nthe design and mitigation of such botnets. We first, introduce OnionBots, what\nwe believe will be the next generation of resilient, stealthy botnets.\nOnionBots use privacy infrastructures for cyber attacks by completely\ndecoupling their operation from the infected host IP address and by carrying\ntraffic that does not leak information about its source, destination, and\nnature. Such bots live symbiotically within the privacy infrastructures to\nevade detection, measurement, scale estimation, observation, and in general all\nIP-based current mitigation techniques. Furthermore, we show that with an\nadequate self-healing network maintenance scheme, that is simple to implement,\nOnionBots achieve a low diameter and a low degree and are robust to\npartitioning under node deletions. We developed a mitigation technique, called\nSOAP, that neutralizes the nodes of the basic OnionBots. We also outline and\ndiscuss a set of techniques that can enable subsequent waves of Super\nOnionBots. In light of the potential of such botnets, we believe that the\nresearch community should proactively develop detection and mitigation methods\nto thwart OnionBots, potentially making adjustments to privacy infrastructure.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jan 2015 15:52:44 GMT"}], "update_date": "2015-01-15", "authors_parsed": [["Sanatinia", "Amirali", ""], ["Noubir", "Guevara", ""]]}, {"id": "1501.03593", "submitter": "Thibaud Antignac", "authors": "Vinh-Thong Ta (Inria Grenoble Rh\\^one-Alpes / CITI Insa de Lyon,\n  CITI), Thibaud Antignac (Inria Grenoble Rh\\^one-Alpes / CITI Insa de Lyon,\n  CITI)", "title": "Privacy by Design: On the Conformance Between Protocols and\n  Architectures", "comments": "FPS - 7th International Symposium on Foundations \\& Practice of\n  Security, Nov 2014, Montreal, Canada. Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In systems design, we generally distinguish the architecture and the protocol\nlevels. In the context of privacy by design, in the first case, we talk about\nprivacy architectures, which define the privacy goals and the main features of\nthe system at high level. In the latter case, we consider the underlying\nconcrete protocols and privacy enhancing technologies that implement the\narchitectures. In this paper, we address the question that whether a given\nprotocol conforms to a privacy architecture and provide the answer based on\nformal methods. We propose a process algebra variant to define protocols and\nreason about privacy properties, as well as a mapping procedure from protocols\nto architectures that are defined in a high-level architecture language.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jan 2015 07:34:33 GMT"}], "update_date": "2015-01-16", "authors_parsed": [["Ta", "Vinh-Thong", "", "Inria Grenoble Rh\u00f4ne-Alpes / CITI Insa de Lyon,\n  CITI"], ["Antignac", "Thibaud", "", "Inria Grenoble Rh\u00f4ne-Alpes / CITI Insa de Lyon,\n  CITI"]]}, {"id": "1501.03617", "submitter": "M. H. Marghny", "authors": "Marghny H. Mohamed, Yousef B. Mahdy, and Wafaa Abd El-Wahed Shaban", "title": "Confidential Algorithm for Golden Cryptography Using Haar Wavelet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  One of the most important consideration techniques when one want to solve the\nprotecting of digital signal is the golden matrix. The golden matrices can be\nused for creation of a new kind of cryptography called the golden cryptography.\nMany research papers have proved that the method is very fast and simple for\ntechnical realization and can be used for cryptographic protection of digital\nsignals. In this paper, we introduce a technique of encryption based on\ncombination of haar wavelet and golden matrix. These combinations carry out\nafter compression data by adaptive Huffman code to reduce data size and remove\nredundant data. This process will provide multisecurity services. In addition\nMessage Authentication Code (MAC) technique can be used to provide\nauthentication and the integrity of this scheme. The proposed scheme is\naccomplished through five stages, the compression data, key generation,\nencryption stage, the decryption stage and decompression at communication ends.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jan 2015 10:07:05 GMT"}], "update_date": "2015-01-16", "authors_parsed": [["Mohamed", "Marghny H.", ""], ["Mahdy", "Yousef B.", ""], ["Shaban", "Wafaa Abd El-Wahed", ""]]}, {"id": "1501.03726", "submitter": "Josep Domingo-Ferrer", "authors": "George Danezis, Josep Domingo-Ferrer, Marit Hansen, Jaap-Henk Hoepman,\n  Daniel Le Metayer, Rodica Tirtea, Stefan Schiffner", "title": "Privacy and Data Protection by Design - from policy to engineering", "comments": "79 pages in European Union Agency for Network and Information\n  Security (ENISA) report, December 2014, ISBN 978-92-9204-108-3", "journal-ref": null, "doi": "10.2824/38623", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy and data protection constitute core values of individuals and of\ndemocratic societies. There have been decades of debate on how those values\n-and legal obligations- can be embedded into systems, preferably from the very\nbeginning of the design process.\n  One important element in this endeavour are technical mechanisms, known as\nprivacy-enhancing technologies (PETs). Their effectiveness has been\ndemonstrated by researchers and in pilot implementations. However, apart from a\nfew exceptions, e.g., encryption became widely used, PETs have not become a\nstandard and widely used component in system design. Furthermore, for unfolding\ntheir full benefit for privacy and data protection, PETs need to be rooted in a\ndata governance strategy to be applied in practice.\n  This report contributes to bridging the gap between the legal framework and\nthe available technological implementation measures by providing an inventory\nof existing approaches, privacy design strategies, and technical building\nblocks of various degrees of maturity from research and development. Starting\nfrom the privacy principles of the legislation, important elements are\npresented as a first step towards a design process for privacy-friendly systems\nand services. The report sketches a method to map legal obligations to design\nstrategies, which allow the system designer to select appropriate techniques\nfor implementing the identified privacy requirements. Furthermore, the report\nreflects limitations of the approach. It concludes with recommendations on how\nto overcome and mitigate these limits.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jan 2015 22:14:57 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2015 19:38:32 GMT"}], "update_date": "2015-04-13", "authors_parsed": [["Danezis", "George", ""], ["Domingo-Ferrer", "Josep", ""], ["Hansen", "Marit", ""], ["Hoepman", "Jaap-Henk", ""], ["Metayer", "Daniel Le", ""], ["Tirtea", "Rodica", ""], ["Schiffner", "Stefan", ""]]}, {"id": "1501.03736", "submitter": "Couvreur Alain", "authors": "Alain Couvreur, Ayoub Otmani, Jean-Pierre Tillich, Val\\'erie\n  Gauthier-Umana", "title": "A Polynomial-Time Attack on the BBCRS Scheme", "comments": "Accepted to the conference Public Key Cryptography (PKC) 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The BBCRS scheme is a variant of the McEliece public-key encryption scheme\nwhere the hiding phase is performed by taking the inverse of a matrix which is\nof the form $\\mathbf{T} +\\mathbf{R}$ where $\\mathbf{T}$ is a sparse matrix with\naverage row/column weight equal to a very small quantity $m$, usually $m < 2$,\nand $\\mathbf{R}$ is a matrix of small rank $z\\geqslant 1$. The rationale of\nthis new transformation is the reintroduction of families of codes, like\ngeneralized Reed-Solomon codes, that are famously known for representing\ninsecure choices. We present a key-recovery attack when $z = 1$ and $m$ is\nchosen between $1$ and $1 + R + O( \\frac{1}{\\sqrt{n}} )$ where $R$ denotes the\ncode rate. This attack has complexity $O(n^6)$ and breaks all the parameters\nsuggested in the literature.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jan 2015 16:40:27 GMT"}], "update_date": "2015-01-16", "authors_parsed": [["Couvreur", "Alain", ""], ["Otmani", "Ayoub", ""], ["Tillich", "Jean-Pierre", ""], ["Gauthier-Umana", "Val\u00e9rie", ""]]}, {"id": "1501.03868", "submitter": "Sa\\v{s}a Radomirovi\\'c", "authors": "Sjouke Mauw and Sasa Radomirovic", "title": "Generalizing Multi-party Contract Signing", "comments": "Extended version of POST 2015 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-party contract signing (MPCS) protocols allow a group of signers to\nexchange signatures on a predefined contract. Previous approaches considered\neither completely linear protocols or fully parallel broadcasting protocols. We\nintroduce the new class of DAG MPCS protocols which combines parallel and\nlinear execution and allows for parallelism even within a signer role. This\ngeneralization is useful in practical applications where the set of signers has\na hierarchical structure, such as chaining of service level agreements and\nsubcontracting.\n  Our novel DAG MPCS protocols are represented by directed acyclic graphs and\nequipped with a labeled transition system semantics. We define the notion of\nabort-chaining sequences and prove that a DAG MPCS protocol satisfies fairness\nif and only if it does not have an abort-chaining sequence. We exhibit several\nexamples of optimistic fair DAG MPCS protocols. The fairness of these protocols\nfollows from our theory and has additionally been verified with our automated\ntool.\n  We define two complexity measures for DAG MPCS protocols, related to\nexecution time and total number of messages exchanged. We prove lower bounds\nfor fair DAG MPCS protocols in terms of these measures.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jan 2015 03:01:21 GMT"}, {"version": "v2", "created": "Tue, 17 Feb 2015 17:25:23 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Mauw", "Sjouke", ""], ["Radomirovic", "Sasa", ""]]}, {"id": "1501.03872", "submitter": "Andr\\'e Luiz Barbosa", "authors": "Andr\\'e Luiz Barbosa", "title": "The Dead Cryptographers Society Problem", "comments": "7 pages, 2 tables, 1 JavaScript code and some great new ideas on\n  Cryptography!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines The Dead Cryptographers Society Problem - DCS (where\nseveral great cryptographers created many polynomial-time Deterministic Turing\nMachines (DTMs) of a specific type, ran them on their proper descriptions\nconcatenated with some arbitrary strings, deleted them and left only the\nresults from those running, after they died: if those DTMs only permute and\nsometimes invert the bits on input, is it possible to decide the language\nformed by such resulting strings within polynomial time?), proves some facts\nabout its computational complexity, and discusses some possible uses on\nCryptography, such as into distance keys distribution, online reverse auction\nand secure communication.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jan 2015 03:40:20 GMT"}, {"version": "v10", "created": "Tue, 4 Jul 2017 06:12:28 GMT"}, {"version": "v11", "created": "Sun, 9 Jul 2017 19:10:02 GMT"}, {"version": "v12", "created": "Fri, 14 Jul 2017 20:36:01 GMT"}, {"version": "v13", "created": "Thu, 28 Sep 2017 23:13:13 GMT"}, {"version": "v14", "created": "Sun, 5 Nov 2017 15:15:49 GMT"}, {"version": "v15", "created": "Sun, 6 May 2018 07:48:56 GMT"}, {"version": "v16", "created": "Fri, 21 Dec 2018 21:34:25 GMT"}, {"version": "v2", "created": "Tue, 20 Jan 2015 20:53:52 GMT"}, {"version": "v3", "created": "Wed, 18 Feb 2015 15:48:09 GMT"}, {"version": "v4", "created": "Sun, 22 Feb 2015 17:55:49 GMT"}, {"version": "v5", "created": "Tue, 6 Oct 2015 04:10:15 GMT"}, {"version": "v6", "created": "Sun, 6 Nov 2016 15:48:20 GMT"}, {"version": "v7", "created": "Thu, 1 Jun 2017 05:56:13 GMT"}, {"version": "v8", "created": "Fri, 2 Jun 2017 06:11:23 GMT"}, {"version": "v9", "created": "Thu, 22 Jun 2017 16:55:37 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Barbosa", "Andr\u00e9 Luiz", ""]]}, {"id": "1501.04036", "submitter": "Soonhak Kwon", "authors": "Namhun Koo and Gook Hwa Cho and Byeonghwan and Soonhak Kwon", "title": "An Improvement of the Cipolla-Lehmer Type Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let F_q be a finite field with q elements with prime power q and let r>1 be\nan integer with $q\\equiv 1 \\pmod{r}$. In this paper, we present a refinement of\nthe Cipolla-Lehmer type algorithm given by H. C. Williams, and subsequently\nimproved by K. S. Williams and K. Hardy. For a given r-th power residue c in\nF_q where r is an odd prime, the algorithm of H. C. Williams determines a\nsolution of X^r=c in $O(r^3\\log q)$ multiplications in F_q, and the algorithm\nof K. S. Williams and K. Hardy finds a solution in $O(r^4+r^2\\log q)$\nmultiplications in F_q. Our refinement finds a solution in $O(r^3+r^2\\log q)$\nmultiplications in F_q. Therefore our new method is better than the previously\nproposed algorithms independent of the size of r, and the implementation result\nvia SAGE shows a substantial speed-up compared with the existing algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jan 2015 16:40:12 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["Koo", "Namhun", ""], ["Cho", "Gook Hwa", ""], ["Byeonghwan", "", ""], ["Kwon", "Soonhak", ""]]}, {"id": "1501.04132", "submitter": "Stefan Heule", "authors": "Stefan Heule, Deian Stefan, Edward Z. Yang, John C. Mitchell,\n  Alejandro Russo", "title": "IFC Inside: Retrofitting Languages with Dynamic Information Flow Control\n  (Extended Version)", "comments": "Extended version of POST'15 paper; 31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many important security problems in JavaScript, such as browser extension\nsecurity, untrusted JavaScript libraries and safe integration of mutually\ndistrustful websites (mash-ups), may be effectively addressed using an\nefficient implementation of information flow control (IFC). Unfortunately\nexisting fine-grained approaches to JavaScript IFC require modifications to the\nlanguage semantics and its engine, a non-goal for browser applications. In this\nwork, we take the ideas of coarse-grained dynamic IFC and provide the\ntheoretical foundation for a language-based approach that can be applied to any\nprogramming language for which external effects can be controlled. We then\napply this formalism to server- and client-side JavaScript, show how it\ngeneralizes to the C programming language, and connect it to the Haskell LIO\nsystem. Our methodology offers design principles for the construction of\ninformation flow control systems when isolation can easily be achieved, as well\nas compositional proofs for optimized concrete implementations of these\nsystems, by relating them to their isolated variants.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jan 2015 23:21:36 GMT"}], "update_date": "2015-01-20", "authors_parsed": [["Heule", "Stefan", ""], ["Stefan", "Deian", ""], ["Yang", "Edward Z.", ""], ["Mitchell", "John C.", ""], ["Russo", "Alejandro", ""]]}, {"id": "1501.04167", "submitter": "Chengqing Li", "authors": "Xiaowei Li, Chengqing Li, Seok-Tae Kim, In-Kwon Lee", "title": "An optical image encryption scheme based on depth-conversion integral\n  imaging and chaotic maps", "comments": "18 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integral imaging-based cryptographic algorithms provides a new way to design\nsecure and robust image encryption schemes. In this paper, we introduce a\nperformance-enhanced image encryption schemes based on depth-conversion\nintegral imaging and chaotic maps, aiming to meet the requirements of secure\nimage transmission. First, the input image is decomposed into an elemental\nimage array (EIA) by utilizing a pinhole array. Then, the obtained image are\nencrypted by combining the use of cellular automata and chaotic logistic maps.\nIn the image reconstruction process, the conventional computational integral\nimaging reconstruction (CIIR) technique is a pixel-superposition technique; the\nresolution of the reconstructed image is dramatically degraded due to the large\nmagnification in the superposition process as the pickup distance increases.\nThe smart mapping technique is introduced to improve the problem of CIIR. A\nnovel property of the proposed scheme is its depth-conversion ability, which\nconverts original elemental images recorded at long distance to ones recorded\nnear the pinhole array and consequently reduce the magnification factor. The\nresults of numerical simulations demonstrate the effectiveness and security of\nthis proposed scheme.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jan 2015 06:28:44 GMT"}], "update_date": "2015-01-20", "authors_parsed": [["Li", "Xiaowei", ""], ["Li", "Chengqing", ""], ["Kim", "Seok-Tae", ""], ["Lee", "In-Kwon", ""]]}, {"id": "1501.04186", "submitter": "Josep Domingo-Ferrer", "authors": "Josep Domingo-Ferrer, Krishnamurty Muralidhar", "title": "New Directions in Anonymization: Permutation Paradigm, Verifiability by\n  Subjects and Intruders, Transparency to Users", "comments": "27 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are currently two approaches to anonymization: \"utility first\" (use an\nanonymization method with suitable utility features, then empirically evaluate\nthe disclosure risk and, if necessary, reduce the risk by possibly sacrificing\nsome utility) or \"privacy first\" (enforce a target privacy level via a privacy\nmodel, e.g., k-anonymity or epsilon-differential privacy, without regard to\nutility). To get formal privacy guarantees, the second approach must be\nfollowed, but then data releases with no utility guarantees are obtained. Also,\nin general it is unclear how verifiable is anonymization by the data subject\n(how safely released is the record she has contributed?), what type of intruder\nis being considered (what does he know and want?) and how transparent is\nanonymization towards the data user (what is the user told about methods and\nparameters used?).\n  We show that, using a generally applicable reverse mapping transformation,\nany anonymization for microdata can be viewed as a permutation plus (perhaps) a\nsmall amount of noise; permutation is thus shown to be the essential principle\nunderlying any anonymization of microdata, which allows giving simple utility\nand privacy metrics. From this permutation paradigm, a new privacy model\nnaturally follows, which we call (d,v)-permuted privacy. The privacy ensured by\nthis method can be verified by each subject contributing an original record\n(subject-verifiability) and also at the data set level by the data protector.\nWe then proceed to define a maximum-knowledge intruder model, which we argue\nshould be the one considered in anonymization. Finally, we make the case for\nanonymization transparent to the data user, that is, compliant with Kerckhoff's\nassumption (only the randomness used, if any, must stay secret).\n", "versions": [{"version": "v1", "created": "Sat, 17 Jan 2015 10:25:33 GMT"}], "update_date": "2015-01-20", "authors_parsed": [["Domingo-Ferrer", "Josep", ""], ["Muralidhar", "Krishnamurty", ""]]}, {"id": "1501.04212", "submitter": "Goutam Paul", "authors": "Arpita Maitra, Sourya Joyee De, Goutam Paul and Asim K. Pal", "title": "Proposal for Quantum Rational Secret Sharing", "comments": null, "journal-ref": "Physical Review A, article 022305, volume 92, issue 2, August 2015", "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A rational secret sharing scheme is a game in which each party responsible\nfor reconstructing a secret tries to maximize his utility by obtaining the\nsecret alone. Quantum secret sharing schemes, either derived from quantum\nteleportation or from quantum error correcting code, do not succeed when we\nassume rational participants. This is because all existing quantum secret\nsharing schemes consider that the secret is reconstructed by a party chosen by\nthe dealer. In this paper, for the first time, we propose a quantum secret\nsharing scheme which is resistant to rational parties. The proposed scheme is\nfair (everyone gets the secret), correct and achieves strict Nash equilibrium.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jan 2015 16:57:39 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2015 13:46:15 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2015 04:23:57 GMT"}, {"version": "v4", "created": "Wed, 5 Aug 2015 13:08:35 GMT"}], "update_date": "2015-08-06", "authors_parsed": [["Maitra", "Arpita", ""], ["De", "Sourya Joyee", ""], ["Paul", "Goutam", ""], ["Pal", "Asim K.", ""]]}, {"id": "1501.04434", "submitter": "Emiliano De Cristofaro", "authors": "Kat Krol and Eleni Philippou and Emiliano De Cristofaro and M. Angela\n  Sasse", "title": "\"`They brought in the horrible key ring thing!\" Analysing the Usability\n  of Two-Factor Authentication in UK Online Banking", "comments": "To appear in NDSS Workshop on Usable Security (USEC 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To prevent password breaches and guessing attacks, banks increasingly turn to\ntwo-factor authentication (2FA), requiring users to present at least one more\nfactor, such as a one-time password generated by a hardware token or received\nvia SMS, besides a password. We can expect some solutions -- especially those\nadding a token -- to create extra work for users, but little research has\ninvestigated usability, user acceptance, and perceived security of deployed\n2FA.\n  This paper presents an in-depth study of 2FA usability with 21 UK online\nbanking customers, 16 of whom had accounts with more than one bank. We\ncollected a rich set of qualitative and quantitative data through two rounds of\nsemi-structured interviews, and an authentication diary over an average of 11\ndays. Our participants reported a wide range of usability issues, especially\nwith the use of hardware tokens, showing that the mental and physical workload\ninvolved shapes how they use online banking. Key targets for improvements are\n(i) the reduction in the number of authentication steps, and (ii) removing\nfeatures that do not add any security but negatively affect the user\nexperience.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jan 2015 09:46:23 GMT"}], "update_date": "2015-01-20", "authors_parsed": [["Krol", "Kat", ""], ["Philippou", "Eleni", ""], ["De Cristofaro", "Emiliano", ""], ["Sasse", "M. Angela", ""]]}, {"id": "1501.04473", "submitter": "Mansaf Alam Dr", "authors": "Shuchi Sethi, Kashish Ara Shakil and Mansaf Alam", "title": "Seeking Black Lining In Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is focused on attacks on confidentiality that require time\nsynchronization. This manuscript proposes a detection framework for covert\nchannel perspective in cloud security. This problem is interpreted as a binary\nclassification problem and the algorithm proposed is based on certain features\nthat emerged after data analysis of Google cluster trace that forms base for\nanalyzing attack free data. This approach can be generalized to study the flow\nof other systems and fault detection. The detection framework proposed does not\nmake assumptions pertaining to data distribution as a whole making it suitable\nto meet cloud dynamism.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jan 2015 12:33:55 GMT"}], "update_date": "2015-01-20", "authors_parsed": [["Sethi", "Shuchi", ""], ["Shakil", "Kashish Ara", ""], ["Alam", "Mansaf", ""]]}, {"id": "1501.04895", "submitter": "Li Yang", "authors": "Li Yang, Min Liang", "title": "Quantum McEliece public-key encryption scheme", "comments": "18pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a quantum version of McEliece public-key encryption\n(PKE) scheme, and analyzes its security. As is well known, the security of\nclassical McEliece PKE is not stronger than the onewayness of related classical\none-way function. We prove the security of quantum McEliece PKE ranks between\nthem. Moreover, we propose the double-encryption technique to improve its\nsecurity, and the security of the improved scheme is proved to be between the\noriginal scheme and the quantum one-time pad.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jan 2015 08:32:42 GMT"}], "update_date": "2015-01-21", "authors_parsed": [["Yang", "Li", ""], ["Liang", "Min", ""]]}, {"id": "1501.04896", "submitter": "Li Yang", "authors": "Chong Xiang, Li Yang, Yong Peng, Dongqing Chen", "title": "The Classification of Quantum Symmetric-Key Encryption Protocols", "comments": "12pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classification of quantum symmetric-key encryption protocol is presented.\nAccording to five elements of a quantum symmetric-key encryption protocol:\nplaintext, ciphertext, key, encryption algorithm and decryption algorithm,\nthere are 32 different kinds of them. Among them, 5 kinds of protocols have\nalready been constructed and studied, and 21 kinds of them are proved to be\nimpossible to construct, the last 6 kinds of them are not yet presented\neffectively. That means the research on quantum symmetric-key encryption\nprotocol only needs to consider with 5 kinds of them nowadays.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jan 2015 08:57:04 GMT"}], "update_date": "2015-01-21", "authors_parsed": [["Xiang", "Chong", ""], ["Yang", "Li", ""], ["Peng", "Yong", ""], ["Chen", "Dongqing", ""]]}, {"id": "1501.04925", "submitter": "Sayan Mitra Sayan Mitra", "authors": "Zhenqi Huang and Yu Wang and Sayan Mitra and Geir Dullerud", "title": "Controller Synthesis for Linear Time-varying Systems with Adversaries", "comments": "10 pages 4 figures; under submission for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a controller synthesis algorithm for a discrete time reach-avoid\nproblem in the presence of adversaries. Our model of the adversary captures\ntypical malicious attacks envisioned on cyber-physical systems such as sensor\nspoofing, controller corruption, and actuator intrusion. After formulating the\nproblem in a general setting, we present a sound and complete algorithm for the\ncase with linear dynamics and an adversary with a budget on the total L2-norm\nof its actions. The algorithm relies on a result from linear control theory\nthat enables us to decompose and precisely compute the reachable states of the\nsystem in terms of a symbolic simulation of the adversary-free dynamics and the\ntotal uncertainty induced by the adversary. With this decomposition, the\nsynthesis problem eliminates the universal quantifier on the adversary's\nchoices and the symbolic controller actions can be effectively solved using an\nSMT solver. The constraints induced by the adversary are computed by solving\nsecond-order cone programmings. The algorithm is later extended to synthesize\nstate-dependent controller and to generate attacks for the adversary. We\npresent preliminary experimental results that show the effectiveness of this\napproach on several example problems.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jan 2015 21:47:11 GMT"}], "update_date": "2015-01-21", "authors_parsed": [["Huang", "Zhenqi", ""], ["Wang", "Yu", ""], ["Mitra", "Sayan", ""], ["Dullerud", "Geir", ""]]}, {"id": "1501.05582", "submitter": "Armin Tavakoli", "authors": "Armin Tavakoli, Isabelle Herbauts, Marek Zukowski and Mohamed\n  Bourennane", "title": "Secret Sharing with a Single d-level Quantum System", "comments": null, "journal-ref": "Phys. Rev. A 92, 030302(R) (2015)", "doi": "10.1103/PhysRevA.92.030302", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an example of a wide class of problems for which quantum information\nprotocols based on multi-system entanglement can be mapped into much simpler\nones involving one system. Secret sharing is a cryptographic primitive which\nplays a central role in various secure multiparty computation tasks and\nmanagement of keys in cryptography. In secret sharing protocols, a classical\nmessage is divided into shares given to recipient parties in such a way that\nsome number of parties need to collaborate in order to reconstruct the message.\nQuantum protocols for the task commonly rely on multi-partite GHZ entanglement.\nWe present a multiparty secret sharing protocol which requires only sequential\ncommunication of a single quantum d-level system (for any prime d). It has huge\nadvantages in scalabilility and can be realized with the state of the art\ntechnology. n be realized with the state of the art technology.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jan 2015 17:38:35 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2015 10:04:33 GMT"}], "update_date": "2016-03-09", "authors_parsed": [["Tavakoli", "Armin", ""], ["Herbauts", "Isabelle", ""], ["Zukowski", "Marek", ""], ["Bourennane", "Mohamed", ""]]}, {"id": "1501.05673", "submitter": "Limin Jia", "authors": "Limin Jia, Shayak Sen, Deepak Garg, and Anupam Datta", "title": "System M: A Program Logic for Code Sandboxing and Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security-sensitive applications that execute untrusted code often check the\ncode's integrity by comparing its syntax to a known good value or sandbox the\ncode to contain its effects. System M is a new program logic for reasoning\nabout such security-sensitive applications. System M extends Hoare Type Theory\n(HTT) to trace safety properties and, additionally, contains two new reasoning\nprinciples. First, its type system internalizes logical equality, facilitating\nreasoning about applications that check code integrity. Second, a confinement\nrule assigns an effect type to a computation based solely on knowledge of the\ncomputation's sandbox. We prove the soundness of system M relative to a\nstep-indexed trace-based semantic model. We illustrate both new reasoning\nprinciples of system M by verifying the main integrity property of the design\nof Memoir, a previously proposed trusted computing system for ensuring state\ncontinuity of isolated security-sensitive applications.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jan 2015 22:22:44 GMT"}], "update_date": "2015-01-26", "authors_parsed": [["Jia", "Limin", ""], ["Sen", "Shayak", ""], ["Garg", "Deepak", ""], ["Datta", "Anupam", ""]]}, {"id": "1501.05916", "submitter": "Nafees Qamar", "authors": "Nafees Qamar, Yilong Yang, Andras Nadas, Zhiming Liu, and Janos\n  Sztipanovits", "title": "Anonymously Analyzing Clinical Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper takes on the problem of automatically identifying\nclinically-relevant patterns in medical datasets without compromising patient\nprivacy. To achieve this goal, we treat datasets as a black box for both\ninternal and external users of data that lets us handle clinical data queries\ndirectly and far more efficiently. The novelty of the approach lies in avoiding\nthe data de-identification process often used as a means of preserving patient\nprivacy. The implemented toolkit combines software engineering technologies\nsuch as Java EE and RESTful web services, to allow exchanging medical data in\nan unidentifiable XML format as well as restricting users to the need-to-know\nprinciple. Our technique also inhibits retrospective processing of data, such\nas attacks by an adversary on a medical dataset using advanced computational\nmethods to reveal Protected Health Information (PHI). The approach is validated\non an endoscopic reporting application based on openEHR and MST standards. From\nthe usability perspective, the approach can be used to query datasets by\nclinical researchers, governmental or non-governmental organizations in\nmonitoring health care services to improve quality of care.\n", "versions": [{"version": "v1", "created": "Wed, 19 Nov 2014 07:53:34 GMT"}], "update_date": "2015-01-26", "authors_parsed": [["Qamar", "Nafees", ""], ["Yang", "Yilong", ""], ["Nadas", "Andras", ""], ["Liu", "Zhiming", ""], ["Sztipanovits", "Janos", ""]]}, {"id": "1501.05943", "submitter": "Li Yang", "authors": "Chenmiao Wu and Li Yang", "title": "Bit-oriented quantum public-key encryption", "comments": "17 pages, no figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a bit-oriented quantum public-key scheme which uses Boolean\nfunction as private-key and randomly changed pairs of quantum state and\nclassical string as public-keys. Contrast to the typical classical public-key\nscheme, one private-key in our scheme corresponds to an exponential number of\npublic-keys. The goal of our scheme is to achieve information-theoretic\nsecurity, and the security analysis is also given.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jan 2015 12:14:36 GMT"}, {"version": "v2", "created": "Thu, 29 Jan 2015 13:12:34 GMT"}], "update_date": "2015-01-30", "authors_parsed": [["Wu", "Chenmiao", ""], ["Yang", "Li", ""]]}, {"id": "1501.05963", "submitter": "Man-Ki Yoon", "authors": "Man-Ki Yoon, Sibin Mohan, Jaesik Choi, Mihai Christodorescu and Lui\n  Sha", "title": "Learning Execution Contexts from System Call Distributions for Intrusion\n  Detection in Embedded Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing techniques used for intrusion detection do not fully utilize the\nintrinsic properties of embedded systems. In this paper, we propose a\nlightweight method for detecting anomalous executions using a distribution of\nsystem call frequencies. We use a cluster analysis to learn the legitimate\nexecution contexts of embedded applications and then monitor them at run-time\nto capture abnormal executions. We also present an architectural framework with\nminor processor modifications to aid in this process. Our prototype shows that\nthe proposed method can effectively detect anomalous executions without relying\non sophisticated analyses or affecting the critical execution paths.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2015 21:28:02 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2015 04:33:17 GMT"}], "update_date": "2015-08-04", "authors_parsed": [["Yoon", "Man-Ki", ""], ["Mohan", "Sibin", ""], ["Choi", "Jaesik", ""], ["Christodorescu", "Mihai", ""], ["Sha", "Lui", ""]]}, {"id": "1501.05990", "submitter": "Paulo Shakarian", "authors": "Jana Shakarian, Paulo Shakarian, Andrew Ruef", "title": "Cyber Attacks and Public Embarrassment: A Survey of Some Notable Hacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We hear it all too often in the media: an organization is attacked, its data,\noften containing personally identifying information, is made public, and a\nhacking group emerges to claim credit. In this excerpt, we discuss how such\ngroups operate and describe the details of a few major cyber-attacks of this\nsort in the wider context of how they occurred. We feel that understanding how\nsuch groups have operated in the past will give organizations ideas of how to\ndefend against them in the future.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jan 2015 02:35:04 GMT"}], "update_date": "2015-01-27", "authors_parsed": [["Shakarian", "Jana", ""], ["Shakarian", "Paulo", ""], ["Ruef", "Andrew", ""]]}, {"id": "1501.06095", "submitter": "Jonathan Ullman", "authors": "Thomas Steinke and Jonathan Ullman", "title": "Between Pure and Approximate Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show a new lower bound on the sample complexity of $(\\varepsilon,\n\\delta)$-differentially private algorithms that accurately answer statistical\nqueries on high-dimensional databases. The novelty of our bound is that it\ndepends optimally on the parameter $\\delta$, which loosely corresponds to the\nprobability that the algorithm fails to be private, and is the first to\nsmoothly interpolate between approximate differential privacy ($\\delta > 0$)\nand pure differential privacy ($\\delta = 0$).\n  Specifically, we consider a database $D \\in \\{\\pm1\\}^{n \\times d}$ and its\n\\emph{one-way marginals}, which are the $d$ queries of the form \"What fraction\nof individual records have the $i$-th bit set to $+1$?\" We show that in order\nto answer all of these queries to within error $\\pm \\alpha$ (on average) while\nsatisfying $(\\varepsilon, \\delta)$-differential privacy, it is necessary that\n$$ n \\geq \\Omega\\left( \\frac{\\sqrt{d \\log(1/\\delta)}}{\\alpha \\varepsilon}\n\\right), $$ which is optimal up to constant factors. To prove our lower bound,\nwe build on the connection between \\emph{fingerprinting codes} and lower bounds\nin differential privacy (Bun, Ullman, and Vadhan, STOC'14).\n  In addition to our lower bound, we give new purely and approximately\ndifferentially private algorithms for answering arbitrary statistical queries\nthat improve on the sample complexity of the standard Laplace and Gaussian\nmechanisms for achieving worst-case accuracy guarantees by a logarithmic\nfactor.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jan 2015 23:26:21 GMT"}], "update_date": "2015-01-27", "authors_parsed": [["Steinke", "Thomas", ""], ["Ullman", "Jonathan", ""]]}, {"id": "1501.06363", "submitter": "Rainer Plaga", "authors": "Rainer Plaga and Dominik Merli", "title": "A new Definition and Classification of Physical Unclonable Functions", "comments": "6 pages, 3 figures; Proceedings \"CS2 '15 Proceedings of the Second\n  Workshop on Cryptography and Security in Computing Systems\", Amsterdam, 2015,\n  ACM Digital Library", "journal-ref": null, "doi": "10.1145/2694805.2694807", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new definition of \"Physical Unclonable Functions\" (PUFs), the first one\nthat fully captures its intuitive idea among experts, is presented. A PUF is an\ninformation-storage system with a security mechanism that is\n  1. meant to impede the duplication of a precisely described\nstorage-functionality in another, separate system and\n  2. remains effective against an attacker with temporary access to the whole\noriginal system.\n  A novel classification scheme of the security objectives and mechanisms of\nPUFs is proposed and its usefulness to aid future research and security\nevaluation is demonstrated. One class of PUF security mechanisms that prevents\nan attacker to apply all addresses at which secrets are stored in the\ninformation-storage system, is shown to be closely analogous to cryptographic\nencryption. Its development marks the dawn of a new fundamental primitive of\nhardware-security engineering: cryptostorage. These results firmly establish\nPUFs as a fundamental concept of hardware security.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jan 2015 12:34:57 GMT"}], "update_date": "2015-01-27", "authors_parsed": [["Plaga", "Rainer", ""], ["Merli", "Dominik", ""]]}, {"id": "1501.06508", "submitter": "Anrin Chakraborti", "authors": "Sumeet Bajaj, Anrin Chakraborti, Radu Sion", "title": "Practical Foundations of History Independence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The way data structures organize data is often a function of the sequence of\npast operations. The organization of data is referred to as the data\nstructure's state, and the sequence of past operations constitutes the data\nstructure's history. A data structure state can therefore be used as an oracle\nto derive information about its history. As a result, for history-sensitive\napplications, such as privacy in e-voting, incremental signature schemes, and\nregulatory compliant data retention; it is imperative to conceal historical\ninformation contained within data structure states.\n  Data structure history can be hidden by making data structures history\nindependent. In this paper, we explore how to achieve history independence.\n  We observe that current history independence notions are significantly\nlimited in number and scope. There are two existing notions of history\nindependence -- weak history independence (WHI) and strong history independence\n(SHI). WHI does not protect against insider adversaries and SHI mandates\ncanonical representations, resulting in inefficiency.\n  We postulate the need for a broad, encompassing notion of history\nindependence, which can capture WHI, SHI, and a broad spectrum of new history\nindependence notions. To this end, we introduce $\\Delta$history independence\n($\\Delta$HI), a generic game-based framework that is malleable enough to\naccommodate existing and new history independence notions.\n  As an essential step towards formalizing $\\Delta$HI, we explore the concepts\nof abstract data types, data structures, machine models, memory representations\nand history independence. Finally, to bridge the gap between theory and\npractice, we outline a general recipe for building end-to-end, history\nindependent systems and demonstrate the use of the recipe in designing two\nhistory independent file systems.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jan 2015 18:22:39 GMT"}, {"version": "v2", "created": "Tue, 27 Jan 2015 01:46:26 GMT"}, {"version": "v3", "created": "Tue, 28 Jul 2015 00:36:39 GMT"}, {"version": "v4", "created": "Tue, 15 Sep 2015 21:01:34 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Bajaj", "Sumeet", ""], ["Chakraborti", "Anrin", ""], ["Sion", "Radu", ""]]}, {"id": "1501.06543", "submitter": "Alexander Zeh", "authors": "Alexander Zeh, San Ling", "title": "Construction of Quasi-Cyclic Product Codes", "comments": "10th International ITG Conference on Systems, Communications and\n  Coding (SCC), Feb 2015, Hamburg, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.DM math.CO math.IT math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear quasi-cyclic product codes over finite fields are investigated. Given\nthe generating set in the form of a reduced Gr{\\\"o}bner basis of a quasi-cyclic\ncomponent code and the generator polynomial of a second cyclic component code,\nan explicit expression of the basis of the generating set of the quasi-cyclic\nproduct code is given. Furthermore, the reduced Gr{\\\"o}bner basis of a\none-level quasi-cyclic product code is derived.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jan 2015 19:56:41 GMT"}], "update_date": "2015-01-27", "authors_parsed": [["Zeh", "Alexander", ""], ["Ling", "San", ""]]}, {"id": "1501.06814", "submitter": "Luca Rossi", "authors": "Luca Rossi, James Walker, Mirco Musolesi", "title": "Spatio-Temporal Techniques for User Identification by means of GPS\n  Mobility Data", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the greatest concerns related to the popularity of GPS-enabled devices\nand applications is the increasing availability of the personal location\ninformation generated by them and shared with application and service\nproviders. Moreover, people tend to have regular routines and be characterized\nby a set of \"significant places\", thus making it possible to identify a user\nfrom his/her mobility data.\n  In this paper we present a series of techniques for identifying individuals\nfrom their GPS movements. More specifically, we study the uniqueness of GPS\ninformation for three popular datasets, and we provide a detailed analysis of\nthe discriminatory power of speed, direction and distance of travel. Most\nimportantly, we present a simple yet effective technique for the identification\nof users from location information that are not included in the original\ndataset used for training, thus raising important privacy concerns for the\nmanagement of location datasets.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2015 16:42:03 GMT"}, {"version": "v2", "created": "Sat, 31 Jan 2015 10:41:03 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2015 15:28:46 GMT"}], "update_date": "2015-07-20", "authors_parsed": [["Rossi", "Luca", ""], ["Walker", "James", ""], ["Musolesi", "Mirco", ""]]}, {"id": "1501.07529", "submitter": "Goutam Paul", "authors": "Kaushik Nandi and Goutam Paul", "title": "Quantum Information splitting using a pair of GHZ states", "comments": null, "journal-ref": "In Quantum Information and Computation, pages 1041--1047, vol. 15,\n  issue 11 & 12, 2015", "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a protocol for quantum information splitting (QIS) of a\nrestricted class of three-qubit states among three parties Alice, Bob and\nCharlie, using a pair of GHZ states as the quantum channel. There are two\ndifferent forms of this three-qubit state that is used for QIS depending on the\ndistribution of the particles among the three parties. There is also a special\ntype of four-qubit state that can be used for QIS using the above channel. We\nexplicitly construct the quantum channel, Alice's measurement basis and the\nanalytic form of the unitary operations required by the receiver for such a\npurpose.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jan 2015 18:14:09 GMT"}, {"version": "v2", "created": "Fri, 1 May 2015 19:55:56 GMT"}], "update_date": "2015-05-04", "authors_parsed": [["Nandi", "Kaushik", ""], ["Paul", "Goutam", ""]]}, {"id": "1501.07756", "submitter": "Goutam Paul", "authors": "Arpita Maitra and Goutam Paul", "title": "A Resilient Quantum Secret Sharing Scheme", "comments": "12 pages, 2 figures", "journal-ref": "In International Journal of Theoretical Physics, pages 398--408,\n  vol. 54, issue 2, February 2015", "doi": "10.1007/s10773-014-2233-3", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A resilient secret sharing scheme is supposed to generate the secret\ncorrectly even after some shares are damaged. In this paper, we show how\nquantum error correcting codes can be exploited to design a resilient quantum\nsecret sharing scheme, where a quantum state is shared among more than one\nparties.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jan 2015 12:49:09 GMT"}], "update_date": "2015-02-02", "authors_parsed": [["Maitra", "Arpita", ""], ["Paul", "Goutam", ""]]}, {"id": "1501.07814", "submitter": "Daniel Karapetyan Dr", "authors": "Jason Crampton and Gregory Z. Gutin and Daniel Karapetyan", "title": "Valued Workflow Satisfiability Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A workflow is a collection of steps that must be executed in some specific\norder to achieve an objective. A computerised workflow management system may\nenforce authorisation policies and constraints, thereby restricting which users\ncan perform particular steps in a workflow. The existence of policies and\nconstraints may mean that a workflow is unsatisfiable, in the sense that it is\nimpossible to find an authorised user for each step in the workflow and satisfy\nall constraints. In this paper, we consider the problem of finding the \"least\nbad\" assignment of users to workflow steps by assigning a weight to each policy\nand constraint violation. To this end, we introduce a framework for associating\ncosts with the violation of workflow policies and constraints and define the\n\\emph{valued workflow satisfiability problem} (Valued WSP), whose solution is\nan assignment of steps to users of minimum cost. We establish the computational\ncomplexity of Valued WSP with user-independent constraints and show that it is\nfixed-parameter tractable. We then describe an algorithm for solving Valued WSP\nwith user-independent constraints and evaluate its performance, comparing it to\nthat of an off-the-shelf mixed integer programming package.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jan 2015 15:47:06 GMT"}], "update_date": "2015-02-02", "authors_parsed": [["Crampton", "Jason", ""], ["Gutin", "Gregory Z.", ""], ["Karapetyan", "Daniel", ""]]}, {"id": "1501.07865", "submitter": "Adebayo Omotosho Mr", "authors": "Adebayo Omotosho, Justice Emuoyibofarhe", "title": "A Criticism of the Current Security, Privacy and Accountability Issues\n  in Electronic Health Records", "comments": "published (2014)", "journal-ref": "International Journal of Applied Information Systems (IJAIS),\n  2014, Vol.7, No.8, pp 11-18", "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Cryptography has been widely accepted for security and partly for privacy\ncontrol as discovered from past works. However, many of these works did not\nprovide a way to manage cryptographic keys effectively especially in EHR\napplications, as this is the Achilles heel of cryptographic techniques\ncurrently proposed. The issue of accountability for legitimate users also has\nnot been so popular and only a few considered it in EHR. Unless a different\napproach is used, the reliant on cryptography and password or escrow based\nsystem for key management will impede trust of the system and hence its\nacceptability. Also users with right access should also be monitored without\naffecting the clinician workflow. This paper presents a detailed review of some\nselected recent approaches to ensuring security, privacy and accountability in\nEHR and gaps for future research were also identified.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jan 2015 17:56:16 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Omotosho", "Adebayo", ""], ["Emuoyibofarhe", "Justice", ""]]}]