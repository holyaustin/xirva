[{"id": "0906.0049", "submitter": "Serguei Mokhov", "authors": "Serguei A. Mokhov, Joey Paquet, and Mourad Debbabi", "title": "Towards Automated Deduction in Blackmail Case Analysis with Forensic\n  Lucid", "comments": "11 pages, 7 figures; related to arXiv:0904.3789 and arXiv:0905.2449", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work-in-progress focuses on the refinement of application of the\nintensional logic to cyberforensic analysis and its benefits are compared with\nthe finite-state automata approach. This work extends the use of the scientific\nintensional programming paradigm onto modeling and implementation of a\ncyberforensics investigation process with the backtrace of event\nreconstruction, modeling the evidence as multidimensional hierarchical\ncontexts, and proving or disproving the claims with it in the intensional\nmanner of evaluation. This is a practical, context-aware improvement over the\nfinite state automata (FSA) approach we have seen in the related works. As a\nbase implementation language model we use in this approach is a new dialect of\nthe Lucid programming language, that we call Forensic Lucid and in this paper\nwe focus on defining hierarchical contexts based on the intensional logic for\nthe evaluation of cyberforensic expressions.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2009 02:04:15 GMT"}], "update_date": "2009-06-02", "authors_parsed": [["Mokhov", "Serguei A.", ""], ["Paquet", "Joey", ""], ["Debbabi", "Mourad", ""]]}, {"id": "0906.0202", "submitter": "Abedelaziz Mohaisen", "authors": "Abedelaziz Mohaisen and Dowon Hong", "title": "Mitigating the ICA Attack against Rotation Based Transformation for\n  Privacy Preserving Clustering", "comments": "3 pages, 1 figure, appeared as a letter in ETRI journal", "journal-ref": "Abedelaziz Mohaisen, and Dowon Hong: Mitigating the ICA Attack\n  against Rotation-Based Transformation for Privacy Preserving Clustering, ETRI\n  Journal, vol.30, no.6, Dec. 2008, pp.868-870", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rotation based transformation (RBT) for privacy preserving data mining\n(PPDM) is vulnerable to the independent component analysis (ICA) attack. This\npaper introduces a modified multiple rotation based transformation (MRBT)\ntechnique for special mining applications mitigating the ICA attack while\nmaintaining the advantages of the RBT.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2009 03:31:26 GMT"}], "update_date": "2009-06-02", "authors_parsed": [["Mohaisen", "Abedelaziz", ""], ["Hong", "Dowon", ""]]}, {"id": "0906.0237", "submitter": "Thomas Roche", "authors": "Thomas Roche and C\\'edric Tavernier", "title": "Multi-Linear cryptanalysis in Power Analysis Attacks MLPA", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power analysis attacks against embedded secret key cryptosystems are widely\nstudied since the seminal paper of Paul Kocher, Joshua Ja, and Benjamin Jun in\n1998 where has been introduced the powerful Differential Power Analysis. The\nstrength of DPA is such that it became necessary to develop sound and efficient\ncountermeasures. Nowadays embedded cryptographic primitives usually integrate\none or several of these countermeasures (e.g. masking techniques, asynchronous\ndesigns, balanced dynamic dual-rail gates designs, noise adding, power\nconsumption smoothing, etc. ...). This document presents a simple, yet\ninteresting, countermeasure to DPA and HO-DPA attacks, called brutal\ncountermeasure and new power analysis attacks using multi-linear approximations\n(MLPA attacks) based on very recent and still unpublished results of Tavernier\net al..\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2009 08:34:50 GMT"}], "update_date": "2009-06-02", "authors_parsed": [["Roche", "Thomas", ""], ["Tavernier", "C\u00e9dric", ""]]}, {"id": "0906.0724", "submitter": "Piotr Bania", "authors": "Piotr Bania", "title": "Dynamic Data Flow Analysis via Virtual Code Integration (aka The\n  SpiderPig case)", "comments": "48 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paper addresses the process of dynamic data flow analysis using virtual code\nintegration (VCI), often refered to as dynamic binary rewriting. This article\nwill try to demonstrate all of the techniques that were applied in the\nSpiderPig project. It will also discuss the main differences between the\nmethods that were employed and those used in other available software, as well\nas introducing other related work. SpiderPig's approach was found to be very\nfast and was transparent enough for reliable and usable data flow analysis. It\nwas created with the purpose of providing a tool which would aid vulnerability\nand security researchers with tracing and analyzing any necessary data and its\nfurther propagation through a program. At the current state it works on IA-32\nplatforms with Microsoft Windows systems and it supports FPU, SSE, MMX and all\nof the IA-32 general instructions. SpiderPig also demonstrates the usage of a\nvirtual code integration (VCI) framework which allows for modifying the target\napplication code at the instruction level. By this I mean that the VCI\nframework allows for custom code insertion, original code modification and full\ncustomization of the original application's code. Instructions can be swapped\nout, deleted or modified at a whim, without corrupting the surrounding code and\nside-effects of the modification are resolved.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2009 14:32:37 GMT"}], "update_date": "2009-06-04", "authors_parsed": [["Bania", "Piotr", ""]]}, {"id": "0906.0921", "submitter": "Matthew Marriotti", "authors": "Matthew Marriotti", "title": "Course Material Selection Rubric for Creating Network Security Courses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Teaching network security can be a difficult task for university teachers,\nespecially for teachers at smaller universities where the course loads are more\ndiverse. Creating a new course in network security requires investigation into\nmultiple subject areas within the field and from multiple sources. This task\ncan be daunting and overwhelming for teachers from smaller universities because\nof their requirement to teach multiple subjects, not just network security.\nAlong with the requirement of teachers to understand the material that they\nwish to teach, the factors of obsolescence and the ability to build material\noff of core topics need to be addressed. These three factors are difficult for\na smaller university teacher to address without a set of standards to analyze\nthese areas. A rubric addressing these topic areas of timelessness,\nassociability, and simplicity has been created to assist in the selection of\nmaterials based on the three criteria. The use of this rubric provides an\neffective means to choose material for a new course and help teachers to\npresent the material they determine most appropriate to teach.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2009 14:46:11 GMT"}], "update_date": "2009-09-30", "authors_parsed": [["Marriotti", "Matthew", ""]]}, {"id": "0906.1030", "submitter": "Stephanie Wehner", "authors": "Robert Koenig, Stephanie Wehner, Juerg Wullschleger", "title": "Unconditional security from noisy quantum storage", "comments": "25 pages (IEEE two column), 13 figures, v4: published version (to\n  appear in IEEE Transactions on Information Theory), including bit wise\n  min-entropy sampling. however, for experimental purposes block sampling can\n  be much more convenient, please see v3 arxiv version if needed. See\n  arXiv:0911.2302 for a companion paper addressing aspects of a practical\n  implementation using block sampling", "journal-ref": "IEEE Trans. Inf. Th., vol. 58, no. 3, p. 1962-1984 (2012)", "doi": "10.1109/TIT.2011.2177772", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the implementation of two-party cryptographic primitives based on\nthe sole assumption that no large-scale reliable quantum storage is available\nto the cheating party. We construct novel protocols for oblivious transfer and\nbit commitment, and prove that realistic noise levels provide security even\nagainst the most general attack. Such unconditional results were previously\nonly known in the so-called bounded-storage model which is a special case of\nour setting. Our protocols can be implemented with present-day hardware used\nfor quantum key distribution. In particular, no quantum storage is required for\nthe honest parties.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2009 03:47:20 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2009 23:47:05 GMT"}, {"version": "v3", "created": "Mon, 19 Jul 2010 04:11:20 GMT"}, {"version": "v4", "created": "Thu, 8 Sep 2011 09:09:02 GMT"}], "update_date": "2013-12-06", "authors_parsed": [["Koenig", "Robert", ""], ["Wehner", "Stephanie", ""], ["Wullschleger", "Juerg", ""]]}, {"id": "0906.1199", "submitter": "Yannick Chevalier", "authors": "Yannick Chevalier (LORIA), Kourjieh Mounira (IRIT)", "title": "On the Decidability of (ground) Reachability Problems for Cryptographic\n  Protocols (extended version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of cryptographic protocols in a symbolic model is relative to a\ndeduction system that models the possible actions of an attacker regarding an\nexecution of this protocol. We present in this paper a transformation algorithm\nfor such deduction systems provided the equational theory has the finite\nvariant property. the termination of this transformation entails the\ndecidability of the ground reachability problems. We prove that it is necessary\nto add one other condition to obtain the decidability of non-ground problems,\nand provide one new such criterion.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2009 20:00:15 GMT"}], "update_date": "2009-06-09", "authors_parsed": [["Chevalier", "Yannick", "", "LORIA"], ["Mounira", "Kourjieh", "", "IRIT"]]}, {"id": "0906.1225", "submitter": "Michael Goodrich", "authors": "Michael T. Goodrich", "title": "Pipelined Algorithms to Detect Cheating in Long-Term Grid Computations", "comments": "Expanded version with an additional figure; ISSN 0304-3975", "journal-ref": "Theoretical Computer Science, Volume 408, Issues 2-3, Excursions\n  in Algorithmics: A Collection of Papers in Honor of Franco P. Preparata, 28\n  November 2008, Pages 199-207", "doi": "10.1016/j.tcs.2008.08.008", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies pipelined algorithms for protecting distributed grid\ncomputations from cheating participants, who wish to be rewarded for tasks they\nreceive but don't perform. We present improved cheater detection algorithms\nthat utilize natural delays that exist in long-term grid computations. In\nparticular, we partition the sequence of grid tasks into two interleaved\nsequences of task rounds, and we show how to use those rounds to devise the\nfirst general-purpose scheme that can catch all cheaters, even when cheaters\ncollude. The main idea of this algorithm might at first seem\ncounter-intuitive--we have the participants check each other's work. A naive\nimplementation of this approach would, of course, be susceptible to collusion\nattacks, but we show that by, adapting efficient solutions to the parallel\nprocessor diagnosis problem, we can tolerate collusions of lazy cheaters, even\nif the number of such cheaters is a fraction of the total number of\nparticipants. We also include a simple economic analysis of cheaters in grid\ncomputations and a parameterization of the main deterrent that can be used\nagainst them--the probability of being caught.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2009 22:29:34 GMT"}], "update_date": "2009-06-09", "authors_parsed": [["Goodrich", "Michael T.", ""]]}, {"id": "0906.1245", "submitter": "R Doomun", "authors": "Marianne Azer, Sherif El-Kassas, Magdy El-Soudani", "title": "A Full Image of the Wormhole Attacks - Towards Introducing Complex\n  Wormhole Attacks in wireless Ad Hoc Networks", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper analyzes wormhole attack modes and classes and point to its threat\nimpacts on ad hoc networks. New improvements are suggested to these types of\nattacks.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2009 03:43:59 GMT"}], "update_date": "2009-06-09", "authors_parsed": [["Azer", "Marianne", ""], ["El-Kassas", "Sherif", ""], ["El-Soudani", "Magdy", ""]]}, {"id": "0906.1835", "submitter": "Ashish Khisti", "authors": "Ashish Khisti, Suhas Diggavi, Gregory Wornell", "title": "Secret-Key Generation using Correlated Sources and Channels", "comments": "29 Pages, Submitted IEEE Trans. Information Theory", "journal-ref": null, "doi": "10.1109/TIT.2011.2173629", "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of generating a shared secret key between two terminals\nin a joint source-channel setup -- the sender communicates to the receiver over\na discrete memoryless wiretap channel and additionally the terminals have\naccess to correlated discrete memoryless source sequences. We establish lower\nand upper bounds on the secret-key capacity. These bounds coincide,\nestablishing the capacity, when the underlying channel consists of independent,\nparallel and reversely degraded wiretap channels. In the lower bound, the\nequivocation terms of the source and channel components are functionally\nadditive. The secret-key rate is maximized by optimally balancing the the\nsource and channel contributions. This tradeoff is illustrated in detail for\nthe Gaussian case where it is also shown that Gaussian codebooks achieve the\ncapacity. When the eavesdropper also observes a source sequence, the secret-key\ncapacity is established when the sources and channels of the eavesdropper are a\ndegraded version of the legitimate receiver. Finally the case when the\nterminals also have access to a public discussion channel is studied. We\npropose generating separate keys from the source and channel components and\nestablish the optimality of this approach when the when the channel outputs of\nthe receiver and the eavesdropper are conditionally independent given the\ninput.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2009 22:36:33 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Khisti", "Ashish", ""], ["Diggavi", "Suhas", ""], ["Wornell", "Gregory", ""]]}, {"id": "0906.1963", "submitter": "Piotr Bania", "authors": "Piotr Bania", "title": "Evading network-level emulation", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently more and more attention has been paid to the intrusion detection\nsystems (IDS) which don't rely on signature based detection approach. Such\nsolutions try to increase their defense level by using heuristics detection\nmethods like network-level emulation. This technique allows the intrusion\ndetection systems to stop unknown threats, which normally couldn't be stopped\nby standard signature detection techniques.\n  In this article author will describe general concepts of network-level\nemulation technique including its advantages and disadvantages (weak sides)\ntogether with providing potential countermeasures against this type of\ndetection method.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2009 16:02:28 GMT"}], "update_date": "2009-06-11", "authors_parsed": [["Bania", "Piotr", ""]]}, {"id": "0906.2446", "submitter": "Serguei Mokhov", "authors": "Marc-Andr\\'e Laverdi\\`ere, Serguei A. Mokhov, Suhasini Tsapa, and\n  Djamel Benredjem", "title": "Ftklipse - Design and Implementation of an Extendable Computer Forensics\n  Environment: Software Requirements Specification Document", "comments": "SRS project document of an open-source project; 25 pages; 4 figures;\n  from April 2006; v2 adds missing .ind file for the index", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The purpose behind this article is to describe the features of Ftklipse, an\nextendable platform for computer forensics. This document designed to provide a\ndetailed specification for the developers of Ftklipse. Ftklipse is a\nthick-client solution for forensics investigation. It is designed to collect\nand preserve evidence, to analyze it and to report on it. It supports chain of\ncustody management, access control policies, and batch operation of its\nincluded tools in order to facilitate and accelerate the investigation. The\nenvironment itself and its tools are configurable as well and is based on\nEclipse.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2009 04:46:52 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2009 04:34:51 GMT"}], "update_date": "2009-07-27", "authors_parsed": [["Laverdi\u00e8re", "Marc-Andr\u00e9", ""], ["Mokhov", "Serguei A.", ""], ["Tsapa", "Suhasini", ""], ["Benredjem", "Djamel", ""]]}, {"id": "0906.2447", "submitter": "Serguei Mokhov", "authors": "Marc-Andr\\'e Laverdi\\`ere, Serguei A. Mokhov, Suhasini Tsapa, and\n  Djamel Benredjem", "title": "Ftklipse - Design and Implementation of an Extendable Computer Forensics\n  Environment: Specification Design Document", "comments": "37 pages, 11 figures, 3 tables, index; April 24, 2006 project. This\n  SDD document follows the SRS specification of the same project found at\n  arXiv:0906.2446 ; v2 adds the missing .ind file for the index", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The purpose of this work is to design and implement a plugin-based\nenvironment that allows to integrate forensic tools working together to support\nprogramming tasks and addition of new tools. Integration is done through GUI\ncomponents. The end-system environment must have user friendly GUI,\nconfiguration capabilities, plug-in capabilities to insert/inject new tools,\ncase management, and chain of custody capabilities, along with evidence\ngathering capabilities, evidence preservation capabilities, and, finally report\ngeneration capabilities. A subset of these requirements has been implemented in\nFtklipse, an open-source project, which is detailed throughout the rest of this\ndocument.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2009 05:06:22 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2009 04:39:22 GMT"}], "update_date": "2009-07-27", "authors_parsed": [["Laverdi\u00e8re", "Marc-Andr\u00e9", ""], ["Mokhov", "Serguei A.", ""], ["Tsapa", "Suhasini", ""], ["Benredjem", "Djamel", ""]]}, {"id": "0906.2512", "submitter": "Serguei Mokhov", "authors": "Marc-Andr\\'e Laverdi\\`ere, Serguei A. Mokhov, and Djamel Benredjem", "title": "On Implementation of a Safer C Library, ISO/IEC TR 24731", "comments": "33 pages, 6 figures, 16 listings, index; a report document on the\n  open source project. April 2006. v2 adds missing .ind file for the index", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The functions standardized as part of ISO C 1999 and their addendums improved\nvery little the security options from the previously available library. The\nlargest flaw remained that no function asked for the buffer size of destination\nbuffers for any function copying data into a user-supplied buffer. According to\nearlier research we performed, we know that error condition handling was the\nfirst solution to security vulnerabilities, followed by precondition\nvalidation. The standard C functions typically perform little precondition\nvalidation and error handling, allowing for a wide range of security issues to\nbe introduced in their use. ISO/IEC TR 24731, titled as \"TR 24731: Safer C\nlibrary functions\", defines 41 new library functions for memory copying, string\nhandling (both for normal and wide character strings), time printing, sorting,\nsearching etc. Another innovation it brings is a constraint handling\narchitecture, forcing error handling when certain security-related\npreconditions are violated when the functions are called. It also specifies the\nnull-termination of all strings manipulated through its function and introduces\na new unsigned integer type that helps preventing integer overflows and\nunderflows. It is currently implemented by Microsoft as part of their Visual\nStudio 2005 and above. We examine the architecture of our implementation of\nISO/IEC TR 24731. We first introduce our architectural philosophy before\ninforming the reader about the Siemens Four View Model, an architectural\nmethodology for the conception of large-scale software systems. Afterwards, we\nexamine each of the view, as architected for our library. Finally, we conclude\nwith other software engineering matters that were of high importance in the\ndevelopment of our implementation.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2009 17:00:24 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2009 04:44:56 GMT"}], "update_date": "2009-07-27", "authors_parsed": [["Laverdi\u00e8re", "Marc-Andr\u00e9", ""], ["Mokhov", "Serguei A.", ""], ["Benredjem", "Djamel", ""]]}, {"id": "0906.2947", "submitter": "Stylianos Basagiannis", "authors": "Stylianos Basagiannis, Panagiotis Katsaros and Andrew Pombortsis", "title": "Attacking an OT-Based Blind Signature Scheme", "comments": "3 pages, 2 figures, sumbitted for evaluation, under the title\n  \"Security Analysis of an OT-based blind signature scheme\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe an attack against one of the\nOblivious-Transfer-based blind signatures scheme, proposed in [1]. An attacker\nwith a primitive capability of producing specific-range random numbers, while\nexhibiting a partial MITM behavior, is able to corrupt the communication\nbetween the protocol participants. The attack is quite efficient as it leads to\na protocol communication corruption and has a sound-minimal computational cost.\nWe propose a solution to fix the security flaw.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2009 14:23:19 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2009 12:02:35 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2009 11:33:05 GMT"}, {"version": "v4", "created": "Tue, 10 Nov 2009 14:24:14 GMT"}], "update_date": "2009-11-10", "authors_parsed": [["Basagiannis", "Stylianos", ""], ["Katsaros", "Panagiotis", ""], ["Pombortsis", "Andrew", ""]]}, {"id": "0906.3461", "submitter": "Martin Drozda", "authors": "Martin Drozda, Sven Schaust, Helena Szczerbicka", "title": "AIS for Misbehavior Detection in Wireless Sensor Networks: Performance\n  and Design Principles", "comments": "16 pages, 20 figures, a full version of our IEEE CEC 2007 paper", "journal-ref": null, "doi": "10.1109/CEC.2007.4424955", "report-no": null, "categories": "cs.NI cs.AI cs.CR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sensor network is a collection of wireless devices that are able to monitor\nphysical or environmental conditions. These devices (nodes) are expected to\noperate autonomously, be battery powered and have very limited computational\ncapabilities. This makes the task of protecting a sensor network against\nmisbehavior or possible malfunction a challenging problem. In this document we\ndiscuss performance of Artificial immune systems (AIS) when used as the\nmechanism for detecting misbehavior.\n  We show that (i) mechanism of the AIS have to be carefully applied in order\nto avoid security weaknesses, (ii) the choice of genes and their interaction\nhave a profound influence on the performance of the AIS, (iii) randomly created\ndetectors do not comply with limitations imposed by communications protocols\nand (iv) the data traffic pattern seems not to impact significantly the overall\nperformance.\n  We identified a specific MAC layer based gene that showed to be especially\nuseful for detection; genes measure a network's performance from a node's\nviewpoint. Furthermore, we identified an interesting complementarity property\nof genes; this property exploits the local nature of sensor networks and moves\nthe burden of excessive communication from normally behaving nodes to\nmisbehaving nodes. These results have a direct impact on the design of AIS for\nsensor networks and on engineering of sensor networks.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2009 15:31:29 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Drozda", "Martin", ""], ["Schaust", "Sven", ""], ["Szczerbicka", "Helena", ""]]}, {"id": "0906.3768", "submitter": "R Doomun", "authors": "Srdjan Stankovic, Dejan Simic", "title": "Defense Strategies Against Modern Botnets", "comments": "7 pages, International Journal of Computer Science and Information\n  Security", "journal-ref": "IJCSIS, June 2009, Vol. 2", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Botnets are networks of compromised computers with malicious code which are\nremotely controlled and which are used for starting distributed denial of\nservice (DDoS) attacks, sending enormous number of e-mails (SPAM) and other\nsorts of attacks. Defense against modern Botnets is a real challenge. This\npaper offers several strategies for defense against Botnets with a list and\ndescription of measures and activities which should be carried out in order to\nestablish successful defense. The paper also offers parallel preview of the\nstrategies with their advantages and disadvantages considered in accordance\nwith various criteria.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2009 02:43:46 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2009 08:01:23 GMT"}], "update_date": "2009-06-23", "authors_parsed": [["Stankovic", "Srdjan", ""], ["Simic", "Dejan", ""]]}, {"id": "0906.3769", "submitter": "R Doomun", "authors": "C. H. Liu, Y. F. Lin, Jason J. Y. Chen", "title": "Using Agent to Coordinate Web Services", "comments": "7 pages, International Journal of Computer Science and Information\n  Security", "journal-ref": "IJCSIS, June 2009, Vol. 2", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, agent and web service are two separate research areas. We\nfigure that, through agent communication, agent is suitable to coordinate web\nservices. However, there exist agent communication problems due to the lack of\nuniform, cross-platform vocabulary. Fortunately, ontology defines a vocabulary.\nWe thus propose a new agent communication layer and present the web ontology\nlanguage (OWL)-based operational ontologies that provides a declarative\ndescription. It can be accessed by various engines to facilitate agent\ncommunication. Further, in our operational ontologies, we define the mental\nattitudes of agents that can be shared among other agents. Our architecture\nenhanced the 3APL agent platform, and it is implemented as an agent\ncommunication framework. Finally, we extended the framework to be compatible\nwith the web ontology language for service (OWL-S), and then develop a movie\nrecommendation system with four OWL-S semantic web services on the framework.\nThe benefits of this work are: 1) dynamic web service coordination, 2)\nontological reasoning through uniform representation, namely, the declarative\ndescription, and 3) easy reuse and extension of both ontology and engine\nthrough extending ontology.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2009 02:46:20 GMT"}], "update_date": "2009-06-23", "authors_parsed": [["Liu", "C. H.", ""], ["Lin", "Y. F.", ""], ["Chen", "Jason J. Y.", ""]]}, {"id": "0906.3843", "submitter": "R Doomun", "authors": "M. A. Faizal, M. Mohd Zaki, S. Shahrin, Y. Robiah, S. Siti Rahayu, B.\n  Nazrulazhar", "title": "Threshold Verification Technique for Network Intrusion Detection System", "comments": "8 Pages, International Journal of Computer Science and Information\n  Security", "journal-ref": "IJCSIS Vol.2, No.1, June 2009", "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet has played a vital role in this modern world, the possibilities and\nopportunities offered are limitless. Despite all the hype, Internet services\nare liable to intrusion attack that could tamper the confidentiality and\nintegrity of important information. An attack started with gathering the\ninformation of the attack target, this gathering of information activity can be\ndone as either fast or slow attack. The defensive measure network administrator\ncan take to overcome this liability is by introducing Intrusion Detection\nSystems (IDSs) in their network. IDS have the capabilities to analyze the\nnetwork traffic and recognize incoming and on-going intrusion. Unfortunately\nthe combination of both modules in real time network traffic slowed down the\ndetection process. In real time network, early detection of fast attack can\nprevent any further attack and reduce the unauthorized access on the targeted\nmachine. The suitable set of feature selection and the correct threshold value,\nadd an extra advantage for IDS to detect anomalies in the network. Therefore\nthis paper discusses a new technique for selecting static threshold value from\na minimum standard features in detecting fast attack from the victim\nperspective. In order to increase the confidence of the threshold value the\nresult is verified using Statistical Process Control (SPC). The implementation\nof this approach shows that the threshold selected is suitable for identifying\nthe fast attack in real time.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2009 04:06:42 GMT"}], "update_date": "2009-06-23", "authors_parsed": [["Faizal", "M. A.", ""], ["Zaki", "M. Mohd", ""], ["Shahrin", "S.", ""], ["Robiah", "Y.", ""], ["Rahayu", "S. Siti", ""], ["Nazrulazhar", "B.", ""]]}, {"id": "0906.3895", "submitter": "Igor Margasi\\'nski Ph.D.", "authors": "Igor Margasinski", "title": "A Parallelism-Based Approach to Network Anonymization", "comments": "16 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering topologies of anonymous networks we used to organizing anonymous\ncommunication into hard to trace paths hiding its origin or destination. In\nanonymity the company is crucial, however the serial transportation imposes a\ncostly tradeoff between a level of privacy and a speed of communication.\n  This paper introduces a framework of a novel architecture for anonymous\nnetworks that hides initiators of communications by parallelization of\nanonymous links. The new approach, which is based on the grounds of the\nanonymous P2P network called P2Priv, does not require content forwarding via a\nchain of proxy nodes to assure high degree of anonymity. Contrary to P2Priv,\nthe new architecture can be suited to anonymization of various network\ncommunications, including anonymous access to distributed as well as\nclient-server services. In particular, it can be considered as an anonymization\nplatform for these network applications where both privacy and low delays are\nrequired.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2009 20:55:13 GMT"}], "update_date": "2009-06-23", "authors_parsed": [["Margasinski", "Igor", ""]]}, {"id": "0906.3956", "submitter": "R Doomun", "authors": "Joe Prathap P M., V. Vasudevan", "title": "Analysis of the various key management algorithms and new proposal in\n  the secure multicast communications", "comments": "8 pages, International Journal of Computer Science and Information\n  Security", "journal-ref": "IJCSIS 2009, June Issue, Vol.2. No.1", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the evolution of the Internet, multicast communications seem\nparticularly well adapted for large scale commercial distribution applications,\nfor example, the pay TV channels and secure videoconferencing. Key management\nfor multicast remains an open topic in secure Communications today. Key\nmanagement mainly has to do with the distribution and update of keying material\nduring the group life. Several key tree based approach has been proposed by\nvarious authors to create and distribute the multicast group key in effective\nmanner. There are different key management algorithms that facilitate efficient\ndistribution and rekeying of the group key. These protocols normally add\ncommunication overhead as well as computation overhead at the group key\ncontroller and at the group members. This paper explores the various algorithms\nalong with the performances and derives an improved method.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2009 08:55:33 GMT"}], "update_date": "2009-06-23", "authors_parsed": [["M.", "Joe Prathap P", ""], ["Vasudevan", "V.", ""]]}, {"id": "0906.4217", "submitter": "Krzysztof Szczypiorski", "authors": "Krzysztof Szczypiorski", "title": "A Performance Analysis of HICCUPS - a Steganographic System for WLAN", "comments": "5 pages, 5 figures, 3 tables. Submitted to the First International\n  Workshop on Network Steganography - IWNS 2009, November 18-20, 2009, Wuhan\n  (China)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents an analysis of performance features of the HICCUPS (HIdden\nCommunication system for CorrUPted networkS) including the efficiency and the\ncost of the system in WLANs (Wireless Local Area Networks). The analysis relies\non the original CSMA/CA (Carrier Sense Multiple Access with Collision\nAvoidance) 802.11 Markov chain-based model.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2009 14:43:07 GMT"}], "update_date": "2009-06-24", "authors_parsed": [["Szczypiorski", "Krzysztof", ""]]}, {"id": "0906.4415", "submitter": "Gaurav  Bhatnagar Mr.", "authors": "Gaurav Bhatnagar and Balasubramanian Raman", "title": "Robust Watermarking in Multiresolution Walsh-Hadamard Transform", "comments": "6 Pages, 16 Figure, 2 Tables", "journal-ref": "Proc. of IEEE International Advance Computing Conference (IACC\n  2009), Patiala, India, 6-7 March 2009, pp. 894-899", "doi": "10.1109/IADCC.2009.4809134", "report-no": null, "categories": "cs.CR cs.IT cs.MM math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a newer version of Walsh-Hadamard Transform namely\nmultiresolution Walsh-Hadamard Transform (MR-WHT) is proposed for images.\nFurther, a robust watermarking scheme is proposed for copyright protection\nusing MRWHT and singular value decomposition. The core idea of the proposed\nscheme is to decompose an image using MR-WHT and then middle singular values of\nhigh frequency sub-band at the coarsest and the finest level are modified with\nthe singular values of the watermark. Finally, a reliable watermark extraction\nscheme is developed for the extraction of the watermark from the distorted\nimage. The experimental results show better visual imperceptibility and\nresiliency of the proposed scheme against intentional or un-intentional variety\nof attacks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2009 07:23:51 GMT"}], "update_date": "2009-06-25", "authors_parsed": [["Bhatnagar", "Gaurav", ""], ["Raman", "Balasubramanian", ""]]}, {"id": "0906.4481", "submitter": "Pankaj Kohli", "authors": "Pankaj Kohli", "title": "Coarse-grained Dynamic Taint Analysis for Defeating Control and\n  Non-control Data Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory corruption attacks remain the primary threat for computer security.\nInformation flow tracking or taint analysis has been proven to be effective\nagainst most memory corruption attacks. However, there are two shortcomings\nwith current taint analysis based techniques. First, these techniques cause\napplication slowdown by about 76% thereby limiting their practicality. Second,\nthese techniques cannot handle non-control data attacks i.e., attacks that do\nnot overwrite control data such as return address, but instead overwrite\ncritical application configuration data or user identity data. In this work, to\naddress these problems, we describe a coarse-grained taint analysis technique\nthat uses information flow tracking at the level of application data objects.\nWe propagate a one-bit taint over each application object that is modified by\nuntrusted data thereby reducing the taint management overhead considerably. We\nperformed extensive experimental evaluation of our approach and show that it\ncan detect all critical attacks such as buffer overflows, and format string\nattacks, including non-control data attacks. Unlike the currently known\napproaches that can detect such a wide range of attacks, our approach does not\nrequire the source code or any hardware extensions. Run-time performance\noverhead evaluation shows that, on an average, our approach causes application\nslowdown by only 37% which is an order of magnitude improvement over existing\napproaches. Finally, since our approach performs run-time binary\ninstrumentation, it is easier to integrate it with existing applications and\nsystems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2009 14:07:35 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2009 07:18:43 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Kohli", "Pankaj", ""]]}, {"id": "0906.4570", "submitter": "Luca Vigan\\`o", "authors": "Michele Barletta, Silvio Ranise, Luca Vigan\\`o", "title": "Verifying the Interplay of Authorization Policies and Workflow in\n  Service-Oriented Architectures (Full version)", "comments": "16 pages, 4 figures, full version of paper at Symposium on Secure\n  Computing (SecureCom09)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A widespread design approach in distributed applications based on the\nservice-oriented paradigm, such as web-services, consists of clearly separating\nthe enforcement of authorization policies and the workflow of the applications,\nso that the interplay between the policy level and the workflow level is\nabstracted away. While such an approach is attractive because it is quite\nsimple and permits one to reason about crucial properties of the policies under\nconsideration, it does not provide the right level of abstraction to specify\nand reason about the way the workflow may interfere with the policies, and vice\nversa. For example, the creation of a certificate as a side effect of a\nworkflow operation may enable a policy rule to fire and grant access to a\ncertain resource; without executing the operation, the policy rule should\nremain inactive. Similarly, policy queries may be used as guards for workflow\ntransitions.\n  In this paper, we present a two-level formal verification framework to\novercome these problems and formally reason about the interplay of\nauthorization policies and workflow in service-oriented architectures. This\nallows us to define and investigate some verification problems for SO\napplications and give sufficient conditions for their decidability.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2009 16:31:42 GMT"}], "update_date": "2009-06-26", "authors_parsed": [["Barletta", "Michele", ""], ["Ranise", "Silvio", ""], ["Vigan\u00f2", "Luca", ""]]}, {"id": "0906.4618", "submitter": "Pedro Peris-Lopez", "authors": "Pedro Peris-Lopez, Julio C. Hernandez-Castro, Christos Dimitrakakis,\n  Aikaterini Mitrokotsa, Juan M. E. Tapiador", "title": "Shedding Light on RFID Distance Bounding Protocols and Terrorist Fraud\n  Attacks", "comments": "31 pages, 10 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vast majority of RFID authentication protocols assume the proximity\nbetween readers and tags due to the limited range of the radio channel.\nHowever, in real scenarios an intruder can be located between the prover (tag)\nand the verifier (reader) and trick this last one into thinking that the prover\nis in close proximity. This attack is generally known as a relay attack in\nwhich scope distance fraud, mafia fraud and terrorist attacks are included.\nDistance bounding protocols represent a promising countermeasure to hinder\nrelay attacks. Several protocols have been proposed during the last years but\nvulnerabilities of major or minor relevance have been identified in most of\nthem. In 2008, Kim et al. [1] proposed a new distance bounding protocol with\nthe objective of being the best in terms of security, privacy, tag\ncomputational overhead and fault tolerance. In this paper, we analyze this\nprotocol and we present a passive full disclosure attack, which allows an\nadversary to discover the long-term secret key of the tag. The presented attack\nis very relevant, since no security objectives are met in Kim et al.'s\nprotocol. Then, design guidelines are introduced with the aim of facilitating\nprotocol designers the stimulating task of designing secure and efficient\nschemes against relay attacks. Finally a new protocol, named Hitomi and\ninspired by [1], is designed conforming the guidelines proposed previously.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2009 07:12:26 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2010 19:35:19 GMT"}], "update_date": "2010-06-22", "authors_parsed": [["Peris-Lopez", "Pedro", ""], ["Hernandez-Castro", "Julio C.", ""], ["Dimitrakakis", "Christos", ""], ["Mitrokotsa", "Aikaterini", ""], ["Tapiador", "Juan M. E.", ""]]}, {"id": "0906.4668", "submitter": "{\\L}ukasz Chmielewski Mr.", "authors": "{\\L}ukasz Chmielewski, Jaap-Henk Hoepman, Peter van Rossum", "title": "Client-Server Password Recovery (Extended Abstract)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human memory is not perfect - people constantly memorize new facts and forget\nold ones. One example is forgetting a password, a common problem raised at IT\nhelp desks. We present several protocols that allow a user to automatically\nrecover a password from a server using partial knowledge of the password. These\nprotocols can be easily adapted to the personal entropy setting, where a user\ncan recover a password only if he can answer a large enough subset of personal\nquestions.\n  We introduce client-server password recovery methods, in which the recovery\ndata are stored at the server, and the recovery procedures are integrated into\nthe login procedures. These methods apply to two of the most common types of\npassword based authentication systems. The security of these solutions is\nsignificantly better than the security of presently proposed password recovery\nschemes. Our protocols are based on a variation of threshold encryption that\nmay be of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2009 14:41:45 GMT"}], "update_date": "2009-06-26", "authors_parsed": [["Chmielewski", "\u0141ukasz", ""], ["Hoepman", "Jaap-Henk", ""], ["van Rossum", "Peter", ""]]}, {"id": "0906.4762", "submitter": "Alin Suciu PhD", "authors": "Cristian Klein, Octavian Cret, Alin Suciu", "title": "Design and Implementation of a High Quality and High Throughput TRNG in\n  FPGA", "comments": "5 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the design and implementation of a high-quality and\nhigh-throughput true-random number generator (TRNG) in FPGA. Various practical\nissues which we encountered are highlighted and the influence of the various\nparameters on the functioning of the TRNG are discussed. We also propose a few\nvalues for the parameters which use the minimum amount of the resources but\nstill pass common random number generator test batteries such as DieHard and\nTestU01.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2009 18:32:24 GMT"}], "update_date": "2009-06-26", "authors_parsed": [["Klein", "Cristian", ""], ["Cret", "Octavian", ""], ["Suciu", "Alin", ""]]}, {"id": "0906.5031", "submitter": "R Doomun", "authors": "Ram Kumar Singh, Prof. T. Ramajujam", "title": "Intrusion Detection System Using Advanced Honeypots", "comments": "9 Pages, International Journal of Computer Science and Information\n  Security (IJCSIS)", "journal-ref": "IJCSIS June 2009 Issue, Vol. 2, No. 1", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exponential growth of Internet traffic has made public servers\nincreasingly vulnerable to unauthorized accesses and intrusions. In addition to\nmaintaining low latency for the client, filtering unauthorized accesses has\nbecome one of the major concerns of a server maintainer. This implementation of\nan Intrusion Detection System distinguishes between the traffic coming from\nclients and the traffic originated from the attackers, in an attempt to\nsimultaneously mitigate the problems of both latency and security. We then\npresent the results of a series of stress and scalability tests, and suggest a\nnumber of potential uses for such a system. As computer attacks are becoming\nmore and more difficult to identify the need for better and more efficient\nintrusion detection systems increases. The main problem with current intrusion\ndetection systems is high rate of false alarms. Using honeypots provides\neffective solution to increase the security.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2009 03:34:28 GMT"}], "update_date": "2009-06-30", "authors_parsed": [["Singh", "Ram Kumar", ""], ["Ramajujam", "Prof. T.", ""]]}, {"id": "0906.5060", "submitter": "R Doomun", "authors": "Prof. Dhananjay R. Kalbande, Dr. G. T. Thampi, Mr. Manish Singh", "title": "Incidence Handling and Response System", "comments": "8 Pages, International Journal of Computer Science and Information\n  Security (IJCSIS)", "journal-ref": "IJCSIS June 2009 Issue, Vol. 2, No. 1", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A computer network can be attacked in a number of ways. The security-related\nthreats have become not only numerous but also diverse and they may also come\nin the form of blended attacks. It becomes difficult for any security system to\nblock all types of attacks. This gives rise to the need of an incidence\nhandling capability which is necessary for rapidly detecting incidents,\nminimizing loss and destruction, mitigating the weaknesses that were exploited\nand restoring the computing services. Incidence response has always been an\nimportant aspect of information security but it is often overlooked by security\nadministrators. in this paper, we propose an automated system which will handle\nthe security threats and make the computer network capable enough to withstand\nany kind of attack. we also present the state-of-the-art technology in\ncomputer, network and software which is required to build such a system.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2009 10:10:18 GMT"}], "update_date": "2009-06-30", "authors_parsed": [["Kalbande", "Prof. Dhananjay R.", ""], ["Thampi", "Dr. G. T.", ""], ["Singh", "Mr. Manish", ""]]}, {"id": "0906.5110", "submitter": "Susmit Jha", "authors": "Susmit Jha", "title": "Statistical Analysis of Privacy and Anonymity Guarantees in Randomized\n  Security Protocol Implementations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security protocols often use randomization to achieve probabilistic\nnon-determinism. This non-determinism, in turn, is used in obfuscating the\ndependence of observable values on secret data. Since the correctness of\nsecurity protocols is very important, formal analysis of security protocols has\nbeen widely studied in literature. Randomized security protocols have also been\nanalyzed using formal techniques such as process-calculi and probabilistic\nmodel checking. In this paper, we consider the problem of validating\nimplementations of randomized protocols. Unlike previous approaches which treat\nthe protocol as a white-box, our approach tries to verify an implementation\nprovided as a black box. Our goal is to infer the secrecy guarantees provided\nby a security protocol through statistical techniques. We learn the\nprobabilistic dependency of the observable outputs on secret inputs using\nBayesian network. This is then used to approximate the leakage of secret. In\norder to evaluate the accuracy of our statistical approach, we compare our\ntechnique with the probabilistic model checking technique on two examples:\ncrowds protocol and dining crypotgrapher's protocol.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2009 23:24:14 GMT"}], "update_date": "2009-06-30", "authors_parsed": [["Jha", "Susmit", ""]]}, {"id": "0906.5123", "submitter": "R Doomun", "authors": "Poonam Garg", "title": "Cryptanalysis of SDES via evolutionary computation techniques", "comments": "7 Pages, International Journal of Computer Science and Information\n  Security (IJCSIS)", "journal-ref": "IJCSIS May 2009 Issue, Vol. 1, No. 1", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cryptanalysis of simplified data encryption standard can be formulated as\nNP-Hard combinatorial problem. The goal of this paper is two fold. First we\nwant to make a study about how evolutionary computation techniques can\nefficiently solve the NP-Hard combinatorial problem. For achieving this goal we\ntest several evolutionary computation techniques like memetic algorithm,\ngenetic algorithm and simulated annealing for the cryptanalysis of simplified\ndata encryption standard problem (SDES). And second was a comparison between\nmemetic algorithm, genetic algorithm and simulated annealing were made in order\nto investigate the performance for the cryptanalysis on SDES. The methods were\ntested and extensive computational results show that memetic algorithm performs\nbetter than genetic algorithms and simulated annealing for such type of NP-Hard\ncombinatorial problem. This paper represents our first effort toward efficient\nmemetic algorithm for the cryptanalysis of SDES.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2009 09:29:04 GMT"}], "update_date": "2009-06-30", "authors_parsed": [["Garg", "Poonam", ""]]}, {"id": "0906.5181", "submitter": "Serguei Mokhov", "authors": "Serguei A. Mokhov, Joey Paquet, and Mourad Debbabi", "title": "Reasoning About a Simulated Printer Case Investigation with Forensic\n  Lucid", "comments": "18 pages, 3 figures, 7 listings, TOC, index; this article closely\n  relates to arXiv:0906.0049 and arXiv:0904.3789 but to remain stand-alone\n  repeats some of the background and introductory content; abstract presented\n  at HSC'09 and the full updated paper at ICDF2C'11. This is an updated/edited\n  version after ICDF2C proceedings with more references and corrections", "journal-ref": "S. A. Mokhov, J. Paquet, and M. Debbabi. Reasoning about a\n  simulated printer case investigation with Forensic Lucid. In P. Gladyshev and\n  M. K. Rogers, editors, Proceedings of ICDF2C'11, number 0088 in LNICST, pp.\n  282-296. Springer, 2012", "doi": "10.1007/978-3-642-35515-8_23", "report-no": null, "categories": "cs.LO cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we model the ACME (a fictitious company name) \"printer case\nincident\" and make its specification in Forensic Lucid, a Lucid- and\nintensional-logic-based programming language for cyberforensic analysis and\nevent reconstruction specification. The printer case involves a dispute between\ntwo parties that was previously solved using the finite-state automata (FSA)\napproach, and is now re-done in a more usable way in Forensic Lucid. Our\nsimulation is based on the said case modeling by encoding concepts like\nevidence and the related witness accounts as an evidential statement context in\na Forensic Lucid program, which is an input to the transition function that\nmodels the possible deductions in the case. We then invoke the transition\nfunction (actually its reverse) with the evidential statement context to see if\nthe evidence we encoded agrees with one's claims and then attempt to\nreconstruct the sequence of events that may explain the claim or disprove it.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2009 00:06:22 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2012 09:41:26 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Mokhov", "Serguei A.", ""], ["Paquet", "Joey", ""], ["Debbabi", "Mourad", ""]]}]