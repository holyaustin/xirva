[{"id": "1703.00031", "submitter": "Dylan Gray", "authors": "Dylan Gray, Joshua Joy and Mario Gerla", "title": "MPC Validation and Aggregation of Unit Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When dealing with privatized data, it is important to be able to protect\nagainst malformed user inputs. This becomes difficult in MPC systems as each\nserver should not contain enough information to know what values any user has\nsubmitted. In this paper, we implement an MPC technique to verify blinded user\ninputs are unit vectors. In addition, we introduce a BGW circuit which can\nsecurely aggregate the blinded inputs while only releasing the result when it\nis above a public threshold. These distributed techniques take as input a unit\nvector. While this initially seems limiting compared to real number input, it\nis quite powerful for cases such as selecting from a list of options,\nindicating a location from a set of possibilities, or any system which uses\none-hot encoding.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 19:17:57 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Gray", "Dylan", ""], ["Joy", "Joshua", ""], ["Gerla", "Mario", ""]]}, {"id": "1703.00053", "submitter": "Catalin Hritcu", "authors": "Jonathan Protzenko, Jean-Karim Zinzindohou\\'e, Aseem Rastogi, Tahina\n  Ramananandro, Peng Wang, Santiago Zanella-B\\'eguelin, Antoine\n  Delignat-Lavaud, Catalin Hritcu, Karthikeyan Bhargavan, C\\'edric Fournet and\n  Nikhil Swamy", "title": "Verified Low-Level Programming Embedded in F*", "comments": "extended version of ICFP final camera ready version; only\n  Acknowledgements differ from 30 Aug 2017 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Low*, a language for low-level programming and verification, and\nits application to high-assurance optimized cryptographic libraries. Low* is a\nshallow embedding of a small, sequential, well-behaved subset of C in F*, a\ndependently-typed variant of ML aimed at program verification. Departing from\nML, Low* does not involve any garbage collection or implicit heap allocation;\ninstead, it has a structured memory model \\`a la CompCert, and it provides the\ncontrol required for writing efficient low-level security-critical code.\n  By virtue of typing, any Low* program is memory safe. In addition, the\nprogrammer can make full use of the verification power of F* to write\nhigh-level specifications and verify the functional correctness of Low* code\nusing a combination of SMT automation and sophisticated manual proofs. At\nextraction time, specifications and proofs are erased, and the remaining code\nenjoys a predictable translation to C. We prove that this translation preserves\nsemantics and side-channel resistance.\n  We provide a new compiler back-end from Low* to C and, to evaluate our\napproach, we implement and verify various cryptographic algorithms,\nconstructions, and tools for a total of about 28,000 lines of code,\nspecification and proof. We show that our Low* code delivers performance\ncompetitive with existing (unverified) C cryptographic libraries, suggesting\nour approach may be applicable to larger-scale low-level software.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 20:53:33 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 09:00:51 GMT"}, {"version": "v3", "created": "Sat, 24 Jun 2017 10:28:26 GMT"}, {"version": "v4", "created": "Tue, 27 Jun 2017 18:41:01 GMT"}, {"version": "v5", "created": "Wed, 30 Aug 2017 06:25:59 GMT"}, {"version": "v6", "created": "Tue, 11 Dec 2018 12:56:19 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Protzenko", "Jonathan", ""], ["Zinzindohou\u00e9", "Jean-Karim", ""], ["Rastogi", "Aseem", ""], ["Ramananandro", "Tahina", ""], ["Wang", "Peng", ""], ["Zanella-B\u00e9guelin", "Santiago", ""], ["Delignat-Lavaud", "Antoine", ""], ["Hritcu", "Catalin", ""], ["Bhargavan", "Karthikeyan", ""], ["Fournet", "C\u00e9dric", ""], ["Swamy", "Nikhil", ""]]}, {"id": "1703.00055", "submitter": "Catalin Hritcu", "authors": "Niklas Grimm, Kenji Maillard, C\\'edric Fournet, Catalin Hritcu, Matteo\n  Maffei, Jonathan Protzenko, Tahina Ramananandro, Aseem Rastogi, Nikhil Swamy,\n  Santiago Zanella-B\\'eguelin", "title": "A Monadic Framework for Relational Verification: Applied to Information\n  Security, Program Equivalence, and Optimizations", "comments": "CPP'18 extended version with the missing ERC acknowledgement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Relational properties describe multiple runs of one or more programs. They\ncharacterize many useful notions of security, program refinement, and\nequivalence for programs with diverse computational effects, and they have\nreceived much attention in the recent literature. Rather than developing\nseparate tools for special classes of effects and relational properties, we\nadvocate using a general purpose proof assistant as a unifying framework for\nthe relational verification of effectful programs. The essence of our approach\nis to model effectful computations using monads and to prove relational\nproperties on their monadic representations, making the most of existing\nsupport for reasoning about pure programs.\n  We apply this method in F* and evaluate it by encoding a variety of\nrelational program analyses, including information flow control, program\nequivalence and refinement at higher order, correctness of program\noptimizations and game-based cryptographic security. By relying on SMT-based\nautomation, unary weakest preconditions, user-defined effects, and monadic\nreification, we show that, compared to unary properties, verifying relational\nproperties requires little additional effort from the F* programmer.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 21:04:50 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 19:29:14 GMT"}, {"version": "v3", "created": "Sat, 8 Jul 2017 16:47:18 GMT"}, {"version": "v4", "created": "Thu, 13 Jul 2017 15:00:38 GMT"}, {"version": "v5", "created": "Thu, 12 Oct 2017 14:53:34 GMT"}, {"version": "v6", "created": "Mon, 27 Nov 2017 14:15:55 GMT"}, {"version": "v7", "created": "Sat, 12 Oct 2019 10:56:42 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Grimm", "Niklas", ""], ["Maillard", "Kenji", ""], ["Fournet", "C\u00e9dric", ""], ["Hritcu", "Catalin", ""], ["Maffei", "Matteo", ""], ["Protzenko", "Jonathan", ""], ["Ramananandro", "Tahina", ""], ["Rastogi", "Aseem", ""], ["Swamy", "Nikhil", ""], ["Zanella-B\u00e9guelin", "Santiago", ""]]}, {"id": "1703.00073", "submitter": "Tetsufumi Tanamoto", "authors": "Tetsufumi Tanamoto, Satoshi Takaya, Nobuaki Sakamoto, Hirotsugu Kasho,\n  Shinichi Yasuda, Takao Marukame, Shinobu Fujita, and Yuichiro Mitani", "title": "Physically unclonable function using initial waveform of ring\n  oscillators on 65 nm CMOS technology", "comments": "5 pages, 9 figures", "journal-ref": "Jpn. J. Appl. Phys. 56, 04CF13 (2017)", "doi": "10.7567/JJAP.56.04CF13", "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A silicon physically unclonable function (PUF) using ring oscillators (ROs)\nhas the advantage of easy application in both an application specific\nintegrated circuit (ASIC) and a field-programmable gate array (FPGA). Here, we\nprovide a RO-PUF using the initial waveform of the ROs based on 65 nm CMOS\ntechnology. Compared with the conventional RO-PUF, the number of ROs is greatly\nreduced and the time needed to generate an ID is within a couple of system\nclocks.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 16:38:17 GMT"}], "update_date": "2017-06-26", "authors_parsed": [["Tanamoto", "Tetsufumi", ""], ["Takaya", "Satoshi", ""], ["Sakamoto", "Nobuaki", ""], ["Kasho", "Hirotsugu", ""], ["Yasuda", "Shinichi", ""], ["Marukame", "Takao", ""], ["Fujita", "Shinobu", ""], ["Mitani", "Yuichiro", ""]]}, {"id": "1703.00207", "submitter": "Aditya Ahuja", "authors": "Aditya Ahuja", "title": "A Quantum-Classical Scheme towards Quantum Functional Encryption", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum encryption is a well studied problem for both classical and quantum\ninformation. However, little is known about quantum encryption schemes which\nenable the user, under different keys, to learn different functions of the\nplaintext, given the ciphertext. In this paper, we give a novel one-bit\nsecret-key quantum encryption scheme, a classical extension of which allows\ndifferent key holders to learn different length subsequences of the plaintext\nfrom the ciphertext. We prove our quantum-classical scheme secure under the\nnotions of quantum semantic security, quantum entropic indistinguishability,\nand recent security definitions from the field of functional encryption.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 10:11:52 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Ahuja", "Aditya", ""]]}, {"id": "1703.00263", "submitter": "Ghazal Kachigar", "authors": "Ghazal Kachigar and Jean-Pierre Tillich", "title": "Quantum Information Set Decoding Algorithms", "comments": "20 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The security of code-based cryptosystems such as the McEliece cryptosystem\nrelies primarily on the difficulty of decoding random linear codes. The best\ndecoding algorithms are all improvements of an old algorithm due to Prange:\nthey are known under the name of information set decoding techniques. It is\nalso important to assess the security of such cryptosystems against a quantum\ncomputer. This research thread started in Overbeck and Sendrier's 2009 survey\non code-based cryptography, and the best algorithm to date has been Bernstein's\nquantising of the simplest information set decoding algorithm, namely Prange's\nalgorithm. It consists in applying Grover's quantum search to obtain a\nquadratic speed-up of Prange's algorithm. In this paper, we quantise other\ninformation set decoding algorithms by using quantum walk techniques which were\ndevised for the subset-sum problem by Bernstein, Jeffery, Lange and Meurer.\nThis results in improving the worst-case complexity of $2^{0.06035n}$ of\nBernstein's algorithm to $2^{0.05869n}$ with the best algorithm presented here\n(where $n$ is the codelength).\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 12:32:44 GMT"}, {"version": "v2", "created": "Sat, 22 Apr 2017 19:55:41 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Kachigar", "Ghazal", ""], ["Tillich", "Jean-Pierre", ""]]}, {"id": "1703.00298", "submitter": "Thomas Rinsma", "authors": "Thomas Rinsma", "title": "Automatic Library Version Identification, an Exploration of Techniques", "comments": "9 pages, short technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is the result of a two month research internship on the topic of\nlibrary version identification. In this paper, ideas and techniques from\nliterature in the area of binary comparison and fingerprinting are outlined and\napplied to the problem of (version) identification of shared libraries and of\nlibraries within statically linked binary executables. Six comparison\ntechniques are chosen and implemented in an open-source tool which in turn\nmakes use of the open-source radare2 framework for signature generation. The\neffectiveness of the techniques is empirically analyzed by comparing both\nartificial and real sample files against a reference dataset of multiple\nversions of dozens of libraries. The results show that out of these techniques,\nreadable string--based techniques perform the best and that one of these\ntechniques correctly identifies multiple libraries contained in a stripped\nstatically linked executable file.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 13:58:52 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Rinsma", "Thomas", ""]]}, {"id": "1703.00366", "submitter": "Emiliano De Cristofaro", "authors": "Apostolos Pyrgelis, Carmela Troncoso, Emiliano De Cristofaro", "title": "What Does The Crowd Say About You? Evaluating Aggregation-based Location\n  Privacy", "comments": "To appear in PETS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information about people's movements and the locations they visit enables an\nincreasing number of mobility analytics applications, e.g., in the context of\nurban and transportation planning, In this setting, rather than collecting or\nsharing raw data, entities often use aggregation as a privacy protection\nmechanism, aiming to hide individual users' location traces. Furthermore, to\nbound information leakage from the aggregates, they can perturb the input of\nthe aggregation or its output to ensure that these are differentially private.\n  In this paper, we set to evaluate the impact of releasing aggregate location\ntime-series on the privacy of individuals contributing to the aggregation. We\nintroduce a framework allowing us to reason about privacy against an adversary\nattempting to predict users' locations or recover their mobility patterns. We\nformalize these attacks as inference problems, and discuss a few strategies to\nmodel the adversary's prior knowledge based on the information she may have\naccess to. We then use the framework to quantify the privacy loss stemming from\naggregate location data, with and without the protection of differential\nprivacy, using two real-world mobility datasets. We find that aggregates do\nleak information about individuals' punctual locations and mobility profiles.\nThe density of the observations, as well as timing, play important roles, e.g.,\nregular patterns during peak hours are better protected than sporadic\nmovements. Finally, our evaluation shows that both output and input\nperturbation offer little additional protection, unless they introduce large\namounts of noise ultimately destroying the utility of the data.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 16:22:52 GMT"}, {"version": "v2", "created": "Tue, 6 Jun 2017 14:43:48 GMT"}, {"version": "v3", "created": "Sat, 10 Jun 2017 10:58:48 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Pyrgelis", "Apostolos", ""], ["Troncoso", "Carmela", ""], ["De Cristofaro", "Emiliano", ""]]}, {"id": "1703.00369", "submitter": "Rob Meijer", "authors": "Rob J Meijer", "title": "MattockFS; Page-cache and access-control concerns in asynchronous\n  message-based forensic frameworks on the Linux platform", "comments": "dissertation, Univ College London, June 2016", "journal-ref": null, "doi": "10.13140/RG.2.2.35426.53440", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this dissertation the feasibility of creating a page-cache efficient\nstorage- and messaging solution with integrity geared access control for a\nscalable forensic framework is researched. The Open Computer Forensics\nArchitecture (OCFA),a lab-side scalable computer forensics framework,\nintroduced the concept of a message passing concurrency based forensic\nframework. Since then, the amount of per-investigation data to be processed in\na lab environment has continued to grow significantly while available RAM and\nCPU processing power combined with prohibitive cost and limited capacity of SSD\nsolutions have shifted processing from being largely CPU constrained to being\nmuch more IO constrained. OCFA suffered from several page-cache-miss related\nperformance issues that have grown more significant as a result of this shift.\nIn the light of anti-forensics and general issues related to process integrity,\nOCFA did not leverage the power of its message passing based design to address\nintegrity concerns.\n  The main purpose of this dissertation is to analyze and evaluate a number of\npage-cache friendly technologies that could contribute to the creation of a\ncomputer forensics lab-geared scalable message-passing-concurrency based\nforensic framework with a significantly reduced quantity of page-cache-miss\ninduced spurious IO operations, taking into account integrity related issues.\n  Provenance logs from historic investigations conducted using the Open\nComputer Forensics Architecture were thoroughly analyzed in this study, during\nwhich several bottlenecks and design flaws in OCFA were identified. A number of\nstrategies were devised to address these bottlenecks in future computer\nforensic frameworks. Finally, the most prominently page-cache related\nstrategies were consolidated with access-control measures into a user-space\nfile-system and low-level API prototype.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 16:30:20 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Meijer", "Rob J", ""]]}, {"id": "1703.00371", "submitter": "Jamie Hayes", "authors": "Jamie Hayes and George Danezis", "title": "Generating Steganographic Images via Adversarial Training", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training was recently shown to be competitive against supervised\nlearning methods on computer vision tasks, however, studies have mainly been\nconfined to generative tasks such as image synthesis. In this paper, we apply\nadversarial training techniques to the discriminative task of learning a\nsteganographic algorithm. Steganography is a collection of techniques for\nconcealing information by embedding it within a non-secret medium, such as\ncover texts or images. We show that adversarial training can produce robust\nsteganographic techniques: our unsupervised training scheme produces a\nsteganographic algorithm that competes with state-of-the-art steganographic\ntechniques, and produces a robust steganalyzer, which performs the\ndiscriminative task of deciding if an image contains secret information. We\ndefine a game between three parties, Alice, Bob and Eve, in order to\nsimultaneously train both a steganographic algorithm and a steganalyzer. Alice\nand Bob attempt to communicate a secret message contained within an image,\nwhile Eve eavesdrops on their conversation and attempts to determine if secret\ninformation is embedded within the image. We represent Alice, Bob and Eve by\nneural networks, and validate our scheme on two independent image datasets,\nshowing our novel method of studying steganographic problems is surprisingly\ncompetitive against established steganographic techniques.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 16:34:59 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 10:58:27 GMT"}, {"version": "v3", "created": "Mon, 24 Jul 2017 13:15:16 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Hayes", "Jamie", ""], ["Danezis", "George", ""]]}, {"id": "1703.00383", "submitter": "Andjela Draganic", "authors": "Andjela Draganic, Milan Maric, Irena Orovic, Srdjan Stankovic", "title": "Identification of image source using serialnumber-based watermarking\n  under Compressive Sensing conditions", "comments": "submitted to MIPRO 2017 conference, Opatija, Croatia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the protection of ownership and the prevention of unauthorized\nmanipulation of digital images becomes an important concern, there is also a\nbig issue of image source origin authentication. This paper proposes a\nprocedure for the identification of the image source and content by using the\nPublic Key Cryptography Signature (PKCS). The procedure is based on the PKCS\nwatermarking of the images captured with numerous automatic observing cameras\nin the Trap View cloud system. Watermark is created based on 32-bit PKCS serial\nnumber and embedded into the captured image. Watermark detection on the\nreceiver side extracts the serial number and indicates the camera which\ncaptured the image by comparing the original and the extracted serial numbers.\nThe watermarking procedure is designed to provide robustness to image\noptimization based on the Compressive Sensing approach. Also, the procedure is\ntested under various attacks and shows successful identification of ownership.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 16:52:16 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Draganic", "Andjela", ""], ["Maric", "Milan", ""], ["Orovic", "Irena", ""], ["Stankovic", "Srdjan", ""]]}, {"id": "1703.00403", "submitter": "Brian McWilliams", "authors": "Christina Heinze-Deml, Brian McWilliams, Nicolai Meinshausen", "title": "Preserving Differential Privacy Between Features in Distributed\n  Estimation", "comments": null, "journal-ref": "Stat 7 (1), 2018", "doi": "10.1002/sta4.189", "report-no": null, "categories": "stat.ML cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy is crucial in many applications of machine learning. Legal, ethical\nand societal issues restrict the sharing of sensitive data making it difficult\nto learn from datasets that are partitioned between many parties. One important\ninstance of such a distributed setting arises when information about each\nrecord in the dataset is held by different data owners (the design matrix is\n\"vertically-partitioned\").\n  In this setting few approaches exist for private data sharing for the\npurposes of statistical estimation and the classical setup of differential\nprivacy with a \"trusted curator\" preparing the data does not apply. We work\nwith the notion of $(\\epsilon,\\delta)$-distributed differential privacy which\nextends single-party differential privacy to the distributed,\nvertically-partitioned case. We propose PriDE, a scalable framework for\ndistributed estimation where each party communicates perturbed random\nprojections of their locally held features ensuring\n$(\\epsilon,\\delta)$-distributed differential privacy is preserved. For\n$\\ell_2$-penalized supervised learning problems PriDE has bounded estimation\nerror compared with the optimal estimates obtained without privacy constraints\nin the non-distributed setting. We confirm this empirically on real world and\nsynthetic datasets.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 17:30:14 GMT"}, {"version": "v2", "created": "Tue, 27 Jun 2017 08:59:48 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Heinze-Deml", "Christina", ""], ["McWilliams", "Brian", ""], ["Meinshausen", "Nicolai", ""]]}, {"id": "1703.00475", "submitter": "Shahrzad Keshavarz Shahrzad Keshavarz", "authors": "Shahrzad Keshavarz, Christof Paar and Daniel Holcomb", "title": "Design Automation for Obfuscated Circuits with Multiple Viable Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gate camouflaging is a technique for obfuscating the function of a circuit\nagainst reverse engineering attacks. However, if an adversary has pre-existing\nknowledge about the set of functions that are viable for an application, random\ncamouflaging of gates will not obfuscate the function well. In this case, the\nadversary can target their search, and only needs to decide whether each of the\nviable functions could be implemented by the circuit.\n  In this work, we propose a method for using camouflaged cells to obfuscate a\ndesign that has a known set of viable functions. The circuit produced by this\nmethod ensures that an adversary will not be able to rule out any viable\nfunctions unless she is able to uncover the gate functions of the camouflaged\ncells. Our method comprises iterated synthesis within an overall optimization\nloop to combine the viable functions, followed by technology mapping to deploy\ncamouflaged cells while maintaining the plausibility of all viable functions.\nWe evaluate our technique on cryptographic S-box functions and show that,\nrelative to a baseline approach, it achieves up to 38\\% area reduction in\nPRESENT-style S-Boxes and 48\\% in DES S-boxes.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 19:32:05 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Keshavarz", "Shahrzad", ""], ["Paar", "Christof", ""], ["Holcomb", "Daniel", ""]]}, {"id": "1703.00536", "submitter": "Ania Piotrowska", "authors": "Ania Piotrowska and Jamie Hayes and Tariq Elahi and Sebastian Meiser\n  and George Danezis", "title": "The Loopix Anonymity System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Loopix, a low-latency anonymous communication system that provides\nbi-directional 'third-party' sender and receiver anonymity and unobservability.\nLoopix leverages cover traffic and brief message delays to provide anonymity\nand achieve traffic analysis resistance, including against a global network\nadversary. Mixes and clients self-monitor the network via loops of traffic to\nprovide protection against active attacks, and inject cover traffic to provide\nstronger anonymity and a measure of sender and receiver unobservability.\nService providers mediate access in and out of a stratified network of Poisson\nmix nodes to facilitate accounting and off-line message reception, as well as\nto keep the number of links in the system low, and to concentrate cover\ntraffic. We provide a theoretical analysis of the Poisson mixing strategy as\nwell as an empirical evaluation of the anonymity provided by the protocol and a\nfunctional implementation that we analyze in terms of scalability by running it\non AWS EC2. We show that a Loopix relay can handle upwards of 300 messages per\nsecond, at a small delay overhead of less than 1.5 ms on top of the delays\nintroduced into messages to provide security. Overall message latency is in the\norder of seconds - which is low for a mix-system. Furthermore, many mix nodes\ncan be securely added to a stratified topology to scale throughput without\nsacrificing anonymity.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 22:33:41 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Piotrowska", "Ania", ""], ["Hayes", "Jamie", ""], ["Elahi", "Tariq", ""], ["Meiser", "Sebastian", ""], ["Danezis", "George", ""]]}, {"id": "1703.00726", "submitter": "Yakup Kutlu", "authors": "Yakup Kutlu, Apdullah Yay{\\i}k", "title": "Grayscale Image Authentication using Neural Hashing", "comments": "international journal of Natural and Engineering Sciences\n  (NESciences.com) : Image Authentication, Cryptology, Hash Function,\n  Statistical and Security Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many different approaches for neural network based hash functions have been\nproposed. Statistical analysis must correlate security of them. This paper\nproposes novel neural hashing approach for gray scale image authentication. The\nsuggested system is rapid, robust, useful and secure. Proposed hash function\ngenerates hash values using neural network one-way property and non-linear\ntechniques. As a result security and performance analysis are performed and\nsatisfying results are achieved. These features are dominant reasons for\npreferring against traditional ones.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 11:26:56 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Kutlu", "Yakup", ""], ["Yay\u0131k", "Apdullah", ""]]}, {"id": "1703.01101", "submitter": "Volker Fischer", "authors": "Volker Fischer, Mummadi Chaithanya Kumar, Jan Hendrik Metzen, Thomas\n  Brox", "title": "Adversarial Examples for Semantic Image Segmentation", "comments": "ICLR 2017 workshop submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning methods in general and Deep Neural Networks in particular\nhave shown to be vulnerable to adversarial perturbations. So far this\nphenomenon has mainly been studied in the context of whole-image\nclassification. In this contribution, we analyse how adversarial perturbations\ncan affect the task of semantic segmentation. We show how existing adversarial\nattackers can be transferred to this task and that it is possible to create\nimperceptible adversarial perturbations that lead a deep network to misclassify\nalmost all pixels of a chosen class while leaving network prediction nearly\nunchanged outside this class.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 10:27:16 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Fischer", "Volker", ""], ["Kumar", "Mummadi Chaithanya", ""], ["Metzen", "Jan Hendrik", ""], ["Brox", "Thomas", ""]]}, {"id": "1703.01106", "submitter": "Mikko Heikkil\\\"a", "authors": "Mikko Heikkil\\\"a and Eemil Lagerspetz and Samuel Kaski and Kana\n  Shimizu and Sasu Tarkoma and Antti Honkela", "title": "Differentially Private Bayesian Learning on Distributed Data", "comments": "13 pages, 7 figures. Modified text, changed algorithm used, included\n  tests on additional dataset, fixed several errors, added proof of asymptotic\n  efficiency to supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications of machine learning, for example in health care, would\nbenefit from methods that can guarantee privacy of data subjects. Differential\nprivacy (DP) has become established as a standard for protecting learning\nresults. The standard DP algorithms require a single trusted party to have\naccess to the entire data, which is a clear weakness. We consider DP Bayesian\nlearning in a distributed setting, where each party only holds a single sample\nor a few samples of the data. We propose a learning strategy based on a secure\nmulti-party sum function for aggregating summaries from data holders and the\nGaussian mechanism for DP. Our method builds on an asymptotically optimal and\npractically efficient DP Bayesian inference with rapidly diminishing extra\ncost.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 10:44:47 GMT"}, {"version": "v2", "created": "Mon, 29 May 2017 15:11:26 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Heikkil\u00e4", "Mikko", ""], ["Lagerspetz", "Eemil", ""], ["Kaski", "Samuel", ""], ["Shimizu", "Kana", ""], ["Tarkoma", "Sasu", ""], ["Honkela", "Antti", ""]]}, {"id": "1703.01284", "submitter": "Filipp Valovich", "authors": "Filipp Valovich", "title": "Investcoin: A System for Privacy-Preserving Investments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a new framework for Privacy-Preserving Investment systems\nin a distributed model. In this model, independent investors can transfer funds\nto independent projects, in the same way as it works on crowdfunding platforms.\nThe framework protects the investors' single payments from being detected (by\nany other party), only the sums of each investor's payments are revealed.\nLikewise, the projects' single incoming payments are concealed and only the\nfinal sums of the incoming payments for every project are revealed. In this\nway, no other party than the investor (not even the system administration) can\ndetect how much she paid to any single project. Though it is still possible to\nconfidentially exchange any part of an investment between any pair of\ninvestors, such that market liquidity is unaffected by the system. On top, our\nframework allows a privacy-preserving return of a multiple of all the held\ninvestments (e.g. interest payments or dividends) to the indivdual investors\nwhile still revealing nothing else than the sum of all returns for every\ninvestor. We provide reasonable security guarantees for this framework that are\nbased on common notions from the Secure Multi-Party Computation literature. As\ninstantiation for this framework we present Investcoin. It is a proper\ncombination of three cryptographic protocols, namely a Private Stream\nAggregation scheme, a Commitment scheme and a Range test and it is usable in\nconnection with any existing currency. The security of these protocols is based\non the DDH assumption. By a composition theorem from the SMPC literature, the\nsecurity of the resulting Investcoin protocol is also based on the DDH\nassumption. Furthermore, we provide a simple decentralised key generation\nprotocol for Investcoin supporting dynamic join/leave and fault-tolarance of\ninvestors and moreover achieves some security guarantees against malicious\ninvestors.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 18:51:20 GMT"}, {"version": "v2", "created": "Tue, 13 Jun 2017 14:15:10 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Valovich", "Filipp", ""]]}, {"id": "1703.01340", "submitter": "Chaofei Yang", "authors": "Chaofei Yang, Qing Wu, Hai Li, Yiran Chen", "title": "Generative Poisoning Attack Method Against Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poisoning attack is identified as a severe security threat to machine\nlearning algorithms. In many applications, for example, deep neural network\n(DNN) models collect public data as the inputs to perform re-training, where\nthe input data can be poisoned. Although poisoning attack against support\nvector machines (SVM) has been extensively studied before, there is still very\nlimited knowledge about how such attack can be implemented on neural networks\n(NN), especially DNNs. In this work, we first examine the possibility of\napplying traditional gradient-based method (named as the direct gradient\nmethod) to generate poisoned data against NNs by leveraging the gradient of the\ntarget model w.r.t. the normal data. We then propose a generative method to\naccelerate the generation rate of the poisoned data: an auto-encoder\n(generator) used to generate poisoned data is updated by a reward function of\nthe loss, and the target NN model (discriminator) receives the poisoned data to\ncalculate the loss w.r.t. the normal data. Our experiment results show that the\ngenerative method can speed up the poisoned data generation rate by up to\n239.38x compared with the direct gradient method, with slightly lower model\naccuracy degradation. A countermeasure is also designed to detect such\npoisoning attack methods by checking the loss of the target model.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 21:13:48 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Yang", "Chaofei", ""], ["Wu", "Qing", ""], ["Li", "Hai", ""], ["Chen", "Yiran", ""]]}, {"id": "1703.01348", "submitter": "Amna Qureshi", "authors": "David Meg\\'ias, Amna Qureshi", "title": "Collusion-resistant and privacy-preserving P2P multimedia distribution\n  based on recombined fingerprinting", "comments": "58 pages, 6 figures, journal", "journal-ref": null, "doi": "10.1016/j.eswa.2016.11.015", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recombined fingerprints have been suggested as a convenient approach to\nimprove the efficiency of anonymous fingerprinting for the legal distribution\nof copyrighted multimedia contents in P2P systems. The recombination idea is\ninspired by the principles of mating, recombination and heredity of the DNA\nsequences of living beings, but applied to binary sequences, like in genetic\nalgorithms. However, the existing recombination-based fingerprinting systems do\nnot provide a convenient solution for collusion resistance, since they require\ndouble-layer fingerprinting codes, making the practical implementation of such\nsystems a challenging task. In fact, collusion resistance is regarded as the\nmost relevant requirement of a fingerprinting scheme, and the lack of any\nacceptable solution to this problem would possibly deter content merchants from\ndeploying any practical implementation of the recombination approach. In this\npaper, this drawback is overcome by introducing two non-trivial improvements,\npaving the way for a future real-life application of recombination-based\nsystems. First, Nuida et al.'s collusion-resistant codes are used in\nsegment-wise fashion for the first time. Second, a novel version of the\ntraitor-tracing algorithm is proposed in the encrypted domain, also for the\nfirst time, making it possible to provide the buyers with security against\nframing. In addition, the proposed method avoids the use of public-key\ncryptography for the multimedia content and expensive cryptographic protocols,\nleading to excellent performance in terms of both computational and\ncommunication burdens. The paper also analyzes the security and privacy\nproperties of the proposed system both formally and informally, whereas the\ncollusion resistance and the performance of the method are shown by means of\nexperiments and simulations.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 21:50:49 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Meg\u00edas", "David", ""], ["Qureshi", "Amna", ""]]}, {"id": "1703.01534", "submitter": "Md Safiur Rahman Mahdi", "authors": "Mohammad Zahidul Hasan, Md Safiur Rahman Mahdi, Noman Mohammed", "title": "Secure Count Query on Encrypted Genomic Data", "comments": "19 pages, 7 figures, 3rd International Workshop on Genome Privacy and\n  Security (GenoPri'16)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capturing the vast amount of meaningful information encoded in the human\ngenome is a fascinating research problem. The outcome of these researches have\nsignificant influences in a number of health related fields --- personalized\nmedicine, paternity testing and disease susceptibility testing are a few to be\nnamed. To facilitate these types of large scale biomedical research projects,\nit oftentimes requires to share genomic and clinical data collected by\ndisparate organizations among themselves. In that case, it is of utmost\nimportance to ensure that sharing, managing and analyzing the data does not\nreveal the identity of the individuals who contribute their genomic samples.\nThe task of storage and computation on the shared data can be delegated to\nthird party cloud infrastructures, equipped with large storage and high\nperformance computation resources. Outsourcing these sensitive genomic data to\nthe third party cloud storage is associated with the challenges of the\npotential loss, theft or misuse of the data as the server administrator cannot\nbe completely trusted as well as there is no guarantee that the security of the\nserver will not be breached. In this paper, we provide a model for secure\nsharing and computation on genomic data in a semi-honest third party cloud\nserver. The security of the shared data is guaranteed through encryption while\nmaking the overall computation fast and scalable enough for real-life\nlarge-scale biomedical applications. We evaluated the efficiency of our\nproposed model on a database of Single-Nucleotide Polymorphism (SNP) sequences\nand experimental results demonstrate that a query of 50 SNPs in a database of\n50000 records, where each record contains 300 SNPs, takes approximately 6\nseconds.\n", "versions": [{"version": "v1", "created": "Sat, 4 Mar 2017 23:17:25 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Hasan", "Mohammad Zahidul", ""], ["Mahdi", "Md Safiur Rahman", ""], ["Mohammed", "Noman", ""]]}, {"id": "1703.01537", "submitter": "Soteris Demetriou", "authors": "Soteris Demetriou, Nan Zhang, Yeonjoon Lee, Xiaofeng Wang, Carl\n  Gunter, Xiaoyong Zhou, Michael Grace", "title": "Guardian of the HAN: Thwarting Mobile Attacks on Smart-Home Devices\n  Using OS-level Situation Awareness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new development of smart-home systems is to use mobile apps to control IoT\ndevices across a Home Area Network (HAN). Those systems tend to rely on the\nWi-Fi router to authenticate other devices; as verified in our study, IoT\nvendors tend to trust all devices connected to the HAN. This treatment exposes\nthem to the attack from malicious apps, particularly those running on\nauthorized phones, which the router does not have information to control, as\nconfirmed in our measurement study. Mitigating this threat cannot solely rely\non IoT manufacturers, which may need to change the hardware on the devices to\nsupport encryption, increasing the cost of the device, or software developers\nwho we need to trust to implement security correctly.\n  In this work, we present a new technique to control the communication between\nthe IoT devices and their apps in a unified, backward-compatible way. Our\napproach, called Hanguard, does not require any changes to the IoT devices\nthemselves, the IoT apps or the OS of the participating phones. Hanguard\nachieves a fine-grained, per-app protection through bridging the OS-level\nsituation awareness and the router-level per-flow control: each phone runs a\nnon-system userspace Monitor app to identify the party that attempts to access\nthe protected IoT device and inform the router through a control plane of its\naccess decision; the router enforces the decision on the data plane after\nverifying whether the phone should be allowed to talk to the device. Hanguard\nuses a role-based access control (RBAC) schema which leverages type enforcement\n(TE) and multi-category security (MCS) primitives to define highly flexible\naccess control rules. We implemented our design over both Android and iOS (>95%\nof mobile OS market share) and a popular router. Our study shows that Hanguard\nis both efficient and effective in practice.\n", "versions": [{"version": "v1", "created": "Sat, 4 Mar 2017 23:58:05 GMT"}, {"version": "v2", "created": "Tue, 7 Mar 2017 01:46:20 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Demetriou", "Soteris", ""], ["Zhang", "Nan", ""], ["Lee", "Yeonjoon", ""], ["Wang", "Xiaofeng", ""], ["Gunter", "Carl", ""], ["Zhou", "Xiaoyong", ""], ["Grace", "Michael", ""]]}, {"id": "1703.01820", "submitter": "Amna Qureshi", "authors": "Amna Qureshi, David Meg\\'ias, Helena Rif\\`a-Pous", "title": "PSUM:Peer-to-peer multimedia content distribution using\n  collusion-resistant fingerprinting", "comments": "38 Pages, Journal", "journal-ref": null, "doi": "10.1016/j.jnca.2016.03.007", "report-no": null, "categories": "cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of peer-to-peer (P2P) networks for multimedia distribution has spread\nout globally in recent years. The mass popularity is primarily driven by\ncost-effective distribution of content, also giving rise to piracy. An end user\n(buyer/peer) of a P2P content distribution system does not want to reveal\nhis/her identity during a transaction with a content owner (merchant), whereas\nthe merchant does not want the buyer to further distribute the content\nillegally. To date, different P2P distribution systems have been proposed that\nprovide copyright and privacy protection at a cost of high computational burden\nat the merchants and/or at the buyer's end and thus, making these systems\nimpractical. In this paper, we propose PSUM, a P2P content distribution system\nwhich allows efficient distribution of large-sized multimedia content while\npreserving the security and privacy of merchants and buyers. The security of\nPSUM is ensured by using an asymmetric fingerprinting protocol based on\ncollusion-resistant codes. In addition, PSUM enables buyers to obtain digital\ncontents anonymously, but this anonymity can be revoked as soon as he/she is\nfound guilty of copyright violation. The paper presents a thorough performance\nanalysis of PSUM, through different experiments and simulations, and also\nanalyzes several security compromising attacks and countermeasures.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 11:47:30 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Qureshi", "Amna", ""], ["Meg\u00edas", "David", ""], ["Rif\u00e0-Pous", "Helena", ""]]}, {"id": "1703.01863", "submitter": "Benjamin Smith", "authors": "Craig Costello, Benjamin Smith (LIX, GRACE)", "title": "Montgomery curves and their arithmetic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Three decades ago, Montgomery introduced a new elliptic curve model for use\nin Lenstra's ECM factorization algorithm. Since then, his curves and the\nalgorithms associated with them have become foundational in the implementation\nof elliptic curve cryptosystems. This article surveys the theory and\ncryptographic applications of Montgomery curves over non-binary finite fields,\nincluding Montgomery's x-only arithmetic and Ladder algorithm, x-only\nDiffie--Hellman, y-coordinate recovery, and 2-dimensional and Euclidean\ndifferential addition chains such as Montgomery's PRAC algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 13:30:11 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Costello", "Craig", "", "LIX, GRACE"], ["Smith", "Benjamin", "", "LIX, GRACE"]]}, {"id": "1703.01959", "submitter": "Fatma Al Maqbali", "authors": "Fatma Al Maqbali and Chris J Mitchell", "title": "AutoPass: An Automatic Password Generator", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text password has long been the dominant user authentication technique and is\nused by large numbers of Internet services. If they follow recommended\npractice, users are faced with the almost insuperable problem of generating and\nmanaging a large number of site-unique and strong (i.e. non-guessable)\npasswords. One way of addressing this problem is through the use of a password\ngenerator, i.e. a client-side scheme which generates (and regenerates)\nsite-specific strong passwords on demand, with the minimum of user input. This\npaper provides a detailed specification and analysis of AutoPass, a password\ngenerator scheme previously outlined as part of a general analysis of such\nschemes. AutoPass has been designed to address issues identified in previously\nproposed password generators, and incorporates novel techniques to address\nthese issues. Unlike almost all previously proposed schemes, AutoPass enables\nthe generation of passwords that meet important real-world requirements,\nincluding forced password changes, use of pre-specified passwords, and\ngeneration of passwords meeting site-specific requirements.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 16:36:29 GMT"}, {"version": "v2", "created": "Wed, 8 Mar 2017 14:24:19 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Maqbali", "Fatma Al", ""], ["Mitchell", "Chris J", ""]]}, {"id": "1703.02002", "submitter": "Md Mizanur Rahman", "authors": "Mahmudur Rahman, Mizanur Rahman, Bogdan Carbunar, Duen Horng Chau", "title": "FairPlay: Fraud and Malware Detection in Google Play", "comments": "Proceedings of the 2016 SIAM International Conference on Data Mining.\n  Society for Industrial and Applied Mathematics, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fraudulent behaviors in Google Android app market fuel search rank abuse and\nmalware proliferation. We present FairPlay, a novel system that uncovers both\nmalware and search rank fraud apps, by picking out trails that fraudsters leave\nbehind. To identify suspicious apps, FairPlay PCF algorithm correlates review\nactivities and uniquely combines detected review relations with linguistic and\nbehavioral signals gleaned from longitudinal Google Play app data. We\ncontribute a new longitudinal app dataset to the community, which consists of\nover 87K apps, 2.9M reviews, and 2.4M reviewers, collected over half a year.\nFairPlay achieves over 95% accuracy in classifying gold standard datasets of\nmalware, fraudulent and legitimate apps. We show that 75% of the identified\nmalware apps engage in search rank fraud. FairPlay discovers hundreds of\nfraudulent apps that currently evade Google Bouncer detection technology, and\nreveals a new type of attack campaign, where users are harassed into writing\npositive reviews, and install and review other apps.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 17:51:16 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Rahman", "Mahmudur", ""], ["Rahman", "Mizanur", ""], ["Carbunar", "Bogdan", ""], ["Chau", "Duen Horng", ""]]}, {"id": "1703.02014", "submitter": "Benjamin Fuller", "authors": "Benjamin Fuller, and Mayank Varia, and Arkady Yerukhimovich, and Emily\n  Shen, and Ariel Hamlin, and Vijay Gadepally, and Richard Shay, and John Darby\n  Mitchell, and Robert K. Cunningham", "title": "SoK: Cryptographically Protected Database Search", "comments": "20 pages, to appear to IEEE Security and Privacy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protected database search systems cryptographically isolate the roles of\nreading from, writing to, and administering the database. This separation\nlimits unnecessary administrator access and protects data in the case of system\nbreaches. Since protected search was introduced in 2000, the area has grown\nrapidly; systems are offered by academia, start-ups, and established companies.\n  However, there is no best protected search system or set of techniques.\nDesign of such systems is a balancing act between security, functionality,\nperformance, and usability. This challenge is made more difficult by ongoing\ndatabase specialization, as some users will want the functionality of SQL,\nNoSQL, or NewSQL databases. This database evolution will continue, and the\nprotected search community should be able to quickly provide functionality\nconsistent with newly invented databases.\n  At the same time, the community must accurately and clearly characterize the\ntradeoffs between different approaches. To address these challenges, we provide\nthe following contributions:\n  1) An identification of the important primitive operations across database\nparadigms. We find there are a small number of base operations that can be used\nand combined to support a large number of database paradigms.\n  2) An evaluation of the current state of protected search systems in\nimplementing these base operations. This evaluation describes the main\napproaches and tradeoffs for each base operation. Furthermore, it puts\nprotected search in the context of unprotected search, identifying key gaps in\nfunctionality.\n  3) An analysis of attacks against protected search for different base\nqueries.\n  4) A roadmap and tools for transforming a protected search system into a\nprotected database, including an open-source performance evaluation platform\nand initial user opinions of protected search.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 18:29:15 GMT"}, {"version": "v2", "created": "Fri, 2 Jun 2017 17:37:11 GMT"}], "update_date": "2017-06-05", "authors_parsed": [["Fuller", "Benjamin", ""], ["Varia", "Mayank", ""], ["Yerukhimovich", "Arkady", ""], ["Shen", "Emily", ""], ["Hamlin", "Ariel", ""], ["Gadepally", "Vijay", ""], ["Shay", "Richard", ""], ["Mitchell", "John Darby", ""], ["Cunningham", "Robert K.", ""]]}, {"id": "1703.02090", "submitter": "Primal Wijesekera", "authors": "Primal Wijesekera, Arjun Baokar, Lynn Tsai, Joel Reardon, Serge\n  Egelman, David Wagner, and Konstantin Beznosov", "title": "The Feasibility of Dynamically Granted Permissions: Aligning Mobile\n  Privacy with User Preferences", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current smartphone operating systems regulate application permissions by\nprompting users on an ask-on-first-use basis. Prior research has shown that\nthis method is ineffective because it fails to account for context: the\ncircumstances under which an application first requests access to data may be\nvastly different than the circumstances under which it subsequently requests\naccess. We performed a longitudinal 131-person field study to analyze the\ncontextuality behind user privacy decisions to regulate access to sensitive\nresources. We built a classifier to make privacy decisions on the user's behalf\nby detecting when context has changed and, when necessary, inferring privacy\npreferences based on the user's past decisions and behavior. Our goal is to\nautomatically grant appropriate resource requests without further user\nintervention, deny inappropriate requests, and only prompt the user when the\nsystem is uncertain of the user's preferences. We show that our approach can\naccurately predict users' privacy decisions 96.8% of the time, which is a\nfour-fold reduction in error rate compared to current systems.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 20:00:45 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Wijesekera", "Primal", ""], ["Baokar", "Arjun", ""], ["Tsai", "Lynn", ""], ["Reardon", "Joel", ""], ["Egelman", "Serge", ""], ["Wagner", "David", ""], ["Beznosov", "Konstantin", ""]]}, {"id": "1703.02162", "submitter": "A. S. M. Kayes", "authors": "A. S. M. Kayes, Jun Han, Wenny Rahayu, Md. Saiful Islam and Alan\n  Colman", "title": "A Policy Model and Framework for Context-Aware Access Control to\n  Information Resources", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In today's dynamic ICT environments, the ability to control users' access to\nresources becomes ever important. On the one hand, it should adapt to the\nusers' changing needs; on the other hand, it should not be compromised.\nTherefore, it is essential to have a flexible access control model,\nincorporating dynamically changing context information. Towards this end, this\npaper introduces a policy framework for context-aware access control (CAAC)\napplications that extends the role-based access control model with both dynamic\nassociations of user-role and role-permission capabilities. We first present a\nformal model of CAAC policies for our framework. Using this model, we then\nintroduce an ontology-based approach and a software prototype for modelling and\nenforcing CAAC policies. In addition, we evaluate our policy ontology model and\nframework by considering (i) the completeness of the ontology concepts,\nspecifying different context-aware user-role and role-permission assignment\npolicies from the healthcare scenarios; (ii) the correctness and consistency of\nthe ontology semantics, assessing the core and domain-specific ontologies\nthrough the healthcare case study; and (iii) the performance of the framework\nby means of response time. The evaluation results demonstrate the feasibility\nof our framework and quantify the performance overhead of achieving\ncontext-aware access control to information resources.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 00:49:44 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Kayes", "A. S. M.", ""], ["Han", "Jun", ""], ["Rahayu", "Wenny", ""], ["Islam", "Md. Saiful", ""], ["Colman", "Alan", ""]]}, {"id": "1703.02200", "submitter": "Lu Yu", "authors": "Xingsi Zhong and Yu Fu and Lu Yu and Richard Brooks", "title": "Stealthy Malware Traffic - Not as Innocent as It Looks", "comments": "9 figures, 2 tables", "journal-ref": "Zhong, Xingsi, Yu Fu, Lu Yu, Richard Brooks, and G. Kumar\n  Venayagamoorthy. \"Stealthy malware traffic-Not as innocent as it looks.\" In\n  Malicious and Unwanted Software (MALWARE), 2015 10th International Conference\n  on, pp. 110-116. IEEE, 2015", "doi": "10.1109/MALWARE.2015.7413691", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware is constantly evolving. Although existing countermeasures have\nsuccess in malware detection, corresponding counter-countermeasures are always\nemerging. In this study, a counter-countermeasure that avoids network-based\ndetection approaches by camouflaging malicious traffic as an innocuous protocol\nis presented. The approach includes two steps: Traffic format transformation\nand side-channel massage (SCM). Format transforming encryption (FTE) translates\nprotocol syntax to mimic another innocuous protocol while SCM obscures traffic\nside-channels. The proposed approach is illustrated by transforming Zeus botnet\n(Zbot) Command and Control (C&C) traffic into smart grid Phasor Measurement\nUnit (PMU) data. The experimental results show that the transformed traffic is\nidentified by Wireshark as synchrophasor protocol, and the transformed protocol\nfools current side-channel attacks. Moreover, it is shown that a real smart\ngrid Phasor Data Concentrator (PDC) accepts the false PMU data.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 03:30:26 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Zhong", "Xingsi", ""], ["Fu", "Yu", ""], ["Yu", "Lu", ""], ["Brooks", "Richard", ""]]}, {"id": "1703.02201", "submitter": "Lu Yu", "authors": "Yu Fu and Zhe Jia and Lu Yu and Xingsi Zhong and Richard Brooks", "title": "A Covert Data Transport Protocol", "comments": "8 pages, 10 figures, conference", "journal-ref": null, "doi": "10.1109/MALWARE.2016.7888734", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both enterprise and national firewalls filter network connections. For data\nforensics and botnet removal applications, it is important to establish the\ninformation source. In this paper, we describe a data transport layer which\nallows a client to transfer encrypted data that provides no discernible\ninformation regarding the data source. We use a domain generation algorithm\n(DGA) to encode AES encrypted data into domain names that current tools are\nunable to reliably differentiate from valid domain names. The domain names are\nregistered using (free) dynamic DNS services. The data transmission format is\nnot vulnerable to Deep Packet Inspection (DPI).\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 03:30:46 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Fu", "Yu", ""], ["Jia", "Zhe", ""], ["Yu", "Lu", ""], ["Zhong", "Xingsi", ""], ["Brooks", "Richard", ""]]}, {"id": "1703.02209", "submitter": "Saba Eskandarian", "authors": "Saba Eskandarian, Eran Messeri, Joseph Bonneau, Dan Boneh", "title": "Certificate Transparency with Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Certificate transparency (CT) is an elegant mechanism designed to detect when\na certificate authority (CA) has issued a certificate incorrectly. Many CAs now\nsupport CT and it is being actively deployed in browsers. However, a number of\nprivacy-related challenges remain. In this paper we propose practical solutions\nto two issues. First, we develop a mechanism that enables web browsers to audit\na CT log without violating user privacy. Second, we extend CT to support\nnon-public subdomains.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 04:31:39 GMT"}, {"version": "v2", "created": "Tue, 4 Apr 2017 22:53:42 GMT"}, {"version": "v3", "created": "Wed, 14 Jun 2017 13:06:34 GMT"}, {"version": "v4", "created": "Mon, 7 Aug 2017 16:05:26 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Eskandarian", "Saba", ""], ["Messeri", "Eran", ""], ["Bonneau", "Joseph", ""], ["Boneh", "Dan", ""]]}, {"id": "1703.02244", "submitter": "Ethan Rudd", "authors": "Steve Cruz, Cora Coleman, Ethan M. Rudd, and Terrance E. Boult", "title": "Open Set Intrusion Recognition for Fine-Grained Attack Categorization", "comments": "Pre-print of camera-ready version to appear at the IEEE Homeland\n  Security Technologies (HST) 2017 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Confidently distinguishing a malicious intrusion over a network is an\nimportant challenge. Most intrusion detection system evaluations have been\nperformed in a closed set protocol in which only classes seen during training\nare considered during classification. Thus far, there has been no realistic\napplication in which novel types of behaviors unseen at training -- unknown\nclasses as it were -- must be recognized for manual categorization. This paper\ncomparatively evaluates malware classification using both closed set and open\nset protocols for intrusion recognition on the KDDCUP'99 dataset. In contrast\nto much of the previous work, we employ a fine-grained recognition protocol, in\nwhich the dataset is loosely open set -- i.e., recognizing individual intrusion\ntypes -- e.g., \"sendmail\", \"snmp guess\", ..., etc., rather than more general\nattack categories (e.g., \"DoS\",\"Probe\",\"R2L\",\"U2R\",\"Normal\"). We also employ\ntwo different classifier types -- Gaussian RBF kernel SVMs, which are not\ntheoretically guaranteed to bound open space risk, and W-SVMs, which are\ntheoretically guaranteed to bound open space risk. We find that the W-SVM\noffers superior performance under the open set regime, particularly as the cost\nof misclassifying unknown classes at query time (i.e., classes not present in\nthe training set) increases. Results of performance tradeoff with respect to\ncost of unknown as well as discussion of the ramifications of these findings in\nan operational setting are presented.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 07:15:43 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Cruz", "Steve", ""], ["Coleman", "Cora", ""], ["Rudd", "Ethan M.", ""], ["Boult", "Terrance E.", ""]]}, {"id": "1703.02248", "submitter": "Ethan Rudd", "authors": "Khudran Alzhrani, Ethan M. Rudd, C. Edward Chow, and Terrance E. Boult", "title": "Automated U.S Diplomatic Cables Security Classification: Topic Model\n  Pruning vs. Classification Based on Clusters", "comments": "Pre-print of camera-ready copy accepted to the 2017 IEEE Homeland\n  Security Technologies (HST) conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The U.S Government has been the target for cyber-attacks from all over the\nworld. Just recently, former President Obama accused the Russian government of\nthe leaking emails to Wikileaks and declared that the U.S. might be forced to\nrespond. While Russia denied involvement, it is clear that the U.S. has to take\nsome defensive measures to protect its data infrastructure. Insider threats\nhave been the cause of other sensitive information leaks too, including the\ninfamous Edward Snowden incident. Most of the recent leaks were in the form of\ntext. Due to the nature of text data, security classifications are assigned\nmanually. In an adversarial environment, insiders can leak texts through\nE-mail, printers, or any untrusted channels. The optimal defense is to\nautomatically detect the unstructured text security class and enforce the\nappropriate protection mechanism without degrading services or daily tasks.\nUnfortunately, existing Data Leak Prevention (DLP) systems are not well suited\nfor detecting unstructured texts. In this paper, we compare two recent\napproaches in the literature for text security classification, evaluating them\non actual sensitive text data from the WikiLeaks dataset.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 07:29:56 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Alzhrani", "Khudran", ""], ["Rudd", "Ethan M.", ""], ["Chow", "C. Edward", ""], ["Boult", "Terrance E.", ""]]}, {"id": "1703.02382", "submitter": "Areg Karapetyan", "authors": "Areg Karapetyan, Syafiq Kamarul Azman, and Zeyar Aung", "title": "Assessing the Privacy Cost in Centralized Event-Based Demand Response\n  for Microgrids", "comments": null, "journal-ref": null, "doi": "10.1109/Trustcom/BigDataSE/ICESS.2017.276", "report-no": null, "categories": "cs.SY cs.CR math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demand response (DR) programs have emerged as a potential key enabling\ningredient in the context of smart grid (SG). Nevertheless, the rising concerns\nover privacy issues raised by customers subscribed to these programs constitute\na major threat towards their effective deployment and utilization. This has\ndriven extensive research to resolve the hindrance confronted, resulting in a\nnumber of methods being proposed for preserving customers' privacy. While these\nmethods provide stringent privacy guarantees, only limited attention has been\npaid to their computational efficiency and performance quality. Under the\nparadigm of differential privacy, this paper initiates a systematic empirical\nstudy on quantifying the trade-off between privacy and optimality in\ncentralized DR systems for maximizing cumulative customer utility. Aiming to\nelucidate the factors governing this trade-off, we analyze the cost of privacy\nin terms of the effect incurred on the objective value of the DR optimization\nproblem when applying the employed privacy-preserving strategy based on Laplace\nmechanism. The theoretical results derived from the analysis are complemented\nwith empirical findings, corroborated extensively by simulations on a 4-bus MG\nsystem with up to thousands of customers. By evaluating the impact of privacy,\nthis pilot study serves DR practitioners when considering the social and\neconomic implications of deploying privacy-preserving DR programs in practice.\nMoreover, it stimulates further research on exploring more efficient approaches\nwith bounded performance guarantees for optimizing energy procurement of MGs\nwithout infringing the privacy of customers on demand side.\n", "versions": [{"version": "v1", "created": "Sat, 4 Mar 2017 02:03:05 GMT"}, {"version": "v2", "created": "Tue, 28 Mar 2017 23:04:12 GMT"}, {"version": "v3", "created": "Sun, 18 Mar 2018 16:34:17 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Karapetyan", "Areg", ""], ["Azman", "Syafiq Kamarul", ""], ["Aung", "Zeyar", ""]]}, {"id": "1703.02451", "submitter": "Ndoundam Rene", "authors": "Rene Ndoundam, Stephane Gael R. Ekodeck", "title": "A Novel Approach of Pseudorandomly sorted list-based Steganography", "comments": "35 pages, 1 figure, 15 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new model of steganography based on a list of pseudo-randomly\nsorted sequences of characters. Given a list $L$ of $m$ columns containing $n$\ndistinct strings each, with low or no semantic relationship between columns\ntaken two by two, and a secret message $s \\in \\{0,1\\}^*$, our model embeds $s$\nin $L$ block by block, by generating, for each column of $L$, a permutation\nnumber and by reordering strings contained in it according to that number.\nWhere, letting $l$ be average bit length of a string, the embedding capacity is\ngiven by $[(m-1)*log_2(n!-1)/n*l]$. We've shown that optimal efficiency of the\nmethod can be obtained with the condition that $(n >> l)$. The results which\nhas been obtained by experiments, show that our model performs a better hiding\nprocess than some of the important existing methods, in terms of hiding\ncapacity.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 16:07:38 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Ndoundam", "Rene", ""], ["Ekodeck", "Stephane Gael R.", ""]]}, {"id": "1703.02577", "submitter": "Md Momin Al Aziz", "authors": "Md Nazmus Sadat, Md Momin Al Aziz, Noman Mohammed, Feng Chen, Shuang\n  Wang, Xiaoqian Jiang", "title": "SAFETY: Secure gwAs in Federated Environment Through a hYbrid solution\n  with Intel SGX and Homomorphic Encryption", "comments": "Hybrid Cryptosystem using SGX and Homomorphic Encryption", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies demonstrate that effective healthcare can benefit from using\nthe human genomic information. For instance, analysis of tumor genomes has\nrevealed 140 genes whose mutations contribute to cancer. As a result, many\ninstitutions are using statistical analysis of genomic data, which are mostly\nbased on genome-wide association studies (GWAS). GWAS analyze genome sequence\nvariations in order to identify genetic risk factors for diseases. These\nstudies often require pooling data from different sources together in order to\nunravel statistical patterns or relationships between genetic variants and\ndiseases. In this case, the primary challenge is to fulfill one major\nobjective: accessing multiple genomic data repositories for collaborative\nresearch in a privacy-preserving manner. Due to the sensitivity and privacy\nconcerns regarding the genomic data, multi-jurisdictional laws and policies of\ncross-border genomic data sharing are enforced among different regions of the\nworld. In this article, we present SAFETY, a hybrid framework, which can\nsecurely perform GWAS on federated genomic datasets using homomorphic\nencryption and recently introduced secure hardware component of Intel Software\nGuard Extensions (Intel SGX) to ensure high efficiency and privacy at the same\ntime. Different experimental settings show the efficacy and applicability of\nsuch hybrid framework in secure conduction of GWAS. To the best of our\nknowledge, this hybrid use of homomorphic encryption along with Intel SGX is\nnot proposed or experimented to this date. Our proposed framework, SAFETY is up\nto 4.82 times faster than the best existing secure computation technique.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 20:21:53 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Sadat", "Md Nazmus", ""], ["Aziz", "Md Momin Al", ""], ["Mohammed", "Noman", ""], ["Chen", "Feng", ""], ["Wang", "Shuang", ""], ["Jiang", "Xiaoqian", ""]]}, {"id": "1703.02688", "submitter": "Rattanavipanon Norrathep", "authors": "Karim ElDefrawy, Norrathep Rattanavipanon, Gene Tsudik", "title": "HYDRA: HYbrid Design for Remote Attestation (Using a Formally Verified\n  Microkernel)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remote Attestation (RA) allows a trusted entity (verifier) to securely\nmeasure internal state of a remote untrusted hardware platform (prover). RA can\nbe used to establish a static or dynamic root of trust in embedded and\ncyber-physical systems. It can also be used as a building block for other\nsecurity services and primitives, such as software updates and patches,\nverifiable deletion and memory resetting. There are three major classes of RA\ndesigns: hardware-based, software-based, and hybrid, each with its own set of\nbenefits and drawbacks. This paper presents the first hybrid RA design, called\nHYDRA, that builds upon formally verified software components that ensure\nmemory isolation and protection, as well as enforce access control to memory\nand other resources. HYDRA obtains these properties by using the formally\nverified seL4 microkernel. (Until now, this was only attainable with purely\nhardware-based designs.) Using seL4 requires fewer hardware modifications to\nthe underlying microprocessor. Building upon a formally verified software\ncomponent increases confidence in security of the overall design of HYDRA and\nits implementation. We instantiate HYDRA on two commodity hardware platforms\nand assess the performance and overhead of performing RA on such platforms via\nexperimentation; we show that HYDRA can attest 10MB of memory in less than\n500msec when using a Speck-based message authentication code (MAC) to compute a\ncryptographic checksum over the memory to be attested.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 03:53:05 GMT"}, {"version": "v2", "created": "Tue, 14 Mar 2017 19:15:39 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["ElDefrawy", "Karim", ""], ["Rattanavipanon", "Norrathep", ""], ["Tsudik", "Gene", ""]]}, {"id": "1703.02698", "submitter": "Dean Sullivan", "authors": "Dean Sullivan, Orlando Arias, David Gens, Lucas Davi, Ahmad-Reza\n  Sadeghi, Yier Jin", "title": "Execution Integrity with In-Place Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instruction set randomization (ISR) was initially proposed with the main goal\nof countering code-injection attacks. However, ISR seems to have lost its\nappeal since code-injection attacks became less attractive because protection\nmechanisms such as data execution prevention (DEP) as well as code-reuse\nattacks became more prevalent.\n  In this paper, we show that ISR can be extended to also protect against\ncode-reuse attacks while at the same time offering security guarantees similar\nto those of software diversity, control-flow integrity, and information hiding.\nWe present Scylla, a scheme that deploys a new technique for in-place code\nencryption to hide the code layout of a randomized binary, and restricts the\ncontrol flow to a benign execution path. This allows us to i) implicitly\nrestrict control-flow targets to basic block entries without requiring the\nextraction of a control-flow graph, ii) achieve execution integrity within\nlegitimate basic blocks, and iii) hide the underlying code layout under\nmalicious read access to the program. Our analysis demonstrates that Scylla is\ncapable of preventing state-of-the-art attacks such as just-in-time\nreturn-oriented programming (JIT-ROP) and crash-resistant oriented programming\n(CROP). We extensively evaluate our prototype implementation of Scylla and show\nfeasible performance overhead. We also provide details on how this overhead can\nbe significantly reduced with dedicated hardware support.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 04:55:35 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Sullivan", "Dean", ""], ["Arias", "Orlando", ""], ["Gens", "David", ""], ["Davi", "Lucas", ""], ["Sadeghi", "Ahmad-Reza", ""], ["Jin", "Yier", ""]]}, {"id": "1703.02868", "submitter": "Tomas Pevny", "authors": "Tomas Pevny and Petr Somol", "title": "Discriminative models for multi-instance problems with tree-structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling network traffic is gaining importance in order to counter modern\nthreats of ever increasing sophistication. It is though surprisingly difficult\nand costly to construct reliable classifiers on top of telemetry data due to\nthe variety and complexity of signals that no human can manage to interpret in\nfull. Obtaining training data with sufficiently large and variable body of\nlabels can thus be seen as prohibitive problem. The goal of this work is to\ndetect infected computers by observing their HTTP(S) traffic collected from\nnetwork sensors, which are typically proxy servers or network firewalls, while\nrelying on only minimal human input in model training phase. We propose a\ndiscriminative model that makes decisions based on all computer's traffic\nobserved during predefined time window (5 minutes in our case). The model is\ntrained on collected traffic samples over equally sized time window per large\nnumber of computers, where the only labels needed are human verdicts about the\ncomputer as a whole (presumed infected vs. presumed clean). As part of training\nthe model itself recognizes discriminative patterns in traffic targeted to\nindividual servers and constructs the final high-level classifier on top of\nthem. We show the classifier to perform with very high precision, while the\nlearned traffic patterns can be interpreted as Indicators of Compromise. In the\nfollowing we implement the discriminative model as a neural network with\nspecial structure reflecting two stacked multi-instance problems. The main\nadvantages of the proposed configuration include not only improved accuracy and\nability to learn from gross labels, but also automatic learning of server types\n(together with their detectors) which are typically visited by infected\ncomputers.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 06:53:34 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Pevny", "Tomas", ""], ["Somol", "Petr", ""]]}, {"id": "1703.02874", "submitter": "Travis Mayberry", "authors": "Jeremy Martin, Travis Mayberry, Collin Donahue, Lucas Foppe, Lamont\n  Brown, Chadwick Riggins, Erik C. Rye, Dane Brown", "title": "A Study of MAC Address Randomization in Mobile Devices and When it Fails", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MAC address randomization is a privacy technique whereby mobile devices\nrotate through random hardware addresses in order to prevent observers from\nsingling out their traffic or physical location from other nearby devices.\nAdoption of this technology, however, has been sporadic and varied across\ndevice manufacturers. In this paper, we present the first wide-scale study of\nMAC address randomization in the wild, including a detailed breakdown of\ndifferent randomization techniques by operating system, manufacturer, and model\nof device.\n  We then identify multiple flaws in these implementations which can be\nexploited to defeat randomization as performed by existing devices. First, we\nshow that devices commonly make improper use of randomization by sending\nwireless frames with the true, global address when they should be using a\nrandomized address. We move on to extend the passive identification techniques\nof Vanhoef et al. to effectively defeat randomization in ~96% of Android\nphones. Finally, we show a method that can be used to track 100% of devices\nusing randomization, regardless of manufacturer, by exploiting a previously\nunknown flaw in the way existing wireless chipsets handle low-level control\nframes.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 15:32:46 GMT"}, {"version": "v2", "created": "Fri, 31 Mar 2017 14:38:09 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Martin", "Jeremy", ""], ["Mayberry", "Travis", ""], ["Donahue", "Collin", ""], ["Foppe", "Lucas", ""], ["Brown", "Lamont", ""], ["Riggins", "Chadwick", ""], ["Rye", "Erik C.", ""], ["Brown", "Dane", ""]]}, {"id": "1703.03262", "submitter": "Ching-Hua Yu", "authors": "Ching-Hua Yu", "title": "Does Nash Envy Immunity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most popular stability notion in games should be Nash equilibrium under\nthe rationality of players who maximize their own payoff individually. In\ncontrast, in many scenarios, players can be (partly) irrational with some\nunpredictable factors. Hence a strategy profile can be more robust if it is\nresilient against certain irrational behaviors. In this paper, we propose a\nstability notion that is resilient against envy. A strategy profile is said to\nbe envy-proof if each player cannot gain a competitive edge with respect to the\nchange in utility over the other players by deviation. Together with Nash\nequilibrium and another stability notion called immunity, we show how these\nseparate notions are related to each other, whether they exist in games, and\nwhether and when a strategy profile satisfying these notions can be efficiently\nfound. We answer these questions by starting with the general two player game\nand extend the discussion for the approximate stability and for the\ncorresponding fault-tolerance notions in multi-player games.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 13:45:45 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Yu", "Ching-Hua", ""]]}, {"id": "1703.03306", "submitter": "Alexander Kott", "authors": "Mona Lange, Alexander Kott, Noam Ben-Asher, Wim Mees, Nazife Baykal,\n  Cristian-Mihai Vidu, Matteo Merialdo, Marek Malowidzki, Bhopinder Madahar", "title": "Recommendations for Model-Driven Paradigms for Integrated Approaches to\n  Cyber Defense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The North Atlantic Treaty Organization (NATO) Exploratory Team meeting,\n\"Model-Driven Paradigms for Integrated Approaches to Cyber Defense,\" was\norganized by the NATO Science and Technology Organization's (STO) Information\nSystems and Technology (IST) panel and conducted its meetings and electronic\nexchanges during 2016. This report describes the proceedings and outcomes of\nthe team's efforts.\n  Many of the defensive activities in the fields of cyber warfare and\ninformation assurance rely on essentially ad hoc techniques. The cyber\ncommunity recognizes that comprehensive, systematic, principle-based modeling\nand simulation are more likely to produce long-term, lasting, reusable\napproaches to defensive cyber operations.\n  A model-driven paradigm is predicated on creation and validation of\nmechanisms of modeling the organization whose mission is subject to assessment,\nthe mission (or missions) itself, and the cyber-vulnerable systems that support\nthe mission. This by any definition is a complex socio-technical system (of\nsystems), and the level of detail of this class of problems ranges from the\nlevel of host and network events to the systems' functions up to the function\nof the enterprise. Solving this class of problems is of medium to high\ndifficulty and can draw in part on advances in Systems Engineering (SE). Such\nmodel-based approaches and analysis could be used to explore multiple\nalternative mitigation and work-around strategies and to select the optimal\ncourse of mitigating actions. Furthermore, the model-driven paradigm applied to\ncyber operations is likely to benefit traditional disciplines of cyber defense\nsuch as security, vulnerability analysis, intrusion prevention, intrusion\ndetection, analysis, forensics, attribution, and recovery.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 15:48:45 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Lange", "Mona", ""], ["Kott", "Alexander", ""], ["Ben-Asher", "Noam", ""], ["Mees", "Wim", ""], ["Baykal", "Nazife", ""], ["Vidu", "Cristian-Mihai", ""], ["Merialdo", "Matteo", ""], ["Malowidzki", "Marek", ""], ["Madahar", "Bhopinder", ""]]}, {"id": "1703.03378", "submitter": "Wei-Han Lee", "authors": "Wei-Han Lee, Ruby Lee", "title": "Multi-sensor authentication to improve smartphone security", "comments": "Published in International Conference on Information Systems Security\n  and Privacy (ICISSP), 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread use of smartphones gives rise to new security and privacy\nconcerns. Smartphone thefts account for the largest percentage of thefts in\nrecent crime statistics. Using a victim's smartphone, the attacker can launch\nimpersonation attacks, which threaten the security of the victim and other\nusers in the network. Our threat model includes the attacker taking over the\nphone after the user has logged on with his password or pin. Our goal is to\ndesign a mechanism for smartphones to better authenticate the current user,\ncontinuously and implicitly, and raise alerts when necessary. In this paper, we\npropose a multi-sensors-based system to achieve continuous and implicit\nauthentication for smartphone users. The system continuously learns the owner's\nbehavior patterns and environment characteristics, and then authenticates the\ncurrent user without interrupting user-smartphone interactions. Our method can\nadaptively update a user's model considering the temporal change of user's\npatterns. Experimental results show that our method is efficient, requiring\nless than 10 seconds to train the model and 20 seconds to detect the abnormal\nuser, while achieving high accuracy (more than 90%). Also the combination of\nmore sensors provide better accuracy. Furthermore, our method enables adjusting\nthe security level by changing the sampling rate.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 18:27:48 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Lee", "Wei-Han", ""], ["Lee", "Ruby", ""]]}, {"id": "1703.03471", "submitter": "Pol Mac Aonghusa", "authors": "Pol Mac Aonghusa and Douglas J. Leith", "title": "Plausible Deniability in Web Search -- From Detection to Assessment", "comments": "14 pages, 1 figure. arXiv admin note: substantial text overlap with\n  arXiv:1609.07922", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We ask how to defend user ability to plausibly deny their interest in topics\ndeemed sensitive in the face of search engine learning. We develop a practical\nand scalable tool called \\PDE{} allowing a user to detect and assess threats to\nplausible deniability. We show that threats to plausible deniability of\ninterest are readily detectable for all topics tested in an extensive testing\nprogram. Of particular concern is observation of threats to deniability of\ninterest in topics related to health and sexual preferences. We show this\nremains the case when attempting to disrupt search engine learning through\nnoise query injection and click obfuscation. We design a defence technique\nexploiting uninteresting, proxy topics and show that it provides a more\neffective defence of plausible deniability in our experiments.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 21:27:41 GMT"}, {"version": "v2", "created": "Fri, 23 Jun 2017 20:03:23 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Mac Aonghusa", "Pol", ""], ["Leith", "Douglas J.", ""]]}, {"id": "1703.03473", "submitter": "Osman Bi\\c{c}er", "authors": "Osman Bi\\c{c}er", "title": "Efficiency Optimizations on Yao's Garbled Circuits and Their Practical\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advance of cloud computing and big data technologies brings out major\nchanges in the ways that people make use of information systems. While those\ntechnologies extremely ease our lives, they impose the danger of compromising\nprivacy and security of data due to performing the computation on an untrusted\nremote server. Moreover, there are also many other real-world scenarios\nrequiring two or more (possibly distrustful) parties to securely compute a\nfunction without leaking their respective inputs to each other. In this\nrespect, various secure computation mechanisms have been proposed in order to\nprotect users' data privacy. Yao's garbled circuit protocol is one of the most\npowerful solutions for this problem. In this thesis, we first describe the\nYao's protocol in detail, and include the complete list of optimizations over\nthe Yao's protocol. We also compare their advantages in terms of communication\nand computation complexities, and analyse their compatibility with each other.\nWe also look into generic Yao implementations (including garbled RAM) to\ndemonstrate the use of this powerful tool in practice. We compare those generic\nimplementations in terms of their use of garbled circuit optimizations. We also\ncover the specific real-world applications for further illustration. Moreover,\nin some scenarios, the functionality itself may also need to be kept private\nwhich leads to an ideal solution of secure computation problem. In this\ndirection, we finally cover the problem of Private Function Evaluation, in\nparticular for the 2-party case where garbled circuits have an important role.\nWe finally analyse the generic mechanism of Mohassel et al. and contribute to\nit by proposing a new technique for the computation of the number of possible\ncircuit mappings.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 21:50:03 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Bi\u00e7er", "Osman", ""]]}, {"id": "1703.03523", "submitter": "Wei-Han Lee", "authors": "Wei-Han Lee, Ruby Lee", "title": "Implicit Sensor-based Authentication of Smartphone Users with Smartwatch", "comments": "Published in Hardware and Architectural Support for Security and\n  Privacy (HASP), 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphones are now frequently used by end-users as the portals to\ncloud-based services, and smartphones are easily stolen or co-opted by an\nattacker. Beyond the initial log-in mechanism, it is highly desirable to\nre-authenticate end-users who are continuing to access security-critical\nservices and data, whether in the cloud or in the smartphone. But attackers who\nhave gained access to a logged-in smartphone have no incentive to\nre-authenticate, so this must be done in an automatic, non-bypassable way.\nHence, this paper proposes a novel authentication system, iAuth, for implicit,\ncontinuous authentication of the end-user based on his or her behavioral\ncharacteristics, by leveraging the sensors already ubiquitously built into\nsmartphones. We design a system that gives accurate authentication using\nmachine learning and sensor data from multiple mobile devices. Our system can\nachieve 92.1% authentication accuracy with negligible system overhead and less\nthan 2% battery consumption.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 02:47:05 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Lee", "Wei-Han", ""], ["Lee", "Ruby", ""]]}, {"id": "1703.03652", "submitter": "Andrew Paverd", "authors": "Philipp Mundhenk, Andrew Paverd, Artur Mrowca, Sebastian Steinhorst,\n  Martin Lukasiewycz, Suhaib A. Fahmy, Samarjit Chakraborty", "title": "Security in Automotive Networks: Lightweight Authentication and\n  Authorization", "comments": "Authors' preprint of an article to appear in ACM Transactions on\n  Design Automation of Electronic Systems (ACM TODAES) 2017", "journal-ref": null, "doi": "10.1145/2960407", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing amount of interconnections between vehicles, the attack\nsurface of internal vehicle networks is rising steeply. Although these networks\nare shielded against external attacks, they often do not have any internal\nsecurity to protect against malicious components or adversaries who breach the\nnetwork perimeter. To secure the in-vehicle network, all communicating\ncomponents must be authenticated, and only authorized components should be\nallowed to send and receive messages. This is achieved using an authentication\nframework. Cryptography is widely used to authenticate communicating parties\nand provide secure communication channels (e.g., Internet communication).\nHowever, the real-time performance requirements of in-vehicle networks restrict\nthe types of cryptographic algorithms and protocols that may be used. In\nparticular, asymmetric cryptography is computationally infeasible during\nvehicle operation.\n  In this work, we address the challenges of designing authentication protocols\nfor automotive systems. We present Lightweight Authentication for Secure\nAutomotive Networks (LASAN), a full lifecycle authentication approach. We\ndescribe the core LASAN protocols and show how they protect the internal\nvehicle network while complying with the real-time constraints and low\ncomputational resources of this domain. Unlike previous work, we also explain\nhow this framework can be integrated into all aspects of the automotive\nlifecycle, including manufacturing, vehicle maintenance, and software updates.\nWe evaluate LASAN in two different ways: First, we analyze the security\nproperties of the protocols using established protocol verification techniques\nbased on formal methods. Second, we evaluate the timing requirements of LASAN\nand compare these to other frameworks using a new highly modular discrete event\nsimulator for in-vehicle networks, which we have developed for this evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 12:25:14 GMT"}, {"version": "v2", "created": "Wed, 15 Mar 2017 09:02:40 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Mundhenk", "Philipp", ""], ["Paverd", "Andrew", ""], ["Mrowca", "Artur", ""], ["Steinhorst", "Sebastian", ""], ["Lukasiewycz", "Martin", ""], ["Fahmy", "Suhaib A.", ""], ["Chakraborty", "Samarjit", ""]]}, {"id": "1703.03754", "submitter": "Petros Wallden Dr", "authors": "Elham Kashefi, Luka Music and Petros Wallden", "title": "The Quantum Cut-and-Choose Technique and Quantum Two-Party Computation", "comments": "25 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application and analysis of the Cut-and-Choose technique in protocols\nsecure against quantum adversaries is not a straightforward transposition of\nthe classical case, among other reasons due to the difficulty to use rewinding\nin the quantum realm. We introduce a Quantum Computation Cut-and-Choose (QC-CC)\ntechnique which is a generalisation of the classical Cut-and-Choose in order to\nbuild quantum protocols secure against quantum covert adversaries. Such\nadversaries can deviate arbitrarily provided that their deviation is not\ndetected. As an application of the QC-CC we give a protocol for securely\nperforming two-party quantum computation with classical input/output. As basis\nwe use secure delegated quantum computing (Broadbent et al 2009), and in\nparticular the garbled quantum computation of (Kashefi et al 2016) that is\nsecure against only a weak specious adversaries, defined in (Dupuis et al\n2010). A unique property of these protocols is the separation between classical\nand quantum communications and the asymmetry between client and server, which\nenables us to sidestep the quantum rewinding issues. This opens the prospect of\nusing the QC-CC to other quantum protocols with this separation. In our proof\nof security we adapt and use (at different parts) two quantum rewinding\ntechniques, namely Watrous' oblivious q-rewinding (Watrous 2009) and Unruh's\nspecial q-rewinding (Unruh 2012). Our protocol achieves the same functionality\nas in previous works (e.g. Dupuis et al 2012), however using the QC-CC\ntechnique on the protocol from (Kashefi et al 2016) leads to the following key\nimprovements: (i) only one-way offline quantum communication is necessary ,\n(ii) only one party (server) needs to have involved quantum technological\nabilities, (iii) only minimal extra cryptographic primitives are required,\nnamely one oblivious transfer for each input bit and quantum-safe commitments.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 16:37:24 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Kashefi", "Elham", ""], ["Music", "Luka", ""], ["Wallden", "Petros", ""]]}, {"id": "1703.03768", "submitter": "John V Monaco", "authors": "John V. Monaco and Manuel M. Vindiola", "title": "Integer Factorization with a Neuromorphic Sieve", "comments": "Fixed typos in equation for modular roots (Section II, par. 6;\n  Section III, par. 2) and phase calculation (Section IV, par 2)", "journal-ref": "Monaco, John V., and Manuel M. Vindiola. \"Integer factorization\n  with a neuromorphic sieve.\" Circuits and Systems (ISCAS), 2017 IEEE\n  International Symposium on. IEEE, 2017", "doi": null, "report-no": null, "categories": "cs.NE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bound to factor large integers is dominated by the computational effort\nto discover numbers that are smooth, typically performed by sieving a\npolynomial sequence. On a von Neumann architecture, sieving has log-log\namortized time complexity to check each value for smoothness. This work\npresents a neuromorphic sieve that achieves a constant time check for\nsmoothness by exploiting two characteristic properties of neuromorphic\narchitectures: constant time synaptic integration and massively parallel\ncomputation. The approach is validated by modifying msieve, one of the fastest\npublicly available integer factorization implementations, to use the IBM\nNeurosynaptic System (NS1e) as a coprocessor for the sieving stage.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 17:15:29 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 18:55:29 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Monaco", "John V.", ""], ["Vindiola", "Manuel M.", ""]]}, {"id": "1703.03779", "submitter": "Massimo Bartoletti", "authors": "Massimo Bartoletti, Salvatore Carta, Tiziana Cimoli, Roberto Saia", "title": "Dissecting Ponzi schemes on Ethereum: identification, analysis, and\n  impact", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ponzi schemes are financial frauds which lure users under the promise of high\nprofits. Actually, users are repaid only with the investments of new users\njoining the scheme: consequently, a Ponzi scheme implodes soon after users stop\njoining it. Originated in the offline world 150 years ago, Ponzi schemes have\nsince then migrated to the digital world, approaching first the Web, and more\nrecently hanging over cryptocurrencies like Bitcoin. Smart contract platforms\nlike Ethereum have provided a new opportunity for scammers, who have now the\npossibility of creating \"trustworthy\" frauds that still make users lose money,\nbut at least are guaranteed to execute \"correctly\". We present a comprehensive\nsurvey of Ponzi schemes on Ethereum, analysing their behaviour and their impact\nfrom various viewpoints.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 17:50:01 GMT"}, {"version": "v2", "created": "Mon, 20 Mar 2017 20:40:14 GMT"}, {"version": "v3", "created": "Tue, 16 May 2017 15:31:58 GMT"}, {"version": "v4", "created": "Tue, 6 Jun 2017 10:43:06 GMT"}, {"version": "v5", "created": "Wed, 19 Jul 2017 13:29:00 GMT"}, {"version": "v6", "created": "Mon, 12 Aug 2019 19:08:55 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Bartoletti", "Massimo", ""], ["Carta", "Salvatore", ""], ["Cimoli", "Tiziana", ""], ["Saia", "Roberto", ""]]}, {"id": "1703.03835", "submitter": "Lu Yu", "authors": "Oluwakemi Hambolu and Lu Yu and Jon Oakley and Richard R. Brooks and\n  Ujan Mukhopadhyay and Anthony Skjellum", "title": "Provenance Threat Modeling", "comments": "4 pages, 1 figure, conference", "journal-ref": null, "doi": "10.1109/PST.2016.7906960", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Provenance systems are used to capture history metadata, applications include\nownership attribution and determining the quality of a particular data set.\nProvenance systems are also used for debugging, process improvement,\nunderstanding data proof of ownership, certification of validity, etc. The\nprovenance of data includes information about the processes and source data\nthat leads to the current representation. In this paper we study the security\nrisks provenance systems might be exposed to and recommend security solutions\nto better protect the provenance information.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 20:17:26 GMT"}], "update_date": "2017-05-19", "authors_parsed": [["Hambolu", "Oluwakemi", ""], ["Yu", "Lu", ""], ["Oakley", "Jon", ""], ["Brooks", "Richard R.", ""], ["Mukhopadhyay", "Ujan", ""], ["Skjellum", "Anthony", ""]]}, {"id": "1703.03887", "submitter": "Maor Ganz", "authors": "Maor Ganz and Or Sattath", "title": "Quantum coin hedging, and a counter measure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A quantum board game is a multi-round protocol between a single quantum\nplayer against the quantum board. Molina and Watrous discovered quantum\nhedging. They gave an example for perfect quantum hedging: a board game with\nwinning probability < 1, such that the player can win with certainty at least\n1-out-of-2 quantum board games played in parallel. Here we show that perfect\nquantum hedging occurs in a cryptographic protocol - quantum coin flipping. For\nthis reason, when cryptographic protocols are composed, hedging may introduce\nserious challenges into their analysis.\n  We also show that hedging cannot occur when playing two-outcome board games\nin sequence. This is done by showing a formula for the value of sequential\ntwo-outcome board games, which depends only on the optimal value of a single\nboard game; this formula applies in a more general setting, in which hedging is\nonly a special case.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 01:18:02 GMT"}, {"version": "v2", "created": "Wed, 3 May 2017 08:11:46 GMT"}, {"version": "v3", "created": "Tue, 13 Jun 2017 17:59:02 GMT"}, {"version": "v4", "created": "Fri, 16 Jun 2017 12:50:15 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Ganz", "Maor", ""], ["Sattath", "Or", ""]]}, {"id": "1703.03912", "submitter": "Haifeng Xu", "authors": "Haifeng Xu, Milind Tambe, Shaddin Dughmi, Venil Loyd Noronha", "title": "Mitigating the Curse of Correlation in Security Games by Entropy\n  Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Stackelberg security games, a defender seeks to randomly allocate limited\nsecurity resources to protect critical targets from an attack. In this paper,\nwe study a fundamental, yet underexplored, phenomenon in security games, which\nwe term the \\emph{Curse of Correlation} (CoC). Specifically, we observe that\nthere are inevitable correlations among the protection status of different\ntargets. Such correlation is a crucial concern, especially in\n\\emph{spatio-temporal} domains like conservation area patrolling, where\nattackers can surveil patrollers at certain areas and then infer their\npatrolling routes using such correlations. To mitigate this issue, we propose\nto design entropy-maximizing defending strategies for spatio-temporal security\ngames, which frequently suffer from CoC. We prove that the problem is \\#P-hard\nin general. However, it admits efficient algorithms in well-motivated special\nsettings. Our experiments show significant advantages of max-entropy algorithms\nover previous algorithms. A scalable implementation of our algorithm is\ncurrently under pre-deployment testing for integration into FAMS software to\nimprove the scheduling of US federal air marshals.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 05:35:09 GMT"}, {"version": "v2", "created": "Wed, 3 Jan 2018 20:09:52 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Xu", "Haifeng", ""], ["Tambe", "Milind", ""], ["Dughmi", "Shaddin", ""], ["Noronha", "Venil Loyd", ""]]}, {"id": "1703.04057", "submitter": "Anh Dinh", "authors": "Tien Tuan Anh Dinh, Ji Wang, Gang Chen, Rui Liu, Beng Chin Ooi,\n  Kian-Lee Tan", "title": "BLOCKBENCH: A Framework for Analyzing Private Blockchains", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain technologies are taking the world by storm. Public blockchains,\nsuch as Bitcoin and Ethereum, enable secure peer-to-peer applications like\ncrypto-currency or smart contracts. Their security and performance are well\nstudied. This paper concerns recent private blockchain systems designed with\nstronger security (trust) assumption and performance requirement. These systems\ntarget and aim to disrupt applications which have so far been implemented on\ntop of database systems, for example banking, finance applications. Multiple\nplatforms for private blockchains are being actively developed and fine tuned.\nHowever, there is a clear lack of a systematic framework with which different\nsystems can be analyzed and compared against each other. Such a framework can\nbe used to assess blockchains' viability as another distributed data processing\nplatform, while helping developers to identify bottlenecks and accordingly\nimprove their platforms.\n  In this paper, we first describe BlockBench, the first evaluation framework\nfor analyzing private blockchains. It serves as a fair means of comparison for\ndifferent platforms and enables deeper understanding of different system design\nchoices. Any private blockchain can be integrated to BlockBench via simple APIs\nand benchmarked against workloads that are based on real and synthetic smart\ncontracts. BlockBench measures overall and component-wise performance in terms\nof throughput, latency, scalability and fault-tolerance. Next, we use\nBlockBench to conduct comprehensive evaluation of three major private\nblockchains: Ethereum, Parity and Hyperledger Fabric. The results demonstrate\nthat these systems are still far from displacing current database systems in\ntraditional data processing workloads. Furthermore, there are gaps in\nperformance among the three systems which are attributed to the design choices\nat different layers of the software stack.\n", "versions": [{"version": "v1", "created": "Sun, 12 Mar 2017 02:10:06 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Dinh", "Tien Tuan Anh", ""], ["Wang", "Ji", ""], ["Chen", "Gang", ""], ["Liu", "Rui", ""], ["Ooi", "Beng Chin", ""], ["Tan", "Kian-Lee", ""]]}, {"id": "1703.04086", "submitter": "L.T. Handoko", "authors": "A.A. Waskita, H. Suhartanto, L.T. Handoko", "title": "A performance study of anomaly detection using entropy method", "comments": "Proceeding of the International Conference on Computer, Control,\n  Informatics and its Applications (2017) pp. 137-140", "journal-ref": null, "doi": "10.1109/IC3INA.2016.7863038", "report-no": "FISIKALIPI-16081", "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An experiment to study the entropy method for an anomaly detection system has\nbeen performed. The study has been conducted using real data generated from the\ndistributed sensor networks at the Intel Berkeley Research Laboratory. The\nexperimental results were compared with the elliptical method and has been\nanalyzed in two dimensional data sets acquired from temperature and humidity\nsensors across 52 micro controllers. Using the binary classification to\ndetermine the upper and lower boundaries for each series of sensors, it has\nbeen shown that the entropy method are able to detect more number of out\nranging sensor nodes than the elliptical methods. It can be argued that the\nbetter result was mainly due to the lack of elliptical approach which is\nrequiring certain correlation between two sensor series, while in the entropy\napproach each sensor series is treated independently. This is very important in\nthe current case where both sensor series are not correlated each other.\n", "versions": [{"version": "v1", "created": "Sun, 12 Mar 2017 09:37:34 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Waskita", "A. A.", ""], ["Suhartanto", "H.", ""], ["Handoko", "L. T.", ""]]}, {"id": "1703.04206", "submitter": "S. Matthew English", "authors": "S. Matthew English and Ehsan Nezhadian", "title": "Application of Bitcoin Data-Structures & Design Principles to Supply\n  Chain Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heretofore the concept of \"blockchain\" has not been precisely defined.\nAccordingly the potential useful applications of this technology have been\nlargely inflated. This work sidesteps the question of what constitutes a\nblockchain as such and focuses on the architectural components of the Bitcoin\ncryptocurrency, insofar as possible, in isolation. We consider common problems\ninherent in the design of effective supply chain management systems. With each\nidentified problem we propose a solution that utilizes one or more component\naspects of Bitcoin. This culminates in five design principles for increased\nefficiency in supply chain management systems through the application of\nincentive mechanisms and data structures native to the Bitcoin cryptocurrency\nprotocol.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 00:32:14 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["English", "S. Matthew", ""], ["Nezhadian", "Ehsan", ""]]}, {"id": "1703.04262", "submitter": "Ruei Hau Hsu", "authors": "Ruei-Hau Hsu and Jemin Lee and Tony Q.S. Quek and Jyh-Cheng Chen", "title": "GRAAD: Group Anonymous and Accountable D2D Communication in Mobile\n  Networks", "comments": "under submission to possible journal publications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Device-to-Device (D2D) communication is mainly launched by the transmission\nrequirements between devices for specific applications such as Proximity\nServices in Long-Term Evolution Advanced (LTE-A) networks, and each application\nwill form a group of devices for the network-covered and network-absent D2D\ncommunications. Although there are many privacy concerns in D2D communication,\nthey have not been well-addressed in current communication standards. This work\nintroduces network-covered and network-absent authenticated key exchange\nprotocols for D2D communications to guarantee accountable group anonymity,\nend-to-end security to network operators, as well as traceability and\nrevocability for accounting and management requirements. We formally prove the\nsecurity of those protocols, and also develop an analytic model to evaluate the\nquality of authentication protocols by authentication success rate in D2D\ncommunications. Besides, we implement the proposed protocols on android mobile\ndevices to evaluate the computation costs of the protocols. We also evaluate\nthe authentication success rate by the proposed analytic model and prove the\ncorrectness of the analytic model via simulation. Those evaluations show that\nthe proposed protocols are feasible to the performance requirements of D2D\ncommunications.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 05:59:52 GMT"}, {"version": "v2", "created": "Wed, 15 Mar 2017 03:08:30 GMT"}, {"version": "v3", "created": "Thu, 6 Apr 2017 02:49:51 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Hsu", "Ruei-Hau", ""], ["Lee", "Jemin", ""], ["Quek", "Tony Q. S.", ""], ["Chen", "Jyh-Cheng", ""]]}, {"id": "1703.04277", "submitter": "Faheem Ullah", "authors": "Faheem Ullah, Adam Johannes Raft, Mojtaba Shahin, Mansooreh Zahedi and\n  Muhammad Ali Babar", "title": "Security Support in Continuous Deployment Pipeline", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous Deployment (CD) has emerged as a new practice in the software\nindustry to continuously and automatically deploy software changes into\nproduction. Continuous Deployment Pipeline (CDP) supports CD practice by\ntransferring the changes from the repository to production. Since most of the\nCDP components run in an environment that has several interfaces to the\nInternet, these components are vulnerable to various kinds of malicious\nattacks. This paper reports our work aimed at designing secure CDP by utilizing\nsecurity tactics. We have demonstrated the effectiveness of five security\ntactics in designing a secure pipeline by conducting an experiment on two CDPs\n- one incorporates security tactics while the other does not. Both CDPs have\nbeen analyzed qualitatively and quantitatively. We used assurance cases with\ngoal-structured notations for qualitative analysis. For quantitative analysis,\nwe used penetration tools. Our findings indicate that the applied tactics\nimprove the security of the major components (i.e., repository, continuous\nintegration server, main server) of a CDP by controlling access to the\ncomponents and establishing secure connections.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 07:38:16 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Ullah", "Faheem", ""], ["Raft", "Adam Johannes", ""], ["Shahin", "Mojtaba", ""], ["Zahedi", "Mansooreh", ""], ["Babar", "Muhammad Ali", ""]]}, {"id": "1703.04285", "submitter": "Aleksey Fedorov", "authors": "I.S. Kabanov, R.R. Yunusov, Y.V. Kurochkin, and A.K. Fedorov", "title": "Practical cryptographic strategies in the post-quantum era", "comments": "5 pages, 2 figures; review paper", "journal-ref": "AIP Conf. Proc. 1936, 020021 (2018)", "doi": "10.1063/1.5025459", "report-no": null, "categories": "quant-ph cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review new frontiers in information security technologies in\ncommunications and distributed storage technologies with the use of classical,\nquantum, hybrid classical-quantum, and post-quantum cryptography. We analyze\nthe current state-of-the-art, critical characteristics, development trends, and\nlimitations of these techniques for application in enterprise information\nprotection systems. An approach concerning the selection of practical\nencryption technologies for enterprises with branched communication networks is\nintroduced.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 08:08:31 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2018 14:40:07 GMT"}, {"version": "v3", "created": "Fri, 9 Mar 2018 10:05:46 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Kabanov", "I. S.", ""], ["Yunusov", "R. R.", ""], ["Kurochkin", "Y. V.", ""], ["Fedorov", "A. K.", ""]]}, {"id": "1703.04482", "submitter": "Stefano Cresci", "authors": "Stefano Cresci, Roberto Di Pietro, Marinella Petrocchi, Angelo\n  Spognardi, Maurizio Tesconi", "title": "Social Fingerprinting: detection of spambot groups through DNA-inspired\n  behavioral modeling", "comments": null, "journal-ref": "IEEE Transactions on Dependable and Secure Computing\n  15(4):561-576, 2018", "doi": "10.1109/TDSC.2017.2681672", "report-no": null, "categories": "cs.SI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spambot detection in online social networks is a long-lasting challenge\ninvolving the study and design of detection techniques capable of efficiently\nidentifying ever-evolving spammers. Recently, a new wave of social spambots has\nemerged, with advanced human-like characteristics that allow them to go\nundetected even by current state-of-the-art algorithms. In this paper, we show\nthat efficient spambots detection can be achieved via an in-depth analysis of\ntheir collective behaviors exploiting the digital DNA technique for modeling\nthe behaviors of social network users. Inspired by its biological counterpart,\nin the digital DNA representation the behavioral lifetime of a digital account\nis encoded in a sequence of characters. Then, we define a similarity measure\nfor such digital DNA sequences. We build upon digital DNA and the similarity\nbetween groups of users to characterize both genuine accounts and spambots.\nLeveraging such characterization, we design the Social Fingerprinting\ntechnique, which is able to discriminate among spambots and genuine accounts in\nboth a supervised and an unsupervised fashion. We finally evaluate the\neffectiveness of Social Fingerprinting and we compare it with three\nstate-of-the-art detection algorithms. Among the peculiarities of our approach\nis the possibility to apply off-the-shelf DNA analysis techniques to study\nonline users behaviors and to efficiently rely on a limited number of\nlightweight account characteristics.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 16:51:11 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Cresci", "Stefano", ""], ["Di Pietro", "Roberto", ""], ["Petrocchi", "Marinella", ""], ["Spognardi", "Angelo", ""], ["Tesconi", "Maurizio", ""]]}, {"id": "1703.04583", "submitter": "Ferdinand Brasser", "authors": "Benny Fuhry (1), Raad Bahmani (2), Ferdinand Brasser (2), Florian Hahn\n  (1), Florian Kerschbaum (3) and Ahmad-Reza Sadeghi (2) ((1) SAP Research, (2)\n  Technische Universit\\\"at Darmstadt, (3) University of Waterloo)", "title": "HardIDX: Practical and Secure Index with SGX", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software-based approaches for search over encrypted data are still either\nchallenged by lack of proper, low-leakage encryption or slow performance.\nExisting hardware-based approaches do not scale well due to hardware\nlimitations and software designs that are not specifically tailored to the\nhardware architecture, and are rarely well analyzed for their security (e.g.,\nthe impact of side channels). Additionally, existing hardware-based solutions\noften have a large code footprint in the trusted environment susceptible to\nsoftware compromises. In this paper we present HardIDX: a hardware-based\napproach, leveraging Intel's SGX, for search over encrypted data. It implements\nonly the security critical core, i.e., the search functionality, in the trusted\nenvironment and resorts to untrusted software for the remainder. HardIDX is\ndeployable as a highly performant encrypted database index: it is logarithmic\nin the size of the index and searches are performed within a few milliseconds\nrather than seconds. We formally model and prove the security of our scheme\nshowing that its leakage is equivalent to the best known searchable encryption\nschemes. Our implementation has a very small code and memory footprint yet\nstill scales to virtually unlimited search index sizes, i.e., size is limited\nonly by the general - non-secure - hardware resources.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 17:09:30 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Fuhry", "Benny", ""], ["Bahmani", "Raad", ""], ["Brasser", "Ferdinand", ""], ["Hahn", "Florian", ""], ["Kerschbaum", "Florian", ""], ["Sadeghi", "Ahmad-Reza", ""]]}, {"id": "1703.04738", "submitter": "Amanda Prorok", "authors": "Amanda Prorok and Vijay Kumar", "title": "Privacy-Preserving Vehicle Assignment for Mobility-on-Demand Systems", "comments": "8 pages; Submitted to IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban transportation is being transformed by mobility-on-demand (MoD)\nsystems. One of the goals of MoD systems is to provide personalized\ntransportation services to passengers. This process is facilitated by a\ncentralized operator that coordinates the assignment of vehicles to individual\npassengers, based on location data. However, current approaches assume that\naccurate positioning information for passengers and vehicles is readily\navailable. This assumption raises privacy concerns. In this work, we address\nthis issue by proposing a method that protects passengers' drop-off locations\n(i.e., their travel destinations). Formally, we solve a batch assignment\nproblem that routes vehicles at obfuscated origin locations to passenger\nlocations (since origin locations correspond to previous drop-off locations),\nsuch that the mean waiting time is minimized. Our main contributions are\ntwo-fold. First, we formalize the notion of privacy for continuous\nvehicle-to-passenger assignment in MoD systems, and integrate a privacy\nmechanism that provides formal guarantees. Second, we present a scalable\nalgorithm that takes advantage of superfluous (idle) vehicles in the system,\ncombining multiple iterations of the Hungarian algorithm to allocate a\nredundant number of vehicles to a single passenger. As a result, we are able to\nreduce the performance deterioration induced by the privacy mechanism. We\nevaluate our methods on a real, large-scale data set consisting of over 11\nmillion taxi rides (specifying vehicle availability and passenger requests),\nrecorded over a month's duration, in the area of Manhattan, New York. Our work\ndemonstrates that privacy can be integrated into MoD systems without incurring\na significant loss of performance, and moreover, that this loss can be further\nminimized at the cost of deploying additional (redundant) vehicles into the\nfleet.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 21:41:20 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Prorok", "Amanda", ""], ["Kumar", "Vijay", ""]]}, {"id": "1703.04797", "submitter": "Amanda Prorok", "authors": "Amanda Prorok and Vijay Kumar", "title": "A Macroscopic Model for Differential Privacy in Dynamic Robotic Networks", "comments": "19 pages, 14 figures; submitted to Swarm Intelligence journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing availability of online and mobile information platforms is\nfacilitating the development of peer-to-peer collaboration strategies in\nlarge-scale networks. These technologies are being leveraged by networked\nrobotic systems to provide applications of automated transport, resource\nredistribution (collaborative consumption), and location services. Yet,\nexternal observations of the system dynamics may expose sensitive information\nabout the participants that compose these networks (robots, resources, and\nhumans). In particular, we are concerned with settings where an adversary gains\naccess to a snapshot of the dynamic state of the system. We propose a method\nthat quantifies how easy it is for the adversary to identify the specific type\nof any agent (which can be a robot, resource, or human) in the network, based\non this observation. We draw from the theory of differential privacy to propose\na closed-form expression for the leakage of the system when the snapshot is\ntaken at steady-state, as well as a numerical approach to compute the leakage\nwhen the snapshot is taken at any given time. The novelty of our approach is\nthat our privacy model builds on a macroscopic description of the system's\nstate, which allows us to take account of protected entities (network\nparticipants) that are interdependent. Our results show how the leakage varies,\nas a function of the composition and dynamic behavior of the network; they also\nindicate design rules for increasing privacy levels.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 22:48:07 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Prorok", "Amanda", ""], ["Kumar", "Vijay", ""]]}, {"id": "1703.04874", "submitter": "Jovonni Pharr", "authors": "Jovonni L. Pharr", "title": "Hacker Combat: A Competitive Sport from Programmatic Dueling &\n  Cyberwarfare", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The history of humanhood has included competitive activities of many\ndifferent forms. Sports have offered many benefits beyond that of\nentertainment. At the time of this article, there exists not a competitive\necosystem for cyber security beyond that of conventional capture the flag\ncompetitions, and the like. This paper introduces a competitive framework with\na foundation on computer science, and hacking. This proposed competitive\nlandscape encompasses the ideas underlying information security, software\nengineering, and cyber warfare. We also demonstrate the opportunity to rank,\nscore, & categorize actionable skill levels into tiers of capability.\nPhysiological metrics are analyzed from participants during gameplay. These\nanalyses provide support regarding the intricacies required for competitive\nplay, and analysis of play. We use these intricacies to build a case for an\norganized competitive ecosystem. Using previous player behavior from gameplay,\nwe also demonstrate the generation of an artificial agent purposed with\ngameplay at a competitive level.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 01:38:16 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Pharr", "Jovonni L.", ""]]}, {"id": "1703.04878", "submitter": "Bj{\\o}rn Kjos-Hanssen", "authors": "Bj{\\o}rn Kjos-Hanssen", "title": "Superposition as memory: unlocking quantum automatic complexity", "comments": "Lecture Notes in Computer Science, UCNC (Unconventional Computation\n  and Natural Computation) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imagine a lock with two states, \"locked\" and \"unlocked\", which may be\nmanipulated using two operations, called 0 and 1. Moreover, the only way to\n(with certainty) unlock using four operations is to do them in the sequence\n0011, i.e., $0^n1^n$ where $n=2$. In this scenario one might think that the\nlock needs to be in certain further states after each operation, so that there\nis some memory of what has been done so far. Here we show that this memory can\nbe entirely encoded in superpositions of the two basic states \"locked\" and\n\"unlocked\", where, as dictated by quantum mechanics, the operations are given\nby unitary matrices. Moreover, we show using the Jordan--Schur lemma that a\nsimilar lock is not possible for $n=60$.\n  We define the semi-classical quantum automatic complexity $Q_{s}(x)$ of a\nword $x$ as the infimum in lexicographic order of those pairs of nonnegative\nintegers $(n,q)$ such that there is a subgroup $G$ of the projective unitary\ngroup PU$(n)$ with $|G|\\le q$ and with $U_0,U_1\\in G$ such that, in terms of a\nstandard basis $\\{e_k\\}$ and with $U_z=\\prod_k U_{z(k)}$, we have $U_x e_1=e_2$\nand $U_y e_1 \\ne e_2$ for all $y\\ne x$ with $|y|=|x|$. We show that $Q_s$ is\nunbounded and not constant for strings of a given length. In particular, \\[\n  Q_{s}(0^21^2)\\le (2,12) < (3,1) \\le Q_{s}(0^{60}1^{60}) \\] and\n$Q_s(0^{120})\\le (2,121)$.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 01:48:37 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Kjos-Hanssen", "Bj\u00f8rn", ""]]}, {"id": "1703.04940", "submitter": "Jacob Steinhardt", "authors": "Jacob Steinhardt and Moses Charikar and Gregory Valiant", "title": "Resilience: A Criterion for Learning in the Presence of Arbitrary\n  Outliers", "comments": "32 pages, full version of ITCS2018 paper (minor citation edit from\n  v2)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a criterion, resilience, which allows properties of a dataset\n(such as its mean or best low rank approximation) to be robustly computed, even\nin the presence of a large fraction of arbitrary additional data. Resilience is\na weaker condition than most other properties considered so far in the\nliterature, and yet enables robust estimation in a broader variety of settings.\nWe provide new information-theoretic results on robust distribution learning,\nrobust estimation of stochastic block models, and robust mean estimation under\nbounded $k$th moments. We also provide new algorithmic results on robust\ndistribution learning, as well as robust mean estimation in $\\ell_p$-norms.\nAmong our proof techniques is a method for pruning a high-dimensional\ndistribution with bounded $1$st moments to a stable \"core\" with bounded $2$nd\nmoments, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 05:43:48 GMT"}, {"version": "v2", "created": "Thu, 23 Nov 2017 07:22:21 GMT"}, {"version": "v3", "created": "Mon, 27 Nov 2017 03:16:54 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Steinhardt", "Jacob", ""], ["Charikar", "Moses", ""], ["Valiant", "Gregory", ""]]}, {"id": "1703.05066", "submitter": "Nasser Al-Fannah", "authors": "Nasser Mohammed Al-Fannah and Wanpeng Li", "title": "Not All Browsers Are Created Equal: Comparing Web Browser\n  Fingerprintability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Browsers and their users can be tracked even in the absence of a persistent\nIP address or cookie. Unique and hence identifying pieces of information,\nmaking up what is known as a fingerprint, can be collected from browsers by a\nvisited website, e.g. using JavaScript. However, browsers vary in precisely\nwhat information they make available, and hence their fingerprintability may\nalso vary. In this paper, we report on the results of experiments examining the\nfingerprintable attributes made available by a range of modern browsers. We\ntested the most widely used browsers for both desktop and mobile platforms. The\nresults reveal significant differences between browsers in terms of their\nfingerprinting potential, meaning that the choice of browser has significant\nprivacy implications.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 10:34:42 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 08:11:18 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Al-Fannah", "Nasser Mohammed", ""], ["Li", "Wanpeng", ""]]}, {"id": "1703.05126", "submitter": "Pengfei Zuo", "authors": "Pengfei Zuo, Yu Hua, Cong Wang, Wen Xia, Shunde Cao, Yukun Zhou,\n  Yuanyuan Sun", "title": "Bandwidth-efficient Storage Services for Mitigating Side Channel Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data deduplication is able to effectively identify and eliminate redundant\ndata and only maintain a single copy of files and chunks. Hence, it is widely\nused in cloud storage systems to save storage space and network bandwidth.\nHowever, the occurrence of deduplication can be easily identified by monitoring\nand analyzing network traffic, which leads to the risk of user privacy leakage.\nThe attacker can carry out a very dangerous side channel attack, i.e.,\nlearn-the-remaining-information (LRI) attack, to reveal users' privacy\ninformation by exploiting the side channel of network traffic in deduplication.\nExisting work addresses the LRI attack at the cost of the high bandwidth\nefficiency of deduplication. In order to address this problem, we propose a\nsimple yet effective scheme, called randomized redundant chunk scheme (RRCS),\nto significantly mitigate the risk of the LRI attack while maintaining the high\nbandwidth efficiency of deduplication. The basic idea behind RRCS is to add\nrandomized redundant chunks to mix up the real deduplication states of files\nused for the LRI attack, which effectively obfuscates the view of the attacker,\nwho attempts to exploit the side channel of network traffic for the LRI attack.\nOur security analysis shows that RRCS could significantly mitigate the risk of\nthe LRI attack. We implement the RRCS prototype and evaluate it by using three\nlarge-scale real-world datasets. Experimental results demonstrate the\nefficiency and efficacy of RRCS.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 12:45:17 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Zuo", "Pengfei", ""], ["Hua", "Yu", ""], ["Wang", "Cong", ""], ["Xia", "Wen", ""], ["Cao", "Shunde", ""], ["Zhou", "Yukun", ""], ["Sun", "Yuanyuan", ""]]}, {"id": "1703.05194", "submitter": "Azadeh Sheikholeslami", "authors": "Azadeh Sheikholeslami, Majid Ghaderi, Hossein Pishro-Nik, Dennis\n  Goeckel", "title": "Energy-Efficient Secrecy in Wireless Networks Based on Random Jamming", "comments": null, "journal-ref": null, "doi": "10.1109/TCOMM.2017.2682238", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers secure energy-efficient routing in the presence of\nmultiple passive eavesdroppers. Previous work in this area has considered\nsecure routing assuming probabilistic or exact knowledge of the location and\nchannel-state-information (CSI) of each eavesdropper. In wireless networks,\nhowever, the locations and CSIs of passive eavesdroppers are not known, making\nit challenging to guarantee secrecy for any routing algorithm.\n  We develop an efficient (in terms of energy consumption and computational\ncomplexity) routing algorithm that does not rely on any information about the\nlocations and CSIs of the eavesdroppers. Our algorithm guarantees secrecy even\nin disadvantaged wireless environments, where multiple eavesdroppers try to\neavesdrop each message, are equipped with directional antennas, or can get\narbitrarily close to the transmitter. The key is to employ additive random\njamming to exploit inherent non-idealities of the eavesdropper's receiver,\nwhich makes the eavesdroppers incapable of recording the messages. We have\nsimulated our proposed algorithm and compared it with existing secrecy routing\nalgorithms in both single-hop and multi-hop networks. Our results indicate that\nwhen the uncertainty in the locations of eavesdroppers is high and/or in\ndisadvantaged wireless environments, our algorithm outperforms existing\nalgorithms in terms of energy consumption and secrecy.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 14:58:46 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Sheikholeslami", "Azadeh", ""], ["Ghaderi", "Majid", ""], ["Pishro-Nik", "Hossein", ""], ["Goeckel", "Dennis", ""]]}, {"id": "1703.05234", "submitter": "Jeffrey Pawlick", "authors": "Jeffrey Pawlick and Quanyan Zhu", "title": "Phishing for Phools in the Internet of Things: Modeling One-to-Many\n  Deception using Poisson Signaling Games", "comments": "This article was not accepted. It was revised and appears here:\n  arXiv:1707.03708", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strategic interactions ranging from politics and pharmaceuticals to\ne-commerce and social networks support equilibria in which agents with private\ninformation manipulate others which are vulnerable to deception. Especially in\ncyberspace and the Internet of things, deception is difficult to detect and\ntrust is complicated to establish. For this reason, effective policy-making,\nprofitable entrepreneurship, and optimal technological design demand\nquantitative models of deception. In this paper, we use game theory to model\nspecifically one-to-many deception. We combine a signaling game with a model\ncalled a Poisson game. The resulting Poisson signaling game extends traditional\nsignaling games to include 1) exogenous evidence of deception, 2) an unknown\nnumber of receivers, and 3) receivers of multiple types. We find closed-form\nequilibrium solutions for a subset of Poisson signaling games, and characterize\nthe rates of deception that they support. We show that receivers with higher\nabilities to detect deception can use crowd-defense tactics to mitigate\ndeception for receivers with lower abilities to detect deception. Finally, we\ndiscuss how Poisson signaling games could be used to defend against the process\nby which the Mirai botnet recruits IoT devices in preparation for a distributed\ndenial-of-service attack.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 16:30:01 GMT"}, {"version": "v2", "created": "Mon, 16 Oct 2017 16:13:40 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Pawlick", "Jeffrey", ""], ["Zhu", "Quanyan", ""]]}, {"id": "1703.05400", "submitter": "Shin-Ming Cheng", "authors": "Shin-Ming Cheng and Pin-Yu Chen and Ching-Chao Lin and Hsu-Chun Hsiao", "title": "Traffic-aware Patching for Cyber Security in Mobile IoT", "comments": "8 pages, 6 figures, To appear in July 2017 IEEE Communications\n  Magazine, feature topic on \"Traffic Measurements for Cyber Security\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The various types of communication technologies and mobility features in\nInternet of Things (IoT) on the one hand enable fruitful and attractive\napplications, but on the other hand facilitates malware propagation, thereby\nraising new challenges on handling IoT-empowered malware for cyber security.\nComparing with the malware propagation control scheme in traditional wireless\nnetworks where nodes can be directly repaired and secured, in IoT, compromised\nend devices are difficult to be patched. Alternatively, blocking malware via\npatching intermediate nodes turns out to be a more feasible and practical\nsolution. Specifically, patching intermediate nodes can effectively prevent the\nproliferation of malware propagation by securing infrastructure links and\nlimiting malware propagation to local device-to-device dissemination. This\narticle proposes a novel traffic-aware patching scheme to select important\nintermediate nodes to patch, which applies to the IoT system with limited\npatching resources and response time constraint. Experiments on real-world\ntrace datasets in IoT networks are conducted to demonstrate the advantage of\nthe proposed traffic-aware patching scheme in alleviating malware propagation.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 21:59:05 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Cheng", "Shin-Ming", ""], ["Chen", "Pin-Yu", ""], ["Lin", "Ching-Chao", ""], ["Hsiao", "Hsu-Chun", ""]]}, {"id": "1703.05435", "submitter": "Mitar Milutinovic", "authors": "Mitar Milutinovic, Warren He, Howard Wu, Maxinder Kanwal", "title": "Proof of Luck: an Efficient Blockchain Consensus Protocol", "comments": "SysTEX '16, December 12-16, 2016, Trento, Italy", "journal-ref": null, "doi": "10.1145/3007788.3007790", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper, we present designs for multiple blockchain consensus primitives\nand a novel blockchain system, all based on the use of trusted execution\nenvironments (TEEs), such as Intel SGX-enabled CPUs. First, we show how using\nTEEs for existing proof of work schemes can make mining equitably distributed\nby preventing the use of ASICs. Next, we extend the design with proof of time\nand proof of ownership consensus primitives to make mining energy- and\ntime-efficient. Further improving on these designs, we present a blockchain\nusing a proof of luck consensus protocol. Our proof of luck blockchain uses a\nTEE platform's random number generation to choose a consensus leader, which\noffers low-latency transaction validation, deterministic confirmation time,\nnegligible energy consumption, and equitably distributed mining. Lastly, we\ndiscuss a potential protection against up to a constant number of compromised\nTEEs.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 00:32:02 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Milutinovic", "Mitar", ""], ["He", "Warren", ""], ["Wu", "Howard", ""], ["Kanwal", "Maxinder", ""]]}, {"id": "1703.05502", "submitter": "Evgeny Burnaev", "authors": "Denis Volkhonskiy and Ivan Nazarov and Evgeny Burnaev", "title": "Steganographic Generative Adversarial Networks", "comments": "15 pages, 10 figures, 5 tables, Workshop on Adversarial Training\n  (NIPS 2016, Barcelona, Spain)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR cs.CV stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Steganography is collection of methods to hide secret information (\"payload\")\nwithin non-secret information \"container\"). Its counterpart, Steganalysis, is\nthe practice of determining if a message contains a hidden payload, and\nrecovering it if possible. Presence of hidden payloads is typically detected by\na binary classifier. In the present study, we propose a new model for\ngenerating image-like containers based on Deep Convolutional Generative\nAdversarial Networks (DCGAN). This approach allows to generate more\nsetganalysis-secure message embedding using standard steganography algorithms.\nExperiment results demonstrate that the new model successfully deceives the\nsteganography analyzer, and for this reason, can be used in steganographic\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 08:28:11 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 19:56:14 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Volkhonskiy", "Denis", ""], ["Nazarov", "Ivan", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1703.05561", "submitter": "Erwin Quiring", "authors": "Erwin Quiring, Daniel Arp, Konrad Rieck", "title": "Fraternal Twins: Unifying Attacks on Machine Learning and Digital\n  Watermarking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is increasingly used in security-critical applications, such\nas autonomous driving, face recognition and malware detection. Most learning\nmethods, however, have not been designed with security in mind and thus are\nvulnerable to different types of attacks. This problem has motivated the\nresearch field of adversarial machine learning that is concerned with attacking\nand defending learning methods. Concurrently, a different line of research has\ntackled a very similar problem: In digital watermarking information are\nembedded in a signal in the presence of an adversary. As a consequence, this\nresearch field has also extensively studied techniques for attacking and\ndefending watermarking methods.\n  The two research communities have worked in parallel so far, unnoticeably\ndeveloping similar attack and defense strategies. This paper is a first effort\nto bring these communities together. To this end, we present a unified notation\nof black-box attacks against machine learning and watermarking that reveals the\nsimilarity of both settings. To demonstrate the efficacy of this unified view,\nwe apply concepts from watermarking to machine learning and vice versa. We show\nthat countermeasures from watermarking can mitigate recent model-extraction\nattacks and, similarly, that techniques for hardening machine learning can fend\noff oracle attacks against watermarks. Our work provides a conceptual link\nbetween two research fields and thereby opens novel directions for improving\nthe security of both, machine learning and digital watermarking.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 11:15:28 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Quiring", "Erwin", ""], ["Arp", "Daniel", ""], ["Rieck", "Konrad", ""]]}, {"id": "1703.05713", "submitter": "Bas Van IJzendoorn", "authors": "Bas van IJzendoorn", "title": "The challenge of decentralized marketplaces", "comments": "responsible teacher: Johan Pouwelse", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online trust systems are playing an important role in to-days world and face\nvarious challenges in building them. Billions of dollars of products and\nservices are traded through electronic commerce, files are shared among large\npeer-to-peer networks and smart contracts can potentially replace paper\ncontracts with digital contracts. These systems rely on trust mechanisms in\npeer-to-peer networks like reputation systems or a trustless public ledger. In\nmost cases, reputation systems are build to determine the trustworthiness of\nusers and to provide incentives for users to make a fair contribution to the\npeer-to-peer network. The main challenges are how to set up a good trust\nsystem, how to deal with security issues and how to deal with strategic users\ntrying to cheat on the system. The Sybil attack, the most important attack on\nreputation systems is discussed. At last match making in two sided markets and\nthe strategy proofness of these markets are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 16:48:28 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["van IJzendoorn", "Bas", ""]]}, {"id": "1703.05778", "submitter": "Ali Sharifara", "authors": "Ali Sharifara, and Amir Ghaderi", "title": "Medical Image Watermarking using 2D-DWT with Enhanced security and\n  capacity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teleradiology enables medical images to be transferred over the computer\nnetworks for many purposes including clinical interpretation, diagnosis,\narchive, etc. In telemedicine, medical images can be manipulated while\ntransferring. In addition, medical information security requirements are\nspecified by the legislative rules, and concerned entities must adhere to them.\nIn this research, we propose a new scheme based on 2-dimensional Discrete\nWavelet Transform (2D DWT) to improve the robustness and authentication of\nmedical images. In addition, the current research improves security and\ncapacity of watermarking using encryption and compression in medical images.\nThe evaluation is performed on the personal dataset, which contains 194 CTI and\n68 MRI cases.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 18:05:32 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Sharifara", "Ali", ""], ["Ghaderi", "Amir", ""]]}, {"id": "1703.05953", "submitter": "Dominik Herrmann", "authors": "Dominik Herrmann", "title": "Das Internet-Adressbuch bedroht unsere Privatsph\\\"are", "comments": "12 pages, in German", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper summarizes selected results of the dissertation\n\"Beobachtungsm\\\"oglichkeiten im Domain Name System: Angriffe auf die\nPrivatsph\\\"are und Techniken zum Selbstdatenschutz\". The dissertation provides\nnew technical insights to answer the questions \"Who can monitor us on the\nInternet?\" and \"How do we protect ourselves?\". It focuses on the Domain Name\nSystem (DNS), the address book of the internet. It shows that recursive\nnameservers have monitoring capabilities that have been neglected so far. In\nparticular, a behavior-based tracking method is introduced, which allows\noperators to track the activities of users over an extended period of time. On\nthe one hand, this threatens the privacy of Internet users, on the other hand,\nlaw enforcement could benefit from this research. Furthermore, new privacy\nenhancing techniques are proposed, which are more effective and more\nuser-friendly than existing approaches.\n  -----\n  Dieser Beitrag fasst ausgew\\\"ahlte Ergebnisse der Dissertation\n\"Beobachtungsm\\\"oglichkeiten im Domain Name System: Angriffe auf die\nPrivatsph\\\"are und Techniken zum Selbstdatenschutz\" zusammen. Die Dissertation\nliefert neue Antworten auf die Fragen \"Wer kann uns im Internet \\\"uberwachen?\"\nund \"Wie sch\\\"utzen wir uns davor?\". Die Arbeit befasst sich mit dem Domain\nName System (DNS), dem Adressbuch des Internets. Es wird gezeigt, dass es im\nDNS bislang vernachl\\\"assigte \\\"Uberwachungsm\\\"oglichkeiten gibt. Insbesondere\nwird ein Verfahren zum verhaltensbasierten Tracking vorgestellt, mit dem die\nAktivit\\\"aten von Internetnutzern unbemerkt \\\"uber l\\\"angere Zeitr\\\"aume\nverfolgt werden k\\\"onnen. Einerseits wird dadurch die Privatsph\\\"are vieler\nInternetnutzer bedroht, andererseits k\\\"onnten daraus neue Werkzeuge f\\\"ur die\nStrafverfolgung entstehen. Weiterhin werden neue Datenschutz-Techniken\nvorgeschlagen, die sicherer und benutzerfreundlicher sind als die bisherigen\nAns\\\"atze.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 10:34:22 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Herrmann", "Dominik", ""]]}, {"id": "1703.06179", "submitter": "Ertan Onur", "authors": "Cansu Betin Onur, Adnan K{\\i}l{\\i}\\c{c}, Ertan Onur", "title": "Impossibility of Three Pass Protocol using Public Abelian Groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Key transport protocols are designed to transfer a secret key from an\ninitiating principal to other entities in a network. The three-pass protocol is\na key transport protocol developed by Adi Shamir in 1980 where Alice wants to\ntransport a secret message to Bob over an insecure channel, and they do not\nhave any pre-shared secret information. In this paper, we prove the\nimpossibility of secret key transportation from a principal to another entity\nin a network by using the three pass protocol over public Abelian groups. If it\nwere possible to employ public Abelian groups to implement the three-pass\nprotocol, we could use it in post-quantum cryptography for transporting keys\nproviding information theoretic security without relying on any computationally\ndifficult problem.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 19:27:01 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Onur", "Cansu Betin", ""], ["K\u0131l\u0131\u00e7", "Adnan", ""], ["Onur", "Ertan", ""]]}, {"id": "1703.06255", "submitter": "Henry Corrigan-Gibbs", "authors": "Henry Corrigan-Gibbs and Dan Boneh", "title": "Prio: Private, Robust, and Scalable Computation of Aggregate Statistics", "comments": "Extended version of NSDI 2017 paper by the same name", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Prio, a privacy-preserving system for the collection of\naggregate statistics. Each Prio client holds a private data value (e.g., its\ncurrent location), and a small set of servers compute statistical functions\nover the values of all clients (e.g., the most popular location). As long as at\nleast one server is honest, the Prio servers learn nearly nothing about the\nclients' private data, except what they can infer from the aggregate statistics\nthat the system computes. To protect functionality in the face of faulty or\nmalicious clients, Prio uses secret-shared non-interactive proofs (SNIPs), a\nnew cryptographic technique that yields a hundred-fold performance improvement\nover conventional zero-knowledge approaches. Prio extends classic private\naggregation techniques to enable the collection of a large class of useful\nstatistics. For example, Prio can perform a least-squares regression on\nhigh-dimensional client-provided data without ever seeing the data in the\nclear.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 04:52:28 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Corrigan-Gibbs", "Henry", ""], ["Boneh", "Dan", ""]]}, {"id": "1703.06322", "submitter": "Massimo Bartoletti", "authors": "Massimo Bartoletti and Livio Pompianu", "title": "An empirical analysis of smart contracts: platforms, applications, and\n  design patterns", "comments": "WTSC 2017", "journal-ref": null, "doi": "10.1007/978-3-319-70278-0", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart contracts are computer programs that can be consistently executed by a\nnetwork of mutually distrusting nodes, without the arbitration of a trusted\nauthority. Because of their resilience to tampering, smart contracts are\nappealing in many scenarios, especially in those which require transfers of\nmoney to respect certain agreed rules (like in financial services and in\ngames). Over the last few years many platforms for smart contracts have been\nproposed, and some of them have been actually implemented and used. We study\nhow the notion of smart contract is interpreted in some of these platforms.\nFocussing on the two most widespread ones, Bitcoin and Ethereum, we quantify\nthe usage of smart contracts in relation to their application domain. We also\nanalyse the most common programming patterns in Ethereum, where the source code\nof smart contracts is available.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 17:39:19 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Bartoletti", "Massimo", ""], ["Pompianu", "Livio", ""]]}, {"id": "1703.06545", "submitter": "Ruben Recabarren", "authors": "Ruben Recabarren and Bogdan Carbunar", "title": "Hardening Stratum, the Bitcoin Pool Mining Protocol", "comments": "18 pages, 17 figures, to appear in PETS 2017, issue 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stratum, the de-facto mining communication protocol used by blockchain based\ncryptocurrency systems, enables miners to reliably and efficiently fetch jobs\nfrom mining pool servers. In this paper we exploit Stratum's lack of encryption\nto develop passive and active attacks on Bitcoin's mining protocol, with\nimportant implications on the privacy, security and even safety of mining\nequipment owners. We introduce StraTap and ISP Log attacks, that infer miner\nearnings if given access to miner communications, or even their logs. We\ndevelop BiteCoin, an active attack that hijacks shares submitted by miners, and\ntheir associated payouts. We build BiteCoin on WireGhost, a tool we developed\nto hijack and surreptitiously maintain Stratum connections. Our attacks reveal\nthat securing Stratum through pervasive encryption is not only undesirable (due\nto large overheads), but also ineffective: an adversary can predict miner\nearnings even when given access to only packet timestamps. Instead, we devise\nBedrock, a minimalistic Stratum extension that protects the privacy and\nsecurity of mining participants. We introduce and leverage the mining cookie\nconcept, a secret that each miner shares with the pool and includes in its\npuzzle computations, and that prevents attackers from reconstructing or\nhijacking the puzzles. We have implemented our attacks and collected 138MB of\nStratum protocol traffic from mining equipment in the US and Venezuela. We show\nthat Bedrock is resilient to active attacks even when an adversary breaks the\ncrypto constructs it uses. Bedrock imposes a daily overhead of 12.03s on a\nsingle pool server that handles mining traffic from 16,000 miners.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 00:14:35 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Recabarren", "Ruben", ""], ["Carbunar", "Bogdan", ""]]}, {"id": "1703.06573", "submitter": "EPTCS", "authors": "Hubert Garavel, Lina Marsso", "title": "A Large Term Rewrite System Modelling a Pioneering Cryptographic\n  Algorithm", "comments": "In Proceedings MARS 2017, arXiv:1703.05812", "journal-ref": "EPTCS 244, 2017, pp. 129-183", "doi": "10.4204/EPTCS.244.6", "report-no": null, "categories": "cs.CR cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a term rewrite system that formally models the Message\nAuthenticator Algorithm (MAA), which was one of the first cryptographic\nfunctions for computing a Message Authentication Code and was adopted, between\n1987 and 2001, in international standards (ISO 8730 and ISO 8731-2) to ensure\nthe authenticity and integrity of banking transactions. Our term rewrite system\nis large (13 sorts, 18 constructors, 644 non-constructors, and 684 rewrite\nrules), confluent, and terminating. Implementations in thirteen different\nlanguages have been automatically derived from this model and used to validate\n200 official test vectors for the MAA.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 02:48:31 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Garavel", "Hubert", ""], ["Marsso", "Lina", ""]]}, {"id": "1703.06586", "submitter": "Aditya Gune", "authors": "Aditya Gune", "title": "The Cryptographic Implications of the LinkedIn Data Breach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data security and personal privacy are difficult to maintain in the Internet\nage. In 2012, professional networking site LinkedIn suffered a breach,\ncompromising the login of over 100 million accounts. The passwords were cracked\nand sold online, exposing the authentication credentials millions of users.\nThis manuscript dissects the cryptographic failures implicated in the breach,\nand explores more secure methods of storing passwords.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 03:52:19 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Gune", "Aditya", ""]]}, {"id": "1703.06659", "submitter": "Shuo Chen", "authors": "Shuo Chen, Rongxing Lu, and Jie Zhang", "title": "A Flexible Privacy-preserving Framework for Singular Value Decomposition\n  under Internet of Things Environment", "comments": "24 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The singular value decomposition (SVD) is a widely used matrix factorization\ntool which underlies plenty of useful applications, e.g. recommendation system,\nabnormal detection and data compression. Under the environment of emerging\nInternet of Things (IoT), there would be an increasing demand for data analysis\nto better human's lives and create new economic growth points. Moreover, due to\nthe large scope of IoT, most of the data analysis work should be done in the\nnetwork edge, i.e. handled by fog computing. However, the devices which provide\nfog computing may not be trustable while the data privacy is often the\nsignificant concern of the IoT application users. Thus, when performing SVD for\ndata analysis purpose, the privacy of user data should be preserved. Based on\nthe above reasons, in this paper, we propose a privacy-preserving fog computing\nframework for SVD computation. The security and performance analysis shows the\npracticability of the proposed framework. Furthermore, since different\napplications may utilize the result of SVD operation in different ways, three\napplications with different objectives are introduced to show how the framework\ncould flexibly achieve the purposes of different applications, which indicates\nthe flexibility of the design.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 10:35:44 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 04:35:23 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Chen", "Shuo", ""], ["Lu", "Rongxing", ""], ["Zhang", "Jie", ""]]}, {"id": "1703.06660", "submitter": "Edward Cartwright", "authors": "Julio Hernandez-Castro, Edward Cartwright and Anna Stepanova", "title": "Economic Analysis of Ransomware", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present in this work an economic analysis of ransomware, with relevant\ndata from Cryptolocker, CryptoWall, TeslaCrypt and other major strands. We\ninclude a detailed study of the impact that different price discrimination\nstrategies can have on the success of a ransomware family, examining uniform\npricing, optimal price discrimination and bargaining strategies and analysing\ntheir advantages and limitations. In addition, we present results of a\npreliminary survey that can helps in estimating an optimal ransom value. We\ndiscuss at each stage whether the different schemes we analyse have been\nencountered already in existing malware, and the likelihood of them being\nimplemented and becoming successful. We hope this work will help to gain some\nuseful insights for predicting how ransomware may evolve in the future and be\nbetter prepared to counter its current and future threat.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 10:40:46 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Hernandez-Castro", "Julio", ""], ["Cartwright", "Edward", ""], ["Stepanova", "Anna", ""]]}, {"id": "1703.06748", "submitter": "Yen-Chen Lin", "authors": "Yen-Chen Lin, Zhang-Wei Hong, Yuan-Hong Liao, Meng-Li Shih, Ming-Yu\n  Liu, Min Sun", "title": "Tactics of Adversarial Attack on Deep Reinforcement Learning Agents", "comments": "To Appear at IJCAI 2017. Project website:\n  http://yenchenlin.me/adversarial_attack_RL/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two tactics to attack agents trained by deep reinforcement\nlearning algorithms using adversarial examples, namely the strategically-timed\nattack and the enchanting attack. In the strategically-timed attack, the\nadversary aims at minimizing the agent's reward by only attacking the agent at\na small subset of time steps in an episode. Limiting the attack activity to\nthis subset helps prevent detection of the attack by the agent. We propose a\nnovel method to determine when an adversarial example should be crafted and\napplied. In the enchanting attack, the adversary aims at luring the agent to a\ndesignated target state. This is achieved by combining a generative model and a\nplanning algorithm: while the generative model predicts the future states, the\nplanning algorithm generates a preferred sequence of actions for luring the\nagent. A sequence of adversarial examples is then crafted to lure the agent to\ntake the preferred sequence of actions. We apply the two tactics to the agents\ntrained by the state-of-the-art deep reinforcement learning algorithm including\nDQN and A3C. In 5 Atari games, our strategically timed attack reduces as much\nreward as the uniform attack (i.e., attacking at every time step) does by\nattacking the agent 4 times less often. Our enchanting attack lures the agent\ntoward designated target states with a more than 70% success rate. Videos are\navailable at http://yenchenlin.me/adversarial_attack_RL/\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 04:39:34 GMT"}, {"version": "v2", "created": "Mon, 1 May 2017 08:12:44 GMT"}, {"version": "v3", "created": "Tue, 23 May 2017 01:26:42 GMT"}, {"version": "v4", "created": "Wed, 13 Nov 2019 01:24:00 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Lin", "Yen-Chen", ""], ["Hong", "Zhang-Wei", ""], ["Liao", "Yuan-Hong", ""], ["Shih", "Meng-Li", ""], ["Liu", "Ming-Yu", ""], ["Sun", "Min", ""]]}, {"id": "1703.06811", "submitter": "Boris \\v{S}kori\\'c", "authors": "Taras Stanko and Boris Skoric", "title": "Minutia-pair spectral representations for fingerprint template\n  protection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new fixed-length representation of fingerprint minutiae, for\nuse in template protection. It is similar to the `spectral minutiae'\nrepresentation of Xu et al. but is based on coordinate differences between\npairs of minutiae. Our technique has the advantage that it does not discard the\nphase information of the spectral functions. We show that the fingerprint\nmatching performance (Equal Error Rate) is comparable to that of the original\nspectral minutiae representation, while the speed is improved.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 15:55:53 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Stanko", "Taras", ""], ["Skoric", "Boris", ""]]}, {"id": "1703.06986", "submitter": "Ahmad Moghimi", "authors": "Ahmad Moghimi and Gorka Irazoqui and Thomas Eisenbarth", "title": "CacheZoom: How SGX Amplifies The Power of Cache Attacks", "comments": "Accepted at Conference on Cryptographic Hardware and Embedded Systems\n  (CHES '17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern computing environments, hardware resources are commonly shared, and\nparallel computation is widely used. Parallel tasks can cause privacy and\nsecurity problems if proper isolation is not enforced. Intel proposed SGX to\ncreate a trusted execution environment within the processor. SGX relies on the\nhardware, and claims runtime protection even if the OS and other software\ncomponents are malicious. However, SGX disregards side-channel attacks. We\nintroduce a powerful cache side-channel attack that provides system adversaries\na high resolution channel. Our attack tool named CacheZoom is able to virtually\ntrack all memory accesses of SGX enclaves with high spatial and temporal\nprecision. As proof of concept, we demonstrate AES key recovery attacks on\ncommonly used implementations including those that were believed to be\nresistant in previous scenarios. Our results show that SGX cannot protect\ncritical data sensitive computations, and efficient AES key recovery is\npossible in a practical environment. In contrast to previous works which\nrequire hundreds of measurements, this is the first cache side-channel attack\non a real system that can recover AES keys with a minimal number of\nmeasurements. We can successfully recover AES keys from T-Table based\nimplementations with as few as ten measurements.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 22:12:10 GMT"}, {"version": "v2", "created": "Sun, 20 Aug 2017 21:20:04 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Moghimi", "Ahmad", ""], ["Irazoqui", "Gorka", ""], ["Eisenbarth", "Thomas", ""]]}, {"id": "1703.06992", "submitter": "AbdelRahman Abdou", "authors": "AbdelRahman Abdou, Paul C. van Oorschot, Tao Wan", "title": "A Framework and Comparative Analysis of Control Plane Security of SDN\n  and Conventional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software defined networking implements the network control plane in an\nexternal entity, rather than in each individual device as in conventional\nnetworks. This architectural difference implies a different design for control\nfunctions necessary for essential network properties, e.g., loop prevention and\nlink redundancy. We explore how such differences redefine the security\nweaknesses in the SDN control plane and provide a framework for comparative\nanalysis which focuses on essential network properties required by typical\nproduction networks. This enables analysis of how these properties are\ndelivered by the control planes of SDN and conventional networks, and to\ncompare security risks and mitigations. Despite the architectural difference,\nwe find similar, but not identical, exposures in control plane security if both\nnetwork paradigms provide the same network properties and are analyzed under\nthe same threat model. However, defenses vary; SDN cannot depend on edge based\nfiltering to protect its control plane, while this is arguably the primary\ndefense in conventional networks. Our concrete security analysis suggests that\na distributed SDN architecture that supports fault tolerance and consistency\nchecks is important for SDN control plane security. Our analysis methodology\nmay be of independent interest for future security analysis of SDN and\nconventional networks.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 22:49:21 GMT"}, {"version": "v2", "created": "Tue, 8 Aug 2017 01:09:52 GMT"}, {"version": "v3", "created": "Wed, 6 Dec 2017 13:17:22 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Abdou", "AbdelRahman", ""], ["van Oorschot", "Paul C.", ""], ["Wan", "Tao", ""]]}, {"id": "1703.07150", "submitter": "Stefano Bennati", "authors": "Stefano Bennati and Catholijn M. Jonker", "title": "PriMaL: A Privacy-Preserving Machine Learning Method for Event Detection\n  in Distributed Sensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces PriMaL, a general PRIvacy-preserving MAchine-Learning\nmethod for reducing the privacy cost of information transmitted through a\nnetwork. Distributed sensor networks are often used for automated\nclassification and detection of abnormal events in high-stakes situations, e.g.\nfire in buildings, earthquakes, or crowd disasters. Such networks might\ntransmit privacy-sensitive information, e.g. GPS location of smartphones, which\nmight be disclosed if the network is compromised. Privacy concerns might slow\ndown the adoption of the technology, in particular in the scenario of social\nsensing where participation is voluntary, thus solutions are needed which\nimprove privacy without compromising on the event detection accuracy. PriMaL is\nimplemented as a machine-learning layer that works on top of an existing event\ndetection algorithm. Experiments are run in a general simulation framework, for\nseveral network topologies and parameter values. The privacy footprint of\nstate-of-the-art event detection algorithms is compared within the proposed\nframework. Results show that PriMaL is able to reduce the privacy cost of a\ndistributed event detection algorithm below that of the corresponding\ncentralized algorithm, within the bounds of some assumptions about the\nprotocol. Moreover the performance of the distributed algorithm is not\nstatistically worse than that of the centralized algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 11:15:15 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Bennati", "Stefano", ""], ["Jonker", "Catholijn M.", ""]]}, {"id": "1703.07427", "submitter": "Chenglu Jin", "authors": "Raihan Sayeed Khan, Nadim Kanan, Chenglu Jin, Jake Scoggin, Nafisa\n  Noor, Sadid Muneer, Faruk Dirisaglik, Phuong Ha Nguyen, Helena Silva, Marten\n  van Dijk, Ali Gokirmak", "title": "Intrinsically Reliable and Lightweight Physical Obfuscated Keys", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical Obfuscated Keys (POKs) allow tamper-resistant storage of random keys\nbased on physical disorder. The output bits of current POK designs need to be\nfirst corrected due to measurement noise and next de-correlated since the\noriginal output bits may not be i.i.d. (independent and identically\ndistributed) and also public helper information for error correction\nnecessarily correlates the corrected output bits.For this reason, current\ndesigns include an interface for error correction and/or output reinforcement,\nand privacy amplification for compressing the corrected output to a uniform\nrandom bit string. We propose two intrinsically reliable POK designs with only\nXOR circuitry for privacy amplification (without need for reliability\nenhancement) by exploiting variability of lithographic process and variability\nof granularity in phase change memory (PCM) materials. The two designs are\ndemonstrated through experiments and simulations.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 21:00:01 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Khan", "Raihan Sayeed", ""], ["Kanan", "Nadim", ""], ["Jin", "Chenglu", ""], ["Scoggin", "Jake", ""], ["Noor", "Nafisa", ""], ["Muneer", "Sadid", ""], ["Dirisaglik", "Faruk", ""], ["Nguyen", "Phuong Ha", ""], ["Silva", "Helena", ""], ["van Dijk", "Marten", ""], ["Gokirmak", "Ali", ""]]}, {"id": "1703.07474", "submitter": "Genqiang Wu", "authors": "Genqiang Wu and Xianyao Xia and Yeping He", "title": "Achieving Dalenius' Goal of Data Privacy with Practical Assumptions", "comments": "50 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies show that differential privacy is vulnerable when different\nindividuals' data in the dataset are correlated, and that there are many cases\nwhere differential privacy implies poor utility. In order to treat the two\nweaknesses, we traced the origin of differential privacy to Dalenius' goal, a\nmore rigorous privacy measure. We formalized Dalenius' goal by using Shannon's\nperfect secrecy and tried to achieve Dalenius' goal with better utility. Our\nfirst result is that, if the independence assumption is true, then differential\nprivacy is equivalent to Dalenius' goal, where the independence assumption\nassumes that each adversary has no knowledge of the correlation among different\nindividuals' data in the dataset. This implies that the security of\ndifferential privacy is based on the independence assumption. Since the\nindependence assumption is impractical, we introduced a new practical\nassumption, which assumes that each adversary is unknown to some data of the\ndataset if the dataset is large enough. Based on the assumption, we can achieve\nDalenius' goal with better utility. Furthermore, we proved a useful result\nwhich can transplant results or approaches of information theory into data\nprivacy protection. We then proved that several basic privacy\nmechanisms/channels satisfy Dalenuis' goal, such as the random response, the\nexponential, and the Gaussian privacy channels, which are respective\ncounterparts of the random response, the exponential, and the Gaussian\nmechanisms of differential privacy. Moreover, the group and the composition\nproperties were also proved. Finally, by using Yao's computational information\ntheory, we extend our model to the computational-bounded case.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 00:03:30 GMT"}, {"version": "v2", "created": "Fri, 7 Apr 2017 09:41:23 GMT"}, {"version": "v3", "created": "Mon, 7 Aug 2017 16:20:23 GMT"}, {"version": "v4", "created": "Sun, 25 Feb 2018 16:18:33 GMT"}, {"version": "v5", "created": "Tue, 5 Jan 2021 15:15:27 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Wu", "Genqiang", ""], ["Xia", "Xianyao", ""], ["He", "Yeping", ""]]}, {"id": "1703.07499", "submitter": "Anibal Sanjab", "authors": "Walid Saad, Anibal Sanjab, Yunpeng Wang, Charles Kamhoua, Kevin Kwiat", "title": "Hardware Trojan Detection Game: A Prospect-Theoretic Approach", "comments": "IEEE Transactions on Vehicular Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.GT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outsourcing integrated circuit (IC) manufacturing to offshore foundries has\ngrown exponentially in recent years. Given the critical role of ICs in the\ncontrol and operation of vehicular systems and other modern engineering\ndesigns, such offshore outsourcing has led to serious security threats due to\nthe potential of insertion of hardware trojans - malicious designs that, when\nactivated, can lead to highly detrimental consequences. In this paper, a novel\ngame-theoretic framework is proposed to analyze the interactions between a\nhardware manufacturer, acting as attacker, and an IC testing facility, acting\nas defender. The problem is formulated as a noncooperative game in which the\nattacker must decide on the type of trojan that it inserts while taking into\naccount the detection penalty as well as the damage caused by the trojan.\nMeanwhile, the resource-constrained defender must decide on the best testing\nstrategy that allows optimizing its overall utility which accounts for both\ndamages and the fines. The proposed game is based on the robust behavioral\nframework of prospect theory (PT) which allows capturing the potential\nuncertainty, risk, and irrational behavior in the decision making of both the\nattacker and defender. For both, the standard rational expected utility (EUT)\ncase and the PT case, a novel algorithm based on fictitious play is proposed\nand shown to converge to a mixed-strategy Nash equilibrium. For an illustrative\ncase study, thorough analytical results are derived for both EUT and PT to\nstudy the properties of the reached equilibrium as well as the impact of key\nsystem parameters such as the defender-set fine. Simulation results assess the\nperformance of the proposed framework under both EUT and PT and show that the\nuse of PT will provide invaluable insights on the outcomes of the proposed\nhardware trojan game, in particular, and system security, in general.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 02:57:19 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Saad", "Walid", ""], ["Sanjab", "Anibal", ""], ["Wang", "Yunpeng", ""], ["Kamhoua", "Charles", ""], ["Kwiat", "Kevin", ""]]}, {"id": "1703.07544", "submitter": "Ayan Mahalanobis", "authors": "Ayan Mahalanobis and Vivek Mallick", "title": "A Las Vegas algorithm to solve the elliptic curve discrete logarithm\n  problem", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.22661.86249", "report-no": null, "categories": "cs.CR cs.IT math.AG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a new Las Vegas algorithm to solve the elliptic\ncurve discrete logarithm problem. The algorithm depends on a property of the\ngroup of rational points of an elliptic curve and is thus not a generic\nalgorithm. The algorithm that we describe has some similarities with the most\npowerful index-calculus algorithm for the discrete logarithm problem over a\nfinite field.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 07:03:29 GMT"}, {"version": "v2", "created": "Tue, 3 Oct 2017 11:09:59 GMT"}, {"version": "v3", "created": "Mon, 5 Feb 2018 10:27:33 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Mahalanobis", "Ayan", ""], ["Mallick", "Vivek", ""]]}, {"id": "1703.07578", "submitter": "Doli\\`ere Francis Som\\'e", "authors": "Doli\\`ere Francis Som\\'e, Nataliia Bielova and Tamara Rezk", "title": "Control What You Include! Server-Side Protection against Third Party Web\n  Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Third party tracking is the practice by which third parties recognize users\naccross different websites as they browse the web. Recent studies show that 90%\nof websites contain third party content that is tracking its users across the\nweb. Website developers often need to include third party content in order to\nprovide basic functionality. However, when a developer includes a third party\ncontent, she cannot know whether the third party contains tracking mechanisms.\nIf a website developer wants to protect her users from being tracked, the only\nsolution is to exclude any third-party content, thus trading functionality for\nprivacy. We describe and implement a privacy-preserving web architecture that\ngives website developers a control over third party tracking: developers are\nable to include functionally useful third party content, the same time ensuring\nthat the end users are not tracked by the third parties.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 09:23:54 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Som\u00e9", "Doli\u00e8re Francis", ""], ["Bielova", "Nataliia", ""], ["Rezk", "Tamara", ""]]}, {"id": "1703.07706", "submitter": "Zelalem Aweke", "authors": "Zelalem Birhanu Aweke, Todd Austin", "title": "Ozone: Efficient Execution with Zero Timing Leakage for Modern\n  Microarchitectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time variation during program execution can leak sensitive information. Time\nvariations due to program control flow and hardware resource contention have\nbeen used to steal encryption keys in cipher implementations such as AES and\nRSA. A number of approaches to mitigate timing-based side-channel attacks have\nbeen proposed including cache partitioning, control-flow obfuscation and\ninjecting timing noise into the outputs of code. While these techniques make\ntiming-based side-channel attacks more difficult, they do not eliminate the\nrisks. Prior techniques are either too specific or too expensive, and all leave\nremnants of the original timing side channel for later attackers to attempt to\nexploit.\n  In this work, we show that the state-of-the-art techniques in timing\nside-channel protection, which limit timing leakage but do not eliminate it,\nstill have significant vulnerabilities to timing-based side-channel attacks. To\nprovide a means for total protection from timing-based side-channel attacks, we\ndevelop Ozone, the first zero timing leakage execution resource for a modern\nmicroarchitecture. Code in Ozone execute under a special hardware thread that\ngains exclusive access to a single core's resources for a fixed (and limited)\nnumber of cycles during which it cannot be interrupted. Memory access under\nOzone thread execution is limited to a fixed size uncached scratchpad memory,\nand all Ozone threads begin execution with a known fixed microarchitectural\nstate. We evaluate Ozone using a number of security sensitive kernels that have\npreviously been targets of timing side-channel attacks, and show that Ozone\neliminates timing leakage with minimal performance overhead.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 19:53:26 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Aweke", "Zelalem Birhanu", ""], ["Austin", "Todd", ""]]}, {"id": "1703.07751", "submitter": "Ben Nassi", "authors": "Ben Nassi, Adi Shamir, Yuval Elovici", "title": "Oops!...I think I scanned a malware", "comments": "Cyber-Security, Covert Channel, Data Infiltration, Scanner", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This article presents a proof-of-concept illustrating the feasibility of\ncreating a covert channel between a C\\&C server and a malware installed in an\norganization by exploiting an organization's scanner and using it as a means of\ninteraction. We take advantage of the light sensitivity of a flatbed scanner,\nusing a light source to infiltrate data to an organization. We present an\nimplementation of the method for different purposes (even to trigger a\nransomware attack) in various experimental setups using: (1) a laser connected\nto a stand (2) a laser carried by a drone, and (3) a hijacked smart bulb within\nthe targeted organization from a passing car. In our experiments we were able\nto infiltrate data using different types of light sources (including infrared\nlight), from a distance of up to 900 meters away from the scanner. We discuss\npotential counter measures to prevent the attack.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 17:12:20 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Nassi", "Ben", ""], ["Shamir", "Adi", ""], ["Elovici", "Yuval", ""]]}, {"id": "1703.07909", "submitter": "Tegjyot Singh Sethi", "authors": "Tegjyot Singh Sethi, Mehmed Kantardzic", "title": "Data Driven Exploratory Attacks on Black Box Classifiers in Adversarial\n  Domains", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2018.02.007", "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While modern day web applications aim to create impact at the civilization\nlevel, they have become vulnerable to adversarial activity, where the next\ncyber-attack can take any shape and can originate from anywhere. The increasing\nscale and sophistication of attacks, has prompted the need for a data driven\nsolution, with machine learning forming the core of many cybersecurity systems.\nMachine learning was not designed with security in mind, and the essential\nassumption of stationarity, requiring that the training and testing data follow\nsimilar distributions, is violated in an adversarial domain. In this paper, an\nadversary's view point of a classification based system, is presented. Based on\na formal adversarial model, the Seed-Explore-Exploit framework is presented,\nfor simulating the generation of data driven and reverse engineering attacks on\nclassifiers. Experimental evaluation, on 10 real world datasets and using the\nGoogle Cloud Prediction Platform, demonstrates the innate vulnerability of\nclassifiers and the ease with which evasion can be carried out, without any\nexplicit information about the classifier type, the training data or the\napplication domain. The proposed framework, algorithms and empirical\nevaluation, serve as a white hat analysis of the vulnerabilities, and aim to\nfoster the development of secure machine learning frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 02:40:36 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Sethi", "Tegjyot Singh", ""], ["Kantardzic", "Mehmed", ""]]}, {"id": "1703.07949", "submitter": "Joshua Joy", "authors": "Joshua Joy, Mario Gerla", "title": "Anonymized Local Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the family of Anonymized Local Privacy\nmechanisms. These mechanisms have an output space of three values \"Yes\", \"No\",\nor \"$\\perp$\" (not participating) and leverage the law of large numbers to\ngenerate linear noise in the number of data owners to protect privacy both\nbefore and after aggregation yet preserve accuracy.\n  We describe the suitability in a distributed on-demand network and evaluate\nover a real dataset as we scale the population.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 07:15:55 GMT"}, {"version": "v2", "created": "Wed, 29 Mar 2017 08:02:36 GMT"}, {"version": "v3", "created": "Tue, 4 Apr 2017 01:40:22 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Joy", "Joshua", ""], ["Gerla", "Mario", ""]]}, {"id": "1703.08151", "submitter": "Faye Bernadette", "authors": "Bernadette Faye", "title": "Extracting a uniform random bit-string over Jacobian of Hyperelliptic\n  curves of Genus $2$", "comments": "11 pages, Comments are welcome!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here, we proposed an improved version of the deterministic random extractors\n$SEJ$ and $PEJ$ proposed by R. R. Farashahi in \\cite{F} in 2009. By using the\nMumford's representation of a reduced divisor $D$ of the Jacobian\n$J(\\mathbb{F}_q)$ of a hyperelliptic curve $\\mathcal{H}$ of genus $2$ with odd\ncharacteristic, we extract a perfectly random bit string of the sum of\nabscissas of rational points on $\\mathcal{H}$ in the support of $D$. By this\nnew approach, we reduce in an elementary way the upper bound of the statistical\ndistance of the deterministic randomness extractors defined over $\\mathbb{F}_q$\nwhere $q=p^n$, for some positive integer $n\\geq 1$ and $p$ an odd prime.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 17:29:10 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Faye", "Bernadette", ""]]}, {"id": "1703.08269", "submitter": "Shiyu Ji", "authors": "Shiyu Ji, Kun Wan", "title": "k-Anonymously Private Search over Encrypted Data", "comments": "7 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we compare the performance of various homomorphic encryption\nmethods on a private search scheme that can achieve $k$-anonymity privacy. To\nmake our benchmarking fair, we use open sourced cryptographic libraries which\nare written by experts and well scrutinized. We find that Goldwasser-Micali\nencryption achieves good enough performance for practical use, whereas fully\nhomomorphic encryptions are much slower than partial ones like\nGoldwasser-Micali and Paillier.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 02:50:08 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Ji", "Shiyu", ""], ["Wan", "Kun", ""]]}, {"id": "1703.08306", "submitter": "Kwangsu Lee", "authors": "Kwangsu Lee", "title": "Permutation Generators Based on Unbalanced Feistel Network: Analysis of\n  the Conditions of Pseudorandomness", "comments": "MS Thesis, Korea Advanced Institute of Science and Technology,\n  February 2000", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A block cipher is a bijective function that transforms a plaintext to a\nciphertext. A block cipher is a principle component in a cryptosystem because\nthe security of a cryptosystem depends on the security of a block cipher. A\nFeistel network is the most widely used method to construct a block cipher.\nThis structure has a property such that it can transform a function to a\nbijective function. But the previous Feistel network is unsuitable to construct\nblock ciphers that have large input-output size. One way to construct block\nciphers with large input-output size is to use an unbalanced Feistel network\nthat is the generalization of a previous Feistel network. There have been\nlittle research on unbalanced Feistel networks and previous work was about some\nparticular structures of unbalanced Feistel networks. So previous work didn't\nprovide a theoretical base to construct block ciphers that are secure and\nefficient using unbalanced Feistel networks.\n  In this thesis, we analyze the minimal number of rounds of pseudo-random\npermutation generators that use unbalanced Feistel networks. That is, after\ncategorizing unbalanced Feistel networks as source-heavy structures and\ntarget-heavy structures, we analyze the minimal number of rounds of\npseudo-random permutation generators that use each structure. Therefore, in\norder to construct a block cipher that is secure and efficient using unbalanced\nFeistel networks, we should follow the results of this thesis. Additionally, we\npropose a new unbalanced Feistel network that has some advantages such that it\ncan extend a previous block cipher with small input-output size to a new block\ncipher with large input-output size. We also analyze the minimum number of\nrounds of a pseudo-random permutation generator that uses this structure.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 08:06:21 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Lee", "Kwangsu", ""]]}, {"id": "1703.08455", "submitter": "Bogdan Carbunar", "authors": "Mahmudur Rahman, Bogdan Carbunar, Umut Topkara", "title": "Secure Management of Low Power Fitness Trackers", "comments": null, "journal-ref": "IEEE Transactions on Mobile Computing Volume: 15, Issue: 2, Feb. 1\n  2016", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing popular interest in personal telemetry, also called the\nQuantified Self or \"lifelogging\", has induced a popularity surge for wearable\npersonal fitness trackers. Fitness trackers automatically collect sensor data\nabout the user throughout the day, and integrate it into social network\naccounts. Solution providers have to strike a balance between many constraints,\nleading to a design process that often puts security in the back seat. Case in\npoint, we reverse engineered and identified security vulnerabilities in Fitbit\nUltra and Gammon Forerunner 610, two popular and representative fitness tracker\nproducts. We introduce FitBite and GarMax, tools to launch efficient attacks\nagainst Fitbit and Garmin.\n  We devise SensCrypt, a protocol for secure data storage and communication,\nfor use by makers of affordable and lightweight personal trackers. SensCrypt\nthwarts not only the attacks we introduced, but also defends against powerful\nJTAG Read attacks. We have built Sens.io, an Arduino Uno based tracker\nplatform, of similar capabilities but at a fraction of the cost of current\nsolutions. On Sens.io, SensCrypt imposes a negligible write overhead and\nsignificantly reduces the end-to-end sync overhead of Fitbit and Garmin.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 15:16:26 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Rahman", "Mahmudur", ""], ["Carbunar", "Bogdan", ""], ["Topkara", "Umut", ""]]}, {"id": "1703.08630", "submitter": "Pedro Hecht", "authors": "Pedro Hecht", "title": "Post-Quantum Cryptography: A Zero-Knowledge Authentication Protocol", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a simple bare-bones solution of a Zero-Knowledge\nauthentication protocol which uses non-commutative algebra and a variation of\nthe generalized symmetric decomposition problem (GSDP) as a one-way function.\nThe cryptographic security is assured as long the GSDP problem is\ncomputationally hard to solve in non-commutative algebraic structures and\nbelongs currently to the PQC category as no quantum computer attack is likely\nto exists.\n", "versions": [{"version": "v1", "created": "Sat, 25 Mar 2017 00:09:14 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Hecht", "Pedro", ""]]}, {"id": "1703.08761", "submitter": "Giulia Fanti", "authors": "Giulia Fanti and Pramod Viswanath", "title": "Anonymity Properties of the Bitcoin P2P Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin is a popular alternative to fiat money, widely used for its perceived\nanonymity properties. However, recent attacks on Bitcoin's peer-to-peer (P2P)\nnetwork demonstrated that its gossip-based flooding protocols, which are used\nto ensure global network consistency, may enable user deanonymization---the\nlinkage of a user's IP address with her pseudonym in the Bitcoin network. In\n2015, the Bitcoin community responded to these attacks by changing the\nnetwork's flooding mechanism to a different protocol, known as diffusion.\nHowever, no systematic justification was provided for the change, and it is\nunclear if diffusion actually improves the system's anonymity. In this paper,\nwe model the Bitcoin networking stack and analyze its anonymity properties,\nboth pre- and post-2015. In doing so, we consider new adversarial models and\nspreading mechanisms that have not been previously studied in the\nsource-finding literature. We theoretically prove that Bitcoin's networking\nprotocols (both pre- and post-2015) offer poor anonymity properties on networks\nwith a regular-tree topology. We validate this claim in simulation on a 2015\nsnapshot of the real Bitcoin P2P network topology.\n", "versions": [{"version": "v1", "created": "Sun, 26 Mar 2017 03:47:26 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Fanti", "Giulia", ""], ["Viswanath", "Pramod", ""]]}, {"id": "1703.08859", "submitter": "Alan Sherman", "authors": "Alan Sherman (UMBC) and M. Dark (Purdue) and A. Chan (Northeastern)\n  and R. Chong (Purdue) and T. Morris (UAH) and L. Oliva (UMBC) and J. Springer\n  (Purdue) and B. Thuraisingham (UTD) and C. Vatcher (UMBC) and R. Verma\n  (Houston) and S. Wetzel (Stevens)", "title": "The INSuRE Project: CAE-Rs Collaborate to Engage Students in\n  Cybersecurity Research", "comments": "A shorter version of this paper has been submitted to IEEE Security\n  and Privacy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since fall 2012, several National Centers of Academic Excellence in Cyber\nDefense Research (CAE-Rs) fielded a collaborative course to engage students in\nsolving applied cybersecurity research problems. We describe our experiences\nwith this Information Security Research and Education (INSuRE) research\ncollaborative. We explain how we conducted our project-based research course,\ngive examples of student projects, and discuss the outcomes and lessons\nlearned.\n", "versions": [{"version": "v1", "created": "Sun, 26 Mar 2017 18:30:06 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Sherman", "Alan", "", "UMBC"], ["Dark", "M.", "", "Purdue"], ["Chan", "A.", "", "Northeastern"], ["Chong", "R.", "", "Purdue"], ["Morris", "T.", "", "UAH"], ["Oliva", "L.", "", "UMBC"], ["Springer", "J.", "", "Purdue"], ["Thuraisingham", "B.", "", "UTD"], ["Vatcher", "C.", "", "UMBC"], ["Verma", "R.", "", "Houston"], ["Wetzel", "S.", "", "Stevens"]]}, {"id": "1703.09028", "submitter": "Xinzhe Fu", "authors": "Luoyi Fu, Xinzhe Fu, Zhongzhao Hu, Zhiying Xu, Xinbing Wang", "title": "De-anonymization of Social Networks with Communities: When\n  Quantifications Meet Algorithms", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A crucial privacy-driven issue nowadays is re-identifying anonymized social\nnetworks by mapping them to correlated cross-domain auxiliary networks. Prior\nworks are typically based on modeling social networks as random graphs\nrepresenting users and their relations, and subsequently quantify the quality\nof mappings through cost functions that are proposed without sufficient\nrationale. Also, it remains unknown how to algorithmically meet the demand of\nsuch quantifications, i.e., to find the minimizer of the cost functions. We\naddress those concerns in a more realistic social network modeling\nparameterized by community structures that can be leveraged as side information\nfor de-anonymization. By Maximum A Posteriori (MAP) estimation, our first\ncontribution is new and well justified cost functions, which, when minimized,\nenjoy superiority to previous ones in finding the correct mapping with the\nhighest probability. The feasibility of the cost functions is then for the\nfirst time algorithmically characterized. While proving the general\nmultiplicative inapproximability, we are able to propose two algorithms, which,\nrespectively, enjoy an \\epsilon-additive approximation and a conditional\noptimality in carrying out successful user re-identification. Our theoretical\nfindings are empirically validated, with a notable dataset extracted from rare\ntrue cross-domain networks that reproduce genuine social network\nde-anonymization. Both theoretical and empirical observations also manifest the\nimportance of community information in enhancing privacy inferencing.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 12:17:35 GMT"}, {"version": "v2", "created": "Tue, 28 Mar 2017 11:18:20 GMT"}, {"version": "v3", "created": "Thu, 27 Jul 2017 03:30:04 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Fu", "Luoyi", ""], ["Fu", "Xinzhe", ""], ["Hu", "Zhongzhao", ""], ["Xu", "Zhiying", ""], ["Wang", "Xinbing", ""]]}, {"id": "1703.09080", "submitter": "Irene Villa", "authors": "Irene Villa", "title": "On Some Properties of Quadratic APN Functions of a Special Form", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper, it is shown that functions of the form\n$L_1(x^3)+L_2(x^9)$, where $L_1$ and $L_2$ are linear, are a good source for\nconstruction of new infinite families of APN functions. In the present work we\nstudy necessary and sufficient conditions for such functions to be APN.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 13:53:33 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 11:21:20 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Villa", "Irene", ""]]}, {"id": "1703.09244", "submitter": "Benedetta Tondi", "authors": "Mauro Barni and Benedetta Tondi", "title": "Adversarial Source Identification Game with Corrupted Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a variant of the source identification game with training data in\nwhich part of the training data is corrupted by an attacker. In the addressed\nscenario, the defender aims at deciding whether a test sequence has been drawn\naccording to a discrete memoryless source $X \\sim P_X$, whose statistics are\nknown to him through the observation of a training sequence generated by $X$.\nIn order to undermine the correct decision under the alternative hypothesis\nthat the test sequence has not been drawn from $X$, the attacker can modify a\nsequence produced by a source $Y \\sim P_Y$ up to a certain distortion, and\ncorrupt the training sequence either by adding some fake samples or by\nreplacing some samples with fake ones. We derive the unique rationalizable\nequilibrium of the two versions of the game in the asymptotic regime and by\nassuming that the defender bases its decision by relying only on the first\norder statistics of the test and the training sequences. By mimicking Stein's\nlemma, we derive the best achievable performance for the defender when the\nfirst type error probability is required to tend to zero exponentially fast\nwith an arbitrarily small, yet positive, error exponent. We then use such a\nresult to analyze the ultimate distinguishability of any two sources as a\nfunction of the allowed distortion and the fraction of corrupted samples\ninjected into the training sequence.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 18:07:32 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Barni", "Mauro", ""], ["Tondi", "Benedetta", ""]]}, {"id": "1703.09308", "submitter": "Susumu Shinohara", "authors": "Susumu Shinohara, Kenichi Arai, Peter Davis, Satoshi Sunada, and\n  Takahisa Harayama", "title": "Chaotic laser based physical random bit streaming system with a computer\n  application interface", "comments": "12 pages, 8 figures", "journal-ref": "Optics Express, Vol. 25, No. 6, pp. 6461-6474 (2017)", "doi": "10.1364/OE.25.006461", "report-no": null, "categories": "physics.ins-det cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate a random bit streaming system that uses a chaotic laser as its\nphysical entropy source. By performing real-time bit manipulation for bias\nreduction, we were able to provide the memory of a personal computer with a\nconstant supply of ready-to-use physical random bits at a throughput of up to 4\nGbps. We pay special attention to the end-to-end entropy source model\ndescribing how the entropy from physical sources is converted into bit entropy.\nWe confirmed the statistical quality of the generated random bits by revealing\nthe pass rate of the NIST SP800-22 test suite to be 65 % to 75 %, which is\ncommonly considered acceptable for a reliable random bit generator. We also\nconfirmed the stable operation of our random bit steaming system with long-term\nbias monitoring.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 00:08:35 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Shinohara", "Susumu", ""], ["Arai", "Kenichi", ""], ["Davis", "Peter", ""], ["Sunada", "Satoshi", ""], ["Harayama", "Takahisa", ""]]}, {"id": "1703.09364", "submitter": "Minghao Ruan", "authors": "Minghao Ruan, Muaz Ahmad, and Yongqiang Wang", "title": "Secure and Privacy-Preserving Average Consensus", "comments": "7 pages, 4 figures, paper is accepted to CPS-SPC'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Average consensus is fundamental for distributed systems since it underpins\nkey functionalities of such systems ranging from distributed information\nfusion, decision-making, to decentralized control. In order to reach an\nagreement, existing average consensus algorithms require each agent to exchange\nexplicit state information with its neighbors. This leads to the disclosure of\nprivate state information, which is undesirable in cases where privacy is of\nconcern. In this paper, we propose a novel approach that enables secure and\nprivacy-preserving average consensus in a decentralized architecture in the\nabsence of any trusted third-parties. By leveraging homomorphic cryptography,\nour approach can guarantee consensus to the exact value in a deterministic\nmanner. The proposed approach is light-weight in computation and communication,\nand applicable to time-varying interaction topology cases. A hardware\nimplementation is presented to demonstrate the capability of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 01:20:39 GMT"}, {"version": "v2", "created": "Tue, 19 Sep 2017 18:35:02 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Ruan", "Minghao", ""], ["Ahmad", "Muaz", ""], ["Wang", "Yongqiang", ""]]}, {"id": "1703.09471", "submitter": "Seong Joon Oh", "authors": "Seong Joon Oh, Mario Fritz, Bernt Schiele", "title": "Adversarial Image Perturbation for Privacy Protection -- A Game Theory\n  Perspective", "comments": "To appear at ICCV'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users like sharing personal photos with others through social media. At the\nsame time, they might want to make automatic identification in such photos\ndifficult or even impossible. Classic obfuscation methods such as blurring are\nnot only unpleasant but also not as effective as one would expect. Recent\nstudies on adversarial image perturbations (AIP) suggest that it is possible to\nconfuse recognition systems effectively without unpleasant artifacts. However,\nin the presence of counter measures against AIPs, it is unclear how effective\nAIP would be in particular when the choice of counter measure is unknown. Game\ntheory provides tools for studying the interaction between agents with\nuncertainties in the strategies. We introduce a general game theoretical\nframework for the user-recogniser dynamics, and present a case study that\ninvolves current state of the art AIP and person recognition techniques. We\nderive the optimal strategy for the user that assures an upper bound on the\nrecognition rate independent of the recogniser's counter measure. Code is\navailable at https://goo.gl/hgvbNK.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 09:17:47 GMT"}, {"version": "v2", "created": "Wed, 26 Jul 2017 10:01:43 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Oh", "Seong Joon", ""], ["Fritz", "Mario", ""], ["Schiele", "Bernt", ""]]}, {"id": "1703.09501", "submitter": "Mohsin Ali Khan Md. Mohsin Ali Khan", "authors": "Mohsin Khan and Valtteri Niemi", "title": "AES and SNOW 3G are Feasible Choices for a 5G Phone from Energy\n  Perspective", "comments": "Accepted in the mentioned conference", "journal-ref": "The 1st EAI International Conference on 5G for Future Wireless\n  Networks, 5GWN 2017", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aspirations for a 5th generation (5G) mobile network are high. It has a\nvision of unprecedented data-rate and extremely pervasive connectivity. To\ncater such aspirations in a mobile phone, many existing efficiency aspects of a\nmobile phone need to be reviewed. We look into the matter of required energy to\nencrypt and decrypt the huge amount of traffic that will leave from and enter\ninto a 5G enabled mobile phone. In this paper, we present an account of the\npower consumption details of the efficient hardware implementations of AES and\nSNOW 3G. We also present an account of the power consumption details of LTE\nprotocol stack on some cutting edge hardware platforms. Based on the\naforementioned two accounts, we argue that the energy requirement for the\ncurrent encryption systems AES and SNOW 3G will not impact the battery-life of\na 5G enabled mobile phone by any significant proportion.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 10:39:22 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Khan", "Mohsin", ""], ["Niemi", "Valtteri", ""]]}, {"id": "1703.09745", "submitter": "Samuel Marchal", "authors": "Radek Tomsu, Samuel Marchal, N. Asokan", "title": "Profiling Users by Modeling Web Transactions", "comments": "Extended technical report of an IEEE ICDCS 2017 publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users of electronic devices, e.g., laptop, smartphone, etc. have\ncharacteristic behaviors while surfing the Web. Profiling this behavior can\nhelp identify the person using a given device. In this paper, we introduce a\ntechnique to profile users based on their web transactions. We compute several\nfeatures extracted from a sequence of web transactions and use them with\none-class classification techniques to profile a user. We assess the efficacy\nand speed of our method at differentiating 25 users on a dataset representing 6\nmonths of web traffic monitoring from a small company network.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 18:54:15 GMT"}, {"version": "v2", "created": "Mon, 3 Apr 2017 10:56:49 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Tomsu", "Radek", ""], ["Marchal", "Samuel", ""], ["Asokan", "N.", ""]]}, {"id": "1703.09752", "submitter": "Nhien-An Le-Khac", "authors": "Loic Bontemps, Van Loi Cao, James McDermott, Nhien-An Le-Khac", "title": "Collective Anomaly Detection based on Long Short Term Memory Recurrent\n  Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrusion detection for computer network systems becomes one of the most\ncritical tasks for network administrators today. It has an important role for\norganizations, governments and our society due to its valuable resources on\ncomputer networks. Traditional misuse detection strategies are unable to detect\nnew and unknown intrusion. Besides, anomaly detection in network security is\naim to distinguish between illegal or malicious events and normal behavior of\nnetwork systems. Anomaly detection can be considered as a classification\nproblem where it builds models of normal network behavior, which it uses to\ndetect new patterns that significantly deviate from the model. Most of the cur-\nrent research on anomaly detection is based on the learning of normally and\nanomaly behaviors. They do not take into account the previous, re- cent events\nto detect the new incoming one. In this paper, we propose a real time\ncollective anomaly detection model based on neural network learning and feature\noperating. Normally a Long Short Term Memory Recurrent Neural Network (LSTM\nRNN) is trained only on normal data and it is capable of predicting several\ntime steps ahead of an input. In our approach, a LSTM RNN is trained with\nnormal time series data before performing a live prediction for each time step.\nInstead of considering each time step separately, the observation of prediction\nerrors from a certain number of time steps is now proposed as a new idea for\ndetecting collective anomalies. The prediction errors from a number of the\nlatest time steps above a threshold will indicate a collective anomaly. The\nmodel is built on a time series version of the KDD 1999 dataset. The\nexperiments demonstrate that it is possible to offer reliable and efficient for\ncollective anomaly detection.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 19:04:11 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Bontemps", "Loic", ""], ["Cao", "Van Loi", ""], ["McDermott", "James", ""], ["Le-Khac", "Nhien-An", ""]]}, {"id": "1703.09763", "submitter": "Andreas Zankl", "authors": "Marc Green, Leandro Rodrigues-Lima, Andreas Zankl, Gorka Irazoqui,\n  Johann Heyszl, Thomas Eisenbarth", "title": "AutoLock: Why Cache Attacks on ARM Are Harder Than You Think", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attacks on the microarchitecture of modern processors have become a practical\nthreat to security and privacy in desktop and cloud computing. Recently, cache\nattacks have successfully been demonstrated on ARM based mobile devices,\nsuggesting they are as vulnerable as their desktop or server counterparts. In\nthis work, we show that previous literature might have left an overly\npessimistic conclusion of ARM's security as we unveil AutoLock: an internal\nperformance enhancement found in inclusive cache levels of ARM processors that\nadversely affects Evict+Time, Prime+Probe, and Evict+Reload attacks. AutoLock's\npresence on system-on-chips (SoCs) is not publicly documented, yet knowing that\nit is implemented is vital to correctly assess the risk of cache attacks. We\ntherefore provide a detailed description of the feature and propose three ways\nto detect its presence on actual SoCs. We illustrate how AutoLock impedes\ncross-core cache evictions, but show that its effect can also be compensated in\na practical attack. Our findings highlight the intricacies of cache attacks on\nARM and suggest that a fair and comprehensive vulnerability assessment requires\nan in-depth understanding of ARM's cache architectures and rigorous testing\nacross a broad range of ARM based devices.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 19:31:08 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Green", "Marc", ""], ["Rodrigues-Lima", "Leandro", ""], ["Zankl", "Andreas", ""], ["Irazoqui", "Gorka", ""], ["Heyszl", "Johann", ""], ["Eisenbarth", "Thomas", ""]]}, {"id": "1703.09809", "submitter": "Nan Zhang", "authors": "Nan Zhang, Soteris Demetriou, Xianghang Mi, Wenrui Diao, Kan Yuan,\n  Peiyuan Zong, Feng Qian, XiaoFeng Wang, Kai Chen, Yuan Tian, Carl A. Gunter,\n  Kehuan Zhang, Patrick Tague and Yue-Hsun Lin", "title": "Understanding IoT Security Through the Data Crystal Ball: Where We Are\n  Now and Where We Are Going to Be", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the boom of the consumer IoT market, many device manufacturers,\nstart-up companies and technology giants have jumped into the space.\nUnfortunately, the exciting utility and rapid marketization of IoT, come at the\nexpense of privacy and security. Industry reports and academic work have\nrevealed many attacks on IoT systems, resulting in privacy leakage, property\nloss and large-scale availability problems. To mitigate such threats, a few\nsolutions have been proposed. However, it is still less clear what are the\nimpacts they can have on the IoT ecosystem. In this work, we aim to perform a\ncomprehensive study on reported attacks and defenses in the realm of IoT aiming\nto find out what we know, where the current studies fall short and how to move\nforward. To this end, we first build a toolkit that searches through massive\namount of online data using semantic analysis to identify over 3000 IoT-related\narticles. Further, by clustering such collected data using machine learning\ntechnologies, we are able to compare academic views with the findings from\nindustry and other sources, in an attempt to understand the gaps between them,\nthe trend of the IoT security risks and new problems that need further\nattention. We systemize this process, by proposing a taxonomy for the IoT\necosystem and organizing IoT security into five problem areas. We use this\ntaxonomy as a beacon to assess each IoT work across a number of properties we\ndefine. Our assessment reveals that relevant security and privacy problems are\nfar from solved. We discuss how each proposed solution can be applied to a\nproblem area and highlight their strengths, assumptions and constraints. We\nstress the need for a security framework for IoT vendors and discuss the trend\nof shifting security liability to external or centralized entities. We also\nidentify open research problems and provide suggestions towards a secure IoT\necosystem.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 21:22:02 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Zhang", "Nan", ""], ["Demetriou", "Soteris", ""], ["Mi", "Xianghang", ""], ["Diao", "Wenrui", ""], ["Yuan", "Kan", ""], ["Zong", "Peiyuan", ""], ["Qian", "Feng", ""], ["Wang", "XiaoFeng", ""], ["Chen", "Kai", ""], ["Tian", "Yuan", ""], ["Gunter", "Carl A.", ""], ["Zhang", "Kehuan", ""], ["Tague", "Patrick", ""], ["Lin", "Yue-Hsun", ""]]}, {"id": "1703.09827", "submitter": "Nhien-An Le-Khac", "authors": "Lionel Prat, Nhien-An Le-Khac, Cheryl Baker", "title": "MapExif: an image scanning and mapping tool for investigators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the integration of geographical coordinates into a picture has\nbecome more and more popular. Indeed almost all smartphones and many cameras\ntoday have a built-in GPS receiver that stores the location information in the\nExif header when a picture is taken. Although the automatic embedding of\ngeotags in pictures is often ignored by smart phone users as it can lead to\nendless discussions about privacy implications, these geotags could be really\nuseful for investigators in analysing criminal activity. Currently, there are\nmany free tools as well as commercial tools available in the market that can\nhelp computer forensics investigators to cover a wide range of geographic\ninformation related to criminal scenes or activities. However, there are not\nspecific forensic tools available to deal with the geolocation of pictures\ntaken by smart phones or cameras. In this paper, we propose and develop an\nimage scanning and mapping tool for investigators. This tool scans all the\nfiles in a given directory and then displays particular photos based on\noptional filters (date, time, device, localisation) on Google Map. The file\nscanning process is not based on the file extension but its header. This tool\ncan also show efficiently to users if there is more than one image on the map\nwith the same GPS coordinates, or even if there are images with no GPS\ncoordinates taken by the same device in the same timeline. Moreover, this new\ntool is portable; investigators can run it on any operating system without any\ninstallation. Another useful feature is to be able to work in a read-only\nenvironment, so that forensic results will not be modified. We also present and\nevaluate this tool real world application in this paper.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 22:15:01 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Prat", "Lionel", ""], ["Le-Khac", "Nhien-An", ""], ["Baker", "Cheryl", ""]]}, {"id": "1703.09846", "submitter": "Nalin Asanka Gamagedara Arachchilage", "authors": "Chamila Wijayarathna, Nalin A.G. Arachchilage, and Jill Slay", "title": "A Generic Cognitive Dimensions Questionnaire to Evaluate the Usability\n  of Security APIs", "comments": "14 pages, 19th International Conference on Human-Computer Interaction\n  (HCII)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programmers use security APIs to embed security into the applications they\ndevelop. Security vulnerabilities get introduced into those applications, due\nto the usability issues that exist in the security APIs. Improving usability of\nsecurity APIs would contribute to improve the security of applications that\nprogrammers develop. However, currently there is no methodology to evaluate the\nusability of security APIs. In this study, we attempt to improve the Cognitive\nDimensions framework based API usability evaluation methodology, to evaluate\nthe usability of security APIs.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 00:25:44 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Wijayarathna", "Chamila", ""], ["Arachchilage", "Nalin A. G.", ""], ["Slay", "Jill", ""]]}, {"id": "1703.09847", "submitter": "Awanthika Senarath", "authors": "Awanthika Senarath, Nalin A.G. Arachchilage, and Jill Slay", "title": "Designing Privacy for You : A User Centric Approach For Privacy", "comments": "14 pages, HCI International 2017 Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy directly concerns the user as the data owner (data- subject) and\nhence privacy in systems should be implemented in a manner which concerns the\nuser (user-centered). There are many concepts and guidelines that support\ndevelopment of privacy and embedding privacy into systems. However, none of\nthem approaches privacy in a user- centered manner. Through this research we\npropose a framework that would enable developers and designers to grasp privacy\nin a user-centered manner and implement it along with the software development\nlife cycle.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 00:27:01 GMT"}, {"version": "v2", "created": "Tue, 18 Apr 2017 03:50:19 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Senarath", "Awanthika", ""], ["Arachchilage", "Nalin A. G.", ""], ["Slay", "Jill", ""]]}, {"id": "1703.09968", "submitter": "Abhishek Kashyap", "authors": "Abhishek Kashyap, Rajesh Singh Parmar, Megha Agrawal, Hariom Gupta", "title": "An Evaluation of Digital Image Forgery Detection Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the headway of the advanced image handling software and altering tools,\na computerized picture can be effectively controlled. The identification of\nimage manipulation is vital in light of the fact that an image can be utilized\nas legitimate confirmation, in crime scene investigation, and in numerous\ndifferent fields. The image forgery detection techniques intend to confirm the\ncredibility of computerized pictures with no prior information about the\noriginal image. There are numerous routes for altering a picture, for example,\nresampling, splicing, and copy-move. In this paper, we have examined different\ntype of image forgery and their detection techniques; mainly we focused on\npixel based image forgery detection techniques.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 10:59:33 GMT"}, {"version": "v2", "created": "Thu, 30 Mar 2017 08:06:10 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Kashyap", "Abhishek", ""], ["Parmar", "Rajesh Singh", ""], ["Agrawal", "Megha", ""], ["Gupta", "Hariom", ""]]}, {"id": "1703.10127", "submitter": "Gautam Kamath", "authors": "Bryan Cai, Constantinos Daskalakis, Gautam Kamath", "title": "Priv'IT: Private and Sample Efficient Identity Testing", "comments": "To appear in ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop differentially private hypothesis testing methods for the small\nsample regime. Given a sample $\\cal D$ from a categorical distribution $p$ over\nsome domain $\\Sigma$, an explicitly described distribution $q$ over $\\Sigma$,\nsome privacy parameter $\\varepsilon$, accuracy parameter $\\alpha$, and\nrequirements $\\beta_{\\rm I}$ and $\\beta_{\\rm II}$ for the type I and type II\nerrors of our test, the goal is to distinguish between $p=q$ and\n$d_{\\rm{TV}}(p,q) \\geq \\alpha$.\n  We provide theoretical bounds for the sample size $|{\\cal D}|$ so that our\nmethod both satisfies $(\\varepsilon,0)$-differential privacy, and guarantees\n$\\beta_{\\rm I}$ and $\\beta_{\\rm II}$ type I and type II errors. We show that\ndifferential privacy may come for free in some regimes of parameters, and we\nalways beat the sample complexity resulting from running the $\\chi^2$-test with\nnoisy counts, or standard approaches such as repetition for endowing\nnon-private $\\chi^2$-style statistics with differential privacy guarantees. We\nexperimentally compare the sample complexity of our method to that of recently\nproposed methods for private hypothesis testing.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 16:42:21 GMT"}, {"version": "v2", "created": "Tue, 4 Apr 2017 14:53:34 GMT"}, {"version": "v3", "created": "Wed, 7 Jun 2017 02:46:11 GMT"}], "update_date": "2017-06-08", "authors_parsed": [["Cai", "Bryan", ""], ["Daskalakis", "Constantinos", ""], ["Kamath", "Gautam", ""]]}, {"id": "1703.10187", "submitter": "Mohamed El Massad", "authors": "Mohamed El Massad, Jun Zhang, Siddharth Garg and Mahesh V. Tripunitara", "title": "Logic Locking for Secure Outsourced Chip Fabrication: A New Attack and\n  Provably Secure Defense Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chip designers outsource chip fabrication to external foundries, but at the\nrisk of IP theft. Logic locking, a promising solution to mitigate this threat,\nadds extra logic gates (key gates) and inputs (key bits) to the chip so that it\nfunctions correctly only when the correct key, known only to the designer but\nnot the foundry, is applied. In this paper, we identify a new vulnerability in\nall existing logic locking schemes. Prior attacks on logic locking have assumed\nthat, in addition to the design of the locked chip, the attacker has access to\na working copy of the chip. Our attack does not require a working copy and yet\nwe successfully recover a significant fraction of key bits from the design of\nthe locked chip only. Empirically, we demonstrate the success of our attack on\neight large benchmark circuits from a benchmark suite that has been tailored\nspecifically for logic synthesis research, for two different logic locking\nschemes. Then, to address this vulnerability, we initiate the study of provably\nsecure logic locking mechanisms. We formalize, for the first time to our\nknowledge, a precise notion of security for logic locking. We establish that\nany locking procedure that is secure under our definition is guaranteed to\ncounter our desynthesis attack, and all other such known attacks. We then\ndevise a new logic locking procedure, Meerkat, that guarantees that the locked\nchip reveals no information about the key or the designer's intended\nfunctionality. A main insight behind Meerkat is that canonical representations\nof boolean functionality via Reduced Ordered Binary Decision Diagrams (ROBDDs)\ncan be leveraged effectively to provide security. We analyze Meerkat with\nregards to its security properties and the overhead it incurs. As such, our\nwork is a contribution to both the foundations and practice of securing digital\nICs.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 18:17:55 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Massad", "Mohamed El", ""], ["Zhang", "Jun", ""], ["Garg", "Siddharth", ""], ["Tripunitara", "Mahesh V.", ""]]}, {"id": "1703.10328", "submitter": "Debayan Das", "authors": "Debayan Das, Shovan Maity, Saad Bin Nasir, Santosh Ghosh, Arijit\n  Raychowdhury, Shreyas Sen", "title": "High Efficiency Power Side-Channel Attack Immunity using Noise Injection\n  in Attenuated Signature Domain", "comments": "IEEE International Symposium on Hardware Oriented Security and Trust\n  (HOST) 2017", "journal-ref": null, "doi": "10.1109/HST.2017.7951799", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancement of technology in the last few decades, leading to the\nwidespread availability of miniaturized sensors and internet-connected things\n(IoT), security of electronic devices has become a top priority. Side-channel\nattack (SCA) is one of the prominent methods to break the security of an\nencryption system by exploiting the information leaked from the physical\ndevices. Correlational power attack (CPA) is an efficient power side-channel\nattack technique, which analyses the correlation between the estimated and\nmeasured supply current traces to extract the secret key. The existing\ncountermeasures to the power attacks are mainly based on reducing the SNR of\nthe leaked data, or introducing large overhead using techniques like power\nbalancing. This paper presents an attenuated signature AES (AS-AES), which\nresists SCA with minimal noise current overhead. AS-AES uses a shunt\nlow-drop-out (LDO) regulator to suppress the AES current signature by 400x in\nthe supply current traces. The shunt LDO has been fabricated and validated in\n130 nm CMOS technology. System-level implementation of the AS-AES along with\nnoise injection, shows that the system remains secure even after 50K\nencryptions, with 10x reduction in power overhead compared to that of noise\naddition alone.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 06:35:15 GMT"}, {"version": "v2", "created": "Mon, 8 May 2017 22:07:40 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Das", "Debayan", ""], ["Maity", "Shovan", ""], ["Nasir", "Saad Bin", ""], ["Ghosh", "Santosh", ""], ["Raychowdhury", "Arijit", ""], ["Sen", "Shreyas", ""]]}, {"id": "1703.10399", "submitter": "Rens Wouter van der Heijden", "authors": "Rens W. van der Heijden and Ala'a Al-Momani and Frank Kargl and Osama\n  M.F. Abu-Sharkh", "title": "Enhanced Position Verification for VANETs using Subjective Logic", "comments": "7 pages, 18 figures, corrected version of a paper submitted to 2016\n  IEEE 84th Vehicular Technology Conference (VTC2016-Fall): revised the way an\n  opinion is created with eART, and re-did the experiments (uploaded here as\n  correction in agreement with TPC Chairs)", "journal-ref": null, "doi": "10.1109/VTCFall.2016.788100", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The integrity of messages in vehicular ad-hoc networks has been extensively\nstudied by the research community, resulting in the IEEE~1609.2 standard, which\nprovides typical integrity guarantees. However, the correctness of message\ncontents is still one of the main challenges of applying dependable and secure\nvehicular ad-hoc networks. One important use case is the validity of position\ninformation contained in messages: position verification mechanisms have been\nproposed in the literature to provide this functionality. A more general\napproach to validate such information is by applying misbehavior detection\nmechanisms. In this paper, we consider misbehavior detection by enhancing two\nposition verification mechanisms and fusing their results in a generalized\nframework using subjective logic. We conduct extensive simulations using VEINS\nto study the impact of traffic density, as well as several types of attackers\nand fractions of attackers on our mechanisms. The obtained results show the\nproposed framework can validate position information as effectively as existing\napproaches in the literature, without tailoring the framework specifically for\nthis use case.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 10:45:00 GMT"}, {"version": "v2", "created": "Fri, 31 Mar 2017 07:22:24 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["van der Heijden", "Rens W.", ""], ["Al-Momani", "Ala'a", ""], ["Kargl", "Frank", ""], ["Abu-Sharkh", "Osama M. F.", ""]]}, {"id": "1703.10454", "submitter": "Yisroel Mirsky Mr.", "authors": "Yisroel Mirsky, Mordechai Guri, Yuval Elovici", "title": "HVACKer: Bridging the Air-Gap by Attacking the Air Conditioning System", "comments": "7 Figures, 10 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern corporations physically separate their sensitive computational\ninfrastructure from public or other accessible networks in order to prevent\ncyber-attacks. However, attackers still manage to infect these networks, either\nby means of an insider or by infiltrating the supply chain. Therefore, an\nattacker's main challenge is to determine a way to command and control the\ncompromised hosts that are isolated from an accessible network (e.g., the\nInternet).\n  In this paper, we propose a new adversarial model that shows how an air\ngapped network can receive communications over a covert thermal channel.\nConcretely, we show how attackers may use a compromised air-conditioning system\n(connected to the internet) to send commands to infected hosts within an\nair-gapped network. Since thermal communication protocols are a rather\nunexplored domain, we propose a novel line-encoding and protocol suitable for\nthis type of channel. Moreover, we provide experimental results to demonstrate\nthe covert channel's feasibility, and to calculate the channel's bandwidth.\nLastly, we offer a forensic analysis and propose various ways this channel can\nbe detected and prevented.\n  We believe that this study details a previously unseen vector of attack that\nsecurity experts should be aware of.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 13:09:35 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Mirsky", "Yisroel", ""], ["Guri", "Mordechai", ""], ["Elovici", "Yuval", ""]]}, {"id": "1703.10660", "submitter": "Tribhuvanesh Orekondy", "authors": "Tribhuvanesh Orekondy, Bernt Schiele, Mario Fritz", "title": "Towards a Visual Privacy Advisor: Understanding and Predicting Privacy\n  Risks in Images", "comments": "ICCV 2017. Project page: https://tribhuvanesh.github.io/vpa", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With an increasing number of users sharing information online, privacy\nimplications entailing such actions are a major concern. For explicit content,\nsuch as user profile or GPS data, devices (e.g. mobile phones) as well as web\nservices (e.g. Facebook) offer to set privacy settings in order to enforce the\nusers' privacy preferences. We propose the first approach that extends this\nconcept to image content in the spirit of a Visual Privacy Advisor. First, we\ncategorize personal information in images into 68 image attributes and collect\na dataset, which allows us to train models that predict such information\ndirectly from images. Second, we run a user study to understand the privacy\npreferences of different users w.r.t. such attributes. Third, we propose models\nthat predict user specific privacy score from images in order to enforce the\nusers' privacy preferences. Our model is trained to predict the user specific\nprivacy risk and even outperforms the judgment of the users, who often fail to\nfollow their own privacy preferences on image data.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 20:18:08 GMT"}, {"version": "v2", "created": "Mon, 7 Aug 2017 08:35:35 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Orekondy", "Tribhuvanesh", ""], ["Schiele", "Bernt", ""], ["Fritz", "Mario", ""]]}, {"id": "1703.10926", "submitter": "Suleiman Yerima", "authors": "Mohammed K. Alzaylaee, Suleiman Y. Yerima, Sakir Sezer", "title": "EMULATOR vs REAL PHONE: Android Malware Detection Using Machine Learning", "comments": "IWSPA 2017 Proceedings of the 3rd ACM International Workshop on\n  Security and Privacy Analytics, co-located with CODASPY'17, Scottsdale,\n  Arizona, USA - March 24 - 24, 2017, pages 65-72", "journal-ref": null, "doi": "10.1145/3041008.3041010", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Android operating system has become the most popular operating system for\nsmartphones and tablets leading to a rapid rise in malware. Sophisticated\nAndroid malware employ detection avoidance techniques in order to hide their\nmalicious activities from analysis tools. These include a wide range of\nanti-emulator techniques, where the malware programs attempt to hide their\nmalicious activities by detecting the emulator. For this reason,\ncountermeasures against antiemulation are becoming increasingly important in\nAndroid malware detection. Analysis and detection based on real devices can\nalleviate the problems of anti-emulation as well as improve the effectiveness\nof dynamic analysis. Hence, in this paper we present an investigation of\nmachine learning based malware detection using dynamic analysis on real\ndevices. A tool is implemented to automatically extract dynamic features from\nAndroid phones and through several experiments, a comparative analysis of\nemulator based vs. device based detection by means of several machine learning\nalgorithms is undertaken. Our study shows that several features could be\nextracted more effectively from the on-device dynamic analysis compared to\nemulators. It was also found that approximately 24% more apps were successfully\nanalysed on the phone. Furthermore, all of the studied machine learning based\ndetection performed better when applied to features extracted from the\non-device dynamic analysis.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 14:59:15 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Alzaylaee", "Mohammed K.", ""], ["Yerima", "Suleiman Y.", ""], ["Sezer", "Sakir", ""]]}]