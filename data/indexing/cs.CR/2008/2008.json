[{"id": "2008.00017", "submitter": "Kevin Fu", "authors": "Kevin Fu, Tadayoshi Kohno, Daniel Lopresti, Elizabeth Mynatt, Klara\n  Nahrstedt, Shwetak Patel, Debra Richardson, and Ben Zorn", "title": "Safety, Security, and Privacy Threats Posed by Accelerating Trends in\n  the Internet of Things", "comments": "A Computing Community Consortium (CCC) white paper, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) is already transforming industries, cities, and\nhomes. The economic value of this transformation across all industries is\nestimated to be trillions of dollars and the societal impact on energy\nefficiency, health, and productivity are enormous. Alongside potential benefits\nof interconnected smart devices comes increased risk and potential for abuse\nwhen embedding sensing and intelligence into every device. One of the core\nproblems with the increasing number of IoT devices is the increased complexity\nthat is required to operate them safely and securely. This increased complexity\ncreates new safety, security, privacy, and usability challenges far beyond the\ndifficult challenges individuals face just securing a single device. We\nhighlight some of the negative trends that smart devices and collections of\ndevices cause and we argue that issues related to security, physical safety,\nprivacy, and usability are tightly interconnected and solutions that address\nall four simultaneously are needed. Tight safety and security standards for\nindividual devices based on existing technology are needed. Likewise research\nthat determines the best way for individuals to confidently manage collections\nof devices must guide the future deployments of such systems.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 18:04:20 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Fu", "Kevin", ""], ["Kohno", "Tadayoshi", ""], ["Lopresti", "Daniel", ""], ["Mynatt", "Elizabeth", ""], ["Nahrstedt", "Klara", ""], ["Patel", "Shwetak", ""], ["Richardson", "Debra", ""], ["Zorn", "Ben", ""]]}, {"id": "2008.00047", "submitter": "Bingyin Zhao", "authors": "Bingyin Zhao, Yingjie Lao", "title": "Class-Oriented Poisoning Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poisoning attacks on machine learning systems compromise the model\nperformance by deliberately injecting malicious samples in the training dataset\nto influence the training process. Prior works focus on either availability\nattacks (i.e., lowering the overall model accuracy) or integrity attacks (i.e.,\nenabling specific instance based backdoor). In this paper, we advance the\nadversarial objectives of the availability attacks to a per-class basis, which\nwe refer to as class-oriented poisoning attacks. We demonstrate that the\nproposed attack is capable of forcing the corrupted model to predict in two\nspecific ways: (i) classify unseen new images to a targeted \"supplanter\" class,\nand (ii) misclassify images from a \"victim\" class while maintaining the\nclassification accuracy on other non-victim classes. To maximize the\nadversarial effect, we propose a gradient-based framework that manipulates the\nlogits to retain/eliminate the desired/undesired feature information in the\ngenerated poisoning images. Using newly defined metrics at the class level, we\nillustrate the effectiveness of the proposed class-oriented poisoning attacks\non various models (e.g., LeNet-5, Vgg-9, and ResNet-50) over a wide range of\ndatasets (e.g., MNIST, CIFAR-10, and ImageNet-ILSVRC2012).\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 19:27:37 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Zhao", "Bingyin", ""], ["Lao", "Yingjie", ""]]}, {"id": "2008.00054", "submitter": "Akshay Agarwal", "authors": "Akhil Goel, Akshay Agarwal, Mayank Vatsa, Richa Singh, and Nalini\n  Ratha", "title": "Securing CNN Model and Biometric Template using Blockchain", "comments": "Published in IEEE BTAS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain has emerged as a leading technology that ensures security in a\ndistributed framework. Recently, it has been shown that blockchain can be used\nto convert traditional blocks of any deep learning models into secure systems.\nIn this research, we model a trained biometric recognition system in an\narchitecture which leverages the blockchain technology to provide fault\ntolerant access in a distributed environment. The advantage of the proposed\napproach is that tampering in one particular component alerts the whole system\nand helps in easy identification of `any' possible alteration. Experimentally,\nwith different biometric modalities, we have shown that the proposed approach\nprovides security to both deep learning model and the biometric template.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 19:42:37 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Goel", "Akhil", ""], ["Agarwal", "Akshay", ""], ["Vatsa", "Mayank", ""], ["Singh", "Richa", ""], ["Ratha", "Nalini", ""]]}, {"id": "2008.00136", "submitter": "Ilia Shumailov", "authors": "Almos Zarandy, Ilia Shumailov, Ross Anderson", "title": "BatNet: Data transmission between smartphones over ultrasound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.NI cs.SD", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we present BatNet, a data transmission mechanism using\nultrasound signals over the built-in speakers and microphones of smartphones.\nUsing phase shift keying with an 8-point constellation and frequencies between\n20--24kHz, it can transmit data at over 600bit/s up to 6m. The target\napplication is a censorship-resistant mesh network. We also evaluated it for\nCovid contact tracing but concluded that in this application ultrasonic\ncommunications do not appear to offer enough advantage over Bluetooth Low\nEnergy to be worth further development.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 00:49:42 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Zarandy", "Almos", ""], ["Shumailov", "Ilia", ""], ["Anderson", "Ross", ""]]}, {"id": "2008.00146", "submitter": "Mengyuan Li", "authors": "Mengyuan Li, Yinqian Zhang, Zhiqiang Lin", "title": "CROSSLINE: Breaking ''Security-by-Crash'' based Memory Isolation in AMD\n  SEV", "comments": "14 pages, 5 figures, security", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AMD's Secure Encrypted Virtualization (SEV) is an emerging security feature\non AMD processors that allows virtual machines to run on encrypted memory and\nperform confidential computing even with an untrusted hypervisor. This paper\nfirst demystifies SEV's improper use of address space identifier (ASID) for\ncontrolling accesses of a VM to encrypted memory pages, cache lines, and TLB\nentries. We then present the CROSSLINE attacks, a novel class of attacks\nagainst SEV that allow the adversary to launch an attacker VM and change its\nASID to that of the victim VM to impersonate the victim. We present two\nvariants of CROSSLINE attacks: CROSSLINE V1 decrypts victim's page tables or\nmemory blocks following the format of a page table entry; CROSSLINE V2\nconstructs encryption and decryption oracles by executing instructions of the\nvictim VM. We have successfully performed CROSSLINE attacks on SEV and SEV-ES\nprocessors.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 01:45:54 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Li", "Mengyuan", ""], ["Zhang", "Yinqian", ""], ["Lin", "Zhiqiang", ""]]}, {"id": "2008.00152", "submitter": "Yang Lu", "authors": "Yang Lu, Jianming Lian, Minghui Zhu, Ke Ma and Wei Zhang", "title": "Cyber-Resilient Transactive Energy System Design over Insecure\n  Communication Links", "comments": "11 pages, 8 figures, journal submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the privacy and security issues associated with transactive\nenergy systems over insecure communications are addressed. In particular, it is\nensured that, during market-based interactions: (1) each agent's bidding\ninformation remains private; and (2) any extraneous data injection attack can\nbe easily detected. A unified cryptography-based approach that can\nsimultaneously achieve both objectives is developed, where privacy preservation\nis realized by the Paillier encryption scheme, and attack detection is achieved\nby the Paillier digital signature scheme. Simulation results verify the\neffectiveness of the proposed cyber-resilient design for transactive energy\nsystems.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 02:27:11 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Lu", "Yang", ""], ["Lian", "Jianming", ""], ["Zhu", "Minghui", ""], ["Ma", "Ke", ""], ["Zhang", "Wei", ""]]}, {"id": "2008.00180", "submitter": "Tao Zhang", "authors": "Tao Zhang, Tianqing Zhu, Renping Liu, Wanlei Zhou", "title": "Correlated Data in Differential Privacy: Definition and Analysis", "comments": "This paper is accepted in Concurrency and Computation: Practice and\n  Experience", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is a rigorous mathematical framework for evaluating and\nprotecting data privacy. In most existing studies, there is a vulnerable\nassumption that records in a dataset are independent when differential privacy\nis applied. However, in real-world datasets, records are likely to be\ncorrelated, which may lead to unexpected data leakage. In this survey, we\ninvestigate the issue of privacy loss due to data correlation under\ndifferential privacy models. Roughly, we classify existing literature into\nthree lines: 1) using parameters to describe data correlation in differential\nprivacy, 2) using models to describe data correlation in differential privacy,\nand 3) describing data correlation based on the framework of Pufferfish.\nFirstly, a detailed example is given to illustrate the issue of privacy leakage\non correlated data in real scenes. Then our main work is to analyze and compare\nthese methods, and evaluate situations that these diverse studies are applied.\nFinally, we propose some future challenges on correlated differential privacy.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 05:56:21 GMT"}, {"version": "v2", "created": "Sat, 9 Jan 2021 22:37:43 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Zhang", "Tao", ""], ["Zhu", "Tianqing", ""], ["Liu", "Renping", ""], ["Zhou", "Wanlei", ""]]}, {"id": "2008.00214", "submitter": "Vasileios Kouliaridis", "authors": "Vasileios Kouliaridis, Georgios Kambourakis, Efstratios Chatzoglou,\n  Dimitrios Geneiatakis, Hua Wang", "title": "Dissecting contact tracing apps in the Android platform", "comments": "Fixed issues with Figures", "journal-ref": "PLOS ONE 16(5), 2021", "doi": "10.1371/journal.pone.0251867", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Contact tracing has historically been used to retard the spread of infectious\ndiseases, but if it is exercised by hand in large-scale, it is known to be a\nresource-intensive and quite deficient process. Nowadays, digital contact\ntracing has promptly emerged as an indispensable asset in the global fight\nagainst the coronavirus pandemic. The work at hand offers a meticulous study of\nall the official Android contact tracing apps deployed hitherto by European\ncountries. Each app is closely scrutinized both statically and dynamically by\nmeans of dynamic instrumentation. Depending on the level of examination, static\nanalysis results are grouped in two axes. The first encompasses permissions,\nAPI calls, and possible connections to external URLs, while the second\nconcentrates on potential security weaknesses and vulnerabilities, including\nthe use of trackers, in-depth manifest analysis, shared software analysis, and\ntaint analysis. Dynamic analysis on the other hand collects data pertaining to\nJava classes and network traffic. The results demonstrate that while overall\nthese apps are well-engineered, they are not free of weaknesses,\nvulnerabilities, and misconfigurations that may ultimately put the user\nsecurity and privacy at risk.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 08:39:53 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 17:50:31 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 13:45:10 GMT"}, {"version": "v4", "created": "Mon, 17 May 2021 13:46:41 GMT"}, {"version": "v5", "created": "Fri, 21 May 2021 07:30:58 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Kouliaridis", "Vasileios", ""], ["Kambourakis", "Georgios", ""], ["Chatzoglou", "Efstratios", ""], ["Geneiatakis", "Dimitrios", ""], ["Wang", "Hua", ""]]}, {"id": "2008.00297", "submitter": "Evgenios Kornaropoulos", "authors": "Evgenios M. Kornaropoulos, Silei Ren, Roberto Tamassia", "title": "The Price of Tailoring the Index to Your Data: Poisoning Attacks on\n  Learned Index Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of learned index structures relies on the idea that the\ninput-output functionality of a database index can be viewed as a prediction\ntask and, thus, be implemented using a machine learning model instead of\ntraditional algorithmic techniques. This novel angle for a decades-old problem\nhas inspired numerous exciting results in the intersection of machine learning\nand data structures. However, the main advantage of learned index structures,\ni.e., the ability to adjust to the data at hand via the underlying ML-model,\ncan become a disadvantage from a security perspective as it could be exploited.\n  In this work, we present the first study of poisoning attacks on learned\nindex structures. The required poisoning approach is different from all\nprevious works since the model under attack is trained on a cumulative\ndistribution function (CDF) and, thus, every injection on the training set has\na cascading impact on multiple data values. We formulate the first poisoning\nattacks on linear regression models trained on the CDF, which is a basic\nbuilding block of the proposed learned index structures. We generalize our\npoisoning techniques to attack a more advanced two-stage design of learned\nindex structures called recursive model index (RMI), which has been shown to\noutperform traditional B-Trees. We evaluate our attacks on real-world and\nsynthetic datasets under a wide variety of parameterizations of the model and\nshow that the error of the RMI increases up to $300\\times$ and the error of its\nsecond-stage models increases up to $3000\\times$.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 17:12:04 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Kornaropoulos", "Evgenios M.", ""], ["Ren", "Silei", ""], ["Tamassia", "Roberto", ""]]}, {"id": "2008.00312", "submitter": "Xinyang Zhang", "authors": "Xinyang Zhang, Zheng Zhang, Shouling Ji and Ting Wang", "title": "Trojaning Language Models for Fun and Profit", "comments": "Additional experiments and text editing; To appear in 2021 6th IEEE\n  European Symposium on Security and Privacy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the emergence of a new paradigm of building\nnatural language processing (NLP) systems: general-purpose, pre-trained\nlanguage models (LMs) are composed with simple downstream models and fine-tuned\nfor a variety of NLP tasks. This paradigm shift significantly simplifies the\nsystem development cycles. However, as many LMs are provided by untrusted third\nparties, their lack of standardization or regulation entails profound security\nimplications, which are largely unexplored.\n  To bridge this gap, this work studies the security threats posed by malicious\nLMs to NLP systems. Specifically, we present TROJAN-LM, a new class of\ntrojaning attacks in which maliciously crafted LMs trigger host NLP systems to\nmalfunction in a highly predictable manner. By empirically studying three\nstate-of-the-art LMs (BERT, GPT-2, XLNet) in a range of security-critical NLP\ntasks (toxic comment detection, question answering, text completion) as well as\nuser studies on crowdsourcing platforms, we demonstrate that TROJAN-LM\npossesses the following properties: (i) flexibility - the adversary is able to\nflexibly dene logical combinations (e.g., 'and', 'or', 'xor') of arbitrary\nwords as triggers, (ii) efficacy - the host systems misbehave as desired by the\nadversary with high probability when trigger-embedded inputs are present, (iii)\nspecificity - the trojan LMs function indistinguishably from their benign\ncounterparts on clean inputs, and (iv) fluency - the trigger-embedded inputs\nappear as fluent natural language and highly relevant to their surrounding\ncontexts. We provide analytical justification for the practicality of\nTROJAN-LM, and further discuss potential countermeasures and their challenges,\nwhich lead to several promising research directions.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 18:22:38 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 21:52:58 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Zhang", "Xinyang", ""], ["Zhang", "Zheng", ""], ["Ji", "Shouling", ""], ["Wang", "Ting", ""]]}, {"id": "2008.00332", "submitter": "Elaine Shi", "authors": "Vijaya Ramachandran and Elaine Shi", "title": "Data Oblivious Algorithms for Multicores", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As secure processors such as Intel SGX (with hyperthreading) become widely\nadopted, there is a growing appetite for private analytics on big data. Most\nprior works on data-oblivious algorithms adopt the classical PRAM model to\ncapture parallelism. However, it is widely understood that PRAM does not best\ncapture realistic multicore processors, nor does it reflect parallel\nprogramming models adopted in practice.\n  In this paper, we initiate the study of parallel data oblivious algorithms on\nrealistic multicores, best captured by the binary fork-join model of\ncomputation. We first show that data-oblivious sorting can be accomplished by a\nbinary fork-join algorithm with optimal total work and optimal\n(cache-oblivious) cache complexity, and in O(log n log log n) span (i.e.,\nparallel time) that matches the best-known insecure algorithm. Using our\nsorting algorithm as a core primitive, we show how to data-obliviously simulate\ngeneral PRAM algorithms in the binary fork-join model with non-trivial\nefficiency. We also present results for several applications including list\nranking, Euler tour, tree contraction, connected components, and minimum\nspanning forest. For a subset of these applications, our data-oblivious\nalgorithms asymptotically outperform the best known insecure algorithms. For\nother applications, we show data oblivious algorithms whose performance bounds\nmatch the best known insecure algorithms.\n  Complementing these asymptotically efficient results, we present a practical\nvariant of our sorting algorithm that is self-contained and potentially\nimplementable. It has optimal caching cost, and it is only a log log n factor\noff from optimal work and about a log n factor off in terms of span; moreover,\nit achieves small constant factors in its bounds.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 20:14:10 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 23:25:52 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Ramachandran", "Vijaya", ""], ["Shi", "Elaine", ""]]}, {"id": "2008.00408", "submitter": "Jonathan Pan", "authors": "Jonathan Pan", "title": "Blackbox Trojanising of Deep Learning Models : Using non-intrusive\n  network structure and binary alterations", "comments": "6 pages, 2 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in Artificial Intelligence namely in Deep Learning has\nheightened its adoption in many applications. Some are playing important roles\nto the extent that we are heavily dependent on them for our livelihood.\nHowever, as with all technologies, there are vulnerabilities that malicious\nactors could exploit. A form of exploitation is to turn these technologies,\nintended for good, to become dual-purposed instruments to support deviant acts\nlike malicious software trojans. As part of proactive defense, researchers are\nproactively identifying such vulnerabilities so that protective measures could\nbe developed subsequently. This research explores a novel blackbox trojanising\napproach using a simple network structure modification to any deep learning\nimage classification model that would transform a benign model into a deviant\none with a simple manipulation of the weights to induce specific types of\nerrors. Propositions to protect the occurrence of such simple exploits are\ndiscussed in this research. This research highlights the importance of\nproviding sufficient safeguards to these models so that the intended good of AI\ninnovation and adoption may be protected.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 06:33:47 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Pan", "Jonathan", ""]]}, {"id": "2008.00414", "submitter": "Mohammad Sayad Haghighi", "authors": "Faezeh Farivar, Mohammad Sayad Haghighi, Alireza Jolfaei, Sheng Wen", "title": "On the Security of Networked Control Systems in Smart Vehicle and its\n  Adaptive Cruise Control", "comments": "This paper has been accepted and is to appear in IEEE Transactions on\n  Intelligent Transportation Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the benefits of Internet of Vehicles (IoV) paradigm, come along\nunprecedented security challenges. Among many applications of inter-connected\nsystems, vehicular networks and smart cars are examples that are already rolled\nout. Smart vehicles not only have networks connecting their internal components\ne.g. via Controller Area Network (CAN) bus, but also are connected to the\noutside world through road side units and other vehicles. In some cases, the\ninternal and external network packets pass through the same hardware and are\nmerely isolated by software defined rules. Any misconfiguration opens a window\nfor the hackers to intrude into vehicles' internal components e.g. central lock\nsystem, Engine Control Unit (ECU), Anti-lock Braking System (ABS) or Adaptive\nCruise Control (ACC) system. Compromise of any of these can lead to disastrous\noutcomes. In this paper, we study the security of smart vehicles' adaptive\ncruise control systems in the presence of covert attacks. We define two\ncovert/stealth attacks in the context of cruise control and propose a novel\nintrusion detection and compensation method to disclose and respond to such\nattacks. More precisely, we focus on the covert cyber attacks that compromise\nthe integrity of cruise controller and employ a neural network identifier in\nthe IDS engine to estimate the system output dynamically and compare it against\nthe ACC output. If any anomaly is detected, an embedded substitute controller\nkicks in and takes over the control. We conducted extensive experiments in\nMATLAB to evaluate the effectiveness of the proposed scheme in a simulated\nenvironment.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 06:52:42 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 10:17:11 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Farivar", "Faezeh", ""], ["Haghighi", "Mohammad Sayad", ""], ["Jolfaei", "Alireza", ""], ["Wen", "Sheng", ""]]}, {"id": "2008.00431", "submitter": "Christoph G\\\"unther", "authors": "Christoph G\\\"unther and Daniel G\\\"unther", "title": "Contact Classification in COVID-19 Tracing", "comments": "Two references added wrto. version of August 2nd: [7] and [10] in new\n  numbering", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper addresses the task of reliably identifying critical\ncontacts by using COVID-19 tracing apps. A reliable classification is crucial\nto ensure a high level of protection, and at the same time to prevent many\npeople from being sent to quarantine by the app. Tracing apps are based on the\ncapabilities of current smartphones to enable a broadest possible availability.\nExisting capabilities of smartphones include the exchange of Bluetooth Low\nEnergy (BLE) signals and of audio signals, as well as the use of gyroscopes and\nmagnetic sensors. The Bluetooth power measurements, which are often used today,\nmay be complemented by audio ranging and attitude estimation in the future.\nSmartphones are worn in different ways, often in pockets and bags, which makes\nthe propagation of signals and thus the classification rather unpredictable.\nRelying on the cooperation of users to wear their phones hanging from their\nneck would change the situation considerably. In this case the performance,\nachievable with BLE and audio measurements, becomes predictable. Our analysis\nidentifies parameters that result in accurate warnings, at least within the\nscope of validity of the models. A significant reduction of the spreading of\nthe disease can then be achieved by the apps, without causing many people to\nunduly go to quarantine. The present paper is the first of three papers which\nanalyze the situation in some detail.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 08:05:26 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 20:43:52 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["G\u00fcnther", "Christoph", ""], ["G\u00fcnther", "Daniel", ""]]}, {"id": "2008.00476", "submitter": "Chang Liu", "authors": "Guanlin Li, Chang Liu, Han Yu, Yanhong Fan, Libang Zhang, Zongyue\n  Wang, Meiqin Wang", "title": "SCNet: A Neural Network for Automated Side-Channel Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The side-channel attack is an attack method based on the information gained\nabout implementations of computer systems, rather than weaknesses in\nalgorithms. Information about system characteristics such as power consumption,\nelectromagnetic leaks and sound can be exploited by the side-channel attack to\ncompromise the system. Much research effort has been directed towards this\nfield. However, such an attack still requires strong skills, thus can only be\nperformed effectively by experts. Here, we propose SCNet, which automatically\nperforms side-channel attacks. And we also design this network combining with\nside-channel domain knowledge and different deep learning model to improve the\nperformance and better to explain the result. The results show that our model\nachieves good performance with fewer parameters. The proposed model is a useful\ntool for automatically testing the robustness of computer systems.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 13:14:12 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Li", "Guanlin", ""], ["Liu", "Chang", ""], ["Yu", "Han", ""], ["Fan", "Yanhong", ""], ["Zhang", "Libang", ""], ["Wang", "Zongyue", ""], ["Wang", "Meiqin", ""]]}, {"id": "2008.00508", "submitter": "Lea Sch\\\"onherr", "authors": "Lea Sch\\\"onherr, Maximilian Golla, Thorsten Eisenhofer, Jan Wiele,\n  Dorothea Kolossa, Thorsten Holz", "title": "Unacceptable, where is my privacy? Exploring Accidental Triggers of\n  Smart Speakers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice assistants like Amazon's Alexa, Google's Assistant, or Apple's Siri,\nhave become the primary (voice) interface in smart speakers that can be found\nin millions of households. For privacy reasons, these speakers analyze every\nsound in their environment for their respective wake word like ''Alexa'' or\n''Hey Siri,'' before uploading the audio stream to the cloud for further\nprocessing. Previous work reported on the inaccurate wake word detection, which\ncan be tricked using similar words or sounds like ''cocaine noodles'' instead\nof ''OK Google.''\n  In this paper, we perform a comprehensive analysis of such accidental\ntriggers, i.,e., sounds that should not have triggered the voice assistant, but\ndid. More specifically, we automate the process of finding accidental triggers\nand measure their prevalence across 11 smart speakers from 8 different\nmanufacturers using everyday media such as TV shows, news, and other kinds of\naudio datasets. To systematically detect accidental triggers, we describe a\nmethod to artificially craft such triggers using a pronouncing dictionary and a\nweighted, phone-based Levenshtein distance. In total, we have found hundreds of\naccidental triggers. Moreover, we explore potential gender and language biases\nand analyze the reproducibility. Finally, we discuss the resulting privacy\nimplications of accidental triggers and explore countermeasures to reduce and\nlimit their impact on users' privacy. To foster additional research on these\nsounds that mislead machine learning models, we publish a dataset of more than\n1000 verified triggers as a research artifact.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 15:52:47 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Sch\u00f6nherr", "Lea", ""], ["Golla", "Maximilian", ""], ["Eisenhofer", "Thorsten", ""], ["Wiele", "Jan", ""], ["Kolossa", "Dorothea", ""], ["Holz", "Thorsten", ""]]}, {"id": "2008.00705", "submitter": "Brian Coyle", "authors": "Brian Coyle, Elham Kashefi and Matty Hoban", "title": "Certified Randomness From Steering Using Sequential Measurements", "comments": "35 pages, 9 Figures. This is a pre-published extended version of a\n  workshop edition which appeared in the proceedings of PC 2018 (EPTCS 273,\n  2018, pp. 14-26). The published version of this work is available below", "journal-ref": "Cryptography 2019, 3(4)", "doi": "10.3390/cryptography3040027", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generation of certifiable randomness is one of the most promising\napplications of quantum technologies. Furthermore, the intrinsic non-locality\nof quantum correlations allow us to certify randomness in a device-independent\nway, i.e. one need not make assumptions about the devices used. Due to the work\nof Curchod et. al., a single entangled two-qubit pure state can be used to\nproduce arbitrary amounts of certified randomness. However, the obtaining of\nthis randomness is experimentally challenging as it requires a large number of\nmeasurements, both projective and general. Motivated by these difficulties in\nthe device-independent setting, we instead consider the scenario of one-sided\ndevice independence where certain devices are trusted, and others not; a\nscenario motivated by asymmetric experimental set-ups such as ion-photon\nnetworks. We show how certain aspects of previous work can be adapted to this\nscenario and provide theoretical bounds on the amount of randomness which can\nbe certified. Furthermore, we give a protocol for unbounded randomness\ncertification in this scenario, and provide numerical results demonstrating the\nprotocol in the ideal case. Finally, we numerically test the possibility of\nimplementing this scheme on near-term quantum technologies, by considering the\nperformance of the protocol on several physical platforms.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 08:18:29 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Coyle", "Brian", ""], ["Kashefi", "Elham", ""], ["Hoban", "Matty", ""]]}, {"id": "2008.00877", "submitter": "Paul Ryan Mr", "authors": "Paul Ryan, Harshvardhan J. Pandit, Rob Brennan", "title": "Towards a Semantic Model of the GDPR Register of Processing Activities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core requirement for GDPR compliance is the maintenance of a register of\nprocessing activities (ROPA). Our analysis of six ROPA templates from EU data\nprotection regulators shows the scope and granularity of a ROPA is subject to\nwidely varying guidance in different jurisdictions. We present a consolidated\ndata model based on common concepts and relationships across analysed\ntemplates. We then analyse the extent of using the Data Privacy Vocabulary - a\nvocabulary specification for GDPR. We show that the DPV currently does not\nprovide sufficient concepts to represent the ROPA data model and propose an\nextension to fill this gap. This will enable creation of a pan-EU information\nmanagement framework for interoperability between organisations and regulators\nfor GDPR compliance.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 13:54:47 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Ryan", "Paul", ""], ["Pandit", "Harshvardhan J.", ""], ["Brennan", "Rob", ""]]}, {"id": "2008.00881", "submitter": "Hitesh Tewari", "authors": "Aritra Banerjee, Michael Clear and Hitesh Tewari", "title": "Demystifying the Role of zk-SNARKs in Zcash", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-knowledge proofs have always provided a clear solution when it comes to\nconveying information from a prover to a verifier or vice versa without\nrevealing essential information about the process. Advancements in\nzero-knowledge have helped develop proofs which are succinct and provide\nnon-interactive arguments of knowledge along with maintaining the\nzero-knowledge criteria. zk-SNARKs (Zero knowledge Succinct Non-Interactive\nArgument of Knowledge) are one such method that outshines itself when it comes\nto advancement of zero-knowledge proofs. The underlying principle of the Zcash\nalgorithm is such that it delivers a full-fledged ledger-based digital currency\nwith strong privacy guarantees and the root of ensuring privacy lies fully on\nthe construction of a proper zk-SNARK. In this paper we elaborate and construct\na concrete zk-SNARK proof from scratch and explain its role in the Zcash\nalgorithm.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 13:59:07 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 18:11:37 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 13:45:25 GMT"}, {"version": "v4", "created": "Tue, 10 Nov 2020 13:43:54 GMT"}, {"version": "v5", "created": "Thu, 12 Nov 2020 20:52:39 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Banerjee", "Aritra", ""], ["Clear", "Michael", ""], ["Tewari", "Hitesh", ""]]}, {"id": "2008.01013", "submitter": "Parker Lamb", "authors": "Parker Lamb, Alexander Millar, Ramon Fuentes", "title": "Swipe dynamics as a means of authentication: results from a Bayesian\n  unsupervised approach", "comments": "9 pages, 7 figures; Layout and editing improved", "journal-ref": null, "doi": "10.1109/IJCB48548.2020.9304876", "report-no": null, "categories": "cs.CR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of behavioural biometrics stands as an appealing alternative to\nmore traditional biometric systems due to the ease of use from a user\nperspective and potential robustness to presentation attacks. This paper\nfocuses its attention to a specific type of behavioural biometric utilising\nswipe dynamics, also referred to as touch gestures. In touch gesture\nauthentication, a user swipes across the touchscreen of a mobile device to\nperform an authentication attempt. A key characteristic of touch gesture\nauthentication and new behavioural biometrics in general is the lack of\navailable data to train and validate models. From a machine learning\nperspective, this presents the classic curse of dimensionality problem and the\nmethodology presented here focuses on Bayesian unsupervised models as they are\nwell suited to such conditions. This paper presents results from a set of\nexperiments consisting of 38 sessions with labelled victim as well as blind and\nover-the-shoulder presentation attacks. Three models are compared using this\ndataset; two single-mode models: a shrunk covariance estimate and a Bayesian\nGaussian distribution, as well as a Bayesian non-parametric infinite mixture of\nGaussians, modelled as a Dirichlet Process. Equal error rates (EER) for the\nthree models are compared and attention is paid to how these vary across the\ntwo single-mode models at differing numbers of enrolment samples.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 16:53:28 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 13:04:11 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Lamb", "Parker", ""], ["Millar", "Alexander", ""], ["Fuentes", "Ramon", ""]]}, {"id": "2008.01120", "submitter": "Hitesh Tewari", "authors": "Sarang Chaudhari, Michael Clear and Hitesh Tewari", "title": "Framework for a DLT Based COVID-19 Passport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uniquely identifying individuals across the various networks they interact\nwith on a daily basis remains a challenge for the digital world that we live\nin, and therefore the development of secure and efficient privacy preserving\nidentity mechanisms has become an important field of research. In addition, the\npopularity of decentralised decision making networks such as Bitcoin has seen a\nhuge interest in making use of distributed ledger technology to store and\nsecurely disseminate end user identity credentials. In this paper we describe a\nmechanism that allows one to store the COVID-19 vaccination details of\nindividuals on a publicly readable, decentralised, immutable blockchain, and\nmakes use of a two-factor authentication system that employs biometric\ncryptographic hashing techniques to generate a unique identifier for each user.\nOur main contribution is the employment of a provably secure input-hiding,\nlocality-sensitive hashing algorithm over an iris extraction technique, that\ncan be used to authenticate users and anonymously locate vaccination records on\nthe blockchain, without leaking any personally identifiable information to the\nblockchain.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 18:28:19 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 13:18:12 GMT"}, {"version": "v3", "created": "Fri, 25 Sep 2020 15:56:03 GMT"}, {"version": "v4", "created": "Mon, 5 Oct 2020 17:07:37 GMT"}, {"version": "v5", "created": "Tue, 20 Oct 2020 11:43:34 GMT"}, {"version": "v6", "created": "Sun, 15 Nov 2020 19:02:01 GMT"}, {"version": "v7", "created": "Mon, 18 Jan 2021 10:42:40 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Chaudhari", "Sarang", ""], ["Clear", "Michael", ""], ["Tewari", "Hitesh", ""]]}, {"id": "2008.01175", "submitter": "Renato Cordeiro de Amorim", "authors": "Renato Cordeiro de Amorim and Carlos David Lopez Ruiz", "title": "Identifying meaningful clusters in malware data", "comments": null, "journal-ref": null, "doi": "10.1016/j.eswa.2021.114971", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Finding meaningful clusters in drive-by-download malware data is a\nparticularly difficult task. Malware data tends to contain overlapping clusters\nwith wide variations of cardinality. This happens because there can be\nconsiderable similarity between malware samples (some are even said to belong\nto the same family), and these tend to appear in bursts. Clustering algorithms\nare usually applied to normalised data sets. However, the process of\nnormalisation aims at setting features with different range values to have a\nsimilar contribution to the clustering. It does not favour more meaningful\nfeatures over those that are less meaningful, an effect one should perhaps\nexpect of the data pre-processing stage.\n  In this paper we introduce a method to deal precisely with the problem above.\nThis is an iterative data pre-processing method capable of aiding to increase\nthe separation between clusters. It does so by calculating the within-cluster\ndegree of relevance of each feature, and then it uses these as a data rescaling\nfactor. By repeating this until convergence our malware data was separated in\nclear clusters, leading to a higher average silhouette width.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 12:36:08 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["de Amorim", "Renato Cordeiro", ""], ["Ruiz", "Carlos David Lopez", ""]]}, {"id": "2008.01330", "submitter": "Safwan Wshah", "authors": "Fayha ALmutairy, Reem Shadid, Safwan Wshah", "title": "Identification and Correction of False Data Injection Attacks against AC\n  State Estimation using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  recent literature has proposed various detection and identification methods\nfor FDIAs, but few studies have focused on a solution that would prevent such\nattacks from occurring. However, great strides have been made using deep\nlearning to detect attacks. Inspired by these advancements, we have developed a\nnew methodology for not only identifying AC FDIAs but, more importantly, for\ncorrection as well. Our methodology utilizes a Long-Short Term Memory Denoising\nAutoencoder (LSTM-DAE) to correct attacked-estimated states based on the\nattacked measurements. The method was evaluated using the IEEE 30 system, and\nthe experiments demonstrated that the proposed method was successfully able to\nidentify the corrupted states and correct them with high accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 05:10:02 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["ALmutairy", "Fayha", ""], ["Shadid", "Reem", ""], ["Wshah", "Safwan", ""]]}, {"id": "2008.01345", "submitter": "Rajat Tandon", "authors": "Rajat Tandon", "title": "A Survey of Distributed Denial of Service Attacks and Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A distributed denial-of-service (DDoS) attack is an attack wherein multiple\ncompromised computer systems flood the bandwidth and/or resources of a target,\nsuch as a server, website or other network resource, and cause a denial of\nservice for users of the targeted resource. The flood of incoming messages,\nconnection requests or malformed packets to the target system forces it to slow\ndown or even crash and shut down, thereby denying service to legitimate users\nor systems. This paper presents a literature review of DDoS attacks and the\ncommon defense mechanisms available. It also presents a literature review of\nthe defenses for low-rate DDoS attacks that have not been handled effectively\nhitherto.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 05:52:32 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Tandon", "Rajat", ""]]}, {"id": "2008.01558", "submitter": "Yanmin Gong", "authors": "Rui Hu and Yanmin Gong and Yuanxiong Guo", "title": "Federated Learning with Sparsification-Amplified Privacy and Adaptive\n  Optimization", "comments": "Accepted in IJCAI 2021, this is the full version with appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) enables distributed agents to collaboratively learn a\ncentralized model without sharing their raw data with each other. However, data\nlocality does not provide sufficient privacy protection, and it is desirable to\nfacilitate FL with rigorous differential privacy (DP) guarantee. Existing DP\nmechanisms would introduce random noise with magnitude proportional to the\nmodel size, which can be quite large in deep neural networks. In this paper, we\npropose a new FL framework with sparsification-amplified privacy. Our approach\nintegrates random sparsification with gradient perturbation on each agent to\namplify privacy guarantee. Since sparsification would increase the number of\ncommunication rounds required to achieve a certain target accuracy, which is\nunfavorable for DP guarantee, we further introduce acceleration techniques to\nhelp reduce the privacy cost. We rigorously analyze the convergence of our\napproach and utilize Renyi DP to tightly account the end-to-end DP guarantee.\nExtensive experiments on benchmark datasets validate that our approach\noutperforms previous differentially-private FL approaches in both privacy\nguarantee and communication efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 20:22:57 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 20:18:08 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Hu", "Rui", ""], ["Gong", "Yanmin", ""], ["Guo", "Yuanxiong", ""]]}, {"id": "2008.01621", "submitter": "Antoine Boutet", "authors": "Claude Castelluccia, Nataliia Bielova, Antoine Boutet, Mathieu Cunche,\n  C\\'edric Lauradoux, Daniel Le M\\'etayer, Vincent Roca", "title": "DESIRE: A Third Way for a European Exposure Notification System\n  Leveraging the best of centralized and decentralized systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document presents an evolution of the ROBERT protocol that decentralizes\nmost of its operations on the mobile devices. DESIRE is based on the same\narchitecture than ROBERT but implements major privacy improvements. In\nparticular, it introduces the concept of Private Encounter Tokens, that are\nsecret and cryptographically generated, to encode encounters. In the DESIRE\nprotocol, the temporary Identifiers that are broadcast on the Bluetooth\ninterfaces are generated by the mobile devices providing more control to the\nusers about which ones to disclose. The role of the server is merely to match\nPETs generated by diagnosed users with the PETs provided by requesting users.\nIt stores minimal pseudonymous data. Finally, all data that are stored on the\nserver are encrypted using keys that are stored on the mobile devices,\nprotecting against data breach on the server. All these modifications improve\nthe privacy of the scheme against malicious users and authority. However, as in\nthe first version of ROBERT, risk scores and notifications are still managed\nand controlled by the server of the health authority, which provides high\nrobustness, flexibility, and efficacy.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 15:10:41 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Castelluccia", "Claude", ""], ["Bielova", "Nataliia", ""], ["Boutet", "Antoine", ""], ["Cunche", "Mathieu", ""], ["Lauradoux", "C\u00e9dric", ""], ["M\u00e9tayer", "Daniel Le", ""], ["Roca", "Vincent", ""]]}, {"id": "2008.01665", "submitter": "Szilvia Lestyan", "authors": "Szilvia Lesty\\'an, Gergely \\'Acs, Gergely Bicz\\'ok", "title": "Privacy-preserving release of mobility data: a clean-slate approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quantity of mobility data is overwhelming nowadays providing tremendous\npotential for various value-added services. While the benefits of these\nmobility datasets are apparent, they also provide significant threat to\nlocation privacy. Although a multitude of anonymization schemes have been\nproposed to release location data, they all suffer from the inherent sparseness\nand high-dimensionality of location trajectories which render most techniques\ninapplicable in practice. In this paper, we revisit the problem of releasing\nlocation trajectories with strong privacy guarantees. We propose a general\napproach to synthesize location trajectories meanwhile providing differential\nprivacy. We model the generator distribution of the dataset by first\nconstructing a model to generate the source and destination location of\ntrajectories along with time information, and then compute all transition\nprobabilities between close locations given the destination of the synthetic\ntrajectory. Finally, an optimization algorithm is used to find the most\nprobable trajectory between the given source and destination at a given time\nusing the computed transition probabilities. We exploit several inherent\nproperties of location data to boost the performance of our model, and\ndemonstrate its usability on a public location dataset. We also develop a novel\ncomposite of generative neural network to synthesize location trajectories\nwhich might be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 15:47:40 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Lesty\u00e1n", "Szilvia", ""], ["\u00c1cs", "Gergely", ""], ["Bicz\u00f3k", "Gergely", ""]]}, {"id": "2008.01704", "submitter": "Depeng Liu", "authors": "Depeng Liu, Bow-yaw Wang and Lijun Zhang", "title": "Verifying Pufferfish Privacy in Hidden Markov Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pufferfish is a Bayesian privacy framework for designing and analyzing\nprivacy mechanisms. It refines differential privacy, the current gold standard\nin data privacy, by allowing explicit prior knowledge in privacy analysis.\nThrough these privacy frameworks, a number of privacy mechanisms have been\ndeveloped in literature. In practice, privacy mechanisms often need be modified\nor adjusted to specific applications. Their privacy risks have to be\nre-evaluated for different circumstances. Moreover, computing devices only\napproximate continuous noises through floating-point computation, which is\ndiscrete in nature. Privacy proofs can thus be complicated and prone to errors.\nSuch tedious tasks can be burdensome to average data curators. In this paper,\nwe propose an automatic verification technique for Pufferfish privacy. We use\nhidden Markov models to specify and analyze discretized Pufferfish privacy\nmechanisms. We show that the Pufferfish verification problem in hidden Markov\nmodels is NP-hard. Using Satisfiability Modulo Theories solvers, we propose an\nalgorithm to analyze privacy requirements. We implement our algorithm in a\nprototypical tool called FAIER, and present several case studies. Surprisingly,\nour case studies show that na\\\"ive discretization of well-established privacy\nmechanisms often fail, witnessed by counterexamples generated by FAIER. In\ndiscretized \\emph{Above Threshold}, we show that it results in absolutely no\nprivacy. Finally, we compare our approach with testing based approach on\nseveral case studies, and show that our verification technique can be combined\nwith testing based approach for the purpose of (i) efficiently certifying\ncounterexamples and (ii) obtaining a better lower bound for the privacy budget\n$\\epsilon$.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 17:11:45 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Liu", "Depeng", ""], ["Wang", "Bow-yaw", ""], ["Zhang", "Lijun", ""]]}, {"id": "2008.01725", "submitter": "Jyoti Prakash", "authors": "Abhishek Tiwari, Jyoti Prakash, Sascha Gross, Christian Hammer", "title": "A Large Scale Analysis of Android-Web Hybridization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many Android applications embed webpages via WebView components and execute\nJavaScript code within Android. Hybrid applications leverage dedicated APIs to\nload a resource and render it in a WebView. Furthermore, Android objects can be\nshared with the JavaScript world. However, bridging the interfaces of the\nAndroid and JavaScript world might also incur severe security threats:\nPotentially untrusted webpages and their JavaScript might interfere with the\nAndroid environment and its access to native features. No general analysis is\ncurrently available to assess the implications of such hybrid apps bridging the\ntwo worlds. To understand the semantics and effects of hybrid apps, we perform\na large-scale study on the usage of the hybridization APIs in the wild. We\nanalyze and categorize the parameters to hybridization APIs for 7,500 randomly\nselected and the 196 most popular applications from the Google Playstore as\nwell as 1000 malware samples. Our results advance the general understanding of\nhybrid applications, as well as implications for potential program analyses,\nand the current security situation: We discovered thousands of flows of\nsensitive data from Android to JavaScript, the vast majority of which could\nflow to potentially untrustworthy code. Our analysis identified numerous web\npages embedding vulnerabilities, which we exemplarily exploited. Additionally,\nwe discovered a multitude of applications in which potentially untrusted\nJavaScript code may interfere with (trusted) Android objects, both in benign\nand malign applications.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 17:58:07 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 02:34:44 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Tiwari", "Abhishek", ""], ["Prakash", "Jyoti", ""], ["Gross", "Sascha", ""], ["Hammer", "Christian", ""]]}, {"id": "2008.01742", "submitter": "Mayank Mundhra", "authors": "Mayank Mundhra, Chester Rebeiro", "title": "SISSLE in consensus-based Ripple: Some Improvements in Speed, Security\n  and Last Mile Connectivity", "comments": "11 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptocurrencies are rapidly finding application in areas such as Real Time\nGross Settlements and Payments. Ripple is a cryptocurrency that has gained\nprominence with banks and payment providers. It solves the Byzantine General's\nProblem with its Ripple Protocol Consensus Algorithm (RPCA), where each server\nmaintains a list of servers, called the Unique Node List (UNL), that represents\nthe network for that server and will not collectively defraud it. The server\nbelieves that the network has come to a consensus when servers on the UNL come\nto a consensus on a transaction.\n  In this paper we improve Ripple to achieve better speed, security and last\nmile connectivity. We implement guidelines for resilience, robustness, improved\nsecurity, and efficient information propagation (IP). We enhance the system to\nensure that each server receives information from across the whole network\nrather than just from the UNL members. We introduce the paradigm of UNL overlap\nas a function of IP and the trust a server assigns to its own UNL. Our design\nmakes it possible to identify and mitigate some malicious behaviours including\nattempts to fraudulently Double Spend or stall the system. We provide\nexperimental evidence of the benefits of our approach over the current Ripple\nscheme. We observe $\\geq 99.67\\%$ reduction in opportunities for double spend\nattacks and censorship, $1.71x$ increase in fault tolerance to $\\geq 34.21\\%$\nmalicious nodes, $\\geq 4.97x$ and $98.22x$ speedup and success rate for IP\nrespectively, and $\\geq 3.16x$ and $51.70x$ speedup and success rate in\nconsensus respectively.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 18:00:51 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 06:39:57 GMT"}, {"version": "v3", "created": "Sat, 15 May 2021 20:10:31 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Mundhra", "Mayank", ""], ["Rebeiro", "Chester", ""]]}, {"id": "2008.01761", "submitter": "Siddhant Garg", "authors": "Siddhant Garg, Adarsh Kumar, Vibhor Goel, Yingyu Liang", "title": "Can Adversarial Weight Perturbations Inject Neural Backdoors?", "comments": "Accepted as a conference paper at CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3412130", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial machine learning has exposed several security hazards of neural\nmodels and has become an important research topic in recent times. Thus far,\nthe concept of an \"adversarial perturbation\" has exclusively been used with\nreference to the input space referring to a small, imperceptible change which\ncan cause a ML model to err. In this work we extend the idea of \"adversarial\nperturbations\" to the space of model weights, specifically to inject backdoors\nin trained DNNs, which exposes a security risk of using publicly available\ntrained models. Here, injecting a backdoor refers to obtaining a desired\noutcome from the model when a trigger pattern is added to the input, while\nretaining the original model predictions on a non-triggered input. From the\nperspective of an adversary, we characterize these adversarial perturbations to\nbe constrained within an $\\ell_{\\infty}$ norm around the original model\nweights. We introduce adversarial perturbations in the model weights using a\ncomposite loss on the predictions of the original model and the desired trigger\nthrough projected gradient descent. We empirically show that these adversarial\nweight perturbations exist universally across several computer vision and\nnatural language processing tasks. Our results show that backdoors can be\nsuccessfully injected with a very small average relative change in model weight\nvalues for several applications.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 18:26:13 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 04:58:59 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Garg", "Siddhant", ""], ["Kumar", "Adarsh", ""], ["Goel", "Vibhor", ""], ["Liang", "Yingyu", ""]]}, {"id": "2008.01765", "submitter": "Gilad Asharov", "authors": "Gilad Asharov, T-H. Hubert Chan, Kartik Nayak, Rafael Pass, Ling Ren,\n  Elaine Shi", "title": "Bucket Oblivious Sort: An Extremely Simple Oblivious Sort", "comments": "Appears in SOSA@SODA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a conceptually simple oblivious sort and oblivious random\npermutation algorithms called bucket oblivious sort and bucket oblivious random\npermutation. Bucket oblivious sort uses $6n\\log n$ time (measured by the number\nof memory accesses) and $2Z$ client storage with an error probability\nexponentially small in $Z$. The above runtime is only $3\\times$ slower than a\nnon-oblivious merge sort baseline; for $2^{30}$ elements, it is $5\\times$\nfaster than bitonic sort, the de facto oblivious sorting algorithm in practical\nimplementations.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 18:45:40 GMT"}, {"version": "v2", "created": "Sun, 16 Aug 2020 06:39:52 GMT"}, {"version": "v3", "created": "Thu, 29 Apr 2021 09:06:48 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Asharov", "Gilad", ""], ["Chan", "T-H. Hubert", ""], ["Nayak", "Kartik", ""], ["Pass", "Rafael", ""], ["Ren", "Ling", ""], ["Shi", "Elaine", ""]]}, {"id": "2008.01855", "submitter": "Ron Korine", "authors": "Ron Korine and Danny Hendler", "title": "DAEMON: Dataset-Agnostic Explainable Malware Classification Using\n  Multi-Stage Feature Mining", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2021.3082173", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Numerous metamorphic and polymorphic malicious variants are generated\nautomatically on a daily basis by mutation engines that transform the code of a\nmalicious program while retaining its functionality, in order to evade\nsignature-based detection. These automatic processes have greatly increased the\nnumber of malware variants, deeming their fully-manual analysis impossible.\nMalware classification is the task of determining to which family a new\nmalicious variant belongs. Variants of the same malware family show similar\nbehavioral patterns. Thus, classifying newly discovered malicious programs and\napplications helps assess the risks they pose. Moreover, malware classification\nfacilitates determining which of the newly discovered variants should undergo\nmanual analysis by a security expert, in order to determine whether they belong\nto a new family (e.g., one whose members exploit a zero-day vulnerability) or\nare simply the result of a concept drift within a known malicious family. This\nmotivated intense research in recent years on devising high-accuracy automatic\ntools for malware classification. In this work, we present DAEMON - a novel\ndataset-agnostic malware classifier. A key property of DAEMON is that the type\nof features it uses and the manner in which they are mined facilitate\nunderstanding the distinctive behavior of malware families, making its\nclassification decisions explainable. We've optimized DAEMON using a\nlarge-scale dataset of x86 binaries, belonging to a mix of several malware\nfamilies targeting computers running Windows. We then re-trained it and applied\nit, without any algorithmic change, feature re-engineering or parameter tuning,\nto two other large-scale datasets of malicious Android applications consisting\nof numerous malware families. DAEMON obtained highly accurate classification\nresults on all datasets, establishing that it is also platform-agnostic.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 21:57:30 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 14:45:44 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Korine", "Ron", ""], ["Hendler", "Danny", ""]]}, {"id": "2008.01916", "submitter": "Dayong Ye", "authors": "Tianqing Zhu and Dayong Ye and Wei Wang and Wanlei Zhou and Philip S.\n  Yu", "title": "More Than Privacy: Applying Differential Privacy in Key Areas of\n  Artificial Intelligence", "comments": null, "journal-ref": "IEEE Tranactions on Knowledge and Data Engineering 2020", "doi": "10.1109/TKDE.2020.3014246", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) has attracted a great deal of attention in\nrecent years. However, alongside all its advancements, problems have also\nemerged, such as privacy violations, security issues and model fairness.\nDifferential privacy, as a promising mathematical model, has several attractive\nproperties that can help solve these problems, making it quite a valuable tool.\nFor this reason, differential privacy has been broadly applied in AI but to\ndate, no study has documented which differential privacy mechanisms can or have\nbeen leveraged to overcome its issues or the properties that make this\npossible. In this paper, we show that differential privacy can do more than\njust privacy preservation. It can also be used to improve security, stabilize\nlearning, build fair models, and impose composition in selected areas of AI.\nWith a focus on regular machine learning, distributed machine learning, deep\nlearning, and multi-agent systems, the purpose of this article is to deliver a\nnew view on many possibilities for improving AI performance with differential\nprivacy techniques.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 03:07:36 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Zhu", "Tianqing", ""], ["Ye", "Dayong", ""], ["Wang", "Wei", ""], ["Zhou", "Wanlei", ""], ["Yu", "Philip S.", ""]]}, {"id": "2008.01919", "submitter": "Xiaojun Jia", "authors": "Xiaojun Jia, Xingxing Wei, Xiaochun Cao and Xiaoguang Han", "title": "Adv-watermark: A Novel Watermark Perturbation for Adversarial Examples", "comments": null, "journal-ref": "ACM MM2020", "doi": null, "report-no": null, "categories": "cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has demonstrated that adding some imperceptible perturbations\nto original images can fool deep learning models. However, the current\nadversarial perturbations are usually shown in the form of noises, and thus\nhave no practical meaning. Image watermark is a technique widely used for\ncopyright protection. We can regard image watermark as a king of meaningful\nnoises and adding it to the original image will not affect people's\nunderstanding of the image content, and will not arouse people's suspicion.\nTherefore, it will be interesting to generate adversarial examples using\nwatermarks. In this paper, we propose a novel watermark perturbation for\nadversarial examples (Adv-watermark) which combines image watermarking\ntechniques and adversarial example algorithms. Adding a meaningful watermark to\nthe clean images can attack the DNN models. Specifically, we propose a novel\noptimization algorithm, which is called Basin Hopping Evolution (BHE), to\ngenerate adversarial watermarks in the black-box attack mode. Thanks to the\nBHE, Adv-watermark only requires a few queries from the threat models to finish\nthe attacks. A series of experiments conducted on ImageNet and CASIA-WebFace\ndatasets show that the proposed method can efficiently generate adversarial\nexamples, and outperforms the state-of-the-art attack methods. Moreover,\nAdv-watermark is more robust against image transformation defense methods.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 03:28:43 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 19:10:01 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Jia", "Xiaojun", ""], ["Wei", "Xingxing", ""], ["Cao", "Xiaochun", ""], ["Han", "Xiaoguang", ""]]}, {"id": "2008.01957", "submitter": "Wei Song", "authors": "Wei Song, Boya Li, Zihan Xue, Zhenzhen Li, Wenhao Wang, Peng Liu", "title": "Randomized Last-Level Caches Are Still Vulnerable to Cache Side-Channel\n  Attacks! But We Can Fix It", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cache randomization has recently been revived as a promising defense against\nconflict-based cache side-channel attacks. As two of the latest\nimplementations, CEASER-S and ScatterCache both claim to thwart conflict-based\ncache side-channel attacks using randomized skewed caches. Unfortunately, our\nexperiments show that an attacker can easily find a usable eviction set within\nthe chosen remap period of CEASER-S and increasing the number of partitions\nwithout dynamic remapping, such as ScatterCache, cannot eliminate the threat.\nBy quantitatively analyzing the access patterns left by various attacks in the\nLLC, we have newly discovered several problems with the hypotheses and\nimplementations of randomized caches, which are also overlooked by the research\non conflict-based cache side-channel attack.\n  However, cache randomization is not a false hope and it is an effective\ndefense that should be widely adopted in future processors. The newly\ndiscovered problems are corresponding to flaws associated with the existing\nimplementation of cache randomization and are fixable. Several new defense\ntechniques are proposed in this paper. our experiments show that all the newly\ndiscovered vulnerabilities of existing randomized caches are fixed within the\ncurrent performance budget. We also argue that randomized set-associative\ncaches can be sufficiently strengthened and possess a better chance to be\nactually adopted in commercial processors than their skewed counterparts as\nthey introduce less overhaul to the existing cache structure.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 06:47:52 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Song", "Wei", ""], ["Li", "Boya", ""], ["Xue", "Zihan", ""], ["Li", "Zhenzhen", ""], ["Wang", "Wenhao", ""], ["Liu", "Peng", ""]]}, {"id": "2008.01976", "submitter": "Tuomas Oikarinen", "authors": "Tuomas Oikarinen, Tsui-Wei Weng, Luca Daniel", "title": "Robust Deep Reinforcement Learning through Adversarial Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks, including reinforcement learning agents, have been\nproven vulnerable to small adversarial changes in the input, thus making\ndeploying such networks in the real world problematic. In this paper, we\npropose RADIAL-RL, a method to train reinforcement learning agents with\nimproved robustness against any $l_p$-bounded adversarial attack. By simply\nminimizing an upper bound of the loss functions under worst case adversarial\nperturbation derived from efficient robustness verification methods, we\nsignificantly improve robustness of RL-agents trained on Atari-2600 games and\nshow that RADIAL-RL can beat state-of-the-art robust training algorithms when\nevaluated against PGD-attacks. We also propose a new evaluation method, Greedy\nWorst-Case Reward (GWC), for measuring attack agnostic robustness of RL agents.\nGWC can be evaluated efficiently and it serves as a good estimate of the reward\nunder the worst possible sequence of adversarial attacks; in particular, GWC\naccounts for the importance of each action and their temporal dependency,\nimproving upon previous approaches that only evaluate whether each single\naction can change under input perturbations. Our code is available at\nhttps://github.com/tuomaso/radial_rl.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 07:49:42 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Oikarinen", "Tuomas", ""], ["Weng", "Tsui-Wei", ""], ["Daniel", "Luca", ""]]}, {"id": "2008.01989", "submitter": "Sinan Yildirim", "authors": "Nurdan Kuru, \\c{S}. \\.Ilker Birbil, Mert Gurbuzbalaban, and Sinan\n  Yildirim", "title": "Differentially Private Accelerated Optimization Algorithms", "comments": "28 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two classes of differentially private optimization algorithms\nderived from the well-known accelerated first-order methods. The first\nalgorithm is inspired by Polyak's heavy ball method and employs a smoothing\napproach to decrease the accumulated noise on the gradient steps required for\ndifferential privacy. The second class of algorithms are based on Nesterov's\naccelerated gradient method and its recent multi-stage variant. We propose a\nnoise dividing mechanism for the iterations of Nesterov's method in order to\nimprove the error behavior of the algorithm. The convergence rate analyses are\nprovided for both the heavy ball and the Nesterov's accelerated gradient method\nwith the help of the dynamical system analysis techniques. Finally, we conclude\nwith our numerical experiments showing that the presented algorithms have\nadvantages over the well-known differentially private algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 08:23:01 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Kuru", "Nurdan", ""], ["Birbil", "\u015e. \u0130lker", ""], ["Gurbuzbalaban", "Mert", ""], ["Yildirim", "Sinan", ""]]}, {"id": "2008.02003", "submitter": "Yael Daihes", "authors": "Yael Daihes, Hen Tzaban, Asaf Nadler, Asaf Shabtai", "title": "MORTON: Detection of Malicious Routines in Large-Scale DNS Traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present MORTON, a method that identifies compromised\ndevices in enterprise networks based on the existence of routine DNS\ncommunication between devices and disreputable host names. With its compact\nrepresentation of the input data and use of efficient signal processing and a\nneural network for classification, MORTON is designed to be accurate, robust,\nand scalable. We evaluate MORTON using a large dataset of corporate DNS logs\nand compare it with two recently proposed beaconing detection methods aimed at\ndetecting malware communication. The results demonstrate that while MORTON's\naccuracy in a synthetic experiment is comparable to that of the other methods,\nit outperforms those methods in terms of its ability to detect sophisticated\nbot communication techniques, such as multistage channels, as well as in its\nrobustness and efficiency. In a real-world evaluation, which includes\npreviously unreported threats, MORTON and the two compared methods were\ndeployed to monitor the (unlabeled) DNS traffic of two global enterprises for a\nweek-long period; this evaluation demonstrates the effectiveness of MORTON in\nreal-world scenarios and showcases its superiority in terms of true and false\npositive rates.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 08:56:43 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 12:11:37 GMT"}, {"version": "v3", "created": "Thu, 21 Jan 2021 18:20:23 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Daihes", "Yael", ""], ["Tzaban", "Hen", ""], ["Nadler", "Asaf", ""], ["Shabtai", "Asaf", ""]]}, {"id": "2008.02076", "submitter": "Dou Yan Liu Goodman", "authors": "Dou Goodman, Hao Xin", "title": "Attacking and Defending Machine Learning Applications of Public Cloud", "comments": "arXiv admin note: text overlap with arXiv:1704.05051 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attack breaks the boundaries of traditional security defense. For\nadversarial attack and the characteristics of cloud services, we propose\nSecurity Development Lifecycle for Machine Learning applications, e.g., SDL for\nML. The SDL for ML helps developers build more secure software by reducing the\nnumber and severity of vulnerabilities in ML-as-a-service, while reducing\ndevelopment cost.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 14:00:31 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Goodman", "Dou", ""], ["Xin", "Hao", ""]]}, {"id": "2008.02196", "submitter": "Peilun Wu", "authors": "Peilun Wu, Nour Moustafa, Shiyi Yang, Hui Guo", "title": "Densely Connected Residual Network for Attack Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High false alarm rate and low detection rate are the major sticking points\nfor unknown threat perception. To address the problems, in the paper, we\npresent a densely connected residual network (Densely-ResNet) for attack\nrecognition. Densely-ResNet is built with several basic residual units, where\neach of them consists of a series of Conv-GRU subnets by wide connections. Our\nevaluation shows that Densely-ResNet can accurately discover various unknown\nthreats that appear in edge, fog and cloud layers and simultaneously maintain a\nmuch lower false alarm rate than existing algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 15:50:22 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Wu", "Peilun", ""], ["Moustafa", "Nour", ""], ["Yang", "Shiyi", ""], ["Guo", "Hui", ""]]}, {"id": "2008.02307", "submitter": "Martin Schwarzl", "authors": "Martin Schwarzl, Thomas Schuster, Michael Schwarz, Daniel Gruss", "title": "Speculative Dereferencing of Registers:Reviving Foreshadow", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since 2016, multiple microarchitectural attacks have exploited an effect that\nis attributed to prefetching. These works observe that certain user-space\noperations can fetch kernel addresses into the cache. Fetching\nuser-inaccessible data into the cache enables KASLR breaks and assists various\nMeltdown-type attacks, especially Foreshadow.\n  In this paper, we provide a systematic analysis of the root cause of this\nprefetching effect. While we confirm the empirical results of previous papers,\nwe show that the attribution to a prefetching mechanism is fundamentally\nincorrect in all previous papers describing or exploiting this effect. In\nparticular, neither the prefetch instruction nor other user-space instructions\nactually prefetch kernel addresses into the cache, leading to incorrect\nconclusions and ineffectiveness of proposed defenses. The effect exploited in\nall of these papers is, in fact, caused by speculative dereferencing of\nuser-space registers in the kernel. Hence, mitigation techniques such as KAISER\ndo not eliminate this leakage as previously believed. Beyond our thorough\nanalysis of these previous works, we also demonstrate new attacks enabled by\nunderstanding the root cause, namely an address-translation attack in more\nrestricted contexts, direct leakage of register values in certain scenarios,\nand the first end-to-end Foreshadow (L1TF) exploit targeting non-L1 data. The\nlatter is effective even with the recommended Foreshadow mitigations enabled\nand thus revives the Foreshadow attack. We demonstrate that these dereferencing\neffects exist even on the most recent Intel CPUs with the latest hardware\nmitigations, and on CPUs previously believed to be unaffected, i.e., ARM, IBM,\nand AMD CPUs.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 18:28:49 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Schwarzl", "Martin", ""], ["Schuster", "Thomas", ""], ["Schwarz", "Michael", ""], ["Gruss", "Daniel", ""]]}, {"id": "2008.02315", "submitter": "Poorvi Vora", "authors": "Filip Zag\\'orski, Grant McClearn, Sarah Morin, Neal McBurnett, Poorvi\n  L. Vora", "title": "The ATHENA Class of Risk-Limiting Ballot Polling Audits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main risk-limiting ballot polling audit in use today, BRAVO, is designed\nfor use when single ballots are drawn at random and a decision regarding\nwhether to stop the audit or draw another ballot is taken after each ballot\ndraw (ballot-by-ballot (B2) audits). On the other hand, real ballot polling\naudits draw many ballots in a single round before determining whether to stop\n(round-by-round (R2) audits). We show that BRAVO results in significant\ninefficiency when directly applied to real R2 audits. We present the ATHENA\nclass of R2 stopping rules, which we show are risk-limiting if the round\nschedule is pre-determined (before the audit begins). We prove that each rule\nis at least as efficient as the corresponding BRAVO stopping rule applied at\nthe end of the round. We have open-source software libraries implementing most\nof our results.\n  We show that ATHENA halves the number of ballots required, for all state\nmargins in the 2016 US Presidential election and a first round with $90\\%$\nstopping probability, when compared to BRAVO (stopping rule applied at the end\nof the round). We present simulation results supporting the 90% stopping\nprobability claims and our claims for the risk accrued in the first round.\nFurther, ATHENA reduces the number of ballots by more than a quarter for low\nmargins, when compared to the BRAVO stopping rule applied on ballots in\nselection order. This implies that keeping track of the order when drawing\nballots R2 is not beneficial, because ATHENA is more efficient even without\ninformation on selection order. These results are significant because current\napproaches to real ballot polling election audits use the B2 BRAVO rules,\nrequiring about twice as much work on the part of election officials. Applying\nthe rules in selection order requires fewer ballots, but keeping track of the\norder, and entering it into audit software, adds to the effort.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 18:47:37 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2020 11:05:26 GMT"}, {"version": "v3", "created": "Sun, 13 Sep 2020 20:50:01 GMT"}, {"version": "v4", "created": "Sun, 4 Oct 2020 23:57:23 GMT"}, {"version": "v5", "created": "Sun, 21 Feb 2021 20:16:18 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Zag\u00f3rski", "Filip", ""], ["McClearn", "Grant", ""], ["Morin", "Sarah", ""], ["McBurnett", "Neal", ""], ["Vora", "Poorvi L.", ""]]}, {"id": "2008.02370", "submitter": "Sean Adamson", "authors": "Sean A. Adamson and Petros Wallden", "title": "Quantum Magic Rectangles: Characterization and Application to Certified\n  Randomness Expansion", "comments": "23 pages, 3 figures; published version with minor corrections", "journal-ref": "Phys. Rev. Research 2, 043317 (2020)", "doi": "10.1103/PhysRevResearch.2.043317", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a generalization of the Mermin-Peres magic square game to arbitrary\nrectangular dimensions. After exhibiting some general properties, these\nrectangular games are fully characterized in terms of their optimal win\nprobabilities for quantum strategies. We find that for $m \\times n$ rectangular\ngames of dimensions $m,n \\geq 3$ there are quantum strategies that win with\ncertainty, while for dimensions $1 \\times n$ quantum strategies do not\noutperform classical strategies. The final case of dimensions $2 \\times n$ is\nricher, and we give upper and lower bounds that both outperform the classical\nstrategies. Finally, we apply our findings to quantum certified randomness\nexpansion to find the noise tolerance and rates for all magic rectangle games.\nTo do this, we use our previous results to obtain the winning probability of\ngames with a distinguished input for which the devices give a deterministic\noutcome, and follow the analysis of C. A. Miller and Y. Shi [SIAM J. Comput.\n46, 1304 (2017)].\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 21:19:34 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 15:55:19 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 20:49:54 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Adamson", "Sean A.", ""], ["Wallden", "Petros", ""]]}, {"id": "2008.02450", "submitter": "AprilPyone MaungMaung", "authors": "MaungMaung AprilPyone and Hitoshi Kiya", "title": "Training DNN Model with Secret Key for Model Protection", "comments": "to appear in 2020 IEEE 9th Global Conference on Consumer Electronics\n  (GCCE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a model protection method by using block-wise pixel\nshuffling with a secret key as a preprocessing technique to input images for\nthe first time. The protected model is built by training with such preprocessed\nimages. Experiment results show that the performance of the protected model is\nclose to that of non-protected models when the key is correct, while the\naccuracy is severely dropped when an incorrect key is given, and the proposed\nmodel protection is robust against not only brute-force attacks but also\nfine-tuning attacks, while maintaining almost the same performance accuracy as\nthat of using a non-protected model.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 04:25:59 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["AprilPyone", "MaungMaung", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "2008.02507", "submitter": "Constantinos Patsakis", "authors": "Fran Casino, Nikolaos Lykousas, Ivan Homoliak, Constantinos Patsakis,\n  Julio Hernandez-Castro", "title": "Intercepting Hail Hydra: Real-Time Detection of Algorithmically\n  Generated Domains", "comments": "The dataset of this paper can be found in\n  https://zenodo.org/record/3965397", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A crucial technical challenge for cybercriminals is to keep control over the\npotentially millions of infected devices that build up their botnets, without\ncompromising the robustness of their attacks. A single, fixed C&C server, for\nexample, can be trivially detected either by binary or traffic analysis and\nimmediately sink-holed or taken-down by security researchers or law\nenforcement. Botnets often use Domain Generation Algorithms (DGAs), primarily\nto evade take-down mechanisms. DGAs enlarge the lifespan of a malware campaign,\nthus enhancing its profitability. They can also contribute to hardening attack\nattribution. In this work, we introduce HYDRA the most comprehensive and\ncomplete available dataset of Algorithmically-Generated Domains (AGD). The\ndataset contains more than 100 DGA families, including both real-world and\nadversarial ones. We analyse the dataset and discuss the possibility of\ndifferentiating between benign requests (to real domains) and malicious ones\n(to AGDs) in real-time. The simultaneous study of so many families and variants\nintroduces several challenges; nonetheless, it alleviates biases found in\nprevious literature that deals with small datasets and exploit some\ncharacteristic features of particular families. To this end, we thoroughly\ncompare our approach with the current state-of-the-art and highlight some\nmethodological shortcomings in the actual state of practice. The outcomes\nobtained show that our method significantly outperforms the current\nstate-of-the-art in terms of both accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 08:07:55 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Casino", "Fran", ""], ["Lykousas", "Nikolaos", ""], ["Homoliak", "Ivan", ""], ["Patsakis", "Constantinos", ""], ["Hernandez-Castro", "Julio", ""]]}, {"id": "2008.02609", "submitter": "Huafei Zhu", "authors": "Huafei Zhu", "title": "On the relationship between (secure) multi-party computation and\n  (secure) federated learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The contribution of this short note, contains the following two parts: in the\nfirst part, we are able to show that the federate learning (FL) procedure\npresented by Kairouz et al. \\cite{Kairouz1901}, is a random processing. Namely,\nan $m$-ary functionality for the FL procedure can be defined in the context of\nmulti-party computation (MPC); Furthermore, an instance of FL protocol along\nKairouz et al.'s definition can be viewed as an implementation of the defined\n$m$-ary functionality. As such, an instance of FL procedure is also an instance\nof MPC protocol. In short, FL is a subset of MPC.\n  To privately computing the defined FL (m-ary) functionality, various\ntechniques such as homomorphic encryption (HE), secure multi-party computation\n(SMPC) and differential privacy (DP) have been deployed. In the second part, we\nare able to show that if the underlying FL instance privately computes the\ndefined $m$-ary functionality in the simulation-based framework, then the\nsimulation-based FL solution is also an instance of SMPC. Consequently, SFL is\na subset of SMPC.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 12:41:09 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Zhu", "Huafei", ""]]}, {"id": "2008.02685", "submitter": "David Skillicorn", "authors": "L. Lapczyk, D.B. Skillicorn", "title": "Activity Detection from Encrypted Remote Desktop Protocol Traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing amount of Internet traffic has its content encrypted. We\naddress the question of whether it is possible to predict the activities taking\nplace over an encrypted channel, in particular Microsoft's Remote Desktop\nProtocol. We show that the presence of five typical activities can be detected\nwith precision greater than 97\\% and recall greater than 94\\% in 30-second\ntraces. We also show that the design of the protocol exposes fine-grained\nactions such as keystrokes and mouse movements which may be leveraged to reveal\nproperties such as lengths of passwords.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 14:36:15 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Lapczyk", "L.", ""], ["Skillicorn", "D. B.", ""]]}, {"id": "2008.02695", "submitter": "Jordan Holland", "authors": "Jordan Holland, Paul Schmitt, Nick Feamster, Prateek Mittal", "title": "New Directions in Automated Traffic Analysis", "comments": "18 pages, 9 tables, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the use of machine learning for many network traffic analysis tasks\nin security, from application identification to intrusion detection, the\naspects of the machine learning pipeline that ultimately determine the\nperformance of the model -- feature selection and representation, model\nselection, and parameter tuning -- remain manual and painstaking. This paper\npresents a method to automate many aspects of traffic analysis, making it\neasier to apply machine learning techniques to a wider variety of traffic\nanalysis tasks. We introduce nPrint, a tool that generates a unified packet\nrepresentation that is amenable for representation learning and model training.\nWe integrate nPrint with automated machine learning (AutoML), resulting in\nnPrintML, a public system that largely eliminates feature extraction and model\ntuning for a wide variety of traffic analysis tasks. We have evaluated nPrintML\non eight separate traffic analysis tasks and released nPrint, nPrintML and the\ncorresponding datasets from our evaluation to enable future work to extend\nthese methods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 14:53:26 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 15:16:07 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 19:45:23 GMT"}, {"version": "v4", "created": "Mon, 8 Feb 2021 16:36:15 GMT"}, {"version": "v5", "created": "Thu, 13 May 2021 16:01:30 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Holland", "Jordan", ""], ["Schmitt", "Paul", ""], ["Feamster", "Nick", ""], ["Mittal", "Prateek", ""]]}, {"id": "2008.02954", "submitter": "Wenjun Qiu", "authors": "Wenjun Qiu and David Lie", "title": "Deep Active Learning with Crowdsourcing Data for Privacy Policy\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy policies are statements that notify users of the services' data\npractices. However, few users are willing to read through policy texts due to\nthe length and complexity. While automated tools based on machine learning\nexist for privacy policy analysis, to achieve high classification accuracy,\nclassifiers need to be trained on a large labeled dataset. Most existing policy\ncorpora are labeled by skilled human annotators, requiring significant amount\nof labor hours and effort. In this paper, we leverage active learning and\ncrowdsourcing techniques to develop an automated classification tool named\nCalpric (Crowdsourcing Active Learning PRIvacy Policy Classifier), which is\nable to perform annotation equivalent to those done by skilled human annotators\nwith high accuracy while minimizing the labeling cost. Specifically, active\nlearning allows classifiers to proactively select the most informative segments\nto be labeled. On average, our model is able to achieve the same F1 score using\nonly 62% of the original labeling effort. Calpric's use of active learning also\naddresses naturally occurring class imbalance in unlabeled privacy policy\ndatasets as there are many more statements stating the collection of private\ninformation than stating the absence of collection. By selecting samples from\nthe minority class for labeling, Calpric automatically creates a more balanced\ntraining set.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 02:13:31 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Qiu", "Wenjun", ""], ["Lie", "David", ""]]}, {"id": "2008.02977", "submitter": "Alireza Poostindouz", "authors": "Alireza Poostindouz and Reihaneh Safavi-Naini", "title": "A Channel Model of Transceivers for Multiterminal Secret Key Agreement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information theoretic secret key agreement is impossible without making\ninitial assumptions. One type of initial assumption is correlated random\nvariables that are generated by using a noisy channel that connects the\nterminals. Terminals use the correlated random variables and communication over\na reliable public channel to arrive at a shared secret key. Previous channel\nmodels assume that each terminal either controls one input to the channel, or\nreceives one output variable of the channel. In this paper, we propose a new\nchannel model of transceivers where each terminal simultaneously controls an\ninput variable and observes an output variable of the (noisy) channel. We give\nupper and lower bounds for the secret key capacity (i.e., highest achievable\nkey rate) of this transceiver model, and prove the secret key capacity under\nthe conditions that the public communication is noninteractive and input\nvariables of the noisy channel are independent.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 03:32:22 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Poostindouz", "Alireza", ""], ["Safavi-Naini", "Reihaneh", ""]]}, {"id": "2008.02979", "submitter": "Iffat Anjum", "authors": "Iffat Anjum, Mu Zhu, Isaac Polinsky, William Enck, Michael K. Reiter,\n  Munindar Singh", "title": "Role-Based Deception in Enterprise Networks", "comments": "15 pages, 7 Figures, coference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Historically, enterprise network reconnaissance is an active process, often\ninvolving port scanning. However, as routers and switches become more complex,\nthey also become more susceptible to compromise. From this vantage point, an\nattacker can passively identify high-value hosts such as the workstations of IT\nadministrators, C-suite executives, and finance personnel. The goal of this\npaper is to develop a technique to deceive and dissuade such adversaries. We\npropose HoneyRoles, which uses honey connections to build metaphorical\nhaystacks around the network traffic of client hosts belonging to high-value\norganizational roles. The honey connections also act as network canaries to\nsignal network compromise, thereby dissuading the adversary from acting on\ninformation observed in network flows. We design a prototype implementation of\nHoneyRoles using an OpenFlow SDN controller and evaluate its security using the\nPRISM probabilistic model checker. Our performance evaluation shows that\nHoneyRoles has a small effect on network request completion time and our\nsecurity analysis demonstrates that once an alert is raised, HoneyRoles can\nquickly identify the compromised switch with high probability. In doing so, we\nshow that a role-based network deception is a promising approach for defending\nagainst adversaries that have compromised network devices.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 03:46:21 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Anjum", "Iffat", ""], ["Zhu", "Mu", ""], ["Polinsky", "Isaac", ""], ["Enck", "William", ""], ["Reiter", "Michael K.", ""], ["Singh", "Munindar", ""]]}, {"id": "2008.02987", "submitter": "Nalin Asanka Gamagedara Arachchilage", "authors": "Abdulrahman Alhazmi and Nalin Asanka Gamagedara Arachchilage", "title": "Why are Developers Struggling to Put GDPR into Practice when Developing\n  Privacy-Preserving Software Systems?", "comments": "5", "journal-ref": "USENIX Symposium on Usable Privacy and Security (SOUPS) 2020.\n  August 9 -- 11, 2020, Boston, MA, USA", "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of software applications is inevitable as they provide different\nservices to users. The software applications collect, store users' data, and\nsometimes share with the third party, even without the user consent. One can\nargue that software developers do not implement privacy into the software\napplications they develop or take GDPR (General Data Protection Law) law into\naccount. Failing to do this, may lead to software applications that open up\nprivacy breaches (e.g. data breach). The GDPR law provides a set of guidelines\nfor developers and organizations on how to protect user data when they are\ninteracting with software applications. Previous research has attempted to\ninvestigate what hinders developers from embedding privacy into software\nsystems. However, there has been no detailed investigation on why they cannot\ndevelop privacy-preserving systems taking GDPR into consideration, which is\nimperative to develop software applications that preserve privacy. Therefore,\nthis paper investigates the issues that hinder software developers from\nimplementing software applications taking GDPR law on-board. Our study findings\nrevealed that developers are not familiar with GDPR principles. Even some of\nthem are, they lack knowledge of the GDPR principles and their techniques to\nuse when developing privacy-preserving software systems\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 04:34:08 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Alhazmi", "Abdulrahman", ""], ["Arachchilage", "Nalin Asanka Gamagedara", ""]]}, {"id": "2008.03072", "submitter": "Philip Sperl", "authors": "Philip Sperl and Konstantin B\\\"ottinger", "title": "Optimizing Information Loss Towards Robust Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Networks (NNs) are vulnerable to adversarial examples. Such inputs\ndiffer only slightly from their benign counterparts yet provoke\nmisclassifications of the attacked NNs. The required perturbations to craft the\nexamples are often negligible and even human imperceptible. To protect deep\nlearning-based systems from such attacks, several countermeasures have been\nproposed with adversarial training still being considered the most effective.\nHere, NNs are iteratively retrained using adversarial examples forming a\ncomputational expensive and time consuming process often leading to a\nperformance decrease. To overcome the downsides of adversarial training while\nstill providing a high level of security, we present a new training approach we\ncall \\textit{entropic retraining}. Based on an information-theoretic-inspired\nanalysis, entropic retraining mimics the effects of adversarial training\nwithout the need of the laborious generation of adversarial examples. We\nempirically show that entropic retraining leads to a significant increase in\nNNs' security and robustness while only relying on the given original data.\nWith our prototype implementation we validate and show the effectiveness of our\napproach for various NN architectures and data sets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 10:12:31 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 14:28:06 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Sperl", "Philip", ""], ["B\u00f6ttinger", "Konstantin", ""]]}, {"id": "2008.03122", "submitter": "Fabio Priuli", "authors": "Fabio S. Priuli, Claudia Violante", "title": "Sulla decifratura di Enigma -- Come un reverendo del XVIII secolo\n  contribu\\`i alla sconfitta degli U-boot tedeschi durante la Seconda Guerra\n  Mondiale", "comments": "39 pages, 10 figures, in Italian", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GL cs.CR stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article, written in Italian language, explores the contribution given by\nBayes' rule and by subjective probability in the work at Bletchley Park towards\ncracking Enigma cyphered messages during WWII.\n  --\n  In questo articolo, scritto in Italiano, esploriamo il contributo dato dal\nteorema di Bayes e dalle idee della probabilit\\`a soggettiva nel lavoro\ncompiuto a Bletchley Park che ha portato a decifrare i messaggi cifrati con\nmacchine Enigma durante la Seconda Guerra Mondiale.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 05:04:37 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Priuli", "Fabio S.", ""], ["Violante", "Claudia", ""]]}, {"id": "2008.03210", "submitter": "Abhishek Kulkarni", "authors": "Abhishek N. Kulkarni and Jie Fu", "title": "A Theory of Hypergames on Graphs for Synthesizing Dynamic Cyber Defense\n  with Deception", "comments": "32 pages, 10 figures, 2 tables, Accepted Book Chapter in \"Game Theory\n  and Machine Learning for Cyber Security\" by Wiley-IEEE press, Editors:\n  Charles A. Kamhoua, Christopher D. Kiekintveld, Fei Fang, Quanyan Zhu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.GT cs.LO cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter, we present an approach using formal methods to synthesize\nreactive defense strategy in a cyber network, equipped with a set of decoy\nsystems. We first generalize formal graphical security models--attack\ngraphs--to incorporate defender's countermeasures in a game-theoretic model,\ncalled an attack-defend game on graph. This game captures the dynamic\ninteractions between the defender and the attacker and their defense/attack\nobjectives in formal logic. Then, we introduce a class of hypergames to model\nasymmetric information created by decoys in the attacker-defender interactions.\nGiven qualitative security specifications in formal logic, we show that the\nsolution concepts from hypergames and reactive synthesis in formal methods can\nbe extended to synthesize effective dynamic defense strategy using cyber\ndeception. The strategy takes the advantages of the misperception of the\nattacker to ensure security specification is satisfied, which may not be\nsatisfiable when the information is symmetric.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 14:59:28 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Kulkarni", "Abhishek N.", ""], ["Fu", "Jie", ""]]}, {"id": "2008.03252", "submitter": "Abdulmalik Alwarafy", "authors": "Abdulmalik Alwarafy, Khaled A. Al-Thelaya, Mohamed Abdallah (Senior\n  Member, IEEE), Jens Schneider, and Mounir Hamdi (Fellow Member, IEEE)", "title": "A Survey on Security and Privacy Issues in Edge Computing-Assisted\n  Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) is an innovative paradigm envisioned to provide\nmassive applications that are now part of our daily lives. Millions of smart\ndevices are deployed within complex networks to provide vibrant functionalities\nincluding communications, monitoring, and controlling of critical\ninfrastructures. However, this massive growth of IoT devices and the\ncorresponding huge data traffic generated at the edge of the network created\nadditional burdens on the state-of-the-art centralized cloud computing paradigm\ndue to the bandwidth and resources scarcity. Hence, edge computing (EC) is\nemerging as an innovative strategy that brings data processing and storage near\nto the end users, leading to what is called EC-assisted IoT. Although this\nparadigm provides unique features and enhanced quality of service (QoS), it\nalso introduces huge risks in data security and privacy aspects. This paper\nconducts a comprehensive survey on security and privacy issues in the context\nof EC-assisted IoT. In particular, we first present an overview of EC-assisted\nIoT including definitions, applications, architecture, advantages, and\nchallenges. Second, we define security and privacy in the context of\nEC-assisted IoT. Then, we extensively discuss the major classifications of\nattacks in EC-assisted IoT and provide possible solutions and countermeasures\nalong with the related research efforts. After that, we further classify some\nsecurity and privacy issues as discussed in the literature based on security\nservices and based on security objectives and functions. Finally, several open\nchallenges and future research directions for secure EC-assisted IoT paradigm\nare also extensively provided.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 20:24:55 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Alwarafy", "Abdulmalik", "", "Senior\n  Member, IEEE"], ["Al-Thelaya", "Khaled A.", "", "Senior\n  Member, IEEE"], ["Abdallah", "Mohamed", "", "Senior\n  Member, IEEE"], ["Schneider", "Jens", "", "Fellow Member, IEEE"], ["Hamdi", "Mounir", "", "Fellow Member, IEEE"]]}, {"id": "2008.03254", "submitter": "Kyle MacMillan", "authors": "Kyle MacMillan, Jordan Holland, Prateek Mittal", "title": "Evaluating Snowflake as an Indistinguishable Censorship Circumvention\n  Tool", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tor is the most well-known tool for circumventing censorship. Unfortunately,\nTor traffic has been shown to be detectable using deep-packet inspection.\nWebRTC is a popular web frame-work that enables browser-to-browser connections.\nSnowflake is a novel pluggable transport that leverages WebRTC to connect Tor\nclients to the Tor network. In theory, Snowflake was created to be\nindistinguishable from other WebRTC services. In this paper, we evaluate the\nindistinguishability of Snowflake. We collect over 6,500 DTLS handshakes from\nSnowflake, Facebook Messenger, Google Hangouts, and Discord WebRTC connections\nand show that Snowflake is identifiable among these applications with 100%\naccuracy. We show that several features, including the extensions offered and\nthe number of packets in the handshake, distinguish Snowflake among these\nservices. Finally, we suggest recommendations for improving identification\nresistance in Snowflake. We have made the dataset publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 17:36:22 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 21:57:38 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 15:08:49 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["MacMillan", "Kyle", ""], ["Holland", "Jordan", ""], ["Mittal", "Prateek", ""]]}, {"id": "2008.03290", "submitter": "Ayush Jain", "authors": "Ayush Jain, Ujjwal Guin", "title": "A Novel Tampering Attack on AES Cores with Hardware Trojans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The implementation of cryptographic primitives in integrated circuits (ICs)\ncontinues to increase over the years due to the recent advancement of\nsemiconductor manufacturing and reduction of cost per transistors. The hardware\nimplementation makes cryptographic operations faster and more energy-efficient.\nHowever, various hardware attacks have been proposed aiming to extract the\nsecret key in order to undermine the security of these primitives. In this\npaper, we focus on the widely used advanced encryption standard (AES) block\ncipher and demonstrate its vulnerability against tampering attack. Our proposed\nattack relies on implanting a hardware Trojan in the netlist by an untrusted\nfoundry, which can design and implement such a Trojan as it has access to the\ndesign layout and mask information. The hardware Trojan's activation modifies a\nparticular round's input data by preventing the effect of all previous rounds'\nkey-dependent computation. We propose to use a sequential hardware Trojan to\ndeliver the payload at the input of an internal round for achieving this\nmodification of data. All the internal subkeys, and finally, the secret key can\nbe computed from the observed ciphertext once the Trojan is activated. We\nimplement our proposed tampering attack with a sequential hardware Trojan\ninserted into a 128-bit AES design from OpenCores benchmark suite and report\nthe area overhead to demonstrate the feasibility of the proposed tampering\nattack.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 17:52:11 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Jain", "Ayush", ""], ["Guin", "Ujjwal", ""]]}, {"id": "2008.03297", "submitter": "MohammadNoor Injadat", "authors": "MohammadNoor Injadat, Abdallah Moubayed, Ali Bou Nassif, Abdallah\n  Shami", "title": "Multi-Stage Optimized Machine Learning Framework for Network Intrusion\n  Detection", "comments": "14 Pages, 13 Figures, 4 tables, Published IEEE Transactions on\n  Network and Service Management ( Early Access )", "journal-ref": "Electronic ISSN: 1932-4537", "doi": "10.1109/TNSM.2020.3014929", "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-security garnered significant attention due to the increased dependency\nof individuals and organizations on the Internet and their concern about the\nsecurity and privacy of their online activities. Several previous machine\nlearning (ML)-based network intrusion detection systems (NIDSs) have been\ndeveloped to protect against malicious online behavior. This paper proposes a\nnovel multi-stage optimized ML-based NIDS framework that reduces computational\ncomplexity while maintaining its detection performance. This work studies the\nimpact of oversampling techniques on the models' training sample size and\ndetermines the minimal suitable training sample size. Furthermore, it compares\nbetween two feature selection techniques, information gain and\ncorrelation-based, and explores their effect on detection performance and time\ncomplexity. Moreover, different ML hyper-parameter optimization techniques are\ninvestigated to enhance the NIDS's performance. The performance of the proposed\nframework is evaluated using two recent intrusion detection datasets, the\nCICIDS 2017 and the UNSW-NB 2015 datasets. Experimental results show that the\nproposed model significantly reduces the required training sample size (up to\n74%) and feature set size (up to 50%). Moreover, the model performance is\nenhanced with hyper-parameter optimization with detection accuracies over 99%\nfor both datasets, outperforming recent literature works by 1-2% higher\naccuracy and 1-2% lower false alarm rate.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 03:18:00 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Injadat", "MohammadNoor", ""], ["Moubayed", "Abdallah", ""], ["Nassif", "Ali Bou", ""], ["Shami", "Abdallah", ""]]}, {"id": "2008.03343", "submitter": "Pedro Miguel Sanchez Sanchez", "authors": "Pedro Miguel S\\'anchez S\\'anchez, Jose Mar\\'ia Jorquera Valero,\n  Alberto Huertas Celdr\\'an, G\\'er\\^ome Bovet, Manuel Gil P\\'erez, and Gregorio\n  Mart\\'inez P\\'erez", "title": "A Survey on Device Behavior Fingerprinting: Data Sources, Techniques,\n  Application Scenarios, and Datasets", "comments": null, "journal-ref": null, "doi": "10.1109/COMST.2021.3064259", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current network-based computing world, where the number of\ninterconnected devices grows exponentially, their diversity, malfunctions, and\ncybersecurity threats are increasing at the same rate. To guarantee the correct\nfunctioning and performance of novel environments such as Smart Cities,\nIndustry 4.0, or crowdsensing, it is crucial to identify the capabilities of\ntheir devices (e.g., sensors, actuators) and detect potential misbehavior that\nmay arise due to cyberattacks, system faults, or misconfigurations. With this\ngoal in mind, a promising research field emerged focusing on creating and\nmanaging fingerprints that model the behavior of both the device actions and\nits components. The article at hand studies the recent growth of the device\nbehavior fingerprinting field in terms of application scenarios, behavioral\nsources, and processing and evaluation techniques. First, it performs a\ncomprehensive review of the device types, behavioral data, and processing and\nevaluation techniques used by the most recent and representative research works\ndealing with two major scenarios: device identification and device misbehavior\ndetection. After that, each work is deeply analyzed and compared, emphasizing\nits characteristics, advantages, and limitations. This article also provides\nresearchers with a review of the most relevant characteristics of existing\ndatasets as most of the novel processing techniques are based on machine\nlearning and deep learning. Finally, it studies the evolution of these two\nscenarios in recent years, providing lessons learned, current trends, and\nfuture research challenges to guide new solutions in the area.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 19:23:33 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 18:44:04 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["S\u00e1nchez", "Pedro Miguel S\u00e1nchez", ""], ["Valero", "Jose Mar\u00eda Jorquera", ""], ["Celdr\u00e1n", "Alberto Huertas", ""], ["Bovet", "G\u00e9r\u00f4me", ""], ["P\u00e9rez", "Manuel Gil", ""], ["P\u00e9rez", "Gregorio Mart\u00ednez", ""]]}, {"id": "2008.03395", "submitter": "Chaitanya Rudrabhatla", "authors": "Chaitanya K. Rudrabhatla", "title": "Security Design Patterns in Distributed Microservice Architecture", "comments": null, "journal-ref": "IJCSIS July 2020, Vol. 18 No. 7 Publication", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Micro service architecture has revolutionized the landscape for the\ndevelopment of web and mobile applications alike. Due to the stateless nature\nand loose coupling involved in the design of micro services, native mobile\napplications can be developed by utilizing the same backend services which feed\nthe inputs to the web application front ends. Extending the same concept, a\nplethora of automated devices, thanks to the advancements in the field of IOT,\nhave come into existence which can feed on the same set of micro services. This\nconcept of build once and utilize for many use cases has become a new norm in\nthe enterprise design patterns. To handle the horizontal scalability needs of\nso many calling clients, significant advancements have been made on the\ncontainerization and their orchestration strategies on the public cloud\nplatforms. However, scalable design techniques have led to the increased\nexposure of backend services to unwanted entities. This broadened the attack\nsurface and also the risk. On top of it the mix of heterogeneous technologies\nin MSA, their distinct logging strategies, makes the central logging difficult,\nwhich in turn loosens the security. Additionally, the complexity around\nbuilding the resilience for fault tolerance across the decentralized networks,\nadds to the security loop holes. The simple security designs which were once\nused with traditional web applications cannot be used for Microservice based\napplications. This paper articulates the innovative approaches of handling the\nsecurity needs involved in protection of distributed services in Microservice\narchitecture.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 23:06:59 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Rudrabhatla", "Chaitanya K.", ""]]}, {"id": "2008.03406", "submitter": "Helen Jiang", "authors": "Helen Jiang", "title": "Security for People with Mental Illness in Telehealth Systems: A\n  Proposal", "comments": "Accepted to 5th Workshop on Inclusive Privacy and Security (WIPS) at\n  16th Symposium on Usable Privacy and Security (SOUPS), August 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mental health crisis is looming large, and needs to be addressed. But\nacross age groups, even just in the United States, more than 50% of people with\nany mental illness (AMI) did not seek or receive any service or treatment. The\nproliferation of telehealth and telepsychiatry tools and systems can help\naddress this crisis, but outside of traditional regulatory aspects on privacy,\ne.g. Health Insurance Portability and Accountability Act (HIPPA), there does\nnot seem to be enough attention on the security needs, concerns, or user\nexperience of people with AMI using those telehealth systems. In this text, I\ntry to explore some priority security properties for telehealth systems used by\npeople with AMI for mental heath services (MHS). I will also suggest some key\nsteps in a proposed process for designing and building security mechanisms into\nsuch systems, so that security is accessible and usable to patients with AMI,\nand these systems can achieve their goals of ameliorate this mental health\ncrisis.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 00:38:45 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Jiang", "Helen", ""]]}, {"id": "2008.03475", "submitter": "Shun Zhang", "authors": "Shun Zhang, Benfei Duan, Zhili Chen, Hong Zhong, Qizhi Yu", "title": "A Differentially Private Framework for Spatial Crowdsourcing with\n  Historical Data Learning", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial crowdsourcing (SC) is an increasing popular category of crowdsourcing\nin the era of mobile Internet and sharing economy. It requires workers to\narrive at a particular location for task fulfillment. Effective protection of\nlocation privacy is essential for workers' enthusiasm and valid task\nassignment. However, existing SC models with differential privacy usually\nperturb real-time location data for both partition and data publication. Such a\nway may produce large perturbations to counting queries that affect assignment\nsuccess rate and allocation accuracy. This paper proposes a framework (R-HT)\nfor protecting location privacy of workers taking advantage of both real-time\nand historical data. We simulate locations by sampling the probability\ndistribution learned from historical data, use them for grid partition, and\nthen publish real-time data under this partitioning with differential privacy.\nThis realizes that most privacy budget is allocated to the worker count of each\ncell and yields an improved Private Spatial Decomposition approach. Moreover,\nwe introduce some strategies for geocast region construction, including quality\nscoring function and local maximum geocast radius. A series of experimental\nresults on real-world datasets shows that R-HT attains a stable success rate of\ntask assignment, saves performance overhead and fits for dynamic assignment on\ncrowdsourcing platforms.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 08:32:06 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 13:18:46 GMT"}, {"version": "v3", "created": "Thu, 5 Nov 2020 05:42:04 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Zhang", "Shun", ""], ["Duan", "Benfei", ""], ["Chen", "Zhili", ""], ["Zhong", "Hong", ""], ["Yu", "Qizhi", ""]]}, {"id": "2008.03554", "submitter": "Sharbani Pandit", "authors": "Sharbani Pandit, Jienan Liu, Roberto Perdisci, Mustaque Ahamad", "title": "Fighting Voice Spam with a Virtual Assistant Prototype", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mass robocalls affect millions of people on a daily basis. Unfortunately,\nmost current defenses against robocalls rely on phone blocklists and are\nineffective against caller ID spoofing. To enable the detection of spoofed\nrobocalls, we propose a {\\em virtual assistant} application that could be\nintegrated on smartphones to automatically vet incoming calls. Similar to a\nhuman assistant, the virtual assistant can pick up an incoming call and screen\nit without user interruption to determine if the call is unwanted. Via a user\nstudy, we show that our virtual assistant is able to preserve the user\nexperience of a typical phone call. At the same time, we show that our system\ncan detect mass robocalls without negatively impacting legitimate callers.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 16:33:16 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Pandit", "Sharbani", ""], ["Liu", "Jienan", ""], ["Perdisci", "Roberto", ""], ["Ahamad", "Mustaque", ""]]}, {"id": "2008.03593", "submitter": "Trent Jaeger", "authors": "Yu-Tsung Lee, William Enck, Haining Chen, Hayawardh Vijayakumar,\n  Ninghui Li, Daimeng Wang, Zhiyun Qian, Giuseppe Petracca, Trent Jaeger", "title": "PolyScope: Multi-Policy Access Control Analysis to Triage Android\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android filesystem access control provides a foundation for Android system\nintegrity. Android utilizes a combination of mandatory (e.g., SEAndroid) and\ndiscretionary (e.g., UNIX permissions) access control, both to protect the\nAndroid platform from Android/OEM services and to protect Android/OEM services\nfrom third-party apps. However, OEMs often create vulnerabilities when they\nintroduce market-differentiating features because they err when re-configuring\nthis complex combination of Android policies. In this paper, we propose the\nPolyScope tool to triage the combination of Android filesystem access control\npolicies to vet releases for vulnerabilities. The PolyScope approach leverages\ntwo main insights: (1) adversaries may exploit the coarse granularity of\nmandatory policies and the flexibility of discretionary policies to increase\nthe permissions available to launch attacks, which we call permission\nexpansion, and (2) system configurations may limit the ways adversaries may use\ntheir permissions to launch attacks, motivating computation of attack\noperations. We apply PolyScope to three Google and five OEM Android releases to\ncompute the attack operations accurately to vet these releases for\nvulnerabilities, finding that permission expansion increases the permissions\navailable to launch attacks, sometimes by more than 10X, but a significant\nfraction of these permissions (about 15-20%) are not convertible into attack\noperations. Using PolyScope, we find two previously unknown vulnerabilities,\nshowing how PolyScope helps OEMs triage the complex combination of access\ncontrol policies down to attack operations worthy of testing.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 20:47:40 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Lee", "Yu-Tsung", ""], ["Enck", "William", ""], ["Chen", "Haining", ""], ["Vijayakumar", "Hayawardh", ""], ["Li", "Ninghui", ""], ["Wang", "Daimeng", ""], ["Qian", "Zhiyun", ""], ["Petracca", "Giuseppe", ""], ["Jaeger", "Trent", ""]]}, {"id": "2008.03621", "submitter": "David Rudo", "authors": "David Rudo and Dr. Kai Zeng", "title": "Consumer UAV Cybersecurity Vulnerability Assessment Using Fuzzing Tests", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned Aerial Vehicles (UAVs) are remote-controlled vehicles capable of\nflight and are present in a variety of environments from military operations to\ndomestic enjoyment. These vehicles are great assets, but just as their pilot\ncan control them remotely, cyberattacks can be executed in a similar manner.\nCyber attacks on UAVs can bring a plethora of issues to physical and virtual\nsystems. Such malfunctions are capable of giving an attacker the ability to\nsteal data, incapacitate the UAV, or hijack the UAV. To mitigate such attacks,\nit is necessary to identify and patch vulnerabilities that may be maliciously\nexploited. In this paper, a new UAV vulnerability is explored with related UAV\nsecurity practices identified for possible exploitation using large streams of\ndata sent at specific ports. The more in-depth model involves strings of data\ninvolving FTP-specific keywords sent to the UAV's FTP port in the form of a\nfuzzing test and launching thousands of packets at other ports on the UAV as\nwell. During these tests, virtual and physical systems are monitored\nextensively to identify specific patterns and vulnerabilities. This model is\napplied to a Parrot Bebop 2, which accurately portrays a UAV that had their\nnetwork compromised by an attacker and portrays many lower-end UAV models for\ndomestic use. During testings, the Parrot Bebop 2 is monitored for degradation\nin GPS performance, video speed, the UAV's reactivity to the pilot, motor\nfunction, and the accuracy of the UAV's sensor data. All these points of\nmonitoring give a comprehensive view of the UAV's reaction to each individual\ntest. In this paper, countermeasures to combat the exploitation of this\nvulnerability will be discussed as well as possible attacks that can branch\nfrom the fuzzing tests.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 00:40:54 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Rudo", "David", ""], ["Zeng", "Dr. Kai", ""]]}, {"id": "2008.03677", "submitter": "Mohammad Hashemi", "authors": "Mohammad J. Hashemi, Eric Keller", "title": "Enhancing Robustness Against Adversarial Examples in Network Intrusion\n  Detection Systems", "comments": "Submitted to 6th IEEE Conference on Network Functions Virtualization\n  and Software Defined Networks (IEEE NFV-SDN 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increase of cyber attacks in both the numbers and varieties in recent\nyears demands to build a more sophisticated network intrusion detection system\n(NIDS). These NIDS perform better when they can monitor all the traffic\ntraversing through the network like when being deployed on a Software-Defined\nNetwork (SDN). Because of the inability to detect zero-day attacks,\nsignature-based NIDS which were traditionally used for detecting malicious\ntraffic are beginning to get replaced by anomaly-based NIDS built on neural\nnetworks. However, recently it has been shown that such NIDS have their own\ndrawback namely being vulnerable to the adversarial example attack. Moreover,\nthey were mostly evaluated on the old datasets which don't represent the\nvariety of attacks network systems might face these days. In this paper, we\npresent Reconstruction from Partial Observation (RePO) as a new mechanism to\nbuild an NIDS with the help of denoising autoencoders capable of detecting\ndifferent types of network attacks in a low false alert setting with an\nenhanced robustness against adversarial example attack. Our evaluation\nconducted on a dataset with a variety of network attacks shows denoising\nautoencoders can improve detection of malicious traffic by up to 29% in a\nnormal setting and by up to 45% in an adversarial setting compared to other\nrecently proposed anomaly detectors.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 07:04:06 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Hashemi", "Mohammad J.", ""], ["Keller", "Eric", ""]]}, {"id": "2008.03681", "submitter": "Zoubir Hamici", "authors": "Zoubir Hamici", "title": "Randomness Evaluation of a Genetic Algorithm for Image Encryption: A\n  Signal Processing Approach", "comments": "10 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a randomness evaluation of a block cipher for secure image\ncommunication is presented. The GFHT cipher is a genetic algorithm, that\ncombines gene fusion (GF) and horizontal gene transfer (HGT) both inspired from\nantibiotic resistance in bacteria. The symmetric encryption key is generated by\nfour pairs of chromosomes with multi-layer random sequences. The encryption\nstarts by a GF of the principal key-agent in a single block, then HGT performs\nobfuscation where the genes are pixels and the chromosomes are the rows and\ncolumns. A Salt extracted from the image hash-value is used to implement\none-time pad (OTP) scheme, hence a modification of one pixel generates a\ndifferent encryption key without changing the main passphrase or key.\nTherefore, an extreme avalanche effect of 99% is achieved. Randomness\nevaluation based on random matrix theory, power spectral density, avalanche\neffect, 2D auto-correlation, pixels randomness tests and chi-square hypotheses\ntesting show that encrypted images adopt the statistical behavior of uniform\nwhite noise; hence validating the theoretical model by experimental results.\nMoreover, performance comparison with chaos-genetic ciphers shows the merit of\nthe GFHT algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 07:50:29 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Hamici", "Zoubir", ""]]}, {"id": "2008.03686", "submitter": "Mengmeng Yang", "authors": "Mengmeng Yang, Lingjuan Lyu, Jun Zhao, Tianqing Zhu, Kwok-Yan Lam", "title": "Local Differential Privacy and Its Applications: A Comprehensive Survey", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the fast development of Information Technology, a tremendous amount of\ndata have been generated and collected for research and analysis purposes. As\nan increasing number of users are growing concerned about their personal\ninformation, privacy preservation has become an urgent problem to be solved and\nhas attracted significant attention. Local differential privacy (LDP), as a\nstrong privacy tool, has been widely deployed in the real world in recent\nyears. It breaks the shackles of the trusted third party, and allows users to\nperturb their data locally, thus providing much stronger privacy protection.\nThis survey provides a comprehensive and structured overview of the local\ndifferential privacy technology. We summarise and analyze state-of-the-art\nresearch in LDP and compare a range of methods in the context of answering a\nvariety of queries and training different machine learning models. We discuss\nthe practical deployment of local differential privacy and explore its\napplication in various domains. Furthermore, we point out several research\ngaps, and discuss promising future research directions.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 08:16:11 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Yang", "Mengmeng", ""], ["Lyu", "Lingjuan", ""], ["Zhao", "Jun", ""], ["Zhu", "Tianqing", ""], ["Lam", "Kwok-Yan", ""]]}, {"id": "2008.03872", "submitter": "Majid Khabbazian", "authors": "Alireza Hafez and Dorsa Nahid and Majid Khabbazian", "title": "Barometers Can Hear, and Sense Finger Taps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most modern smartphones are equipped with a barometer to sample air pressure.\nAccessing these samples is deemed harmless, hence does not require any\npermission. In this work, we show, however, that these samples can reveal\nsensitive information in smartphones with ingress protection. For the first\ntime, it is shown that barometer samples, even at a low rate of 25 Hz, can leak\ninformation about the smartphone's speaker activity. Specifically, we use these\nsamples to detect with high accuracy (>= 95%) whether the smartphone's speaker\nis silent or playing a sound such as a ringtone. In addition, we use the\nsamples to detect the activity of an external speaker. Finally, we show that\nlow-rate barometer samples can be used to 1) detect touchscreen finger taps\nwith 100% accuracy, and 2) gain information about the positions of finger taps.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 02:56:58 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Hafez", "Alireza", ""], ["Nahid", "Dorsa", ""], ["Khabbazian", "Majid", ""]]}, {"id": "2008.03913", "submitter": "Max Maass", "authors": "Steffen Klee, Alexandros Roussos, Max Maass, Matthias Hollick", "title": "NFCGate: Opening the Door for NFC Security Research with a\n  Smartphone-Based Toolkit", "comments": "Accepted to Usenix WOOT'20. Source Code and binaries available at\n  https://github.com/nfcgate/nfcgate", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Near-Field Communication (NFC) is being used in a variety of\nsecurity-critical applications, from access control to payment systems.\nHowever, NFC protocol analysis typically requires expensive or conspicuous\ndedicated hardware, or is severely limited on smartphones. In 2015, the NFCGate\nproof of concept aimed at solving this issue by providing capabilities for NFC\nanalysis employing off-the-shelf Android smartphones.\n  In this paper, we present an extended and improved NFC toolkit based on the\nfunctionally limited original open-source codebase. With in-flight traffic\nanalysis and modification, relay, and replay features this toolkit turns an\noff-the-shelf smartphone into a powerful NFC research tool. To support the\ndevelopment of countermeasures against relay attacks, we investigate the\nlatency incurred by NFCGate in different configurations.\n  Our newly implemented features and improvements enable the case study of an\naward-winning, enterprise-level NFC lock from a well-known European lock\nvendor, which would otherwise require dedicated hardware. The analysis of the\nlock reveals several security issues, which were disclosed to the vendor.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 06:14:05 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Klee", "Steffen", ""], ["Roussos", "Alexandros", ""], ["Maass", "Max", ""], ["Hollick", "Matthias", ""]]}, {"id": "2008.04113", "submitter": "Abigail Goldsteen", "authors": "Abigail Goldsteen, Gilad Ezov, Ron Shmelkin, Micha Moffie, Ariel\n  Farkash", "title": "Data Minimization for GDPR Compliance in Machine Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The EU General Data Protection Regulation (GDPR) mandates the principle of\ndata minimization, which requires that only data necessary to fulfill a certain\npurpose be collected. However, it can often be difficult to determine the\nminimal amount of data required, especially in complex machine learning models\nsuch as neural networks. We present a first-of-a-kind method to reduce the\namount of personal data needed to perform predictions with a machine learning\nmodel, by removing or generalizing some of the input features. Our method makes\nuse of the knowledge encoded within the model to produce a generalization that\nhas little to no impact on its accuracy. This enables the creators and users of\nmachine learning models to acheive data minimization, in a provable manner.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 08:21:15 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Goldsteen", "Abigail", ""], ["Ezov", "Gilad", ""], ["Shmelkin", "Ron", ""], ["Moffie", "Micha", ""], ["Farkash", "Ariel", ""]]}, {"id": "2008.04176", "submitter": "Triet Le", "authors": "Triet H. M. Le, Roland Croft, David Hin, M. Ali Babar", "title": "A Large-scale Study of Security Vulnerability Support on Developer Q&A\n  Websites", "comments": "Accepted for publication at the 25th International Conference on\n  Evaluation and Assessment in Software Engineering (EASE 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Context: Security Vulnerabilities (SVs) pose many serious threats to software\nsystems. Developers usually seek solutions to addressing these SVs on developer\nQuestion and Answer (Q&A) websites. However, there is still little known about\non-going SV-specific discussions on different developer Q&A sites. Objective:\nWe present a large-scale empirical study to understand developers' SV\ndiscussions and how these discussions are being supported by Q&A sites. Method:\nWe first curate 71,329 SV posts from two large Q&A sites, namely Stack Overflow\n(SO) and Security StackExchange (SSE). We then use topic modeling to uncover\nthe topics of SV-related discussions and analyze the popularity, difficulty,\nand level of expertise for each topic. We also perform a qualitative analysis\nto identify the types of solutions to SV-related questions. Results: We\nidentify 13 main SV discussion topics on Q&A sites. Many topics do not follow\nthe distributions and trends in expert-based security sources such as Common\nWeakness Enumeration (CWE) and Open Web Application Security Project (OWASP).\nWe also discover that SV discussions attract more experts to answer than many\nother domains, but some difficult SV topics (e.g., Vulnerability Scanning\nTools) still receive quite limited support from experts. Moreover, we identify\nseven key types of answers given to SV questions on Q&A sites, in which SO\noften provides code and instructions, while SSE usually gives experience-based\nadvice and explanations. Conclusion: Our findings provide support for\nresearchers and practitioners to effectively acquire, share and leverage SV\nknowledge on Q&A sites.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 14:58:23 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 13:55:45 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Le", "Triet H. M.", ""], ["Croft", "Roland", ""], ["Hin", "David", ""], ["Babar", "M. Ali", ""]]}, {"id": "2008.04357", "submitter": "Sinan Aksoy", "authors": "Sinan G. Aksoy, Emilie Purvine, Stephen J. Young", "title": "Directional Laplacian Centrality for Cyber Situational Awareness", "comments": "25 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber operations is drowning in diverse, high-volume, multi-source data. In\norder to get a full picture of current operations and identify malicious events\nand actors analysts must see through data generated by a mix of human activity\nand benign automated processes. Although many monitoring and alert systems\nexist, they typically use signature-based detection methods. We introduce a\ngeneral method rooted in spectral graph theory to discover patterns and\nanomalies without a priori knowledge of signatures. We derive and propose a new\ngraph-theoretic centrality measure based on the derivative of the graph\nLaplacian matrix in the direction of a vertex. To build intuition about our\nmeasure we show how it identifies the most central vertices in standard network\ndata sets and compare to other graph centrality measures. Finally, we focus our\nattention on studying its effectiveness in identifying important IP addresses\nin network flow data. Using both real and synthetic network flow data, we\nconduct several experiments to test our measure's sensitivity to two types of\ninjected attack profiles, and show that vertices participating in injected\nattack profiles exhibit noticeable changes in our centrality measures, even\nwhen the injected anomalies are relatively small, and in the presence of\nsimulated network dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 18:42:20 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 23:58:57 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Aksoy", "Sinan G.", ""], ["Purvine", "Emilie", ""], ["Young", "Stephen J.", ""]]}, {"id": "2008.04377", "submitter": "Asaf Shabtai", "authors": "Hodaya Binyamini, Ron Bitton, Masaki Inokuchi, Tomohiko Yagyu, Yuval\n  Elovici, Asaf Shabtai", "title": "An Automated, End-to-End Framework for Modeling Attacks From\n  Vulnerability Descriptions", "comments": "16 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attack graphs are one of the main techniques used to automate the risk\nassessment process. In order to derive a relevant attack graph, up-to-date\ninformation on known attack techniques should be represented as interaction\nrules. Designing and creating new interaction rules is not a trivial task and\ncurrently performed manually by security experts. However, since the number of\nnew security vulnerabilities and attack techniques continuously and rapidly\ngrows, there is a need to frequently update the rule set of attack graph tools\nwith new attack techniques to ensure that the set of interaction rules is\nalways up-to-date. We present a novel, end-to-end, automated framework for\nmodeling new attack techniques from textual description of a security\nvulnerability. Given a description of a security vulnerability, the proposed\nframework first extracts the relevant attack entities required to model the\nattack, completes missing information on the vulnerability, and derives a new\ninteraction rule that models the attack; this new rule is integrated within\nMulVAL attack graph tool. The proposed framework implements a novel pipeline\nthat includes a dedicated cybersecurity linguistic model trained on the the NVD\nrepository, a recurrent neural network model used for attack entity extraction,\na logistic regression model used for completing the missing information, and a\nnovel machine learning-based approach for automatically modeling the attacks as\nMulVAL's interaction rule. We evaluated the performance of each of the\nindividual algorithms, as well as the complete framework and demonstrated its\neffectiveness.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 19:27:34 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Binyamini", "Hodaya", ""], ["Bitton", "Ron", ""], ["Inokuchi", "Masaki", ""], ["Yagyu", "Tomohiko", ""], ["Elovici", "Yuval", ""], ["Shabtai", "Asaf", ""]]}, {"id": "2008.04449", "submitter": "Rosario Cammarota", "authors": "Rosario Cammarota, Matthias Schunter, Anand Rajan, Fabian Boemer,\n  \\'Agnes Kiss, Amos Treiber, Christian Weinert, Thomas Schneider, Emmanuel\n  Stapf, Ahmad-Reza Sadeghi, Daniel Demmler, Huili Chen, Siam Umar Hussain,\n  Sadegh Riazi, Farinaz Koushanfar, Saransh Gupta, Tajan Simunic Rosing,\n  Kamalika Chaudhuri, Hamid Nejatollahi, Nikil Dutt, Mohsen Imani, Kim Laine,\n  Anuj Dubey, Aydin Aysu, Fateme Sadat Hosseini, Chengmo Yang, Eric Wallace,\n  Pamela Norton", "title": "Trustworthy AI Inference Systems: An Industry Research View", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.AR cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we provide an industry research view for approaching the\ndesign, deployment, and operation of trustworthy Artificial Intelligence (AI)\ninference systems. Such systems provide customers with timely, informed, and\ncustomized inferences to aid their decision, while at the same time utilizing\nappropriate security protection mechanisms for AI models. Additionally, such\nsystems should also use Privacy-Enhancing Technologies (PETs) to protect\ncustomers' data at any time.\n  To approach the subject, we start by introducing trends in AI inference\nsystems. We continue by elaborating on the relationship between Intellectual\nProperty (IP) and private data protection in such systems. Regarding the\nprotection mechanisms, we survey the security and privacy building blocks\ninstrumental in designing, building, deploying, and operating private AI\ninference systems. For example, we highlight opportunities and challenges in AI\nsystems using trusted execution environments combined with more recent advances\nin cryptographic techniques to protect data in use. Finally, we outline areas\nof further development that require the global collective attention of\nindustry, academia, and government researchers to sustain the operation of\ntrustworthy AI inference systems.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 23:05:55 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Cammarota", "Rosario", ""], ["Schunter", "Matthias", ""], ["Rajan", "Anand", ""], ["Boemer", "Fabian", ""], ["Kiss", "\u00c1gnes", ""], ["Treiber", "Amos", ""], ["Weinert", "Christian", ""], ["Schneider", "Thomas", ""], ["Stapf", "Emmanuel", ""], ["Sadeghi", "Ahmad-Reza", ""], ["Demmler", "Daniel", ""], ["Chen", "Huili", ""], ["Hussain", "Siam Umar", ""], ["Riazi", "Sadegh", ""], ["Koushanfar", "Farinaz", ""], ["Gupta", "Saransh", ""], ["Rosing", "Tajan Simunic", ""], ["Chaudhuri", "Kamalika", ""], ["Nejatollahi", "Hamid", ""], ["Dutt", "Nikil", ""], ["Imani", "Mohsen", ""], ["Laine", "Kim", ""], ["Dubey", "Anuj", ""], ["Aysu", "Aydin", ""], ["Hosseini", "Fateme Sadat", ""], ["Yang", "Chengmo", ""], ["Wallace", "Eric", ""], ["Norton", "Pamela", ""]]}, {"id": "2008.04477", "submitter": "Farhad Farokhi", "authors": "Farhad Farokhi and Peyman Mohajerin Esfahani", "title": "Security Versus Privacy", "comments": null, "journal-ref": "2018 IEEE Conference on Decision and Control (CDC)", "doi": "10.1109/CDC.2018.8619460", "report-no": null, "categories": "cs.CR cs.IT cs.SY eess.SY math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear queries can be submitted to a server containing private data. The\nserver provides a response to the queries systematically corrupted using an\nadditive noise to preserve the privacy of those whose data is stored on the\nserver. The measure of privacy is inversely proportional to the trace of the\nFisher information matrix. It is assumed that an adversary can inject a false\nbias to the responses. The measure of the security, capturing the ease of\ndetecting the presence of the false data injection, is the sensitivity of the\nKullback-Leiber divergence to the additive bias. An optimization problem for\nbalancing privacy and security is proposed and subsequently solved. It is shown\nthat the level of guaranteed privacy times the level of security equals a\nconstant. Therefore, by increasing the level of privacy, the security\nguarantees can only be weakened and vice versa. Similar results are developed\nunder the differential privacy framework.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 02:04:58 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Farokhi", "Farhad", ""], ["Esfahani", "Peyman Mohajerin", ""]]}, {"id": "2008.04480", "submitter": "Umar Iqbal", "authors": "Umar Iqbal (1), Steven Englehardt (2), Zubair Shafiq (3) ((1) The\n  University of Iowa, (2) Mozilla Corporation, (3) University of California,\n  Davis)", "title": "Fingerprinting the Fingerprinters: Learning to Detect Browser\n  Fingerprinting Behaviors", "comments": "To appear in the Proceedings of the IEEE Symposium on Security &\n  Privacy 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Browser fingerprinting is an invasive and opaque stateless tracking\ntechnique. Browser vendors, academics, and standards bodies have long struggled\nto provide meaningful protections against browser fingerprinting that are both\naccurate and do not degrade user experience. We propose FP-Inspector, a machine\nlearning based syntactic-semantic approach to accurately detect browser\nfingerprinting. We show that FP-Inspector performs well, allowing us to detect\n26% more fingerprinting scripts than the state-of-the-art. We show that an\nAPI-level fingerprinting countermeasure, built upon FP-Inspector, helps reduce\nwebsite breakage by a factor of 2. We use FP-Inspector to perform a measurement\nstudy of browser fingerprinting on top-100K websites. We find that browser\nfingerprinting is now present on more than 10% of the top-100K websites and\nover a quarter of the top-10K websites. We also discover previously unreported\nuses of JavaScript APIs by fingerprinting scripts suggesting that they are\nlooking to exploit APIs in new and unexpected ways.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 02:12:23 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Iqbal", "Umar", ""], ["Englehardt", "Steven", ""], ["Shafiq", "Zubair", ""]]}, {"id": "2008.04495", "submitter": "Jinyuan Jia", "authors": "Jinyuan Jia and Xiaoyu Cao and Neil Zhenqiang Gong", "title": "Intrinsic Certified Robustness of Bagging against Data Poisoning Attacks", "comments": "Accepted by AAAI'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In a \\emph{data poisoning attack}, an attacker modifies, deletes, and/or\ninserts some training examples to corrupt the learnt machine learning model.\n\\emph{Bootstrap Aggregating (bagging)} is a well-known ensemble learning\nmethod, which trains multiple base models on random subsamples of a training\ndataset using a base learning algorithm and uses majority vote to predict\nlabels of testing examples. We prove the intrinsic certified robustness of\nbagging against data poisoning attacks. Specifically, we show that bagging with\nan arbitrary base learning algorithm provably predicts the same label for a\ntesting example when the number of modified, deleted, and/or inserted training\nexamples is bounded by a threshold. Moreover, we show that our derived\nthreshold is tight if no assumptions on the base learning algorithm are made.\nWe evaluate our method on MNIST and CIFAR10. For instance, our method achieves\na certified accuracy of $91.1\\%$ on MNIST when arbitrarily modifying, deleting,\nand/or inserting 100 training examples. Code is available at:\n\\url{https://github.com/jjy1994/BaggingCertifyDataPoisoning}.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 03:12:42 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 01:48:26 GMT"}, {"version": "v3", "created": "Fri, 4 Sep 2020 00:42:43 GMT"}, {"version": "v4", "created": "Wed, 23 Sep 2020 18:49:26 GMT"}, {"version": "v5", "created": "Mon, 5 Oct 2020 20:41:55 GMT"}, {"version": "v6", "created": "Tue, 8 Dec 2020 16:17:16 GMT"}, {"version": "v7", "created": "Wed, 9 Dec 2020 21:44:40 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Jia", "Jinyuan", ""], ["Cao", "Xiaoyu", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "2008.04500", "submitter": "Jingyi Wang", "authors": "Jiahao Ding and Jingyi Wang and Guannan Liang and Jinbo Bi and Miao\n  Pan", "title": "Towards Plausible Differentially Private ADMM Based Distributed Machine\n  Learning", "comments": "Comments: Accepted for publication in CIKM'20", "journal-ref": null, "doi": "10.1145/3340531.3411860", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Alternating Direction Method of Multipliers (ADMM) and its distributed\nversion have been widely used in machine learning. In the iterations of ADMM,\nmodel updates using local private data and model exchanges among agents impose\ncritical privacy concerns. Despite some pioneering works to relieve such\nconcerns, differentially private ADMM still confronts many research challenges.\nFor example, the guarantee of differential privacy (DP) relies on the premise\nthat the optimality of each local problem can be perfectly attained in each\nADMM iteration, which may never happen in practice. The model trained by DP\nADMM may have low prediction accuracy. In this paper, we address these concerns\nby proposing a novel (Improved) Plausible differentially Private ADMM\nalgorithm, called PP-ADMM and IPP-ADMM. In PP-ADMM, each agent approximately\nsolves a perturbed optimization problem that is formulated from its local\nprivate data in an iteration, and then perturbs the approximate solution with\nGaussian noise to provide the DP guarantee. To further improve the model\naccuracy and convergence, an improved version IPP-ADMM adopts sparse vector\ntechnique (SVT) to determine if an agent should update its neighbors with the\ncurrent perturbed solution. The agent calculates the difference of the current\nsolution from that in the last iteration, and if the difference is larger than\na threshold, it passes the solution to neighbors; or otherwise the solution\nwill be discarded. Moreover, we propose to track the total privacy loss under\nthe zero-concentrated DP (zCDP) and provide a generalization performance\nanalysis. Experiments on real-world datasets demonstrate that under the same\nprivacy guarantee, the proposed algorithms are superior to the state of the art\nin terms of model accuracy and convergence rate.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 03:40:55 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Ding", "Jiahao", ""], ["Wang", "Jingyi", ""], ["Liang", "Guannan", ""], ["Bi", "Jinbo", ""], ["Pan", "Miao", ""]]}, {"id": "2008.04516", "submitter": "Shiqi Shen", "authors": "Shiqi Shen, Aashish Kolluri, Zhen Dong, Prateek Saxena and Abhik\n  Roychoudhury", "title": "Localizing Patch Points From One Exploit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic patch generation can significantly reduce the window of exposure\nafter a vulnerability is disclosed. Towards this goal, a long-standing problem\nhas been that of patch localization: to find a program point at which a patch\ncan be synthesized. We present PatchLoc, one of the first systems which\nautomatically identifies such a location in a vulnerable binary, given just one\nexploit, with high accuracy. PatchLoc does not make any assumptions about the\navailability of source code, test suites, or specialized knowledge of the\nvulnerability. PatchLoc pinpoints valid patch locations in large real-world\napplications with high accuracy for about 88% of 43 CVEs we study. These\nresults stem from a novel approach to automatically synthesizing a test-suite\nwhich enables probabilistically ranking and effectively differentiating between\ncandidate program patch locations.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 05:22:11 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Shen", "Shiqi", ""], ["Kolluri", "Aashish", ""], ["Dong", "Zhen", ""], ["Saxena", "Prateek", ""], ["Roychoudhury", "Abhik", ""]]}, {"id": "2008.04568", "submitter": "Bodin Chinthanet", "authors": "Bodin Chinthanet, Serena Elisa Ponta, Henrik Plate, Antonino Sabetta,\n  Raula Gaikovina Kula, Takashi Ishio, Kenichi Matsumoto", "title": "Code-based Vulnerability Detection in Node.js Applications: How far are\n  we?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With one of the largest available collection of reusable packages, the\nJavaScript runtime environment Node.js is one of the most popular programming\napplication. With recent work showing evidence that known vulnerabilities are\nprevalent in both open source and industrial software, we propose and implement\na viable code-based vulnerability detection tool for Node.js applications. Our\ncase study lists the challenges encountered while implementing our Node.js\nvulnerable code detector.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 07:57:58 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Chinthanet", "Bodin", ""], ["Ponta", "Serena Elisa", ""], ["Plate", "Henrik", ""], ["Sabetta", "Antonino", ""], ["Kula", "Raula Gaikovina", ""], ["Ishio", "Takashi", ""], ["Matsumoto", "Kenichi", ""]]}, {"id": "2008.04632", "submitter": "Alex Shafarenko", "authors": "Alex Shafarenko", "title": "A PLS blockchain for IoT applications: protocols and architecture", "comments": "24 pages, 5 figures", "journal-ref": "Cybersecur 4, 4 (2021)", "doi": "10.1186/s42400-020-00068-0", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an architecture and a protocol suite for a permissioned\nblockchain for a local IoT network. The architecture is based on a sealed\nSequencer and a Fog Server running (post-quantum) Guy Fawkes protocols. The\nblocks of the blockchain are stored in networked Content Addressable Storage\nalongside any user data and validity proofs. We maintain that a typical IoT\ndevice can, despite its resource limitations, use our blockchain protocols\ndirectly, without a trusted intermediary. This includes posting and monitoring\ntransactions as well as off-chain (post-quantum) emergency communications\nwithout an explicit public key. Keywords: blockchain, Guy Fawkes protocol,\npost-quantum, HORS-OTS, LoRa, concurrent transmission\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 11:21:47 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 14:41:20 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Shafarenko", "Alex", ""]]}, {"id": "2008.04676", "submitter": "Bobby Filar", "authors": "Bobby Filar and David French", "title": "ProblemChild: Discovering Anomalous Patterns based on Parent-Child\n  Process Relationships", "comments": "VirusBulletin 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is becoming more common that adversary attacks consist of more than a\nstandalone executable or script. Often, evidence of an attack includes\nconspicuous process heritage that may be ignored by traditional static machine\nlearning models. Advanced attacker techniques, like \"living off the land\" that\nappear normal in isolation become more suspicious when observed in a\nparent-child context. The context derived from parent-child process chains can\nhelp identify and group malware families, as well as discover novel attacker\ntechniques. Adversaries chain these techniques to achieve persistence, bypass\ndefenses, and execute actions. Traditional heuristic-based detections often\ngenerate noise or disparate events that belong to what constitutes a single\nattack. ProblemChild is a graph-based framework designed to address these\nissues. ProblemChild applies a supervised learning classifier to derive a\nweighted graph used to identify communities of seemingly disparate events into\nlarger attack sequences. ProblemChild applies conditional probability to\nautomatically rank anomalous communities as well as suppress commonly occurring\nparent-child chains. In combination, this framework can be used by analysts to\naid in the crafting or tuning of detectors and reduce false-positives over\ntime. We evaluate ProblemChild against the 2018 MITRE ATT&CK(TM) emulation of\nAPT3 attack to demonstrate its promise in identifying anomalous parent-child\nprocess chains.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 12:59:07 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Filar", "Bobby", ""], ["French", "David", ""]]}, {"id": "2008.04698", "submitter": "Jason R.C. Nurse Dr", "authors": "Anjuli R. K. Shere and Jason R. C. Nurse and Ivan Flechais", "title": "Security should be there by default: Investigating how journalists\n  perceive and respond to risks from the Internet of Things", "comments": "5th European Workshop on Usable Security, at 2020 IEEE European\n  Symposium on Security and Privacy (EuroS&P)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Journalists have long been the targets of both physical and cyber-attacks\nfrom well-resourced adversaries. Internet of Things (IoT) devices are arguably\na new avenue of threat towards journalists through both targeted and\ngeneralised cyber-physical exploitation. This study comprises three parts:\nFirst, we interviewed 11 journalists and surveyed 5 further journalists, to\ndetermine the extent to which journalists perceive threats through the IoT,\nparticularly via consumer IoT devices. Second, we surveyed 34 cyber security\nexperts to establish if and how lay-people can combat IoT threats. Third, we\ncompared these findings to assess journalists' knowledge of threats, and\nwhether their protective mechanisms would be effective against experts'\ndepictions and predictions of IoT threats. Our results indicate that\njournalists generally are unaware of IoT-related risks and are not adequately\nprotecting themselves; this considers cases where they possess IoT devices, or\nwhere they enter IoT-enabled environments (e.g., at work or home). Expert\nrecommendations spanned both immediate and long-term mitigation methods,\nincluding practical actions that are technical and socio-political in nature.\nHowever, all proposed individual mitigation methods are likely to be short-term\nsolutions, with 26 of 34 (76.5%) of cyber security experts responding that\nwithin the next five years it will not be possible for the public to opt-out of\ninteraction with the IoT.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 13:41:22 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Shere", "Anjuli R. K.", ""], ["Nurse", "Jason R. C.", ""], ["Flechais", "Ivan", ""]]}, {"id": "2008.04713", "submitter": "Jason R.C. Nurse Dr", "authors": "Jason R. C. Nurse and Louise Axon and Arnau Erola and Ioannis\n  Agrafiotis and Michael Goldsmith and Sadie Creese", "title": "The Data that Drives Cyber Insurance: A Study into the Underwriting and\n  Claims Processes", "comments": null, "journal-ref": "2020 International Conference on Cyber Situational Awareness, Data\n  Analytics and Assessment (CyberSA)", "doi": "10.1109/CyberSA49311.2020.9139703", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber insurance is a key component in risk management, intended to transfer\nrisks and support business recovery in the event of a cyber incident. As cyber\ninsurance is still a new concept in practice and research, there are many\nunanswered questions regarding the data and economic models that drive it, the\ncoverage options and pricing of premiums, and its more procedural\npolicy-related aspects. This paper aims to address some of these questions by\nfocusing on the key types of data which are used by cyber-insurance\npractitioners, particularly for decision-making in the insurance underwriting\nand claim processes. We further explore practitioners' perceptions of the\nchallenges they face in gathering and using data, and identify gaps where\nfurther data is required. We draw our conclusions from a qualitative study by\nconducting a focus group with a range of cyber-insurance professionals\n(including underwriters, actuaries, claims specialists, breach responders, and\ncyber operations specialists) and provide valuable contributions to existing\nknowledge. These insights include examples of key data types which contribute\nto the calculation of premiums and decisions on claims, the identification of\nchallenges and gaps at various stages of data gathering, and initial\nperspectives on the development of a pre-competitive dataset for the cyber\ninsurance industry. We believe an improved understanding of data gathering and\nusage in cyber insurance, and of the current challenges faced, can be\ninvaluable for informing future research and practice.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 14:18:52 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Nurse", "Jason R. C.", ""], ["Axon", "Louise", ""], ["Erola", "Arnau", ""], ["Agrafiotis", "Ioannis", ""], ["Goldsmith", "Michael", ""], ["Creese", "Sadie", ""]]}, {"id": "2008.04743", "submitter": "Jiawen Kang", "authors": "Jiawen Kang, Zehui Xiong, Chunxiao Jiang, Yi Liu, Song Guo, Yang\n  Zhang, Dusit Niyato, Cyril Leung, Chunyan Miao", "title": "Scalable and Communication-efficient Decentralized Federated Edge\n  Learning with Multi-blockchain Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging Federated Edge Learning (FEL) technique has drawn considerable\nattention, which not only ensures good machine learning performance but also\nsolves \"data island\" problems caused by data privacy concerns. However,\nlarge-scale FEL still faces following crucial challenges: (i) there lacks a\nsecure and communication-efficient model training scheme for FEL; (2) there is\nno scalable and flexible FEL framework for updating local models and global\nmodel sharing (trading) management. To bridge the gaps, we first propose a\nblockchain-empowered secure FEL system with a hierarchical blockchain framework\nconsisting of a main chain and subchains. This framework can achieve scalable\nand flexible decentralized FEL by individually manage local model updates or\nmodel sharing records for performance isolation. A Proof-of-Verifying consensus\nscheme is then designed to remove low-quality model updates and manage\nqualified model updates in a decentralized and secure manner, thereby achieving\nsecure FEL. To improve communication efficiency of the blockchain-empowered\nFEL, a gradient compression scheme is designed to generate sparse but important\ngradients to reduce communication overhead without compromising accuracy, and\nalso further strengthen privacy preservation of training data. The security\nanalysis and numerical results indicate that the proposed schemes can achieve\nsecure, scalable, and communication-efficient decentralized FEL.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 09:24:48 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Kang", "Jiawen", ""], ["Xiong", "Zehui", ""], ["Jiang", "Chunxiao", ""], ["Liu", "Yi", ""], ["Guo", "Song", ""], ["Zhang", "Yang", ""], ["Niyato", "Dusit", ""], ["Leung", "Cyril", ""], ["Miao", "Chunyan", ""]]}, {"id": "2008.04761", "submitter": "Michele Marchesi", "authors": "Lodovica Marchesi, Michele Marchesi, Livio Pompianu, Roberto Tonelli", "title": "Security checklists for Ethereum smart contract development: patterns\n  and best practices", "comments": "13 pages, 5 tables. To be submitted to a Journal. arXiv admin note:\n  substantial text overlap with arXiv:1912.09074", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In recent years Smart Contracts and DApps are becoming increasingly important\nand widespread thanks to the properties of blockchain technology. In most cases\nDApps are business critical, and very strict security requirements should be\nassured. Developing safe and reliable Smart Contracts, however, is not a\ntrivial task. Several researchers have studied the security issues, however\nnone of these provide a simple and intuitive tool to overcome these problems.\nIn this paper we collected a list of security patterns for DApps. Moreover,\nbased on these patterns, we provide the reader with security assessment\nchecklists that can be easily used for the development of SCs. We cover the\nphases of design, coding, and testing and deployment of the software lifecycle.\nIn this way, we allow developers to easily verify if they applied all the\nrelevant security patterns to their smart contracts. We focus all the analysis\non the most popular Ethereum blockchain, and on the Solidity language.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 09:36:23 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Marchesi", "Lodovica", ""], ["Marchesi", "Michele", ""], ["Pompianu", "Livio", ""], ["Tonelli", "Roberto", ""]]}, {"id": "2008.04773", "submitter": "Shamal Faily", "authors": "Shamal Faily, Claudia Iacob, Raian Ali, and Duncan Ki-Aries", "title": "Identifying Implicit Vulnerabilities through Personas as Goal Models", "comments": "SECPRE 2020 workshop pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When used in requirements processes and tools, personas have the potential to\nidentify vulnerabilities resulting from misalignment between user expectations\nand system goals. Typically, however, this potential is unfulfilled as personas\nand system goals are captured with different mindsets, by different teams, and\nfor different purposes. If personas are visualised as goal models, it may be\neasier for stakeholders to see implications of their goals being satisfied or\ndenied, and designers to incorporate the creation and analysis of such models\ninto the broader RE tool-chain. This paper outlines a tool-supported approach\nfor finding implicit vulnerabilities from user and system goals by reframing\npersonas as social goal models. We illustrate this approach with a case study\nwhere previously hidden vulnerabilities based on human behaviour were\nidentified.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 15:23:51 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 03:54:27 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Faily", "Shamal", ""], ["Iacob", "Claudia", ""], ["Ali", "Raian", ""], ["Ki-Aries", "Duncan", ""]]}, {"id": "2008.04814", "submitter": "Reza Parizi", "authors": "Samuel P. Mullinix, Erikton Konomi, Renee Davis Townsend, Reza M.\n  Parizi", "title": "On Security Measures for Containerized Applications Imaged with Docker", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linux containers have risen in popularity in the last few years, making their\nway to commercial IT service offerings (such as PaaS), application deployments,\nand Continuous Delivery/Integration pipelines within various development teams.\nAlong with the wide adoption of Docker, security vulnerabilities and concerns\nhave also surfaced. In this survey, we examine the state of security for the\nmost popular container system at the moment: Docker. We will also look into its\norigins stemming from the Linux technologies built into the OS itself; examine\nintrinsic vulnerabilities, such as the Docker Image implementation; and provide\nan analysis of current tools and modern methodologies used in the field to\nevaluate and enhance its security. For each section, we pinpoint metrics of\ninterest, as they have been revealed by researchers and experts in the domain\nand summarize their findings to paint a holistic picture of the efforts behind\nthose findings. Lastly, we look at tools utilized in the industry to streamline\nDocker security scanning and analytics which provide built-in aggregation of\nkey metrics.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 16:10:57 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Mullinix", "Samuel P.", ""], ["Konomi", "Erikton", ""], ["Townsend", "Renee Davis", ""], ["Parizi", "Reza M.", ""]]}, {"id": "2008.04863", "submitter": "Qin Wang", "authors": "Bozhi Wang and Qin Wang and Shiping Chen and Yang Xiang", "title": "Security Analysis on Tangle-based Blockchain through Simulation", "comments": "Full version with 22pages. The conference version has been published\n  at ACISP'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Tangle-based structure becomes one of the most promising solutions when\ndesigning DAG-based blockchain systems. The approach improves the scalability\nby directly confirming multiple transactions in parallel instead of single\nblocks in linear. However, the performance gain may bring potential security\nrisks. In this paper, we construct three types of attacks with comprehensive\nevaluations, namely parasite attack (PS), double spending attack (DS), and\nhybrid attack (HB). To achieve that, we deconstruct the Tangle-based projects\n(e.g. IOTA) and abstract the main components to rebuild a simple but flexible\nnetwork for the simulation. Then, we informally define three smallest actions\nto build up the attack strategies layer by layer. Based on that, we provide\nanalyses to evaluate different types of attacks. To the best of our knowledge,\nthis is the first study to provide a comprehensive security analysis of\nTangle-based blockchains.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 17:08:05 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 03:30:15 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Wang", "Bozhi", ""], ["Wang", "Qin", ""], ["Chen", "Shiping", ""], ["Xiang", "Yang", ""]]}, {"id": "2008.04893", "submitter": "Song Fang", "authors": "Song Fang and Quanyan Zhu", "title": "Channel Leakage, Information-Theoretic Limitations of Obfuscation, and\n  Optimal Privacy Mask Design for Streaming Data", "comments": "The title was changed from \"Channel Leakage and Information Theoretic\n  Privacy-Distortion Tradeoffs for Streaming Data\" to the current one on 29th\n  September 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.LG eess.SP math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we first introduce the notion of channel leakage as the\nminimum mutual information between the channel input and channel output. As its\nname indicates, channel leakage quantifies the minimum information leakage to\nthe malicious receiver. In a broad sense, it can be viewed as a dual concept of\nchannel capacity, which characterizes the maximum information transmission to\nthe targeted receiver. We obtain explicit formulas of channel leakage for the\nwhite Gaussian case, the colored Gaussian case, and the fading case. We then\nutilize this notion to investigate the fundamental limitations of obfuscation\nin terms of privacy-distortion tradeoffs (as well as privacy-power tradeoffs)\nfor streaming data; particularly, we derive analytical tradeoff equations for\nthe stationary case, the non-stationary case, and the finite-time case. Our\nresults also indicate explicitly how to design the privacy masks in an optimal\nway.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 17:55:47 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 16:47:49 GMT"}, {"version": "v3", "created": "Tue, 25 Aug 2020 16:16:33 GMT"}, {"version": "v4", "created": "Thu, 24 Sep 2020 23:32:36 GMT"}, {"version": "v5", "created": "Tue, 29 Sep 2020 21:15:37 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Fang", "Song", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2008.04936", "submitter": "Soujanya Ponnapalli", "authors": "Zsolt Istvan (IMDEA Software Institute, Madrid), Soujanya Ponnapalli\n  (University of Texas, Austin) and Vijay Chidambaram (University of Texas,\n  Austin and VMWare)", "title": "Towards Software-Defined Data Protection: GDPR Compliance at the Storage\n  Layer is Within Reach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enforcing data protection and privacy rules within large data processing\napplications is becoming increasingly important, especially in the light of\nGDPR and similar regulatory frameworks. Most modern data processing happens on\ntop of a distributed storage layer, and securing this layer against accidental\nor malicious misuse is crucial to ensuring global privacy guarantees. However,\nthe performance overhead and the additional complexity for this is often\nassumed to be significant -- in this work we describe a path forward that\ntackles both challenges. We propose \"Software-Defined Data Protection\" (SDP),\nan adoption of the \"Software-Defined Storage\" approach to non-performance\naspects: a trusted controller translates company and application-specific\npolicies to a set of rules deployed on the storage nodes. These, in turn, apply\nthe rules at line-rate but do not take any decisions on their own. Such an\napproach decouples often changing policies from request-level enforcement and\nallows storage nodes to implement the latter more efficiently.\n  Even though in-storage processing brings challenges, mainly because it can\njeopardize line-rate processing, we argue that today's Smart Storage solutions\ncan already implement the required functionality, thanks to the separation of\nconcerns introduced by SDP. We highlight the challenges that remain, especially\nthat of trusting the storage nodes. These need to be tackled before we can\nreach widespread adoption in cloud environments.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 18:06:46 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Istvan", "Zsolt", "", "IMDEA Software Institute, Madrid"], ["Ponnapalli", "Soujanya", "", "University of Texas, Austin"], ["Chidambaram", "Vijay", "", "University of Texas,\n  Austin and VMWare"]]}, {"id": "2008.04979", "submitter": "Athar Khodabakhsh", "authors": "Athar Khodabakhsh, Sule Yildirim Yayilgan", "title": "Data Privacy in IoT Equipped Future Smart Homes", "comments": "8 pages, 3 figures, 3rd International Conference on Intelligent\n  Technologies and Applications INTAP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart devices are becoming inseparable from daily lives and are improving\nfast for providing intelligent services and remote monitoring and control. In\norder to provide personalized and customized services more personal data\ncollection is required. Consequently, intelligent services are becoming\nintensely personal and they raise concerns regarding data privacy and security.\nIn this paper data privacy requirements in a smart home environment equipped\nwith \"Internet of Things\" are described and privacy challenges for data and\nmodels are addressed.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 19:26:51 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Khodabakhsh", "Athar", ""], ["Yayilgan", "Sule Yildirim", ""]]}, {"id": "2008.04998", "submitter": "Wei Xie", "authors": "Keqi Wang, Wencen Wu, Wei Xie, Jinxiang Pei, Qi Zhou", "title": "Blockchain-Enabled Internet-of-Things Platform for End-to-End Industrial\n  Hemp Supply Chain", "comments": "18 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  After being legalized as an agricultural commodity by the 2018 U.S. Farm\nBill, the Industrial Hemp production is moved from limited pilot programs to a\nregulated agriculture production system, and the market keeps increasing since\nthen. However, Industrial Hemp Supply Chain (IHSC) faces several critical\nchallenges, including high complexity and variability, data tampering, and lack\nof immutable information tracking system. In this paper, we develop a\nblockchain enabled internet-of-things (IoT) platform for IHSC to support\nprocess tracking, scalability, interoperability, and risk management.\nBasically, we create a two-layer blockchain with proof-of-authority based smart\ncontract, which can leverage local authorities with state/federal regulators to\nensure and accelerate quality control verification and regulatory compliance.\nThen, we develop a user-friendly mobile app so that each participant can use\nsmart phone to real-time collect and upload their data to the cloud, and\nfurther share the process verification and tracking information through the\nblockchain network. Our study indicates the proposed platform can support\ninteroperability, improve the efficiency of quality control verification, and\nensure the safety of regulated IHSC.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 20:44:01 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Wang", "Keqi", ""], ["Wu", "Wencen", ""], ["Xie", "Wei", ""], ["Pei", "Jinxiang", ""], ["Zhou", "Qi", ""]]}, {"id": "2008.05048", "submitter": "Thomas Hardjono", "authors": "Thomas Hardjono", "title": "Trust Infrastructures for Virtual Asset Service Providers", "comments": "21 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Virtual asset service providers (VASPs) currently face a number of\nchallenges, both from the technological and the regulatory perspectives. In the\ncontext of virtual asset transfers one key issue is the need for VASPs to\nsecurely exchange customer information to comply to the Travel Rule. We discuss\na VASP information sharing network as one form of a trust infrastructure for\nVASP-to-VASP interactions. Related to this is the need for a trusted identity\ninfrastructure for VASPs that would permit other entities to quickly ascertain\nthe legal business status of a VASP. For regulated wallets, an attestation\ninfrastructure may provide VASPs and insurance providers with better visibility\ninto the state of wallets based on trusted hardware. Finally, for customers of\nVASPs there is a need for seamless integration between the VASP services with\nthe existing consumer identity management infrastructure, providing a\nuser-friendly experience for transferring virtual assets to other users.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 00:55:41 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 17:18:09 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Hardjono", "Thomas", ""]]}, {"id": "2008.05241", "submitter": "Markus Heinrich", "authors": "Markus Heinrich, Arwed G\\\"olz, Tolga Arul, Stefan Katzenbeisser", "title": "Rule-based Anomaly Detection for Railway Signalling Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a rule-based anomaly detection system for railway signalling that\nmitigates attacks by a Dolev-Yao attacker who is able to inject control\ncommands and to perform semantic attacks. The system as well mitigates the\neffects of a compromised signal box that an attacker uses to issue licit but\nmistimed control messages. We consider an attacker that could cause train\nderailments and collisions, if our countermeasure is not employed. We apply\nsafety principles of railway operation to a distributed anomaly detection\nsystem that inspects incoming commands on the signals and points. The proposed\nanomaly detection system detects all attacks of our model without producing\nfalse positives, while it requires only a small amount of overhead in terms of\nnetwork communication and latency compared to normal train operation.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 11:21:23 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Heinrich", "Markus", ""], ["G\u00f6lz", "Arwed", ""], ["Arul", "Tolga", ""], ["Katzenbeisser", "Stefan", ""]]}, {"id": "2008.05286", "submitter": "Mustafa Ozdayi", "authors": "Md Shihabul Islam, Mustafa Safa Ozdayi, Latifur Khan, Murat\n  Kantarcioglu", "title": "Secure IoT Data Analytics in Cloud via Intel SGX", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing adoption of IoT devices in our daily life is engendering a data\ndeluge, mostly private information that needs careful maintenance and secure\nstorage system to ensure data integrity and protection. Also, the prodigious\nIoT ecosystem has provided users with opportunities to automate systems by\ninterconnecting their devices and other services with rule-based programs. The\ncloud services that are used to store and process sensitive IoT data turn out\nto be vulnerable to outside threats. Hence, sensitive IoT data and rule-based\nprograms need to be protected against cyberattacks. To address this important\nchallenge, in this paper, we propose a framework to maintain confidentiality\nand integrity of IoT data and rule-based program execution. We design the\nframework to preserve data privacy utilizing Trusted Execution Environment\n(TEE) such as Intel SGX, and end-to-end data encryption mechanism. We evaluate\nthe framework by executing rule-based programs in the SGX securely with both\nsimulated and real IoT device data.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 20:26:05 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Islam", "Md Shihabul", ""], ["Ozdayi", "Mustafa Safa", ""], ["Khan", "Latifur", ""], ["Kantarcioglu", "Murat", ""]]}, {"id": "2008.05290", "submitter": "Unnikrishnan Menon", "authors": "Unnikrishnan Menon, Atharva Hudlikar, Divyani Panda", "title": "Scytale -- An Evolutionary Cryptosystem", "comments": "7 pages, 6 figures, 2 tables", "journal-ref": "International Journal of Computer Science and Network,\n  9(4):153-159 (2020)", "doi": null, "report-no": "IJCSN-2020-9-4-103", "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of quantum computing, and other advancements in computation\nand processing capabilities of modern systems, there arises a need to develop\nnew trapdoor functions that will serve as the foundation for a new generation\nof encryption schemes. This paper explores the possibility of one such\npotential trapdoor function using concepts stemming from Reversible Cellular\nAutomata (RCA) -- specifically, the Critter's Rule set up in a Margolus\nNeighborhood. The proposed block encryption algorithm discusses how sensitive\ndata can be manipulated and converted efficiently into a two dimensional\nsequence of bits, that can be iteratively evolved using the rules of the RCA\nand a private key to achieve a desirable level of encryption within a\nreasonable runtime. The performance benchmark and analysis results exemplify\nhow well the proposed encryption algorithm stands against different forms of\nattacks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 15:01:09 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Menon", "Unnikrishnan", ""], ["Hudlikar", "Atharva", ""], ["Panda", "Divyani", ""]]}, {"id": "2008.05299", "submitter": "Vasileios Kouliaridis", "authors": "Vasileios Kouliaridis, Georgios Kambourakis, Tao Peng", "title": "Feature importance in mobile malware detection", "comments": "improved our experiments and discussion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The topic of mobile malware detection on the Android platform has attracted\nsignificant attention over the last several years. However, while much research\nhas been conducted toward mobile malware detection techniques, little attention\nhas been devoted to feature selection and feature importance. That is, which\napp feature matters more when it comes to machine learning classification.\nAfter succinctly surveying all major, dated from 2012 to 2020, datasets used by\nstate-of-the-art malware detection works in the literature, we analyse a\ncritical mass of apps from the most contemporary and prevailing datasets,\nnamely Drebin, VirusShare, and AndroZoo. Next, we rank the importance of app\nclassification features pertaining to permissions and intents using the\nInformation Gain algorithm for all the three above-mentioned datasets.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 07:17:08 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 13:54:47 GMT"}, {"version": "v3", "created": "Fri, 28 Aug 2020 10:57:56 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Kouliaridis", "Vasileios", ""], ["Kambourakis", "Georgios", ""], ["Peng", "Tao", ""]]}, {"id": "2008.05300", "submitter": "Divya Siddarth", "authors": "Divya Siddarth, Sergey Ivliev, Santiago Siri, Paula Berman", "title": "Who Watches the Watchmen? A Review of Subjective Approaches for\n  Sybil-resistance in Proof of Personhood Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most current self-sovereign identity systems may be categorized as strictly\nobjective, consisting of cryptographically signed statements issued by trusted\nthird party attestors. This failure to provide an input for subjectivity\naccounts for a central challenge: the inability to address the question of \"Who\nverifies the verifier?\". Instead, these protocols outsource their legitimacy to\nmechanisms beyond their internal structure, relying on traditional centralized\ninstitutions such as national ID issuers and KYC providers to verify the claims\nthey hold. This reliance has been employed to safeguard applications from a\nvulnerability previously thought to be impossible to address in distributed\nsystems: the Sybil attack problem, which describes the abuse of an online\nsystem by creating many illegitimate virtual personas. Inspired by the progress\nin cryptocurrencies and blockchain technology, there has recently been a surge\nin networked protocols that make use of subjective inputs such as voting,\nvouching, and interpreting, to arrive at a decentralized and sybil-resistant\nconsensus for identity. In this article, we will outline the approaches of\nthese new and natively digital sources of authentication -- their attributes,\nmethodologies strengths, and weaknesses -- and sketch out possible directions\nfor future developments.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 15:39:43 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 04:04:06 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 20:18:50 GMT"}, {"version": "v4", "created": "Fri, 4 Sep 2020 19:15:57 GMT"}, {"version": "v5", "created": "Tue, 13 Oct 2020 15:11:33 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Siddarth", "Divya", ""], ["Ivliev", "Sergey", ""], ["Siri", "Santiago", ""], ["Berman", "Paula", ""]]}, {"id": "2008.05449", "submitter": "Sonia Laudanna", "authors": "Gerardo Canfora, Andrea Di Sorbo, Sonia Laudanna, Anna Vacca, Corrado\n  A. Visaggio", "title": "Profiling Gas Leaks in Solidity Smart Contracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, more and more applications are developed for running on a\ndistributed ledger technology, namely dApps. The business logic of dApps is\nusually implemented within smart contracts developed through Solidity, a\nprogramming language for writing smart contracts on different blockchain\nplatforms, including the popular Ethereum. In Ethereum, the smart contracts run\non the machines of miners and the gas corresponds to the execution fee\ncompensating such computing resources. However, the deployment and execution\ncosts of a smart contract depend on the implementation choices done by\ndevelopers. Unappropriated design choices could lead to higher gas consumption\nthan necessary. In this paper, we (i) identify a set of 19 Solidity code smells\naffecting the deployment and transaction costs of a smart contract, and (ii)\nassess the relevance of such smells through a survey involving 34 participants.\nOn top of these smells, we propose GasMet, a suite of metrics for statically\nevaluating the code quality of a smart contract from the gas consumption\nperspective. An experiment involving 2,186 smart contracts demonstrates that\nthe proposed metrics have direct associations with deployment costs. The\nmetrics in our suite can be used for more easily identifying source code\nsegments that need optimizations.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 17:26:55 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 10:24:04 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Canfora", "Gerardo", ""], ["Di Sorbo", "Andrea", ""], ["Laudanna", "Sonia", ""], ["Vacca", "Anna", ""], ["Visaggio", "Corrado A.", ""]]}, {"id": "2008.05600", "submitter": "Dongbo Xi", "authors": "Dongbo Xi, Bowen Song, Fuzhen Zhuang, Yongchun Zhu, Shuai Chen, Tianyi\n  Zhang, Yuan Qi, Qing He", "title": "Modeling the Field Value Variations and Field Interactions\n  Simultaneously for Fraud Detection", "comments": "Accepted by AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the explosive growth of e-commerce, online transaction fraud has become\none of the biggest challenges for e-commerce platforms. The historical\nbehaviors of users provide rich information for digging into the users' fraud\nrisk. While considerable efforts have been made in this direction, a\nlong-standing challenge is how to effectively exploit internal user information\nand provide explainable prediction results. In fact, the value variations of\nsame field from different events and the interactions of different fields\ninside one event have proven to be strong indicators for fraudulent behaviors.\nIn this paper, we propose the Dual Importance-aware Factorization Machines\n(DIFM), which exploits the internal field information among users' behavior\nsequence from dual perspectives, i.e., field value variations and field\ninteractions simultaneously for fraud detection. The proposed model is deployed\nin the risk management system of one of the world's largest e-commerce\nplatforms, which utilize it to provide real-time transaction fraud detection.\nExperimental results on real industrial data from different regions in the\nplatform clearly demonstrate that our model achieves significant improvements\ncompared with various state-of-the-art baseline models. Moreover, the DIFM\ncould also give an insight into the explanation of the prediction results from\ndual perspectives.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 18:44:00 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 09:39:43 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Xi", "Dongbo", ""], ["Song", "Bowen", ""], ["Zhuang", "Fuzhen", ""], ["Zhu", "Yongchun", ""], ["Chen", "Shuai", ""], ["Zhang", "Tianyi", ""], ["Qi", "Yuan", ""], ["He", "Qing", ""]]}, {"id": "2008.05629", "submitter": "Dayong Ye", "authors": "Dayong Ye and Tianqing Zhu and Shen Sheng and Wanlei Zhou", "title": "A Differentially Private Game Theoretic Approach for Deceiving Cyber\n  Adversaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber deception is one of the key approaches used to mislead attackers by\nhiding or providing inaccurate system information. There are two main factors\nlimiting the real-world application of existing cyber deception approaches. The\nfirst limitation is that the number of systems in a network is assumed to be\nfixed. However, in the real world, the number of systems may be dynamically\nchanged. The second limitation is that attackers' strategies are simplified in\nthe literature. However, in the real world, attackers may be more powerful than\ntheory suggests. To overcome these two limitations, we propose a novel\ndifferentially private game theoretic approach to cyber deception. In this\nproposed approach, a defender adopts differential privacy mechanisms to\nstrategically change the number of systems and obfuscate the configurations of\nsystems, while an attacker adopts a Bayesian inference approach to infer the\nreal configurations of systems. By using the differential privacy technique,\nthe proposed approach can 1) reduce the impacts on network security resulting\nfrom changes in the number of systems and 2) resist attacks regardless of\nattackers' reasoning power. The experimental results demonstrate the\neffectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 01:02:17 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Ye", "Dayong", ""], ["Zhu", "Tianqing", ""], ["Sheng", "Shen", ""], ["Zhou", "Wanlei", ""]]}, {"id": "2008.05646", "submitter": "Sudipta Paul Ms.", "authors": "Sudipta Paul and Subhankar Mishra", "title": "LAC : LSTM AUTOENCODER with Community for Insider Threat Detection", "comments": "10 pages, 8 figures, 5 tables, Accepted to the 3rd ICIST 2020, Tokyo,\n  Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The employees of any organization, institute, or industry, spend a\nsignificant amount of time on a computer network, where they develop their own\nroutine of activities in the form of network transactions over a time period.\nInsider threat detection involves identifying deviations in the routines or\nanomalies which may cause harm to the organization in the form of data leaks\nand secrets sharing. If not automated, this process involves feature\nengineering for modeling human behavior which is a tedious and time-consuming\ntask. Anomalies in human behavior are forwarded to a human analyst for final\nthreat classification. We developed an unsupervised deep neural network model\nusing LSTM AUTOENCODER which learns to mimic the behavior of individual\nemployees from their day-wise time-stamped sequence of activities. It predicts\nthe threat scenario via significant loss from anomalous routine. Employees in a\ncommunity tend to align their routine with each other rather than the employees\noutside their communities, this motivates us to explore a variation of the\nAUTOENCODER, LSTM AUTOENCODER- trained on the interleaved sequences of\nactivities in the Community (LAC). We evaluate the model on the CERT v6.2\ndataset and perform analysis on the loss for normal and anomalous routine\nacross 4000 employees. The aim of our paper is to detect the anomalous\nemployees as well as to explore how the surrounding employees are affecting\nthat employees' routine over time.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 02:08:39 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Paul", "Sudipta", ""], ["Mishra", "Subhankar", ""]]}, {"id": "2008.05705", "submitter": "Koji Nuida", "authors": "Koji Nuida", "title": "An Elementary Linear-Algebraic Proof without Computer-Aided Arguments\n  for the Group Law on Elliptic Curves", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CR math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The group structure on the rational points of elliptic curves plays several\nimportant roles, in mathematics and recently also in other areas such as\ncryptography. However, the famous proofs for the group property (in particular,\nfor its associative law) require somewhat advanced mathematics and therefore\nare not easily accessible by non-mathematician. On the other hand, there have\nbeen attempts in the literature to give an elementary proof, but those rely on\ncomputer-aided calculation for some part in their proofs. In this paper, we\ngive a self-contained proof of the associative law for this operation, assuming\nmathematical knowledge only at the level of basic linear algebra and not\nrequiring computer-aided arguments.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 06:14:47 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 04:13:36 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Nuida", "Koji", ""]]}, {"id": "2008.05791", "submitter": "Soumyabrata Dev", "authors": "Mahmoud Said Elsayed, Nhien-An Le-Khac, Soumyabrata Dev, and Anca\n  Delia Jurcut", "title": "Detecting Abnormal Traffic in Large-Scale Networks", "comments": "Published in Proc. IEEE International Symposium on Networks,\n  Computers and Communications (ISNCC)2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid technological advancements, organizations need to rapidly\nscale up their information technology (IT) infrastructure viz. hardware,\nsoftware, and services, at a low cost. However, the dynamic growth in the\nnetwork services and applications creates security vulnerabilities and new\nrisks that can be exploited by various attacks. For example, User to Root (U2R)\nand Remote to Local (R2L) attack categories can cause a significant damage and\nparalyze the entire network system. Such attacks are not easy to detect due to\nthe high degree of similarity to normal traffic. While network anomaly\ndetection systems are being widely used to classify and detect malicious\ntraffic, there are many challenges to discover and identify the minority\nattacks in imbalanced datasets. In this paper, we provide a detailed and\nsystematic analysis of the existing Machine Learning (ML) approaches that can\ntackle most of these attacks. Furthermore, we propose a Deep Learning (DL)\nbased framework using Long Short Term Memory (LSTM) autoencoder that can\naccurately detect malicious traffics in network traffic. We perform our\nexperiments in a publicly available dataset of Intrusion Detection Systems\n(IDSs). We obtain a significant improvement in attack detection, as compared to\nother benchmarking methods. Hence, our method provides great confidence in\nsecuring these networks from malicious traffic.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 10:08:27 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Elsayed", "Mahmoud Said", ""], ["Le-Khac", "Nhien-An", ""], ["Dev", "Soumyabrata", ""], ["Jurcut", "Anca Delia", ""]]}, {"id": "2008.05833", "submitter": "Byoung Ham", "authors": "Byoung S. Ham", "title": "Experimental demonstrations of unconditional security in a purely\n  classical regime", "comments": "8 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  So far, unconditional security in key distribution processes has been\nconfined to quantum key distribution (QKD) protocols based on the no-cloning\ntheorem of nonorthogonal bases. Recently, a completely different approach, the\nunconditionally secured classical key distribution (USCKD), has been proposed\nfor unconditional security in the purely classical regime. Unlike QKD, both\nclassical channels and orthogonal bases are key ingredients in USCKD, where\nunconditional security is provided by deterministic randomness via path\nsuperposition-based reversible unitary transformations in a coupled\nMach-Zehnder interferometer. Here, the first experimental demonstration of the\nUSCKD protocol is presented.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 11:41:52 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Ham", "Byoung S.", ""]]}, {"id": "2008.05836", "submitter": "Hazel Murray", "authors": "Hazel Murray, David Malone", "title": "Costs and benefits of authentication advice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When it comes to passwords, conflicting advice can be found everywhere.\nDifferent sources give different types of advice related to authentication. In\nthis paper such advice is studied. First, using a sample collection of\nauthentication advice, we observe that different organizations' advice is often\ncontradictory and at odds with current research. We highlight the difficulties\norganizations and users have when determining which advice is worth following.\nConsequently, we develop a model for identifying costs of advice. Our model\nincorporates factors that affect organizations and users, including, for\nexample, usability aspects. Similarly, we model the security benefits brought\nby such advice. We then apply these models to our taxonomy of advice to\nindicate the potential effectiveness of the security recommendations. We find\nthat organizations experience fewer costs than users as a result of\nauthentication policies. Reassuringly, the advice our model has classified as\ngood or bad, is in line with the NIST 2017 digital authentication guidelines.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 11:44:37 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Murray", "Hazel", ""], ["Malone", "David", ""]]}, {"id": "2008.05840", "submitter": "Peter Hines", "authors": "Peter Hines", "title": "A diagrammatic approach to information flow in encrypted communication\n  (extended version)", "comments": "Extended version of a presentation at Graphical Models for Security\n  (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give diagrammatic tools to reason about information flow within encrypted\ncommunication. In particular, we are interested in deducing where information\nflow (communication or otherwise) has taken place, and fully accounting for all\npossible paths. The core mathematical concept is using a single categorical\ndiagram to model the underlying mathematics, the epistemic knowledge of the\nparticipants, and (implicitly) the potential or actual communication between\nparticipants. A key part of this is a `correctness' or `consistency' criterion\nthat ensures we accurately & fully account for the distinct routes by which\ninformation may come to be known (i.e. communication and / or calculation). We\ndemonstrate how this formalism may be applied to answer questions about\ncommunication scenarios where we have the partial information about the\nparticipants and their interactions. Similarly, we show how to analyse the\nconsequences of changes to protocols or communications, and to enumerate the\ndistinct orders in which events may have occurred. We use various forms of\nDiffie-Hellman key exchange as an illustration of these techniques. However,\nthey are entirely general; we illustrate in an appendix how other protocols\nfrom non-commutative cryptography may be analysed in the same manner.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 11:56:37 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Hines", "Peter", ""]]}, {"id": "2008.05864", "submitter": "Ming Fan", "authors": "Ming Fan, Le Yu, Sen Chen, Hao Zhou, Xiapu Luo, Shuyue Li, Yang Liu,\n  Jun Liu, Ting Liu", "title": "An Empirical Evaluation of GDPR Compliance Violations in Android mHealth\n  Apps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of the General Data Protection Regulation (GDPR) is to provide\nimproved privacy protection. If an app controls personal data from users, it\nneeds to be compliant with GDPR. However, GDPR lists general rules rather than\nexact step-by-step guidelines about how to develop an app that fulfills the\nrequirements. Therefore, there may exist GDPR compliance violations in existing\napps, which would pose severe privacy threats to app users. In this paper, we\ntake mobile health applications (mHealth apps) as a peephole to examine the\nstatus quo of GDPR compliance in Android apps. We first propose an automated\nsystem, named \\mytool, to bridge the semantic gap between the general rules of\nGDPR and the app implementations by identifying the data practices declared in\nthe app privacy policy and the data relevant behaviors in the app code. Then,\nbased on \\mytool, we detect three kinds of GDPR compliance violations,\nincluding the incompleteness of privacy policy, the inconsistency of data\ncollections, and the insecurity of data transmission. We perform an empirical\nevaluation of 796 mHealth apps. The results reveal that 189 (23.7\\%) of them do\nnot provide complete privacy policies. Moreover, 59 apps collect sensitive data\nthrough different measures, but 46 (77.9\\%) of them contain at least one\ninconsistent collection behavior. Even worse, among the 59 apps, only 8 apps\ntry to ensure the transmission security of collected data. However, all of them\ncontain at least one encryption or SSL misuse. Our work exposes severe privacy\nissues to raise awareness of privacy protection for app users and developers.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 12:50:15 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 09:16:47 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Fan", "Ming", ""], ["Yu", "Le", ""], ["Chen", "Sen", ""], ["Zhou", "Hao", ""], ["Luo", "Xiapu", ""], ["Li", "Shuyue", ""], ["Liu", "Yang", ""], ["Liu", "Jun", ""], ["Liu", "Ting", ""]]}, {"id": "2008.05895", "submitter": "Ming Fan", "authors": "Ming Fan, Wenying Wei, Xiaofei Xie, Yang Liu, Xiaohong Guan, Ting Liu", "title": "Can We Trust Your Explanations? Sanity Checks for Interpreters in\n  Android Malware Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of Android malware, many machine learning-based malware\nanalysis approaches are proposed to mitigate the severe phenomenon. However,\nsuch classifiers are opaque, non-intuitive, and difficult for analysts to\nunderstand the inner decision reason. For this reason, a variety of explanation\napproaches are proposed to interpret predictions by providing important\nfeatures. Unfortunately, the explanation results obtained in the malware\nanalysis domain cannot achieve a consensus in general, which makes the analysts\nconfused about whether they can trust such results. In this work, we propose\nprincipled guidelines to assess the quality of five explanation approaches by\ndesigning three critical quantitative metrics to measure their stability,\nrobustness, and effectiveness. Furthermore, we collect five widely-used malware\ndatasets and apply the explanation approaches on them in two tasks, including\nmalware detection and familial identification. Based on the generated\nexplanation results, we conduct a sanity check of such explanation approaches\nin terms of the three metrics. The results demonstrate that our metrics can\nassess the explanation approaches and help us obtain the knowledge of most\ntypical malicious behaviors for malware analysis.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 13:27:59 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Fan", "Ming", ""], ["Wei", "Wenying", ""], ["Xie", "Xiaofei", ""], ["Liu", "Yang", ""], ["Guan", "Xiaohong", ""], ["Liu", "Ting", ""]]}, {"id": "2008.05923", "submitter": "Yue Qi", "authors": "Yue Qi, Mojtaba Vaezi", "title": "Secure Transmission in MIMO-NOMA Networks", "comments": "To appear in IEEE Communications Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter focuses on the physical layer security over two-user\nmultiple-input multiple-output (MIMO) non-orthogonal multiple access (NOMA)\nnetworks. A linear precoding technique is designed to ensure the\nconfidentiality of the message of each user from its counterpart. This\ntechnique first splits the base station power between the two users and, based\non that, decomposes the secure MIMO-NOMA channel into two MIMO wiretap\nchannels, and designs the transmit covariance matrix for each channel\nseparately. The proposed method substantially enlarges the secrecy rate\ncompared to existing linear precoding methods and strikes a balance between\nperformance and computation cost. Simulation results verify the effectiveness\nof the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 14:09:37 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Qi", "Yue", ""], ["Vaezi", "Mojtaba", ""]]}, {"id": "2008.05958", "submitter": "Antoine Rondelet", "authors": "Antoine Rondelet", "title": "Zecale: Reconciling Privacy and Scalability on Ethereum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present Zecale, a general purpose SNARK proof aggregator\nthat uses recursive composition of SNARKs. We start by introducing the notion\nof recursive composition of SNARKs, before introducing Zecale as a privacy\npreserving scalability solution. Then, we list application types that can\nemerge and be built with Zecale. Finally, we argue that such scalability\nsolutions for privacy preserving state transitions are paramount to emulate\n\"cash\" on blockchain systems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 15:04:09 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 14:00:50 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Rondelet", "Antoine", ""]]}, {"id": "2008.05966", "submitter": "Manaar Alam", "authors": "Manaar Alam and Sayandeep Saha and Debdeep Mukhopadhyay and Sandip\n  Kundu", "title": "Deep-Lock: Secure Authorization for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trained Deep Neural Network (DNN) models are considered valuable Intellectual\nProperties (IP) in several business models. Prevention of IP theft and\nunauthorized usage of such DNN models has been raised as of significant concern\nby industry. In this paper, we address the problem of preventing unauthorized\nusage of DNN models by proposing a generic and lightweight key-based\nmodel-locking scheme, which ensures that a locked model functions correctly\nonly upon applying the correct secret key. The proposed scheme, known as\nDeep-Lock, utilizes S-Boxes with good security properties to encrypt each\nparameter of a trained DNN model with secret keys generated from a master key\nvia a key scheduling algorithm. The resulting dense network of encrypted\nweights is found robust against model fine-tuning attacks. Finally, Deep-Lock\ndoes not require any intervention in the structure and training of the DNN\nmodels, making it applicable for all existing software and hardware\nimplementations of DNN.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 15:22:49 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Alam", "Manaar", ""], ["Saha", "Sayandeep", ""], ["Mukhopadhyay", "Debdeep", ""], ["Kundu", "Sandip", ""]]}, {"id": "2008.05997", "submitter": "Zhen Yu Ding", "authors": "Zhen Yu Ding, Benjamin Khakshoor, Justin Paglierani, Mantej Rajpal", "title": "Sniffing for Codebase Secret Leaks with Known Production Secrets in\n  Industry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leaked secrets, such as passwords and API keys, in codebases were responsible\nfor numerous security breaches. Existing heuristic techniques, such as pattern\nmatching, entropy analysis, and machine learning, exist to detect and alert\ndevelopers of such leaks. Heuristics, however, naturally exhibit false\npositives, which require triaging and can lead to developer frustration. We\npropose to use known production secrets as a source of ground truth for\nsniffing secret leaks in codebases. We develop techniques for using known\nsecrets to sniff whole codebases and continuously sniff differential code\nrevisions. We uncover different performance and security needs when sniffing\nfor known secrets in these two situations in an industrial environment.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 16:33:10 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Ding", "Zhen Yu", ""], ["Khakshoor", "Benjamin", ""], ["Paglierani", "Justin", ""], ["Rajpal", "Mantej", ""]]}, {"id": "2008.06004", "submitter": "Billy Bob Brumley", "authors": "Sohaib ul Hassan, Iaroslav Gridin, Ignacio M. Delgado-Lozano, Cesar\n  Pereida Garc\\'ia, Jes\\'us-Javier Chi-Dom\\'inguez, Alejandro Cabrera Aldaya,\n  Billy Bob Brumley", "title": "D\\'{e}j\\`{a} Vu: Side-Channel Analysis of Mozilla's NSS", "comments": "To appear at ACM CCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent work on Side Channel Analysis (SCA) targets old, well-known\nvulnerabilities, even previously exploited, reported, and patched in\nhigh-profile cryptography libraries. Nevertheless, researchers continue to find\nand exploit the same vulnerabilities in old and new products, highlighting a\nbig issue among vendors: effectively tracking and fixing security\nvulnerabilities when disclosure is not done directly to them. In this work, we\npresent another instance of this issue by performing the first library-wide SCA\nsecurity evaluation of Mozilla's NSS security library. We use a combination of\ntwo independently-developed SCA security frameworks to identify and test\nsecurity vulnerabilities. Our evaluation uncovers several new vulnerabilities\nin NSS affecting DSA, ECDSA, and RSA cryptosystems. We exploit said\nvulnerabilities and implement key recovery attacks using signals---extracted\nthrough different techniques such as timing, microarchitecture, and EM---and\nimproved lattice methods.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 16:45:51 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Hassan", "Sohaib ul", ""], ["Gridin", "Iaroslav", ""], ["Delgado-Lozano", "Ignacio M.", ""], ["Garc\u00eda", "Cesar Pereida", ""], ["Chi-Dom\u00ednguez", "Jes\u00fas-Javier", ""], ["Aldaya", "Alejandro Cabrera", ""], ["Brumley", "Billy Bob", ""]]}, {"id": "2008.06163", "submitter": "Tiantian Ji", "authors": "Tiantian Ji, Binxing Fang, Xiang Cui, Zhongru Wang, Jiawen Diao, Tian\n  Wang, Weiqiang Yu", "title": "The First Step Towards Modeling Unbreakable Malware", "comments": "13 pages, 11 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing stealthy malware has gained increasing popularity among cyber\nattackers to conceal their malicious intent. Nevertheless, the constructed\nstealthy malware still fails to survive the reverse engineering by security\nexperts. Therefore, this paper modeled a type of malware with an \"unbreakable\"\nsecurity attribute-unbreakable malware (UBM), and made a systematical probe\ninto this new type of threat through modeling, method analysis, experiments,\nevaluation and anti-defense capacity tests. Specifically, we first formalized\nthe definition of UBM and analyzed its security attributes, put forward two\ncore features that are essential for realizing the \"unbreakable\" security\nattribute, and their relevant tetrad for evaluation. Then, we worked out and\nimplemented four algorithms for constructing UBM, and verified the\n\"unbreakable\" security attribute based on our evaluation of the abovementioned\ntwo core features. After that, the four verified algorithms were employed to\nconstruct UBM instances, and by analyzing their volume increment and\nanti-defense capacity, we confirmed real-world applicability of UBM. Finally,\nto address the new threats incurred by UBM to the cyberspace, this paper\nexplored some possible defense measures, with a view to establishing defense\nsystems against UBM attacks.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 02:03:52 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 02:31:59 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Ji", "Tiantian", ""], ["Fang", "Binxing", ""], ["Cui", "Xiang", ""], ["Wang", "Zhongru", ""], ["Diao", "Jiawen", ""], ["Wang", "Tian", ""], ["Yu", "Weiqiang", ""]]}, {"id": "2008.06170", "submitter": "Yuncheng Wu", "authors": "Yuncheng Wu, Shaofeng Cai, Xiaokui Xiao, Gang Chen, Beng Chin Ooi", "title": "Privacy Preserving Vertical Federated Learning for Tree-based Models", "comments": "Proc. VLDB Endow. 13(11): 2090-2103 (2020)", "journal-ref": null, "doi": "10.14778/3407790.3407811", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is an emerging paradigm that enables multiple\norganizations to jointly train a model without revealing their private data to\neach other. This paper studies {\\it vertical} federated learning, which tackles\nthe scenarios where (i) collaborating organizations own data of the same set of\nusers but with disjoint features, and (ii) only one organization holds the\nlabels. We propose Pivot, a novel solution for privacy preserving vertical\ndecision tree training and prediction, ensuring that no intermediate\ninformation is disclosed other than those the clients have agreed to release\n(i.e., the final tree model and the prediction output). Pivot does not rely on\nany trusted third party and provides protection against a semi-honest adversary\nthat may compromise $m-1$ out of $m$ clients. We further identify two privacy\nleakages when the trained decision tree model is released in plaintext and\npropose an enhanced protocol to mitigate them. The proposed solution can also\nbe extended to tree ensemble models, e.g., random forest (RF) and gradient\nboosting decision tree (GBDT) by treating single decision trees as building\nblocks. Theoretical and experimental analysis suggest that Pivot is efficient\nfor the privacy achieved.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 02:32:36 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Wu", "Yuncheng", ""], ["Cai", "Shaofeng", ""], ["Xiao", "Xiaokui", ""], ["Chen", "Gang", ""], ["Ooi", "Beng Chin", ""]]}, {"id": "2008.06228", "submitter": "Farhan Musanna", "authors": "Farhan Musanna and Sanjeev Kumar", "title": "A novel three party Quantum secret sharing scheme based on Bell state\n  sequential measurements with application in quantum image sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a quantum secret sharing scheme based on Bell state\nentanglement and sequential projection measurements. The protocol verifies the\n$n$ out of $n$ scheme and supports the aborting of the protocol in case all the\nparties do not divulge in their valid measurement outcomes. The operator-qubit\npair forms an integral part of the scheme determining the classical secret to\nbe shared. The protocol is robust enough to neutralize any eavesdropping on a\nparticular qubit of the dealer. The experimental demonstration of the scheme is\ndone on IBM-QE cloud platform with backends \\texttt{IBMQ\\_16\\_Melbourne} and\n\\texttt{IBMQ\\_QASM\\_SIMULATOR\\_V0.1.547} simulator. The security analysis\nperformed on the scheme and the comparative analysis supports our claim of a\nstringent and an efficient scheme as compared to some recent quantum and\nsemi-quantum techniques of secret sharing.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 07:50:35 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Musanna", "Farhan", ""], ["Kumar", "Sanjeev", ""]]}, {"id": "2008.06255", "submitter": "Seung-Hun Nam", "authors": "Seung-Hun Nam, Wonhyuk Ahn, In-Jae Yu, Seung-Min Mun", "title": "WAN: Watermarking Attack Network", "comments": "Seung-Hun Nam and Wonhyuk Ahn contributed equally to this work.\n  Corresponding author: Seung-Hun Nam", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-bit watermarking (MW) has been developed to improve robustness against\nsignal processing operations and geometric distortions. To this end, benchmark\ntools that test robustness by applying simulated attacks on watermarked images\nare available. However, limitations in these general attacks exist since they\ncannot exploit specific characteristics of the targeted MW. In addition, these\nattacks are usually devised without consideration of visual quality, which\nrarely occurs in the real world. To address these limitations, we propose a\nwatermarking attack network (WAN), a fully trainable watermarking benchmark\ntool that utilizes the weak points of the target MW and induces an inversion of\nthe watermark bit, thereby considerably reducing the watermark extractability.\nTo hinder the extraction of hidden information while ensuring high visual\nquality, we utilize a residual dense blocks-based architecture specialized in\nlocal and global feature learning. A novel watermarking attack loss is\nintroduced to break the MW systems. We empirically demonstrate that the WAN can\nsuccessfully fool various block-based MW systems.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 09:11:46 GMT"}, {"version": "v2", "created": "Sat, 9 Jan 2021 21:32:50 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Nam", "Seung-Hun", ""], ["Ahn", "Wonhyuk", ""], ["Yu", "In-Jae", ""], ["Mun", "Seung-Min", ""]]}, {"id": "2008.06297", "submitter": "Kai Hormann", "authors": "Craig Gotsman, Kai Hormann", "title": "Secure Data Hiding for Contact Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact tracing is an effective tool in controlling the spread of infectious\ndiseases such as COVID-19. It involves digital monitoring and recording of\nphysical proximity between people over time with a central and trusted\nauthority, so that when one user reports infection, it is possible to identify\nall other users who have been in close proximity to that person during a\nrelevant time period in the past and alert them. One way to achieve this\ninvolves recording on the server the locations, e.g. by reading and reporting\nthe GPS coordinates of a smartphone, of all users over time. Despite its\nsimplicity, privacy concerns have prevented widespread adoption of this method.\nTechnology that would enable the \"hiding\" of data could go a long way towards\nalleviating privacy concerns and enable contact tracing at a very large scale.\nIn this article we describe a general method to hide data. By hiding, we mean\nthat instead of disclosing a data value x, we would disclose an \"encoded\"\nversion of x, namely E(x), where E(x) is easy to compute but very difficult,\nfrom a computational point of view, to invert. We propose a general\nconstruction of such a function E and show that it guarantees perfect recall,\nnamely, all individuals who have potentially been exposed to infection are\nalerted, at the price of an infinitesimal number of false alarms, namely, only\na negligible number of individuals who have not actually been exposed will be\nwrongly informed that they have.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 11:38:20 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Gotsman", "Craig", ""], ["Hormann", "Kai", ""]]}, {"id": "2008.06403", "submitter": "Violetta Weger", "authors": "Marco Baldi, Massimo Battaglioni, Franco Chiaraluce, Anna-Lena\n  Horlemann-Trautmann, Edoardo Persichetti, Paolo Santini, Violetta Weger", "title": "A New Path to Code-based Signatures via Identification Schemes with\n  Restricted Errors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a variant of the Syndrome Decoding Problem (SDP),\nthat we call Restricted SDP (R-SDP), in which the entries of the searched\nvector are defined over a subset of the underlying finite field. We prove the\nNP-completeness of R-SDP, via a reduction from the classical SDP, and describe\nalgorithms which solve such new problem. We study the properties of random\ncodes under this new decoding perspective, in the fashion of traditional coding\ntheory results, and assess the complexity of solving a random R-SDP instance.\nAs a concrete application, we describe how Zero-Knowledge Identification\n(ZK-ID) schemes based on SDP can be tweaked to rely on R-SDP, and show that\nthis leads to compact public keys as well as significantly reduced\ncommunication costs. Thus, these schemes offer an improved basis for the\nconstruction of code-based digital signature schemes derived from\nidentification schemes through the well-know Fiat-Shamir transformation.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 15:00:30 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 14:11:01 GMT"}, {"version": "v3", "created": "Sat, 30 Jan 2021 13:36:12 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Baldi", "Marco", ""], ["Battaglioni", "Massimo", ""], ["Chiaraluce", "Franco", ""], ["Horlemann-Trautmann", "Anna-Lena", ""], ["Persichetti", "Edoardo", ""], ["Santini", "Paolo", ""], ["Weger", "Violetta", ""]]}, {"id": "2008.06430", "submitter": "William Buchanan Prof", "authors": "Pavlos Papadopoulos, Nikolaos Pitropakis, William J. Buchanan, Owen Lo\n  and Sokratis Katsikas", "title": "Privacy Preserving Passive DNS", "comments": null, "journal-ref": "Computers 2020, 9, 64", "doi": "10.3390/computers9030064", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Domain Name System (DNS) was created to resolve the IP addresses of the\nweb servers to easily remembered names. When it was initially created, security\nwas not a major concern; nowadays, this lack of inherent security and trust has\nexposed the global DNS infrastructure to malicious actors. The passive DNS data\ncollection process creates a database containing various DNS data elements,\nsome of which are personal and need to be protected to preserve the privacy of\nthe end users. To this end, we propose the use of distributed ledger\ntechnology. We use Hyperledger Fabric to create a permissioned blockchain,\nwhich only authorized entities can access. The proposed solution supports\nqueries for storing and retrieving data from the blockchain ledger, allowing\nthe use of the passive DNS database for further analysis, e.g. for the\nidentification of malicious domain names. Additionally, it effectively protects\nthe DNS personal data from unauthorized entities, including the administrators\nthat can act as potential malicious insiders, and allows only the data owners\nto perform queries over these data. We evaluated our proposed solution by\ncreating a proof-of-concept experimental setup that passively collects DNS data\nfrom a network and then uses the distributed ledger technology to store the\ndata in an immutable ledger, thus providing a full historical overview of all\nthe records.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 15:54:00 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Papadopoulos", "Pavlos", ""], ["Pitropakis", "Nikolaos", ""], ["Buchanan", "William J.", ""], ["Lo", "Owen", ""], ["Katsikas", "Sokratis", ""]]}, {"id": "2008.06503", "submitter": "Yaroslav Balytskyi", "authors": "Yaroslav Balytskyi, Sang-Yoon Chang, Anatoliy Pinchuk, and Manohar\n  Raavi", "title": "Discriminating an Arbitrary Number of Pure Quantum States by the\n  Combined $\\mathcal{CPT}$ and Hermitian Measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  If the system is known to be in one of two non-orthogonal quantum states,\n$|\\psi_1\\rangle$ or $|\\psi_2\\rangle$, $\\mathcal{PT}$-symmetric quantum\nmechanics can discriminate them, \\textit{in principle}, by a single\nmeasurement. We extend this approach by combining $\\mathcal{PT}$-symmetric and\nHermitian measurements and show that it's possible to distinguish an arbitrary\nnumber of pure quantum states by an appropriate choice of the parameters of\n$\\mathcal{PT}$-symmetric Hamiltonian.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 17:05:50 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Balytskyi", "Yaroslav", ""], ["Chang", "Sang-Yoon", ""], ["Pinchuk", "Anatoliy", ""], ["Raavi", "Manohar", ""]]}, {"id": "2008.06529", "submitter": "Shahab Asoodeh", "authors": "Shahab Asoodeh, Jiachun Liao, Flavio P. Calmon, Oliver Kosut, and\n  Lalitha Sankar", "title": "Three Variants of Differential Privacy: Lossless Conversion and\n  Applications", "comments": "To appear in IEEE Journal on Selected Areas in Information Theory,\n  Special Issue on Privacy and Security of Information Systems. arXiv admin\n  note: text overlap with arXiv:2001.05990", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.CR math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider three different variants of differential privacy (DP), namely\napproximate DP, R\\'enyi DP (RDP), and hypothesis test DP. In the first part, we\ndevelop a machinery for optimally relating approximate DP to RDP based on the\njoint range of two $f$-divergences that underlie the approximate DP and RDP. In\nparticular, this enables us to derive the optimal approximate DP parameters of\na mechanism that satisfies a given level of RDP. As an application, we apply\nour result to the moments accountant framework for characterizing privacy\nguarantees of noisy stochastic gradient descent (SGD). When compared to the\nstate-of-the-art, our bounds may lead to about 100 more stochastic gradient\ndescent iterations for training deep learning models for the same privacy\nbudget. In the second part, we establish a relationship between RDP and\nhypothesis test DP which allows us to translate the RDP constraint into a\ntradeoff between type I and type II error probabilities of a certain binary\nhypothesis test. We then demonstrate that for noisy SGD our result leads to\ntighter privacy guarantees compared to the recently proposed $f$-DP framework\nfor some range of parameters.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 18:23:50 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 19:34:51 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Asoodeh", "Shahab", ""], ["Liao", "Jiachun", ""], ["Calmon", "Flavio P.", ""], ["Kosut", "Oliver", ""], ["Sankar", "Lalitha", ""]]}, {"id": "2008.06536", "submitter": "Adriana Szekeres", "authors": "Adriana Szekeres, Irene Zhang, Katelin Bailey, Isaac Ackerman, Haichen\n  Shen, Franziska Roesner, Dan R. K. Ports, Arvind Krishnamurthy, and Henry M.\n  Levy", "title": "Making Distributed Mobile Applications SAFE: Enforcing User Privacy\n  Policies on Untrusted Applications with Secure Application Flow Enforcement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's mobile devices sense, collect, and store huge amounts of personal\ninformation, which users share with family and friends through a wide range of\napplications. Once users give applications access to their data, they must\nimplicitly trust that the apps correctly maintain data privacy. As we know from\nboth experience and all-too-frequent press articles, that trust is often\nmisplaced. While users do not trust applications, they do trust their mobile\ndevices and operating systems. Unfortunately, sharing applications are not\nlimited to mobile clients but must also run on cloud services to share data\nbetween users. In this paper, we leverage the trust that users have in their\nmobile OSes to vet cloud services. To do so, we define a new Secure Application\nFlow Enforcement (SAFE) framework, which requires cloud services to attest to a\nsystem stack that will enforce policies provided by the mobile OS for user\ndata. We implement a mobile OS that enforces SAFE policies on unmodified mobile\napps and two systems for enforcing policies on untrusted cloud services. Using\nthese prototypes, we demonstrate that it is possible to enforce existing user\nprivacy policies on unmodified applications.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 18:35:38 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Szekeres", "Adriana", ""], ["Zhang", "Irene", ""], ["Bailey", "Katelin", ""], ["Ackerman", "Isaac", ""], ["Shen", "Haichen", ""], ["Roesner", "Franziska", ""], ["Ports", "Dan R. K.", ""], ["Krishnamurthy", "Arvind", ""], ["Levy", "Henry M.", ""]]}, {"id": "2008.06612", "submitter": "Ahmed Alshehri", "authors": "Ahmed Alshehri, Malek Ben Salem, and Lei Ding", "title": "Are Smart Home Devices Abandoning IPV Victims?", "comments": null, "journal-ref": null, "doi": "10.1109/TrustCom50675.2020.00184", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart home devices have brought us many benefits such as advanced security,\nconvenience, and entertainment. However, these devices also have made\nunintended consequences like giving ultimate power for devices' owners over\ntheir intimate partners in the same household which might lead to\ntech-facilitated domestic abuse (tech-abuse) as recent research has shown. In\nthis paper, we systematize findings on tech-abuse in smart homes. We show that\ndomestic abuse and Intimate Partner Violence (IPV) in smart homes is more\neffective and less risky for abusers. Victims find it more harmful and more\nchallenging to protect themselves from. We articulate a comprehensive analysis\nof all the phases of abuse in smart homes and categorize risks and needs in\neach phase. Technical analysis of current smart home technologies is conducted\nto shed light upon their limitations. We also summarize recent recommendations\nto combat tech-abuse in smart homes and focus on their potentials and\nshortcomings. Unsurprisingly, we find that many recommendations conflict with\neach other due to a lack of understanding of phases of abuse in smart homes.\nDesirable properties to design abuse-resistant smart home devices are proposed\nfor all the phases of abuse. The research community benefits from our analysis\nand recommendations to move forward with a focus on filling the blind spots of\nexisting smart home devices' safety measures and building appropriate safety\nmeasures that consider tech-abuse threats in smart homes.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 00:43:15 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Alshehri", "Ahmed", ""], ["Salem", "Malek Ben", ""], ["Ding", "Lei", ""]]}, {"id": "2008.06617", "submitter": "Venkat Anantharam", "authors": "Venkat Anantharam and Francois Baccelli", "title": "Nash equilibrium structure of Cox process Hotelling games", "comments": "Preliminary versions presented at the Workshop on Information Theory\n  and its Applications, ITA-2019, San Diego, in February 2019 and the Symposium\n  on Advances in Communications Networks, IISC, Bengaluru, in July 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CR cs.GT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an N-player game where a pure action of each player is to select a\nnon-negative function on a Polish space supporting a finite diffuse measure,\nsubject to a finite constraint on the integral of the function. This function\nis used to define the intensity of a Poisson point process on the Polish space.\nThe processes are independent over the players, and the value to a player is\nthe measure of the union of its open Voronoi cells in the superposition point\nprocess. Under randomized strategies, the process of points of a player is thus\na Cox process, and the nature of competition between the players is akin to\nthat in Hotelling competition games. We characterize when such a game admits\nNash equilibria and prove that when a Nash equilibrium exists, it is unique and\ncomprised of pure strategies that are proportional in the same proportions as\nthe total intensities. We give examples of such games where Nash equilibria do\nnot exist. A better understanding of the criterion for the existence of Nash\nequilibria remains an intriguing open problem.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 01:11:16 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Anantharam", "Venkat", ""], ["Baccelli", "Francois", ""]]}, {"id": "2008.06627", "submitter": "Rishabh Poddar", "authors": "Rishabh Poddar, Stephanie Wang, Jianan Lu, Raluca Ada Popa", "title": "Practical Volume-Based Attacks on Encrypted Databases", "comments": "IEEE EuroS&P 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen an increased interest towards strong security\nprimitives for encrypted databases (such as oblivious protocols), that hide the\naccess patterns of query execution, and reveal only the volume of results.\nHowever, recent work has shown that even volume leakage can enable the\nreconstruction of entire columns in the database. Yet, existing attacks rely on\na set of assumptions that are unrealistic in practice: for example, they (i)\nrequire a large number of queries to be issued by the user, or (ii) assume\ncertain distributions on the queries or underlying data (e.g., that the queries\nare distributed uniformly at random, or that the database does not contain\nmissing values).\n  In this work, we present new attacks for recovering the content of individual\nuser queries, assuming no leakage from the system except the number of results\nand avoiding the limiting assumptions above. Unlike prior attacks, our attacks\nrequire only a single query to be issued by the user for recovering the\nkeyword. Furthermore, our attacks make no assumptions about the distribution of\nissued queries or the underlying data. Instead, our key insight is to exploit\nthe behavior of real-world applications.\n  We start by surveying 11 applications to identify two key characteristics\nthat can be exploited by attackers: (i) file injection, and (ii) automatic\nquery replay. We present attacks that leverage these two properties in concert\nwith volume leakage, independent of the details of any encrypted database\nsystem. Subsequently, we perform an attack on the real Gmail web client by\nsimulating a server-side adversary. Our attack on Gmail completes within a\nmatter of minutes, demonstrating the feasibility of our techniques. We also\npresent three ancillary attacks for situations when certain mitigation\nstrategies are employed.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 02:20:53 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Poddar", "Rishabh", ""], ["Wang", "Stephanie", ""], ["Lu", "Jianan", ""], ["Popa", "Raluca Ada", ""]]}, {"id": "2008.06648", "submitter": "Abhishek Singh", "authors": "Priyanka Singh, Abhishek Singh, Gabriel Cojocaru, Praneeth Vepakomma,\n  Ramesh Raskar", "title": "PPContactTracing: A Privacy-Preserving Contact Tracing Protocol for\n  COVID-19 Pandemic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several contact tracing solutions have been proposed and implemented all\naround the globe to combat the spread of COVID-19 pandemic. But, most of these\nsolutions endanger the privacy rights of the individuals and hinder their\nwidespread adoption. We propose a privacy-preserving contact tracing protocol\nfor the efficient tracing of the spread of the global pandemic. It is based on\nthe private set intersection (PSI) protocol and utilizes the homomorphic\nproperties to preserve the privacy at the individual level. A hierarchical\nmodel for the representation of landscapes and rate-limiting factor on the\nnumber of queries have been adopted to maintain the efficiency of the protocol.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 04:20:09 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Singh", "Priyanka", ""], ["Singh", "Abhishek", ""], ["Cojocaru", "Gabriel", ""], ["Vepakomma", "Praneeth", ""], ["Raskar", "Ramesh", ""]]}, {"id": "2008.06694", "submitter": "Cristian Mart\\'in Dr", "authors": "Cristian Mart\\'in, Iv\\'an Alba, Joaqu\\'in Trillo, Enrique Soler,\n  Bartolom\\'e Rubio and Manuel D\\'iaz", "title": "Providing reliability and auditability to the IoT LwM2M protocol through\n  Blockchain", "comments": "13 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain has come to provide transparency, reliability as well as to\nincrease the security in computer systems, especially in distributed ones like\nthe Internet of Things (IoT). A few integrations have been proposed in this\ncontext so far; however, most of these solutions do not pay special attention\nto the interoperability of the IoT, one of the biggest challenges in this\nfield. In this paper, a Blockchain solution has been integrated into the OMA\nLightweight M2M (LwM2M), a promising industry IoT protocol for global\ninteroperability. This integration provides reliability and auditability to the\nLwM2M protocol enabling IoT devices (LwM2M clients) to transparently interact\nwith the protocol. Furthermore, a missing reliable API to allow users and\napplications to securely interact with the system and an interface to store\ncritical information like anomalies for auditability have been defined.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 10:12:16 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Mart\u00edn", "Cristian", ""], ["Alba", "Iv\u00e1n", ""], ["Trillo", "Joaqu\u00edn", ""], ["Soler", "Enrique", ""], ["Rubio", "Bartolom\u00e9", ""], ["D\u00edaz", "Manuel", ""]]}, {"id": "2008.06747", "submitter": "Shailesh Mishra", "authors": "Shailesh Mishra and Shivam Kumar", "title": "Smart Voltage Monitoring: Centralised and Blockchain-based Decentralised\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voltage controls the majority of the processes around us, starting from\nlighting an incandescent lamp to running huge machines in industries.\nTherefore, voltage monitoring becomes essential, which demands efficient\nmeasurement and storage of voltage data. However, there is hardly any system\ntill date that fulfils both the goals of voltage monitoring and voltage data\nstorage. To achieve this goal, we propose the application of the Internet of\nThings along with the server-based framework and Distributed Ledger Technology\nto build systems for smart voltage monitoring. Two models - a centralised model\nand a decentralised model have been presented and analysed thoroughly in this\npaper. The centralised model is built on client-server architecture, whereas\nthe decentralised model is based on a peer-to-peer architecture. Blockchain and\nInterPlanetary File System have been used for the implementation of the\ndecentralised system. Potential improvements to make these systems robust have\nalso been discussed. The methods proposed in this paper for voltage monitoring\nare novel; ensure efficient data storage and can be used for IoT data storage\nof any form.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 16:16:05 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 14:36:02 GMT"}, {"version": "v3", "created": "Thu, 17 Sep 2020 16:59:21 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Mishra", "Shailesh", ""], ["Kumar", "Shivam", ""]]}, {"id": "2008.06763", "submitter": "William Buchanan Prof", "authors": "Zakwan Jaroucheh, Baraq Ghaleb and William J Buchanan", "title": "SklCoin: Toward a Scalable Proof-of-Stake and Collective Signature Based\n  Consensus Protocol for Strong Consistency in Blockchain", "comments": null, "journal-ref": "IEEE Conference on Software Architecture Companion, 143-150, 2020", "doi": "10.1109/ICSA-C50368.2020.00034", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The proof-of-work consensus protocol suffers from two main limitations: waste\nof energy and offering only probabilistic guarantees about the status of the\nblockchain. This paper introduces SklCoin, a new Byzantine consensus protocol\nand its corresponding software architecture. This protocol leverages two ideas:\n1) the proof-of-stake concept to dynamically form stake proportionate consensus\ngroups that represent block miners (stakeholders), and 2) scalable collective\nsigning to efficiently commit transactions irreversibly. SklCoin has immediate\nfinality characteristic where all miners instantly agree on the validity of\nblocks. In addition, SklCoin supports high transaction rate because of its fast\nminer election mechanism\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 18:50:26 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Jaroucheh", "Zakwan", ""], ["Ghaleb", "Baraq", ""], ["Buchanan", "William J", ""]]}, {"id": "2008.06813", "submitter": "Nissy Sombatruang", "authors": "Nissy Sombatruang, Tan Omiya, Daisuke Miyamoto, M. Angela Sasse, Youki\n  Kadobayashi, Michelle Baddeley", "title": "Attributes affecting user decision to adopt a Virtual Private Network\n  (VPN) app", "comments": "First published in the 22nd International Conference on Information\n  and Communications Security (ICICS 2020), Copenhagen, Denmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Virtual Private Network (VPN) helps to mitigate security and privacy risks\nof data transmitting on unsecured network such as public Wi-Fi. However,\ndespite awareness of public Wi-Fi risks becoming increasingly common, the use\nof VPN when using public Wi-Fi is low. To increase adoption, understanding\nfactors driving user decision to adopt a VPN app is an important first step.\nThis study is the first to achieve this objective using discrete choice\nexperiments (DCEs) to elicit individual preferences of specific attributes of a\nVPN app. The experiments were run in the United Kingdom (UK) and Japan (JP). We\nfirst interviewed participants (15 UK, 17 JP) to identify common attributes of\na VPN app which they considered important. The results were used to design and\nrun a DCE in each country. Participants (149 UK, 94 JP) were shown a series of\ntwo hypothetical VPN apps, varying in features, and were asked to choose one\nwhich they preferred. Customer review rating, followed by price of a VPN app,\nsignificantly affected the decision to choose which VPN app to download and\ninstall. A change from a rating of 3 to 4-5 stars increased the probability of\nchoosing an app by 33% in the UK and 14% in Japan. Unsurprisingly, price was a\ndeterrent. Recommendations by friends, source of product reviews, and the\npresence of in-app ads also played a role but to a lesser extent. To actually\nuse a VPN app, participants considered Internet speed, connection stability,\nbattery level on mobile devices, and the presence of in-app ads as key drivers.\nParticipants in the UK and in Japan prioritized these attributes differently,\nsuggesting possible influences from cultural differences.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 00:02:49 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Sombatruang", "Nissy", ""], ["Omiya", "Tan", ""], ["Miyamoto", "Daisuke", ""], ["Sasse", "M. Angela", ""], ["Kadobayashi", "Youki", ""], ["Baddeley", "Michelle", ""]]}, {"id": "2008.06822", "submitter": "Sizhe Chen", "authors": "Sizhe Chen, Fan He, Xiaolin Huang, Kun Zhang", "title": "Relevance Attack on Detectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on high-transferable adversarial attacks on detectors,\nwhich are hard to attack in a black-box manner, because of their\nmultiple-output characteristics and the diversity across architectures. To\npursue a high attack transferability, one plausible way is to find a common\nproperty across detectors, which facilitates the discovery of common\nweaknesses. We are the first to suggest that the relevance map from\ninterpreters for detectors is such a property. Based on it, we design a\nRelevance Attack on Detectors (RAD), which achieves a state-of-the-art\ntransferability, exceeding existing results by above 20%. On MS COCO, the\ndetection mAPs for all 8 black-box architectures are more than halved and the\nsegmentation mAPs are also significantly influenced. Given the great\ntransferability of RAD, we generate the first adversarial dataset for object\ndetection and instance segmentation, i.e., Adversarial Objects in COntext\n(AOCO), which helps to quickly evaluate and improve the robustness of\ndetectors.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 02:44:25 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 06:27:56 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Chen", "Sizhe", ""], ["He", "Fan", ""], ["Huang", "Xiaolin", ""], ["Zhang", "Kun", ""]]}, {"id": "2008.06832", "submitter": "Dayong Ye", "authors": "Dayong Ye and Tianqing Zhu and Sheng Shen and Wanlei Zhou and Philip\n  S. Yu", "title": "Differentially Private Multi-Agent Planning for Logistic-like Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning is one of the main approaches used to improve agents' working\nefficiency by making plans beforehand. However, during planning, agents face\nthe risk of having their private information leaked. This paper proposes a\nnovel strong privacy-preserving planning approach for logistic-like problems.\nThis approach outperforms existing approaches by addressing two challenges: 1)\nsimultaneously achieving strong privacy, completeness and efficiency, and 2)\naddressing communication constraints. These two challenges are prevalent in\nmany real-world applications including logistics in military environments and\npacket routing in networks. To tackle these two challenges, our approach adopts\nthe differential privacy technique, which can both guarantee strong privacy and\ncontrol communication overhead. To the best of our knowledge, this paper is the\nfirst to apply differential privacy to the field of multi-agent planning as a\nmeans of preserving the privacy of agents for logistic-like problems. We\ntheoretically prove the strong privacy and completeness of our approach and\nempirically demonstrate its efficiency. We also theoretically analyze the\ncommunication overhead of our approach and illustrate how differential privacy\ncan be used to control it.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 03:43:09 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Ye", "Dayong", ""], ["Zhu", "Tianqing", ""], ["Shen", "Sheng", ""], ["Zhou", "Wanlei", ""], ["Yu", "Philip S.", ""]]}, {"id": "2008.06860", "submitter": "Sachin Saxena", "authors": "Sachin Saxena", "title": "TextDecepter: Hard Label Black Box Attack on Text Classifiers", "comments": "10 pages, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has been proven to be susceptible to carefully crafted\nsamples, known as adversarial examples. The generation of these adversarial\nexamples helps to make the models more robust and gives us an insight into the\nunderlying decision-making of these models. Over the years, researchers have\nsuccessfully attacked image classifiers in both, white and black-box settings.\nHowever, these methods are not directly applicable to texts as text data is\ndiscrete. In recent years, research on crafting adversarial examples against\ntextual applications has been on the rise. In this paper, we present a novel\napproach for hard-label black-box attacks against Natural Language Processing\n(NLP) classifiers, where no model information is disclosed, and an attacker can\nonly query the model to get a final decision of the classifier, without\nconfidence scores of the classes involved. Such an attack scenario applies to\nreal-world black-box models being used for security-sensitive applications such\nas sentiment analysis and toxic content detection.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 08:57:01 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 00:06:56 GMT"}, {"version": "v3", "created": "Fri, 27 Nov 2020 02:27:55 GMT"}, {"version": "v4", "created": "Sat, 19 Dec 2020 23:01:13 GMT"}, {"version": "v5", "created": "Tue, 22 Dec 2020 03:21:17 GMT"}, {"version": "v6", "created": "Mon, 28 Dec 2020 00:23:08 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Saxena", "Sachin", ""]]}, {"id": "2008.06890", "submitter": "Gaurav Kasbekar", "authors": "Adhirath Kabra, Sumit Kumar, Gaurav S. Kasbekar", "title": "Efficient, Flexible and Secure Group Key Management Protocol for Dynamic\n  IoT Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many Internet of Things (IoT) scenarios require communication to and data\nacquisition from multiple devices with similar functionalities. For such\nscenarios, group communication in the form of multicasting and broadcasting has\nproven to be effective. Group Key Management (GKM) involves the handling,\nrevocation, updation and distribution of cryptographic keys to members of\nvarious groups. Classical GKM schemes perform inefficiently in dynamic IoT\nenvironments, which are those wherein nodes frequently leave or join a network\nor migrate from one group to another over time. Recently, the `GroupIt' scheme\nhas been proposed for GKM in dynamic IoT environments. However, this scheme has\nseveral limitations such as vulnerability to collusion attacks, the use of\ncomputationally expensive asymmetric encryption and threats to the backward\nsecrecy of the system. In this paper, we present a highly efficient and secure\nGKM protocol for dynamic IoT settings, which maintains forward and backward\nsecrecy at all times. Our proposed protocol uses only symmetric encryption, and\nis completely resistant to collusion attacks. Also, our protocol is highly\nflexible and can handle several new scenarios in which device or user dynamics\nmay take place, e.g., allowing a device group to join or leave the network or\ncreation or dissolution of a user group, which are not handled by schemes\nproposed in prior literature. We evaluate the performance of the proposed\nprotocol via extensive mathematical analysis and numerical computations, and\nshow that it outperforms the GroupIt scheme in terms of the communication and\ncomputation costs incurred by users and devices.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 11:56:30 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Kabra", "Adhirath", ""], ["Kumar", "Sumit", ""], ["Kasbekar", "Gaurav S.", ""]]}, {"id": "2008.06913", "submitter": "Harry Halpin", "authors": "Harry Halpin", "title": "SoK: Why Johnny Can't Fix PGP Standardization", "comments": null, "journal-ref": null, "doi": "10.1145/3407023.3407083", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretty Good Privacy (PGP) has long been the primary IETF standard for\nencrypting email, but suffers from widespread usability and security problems\nthat have limited its adoption. As time has marched on, the underlying\ncryptographic protocol has fallen out of date insofar as PGP is unauthenticated\non a per message basis and compresses before encryption. There have been an\nincreasing number of attacks on the increasingly outdated primitives and\ncomplex clients used by the PGP eco-system. However, attempts to update the\nOpenPGP standard have failed at the IETF except for adding modern cryptographic\nprimitives. Outside of official standardization, Autocrypt is a \"bottom-up\"\ncommunity attempt to fix PGP, but still falls victim to attacks on PGP\ninvolving authentication. The core reason for the inability to \"fix\" PGP is the\nlack of a simple AEAD interface which in turn requires a decentralized public\nkey infrastructure to work with email. Yet even if standards like MLS replace\nPGP, the deployment of a decentralized PKI remains an open issue.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 14:13:05 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Halpin", "Harry", ""]]}, {"id": "2008.06923", "submitter": "Zhihuai Chen", "authors": "Zhihuai Chen, Bo Li, Xiaohan Shan, Xiaoming Sun, Jialin Zhang", "title": "Discouraging Pool Block Withholding Attacks in Bitcoins", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The arisen of Bitcoin has led to much enthusiasm for blockchain research and\nblock mining, and the extensive existence of mining pools helps its\nparticipants (i.e., miners) gain reward more frequently. Recently, the mining\npools are proved to be vulnerable for several possible attacks, and pool block\nwithholding attack is one of them: one strategic pool manager sends some of her\nminers to other pools and these miners pretend to work on the puzzles but\nactually do nothing. And these miners still get reward since the pool manager\ncan not recognize these malicious miners. In this work, we revisit the\ngame-theoretic model for pool block withholding attacks and propose a revised\napproach to reallocate the reward to the miners. Fortunately, in the new model,\nthe pool managers have strong incentive to not launch such attacks. We show\nthat for any number of mining pools, no-pool-attacks is always a Nash\nequilibrium. Moreover, with only two minority mining pools participating,\nno-pool-attacks is actually the unique Nash equilibrium.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 14:40:39 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Chen", "Zhihuai", ""], ["Li", "Bo", ""], ["Shan", "Xiaohan", ""], ["Sun", "Xiaoming", ""], ["Zhang", "Jialin", ""]]}, {"id": "2008.06926", "submitter": "Charalambos Konstantinou", "authors": "Ali Sayghe, Yaodan Hu, Ioannis Zografopoulos, XiaoRui Liu, Raj Gautam\n  Dutta, Yier Jin, Charalambos Konstantinou", "title": "A Survey of Machine Learning Methods for Detecting False Data Injection\n  Attacks in Power Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decade, the number of cyberattacks targeting power systems and\ncausing physical and economic damages has increased rapidly. Among them, False\nData Injection Attacks (FDIAs) is a class of cyberattacks against power grid\nmonitoring systems. Adversaries can successfully perform FDIAs in order to\nmanipulate the power system State Estimation (SE) by compromising sensors or\nmodifying system data. SE is an essential process performed by the Energy\nManagement System (EMS) towards estimating unknown state variables based on\nsystem redundant measurements and network topology. SE routines include Bad\nData Detection (BDD) algorithms to eliminate errors from the acquired\nmeasurements, e.g., in case of sensor failures. FDIAs can bypass BDD modules to\ninject malicious data vectors into a subset of measurements without being\ndetected, and thus manipulate the results of the SE process. In order to\novercome the limitations of traditional residual-based BDD approaches,\ndata-driven solutions based on machine learning algorithms have been widely\nadopted for detecting malicious manipulation of sensor data due to their fast\nexecution times and accurate results. This paper provides a comprehensive\nreview of the most up-to-date machine learning methods for detecting FDIAs\nagainst power system SE algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 14:48:26 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Sayghe", "Ali", ""], ["Hu", "Yaodan", ""], ["Zografopoulos", "Ioannis", ""], ["Liu", "XiaoRui", ""], ["Dutta", "Raj Gautam", ""], ["Jin", "Yier", ""], ["Konstantinou", "Charalambos", ""]]}, {"id": "2008.07072", "submitter": "Fatemeh Ganji", "authors": "Shahin Tajik and Fatemeh Ganji", "title": "Artificial Neural Networks and Fault Injection Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This chapter is on the security assessment of artificial intelligence (AI)\nand neural network (NN) accelerators in the face of fault injection attacks.\nMore specifically, it discusses the assets on these platforms and compares them\nwith ones known and well-studied in the field of cryptographic systems. This is\na crucial step that must be taken in order to define the threat models\nprecisely. With respect to that, fault attacks mounted on NNs and AI\naccelerators are explored.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 03:29:57 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 16:27:03 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Tajik", "Shahin", ""], ["Ganji", "Fatemeh", ""]]}, {"id": "2008.07076", "submitter": "Vipin Singh Sehrawat", "authors": "Vipin Singh Sehrawat, Yogendra Shah, Vinod Kumar Choyi, Alec\n  Brusilovsky and Samir Ferdi", "title": "Certificate and Signature Free Anonymity for V2V Communications", "comments": "This is the full version of the paper that appeared in 2017 IEEE\n  Vehicular Networking Conference (VNC), pp. 139-146. DOI:\n  10.1109/VNC.2017.8275624", "journal-ref": "IEEE Vehicular Networking Conference (VNC), pp. 139-146, 2017", "doi": "10.1109/VNC.2017.8275624", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anonymity is a desirable feature for vehicle-to-vehicle (V2V) communications,\nbut it conflicts with other requirements such as non-repudiation and\nrevocation. Existing, pseudonym-based V2V communications schemes rely on\ncertificate generation and signature verification. These schemes require\ncumbersome key management, frequent updating of certificate chains and other\ncostly procedures such as cryptographic pairings. In this paper, we present\nnovel V2V communications schemes, that provide authentication, authorization,\nanonymity, non-repudiation, replay protection, pseudonym revocation, and\nforward secrecy without relying on traditional certificate generation and\nsignature verification. Security and privacy of our schemes rely on hard\nproblems in number theory. Furthermore, our schemes guarantee security and\nprivacy in the presence of subsets of colluding malicious parties, provided\nthat the cardinality of such sets is below a fixed threshold.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 03:52:33 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Sehrawat", "Vipin Singh", ""], ["Shah", "Yogendra", ""], ["Choyi", "Vinod Kumar", ""], ["Brusilovsky", "Alec", ""], ["Ferdi", "Samir", ""]]}, {"id": "2008.07125", "submitter": "Luca Demetrio", "authors": "Luca Demetrio and Scott E. Coull and Battista Biggio and Giovanni\n  Lagorio and Alessandro Armando and Fabio Roli", "title": "Adversarial EXEmples: A Survey and Experimental Evaluation of Practical\n  Attacks on Machine Learning for Windows Malware Detection", "comments": null, "journal-ref": "ACM Transactions on Privacy and Security, 2021", "doi": "10.1145/3473039", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that adversarial Windows malware samples - referred to\nas adversarial EXEmples in this paper - can bypass machine learning-based\ndetection relying on static code analysis by perturbing relatively few input\nbytes. To preserve malicious functionality, previous attacks either add bytes\nto existing non-functional areas of the file, potentially limiting their\neffectiveness, or require running computationally-demanding validation steps to\ndiscard malware variants that do not correctly execute in sandbox environments.\nIn this work, we overcome these limitations by developing a unifying framework\nthat does not only encompass and generalize previous attacks against\nmachine-learning models, but also includes three novel attacks based on\npractical, functionality-preserving manipulations to the Windows Portable\nExecutable (PE) file format. These attacks, named Full DOS, Extend and Shift,\ninject the adversarial payload by respectively manipulating the DOS header,\nextending it, and shifting the content of the first section. Our experimental\nresults show that these attacks outperform existing ones in both white-box and\nblack-box scenarios, achieving a better trade-off in terms of evasion rate and\nsize of the injected payload, while also enabling evasion of models that have\nbeen shown to be robust to previous attacks. To facilitate reproducibility of\nour findings, we open source our framework and all the corresponding attack\nimplementations as part of the secml-malware Python library. We conclude this\nwork by discussing the limitations of current machine learning-based malware\ndetectors, along with potential mitigation strategies based on embedding domain\nknowledge coming from subject-matter experts directly into the learning\nprocess.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 07:16:57 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 08:15:59 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Demetrio", "Luca", ""], ["Coull", "Scott E.", ""], ["Biggio", "Battista", ""], ["Lagorio", "Giovanni", ""], ["Armando", "Alessandro", ""], ["Roli", "Fabio", ""]]}, {"id": "2008.07185", "submitter": "Javier Cabrera Arteaga", "authors": "Javier Cabrera Arteaga, Orestis Floros Malivitsis, Oscar Luis Vera\n  P\\'erez, Benoit Baudry, Martin Monperrus", "title": "CROW: Code Diversification for WebAssembly", "comments": null, "journal-ref": "Proceedings of the Workshop on Measurements, Attacks, and Defenses\n  for the Web (MADWeb), 2021", "doi": "10.14722/madweb.2021.23xxx", "report-no": null, "categories": "cs.SE cs.CR cs.PL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The adoption of WebAssembly has rapidly increased in the last few years as it\nprovides a fast and safe model for program execution. However, WebAssembly is\nnot exempt from vulnerabilities that could be exploited by side channels\nattacks. This class of vulnerabilities that can be addressed by code\ndiversification. In this paper, we present the first fully automated workflow\nfor the diversification of WebAssembly binaries. We present CROW, an\nopen-source tool implementing this workflow. We evaluate CROW's capabilities on\n303 C programs and study its use on a real-life security-sensitive program:\nlibsodium, a cryptographic library. Overall, CROWis able to generate diverse\nvariants for 239 out of 303,(79%) small programs. Furthermore, our experiments\nshow that our approach and tool is able to successfully diversify off-the-shelf\ncryptographic software (libsodium).\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 10:00:32 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 07:27:38 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 11:02:47 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Arteaga", "Javier Cabrera", ""], ["Malivitsis", "Orestis Floros", ""], ["P\u00e9rez", "Oscar Luis Vera", ""], ["Baudry", "Benoit", ""], ["Monperrus", "Martin", ""]]}, {"id": "2008.07216", "submitter": "Igor Semaev", "authors": "Igor Semaev", "title": "Algorithm for SIS and MultiSIS problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SIS problem has numerous applications in cryptography. Known algorithms for\nsolving that problem are exponential in complexity. A new algorithm is\nsuggested in this note, its complexity is sub-exponential for a range of\nparameters.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 10:53:57 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Semaev", "Igor", ""]]}, {"id": "2008.07298", "submitter": "Buse Gul Atli Tekgul", "authors": "Buse Gul Atli, Yuxi Xia, Samuel Marchal, N. Asokan", "title": "WAFFLE: Watermarking in Federated Learning", "comments": "Will appear in the proceedings of SRDS 2021; 14 pages, 11 figures, 10\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning is a distributed learning technique where machine learning\nmodels are trained on client devices in which the local training data resides.\nThe training is coordinated via a central server which is, typically,\ncontrolled by the intended owner of the resulting model. By avoiding the need\nto transport the training data to the central server, federated learning\nimproves privacy and efficiency. But it raises the risk of model theft by\nclients because the resulting model is available on every client device. Even\nif the application software used for local training may attempt to prevent\ndirect access to the model, a malicious client may bypass any such restrictions\nby reverse engineering the application software. Watermarking is a well-known\ndeterrence method against model theft by providing the means for model owners\nto demonstrate ownership of their models. Several recent deep neural network\n(DNN) watermarking techniques use backdooring: training the models with\nadditional mislabeled data. Backdooring requires full access to the training\ndata and control of the training process. This is feasible when a single party\ntrains the model in a centralized manner, but not in a federated learning\nsetting where the training process and training data are distributed among\nseveral client devices. In this paper, we present WAFFLE, the first approach to\nwatermark DNN models trained using federated learning. It introduces a\nretraining step at the server after each aggregation of local models into the\nglobal model. We show that WAFFLE efficiently embeds a resilient watermark into\nmodels incurring only negligible degradation in test accuracy (-0.17%), and\ndoes not require access to training data. We also introduce a novel technique\nto generate the backdoor used as a watermark. It outperforms prior techniques,\nimposing no communication, and low computational (+3.2%) overhead.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 13:27:45 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 13:33:02 GMT"}, {"version": "v3", "created": "Thu, 22 Jul 2021 10:04:49 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Atli", "Buse Gul", ""], ["Xia", "Yuxi", ""], ["Marchal", "Samuel", ""], ["Asokan", "N.", ""]]}, {"id": "2008.07370", "submitter": "Oliver Hohlfeld", "authors": "Jens Helge Reelfs and Oliver Hohlfeld and Ingmar Poese", "title": "Corona-Warn-App: Tracing the Start of the Official COVID-19 Exposure\n  Notification App for Germany", "comments": "To appear at ACM SIGCOMM 2020 Posters", "journal-ref": null, "doi": "10.1145/3405837.3411378", "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On June 16, 2020, Germany launched an open-source smartphone contact tracing\napp (\"Corona-Warn-App\") to help tracing SARS-CoV-2 (coronavirus) infection\nchains. It uses a decentralized, privacy-preserving design based on the\nExposure Notification APIs in which a centralized server is only used to\ndistribute a list of keys of SARS-CoV-2 infected users that is fetched by the\napp once per day. Its success, however, depends on its adoption. In this\nposter, we characterize the early adoption of the app using Netflow traces\ncaptured directly at its hosting infrastructure. We show that the app generated\ntraffic from allover Germany---already on the first day. We further observe\nthat local COVID-19 outbreaks do not result in noticeable traffic increases.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 22:00:43 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Reelfs", "Jens Helge", ""], ["Hohlfeld", "Oliver", ""], ["Poese", "Ingmar", ""]]}, {"id": "2008.07381", "submitter": "Kaspar Rosager Ludvigsen", "authors": "Kaspar Rosager Ludvigsen and Shishir Nagaraja", "title": "Dissecting liabilities in adversarial surgical robot failures: A\n  national (Danish) and European law perspective", "comments": "38 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being connected to a network exposes surgical robots to cyberattacks, which\ncan damage the patient or the operator. These injuries are normally caused by\nsafety failures, such as accidents with industrial robots, but cyberattacks are\ncaused by security failures instead. Surgical robots are increasingly sold and\nused in the European Union, so we decide to uncover whether this change has\nbeen considered by EU law, and which legal remedies and actions a patient or\nmanufacturer would have in a single national legal system in the union. We\nfirst conduct a case study, where we analyse which legal remedies a patient can\nmake use of, if they are injured by a surgical robot caused by a cyberattack in\nthe national legal system. We also explore whether cybersecurity and\ncyberattacks are considered by the upcoming Medical Device Regulation of the\nEU. We show that the selected national legal system is adequate. This is\nbecause of its flexibility and in a certain approach even to ignore the\ndistinction between safety and security to the benefit of the patient, and in\none situation to remove liability from the manufacturer by erasing its status\nas party. Otherwise, unless the operator or other parties have made the\ncyberattack more likely to occur, the manufacturer is liable. We find that the\nregulation does not directly consider security defects, requiring\ninterpretation and use of guidance to show it. Due to the risk cyberattacks\npose on medical equipment, we find this to not be adequate. We further find\nthat the regulators of medical devices, including surgical robots, will not\nnecessarily have adequate staff or rules of enforcement, as this has been left\nto the member states to solve. But, we also find, due to the comprehensive\nnumber of rules that can be applied cumulatively, together with the possibility\nfor further rules and compliance later on, that these issues could be solved in\nthe future.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 13:04:22 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Ludvigsen", "Kaspar Rosager", ""], ["Nagaraja", "Shishir", ""]]}, {"id": "2008.07405", "submitter": "Mubarak Albarka Umar", "authors": "Mubarak Albarka Umar, Chen Zhanfang, Yan Liu", "title": "Network Intrusion Detection Using Wrapper-based Decision Tree for\n  Feature Selection", "comments": "8 pages, 3 figures, Presented at ICICSE 2020 Conference Proceedings,\n  which will be published in the International Conference Proceedings Series by\n  ACM, and will be archived in the ACM Digital Library", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the key challenges of machine learning (ML) based intrusion detection\nsystem (IDS) is the expensive computational complexity which is largely due to\nredundant, incomplete, and irrelevant features contain in the IDS datasets. To\novercome such challenge and ensure building an efficient and more accurate IDS\nmodels, many researchers utilize preprocessing techniques such as normalization\nand feature selection in a hybrid modeling approach. In this work, we propose a\nhybrid IDS modeling approach with an algorithm for feature selection (FS) and\nanother for building an IDS. The FS algorithm is a wrapper-based with a\ndecision tree as the feature evaluator. The propose FS method is used in\ncombination with some selected ML algorithms to build IDS models using the\nUNSW-NB15 dataset. Some IDS models are built as a baseline in a single modeling\napproach using the full features of the dataset. We evaluate the effectiveness\nof our propose method by comparing it with the baseline models and also with\nstate-of-the-art works. Our method achieves the best DR of 97.95% and shown to\nbe quite effective in comparison to state-of-the-art works. We, therefore,\nrecommend its usage especially in IDS modeling with the UNSW-NB15 dataset.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 04:00:58 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Umar", "Mubarak Albarka", ""], ["Zhanfang", "Chen", ""], ["Liu", "Yan", ""]]}, {"id": "2008.07504", "submitter": "Karim Banawan", "authors": "Zhusheng Wang and Karim Banawan and Sennur Ulukus", "title": "Multi-Party Private Set Intersection: An Information-Theoretic Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.DB eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of multi-party private set intersection (MP-PSI).\nIn MP-PSI, there are $M$ parties, each storing a data set $\\mathcal{p}_i$ over\n$N_i$ replicated and non-colluding databases, and we want to calculate the\nintersection of the data sets $\\cap_{i=1}^M \\mathcal{p}_i$ without leaking any\ninformation beyond the set intersection to any of the parties. We consider a\nspecific communication protocol where one of the parties, called the leader\nparty, initiates the MP-PSI protocol by sending queries to the remaining\nparties which are called client parties. The client parties are not allowed to\ncommunicate with each other. We propose an information-theoretic scheme that\nprivately calculates the intersection $\\cap_{i=1}^M \\mathcal{p}_i$ with a\ndownload cost of $D = \\min_{t \\in \\{1, \\cdots, M\\}} \\sum_{i \\in \\{1, \\cdots\nM\\}\\setminus {t}} \\left\\lceil \\frac{|\\mathcal{p}_t|N_i}{N_i-1}\\right\\rceil$.\nSimilar to the 2-party PSI problem, our scheme builds on the connection between\nthe PSI problem and the multi-message symmetric private information retrieval\n(MM-SPIR) problem. Our scheme is a non-trivial generalization of the 2-party\nPSI scheme as it needs an intricate design of the shared common randomness.\nInterestingly, in terms of the download cost, our scheme does not incur any\npenalty due to the more stringent privacy constraints in the MP-PSI problem\ncompared to the 2-party PSI problem.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 17:51:53 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wang", "Zhusheng", ""], ["Banawan", "Karim", ""], ["Ulukus", "Sennur", ""]]}, {"id": "2008.07664", "submitter": "Javad Rahimipour Anaraki", "authors": "Javad Rahimipour Anaraki, Saeed Samet", "title": "Privacy-preserving feature selection: A survey and proposing a new set\n  of protocols", "comments": "29 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is the process of sieving features, in which informative\nfeatures are separated from the redundant and irrelevant ones. This process\nplays an important role in machine learning, data mining and bioinformatics.\nHowever, traditional feature selection methods are only capable of processing\ncentralized datasets and are not able to satisfy today's distributed data\nprocessing needs. These needs require a new category of data processing\nalgorithms called privacy-preserving feature selection, which protects users'\ndata by not revealing any part of the data neither in the intermediate\nprocessing nor in the final results. This is vital for the datasets which\ncontain individuals' data, such as medical datasets. Therefore, it is rational\nto either modify the existing algorithms or propose new ones to not only\nintroduce the capability of being applied to distributed datasets, but also act\nresponsibly in handling users' data by protecting their privacy. In this paper,\nwe will review three privacy-preserving feature selection methods and provide\nsuggestions to improve their performance when any gap is identified. We will\nalso propose a privacy-preserving feature selection method based on the rough\nset feature selection. The proposed method is capable of processing both\nhorizontally and vertically partitioned datasets in two- and multi-parties\nscenarios.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 23:14:45 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Anaraki", "Javad Rahimipour", ""], ["Samet", "Saeed", ""]]}, {"id": "2008.07711", "submitter": "Shanjiaoyang Huang", "authors": "Shanjiaoyang Huang, Weiqi Peng, Zhiwei Jia, Zhuowen Tu", "title": "One-pixel Signature: Characterizing CNN Models for Backdoor Detection", "comments": "Accepted at ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the convolution neural networks (CNNs) backdoor detection problem\nby proposing a new representation called one-pixel signature. Our task is to\ndetect/classify if a CNN model has been maliciously inserted with an unknown\nTrojan trigger or not. Here, each CNN model is associated with a signature that\nis created by generating, pixel-by-pixel, an adversarial value that is the\nresult of the largest change to the class prediction. The one-pixel signature\nis agnostic to the design choice of CNN architectures, and how they were\ntrained. It can be computed efficiently for a black-box CNN model without\naccessing the network parameters. Our proposed one-pixel signature demonstrates\na substantial improvement (by around 30% in the absolute detection accuracy)\nover the existing competing methods for backdoored CNN\ndetection/classification. One-pixel signature is a general representation that\ncan be used to characterize CNN models beyond backdoor detection.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 02:54:47 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Huang", "Shanjiaoyang", ""], ["Peng", "Weiqi", ""], ["Jia", "Zhiwei", ""], ["Tu", "Zhuowen", ""]]}, {"id": "2008.07738", "submitter": "Helen Jiang", "authors": "Helen Jiang, Erwen Senge", "title": "Usable Security for ML Systems in Mental Health: A Framework", "comments": "Accepted to Designing AI in Support of Good Mental Health (GOOD)\n  Workshop at KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the applications and demands of Machine learning (ML) systems in mental\nhealth are growing, there is little discussion nor consensus regarding a\nuniquely challenging aspect: building security methods and requirements into\nthese ML systems, and keep the ML system usable for end-users. This question of\nusable security is very important, because the lack of consideration in either\nsecurity or usability would hinder large-scale user adoption and active usage\nof ML systems in mental health applications.\n  In this short paper, we introduce a framework of four pillars, and a set of\ndesired properties which can be used to systematically guide and evaluate\nsecurity-related designs, implementations, and deployments of ML systems for\nmental health. We aim to weave together threads from different domains,\nincorporate existing views, and propose new principles and requirements, in an\neffort to lay out a clear framework where criteria and expectations are\nestablished, and are used to make security mechanisms usable for end-users of\nthose ML systems in mental health. Together with this framework, we present\nseveral concrete scenarios where different usable security cases and profiles\nin ML-systems in mental health applications are examined and evaluated.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 04:44:47 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Jiang", "Helen", ""], ["Senge", "Erwen", ""]]}, {"id": "2008.07758", "submitter": "Fei Zheng", "authors": "Fei Zheng", "title": "Efficient Private Machine Learning by Differentiable Random\n  Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing demands for privacy protection, many privacy-preserving\nmachine learning systems were proposed in recent years. However, most of them\ncannot be put into production due to their slow training and inference speed\ncaused by the heavy cost of homomorphic encryption and secure multiparty\ncomputation(MPC) methods. To circumvent this, I proposed a privacy definition\nwhich is suitable for large amount of data in machine learning tasks. Based on\nthat, I showed that random transformations like linear transformation and\nrandom permutation can well protect privacy. Merging random transformations and\narithmetic sharing together, I designed a framework for private machine\nlearning with high efficiency and low computation cost.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 06:17:31 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Zheng", "Fei", ""]]}, {"id": "2008.07795", "submitter": "Stephan Wiefling", "authors": "Stephan Wiefling, Tanvi Patil, Markus D\\\"urmuth and Luigi Lo Iacono", "title": "Evaluation of Risk-based Re-Authentication Methods", "comments": "14 pages, 5 figures. Paper accepted for IFIP SEC 2020. Keywords:\n  Risk-based Authentication (RBA), Re-authentication, Usable Security", "journal-ref": "35th IFIP TC-11 International Conference on Information Security\n  and Privacy Protection (IFIP SEC 2020). IFIP Advances in Information and\n  Communication Technology, vol. 580, pp. 280-294. Springer, Cham", "doi": "10.1007/978-3-030-58201-2_19", "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk-based Authentication (RBA) is an adaptive security measure that improves\nthe security of password-based authentication by protecting against credential\nstuffing, password guessing, or phishing attacks. RBA monitors extra features\nduring login and requests for an additional authentication step if the observed\nfeature values deviate from the usual ones in the login history. In\nstate-of-the-art RBA re-authentication deployments, users receive an email with\na numerical code in its body, which must be entered on the online service.\nAlthough this procedure has a major impact on RBA's time exposure and\nusability, these aspects were not studied so far.\n  We introduce two RBA re-authentication variants supplementing the de facto\nstandard with a link-based and another code-based approach. Then, we present\nthe results of a between-group study (N=592) to evaluate these three\napproaches. Our observations show with significant results that there is\npotential to speed up the RBA re-authentication process without reducing\nneither its security properties nor its security perception. The link-based\nre-authentication via \"magic links\", however, makes users significantly more\nanxious than the code-based approaches when perceived for the first time. Our\nevaluations underline the fact that RBA re-authentication is not a uniform\nprocedure. We summarize our findings and provide recommendations.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 08:08:12 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Wiefling", "Stephan", ""], ["Patil", "Tanvi", ""], ["D\u00fcrmuth", "Markus", ""], ["Iacono", "Luigi Lo", ""]]}, {"id": "2008.07958", "submitter": "Fran Casino", "authors": "Lamprini Zarpala and Fran Casino", "title": "A blockchain-based Forensic Model for Financial Crime Investigation: The\n  Embezzlement Scenario", "comments": "Digit Finance (2021)", "journal-ref": null, "doi": "10.1007/s42521-021-00035-5", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The financial crime landscape is evolving along with the digitization in\nfinancial services. In this context, laws and regulations cannot efficiently\ncope with a fast-moving industry such as finance, which translates in late\nadoption of measures and legal voids, providing a fruitful landscape for\nmalicious actors. In parallel, blockchain technology and its promising features\nsuch as immutability, verifiability, and authentication, enhance the\nopportunities of financial forensics. In this paper, we focus on an\nembezzlement scheme and we provide a forensic-by-design methodology for its\ninvestigation. In addition, the feasibility and adaptability of our approach\ncan be extended and embrace digital investigations on other types of schemes.\nWe provide a functional implementation based on smart contracts and we\nintegrate standardised forensic flows and chain of custody preservation\nmechanisms. Finally, we discuss the benefits and challenges of the symbiotic\nrelationship between blockchain and financial investigations, along with future\nresearch directions.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 14:38:01 GMT"}, {"version": "v2", "created": "Sun, 23 Aug 2020 15:27:59 GMT"}, {"version": "v3", "created": "Mon, 19 Jul 2021 11:42:41 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Zarpala", "Lamprini", ""], ["Casino", "Fran", ""]]}, {"id": "2008.07969", "submitter": "Vipin Singh Sehrawat", "authors": "Vipin Singh Sehrawat and Yvo Desmedt", "title": "Access Structure Hiding Secret Sharing from Novel Set Systems and Vector\n  Families", "comments": "This is the full version of the paper that appears in D. Kim et al.\n  (Eds.): COCOON 2020 (The 26th International Computing and Combinatorics\n  Conference), LNCS 12273, pp. 246-261. This version contains tighter bounds on\n  the maximum share size, and the total number of access structures supported", "journal-ref": "Computing and Combinatorics. COCOON 2020. LNCS, vol 12273, pp.\n  246-261", "doi": "10.1007/978-3-030-58150-3_20", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secret sharing provides a means to distribute shares of a secret such that\nany authorized subset of shares, specified by an access structure, can be\npooled together to recompute the secret. The standard secret sharing model\nrequires public access structures, which violates privacy and facilitates the\nadversary by revealing high-value targets. In this paper, we address this\nshortcoming by introducing \\emph{hidden access structures}, which remain secret\nuntil some authorized subset of parties collaborate. The central piece of this\nwork is the construction of a set-system $\\mathcal{H}$ with strictly greater\nthan $\\exp\\left(c \\dfrac{1.5 (\\log h)^2}{\\log \\log h}\\right)$ subsets of a set\nof $h$ elements. Our set-system $\\mathcal{H}$ is defined over $\\mathbb{Z}_m$,\nwhere $m$ is a non-prime-power, such that the size of each set in $\\mathcal{H}$\nis divisible by $m$ but the sizes of their pairwise intersections are not\ndivisible by $m$, unless one set is a subset of another. We derive a vector\nfamily $\\mathcal{V}$ from $\\mathcal{H}$ such that superset-subset relationships\nin $\\mathcal{H}$ are represented by inner products in $\\mathcal{V}$. We use\n$\\mathcal{V}$ to \"encode\" the access structures and thereby develop the first\n\\emph{access structure hiding} secret sharing scheme. For a setting with $\\ell$\nparties, our scheme supports $2^{\\binom{\\ell}{\\ell/2+1}}$ out of the\n$2^{2^{\\ell - O(\\log \\ell)}}$ total monotone access structures, and its maximum\nshare size for any access structures is $(1+ o(1)) \\dfrac{2^{\\ell+1}}{\\sqrt{\\pi\n\\ell/2}}$. The scheme assumes semi-honest polynomial-time parties, and its\nsecurity relies on the Generalized Diffie-Hellman assumption.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 15:04:13 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 07:53:23 GMT"}, {"version": "v3", "created": "Sun, 23 May 2021 09:03:06 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Sehrawat", "Vipin Singh", ""], ["Desmedt", "Yvo", ""]]}, {"id": "2008.07986", "submitter": "Zachary Parish", "authors": "Zach Parish (1), Connor Cushing (1), Shourya Aggarwal (2), Amirali\n  Salehi-Abari (1), Julie Thorpe (1) ((1) Ontario Tech University (2) Indian\n  Institute of Technology Delhi)", "title": "Password Guessers Under a Microscope: An In-Depth Analysis to Inform\n  Deployments", "comments": "14 pages, 20 individual figures including 9 scale bars; clarified\n  that default settings were used for the guessing tools; modified table\n  formats", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Password guessers are instrumental for assessing the strength of passwords.\nDespite their diversity and abundance, little is known about how different\nguessers compare to each other. We perform in-depth analyses and comparisons of\nthe guessing abilities and behavior of password guessers. To extend analyses\nbeyond number of passwords cracked, we devise an analytical framework to\ncompare the types of passwords that guessers generate under various conditions\n(e.g., limited training data, limited number of guesses, and dissimilar\ntraining and target data). Our results show that guessers often produce\ndissimilar guesses, even when trained on the same data. We leverage this result\nto show that combinations of computationally-cheap guessers are as effective as\ncomputationally intensive guessers, but more efficient. Our insights allow us\nto provide a concrete set of recommendations for system administrators when\nperforming password checking.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 15:31:00 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 02:56:15 GMT"}, {"version": "v3", "created": "Sun, 21 Feb 2021 01:21:06 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Parish", "Zach", ""], ["Cushing", "Connor", ""], ["Aggarwal", "Shourya", ""], ["Salehi-Abari", "Amirali", ""], ["Thorpe", "Julie", ""]]}, {"id": "2008.08007", "submitter": "Badih Ghazi", "authors": "Badih Ghazi, Ravi Kumar, Pasin Manurangsi", "title": "Differentially Private Clustering: Tight Approximation Ratios", "comments": "60 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the task of differentially private clustering. For several basic\nclustering problems, including Euclidean DensestBall, 1-Cluster, k-means, and\nk-median, we give efficient differentially private algorithms that achieve\nessentially the same approximation ratios as those that can be obtained by any\nnon-private algorithm, while incurring only small additive errors. This\nimproves upon existing efficient algorithms that only achieve some large\nconstant approximation factors.\n  Our results also imply an improved algorithm for the Sample and Aggregate\nprivacy framework. Furthermore, we show that one of the tools used in our\n1-Cluster algorithm can be employed to get a faster quantum algorithm for\nClosestPair in a moderate number of dimensions.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 16:22:06 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Ghazi", "Badih", ""], ["Kumar", "Ravi", ""], ["Manurangsi", "Pasin", ""]]}, {"id": "2008.08134", "submitter": "Martin Aum\\\"uller", "authors": "Martin Aum\\\"uller and Anders Bourgeat and Jana Schmurr", "title": "Differentially Private Sketches for Jaccard Similarity Estimation", "comments": "Accepted at SISAP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes two locally-differential private algorithms for\nreleasing user vectors such that the Jaccard similarity between these vectors\ncan be efficiently estimated. The basic building block is the well known\nMinHash method. To achieve a privacy-utility trade-off, MinHash is extended in\ntwo ways using variants of Generalized Randomized Response and the Laplace\nMechanism. A theoretical analysis provides bounds on the absolute error and\nexperiments show the utility-privacy trade-off on synthetic and real-world\ndata. The paper ends with a critical discussion of related work.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 19:42:46 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Aum\u00fcller", "Martin", ""], ["Bourgeat", "Anders", ""], ["Schmurr", "Jana", ""]]}, {"id": "2008.08138", "submitter": "Enes Altinisik", "authors": "Enes Altinisik, Kasim Tasdemir, Husrev Taha Sencar", "title": "PRNU Estimation from Encoded Videos Using Block-Based Weighting", "comments": null, "journal-ref": null, "doi": "10.2352/ISSN.2470-1173.2021.4.MWSF-338", "report-no": null, "categories": "eess.IV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the photo-response non-uniformity (PRNU) of an imaging sensor from\nvideos is a challenging task due to complications created by several processing\nsteps in the camera imaging pipeline. Among these steps, video coding is one of\nthe most disruptive to PRNU estimation because of its lossy nature. Since\nvideos are always stored in a compressed format, the ability to cope with the\ndisruptive effects of encoding is central to reliable attribution. In this\nwork, by focusing on the block-based operation of widely used video coding\nstandards, we present an improved approach to PRNU estimation that exploits\nthis behavior. To this purpose, several PRNU weighting schemes that utilize\nblock-level parameters, such as encoding block type, quantization strength, and\nrate-distortion value, are proposed and compared. Our results show that the use\nof the coding rate of a block serves as a better estimator for the strength of\nPRNU with almost three times improvement in the matching statistic at low to\nmedium coding bitrates as compared to the basic estimation method developed for\nphotos.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 19:56:56 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 06:48:40 GMT"}, {"version": "v3", "created": "Thu, 28 Jan 2021 20:30:09 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Altinisik", "Enes", ""], ["Tasdemir", "Kasim", ""], ["Sencar", "Husrev Taha", ""]]}, {"id": "2008.08161", "submitter": "Junhua Yan", "authors": "Junhua Yan, Hasan Faik Alan and Jasleen Kaur", "title": "Fingerprinting Search Keywords over HTTPS at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The possibility of fingerprinting the search keywords issued by a user on\npopular web search engines is a significant threat to user privacy. This threat\nhas received surprisingly little attention in the network traffic analysis\nliterature. In this work, we consider the problem of keyword fingerprinting of\nHTTPS traffic -- we study the impact of several factors, including client\nplatform diversity, choice of search engine, feature sets as well as\nclassification frameworks. We conduct both closed-world and open-world\nevaluations using nearly 4 million search queries collected over a period of\nthree months. Our analysis reveals several insights into the threat of keyword\nfingerprinting in modern HTTPS traffic.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 21:24:52 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Yan", "Junhua", ""], ["Alan", "Hasan Faik", ""], ["Kaur", "Jasleen", ""]]}, {"id": "2008.08166", "submitter": "Bharvee Acharya", "authors": "Chinwe Ekenna and Bharvee Acharya", "title": "Clustering and Analysis of Vulnerabilities Present in Different Robot\n  Types", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the new advancements in automation using Artificial Intelligence,\nRobotics and Internet of Things it has become crucial to pay attention to\npossible vulnerabilities in order to avoid cyber attack and hijacking that can\noccur which can be catastrophic. There have been many consequences of disasters\ndue to vulnerabilities in Robotics, these vulnerabilities need to be analyzed\nto target the severe ones before they cause cataclysm. This paper aims to\nhighlight the areas and severity of each type of vulnerability by analyzing\nissues categorized under the type of vulnerability. This we achieve by careful\nanalysis of the data and application of information retrieval techniques like\nTerm Frequency - Inverse Document Frequency, dimension reduction techniques\nlike Principal Component Analysis and Clustering using Machine Learning\ntechniques like K-means. By performing this analysis, the severity of robotic\nissues in different domains and the severity of the issue based on type of\nissue is detected.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 21:59:57 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Ekenna", "Chinwe", ""], ["Acharya", "Bharvee", ""]]}, {"id": "2008.08184", "submitter": "Wensheng Gan", "authors": "Muchuang Hu, Jiahui Chen, Wensheng Gan, and Chien-Ming Chen", "title": "A Jumping Mining Attack and Solution", "comments": "Applied Intelligence, 6 figures", "journal-ref": "Applied Intelligence, 2021", "doi": "10.1007/s10489-020-01866-2", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining is the important part of the blockchain used the proof of work (PoW)\non its consensus, looking for the matching block through testing a number of\nhash calculations. In order to attract more hash computing power, the miner who\nfinds the proper block can obtain some rewards. Actually, these hash\ncalculations ensure that the data of the blockchain is not easily tampered.\nThus, the incentive mechanism for mining affects the security of the blockchain\ndirectly. This paper presents an approach to attack against the difficulty\nadjustment algorithm (abbreviated as DAA) used in blockchain mining, which has\na direct impact on miners' earnings. In this method, the attack miner jumps\nbetween different blockchains to get more benefits than the honest miner who\nkeep mining on only one blockchain. We build a probabilistic model to simulate\nthe time to obtain the next block at different hash computing power called\nhashrate. Based on this model, we analyze the DAAs of the major\ncryptocurrencies, including Bitcoin, Bitcoin Cash, Zcash, and Bitcoin Gold. We\nfurther verify the effectiveness of this attack called jumping mining through\nsimulation experiments, and also get the characters for the attack in the\npublic block data of Bitcoin Gold. Finally, we give an improved DAA scheme\nagainst this attack. Extensive experiments are provided to support the\nefficiency of our designed scheme.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 23:07:53 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Hu", "Muchuang", ""], ["Chen", "Jiahui", ""], ["Gan", "Wensheng", ""], ["Chen", "Chien-Ming", ""]]}, {"id": "2008.08208", "submitter": "Dongfang Zhao", "authors": "Dongfang Zhao", "title": "An Algebraic-Topological Approach to Processing Cross-Blockchain\n  Transactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-the-art techniques for processing cross-blockchain transactions\ntake a simple centralized approach: when the assets on blockchain $X$, say\n$X$-coins, are exchanged with the assets on blockchain $Y$---the $Y$-coins,\nthose $X$-coins need to be exchanged to a \"middle\" medium (such as Bitcoin)\nthat is then exchanged to $Y$-coins. If there are more than two parties\ninvolved in a single global transaction, the global transaction is split into\nmultiple local two-party transactions, each of which follows the above\ncentral-exchange protocol. Unfortunately, the atomicity of the global\ntransaction is violated with the central-exchange approach: those local\ntwo-party transactions, once committed, cannot be rolled back if the global\ntransaction decides to abort. In a more general sense, the graph-based model of\n(two-party) transactions can hardly be extended to an arbitrary number of\nparties in a cross-blockchain transaction. %from why to how In this paper, we\nintroduce a higher-level abstraction of cross-blockchain transactions. We adopt\nthe \\textit{abstract simplicial complex}, an extensively-studied mathematical\nobject in algebraic topology, to represent an arbitrary number of parties\ninvolved in the blockchain transactions. Essentially, each party in the global\ntransaction is modeled as a vertex and the global transaction among $n+1$ ($n\n\\in \\mathbb{Z}$, $n > 0$) parties compose a $n$-dimensional simplex. While this\nhigher-level abstraction seems plausibly trivial, we will show how this simple\nextension leads to a new line of modeling methods and protocols for better\nprocessing cross-blockchain transactions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 00:38:31 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Zhao", "Dongfang", ""]]}, {"id": "2008.08330", "submitter": "Junjie Tan", "authors": "Junjie Tan, Ying-Chang Liang, Nguyen Cong Luong, Dusit Niyato", "title": "Toward Smart Security Enhancement of Federated Learning Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As traditional centralized learning networks (CLNs) are facing increasing\nchallenges in terms of privacy preservation, communication overheads, and\nscalability, federated learning networks (FLNs) have been proposed as a\npromising alternative paradigm to support the training of machine learning (ML)\nmodels. In contrast to the centralized data storage and processing in CLNs,\nFLNs exploit a number of edge devices (EDs) to store data and perform training\ndistributively. In this way, the EDs in FLNs can keep training data locally,\nwhich preserves privacy and reduces communication overheads. However, since the\nmodel training within FLNs relies on the contribution of all EDs, the training\nprocess can be disrupted if some of the EDs upload incorrect or falsified\ntraining results, i.e., poisoning attacks. In this paper, we review the\nvulnerabilities of FLNs, and particularly give an overview of poisoning attacks\nand mainstream countermeasures. Nevertheless, the existing countermeasures can\nonly provide passive protection and fail to consider the training fees paid for\nthe contributions of the EDs, resulting in a unnecessarily high training cost.\nHence, we present a smart security enhancement framework for FLNs. In\nparticular, a verify-before-aggregate (VBA) procedure is developed to identify\nand remove the non-benign training results from the EDs. Afterward, deep\nreinforcement learning (DRL) is applied to learn the behaving patterns of the\nEDs and to actively select the EDs that can provide benign training results and\ncharge low training fees. Simulation results reveal that the proposed framework\ncan protect FLNs effectively and efficiently.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 08:46:39 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Tan", "Junjie", ""], ["Liang", "Ying-Chang", ""], ["Luong", "Nguyen Cong", ""], ["Niyato", "Dusit", ""]]}, {"id": "2008.08339", "submitter": "Wazen Shbair", "authors": "Wazen M. Shbair, Thibault Cholez, Jerome Francois, Isabelle Chrisment", "title": "A Survey of HTTPS Traffic and Services Identification Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HTTPS is quickly rising alongside the need of Internet users to benefit from\nsecurity and privacy when accessing the Web, and it becomes the predominant\napplication protocol on the Internet. This migration towards a secure Web using\nHTTPS comes with important challenges related to the management of HTTPS\ntraffic to guarantee basic network properties such as security, QoS,\nreliability, etc. But encryption undermines the effectiveness of standard\nmonitoring techniques and makes it difficult for ISPs and network\nadministrators to properly identify and manage the services behind HTTPS\ntraffic. This survey details the techniques used to monitor HTTPS traffic, from\nthe most basic level of protocol identification (TLS, HTTPS), to the finest\nidentification of precise services. We show that protocol identification is\nwell mastered while more precise levels keep being challenging despite recent\nadvances. We also describe practical solutions that lead us to discuss the\ntrade-off between security and privacy and the research directions to guarantee\nboth of them.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 09:04:15 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Shbair", "Wazen M.", ""], ["Cholez", "Thibault", ""], ["Francois", "Jerome", ""], ["Chrisment", "Isabelle", ""]]}, {"id": "2008.08350", "submitter": "Wazen Shbair", "authors": "Wazen M. Shbair, Thibault Cholez, Jerome Francois, Isabelle Chrisment", "title": "Early Identification of Services in HTTPS Traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic monitoring is essential for network management tasks that ensure\nsecurity and QoS. However, the continuous increase of HTTPS traffic undermines\nthe effectiveness of current service-level monitoring that can only rely on\nunreliable parameters from the TLS handshake (X.509 certificate, SNI) or must\ndecrypt the traffic. We propose a new machine learning-based method to identify\nHTTPS services without decryption. By extracting statistical features on TLS\nhandshake packets and on a small number of application data packets, we can\nidentify HTTPS services very early in the session. Extensive experiments\nperformed over a significant and open dataset show that our method offers a\ngood accuracy and a prototype implementation confirms that the early\nidentification of HTTPS services is satisfied.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 09:37:53 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Shbair", "Wazen M.", ""], ["Cholez", "Thibault", ""], ["Francois", "Jerome", ""], ["Chrisment", "Isabelle", ""]]}, {"id": "2008.08409", "submitter": "Xinhui Lai", "authors": "Xinhui Lai, Maksim Jenihhin, Georgios Selimis, Sven Goossens, Roel\n  Maes, Kolin Paul", "title": "Early RTL Analysis for SCA Vulnerability in Fuzzy Extractors of\n  Memory-Based PUF Enabled Devices", "comments": "6 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical Unclonable Functions (PUFs) are gaining attention in the\ncryptography community because of the ability to efficiently harness the\nintrinsic variability in the manufacturing process. However, this means that\nthey are noisy devices and require error correction mechanisms, e.g., by\nemploying Fuzzy Extractors (FEs). Recent works demonstrated that applying FEs\nfor error correction may enable new opportunities to break the PUFs if no\ncountermeasures are taken. In this paper, we address an attack model on FEs\nhardware implementations and provide a solution for early identification of the\ntiming Side-Channel Attack (SCA) vulnerabilities which can be exploited by\nphysical fault injection. The significance of this work stems from the fact\nthat FEs are an essential building block in the implementations of PUF-enabled\ndevices. The information leaked through the timing side-channel during the\nerror correction process can reveal the FE input data and thereby can endanger\nrevealing secrets. Therefore, it is very important to identify the potential\nleakages early in the process during RTL design. Experimental results based on\nRTL analysis of several Bose-Chaudhuri-Hocquenghem (BCH) and Reed-Solomon\ndecoders for PUF-enabled devices with FEs demonstrate the feasibility of the\nproposed methodology.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 12:59:12 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Lai", "Xinhui", ""], ["Jenihhin", "Maksim", ""], ["Selimis", "Georgios", ""], ["Goossens", "Sven", ""], ["Maes", "Roel", ""], ["Paul", "Kolin", ""]]}, {"id": "2008.08444", "submitter": "Scott Stoller", "authors": "Thang Bui and Scott D. Stoller", "title": "Learning Attribute-Based and Relationship-Based Access Control Policies\n  with Unknown Values", "comments": "arXiv admin note: text overlap with arXiv:1909.12095", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribute-Based Access Control (ABAC) and Relationship-based access control\n(ReBAC) provide a high level of expressiveness and flexibility that promote\nsecurity and information sharing, by allowing policies to be expressed in terms\nof attributes of and chains of relationships between entities. Algorithms for\nlearning ABAC and ReBAC policies from legacy access control information have\nthe potential to significantly reduce the cost of migration to ABAC or ReBAC.\n  This paper presents the first algorithms for mining ABAC and ReBAC policies\nfrom access control lists (ACLs) and incomplete information about entities,\nwhere the values of some attributes of some entities are unknown. We show that\nthe core of this problem can be viewed as learning a concise three-valued logic\nformula from a set of labeled feature vectors containing unknowns, and we give\nthe first algorithm (to the best of our knowledge) for that problem.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 13:56:29 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 14:59:55 GMT"}, {"version": "v3", "created": "Wed, 26 Aug 2020 19:27:26 GMT"}, {"version": "v4", "created": "Mon, 23 Nov 2020 18:45:06 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Bui", "Thang", ""], ["Stoller", "Scott D.", ""]]}, {"id": "2008.08536", "submitter": "Damjan Vukcevic", "authors": "Zhuoqun Huang, Ronald L. Rivest, Philip B. Stark, Vanessa Teague,\n  Damjan Vukcevic", "title": "A Unified Evaluation of Two-Candidate Ballot-Polling Election Auditing\n  Methods", "comments": "27 pages. This version includes substantially expanded appendices and\n  several corrections to the main text", "journal-ref": "Electronic Voting, E-Vote-ID 2020, Lecture Notes in Computer\n  Science 12455 (2020) 112-128", "doi": "10.1007/978-3-030-60347-2_8", "report-no": null, "categories": "stat.AP cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counting votes is complex and error-prone. Several statistical methods have\nbeen developed to assess election accuracy by manually inspecting randomly\nselected physical ballots. Two 'principled' methods are risk-limiting audits\n(RLAs) and Bayesian audits (BAs). RLAs use frequentist statistical inference\nwhile BAs are based on Bayesian inference. Until recently, the two have been\nthought of as fundamentally different.\n  We present results that unify and shed light upon 'ballot-polling' RLAs and\nBAs (which only require the ability to sample uniformly at random from all cast\nballot cards) for two-candidate plurality contests, which are building blocks\nfor auditing more complex social choice functions, including some preferential\nvoting systems. We highlight the connections between the methods and explore\ntheir performance.\n  First, building on a previous demonstration of the mathematical equivalence\nof classical and Bayesian approaches, we show that BAs, suitably calibrated,\nare risk-limiting. Second, we compare the efficiency of the methods across a\nwide range of contest sizes and margins, focusing on the distribution of sample\nsizes required to attain a given risk limit. Third, we outline several ways to\nimprove performance and show how the mathematical equivalence explains the\nimprovements.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 16:30:03 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 04:37:16 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Huang", "Zhuoqun", ""], ["Rivest", "Ronald L.", ""], ["Stark", "Philip B.", ""], ["Teague", "Vanessa", ""], ["Vukcevic", "Damjan", ""]]}, {"id": "2008.08672", "submitter": "Mohammad Sayad Haghighi", "authors": "Mohammad Sayad Haghighi, Orwa Nader, Alireza Jolfaei", "title": "A Computationally Intelligent Hierarchical Authentication and Key\n  Establishment Framework for Internet of Things", "comments": "This paper is to appear in IEEE Internet of Things Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our high expectations from Internet of Things (IoT) and how it will\npositively influence our lifestyles depend on a secure and trusted\nimplementation of it, especially in the sensitive sectors such as health or\nfinancial. IoT platforms and solutions must provide Confidentiality, Integrity\nand Availability (CIA) in a secure and transparent way. Due to the extremely\nlarge scales of IoT, traditional centralized solutions for security\nprovisioning cannot be employed in their original form. This article discusses\nthe authentication problem in IoT, which is fundamental to providing CIA. We\npropose a hierarchical security architecture for this problem and focus on\ncomputationally lightweight authentication protocols which can intelligently\ndistribute the computational load across multiple levels and effectively push\nthe load towards upper layers.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 21:19:46 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Haghighi", "Mohammad Sayad", ""], ["Nader", "Orwa", ""], ["Jolfaei", "Alireza", ""]]}, {"id": "2008.08692", "submitter": "Yingtong Dou", "authors": "Yingtong Dou, Zhiwei Liu, Li Sun, Yutong Deng, Hao Peng, Philip S. Yu", "title": "Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged\n  Fraudsters", "comments": "Accepted by CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3411903", "report-no": null, "categories": "cs.SI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have been widely applied to fraud detection\nproblems in recent years, revealing the suspiciousness of nodes by aggregating\ntheir neighborhood information via different relations. However, few prior\nworks have noticed the camouflage behavior of fraudsters, which could hamper\nthe performance of GNN-based fraud detectors during the aggregation process. In\nthis paper, we introduce two types of camouflages based on recent empirical\nstudies, i.e., the feature camouflage and the relation camouflage. Existing\nGNNs have not addressed these two camouflages, which results in their poor\nperformance in fraud detection problems. Alternatively, we propose a new model\nnamed CAmouflage-REsistant GNN (CARE-GNN), to enhance the GNN aggregation\nprocess with three unique modules against camouflages. Concretely, we first\ndevise a label-aware similarity measure to find informative neighboring nodes.\nThen, we leverage reinforcement learning (RL) to find the optimal amounts of\nneighbors to be selected. Finally, the selected neighbors across different\nrelations are aggregated together. Comprehensive experiments on two real-world\nfraud datasets demonstrate the effectiveness of the RL algorithm. The proposed\nCARE-GNN also outperforms state-of-the-art GNNs and GNN-based fraud detectors.\nWe integrate all GNN-based fraud detectors as an opensource toolbox:\nhttps://github.com/safe-graph/DGFraud. The CARE-GNN code and datasets are\navailable at https://github.com/YingtongDou/CARE-GNN.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 22:33:12 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Dou", "Yingtong", ""], ["Liu", "Zhiwei", ""], ["Sun", "Li", ""], ["Deng", "Yutong", ""], ["Peng", "Hao", ""], ["Yu", "Philip S.", ""]]}, {"id": "2008.08753", "submitter": "Chaochao Chen", "authors": "Chaochao Chen, Jun Zhou, Li Wang, Xibin Wu, Wenjing Fang, Jin Tan, Lei\n  Wang, Alex X. Liu, Hao Wang, Cheng Hong", "title": "When Homomorphic Encryption Marries Secret Sharing: Secure Large-Scale\n  Sparse Logistic Regression and Applications in Risk Control", "comments": "Accepted by KDD'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logistic Regression (LR) is the most widely used machine learning model in\nindustry for its efficiency, robustness, and interpretability. Due to the\nproblem of data isolation and the requirement of high model performance, many\napplications in industry call for building a secure and efficient LR model for\nmultiple parties. Most existing work uses either Homomorphic Encryption (HE) or\nSecret Sharing (SS) to build secure LR. HE based methods can deal with\nhigh-dimensional sparse features, but they incur potential security risks. SS\nbased methods have provable security, but they have efficiency issue under\nhigh-dimensional sparse features. In this paper, we first present CAESAR, which\ncombines HE and SS to build secure large-scale sparse logistic regression model\nand achieves both efficiency and security. We then present the distributed\nimplementation of CAESAR for scalability requirement. We have deployed CAESAR\nin a risk control task and conducted comprehensive experiments. Our\nexperimental results show that CAESAR improves the state-of-the-art model by\naround 130 times.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 03:26:51 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 08:50:25 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Chen", "Chaochao", ""], ["Zhou", "Jun", ""], ["Wang", "Li", ""], ["Wu", "Xibin", ""], ["Fang", "Wenjing", ""], ["Tan", "Jin", ""], ["Wang", "Lei", ""], ["Liu", "Alex X.", ""], ["Wang", "Hao", ""], ["Hong", "Cheng", ""]]}, {"id": "2008.08807", "submitter": "Benjamin Zi Hao Zhao", "authors": "Benjamin Zi Hao Zhao, Mohamed Ali Kaafar, Nicolas Kourtellis", "title": "Not one but many Tradeoffs: Privacy Vs. Utility in Differentially\n  Private Machine Learning", "comments": "12 pages, Accepted at CCSW'20, an ACM CCS Workshop", "journal-ref": null, "doi": "10.1145/3411495.3421352", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data holders are increasingly seeking to protect their user's privacy, whilst\nstill maximizing their ability to produce machine models with high quality\npredictions. In this work, we empirically evaluate various implementations of\ndifferential privacy (DP), and measure their ability to fend off real-world\nprivacy attacks, in addition to measuring their core goal of providing accurate\nclassifications. We establish an evaluation framework to ensure each of these\nimplementations are fairly evaluated. Our selection of DP implementations add\nDP noise at different positions within the framework, either at the point of\ndata collection/release, during updates while training of the model, or after\ntraining by perturbing learned model parameters. We evaluate each\nimplementation across a range of privacy budgets, and datasets, each\nimplementation providing the same mathematical privacy guarantees. By measuring\nthe models' resistance to real world attacks of membership and attribute\ninference, and their classification accuracy. we determine which\nimplementations provide the most desirable tradeoff between privacy and\nutility. We found that the number of classes of a given dataset is unlikely to\ninfluence where the privacy and utility tradeoff occurs. Additionally, in the\nscenario that high privacy constraints are required, perturbing input training\ndata does not trade off as much utility, as compared to noise added later in\nthe ML process.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 07:06:28 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 06:39:39 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Zhao", "Benjamin Zi Hao", ""], ["Kaafar", "Mohamed Ali", ""], ["Kourtellis", "Nicolas", ""]]}, {"id": "2008.08936", "submitter": "Vinh Thong Ta", "authors": "Vinh Thong Ta", "title": "DataProVe: A Data Protection Policy and System Architecture Verification\n  Tool", "comments": "65 pages. Improved algorithm description and explanation. Semantics\n  of policy language added. More complete list of properties, and inference\n  rules added. More figures and discussion section added. Finally, we refer to\n  this version in our (shorter) paper under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a tool, called DataProVe, for specifying high-level\ndata protection policies and system architectures, as well as verifying the\nconformance between them in a fully automated way. The syntax of the policies\nand the architectures is based on semi-formal languages, and the automated\nverification engine relies on logic and resolution based proofs. The\nfunctionality and operation of the tool are presented using different examples.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 12:38:24 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 16:44:57 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 15:57:22 GMT"}, {"version": "v4", "created": "Thu, 17 Dec 2020 07:51:05 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Ta", "Vinh Thong", ""]]}, {"id": "2008.08973", "submitter": "Evita Bakopoulou", "authors": "Evita Bakopoulou, Anastasia Shuba, Athina Markopoulou", "title": "Exposures Exposed: A Measurement and User Study to Assess Mobile Data\n  Privacy in Context", "comments": "arXiv admin note: text overlap with arXiv:1803.01261", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile devices have access to personal, potentially sensitive data, and there\nis a large number of mobile applications and third-party libraries that\ntransmit this information over the network to remote servers (including app\ndeveloper servers and third party servers). In this paper, we are interested in\nbetter understanding of not just the extent of personally identifiable\ninformation (PII) exposure, but also its context i.e., functionality of the\napp, destination server, encryption used, etc.) and the risk perceived by\nmobile users today. To that end we take two steps. First, we perform a\nmeasurement study: we collect a new dataset via manual and automatic testing\nand capture the exposure of 16 PII types from 400 most popular Android apps. We\nanalyze these exposures and provide insights into the extent and patterns of\nmobile apps sharing PII, which can be later used for prediction and prevention.\nSecond, we perform a user study with 220 participants on Amazon Mechanical\nTurk: we summarize the results of the measurement study in categories, present\nthem in a realistic context, and assess users' understanding, concern, and\nwillingness to take action. To the best of our knowledge, our user study is the\nfirst to collect and analyze user input in such fine granularity and on actual\n(not just potential or permitted) privacy exposures on mobile devices. Although\nmany users did not initially understand the full implications of their PII\nbeing exposed, after being better informed through the study, they became\nappreciative and interested in better privacy practices.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 02:42:30 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Bakopoulou", "Evita", ""], ["Shuba", "Anastasia", ""], ["Markopoulou", "Athina", ""]]}, {"id": "2008.09192", "submitter": "Craig Laprade", "authors": "Craig Laprade, Benjamin Bowman, H. Howie Huang", "title": "PicoDomain: A Compact High-Fidelity Cybersecurity Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Analysis of cyber relevant data has become an area of increasing focus. As\nlarger percentages of businesses and governments begin to understand the\nimplications of cyberattacks, the impetus for better cybersecurity solutions\nhas increased. Unfortunately, current cybersecurity datasets either offer no\nground truth or do so with anonymized data. The former leads to a quandary when\nverifying results and the latter can remove valuable information. Additionally,\nmost existing datasets are large enough to make them unwieldy during prototype\ndevelopment. In this paper we have developed the PicoDomain dataset, a compact\nhigh-fidelity collection of Zeek logs from a realistic intrusion using relevant\nTools, Techniques, and Procedures. While simulated on a small-scale network,\nthis dataset consists of traffic typical of an enterprise network, which can be\nutilized for rapid validation and iterative development of analytics platforms.\nWe have validated this dataset using traditional statistical analysis and\noff-the-shelf Machine Learning techniques.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 20:18:04 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Laprade", "Craig", ""], ["Bowman", "Benjamin", ""], ["Huang", "H. Howie", ""]]}, {"id": "2008.09194", "submitter": "Baiwu Zhang", "authors": "Baiwu Zhang, Jin Peng Zhou, Ilia Shumailov, Nicolas Papernot", "title": "On Attribution of Deepfakes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress in generative modelling, especially generative adversarial networks,\nhave made it possible to efficiently synthesize and alter media at scale.\nMalicious individuals now rely on these machine-generated media, or deepfakes,\nto manipulate social discourse. In order to ensure media authenticity, existing\nresearch is focused on deepfake detection. Yet, the adversarial nature of\nframeworks used for generative modeling suggests that progress towards\ndetecting deepfakes will enable more realistic deepfake generation. Therefore,\nit comes at no surprise that developers of generative models are under the\nscrutiny of stakeholders dealing with misinformation campaigns. At the same\ntime, generative models have a lot of positive applications. As such, there is\na clear need to develop tools that ensure the transparent use of generative\nmodeling, while minimizing the harm caused by malicious applications.\n  Our technique optimizes over the source of entropy of each generative model\nto probabilistically attribute a deepfake to one of the models. We evaluate our\nmethod on the seminal example of face synthesis, demonstrating that our\napproach achieves 97.62% attribution accuracy, and is less sensitive to\nperturbations and adversarial examples. We discuss the ethical implications of\nour work, identify where our technique can be used, and highlight that a more\nmeaningful legislative framework is required for a more transparent and ethical\nuse of generative modeling. Finally, we argue that model developers should be\ncapable of claiming plausible deniability and propose a second framework to do\nso -- this allows a model developer to produce evidence that they did not\nproduce media that they are being accused of having produced.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 20:25:18 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 21:41:33 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Zhang", "Baiwu", ""], ["Zhou", "Jin Peng", ""], ["Shumailov", "Ilia", ""], ["Papernot", "Nicolas", ""]]}, {"id": "2008.09268", "submitter": "Meihui Zhang", "authors": "Meihui Zhang, Zhongle Xie, Cong Yue, Ziyue Zhong", "title": "Spitz: A Verifiable Database System", "comments": null, "journal-ref": null, "doi": "10.14778/3415478.3415567", "report-no": null, "categories": "cs.DB cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Databases in the past have helped businesses maintain and extract insights\nfrom their data. Today, it is common for a business to involve multiple\nindependent, distrustful parties. This trend towards decentralization\nintroduces a new and important requirement to databases: the integrity of the\ndata, the history, and the execution must be protected. In other words, there\nis a need for a new class of database systems whose integrity can be verified\n(or verifiable databases).\n  In this paper, we identify the requirements and the design challenges of\nverifiable databases.We observe that the main challenges come from the need to\nbalance data immutability, tamper evidence, and performance. We first consider\napproaches that extend existing OLTP and OLAP systems with support for\nverification. We next examine a clean-slate approach, by describing a new\nsystem, Spitz, specifically designed for efficiently supporting immutable and\ntamper-evident transaction management. We conduct a preliminary performance\nstudy of both approaches against a baseline system, and provide insights on\ntheir performance.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 02:16:12 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Zhang", "Meihui", ""], ["Xie", "Zhongle", ""], ["Yue", "Cong", ""], ["Zhong", "Ziyue", ""]]}, {"id": "2008.09275", "submitter": "Gilles Brassard", "authors": "Alexandre Bibeau-Delisle and Gilles Brassard", "title": "Probability and consequences of living inside a computer simulation", "comments": "17 pages, 2 figures, 1 table", "journal-ref": "Proceedings of the Royal Society A, Vol. 477, no. 2247, March 2021", "doi": "10.1098/rspa.2020.0658", "report-no": null, "categories": "physics.pop-ph cs.CR cs.CY quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown that under reasonable assumptions a Drake-style equation can be\nobtained for the probability that our universe is the result of a deliberate\nsimulation. Evaluating loose bounds for certain terms in the equation shows\nthat the probability is unlikely to be as high as previously reported in the\nliterature, especially in a scenario where the simulations are recursive.\nFurthermore, we investigate the possibility of eavesdropping from the outside\nof such a simulation and introduce a general attack that can circumvent\nattempts at quantum cryptography inside the simulation, even if the quantum\nproperties of the simulation are genuine.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 02:41:33 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Bibeau-Delisle", "Alexandre", ""], ["Brassard", "Gilles", ""]]}, {"id": "2008.09317", "submitter": "Aayush Jain", "authors": "Aayush Jain and Huijia Lin and Amit Sahai", "title": "Indistinguishability Obfuscation from Well-Founded Assumptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we show how to construct indistinguishability obfuscation from\nsubexponential hardness of four well-founded assumptions. We prove:\n  Let $\\tau \\in (0,\\infty), \\delta \\in (0,1), \\epsilon \\in (0,1)$ be arbitrary\nconstants. Assume sub-exponential security of the following assumptions, where\n$\\lambda$ is a security parameter, and the parameters $\\ell,k,n$ below are\nlarge enough polynomials in $\\lambda$:\n  - The SXDH assumption on asymmetric bilinear groups of a prime order $p =\nO(2^\\lambda)$,\n  - The LWE assumption over $\\mathbb{Z}_{p}$ with subexponential\nmodulus-to-noise ratio $2^{k^\\epsilon}$, where $k$ is the dimension of the LWE\nsecret,\n  - The LPN assumption over $\\mathbb{Z}_p$ with polynomially many LPN samples\nand error rate $1/\\ell^\\delta$, where $\\ell$ is the dimension of the LPN\nsecret,\n  - The existence of a Boolean PRG in $\\mathsf{NC}^0$ with stretch\n$n^{1+\\tau}$,\n  Then, (subexponentially secure) indistinguishability obfuscation for all\npolynomial-size circuits exists.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 05:34:30 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Jain", "Aayush", ""], ["Lin", "Huijia", ""], ["Sahai", "Amit", ""]]}, {"id": "2008.09339", "submitter": "Ayyoob Hamza", "authors": "Ayyoob Hamza, Hassan Habibi Gharakheili, Vijay Sivaraman", "title": "IoT Network Security: Requirements, Threats, and Countermeasures", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IoT devices are increasingly utilized in critical infrastructure,\nenterprises, and households. There are several sophisticated cyber-attacks that\nhave been reported and many networks have proven vulnerable to both active and\npassive attacks by leaking private information, allowing unauthorized access,\nand being open to denial of service attacks.\n  This paper aims firstly, to assist network operators to understand the need\nfor an IoT network security solution, and then secondly, to survey IoT network\nattack vectors, cyber threats, and countermeasures with a focus on improving\nthe robustness of existing security solutions. Our first contribution\nhighlights viewpoints on IoT security from the perspective of stakeholders such\nas manufacturers, service providers, consumers, and authorities. We discuss the\ndifferences between IoT and IT systems, the need for IoT security solutions,\nand we highlight the key components required for IoT network security system\narchitecture. For our second contribution, we survey the types of IoT attacks\nby grouping them based on their impact. We discuss various attack techniques,\nthreats, and shortfalls of existing countermeasures with an intention to enable\nfuture research into improving IoT network security.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 07:19:32 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Hamza", "Ayyoob", ""], ["Gharakheili", "Hassan Habibi", ""], ["Sivaraman", "Vijay", ""]]}, {"id": "2008.09351", "submitter": "Bo-Rong Chen", "authors": "Bo-Rong Chen, Yih-Chun Hu", "title": "BlindSignedID: Mitigating Denial-of-Service Attacks on Digital Contact\n  Tracing", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": "10.1145/3384419.3430599", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the recent outbreak of COVID-19, many governments suspended outdoor\nactivities and imposed social distancing policies to prevent the transmission\nof SARS-CoV-2. These measures have had severe impact on the economy and\npeoples' daily lives. An alternative to widespread lockdowns is effective\ncontact tracing during an outbreak's early stage. However, mathematical models\nsuggest that epidemic control for SARS-CoV-2 transmission with manual contact\ntracing is implausible. To reduce the effort of contact tracing, many digital\ncontact tracing projects (e.g., PEPP-PT, DP-3T, TCN, BlueTrace, Google/Apple\nExposure Notification, and East/West Coast PACT) are being developed to\nsupplement manual contact tracing. However, digital contact tracing has drawn\nscrutiny from privacy advocates, since governments or other parties may attempt\nto use contact tracing protocols for mass surveillance. As a result, many\ndigital contact tracing projects build privacy-preserving mechanisms to limit\nthe amount of privacy-sensitive information leaked by the protocol. In this\npaper, we examine how these architectures resist certain classes of attacks,\nspecifically DoS attacks, and present BlindSignedIDs, a privacy-preserving\ndigital contact tracing mechanism, which are verifiable ephemeral identifiers\nto limit the effectiveness of MAC-compliant DoS attacks. In our evaluations, we\nshowed BlindSignedID can effectively deny bogus EphIDs, mitigating DoS attacks\non the local storage beyond 90% of stored EphIDs. Our example DoS attacks\nshowed that using 4 attackers can cause the gigabyte level DoS attacks within\nnormal working hours and days.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 07:51:57 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 07:14:02 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Chen", "Bo-Rong", ""], ["Hu", "Yih-Chun", ""]]}, {"id": "2008.09501", "submitter": "Guoxing Chen", "authors": "Guoxing Chen and Yinqian Zhang", "title": "MAGE: Mutual Attestation for a Group of Enclaves without Trusted Third\n  Parties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intel Software Guard Extensions (SGX) local and remote attestation mechanisms\nenable an enclave to attest its identity (i.e., the enclave measurement, which\nis the cryptographic hash of its initial code and data) to an enclave. To\nverify that the attested identity is trusted, one enclave usually includes the\nmeasurement of the enclave it trusts into its initial data in advance assuming\nno trusted third parties are available during runtime to provide this piece of\ninformation. However, when mutual trust between these two enclaves is required,\nit is infeasible to simultaneously include into their own initial data the\nother's measurements respectively as any change to the initial data will change\ntheir measurements, making the previously included measurements invalid. In\nthis paper, we propose MAGE, a framework enabling a group of enclaves to\nmutually attest each other without trusted third parties. Particularly, we\nintroduce a technique to instrument these enclaves so that each of them could\nderive the others' measurements using information solely from its own initial\ndata. We also provide a prototype implementation based on Intel SGX SDK, to\nfacilitate enclave developers to adopt this technique.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 14:29:31 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Chen", "Guoxing", ""], ["Zhang", "Yinqian", ""]]}, {"id": "2008.09518", "submitter": "H\\'ector Eduardo Ugarte Rojas", "authors": "Ugarte-Rojas Hector, Chullo-Llave Boris", "title": "BLONDiE: Blockchain Ontology with Dynamic Extensibility", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are thousands of projects worldwide based primarily on blockchain\ntechnology. These have a large number of users and hundreds of use cases. One\nof the most popular is the use of cryptocurrencies and their benefits against\nmoney without intrinsic value (fiat money) and centralized financial solutions.\nHowever, although thousands of new transactions are carried out daily in\ndifferent platforms, uniform and standardized information does not exist to be\nable to manage the large amount of data that is generated and exchanged between\nusers through transactions and the generation of new blocks. This research\nreports the development of BLONDiE, an ontology that allows the semantic\nrepresentation of knowledge to describe the native structure and related\ninformation of the three most relevant blockchain projects to date: Bitcoin,\nEthereum and in the recent 1.0 version extends its definitions to include\nHyperledger, specifically the Hyperledger Fabric infrastructure. Its use allows\nhaving common data formats of different platforms for further processing, such\nas the execution of semantic queries.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 14:43:43 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Hector", "Ugarte-Rojas", ""], ["Boris", "Chullo-Llave", ""]]}, {"id": "2008.09608", "submitter": "Anisa Halimi", "authors": "Anisa Halimi and Erman Ayday", "title": "Profile Matching Across Online Social Networks", "comments": "arXiv admin note: substantial text overlap with arXiv:1711.01815", "journal-ref": "Proceedings of the 22nd International Conference on Information\n  and Communications Security (ICICS 2020)", "doi": null, "report-no": null, "categories": "cs.SI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the privacy risk due to profile matching across online\nsocial networks (OSNs), in which anonymous profiles of OSN users are matched to\ntheir real identities using auxiliary information about them. We consider\ndifferent attributes that are publicly shared by users. Such attributes include\nboth strong identifiers such as user name and weak identifiers such as interest\nor sentiment variation between different posts of a user in different\nplatforms. We study the effect of using different combinations of these\nattributes to profile matching in order to show the privacy threat in an\nextensive way. The proposed framework mainly relies on machine learning\ntechniques and optimization algorithms. We evaluate the proposed framework on\nthree datasets (Twitter - Foursquare, Google+ - Twitter, and Flickr) and show\nhow profiles of the users in different OSNs can be matched with high\nprobability by using the publicly shared attributes and/or the underlying\ngraphical structure of the OSNs. We also show that the proposed framework\nnotably provides higher precision values compared to state-of-the-art that\nrelies on machine learning techniques. We believe that this work will be a\nvaluable step to build a tool for the OSN users to understand their privacy\nrisks due to their public sharings.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 02:48:45 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Halimi", "Anisa", ""], ["Ayday", "Erman", ""]]}, {"id": "2008.09702", "submitter": "Rafael Gregorio Lucas D'Oliveira", "authors": "Rafael G. L. D'Oliveira, Salman Salamatian, Muriel M\\'edard, Parastoo\n  Sadeghi", "title": "Low Influence, Utility, and Independence in Differential Privacy: A\n  Curious Case of $3 \\choose 2$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the relationship between randomized low influence functions and\ndifferentially private mechanisms. Our main aim is to formally determine\nwhether differentially private mechanisms are low influence and whether low\ninfluence randomized functions can be differentially private. We show that\ndifferential privacy does not necessarily imply low influence in a formal\nsense. However, low influence implies approximate differential privacy. These\nresults hold for both independent and non-independent randomized mechanisms,\nwhere an important instance of the former is the widely-used additive noise\ntechniques in the differential privacy literature. Our study also reveals the\ninteresting dynamics between utility, low influence, and independence of a\ndifferentially private mechanism. As the name of this paper suggests, we show\nthat any two such features are simultaneously possible. However, in order to\nhave a differentially private mechanism that has both utility and low\ninfluence, even under a very mild utility condition, one has to employ\nnon-independent mechanisms.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 22:23:32 GMT"}, {"version": "v2", "created": "Sun, 7 Feb 2021 23:40:42 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["D'Oliveira", "Rafael G. L.", ""], ["Salamatian", "Salman", ""], ["M\u00e9dard", "Muriel", ""], ["Sadeghi", "Parastoo", ""]]}, {"id": "2008.09710", "submitter": "Marc Schink", "authors": "Johannes Obermaier and Marc Schink and Kosma Moczek", "title": "One Exploit to Rule them All? On the Security of Drop-in Replacement and\n  Counterfeit Microcontrollers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing complexity of embedded systems, the firmware has become a\nvaluable asset. At the same time, pressure for cost reductions in hardware is\nimminent. These two aspects are united at the heart of the system, i.e., the\nmicrocontroller. It runs and protects its firmware, but simultaneously has to\nprevail against cheaper alternatives. For the very popular STM32F1\nmicrocontroller series, this has caused the emergence of many competitors in\nthe last few years who offer drop-in replacements or even sell counterfeit\ndevices at a fraction of the original price. Thus, the question emerges whether\nthe replacements are silicon-level clones and, if not, whether they provide\nbetter, equal, or less security. In this paper, we analyze a total of six\ndevices by four manufacturers, including the original device, in depth. Via a\nlow-level analysis, we identify all of them as being individually developed\ndevices. We further put the focus on debug and hardware security, discovering\nseveral novel vulnerabilities in all devices, causing the exposure of the\nentire firmware. All of the presented vulnerabilities, including invasive ones,\nare on a Do it Yourself (DiY) level without the demand for a sophisticated lab\n-- thereby underlining the urgency for hardware fixes. To facilitate further\nresearch, reproduction, and testing of other devices, we provide a\ncomprehensive description of all vulnerabilities in this paper and code for\nproofs-of-concepts online.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 23:12:53 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Obermaier", "Johannes", ""], ["Schink", "Marc", ""], ["Moczek", "Kosma", ""]]}, {"id": "2008.09724", "submitter": "Xingjian Ding", "authors": "Xingjian Ding, Jianxiong Guo, Deying Li, and Weili Wu", "title": "Pricing and Budget Allocation for IoT Blockchain with Edge Computing", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attracted by the inherent security and privacy protection of the blockchain,\nincorporating blockchain into Internet of Things (IoT) has been widely studied\nin these years. However, the mining process requires high computational power,\nwhich prevents IoT devices from directly participating in blockchain\nconstruction. For this reason, edge computing service is introduced to help\nbuild the IoT blockchain, where IoT devices could purchase computational\nresources from the edge servers. In this paper, we consider the case that IoT\ndevices also have other tasks that need the help of edge servers, such as data\nanalysis and data storage. The profits they can get from these tasks is closely\nrelated to the amounts of resources they purchased from the edge servers. In\nthis scenario, IoT devices will allocate their limited budgets to purchase\ndifferent resources from different edge servers, such that their profits can be\nmaximized. Moreover, edge servers will set \"best\" prices such that they can get\nthe biggest benefits. Accordingly, there raise a pricing and budget allocation\nproblem between edge servers and IoT devices. We model the interaction between\nedge servers and IoT devices as a multi-leader multi-follower Stackelberg game,\nwhose objective is to reach the Stackelberg Equilibrium (SE). We prove the\nexistence and uniqueness of the SE point, and design efficient algorithms to\nreach the SE point. In the end, we verify our model and algorithms by\nperforming extensive simulations, and the results show the correctness and\neffectiveness of our designs.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 00:41:26 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Ding", "Xingjian", ""], ["Guo", "Jianxiong", ""], ["Li", "Deying", ""], ["Wu", "Weili", ""]]}, {"id": "2008.09841", "submitter": "Christian Killer", "authors": "Christian Killer, Lucas Thorbecke, Bruno Rodrigues, Eder Scheid,\n  Muriel Franco, Burkhard Stiller", "title": "Proverum: A Hybrid Public Verifiability and Decentralized Identity\n  Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trust in electoral processes is fundamental for democracies. Further, the\nidentity management of citizen data is crucial, because final tallies cannot be\nguaranteed without the assurance that every final vote was cast by an eligible\nvoter. In order to establish a basis for a hybrid public verifiability of\nvoting, this work (1) introduces Proverum, an approach combining a private\nenvironment based on private permissioned Distributed Ledgers with a public\nenvironment based on public Blockchains, (2) describes the application of the\nProverum architecture to the Swiss Remote Postal Voting system, mitigating\nthreats present in the current system, and (3) addresses successfully the\ndecentralized identity management in a federalistic state.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 13:53:55 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Killer", "Christian", ""], ["Thorbecke", "Lucas", ""], ["Rodrigues", "Bruno", ""], ["Scheid", "Eder", ""], ["Franco", "Muriel", ""], ["Stiller", "Burkhard", ""]]}, {"id": "2008.09845", "submitter": "Hongbin Liu", "authors": "Hongbin Liu, Jinyuan Jia, Neil Zhenqiang Gong", "title": "On the Intrinsic Differential Privacy of Bagging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentially private machine learning trains models while protecting\nprivacy of the sensitive training data. The key to obtain differentially\nprivate models is to introduce noise/randomness to the training process. In\nparticular, existing differentially private machine learning methods add noise\nto the training data, the gradients, the loss function, and/or the model\nitself. Bagging, a popular ensemble learning framework, randomly creates some\nsubsamples of the training data, trains a base model for each subsample using a\nbase learner, and takes majority vote among the base models when making\npredictions. Bagging has intrinsic randomness in the training process as it\nrandomly creates subsamples. Our major theoretical results show that such\nintrinsic randomness already makes Bagging differentially private without the\nneeds of additional noise. In particular, we prove that, for any base learner,\nBagging with and without replacement respectively achieves $\\left(N\\cdot k\n\\cdot \\ln{\\frac{n+1}{n}},1- (\\frac{n-1}{n})^{N\\cdot k}\\right)$-differential\nprivacy and $\\left(\\ln{\\frac{n+1}{n+1-N\\cdot k}}, \\frac{N\\cdot k}{n}\n\\right)$-differential privacy, where $n$ is the training data size, $k$ is the\nsubsample size, and $N$ is the number of base models. Moreover, we prove that\nif no assumptions about the base learner are made, our derived privacy\nguarantees are tight. We empirically evaluate Bagging on MNIST and CIFAR10. Our\nexperimental results demonstrate that Bagging achieves significantly higher\naccuracies than state-of-the-art differentially private machine learning\nmethods with the same privacy budgets.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 14:17:55 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Liu", "Hongbin", ""], ["Jia", "Jinyuan", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "2008.09933", "submitter": "Hong-Ning Dai Prof.", "authors": "Hong-Ning Dai and Muhammad Imran and Noman Haider", "title": "Blockchain-enabled Internet of Medical Things to Combat COVID-19", "comments": "7 pages, 4 figures, 1 table", "journal-ref": "IEEE Internet of Things Magazine, 2020", "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We are experiencing an unprecedented healthcare crisis caused by\nnewly-discovered corona-virus disease (COVID-19). The outbreaks of COVID-19\nreveal the frailties of existing healthcare systems. Therefore, the digital\ntransformation of healthcare systems becomes an inevitable trend. During this\nprocess, the Internet of Medical Things (IoMT) plays a crucial role while\nintrinsic vulnerabilities of security and privacy deter the wide adoption of\nIoMT. In this article, we present a blockchain-enabled IoMT to address the\nsecurity and privacy concerns of IoMT systems. We also discuss the solutions\nbrought by blockchain-enabled IoMT to COVID-19 from five different\nperspectives. Moreover, we outline the open challenges and future directions of\nblockchain-enabled IoMT.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 00:46:03 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Dai", "Hong-Ning", ""], ["Imran", "Muhammad", ""], ["Haider", "Noman", ""]]}, {"id": "2008.10189", "submitter": "Jos\\'e I. Orlicki", "authors": "Jos\\'e I. Orlicki", "title": "Fair Proof-of-Stake using VDF+VRF Consensus", "comments": "5 pages, 1 figure, 6 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new Proof-of-Stake consensus protocol constructed with a\nverifiable random function (VRF) and a verifiable delay function (VDF) that has\nthe following properties: a) all addresses with positive stake can participate;\nb) is fair because the coin stake is proportional to the distribution of\nrewards; c) is resistant to several classic blockchain attacks such as Sybil\nattacks, \"Nothing-at-stake\" attacks and \"Winner-takes-all\" attacks. We call it\nVixify Consensus.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 04:38:43 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 22:32:54 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Orlicki", "Jos\u00e9 I.", ""]]}, {"id": "2008.10202", "submitter": "Ruobin Gong", "authors": "Ruobin Gong and Xiao-Li Meng", "title": "Congenial Differential Privacy under Mandated Disclosure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentially private data releases are often required to satisfy a set of\nexternal constraints that reflect the legal, ethical, and logical mandates to\nwhich the data curator is obligated. The enforcement of constraints, when\ntreated as post-processing, adds an extra phase in the production of privatized\ndata. It is well understood in the theory of multi-phase processing that\ncongeniality, a form of procedural compatibility between phases, is a\nprerequisite for the end users to straightforwardly obtain statistically valid\nresults. Congenial differential privacy is theoretically principled, which\nfacilitates transparency and intelligibility of the mechanism that would\notherwise be undermined by ad-hoc post-processing procedures. We advocate for\nthe systematic integration of mandated disclosure into the design of the\nprivacy mechanism via standard probabilistic conditioning on the invariant\nmargins. Conditioning automatically renders congeniality because any extra\npost-processing phase becomes unnecessary. We provide both initial theoretical\nguarantees and a Markov chain algorithm for our proposal. We also discuss\nintriguing theoretical issues that arise in comparing congenital differential\nprivacy and optimization-based post-processing, as well as directions for\nfurther research.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 05:51:12 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Gong", "Ruobin", ""], ["Meng", "Xiao-Li", ""]]}, {"id": "2008.10479", "submitter": "Imdad Ullh", "authors": "Imdad Ullah, Salil S. Kanhere, and Roksana Boreli", "title": "Privacy-preserving targeted mobile advertising: A Blockchain-based\n  framework for mobile ads", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The targeted advertising is based on preference profiles inferred via\nrelationships among individuals, their monitored responses to previous\nadvertising and temporal activity over the Internet, which has raised critical\nprivacy concerns. In this paper, we present a novel proposal for a\nBlockchain-based advertising platform that provides: a system for privacy\npreserving user profiling, privately requesting ads from the advertising\nsystem, the billing mechanisms for presented and clicked ads, the advertising\nsystem that uploads ads to the cloud according to profiling interests, various\ntypes of transactions to enable advertising operations in Blockchain-based\nnetwork, and the method that allows a cloud system to privately compute the\naccess policies for various resources (such as ads, mobile user profiles). Our\nmain goal is to design a decentralized framework for targeted ads, which\nenables private delivery of ads to users whose behavioral profiles accurately\nmatch the presented ads, defined by the ad system. We implement a POC of our\nproposed framework i.e. a Bespoke Miner and experimentally evaluate various\ncomponents of Blockchain-based in-app advertising system, implementing various\ncritical components; such as, evaluating user profiles, implementing access\npolicies, encryption and decryption of users' profiles. We observe that the\nprocessing delay for traversing policies of various tree sizes, the\nencryption/decryption time of user profiling with various key-sizes and user\nprofiles of various interests evaluates to an acceptable amount of processing\ntime as that of the currently implemented ad systems.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 14:38:56 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Ullah", "Imdad", ""], ["Kanhere", "Salil S.", ""], ["Boreli", "Roksana", ""]]}, {"id": "2008.10497", "submitter": "Pouyan Fotouhi Tehrani", "authors": "Pouyan Fotouhi Tehrani, Eric Osterweil, Jochen H. Schiller, Thomas C.\n  Schmidt, Matthias W\\\"ahlisch", "title": "Security of Alerting Authorities in the WWW: Measuring Namespaces,\n  DNSSEC, and Web PKI", "comments": "12 pages and 8 figures", "journal-ref": "Proceedings of the Web Conference 2021 (WWW '21)", "doi": "10.1145/3442381.3450033", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During disasters, crisis, and emergencies the public relies on online\nservices provided by official authorities to receive timely alerts, trustworthy\ninformation, and access to relief programs. It is therefore crucial for the\nauthorities to reduce risks when accessing their online services. This includes\ncatering to secure identification of service, secure resolution of name to\nnetwork service, and content security and privacy as a minimum base for\ntrustworthy communication.\n  In this paper, we take a first look at Alerting Authorities (AA) in the US\nand investigate security measures related to trustworthy and secure\ncommunication. We study the domain namespace structure, DNSSEC penetration, and\nweb certificates. We introduce an integrative threat model to better understand\nwhether and how the online presence and services of AAs are harmed. As an\nillustrative example, we investigate 1,388 Alerting Authorities. We observe\npartial heightened security relative to the global Internet trends, yet find\ncause for concern as about 78% of service providers fail to deploy measures of\ntrustworthy service provision. Our analysis shows two major shortcomings.\nFirst, how the DNS ecosystem is leveraged: about 50% of organizations do not\nown their dedicated domain names and are dependent on others, 55% opt for\nunrestricted-use namespaces, which simplifies phishing, and less than 4% of\nunique AA domain names are secured by DNSSEC, which can lead to DNS poisoning\nand possibly to certificate misissuance. Second, how Web PKI certificates are\nutilized: 15% of all hosts provide none or invalid certificates, thus cannot\ncater to confidentiality and data integrity, 64% of the hosts provide domain\nvalidation certification that lack any identity information, and shared\ncertificates have gained on popularity, which leads to fate-sharing and can be\na cause for instability.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 15:02:09 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 21:12:42 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 08:44:09 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Tehrani", "Pouyan Fotouhi", ""], ["Osterweil", "Eric", ""], ["Schiller", "Jochen H.", ""], ["Schmidt", "Thomas C.", ""], ["W\u00e4hlisch", "Matthias", ""]]}, {"id": "2008.10538", "submitter": "Florian Wilkens", "authors": "Florian Wilkens, Samuel Botzler, Julia Curts, Skadi Dinter, Malte\n  Hamann, Vincent Hubbe, Aleksandra Kornivetc, Nurefsan Sertbas, Mathias\n  Fischer", "title": "Towards Flexible Security Testing of OT Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the factory of the future traditional and formerly isolated Operational\nTechnology (OT) hardware will become connected with all kinds of networks. This\nleads to more complex security challenges during design, deployment and use of\nindustrial control systems. As it is infeasible to perform security tests on\nproduction hardware and it is expensive to build hardware setups dedicated to\nsecurity testing, virtualised testbeds are gaining interest. We create a\ntestbed based on a virtualised factory which can be controlled by real and\nvirtualised hardware. This allows for a flexible evaluation of security\nstrategies.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 16:20:11 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Wilkens", "Florian", ""], ["Botzler", "Samuel", ""], ["Curts", "Julia", ""], ["Dinter", "Skadi", ""], ["Hamann", "Malte", ""], ["Hubbe", "Vincent", ""], ["Kornivetc", "Aleksandra", ""], ["Sertbas", "Nurefsan", ""], ["Fischer", "Mathias", ""]]}, {"id": "2008.10681", "submitter": "Adam Aviv", "authors": "Timothy J. Forman and Adam J. Aviv", "title": "Double Patterns: A Usable Solution to Increase the Security of Android\n  Unlock Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android unlock patterns remain quite common. Our study, as well as others,\nfinds that roughly 25\\% of respondents use a pattern when unlocking their\nphone. Despite known security issues, the design of the pattern interface\nremains unchanged since first launch. We propose Double Patterns, a natural and\neasily adoptable advancement on Android unlock patterns that maintains the core\ndesign features, but instead of selecting a single pattern, a user selects two,\nconcurrent Android unlock patterns entered one-after-the-other super-imposed on\nthe same 3x3 grid. We evaluated Double Patterns for both security and usability\nby conducting an online study with $n=634$ participants in three treatments: a\ncontrol treatment, a first pattern entry blocklist, and a blocklist for both\npatterns. We find that in all settings, user chosen Double Patterns are more\nsecure than traditional patterns based on standard guessability metrics, more\nsimilar to that of 4-/6-digit PINs, and even more difficult to guess for a\nsimulated attacker. Users express positive sentiments in qualitative feedback,\nparticularly those who currently (or previously) used Android unlock patterns,\nand overall, participants found the Double Pattern interface quite usable, with\nhigh recall retention and comparable entry times to traditional patterns. In\nparticular, current Android pattern users, the target population for Double\nPatterns, reported SUS scores in the 80th percentile and high perceptions of\nsecurity and usability in responses to open- and closed-questions. Based on\nthese findings, we would recommend adding Double Patterns as an advancement to\nAndroid patterns, much like allowing for added PIN length.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 20:02:39 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Forman", "Timothy J.", ""], ["Aviv", "Adam J.", ""]]}, {"id": "2008.10697", "submitter": "Adam Aviv", "authors": "Hassan Khan and Jason Ceci and Jonah Stegman and Adam J. Aviv and\n  Rozita Dara and Ravi Kuber", "title": "Widely Reused and Shared, Infrequently Updated, and Sometimes Inherited:\n  A Holistic View of PIN Authentication in Digital Lives and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personal Identification Numbers (PINs) are widely used as an access control\nmechanism for digital assets (e.g., smartphones), financial assets (e.g., ATM\ncards), and physical assets (e.g., locks for garage doors or homes). Using\nsemi-structured interviews (n=35), participants reported on PIN usage for\ndifferent types of assets, including how users choose, share, inherit, and\nreuse PINs, as well as behaviour following the compromise of a PIN. We find\nthat memorability is the most important criterion when choosing a PIN, more so\nthan security or concerns of reuse. Updating or changing a PIN is very\nuncommon, even when a PIN is compromised. Participants reported sharing PINs\nfor one type of asset with acquaintances but inadvertently reused them for\nother assets, thereby subjecting themselves to potential risks. Participants\nalso reported using PINs originally set by previous homeowners for physical\ndevices (e.g., alarm or keypad door entry systems). While aware of the risks of\nnot updating PINs, this did not always deter participants from using inherited\nPINs, as they were often missing instructions on how to update them. %While\naware of the risks of not updating PINs, participants continued using these\nPINs, as they were often missing instructions on how to update them.Given the\nexpected increase in PIN-protected assets (e.g., loyalty cards, smart locks,\nand web apps), we provide suggestions and future research directions to better\nsupport users with multiple digital and non-digital assets and more secure\nhuman-device interaction when utilizing PINs.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 20:29:59 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Khan", "Hassan", ""], ["Ceci", "Jason", ""], ["Stegman", "Jonah", ""], ["Aviv", "Adam J.", ""], ["Dara", "Rozita", ""], ["Kuber", "Ravi", ""]]}, {"id": "2008.10705", "submitter": "Shammya Saha", "authors": "Shammya Shananda Saha, Christopher Gorog, Adam Moser, Anna Scaglione,\n  Nathan G. Johnson", "title": "Integrating Hardware Security into a Blockchain-Based Transactive Energy\n  Platform", "comments": "2021 North American Power Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This applied research paper introduces a novel framework for integrating\nhardware security and blockchain functionality with grid-edge devices to\nestablish a distributed cyber-security mechanism that verifies the provenance\nof messages to and from the devices. Expanding the idea of Two Factor\nAuthentication and Hardware Root of Trust, this work describes the development\nof a Cryptographic Trust Center(TM) (CTC(TM)) chip integrated into grid-edge\ndevices to create uniform cryptographic key management. Product managers,\nenergy system designers, and security architects can utilize this modular\nframework as a unified approach to manage distributed devices of various\nvendors, vintages, and sizes. Results demonstrate the application of CTC(TM) to\na blockchain-based Transactive Energy (TE) platform for provisioning of\ncryptographic keys and improved uniformity of the operational network and data\nmanagement. This process of configuring, installing, and maintaining keys is\ndescribed as Eco-Secure Provisioning(TM) (ESP(TM)). Laboratory test results\nshow the approach can resolve several cyber-security gaps in common blockchain\nframeworks such as Hyperledger Fabric.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 20:50:15 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Saha", "Shammya Shananda", ""], ["Gorog", "Christopher", ""], ["Moser", "Adam", ""], ["Scaglione", "Anna", ""], ["Johnson", "Nathan G.", ""]]}, {"id": "2008.10715", "submitter": "Binghui Wang", "authors": "Binghui Wang, Jinyuan Jia, Xiaoyu Cao, Neil Zhenqiang Gong", "title": "Certified Robustness of Graph Neural Networks against Adversarial\n  Structural Perturbation", "comments": "Accepted by ACM SIGKDD'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have recently gained much attention for node and\ngraph classification tasks on graph-structured data. However, multiple recent\nworks showed that an attacker can easily make GNNs predict incorrectly via\nperturbing the graph structure, i.e., adding or deleting edges in the graph. We\naim to defend against such attacks via developing certifiably robust GNNs.\nSpecifically, we prove the certified robustness guarantee of any GNN for both\nnode and graph classifications against structural perturbation. Moreover, we\nshow that our certified robustness guarantee is tight. Our results are based on\na recently proposed technique called randomized smoothing, which we extend to\ngraph data. We also empirically evaluate our method for both node and graph\nclassifications on multiple GNNs and multiple benchmark datasets. For instance,\non the Cora dataset, Graph Convolutional Network with our randomized smoothing\ncan achieve a certified accuracy of 0.49 when the attacker can arbitrarily\nadd/delete at most 15 edges in the graph.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 21:39:10 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 02:34:29 GMT"}, {"version": "v3", "created": "Fri, 16 Jul 2021 01:54:43 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Wang", "Binghui", ""], ["Jia", "Jinyuan", ""], ["Cao", "Xiaoyu", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "2008.10733", "submitter": "Chandra Thapa", "authors": "Chandra Thapa and Seyit Camtepe", "title": "Precision Health Data: Requirements, Challenges and Existing Techniques\n  for Data Security and Privacy", "comments": "35 pages, 3 figures, 7 tables", "journal-ref": "Computers in Biology and Medicine 129 (2021) 104130", "doi": "10.1016/j.compbiomed.2020.104130", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precision health leverages information from various sources, including omics,\nlifestyle, environment, social media, medical records, and medical insurance\nclaims to enable personalized care, prevent and predict illness, and precise\ntreatments. It extensively uses sensing technologies (e.g., electronic health\nmonitoring devices), computations (e.g., machine learning), and communication\n(e.g., interaction between the health data centers). As health data contain\nsensitive private information, including the identity of patient and carer and\nmedical conditions of the patient, proper care is required at all times.\nLeakage of these private information affects the personal life, including\nbullying, high insurance premium, and loss of job due to the medical history.\nThus, the security, privacy of and trust on the information are of utmost\nimportance. Moreover, government legislation and ethics committees demand the\nsecurity and privacy of healthcare data. Herein, in the light of precision\nhealth data security, privacy, ethical and regulatory requirements, finding the\nbest methods and techniques for the utilization of the health data, and thus\nprecision health is essential. In this regard, firstly, this paper explores the\nregulations, ethical guidelines around the world, and domain-specific needs.\nThen it presents the requirements and investigates the associated challenges.\nSecondly, this paper investigates secure and privacy-preserving machine\nlearning methods suitable for the computation of precision health data along\nwith their usage in relevant health projects. Finally, it illustrates the best\navailable techniques for precision health data security and privacy with a\nconceptual system model that enables compliance, ethics clearance, consent\nmanagement, medical innovations, and developments in the health domain.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 22:17:32 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Thapa", "Chandra", ""], ["Camtepe", "Seyit", ""]]}, {"id": "2008.10771", "submitter": "Boyu Li", "authors": "Boyu Li, Yuyi Wang, and Kun He", "title": "Privacy-Preserving Data Publishing via Mutual Cover", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study anonymization techniques for preserving privacy in the publication\nof microdata tables. Although existing approaches based on generalization can\nprovide enough protection for identities, anonymized tables always suffer from\nvarious attribute disclosures because generalization is inefficient to protect\nsensitive values and the partition of equivalence groups is directly shown to\nthe adversary. Besides, the generalized table also suffers from serious\ninformation loss because the original Quasi-Identifier (QI) values are hardly\npreserved and the protection against attribute disclosure often causes\nover-protection against identity disclosure. To this end, we propose a novel\ntechnique, called mutual cover, to hinder the adversary from matching the\ncombination of QI values in microdata tables. The rationale is to replace the\noriginal QI values with random QI values according to some random output tables\nthat make similar tuples to cover for each other at the minimal cost. As a\nresult, the mutual cover prevents identity disclosure and attribute disclosure\nmore effectively than generalization while retaining the distribution of\noriginal QI values as far as possible, and the information utility hardly\ndecreases when enhancing the protection for sensitive values. The effectiveness\nof mutual cover is verified with extensive experiments.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 01:10:24 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 01:04:10 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Li", "Boyu", ""], ["Wang", "Yuyi", ""], ["He", "Kun", ""]]}, {"id": "2008.10772", "submitter": "Ben Kaiser", "authors": "Ben Kaiser, Jerry Wei, Elena Lucherini, Kevin Lee, J. Nathan Matias,\n  Jonathan Mayer", "title": "Adapting Security Warnings to Counter Online Disinformation", "comments": "To be published in USENIX Security '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Disinformation is proliferating on the internet, and platforms are responding\nby attaching warnings to content. There is little evidence, however, that these\nwarnings help users identify or avoid disinformation. In this work, we adapt\nmethods and results from the information security warning literature in order\nto design and evaluate effective disinformation warnings.\n  In an initial laboratory study, we used a simulated search task to examine\ncontextual and interstitial disinformation warning designs. We found that users\nroutinely ignore contextual warnings, but users notice interstitial\nwarnings--and respond by seeking information from alternative sources.\n  We then conducted a follow-on crowdworker study with eight interstitial\nwarning designs. We confirmed a significant impact on user information-seeking\nbehavior, and we found that a warning's design could effectively inform users\nor convey a risk of harm. We also found, however, that neither user\ncomprehension nor fear of harm moderated behavioral effects.\n  Our work provides evidence that disinformation warnings can -- when designed\nwell -- help users identify and avoid disinformation. We show a path forward\nfor designing effective warnings, and we contribute repeatable methods for\nevaluating behavioral effects. We also surface a possible dilemma:\ndisinformation warnings might be able to inform users and guide behavior, but\nthe behavioral effects might result from user experience friction, not informed\ndecision making.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 01:10:57 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 15:56:11 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 22:55:30 GMT"}, {"version": "v4", "created": "Thu, 15 Oct 2020 15:36:03 GMT"}, {"version": "v5", "created": "Fri, 16 Oct 2020 18:19:45 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Kaiser", "Ben", ""], ["Wei", "Jerry", ""], ["Lucherini", "Elena", ""], ["Lee", "Kevin", ""], ["Matias", "J. Nathan", ""], ["Mayer", "Jonathan", ""]]}, {"id": "2008.10895", "submitter": "Zhaohua Chen", "authors": "Zhaohua Chen, Guang Yang", "title": "Decentralized Asset Custody Scheme with Security against Rational\n  Adversary", "comments": "40 pages, 5 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asset custody is a core financial service in which the custodian holds\nin-safekeeping assets on behalf of the client. Although traditional custody\nservice is typically endorsed by centralized authorities, decentralized custody\nscheme has become technically feasible since the emergence of digital assets,\nand furthermore, it is greatly needed by new applications such as blockchain\nand DeFi (Decentralized Finance).\n  In this work, we propose a framework of decentralized asset custody scheme\nthat is able to support a large number of custodians and safely hold customer\nassets of multiple times the value of the total security deposit. The proposed\ncustody scheme distributes custodians and assets into many custodian groups via\ncombinatorial designs, where each group fully controls the assigned assets.\nSince every custodian group is small, the overhead cost is significantly\nreduced. The liveness is also improved because even a single alive group would\nbe able to process transactions.\n  The security of this custody scheme is guaranteed under the rational\nadversary model, such that any adversary corrupting a bounded fraction of\ncustodians cannot move assets more than the security deposit paid. We further\nanalyze the security and performance of our constructions from both theoretical\nand experimental sides and give explicit examples with concrete numbers and\nfigures for a better understanding of our results.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 09:08:54 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 07:46:24 GMT"}, {"version": "v3", "created": "Tue, 13 Jul 2021 09:32:41 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Chen", "Zhaohua", ""], ["Yang", "Guang", ""]]}, {"id": "2008.11009", "submitter": "Chee Seng Chan", "authors": "Jian Han Lim, Chee Seng Chan, Kam Woh Ng, Lixin Fan, Qiang Yang", "title": "Protect, Show, Attend and Tell: Image Captioning Model with Ownership\n  Protection", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By and large, existing Intellectual Property Right (IPR) protection on deep\nneural networks typically i) focus on image classification task only, and ii)\nfollow a standard digital watermarking framework that were conventionally used\nto protect the ownership of multimedia and video content. This paper\ndemonstrates that current digital watermarking framework is insufficient to\nprotect image captioning task that often regarded as one of the frontier A.I.\nproblems. As a remedy, this paper studies and proposes two different embedding\nschemes in the hidden memory state of a recurrent neural network to protect\nimage captioning model. From both theoretically and empirically points, we\nprove that a forged key will yield an unusable image captioning model,\ndefeating the purpose on infringement. To the best of our knowledge, this work\nis the first to propose ownership protection on image captioning task. Also,\nextensive experiments show that the proposed method does not compromise the\noriginal image captioning performance on all common captioning metrics on\nFlickr30k and MS-COCO datasets, and at the same time it is able to withstand\nboth removal and ambiguity attacks.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 13:48:35 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Lim", "Jian Han", ""], ["Chan", "Chee Seng", ""], ["Ng", "Kam Woh", ""], ["Fan", "Lixin", ""], ["Yang", "Qiang", ""]]}, {"id": "2008.11016", "submitter": "Boyu Li", "authors": "Boyu Li, Kun He, and Geng Sun", "title": "Local Generalization and Bucketization Technique for Personalized\n  Privacy Preservation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anonymization technique has been extensively studied and widely applied for\nprivacy-preserving data publishing. In most previous approaches, a microdata\ntable consists of three categories of attribute: explicit-identifier,\nquasi-identifier (QI), and sensitive attribute. Actually, different individuals\nmay have different view on the sensitivity of different attributes. Therefore,\nthere is another type of attribute that contains both QI values and sensitive\nvalues, namely, semi-sensitive attribute. Based on such observation, we propose\na new anonymization technique, called local generalization and bucketization,\nto prevent identity disclosure and protect the sensitive values on each\nsemi-sensitive attribute and sensitive attribute. The rationale is to use local\ngeneralization and local bucketization to divide the tuples into local\nequivalence groups and partition the sensitive values into local buckets,\nrespectively. The protections of local generalization and local bucketization\nare independent, so that they can be implemented by appropriate algorithms\nwithout weakening other protection, respectively. Besides, the protection of\nlocal bucketization for each semi-sensitive attribute and sensitive attribute\nis also independent. Consequently, local bucketization can comply with various\nprinciples in different attributes according to the actual requirements of\nanonymization. The conducted extensive experiments illustrate the effectiveness\nof the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 13:52:37 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Li", "Boyu", ""], ["He", "Kun", ""], ["Sun", "Geng", ""]]}, {"id": "2008.11193", "submitter": "Tijana Zrnic", "authors": "Vitaly Feldman and Tijana Zrnic", "title": "Individual Privacy Accounting via a Renyi Filter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a sequential setting in which a single dataset of individuals is\nused to perform adaptively-chosen analyses, while ensuring that the\ndifferential privacy loss of each participant does not exceed a pre-specified\nprivacy budget. The standard approach to this problem relies on bounding a\nworst-case estimate of the privacy loss over all individuals and all possible\nvalues of their data, for every single analysis. Yet, in many scenarios this\napproach is overly conservative, especially for \"typical\" data points which\nincur little privacy loss by participation in most of the analyses. In this\nwork, we give a method for tighter privacy loss accounting based on the value\nof a personalized privacy loss estimate for each individual in each analysis.\nTo implement the accounting method we design a filter for R\\'enyi differential\nprivacy. A filter is a tool that ensures that the privacy parameter of a\ncomposed sequence of algorithms with adaptively-chosen privacy parameters does\nnot exceed a pre-specified budget. Our filter is simpler and tighter than the\nknown filter for $(\\epsilon,\\delta)$-differential privacy by Rogers et al. We\napply our results to the analysis of noisy gradient descent and show that\npersonalized accounting can be practical, easy to implement, and can only make\nthe privacy-utility tradeoff tighter.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 17:49:48 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 15:02:45 GMT"}, {"version": "v3", "created": "Mon, 28 Jun 2021 15:34:21 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Feldman", "Vitaly", ""], ["Zrnic", "Tijana", ""]]}, {"id": "2008.11278", "submitter": "Yi Li", "authors": "Yi Li, Jing Lin, and Kaiqi Xiong", "title": "An Adversarial Attack Defending System for Securing In-Vehicle Networks", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In a modern vehicle, there are over seventy Electronics Control Units (ECUs).\nFor an in-vehicle network, ECUs communicate with each other by following a\nstandard communication protocol, such as Controller Area Network (CAN).\nHowever, an attacker can easily access the in-vehicle network to compromise\nECUs through a WLAN or Bluetooth. Though there are various deep learning (DL)\nmethods suggested for securing in-vehicle networks, recent studies on\nadversarial examples have shown that attackers can easily fool DL models. In\nthis research, we further explore adversarial examples in an in-vehicle\nnetwork. We first discover and implement two adversarial attack models that are\nharmful to a Long Short Term Memory (LSTM)-based detection model used in the\nin-vehicle network. Then, we propose an Adversarial Attack Defending System\n(AADS) for securing an in-vehicle network. Specifically, we focus on\nbrake-related ECUs in an in-vehicle network. Our experimental results\ndemonstrate that adversaries can easily attack the LSTM-based detection model\nwith a success rate of over 98%, and the proposed AADS achieves over 99%\naccuracy for detecting adversarial attacks.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 21:23:49 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 17:19:09 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Li", "Yi", ""], ["Lin", "Jing", ""], ["Xiong", "Kaiqi", ""]]}, {"id": "2008.11317", "submitter": "Mohsen Minaei", "authors": "Mohsen Minaei, Mainack Mondal, Aniket Kate", "title": "\"My Friend Wanted to Talk About It and I Didn't\": Understanding\n  Perceptions of Deletion Privacy in Social Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing concern and awareness about the right-to-be-forgotten\nissues among regulators as well as users all over the world. To cope with these\nprivacy concerns, social platforms offer deletion mechanisms that give the\nusers the opportunity to remove their contents and in some cases the platforms\nremove them automatically. However, this leaves the users vulnerable to attacks\nby adversaries who specifically seek the damaging content of the users and\nexploit the act of deletion as a strong signal for it.\n  In this paper, we conduct a user study on 191 participants to study their\nprior deletion experiences, their expectations of deletion privacy, and how\neffective do they find the current deletion mechanisms. We find that more than\n80\\% of the users have deleted at least a social media post and 35\\% of the\ndeletions happened after a week of posting. While the participants identified\nthe irrelevancy of the content due to time passing as the main reason for\nremoving their contents, a majority of the participant believe that deletions\nindicate that the deleted content includes some damaging information to the\nowner. Importantly, the participants are significantly more concerned about\ntheir deletions being noticed by large-scale data collectors (e.g., a\nthird-party data collecting company or the government) than any other\nindividual from their social circle. Further, a third of the participants think\nthat they can be attacked by these large-scale data collectors. Finally, the\nparticipants find the current deletion mechanisms to be inadequate in\nprotecting the privacy of their deletions and provide guidelines for the future\nof deletion mechanisms.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 00:44:02 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Minaei", "Mohsen", ""], ["Mondal", "Mainack", ""], ["Kate", "Aniket", ""]]}, {"id": "2008.11355", "submitter": "Fatemeh Ganji", "authors": "Fatemeh Ganji and Shahin Tajik", "title": "Physically Unclonable Functions and AI: Two Decades of Marriage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The current chapter aims at establishing a relationship between artificial\nintelligence (AI) and hardware security. Such a connection between AI and\nsoftware security has been confirmed and well-reviewed in the relevant\nliterature. The main focus here is to explore the methods borrowed from AI to\nassess the security of a hardware primitive, namely physically unclonable\nfunctions (PUFs), which has found applications in cryptographic protocols,\ne.g., authentication and key generation. Metrics and procedures devised for\nthis are further discussed. Moreover, By reviewing PUFs designed by applying AI\ntechniques, we give insight into future research directions in this area.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 02:53:40 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 16:32:35 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Ganji", "Fatemeh", ""], ["Tajik", "Shahin", ""]]}, {"id": "2008.11358", "submitter": "Kaihua Qin", "authors": "Kaihua Qin, Henryk Hadass, Arthur Gervais and Joel Reardon", "title": "Applying Private Information Retrieval to Lightweight Bitcoin Clients", "comments": null, "journal-ref": null, "doi": "10.1109/CVCBT.2019.00012", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lightweight Bitcoin clients execute a Simple Payment Verification (SPV)\nprotocol to verify the validity of transactions related to a particular user.\nCurrently, lightweight clients use Bloom filters to significantly reduce the\namount of bandwidth required to validate a particular transaction. This is\ndespite the fact that research has shown that Bloom filters are insufficient at\npreserving the privacy of clients' queries.\n  In this paper we describe our design of an SPV protocol that leverages\nPrivate Information Retrieval (PIR) to create fully private and performant\nqueries. We show that our protocol has a low bandwidth and latency cost;\nproperties that make our protocol a viable alternative for lightweight Bitcoin\nclients and other cryptocurrencies with a similar SPV model. In contract to\nBloom filters, our PIR-based approach offers deterministic privacy to the user.\n  Among our results, we show that in the worst case, clients who would like to\nverify 100 transactions occurring in the past week incurs a bandwidth cost of\n33.54 MB with an associated latency of approximately 4.8 minutes, when using\nour protocol. The same query executed using the Bloom-filter-based SPV protocol\nincurs a bandwidth cost of 12.85 MB; this is a modest overhead considering the\nprivacy guarantees it provides.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 03:13:28 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Qin", "Kaihua", ""], ["Hadass", "Henryk", ""], ["Gervais", "Arthur", ""], ["Reardon", "Joel", ""]]}, {"id": "2008.11362", "submitter": "Kaihua Qin", "authors": "Simon Janin, Kaihua Qin, Akaki Mamageishvili, Arthur Gervais", "title": "FileBounty: Fair Data Exchange", "comments": "Simon Janin and Kaihua Qin contributed equally to this work", "journal-ref": null, "doi": "10.1109/EuroS&PW51379.2020.00055", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital contents are typically sold online through centralized and custodian\nmarketplaces, which requires the trading partners to trust a central entity. We\npresent FileBounty, a fair protocol which, assuming the cryptographic hash of\nthe file of interest is known to the buyer, is trust-free and lets a buyer\npurchase data for a previously agreed monetary amount, while guaranteeing the\nintegrity of the contents. To prevent misbehavior, FileBounty guarantees that\nany deviation from the expected participants' behavior results in a negative\nfinancial payoff; i.e. we show that honest behavior corresponds to a subgame\nperfect Nash equilibrium. Our novel deposit refunding scheme is resistant to\nextortion attacks under rational adversaries. If buyer and seller behave\nhonestly, FileBounty's execution requires only three on-chain transactions,\nwhile the actual data is exchanged off-chain in an efficient and\nprivacy-preserving manner. We moreover show how FileBounty enables a flexible\npeer-to-peer setting where multiple parties fairly sell a file to a buyer.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 03:31:27 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 14:16:47 GMT"}, {"version": "v3", "created": "Fri, 9 Jul 2021 06:36:26 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Janin", "Simon", ""], ["Qin", "Kaihua", ""], ["Mamageishvili", "Akaki", ""], ["Gervais", "Arthur", ""]]}, {"id": "2008.11366", "submitter": "Yinghan Wang", "authors": "Liping Zhang, Yue Zhu, Wei Ren, Yinghan Wang, and Neal N. Xiong", "title": "An Energy Efficient Authentication Scheme using Chebyshev Chaotic Map\n  for Smart Grid Environment", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of the important applications of Smart grid, charging between electric\nvehicles has attracted much attention. However, authentication between vehicle\nusers and an aggregator may be vulnerable to various attacks due to the usage\nof wireless communications. In order to reduce the computational costs yet\npreserve required security, the Chebyshev chaotic map based authentication\nschemes are proposed. However, the security requirements of Chebyshev\npolynomials bring a new challenge to the design of authentication schemes based\non Chebyshev chaotic maps. To solve this issue, we propose a practical\nChebyshev polynomial algorithm by using a binary exponentiation algorithm based\non square matrix to achieve secure and efficient Chebyshev polynomial\ncomputation. We further apply the proposed algorithm to construct an\nenergy-efficient authentication and key agreement scheme for smart grid\nenvironments. Compared with state-of-the-art schemes, the proposed\nauthentication scheme effectively reduces the computational costs and\ncommunication costs by adopting the proposed Chebyshev polynomial algorithm.\nFurthermore, the ProVerif tool is employed to analyze the security of the\nproposed authentication scheme. Our experimental results justified that our\nproposed authentication scheme can outperform state-of-the-art schemes in terms\nof the computational overhead while achieving privacy protection.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 03:42:17 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 10:36:58 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 08:43:33 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Zhang", "Liping", ""], ["Zhu", "Yue", ""], ["Ren", "Wei", ""], ["Wang", "Yinghan", ""], ["Xiong", "Neal N.", ""]]}, {"id": "2008.11533", "submitter": "Xueyuan Han", "authors": "Xueyuan Han, Xiao Yu, Thomas Pasquier, Ding Li, Junghwan Rhee, James\n  Mickens, Margo Seltzer, Haifeng Chen", "title": "SIGL: Securing Software Installations Through Deep Graph Learning", "comments": "18 pages, to appear in the 30th USENIX Security Symposium (USENIX\n  Security '21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many users implicitly assume that software can only be exploited after it is\ninstalled. However, recent supply-chain attacks demonstrate that application\nintegrity must be ensured during installation itself. We introduce SIGL, a new\ntool for detecting malicious behavior during software installation. SIGL\ncollects traces of system call activity, building a data provenance graph that\nit analyzes using a novel autoencoder architecture with a graph long short-term\nmemory network (graph LSTM) for the encoder and a standard multilayer\nperceptron for the decoder. SIGL flags suspicious installations as well as the\nspecific installation-time processes that are likely to be malicious. Using a\ntest corpus of 625 malicious installers containing real-world malware, we\ndemonstrate that SIGL has a detection accuracy of 96%, outperforming similar\nsystems from industry and academia by up to 87% in precision and recall and 45%\nin accuracy. We also demonstrate that SIGL can pinpoint the processes most\nlikely to have triggered malicious behavior, works on different audit platforms\nand operating systems, and is robust to training data contamination and\nadversarial attack. It can be used with application-specific models, even in\nthe presence of new software versions, as well as application-agnostic\nmeta-models that encompass a wide range of applications and installers.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 12:52:34 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 23:29:44 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Han", "Xueyuan", ""], ["Yu", "Xiao", ""], ["Pasquier", "Thomas", ""], ["Li", "Ding", ""], ["Rhee", "Junghwan", ""], ["Mickens", "James", ""], ["Seltzer", "Margo", ""], ["Chen", "Haifeng", ""]]}, {"id": "2008.11612", "submitter": "Andrew Quijano", "authors": "Andrew Quijano and Kemal Akkaya", "title": "Server-side Fingerprint-Based Indoor Localization Using Encrypted\n  Sorting", "comments": "This paper was presented in the IEEE MASS REU workshop, 2019,\n  Monterrey, CA", "journal-ref": "2019 IEEE 16th International Conference on Mobile Ad Hoc and\n  Sensor Systems Workshops (MASSW), pp. 53-57", "doi": "10.1109/MASSW.2019.00017", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GPS signals, the main origin of navigation, are not functional in indoor\nenvironments. Therefore, Wi-Fi access points have started to be increasingly\nused for localization and tracking inside the buildings by relying on a\nfingerprint-based approach. However, with these types of approaches, several\nconcerns regarding the privacy of the users have arisen. Malicious individuals\ncan determine a client's daily habits and activities by simply analyzing their\nwireless signals. While there are already efforts to incorporate privacy into\nthe existing fingerprint-based approaches, they are limited to the\ncharacteristics of the homomorphic cryptographic schemes they employed. In this\npaper, we propose to enhance the performance of these approaches by exploiting\nanother homomorphic algorithm, namely DGK, with its unique encrypted sorting\ncapability and thus pushing most of the computations to the server side. We\ndeveloped an Android app and tested our system within a Columbia University\ndormitory. Compared to existing systems, the results indicated that more power\nsavings can be achieved at the client side and DGK can be a viable option with\nmore powerful server computation capabilities.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 15:12:09 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Quijano", "Andrew", ""], ["Akkaya", "Kemal", ""]]}, {"id": "2008.11632", "submitter": "Weizhe Hua", "authors": "Weizhe Hua, Muhammad Umar, Zhiru Zhang, G. Edward Suh", "title": "GuardNN: Secure DNN Accelerator for Privacy-Preserving Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes GuardNN, a secure deep neural network (DNN) accelerator,\nwhich provides strong hardware-based protection for user data and model\nparameters even in an untrusted environment. GuardNN shows that the\narchitecture and protection can be customized for a specific application to\nprovide strong confidentiality and integrity protection with negligible\noverhead. The design of the GuardNN instruction set reduces the TCB to just the\naccelerator and enables confidentiality protection without the overhead of\nintegrity protection. GuardNN also introduces a new application-specific memory\nprotection scheme to minimize the overhead of memory encryption and integrity\nverification. The scheme shows that most of the off-chip meta-data in today's\nstate-of-the-art memory protection can be removed by exploiting the known\nmemory access patterns of a DNN accelerator. GuardNN is implemented as an FPGA\nprototype, which demonstrates effective protection with less than 2%\nperformance overhead for inference over a variety of modern DNN models.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 15:43:50 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Hua", "Weizhe", ""], ["Umar", "Muhammad", ""], ["Zhang", "Zhiru", ""], ["Suh", "G. Edward", ""]]}, {"id": "2008.11817", "submitter": "Kien Nguyen", "authors": "Kien Nguyen, John Krumm, Cyrus Shahabi", "title": "Spatial Privacy Pricing: The Interplay between Privacy, Utility and\n  Price in Geo-Marketplaces", "comments": "10 pages, SIGSPATIAL'20", "journal-ref": null, "doi": "10.1145/3397536.3422213", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A geo-marketplace allows users to be paid for their location data. Users\nconcerned about privacy may want to charge more for data that pinpoints their\nlocation accurately, but may charge less for data that is more vague. A buyer\nwould prefer to minimize data costs, but may have to spend more to get the\nnecessary level of accuracy. We call this interplay between privacy, utility,\nand price \\emph{spatial privacy pricing}. We formalize the issues\nmathematically with an example problem of a buyer deciding whether or not to\nopen a restaurant by purchasing location data to determine if the potential\nnumber of customers is sufficient to open. The problem is expressed as a\nsequential decision making problem, where the buyer first makes a series of\ndecisions about which data to buy and concludes with a decision about opening\nthe restaurant or not. We present two algorithms to solve this problem,\nincluding experiments that show they perform better than baselines.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 06:28:02 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 01:11:07 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Nguyen", "Kien", ""], ["Krumm", "John", ""], ["Shahabi", "Cyrus", ""]]}, {"id": "2008.11927", "submitter": "Karan Khathuria", "authors": "Karan Khathuria", "title": "Galois ring isomorphism problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Dor\\\"oz et al. (2017) proposed a new hard problem, called the\nfinite field isomorphism problem, and constructed a fully homomorphic\nencryption scheme based on this problem. In this paper, we generalize the\nproblem to the case of Galois rings, resulting in the Galois ring isomorphism\nproblem. The generalization is achieved by lifting the isomorphism between the\ncorresponding residue fields. As a result, this generalization allows us to\nconstruct cryptographic primitives over the ring of integers modulo a prime\npower, instead of a large prime number.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 06:07:06 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Khathuria", "Karan", ""]]}, {"id": "2008.11989", "submitter": "Dongming Han", "authors": "Dongming Han, Wei Chen, Rusheng Pan, Yijing Liu, Jiehui Zhou, Ying Xu,\n  Tianye Zhang, Changjie Fan, Jianrong Tao and Xiaolong (Luke) Zhang", "title": "GraphFederator: Federated Visual Analysis for Multi-party Graphs", "comments": "12 pages,8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents GraphFederator, a novel approach to construct joint\nrepresentations of multi-party graphs and supports privacy-preserving visual\nanalysis of graphs. Inspired by the concept of federated learning, we\nreformulate the analysis of multi-party graphs into a decentralization process.\nThe new federation framework consists of a shared module that is responsible\nfor joint modeling and analysis, and a set of local modules that run on\nrespective graph data. Specifically, we propose a federated graph\nrepresentation model (FGRM) that is learned from encrypted characteristics of\nmulti-party graphs in local modules. We also design multiple visualization\nviews for joint visualization, exploration, and analysis of multi-party graphs.\nExperimental results with two datasets demonstrate the effectiveness of our\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 08:36:10 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Han", "Dongming", "", "Luke"], ["Chen", "Wei", "", "Luke"], ["Pan", "Rusheng", "", "Luke"], ["Liu", "Yijing", "", "Luke"], ["Zhou", "Jiehui", "", "Luke"], ["Xu", "Ying", "", "Luke"], ["Zhang", "Tianye", "", "Luke"], ["Fan", "Changjie", "", "Luke"], ["Tao", "Jianrong", "", "Luke"], ["Xiaolong", "", "", "Luke"], ["Zhang", "", ""]]}, {"id": "2008.12008", "submitter": "Zhongyuan Hau", "authors": "Zhongyuan Hau, Soteris Demetriou, Luis Mu\\~noz-Gonz\\'alez, Emil C.\n  Lupu", "title": "Shadow-Catcher: Looking Into Shadows to Detect Ghost Objects in\n  Autonomous Vehicle 3D Sensing", "comments": "To appear in 26th European Symposium on Research in Computer Security\n  (ESORICS) 2021. Accepted at ESORICS'21 for the Winter Cycle submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LiDAR-driven 3D sensing allows new generations of vehicles to achieve\nadvanced levels of situation awareness. However, recent works have demonstrated\nthat physical adversaries can spoof LiDAR return signals and deceive 3D object\ndetectors to erroneously detect \"ghost\" objects. Existing defenses are either\nimpractical or focus only on vehicles. Unfortunately, it is easier to spoof\nsmaller objects such as pedestrians and cyclists, but harder to defend against\nand can have worse safety implications. To address this gap, we introduce\nShadow-Catcher, a set of new techniques embodied in an end-to-end prototype to\ndetect both large and small ghost object attacks on 3D detectors. We\ncharacterize a new semantically meaningful physical invariant (3D shadows)\nwhich Shadow-Catcher leverages for validating objects. Our evaluation on the\nKITTI dataset shows that Shadow-Catcher consistently achieves more than 94%\naccuracy in identifying anomalous shadows for vehicles, pedestrians, and\ncyclists, while it remains robust to a novel class of strong \"invalidation\"\nattacks targeting the defense system. Shadow-Catcher can achieve real-time\ndetection, requiring only between 0.003s-0.021s on average to process an object\nin a 3D point cloud on commodity hardware and achieves a 2.17x speedup compared\nto prior work\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 09:24:55 GMT"}, {"version": "v2", "created": "Sat, 16 Jan 2021 03:24:54 GMT"}, {"version": "v3", "created": "Mon, 3 May 2021 03:33:25 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Hau", "Zhongyuan", ""], ["Demetriou", "Soteris", ""], ["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["Lupu", "Emil C.", ""]]}, {"id": "2008.12188", "submitter": "Ida Bruhns", "authors": "Samira Briongos, Ida Bruhns, Pedro Malag\\'on, Thomas Eisenbarth and\n  Jos\\'e M. Moya", "title": "CACHE SNIPER : Accurate timing control of cache evictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microarchitectural side channel attacks have been very prominent in security\nresearch over the last few years. Caches have been an outstanding covert\nchannel, as they provide high resolution and generic cross-core leakage even\nwith simple user-mode code execution privileges. To prevent these generic\ncross-core attacks, all major cryptographic libraries now provide\ncountermeasures to hinder key extraction via cross-core cache attacks, for\ninstance avoiding secret dependent access patterns and prefetching data. In\nthis paper, we show that implementations protected by 'good-enough'\ncountermeasures aimed at preventing simple cache attacks are still vulnerable.\nWe present a novel attack that uses a special timing technique to determine\nwhen an encryption has started and then evict the data precisely at the desired\ninstant. This new attack does not require special privileges nor explicit\nsynchronization between the attacker and the victim. One key improvement of our\nattack is a method to evict data from the cache with a single memory access and\nin absence of shared memory by leveraging the transient capabilities of TSX and\nrelying on the recently reverse-engineered L3 replacement policy. We\ndemonstrate the efficiency by performing an asynchronous last level cache\nattack to extract an RSA key from the latest wolfSSL library, which has been\nespecially adapted to avoid leaky access patterns, and by extracting an AES key\nfrom the S-Box implementation included in OpenSSL bypassing the per round\nprefetch intended as a protection against cache attacks.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 15:31:09 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Briongos", "Samira", ""], ["Bruhns", "Ida", ""], ["Malag\u00f3n", "Pedro", ""], ["Eisenbarth", "Thomas", ""], ["Moya", "Jos\u00e9 M.", ""]]}, {"id": "2008.12199", "submitter": "Chi Liu Mr", "authors": "Chi Liu, Tianqing Zhu, Jun Zhang, Wanlei Zhou", "title": "Privacy Intelligence: A Survey on Image Privacy in Online Social\n  Networks", "comments": "32 pages, 9 figures. Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image sharing on online social networks (OSNs) has become an indispensable\npart of daily social activities, but it has also led to an increased risk of\nprivacy invasion. The recent image leaks from popular OSN services and the\nabuse of personal photos using advanced algorithms (e.g. DeepFake) have\nprompted the public to rethink individual privacy needs in OSN image sharing.\nHowever, OSN image privacy itself is quite complicated, and solutions currently\nin place for privacy management in reality are insufficient to provide\npersonalized, accurate and flexible privacy protection. A more intelligent\nenvironment for privacy-friendly OSN image sharing is in demand. To fill the\ngap, we contribute a survey of \"privacy intelligence\" that targets modern\nprivacy issues in dynamic OSN image sharing from a user-centric perspective.\nSpecifically, we present a definition and a taxonomy of OSN image privacy, and\na high-level privacy analysis framework based on the lifecycle of OSN image\nsharing. The framework consists of three stages with different principles of\nprivacy by design. At each stage, we identify typical user behaviors in OSN\nimage sharing and the privacy issues associated with these behaviors. Then a\nsystematic review on the representative intelligent solutions targeting those\nprivacy issues is conducted, also in a stage-based manner. The resulting\nanalysis describes an intelligent privacy firewall for closed-loop privacy\nmanagement. We also discuss the challenges and future directions in this area.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 15:52:16 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 03:43:39 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Liu", "Chi", ""], ["Zhu", "Tianqing", ""], ["Zhang", "Jun", ""], ["Zhou", "Wanlei", ""]]}, {"id": "2008.12282", "submitter": "Saskia Nu\\~nez von Voigt", "authors": "Saskia Nu\\~nez von Voigt, Mira Pauli, Johanna Reichert, Florian\n  Tschorsch", "title": "Every Query Counts: Analyzing the Privacy Loss of Exploratory Data\n  Analyses", "comments": "Accepted Paper for DPM 2020 co-located ESORICS 2020", "journal-ref": null, "doi": "10.1007/978-3-030-66172-4_17", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An exploratory data analysis is an essential step for every data analyst to\ngain insights, evaluate data quality and (if required) select a machine\nlearning model for further processing. While privacy-preserving machine\nlearning is on the rise, more often than not this initial analysis is not\ncounted towards the privacy budget. In this paper, we quantify the privacy loss\nfor basic statistical functions and highlight the importance of taking it into\naccount when calculating the privacy-loss budget of a machine learning\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 17:40:29 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["von Voigt", "Saskia Nu\u00f1ez", ""], ["Pauli", "Mira", ""], ["Reichert", "Johanna", ""], ["Tschorsch", "Florian", ""]]}, {"id": "2008.12428", "submitter": "Sencun Zhu", "authors": "Tianrou Xia, Yuanyi Sun, Sencun Zhu, Zeeshan Rasheed, Khurram Shafique", "title": "Toward A Network-Assisted Approach for Effective Ransomware Detection", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ransomware is a kind of malware using cryptographic mechanisms to prevent\nvictims from normal use of their computers. As a result, victims lose the\naccess to their files and desktops unless they pay the ransom to the attackers.\nBy the end of 2019, ransomware attack had caused more than 10 billion dollars\nof financial loss to enterprises and individuals. In this work, we propose\nNetwork-Assisted Approach (NAA), which contains effective local detection and\nnetwork-level detection mechanisms, to help users determine whether a machine\nhas been infected by ransomware. To evaluate its performance, we built 100\ncontainers in Docker to simulate network scenarios. A hybrid ransomware sample\nwhich is close to real-world ransomware is deployed on stimulative infected\nmachines. The experiment results show that our network-level detection\nmechanisms are separately applicable to WAN and LAN environments for ransomware\ndetection.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 01:36:16 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 21:03:46 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Xia", "Tianrou", ""], ["Sun", "Yuanyi", ""], ["Zhu", "Sencun", ""], ["Rasheed", "Zeeshan", ""], ["Shafique", "Khurram", ""]]}, {"id": "2008.12466", "submitter": "Farhad Farokhi", "authors": "Farhad Farokhi", "title": "Deconvoluting Kernel Density Estimation and Regression for Locally\n  Differentially Private Data", "comments": "updated reference list, deeper numerical analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CR cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local differential privacy has become the gold-standard of privacy literature\nfor gathering or releasing sensitive individual data points in a\nprivacy-preserving manner. However, locally differential data can twist the\nprobability density of the data because of the additive noise used to ensure\nprivacy. In fact, the density of privacy-preserving data (no matter how many\nsamples we gather) is always flatter in comparison with the density function of\nthe original data points due to convolution with privacy-preserving noise\ndensity function. The effect is especially more pronounced when using\nslow-decaying privacy-preserving noises, such as the Laplace noise. This can\nresult in under/over-estimation of the heavy-hitters. This is an important\nchallenge facing social scientists due to the use of differential privacy in\nthe 2020 Census in the United States. In this paper, we develop density\nestimation methods using smoothing kernels. We use the framework of\ndeconvoluting kernel density estimators to remove the effect of\nprivacy-preserving noise. This approach also allows us to adapt the results\nfrom non-parameteric regression with errors-in-variables to develop regression\nmodels based on locally differentially private data. We demonstrate the\nperformance of the developed methods on financial and demographic datasets.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 03:39:17 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 03:32:15 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Farokhi", "Farhad", ""]]}, {"id": "2008.12469", "submitter": "Meng Shen", "authors": "Meng Shen, Yaqian Wei, and Tong Li", "title": "Bluetooth-based COVID-19 Proximity Tracing Proposals: An Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale COVID-19 infections have occurred worldwide, which has caused\ntremendous impact on the economy and people's lives. The traditional method for\ntracing contagious virus, for example, determining the infection chain\naccording to the memory of infected people, has many drawbacks. With the\ncontinuous spread of the pandemic, many countries or organizations have started\nto study how to use mobile devices to trace COVID-19, aiming to help people\nautomatically record information about incidents with infected people through\ntechnologies, reducing the manpower required to determine the infection chain\nand alerting people at risk of infection. This article gives an overview on\nvarious Bluetooth-based COVID-19 proximity tracing proposals including\ncentralized and decentralized proposals. We discussed the basic workflow and\nthe differences between them before providing a survey of five typical\nproposals with explanations of their design features and benefits. Then, we\nsummarized eight security and privacy design goals for Bluetooth-based COVID-19\nproximity tracing proposals and applied them to analyze the five proposals.\nFinally, open problems and future directions are discussed.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 03:43:05 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Shen", "Meng", ""], ["Wei", "Yaqian", ""], ["Li", "Tong", ""]]}, {"id": "2008.12569", "submitter": "Pavlos Charalampidis", "authors": "Pavlos Charalampidis and Alexandros Fragkiadakis", "title": "When Distributed Ledger Technology meets Internet of Things -- Benefits\n  and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest from both the academia and industry to employ\ndistributed ledger technology in the Internet-of-Things domain for addressing\nsecurity-related and performance challenges. Distributed ledger technology\nenables non-trusted entities to communicate and reach consensus in a fully\ndistributed manner through a cryptographically secure and immutable ledger.\nHowever, significant challenges arise mainly related to transaction processing\nspeed and user privacy. This work explores the interplay between\nInternet-of-Things and distributed ledger technology, analysing the fundamental\ncharacteristics of this technology and discussing the related benefits and\nchallenges.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 10:26:59 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Charalampidis", "Pavlos", ""], ["Fragkiadakis", "Alexandros", ""]]}, {"id": "2008.12618", "submitter": "Dongjie Wang", "authors": "Dongjie Wang, Pengyang Wang, Jingbo Zhou, Leilei Sun, Bowen Du, Yanjie\n  Fu", "title": "Defending Water Treatment Networks: Exploiting Spatio-temporal Effects\n  for Cyber Attack Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Water Treatment Networks (WTNs) are critical infrastructures for local\ncommunities and public health, WTNs are vulnerable to cyber attacks. Effective\ndetection of attacks can defend WTNs against discharging contaminated water,\ndenying access, destroying equipment, and causing public fear. While there are\nextensive studies in WTNs attack detection, they only exploit the data\ncharacteristics partially to detect cyber attacks. After preliminary exploring\nthe sensing data of WTNs, we find that integrating spatio-temporal knowledge,\nrepresentation learning, and detection algorithms can improve attack detection\naccuracy. To this end, we propose a structured anomaly detection framework to\ndefend WTNs by modeling the spatio-temporal characteristics of cyber attacks in\nWTNs. In particular, we propose a spatio-temporal representation framework\nspecially tailored to cyber attacks after separating the sensing data of WTNs\ninto a sequence of time segments. This framework has two key components. The\nfirst component is a temporal embedding module to preserve temporal patterns\nwithin a time segment by projecting the time segment of a sensor into a\ntemporal embedding vector. We then construct Spatio-Temporal Graphs (STGs),\nwhere a node is a sensor and an attribute is the temporal embedding vector of\nthe sensor, to describe the state of the WTNs. The second component is a\nspatial embedding module, which learns the final fused embedding of the WTNs\nfrom STGs. In addition, we devise an improved one class-SVM model that utilizes\na new designed pairwise kernel to detect cyber attacks. The devised pairwise\nkernel augments the distance between normal and attack patterns in the fused\nembedding space. Finally, we conducted extensive experimental evaluations with\nreal-world data to demonstrate the effectiveness of our framework.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 15:56:55 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Wang", "Dongjie", ""], ["Wang", "Pengyang", ""], ["Zhou", "Jingbo", ""], ["Sun", "Leilei", ""], ["Du", "Bowen", ""], ["Fu", "Yanjie", ""]]}, {"id": "2008.12645", "submitter": "Awnon Bhowmik", "authors": "Awnon Bhowmik and Unnikrishnan Menon", "title": "Dragon Crypto -- An Innovative Cryptosystem", "comments": "5 pages, 6 figures, 1 table", "journal-ref": "International Journal of Computer Applications 176(29):37-41, June\n  2020", "doi": "10.5120/ijca2020920331", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years cyber-attacks are continuously developing. This means that\nhackers can find their way around the traditional cryptosystems. This calls for\nnew and more secure cryptosystems to take their place. This paper outlines a\nnew cryptosystem based on the dragon curve fractal. The security level of this\nscheme is based on multiple private keys, that are crucial for effective\nencryption and decryption of data. This paper discusses, how core concepts\nemerging from fractal geometry can be used as a trapdoor function for this\ncryptosystem.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 20:55:24 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Bhowmik", "Awnon", ""], ["Menon", "Unnikrishnan", ""]]}, {"id": "2008.12671", "submitter": "Andreea Alexandru", "authors": "Andreea B. Alexandru, Anastasios Tsiamis and George J. Pappas", "title": "Data-driven control on encrypted data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an efficient and private solution to the problem of\nencryption-aware data-driven control. We investigate a Control as a Service\nscenario, where a client employs a specialized outsourced control solution from\na service provider. The privacy-sensitive model parameters of the client's\nsystem are either not available or variable. Hence, we require the service\nprovider to perform data-driven control in a privacy-preserving manner on the\ninput-output data samples from the client. To this end, we co-design the\ncontrol scheme with respect to both control performance and privacy\nspecifications. First, we formulate our control algorithm based on recent\nresults from the behavioral framework, and we prove closeness between the\nclassical formulation and our formulation that accounts for noise and precision\nerrors arising from encryption. Second, we use a state-of-the-art leveled\nhomomorphic encryption scheme to enable the service provider to perform high\ncomplexity computations on the client's encrypted data, ensuring privacy.\nFinally, we streamline our solution by exploiting the rich structure of data,\nand meticulously employing ciphertext batching and rearranging operations to\nenable parallelization. This solution achieves more than twofold runtime and\nmemory improvements compared to our prior work.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 14:18:03 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 09:55:09 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Alexandru", "Andreea B.", ""], ["Tsiamis", "Anastasios", ""], ["Pappas", "George J.", ""]]}, {"id": "2008.12686", "submitter": "Yang Chen Dr.", "authors": "Yang Chen, Nami Ashizawa, Seanglidet Yean, Chai Kiat Yeo, Naoto Yanai", "title": "Self-Organizing Map assisted Deep Autoencoding Gaussian Mixture Model\n  for Intrusion Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the information age, a secure and stable network environment is essential\nand hence intrusion detection is critical for any networks. In this paper, we\npropose a self-organizing map assisted deep autoencoding Gaussian mixture model\n(SOMDAGMM) supplemented with well-preserved input space topology for more\naccurate network intrusion detection. The deep autoencoding Gaussian mixture\nmodel comprises a compression network and an estimation network which is able\nto perform unsupervised joint training. However, the code generated by the\nautoencoder is inept at preserving the topology of the input space, which is\nrooted in the bottleneck of the adopted deep structure. A self-organizing map\nhas been introduced to construct SOMDAGMM for addressing this issue. The\nsuperiority of the proposed SOM-DAGMM is empirically demonstrated with\nextensive experiments conducted upon two datasets. Experimental results show\nthat SOM-DAGMM outperforms state-of-the-art DAGMM on all tests, and achieves up\nto 15.58% improvement in F1 score and with better stability.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 14:41:18 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Chen", "Yang", ""], ["Ashizawa", "Nami", ""], ["Yean", "Seanglidet", ""], ["Yeo", "Chai Kiat", ""], ["Yanai", "Naoto", ""]]}, {"id": "2008.12843", "submitter": "Charalambos Konstantinou", "authors": "Jim Stright, Peter Cheetham, Charalambos Konstantinou", "title": "Defensive Cost-Benefit Analysis of Smart Grid Digital Functionalities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart grids offer several types of digital control and monitoring of electric\npower transmission and distribution. The potential costs of inherent security\nvulnerabilities, including likelihoods of exploitation, are difficult to\ndetermine. This article presents a method for comparing the economic benefits\nand costs of cyber-functionalities associated with smart grids.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 20:55:23 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Stright", "Jim", ""], ["Cheetham", "Peter", ""], ["Konstantinou", "Charalambos", ""]]}, {"id": "2008.12859", "submitter": "Charalambos Konstantinou", "authors": "Olugbenga Moses Anubi, Charalambos Konstantinou, Carlos A. Wong,\n  Satish Vedula", "title": "Multi-Model Resilient Observer under False Data Injection Attacks", "comments": "Presented at 2020 IEEE Conference on Control Technology and\n  Applications (CCTA 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the concept of boosting the resiliency of\noptimization-based observers for cyber-physical systems (CPS) using auxiliary\nsources of information. Due to the tight coupling of physics, communication and\ncomputation, a malicious agent can exploit multiple inherent vulnerabilities in\norder to inject stealthy signals into the measurement process. The problem\nsetting considers the scenario in which an attacker strategically corrupts\nportions of the data in order to force wrong state estimates which could have\ncatastrophic consequences. The goal of the proposed observer is to compute the\ntrue states in-spite of the adversarial corruption. In the formulation, we use\na measurement prior distribution generated by the auxiliary model to refine the\nfeasible region of a traditional compressive sensing-based regression problem.\nA constrained optimization-based observer is developed using l1-minimization\nscheme. Numerical experiments show that the solution of the resulting problem\nrecovers the true states of the system. The developed algorithm is evaluated\nthrough a numerical simulation example of the IEEE 14-bus system.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 21:51:53 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Anubi", "Olugbenga Moses", ""], ["Konstantinou", "Charalambos", ""], ["Wong", "Carlos A.", ""], ["Vedula", "Satish", ""]]}, {"id": "2008.12930", "submitter": "Itzel Vazquez Sandoval", "authors": "Itzel Vazquez Sandoval and Gabriele Lenzini", "title": "A Formal Security Analysis of the pEp Authentication Protocol for\n  Decentralized Key Distribution and End-to-End Encrypted Email", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": "10.1007/978-3-030-39749-4_11", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To send encrypted emails, users typically need to create and exchange keys\nwhich later should be manually authenticated, for instance, by comparing long\nstrings of characters. These tasks are cumbersome for the average user. To make\nmore accessible the use of encrypted email, a secure email application named\npEp automates the key management operations; pEp still requires the users to\ncarry out the verification, however, the authentication process is simple:\nusers have to compare familiar words instead of strings of random characters,\nthen the application shows the users what level of trust they have achieved via\ncolored visual indicators. Yet, users may not execute the authentication\nceremony as intended, pEp's trust rating may be wrongly assigned, or both. To\nlearn whether pEp's trust ratings (and the corresponding visual indicators) are\nassigned consistently, we present a formal security analysis of pEp's\nauthentication ceremony. From the software implementation in C, we derive the\nspecifications of an abstract protocol for public key distribution, encryption\nand trust establishment; then, we model the protocol in a variant of the\napplied pi calculus and later formally verify and validate specific privacy and\nauthentication properties. We also discuss alternative research directions that\ncould enrich the analysis.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 07:49:03 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Sandoval", "Itzel Vazquez", ""], ["Lenzini", "Gabriele", ""]]}, {"id": "2008.12952", "submitter": "Aleksandar Bojchevski", "authors": "Aleksandar Bojchevski, Johannes Klicpera, Stephan G\\\"unnemann", "title": "Efficient Robustness Certificates for Discrete Data: Sparsity-Aware\n  Randomized Smoothing for Graphs, Images and More", "comments": "Proceedings of the 37th International Conference on Machine Learning\n  (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing techniques for certifying the robustness of models for discrete data\neither work only for a small class of models or are general at the expense of\nefficiency or tightness. Moreover, they do not account for sparsity in the\ninput which, as our findings show, is often essential for obtaining non-trivial\nguarantees. We propose a model-agnostic certificate based on the randomized\nsmoothing framework which subsumes earlier work and is tight, efficient, and\nsparsity-aware. Its computational complexity does not depend on the number of\ndiscrete categories or the dimension of the input (e.g. the graph size), making\nit highly scalable. We show the effectiveness of our approach on a wide variety\nof models, datasets, and tasks -- specifically highlighting its use for Graph\nNeural Networks. So far, obtaining provable guarantees for GNNs has been\ndifficult due to the discrete and non-i.i.d. nature of graph data. Our method\ncan certify any GNN and handles perturbations to both the graph structure and\nthe node attributes.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 10:09:02 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Bojchevski", "Aleksandar", ""], ["Klicpera", "Johannes", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "2008.12981", "submitter": "Xuewei Feng", "authors": "Xuewei Feng, Chuanpu Fu, Qi Li, Kun Sun, Ke Xu", "title": "Off-Path TCP Exploits of the Mixed IPID Assignment", "comments": null, "journal-ref": "2020 ACM SIGSAC Conference on Computer and Communications Security\n  (CCS'20)", "doi": "10.1145/3372297.3417884", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we uncover a new off-path TCP hijacking attack that can be\nused to terminate victim TCP connections or inject forged data into victim TCP\nconnections by manipulating the new mixed IPID assignment method, which is\nwidely used in Linux kernel version 4.18 and beyond to help defend against TCP\nhijacking attacks. The attack has three steps. First, an off-path attacker can\ndowngrade the IPID assignment for TCP packets from the more secure\nper-socket-based policy to the less secure hash-based policy, building a shared\nIPID counter that forms a side channel on the victim. Second, the attacker\ndetects the presence of TCP connections by observing the shared IPID counter on\nthe victim. Third, the attacker infers the sequence number and the\nacknowledgment number of the detected connection by observing the side channel\nof the shared IPID counter. Consequently, the attacker can completely hijack\nthe connection, i.e., resetting the connection or poisoning the data stream.\n  We evaluate the impacts of this off-path TCP attack in the real world. Our\ncase studies of SSH DoS, manipulating web traffic, and poisoning BGP routing\ntables show its threat on a wide range of applications. Our experimental\nresults show that our off-path TCP attack can be constructed within 215 seconds\nand the success rate is over 88%. Finally, we analyze the root cause of the\nexploit and develop a new IPID assignment method to defeat this attack. We\nprototype our defense in Linux 4.18 and confirm its effectiveness through\nextensive evaluation over real applications on the Internet.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 14:12:44 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Feng", "Xuewei", ""], ["Fu", "Chuanpu", ""], ["Li", "Qi", ""], ["Sun", "Kun", ""], ["Xu", "Ke", ""]]}, {"id": "2008.13072", "submitter": "Kaiyang Li", "authors": "Kaiyang Li, Guangchun Luo, Yang Ye, Wei Li, Shihao Ji, Zhipeng Cai", "title": "Adversarial Privacy Preserving Graph Embedding against Inference Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the surge in popularity of Internet of Things (IoT), mobile\ndevices, social media, etc. has opened up a large source for graph data. Graph\nembedding has been proved extremely useful to learn low-dimensional feature\nrepresentations from graph structured data. These feature representations can\nbe used for a variety of prediction tasks from node classification to link\nprediction. However, existing graph embedding methods do not consider users'\nprivacy to prevent inference attacks. That is, adversaries can infer users'\nsensitive information by analyzing node representations learned from graph\nembedding algorithms. In this paper, we propose Adversarial Privacy Graph\nEmbedding (APGE), a graph adversarial training framework that integrates the\ndisentangling and purging mechanisms to remove users' private information from\nlearned node representations. The proposed method preserves the structural\ninformation and utility attributes of a graph while concealing users' private\nattributes from inference attacks. Extensive experiments on real-world graph\ndatasets demonstrate the superior performance of APGE compared to the\nstate-of-the-arts. Our source code can be found at\nhttps://github.com/uJ62JHD/Privacy-Preserving-Social-Network-Embedding.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 00:06:49 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Li", "Kaiyang", ""], ["Luo", "Guangchun", ""], ["Ye", "Yang", ""], ["Li", "Wei", ""], ["Ji", "Shihao", ""], ["Cai", "Zhipeng", ""]]}, {"id": "2008.13115", "submitter": "Michael Maher", "authors": "Michael J. Maher", "title": "Corruption and Audit in Strategic Argumentation", "comments": "Reasoning Research Institute technical report, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strategic argumentation provides a simple model of disputation and\nnegotiation among agents. Although agents might be expected to act in our best\ninterests, there is little that enforces such behaviour. (Maher, 2016)\nintroduced a model of corruption and resistance to corruption within strategic\nargumentation. In this paper we identify corrupt behaviours that are not\ndetected in that formulation. We strengthen the model to detect such\nbehaviours, and show that, under the strengthened model, all the strategic aims\nin (Maher, 2016) are resistant to corruption.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 08:08:26 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Maher", "Michael J.", ""]]}, {"id": "2008.13144", "submitter": "Paul-Gauthier No\\'e", "authors": "Paul-Gauthier No\\'e, Jean-Fran\\c{c}ois Bonastre, Driss Matrouf,\n  Natalia Tomashenko, Andreas Nautsch, Nicholas Evans", "title": "Speech Pseudonymisation Assessment Using Voice Similarity Matrices", "comments": "Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of speech technologies and rising privacy legislation calls\nfor the development of privacy preservation solutions for speech applications.\nThese are essential since speech signals convey a wealth of rich, personal and\npotentially sensitive information. Anonymisation, the focus of the recent\nVoicePrivacy initiative, is one strategy to protect speaker identity\ninformation. Pseudonymisation solutions aim not only to mask the speaker\nidentity and preserve the linguistic content, quality and naturalness, as is\nthe goal of anonymisation, but also to preserve voice distinctiveness. Existing\nmetrics for the assessment of anonymisation are ill-suited and those for the\nassessment of pseudonymisation are completely lacking. Based upon voice\nsimilarity matrices, this paper proposes the first intuitive visualisation of\npseudonymisation performance for speech signals and two novel metrics for\nobjective assessment. They reflect the two, key pseudonymisation requirements\nof de-identification and voice distinctiveness.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 11:31:07 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["No\u00e9", "Paul-Gauthier", ""], ["Bonastre", "Jean-Fran\u00e7ois", ""], ["Matrouf", "Driss", ""], ["Tomashenko", "Natalia", ""], ["Nautsch", "Andreas", ""], ["Evans", "Nicholas", ""]]}, {"id": "2008.13151", "submitter": "Milan Lopuha\\\"a-Zwakenberg", "authors": "Milan Lopuha\\\"a-Zwakenberg, Haochen Tong and Boris \\v{S}kori\\'c", "title": "Data Sanitisation Protocols for the Privacy Funnel with Differential\n  Privacy Guarantees", "comments": "This preprint is an extended version of arXiv:2002.01501 (Fourteenth\n  International Conference on the Digital Society, 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Open Data approach, governments and other public organisations want to\nshare their datasets with the public, for accountability and to support\nparticipation. Data must be opened in such a way that individual privacy is\nsafeguarded. The Privacy Funnel is a mathematical approach that produces a\nsanitised database that does not leak private data beyond a chosen threshold.\nThe downsides to this approach are that it does not give worst-case privacy\nguarantees, and that finding optimal sanitisation protocols can be\ncomputationally prohibitive. We tackle these problems by using differential\nprivacy metrics, and by considering local protocols which operate on one entry\nat a time. We show that under both the Local Differential Privacy and Local\nInformation Privacy leakage metrics, one can efficiently obtain optimal\nprotocols. Furthermore, Local Information Privacy is both more closely aligned\nto the privacy requirements of the Privacy Funnel scenario, and more\nefficiently computable. We also consider the scenario where each user has\nmultiple attributes, for which we define Side-channel Resistant Local\nInformation Privacy, and we give efficient methods to find protocols satisfying\nthis criterion while still offering good utility. Finally, we introduce\nConditional Reporting, an explicit LIP protocol that can be used when the\noptimal protocol is infeasible to compute, and we test this protocol on\nreal-world and synthetic data. Experiments on real-world and synthetic data\nconfirm the validity of these methods.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 12:19:34 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Lopuha\u00e4-Zwakenberg", "Milan", ""], ["Tong", "Haochen", ""], ["\u0160kori\u0107", "Boris", ""]]}, {"id": "2008.13212", "submitter": "Christopher Neal", "authors": "Christopher Neal, Hanane Dagdougui, Andrea Lodi, Jos\\'e Fernandez", "title": "Reinforcement Learning Based Penetration Testing of a Microgrid Control\n  Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microgrids (MGs) are small-scale power systems which interconnect distributed\nenergy resources and loads within clearly defined regions. However, the digital\ninfrastructure used in an MG to relay sensory information and perform control\ncommands can potentially be compromised due to a cyberattack from a capable\nadversary. An MG operator is interested in knowing the inherent vulnerabilities\nin their system and should regularly perform Penetration Testing (PT)\nactivities to prepare for such an event. PT generally involves looking for\ndefensive coverage blindspots in software and hardware infrastructure, however\nthe logic in control algorithms which act upon sensory information should also\nbe considered in PT activities. This paper demonstrates a case study of PT for\nan MG control algorithm by using Reinforcement Learning (RL) to uncover\nmalicious input which compromises the effectiveness of the controller. Through\ntrial-and-error episodic interactions with a simulated MG, we train an RL agent\nto find malicious input which reduces the effectiveness of the MG controller.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 16:45:07 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Neal", "Christopher", ""], ["Dagdougui", "Hanane", ""], ["Lodi", "Andrea", ""], ["Fernandez", "Jos\u00e9", ""]]}, {"id": "2008.13317", "submitter": "Sang-Yoon Chang", "authors": "Sang-Yoon Chang (University of Colorado Colorado Springs)", "title": "Share Withholding Attack in Blockchain Mining: Technical Report", "comments": "27 pages, 7 figures, to be published in EAI SecureComm 2020\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptocurrency achieves distributed consensus using proof of work (PoW).\nPrior research in blockchain security identified financially incentivized\nattacks based on withholding blocks which have the attacker compromise a victim\npool and pose as a PoW contributor by submitting the shares (earning credit for\nmining) but withholding the blocks (no actual contributions to the pool). We\nadvance such threats to generate greater reward advantage to the attackers\nwhile undermining the other miners and introduce the share withholding attack\n(SWH). SWH withholds shares to increase the attacker's reward payout within the\npool, in contrast to the prior threats withholding blocks, and rather builds on\nthe block-withholding threats in order to exploit the information about the\nimpending block submission timing, challenging the popularly established\nassumption that the block submission time is completely random and unknown to\nminers. We analyze SWH's incentive compatibility and the vulnerability scope by\nidentifying the critical systems and environmental parameters which determine\nthe attack's impact. Our results show that SWH in conjunction with block\nwithholding yield unfair reward advantage at the expense of the\nprotocol-complying victim miners and that a rational miner will selfishly\nlaunch SWH to maximize its reward profit. We inform the blockchain and\ncryptocurrency research of the novel SWH threat and include the potential\ncountermeasure directions to facilitate such research and development.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 02:12:02 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Chang", "Sang-Yoon", "", "University of Colorado Colorado Springs"]]}, {"id": "2008.13346", "submitter": "Naoto Yanai", "authors": "Ouyang Junjie and Naoto Yanai and Tatsuya Takemura and Masayuki Okada\n  and Shingo Okamura and Jason Paul Cruz", "title": "APVAS: Reducing Memory Size of AS\\_PATH Validation by Using Aggregate\n  Signatures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \\textit{BGPsec} protocol, which is an extension of the border gateway\nprotocol (BGP), uses digital signatures to guarantee the validity of routing\ninformation. However, BGPsec's use of digital signatures in routing information\ncauses a lack of memory in BGP routers and therefore creates a gaping security\nhole in today's Internet. This problem hinders the practical realization and\nimplementation of BGPsec. In this paper, we present APVAS (AS path validation\nbased on aggregate signatures), a new validation method that reduces memory\nconsumption of BGPsec when validating paths in routing information. To do this,\nAPVAS relies on a novel aggregate signature scheme that compresses individually\ngenerated signatures into a single signature in two ways, i.e., in sequential\nand interactive fashions. Furthermore, we implement a prototype of APVAS on\n\\textit{BIRD Internet Routing Daemon} and demonstrate its efficiency on actual\nBGP connections. Our results show that APVAS can reduce memory consumption by\n80\\% in comparison with the conventional BGPsec.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 03:57:15 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Junjie", "Ouyang", ""], ["Yanai", "Naoto", ""], ["Takemura", "Tatsuya", ""], ["Okada", "Masayuki", ""], ["Okamura", "Shingo", ""], ["Cruz", "Jason Paul", ""]]}, {"id": "2008.13405", "submitter": "Seyedmostafa Safavi", "authors": "Seyedmostafa Safavi, Zarina Shukur", "title": "CenterYou: A cloud-based Approach to Simplify Android Privacy Management", "comments": "14 Figures, 21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With mobile applications and associated services becoming increasingly\npopular, concerns are being raised about private data leakages have raised.\nPrevious solutions to this well-known set of problems have approached it from\nthe ground up but required rewriting the operating system which is unnecessary\nand burdensome. In this work, a framework we proposed to overcome these issues\nby applying a pseudo data technique and cloud-based decision-making system to\nidentify potential privacy leakages.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 07:41:58 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Safavi", "Seyedmostafa", ""], ["Shukur", "Zarina", ""]]}, {"id": "2008.13413", "submitter": "Bin Hu", "authors": "Bin Hu, Zongyang Zhang, Jianwei Liu, Yizhong Liu, Jiayuan Yin,\n  Rongxing Lu, Xiaodong Lin", "title": "A comprehensive survey on smart contract construction and execution:\n  paradigms, tools, and systems", "comments": "Published on Patterns (Cell Press), see\n  https://www.cell.com/patterns/fulltext/S2666-3899(20)30243-9", "journal-ref": "Patterns, Volume 2, Issue 2, 2021, 100179", "doi": "10.1016/j.patter.2020.100179", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Smart contracts are regarded as one of the most promising and appealing\nnotions in blockchain technology. Their self-enforcing and event-driven\nfeatures make some online activities possible without a trusted third party.\nNevertheless, problems such as miscellaneous attacks, privacy leakage, and low\nprocessing rates pre-vent them from being widely applied. Various schemes and\ntools have been proposed to facilitate the construction and execution of secure\nsmart contracts. However, a comprehensive survey for these proposals is absent,\nhindering new researchers and developers from a quick start. This paper surveys\nthe literature and online resources on smart contract construction and\nexecution over the period 2008-2020. We divide the studies into three\ncategories: (1) design paradigms that give examples and patterns on contract\nconstruction, (2) design tools that facilitate the development of secure smart\ncontracts, and (3) extensions and alternatives that improve the privacy or\nefficiency of the system. We start by grouping the relevant construction\nschemes into the first two categories. We then review the execution mechanisms\nin the last category and further divide the state-of-the-art solutions into\nthree classes: private contracts with extra tools, off-chain channels, and\nextensions on core functionalities. Finally, we summarize several challenges\nand identify future research directions toward developing secure,\nprivacy-preserving, and efficient smart contracts.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 08:07:55 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 10:21:22 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Hu", "Bin", ""], ["Zhang", "Zongyang", ""], ["Liu", "Jianwei", ""], ["Liu", "Yizhong", ""], ["Yin", "Jiayuan", ""], ["Lu", "Rongxing", ""], ["Lin", "Xiaodong", ""]]}, {"id": "2008.13515", "submitter": "Ilya Sapranidi", "authors": "Aleksei Pupyshev, Elshan Dzhafarov, Ilya Sapranidi, Inal Kardanov,\n  Shamil Khalilov, Sten Laureyssens", "title": "SuSy: a blockchain-agnostic cross-chain asset transfer gateway protocol\n  based on Gravity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document is a specialized technical description of one of the potential\nimplementations of a second layer protocol over Gravity, a\nblockchain-/token-agnostic decentralized oracle protocol. The SuSy protocol\nprescribes an implementation of cross-chain transfers of digital assets\n(tokens) in blockchain networks that support smart contracts, focused primarily\non popular blockchains with varying architectures, consensuses and\ncryptography. SuSy is centered exclusively around technical implementation of\ntransfers, without bringing any incentive models for cross-chain transfer\nproviders. In addition, we describe the most popular inter-chain communication\nsolutions such as Polkadot, Cosmos Hub, Rainbow and RenVM, as a backdrop for\nthe new solution proposed in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 12:22:06 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 18:05:56 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Pupyshev", "Aleksei", ""], ["Dzhafarov", "Elshan", ""], ["Sapranidi", "Ilya", ""], ["Kardanov", "Inal", ""], ["Khalilov", "Shamil", ""], ["Laureyssens", "Sten", ""]]}, {"id": "2008.13551", "submitter": "Fr\\'ed\\'erique Oggier", "authors": "Fr\\'ed\\'erique Oggier, Gilles Z\\'emor", "title": "Coding Constructions for Efficient Oblivious Transfer from Noisy\n  Channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider oblivious transfer protocols performed over binary symmetric\nchannels in a malicious setting where parties will actively cheat if they can.\nWe provide constructions purely based on coding theory that achieve an explicit\npositive rate, the essential ingredient being the existence of linear codes\nwhose Schur products are asymptotically good.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 12:33:48 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Oggier", "Fr\u00e9d\u00e9rique", ""], ["Z\u00e9mor", "Gilles", ""]]}, {"id": "2008.13613", "submitter": "Sanchari Das", "authors": "Sanchari Das, Andrew Kim, Sayar Karmakar", "title": "Change-Point Analysis of Cyberbullying-Related Twitter Discussions\n  During COVID-19", "comments": null, "journal-ref": "16th Annual Social Informatics Research Symposium (\"Sociotechnical\n  Change Agents: ICTs, Sustainability, and Global Challenges\") in Conjunction\n  with the 83rd Association for Information Science and Technology (ASIS&T),\n  2020", "doi": null, "report-no": null, "categories": "cs.SI cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the outbreak of COVID-19, users are increasingly turning to online\nservices. An increase in social media usage has also been observed, leading to\nthe suspicion that this has also raised cyberbullying. In this initial work, we\nexplore the possibility of an increase in cyberbullying incidents due to the\npandemic and high social media usage. To evaluate this trend, we collected\n454,046 cyberbullying-related public tweets posted between January 1st, 2020 --\nJune 7th, 2020. We summarize the tweets containing multiple keywords into their\ndaily counts. Our analysis showed the existence of at most one statistically\nsignificant changepoint for most of these keywords, which were primarily\nlocated around the end of March. Almost all these changepoint time-locations\ncan be attributed to COVID-19, which substantiates our initial hypothesis of an\nincrease in cyberbullying through analysis of discussions over Twitter.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 22:50:42 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Das", "Sanchari", ""], ["Kim", "Andrew", ""], ["Karmakar", "Sayar", ""]]}, {"id": "2008.13632", "submitter": "William Buchanan Prof", "authors": "Zakwan Jaroucheh, Mohamad Alissa, William J Buchanan", "title": "TRUSTD: Combat Fake Content using Blockchain and Collective Signature\n  Technologies", "comments": "arXiv admin note: text overlap with arXiv:1812.00315,\n  arXiv:1807.06346, arXiv:1904.05386 by other authors", "journal-ref": "2020 IEEE International Conference on Blockchain and\n  Cryptocurrency (ICBC), Toronto, ON, Canada, 2020, pp. 1-3", "doi": "10.1109/ICBC48266.2020.9169435", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The growing trend of sharing news/contents, through social media platforms\nand the World Wide Web has been seen to impact our perception of the truth,\naltering our views about politics, economics, relationships, needs and wants.\nThis is because of the growing spread of misinformation and disinformation\nintentionally or unintentionally by individuals and organizations. This trend\nhas grave political, social, ethical, and privacy implications for society due\nto 1) the rapid developments in the field of Machine Learning (ML) and Deep\nLearning (DL) algorithms in creating realistic-looking yet fake digital content\n(such as text, images, and videos), 2) the ability to customize the content\nfeeds and to create a polarized so-called \"filter-bubbles\" leveraging the\navailability of the big-data. Therefore, there is an ethical need to combat the\nflow of fake content. This paper attempts to resolve some of the aspects of\nthis combat by presenting a high-level overview of TRUSTD, a blockchain and\ncollective signature-based ecosystem to help content creators in getting their\ncontent backed by the community, and to help users judge on the credibility and\ncorrectness of these contents.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 14:52:08 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Jaroucheh", "Zakwan", ""], ["Alissa", "Mohamad", ""], ["Buchanan", "William J", ""]]}, {"id": "2008.13707", "submitter": "Xiaoyong Yuan", "authors": "Xiaoyong Yuan, Lei Ding, Malek Ben Salem, Xiaolin Li, Dapeng Wu", "title": "Connecting Web Event Forecasting with Anomaly Detection: A Case Study on\n  Enterprise Web Applications Using Self-Supervised Neural Networks", "comments": "accepted at EAI SecureComm 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently web applications have been widely used in enterprises to assist\nemployees in providing effective and efficient business processes. Forecasting\nupcoming web events in enterprise web applications can be beneficial in many\nways, such as efficient caching and recommendation. In this paper, we present a\nweb event forecasting approach, DeepEvent, in enterprise web applications for\nbetter anomaly detection. DeepEvent includes three key features: web-specific\nneural networks to take into account the characteristics of sequential web\nevents, self-supervised learning techniques to overcome the scarcity of labeled\ndata, and sequence embedding techniques to integrate contextual events and\ncapture dependencies among web events. We evaluate DeepEvent on web events\ncollected from six real-world enterprise web applications. Our experimental\nresults demonstrate that DeepEvent is effective in forecasting sequential web\nevents and detecting web based anomalies. DeepEvent provides a context-based\nsystem for researchers and practitioners to better forecast web events with\nsituational awareness.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 16:09:04 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 13:56:01 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Yuan", "Xiaoyong", ""], ["Ding", "Lei", ""], ["Salem", "Malek Ben", ""], ["Li", "Xiaolin", ""], ["Wu", "Dapeng", ""]]}, {"id": "2008.13768", "submitter": "Guozhu Meng", "authors": "Wei Wang and Guozhu Meng and Haoyu Wang and Kai Chen and Weimin Ge and\n  Xiaohong Li", "title": "A3Ident: A Two-phased Approach to Identify the Leading Authors of\n  Android Apps", "comments": "12 pages", "journal-ref": "ICSME 2020: 36th IEEE International Conference on Software\n  Maintenance and Evolution", "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authorship identification is the process of identifying and classifying\nauthors through given codes. Authorship identification can be used in a wide\nrange of software domains, e.g., code authorship disputes, plagiarism\ndetection, exposure of attackers' identity. Besides the inherent challenges\nfrom legacy software development, framework programming and crowdsourcing mode\nin Android raise the difficulties of authorship identification significantly.\nMore specifically, widespread third party libraries and inherited components\n(e.g., classes, methods, and variables) dilute the primary code within the\nentire Android app and blur the boundaries of code written by different\nauthors. However, prior research has not well addressed these challenges.\n  To this end, we design a two-phased approach to attribute the primary code of\nan Android app to the specific developer. In the first phase, we put forward\nthree types of strategies to identify the relationships between Java packages\nin an app, which consist of context, semantic and structural relationships. A\npackage aggregation algorithm is developed to cluster all packages that are of\nhigh probability written by the same authors. In the second phase, we develop\nthree types of features to capture authors' coding habits and code stylometry.\nBased on that, we generate fingerprints for an author from its developed\nAndroid apps and employ several machine learning algorithms for authorship\nclassification. We evaluate our approach in three datasets that contain 15,666\napps from 257 distinct developers and achieve a 92.5% accuracy rate on average.\nAdditionally, we test it on 2,900 obfuscated apps and our approach can classify\napps with an accuracy rate of 80.4%.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 17:40:20 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Wang", "Wei", ""], ["Meng", "Guozhu", ""], ["Wang", "Haoyu", ""], ["Chen", "Kai", ""], ["Ge", "Weimin", ""], ["Li", "Xiaohong", ""]]}]