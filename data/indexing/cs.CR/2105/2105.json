[{"id": "2105.00013", "submitter": "Martin Henze", "authors": "Tim Krause, Raphael Ernst, Benedikt Klaer, Immanuel Hacker, Martin\n  Henze", "title": "Cybersecurity in Power Grids: Challenges and Opportunities", "comments": "11 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing volatilities within power transmission and distribution force\npower grid operators to amplify their use of communication infrastructure to\nmonitor and control their grid. The resulting increase in communication creates\na larger attack surface for malicious actors. Indeed, cyber attacks on power\ngrids have already succeeded in causing temporary, large-scale blackouts in the\nrecent past. In this paper, we analyze the communication infrastructure of\npower grids to derive resulting fundamental challenges of power grids with\nrespect to cybersecurity. Based on these challenges, we identify a broad set of\nresulting attack vectors and attack scenarios that threaten the security of\npower grids. To address these challenges, we propose to rely on a\ndefense-in-depth strategy, which encompasses measures for (i) device and\napplication security, (ii) network security, (iii) physical security, as well\nas (iv) policies, procedures, and awareness. For each of these categories, we\ndistill and discuss a comprehensive set of state-of-the art approaches, and\nidentify further opportunities to strengthen cybersecurity in interconnected\npower grids.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 18:00:09 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Krause", "Tim", ""], ["Ernst", "Raphael", ""], ["Klaer", "Benedikt", ""], ["Hacker", "Immanuel", ""], ["Henze", "Martin", ""]]}, {"id": "2105.00033", "submitter": "Matthew Kolosick", "authors": "Matthew Kolosick and Shravan Narayan and Conrad Watt and Michael LeMay\n  and Deepak Garg and Ranjit Jhala and Deian Stefan", "title": "Isolation Without Taxation: Near Zero Cost Transitions for SFI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Almost all SFI systems use heavyweight transitions that incur significant\nperformance overhead from saving and restoring registers when context switching\nbetween application and sandbox code. We identify a set of zero-cost conditions\nthat characterize when sandboxed code is well-structured enough so that\nsecurity can be guaranteed via lightweight zero-cost transitions. We show that\nusing WebAssembly (Wasm) as an intermediate representation for low-level code\nnaturally results in a SFI transition system with zero-cost transitions, and\nmodify the Lucet Wasm compiler and its runtime to use zero-cost transitions.\nOur modifications speed up font and image rendering in Firefox by up to 29.7%\nand 10% respectively. We also describe a new purpose-built fast SFI system,\nSegmentZero32, that uses x86 segmentation and LLVM with mostly off-the-shelf\npasses to enforce our zero-cost conditions. While this enforcement incurs some\nruntime cost within the sandboxed code, we find that, on Firefox image and font\nrendering benchmarks, the time saved per transition allows SegmentZero32 to\noutperform even an idealized hardware isolation system where memory isolation\nincurs zero performance overhead but the use of heavyweight transitions is\nrequired.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 18:21:32 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Kolosick", "Matthew", ""], ["Narayan", "Shravan", ""], ["Watt", "Conrad", ""], ["LeMay", "Michael", ""], ["Garg", "Deepak", ""], ["Jhala", "Ranjit", ""], ["Stefan", "Deian", ""]]}, {"id": "2105.00113", "submitter": "Yisroel Mirsky Dr.", "authors": "Yisroel Mirsky", "title": "IPatch: A Remote Adversarial Patch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Applications such as autonomous vehicles and medical screening use deep\nlearning models to localize and identify hundreds of objects in a single frame.\nIn the past, it has been shown how an attacker can fool these models by placing\nan adversarial patch within a scene. However, these patches must be placed in\nthe target location and do not explicitly alter the semantics elsewhere in the\nimage.\n  In this paper, we introduce a new type of adversarial patch which alters a\nmodel's perception of an image's semantics. These patches can be placed\nanywhere within an image to change the classification or semantics of locations\nfar from the patch. We call this new class of adversarial examples `remote\nadversarial patches' (RAP).\n  We implement our own RAP called IPatch and perform an in-depth analysis on\nimage segmentation RAP attacks using five state-of-the-art architectures with\neight different encoders on the CamVid street view dataset. Moreover, we\ndemonstrate that the attack can be extended to object recognition models with\npreliminary results on the popular YOLOv3 model. We found that the patch can\nchange the classification of a remote target region with a success rate of up\nto 93% on average.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 22:34:32 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 15:21:53 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Mirsky", "Yisroel", ""]]}, {"id": "2105.00117", "submitter": "Fatemeh Ganji", "authors": "Rabin Yu Acharya, Fatemeh Ganji, Domenic Forte", "title": "InfoNEAT: Information Theory-based NeuroEvolution of Augmenting\n  Topologies for Side-channel Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Profiled side-channel analysis (SCA) leverages leakage from cryptographic\nimplementations to extract the secret key. When combined with advanced methods\nin neural networks (NNs), profiled SCA can successfully attack even those\ncrypto-cores assumed to be protected against SCA. Despite the rise in the\nnumber of studies devoted to NN-based SCA, existing methods could not\nsystematically address the challenges involved in the NN-based SCA. A range of\nquestions has remained unanswered, namely: how to choose a NN with an adequate\nsize, how to tune the NN's hyperparameters, when to stop the training, and how\nto explain the performance of the NN model in quantitative terms, in the\ncontext of SCA. Our proposed approach, \"InfoNEAT,\" tackles these issues in a\nnatural way. InfoNEAT relies on the concept of evolution of NNs (both the\nnetwork architecture and parameters, so-called neuroevolution), enhanced by\ninformation-theoretic metrics to guide the evolution, halt it with a novel\nstopping criteria, and improve time-complexity and memory footprint. The\nperformance of InfoNEAT is evaluated by applying it to publicly available\ndatasets composed of real side-channel measurements. In addition to the\nconsiderable advantages regarding the automated configuration of NNs, InfoNEAT\ndemonstrates significant improvements over other approaches including a\nreduction in the number of epochs and width of the NN (i.e., the number of\nnodes in a layer) by factors of at least 1.25 and 6.66, respectively. According\nto our assessment and on the basis of our results, this is indeed achieved\nwithout any deterioration in the performance of SCA compared to the\nstate-of-the-art NN-based methods.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 23:01:50 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 03:46:25 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Acharya", "Rabin Yu", ""], ["Ganji", "Fatemeh", ""], ["Forte", "Domenic", ""]]}, {"id": "2105.00132", "submitter": "Nikolay Ivanov", "authors": "Nikolay Ivanov, Jianzhi Lou, Ting Chen, Jin Li, Qiben Yan", "title": "Targeting the Weakest Link: Social Engineering Attacks in Ethereum Smart\n  Contracts", "comments": "ACM ASIA Conference on Computer and Communications Security 2021, 15\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ethereum holds multiple billions of U.S. dollars in the form of Ether\ncryptocurrency and ERC-20 tokens, with millions of deployed smart contracts\nalgorithmically operating these funds. Unsurprisingly, the security of Ethereum\nsmart contracts has been under rigorous scrutiny. In recent years, numerous\ndefense tools have been developed to detect different types of smart contract\ncode vulnerabilities. When opportunities for exploiting code vulnerabilities\ndiminish, the attackers start resorting to social engineering attacks, which\naim to influence humans -- often the weakest link in the system. The only known\nclass of social engineering attacks in Ethereum are honeypots, which plant\nhidden traps for attackers attempting to exploit existing vulnerabilities,\nthereby targeting only a small population of potential victims.\n  In this work, we explore the possibility and existence of new social\nengineering attacks beyond smart contract honeypots. We present two novel\nclasses of Ethereum social engineering attacks - Address Manipulation and\nHomograph - and develop six zero-day social engineering attacks. To show how\nthe attacks can be used in popular programming patterns, we conduct a case\nstudy of five popular smart contracts with combined market capitalization\nexceeding $29 billion, and integrate our attack patterns in their source codes\nwithout altering their existing functionality. Moreover, we show that these\nattacks remain dormant during the test phase but activate their malicious logic\nonly at the final production deployment. We further analyze 85,656 open-source\nsmart contracts, and discover that 1,027 of them can be used for the proposed\nsocial engineering attacks. We conduct a professional opinion survey with\nexperts from seven smart contract auditing firms, corroborating that the\nexposed social engineering attacks bring a major threat to the smart contract\nsystems.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 00:39:59 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 23:58:08 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Ivanov", "Nikolay", ""], ["Lou", "Jianzhi", ""], ["Chen", "Ting", ""], ["Li", "Jin", ""], ["Yan", "Qiben", ""]]}, {"id": "2105.00146", "submitter": "Chong Li", "authors": "Chong Li, Lei Zhang, Serbiao Fang", "title": "EntrapNet: a Blockchain-Based Verification Protocol for Trustless\n  Computing", "comments": "10 pages. submitted to Journal Internet of Things", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we propose a blockchain-based computing verification protocol,\ncalled EntrapNet, for distributed shared computing networks, an emerging\nunderlying network for many internet of things (IoT) applications. EntrapNet\nborrows the idea from the practice of entrapment in criminal law to reduce the\npossibility of receiving incorrect computing results from trustless service\nproviders who have offered the computing resources. Furthermore, we\nmathematically optimize EntrapNet to deal with the fundamental tradeoff of a\nnetwork: security and efficiency. We present an asymptotic optimal solution to\nthis optimization. It will be seen that EntrapNet can be performed as an\nindependent and low-cost layer atop any trustless network that requires\noutsourced computing, thus making secure computing affordable and practical.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 01:58:26 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Li", "Chong", ""], ["Zhang", "Lei", ""], ["Fang", "Serbiao", ""]]}, {"id": "2105.00164", "submitter": "Shaofeng Li", "authors": "Shaofeng Li, Hui Liu, Tian Dong, Benjamin Zi Hao Zhao, Minhui Xue,\n  Haojin Zhu, Jialiang Lu", "title": "Hidden Backdoors in Human-Centric Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Natural language processing (NLP) systems have been proven to be vulnerable\nto backdoor attacks, whereby hidden features (backdoors) are trained into a\nlanguage model and may only be activated by specific inputs (called triggers),\nto trick the model into producing unexpected behaviors. In this paper, we\ncreate covert and natural triggers for textual backdoor attacks, \\textit{hidden\nbackdoors}, where triggers can fool both modern language models and human\ninspection. We deploy our hidden backdoors through two state-of-the-art trigger\nembedding methods. The first approach via homograph replacement, embeds the\ntrigger into deep neural networks through the visual spoofing of lookalike\ncharacter replacement. The second approach uses subtle differences between text\ngenerated by language models and real natural text to produce trigger sentences\nwith correct grammar and high fluency. We demonstrate that the proposed hidden\nbackdoors can be effective across three downstream security-critical NLP tasks,\nrepresentative of modern human-centric NLP systems, including toxic comment\ndetection, neural machine translation (NMT), and question answering (QA). Our\ntwo hidden backdoor attacks can achieve an Attack Success Rate (ASR) of at\nleast $97\\%$ with an injection rate of only $3\\%$ in toxic comment detection,\n$95.1\\%$ ASR in NMT with less than $0.5\\%$ injected data, and finally $91.12\\%$\nASR against QA updated with only 27 poisoning data samples on a model\npreviously trained with 92,024 samples (0.029\\%). We are able to demonstrate\nthe adversary's high success rate of attacks, while maintaining functionality\nfor regular users, with triggers inconspicuous by the human administrators.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 04:41:00 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 13:46:40 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Li", "Shaofeng", ""], ["Liu", "Hui", ""], ["Dong", "Tian", ""], ["Zhao", "Benjamin Zi Hao", ""], ["Xue", "Minhui", ""], ["Zhu", "Haojin", ""], ["Lu", "Jialiang", ""]]}, {"id": "2105.00174", "submitter": "Hao Wang", "authors": "Qing Yang, Hao Wang, Taotao Wang, Shengli Zhang, Xiaoxiao Wu, Hui Wang", "title": "Blockchain-Based Decentralized Energy Management Platform for\n  Residential Distributed Energy Resources in A Virtual Power Plant", "comments": null, "journal-ref": "Applied Energy, 2021", "doi": "10.1016/j.apenergy.2021.117026", "report-no": null, "categories": "eess.SY cs.CR cs.DC cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The advent of distributed energy resources (DERs), such as distributed\nrenewables, energy storage, electric vehicles, and controllable loads,\n\\rv{brings} a significantly disruptive and transformational impact on the\ncentralized power system. It is widely accepted that a paradigm shift to a\ndecentralized power system with bidirectional power flow is necessary to the\nintegration of DERs. The virtual power plant (VPP) emerges as a promising\nparadigm for managing DERs to participate in the power system. In this paper,\nwe develop a blockchain-based VPP energy management platform to facilitate a\nrich set of transactive energy activities among residential users with\nrenewables, energy storage, and flexible loads in a VPP. Specifically, users\ncan interact with each other to trade energy for mutual benefits and provide\nnetwork services, such as feed-in energy, reserve, and demand response, through\nthe VPP. To respect the users' independence and preserve their privacy, we\ndesign a decentralized optimization algorithm to optimize the users' energy\nscheduling, energy trading, and network services. Then we develop a prototype\nblockchain network for VPP energy management and implement the proposed\nalgorithm on the blockchain network. By experiments using real-world\ndata-trace, we validated the feasibility and effectiveness of our algorithm and\nthe blockchain system. The simulation results demonstrate that our\nblockchain-based VPP energy management platform reduces the users' cost by up\nto 38.6% and reduces the overall system cost by 11.2%.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 06:04:27 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 06:52:05 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Yang", "Qing", ""], ["Wang", "Hao", ""], ["Wang", "Taotao", ""], ["Zhang", "Shengli", ""], ["Wu", "Xiaoxiao", ""], ["Wang", "Hui", ""]]}, {"id": "2105.00183", "submitter": "Jinghua Yu", "authors": "Jinghua Yu, Stefan Wagner, Bowen Wang, Feng Luo", "title": "A systematic mapping study on security countermeasures of in-vehicle\n  communication systems", "comments": "31 pages, 19 figures, submitted to Vehicular Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The innovations of vehicle connectivity have been increasing dramatically to\nenhance the safety and user experience of driving, while the rising numbers of\ninterfaces to the external world also bring security threats to vehicles. Many\nsecurity countermeasures have been proposed and discussed to protect the\nsystems and services against attacks. To provide an overview of the current\nstates in this research field, we conducted a systematic mapping study on the\ntopic area \"security countermeasures of in-vehicle communication systems\". 279\npapers are identified based on the defined study identification strategy and\ncriteria. We discussed four research questions related to the security\ncountermeasures, validation methods, publication patterns, and research trends\nand gaps based on the extracted and classified data. Finally, we evaluated the\nvalidity threats, the study identification results, and the whole mapping\nprocess. We found that the studies in this topic area are increasing rapidly in\nrecent years. However, there are still gaps in various subtopics like\nautomotive Ethernet security, anomaly reaction, and so on. This study reviews\nthe target field not only related to research findings but also research\nactivities, which can help identify research gaps at a high level and inspire\nnew ideas for future work.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 07:23:00 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Yu", "Jinghua", ""], ["Wagner", "Stefan", ""], ["Wang", "Bowen", ""], ["Luo", "Feng", ""]]}, {"id": "2105.00187", "submitter": "Shahroz Tariq", "authors": "Shahroz Tariq, Sangyup Lee and Simon S. Woo", "title": "One Detector to Rule Them All: Towards a General Deepfake Attack\n  Detection Framework", "comments": "14 pages, 8 Figures, 6 Tables, Accepted for publication in The Web\n  Conference WWW 2021", "journal-ref": null, "doi": "10.1145/3442381.3449809", "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning-based video manipulation methods have become widely accessible\nto the masses. With little to no effort, people can quickly learn how to\ngenerate deepfake (DF) videos. While deep learning-based detection methods have\nbeen proposed to identify specific types of DFs, their performance suffers for\nother types of deepfake methods, including real-world deepfakes, on which they\nare not sufficiently trained. In other words, most of the proposed deep\nlearning-based detection methods lack transferability and generalizability.\nBeyond detecting a single type of DF from benchmark deepfake datasets, we focus\non developing a generalized approach to detect multiple types of DFs, including\ndeepfakes from unknown generation methods such as DeepFake-in-the-Wild (DFW)\nvideos. To better cope with unknown and unseen deepfakes, we introduce a\nConvolutional LSTM-based Residual Network (CLRNet), which adopts a unique model\ntraining strategy and explores spatial as well as the temporal information in\ndeepfakes. Through extensive experiments, we show that existing defense methods\nare not ready for real-world deployment. Whereas our defense method (CLRNet)\nachieves far better generalization when detecting various benchmark deepfake\nmethods (97.57% on average). Furthermore, we evaluate our approach with a\nhigh-quality DeepFake-in-the-Wild dataset, collected from the Internet\ncontaining numerous videos and having more than 150,000 frames. Our CLRNet\nmodel demonstrated that it generalizes well against high-quality DFW videos by\nachieving 93.86% detection accuracy, outperforming existing state-of-the-art\ndefense methods by a considerable margin.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 08:02:59 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Tariq", "Shahroz", ""], ["Lee", "Sangyup", ""], ["Woo", "Simon S.", ""]]}, {"id": "2105.00203", "submitter": "Ahmed Aldahdooh", "authors": "Ahmed Aldahdooh, Wassim Hamidouche, Sid Ahmed Fezza, Olivier Deforges", "title": "Adversarial Example Detection for DNN Models: A Review", "comments": "Preprint, submitted to Artificial Intelligence Review journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Learning (DL) has shown great success in many human-related tasks, which\nhas led to its adoption in many computer vision based applications, such as\nsecurity surveillance system, autonomous vehicles and healthcare. Such\nsafety-critical applications have to draw its path to success deployment once\nthey have the capability to overcome safety-critical challenges. Among these\nchallenges are the defense against or/and the detection of the adversarial\nexample (AE). Adversary can carefully craft small, often imperceptible, noise\ncalled perturbations, to be added to the clean image to generate the AE. The\naim of AE is to fool the DL model which makes it a potential risk for DL\napplications. Many test-time evasion attacks and countermeasures, i.e., defense\nor detection methods, are proposed in the literature. Moreover, few reviews and\nsurveys were published and theoretically showed the taxonomy of the threats and\nthe countermeasure methods with little focus in AE detection methods. In this\npaper, we attempt to provide a theoretical and experimental review for AE\ndetection methods. A detailed discussion for such methods is provided and\nexperimental results for eight state-of-the-art detectors are presented under\ndifferent scenarios on four datasets. We also provide potential challenges and\nfuture perspectives for this research direction.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 09:55:17 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Aldahdooh", "Ahmed", ""], ["Hamidouche", "Wassim", ""], ["Fezza", "Sid Ahmed", ""], ["Deforges", "Olivier", ""]]}, {"id": "2105.00227", "submitter": "Cory Merkel", "authors": "Micah Gorsline, James Smith, Cory Merkel", "title": "On the Adversarial Robustness of Quantized Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing the size of neural network models is a critical step in moving AI\nfrom a cloud-centric to an edge-centric (i.e. on-device) compute paradigm. This\nshift from cloud to edge is motivated by a number of factors including reduced\nlatency, improved security, and higher flexibility of AI algorithms across\nseveral application domains (e.g. transportation, healthcare, defense, etc.).\nHowever, it is currently unclear how model compression techniques may affect\nthe robustness of AI algorithms against adversarial attacks. This paper\nexplores the effect of quantization, one of the most common compression\ntechniques, on the adversarial robustness of neural networks. Specifically, we\ninvestigate and model the accuracy of quantized neural networks on\nadversarially-perturbed images. Results indicate that for simple gradient-based\nattacks, quantization can either improve or degrade adversarial robustness\ndepending on the attack strength.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 11:46:35 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Gorsline", "Micah", ""], ["Smith", "James", ""], ["Merkel", "Cory", ""]]}, {"id": "2105.00278", "submitter": "Rj Yang", "authors": "Ruijie Yang, Yunhong Wang and Yuanfang Guo", "title": "A Perceptual Distortion Reduction Framework for Adversarial Perturbation\n  Generation", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the adversarial attack methods suffer from large perceptual\ndistortions such as visible artifacts, when the attack strength is relatively\nhigh. These perceptual distortions contain a certain portion which contributes\nless to the attack success rate. This portion of distortions, which is induced\nby unnecessary modifications and lack of proper perceptual distortion\nconstraint, is the target of the proposed framework. In this paper, we propose\na perceptual distortion reduction framework to tackle this problem from two\nperspectives. We guide the perturbation addition process to reduce unnecessary\nmodifications by proposing an activated region transfer attention mask, which\nintends to transfer the activated regions of the target model from the correct\nprediction to incorrect ones. Note that an ensemble model is adopted to predict\nthe activated regions of the unseen models in the black-box setting of our\nframework. Besides, we propose a perceptual distortion constraint and add it\ninto the objective function of adversarial attack to jointly optimize the\nperceptual distortions and attack success rate. Extensive experiments have\nverified the effectiveness of our framework on several baseline methods.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 15:08:10 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Yang", "Ruijie", ""], ["Wang", "Yunhong", ""], ["Guo", "Yuanfang", ""]]}, {"id": "2105.00314", "submitter": "Yao Zheng", "authors": "Yao Zheng, Shekh Md Mahmudul Islam, Yanjun Pan, Marionne Millan,\n  Samson Aggelopoulos, Brian Lu, Alvin Yang, Thomas Yang, Stephanie Aelmore,\n  Willy Chang, Alana Power, Ming Li, Olga Bori\\'c-Lubecke, Victor Lubecke,\n  Wenhai Sun", "title": "Technical Report: Insider-Resistant Context-Based Pairing for\n  Multimodality Sleep Apnea Test", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The increasingly sophisticated at-home screening systems for obstructive\nsleep apnea (OSA), integrated with both contactless and contact-based sensing\nmodalities, bring convenience and reliability to remote chronic disease\nmanagement. However, the device pairing processes between system components are\nvulnerable to wireless exploitation from a non-compliant user wishing to\nmanipulate the test results. This work presents SIENNA, an insider-resistant\ncontext-based pairing protocol. SIENNA leverages JADE-ICA to uniquely identify\na user's respiration pattern within a multi-person environment and fuzzy\ncommitment for automatic device pairing, while using friendly jamming technique\nto prevents an insider with knowledge of respiration patterns from acquiring\nthe pairing key. Our analysis and test results show that SIENNA can achieve\nreliable (> 90% success rate) device pairing under a noisy environment and is\nrobust against the attacker with full knowledge of the context information.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 18:09:59 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 19:17:38 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Zheng", "Yao", ""], ["Islam", "Shekh Md Mahmudul", ""], ["Pan", "Yanjun", ""], ["Millan", "Marionne", ""], ["Aggelopoulos", "Samson", ""], ["Lu", "Brian", ""], ["Yang", "Alvin", ""], ["Yang", "Thomas", ""], ["Aelmore", "Stephanie", ""], ["Chang", "Willy", ""], ["Power", "Alana", ""], ["Li", "Ming", ""], ["Bori\u0107-Lubecke", "Olga", ""], ["Lubecke", "Victor", ""], ["Sun", "Wenhai", ""]]}, {"id": "2105.00334", "submitter": "Hanieh Hashemi", "authors": "Hanieh Hashemi, Yongqin Wang, Murali Annavaram", "title": "Privacy and Integrity Preserving Training Using Trusted Hardware", "comments": null, "journal-ref": "Distributed and Private Machine Learning ICLR 2021 Workshop", "doi": null, "report-no": null, "categories": "cs.CR cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy and security-related concerns are growing as machine learning reaches\ndiverse application domains. The data holders want to train with private data\nwhile exploiting accelerators, such as GPUs, that are hosted in the cloud.\nHowever, Cloud systems are vulnerable to attackers that compromise the privacy\nof data and integrity of computations. This work presents DarKnight, a\nframework for large DNN training while protecting input privacy and computation\nintegrity. DarKnight relies on cooperative execution between trusted execution\nenvironments (TEE) and accelerators, where the TEE provides privacy and\nintegrity verification, while accelerators perform the computation heavy linear\nalgebraic operations.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 19:33:28 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Hashemi", "Hanieh", ""], ["Wang", "Yongqin", ""], ["Annavaram", "Murali", ""]]}, {"id": "2105.00378", "submitter": "Deeksha Dangwal", "authors": "Deeksha Dangwal, Meghan Cowan, Armin Alaghi, Vincent T. Lee, Brandon\n  Reagen, Caroline Trippel", "title": "SoK: Opportunities for Software-Hardware-Security Codesign for Next\n  Generation Secure Computing", "comments": "9 pages", "journal-ref": null, "doi": "10.1145/3458903.345891", "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users are demanding increased data security. As a result, security is rapidly\nbecoming a first-order design constraint in next generation computing systems.\nResearchers and practitioners are exploring various security technologies to\nmeet user demand such as trusted execution environments (e.g., Intel SGX, ARM\nTrustZone), homomorphic encryption, and differential privacy. Each technique\nprovides some degree of security, but differs with respect to threat coverage,\nperformance overheads, as well as implementation and deployment challenges. In\nthis paper, we present a systemization of knowledge (SoK) on these design\nconsiderations and trade-offs using several prominent security technologies.\nOur study exposes the need for \\textit{software-hardware-security} codesign to\nrealize efficient and effective solutions of securing user data. In particular,\nwe explore how design considerations across applications, hardware, and\nsecurity mechanisms must be combined to overcome fundamental limitations in\ncurrent technologies so that we can minimize performance overhead while\nachieving sufficient threat model coverage. Finally, we propose a set of\nguidelines to facilitate putting these secure computing technologies into\npractice.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 02:19:12 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Dangwal", "Deeksha", ""], ["Cowan", "Meghan", ""], ["Alaghi", "Armin", ""], ["Lee", "Vincent T.", ""], ["Reagen", "Brandon", ""], ["Trippel", "Caroline", ""]]}, {"id": "2105.00384", "submitter": "Arlindo Flavio da Concei\\c{c}\\~ao", "authors": "Poliana de Moraes and Arlindo Flavio da Concei\\c{c}\\~ao", "title": "A Systematic Review of Security in the LoRaWAN Network Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The age of the Internet of Things is adding an increasing number of new\ndevices to the Internet and is expected to have fifty billion connected units\nby 2021. These form an extensive network that may have multiple points where\nthere is a risk of attacks that can compromise the entire system. This paper\nhas conducted a systematic review of security in LoRaWAN protocol specification\nversions 1.0 and 1.1 by locating its vulnerabilities and determining what\nmeasures can be taken for improvement and how they can be checked or tested.\nThe review identifies nineteen areas of vulnerability in the LoRaWAN protocol\nand shows that the current studies focus on specification version 1.0, key\nmanagement, and authentication procedures.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 02:51:57 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["de Moraes", "Poliana", ""], ["da Concei\u00e7\u00e3o", "Arlindo Flavio", ""]]}, {"id": "2105.00391", "submitter": "Chijung Jung", "authors": "Meng Wang, Chijung Jung, Ali Ahad, and Yonghwi Kwon", "title": "Spinner: Automated Dynamic Command Subsystem Perturbation", "comments": "22 pages, 20 figures, CCS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Injection attacks have been a major threat to web applications. Despite the\nsignificant effort in thwarting injection attacks, protection against injection\nattacks remains challenging due to the sophisticated attacks that exploit the\nexisting protection techniques' design and implementation flaws. In this paper,\nwe develop Spinner, a system that provides general protection against input\ninjection attacks, including OS/shell command, SQL, and XXE injection. Instead\nof focusing on detecting malicious inputs, Spinner constantly randomizes\nunderlying subsystems so that injected inputs (e.g., commands or SQL queries)\nthat are not properly randomized will not be executed, hence prevented. We\nrevisit the design and implementation choices of previous randomization-based\ntechniques and develop a more robust and practical protection against various\nsophisticated input injection attacks. To handle complex real-world\napplications, we develop a bidirectional analysis that combines forward and\nbackward static analysis techniques to identify intended commands or SQL\nqueries to ensure the correct execution of the randomized target program. We\nimplement Spinner for the shell command processor and two different database\nengines (MySQL and SQLite) and in diverse programming languages including\nC/C++, PHP, JavaScript and Lua. Our evaluation results on 42 real-world\napplications including 27 vulnerable ones show that it effectively prevents a\nvariety of input injection attacks with low runtime overhead (around 5%).\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 05:14:25 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Wang", "Meng", ""], ["Jung", "Chijung", ""], ["Ahad", "Ali", ""], ["Kwon", "Yonghwi", ""]]}, {"id": "2105.00395", "submitter": "Yusuke Koda", "authors": "Yusuke Koda and Jihong Park and Mehdi Bennis and Praneeth Vepakomma\n  and Ramesh Raskar", "title": "AirMixML: Over-the-Air Data Mixup for Inherently Privacy-Preserving Edge\n  Machine Learning", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless channels can be inherently privacy-preserving by distorting the\nreceived signals due to channel noise, and superpositioning multiple signals\nover-the-air. By harnessing these natural distortions and superpositions by\nwireless channels, we propose a novel privacy-preserving machine learning (ML)\nframework at the network edge, coined over-the-air mixup ML (AirMixML). In\nAirMixML, multiple workers transmit analog-modulated signals of their private\ndata samples to an edge server who trains an ML model using the received\nnoisy-and superpositioned samples. AirMixML coincides with model training using\nmixup data augmentation achieving comparable accuracy to that with raw data\nsamples. From a privacy perspective, AirMixML is a differentially private (DP)\nmechanism limiting the disclosure of each worker's private sample information\nat the server, while the worker's transmit power determines the privacy\ndisclosure level. To this end, we develop a fractional channel-inversion power\ncontrol (PC) method, {\\alpha}-Dirichlet mixup PC (DirMix({\\alpha})-PC), wherein\nfor a given global power scaling factor after channel inversion, each worker's\nlocal power contribution to the superpositioned signal is controlled by the\nDirichlet dispersion ratio {\\alpha}. Mathematically, we derive a closed-form\nexpression clarifying the relationship between the local and global PC factors\nto guarantee a target DP level. By simulations, we provide DirMix({\\alpha})-PC\ndesign guidelines to improve accuracy, privacy, and energy-efficiency. Finally,\nAirMixML with DirMix({\\alpha})-PC is shown to achieve reasonable accuracy\ncompared to a privacy-violating baseline with neither superposition nor PC.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 05:45:43 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Koda", "Yusuke", ""], ["Park", "Jihong", ""], ["Bennis", "Mehdi", ""], ["Vepakomma", "Praneeth", ""], ["Raskar", "Ramesh", ""]]}, {"id": "2105.00417", "submitter": "Sean Anderson", "authors": "Sean Noble Anderson, Leonidas Lampropoulos, Roberto Blanco, Benjamin\n  C. Pierce, and Andrew Tolmach", "title": "Security Properties for Stack Safety", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  What exactly does \"stack safety\" mean? The phrase is associated with a\nvariety of compiler, run-time, and hardware mechanisms for protecting stack\nmemory. But these mechanisms typically lack precise specifications, relying\ninstead on informal descriptions and examples of bad behaviors that they\nprevent.\n  We propose a formal characterization of stack safety, formulated with\nconcepts from language-based security: a combination of an integrity property\n(\"the private state in each caller's stack frame is held invariant by the\ncallee\"), a confidentiality property (\"the callee's behavior is insensitive to\nthe caller's private state\"), and a well-bracketedness property (\"each callee\nreturns control to its immediate caller\"). We use these properties to validate\nthe stack-safety \"micro-policies\" proposed by Roessler and DeHon [2018].\nSpecifically, we check (with property-based random testing) that Roessler and\nDehon's \"eager\" micro-policy, which catches violations as early as possible,\nenforces a simple \"stepwise\" variant of our properties and correctly detects\nseveral broken variants, and that (a repaired version of) their more performant\n\"lazy\" micro-policy corresponds to a slightly weaker and more extensional\n\"observational\" variant of our properties.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 08:18:34 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Anderson", "Sean Noble", ""], ["Lampropoulos", "Leonidas", ""], ["Blanco", "Roberto", ""], ["Pierce", "Benjamin C.", ""], ["Tolmach", "Andrew", ""]]}, {"id": "2105.00433", "submitter": "Ziv Katzir", "authors": "Ziv Katzir, Yuval Elovici", "title": "Who's Afraid of Adversarial Transferability?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial transferability, namely the ability of adversarial perturbations\nto simultaneously fool multiple learning models, has long been the \"big bad\nwolf\" of adversarial machine learning. Successful transferability-based attacks\nrequiring no prior knowledge of the attacked model's parameters or training\ndata have been demonstrated numerous times in the past, implying that machine\nlearning models pose an inherent security threat to real-life systems. However,\nall of the research performed in this area regarded transferability as a\nprobabilistic property and attempted to estimate the percentage of adversarial\nexamples that are likely to mislead a target model given some predefined\nevaluation set. As a result, those studies ignored the fact that real-life\nadversaries are often highly sensitive to the cost of a failed attack. We argue\nthat overlooking this sensitivity has led to an exaggerated perception of the\ntransferability threat, when in fact real-life transferability-based attacks\nare quite unlikely. By combining theoretical reasoning with a series of\nempirical results, we show that it is practically impossible to predict whether\na given adversarial example is transferable to a specific target model in a\nblack-box setting, hence questioning the validity of adversarial\ntransferability as a real-life attack tool for adversaries that are sensitive\nto the cost of a failed attack.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 09:44:12 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 11:16:59 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Katzir", "Ziv", ""], ["Elovici", "Yuval", ""]]}, {"id": "2105.00473", "submitter": "Charles-Henry Bertrand Van Ouytsel", "authors": "Charles-Henry Bertrand Van Ouytsel, Thomas Given-Wilson, Jeremy Minet,\n  Julian Roussieau, Axel Legay", "title": "Analysis of Machine Learning Approaches to Packing Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Packing is an obfuscation technique widely used by malware to hide the\ncontent and behavior of a program. Much prior research has explored how to\ndetect whether a program is packed. This research includes a broad variety of\napproaches such as entropy analysis, syntactic signatures and more recently\nmachine learning classifiers using various features. However, no robust results\nhave indicated which algorithms perform best, or which features are most\nsignificant. This is complicated by considering how to evaluate the results\nsince accuracy, cost, generalization capabilities, and other measures are all\nreasonable. This work explores eleven different machine learning approaches\nusing 119 features to understand: which features are most significant for\npacking detection; which algorithms offer the best performance; and which\nalgorithms are most economical.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 13:37:15 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Van Ouytsel", "Charles-Henry Bertrand", ""], ["Given-Wilson", "Thomas", ""], ["Minet", "Jeremy", ""], ["Roussieau", "Julian", ""], ["Legay", "Axel", ""]]}, {"id": "2105.00529", "submitter": "Jingjing Deng", "authors": "Hanchi Ren, Jingjing Deng and Xianghua Xie", "title": "GRNN: Generative Regression Neural Network -- A Data Leakage Attack for\n  Federated Learning", "comments": "Submitted to ACM Transactions on Intelligent Systems and Technology.\n  For associated source file, see https://github.com/Rand2AI/GRNN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data privacy has become an increasingly important issue in machine learning.\nMany approaches have been developed to tackle this issue, e.g., cryptography\n(Homomorphic Encryption, Differential Privacy, etc.) and collaborative training\n(Secure Multi-Party Computation, Distributed Learning and Federated Learning).\nThese techniques have a particular focus on data encryption or secure local\ncomputation. They transfer the intermediate information to the third-party to\ncompute the final result. Gradient exchanging is commonly considered to be a\nsecure way of training a robust model collaboratively in deep learning.\nHowever, recent researches have demonstrated that sensitive information can be\nrecovered from the shared gradient. Generative Adversarial Networks (GAN), in\nparticular, have shown to be effective in recovering those information.\nHowever, GAN based techniques require additional information, such as class\nlabels which are generally unavailable for privacy persevered learning. In this\npaper, we show that, in Federated Learning (FL) system, image-based privacy\ndata can be easily recovered in full from the shared gradient only via our\nproposed Generative Regression Neural Network (GRNN). We formulate the attack\nto be a regression problem and optimise two branches of the generative model by\nminimising the distance between gradients. We evaluate our method on several\nimage classification tasks. The results illustrate that our proposed GRNN\noutperforms state-of-the-art methods with better stability, stronger\nrobustness, and higher accuracy. It also has no convergence requirement to the\nglobal FL model. Moreover, we demonstrate information leakage using face\nre-identification. Some defense strategies are also discussed in this work.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 18:39:37 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Ren", "Hanchi", ""], ["Deng", "Jingjing", ""], ["Xie", "Xianghua", ""]]}, {"id": "2105.00542", "submitter": "Ronen Ben David", "authors": "Ronen Ben David, Anat Bremler Barr", "title": "Kubernetes Autoscaling: YoYo Attack Vulnerability and Mitigation", "comments": "Paper contains 14 pages, 4 figures. This paper was presented in\n  CLOSER 2021 conference on April 28,2021. CLOSER 2021 is the 11th\n  International Conference on Cloud Computing and Services Science, which was\n  organized by INSTICC. The paper is available soon at SCITEPRESS Digital\n  Library", "journal-ref": "Volume 1: CLOSER 2021,ISBN 978-989-758-510-4, pages 34-44", "doi": "10.5220/0010397900340044", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In recent years, we have witnessed a new kind of DDoS attack, the burst\nattack(Chai, 2013; Dahan, 2018), where the attacker launches periodic bursts of\ntraffic overload on online targets. Recent work presents a new kind of Burst\nattack, the YoYo attack (Bremler-Barr et al., 2017) that operates against the\nauto-scaling mechanism of VMs in the cloud. The periodic bursts of traffic\nloads cause the auto-scaling mechanism to oscillate between scale-up and\nscale-down phases. The auto-scaling mechanism translates the flat DDoS attacks\ninto Economic Denial of Sustainability attacks (EDoS), where the victim suffers\nfrom economic damage accrued by paying for extra resources required to process\nthe traffic generated by the attacker. However, it was shown that YoYo attack\nalso causes significant performance degradation since it takes time to scale-up\nVMs. In this research, we analyze the resilience of Kubernetes auto-scaling\nagainst YoYo attacks. As containerized cloud applications using Kubernetes gain\npopularity and replace VM-based architecture in recent years. We present\nexperimental results on Google Cloud Platform, showing that even though the\nscale-up time of containers is much lower than VM, Kubernetes is still\nvulnerable to the YoYo attack since VMs are still involved. Finally, we\nevaluate ML models that can accurately detect YoYo attack on a Kubernetes\ncluster.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 19:54:35 GMT"}, {"version": "v2", "created": "Sat, 8 May 2021 09:37:32 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["David", "Ronen Ben", ""], ["Barr", "Anat Bremler", ""]]}, {"id": "2105.00565", "submitter": "Constantinos Patsakis", "authors": "Vasilios Koutsokostas and Constantinos Patsakis", "title": "Python and Malware: Developing Stealth and Evasive Malware Without\n  Obfuscation", "comments": "To appear in SECRYPT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the continuous rise of malicious campaigns and the exploitation of new\nattack vectors, it is necessary to assess the efficacy of the defensive\nmechanisms used to detect them. To this end, the contribution of our work is\ntwofold. First, it introduces a new method for obfuscating malicious code to\nbypass all static checks of multi-engine scanners, such as VirusTotal.\nInterestingly, our approach to generating the malicious executables is not\nbased on introducing a new packer but on the augmentation of the capabilities\nof an existing and widely used tool for packaging Python, PyInstaller but can\nbe used for all similar packaging tools. As we prove, the problem is deeper and\ninherent in almost all antivirus engines and not PyInstaller specific. Second,\nour work exposes significant issues of well-known sandboxes that allow malware\nto evade their checks. As a result, we show that stealth and evasive malware\ncan be efficiently developed, bypassing with ease state of the art malware\ndetection tools without raising any alert.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 22:29:22 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Koutsokostas", "Vasilios", ""], ["Patsakis", "Constantinos", ""]]}, {"id": "2105.00579", "submitter": "Zaynah Javed", "authors": "Lun Wang, Zaynah Javed, Xian Wu, Wenbo Guo, Xinyu Xing, Dawn Song", "title": "BACKDOORL: Backdoor Attack against Competitive Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent research has confirmed the feasibility of backdoor attacks in deep\nreinforcement learning (RL) systems. However, the existing attacks require the\nability to arbitrarily modify an agent's observation, constraining the\napplication scope to simple RL systems such as Atari games. In this paper, we\nmigrate backdoor attacks to more complex RL systems involving multiple agents\nand explore the possibility of triggering the backdoor without directly\nmanipulating the agent's observation. As a proof of concept, we demonstrate\nthat an adversary agent can trigger the backdoor of the victim agent with its\nown action in two-player competitive RL systems. We prototype and evaluate\nBACKDOORL in four competitive environments. The results show that when the\nbackdoor is activated, the winning rate of the victim drops by 17% to 37%\ncompared to when not activated.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 23:47:55 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 22:40:51 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Wang", "Lun", ""], ["Javed", "Zaynah", ""], ["Wu", "Xian", ""], ["Guo", "Wenbo", ""], ["Xing", "Xinyu", ""], ["Song", "Dawn", ""]]}, {"id": "2105.00618", "submitter": "Sina Shaham", "authors": "Sina Shaham, Gabriel Ghinita, Cyrus Shahabi", "title": "An Efficient and Secure Location-based Alert Protocol using Searchable\n  Encryption and Huffman Codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Location data are widely used in mobile apps, ranging from location-based\nrecommendations, to social media and navigation. A specific type of interaction\nis that of location-based alerts, where mobile users subscribe to a service\nprovider (SP) in order to be notified when a certain event occurs nearby.\nConsider, for instance, the ongoing COVID-19 pandemic, where contact tracing\nhas been singled out as an effective means to control the virus spread. Users\nwish to be notified if they came in proximity to an infected individual.\nHowever, serious privacy concerns arise if the users share their location\nhistory with the SP in plaintext. To address privacy, recent work proposed\nseveral protocols that can securely implement location-based alerts. The users\nupload their encrypted locations to the SP, and the evaluation of location\npredicates is done directly on ciphertexts. When a certain individual is\nreported as infected, all matching ciphertexts are found (e.g., according to a\npredicate such as \"10 feet proximity to any of the locations visited by the\ninfected patient in the last week\"), and the corresponding users notified.\nHowever, there are significant performance issues associated with existing\nprotocols. The underlying searchable encryption primitives required to perform\nthe matching on ciphertexts are expensive, and without a proper encoding of\nlocations and search predicates, the performance can degrade a lot. In this\npaper, we propose a novel method for variable-length location encoding based on\nHuffman codes. By controlling the length required to represent encrypted\nlocations and the corresponding matching predicates, we are able to\nsignificantly speed up performance. We provide a theoretical analysis of the\ngain achieved by using Huffman codes, and we show through extensive experiments\nthat the improvement compared with fixed-length encoding methods is\nsubstantial.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 03:55:25 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Shaham", "Sina", ""], ["Ghinita", "Gabriel", ""], ["Shahabi", "Cyrus", ""]]}, {"id": "2105.00625", "submitter": "Jie Ma", "authors": "Jie Ma, Bin Qi, Kewei Lv", "title": "Three-Party Integer Comparison and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure integer comparison has been a popular research topic in cryptography,\nboth for its simplicity to describe and for its applications. The aim is to\nenable two parties to compare their inputs without revealing the exact value of\nthose inputs.\n  In this paper, we highlight three-party integer comparison (TPIC), where a\n\\emph{judge}, with no private input, wants to know the comparison result, while\ntwo \\emph{competitors} hold secret integers to do privacy-preserving\ncomparison. The judge actively obtains the result rather than passively waiting\nfor it sent by a competitor. We give two TPIC constructions considering\n\\emph{Mixed adversaries}, who have with different capabilities. One is secure\nagainst a semi-honest adversary with low computation and communication cost,\nwhile the other is secure against a malicious adversary.\n  Basing on TPIC, we present multi-party comparisons through concrete\napplications, including a joint bidding scheme and a practical auction. Brief\nsecurity proofs and analysis for the applications are presented. In comparison,\nour auction scheme is more efficient with lower cost, making it feasible in\npractice rather than a theoretical design. All the comparisons and application\nschemes run on top of blockchain requiring a constant number of rounds.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 04:32:18 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Ma", "Jie", ""], ["Qi", "Bin", ""], ["Lv", "Kewei", ""]]}, {"id": "2105.00645", "submitter": "Muslum Ozgur Ozmen", "authors": "Furkan Goksel, Muslum Ozgur Ozmen, Michael Reeves, Basavesh Shivakumar\n  and Z. Berkay Celik", "title": "On the Safety Implications of Misordered Events and Commands in IoT\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IoT devices, equipped with embedded actuators and sensors, provide custom\nautomation in the form of IoT apps. IoT apps subscribe to events and upon\nreceipt, transmit actuation commands which trigger a set of actuators. Events\nand actuation commands follow paths in the IoT ecosystem such as\nsensor-to-edge, edge-to-cloud, and cloud-to-actuator, with different network\nand processing delays between these connections. Significant delays may occur\nespecially when an IoT system cloud interacts with other clouds. Due to this\nvariation in delays, the cloud may receive events in an incorrect order, and in\nturn, devices may receive and actuate misordered commands. In this paper, we\nfirst study eight major IoT platforms and show that they do not make strong\nguarantees on event orderings to address these issues. We then analyze the\nend-to-end interactions among IoT components, from the creation of an event to\nthe invocation of a command. From this, we identify and formalize the root\ncauses of misorderings in events and commands leading to undesired states. We\ndeploy 23 apps in a simulated smart home containing 35 IoT devices to evaluate\nthe misordering problem. Our experiments demonstrate a high number of\nmisordered events and commands that occur through different interaction paths.\nThrough this effort, we reveal the root and extent of the misordering problem\nand guide future work to ensure correct ordering in IoT systems.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 06:32:10 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Goksel", "Furkan", ""], ["Ozmen", "Muslum Ozgur", ""], ["Reeves", "Michael", ""], ["Shivakumar", "Basavesh", ""], ["Celik", "Z. Berkay", ""]]}, {"id": "2105.00710", "submitter": "Iftach Haitner", "authors": "Nir Bitansky, Iftach Haitner, Ilan Komargodski, Eylon Yogev", "title": "Distributional Collision Resistance Beyond One-Way Functions", "comments": "A preliminary version appeared in Eurocrypt 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributional collision resistance is a relaxation of collision resistance\nthat only requires that it is hard to sample a collision $(x,y)$ where $x$ is\nuniformly random and $y$ is uniformly random conditioned on colliding with $x$.\nThe notion lies between one-wayness and collision resistance, but its exact\npower is still not well-understood. On one hand, distributional collision\nresistant hash functions cannot be built from one-way functions in a black-box\nway, which may suggest that they are stronger. On the other hand, so far, they\nhave not yielded any applications beyond one-way functions.\n  Assuming distributional collision resistant hash functions, we construct\n\\emph{constant-round} statistically hiding commitment scheme. Such commitments\nare not known based on one-way functions and are impossible to obtain from\none-way functions in a black-box way. Our construction relies on the reduction\nfrom inaccessible entropy generators to statistically hiding commitments by\nHaitner et al.\\ (STOC '09). In the converse direction, we show that two-message\nstatistically hiding commitments imply distributional collision resistance,\nthereby establishing a loose equivalence between the two notions.\n  A corollary of the first result is that constant-round statistically hiding\ncommitments are implied by average-case hardness in the class $SZK$ (which is\nknown to imply distributional collision resistance). This implication seems to\nbe folklore, but to the best of our knowledge has not been proven explicitly.\nWe provide yet another proof of this implication, which is arguably more direct\nthan the one going through distributional collision resistance.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 09:36:53 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Bitansky", "Nir", ""], ["Haitner", "Iftach", ""], ["Komargodski", "Ilan", ""], ["Yogev", "Eylon", ""]]}, {"id": "2105.00732", "submitter": "Iftach Haitner", "authors": "Ran Cohen and Iftach Haitner and Eran Omri and Lior Rotem", "title": "Characterization of Secure Multiparty Computation Without Broadcast", "comments": "This is the final draft of this paper. The full version was published\n  in the Journal of Cryptology 2018. An extended abstract of this work appeared\n  in the Theory of Cryptography Conference (TCC) 2016-A", "journal-ref": null, "doi": "10.1007/s00145-017-9264-x", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in the study of cryptography is characterizing the\nnecessary and sufficient assumptions required to carry out a given\ncryptographic task. The focus of this work is the necessity of a broadcast\nchannel for securely computing symmetric functionalities (where all the parties\nreceive the same output) when one third of the parties, or more, might be\ncorrupted. Assuming all parties are connected via a peer-to-peer network, but\nno broadcast channel (nor a secure setup phase) is available, we prove the\nfollowing characterization:\n  1) A symmetric $n$-party functionality can be securely computed facing\n$n/3\\le t<n/2$ corruptions (\\ie honest majority), if and only if it is\n\\emph{$(n-2t)$-dominated}; a functionality is $k$-dominated, if \\emph{any}\n$k$-size subset of its input variables can be set to \\emph{determine} its\noutput.\n  2) Assuming the existence of one-way functions, a symmetric $n$-party\nfunctionality can be securely computed facing $t\\ge n/2$ corruptions (\\ie no\nhonest majority), if and only if it is $1$-dominated and can be securely\ncomputed with broadcast.\n  It follows that, in case a third of the parties might be corrupted, broadcast\nis necessary for securely computing non-dominated functionalities (in which\n\"small\" subsets of the inputs cannot determine the output), including, as\ninteresting special cases, the Boolean XOR and coin-flipping functionalities.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 10:20:31 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 12:37:24 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Cohen", "Ran", ""], ["Haitner", "Iftach", ""], ["Omri", "Eran", ""], ["Rotem", "Lior", ""]]}, {"id": "2105.00743", "submitter": "Iftach Haitner", "authors": "Amos Beimel and Iftach Haitner and Nikolaos Makriyannis and Eran Omri", "title": "Tighter Bounds on Multi-Party Coin Flipping via Augmented Weak\n  Martingales and Differentially Private Sampling", "comments": "A preliminary version appeared in FOCS 18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In his seminal work, Cleve [STOC '86] has proved that any $r$-round\ncoin-flipping protocol can be efficiently biased by $\\Theta(1/r)$. This lower\nbound was met for the two-party case by Moran, Naor, and Segev [Journal of\nCryptology '16], and the three-party case (up to a $polylog$ factor) by Haitner\nand Tsfadi [SICOMP '17], and was approached for $n$-party protocols when $n<\nloglog r$ by Buchbinder, Haitner, Levi, and Tsfadia [SODA '17]. For $n> loglog\nr$, however, the best bias for $n$-party coin-flipping protocols remains\n$O(n/\\sqrt{r})$ achieved by the majority protocol of Awerbuch, Blum, Chor,\nGoldwasser, and Micali [Manuscript '85].\n  Our main result is a tighter lower bound on the bias of coin-flipping\nprotocols, showing that, for every constant $\\epsilon >0$, an\n$r^{\\epsilon}$-party $r$-round coin-flipping protocol can be efficiently biased\nby $\\widetilde{\\Omega}(1/\\sqrt{r})$. As far as we know, this is the first\nimprovement of Cleve's bound, and is only $n=r^{\\epsilon}$ (multiplicative) far\nfrom the aforementioned upper bound of Awerbuch et al.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 10:39:48 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Beimel", "Amos", ""], ["Haitner", "Iftach", ""], ["Makriyannis", "Nikolaos", ""], ["Omri", "Eran", ""]]}, {"id": "2105.00761", "submitter": "Noam Mazor", "authors": "Dror Chawin, Iftach Haitner, Noam Mazor", "title": "Lower Bounds on the Time/Memory Tradeoff of Function Inversion", "comments": "A preliminary version appeared in TCC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study time/memory tradeoffs of function inversion: an algorithm, i.e., an\ninverter, equipped with an s-bit advice on a randomly chosen function $f : [n]\n-> [n]$ and using $q$ oracle queries to $f$, tries to invert a randomly chosen\noutput $y$ of $f$, i.e., to find $x\\in f^{-1}(y)$. Much progress was done\nregarding adaptive function inversion - the inverter is allowed to make\nadaptive oracle queries. Hellman [IEEE transactions on Information Theory 80]\npresented an adaptive inverter that inverts with high probability a random $f$.\nFiat and Naor [SICOMP 00] proved that for any $s$, $q$ with $s^3q = n$\n(ignoring low-order terms), an $s$-advice, $q$-query variant of Hellmans\nalgorithm inverts a constant fraction of the image points of any function. Yao\n[STOC 90] proved a lower bound of $sq \\geq n$ for this problem. Closing the gap\nbetween the above lower and upper bounds is a long-standing open question. Very\nlittle is known for the non-adaptive variant of the question. The only known\nupper bounds, i.e., inverters, are the trivial ones (with $s+q = n$), and the\nonly lower bound is the above bound of Yao. In a recent work, Corrigan-Gibbs\nand Kogan [TCC 19] partially justified the difficulty of finding lower bounds\non non-adaptive inverters, showing that a lower bound on the time/memory\ntradeoff of non-adaptive inverters implies a lower bound on low-depth Boolean\ncircuits. Bounds that, for a strong enough choice of parameters, are\nnotoriously hard to prove. We make progress on the above intriguing question,\nboth for the adaptive and the non-adaptive case, proving the following lower\nbounds on restricted families of inverters.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 11:38:42 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 12:46:19 GMT"}, {"version": "v3", "created": "Wed, 5 May 2021 08:08:45 GMT"}, {"version": "v4", "created": "Sun, 9 May 2021 12:54:08 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Chawin", "Dror", ""], ["Haitner", "Iftach", ""], ["Mazor", "Noam", ""]]}, {"id": "2105.00765", "submitter": "Jad Silbak", "authors": "Iftach Haitner, Kobbi Nissim, Eran Omri, Ronen Shaltiel and Jad Silbak", "title": "Computational Two-Party Correlation: A Dichotomy for Key-Agreement\n  Protocols", "comments": "A preliminary version appeared in FOCS 2018. Published in SIAM\n  Journal on Computing 2020", "journal-ref": "SIAM Journal on Computing 49, no. 6 (2020): 1041-1082", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\pi$ be an efficient two-party protocol that given security parameter\n$\\kappa$, both parties output single bits $X_\\kappa$ and $Y_\\kappa$,\nrespectively. We are interested in how $(X_\\kappa,Y_\\kappa)$ \"appears\" to an\nefficient adversary that only views the transcript $T_\\kappa$. We make the\nfollowing contributions:\n  $\\bullet$ We develop new tools to argue about this loose notion and show\n(modulo some caveats) that for every such protocol $\\pi$, there exists an\nefficient simulator such that the following holds: on input $T_\\kappa$, the\nsimulator outputs a pair $(X'_\\kappa ,Y'_\\kappa)$ such that\n$(X'_\\kappa,Y'_\\kappa,T_\\kappa)$ is (somewhat) computationally\nindistinguishable from $(X_\\kappa,Y_\\kappa,T_\\kappa)$.\n  $\\bullet$ We use these tools to prove the following dichotomy theorem: every\nsuch protocol $\\pi$ is:\n  - either uncorrelated -- it is (somewhat) indistinguishable from an efficient\nprotocol whose parties interact to produce $T_\\kappa$, but then choose their\noutputs independently from some product distribution (that is determined in\npoly-time from $T_\\kappa$),\n  - or, the protocol implies a key-agreement protocol (for infinitely many\n$\\kappa$'s).\n  Uncorrelated protocols are uninteresting from a cryptographic viewpoint, as\nthe correlation between outputs is (computationally) trivial. Our dichotomy\nshows that every protocol is either completely uninteresting or implies\nkey-agreement.\n  $\\bullet$ We use the above dichotomy to make progress on open problems on\nminimal cryptographic assumptions required for differentially private\nmechanisms for the XOR function.\n  $\\bullet$ A subsequent work of Haitner et al. uses the above dichotomy to\nmakes progress on a longstanding open question regarding the complexity of fair\ntwo-party coin-flipping protocols.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 11:48:30 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 08:18:00 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Haitner", "Iftach", ""], ["Nissim", "Kobbi", ""], ["Omri", "Eran", ""], ["Shaltiel", "Ronen", ""], ["Silbak", "Jad", ""]]}, {"id": "2105.00770", "submitter": "Noam Mazor", "authors": "Iftach Haitner, Noam Mazor, Ronen Shaltiel, Jad Silbak", "title": "Channels of Small Log-Ratio Leakage and Characterization of Two-Party\n  Differentially Private Computation", "comments": "A preliminary version appeared in TCC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a PPT two-party protocol $\\pi=(A,B)$ in which the parties get no\nprivate inputs and obtain outputs $O^A,O^B\\in \\{0,1\\}$, and let $V^A$ and $V^B$\ndenote the parties' individual views. Protocol $\\pi$ has $\\alpha$-agreement if\n$Pr[O^A=O^B]=1/2+\\alpha$. The leakage of $\\pi$ is the amount of information a\nparty obtains about the event $\\{O^A=O^B\\}$; that is, the leakage $\\epsilon$ is\nthe maximum, over $P\\in\\{A,B\\}$, of the distance between $V^P|OA=OB$ and\n$V^P|OA\\neq OB$. Typically, this distance is measured in statistical distance,\nor, in the computational setting, in computational indistinguishability. For\nthis choice, Wullschleger [TCC 09] showed that if $\\alpha>>\\epsilon$ then the\nprotocol can be transformed into an OT protocol.\n  We consider measuring the protocol leakage by the log-ratio distance (which\nwas popularized by its use in the differential privacy framework). The\nlog-ratio distance between X,Y over domain \\Omega is the minimal $\\epsilon>0$\nfor which, for every $v\\in\\Omega$, $log(Pr[X=v]/Pr[Y=v])\\in\n[-\\epsilon,\\epsilon]$. In the computational setting, we use computational\nindistinguishability from having log-ratio distance $\\epsilon$. We show that a\nprotocol with (noticeable) accuracy $\\alpha\\in\\Omega(\\epsilon^2)$ can be\ntransformed into an OT protocol (note that this allows $\\epsilon>>\\alpha$). We\ncomplete the picture, in this respect, showing that a protocol with $\\alpha\\in\no(\\epsilon^2)$ does not necessarily imply OT. Our results hold for both the\ninformation theoretic and the computational settings, and can be viewed as a\n\"fine grained\" approach to \"weak OT amplification\".\n  We then use the above result to fully characterize the complexity of\ndifferentially private two-party computation for the XOR function, answering\nthe open question put by Goyal, Khurana, Mironov, Pandey, and Sahai [ICALP 16]\nand Haitner, Nissim, Omri, Shaltiel, and Silbak [FOCS 18].\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 11:55:00 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 12:44:32 GMT"}, {"version": "v3", "created": "Sun, 9 May 2021 12:40:40 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Haitner", "Iftach", ""], ["Mazor", "Noam", ""], ["Shaltiel", "Ronen", ""], ["Silbak", "Jad", ""]]}, {"id": "2105.00780", "submitter": "Iftach Haitner", "authors": "Iftach Haitner and Nikolaos Makriyannis and Eran Omri", "title": "On the Complexity of Fair Coin Flipping", "comments": "A preliminary version appeared in Theory of Cryptography Conference,\n  TCC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A two-party coin-flipping protocol is $\\epsilon$-fair if no efficient\nadversary can bias the output of the honest party (who always outputs a bit,\neven if the other party aborts) by more than $\\epsilon$. Cleve [STOC '86]\nshowed that $r$-round $o(1/r)$-fair coin-flipping protocols do not exist.\nAwerbuch, Blum, Chor, Goldwasser, and Micali[Manuscript '85] constructed a\n$\\Theta(1/\\sqrt{r})$-fair coin-flipping protocol, assuming the existence of\none-way functions. Moran, Naor, and Segev [Journal of Cryptology '16]\nconstructed an $r$-round coin-flipping protocol that is $\\Theta(1/r)$-fair\n(thus matching the aforementioned lower bound of Cleve [STOC '86]), assuming\nthe existence of oblivious transfer.\n  The above gives rise to the intriguing question of whether oblivious\ntransfer, or more generally ``public-key primitives,'' is required for an\n$o(1/\\sqrt r)$-fair coin flipping protocol. We make a different progress\ntowards answering the question by showing that, for any constant $r\\in \\N$, the\nexistence of an $1/(c\\cdot \\sqrt{r})$-fair, $r$-round coin-flipping protocol\nimplies the existence of an infinitely-often key-agreement protocol, where $c$\ndenotes some universal constant (independent of $r$). Our reduction is\n\\emph{non} black-box and makes a novel use of the recent dichotomy for\ntwo-party protocols of Haitner, Nissim, Omri, Shaltiel, and Silbak [FOCS '18]\nto facilitate a two-party variant of the recent attack of Beimel, Haitner,\nMakriyannis, and Omri [FOCS '18] on multi-party coin-flipping protocols.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 12:37:21 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Haitner", "Iftach", ""], ["Makriyannis", "Nikolaos", ""], ["Omri", "Eran", ""]]}, {"id": "2105.00801", "submitter": "Eliad Tsfadia", "authors": "Itay Berman, Iftach Haitner, Eliad Tsfadia", "title": "A Tight Parallel Repetition Theorem for Partially Simulatable\n  Interactive Arguments via Smooth KL-Divergence", "comments": "A preliminary version appeared in Crypto 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardness amplification is a central problem in the study of interactive\nprotocols. While ``natural'' parallel repetition transformation is known to\nreduce the soundness error of some special cases of interactive arguments:\nthree-message protocols and public-coin protocols, it fails to do so in the\ngeneral case.\n  The only known round-preserving approach that applies to all interactive\narguments is Haitner's random-terminating transformation [SICOMP '13], who\nshowed that the parallel repetition of the transformed protocol reduces the\nsoundness error at a weak exponential rate: if the original $m$-round protocol\nhas soundness error $1-p$, then the $n$-parallel repetition of its\nrandom-terminating variant has soundness error $(1-p)^{p n / m^4}$ (omitting\nconstant factors). Hastad et al. [TCC '10] have generalized this result to\npartially simulatable interactive arguments, showing that the $n$-fold\nrepetition of an $m$-round $\\delta$-simulatable argument of soundness error\n$1-p$ has soundness error $(1-p)^{p \\delta^2 n / m^2}$. When applied to\nrandom-terminating arguments, the Hastad et al. bound matches that of Haitner.\n  In this work we prove that parallel repetition of random-terminating\narguments reduces the soundness error at a much stronger exponential rate: the\nsoundness error of the $n$ parallel repetition is $(1-p)^{n / m}$, only an $m$\nfactor from the optimal rate of $(1-p)^n$ achievable in public-coin and\nthree-message arguments. The result generalizes to $\\delta$-simulatable\narguments, for which we prove a bound of $(1-p)^{\\delta n / m}$. This is\nachieved by presenting a tight bound on a relaxed variant of the KL-divergence\nbetween the distribution induced by our reduction and its ideal variant, a\nresult whose scope extends beyond parallel repetition proofs. We prove the\ntightness of the above bound for random-terminating arguments, by presenting a\nmatching protocol.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 12:59:01 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Berman", "Itay", ""], ["Haitner", "Iftach", ""], ["Tsfadia", "Eliad", ""]]}, {"id": "2105.00850", "submitter": "Eliad Tsfadia", "authors": "Iftach Haitner, Eliad Tsfadia", "title": "An Almost-Optimally Fair Three-Party Coin-Flipping Protocol", "comments": "Published in SIAM Journal on Computing (SICOMP) 2017. A preliminary\n  version appeared in STOC 2014. arXiv admin note: text overlap with\n  arXiv:2104.08820", "journal-ref": "SIAM Journal on Computing (SICOMP): Vol. 46, Issue 2, 479-542,\n  2017", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a multiparty fair coin-flipping protocol, the parties output a common\n(close to) unbiased bit, even when some corrupted parties try to bias the\noutput. Cleve [STOC 1986] has shown that in the case of dishonest majority\n(i.e., at least half of the parties can be corrupted), in any $m$-round\ncoin-flipping protocol the corrupted parties can bias the honest parties'\ncommon output bit by $\\Omega(\\frac1{m})$. For more than two decades the best\nknown coin-flipping protocols against dishonest majority had bias\n$\\Theta(\\frac{\\ell}{\\sqrt{m}})$, where $\\ell$ is the number of corrupted\nparties. This was changed by a recent breakthrough result of Moran et al. [TCC\n2009], who constructed an $m$-round, two-party coin-flipping protocol with\noptimal bias $\\Theta(\\frac1{m})$. In a subsequent work, Beimel et al. [Crypto\n2010] extended this result to the multiparty case in which less than $\\frac23$\nof the parties can be corrupted. Still for the case of $\\frac23$ (or more)\ncorrupted parties, the best known protocol had bias\n$\\Theta(\\frac{\\ell}{\\sqrt{m}})$. In particular, this was the state of affairs\nfor the natural three-party case.\n  We make a step towards eliminating the above gap, presenting an $m$-round,\nthree-party coin-flipping protocol, with bias $\\frac{O(\\log^3 m)}m$. Our\napproach (which we also apply for the two-party case) does not follow the\n\"threshold round\" paradigm used in the work of Moran et al. and Beimel et al.,\nbut rather is a variation of the majority protocol of Cleve, used to obtain the\naforementioned $\\Theta(\\frac{\\ell}{\\sqrt{m}})$-bias protocol.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 13:38:58 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 11:47:55 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Haitner", "Iftach", ""], ["Tsfadia", "Eliad", ""]]}, {"id": "2105.00962", "submitter": "Iftach Haitner", "authors": "Ran Cohen and Iftach Haitner and Eran Omri and Lior Rotem", "title": "From Fairness to Full Security in Multiparty Computation", "comments": "Preliminary version appeared in Conference on Security and\n  Cryptography for Networks, SCN 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the setting of secure multiparty computation (MPC), a set of mutually\ndistrusting parties wish to jointly compute a function, while guaranteeing the\nprivacy of their inputs and the correctness of the output. An MPC protocol is\ncalled \\emph{fully secure} if no adversary can prevent the honest parties from\nobtaining their outputs. A protocol is called \\emph{fair} if an adversary can\nprematurely abort the computation, however, only before learning any new\ninformation.\n  We present highly efficient transformations from fair computations to fully\nsecure computations, assuming the fraction of honest parties is constant (e.g.,\n$1\\%$ of the parties are honest). Compared to previous transformations that\nrequire linear invocations (in the number of parties) of the fair computation,\nour transformations require super-logarithmic, and sometimes even\nsuper-constant, such invocations. The main idea is to delegate the computation\nto chosen random committees that invoke the fair computation. Apart from the\nbenefit of uplifting security, the reduction in the number of parties is also\nuseful, since only committee members are required to work, whereas the\nremaining parties simply \"listen\" to the computation over a broadcast channel.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 16:00:22 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 06:30:48 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Cohen", "Ran", ""], ["Haitner", "Iftach", ""], ["Omri", "Eran", ""], ["Rotem", "Lior", ""]]}, {"id": "2105.01242", "submitter": "Joseph Jaeger", "authors": "Joseph Jaeger and Fang Song and Stefano Tessaro", "title": "Quantum Key-length Extension", "comments": "26 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Should quantum computers become available, they will reduce the effective key\nlength of basic secret-key primitives, such as blockciphers. To address this we\nwill either need to use blockciphers which inherently have longer keys or use\nkey-length extension techniques which employ a blockcipher to construct a more\nsecure blockcipher that uses longer keys.\n  We consider the latter approach by analyzing the security of the FX and\ndouble encryption constructions. Classically, FX is known to be secure, while\ndouble encryption is no more secure than single encryption due to a\nmeet-in-the-middle attack. We provide positive results, with concrete and tight\nbounds, for both of these constructions against quantum attackers in ideal\nmodels.\n  For FX, we consider security in the \"Q1 model,\" a natural model in which the\nattacker has quantum access to the ideal primitive, but only classic access to\nFX. We provide two partial results in this model. The first establishes the\nsecurity of FX against non-adaptive attackers. The second establishes fully\nadaptive security when considering a variant of FX using a random oracle in\nplace of an ideal cipher. This result relies on the techniques of Zhandry\n(CRYPTO '19) for lazily sampling a quantum random oracle and are thus hard to\nextend to the true FX construction because it is unknown if a quantum random\npermutation can be lazily sampled. To the best of our knowledge, this result\nalso is the first to introduce techniques to handle Q1 security in ideal models\nwithout analyzing the classical and quantum oracles separately, which may be of\nbroader interest.\n  For double encryption we apply a technique of Tessaro and Thiruvengadam (TCC\n'18) to establish that security reduces to the difficulty of solving the list\ndisjointness problem, which we are able to reduce through a chain of results to\nthe known quantum difficulty of the element distinctness problem.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 01:40:42 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Jaeger", "Joseph", ""], ["Song", "Fang", ""], ["Tessaro", "Stefano", ""]]}, {"id": "2105.01262", "submitter": "Dajiang Suo", "authors": "Dajiang Suo, M. Elena Renda, and Jinhua Zhao", "title": "Quantifying the Tradeoff Between Cybersecurity and Location Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous data breaches that occurred in the mobility sector, such as Uber's\ndata leakage in 2016, lead to privacy concerns over confidentiality and the\npotential abuse of customer data. To protect customer privacy, location-based\nservice (LBS) providers may have the motivation to adopt privacy preservation\nmechanisms, such as obfuscating data from vehicles or mobile through a trusted\ndata server. However, the efforts for protecting privacy might be in conflict\nwith those for detecting malicious behaviors or misbehaviors by drivers. The\nreason is that the accuracy of data about vehicle locations and trajectory is\ncrucial in determining whether a vehicle trip is fabricated by adversaries,\nespecially when machine learning methods are adopted by LBS for this purpose.\nThis paper tackles this dilemma situation by evaluating the tradeoff between\nlocation privacy and security. Specifically, vehicle trips are obfuscated with\n2D Laplace noise that meets the requirement of differential privacy. The\nobfuscated vehicle trips are then fed into a benchmark Recurrent Neural Network\n(RNN) that is widely used for detecting anomalous trips. This allows us to\ninvestigate the influence of the privacy-preservation technique on model\nperformance. The experiment results suggest that applying Laplace mechanism to\nachieve high-level of differential privacy in the context of location-based\nvehicle trips will result in low true-positive or high false-negative rate by\nthe RNN, which is reflected in the area under the curve scores (less than 0.7),\nwhich diminishes the value of RNN as more anomalous trips will be classified as\nnormal ones.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 03:03:24 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Suo", "Dajiang", ""], ["Renda", "M. Elena", ""], ["Zhao", "Jinhua", ""]]}, {"id": "2105.01281", "submitter": "Chengliang Zhang Dr", "authors": "Chengliang Zhang, Junzhe Xia, Baichen Yang, Huancheng Puyang, Wei\n  Wang, Ruichuan Chen, Istemi Ekin Akkus, Paarijaat Aditya, Feng Yan", "title": "Citadel: Protecting Data Privacy and Model Confidentiality for\n  Collaborative Learning with SGX", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancement of machine learning (ML) and its growing awareness, many\norganizations who own data but not ML expertise (data owner) would like to pool\ntheir data and collaborate with those who have expertise but need data from\ndiverse sources to train truly generalizable models (model owner). In such\ncollaborative ML, the data owner wants to protect the privacy of its training\ndata, while the model owner desires the confidentiality of the model and the\ntraining method which may contain intellectual properties. However, existing\nprivate ML solutions, such as federated learning and split learning, cannot\nmeet the privacy requirements of both data and model owners at the same time.\n  This paper presents Citadel, a scalable collaborative ML system that protects\nthe privacy of both data owner and model owner in untrusted infrastructures\nwith the help of Intel SGX. Citadel performs distributed training across\nmultiple training enclaves running on behalf of data owners and an aggregator\nenclave on behalf of the model owner. Citadel further establishes a strong\ninformation barrier between these enclaves by means of zero-sum masking and\nhierarchical aggregation to prevent data/model leakage during collaborative\ntraining. Compared with the existing SGX-protected training systems, Citadel\nenables better scalability and stronger privacy guarantees for collaborative\nML. Cloud deployment with various ML models shows that Citadel scales to a\nlarge number of enclaves with less than 1.73X slowdown caused by SGX.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 04:17:29 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Zhang", "Chengliang", ""], ["Xia", "Junzhe", ""], ["Yang", "Baichen", ""], ["Puyang", "Huancheng", ""], ["Wang", "Wei", ""], ["Chen", "Ruichuan", ""], ["Akkus", "Istemi Ekin", ""], ["Aditya", "Paarijaat", ""], ["Yan", "Feng", ""]]}, {"id": "2105.01316", "submitter": "Jack Tanner", "authors": "Jack Tanner, Roshaan Khan", "title": "Technology Review of Blockchain Data Privacy Solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This objective of this report is to review existing enterprise blockchain\ntechnologies - EOSIO powered systems, Hyperledger Fabric and Besu, Consensus\nQuorum, R3 Corda and Ernst and Young's Nightfall - that provide data privacy\nwhile leveraging the data integrity benefits of blockchain. By reviewing and\ncomparing how and how well these technologies achieve data privacy, a snapshot\nis captured of the industry's current best practices and data privacy models.\nMajor enterprise technologies are contrasted in parallel to EOSIO to better\nunderstand how EOSIO can evolve to meet the trends seen in enterprise\nblockchain privacy. The following strategies and trends were generally observed\nin these technologies:\n  Cryptography: the hashing algorithm was found to be the most used\ncryptographic primitive in enterprise or changeover privacy solutions.\nCoordination via on-chain contracts - a common strategy was to use a shared\npublicly ledger to coordinate data privacy groups and more generally managed\nidentities and access control.\n  Transaction and contract code sharing: there was a variety of different\nlevels of privacy around the business logic (smart contract code) visibility.\nSome solutions only allowed authorised peers to view code while others made\nthis accessible to everybody that was a member of the shared ledger.\n  Data migrations for data privacy applications: significant challenges exist\nwhen using cryptographically stored data in terms of being able to run system\nupgrades.\n  Multiple blockchain ledgers for data privacy: solutions attempted to create a\nnew private blockchain for every private data relationship which was eventually\nabandoned in favour of one shared ledger with private data\ncollections/transactions that were anchored to the ledger with a hash in order\nto improve scaling.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 06:56:42 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Tanner", "Jack", ""], ["Khan", "Roshaan", ""]]}, {"id": "2105.01324", "submitter": "Aleksey Fedorov", "authors": "S.E. Yunakovsky, M. Kot, N.O. Pozhar, D. Nabokov, M.A. Kudinov, A.\n  Guglya, E.O. Kiktenko, E. Kolycheva, A. Borisov, and A.K. Fedorov", "title": "Towards security recommendations for public-key infrastructures for\n  production environments in the post-quantum era", "comments": "24 pages, 1 figure", "journal-ref": "EPJ Quantum Technol. 8, 14 (2021)", "doi": "10.1140/epjqt/s40507-021-00104-z", "report-no": null, "categories": "quant-ph cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing technologies pose a significant threat to the currently\nemployed public-key cryptography protocols. In this paper, we discuss the\nimpact of the quantum threat on public key infrastructures (PKIs), which are\nused as a part of security systems for protecting production environments. We\nanalyze security issues of existing models with a focus on requirements for a\nfast transition to post-quantum solutions. Although our primary focus is on the\nattacks with quantum computing, we also discuss some security issues that are\nnot directly related to the used cryptographic algorithms but are essential for\nthe overall security of the PKI. We attempt to provide a set of security\nrecommendations regarding the PKI from the viewpoints of attacks with quantum\ncomputers.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 07:11:57 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 07:45:29 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Yunakovsky", "S. E.", ""], ["Kot", "M.", ""], ["Pozhar", "N. O.", ""], ["Nabokov", "D.", ""], ["Kudinov", "M. A.", ""], ["Guglya", "A.", ""], ["Kiktenko", "E. O.", ""], ["Kolycheva", "E.", ""], ["Borisov", "A.", ""], ["Fedorov", "A. K.", ""]]}, {"id": "2105.01347", "submitter": "Adit Goyal", "authors": "Vikas Hassija (1), Vinay Chamola (Senior Member IEEE and Department of\n  Electrical and Electronics Engineering & APPCAIR, BITS-Pilani, Pilani\n  Campus), Adhar Agrawal (1), Adit Goyal (1), Nguyen Cong Luong (Faculty of\n  Information Technology, PHENIKAA University, Hanoi 12116, Vietnam and\n  PHENIKAA Research and Technology Institute (PRATI), A&A Green Phoenix Group\n  JSC, Hanoi, Vietnam), Dusit Niyato (Fellow IEEE and School of Computer\n  Science and Engineering, Nanyang Technological University, Singapore), F.\n  Richard Yu (Fellow IEEE and Department of Systems and Computer Engineering,\n  Carleton University, Ottawa, Canada) and Mohsen Guizani (Fellow IEEE and\n  Computer Science and Engineering Department, Qatar University, Qatar) ((1)\n  Department of Computer Science and IT, Jaypee Institute of Information\n  Technology, Noida, India)", "title": "Fast, Reliable, and Secure Drone Communication: A Comprehensive Survey", "comments": "31 pages, 12 Figures, Submitted to IEEE Communications Surveys and\n  Tutorials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Drone security is currently a major topic of discussion among researchers and\nindustrialists. Although there are multiple applications of drones, if the\nsecurity challenges are not anticipated and required architectural changes are\nnot made, the upcoming drone applications will not be able to serve their\nactual purpose. Therefore, in this paper, we present a detailed review of the\nsecurity-critical drone applications, and security-related challenges in drone\ncommunication such as DoS attacks, Man-in-the-middle attacks, De-Authentication\nattacks, and so on. Furthermore, as part of solution architectures, the use of\nBlockchain, Software Defined Networks (SDN), Machine Learning, and Fog/Edge\ncomputing are discussed as these are the most emerging technologies. Drones are\nhighly resource-constrained devices and therefore it is not possible to deploy\nheavy security algorithms on board. Blockchain can be used to cryptographically\nstore all the data that is sent to/from the drones, thereby saving it from\ntampering and eavesdropping. Various ML algorithms can be used to detect\nmalicious drones in the network and to detect safe routes. Additionally, the\nSDN technology can be used to make the drone network reliable by allowing the\ncontroller to keep a close check on data traffic, and fog computing can be used\nto keep the computation capabilities closer to the drones without overloading\nthem.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 07:54:52 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Hassija", "Vikas", "", "Senior Member IEEE and Department of\n  Electrical and Electronics Engineering & APPCAIR, BITS-Pilani, Pilani\n  Campus"], ["Chamola", "Vinay", "", "Senior Member IEEE and Department of\n  Electrical and Electronics Engineering & APPCAIR, BITS-Pilani, Pilani\n  Campus"], ["Agrawal", "Adhar", "", "Faculty of\n  Information Technology, PHENIKAA University, Hanoi 12116, Vietnam and\n  PHENIKAA Research and Technology Institute"], ["Goyal", "Adit", "", "Faculty of\n  Information Technology, PHENIKAA University, Hanoi 12116, Vietnam and\n  PHENIKAA Research and Technology Institute"], ["Luong", "Nguyen Cong", "", "Faculty of\n  Information Technology, PHENIKAA University, Hanoi 12116, Vietnam and\n  PHENIKAA Research and Technology Institute"], ["Niyato", "Dusit", "", "Fellow IEEE and School of Computer\n  Science and Engineering, Nanyang Technological University, Singapore"], ["Yu", "F. Richard", "", "Fellow IEEE and Department of Systems and Computer Engineering,\n  Carleton University, Ottawa, Canada"], ["Guizani", "Mohsen", "", "Fellow IEEE and\n  Computer Science and Engineering Department, Qatar University, Qatar"]]}, {"id": "2105.01350", "submitter": "Onur G\\\"unl\\\"u Dr.-Ing.", "authors": "Onur G\\\"unl\\\"u and Ueli Maurer and Jo\\~ao Ribeiro", "title": "Effects of Quantization on the Multiple-Round Secret-Key Capacity", "comments": "Submitted to IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR eess.SP math.IT math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the strong secret key (SK) agreement problem for the satellite\ncommunication setting, where a remote source (a satellite) chooses a common\nbinary phase shift keying (BPSK) modulated input for three statistically\nindependent additive white Gaussian noise (AWGN) channels whose outputs are\nobserved by, respectively, two legitimate receivers (Alice and Bob) and an\neavesdropper (Eve). Legitimate receivers have access to an authenticated,\nnoiseless, two-way, and public communication link, so they can exchange\nmultiple rounds of public messages to agree on a SK hidden from Eve. Without\nloss of essential generality, the noise variances for Alice's and Bob's\nmeasurement channels are both fixed to a value $Q>1$, whereas the noise over\nEve's measurement channel has a unit variance, so $Q$ represents a channel\nquality ratio. The significant and not necessarily expected effect of\nquantizations at all receivers on the scaling of the SK capacity with respect\nto a sufficiently large and finite channel quality ratio $Q$ is illustrated by\nshowing 1) the achievability of a constant SK for any finite BPSK modulated\nsatellite output by proposing a thresholding algorithm as an advantage\ndistillation protocol for AWGN channels and 2) the converse (i.e.,\nunachievability) bound for the case when all receivers apply a one-bit uniform\nquantizer to their noisy observations before SK agreement, for which the SK\ncapacity is shown to decrease quadratically in $Q$. Our results prove that soft\ninformation increases not only the reliability and the achieved SK rate but\nalso the scaling of the SK capacity at least quadratically in $Q$ as compared\nto hard information.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 07:58:06 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 07:52:47 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["G\u00fcnl\u00fc", "Onur", ""], ["Maurer", "Ueli", ""], ["Ribeiro", "Jo\u00e3o", ""]]}, {"id": "2105.01400", "submitter": "Iftach Haitner", "authors": "Itay Berman and Iftach Haitner and Aris Tentes", "title": "Coin Flipping of \\emph{Any} Constant Bias Implies One-Way Functions", "comments": "This is the final draft of this paper. The full version was published\n  in the Journal of the ACM 2018. An extended abstract of this work appeared in\n  the proceedings of STOC 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the existence of a coin-flipping protocol safe against\n\\emph{any} non-trivial constant bias (\\eg $.499$) implies the existence of\none-way functions. This improves upon a recent result of Haitner and Omri [FOCS\n'11], who proved this implication for protocols with bias $\\frac{\\sqrt2 -1}2 -\no(1) \\approx .207$. Unlike the result of Haitner and Omri, our result also\nholds for \\emph{weak} coin-flipping protocols.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 10:26:22 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Berman", "Itay", ""], ["Haitner", "Iftach", ""], ["Tentes", "Aris", ""]]}, {"id": "2105.01401", "submitter": "Pierre-Alain Mo\\\"ellic", "authors": "Rapha\\\"el Joud, Pierre-Alain Moellic, R\\'emi Bernhard, Jean-Baptiste\n  Rigaud", "title": "A Review of Confidentiality Threats Against Embedded Neural Network\n  Models", "comments": "Accepted at 7th IEEE World Forum on Internet of Things (2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Utilization of Machine Learning (ML) algorithms, especially Deep Neural\nNetwork (DNN) models, becomes a widely accepted standard in many domains more\nparticularly IoT-based systems. DNN models reach impressive performances in\nseveral sensitive fields such as medical diagnosis, smart transport or security\nthreat detection, and represent a valuable piece of Intellectual Property. Over\nthe last few years, a major trend is the large-scale deployment of models in a\nwide variety of devices. However, this migration to embedded systems is slowed\ndown because of the broad spectrum of attacks threatening the integrity,\nconfidentiality and availability of embedded models. In this review, we cover\nthe landscape of attacks targeting the confidentiality of embedded DNN models\nthat may have a major impact on critical IoT systems, with a particular focus\non model extraction and data leakage. We highlight the fact that Side-Channel\nAnalysis (SCA) is a relatively unexplored bias by which model's confidentiality\ncan be compromised. Input data, architecture or parameters of a model can be\nextracted from power or electromagnetic observations, testifying a real need\nfrom a security point of view.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 10:27:20 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Joud", "Rapha\u00ebl", ""], ["Moellic", "Pierre-Alain", ""], ["Bernhard", "R\u00e9mi", ""], ["Rigaud", "Jean-Baptiste", ""]]}, {"id": "2105.01403", "submitter": "Pierre-Alain Mo\\\"ellic", "authors": "Mathieu Dumont, Pierre-Alain Moellic, Raphael Viera, Jean-Max\n  Dutertre, R\\'emi Bernhard", "title": "An Overview of Laser Injection against Embedded Neural Network Models", "comments": "Accepted at 7th IEEE World Forum on Internet of Things (2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many IoT domains, Machine Learning and more particularly Deep Learning\nbrings very efficient solutions to handle complex data and perform challenging\nand mostly critical tasks. However, the deployment of models in a large variety\nof devices faces several obstacles related to trust and security. The latest is\nparticularly critical since the demonstrations of severe flaws impacting the\nintegrity, confidentiality and accessibility of neural network models. However,\nthe attack surface of such embedded systems cannot be reduced to abstract flaws\nbut must encompass the physical threats related to the implementation of these\nmodels within hardware platforms (e.g., 32-bit microcontrollers). Among\nphysical attacks, Fault Injection Analysis (FIA) are known to be very powerful\nwith a large spectrum of attack vectors. Most importantly, highly focused FIA\ntechniques such as laser beam injection enable very accurate evaluation of the\nvulnerabilities as well as the robustness of embedded systems. Here, we propose\nto discuss how laser injection with state-of-the-art equipment, combined with\ntheoretical evidences from Adversarial Machine Learning, highlights worrying\nthreats against the integrity of deep learning inference and claims that join\nefforts from the theoretical AI and Physical Security communities are a urgent\nneed.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 10:32:30 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Dumont", "Mathieu", ""], ["Moellic", "Pierre-Alain", ""], ["Viera", "Raphael", ""], ["Dutertre", "Jean-Max", ""], ["Bernhard", "R\u00e9mi", ""]]}, {"id": "2105.01409", "submitter": "Iftach Haitner", "authors": "Itay Berman and Iftach Haitner and Ilan Komargodski and Moni Naor", "title": "Hardness-Preserving Reductions via Cuckoo Hashing", "comments": "This is the final draft of this paper. The full version was published\n  in the Journal of Cryptology 2019. An extended abstract of this work appeared\n  in the Theory of Cryptography Conference (TCC) 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The focus of this work is \\emph{hardness-preserving} transformations of\nsomewhat limited pseudorandom functions families (PRFs) into ones with more\nversatile characteristics. Consider the problem of \\emph{domain extension} of\npseudorandom functions: given a PRF that takes as input elements of some domain\n$U$, we would like to come up with a PRF over a larger domain. Can we do it\nwith little work and without significantly impacting the security of the\nsystem? One approach is to first hash the larger domain into the smaller one\nand then apply the original PRF. Such a reduction, however, is vulnerable to a\n\"birthday attack\": after $\\sqrt{\\size{U}}$ queries to the resulting PRF, a\ncollision (\\ie two distinct inputs having the same hash value) is very likely\nto occur. As a consequence, the resulting PRF is \\emph{insecure} against an\nattacker making this number of queries. In this work we show how to go beyond\nthe aforementioned birthday attack barrier by replacing the above simple\nhashing approach with a variant of \\textit{cuckoo hashing}, a hashing paradigm\nthat resolves collisions in a table by using two hash functions and two tables,\ncleverly assigning each element to one of the two tables. We use this approach\nto obtain: (i) a domain extension method that requires {\\em just two calls} to\nthe original PRF, can withstand as many queries as the original domain size,\nand has a distinguishing probability that is exponentially small in the amount\nof non-cryptographic work; and (ii) a {\\em security-preserving} reduction from\nnon-adaptive to adaptive PRFs.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 10:42:38 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Berman", "Itay", ""], ["Haitner", "Iftach", ""], ["Komargodski", "Ilan", ""], ["Naor", "Moni", ""]]}, {"id": "2105.01417", "submitter": "Iftach Haitner", "authors": "Iftach Haitner and Jonathan J. Hoch and Omer Reingold and Gil Segev", "title": "Finding Collisions in Interactive Protocols -- Tight Lower Bounds on the\n  Round and Communication Complexities of Statistically Hiding Commitments", "comments": "The full version was published in the SIAM Journal on Computing 2015.\n  Extended abstracts of this work appeared in the Annual Symposium on\n  Foundations of Computer Science (FOCS) 2007 and in the Theory of Cryptography\n  Conference (TCC) 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the round and communication complexities of various cryptographic\nprotocols. We give tight lower bounds on the round and communication\ncomplexities of any fully black-box reduction of a statistically hiding\ncommitment scheme from one-way permutations, and from trapdoor permutations. As\na corollary, we derive similar tight lower bounds for several other\ncryptographic protocols, such as single-server private information retrieval,\ninteractive hashing, and oblivious transfer that guarantees statistical\nsecurity for one of the parties. Our techniques extend the collision-finding\noracle due to Simon (EUROCRYPT '98) to the setting of interactive protocols and\nthe reconstruction paradigm of Gennaro and Trevisan (FOCS '00).\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 11:04:11 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Haitner", "Iftach", ""], ["Hoch", "Jonathan J.", ""], ["Reingold", "Omer", ""], ["Segev", "Gil", ""]]}, {"id": "2105.01448", "submitter": "Ozan Alp Topal", "authors": "Ozan Alp Topal, Gunes Karabulut Kurt, Halim Yanikomeroglu", "title": "Securing the Inter-Spacecraft Links: Physical Layer Key Generation from\n  Doppler Frequency Shift", "comments": "arXiv admin note: text overlap with arXiv:2008.13396", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we propose a secret key generation procedure specifically\ndesigned for the inter-spacecraft communication links. As a novel secrecy\nsource, the spacecrafts utilize Doppler frequency shift based measurements. In\nthis way, the mobilities of the communication devices are exploited to generate\nsecret keys, where this resource can be utilized in the environments that the\nchannel fading based key generation methods are not available. The mobility of\na spacecraft is modeled as the superposition of a pre-determined component and\na dynamic component. We derive the maximum achievable secret key generation\nrate from the Doppler frequency shift. The proposed secret key generation\nprocedure extracts the Doppler frequency shift in the form of nominal power\nspectral density samples (NPSDS). We propose a maximum-likelihood (ML)\nestimation for the NPSDS at the spacecrafts, then a uniform quantizer is\nutilized to obtain secret key bits. The key disagreement rate (KDR) is\nanalytically obtained for the proposed key generation procedure. Through\nnumerical studies, the tightness of the provided approximations is shown. Both\nthe theoretical and numerical results demonstrate the validity and the\npracticality of the presented physical layer key generation procedure\nconsidering the security of the communication links of spacecrafts.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 12:15:44 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Topal", "Ozan Alp", ""], ["Kurt", "Gunes Karabulut", ""], ["Yanikomeroglu", "Halim", ""]]}, {"id": "2105.01459", "submitter": "Iftach Haitner", "authors": "Iftach Haitner and Thomas Holenstein and Omer Reingold and Salil\n  Vadhan and Hoeteck Wee", "title": "Inaccessible Entropy II: IE Functions and Universal One-Way Hashing", "comments": "This is the final draft of this paper. The full version was published\n  in the Theory of Computing 2020. An extended abstract of this work appeared\n  appeared as \"Universal One-Way Hash Functions via Inaccessible Entropy\" in\n  Eurocrypt 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper uses a variant of the notion of \\emph{inaccessible entropy}\n(Haitner, Reingold, Vadhan and Wee, STOC 2009), to give an alternative\nconstruction and proof for the fundamental result, first proved by Rompel (STOC\n1990), that \\emph{Universal One-Way Hash Functions (UOWHFs)} can be based on\nany one-way functions. We observe that a small tweak of any one-way function\n$f$ is already a weak form of a UOWHF: consider the function $F(x,i)$ that\nreturns the $i$-bit-long prefix of $f(x)$. If $F$ were a UOWHF then given a\nrandom $x$ and $i$ it would be hard to come up with $x'\\neq x$ such that\n$F(x,i)=F(x',i)$. While this may not be the case, we show (rather easily) that\nit is hard to sample $x'$ with almost full entropy among all the possible such\nvalues of $x'$. The rest of our construction simply amplifies and exploits this\nbasic property.Combined with other recent work, the construction of three\nfundamental cryptographic primitives (Pseudorandom Generators, Statistically\nHiding Commitments and UOWHFs) out of one-way functions is now to a large\nextent unified. In particular, all three constructions rely on and manipulate\ncomputational notions of entropy in similar ways. Pseudorandom Generators rely\non the well-established notion of pseudoentropy, whereas Statistically Hiding\nCommitments and UOWHFs rely on the newer notion of inaccessible entropy.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 12:40:53 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Haitner", "Iftach", ""], ["Holenstein", "Thomas", ""], ["Reingold", "Omer", ""], ["Vadhan", "Salil", ""], ["Wee", "Hoeteck", ""]]}, {"id": "2105.01622", "submitter": "Nicholas Carlini", "authors": "Nicholas Carlini", "title": "Poisoning the Unlabeled Dataset of Semi-Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised machine learning models learn from a (small) set of labeled\ntraining examples, and a (large) set of unlabeled training examples.\nState-of-the-art models can reach within a few percentage points of\nfully-supervised training, while requiring 100x less labeled data.\n  We study a new class of vulnerabilities: poisoning attacks that modify the\nunlabeled dataset. In order to be useful, unlabeled datasets are given strictly\nless review than labeled datasets, and adversaries can therefore poison them\neasily. By inserting maliciously-crafted unlabeled examples totaling just 0.1%\nof the dataset size, we can manipulate a model trained on this poisoned dataset\nto misclassify arbitrary examples at test time (as any desired label). Our\nattacks are highly effective across datasets and semi-supervised learning\nmethods.\n  We find that more accurate methods (thus more likely to be used) are\nsignificantly more vulnerable to poisoning attacks, and as such better training\nmethods are unlikely to prevent this attack. To counter this we explore the\nspace of defenses, and propose two methods that mitigate our attack.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 16:55:20 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Carlini", "Nicholas", ""]]}, {"id": "2105.01632", "submitter": "Chike Abuah", "authors": "Chike Abuah, David Darais, Joseph P. Near", "title": "Solo: Enforcing Differential Privacy Without Fancy Types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  All current approaches for statically enforcing differential privacy in\nhigher order languages make use of either linear or relational refinement\ntypes. A barrier to adoption for these approaches is the lack of support for\nexpressing these \"fancy types\" in mainstream programming languages. For\nexample, no mainstream language supports relational refinement types, and\nalthough Rust and modern versions of Haskell both employ some linear typing\ntechniques, they are inadequate for embedding enforcement of differential\nprivacy, which requires \"full\" linear types a la Girard/Reynolds. We propose a\nnew type system that enforces differential privacy, avoids the use of linear\nand relational refinement types, and can be easily embedded in mainstream\nrichly typed programming languages such as Scala, OCaml and Haskell. We\ndemonstrate such an embedding in Haskell, demonstrate its expressiveness on\ncase studies, and prove that our type-based enforcement of differential privacy\nis sound.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 17:18:16 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Abuah", "Chike", ""], ["Darais", "David", ""], ["Near", "Joseph P.", ""]]}, {"id": "2105.01651", "submitter": "Shuyuan Zheng", "authors": "Shuyuan Zheng, Yang Cao, Masatoshi Yoshikawa", "title": "Trading Data with Personalized Differential Privacy and Partial\n  Arbitrage Freeness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing trend regarding perceiving personal data as a commodity.\nExisting studies have built frameworks and theories about how to determine an\narbitrage-free price of a given query according to the privacy loss quantified\nby differential privacy. However, those previous works have assumed that data\nbuyers can purchase query answers with the arbitrary privacy loss of data\nowners, which may not be valid under strict privacy regulations such as GDPR\nand the increasing privacy concerns of data owners. In this paper, we study how\nto empower data owners with the control of privacy loss in regard to data\ntrading. First, we propose a modularized framework for trading personal data\nthat enables each data owner to bound her personalized privacy loss from data\ntrading. Second, since bounded privacy losses indicate bounded utilities of\nquery answers, we propose a reasonable relaxation of arbitrage freeness named\npartial arbitrage freeness, i.e., the guarantee of arbitrage-free pricing only\nfor a limited range of utilities, which provides more possibilities for our\nmarket design. Third, to avoid arbitrage behaviors, we propose a general method\nfor ensuring arbitrage freeness under personalized differential privacy.\nFourth, to make full use of data owners' personalized privacy loss bounds, we\npropose online privacy budget allocation techniques to dynamically allocate\nprivacy losses for queries under arbitrage freeness.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 17:53:30 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Zheng", "Shuyuan", ""], ["Cao", "Yang", ""], ["Yoshikawa", "Masatoshi", ""]]}, {"id": "2105.01762", "submitter": "Arseni Kalma", "authors": "Shlomi Dolev and Arseni Kalma", "title": "Verifiable Computing Using Computation Fingerprints Within FHE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest using Fully Homomorphic Encryption (FHE) to be used, not only to\nkeep the privacy of information but also, to verify computations with no\nadditional significant overhead, using only part of the variables length for\nverification. This method supports the addition of encrypted values as well as\nmultiplication of encrypted values by the addition of their logarithmic\nrepresentations and is based on a separation between hardware functionalities.\nThe computer/server performs blackbox additions and is based on the separation\nof server/device/hardware, such as the enclave, that may deal with additions of\nlogarithmic values and exponentiation. The main idea is to restrict the\ncomputer operations and to use part of the variable for computation\nverification (computation fingerprints) and the other for the actual\ncalculation. The verification part holds the FHE value, of which the calculated\nresult is known (either due to computing locally once or from previous verified\ncomputations) and will be checked against the returned FHE value. We prove that\na server with bit computation granularity can return consistent encrypted wrong\nresults even when the public key is not provided. For the case of computer word\ngranularity the verification and the actual calculation parts are separated,\nthe verification part (the consecutive bits from the LSB to the MSB of the\nvariables) is fixed across all input vectors. We also consider the case of\nSingle Instruction Multiple Data (SIMD) where the computation fingerprints\nindex in the input vectors is fixed across all vectors.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 21:03:06 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Dolev", "Shlomi", ""], ["Kalma", "Arseni", ""]]}, {"id": "2105.01815", "submitter": "Carlos Perez-Delgado", "authors": "Joseph J. Kearney, Carlos A. Perez-Delgado", "title": "Vulnerability of Blockchain Technologies to Quantum Attacks", "comments": "16 pages", "journal-ref": "Array, 10:100065, 2021", "doi": "10.1016/j.array.2021.100065", "report-no": null, "categories": "quant-ph cs.CR cs.CY cs.ET", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quantum computation represents a threat to many cryptographic protocols in\noperation today. It has been estimated that by 2035, there will exist a quantum\ncomputer capable of breaking the vital cryptographic scheme RSA2048. Blockchain\ntechnologies rely on cryptographic protocols for many of their essential\nsub-routines. Some of these protocols, but not all, are open to quantum\nattacks. Here we analyze the major blockchain-based cryptocurrencies deployed\ntoday -- including Bitcoin, Ethereum, Litecoin and ZCash, and determine their\nrisk exposure to quantum attacks. We finish with a comparative analysis of the\nstudied cryptocurrencies and their underlying blockchain technologies and their\nrelative levels of vulnerability to quantum attacks.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 01:01:42 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Kearney", "Joseph J.", ""], ["Perez-Delgado", "Carlos A.", ""]]}, {"id": "2105.01821", "submitter": "Carlos Perez-Delgado", "authors": "Dan A. Bard, Joseph J. Kearney, Carlos A. Perez-Delgado", "title": "Quantum Advantage on Proof of Work", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR cs.CY cs.ET cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Proof-of-Work (PoW) is a fundamental underlying technology behind most major\nblockchain cryptocurrencies. It has been previously pointed out that quantum\ndevices provide a computational advantage in performing PoW in the context of\nBitcoin. Here we make the case that this quantum advantage extends not only to\nall existing PoW mechanisms, but to any possible PoW as well. This has strong\nconsequences regarding both quantum-based attacks on the integrity of the\nentirety of the blockchain, as well as more legitimate uses of quantum\ncomputation for the purpose of mining Bitcoin and other cryptocurrencies. For\nthe first case, we estimate when these quantum attacks will become feasible,\nfor various cryptocurrencies, and discuss the impact of such attacks. For the\nlatter, we derive a precise formula to calculate the economic incentive for\nswitching to quantum-based cryptocurrency miners. Using this formula, we\nanalyze several test scenarios, and conclude that investing in quantum hardware\nfor cryptocurrency mining has the potential to pay off immensely.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 01:27:31 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Bard", "Dan A.", ""], ["Kearney", "Joseph J.", ""], ["Perez-Delgado", "Carlos A.", ""]]}, {"id": "2105.01827", "submitter": "Qiao Zhang", "authors": "Qiao Zhang, Chunsheng Xin, and Hongyi Wu", "title": "GALA: Greedy ComputAtion for Linear Algebra in Privacy-Preserved Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning as a Service (MLaaS) is enabling a wide range of smart\napplications on end devices. However, privacy-preserved computation is still\nexpensive. Our investigation has found that the most time-consuming component\nof the HE-based linear computation is a series of Permutation (Perm) operations\nthat are imperative for dot product and convolution in privacy-preserved MLaaS.\nTo this end, we propose GALA: Greedy computAtion for Linear Algebra in\nprivacy-preserved neural networks, which views the HE-based linear computation\nas a series of Homomorphic Add, Mult and Perm operations and chooses the least\nexpensive operation in each linear computation step to reduce the overall cost.\nGALA makes the following contributions: (1) It introduces a row-wise weight\nmatrix encoding and combines the share generation that is needed for the\nGC-based nonlinear computation, to reduce the Perm operations for the dot\nproduct; (2) It designs a first-Add-second-Perm approach (named kernel\ngrouping) to reduce Perm operations for convolution. As such, GALA efficiently\nreduces the cost for the HE-based linear computation, which is a critical\nbuilding block in almost all of the recent frameworks for privacy-preserved\nneural networks, including GAZELLE (Usenix Security'18), DELPHI (Usenix\nSecurity'20), and CrypTFlow2 (CCS'20). With its deep optimization of the\nHE-based linear computation, GALA can be a plug-and-play module integrated into\nthese systems to further boost their efficiency. Our experiments show that it\nachieves a significant speedup up to 700x for the dot product and 14x for the\nconvolution computation under different data dimensions. Meanwhile, GALA\ndemonstrates an encouraging runtime boost by 2.5x, 2.7x, 3.2x, 8.3x, 7.7x, and\n7.5x over GAZELLE and 6.5x, 6x, 5.7x, 4.5x, 4.2x, and 4.1x over CrypTFlow2, on\nAlexNet, VGG, ResNet-18, ResNet-50, ResNet-101, and ResNet-152, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 01:53:25 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Zhang", "Qiao", ""], ["Xin", "Chunsheng", ""], ["Wu", "Hongyi", ""]]}, {"id": "2105.01860", "submitter": "Harshad Sathaye", "authors": "Harshad Sathaye, Gerald LaMountain, Pau Closas, and Aanjhan\n  Ranganathan", "title": "SemperFi: A Spoofer Eliminating GPS Receiver for UAVs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that GPS is vulnerable to signal spoofing attacks. Although\nseveral spoofing detection techniques exist, they are incapable of mitigation\nand recovery from stealthy attackers. In this work, we present SemperFi, a\nsingle antenna GPS receiver capable of tracking legitimate GPS satellite\nsignals and estimating the true location even during a spoofing attack. The\nmain challenge in building SemperFi is, unlike most wireless systems where\n\\emph{the data} contained in the wireless signals is important, GPS relies on\nthe time of arrival (ToA) of satellite signals. SemperFi is capable of\ndistinguishing spoofing signals and recovering legitimate GPS signals that are\neven completely overshadowed by a strong adversary. We exploit the short-term\nstability of inertial sensors to identify the spoofing signal and extend the\nsuccessive interference cancellation algorithm to preserve the legitimate\nsignal's ToA. We implement SemperFi in GNSS-SDR, an open-source\nsoftware-defined GNSS receiver, and evaluate its performance using UAV\nsimulators, real drones, a variety of real-world GPS datasets, and various\nembedded platforms. Our evaluation results indicate that in many scenarios,\nSemperFi can identify adversarial peaks by executing flight patterns that are\nless than 50 m long and recover the true location within 10 seconds (Jetson\nXavier). We show that our receiver is secure against stealthy attackers who\nexploit inertial sensor errors and execute seamless takeover attacks. We design\nSemperFi as a pluggable module capable of generating a spoofer-free GPS signal\nfor processing on any commercial-off-the-shelf GPS receiver available today.\nFinally, we release our implementation to the community for usage and further\nresearch.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 04:18:54 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Sathaye", "Harshad", ""], ["LaMountain", "Gerald", ""], ["Closas", "Pau", ""], ["Ranganathan", "Aanjhan", ""]]}, {"id": "2105.01958", "submitter": "Noam Mazor", "authors": "Iftach Haitner, Noam Mazor, Rotem Oshman, Omer Reingold, Amir\n  Yehudayoff", "title": "On the Communication Complexity of Key-Agreement Protocols", "comments": "A preliminary version appeared in ITCS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Key-agreement protocols whose security is proven in the random oracle model\nare an important alternative to protocols based on public-key cryptography. In\nthe random oracle model, the parties and the eavesdropper have access to a\nshared random function (an \"oracle\"), but the parties are limited in the number\nof queries they can make to the oracle. The random oracle serves as an\nabstraction for black-box access to a symmetric cryptographic primitive, such\nas a collision resistant hash. Unfortunately, as shown by Impagliazzo and\nRudich [STOC '89] and Barak and Mahmoody [Crypto '09], such protocols can only\nguarantee limited secrecy: the key of any $\\ell$-query protocol can be revealed\nby an $O(\\ell^2)$-query adversary. This quadratic gap between the query\ncomplexity of the honest parties and the eavesdropper matches the gap obtained\nby the Merkle's Puzzles protocol of Merkle [CACM '78].\n  In this work we tackle a new aspect of key-agreement protocols in the random\noracle model: their communication complexity. In Merkle's Puzzles, to obtain\nsecrecy against an eavesdropper that makes roughly $\\ell^2$ queries, the honest\nparties need to exchange $\\Omega(\\ell)$ bits. We show that for protocols with\ncertain natural properties, ones that Merkle's Puzzle has, such high\ncommunication is unavoidable. Specifically, this is the case if the honest\nparties' queries are uniformly random, or alternatively if the protocol uses\nnon-adaptive queries and has only two rounds. Our proof for the first setting\nuses a novel reduction from the set-disjointness problem in two-party\ncommunication complexity. For the second setting we prove the lower bound\ndirectly, using information-theoretic arguments.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 09:58:32 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 07:32:11 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Haitner", "Iftach", ""], ["Mazor", "Noam", ""], ["Oshman", "Rotem", ""], ["Reingold", "Omer", ""], ["Yehudayoff", "Amir", ""]]}, {"id": "2105.01959", "submitter": "Matthew Watson", "authors": "Matthew Watson (1) and Noura Al Moubayed (1) ((1) Durham University,\n  Durham, UK)", "title": "Attack-agnostic Adversarial Detection on Medical Data Using Explainable\n  Machine Learning", "comments": "13 pages, 6 figures, accepted to ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Explainable machine learning has become increasingly prevalent, especially in\nhealthcare where explainable models are vital for ethical and trusted automated\ndecision making. Work on the susceptibility of deep learning models to\nadversarial attacks has shown the ease of designing samples to mislead a model\ninto making incorrect predictions. In this work, we propose a model agnostic\nexplainability-based method for the accurate detection of adversarial samples\non two datasets with different complexity and properties: Electronic Health\nRecord (EHR) and chest X-ray (CXR) data. On the MIMIC-III and Henan-Renmin EHR\ndatasets, we report a detection accuracy of 77% against the Longitudinal\nAdversarial Attack. On the MIMIC-CXR dataset, we achieve an accuracy of 88%;\nsignificantly improving on the state of the art of adversarial detection in\nboth datasets by over 10% in all settings. We propose an anomaly detection\nbased method using explainability techniques to detect adversarial samples\nwhich is able to generalise to different attack methods without a need for\nretraining.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 10:01:53 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Watson", "Matthew", ""], ["Moubayed", "Noura Al", ""]]}, {"id": "2105.01970", "submitter": "Marius Schlegel", "authors": "Marius Schlegel", "title": "Trusted Enforcement of Application-specific Security Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there have been approaches for integrating security policies into\noperating systems (OSs) for more than two decades, applications often use\nobjects of higher abstraction requiring individual security policies with\napplication-specific semantics. Due to insufficient OS support, current\napproaches for enforcing application-level policies typically lead to large and\ncomplex trusted computing bases rendering tamperproofness and correctness\ndifficult to achieve. To mitigate this problem, we propose the\napplication-level policy enforcement architecture AppSPEAR and a C++ framework\nfor its implementation. The configurable framework enables developers to\nbalance enforcement rigor and costs imposed by different implementation\nalternatives and thus to easily tailor an AppSPEAR implementation to individual\napplication requirements. We especially argue that hardware-based trusted\nexecution environments offer an optimal balance between effectiveness and\nefficiency of policy protection and enforcement. This claim is substantiated by\na practical evaluation based on an electronic medical record system.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 10:50:18 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Schlegel", "Marius", ""]]}, {"id": "2105.02029", "submitter": "Semyon Yurkov", "authors": "Ross Horne, Sjouke Mauw, Semen Yurkov", "title": "Breaking and Fixing Unlinkability of the Key Agreement Protocol for 2nd\n  Gen EMV Payments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address privacy problems with the EMV standard, EMVco proposed a Blinded\nDiffie-Hellman key establishment protocol. We point out that active attackers\nwere not previously accounted for in the privacy requirements of this proposed\nprotocol, despite the fact that an active attacker can compromise\nunlinkability. Here, we adopt a strong definition of unlinkability that does\naccount for active attackers and propose an enhancement of the protocol\nproposed by EMVco where we make use of Verheul certificates. We prove that our\nprotocol does satisfy strong unlinkability, while preserving authentication.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 12:57:01 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Horne", "Ross", ""], ["Mauw", "Sjouke", ""], ["Yurkov", "Semen", ""]]}, {"id": "2105.02031", "submitter": "Joseph Hallett", "authors": "Nikhil Patnaik, Andrew C. Dwyer, Joseph Hallett, Awais Rashid", "title": "Don't forget your classics: Systematizing 45 years of Ancestry for\n  Security API Usability Recommendations", "comments": "24 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Producing secure software is challenging. The poor usability of security APIs\nmakes this even harder. Many recommendations have been proposed to support\ndevelopers by improving the usability of cryptography libraries and APIs;\nrooted in wider best practice guidance in software engineering and API design.\nIn this SLR, we systematize knowledge regarding these recommendations.\n  We identify and analyze 65 papers spanning 45 years, offering a total of 883\nrecommendations.We undertake a thematic analysis to identify 7 core ways to\nimprove usability of APIs. We find that most of the recommendations focus on\nhelping API developers to construct and structure their code and make it more\nusable and easier for programmers to understand. There is less focus, however,\non documentation, writing requirements, code quality assessment and the impact\nof organizational software development practices. By tracing and analyzing\npaper ancestry, we map how this knowledge becomes validated and translated over\ntime.We find evidence that less than a quarter of all API usability\nrecommendations are empirically validated, and that recommendations specific to\nusable security APIs lag even further behind in this regard.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 13:00:32 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Patnaik", "Nikhil", ""], ["Dwyer", "Andrew C.", ""], ["Hallett", "Joseph", ""], ["Rashid", "Awais", ""]]}, {"id": "2105.02118", "submitter": "Olga Labazova", "authors": "Olga Labazova (University of Cologne), Erol Kazan (IT University of\n  Copenhagen), Tobias Dehling (Karlsruhe Institute of Technology), Tuure\n  Tuunanen (University of Jyvaskyla), Ali Sunyaev (Karlsruhe Institute of\n  Technology)", "title": "Managing Blockchain Systems and Applications: A Process Model for\n  Blockchain Configurations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain is a radical innovation with a unique value proposition that\nshifts trust from institutions to algorithms. Still, the potential of\nblockchains remains elusive due to knowledge gaps between computer science\nresearch and socio-economic research. Building on information technology\ngovernance literature and the theory of coevolution, this study develops a\nprocess model for blockchain configurations that captures blockchain capability\ndimensions and application areas. We demonstrate the applicability of the\nproposed blockchain configuration process model on four blockchain projects.\nThe proposed blockchain configuration process model assists with the selection\nand configuration of blockchain systems based on a set of known requirements\nfor a blockchain project. Our findings contribute to research by bridging\nknowledge gaps between computer science and socio-economic research on\nblockchain. Specifically, we explore existing blockchain concepts and integrate\nthem in a process model for blockchain configurations.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 14:49:38 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Labazova", "Olga", "", "University of Cologne"], ["Kazan", "Erol", "", "IT University of\n  Copenhagen"], ["Dehling", "Tobias", "", "Karlsruhe Institute of Technology"], ["Tuunanen", "Tuure", "", "University of Jyvaskyla"], ["Sunyaev", "Ali", "", "Karlsruhe Institute of\n  Technology"]]}, {"id": "2105.02124", "submitter": "Pontus Johnson", "authors": "Pontus Johnson", "title": "Intrinsic Propensity for Vulnerability in Computers? Arbitrary Code\n  Execution in the Universal Turing Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The universal Turing machine is generally considered to be the simplest, most\nabstract model of a computer. This paper reports on the discovery of an\naccidental arbitrary code execution vulnerability in Marvin Minsky's 1967\nimplementation of the universal Turing machine. By submitting crafted data, the\nmachine may be coerced into executing user-provided code. The article presents\nthe discovered vulnerability in detail and discusses its potential\nimplications. To the best of our knowledge, an arbitrary code execution\nvulnerability has not previously been reported for such a simple system.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 11:34:28 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Johnson", "Pontus", ""]]}, {"id": "2105.02175", "submitter": "Laura Boeschoten", "authors": "Laura Boeschoten, Roos Voorvaart, Casper Kaandorp, Ruben van den\n  Goorbergh, Martine de Vos", "title": "Automatic de-identification of Data Download Packages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The General Data Protection Regulation (GDPR) grants all natural persons the\nright of access to their personal data if this is being processed by data\ncontrollers. The data controllers are obliged to share the data in an\nelectronic format and often provide the data in a so called Data Download\nPackage (DDP). These DDPs contain all data collected by public and private\nentities during the course of citizens' digital life and form a treasure trove\nfor social scientists. However, the data can be deeply private. To protect the\nprivacy of research participants while using their DDPs for scientific\nresearch, we developed de-identification software that is able to handle\ntypical characteristics of DDPs such as regularly changing file structures,\nvisual and textual content, different file formats, different file structures\nand accounting for usernames. We investigate the performance of the software\nand illustrate how the software can be tailored towards specific DDP\nstructures.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 14:17:33 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Boeschoten", "Laura", ""], ["Voorvaart", "Roos", ""], ["Kaandorp", "Casper", ""], ["Goorbergh", "Ruben van den", ""], ["de Vos", "Martine", ""]]}, {"id": "2105.02215", "submitter": "Marziyeh Soltani", "authors": "Marziyeh Soltani (1), Mahtab Mirmohseni (1), Panos Papadimitratos (2)\n  ((1) Department of Electrical Engineering, sharif University of Technology,\n  (2) Networked Systems Security group, KTH Royal Institute of Technology)", "title": "Massive MIMO-NOMA Systems Secrecy in the Presence of Active\n  Eavesdroppers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-orthogonal multiple access (NOMA) and massive multiple-input\nmultiple-output (MIMO) systems are highly efficient. Massive MIMO systems are\ninherently resistant to passive attackers (eavesdroppers), thanks to\ntransmissions directed to the desired users. However, active attackers can\ntransmit a combination of legitimate user pilot signals during the channel\nestimation phase. This way they can mislead the base station (BS) to rotate the\ntransmission in their direction, and allow them to eavesdrop during the\ndownlink data transmission phase. In this paper, we analyse this vulnerability\nin an improved system model and stronger adversary assumptions, and investigate\nhow physical layer security can mitigate such attacks and ensure secure\n(confidential) communication. We derive the secrecy outage probability (SOP)\nand a lower bound on the ergodic secrecy capacity, using stochastic geometry\ntools when the number of antennas in the BSs tends to infinity. We adapt the\nresult to evaluate the secrecy performance in massive orthogonal multiple\naccess (OMA). We find that appropriate power allocation allows NOMA to\noutperform OMA in terms of ergodic secrecy rate and SOP.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 17:47:22 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Soltani", "Marziyeh", ""], ["Mirmohseni", "Mahtab", ""], ["Papadimitratos", "Panos", ""]]}, {"id": "2105.02295", "submitter": "Hanieh Hashemi", "authors": "Hanieh Hashemi, Yongqin Wang, Chuan Guo, Murali Annavaram", "title": "Byzantine-Robust and Privacy-Preserving Framework for FedML", "comments": null, "journal-ref": "Security and Safety in Machine Learning Systems Workshop in ICLR\n  2021", "doi": null, "report-no": null, "categories": "cs.CR cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning has emerged as a popular paradigm for collaboratively\ntraining a model from data distributed among a set of clients. This learning\nsetting presents, among others, two unique challenges: how to protect privacy\nof the clients' data during training, and how to ensure integrity of the\ntrained model. We propose a two-pronged solution that aims to address both\nchallenges under a single framework. First, we propose to create secure\nenclaves using a trusted execution environment (TEE) within the server. Each\nclient can then encrypt their gradients and send them to verifiable enclaves.\nThe gradients are decrypted within the enclave without the fear of privacy\nbreaches. However, robustness check computations in a TEE are computationally\nprohibitive. Hence, in the second step, we perform a novel gradient encoding\nthat enables TEEs to encode the gradients and then offloading Byzantine check\ncomputations to accelerators such as GPUs. Our proposed approach provides\ntheoretical bounds on information leakage and offers a significant speed-up\nover the baseline in empirical evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 19:36:21 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Hashemi", "Hanieh", ""], ["Wang", "Yongqin", ""], ["Guo", "Chuan", ""], ["Annavaram", "Murali", ""]]}, {"id": "2105.02334", "submitter": "Simone Rodigari Mr", "authors": "Simone Rodigari, Donna O'Shea, Pat McCarthy, Martin McCarry, Sean\n  McSweeney", "title": "Performance Analysis of Zero-Trust multi-cloud", "comments": "This paper was submitted for the IEEE CLOUD 2021 Conference and is\n  currently being reviewed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero Trust security model permits to secure cloud native applications while\nencrypting all network communication, authenticating, and authorizing every\nrequest. The service mesh can enable Zero Trust using a side-car proxy without\nchanges to the application code. To the best of our knowledge, no previous work\nhas provided a performance analysis of Zero Trust in a multi-cloud environment.\nThis paper proposes a multi-cloud framework and a testing workflow to analyze\nperformance of the data plane under load and the impact on the control plane,\nwhen Zero Trust is enabled. The results of preliminary tests show that Istio\nhas reduced latency variability in responding to sequential HTTP requests.\nResults also reveal that the overall CPU and memory usage can increase based on\nservice mesh configuration and the cloud environment.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 21:29:13 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Rodigari", "Simone", ""], ["O'Shea", "Donna", ""], ["McCarthy", "Pat", ""], ["McCarry", "Martin", ""], ["McSweeney", "Sean", ""]]}, {"id": "2105.02388", "submitter": "Noah Ziems", "authors": "Noah Ziems, Shaoen Wu", "title": "Security Vulnerability Detection Using Deep Learning Natural Language\n  Processing", "comments": "IEEE INFOCOM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Detecting security vulnerabilities in software before they are exploited has\nbeen a challenging problem for decades. Traditional code analysis methods have\nbeen proposed, but are often ineffective and inefficient. In this work, we\nmodel software vulnerability detection as a natural language processing (NLP)\nproblem with source code treated as texts, and address the automated software\nvenerability detection with recent advanced deep learning NLP models assisted\nby transfer learning on written English. For training and testing, we have\npreprocessed the NIST NVD/SARD databases and built a dataset of over 100,000\nfiles in $C$ programming language with 123 types of vulnerabilities. The\nextensive experiments generate the best performance of over 93\\% accuracy in\ndetecting security vulnerabilities.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 01:28:21 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Ziems", "Noah", ""], ["Wu", "Shaoen", ""]]}, {"id": "2105.02435", "submitter": "Billy Bob Brumley", "authors": "Ignacio M. Delgado-Lozano, Macarena C. Mart\\'inez-Rodr\\'iguez,\n  Alexandros Bakas, Billy Bob Brumley, Antonis Michalas", "title": "Attestation Waves: Platform Trust via Remote Power Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attestation is a strong tool to verify the integrity of an untrusted system.\nHowever, in recent years, different attacks have appeared that are able to\nmislead the attestation process with treacherous practices as memory copy,\nproxy and rootkit attacks, just to name a few. A successful attack leads to\nsystems that are considered trusted by a verifier system, while the prover has\nbypassed the challenge. To harden these attacks against attestation methods and\nprotocols, some proposals have considered the use of side-channel information\nthat can be measured externally, as it is the case of electromagnetic (EM)\nemanation. Nonetheless, these methods require the physical proximity of an\nexternal setup to capture the EM radiation.\n  In this paper, we present the possibility of performing attestation by using\nthe side channel information captured by a sensor or peripheral that lives in\nthe same System-on-Chip (SoC) than the processor system (PS) which executes the\noperation that we aim to attest, by only sharing the Power Distribution Network\n(PDN). In our case, an analog-to-digital converter (ADC) that captures the\nvoltage fluctuations at its input terminal while a certain operation is taking\nplace is suitable to characterize itself and to distinguish it from other\nbinaries. The resultant power traces are enough to clearly identify a given\noperation without the requirement of physical proximity.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 04:29:27 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Delgado-Lozano", "Ignacio M.", ""], ["Mart\u00ednez-Rodr\u00edguez", "Macarena C.", ""], ["Bakas", "Alexandros", ""], ["Brumley", "Billy Bob", ""], ["Michalas", "Antonis", ""]]}, {"id": "2105.02466", "submitter": "Alexander Sprog{\\o} Banks", "authors": "Alexander Sprog{\\o} Banks, Marek Kisiel and Philip Korsholm", "title": "Remote Attestation: A Literature Review", "comments": "34 pages, 2 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the rising number of IoT devices, the security of such devices becomes\nincreasingly important. Remote attestation (RA) is a distinct security service\nthat allows a remote verifer to reason about the state of an untrusted remote\nprover (device).\n  Paradigms of remote attestation span from exclusively software, in\nsoftware-based attestation, to exclusively hardware-based. In between the\nextremes are hybrid attestation that utilize the enhanced security of secure\nhardware components in combination with the lower cost of purely software-based\nimplementations.\n  Traditional remote attestation protocols are concerned with reasoning about\nthe state of a prover. However, extensions to remote attestation also exist,\nsuch as code updates, device resets, erasure and attestation of the device's\nrun-time state. Furthermore, as interconnected IoT devices are becoming\nincreasingly more popular, so is the need for attestation of device swarms.\n  We will describe and evaluate the state-of-the-art for remote attestation,\nwhich covers singular attestation of devices as well as newer research in the\narea of formally verified RA protocols, swarm attestation and control-flow\nattestation.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 06:57:44 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 07:17:45 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Banks", "Alexander Sprog\u00f8", ""], ["Kisiel", "Marek", ""], ["Korsholm", "Philip", ""]]}, {"id": "2105.02526", "submitter": "Sevvandi Kandanaarachchi", "authors": "Sevvandi Kandanaarachchi, Hideya Ochiai, Asha Rao", "title": "Honeyboost: Boosting honeypot performance with data fusion and anomaly\n  detection", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With cyber incidents and data breaches becoming increasingly common, being\nable to predict a cyberattack has never been more crucial. Network Anomaly\nDetection Systems (NADS) ability to identify unusual behavior makes them useful\nin predicting such attacks. In this paper, we introduce a novel framework to\nenhance the performance of honeypot aided NADS. We use a hybrid of two\napproaches: horizontal and vertical. The horizontal approach constructs a time\nseries from the communications of each node, with node-level features\nencapsulating their behavior over time. The vertical approach finds anomalies\nin each protocol space. To the best of our knowledge, this is the first time\nnode-level features have been used in honeypot aided NADS. Furthermore, using\nextreme value theory, anomaly detection with low false positive rates is\npossible. Experimental results indicate the efficacy of our framework in\nidentifying suspicious activities of nodes from node-level features, often\nbefore the honeypot does.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 08:59:44 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Kandanaarachchi", "Sevvandi", ""], ["Ochiai", "Hideya", ""], ["Rao", "Asha", ""]]}, {"id": "2105.02606", "submitter": "Panagiotis Gkikopoulos", "authors": "Panagiotis Gkikopoulos, Valerio Schiavoni, Josef Spillner", "title": "Analysis and Improvement of Heterogeneous Hardware Support in Docker\n  Images", "comments": "21st International Conference on Distributed Applications and\n  Interoperable Systems", "journal-ref": null, "doi": "10.1007/978-3-030-78198-9_9", "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Docker images are used to distribute and deploy cloud-native applications in\ncontainerised form. A container engine runs them with separated privileges\naccording to namespaces. Recent studies have investigated security\nvulnerabilities and runtime characteristics of Docker images. In contrast,\nlittle is known about the extent of hardware-dependent features in them such as\nprocessor-specific trusted execution environments, graphics acceleration or\nextension boards. This problem can be generalised to missing knowledge about\nthe extent of any hardware-bound instructions within the images that may\nrequire elevated privileges. We first conduct a systematic one-year evolution\nanalysis of a sample of Docker images concerning their use of hardware-specific\nfeatures. To improve the state of technology, we contribute novel tools to\nmanage such images. Our heuristic hardware dependency detector and a\nhardware-aware Docker executor give early warnings upon missing dependencies\ninstead of leading to silent or untimely failures. Our dataset and tools are\nreleased to the research community.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 12:20:52 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 07:13:56 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Gkikopoulos", "Panagiotis", ""], ["Schiavoni", "Valerio", ""], ["Spillner", "Josef", ""]]}, {"id": "2105.02608", "submitter": "Mohammed Gharib Dr.", "authors": "Mohammed Gharib and Fatemeh Afghah", "title": "How UAVs' Highly Dynamic 3D Movement Improves Network Security?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Cooperative ad hoc unmanned aerial vehicle (UAV) networks need essential\nsecurity services to ensure their communication security. Cryptography, as the\ninseparable tool for providing security services, requires a robust key\nmanagement system. Alas, the absence of infrastructure in cooperative networks\nleads to the infeasibility of providing conventional key management systems.\nKey pre-distribution schemes have shown promising performance in different\ncooperative networks due to their lightweight nature. However, intermediate\ndecryption-encryption (DE) steps and the lack of key updates are the most\nconcerning issues they suffer from. In this paper, we propose a simple and\neffective key management algorithm inspired by the idea of key\npre-distribution, where it utilizes the highly dynamic UAV node movement in 3D\nspace to provide the key update feature and optimizes the number of\nintermediate DE steps. Although it is a general model for any mobile ad hoc\nnetwork, we have selected UAV network as an example domain to show the\nefficiency of the model given the high mobility. We define the communication\ndensity parameter to analytically show that using any highly dynamic random\nmovement pattern leads our algorithm to work effectively. To show the proposed\nalgorithm's effectiveness, we exhaustively analyze its security and performance\nin the UAV network using the ns-3 network simulator. Results validate our\nanalytical findings and show how the highly dynamic UAV network movement helps\nour algorithm to provide the key update feature and to optimize the number of\nDE steps.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 12:29:31 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Gharib", "Mohammed", ""], ["Afghah", "Fatemeh", ""]]}, {"id": "2105.02664", "submitter": "Felipe Boeira", "authors": "Felipe Boeira and Mikael Asplund", "title": "Exploiting Partial Order of Keys to Verify Security of a Vehicular Group\n  Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Vehicular networks will enable a range of novel applications to enhance road\ntraffic efficiency, safety, and reduce fuel consumption. As for other\ncyber-physical systems, security is essential to the deployment of these\napplications and standardisation efforts are ongoing. In this paper, we perform\na systematic security evaluation of a vehicular platooning protocol through a\nthorough analysis of the protocol and security standards. We tackle the\ncomplexity of the resulting model with a proof strategy based on a relation on\nkeys. The key relation forms a partial order, which encapsulates both secrecy\nand authenticity dependencies. We show that our order-aware approach makes the\nverification feasible and proves strong authenticity properties along with\nsecrecy of all keys used throughout the protocol.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 13:45:09 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Boeira", "Felipe", ""], ["Asplund", "Mikael", ""]]}, {"id": "2105.02784", "submitter": "Ye Wang", "authors": "Ye Wang and Yan Chen and Shuiguang Deng and Roger Wattenhofer", "title": "Cyclic Arbitrage in Decentralized Exchange Markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.CE cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In May 2020, Uniswap V2 was officially launched on Ethereum. Uniswap V2\nallows users to create trading pools between any pair of cryptocurrencies,\nwithout the need for ETH as an intermediary currency. Uniswap V2 introduces new\narbitrage opportunities: Traders are now able to trade cryptocurrencies\ncyclically: A trader can exchange currency A for B, then B for C, and finally C\nfor A again through different trading pools. Almost surely, the three floating\nexchange rates are not perfectly in sync, which opens up arbitrage\npossibilities for cyclic trading.\n  In this paper, we study cyclic arbitrages in Decentralized Exchanges (DEXes)\nof cryptocurrencies with transaction-level data on Uniswap V2, observing\n285,127 cyclic arbitrages over eight months. We conduct a theoretical analysis\nand an empirical evaluation to understand cyclic arbitrages systematically. We\nstudy the market size (the revenue and the cost) of cyclic arbitrages, how\ncyclic arbitrages change market prices, how cyclic arbitrageurs influence other\nparticipants, and the implementations of cyclic arbitrages.\n  Beyond the understanding of cyclic arbitrages, this paper suggests that with\nthe smart contract technology and the replicated state machine setting of\nEthereum, arbitrage strategies are easier implemented in DEXes than in\nCentralized Exchanges (CEXes). We find that deploying private smart contracts\nto implement cyclic arbitrages is more resilient to front-running attacks than\napplying cyclic arbitrages through public (open-source) smart contracts.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 10:42:39 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Wang", "Ye", ""], ["Chen", "Yan", ""], ["Deng", "Shuiguang", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "2105.02793", "submitter": "Harry Halpin", "authors": "Harry Halpin", "title": "Holistic Privacy and Usability of a Cryptocurrency Wallet", "comments": "Workshop on Usable Security and Privacy (USEC) 2021", "journal-ref": null, "doi": "10.14722/usec.2021.23007", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we overview the problems associated with the usability of\ncryptocurrency wallets, such as those used by ZCash, for end-users. The concept\nof \"holistic privacy,\" where information leaks in one part of a system can\nviolate the privacy expectations of different parts of the system, is\nintroduced as a requirement. To test this requirement with real-world software,\nwe did a 60 person task-based evaluation of the usability of a ZCash\ncryptocurrency wallet by having users install and try to both send and receive\nanonymized ZCash transactions, as well as install a VPN and Tor. While the\ninitial wallet installation was difficult, we found even a larger amount of\ndifficulty integrating the ZCash wallet into network-level protection like VPNs\nor Tor, so only a quarter of users could complete a real-world purchase using\nthe wallet.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 16:33:37 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Halpin", "Harry", ""]]}, {"id": "2105.02803", "submitter": "Ruoxi Qin", "authors": "Ruoxi Qin, Linyuan Wang, Xingyuan Chen, Xuehui Du, Bin Yan", "title": "Dynamic Defense Approach for Adversarial Robustness in Deep Neural\n  Networks via Stochastic Ensemble Smoothed Model", "comments": "17 pages,8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been shown to suffer from critical vulnerabilities\nunder adversarial attacks. This phenomenon stimulated the creation of different\nattack and defense strategies similar to those adopted in cyberspace security.\nThe dependence of such strategies on attack and defense mechanisms makes the\nassociated algorithms on both sides appear as closely reciprocating processes.\nThe defense strategies are particularly passive in these processes, and\nenhancing initiative of such strategies can be an effective way to get out of\nthis arms race. Inspired by the dynamic defense approach in cyberspace, this\npaper builds upon stochastic ensemble smoothing based on defense method of\nrandom smoothing and model ensemble. Proposed method employs network\narchitecture and smoothing parameters as ensemble attributes, and dynamically\nchange attribute-based ensemble model before every inference prediction\nrequest. The proposed method handles the extreme transferability and\nvulnerability of ensemble models under white-box attacks. Experimental\ncomparison of ASR-vs-distortion curves with different attack scenarios shows\nthat even the attacker with the highest attack capability cannot easily exceed\nthe attack success rate associated with the ensemble smoothed model, especially\nunder untargeted attacks.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 16:48:52 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Qin", "Ruoxi", ""], ["Wang", "Linyuan", ""], ["Chen", "Xingyuan", ""], ["Du", "Xuehui", ""], ["Yan", "Bin", ""]]}, {"id": "2105.02852", "submitter": "Noama Fatima Samreen", "authors": "Noama Fatima Samreen and Manar H. Alalfi", "title": "SmartScan: An approach to detect Denial of Service Vulnerability in\n  Ethereum Smart Contracts", "comments": null, "journal-ref": "ICSEW 21 Proceedings of the IEEE/ACM 43rd International Conference\n  on Software Engineering Workshops May 2021", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain technology (BT) Ethereum Smart Contracts allows programmable\ntransactions that involve the transfer of monetary assets among peers on a BT\nnetwork independent of a central authorizing agency. Ethereum Smart Contracts\nare programs that are deployed as decentralized applications, having the\nbuilding blocks of the blockchain consensus protocol. This technology enables\nconsumers to make agreements in a transparent and conflict-free environment.\nHowever, the security vulnerabilities within these smart contracts are a\npotential threat to the applications and their consumers and have shown in the\npast to cause huge financial losses. In this paper, we propose a framework that\ncombines static and dynamic analysis to detect Denial of Service (DoS)\nvulnerability due to an unexpected revert in Ethereum Smart Contracts. Our\nframework, SmartScan, statically scans smart contracts under test (SCUTs) to\nidentify patterns that are potentially vulnerable in these SCUTs and then uses\ndynamic analysis to precisely confirm their exploitability of the\nDoS-Unexpected Revert vulnerability, thus achieving increased performance and\nmore precise results. We evaluated SmartScan on a set of 500 smart contracts\ncollected from the Etherscan. Our approach shows an improvement in precision\nand recall when compared to available state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 17:41:43 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 17:28:21 GMT"}, {"version": "v3", "created": "Thu, 20 May 2021 04:03:08 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Samreen", "Noama Fatima", ""], ["Alalfi", "Manar H.", ""]]}, {"id": "2105.02866", "submitter": "Umang Gupta", "authors": "Umang Gupta, Dimitris Stripelis, Pradeep K. Lam, Paul M. Thompson,\n  Jos\\'e Luis Ambite, Greg Ver Steeg", "title": "Membership Inference Attacks on Deep Regression Models for Neuroimaging", "comments": "To appear at Medical Imaging with Deep Learning 2021 (MIDL 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring the privacy of research participants is vital, even more so in\nhealthcare environments. Deep learning approaches to neuroimaging require large\ndatasets, and this often necessitates sharing data between multiple sites,\nwhich is antithetical to the privacy objectives. Federated learning is a\ncommonly proposed solution to this problem. It circumvents the need for data\nsharing by sharing parameters during the training process. However, we\ndemonstrate that allowing access to parameters may leak private information\neven if data is never directly shared. In particular, we show that it is\npossible to infer if a sample was used to train the model given only access to\nthe model prediction (black-box) or access to the model itself (white-box) and\nsome leaked samples from the training data distribution. Such attacks are\ncommonly referred to as Membership Inference attacks. We show realistic\nMembership Inference attacks on deep learning models trained for 3D\nneuroimaging tasks in a centralized as well as decentralized setup. We\ndemonstrate feasible attacks on brain age prediction models (deep learning\nmodels that predict a person's age from their brain MRI scan). We correctly\nidentified whether an MRI scan was used in model training with a 60% to over\n80% success rate depending on model complexity and security assumptions.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 17:51:06 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 08:02:00 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Gupta", "Umang", ""], ["Stripelis", "Dimitris", ""], ["Lam", "Pradeep K.", ""], ["Thompson", "Paul M.", ""], ["Ambite", "Jos\u00e9 Luis", ""], ["Steeg", "Greg Ver", ""]]}, {"id": "2105.02881", "submitter": "Noama Fatima Samreen", "authors": "Noama Fatima Samreen and Manar H. Alalfi", "title": "Reentrancy Vulnerability Identification in Ethereum Smart Contracts", "comments": "arXiv admin note: text overlap with arXiv:2105.02852", "journal-ref": "2020 IEEE International Workshop on Blockchain Oriented Software\n  Engineering (IWBOSE)", "doi": "10.1109/IWBOSE50093.2020.9050260", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ethereum Smart contracts use blockchain to transfer values among peers on\nnetworks without central agency. These programs are deployed on decentralized\napplications running on top of the blockchain consensus protocol to enable\npeople to make agreements in a transparent and conflict-free environment. The\nsecurity vulnerabilities within those smart contracts are a potential threat to\nthe applications and have caused huge financial losses to their users. In this\npaper, we present a framework that combines static and dynamic analysis to\ndetect Reentrancy vulnerabilities in Ethereum smart contracts. This framework\ngenerates an attacker contract based on the ABI specifications of smart\ncontracts under test and analyzes the contract interaction to precisely report\nReentrancy vulnerability. We conducted a preliminary evaluation of our proposed\nframework on 5 modified smart contracts from Etherscan and our framework was\nable to detect the Reentrancy vulnerability in all our modified contracts. Our\nframework analyzes smart contracts statically to identify potentially\nvulnerable functions and then uses dynamic analysis to precisely confirm\nReentrancy vulnerability, thus achieving increased performance and reduced\nfalse positives.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 17:44:11 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Samreen", "Noama Fatima", ""], ["Alalfi", "Manar H.", ""]]}, {"id": "2105.02905", "submitter": "Roberto Metere", "authors": "Roberto Metere, Myriam Neaimeh, Charles Morisset, Carsten Maple,\n  Xavier Bellekens, Ricardo M. Czekster", "title": "Securing the Electric Vehicle Charging Infrastructure", "comments": "39 pages, white paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electric Vehicles (EVs) can help alleviate our reliance on fossil fuels for\ntransport and electricity systems. However, charging millions of EV batteries\nrequires management to prevent overloading the electricity grid and minimise\ncostly upgrades that are ultimately paid for by consumers.\n  Managed chargers, such as Vehicle-to-Grid (V2G) chargers, allow control over\nthe time, speed and direction of charging. Such control assists in balancing\nelectricity supply and demand across a green electricity system and could\nreduce costs for consumers.\n  Smart and V2G chargers connect EVs to the power grid using a charging device\nwhich includes a data connection to exchange information and control commands\nbetween various entities in the EV ecosystem. This introduces data privacy\nconcerns and is a potential target for cyber-security attacks. Therefore, the\nimplementation of a secure system is crucial to permit both consumers and\nelectricity system operators to trust smart charging and V2G.\n  In principle, we already have the technology needed for a connected EV\ncharging infrastructure to be securely enabled, borrowing best practices from\nthe Internet and industrial control systems. We must properly adapt the\nsecurity technology to take into account the challenges peculiar to the EV\ncharging infrastructure. Challenges go beyond technical considerations and\nother issues arise such as balancing trade-offs between security and other\ndesirable qualities such as interoperability, scalability, crypto-agility,\naffordability and energy efficiency.\n  This document reviews security and privacy topics relevant to the EV charging\necosystem with a focus on smart charging and V2G.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 18:10:42 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Metere", "Roberto", ""], ["Neaimeh", "Myriam", ""], ["Morisset", "Charles", ""], ["Maple", "Carsten", ""], ["Bellekens", "Xavier", ""], ["Czekster", "Ricardo M.", ""]]}, {"id": "2105.02917", "submitter": "Gino Chacon", "authors": "Tapojyoti Mandal, Gino Chacon, Johann Knechtel, Ozgur Sinanoglu, Paul\n  Gratz, Vassos Soteriou", "title": "Interposer-Based Root of Trust", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Industry is moving towards large-scale system-on-chip (SoC) designs where\nheterogeneous components such as processor cores, DSPs, memory controllers, and\naccelerator units are bundled via 2.5D integration. That is, these components\nare fabricated separately onto chiplets and then integrated using an\ninterconnect carrier, a so-called interposer. Independently, however,\ngeneral-purpose SoC architectures have raised significant security concerns.\nTherefore, with many IP modules and hardware components coming from various\nthird-party vendors and manufacturers, ensuring security and integrity of\nchiplets-based system is a grand challenge. Further, malicious software running\nwithin a chiplet can pose significant risks as well. In this work, we propose\nto leverage an active interposer as secure-by-construction, generic root of\ntrust platform for such modern systems. Our work presents a new architectural\nframework where untrusted processing elements, running untrusted code, are\nintegrated on top of such an interposer-based root of trust, allowing us to\ndetect and prevent any form of malicious messages exchanged between the\nheterogeneous components. Our technique has limited design overhead that is\nfurthermore restricted to the active interposer, allowing the heterogeneous\ncomponents within chiplets to remain untouched. We show that our scheme\ncorrectly handles attempted security violations with little impact on system\nperformance, around 4%.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 19:06:04 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Mandal", "Tapojyoti", ""], ["Chacon", "Gino", ""], ["Knechtel", "Johann", ""], ["Sinanoglu", "Ozgur", ""], ["Gratz", "Paul", ""], ["Soteriou", "Vassos", ""]]}, {"id": "2105.02927", "submitter": "Xuechao Wang", "authors": "Xuechao Wang, Viswa Virinchi Muppirala, Lei Yang, Sreeram Kannan,\n  Pramod Viswanath", "title": "Securing Parallel-chain Protocols under Variable Mining Power", "comments": "26 pages, 18 figures. A shorter version of this paper will appear in\n  the 2021 ACM Conference on Computer and Communications Security (CCS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Several emerging PoW blockchain protocols rely on a \"parallel-chain\"\narchitecture for scaling, where instead of a single chain, multiple chains are\nrun in parallel and aggregated. A key requirement of practical PoW blockchains\nis to adapt to mining power variations over time. In this paper, we consider\nthe design of provably secure parallel-chain protocols which can adapt to such\nmining power variations.\n  The Bitcoin difficulty adjustment rule adjusts the difficulty target of block\nmining periodically to get a constant mean inter-block time. While\nsuperficially simple, the rule has proved itself to be sophisticated and\nsuccessfully secure, both in practice and in theory. We show that natural\nadaptations of the Bitcoin adjustment rule to the parallel-chain case open the\ndoor to subtle, but catastrophic safety and liveness breaches. We uncover a\nmeta-design principle that allow us to design variable mining difficulty\nprotocols for three popular PoW blockchain proposals (Prism, OHIE, and\nFruitchains) inside a common rubric.\n  The principle has three components:(M1) a pivot chain, based on which blocks\nin all chains choose difficulty, (M2) a monotonicity condition for referencing\npivot chain blocks and (M3) translating additional protocol aspects from using\nlevels (depth) to using \"difficulty levels\". We show that protocols employing a\nsubset of these principles may have catastrophic failures. The security of the\ndesigns is also proved using a common rubric - the key technical challenge\ninvolves analyzing the interaction between the pivot chain and the other\nchains, as well as bounding the sudden changes in difficulty target experienced\nin non-pivot chains. We empirically investigate the responsivity of the new\nmining difficulty rule via simulations based on historical Bitcoin data, and\nfind that the protocol very effectively controls the forking rate across all\nthe chains.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 19:49:26 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 01:40:29 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Wang", "Xuechao", ""], ["Muppirala", "Viswa Virinchi", ""], ["Yang", "Lei", ""], ["Kannan", "Sreeram", ""], ["Viswanath", "Pramod", ""]]}, {"id": "2105.02930", "submitter": "Maria Bada Dr", "authors": "Maria Bada and Jason R.C. Nurse", "title": "Profiling the Cybercriminal: A Systematic Review of Research", "comments": null, "journal-ref": "IEEE, 14-18 June 2021, pp. 1-8", "doi": "10.1109/CyberSA52016.2021.9478246", "report-no": "2021 International Conference on Cyber Situational Awareness, Data\n  Analytics and Assessment (CyberSA)", "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As cybercrime becomes one of the most significant threats facing society\ntoday, it is of utmost importance to better understand the perpetrators behind\nsuch attacks. In this article, we seek to advance research and practitioner\nunderstanding of the cybercriminal (cyber-offender) profiling domain by\nconducting a rigorous systematic review. This work investigates the\naforementioned domain to answer the question: what is the state-of-the-art in\nthe academic field of understanding, characterising and profiling\ncybercriminals. Through the application of the PRISMA systematic literature\nreview technique, we identify 39 works from the last 14 years (2006-2020). Our\nfindings demonstrate that overall, there is lack of a common definition of\nprofiling for cyber-offenders. The review found that one of the primary types\nof cybercriminals that studies have focused on is hackers and the majority of\npapers used the deductive approach as a preferred one. This article produces an\nup-to-date characterisation of the field and also defines open issues deserving\nof further attention such as the role of security professionals and law\nenforcement in supporting such research, as well as factors including\npersonality traits which must be further researched whilst exploring online\ncriminal behaviour. By understanding online offenders and their pathways\ntowards malevolent behaviours, we can better identify steps that need to be\ntaken to prevent such criminal activities.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 19:56:55 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 19:55:52 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Bada", "Maria", ""], ["Nurse", "Jason R. C.", ""]]}, {"id": "2105.02933", "submitter": "Maria Bada Dr", "authors": "Maria Bada and Basie von Solms", "title": "A Cybersecurity Guide for Using Fitness Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The popularity of wearable devices is growing exponentially, with consumers\nusing these for a variety of services. Fitness devices are currently offering\nnew services such as shopping or buying train tickets using contactless\npayment. In addition, fitness devices are collecting a number of personal\ninformation such as body temperature, pulse rate, food habits and body weight,\nsteps-distance travelled, calories burned and sleep stage. Although these\ndevices can offer convenience to consumers, more and more reports are warning\nof the cybersecurity risks of such devices, and the possibilities for such\ndevices to be hacked and used as springboards to other systems. Due to their\nwireless transmissions, these devices can potentially be vulnerable to a\nmalicious attack allowing the data collected to be exposed. The vulnerabilities\nof these devices stem from lack of authentication, disadvantages of Bluetooth\nconnections, location tracking as well as third party vulnerabilities.\nGuidelines do exist for securing such devices, but most of such guidance is\ndirected towards device manufacturers or IoT providers, while consumers are\noften unaware of potential risks. The aim of this paper is to provide\ncybersecurity guidelines for users in order to take measures to avoid risks\nwhen using fitness devices.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 20:10:34 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Bada", "Maria", ""], ["von Solms", "Basie", ""]]}, {"id": "2105.02937", "submitter": "Jan Kalbantner", "authors": "J. Kalbantner, K. Markantonakis, D. Hurley-Smith, C. Shepherd, B.\n  Semal", "title": "A DLT-based Smart Contract Architecture for Atomic and Scalable Trading", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Distributed Ledger Technology (DLT) has an enormous potential but also\ndownsides. One downside of many DLT systems, such as blockchain, is their\nlimited transaction throughput that hinders their adoption in many use cases\n(e.g., real-time payments). State channels have emerged as a potential solution\nto enhance throughput by allowing transactions to process off-chain. While\ncurrent proposals can increase scalability, they require high collateral and\nlack support for dynamic systems that require asynchronous state transitions.\nAdditionally, the latency of channel initialisations can cause issues\nespecially if fast interactions are required. In this paper, we propose an\natomic, scalable and privacy-preserving protocol that enables secure and\ndynamic updates. We develop a smart contract-based Credit-Note System (CNS)\nthat allows participants to lock funds before a state channel initialisation,\nwhich enhances flexibility and efficiency. We formalise our model using the\nUniversal Composability (UC) framework and demonstrate that it achieves the\nstated design goals of privacy, scalability, and atomicity. Moreover, we\nimplement a dispute process in the state channel to counter availability\nattacks. Finally, we analyse the protocol in the context of an asynchronous\nsmart grid-based marketplace.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 20:24:09 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Kalbantner", "J.", ""], ["Markantonakis", "K.", ""], ["Hurley-Smith", "D.", ""], ["Shepherd", "C.", ""], ["Semal", "B.", ""]]}, {"id": "2105.02996", "submitter": "Haizhou Wang", "authors": "Haizhou Wang, Peng Liu", "title": "Tackling Imbalanced Data in Cybersecurity with Transfer Learning: A Case\n  with ROP Payload Detection", "comments": "19 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning gained proliferating popularity in the\ncybersecurity application domain, since when being compared to traditional\nmachine learning, it usually involves less human effort, produces better\nresults, and provides better generalizability. However, the imbalanced data\nissue is very common in cybersecurity, which can substantially deteriorate the\nperformance of the deep learning models. This paper introduces a transfer\nlearning based method to tackle the imbalanced data issue in cybersecurity\nusing Return-Oriented Programming (ROP) payload detection as a case study. We\nachieved 0.033 average false positive rate, 0.9718 average F1 score and 0.9418\naverage detection rate on 3 different target domain programs using 2 different\nsource domain programs, with 0 benign training data samples in the target\ndomain. The performance improvement compared to the baseline is a trade-off\nbetween false positive rate and detection rate. Using our approach, the number\nof false positives is reduced by 23.20%, and as a trade-off, the number of\ndetected malicious samples is reduced by 0.50%.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 22:18:41 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Wang", "Haizhou", ""], ["Liu", "Peng", ""]]}, {"id": "2105.03131", "submitter": "Zeki Bilgin", "authors": "Zeki Bilgin", "title": "Code2Image: Intelligent Code Analysis by Computer Vision Techniques and\n  Application to Vulnerability Prediction", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR cs.LG cs.PL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Intelligent code analysis has received increasing attention in parallel with\nthe remarkable advances in the field of machine learning (ML) in recent years.\nA major challenge in leveraging ML for this purpose is to represent source code\nin a useful form that ML algorithms can accept as input. In this study, we\npresent a novel method to represent source code as image while preserving\nsemantic and syntactic properties, which paves the way for leveraging computer\nvision techniques to use for code analysis. Indeed the method makes it possible\nto directly enter the resulting image representation of source codes into deep\nlearning (DL) algorithms as input without requiring any further data\npre-processing or feature extraction step. We demonstrate feasibility and\neffectiveness of our method by realizing a vulnerability prediction use case\nover a public dataset containing a large number of real-world source code\nsamples with performance evaluation in comparison to the state-of-art\nsolutions. Our implementation is publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 09:10:20 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Bilgin", "Zeki", ""]]}, {"id": "2105.03135", "submitter": "Pallavi Sivakumaran", "authors": "Pallavi Sivakumaran, Jorge Blasco", "title": "argXtract: Deriving IoT Security Configurations via Automated Static\n  Analysis of Stripped ARM Binaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent high-profile attacks on the Internet of Things (IoT) have brought to\nthe forefront the vulnerability of \"smart\" devices, and have resulted in\nnumerous IoT-focused security analyses. Many of the attacks had weak device\nconfiguration as the root cause. One potential source of rich and definitive\ninformation about the configuration of an IoT device is the device's firmware.\nHowever, firmware analysis is complex and automated firmware analyses have thus\nfar been confined to devices with more traditional operating systems such as\nLinux or VxWorks. Most IoT peripherals, due to lacking traditional operating\nsystems and implementing a wide variety of communication technologies, have\nonly been the subject of smaller-scale analyses. Peripheral firmware analysis\nis further complicated by the fact that such firmware files are predominantly\navailable as stripped binaries, without the ELF headers and symbol tables that\nwould simplify reverse engineering.\n  In this paper, we present argXtract, an open-source automated static analysis\ntool, which extracts security-relevant configuration information from stripped\nIoT peripheral firmware. Specifically, we focus on binaries that target the ARM\nCortex-M architecture, due to its growing popularity among IoT peripherals.\nargXtract overcomes the challenges associated with stripped Cortex-M analysis\nand is able to retrieve arguments to security-relevant supervisor and function\ncalls, enabling automated bulk analysis of firmware files. We demonstrate this\nvia three real-world case studies. The largest case study covers a dataset of\n243 Bluetooth Low Energy binaries targeting Nordic Semiconductor chipsets,\nwhile the other two focus on Nordic ANT and STMicroelectronics BlueNRG\nbinaries. The results reveal widespread lack of security and privacy controls\nin IoT, such as minimal or no protection for data, fixed passkeys and trackable\ndevice addresses.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 09:22:09 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Sivakumaran", "Pallavi", ""], ["Blasco", "Jorge", ""]]}, {"id": "2105.03167", "submitter": "Fangqi Li", "authors": "Fang-Qi Li, Shi-Lin Wang, and Alan Wee-Chung Liew", "title": "Towards Practical Watermark for Deep Neural Networks in Federated\n  Learning", "comments": "No comments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the wide application of deep neural networks, it is important to verify\na host's possession over a deep neural network model and protect the model. To\nmeet this goal, various mechanisms have been designed. By embedding extra\ninformation into a network and revealing it afterward, the watermark becomes a\ncompetitive candidate in proving integrity for deep learning systems. However,\nconcurrent watermarking schemes can hardly be adopted for emerging distributed\nlearning paradigms that raise extra requirements during the ownership\nverification. A spearheading distributed learning paradigm is federated\nlearning (FL) where many parties participate in training one single model. Each\nauthor participating in the FL should be able to verify its ownership\nindependently. Moreover, there are other potential threat and corresponding\nsecurity requirements under this scenario. To meet those requirements, in this\npaper, we demonstrate a watermarking protocol for protecting deep neural\nnetworks in the setting of FL. By incorporating the state-of-the-art\nwatermarking scheme and the cryptological primitive designed for distributed\nstorage, the protocol meets the need for ownership verification in the FL\nscenario without violating the privacy for each participant. This work paves\nthe way for generalizing watermark as a practical security mechanism for\nprotecting deep learning models in distributed learning platforms.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 11:19:43 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 14:39:33 GMT"}, {"version": "v3", "created": "Fri, 16 Jul 2021 04:19:51 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Li", "Fang-Qi", ""], ["Wang", "Shi-Lin", ""], ["Liew", "Alan Wee-Chung", ""]]}, {"id": "2105.03204", "submitter": "Mahendra Shukla", "authors": "Abhishek Gupta, Om Jee Pandey, Mahendra Shukla, Anjali Dadhich, Samar\n  Mathur, Anup Ingle", "title": "Computational Intelligence based Intrusion Detection Systems for\n  Wireless Communication", "comments": null, "journal-ref": null, "doi": "10.1109/ICCIC.2013.6724156", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The emerging trend of ubiquitous and pervasive computing aims at embedding\neveryday devices such as wristwatches, smart phones, home video systems,\nautofocus cameras, intelligent vehicles, musical instruments, kitchen\nappliances etc. with microprocessors and imparts them with wireless\ncommunication capability. This advanced computing paradigm, also known as the\nInternet of Things or cyber-physical computing, leads internet and computing to\nappear everywhere and anywhere using any device and location. With maximum\nappreciation and due regards to the evolutionary arc, depth and scope of\nceaseless internet utilities, it is equally necessary to envisage the security\nand data confidentiality challenges posed by the free and ubiquitous\navailability of internet. This paper analyses the role of computational\nintelligence techniques to design adaptive and cognitive intrusion detection\nsystems that can efficiently detect malicious network activities and proposes\nnovel three-tier architecture for designing intelligent intrusion detection\nsystems for wireless networks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 10:14:52 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Gupta", "Abhishek", ""], ["Pandey", "Om Jee", ""], ["Shukla", "Mahendra", ""], ["Dadhich", "Anjali", ""], ["Mathur", "Samar", ""], ["Ingle", "Anup", ""]]}, {"id": "2105.03219", "submitter": "Christian Porter", "authors": "Christian Porter, Andrew Mendelsohn and Cong Ling", "title": "Subfield Algorithms for Ideal- and Module-SVP Based on the Decomposition\n  Group", "comments": "30 pages plus appendix, submitted to ASIACRYPT pending review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.NT math.RA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Whilst lattice-based cryptosystems are believed to be resistant to quantum\nattack, they are often forced to pay for that security with inefficiencies in\nimplementation. This problem is overcome by ring- and module-based schemes such\nas Ring-LWE or Module-LWE, whose keysize can be reduced by exploiting its\nalgebraic structure, allowing for neater and faster computations. Many rings\nmay be chosen to define such cryptoschemes, but cyclotomic rings, due to their\ncyclic nature allowing for easy multiplication, are the community standard.\nHowever, there is still much uncertainty as to whether this structure may be\nexploited to an adversary's benefit. In this paper, we show that the\ndecomposition group of a cyclotomic ring of arbitrary conductor may be utilised\nin order to significantly decrease the dimension of the ideal (or module)\nlattice required to solve a given instance of SVP. Moreover, we show that there\nexist a large number of rational primes for which, if the prime ideal factors\nof an ideal lie over primes of this form, give rise to an \"easy\" instance of\nSVP. However, it is important to note that this work does not break Ring-LWE or\nModule-LWE, since the security reduction is from worst case ideal or module SVP\nto average case Ring-LWE or Module-LWE respectively, and is one way.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 12:46:45 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 21:46:54 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Porter", "Christian", ""], ["Mendelsohn", "Andrew", ""], ["Ling", "Cong", ""]]}, {"id": "2105.03251", "submitter": "Faiq Khalid", "authors": "Faiq Khalid, Muhammad Abdullah Hanif, Muhammad Shafique", "title": "Exploiting Vulnerabilities in Deep Neural Networks: Adversarial and\n  Fault-Injection Attacks", "comments": "CYBER 2020, The Fifth International Conference on Cyber-Technologies\n  and Cyber-Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From tiny pacemaker chips to aircraft collision avoidance systems, the\nstate-of-the-art Cyber-Physical Systems (CPS) have increasingly started to rely\non Deep Neural Networks (DNNs). However, as concluded in various studies, DNNs\nare highly susceptible to security threats, including adversarial attacks. In\nthis paper, we first discuss different vulnerabilities that can be exploited\nfor generating security attacks for neural network-based systems. We then\nprovide an overview of existing adversarial and fault-injection-based attacks\non DNNs. We also present a brief analysis to highlight different challenges in\nthe practical implementation of adversarial attacks. Finally, we also discuss\nvarious prospective ways to develop robust DNN-based systems that are resilient\nto adversarial and fault-injection attacks.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 08:11:03 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Khalid", "Faiq", ""], ["Hanif", "Muhammad Abdullah", ""], ["Shafique", "Muhammad", ""]]}, {"id": "2105.03273", "submitter": "Daniel Karapetyan Dr", "authors": "Daniel Karapetyan and Gregory Gutin", "title": "Solving the Workflow Satisfiability Problem using General Purpose\n  Solvers", "comments": "Associated data: http://doi.org/10.17639/nott.7116", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The workflow satisfiability problem (WSP) is a well-studied problem in access\ncontrol seeking allocation of authorised users to every step of the workflow,\nsubject to workflow specification constraints. It was noticed that the number\n$k$ of steps is typically small compared to the number of users in the\nreal-world instances of WSP; therefore $k$ is considered as the parameter in\nWSP parametrised complexity research. While WSP in general was shown to be\nW[1]-hard, WSP restricted to a special case of user-independent (UI)\nconstraints is fixed-parameter tractable (FPT). However, restriction to the UI\nconstraints might be impractical.\n  To efficiently handle non-UI constraints, we introduce the notion of\nbranching factor of a constraint. As long as the branching factors of the\nconstraints are relatively small and the number of non-UI constraints is\nreasonable, WSP can be solved in FPT time.\n  Extending the results from Karapetyan et al. (2019), we demonstrate that\ngeneral-purpose solvers are capable of achieving FPT-like performance on WSP\nwith arbitrary constraints when used with appropriate formulations. This\nenables one to tackle most of practical WSP instances. While important on its\nown, we hope that this result will also motivate researchers to look for\nFPT-aware formulations of other FPT problems.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 13:59:30 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Karapetyan", "Daniel", ""], ["Gutin", "Gregory", ""]]}, {"id": "2105.03346", "submitter": "Antonino Sabetta", "authors": "Therese Fehrer, Roc\\'io Cabrera Lozoya, Antonino Sabetta, Dario Di\n  Nucci, Damian A. Tamburri", "title": "Detecting Security Fixes in Open-Source Repositories using Static Code\n  Analyzers", "comments": "Submitted to ESEC/FSE 2021, Industry Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sources of reliable, code-level information about vulnerabilities that\naffect open-source software (OSS) are scarce, which hinders a broad adoption of\nadvanced tools that provide code-level detection and assessment of vulnerable\nOSS dependencies.\n  In this paper, we study the extent to which the output of off-the-shelf\nstatic code analyzers can be used as a source of features to represent commits\nin Machine Learning (ML) applications. In particular, we investigate how such\nfeatures can be used to construct embeddings and train ML models to\nautomatically identify source code commits that contain vulnerability fixes.\n  We analyze such embeddings for security-relevant and non-security-relevant\ncommits, and we show that, although in isolation they are not different in a\nstatistically significant manner, it is possible to use them to construct a ML\npipeline that achieves results comparable with the state of the art.\n  We also found that the combination of our method with commit2vec represents a\ntangible improvement over the state of the art in the automatic identification\nof commits that fix vulnerabilities: the ML models we construct and commit2vec\nare complementary, the former being more generally applicable, albeit not as\naccurate.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 15:57:17 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Fehrer", "Therese", ""], ["Lozoya", "Roc\u00edo Cabrera", ""], ["Sabetta", "Antonino", ""], ["Di Nucci", "Dario", ""], ["Tamburri", "Damian A.", ""]]}, {"id": "2105.03395", "submitter": "Pascal Nasahl", "authors": "Stefan Steinegger, David Schrammel, Samuel Weiser, Pascal Nasahl,\n  Stefan Mangard", "title": "SERVAS! Secure Enclaves via RISC-V Authenticryption Shield", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Isolation is a long-standing challenge of software security. Traditional\nprivilege rings and virtual memory are more and more augmented with concepts\nsuch as capabilities, protection keys, and powerful enclaves. At the same time,\nwe are evidencing an increased need for physical protection, shifting towards\nfull memory encryption schemes. This results in a complex interplay of various\nsecurity mechanisms, increasing the burden for system architects and security\nanalysts.\n  In this work, we tackle the isolation challenge with a new isolation\nprimitive called authenticryption shield that unifies both traditional and\nadvanced isolation policies while offering the potential for future\nextensibility. At the core, we build upon an authenticated memory encryption\nscheme that gives cryptographic isolation guarantees and, thus, streamlines the\nsecurity reasoning. We showcase the versatility of our approach by designing\nand prototyping SERVAS -- an innovative enclave architecture for RISC-V. Unlike\ncurrent enclave systems, SERVAS facilitates efficient and secure enclave memory\nsharing. While the memory encryption constitutes the main overhead, entering or\nexiting a SERVAS enclave requires only 3.5x of a simple syscall, instead of 71x\nfor Intel SGX.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 17:09:51 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Steinegger", "Stefan", ""], ["Schrammel", "David", ""], ["Weiser", "Samuel", ""], ["Nasahl", "Pascal", ""], ["Mangard", "Stefan", ""]]}, {"id": "2105.03502", "submitter": "Fitzroy Nembhard", "authors": "Fitzroy D. Nembhard and Marco M. Carvalho", "title": "Conversational Code Analysis: The Future of Secure Coding", "comments": "Accepted on May 12, 2021 for publication in Coding Theory - Recent\n  Advances, New Perspectives and Applications, IntechOpen, London", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The area of software development and secure coding can benefit significantly\nfrom advancements in virtual assistants. Research has shown that many coders\nneglect security in favor of meeting deadlines. This shortcoming leaves systems\nvulnerable to attackers. While a plethora of tools are available for\nprogrammers to scan their code for vulnerabilities, finding the right tool can\nbe challenging. It is therefore imperative to adopt measures to get programmers\nto utilize code analysis tools that will help them produce more secure code.\nThis chapter looks at the limitations of existing approaches to secure coding\nand proposes a methodology that allows programmers to scan and fix\nvulnerabilities in program code by communicating with virtual assistants on\ntheir smart devices. With the ubiquitous move towards virtual assistants, it is\nimportant to design systems that are more reliant on voice than on standard\npoint-and-click and keyboard-driven approaches. Consequently, we propose\nMyCodeAnalyzer, a Google Assistant app and code analysis framework, which was\ndesigned to interactively scan program code for vulnerabilities and flaws using\nvoice commands during development. We describe the proposed methodology,\nimplement a prototype, test it on a vulnerable project and present our results.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 20:53:44 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 20:28:30 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Nembhard", "Fitzroy D.", ""], ["Carvalho", "Marco M.", ""]]}, {"id": "2105.03509", "submitter": "Walter Lucia", "authors": "Walter Lucia and Amr Youssef", "title": "Wyner wiretap-like encoding scheme for cyber-physical systems", "comments": null, "journal-ref": "IET Cyber-Physical Systems: Theory & Applications, Vol. 5, No. 4,\n  pp. 359-365, 2020", "doi": "10.1049/iet-cps.2020.0012", "report-no": null, "categories": "eess.SY cs.CR cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, the authors consider the problem of exchanging secrete\nmessages in cyber-physical systems (CPSs) without resorting to cryptographic\nsolutions. In particular, they consider a CPS where the networked controller\nwants to send a secrete message to the plant. They show that such a problem can\nbe solved by exploiting a Wyner wiretap-like encoding scheme taking advantage\nof the closed-loop operations typical of feedback control systems.\nSpecifically, by resorting to the control concept of one-step reachable sets,\nthey first show that a wiretap-like encoding scheme exists whenever there is an\nasymmetry in the plant model knowledge available to control system (the\ndefender) and to the eavesdropper. The effectiveness of the proposed scheme is\nconfirmed by means of a numerical example. Finally, they conclude the study by\npresenting open design challenges that can be addressed by the research\ncommunity to improve, in different directions, the secrete message exchange\nproblem in CPSs\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 21:13:48 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Lucia", "Walter", ""], ["Youssef", "Amr", ""]]}, {"id": "2105.03521", "submitter": "Ian Moore PhD", "authors": "Ian C. Moore and Jagdeep Sidhu", "title": "Stochastic Properties of EIP-1559 Basefees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  EIP-1559 is a new proposed pricing mechanism for the Ethereum protocol\ndeveloped to bring stability to fluctuating gas prices. To properly understand\nthis as a stochastic process, it is necessary to develop the mathematical\nfoundations to understand under what conditions the base fee gas price outcomes\nbehave as a stationary process, and when it does not. Understanding these\nmathematical fundamentals is critical to properly engineering a stable system.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 22:14:22 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 19:53:36 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Moore", "Ian C.", ""], ["Sidhu", "Jagdeep", ""]]}, {"id": "2105.03567", "submitter": "Weibin Li", "authors": "Weibin Li, Qiwei Zhong, Qingyang Zhao, Hongchun Zhang, Xiaonan Meng", "title": "Multimodal and Contrastive Learning for Click Fraud Detection", "comments": "Accepted to DeMal@WWW 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Advertising click fraud detection plays one of the vital roles in current\nE-commerce websites as advertising is an essential component of its business\nmodel. It aims at, given a set of corresponding features, e.g., demographic\ninformation of users and statistical features of clicks, predicting whether a\nclick is fraudulent or not in the community. Recent efforts attempted to\nincorporate attributed behavior sequence and heterogeneous network for\nextracting complex features of users and achieved significant effects on click\nfraud detection. In this paper, we propose a Multimodal and Contrastive\nlearning network for Click Fraud detection (MCCF). Specifically, motivated by\nthe observations on differences of demographic information, behavior sequences\nand media relationship between fraudsters and genuine users on E-commerce\nplatform, MCCF jointly utilizes wide and deep features, behavior sequence and\nheterogeneous network to distill click representations. Moreover, these three\nmodules are integrated by contrastive learning and collaboratively contribute\nto the final predictions. With the real-world datasets containing 2.54 million\nclicks on Alibaba platform, we investigate the effectiveness of MCCF. The\nexperimental results show that the proposed approach is able to improve AUC by\n7.2% and F1-score by 15.6%, compared with the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 03:03:11 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Li", "Weibin", ""], ["Zhong", "Qiwei", ""], ["Zhao", "Qingyang", ""], ["Zhang", "Hongchun", ""], ["Meng", "Xiaonan", ""]]}, {"id": "2105.03572", "submitter": "Bin Cao", "authors": "Bin Cao, Zixin Wang, Long Zhang, Daquan Feng, Mugen Peng, Lei Zhang", "title": "Blockchain Systems, Technologies and Applications: A Methodology\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, blockchain has shown a promising vision greatly to build\nthe trust without any powerful third party in a secure, decentralized and\nsalable manner. However, due to the wide application and future development\nfrom cryptocurrency to Internet of Things, blockchain is an extremely complex\nsystem enabling integration with mathematics, finance, computer science,\ncommunication and network engineering, etc. As a result, it is a challenge for\nengineer, expert and researcher to fully understand the blockchain process in a\nsystematic view from top to down. First, this article introduces how blockchain\nworks, the research activity and challenge, and illustrates the roadmap\ninvolving the classic methodology with typical blockchain use cases and topics.\nSecond, in blockchain system, how to adopt stochastic process, game theory,\noptimization, machine learning and cryptography to study blockchain running\nprocess and design blockchain protocol/algorithm are discussed in details.\nMoreover, the advantage and limitation using these methods are also summarized\nas the guide of future work to further considered. Finally, some remaining\nproblems from technical, commercial and political views are discussed as the\nopen issues. The main findings of this article will provide an overview in a\nmethodology perspective to study theoretical model for blockchain fundamentals\nunderstanding, design network service for blockchain-based mechanisms and\nalgorithms, as well as apply blockchain for Internet of Things, etc.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 03:19:11 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Cao", "Bin", ""], ["Wang", "Zixin", ""], ["Zhang", "Long", ""], ["Feng", "Daquan", ""], ["Peng", "Mugen", ""], ["Zhang", "Lei", ""]]}, {"id": "2105.03592", "submitter": "Chen Wang", "authors": "Jian Chen, Xuxin Zhang, Rui Zhang, Chen Wang, Ling Liu", "title": "De-Pois: An Attack-Agnostic Defense against Data Poisoning Attacks", "comments": "To be published in IEEE Transactions on Information Forensics and\n  Security", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques have been widely applied to various applications.\nHowever, they are potentially vulnerable to data poisoning attacks, where\nsophisticated attackers can disrupt the learning procedure by injecting a\nfraction of malicious samples into the training dataset. Existing defense\ntechniques against poisoning attacks are largely attack-specific: they are\ndesigned for one specific type of attacks but do not work for other types,\nmainly due to the distinct principles they follow. Yet few general defense\nstrategies have been developed. In this paper, we propose De-Pois, an\nattack-agnostic defense against poisoning attacks. The key idea of De-Pois is\nto train a mimic model the purpose of which is to imitate the behavior of the\ntarget model trained by clean samples. We take advantage of Generative\nAdversarial Networks (GANs) to facilitate informative training data\naugmentation as well as the mimic model construction. By comparing the\nprediction differences between the mimic model and the target model, De-Pois is\nthus able to distinguish the poisoned samples from clean ones, without explicit\nknowledge of any ML algorithms or types of poisoning attacks. We implement four\ntypes of poisoning attacks and evaluate De-Pois with five typical defense\nmethods on different realistic datasets. The results demonstrate that De-Pois\nis effective and efficient for detecting poisoned data against all the four\ntypes of poisoning attacks, with both the accuracy and F1-score over 0.9 on\naverage.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 04:47:37 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Chen", "Jian", ""], ["Zhang", "Xuxin", ""], ["Zhang", "Rui", ""], ["Wang", "Chen", ""], ["Liu", "Ling", ""]]}, {"id": "2105.03619", "submitter": "Tao Wang", "authors": "Tao Wang and Tongjiang Yan and Xueting Wang", "title": "Quantum Synchronizable Codes on Sextic Cyclotomy", "comments": "Quantum Synchronizable, Sextic cyclotomy, Cyclic code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum synchronizable codes are kinds of quantum error-correcting codes that\ncan not only correct the effects of quantum noise on qubits but also the\nmisalignment in block synchronization. In this paper, the quantum\nsynchronizable codes constructed are CSS quantum error-correcting codes whose\nsynchronization capabilities reach the upper bound. And we use cyclic codes\ngained by sextic cyclotomic classes to construct two classes of quantum\nsynchronizable codes. Moreover, the quantum synchronizable codes are posses\ngood error-correcting capability towards bit error and phase error, since the\ncyclic codes we used are optimal or almost optimal.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 07:45:36 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Wang", "Tao", ""], ["Yan", "Tongjiang", ""], ["Wang", "Xueting", ""]]}, {"id": "2105.03642", "submitter": "Neel Kanth Kundu", "authors": "Neel Kanth Kundu, Soumya P. Dash, Matthew R. McKay, and Ranjan K.\n  Mallik", "title": "MIMO Terahertz Quantum Key Distribution", "comments": "Revisions submitted to IEEE Communications Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR eess.SP math.IT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multiple-input multiple-output (MIMO) quantum key distribution\n(QKD) scheme for terahertz (THz) frequency applications operating at room\ntemperature. Motivated by classical MIMO communications, a transmit-receive\nbeamforming scheme is proposed that converts the rank-$r$ MIMO channel between\nAlice and Bob into $r$ parallel lossy quantum channels. Compared with existing\nsingle-antenna QKD schemes, we demonstrate that the MIMO QKD scheme leads to\nperformance improvements by increasing the secret key rate and extending the\ntransmission distance. Our simulation results show that multiple antennas are\nnecessary to overcome the high free-space path loss at THz frequencies. We\ndemonstrate a non-monotonic relation between performance and frequency, and\nreveal that positive key rates are achievable in the $10-30$ THz frequency\nrange. The proposed scheme can be used for both indoor and outdoor QKD\napplications for beyond fifth-generation ultra-secure wireless communications\nsystems.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 08:54:02 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 03:28:01 GMT"}, {"version": "v3", "created": "Sat, 10 Jul 2021 05:39:28 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Kundu", "Neel Kanth", ""], ["Dash", "Soumya P.", ""], ["McKay", "Matthew R.", ""], ["Mallik", "Ranjan K.", ""]]}, {"id": "2105.03689", "submitter": "Leo Yu Zhang Dr.", "authors": "Zhaoxi Zhang, Leo Yu Zhang, Xufei Zheng, Shengshan Hu, Jinyu Tian,\n  Jiantao Zhou", "title": "Self-Supervised Adversarial Example Detection by Disentangled\n  Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning models are known to be vulnerable to adversarial examples that\nare elaborately designed for malicious purposes and are imperceptible to the\nhuman perceptual system. Autoencoder, when trained solely over benign examples,\nhas been widely used for (self-supervised) adversarial detection based on the\nassumption that adversarial examples yield larger reconstruction error.\nHowever, because lacking adversarial examples in its training and the too\nstrong generalization ability of autoencoder, this assumption does not always\nhold true in practice. To alleviate this problem, we explore to detect\nadversarial examples by disentangled representations of images under the\nautoencoder structure. By disentangling input images as class features and\nsemantic features, we train an autoencoder, assisted by a discriminator\nnetwork, over both correctly paired class/semantic features and incorrectly\npaired class/semantic features to reconstruct benign and counterexamples. This\nmimics the behavior of adversarial examples and can reduce the unnecessary\ngeneralization ability of autoencoder. Compared with the state-of-the-art\nself-supervised detection methods, our method exhibits better performance in\nvarious measurements (i.e., AUC, FPR, TPR) over different datasets (MNIST,\nFashion-MNIST and CIFAR-10), different adversarial attack methods (FGSM, BIM,\nPGD, DeepFool, and CW) and different victim models (8-layer CNN and 16-layer\nVGG). We compare our method with the state-of-the-art self-supervised detection\nmethods under different adversarial attacks and different victim models (30\nattack settings), and it exhibits better performance in various measurements\n(AUC, FPR, TPR) for most attacks settings. Ideally, AUC is $1$ and our method\nachieves $0.99+$ on CIFAR-10 for all attacks. Notably, different from other\nAutoencoder-based detectors, our method can provide resistance to the adaptive\nadversary.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 12:48:18 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 12:37:42 GMT"}, {"version": "v3", "created": "Thu, 27 May 2021 12:07:49 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Zhang", "Zhaoxi", ""], ["Zhang", "Leo Yu", ""], ["Zheng", "Xufei", ""], ["Hu", "Shengshan", ""], ["Tian", "Jinyu", ""], ["Zhou", "Jiantao", ""]]}, {"id": "2105.03692", "submitter": "Charles Jin", "authors": "Charles Jin, Melinda Sun, Martin Rinard", "title": "Provable Guarantees against Data Poisoning Using Self-Expansion and\n  Compatibility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A recent line of work has shown that deep networks are highly susceptible to\nbackdoor data poisoning attacks. Specifically, by injecting a small amount of\nmalicious data into the training distribution, an adversary gains the ability\nto control the model's behavior during inference. In this work, we propose an\niterative training procedure for removing poisoned data from the training set.\nOur approach consists of two steps. We first train an ensemble of weak learners\nto automatically discover distinct subpopulations in the training set. We then\nleverage a boosting framework to recover the clean data. Empirically, our\nmethod successfully defends against several state-of-the-art backdoor attacks,\nincluding both clean and dirty label attacks. We also present results from an\nindependent third-party evaluation including a recent \\textit{adaptive}\npoisoning adversary. The results indicate our approach is competitive with\nexisting defenses against backdoor attacks on deep neural networks, and\nsignificantly outperforms the state-of-the-art in several scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 13:01:42 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Jin", "Charles", ""], ["Sun", "Melinda", ""], ["Rinard", "Martin", ""]]}, {"id": "2105.03726", "submitter": "Kathrin Grosse", "authors": "Lukas Bieringer, Kathrin Grosse, Michael Backes, Katharina Krombholz", "title": "Mental Models of Adversarial Machine Learning", "comments": "19 pages, 8 figures, under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although machine learning (ML) is widely used in practice, little is known\nabout practitioners' actual understanding of potential security challenges. In\nthis work, we close this substantial gap in the literature and contribute a\nqualitative study focusing on developers' mental models of the ML pipeline and\npotentially vulnerable components. Studying mental models has helped in other\nsecurity fields to discover root causes or improve risk communication. Our\nstudy reveals four characteristic ranges in mental models of industrial\npractitioners. The first range concerns the intertwined relationship of\nadversarial machine learning (AML) and classical security. The second range\ndescribes structural and functional components. The third range expresses\nindividual variations of mental models, which are neither explained by the\napplication nor by the educational background of the corresponding subjects.\nThe fourth range corresponds to the varying levels of technical depth, which\nare however not determined by our subjects' level of knowledge. Our\ncharacteristic ranges have implications for the integration of AML into\ncorporate workflows, security enhancing tools for practitioners, and creating\nappropriate regulatory frameworks for AML.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 16:05:07 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Bieringer", "Lukas", ""], ["Grosse", "Kathrin", ""], ["Backes", "Michael", ""], ["Krombholz", "Katharina", ""]]}, {"id": "2105.03822", "submitter": "Huming Qiu", "authors": "Huming Qiu, Hua Ma, Zhi Zhang, Yifeng Zheng, Anmin Fu, Pan Zhou,\n  Yansong Gao, Derek Abbott, Said F. Al-Sarawi", "title": "RBNN: Memory-Efficient Reconfigurable Deep Binary Neural Network with IP\n  Protection for Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though deep neural network models exhibit outstanding performance for various\napplications, their large model size and extensive floating-point operations\nrender deployment on mobile computing platforms a major challenge, and, in\nparticular, on Internet of Things devices. One appealing solution is model\nquantization that reduces the model size and uses integer operations commonly\nsupported by microcontrollers . To this end, a 1-bit quantized DNN model or\ndeep binary neural network maximizes the memory efficiency, where each\nparameter in a BNN model has only 1-bit. In this paper, we propose a\nreconfigurable BNN (RBNN) to further amplify the memory efficiency for\nresource-constrained IoT devices. Generally, the RBNN can be reconfigured on\ndemand to achieve any one of M (M>1) distinct tasks with the same parameter\nset, thus only a single task determines the memory requirements. In other\nwords, the memory utilization is improved by times M. Our extensive experiments\ncorroborate that up to seven commonly used tasks can co-exist (the value of M\ncan be larger). These tasks with a varying number of classes have no or\nnegligible accuracy drop-off on three binarized popular DNN architectures\nincluding VGG, ResNet, and ReActNet. The tasks span across different domains,\ne.g., computer vision and audio domains validated herein, with the prerequisite\nthat the model architecture can serve those cross-domain tasks. To protect the\nintellectual property of an RBNN model, the reconfiguration can be controlled\nby both a user key and a device-unique root key generated by the intrinsic\nhardware fingerprint. By doing so, an RBNN model can only be used per paid user\nper authorized device, thus benefiting both the user and the model provider.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 03:28:14 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 04:51:44 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Qiu", "Huming", ""], ["Ma", "Hua", ""], ["Zhang", "Zhi", ""], ["Zheng", "Yifeng", ""], ["Fu", "Anmin", ""], ["Zhou", "Pan", ""], ["Gao", "Yansong", ""], ["Abbott", "Derek", ""], ["Al-Sarawi", "Said F.", ""]]}, {"id": "2105.03834", "submitter": "Hyung-Jin Yoon", "authors": "Hyung-Jin Yoon, Hamidreza Jafarnejadsani, Petros Voulgaris", "title": "Learning Image Attacks toward Vision Guided Autonomous Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While adversarial neural networks have been shown successful for static image\nattacks, very few approaches have been developed for attacking online image\nstreams while taking into account the underlying physical dynamics of\nautonomous vehicles, their mission, and environment. This paper presents an\nonline adversarial machine learning framework that can effectively misguide\nautonomous vehicles' missions. In the existing image attack methods devised\ntoward autonomous vehicles, optimization steps are repeated for every image\nframe. This framework removes the need for fully converged optimization at\nevery frame to realize image attacks in real-time. Using reinforcement\nlearning, a generative neural network is trained over a set of image frames to\nobtain an attack policy that is more robust to dynamic and uncertain\nenvironments. A state estimator is introduced for processing image streams to\nreduce the attack policy's sensitivity to physical variables such as unknown\nposition and velocity. A simulation study is provided to validate the results.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 04:34:10 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 19:01:33 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Yoon", "Hyung-Jin", ""], ["Jafarnejadsani", "Hamidreza", ""], ["Voulgaris", "Petros", ""]]}, {"id": "2105.03867", "submitter": "Weixuan Tang", "authors": "Weixuan Tang, Bin Li, Mauro Barni, Jin Li, Jiwu Huang", "title": "Improving Cost Learning for JPEG Steganography by Exploiting JPEG Domain\n  Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although significant progress in automatic learning of steganographic cost\nhas been achieved recently, existing methods designed for spatial images are\nnot well applicable to JPEG images which are more common media in daily life.\nThe difficulties of migration mostly lie in the unique and complicated JPEG\ncharacteristics caused by 8x8 DCT mode structure. To address the issue, in this\npaper we extend an existing automatic cost learning scheme to JPEG, where the\nproposed scheme called JEC-RL (JPEG Embedding Cost with Reinforcement Learning)\nis explicitly designed to tailor the JPEG DCT structure. It works with the\nembedding action sampling mechanism under reinforcement learning, where a\npolicy network learns the optimal embedding policies via maximizing the rewards\nprovided by an environment network. The policy network is constructed following\na domain-transition design paradigm, where three modules including pixel-level\ntexture complexity evaluation, DCT feature extraction, and mode-wise\nrearrangement, are proposed. These modules operate in serial, gradually\nextracting useful features from a decompressed JPEG image and converting them\ninto embedding policies for DCT elements, while considering JPEG\ncharacteristics including inter-block and intra-block correlations\nsimultaneously. The environment network is designed in a gradient-oriented way\nto provide stable reward values by using a wide architecture equipped with a\nfixed preprocessing layer with 8x8 DCT basis filters. Extensive experiments and\nablation studies demonstrate that the proposed method can achieve good security\nperformance for JPEG images against both advanced feature based and modern CNN\nbased steganalyzers.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 08:10:41 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Tang", "Weixuan", ""], ["Li", "Bin", ""], ["Barni", "Mauro", ""], ["Li", "Jin", ""], ["Huang", "Jiwu", ""]]}, {"id": "2105.03875", "submitter": "Ganesh Del Grosso", "authors": "Ganesh Del Grosso, Georg Pichler, Catuscia Palamidessi, Pablo\n  Piantanida", "title": "Bounding Information Leakage in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine Learning services are being deployed in a large range of applications\nthat make it easy for an adversary, using the algorithm and/or the model, to\ngain access to sensitive data. This paper investigates fundamental bounds on\ninformation leakage. First, we identify and bound the success rate of the\nworst-case membership inference attack, connecting it to the generalization\nerror of the target model. Second, we study the question of how much sensitive\ninformation is stored by the algorithm about the training set and we derive\nbounds on the mutual information between the sensitive attributes and model\nparameters. Although our contributions are mostly of theoretical nature, the\nbounds and involved concepts are of practical relevance. Inspired by our\ntheoretical analysis, we study linear regression and DNN models to illustrate\nhow these bounds can be used to assess the privacy guarantees of ML models.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 08:49:14 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Del Grosso", "Ganesh", ""], ["Pichler", "Georg", ""], ["Palamidessi", "Catuscia", ""], ["Piantanida", "Pablo", ""]]}, {"id": "2105.03905", "submitter": "Ferhat Ozgur Catak", "authors": "Ferhat Ozgur Catak, Evren Catak, Murat Kuzlu, Umit Cali, Devrim Unal", "title": "Security Concerns on Machine Learning Solutions for 6G Networks in\n  mmWave Beam Prediction", "comments": "16 Pages, under review. arXiv admin note: substantial text overlap\n  with arXiv:2103.07268", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  6G -- sixth generation -- is the latest cellular technology currently under\ndevelopment for wireless communication systems. In recent years, machine\nlearning algorithms have been applied widely in various fields, such as\nhealthcare, transportation, energy, autonomous car, and many more. Those\nalgorithms have been also using in communication technologies to improve the\nsystem performance in terms of frequency spectrum usage, latency, and security.\nWith the rapid developments of machine learning techniques, especially deep\nlearning, it is critical to take the security concern into account when\napplying the algorithms. While machine learning algorithms offer significant\nadvantages for 6G networks, security concerns on Artificial Intelligent (AI)\nmodels is typically ignored by the scientific community so far. However,\nsecurity is also a vital part of the AI algorithms, this is because the AI\nmodel itself can be poisoned by attackers. This paper proposes a mitigation\nmethod for adversarial attacks against proposed 6G machine learning models for\nthe millimeter-wave (mmWave) beam prediction using adversarial learning. The\nmain idea behind adversarial attacks against machine learning models is to\nproduce faulty results by manipulating trained deep learning models for 6G\napplications for mmWave beam prediction. We also present the adversarial\nlearning mitigation method's performance for 6G security in mmWave beam\nprediction application with fast gradient sign method attack. The mean square\nerrors (MSE) of the defended model under attack are very close to the\nundefended model without attack.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 10:38:53 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 11:17:01 GMT"}, {"version": "v3", "created": "Fri, 23 Jul 2021 10:51:12 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Catak", "Ferhat Ozgur", ""], ["Catak", "Evren", ""], ["Kuzlu", "Murat", ""], ["Cali", "Umit", ""], ["Unal", "Devrim", ""]]}, {"id": "2105.03931", "submitter": "Qi-An Fu", "authors": "Qi-An Fu, Yinpeng Dong, Hang Su, Jun Zhu", "title": "Automated Decision-based Adversarial Attacks", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are vulnerable to adversarial examples, which can fool a\ntarget classifier by imposing imperceptible perturbations onto natural\nexamples. In this work, we consider the practical and challenging\ndecision-based black-box adversarial setting, where the attacker can only\nacquire the final classification labels by querying the target model without\naccess to the model's details. Under this setting, existing works often rely on\nheuristics and exhibit unsatisfactory performance. To better understand the\nrationality of these heuristics and the limitations of existing methods, we\npropose to automatically discover decision-based adversarial attack algorithms.\nIn our approach, we construct a search space using basic mathematical\noperations as building blocks and develop a random search algorithm to\nefficiently explore this space by incorporating several pruning techniques and\nintuitive priors inspired by program synthesis works. Although we use a small\nand fast model to efficiently evaluate attack algorithms during the search,\nextensive experiments demonstrate that the discovered algorithms are simple yet\nquery-efficient when transferred to larger normal and defensive models on the\nCIFAR-10 and ImageNet datasets. They achieve comparable or better performance\nthan the state-of-the-art decision-based attack methods consistently.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 13:15:10 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Fu", "Qi-An", ""], ["Dong", "Yinpeng", ""], ["Su", "Hang", ""], ["Zhu", "Jun", ""]]}, {"id": "2105.03941", "submitter": "Lorenzo Minto", "authors": "Lorenzo Minto, Moritz Haller, Hamed Haddadi, Benjamin Livshits", "title": "Stronger Privacy for Federated Collaborative Filtering with Implicit\n  Feedback", "comments": "Accepted for publication at RecSys 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are commonly trained on centrally collected user\ninteraction data like views or clicks. This practice however raises serious\nprivacy concerns regarding the recommender's collection and handling of\npotentially sensitive data. Several privacy-aware recommender systems have been\nproposed in recent literature, but comparatively little attention has been\ngiven to systems at the intersection of implicit feedback and privacy. To\naddress this shortcoming, we propose a practical federated recommender system\nfor implicit data under user-level local differential privacy (LDP). The\nprivacy-utility trade-off is controlled by parameters $\\epsilon$ and $k$,\nregulating the per-update privacy budget and the number of $\\epsilon$-LDP\ngradient updates sent by each user respectively. To further protect the user's\nprivacy, we introduce a proxy network to reduce the fingerprinting surface by\nanonymizing and shuffling the reports before forwarding them to the\nrecommender. We empirically demonstrate the effectiveness of our framework on\nthe MovieLens dataset, achieving up to Hit Ratio with K=10 (HR@10) 0.68 on 50k\nusers with 5k items. Even on the full dataset, we show that it is possible to\nachieve reasonable utility with HR@10>0.5 without compromising user privacy.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 13:41:45 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 10:05:37 GMT"}, {"version": "v3", "created": "Wed, 28 Jul 2021 09:39:01 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Minto", "Lorenzo", ""], ["Haller", "Moritz", ""], ["Haddadi", "Hamed", ""], ["Livshits", "Benjamin", ""]]}, {"id": "2105.04044", "submitter": "Sean Adamson", "authors": "Sean A. Adamson, Petros Wallden", "title": "Practical Parallel Self-testing of Bell States via Magic Rectangles", "comments": "26 pages, 4 figures; comments are very welcome!", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-testing is a method to verify that one has a particular quantum state\nfrom purely classical statistics. For practical applications, such as\ndevice-independent delegated verifiable quantum computation, it is crucial that\none self-tests multiple Bell states in parallel while keeping the quantum\ncapabilities required of one side to a minimum. In this work we use the $3\n\\times n$ magic rectangle games (generalisations of the magic square game) to\nobtain a self-test for $n$ Bell states where the one side needs only to measure\nsingle-qubit Pauli observables. The protocol requires small input size\n(constant for Alice and $O(\\log n)$ bits for Bob) and is robust with robustness\n$O(n^{5/2} \\sqrt{\\varepsilon})$, where $\\varepsilon$ is the closeness of the\nobserved correlations to the ideal. To achieve the desired self-test we\nintroduce a one-side-local quantum strategy for the magic square game that wins\nwith certainty, generalise this strategy to the family of $3 \\times n$ magic\nrectangle games, and supplement these nonlocal games with extra check rounds\n(of single and pairs of observables).\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 23:07:18 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Adamson", "Sean A.", ""], ["Wallden", "Petros", ""]]}, {"id": "2105.04236", "submitter": "Deevashwer Rathee", "authors": "Deevashwer Rathee, Mayank Rathee, Rahul Kranti Kiran Goli, Divya\n  Gupta, Rahul Sharma, Nishanth Chandran, Aseem Rastogi", "title": "SIRNN: A Math Library for Secure RNN Inference", "comments": "IEEE Security and Privacy 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex machine learning (ML) inference algorithms like recurrent neural\nnetworks (RNNs) use standard functions from math libraries like exponentiation,\nsigmoid, tanh, and reciprocal of square root. Although prior work on secure\n2-party inference provides specialized protocols for convolutional neural\nnetworks (CNNs), existing secure implementations of these math operators rely\non generic 2-party computation (2PC) protocols that suffer from high\ncommunication. We provide new specialized 2PC protocols for math functions that\ncrucially rely on lookup-tables and mixed-bitwidths to address this performance\noverhead; our protocols for math functions communicate up to 423x less data\nthan prior work. Some of the mixed bitwidth operations used by our math\nimplementations are (zero and signed) extensions, different forms of\ntruncations, multiplication of operands of mixed-bitwidths, and digit\ndecomposition (a generalization of bit decomposition to larger digits). For\neach of these primitive operations, we construct specialized 2PC protocols that\nare more communication efficient than generic 2PC, and can be of independent\ninterest. Furthermore, our math implementations are numerically precise, which\nensures that the secure implementations preserve model accuracy of cleartext.\nWe build on top of our novel protocols to build SIRNN, a library for end-to-end\nsecure 2-party DNN inference, that provides the first secure implementations of\nan RNN operating on time series sensor data, an RNN operating on speech data,\nand a state-of-the-art ML architecture that combines CNNs and RNNs for\nidentifying all heads present in images. Our evaluation shows that SIRNN\nachieves up to three orders of magnitude of performance improvement when\ncompared to inference of these models using an existing state-of-the-art 2PC\nframework.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 10:04:46 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Rathee", "Deevashwer", ""], ["Rathee", "Mayank", ""], ["Goli", "Rahul Kranti Kiran", ""], ["Gupta", "Divya", ""], ["Sharma", "Rahul", ""], ["Chandran", "Nishanth", ""], ["Rastogi", "Aseem", ""]]}, {"id": "2105.04260", "submitter": "Sarad Venugopalan", "authors": "Nandha Kumar Kandasamy, Sarad Venugopalan, Tin Kit Wong, Leu Junming\n  Nicholas", "title": "EPICTWIN: An Electric Power Digital Twin for Cyber Security Testing,\n  Research and Education", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Cyber-Physical Systems (CPS) rely on advanced communication and control\ntechnologies to efficiently manage devices and the flow of information in the\nsystem. However, a wide variety of potential security challenges has emerged\ndue to the evolution of critical infrastructures (CI) from siloed sub-systems\ninto connected and integrated networks. This is also the case for CI such as a\nsmart grid. Smart grid security studies are carried out on physical test-beds\nto provide its users a platform to train and test cyber attacks, in a safe and\ncontrolled environment. However, it has limitations w.r.t modifying physical\nconfiguration and difficulty to scale.\n  To overcome these shortcomings, we built a digital power twin for a physical\ntest-bed that is used for cyber security studies on smart grids. On the\ndeveloped twin, the users can deploy real world attacks and countermeasures, to\ntest and study its effectiveness. The difference from the physical test-bed is\nthat its users may easily modify their power system components and\nconfigurations. Further, reproducing the twin for using and advancing the\nresearch is significantly cheaper. The developed twin has advanced features\ncompared to any equivalent system in the literature. To illustrate a typical\nuse case, we present a case study where a cyber attack is launched and discuss\nits implications.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 10:56:55 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Kandasamy", "Nandha Kumar", ""], ["Venugopalan", "Sarad", ""], ["Wong", "Tin Kit", ""], ["Nicholas", "Leu Junming", ""]]}, {"id": "2105.04264", "submitter": "Nicholas Kolokotronis", "authors": "Christos-Minas Mathas, Konstantinos-Panagiotis Grammatikakis, Costas\n  Vassilakis, Nicholas Kolokotronis, Vasiliki-Georgia Bilali, Dimitris\n  Kavallieros", "title": "Threat Landscape for Smart Grid Systems", "comments": null, "journal-ref": "15th International Conference on Availability, Reliability and\n  Security (ARES 2020)", "doi": "10.1145/3407023.3409229", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart Grids are energy delivery networks, constituting an evolution of power\ngrids, in which a bidirectional flow between power providers and consumers is\nestablished. These flows support the transfer of electricity and information,\nin order to support automation actions in the context of the energy delivery\nnetwork. Insofar, many smart grid implementations and implementation proposals\nhave emerged, with varying degrees of feature delivery and sophistication.\nWhile smart grids offer many advantages, their distributed nature and\ninformation flow streams between energy producers and consumers enable the\nlaunching of a number of attacks against the smart grid infrastructure, where\nthe related consequences may range from economic loss to complete failure of\nthe smart grid. In this paper, we survey the threat landscape of smart grids,\nidentifying threats that are specific to this infrastructure, providing an\nassessment of the severity of the consequences of each attack type, discerning\nfeatures that can be utilized to detect attacks and listing methods that can be\nused to mitigate them.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 11:03:05 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Mathas", "Christos-Minas", ""], ["Grammatikakis", "Konstantinos-Panagiotis", ""], ["Vassilakis", "Costas", ""], ["Kolokotronis", "Nicholas", ""], ["Bilali", "Vasiliki-Georgia", ""], ["Kavallieros", "Dimitris", ""]]}, {"id": "2105.04272", "submitter": "Nicholas Kolokotronis", "authors": "Gueltoum Bendiab, Konstantinos-Panagiotis Grammatikakis, Ioannis\n  Koufos, Nicholas Kolokotronis, and Stavros Shiaeles", "title": "Advanced Metering Infrastructures: Security Risks and Mitigation", "comments": null, "journal-ref": "15th International Conference on Availability, Reliability and\n  Security (ARES 2020)", "doi": "10.1145/3407023.3409312", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy providers are moving to the smart meter era, encouraging consumers to\ninstall, free of charge, these devices in their homes, automating consumption\nreadings submission and making consumers life easier. However, the increased\ndeployment of such smart devices brings a lot of security and privacy risks. In\norder to overcome such risks, Intrusion Detection Systems are presented as\npertinent tools that can provide network-level protection for smart devices\ndeployed in home environments. In this context, this paper is exploring the\nproblems of Advanced Metering Infrastructures (AMI) and proposing a novel\nMachine Learning (ML) Intrusion Prevention System (IPS) to get optimal\ndecisions based on a variety of factors and graphical security models able to\ntackle zero-day attacks.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 11:16:58 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Bendiab", "Gueltoum", ""], ["Grammatikakis", "Konstantinos-Panagiotis", ""], ["Koufos", "Ioannis", ""], ["Kolokotronis", "Nicholas", ""], ["Shiaeles", "Stavros", ""]]}, {"id": "2105.04301", "submitter": "Zhewei Chen", "authors": "Zhewei Chen, Linyue Zhou, Wenwen Yu", "title": "ADASYN-Random Forest Based Intrusion Detection Model", "comments": "SPML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrusion detection has been a key topic in the field of cyber security, and\nthe common network threats nowadays have the characteristics of varieties and\nvariation. Considering the serious imbalance of intrusion detection datasets\nwill result in low classification performance on attack behaviors of small\nsample size and difficulty to detect network attacks accurately and\nefficiently, using Adaptive Synthetic Sampling (ADASYN) method to balance\ndatasets was proposed in this paper. In addition, Random Forest algorithm was\nused to train intrusion detection classifiers. Through the comparative\nexperiment of Intrusion detection on CICIDS 2017 dataset, it is found that\nADASYN with Random Forest performs better. Based on the experimental results,\nthe improvement of precision, recall, F1 scores and AUC values after ADASYN is\nthen analyzed. Experiments show that the proposed method can be applied to\nintrusion detection with large data, and can effectively improve the\nclassification accuracy of network attack behaviors. Compared with traditional\nmachine learning models, it has better performance, generalization ability and\nrobustness.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 12:22:36 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 14:26:18 GMT"}, {"version": "v3", "created": "Thu, 20 May 2021 02:04:09 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Chen", "Zhewei", ""], ["Zhou", "Linyue", ""], ["Yu", "Wenwen", ""]]}, {"id": "2105.04351", "submitter": "Srinivas Vivek", "authors": "Srinivas Vivek", "title": "Attacks on a Privacy-Preserving Publish-Subscribe System and a\n  Ride-Hailing Service", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A privacy-preserving Context-Aware Publish-Subscribe System (CA-PSS) enables\nan intermediary (broker) to match the content from a publisher and the\nsubscription by a subscriber based on the current context while preserving\nconfidentiality of the subscriptions and notifications. While a\nprivacy-preserving Ride-Hailing Service (RHS) enables an intermediary (service\nprovider) to match a ride request with a taxi driver in a privacy-friendly\nmanner. In this work, we attack a privacy-preserving CA-PSS proposed by Nabeel\net al. (2013), where we show that any entity in the system including the broker\ncan learn the confidential subscriptions of the subscribers. We also attack a\nprivacy-preserving RHS called lpRide proposed by Yu et al. (2019), where we\nshow that any rider/driver can efficiently recover the secret keys of all other\nriders and drivers. Also, we show that any rider/driver will be able to learn\nthe location of any rider. The attacks are based on our cryptanalysis of the\nmodified Paillier cryptosystem proposed by Nabeel et al. that forms a building\nblock for both the above protocols.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 13:38:10 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Vivek", "Srinivas", ""]]}, {"id": "2105.04380", "submitter": "Haaroon Yousaf", "authors": "Tyler Kell, Haaroon Yousaf, Sarah Allen, Sarah Meiklejohn, Ari Juels", "title": "Forsage: Anatomy of a Smart-Contract Pyramid Scheme", "comments": "17 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pyramid schemes are investment scams in which top-level participants in a\nhierarchical network recruit and profit from an expanding base of defrauded\nnewer participants. Pyramid schemes have existed for over a century, but there\nhave been no in-depth studies of their dynamics and communities because of the\nopacity of participants' transactions.\n  In this paper, we present an empirical study of Forsage, a pyramid scheme\nimplemented as a smart contract and at its peak one of the largest consumers of\nresources in Ethereum. As a smart contract, Forsage makes its (byte)code and\nall of its transactions visible on the blockchain. We take advantage of this\nunprecedented transparency to gain insight into the mechanics, impact on\nparticipants, and evolution of Forsage.\n  We quantify the (multi-million-dollar) gains of top-level participants as\nwell as the losses of the vast majority (around 88%) of users. We analyze\nForsage code both manually and using a purpose-built transaction simulator to\nuncover the complex mechanics of the scheme. Through complementary study of\npromotional videos and social media, we show how Forsage promoters have\nleveraged the unique features of smart contracts to lure users with false\nclaims of trustworthiness and profitability, and how Forsage activity is\nconcentrated within a small number of national communities.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 14:00:22 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Kell", "Tyler", ""], ["Yousaf", "Haaroon", ""], ["Allen", "Sarah", ""], ["Meiklejohn", "Sarah", ""], ["Juels", "Ari", ""]]}, {"id": "2105.04381", "submitter": "Imane Fouad", "authors": "Imane Fouad, Cristiana Santos, Arnaud Legout, Nataliia Bielova", "title": "Did I delete my cookies? Cookies respawning with browser fingerprinting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Stateful and stateless web tracking gathered much attention in the last\ndecade, however they were always measured separately. To the best of our\nknowledge, our study is the first to detect and measure cookie respawning with\nbrowser and machine fingerprinting. We develop a detection methodology that\nallows us to detect cookies dependency on browser and machine features. Our\nresults show that 1,150 out of the top 30, 000 Alexa websites deploy this\ntracking mechanism. We further uncover how domains collaborate to respawn\ncookies through fingerprinting. We find out that this technique can be used to\ntrack users across websites even when third-party cookies are deprecated.\nTogether with a legal scholar, we conclude that cookie respawning with browser\nfingerprinting lacks legal interpretation under the GDPR and the ePrivacy\ndirective, but its use in practice may breach them, thus subjecting it to fines\nup to 20 million euro.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 08:18:12 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Fouad", "Imane", ""], ["Santos", "Cristiana", ""], ["Legout", "Arnaud", ""], ["Bielova", "Nataliia", ""]]}, {"id": "2105.04454", "submitter": "Carlton Shepherd", "authors": "Carlton Shepherd, Konstantinos Markantonakis, Nico van Heijningen,\n  Driss Aboulkassimi, Cl\\'ement Gaine, Thibaut Heckmann, David Naccache", "title": "Physical Fault Injection and Side-Channel Attacks on Mobile Devices: A\n  Comprehensive Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Today's mobile devices contain densely packaged system-on-chips (SoCs) with\nmulti-core, high-frequency CPUs and complex pipelines. In parallel,\nsophisticated SoC-assisted security mechanisms have become commonplace for\nprotecting device data, such as trusted execution environments (TEEs),\nfull-disk and file-based encryption. Both advancements have dramatically\ncomplicated the use of conventional physical attacks, which has required the\ndevelopment of specialised attacks. In this survey, we consolidate recent\ndevelopments in physical fault injections (FIAs) and side-channel attacks\n(SCAs) on modern mobile devices. In total, we comprehensively survey over 50\nfault injection and side-channel attack papers published between 2009--2021. We\nevaluate the prevailing methods, compare existing attacks using a common\nframework, identify several challenges and shortcomings, and suggest future\ndirections of research.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 15:37:09 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 13:54:56 GMT"}, {"version": "v3", "created": "Fri, 14 May 2021 12:36:30 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Shepherd", "Carlton", ""], ["Markantonakis", "Konstantinos", ""], ["van Heijningen", "Nico", ""], ["Aboulkassimi", "Driss", ""], ["Gaine", "Cl\u00e9ment", ""], ["Heckmann", "Thibaut", ""], ["Naccache", "David", ""]]}, {"id": "2105.04485", "submitter": "Hitesh Tewari Dr", "authors": "Hitesh Tewari", "title": "T-Cash: Transferable Fiat Backed Coins", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Numerous electronic cash schemes have been proposed over the years - however\nnone have been embraced by financial institutions as an alternative to fiat\ncurrency. David Chaum's ecash scheme was the closest to something that mimicked\na modern day currency system, with the important property that it provided\nanonymity for users when purchasing coins from a bank, and subsequently\nspending them at a merchant premises. However it lacked a crucial element\npresent in current fiat-based systems - the ability to continuously spend or\ntransfer coins. Bitcoin reignited the interest in cryptocurrencies in the last\ndecade but is now seen as more of an asset store as opposed to a financial\ninstrument. One interesting thing that has come out of the Bitcoin system is\nblockchains and the associated distributed consensus protocols. In this paper\nwe propose a transferable electronic cash scheme using blockchain technology\nwhich allows users to continuously reuse coins within the system.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 16:22:46 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Tewari", "Hitesh", ""]]}, {"id": "2105.04487", "submitter": "Naresh Goud Boddu", "authors": "Naresh Goud Boddu and Upendra S. Kapshikar", "title": "Tamper Detection against Unitary Operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider (Enc, Dec) schemes which are used to encode a classical/quantum\nmessage $m$ and derive an $n$-qubit quantum codeword $\\psi_m$. The quantum\ncodeword $\\psi_m$ can adversarially tamper via a unitary $U \\in \\mathcal{U}$\nfrom some known tampering unitary family $\\mathcal{U}$, resulting in $U \\psi_m\nU^\\dagger$.\n  Firstly, we initiate the general study of quantum tamper detection codes,\nwhich must detect that tampering occurred with high probability. In case there\nwas no tampering, we would like to output the message $m$ with a probability of\n$1$. We show that quantum tamper detection codes exist for both classical\nmessages and quantum messages for any family of unitaries $\\mathcal{U}$, such\nthat $|\\mathcal{U}| < 2^{2^{\\alpha n}}$ for some known constant $\\alpha \\in\n(0,1)$ and all the unitaries satisfy one additional condition :\n  \\begin{itemize}\n  \\item Far from Identity : For each $U \\in \\mathcal{U}$, we require that its\nmodulus of trace value isn't too much i.e. $ |Trace(U)| \\leq \\phi N$, where\n$N=2^n.$\n  \\end{itemize}\n  Quantum tamper-detection codes are quantum generalizations of classical\ntamper detection codes studied by Jafargholi et al. \\cite{JW15}.\n  Additionally for classical message $m$, if we must either output message $m$\nor detect that tampering occurred and output $\\perp$ with high probability, we\nshow that it is possible without the restriction of Far from Identity condition\nfor any family of unitaries $\\mathcal{U}$, such that $|\\mathcal{U} | <\n2^{2^{\\alpha n}}$. We also provide efficient (Enc, Dec) schemes when the family\nof tampering unitaries are from Pauli group $\\mathcal{P}_n$, which can be\nthought of as a quantum version of the algebraic manipulation detection (AMD)\ncodes of Cramer et al. \\cite{CDFPW08}.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 16:26:41 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 15:51:43 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Boddu", "Naresh Goud", ""], ["Kapshikar", "Upendra S.", ""]]}, {"id": "2105.04615", "submitter": "Mohit Kumar", "authors": "Mohit Kumar", "title": "Differentially Private Transfer Learning with Conditionally Deep\n  Autoencoders", "comments": "arXiv admin note: substantial text overlap with arXiv:2104.07060", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper considers the problem of differentially private semi-supervised\ntransfer learning. The notion of membership-mapping is developed using measure\ntheory basis to learn data representation via a fuzzy membership function. An\nalternative conception of deep autoencoder, referred to as Conditionally Deep\nMembership-Mapping Autoencoder (CDMMA) (that consists of a nested compositions\nof membership-mappings), is considered. Under practice-oriented settings, an\nanalytical solution for the learning of CDMFA can be derived by means of\nvariational optimization. The paper proposes a transfer learning approach that\ncombines CDMMA with a tailored noise adding mechanism to achieve a given level\nof privacy-loss bound with the minimum perturbation of the data. Numerous\nexperiments were carried out using MNIST, USPS, Office, and Caltech256 datasets\nto verify the competitive robust performance of the proposed methodology.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 18:52:44 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 05:02:54 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Kumar", "Mohit", ""]]}, {"id": "2105.04733", "submitter": "Kfir Sulimany", "authors": "Kfir Sulimany, Rom Dudkiewicz, Simcha Korenblit, Hagai S. Eisenberg,\n  Yaron Bromberg, Michael Ben-Or", "title": "Fast and Simple One-Way High-Dimensional Quantum Key Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR cs.IT math.IT physics.optics", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High-dimensional quantum key distribution (QKD) provides ultimate secure\ncommunication with secure key rates that cannot be obtained by QKD protocols\nwith binary encoding. However, so far the proposed protocols required\nadditional experimental resources, thus raising the cost of practical\nhigh-dimensional systems and limiting their use. Here, we analyze and\ndemonstrate a novel scheme for fiber-based arbitrary-dimensional QKD, based on\nthe most popular commercial hardware for binary time bins encoding. Quantum\nstate transmission is tested over 40 km channel length of standard single-mode\nfiber, exhibiting a two-fold enhancement of the secret key rate in comparison\nto the binary Coherent One Way (COW) protocol, without introducing any hardware\nmodifications. This work holds a great potential to enhance the performance of\nalready installed QKD systems by software update alone.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 01:06:36 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Sulimany", "Kfir", ""], ["Dudkiewicz", "Rom", ""], ["Korenblit", "Simcha", ""], ["Eisenberg", "Hagai S.", ""], ["Bromberg", "Yaron", ""], ["Ben-Or", "Michael", ""]]}, {"id": "2105.04749", "submitter": "Aron Laszka", "authors": "Shanto Roy, Nazia Sharmin, Jamie C. Acosta, Christopher Kiekintveld,\n  Aron Laszka", "title": "Survey and Taxonomy of Adversarial Reconnaissance Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversaries are often able to penetrate networks and compromise systems by\nexploiting vulnerabilities in people and systems. The key to the success of\nthese attacks is information that adversaries collect throughout the phases of\nthe cyber kill chain. We summarize and analyze the methods, tactics, and tools\nthat adversaries use to conduct reconnaissance activities throughout the attack\nprocess. First, we discuss what types of information adversaries seek, and how\nand when they can obtain this information. Then, we provide a taxonomy and\ndetailed overview of adversarial reconnaissance techniques. The taxonomy\nintroduces a categorization of reconnaissance techniques based on the technical\napproach, including target footprinting, social engineering, network scanning,\nand local discovery. This paper provides a comprehensive view of adversarial\nreconnaissance that can help in understanding and modeling this complex but\nvital aspect of cyber attacks as well as insights that can improve defensive\nstrategies, such as cyber deception.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 02:09:12 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Roy", "Shanto", ""], ["Sharmin", "Nazia", ""], ["Acosta", "Jamie C.", ""], ["Kiekintveld", "Christopher", ""], ["Laszka", "Aron", ""]]}, {"id": "2105.04773", "submitter": "Rajat Gupta", "authors": "Rajat Gupta, Madhu Viswanatham V., Manikandan K", "title": "An Innovative Security Strategy using Reactive Web Application Honeypot", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nowadays, web applications have become most prevalent in the industry, and\nthe critical data of most organizations stored using web apps. Hence, web\napplications a much bigger target for diverse cyber-attacks, which varies from\ndatabase injections-SQL injection, PHP object injection, template injection,\nXML external entity injection, unsanitized input attacks- Cross-Site\nScripting(XSS), and many more. As mitigation for them, among many proposed\nsolutions, web application honeypots are a much sophisticated and powerful\nprotection mechanism.\n  In this paper, we propose a low interaction, adaptive, and dynamic web\napplication honeypot that imitates the vulnerabilities through HTTP events. The\nhoneypot is built with SNARE and TANNER; SNARE creates the attack surface and\nsends the requests to TANNER, which evaluates them and decides how SNARE should\nrespond to the requests. TANNER is an analysis and classification tool, which\nanalyzes and evaluates HTTP requests served by SNARE and to compose the\nresponse, it is powered by emulators, which are engines used for the emulation\nof vulnerabilities.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 03:57:37 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Gupta", "Rajat", ""], ["V.", "Madhu Viswanatham", ""], ["K", "Manikandan", ""]]}, {"id": "2105.04808", "submitter": "Lingjuan Lyu", "authors": "Lingjuan Lyu", "title": "DP-SIGNSGD: When Efficiency Meets Privacy and Robustness", "comments": "Accepted by ICASSP21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) has emerged as a promising collaboration paradigm by\nenabling a multitude of parties to construct a joint model without exposing\ntheir private training data. Three main challenges in FL are efficiency,\nprivacy, and robustness. The recently proposed SIGNSGD with majority vote shows\na promising direction to deal with efficiency and Byzantine robustness.\nHowever, there is no guarantee that SIGNSGD is privacy-preserving. In this\npaper, we bridge this gap by presenting an improved method called DP-SIGNSGD,\nwhich can meet all the aforementioned properties. We further propose an\nerror-feedback variant of DP-SIGNSGD to improve accuracy. Experimental results\non benchmark image datasets demonstrate the effectiveness of our proposed\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 06:43:38 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Lyu", "Lingjuan", ""]]}, {"id": "2105.04919", "submitter": "Zihan Zheng", "authors": "Zihan Zheng, Peichen Xie, Xian Zhang, Shuo Chen, Yang Chen, Xiaobing\n  Guo, Guangzhong Sun, Guangyu Sun, Lidong Zhou", "title": "Agatha: Smart Contract for DNN Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart contract is one of the core features of Ethereum and has inspired many\nblockchain descendants. Since its advent, the verification paradigm of smart\ncontract has been improving toward high scalability. It shifts from the\nexpensive on-chain verification to the orchestration of off-chain VM (virtual\nmachine) execution and on-chain arbitration with the pinpoint protocol. The\nrepresentative projects are TrueBit, Arbitrum, YODA, ACE, and Optimism.\nInspired by visionaries in academia and industry, we consider the DNN\ncomputation to be promising but on the next level of complexity for the\nverification paradigm of smart contract. Unfortunately, even for the\nstate-of-the-art verification paradigm, off-chain VM execution of DNN\ncomputation has an orders-of-magnitude slowdown compared to the native\noff-chain execution.\n  To enable the native off-chain execution of verifiable DNN computation, we\npresent Agatha system, which solves the significant challenges of misalignment\nand inconsistency: (1) Native DNN computation has a graph-based computation\nparadigm misaligned with previous VM-based execution and arbitration; (2)\nNative DNN computation may be inconsistent cross platforms which invalidates\nthe verification paradigm. In response, we propose the graph-based pinpoint\nprotocol (GPP) which enables the pinpoint protocol on computational graphs, and\nbridges the native off-chain execution and the contract arbitration. We also\ndevelop a technique named Cross-evaluator Consistent Execution (XCE), which\nguarantees cross-platform consistency and forms the correctness foundation of\nGPP. We showcase Agatha for the DNN computation of popular models (MobileNet,\nResNet50 and VGG16) on Ethereum. Agatha achieves a negligible on-chain\noverhead, and an off-chain execution overhead of 3.0%, which represents an\noff-chain latency reduction of at least 602x compared to the state-of-the-art\nverification paradigm.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 10:08:46 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Zheng", "Zihan", ""], ["Xie", "Peichen", ""], ["Zhang", "Xian", ""], ["Chen", "Shuo", ""], ["Chen", "Yang", ""], ["Guo", "Xiaobing", ""], ["Sun", "Guangzhong", ""], ["Sun", "Guangyu", ""], ["Zhou", "Lidong", ""]]}, {"id": "2105.04950", "submitter": "Krishna Narasimhan", "authors": "Rodrigo Bonifacio, Stefan Kr\\\"uger, Krishna Narasimhan, Eric Bodden,\n  Mira Mezini", "title": "Dealing with Variability in API Misuse Specification", "comments": "28 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  APIs are the primary mechanism for developers to gain access to externally\ndefined services and tools. However, previous research has revealed API misuses\nthat violate the contract of APIs to be prevalent. Such misuses can have\nharmful consequences, especially in the context of cryptographic libraries.\nVarious API misuse detectors have been proposed to address this issue including\nCogniCrypt, one of the most versatile of such detectors and that uses a\nlanguage CrySL to specify cryptographic API usage contracts. Nonetheless,\nexisting approaches to detect API misuse had not been designed for systematic\nreuse, ignoring the fact that different versions of a library, different\nversions of a platform, and different recommendations or guidelines might\nintroduce variability in the correct usage of an API. Yet, little is known\nabout how such variability impacts the specification of the correct API usage.\nThis paper investigates this question by analyzing the impact of various\nsources of variability on widely used Java cryptographic libraries including\nJCA, Bouncy Castle, and Google Tink. The results of our investigation show that\nsources of variability like new versions of the API and security standards\nsignificantly impact the specifications. We then use the insights gained from\nour investigation to motivate an extension to the CrySL language named\nMetaCrySL, which builds on meta programming concepts. We evaluate MetaCrySL by\nspecifying usage rules for a family of Android versions and illustrate that\nMetaCrySL can model all forms of variability we identified and drastically\nreduce the size of a family of specifications for the correct usage of\ncryptographic APIs\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 11:40:24 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 07:38:38 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Bonifacio", "Rodrigo", ""], ["Kr\u00fcger", "Stefan", ""], ["Narasimhan", "Krishna", ""], ["Bodden", "Eric", ""], ["Mezini", "Mira", ""]]}, {"id": "2105.05016", "submitter": "Uriel Shinar Shinar", "authors": "Amit Behera, Or Sattath, Uriel Shinar", "title": "Noise-Tolerant Quantum Tokens for MAC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Message Authentication Code or MAC, is a well-studied cryptographic primitive\nthat is used in order to authenticate communication between two parties sharing\na secret key. A Tokenized MAC or TMAC is a related cryptographic primitive,\nintroduced by Ben-David & Sattath (QCrypt'17) which allows to delegate limited\nsigning authority to third parties via the use of single-use quantum signing\ntokens. These tokens can be issued using the secret key, such that each token\ncan be used to sign at most one document.\n  We provide an elementary construction for TMAC based on BB84 states. Our\nconstruction can tolerate up to 14% noise, making it the first noise-tolerant\nTMAC construction. The simplicity of the quantum states required for our\nconstruction combined with the noise-tolerance, makes it practically more\nfeasible than the previous TMAC construction.\n  The TMAC is existentially unforgeable against adversaries with signing and\nverification oracles (i.e., analogous to EUF-CMA security for MAC), assuming\npost-quantum collision-resistant hash functions exist.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 13:24:39 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Behera", "Amit", ""], ["Sattath", "Or", ""], ["Shinar", "Uriel", ""]]}, {"id": "2105.05029", "submitter": "Jing Li", "authors": "Tiangang Li", "title": "Adversarial examples attack based on random warm restart mechanism and\n  improved Nesterov momentum", "comments": "9 pages, 7 figures, 5 tables, CCS 2021 Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The deep learning algorithm has achieved great success in the field of\ncomputer vision, but some studies have pointed out that the deep learning model\nis vulnerable to attacks adversarial examples and makes false decisions. This\nchallenges the further development of deep learning, and urges researchers to\npay more attention to the relationship between adversarial examples attacks and\ndeep learning security. This work focuses on adversarial examples, optimizes\nthe generation of adversarial examples from the view of adversarial robustness,\ntakes the perturbations added in adversarial examples as the optimization\nparameter. We propose RWR-NM-PGD attack algorithm based on random warm restart\nmechanism and improved Nesterov momentum from the view of gradient\noptimization. The algorithm introduces improved Nesterov momentum, using its\ncharacteristics of accelerating convergence and improving gradient update\ndirection in optimization algorithm to accelerate the generation of adversarial\nexamples. In addition, the random warm restart mechanism is used for\noptimization, and the projected gradient descent algorithm is used to limit the\nrange of the generated perturbations in each warm restart, which can obtain\nbetter attack effect. Experiments on two public datasets show that the\nalgorithm proposed in this work can improve the success rate of attacking deep\nlearning models without extra time cost. Compared with the benchmark attack\nmethod, the algorithm proposed in this work can achieve better attack success\nrate for both normal training model and defense model. Our method has average\nattack success rate of 46.3077%, which is 27.19% higher than I-FGSM and 9.27%\nhigher than PGD. The attack results in 13 defense models show that the attack\nalgorithm proposed in this work is superior to the benchmark algorithm in\nattack universality and transferability.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 07:24:25 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Li", "Tiangang", ""]]}, {"id": "2105.05085", "submitter": "Heejin Park", "authors": "Heejin Park, Felix Xiaozhu Lin", "title": "TinyStack: A Minimal GPU Stack for Client ML", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TinyStack is a novel way for deploying GPU-accelerated computation on mobile\nand embedded devices. It addresses the high complexity of a modern GPU stack.\nWithout an overhaul of the stack, TinyStack provides a static, fast path for an\napp to push its computation to GPU. It records GPU executions on the full GPU\nstack ahead of time and replays the executions with only a small replayer on\nnew input at run time. TinyStack addresses challenges in capturing key CPU/GPU\ninteractions and GPU states, working around proprietary GPU internals, and\npreventing replay divergence. The resultant replayer is a drop-in replacement\nof the original GPU stack. It is tiny (as few as 50 KB executable), robust\n(replaying long executions without divergence), portable (running in a POSIX\nOS, in TEE, or on baremetal), and quick to launch (speeding up startup by up to\ntwo orders of magnitude). We have implemented TinyStack and tested it with a\nvariety of ML frameworks, GPU programming APIs, and integrated GPUs.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 07:55:19 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Park", "Heejin", ""], ["Lin", "Felix Xiaozhu", ""]]}, {"id": "2105.05103", "submitter": "Antonio Nappa", "authors": "Antonio Nappa, Christopher Hobbs, Andrea Lanzi", "title": "Deja-Vu: A Glimpse on Radioactive Soft-Error Consequences on Classical\n  and Quantum Computations", "comments": "6 Pages - Preliminary Work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  What do Apple, the FBI and a Belgian politician have in common? In 2003, in\nBelgium there was an election using electronic voting machines. Mysteriously\none candidate summed an excess of 4096 votes. An accurate analysis led to the\nofficial explanation that a spontaneous creation of a bit in position 13 of the\nmemory of the computer attributed 4096 extra votes to one candidate. One of the\nmost credited answers to this event is attributed to cosmic rays i.e.(gamma),\nwhich can filter through the atmosphere. There are cases though, with classical\ncomputers, like forensic investigations, or system recovery where such\nsoft-errors may be helpful to gain root privileges and recover data. In this\npaper we show preliminary results of using radioactive sources as a mean to\ngenerate bit-flips and exploit classical electronic computation devices. We\nused low radioactive emissions generated by Cobalt and Cesium and obtained\nbit-flips which made the program under attack crash. We also provide the first\noverview of the consequences of SEUs in quantum computers which are today used\nin production for protein folding optimization, showing potential impactful\nconsequences. To the best of our knowledge we are the first to leverage SEUs\nfor exploitation purposes which could be of great impact on classical and\nquantum computers.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 08:42:38 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Nappa", "Antonio", ""], ["Hobbs", "Christopher", ""], ["Lanzi", "Andrea", ""]]}, {"id": "2105.05126", "submitter": "Guoxin Wang", "authors": "Conor Smyth, Guoxin Wang, Rajesh Panicker, Avishek Nag, Barry Cardiff,\n  Deepu John", "title": "Continuous User Authentication using IoT Wearable Sensors", "comments": null, "journal-ref": null, "doi": "10.1109/ISCAS51556.2021.9401741", "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the past several years, the electrocardiogram (ECG) has been\ninvestigated for its uniqueness and potential to discriminate between\nindividuals. This paper discusses how this discriminatory information can help\nin continuous user authentication by a wearable chest strap which uses dry\nelectrodes to obtain a single lead ECG signal. To the best of the authors'\nknowledge, this is the first such work which deals with continuous\nauthentication using a genuine wearable device as most prior works have either\nused medical equipment employing gel electrodes to obtain an ECG signal or have\nobtained an ECG signal through electrode positions that would not be feasible\nusing a wearable device. Prior works have also mainly dealt with using the ECG\nsignal for identification rather than verification, or dealt with using the ECG\nsignal for discrete authentication. This paper presents a novel algorithm which\nuses QRS detection, weighted averaging, Discrete Cosine Transform (DCT), and a\nSupport Vector Machine (SVM) classifier to determine whether the wearer of the\ndevice should be positively verified or not. Zero intrusion attempts were\nsuccessful when tested on a database consisting of 33 subjects.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 04:22:05 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Smyth", "Conor", ""], ["Wang", "Guoxin", ""], ["Panicker", "Rajesh", ""], ["Nag", "Avishek", ""], ["Cardiff", "Barry", ""], ["John", "Deepu", ""]]}, {"id": "2105.05180", "submitter": "Antonious Girgis", "authors": "Antonious M. Girgis, Deepesh Data, Suhas Diggavi, Ananda Theertha\n  Suresh, and Peter Kairouz", "title": "On the Renyi Differential Privacy of the Shuffle Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The central question studied in this paper is Renyi Differential Privacy\n(RDP) guarantees for general discrete local mechanisms in the shuffle privacy\nmodel. In the shuffle model, each of the $n$ clients randomizes its response\nusing a local differentially private (LDP) mechanism and the untrusted server\nonly receives a random permutation (shuffle) of the client responses without\nassociation to each client. The principal result in this paper is the first\nnon-trivial RDP guarantee for general discrete local randomization mechanisms\nin the shuffled privacy model, and we develop new analysis techniques for\nderiving our results which could be of independent interest. In applications,\nsuch an RDP guarantee is most useful when we use it for composing several\nprivate interactions. We numerically demonstrate that, for important regimes,\nwith composition our bound yields an improvement in privacy guarantee by a\nfactor of $8\\times$ over the state-of-the-art approximate Differential Privacy\n(DP) guarantee (with standard composition) for shuffled models. Moreover,\ncombining with Poisson subsampling, our result leads to at least $10\\times$\nimprovement over subsampled approximate DP with standard composition.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 16:34:09 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Girgis", "Antonious M.", ""], ["Data", "Deepesh", ""], ["Diggavi", "Suhas", ""], ["Suresh", "Ananda Theertha", ""], ["Kairouz", "Peter", ""]]}, {"id": "2105.05192", "submitter": "Jens Hunhevicz", "authors": "Jens J. Hunhevicz, Mahshid Motie, Daniel M. Hall", "title": "Digital Building Twins and Blockchain for Performance-Based (Smart)\n  Contracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance contracts used for servitized business models enable\nconsideration of overall life-cycle costs rather than just production costs.\nHowever, practical implementation of performance contracts has been limited due\nto challenges with performance evaluation, accountability, and financial\nconcepts. As a solution, this paper proposes the connection of the digital\nbuilding twin with blockchain-based smart contracts to execute\nperformance-based digital payments. First, we conceptualize a technical\narchitecture to connect blockchain to digital building twins. The digital\nbuilding twin stores and evaluates performance data in real-time while the\nblockchain ensures transparency and trusted execution of automatic performance\nevaluation and rewards through smart contracts. Next, we demonstrate the\nfeasibility of both the concept and technical architecture by integrating the\nEthereum blockchain with digital building models and sensors via the Siemens\nbuilding twin platform. The resulting prototype is the first full-stack\nimplementation of a performance-based smart contract in the built environment.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 16:55:36 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Hunhevicz", "Jens J.", ""], ["Motie", "Mahshid", ""], ["Hall", "Daniel M.", ""]]}, {"id": "2105.05248", "submitter": "Reza Fotohi", "authors": "Samane Asgari, Shahram Jamali, Reza Fotohi, and Mahdi Nooshyar", "title": "Performance-aware placement and chaining scheme for virtualized network\n  functions: a particle swarm optimization approach", "comments": "22 pages, 10 Figures, 3 Tables, J Supercomput (2021)", "journal-ref": null, "doi": "10.1007/s11227-021-03758-9", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Network functions virtualization (NFV) is a new concept that has received the\nattention of both researchers and network providers. NFV decouples network\nfunctions from specialized hardware devices and virtualizes these network\nfunctions as software instances called virtualized network functions (VNFs).\nNFV leads to various benefits, including more flexibility, high resource\nutilization, and easy upgrades and maintenances. Despite recent works in this\nfield, placement and chaining of VNFs need more attention. More specifically,\nsome of the existing works have considered only the placement of VNFs and\nignored the chaining part. So, they have not provided an integrated view of\nhost or bandwidth resources and propagation delay of paths. In this paper, we\nsolve the VNF placement and chaining problem as an optimization problem based\non the particle swarm optimization (PSO) algorithm. Our goal is to minimize the\nrequired number of used servers, the average propagation delay of paths, and\nthe average utilization of links while meeting network demands and constraints.\nBased on the obtained results, the algorithm proposed in this study can find\nfeasible and high-quality solutions.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 07:26:50 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Asgari", "Samane", ""], ["Jamali", "Shahram", ""], ["Fotohi", "Reza", ""], ["Nooshyar", "Mahdi", ""]]}, {"id": "2105.05338", "submitter": "AKM Bahalul Haque", "authors": "AKM Bahalul Haque, Md. Rifat Hasan, Md. Oahiduzzaman Mondol Zihad", "title": "SmartOil: Blockchain and smart contract-based oil supply chain\n  management", "comments": "Accepted as Open access article in IET Blockchain", "journal-ref": "IET Blockchain, 2021", "doi": "10.1049/blc2.12005", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The traditional oil supply chain suffers from various shortcomings regarding\ncrude oil extraction, processing, distribution, environmental pollution, and\ntraceability. It offers an only a forward flow of products with almost no\nsecurity and tracking process. In time, the system will lag behind due to the\nlimitations in quality inspection, fraudulent information, and monopolistic\nbehavior of supply chain entities. Inclusion of counterfeiting products and\nopaqueness of the system urge renovation in this sector. The recent evolution\nof Industry 4.0 leads to the alternation in the supply chain introducing the\nsmart supply chain. Technological advancement can now reshape the\ninfrastructure of the supply chain for the future. In this paper, we suggest a\nconceptual framework utilizing Blockchain and Smart Contract to monitor the\noverall oil supply chain. Blockchain is a groundbreaking technology to monitor\nand support the security building of a decentralized type supply chain over a\npeer-to-peer network. The use of the Internet of Things (IoT), especially\nsensors, opens broader window to track the global supply chain in real-time. We\nconstruct a methodology to support reverse traceability for each participant of\nthe supply chain. The functions and characteristics of Blockchain and Smart\nContract are defined. Implementation of Smart Contracts has also been shown\nwith detailed analysis. We further describe the challenges of implementing such\na system and validate our framework's adaptability in the real world. The paper\nconcludes with future research scope to mitigate the restrictions of data\nmanagement and maintenance with advanced working prototypes and agile systems\nachieving greater traceability and transparency.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 20:45:13 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Haque", "AKM Bahalul", ""], ["Hasan", "Md. Rifat", ""], ["Zihad", "Md. Oahiduzzaman Mondol", ""]]}, {"id": "2105.05381", "submitter": "Shahbaz Rezaei", "authors": "Shahbaz Rezaei, Zubair Shafiq, Xin Liu", "title": "Accuracy-Privacy Trade-off in Deep Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep ensemble learning has been shown to improve accuracy by training\nmultiple neural networks and fusing their outputs. Ensemble learning has also\nbeen used to defend against membership inference attacks that undermine\nprivacy. In this paper, we empirically demonstrate a trade-off between these\ntwo goals, namely accuracy and privacy (in terms of membership inference\nattacks), in deep ensembles. Using a wide range of datasets and model\narchitectures, we show that the effectiveness of membership inference attacks\nalso increases when ensembling improves accuracy. To better understand this\ntrade-off, we study the impact of various factors such as prediction confidence\nand agreement between models that constitute the ensemble. Finally, we evaluate\ndefenses against membership inference attacks based on regularization and\ndifferential privacy. We show that while these defenses can mitigate the\neffectiveness of the membership inference attack, they simultaneously degrade\nensemble accuracy. The source code is available at\nhttps://github.com/shrezaei/MI-on-EL.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 00:58:04 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 16:48:18 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Rezaei", "Shahbaz", ""], ["Shafiq", "Zubair", ""], ["Liu", "Xin", ""]]}, {"id": "2105.05393", "submitter": "Ryo Nishimaki", "authors": "Taiga Hiroka, Tomoyuki Morimae, Ryo Nishimaki, Takashi Yamakawa", "title": "Quantum Encryption with Certified Deletion, Revisited: Public Key,\n  Attribute-Based, and Classical Communication", "comments": "51 pages", "journal-ref": null, "doi": null, "report-no": "YITP-21-40", "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Broadbent and Islam (TCC '20) proposed a quantum cryptographic primitive\ncalled quantum encryption with certified deletion. In this primitive, a\nreceiver in possession of a quantum ciphertext can generate a classical\ncertificate that the encrypted message is deleted. Although their construction\nis information-theoretically secure, it is limited to the setting of one-time\nsymmetric key encryption (SKE), where a sender and receiver have to share a\ncommon key in advance and the key can be used only once. Moreover, the sender\nhas to generate a quantum state and send it to the receiver over a quantum\nchannel in their construction. Although deletion certificates are privately\nverifiable, which means a verification key for a certificate has to be kept\nsecret, in the definition by Broadbent and Islam, we can also consider public\nverifiability.\n  In this work, we present various constructions of encryption with certified\ndeletion.\n  - Quantum communication case: We achieve (reusable-key) public key encryption\n(PKE) and attribute-based encryption (ABE) with certified deletion. Our PKE\nscheme with certified deletion is constructed assuming the existence of IND-CPA\nsecure PKE, and our ABE scheme with certified deletion is constructed assuming\nthe existence of indistinguishability obfuscation and one-way function. These\ntwo schemes are privately verifiable.\n  - Classical communication case: We also achieve PKE with certified deletion\nthat uses only classical communication. We give two schemes, a privately\nverifiable one and a publicly verifiable one. The former is constructed\nassuming the LWE assumption in the quantum random oracle model. The latter is\nconstructed assuming the existence of one-shot signatures and extractable\nwitness encryption.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 01:41:46 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Hiroka", "Taiga", ""], ["Morimae", "Tomoyuki", ""], ["Nishimaki", "Ryo", ""], ["Yamakawa", "Takashi", ""]]}, {"id": "2105.05443", "submitter": "Wei Dong", "authors": "Wei Dong and Ke Yi", "title": "A Nearly Instance-optimal Differentially Private Mechanism for\n  Conjunctive Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Releasing the result size of conjunctive queries and graph pattern queries\nunder differential privacy (DP) has received considerable attention in the\nliterature, but existing solutions do not offer any optimality guarantees. We\nprovide the first DP mechanism for this problem with a fairly strong notion of\noptimality, which can be considered as a natural relaxation of\ninstance-optimality.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 05:47:07 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Dong", "Wei", ""], ["Yi", "Ke", ""]]}, {"id": "2105.05445", "submitter": "Xiaotao Feng", "authors": "Xiaotao Feng (1), Ruoxi Sun (2), Xiaogang Zhu (1), Minhui Xue (2),\n  Sheng Wen (1), Dongxi Liu (3), Surya Nepal (3) and Yang Xiang (1) ((1)\n  Swinburne University of Technology, (2) The University of Adelaide, (3) CSIRO\n  Data61)", "title": "Snipuzz: Black-box Fuzzing of IoT Firmware via Message Snippet Inference", "comments": "Accepted to ACM CCS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of Internet of Things (IoT) devices has made people's lives\nmore convenient, but it has also raised many security concerns. Due to the\ndifficulty of obtaining and emulating IoT firmware, the black-box fuzzing of\nIoT devices has become a viable option. However, existing black-box fuzzers\ncannot form effective mutation optimization mechanisms to guide their testing\nprocesses, mainly due to the lack of feedback. It is difficult or even\nimpossible to apply existing grammar-based fuzzing strategies. Therefore, an\nefficient fuzzing approach with syntax inference is required in the IoT fuzzing\ndomain. To address these critical problems, we propose a novel automatic\nblack-box fuzzing for IoT firmware, termed Snipuzz. Snipuzz runs as a client\ncommunicating with the devices and infers message snippets for mutation based\non the responses. Each snippet refers to a block of consecutive bytes that\nreflect the approximate code coverage in fuzzing. This mutation strategy based\non message snippets considerably narrows down the search space to change the\nprobing messages. We compared Snipuzz with four state-of-the-art IoT fuzzing\napproaches, i.e., IoTFuzzer, BooFuzz, Doona, and Nemesys. Snipuzz not only\ninherits the advantages of app-based fuzzing (e.g., IoTFuzzer, but also\nutilizes communication responses to perform efficient mutation. Furthermore,\nSnipuzz is lightweight as its execution does not rely on any prerequisite\noperations, such as reverse engineering of apps. We also evaluated Snipuzz on\n20 popular real-world IoT devices. Our results show that Snipuzz could identify\n5 zero-day vulnerabilities, and 3 of them could be exposed only by Snipuzz. All\nthe newly discovered vulnerabilities have been confirmed by their vendors.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 05:55:19 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 06:26:34 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Feng", "Xiaotao", ""], ["Sun", "Ruoxi", ""], ["Zhu", "Xiaogang", ""], ["Xue", "Minhui", ""], ["Wen", "Sheng", ""], ["Liu", "Dongxi", ""], ["Nepal", "Surya", ""], ["Xiang", "Yang", ""]]}, {"id": "2105.05510", "submitter": "Jennifer Bellizzi", "authors": "Jennifer Bellizzi, Mark Vella, Christian Colombo and Julio\n  Hernandez-Castro", "title": "Responding to Living-Off-the-Land Tactics using Just-in-Time Memory\n  Forensics (JIT-MF) for Android", "comments": "14 pages, 3 figures, 2 tables, 2 listings, SECRYPT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Digital investigations of stealthy attacks on Android devices pose particular\nchallenges to incident responders. Whereas consequential late detection demands\naccurate and comprehensive forensic timelines to reconstruct all malicious\nactivities, reduced forensic footprints with minimal malware involvement, such\nas when Living-Off-the-Land (LOtL) tactics are adopted, leave investigators\nlittle evidence to work with. Volatile memory forensics can be an effective\napproach since app execution of any form is always bound to leave a trail of\nevidence in memory, even if perhaps ephemeral. Just-in-Time Memory Forensics\n(JIT-MF) is a recently proposed technique that describes a framework to process\nmemory forensics on existing stock Android devices, without compromising their\nsecurity by requiring them to be rooted. Within this framework, JIT-MF drivers\nare designed to promptly dump in-memory evidence related to app usage or\nmisuse. In this work, we primarily introduce a conceptualized presentation of\nJIT-MF drivers. Subsequently, through a series of case studies involving the\nhijacking of widely-used messaging apps, we show that when the target apps are\nforensically enhanced with JIT-MF drivers, investigators can generate richer\nforensic timelines to support their investigation, which are on average 26%\ncloser to ground truth.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 08:37:59 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Bellizzi", "Jennifer", ""], ["Vella", "Mark", ""], ["Colombo", "Christian", ""], ["Hernandez-Castro", "Julio", ""]]}, {"id": "2105.05525", "submitter": "Chun Liu", "authors": "Chun Liu, Xuexian Hu, Xiaofeng Chen, Jianghong Wei, Wenfen Liu", "title": "An Efficient Matrix Multiplication with Enhanced Privacy Protection in\n  Cloud Computing and Its Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of the most important basic operations, matrix multiplication\ncomputation (MMC) has varieties of applications in the scientific and\nengineering community such as linear regression, k-nearest neighbor\nclassification and biometric identification. However handling these tasks with\nlarge-scale datasets will lead to huge computation beyond resource-constrained\nclient s computation power. With the rapid development of cloud computing,\noutsourcing intensive tasks to cloud server has become a promising method.\nWhile the cloud server is generally out of the control of clients, there are\nstill many challenges concerned with the privacy security of clients sensitive\ndata. Motivated by this, Lei et al. presented an efficient encryption scheme\nbased on random permutation to protect the privacy of client s data in\noutsourcing MMC task. Nevertheless, there exists inherent security flaws in\ntheir scheme, revealing the statistic information of zero elements in the\noriginal data thus not satisfying the computational indistinguishability\n(IND-ZEA). Aiming to enhance the security of the outsourcing MMC task, we\npropose a new encryption scheme based on subtly designed invertible matrix\nwhere the additive perturbation is introduced besides the multiplicative\nperturbation. Furthermore, we show that the proposed encryption scheme can be\napplied to not only MMC task but also other kinds of outsourced tasks such as\nlinear regression and principal component analysis. Theoretical analyses and\nexperiments indicate that our methods are more secure in terms of data privacy,\nwith comparable performance to the state-of-the-art scheme based on matrix\ntransformation.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 09:00:14 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Liu", "Chun", ""], ["Hu", "Xuexian", ""], ["Chen", "Xiaofeng", ""], ["Wei", "Jianghong", ""], ["Liu", "Wenfen", ""]]}, {"id": "2105.05551", "submitter": "Thomas Sutter", "authors": "Thomas Sutter, Kevin Lapagna, Peter Berlich, Marc Rennhard, Fabio\n  Germann", "title": "Web Content Signing with Service Workers", "comments": "9 pages, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Securing the communication between a web server and a browser is a\nfundamental task of securing the World Wide Web. Websites today rely heavily on\nHTTPS to set up secure connections. In recent years, several incidents\nundermined this trust and therefore the security of the HTTPS system. In this\npaper we introduce an approach allowing to secure JavaScript files in case a\nHTTPS connection between web server and browser is compromised. Our paper\npresents a solution to safeguard the user's browser so that it only processes\ncontent (e.g., JavaScript or HTML) that was genuinely provided by the web\napplication service providers themselves. Our solution makes use of service\nworkers, a recently proposed W3C Candidate Recommendation enabling applications\nto take advantage of persistent background processing, including hooks to\nenable bootstrapping of web applications while offline. It demonstrates how\nservice workers are able to validate the integrity of JavaScript files within\nthe client's browser and how service workers are used to detect and mitigate\nmalicious JavaScript files.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 10:06:54 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Sutter", "Thomas", ""], ["Lapagna", "Kevin", ""], ["Berlich", "Peter", ""], ["Rennhard", "Marc", ""], ["Germann", "Fabio", ""]]}, {"id": "2105.05608", "submitter": "Johanna Loyer", "authors": "Andr\\'e Chailloux and Johanna Loyer", "title": "Lattice sieving via quantum random walks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Lattice-based cryptography is one of the leading proposals for post-quantum\ncryptography. The Shortest Vector Problem (SVP) is arguably the most important\nproblem for the cryptanalysis of lattice-based cryptography, and many\nlattice-based schemes have security claims based on its hardness. The best\nquantum algorithm for the SVP is due to Laarhoven [Laa16 PhD] and runs in\n(heuristic) time $2^{0.2653d + o(d)}$. In this article, we present an\nimprovement over Laarhoven's result and present an algorithm that has a\n(heuristic) running time of $2^{0.2570 d + o(d)}$ where $d$ is the lattice\ndimension. We also present time-memory trade-offs where we quantify the amount\nof quantum memory and quantum random access memory of our algorithm. The core\nidea is to replace Grover's algorithm used in [Laa16 PhD] in a key part of the\nsieving algorithm by a quantum random walk in which we add a layer of local\nsensitive filtering.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 11:59:30 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Chailloux", "Andr\u00e9", ""], ["Loyer", "Johanna", ""]]}, {"id": "2105.05717", "submitter": "Lunchen Xie", "authors": "Lunchen Xie, Jiaqi Liu, Songtao Lu, Tsung-hui Chang, Qingjiang Shi", "title": "An Efficient Learning Framework For Federated XGBoost Using Secret\n  Sharing And Distributed Optimization", "comments": "24 pages, Special issue of ACM Transactions on Intelligent Systems\n  and Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  XGBoost is one of the most widely used machine learning models in the\nindustry due to its superior learning accuracy and efficiency. Targeting at\ndata isolation issues in the big data problems, it is crucial to deploy a\nsecure and efficient federated XGBoost (FedXGB) model. Existing FedXGB models\neither have data leakage issues or are only applicable to the two-party setting\nwith heavy communication and computation overheads. In this paper, a lossless\nmulti-party federated XGB learning framework is proposed with a security\nguarantee, which reshapes the XGBoost's split criterion calculation process\nunder a secret sharing setting and solves the leaf weight calculation problem\nby leveraging distributed optimization. Remarkably, a thorough analysis of\nmodel security is provided as well, and multiple numerical results showcase the\nsuperiority of the proposed FedXGB compared with the state-of-the-art models on\nbenchmark datasets.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 15:04:18 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Xie", "Lunchen", ""], ["Liu", "Jiaqi", ""], ["Lu", "Songtao", ""], ["Chang", "Tsung-hui", ""], ["Shi", "Qingjiang", ""]]}, {"id": "2105.05734", "submitter": "Julian Matschinske", "authors": "Julian Matschinske, Julian Sp\\\"ath, Reza Nasirigerdeh, Reihaneh\n  Torkzadehmahani, Anne Hartebrodt, Bal\\'azs Orb\\'an, S\\'andor Fej\\'er, Olga\n  Zolotareva, Mohammad Bakhtiari, B\\'ela Bihari, Marcus Bloice, Nina C Donner,\n  Walid Fdhila, Tobias Frisch, Anne-Christin Hauschild, Dominik Heider, Andreas\n  Holzinger, Walter H\\\"otzendorfer, Jan Hospes, Tim Kacprowski, Markus\n  Kastelitz, Markus List, Rudolf Mayer, M\\'onika Moga, Heimo M\\\"uller,\n  Anastasia Pustozerova, Richard R\\\"ottger, Anna Saranti, Harald HHW Schmidt,\n  Christof Tschohl, Nina K Wenke, Jan Baumbach", "title": "The FeatureCloud AI Store for Federated Learning in Biomedicine and\n  Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine Learning (ML) and Artificial Intelligence (AI) have shown promising\nresults in many areas and are driven by the increasing amount of available\ndata. However, this data is often distributed across different institutions and\ncannot be shared due to privacy concerns. Privacy-preserving methods, such as\nFederated Learning (FL), allow for training ML models without sharing sensitive\ndata, but their implementation is time-consuming and requires advanced\nprogramming skills. Here, we present the FeatureCloud AI Store for FL as an\nall-in-one platform for biomedical research and other applications. It removes\nlarge parts of this complexity for developers and end-users by providing an\nextensible AI Store with a collection of ready-to-use apps. We show that the\nfederated apps produce similar results to centralized ML, scale well for a\ntypical number of collaborators and can be combined with Secure Multiparty\nComputation (SMPC), thereby making FL algorithms safely and easily applicable\nin biomedical and clinical environments.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 15:31:46 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Matschinske", "Julian", ""], ["Sp\u00e4th", "Julian", ""], ["Nasirigerdeh", "Reza", ""], ["Torkzadehmahani", "Reihaneh", ""], ["Hartebrodt", "Anne", ""], ["Orb\u00e1n", "Bal\u00e1zs", ""], ["Fej\u00e9r", "S\u00e1ndor", ""], ["Zolotareva", "Olga", ""], ["Bakhtiari", "Mohammad", ""], ["Bihari", "B\u00e9la", ""], ["Bloice", "Marcus", ""], ["Donner", "Nina C", ""], ["Fdhila", "Walid", ""], ["Frisch", "Tobias", ""], ["Hauschild", "Anne-Christin", ""], ["Heider", "Dominik", ""], ["Holzinger", "Andreas", ""], ["H\u00f6tzendorfer", "Walter", ""], ["Hospes", "Jan", ""], ["Kacprowski", "Tim", ""], ["Kastelitz", "Markus", ""], ["List", "Markus", ""], ["Mayer", "Rudolf", ""], ["Moga", "M\u00f3nika", ""], ["M\u00fcller", "Heimo", ""], ["Pustozerova", "Anastasia", ""], ["R\u00f6ttger", "Richard", ""], ["Saranti", "Anna", ""], ["Schmidt", "Harald HHW", ""], ["Tschohl", "Christof", ""], ["Wenke", "Nina K", ""], ["Baumbach", "Jan", ""]]}, {"id": "2105.05801", "submitter": "Sunjay Cauligi", "authors": "Sunjay Cauligi, Craig Disselkoen, Daniel Moghimi, Gilles Barthe, Deian\n  Stefan", "title": "SoK: Practical Foundations for Spectre Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spectre vulnerabilities violate our fundamental assumptions about\narchitectural abstractions, allowing attackers to steal sensitive data despite\npreviously state-of-the-art countermeasures. To defend against Spectre,\ndevelopers of verification tools and compiler-based mitigations are forced to\nreason about microarchitectural details such as speculative execution. In order\nto aid developers with these attacks in a principled way, the research\ncommunity has sought formal foundations for speculative execution upon which to\nrebuild provable security guarantees.\n  This paper systematizes the community's current knowledge about software\nverification and mitigation for Spectre. We study state-of-the-art software\ndefenses, both with and without associated formal models, and use a cohesive\nframework to compare the security properties each defense provides. We explore\na wide variety of tradeoffs in the complexity of formal frameworks, the\nperformance of defense tools, and the resulting security guarantees. As a\nresult of our analysis, we suggest practical choices for developers of analysis\nand mitigation tools, and we identify several open problems in this area to\nguide future work on grounded software defenses.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 17:09:43 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Cauligi", "Sunjay", ""], ["Disselkoen", "Craig", ""], ["Moghimi", "Daniel", ""], ["Barthe", "Gilles", ""], ["Stefan", "Deian", ""]]}, {"id": "2105.05807", "submitter": "Zhusheng Wang", "authors": "Zhusheng Wang and Sennur Ulukus", "title": "Symmetric Private Information Retrieval with User-Side Common Randomness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.DB eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of symmetric private information retrieval (SPIR)\nwith user-side common randomness. In SPIR, a user retrieves a message out of\n$K$ messages from $N$ non-colluding and replicated databases in such a way that\nno single database knows the retrieved message index (user privacy), and the\nuser gets to know nothing further than the retrieved message (database\nprivacy). SPIR has a capacity smaller than the PIR capacity which requires only\nuser privacy, is infeasible in the case of a single database, and requires\nshared common randomness among the databases. We introduce a new variant of\nSPIR where the user is provided with a random subset of the shared database\ncommon randomness, which is unknown to the databases. We determine the exact\ncapacity region of the triple $(d, \\rho_S, \\rho_U)$, where $d$ is the download\ncost, $\\rho_S$ is the amount of shared database (server) common randomness, and\n$\\rho_U$ is the amount of available user-side common randomness. We show that\nwith a suitable amount of $\\rho_U$, this new SPIR achieves the capacity of\nconventional PIR. As a corollary, single-database SPIR becomes feasible.\nFurther, the presence of user-side $\\rho_U$ reduces the amount of required\nserver-side $\\rho_S$.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 17:11:35 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Wang", "Zhusheng", ""], ["Ulukus", "Sennur", ""]]}, {"id": "2105.05937", "submitter": "Vladimir Vakhter", "authors": "Vladimir Vakhter, Betul Soysal, Patrick Schaumont, Ulkuhan Guler", "title": "Security for Emerging Miniaturized Wireless Biomedical Devices: Threat\n  Modeling with Application to Case Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The landscape of miniaturized wireless biomedical devices (MWBDs) is rapidly\nexpanding as proactive mobile healthcare proliferates. MWBDs are diverse and\ninclude various injectable, ingestible, implantable, and wearable devices.\nWhile the growth of MWBDs increases the flexibility of medical services, the\nadoption of these technologies brings privacy and security risks for their\nusers. MWBDs can operate with sensitive, private information and affect\npatients through the use of stimulation and drug delivery. Therefore, these\ndevices require trust and need to be secure. Embedding protective mechanisms\ninto MWBDs is challenging because they are restricted in size, power budget, as\nwell as processing and storage capabilities. Nevertheless, MWBDs need to be at\nleast minimally securable in the face of evolving threats. The main intent of\nthis work is to make the primary stakeholders of MWBDs aware of associated\nrisks and to help the architects and the manufacturers of MWBDs protect their\nemerging designs in a repeatable and structured manner. Making MWBDs securable\nbegins with performing threat modeling. This paper introduces a domain-specific\nqualitative-quantitative threat model dedicated to MWBDs. The proposed model is\nthen applied to representative case studies from each category of MWBDs.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 20:00:28 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Vakhter", "Vladimir", ""], ["Soysal", "Betul", ""], ["Schaumont", "Patrick", ""], ["Guler", "Ulkuhan", ""]]}, {"id": "2105.05943", "submitter": "Yuanzhe Jin", "authors": "Yuanzhe Jin, Ziheng Dong, Xing Li", "title": "Tomen: Application of Bitcoin Transaction Based on Tor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin has emerged in 2008, and after decades of development, it has become\nthe largest trading currency by far. The core of the blockchain is to ensure\nthe anonymity of user transactions. As more and more analysis algorithms for\nblockchain transactions appear, the anonymity of the blockchain is increasingly\nthreatened. We propose Tomen, an encryption application for the communication\nprocess in the bitcoin transaction process, combined with the encryption\nprinciple method of Tor. The goal is to achieve the application of the\nanonymization of bitcoin transaction communication.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 20:13:42 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Jin", "Yuanzhe", ""], ["Dong", "Ziheng", ""], ["Li", "Xing", ""]]}, {"id": "2105.05949", "submitter": "Martti Karvonen", "authors": "Anne Broadbent and Martti Karvonen", "title": "Categorical composable cryptography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize the simulation paradigm of cryptography in terms of category\ntheory and show that protocols secure against abstract attacks form a symmetric\nmonoidal category, thus giving an abstract model of composable security\ndefinitions in cryptography. Our model is able to incorporate computational\nsecurity, set-up assumptions and various attack models such as colluding or\nindependently acting subsets of adversaries in a modular, flexible fashion. We\nconclude by using string diagrams to rederive no-go results concerning the\nlimits of bipartite and tripartite cryptography, ruling out e.g. composable\ncommitments and broadcasting. On the way, we exhibit two categorical\nconstructions of resource theories that might be of independent interest: one\ncapturing resources shared among n parties and one capturing resource\nconversions that succeed asymptotically.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 20:25:14 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Broadbent", "Anne", ""], ["Karvonen", "Martti", ""]]}, {"id": "2105.05962", "submitter": "Pedro Antonino", "authors": "Pedro Antonino and Wojciech Aleksander Wo{\\l}oszyn and A. W. Roscoe", "title": "Guardian: symbolic validation of orderliness in SGX enclaves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern processors can offer hardware primitives that allow a process to run\nin isolation. These primitives implement a trusted execution environment (TEE)\nin which a program can run such that the integrity and confidentiality of its\nexecution are guaranteed. Intel's Software Guard eXtensions (SGX) is an example\nof such primitives and its isolated processes are called \\emph{enclaves}. These\nguarantees, however, can be easily thwarted if the enclave has not been\nproperly designed. Its interface with the untrusted software stack is arguably\nthe largest attack surface that adversaries can exploit; unintended\ninteractions with untrusted code can expose the enclave to memory corruption\nattacks, for instance. In this paper, we propose a notion of an \\emph{orderly}\nenclave which splits its behaviour into several execution phases each of which\nimposes a set of restrictions on accesses to untrusted memory, phase\ntransitions and registers sanitisation. A violation to these restrictions\nindicates an undesired behaviour which could be harnessed to perpetrate attacks\nagainst the enclave. We also introduce \\Analyser{}: a tool that uses symbolic\nexecution to carry out the validation of an enclave against our notion of an\norderly enclave; in this process, it also looks for some typical\nmemory-corruption vulnerabilities. We discuss how our approach can prevent and\nflag enclave vulnerabilities that have been identified in the literature.\nMoreover, we have evaluated how our approach fares in the analysis of some\npractical enclaves. \\Analyser{} was able to identify real vulnerabilities on\nthese enclaves which have been acknowledged and fixed by their maintainers.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 20:50:33 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Antonino", "Pedro", ""], ["Wo\u0142oszyn", "Wojciech Aleksander", ""], ["Roscoe", "A. W.", ""]]}, {"id": "2105.06004", "submitter": "Debarnab Mitra", "authors": "Debarnab Mitra, Lev Tauz and Lara Dolecek", "title": "Communication-Efficient LDPC Code Design for Data Availability Oracle in\n  Side Blockchains", "comments": "7 pages, 2 figures, 2 tables, submitted to ITW 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A popular method of improving the throughput of blockchain systems is by\nrunning smaller side blockchains that push the hashes of their blocks onto a\ntrusted blockchain. Side blockchains are vulnerable to stalling attacks where a\nside blockchain node pushes the hash of a block to the trusted blockchain but\nmakes the block unavailable to other nodes in the side blockchain. Recently,\nSheng et al. proposed a data availability oracle based on LDPC codes and a data\ndispersal protocol as a solution to the above problem. While showing great\nimprovements, the codes and the dispersal protocol were designed disjointly\nfrom each other which may not be optimal in terms of the communication cost\nassociated with the oracle. In this paper, we provide a tailored dispersal\nprotocol and a specialized LDPC code construction based on the Progressive Edge\nGrowth (PEG) algorithm called the dispersal-efficient PEG (DE-PEG) algorithm\naimed to reduce the communication cost associated with the new dispersal\nprotocol. Our new code construction reduces the communication cost, and\nadditionally, is less restrictive in terms of system design.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 23:57:42 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Mitra", "Debarnab", ""], ["Tauz", "Lev", ""], ["Dolecek", "Lara", ""]]}, {"id": "2105.06075", "submitter": "Joachim Neu", "authors": "Joachim Neu, Ertem Nusret Tas, David Tse", "title": "The Availability-Accountability Dilemma and its Resolution via\n  Accountability Gadgets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Byzantine fault tolerant (BFT) consensus protocols are traditionally\ndeveloped to support reliable distributed computing. For applications where the\nprotocol participants are economic agents, recent works highlighted the\nimportance of accountability: the ability to identify participants who provably\nviolate the protocol. We propose to evaluate the security of an accountable\nprotocol in terms of its liveness resilience, the minimum number of Byzantine\nnodes when liveness is violated, and its accountable safety resilience, the\nminimum number of accountable Byzantine nodes when safety is violated. We\ncharacterize the optimal tradeoffs between these two resiliences in different\nnetwork environments, and identify an availability-accountability dilemma: in\nan environment with dynamic participation, no protocol can simultaneously be\naccountably-safe and live. We provide a resolution to this dilemma by\nconstructing an optimally-resilient accountability gadget to checkpoint a\nlongest chain protocol, such that the full ledger is live under dynamic\nparticipation and the checkpointed prefix ledger is accountable. Our\naccountability gadget construction is black-box and can use any BFT protocol\nwhich is accountable under static participation. Using HotStuff as the black\nbox, we implemented our construction as a protocol for the Ethereum 2.0 beacon\nchain, and our Internet-scale experiments with more than 4000 nodes show that\nthe protocol can achieve the required scalability and has better latency than\nthe current solution Gasper, while having the advantage of being provably\nsecure. To contrast, we demonstrate a new attack on Gasper.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 04:45:04 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Neu", "Joachim", ""], ["Tas", "Ertem Nusret", ""], ["Tse", "David", ""]]}, {"id": "2105.06105", "submitter": "Kristen Titus W", "authors": "Prasanna Venkatesan E, Kristen Titus W", "title": "Trusted Authentication using hybrid security algorithm in VANET", "comments": "arXiv admin note: text overlap with arXiv:2105.05751", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Vehicular Ad Hoc Networks (VANETs) improves traffic management and reduce the\namount of road accidents by providing safety applications. However, VANETs are\nvulnerable to variety of security attacks from malicious entities. An\nauthentication is an integral a neighborhood of trust establishment and secure\ncommunications between vehicles. The Road-side Unit (RSU) evaluates trust-value\nand the Agent Trusted Authority (ATA) helps in computing the trust-value of\nauto supported its reward-points. The communication between nodes is enhanced,\nthis can reduce 50% of road accidents. The security of the VANET is improved.\nWe propose the utilization of Elliptic Curve Cryptography in the design of an\nefficient data encryption/decryption system for sensor nodes in a wireless\nnetwork. Elliptic Curve Cryptography can provide impressive levels of security\nstandards while keeping down the cost of certain issues, primarily storage\nspace. Sensors will benefit from having to store relatively smaller keys\ncoupled with increased computational capability and this will be a stronger\ndesign as the bit-level security is improved. Thus, reducing the time delay\nbetween the nodes and to provide better results between them we have made use\nof this method. The implementation of this work is done with NS2 software.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 06:51:51 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["E", "Prasanna Venkatesan", ""], ["W", "Kristen Titus", ""]]}, {"id": "2105.06122", "submitter": "Levent Aksoy", "authors": "Levent Aksoy, Quang-Linh Nguyen, Felipe Almeida, Jaan Raik, Marie-Lise\n  Flottes, Sophie Dupuis, and Samuel Pagliarini", "title": "High-level Intellectual Property Obfuscation via Decoy Constants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a high-level circuit obfuscation technique to prevent the\ntheft of intellectual property (IP) of integrated circuits. In particular, our\ntechnique protects a class of circuits that relies on constant multiplications,\nsuch as filters and neural networks, where the constants themselves are the IP\nto be protected. By making use of decoy constants and a key-based scheme, a\nreverse engineer adversary at an untrusted foundry is rendered incapable of\ndiscerning true constants from decoy constants. The time-multiplexed constant\nmultiplication (TMCM) block of such circuits, which realizes the multiplication\nof an input variable by a constant at a time, is considered as our case study\nfor obfuscation. Furthermore, two TMCM design architectures are taken into\naccount; an implementation using a multiplier and a multiplierless shift-adds\nimplementation. Optimization methods are also applied to reduce the hardware\ncomplexity of these architectures. The well-known satisfiability (SAT) and\nautomatic test pattern generation (ATPG) attacks are used to determine the\nvulnerability of the obfuscated designs. It is observed that the proposed\ntechnique incurs small overheads in area, power, and delay that are comparable\nto the hardware complexity of prominent logic locking methods. Yet, the\nadvantage of our approach is in the insight that constants -- instead of\narbitrary circuit nodes -- become key-protected.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 07:52:00 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Aksoy", "Levent", ""], ["Nguyen", "Quang-Linh", ""], ["Almeida", "Felipe", ""], ["Raik", "Jaan", ""], ["Flottes", "Marie-Lise", ""], ["Dupuis", "Sophie", ""], ["Pagliarini", "Samuel", ""]]}, {"id": "2105.06165", "submitter": "Dorjan Hitaj", "authors": "Giulio Pagnotta, Dorjan Hitaj, Fabio De Gaspari, Luigi V. Mancini", "title": "PassFlow: Guessing Passwords with Generative Flows", "comments": "19 pages, 5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in generative machine learning models rekindled research\ninterest in the area of password guessing. Data-driven password guessing\napproaches based on GANs, language models and deep latent variable models show\nimpressive generalization performance and offer compelling properties for the\ntask of password guessing. In this paper, we propose a flow-based generative\nmodel approach to password guessing. Flow-based models allow for precise\nlog-likelihood computation and optimization, which enables exact latent\nvariable inference. Additionally, flow-based models provide meaningful latent\nspace representation, which enables operations such as exploration of specific\nsubspaces of the latent space and interpolation. We demonstrate the\napplicability of generative flows to the context of password guessing,\ndeparting from previous applications of flow networks which are mainly limited\nto the continuous space of image generation. We show that the above-mentioned\nproperties allow flow-based models to outperform deep latent variable model\napproaches and remain competitive with state-of-the-art GANs in the password\nguessing task, while using a training set that is orders of magnitudes smaller\nthan that of previous art. Furthermore, a qualitative analysis of the generated\nsamples shows that flow-based networks are able to accurately model the\noriginal passwords distribution, with even non-matched samples closely\nresembling human-like passwords.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 09:50:36 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Pagnotta", "Giulio", ""], ["Hitaj", "Dorjan", ""], ["De Gaspari", "Fabio", ""], ["Mancini", "Luigi V.", ""]]}, {"id": "2105.06209", "submitter": "Yingzhe He", "authors": "Yingzhe He, Guozhu Meng, Kai Chen, Jinwen He, Xingbo Hu", "title": "DeepObliviate: A Powerful Charm for Erasing Data Residual Memory in Deep\n  Neural Networks", "comments": "16 pages, 10 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine unlearning has great significance in guaranteeing model security and\nprotecting user privacy. Additionally, many legal provisions clearly stipulate\nthat users have the right to demand model providers to delete their own data\nfrom training set, that is, the right to be forgotten. The naive way of\nunlearning data is to retrain the model without it from scratch, which becomes\nextremely time and resource consuming at the modern scale of deep neural\nnetworks. Other unlearning approaches by refactoring model or training data\nstruggle to gain a balance between overhead and model usability.\n  In this paper, we propose an approach, dubbed as DeepObliviate, to implement\nmachine unlearning efficiently, without modifying the normal training mode. Our\napproach improves the original training process by storing intermediate models\non the hard disk. Given a data point to unlearn, we first quantify its temporal\nresidual memory left in stored models. The influenced models will be retrained\nand we decide when to terminate the retraining based on the trend of residual\nmemory on-the-fly. Last, we stitch an unlearned model by combining the\nretrained models and uninfluenced models. We extensively evaluate our approach\non five datasets and deep learning models. Compared to the method of retraining\nfrom scratch, our approach can achieve 99.0%, 95.0%, 91.9%, 96.7%, 74.1%\naccuracy rates and 66.7$\\times$, 75.0$\\times$, 33.3$\\times$, 29.4$\\times$,\n13.7$\\times$ speedups on the MNIST, SVHN, CIFAR-10, Purchase, and ImageNet\ndatasets, respectively. Compared to the state-of-the-art unlearning approach,\nwe improve 5.8% accuracy, 32.5$\\times$ prediction speedup, and reach a\ncomparable retrain speedup under identical settings on average on these\ndatasets. Additionally, DeepObliviate can also pass the backdoor-based\nunlearning verification.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 12:02:04 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["He", "Yingzhe", ""], ["Meng", "Guozhu", ""], ["Chen", "Kai", ""], ["He", "Jinwen", ""], ["Hu", "Xingbo", ""]]}, {"id": "2105.06300", "submitter": "Xiaoyu Zhang", "authors": "Xiaoyu Zhang, Chao Chen, Yi Xie, Xiaofeng Chen, Jun Zhang, Yang Xiang", "title": "Privacy Inference Attacks and Defenses in Cloud-based Deep Neural\n  Network: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network (DNN), one of the most powerful machine learning\nalgorithms, is increasingly leveraged to overcome the bottleneck of effectively\nexploring and analyzing massive data to boost advanced scientific development.\nIt is not a surprise that cloud computing providers offer the cloud-based DNN\nas an out-of-the-box service. Though there are some benefits from the\ncloud-based DNN, the interaction mechanism among two or multiple entities in\nthe cloud inevitably induces new privacy risks. This survey presents the most\nrecent findings of privacy attacks and defenses appeared in cloud-based neural\nnetwork services. We systematically and thoroughly review privacy attacks and\ndefenses in the pipeline of cloud-based DNN service, i.e., data manipulation,\ntraining, and prediction. In particular, a new theory, called cloud-based ML\nprivacy game, is extracted from the recently published literature to provide a\ndeep understanding of state-of-the-art research. Finally, the challenges and\nfuture work are presented to help researchers to continue to push forward the\ncompetitions between privacy attackers and defenders.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 13:45:28 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Zhang", "Xiaoyu", ""], ["Chen", "Chao", ""], ["Xie", "Yi", ""], ["Chen", "Xiaofeng", ""], ["Zhang", "Jun", ""], ["Xiang", "Yang", ""]]}, {"id": "2105.06319", "submitter": "Lawrence Paulson", "authors": "Lawrence C. Paulson", "title": "The Inductive Approach to Verifying Cryptographic Protocols", "comments": null, "journal-ref": "J. Computer Security 6 (1998), 85-128", "doi": "10.3233/JCS-1998-61-205", "report-no": null, "categories": "cs.CR cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Informal arguments that cryptographic protocols are secure can be made\nrigorous using inductive definitions. The approach is based on ordinary\npredicate calculus and copes with infinite-state systems. Proofs are generated\nusing Isabelle/HOL. The human effort required to analyze a protocol can be as\nlittle as a week or two, yielding a proof script that takes a few minutes to\nrun.\n  Protocols are inductively defined as sets of traces. A trace is a list of\ncommunication events, perhaps comprising many interleaved protocol runs.\nProtocol descriptions incorporate attacks and accidental losses. The model spy\nknows some private keys and can forge messages using components decrypted from\nprevious traffic. Three protocols are analyzed below: Otway-Rees (which uses\nshared-key encryption), Needham-Schroeder (which uses public-key encryption),\nand a recursive protocol by Bull and Otway (which is of variable length).\n  One can prove that event $ev$ always precedes event $ev'$ or that property\n$P$ holds provided $X$ remains secret. Properties can be proved from the\nviewpoint of the various principals: say, if $A$ receives a final message from\n$B$ then the session key it conveys is good.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 14:17:05 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Paulson", "Lawrence C.", ""]]}, {"id": "2105.06322", "submitter": "Maurice Herlihy", "authors": "Yingjie Xue and Maurice Herlihy", "title": "Hedging Against Sore Loser Attacks in Cross-Chain Transactions", "comments": "To apper in PODC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A *sore loser attack* in cross-blockchain commerce rises when one party\ndecides to halt participation partway through, leaving other parties' assets\nlocked up for a long duration. Although vulnerability to sore loser attacks\ncannot be entirely eliminated, it can be reduced to an arbitrarily low level.\nThis paper proposes new distributed protocols for hedging a range of\ncross-chain transactions in a synchronous communication model, such as\ntwo-party swaps, $n$-party swaps, brokered transactions, and auctions.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 14:22:04 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 17:21:23 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Xue", "Yingjie", ""], ["Herlihy", "Maurice", ""]]}, {"id": "2105.06381", "submitter": "Yongxin Liu", "authors": "Yongxin Liu, Jian Wang, Jianqiang Li, Shuteng Niu, Houbing Song", "title": "Class-Incremental Learning for Wireless Device Identification in IoT", "comments": "Accepted for publication by IEEE Internet of Things Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Learning (DL) has been utilized pervasively in the Internet of Things\n(IoT). One typical application of DL in IoT is device identification from\nwireless signals, namely Non-cryptographic Device Identification (NDI).\nHowever, learning components in NDI systems have to evolve to adapt to\noperational variations, such a paradigm is termed as Incremental Learning (IL).\nVarious IL algorithms have been proposed and many of them require dedicated\nspace to store the increasing amount of historical data, and therefore, they\nare not suitable for IoT or mobile applications. However, conventional IL\nschemes can not provide satisfying performance when historical data are not\navailable. In this paper, we address the IL problem in NDI from a new\nperspective, firstly, we provide a new metric to measure the degree of\ntopological maturity of DNN models from the degree of conflict of\nclass-specific fingerprints. We discover that an important cause for\nperformance degradation in IL enabled NDI is owing to the conflict of devices'\nfingerprints. Second, we also show that the conventional IL schemes can lead to\nlow topological maturity of DNN models in NDI systems. Thirdly, we propose a\nnew Channel Separation Enabled Incremental Learning (CSIL) scheme without using\nhistorical data, in which our strategy can automatically separate devices'\nfingerprints in different learning stages and avoid potential conflict.\nFinally, We evaluated the effectiveness of the proposed framework using real\ndata from ADS-B (Automatic Dependent Surveillance-Broadcast), an application of\nIoT in aviation. The proposed framework has the potential to be applied to\naccurate identification of IoT devices in a variety of IoT applications and\nservices. Data and code available at IEEE Dataport (DOI: 10.21227/1bxc-ke87)\nand \\url{https://github.com/pcwhy/CSIL}}\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 09:11:07 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Liu", "Yongxin", ""], ["Wang", "Jian", ""], ["Li", "Jianqiang", ""], ["Niu", "Shuteng", ""], ["Song", "Houbing", ""]]}, {"id": "2105.06401", "submitter": "Mohamamd Nasim Imtiaz Khan", "authors": "Mohammad Nasim Imtiaz Khan and Swaroop Ghosh", "title": "Comprehensive Study of Security and Privacy of Emerging Non-Volatile\n  Memories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.ET", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  At the end of Silicon roadmap, keeping the leakage power in tolerable limit\nand bridging the bandwidth gap between processor and memory have become some of\nthe biggest challenges. Several promising Non-Volatile Memories (NVMs) such as,\nSpin-Transfer Torque RAM (STTRAM), Magnetic RAM (MRAM), Phase Change Memory\n(PCM), Resistive RAM (RRAM) and Ferroelectric RAM (FeRAM) are being\ninvestigated to address the above issues since they offer high density and\nconsumes zero leakage power. On one hand, the desirable properties of emerging\nNVMs make them suitable candidates for several applications including\nreplacement of conventional memories. On the other hand, their unique\ncharacteristics such as, high and asymmetric read/write current and persistence\nbring new threats to data security and privacy. Some of these memories are\nalready deployed in full systems and as discrete chips and are believed to\nbecome ubiquitous in future computing devices. Therefore, it is of utmost\nimportant to investigate their security and privacy issues. Note that these\nNVMs can be considered for cache, main memory or storage application. They are\nalso suitable to implement in-memory computation which increases system\nthroughput and eliminates Von-Neumann Bottleneck. Compute-capable NVMs impose\nnew security and privacy challenges that are fundamentally different than their\nstorage counterpart. This work identifies NVM vulnerabilities, attack vectors\noriginating from device level all the way to circuits and systems considering\nboth storage and compute applications. We also summarize the circuit/system\nlevel countermeasures to make the NVMs robust against security and privacy\nissues.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 16:27:08 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Khan", "Mohammad Nasim Imtiaz", ""], ["Ghosh", "Swaroop", ""]]}, {"id": "2105.06512", "submitter": "Lorena Qendro", "authors": "Lorena Qendro, Sangwon Ha, Ren\\'e de Jong, Partha Maji", "title": "Stochastic-Shield: A Probabilistic Approach Towards Training-Free\n  Adversarial Defense in Quantized CNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantized neural networks (NN) are the common standard to efficiently deploy\ndeep learning models on tiny hardware platforms. However, we notice that\nquantized NNs are as vulnerable to adversarial attacks as the full-precision\nmodels. With the proliferation of neural networks on small devices that we\ncarry or surround us, there is a need for efficient models without sacrificing\ntrust in the prediction in presence of malign perturbations. Current mitigation\napproaches often need adversarial training or are bypassed when the strength of\nadversarial examples is increased.\n  In this work, we investigate how a probabilistic framework would assist in\novercoming the aforementioned limitations for quantized deep learning models.\nWe explore Stochastic-Shield: a flexible defense mechanism that leverages input\nfiltering and a probabilistic deep learning approach materialized via Monte\nCarlo Dropout. We show that it is possible to jointly achieve efficiency and\nrobustness by accurately enabling each module without the burden of\nre-retraining or ad hoc fine-tuning.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 18:59:15 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Qendro", "Lorena", ""], ["Ha", "Sangwon", ""], ["de Jong", "Ren\u00e9", ""], ["Maji", "Partha", ""]]}, {"id": "2105.06545", "submitter": "Robert Bridges", "authors": "Edmon Begoli, Robert A. Bridges, Sean Oesch, Kathryn E. Knight", "title": "What Clinical Trials Can Teach Us about the Development of More\n  Resilient AI for Cybersecurity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy-mandated, rigorously administered scientific testing is needed to\nprovide transparency into the efficacy of artificial intelligence-based\n(AI-based) cyber defense tools for consumers and to prioritize future research\nand development. In this article, we propose a model that is informed by our\nexperience, urged forward by massive scale cyberattacks, and inspired by\nparallel developments in the biomedical field and the unprecedentedly fast\ndevelopment of new vaccines to combat global pathogens.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 20:40:45 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Begoli", "Edmon", ""], ["Bridges", "Robert A.", ""], ["Oesch", "Sean", ""], ["Knight", "Kathryn E.", ""]]}, {"id": "2105.06612", "submitter": "Charalambos Konstantinou", "authors": "Christos Xenofontos, Ioannis Zografopoulos, Charalambos Konstantinou,\n  Alireza Jolfaei, Muhammad Khurram Khan, Kim-Kwang Raymond Choo", "title": "Consumer, Commercial and Industrial IoT (In)Security: Attack Taxonomy\n  and Case Studies", "comments": "IEEE Internet of Things Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) devices are becoming ubiquitous in our lives, with\napplications spanning from the consumer domain to commercial and industrial\nsystems. The steep growth and vast adoption of IoT devices reinforce the\nimportance of sound and robust cybersecurity practices during the device\ndevelopment life-cycles. IoT-related vulnerabilities, if successfully exploited\ncan affect, not only the device itself, but also the application field in which\nthe IoT device operates. Evidently, identifying and addressing every single\nvulnerability is an arduous, if not impossible, task. Attack taxonomies can\nassist in classifying attacks and their corresponding vulnerabilities. Security\ncountermeasures and best practices can then be leveraged to mitigate threats\nand vulnerabilities before they emerge into catastrophic attacks and ensure\noverall secure IoT operation. Therefore, in this paper, we provide an attack\ntaxonomy which takes into consideration the different layers of IoT stack,\ni.e., device, infrastructure, communication, and service, and each layer's\ndesignated characteristics which can be exploited by adversaries. Furthermore,\nusing nine real-world cybersecurity incidents, that had targeted IoT devices\ndeployed in the consumer, commercial, and industrial sectors, we describe the\nIoT-related vulnerabilities, exploitation procedures, attacks, impacts, and\npotential mitigation mechanisms and protection strategies. These (and many\nother) incidents highlight the underlying security concerns of IoT systems and\ndemonstrate the potential attack impacts of such connected ecosystems, while\nthe proposed taxonomy provides a systematic procedure to categorize attacks\nbased on the affected layer and corresponding impact.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 01:44:55 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Xenofontos", "Christos", ""], ["Zografopoulos", "Ioannis", ""], ["Konstantinou", "Charalambos", ""], ["Jolfaei", "Alireza", ""], ["Khan", "Muhammad Khurram", ""], ["Choo", "Kim-Kwang Raymond", ""]]}, {"id": "2105.06638", "submitter": "Boris Ryabko", "authors": "Boris Ryabko", "title": "Calibrating random number generator tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CR cs.IT math.IT stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Currently, statistical tests for random number generators (RNGs) are widely\nused in practice, and some of them are even included in information security\nstandards. But despite the popularity of RNGs, consistent tests are known only\nfor stationary ergodic deviations of randomness (a test is consistent if it\ndetects any deviations from a given class when the sample size goes to $ \\infty\n$). However, the model of a stationary ergodic source is too narrow for some\nRNGs, in particular, for generators based on physical effects. In this article,\nwe propose computable consistent tests for some classes of deviations more\ngeneral than stationary ergodic and describe some general properties of\nstatistical tests. The proposed approach and the resulting test are based on\nthe ideas and methods of information theory.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 04:19:31 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Ryabko", "Boris", ""]]}, {"id": "2105.06731", "submitter": "Alexander Dax", "authors": "Alexander Dax and Robert K\\\"unnemann", "title": "On the Soundness of Infrastructure Adversaries", "comments": "32 pages, Full version, To be published at IEEE CSF'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Companies and network operators perform risk assessment to inform\npolicy-making, guide infrastructure investments or to comply with security\nstandards such as ISO 27001. Due to the size and complexity of these networks,\nrisk assessment techniques such as attack graphs or trees describe the attacker\nwith a finite set of rules. This characterization of the attacker can easily\nmiss attack vectors or overstate them, potentially leading to incorrect risk\nestimation.\n  In this work, we propose the first methodology to justify a rule-based\nattacker model. Conceptually, we add another layer of abstraction on top of the\nsymbolic model of cryptography, which reasons about protocols and abstracts\ncryptographic primitives. This new layer reasons about Internet-scale networks\nand abstracts protocols.\n  We show, in general, how the soundness and completeness of a rule-based model\ncan be ensured by verifying trace properties, linking soundness to safety\nproperties and completeness to liveness properties. We then demonstrate the\napproach for a recently proposed threat model that quantifies the\nconfidentiality of email communication on the Internet, including DNS, DNSSEC,\nand SMTP. Using off-the-shelf protocol verification tools, we discover two\nflaws in their threat model. After fixing them, we show that it provides\nsymbolic soundness.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 09:40:30 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Dax", "Alexander", ""], ["K\u00fcnnemann", "Robert", ""]]}, {"id": "2105.06742", "submitter": "Nathaniel Bastian PhD", "authors": "David A. Bierbrauer and Alexander Chang and Will Kritzer and Nathaniel\n  D. Bastian", "title": "Anomaly Detection in Cybersecurity: Unsupervised, Graph-Based and\n  Supervised Learning Methods in Adversarial Environments", "comments": "6 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning for anomaly detection has become a widely researched field\nin cybersecurity. Inherent to today's operating environment is the practice of\nadversarial machine learning, which attempts to circumvent machine learning\nmodels. In this work, we examine the feasibility of unsupervised learning and\ngraph-based methods for anomaly detection in the network intrusion detection\nsystem setting, as well as leverage an ensemble approach to supervised learning\nof the anomaly detection problem. We incorporate a realistic adversarial\ntraining mechanism when training our supervised models to enable strong\nclassification performance in adversarial environments. Our results indicate\nthat the unsupervised and graph-based methods were outperformed in detecting\nanomalies (malicious activity) by the supervised stacking ensemble method with\ntwo levels. This model consists of three different classifiers in the first\nlevel, followed by either a Naive Bayes or Decision Tree classifier for the\nsecond level. We see that our model maintains an F1-score above 0.97 for\nmalicious samples across all tested level two classifiers. Notably, Naive Bayes\nis the fastest level two classifier averaging 1.12 seconds while Decision Tree\nmaintains the highest AUC score of 0.98.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 10:05:10 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Bierbrauer", "David A.", ""], ["Chang", "Alexander", ""], ["Kritzer", "Will", ""], ["Bastian", "Nathaniel D.", ""]]}, {"id": "2105.06807", "submitter": "Ruoxi Chen", "authors": "Jinyin Chen, Ruoxi Chen, Haibin Zheng, Zhaoyan Ming, Wenrong Jiang and\n  Chen Cui", "title": "Salient Feature Extractor for Adversarial Defense on Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed unprecedented success achieved by deep learning\nmodels in the field of computer vision. However, their vulnerability towards\ncarefully crafted adversarial examples has also attracted the increasing\nattention of researchers. Motivated by the observation that adversarial\nexamples are due to the non-robust feature learned from the original dataset by\nmodels, we propose the concepts of salient feature(SF) and trivial feature(TF).\nThe former represents the class-related feature, while the latter is usually\nadopted to mislead the model. We extract these two features with coupled\ngenerative adversarial network model and put forward a novel detection and\ndefense method named salient feature extractor (SFE) to defend against\nadversarial attacks. Concretely, detection is realized by separating and\ncomparing the difference between SF and TF of the input. At the same time,\ncorrect labels are obtained by re-identifying SF to reach the purpose of\ndefense. Extensive experiments are carried out on MNIST, CIFAR-10, and ImageNet\ndatasets where SFE shows state-of-the-art results in effectiveness and\nefficiency compared with baselines. Furthermore, we provide an interpretable\nunderstanding of the defense and detection process.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 12:56:06 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Chen", "Jinyin", ""], ["Chen", "Ruoxi", ""], ["Zheng", "Haibin", ""], ["Ming", "Zhaoyan", ""], ["Jiang", "Wenrong", ""], ["Cui", "Chen", ""]]}, {"id": "2105.06872", "submitter": "Oleksii Oleksenko", "authors": "Oleksii Oleksenko, Christof Fetzer, Boris K\\\"opf, Mark Silberstein", "title": "Revizor: Fuzzing for Leaks in Black-box CPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shared microarchitectural state has become a prime target for side-channel\nattacks that leverage timing measurements to leak information across security\ndomains. Combined with speculative execution, they cause vulnerabilities like\nSpectre and Meltdown. Such vulnerabilities often stay undetected for a long\ntime because we lack the tools for systematic testing of CPUs against them.\n  In this paper, we propose an approach to automatically detect\nmicroarchitectural information leakage in commercial black-box CPUs. We base\nour approach on speculation contracts, which we employ to specify the permitted\nside effects of program execution on the microarchitectural state. We propose a\ntechnique, called Model-based Relational Fuzzing (MRF), that enables testing of\nCPUs against these specifications.\n  We implement MRF in a fuzzing framework called Revizor, and showcase its\neffectiveness on real Intel x86 CPUs: It automatically detects violations of a\nrich set of contracts, or indicates their absence. A highlight of our findings\nis that Revizor managed to automatically surface Spectre, MDS, and LVI by\nfuzzing against increasingly liberal contracts.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 14:56:15 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Oleksenko", "Oleksii", ""], ["Fetzer", "Christof", ""], ["K\u00f6pf", "Boris", ""], ["Silberstein", "Mark", ""]]}, {"id": "2105.06899", "submitter": "H{\\aa}rek Haugerud", "authors": "Eirik Molde B{\\aa}rli, Anis Yazidi, Enrique Herrera Viedma, H{\\aa}rek\n  Haugerud", "title": "DoS and DDoS Mitigation Using Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DoS and DDoS attacks have been growing in size and number over the last\ndecade and existing solutions to mitigate these attacks are in general\ninefficient. Compared to other types of malicious cyber attacks, DoS and DDoS\nattacks are particularly more challenging to combat. With their ability to mask\nthemselves as legitimate traffic, developing methods to detect these types of\nattacks on a packet or flow level, has proven to be a difficult task. In this\npaper, we explore the potential of Variational Autoencoders to serve as a\ncomponent within an intelligent security solution that differentiates between\nnormal and malicious traffic. Two methods based on the ability of Variational\nAutoencoders to learn latent representations from network traffic flows are\nproposed. The first method resorts to a classifier based on the latent\nencodings obtained from Variational Autoencoders learned from traffic traces.\nThe second method is rather an anomaly detection method where the Variational\nAutoencoder is used to learn the abstract feature representations of\nexclusively legitimate traffic. Then anomalies are filtered out by relying on\nthe reconstruction loss of the Variational Autoencoder.\n  Both of the proposed methods have been thoroughly tested on two separate\ndatasets with a similar feature space. The results show that both methods are\npromising, with a slight superiority of the classifier based method over the\nanomaly based one.\n  %that the first method is able to successfully detect individual traffic\nflows with high precision on the training and validation data, slightly less\nsuccessfully on the test data. For the second method, the Variational\nAutoencoder will require further adjustments to be able to sufficiently filter\nout anomalies from network traffic flows.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 15:38:40 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["B\u00e5rli", "Eirik Molde", ""], ["Yazidi", "Anis", ""], ["Viedma", "Enrique Herrera", ""], ["Haugerud", "H\u00e5rek", ""]]}, {"id": "2105.06942", "submitter": "Yoshimichi Nakatsuka", "authors": "Scott Jordan, Yoshimichi Nakatsuka, Ercan Ozturk, Andrew Paverd, Gene\n  Tsudik", "title": "VICEROY: GDPR-/CCPA-compliant Enforcement of Verifiable Accountless\n  Consumer Requests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent data protection regulations (such as GDPR and CCPA) grant consumers\nvarious rights, including the right to access, modify or delete any personal\ninformation collected about them (and retained) by a service provider. To\nexercise these rights, one must submit a verifiable consumer request proving\nthat collected data indeed pertains to them. This action is relatively\nstraightforward for consumers with active accounts with a service provider at\nthe time of data collection, since they can use standard (e.g., password-based)\nmeans of authentication to validate their requests. However, a major conundrum\narises from the need to support consumers without accounts to exercise their\nrights. To this end, some service providers began requiring these accountless\nconsumers to reveal and prove their identities (e.g., using government-issued\ndocuments, utility bills or credit card numbers) as part of issuing a\nverifiable consumer request. While understandable as a short-term cure, this\napproach is, at the same time, cumbersome and expensive for service providers\nas well as very privacy-invasive for consumers. Consequently, there is a strong\nneed to provide better means of authenticating requests from accountless\nconsumers. To achieve this, we propose VICEROY, a privacy-preserving and\nscalable framework for producing proofs of data ownership, which can be used as\na basis for verifiable consumer requests. Building upon existing web techniques\nand features (e.g., cookies), VICEROY allows accountless consumers to interact\nwith service providers, and later prove -- in a privacy-preserving manner --\nthat they are the same person, with minimal requirements for both parties. We\ndesign and implement VICEROY with the emphasis on security/privacy,\ndeployability and usability. We also thoroughly assess its practicality via\nextensive experiments.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 16:34:32 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Jordan", "Scott", ""], ["Nakatsuka", "Yoshimichi", ""], ["Ozturk", "Ercan", ""], ["Paverd", "Andrew", ""], ["Tsudik", "Gene", ""]]}, {"id": "2105.06974", "submitter": "Noama Fatima Samreen", "authors": "Noama Fatima Samreen and Manar H. Alalfi", "title": "A Survey of Security Vulnerabilities in Ethereum Smart Contracts", "comments": null, "journal-ref": "CASCON20 Proceedings of the 30th Annual International Conference\n  on Computer Science and Software Engineering November 2020", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ethereum Smart Contracts based on Blockchain Technology (BT)enables monetary\ntransactions among peers on a blockchain network independent of a central\nauthorizing agency. Ethereum smart contracts are programs that are deployed as\ndecentralized applications, having the building blocks of the blockchain\nconsensus protocol. This enables consumers to make agreements in a transparent\nand conflict-free environment. However, there exist some security\nvulnerabilities within these smart contracts that are a potential threat to the\napplications and their consumers and have shown in the past to cause huge\nfinancial losses. In this study, we review the existing literature and broadly\nclassify the BT applications. As Ethereum smart contracts find their\napplication mostly in e-commerce applications, we believe these are more\ncommonly vulnerable to attacks. In these smart contracts, we mainly focus on\nidentifying vulnerabilities that programmers and users of smart contracts must\navoid. This paper aims at explaining eight vulnerabilities that are specific to\nthe application level of BT by analyzing the past exploitation case scenarios\nof these security vulnerabilities. We also review some of the available tools\nand applications that detect these vulnerabilities in terms of their approach\nand effectiveness. We also investigated the availability of detection tools for\nidentifying these security vulnerabilities and lack thereof to identify some of\nthem\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 17:24:34 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Samreen", "Noama Fatima", ""], ["Alalfi", "Manar H.", ""]]}, {"id": "2105.07037", "submitter": "Giulia Cisotto", "authors": "Anna V. Guglielmi, Alberto Muraro, Giulia Cisotto, Nicola Laurenti", "title": "Information Theoretic Key Agreement Protocol based on ECG signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless body area networks (WBANs) are becoming increasingly popular as they\nallow individuals to continuously monitor their vitals and physiological\nparameters remotely from the hospital. With the spread of the SARS-CoV-2\npandemic, the availability of portable pulse-oximeters and wearable heart rate\ndetectors has boomed in the market. At the same time, in 2020 we assisted to an\nunprecedented increase of healthcare breaches, revealing the extreme\nvulnerability of the current generation of WBANs. Therefore, the development of\nnew security protocols to ensure data protection, authentication, integrity and\nprivacy within WBANs are highly needed. Here, we targeted a WBAN collecting ECG\nsignals from different sensor nodes on the individual's body, we extracted the\ninter-pulse interval (i.e., R-R interval) sequence from each of them, and we\ndeveloped a new information theoretic key agreement protocol that exploits the\ninherent randomness of ECG to ensure authentication between sensor pairs within\nthe WBAN. After proper pre-processing, we provide an analytical solution that\nensures robust authentication; we provide a unique information reconciliation\nmatrix, which gives good performance for all ECG sensor pairs; and we can show\nthat a relationship between information reconciliation and privacy\namplification matrices can be found. Finally, we show the trade-off between the\nlevel of security, in terms of key generation rate, and the complexity of the\nerror correction scheme implemented in the system.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 18:58:44 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Guglielmi", "Anna V.", ""], ["Muraro", "Alberto", ""], ["Cisotto", "Giulia", ""], ["Laurenti", "Nicola", ""]]}, {"id": "2105.07078", "submitter": "Siyue Wang", "authors": "Siyue Wang, Xiao Wang, Pin-Yu Chen, Pu Zhao and Xue Lin", "title": "High-Robustness, Low-Transferability Fingerprinting of Neural Networks", "comments": "ICLR 2021 Workshop on Security and Safety in Machine Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes Characteristic Examples for effectively fingerprinting\ndeep neural networks, featuring high-robustness to the base model against model\npruning as well as low-transferability to unassociated models. This is the\nfirst work taking both robustness and transferability into consideration for\ngenerating realistic fingerprints, whereas current methods lack practical\nassumptions and may incur large false positive rates. To achieve better\ntrade-off between robustness and transferability, we propose three kinds of\ncharacteristic examples: vanilla C-examples, RC-examples, and LTRC-example, to\nderive fingerprints from the original base model. To fairly characterize the\ntrade-off between robustness and transferability, we propose Uniqueness Score,\na comprehensive metric that measures the difference between robustness and\ntransferability, which also serves as an indicator to the false alarm problem.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 21:48:23 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Wang", "Siyue", ""], ["Wang", "Xiao", ""], ["Chen", "Pin-Yu", ""], ["Zhao", "Pu", ""], ["Lin", "Xue", ""]]}, {"id": "2105.07120", "submitter": "Akinori Kawachi", "authors": "Akinori Kawachi and Harumichi Nishimura", "title": "Communication Complexity of Private Simultaneous Quantum Messages\n  Protocols", "comments": "19 pages, to be published in Proc. ITC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The private simultaneous messages model is a non-interactive version of the\nmultiparty secure computation, which has been intensively studied to examine\nthe communication cost of the secure computation. We consider its quantum\ncounterpart, the private simultaneous quantum messages (PSQM) model, and\nexamine the advantages of quantum communication and prior entanglement of this\nmodel. In the PSQM model, $k$ parties $P_1,\\ldots,P_k$ initially share a common\nrandom string (or entangled states in a stronger setting), and they have\nprivate classical inputs $x_1,\\ldots, x_k$. Every $P_i$ generates a quantum\nmessage from the private input $x_i$ and the shared random string (entangled\nstates), and then sends it to the referee $R$. Receiving the messages, $R$\ncomputes $F(x_1,\\ldots,x_k)$. Then, $R$ learns nothing except for\n$F(x_1,\\ldots,x_k)$ as the privacy condition. We obtain the following results\nfor this PSQM model. (1) We demonstrate that the privacy condition inevitably\nincreases the communication cost in the two-party PSQM model as well as in the\nclassical case presented by Applebaum, Holenstein, Mishra, and Shayevitz. In\nparticular, we prove a lower bound $(3-o(1))n$ of the communication complexity\nin PSQM protocols with a shared random string for random Boolean functions of\n$2n$-bit input, which is larger than the trivial upper bound $2n$ of the\ncommunication complexity without the privacy condition. (2) We demonstrate a\nfactor two gap between the communication complexity of PSQM protocols with\nshared entangled states and with shared random strings by designing a\nmultiparty PSQM protocol with shared entangled states for a total function that\nextends the two-party equality function. (3) We demonstrate an exponential gap\nbetween the communication complexity of PSQM protocols with shared entangled\nstates and with shared random strings for a two-party partial function.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 03:08:01 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Kawachi", "Akinori", ""], ["Nishimura", "Harumichi", ""]]}, {"id": "2105.07176", "submitter": "Natasha Fernandes", "authors": "Natasha Fernandes and Annabelle McIver and Carroll Morgan", "title": "The Laplace Mechanism has optimal utility for differential privacy over\n  continuous queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential Privacy protects individuals' data when statistical queries are\npublished from aggregated databases: applying \"obfuscating\" mechanisms to the\nquery results makes the released information less specific but, unavoidably,\nalso decreases its utility. Yet it has been shown that for discrete data (e.g.\ncounting queries), a mandated degree of privacy and a reasonable interpretation\nof loss of utility, the Geometric obfuscating mechanism is optimal: it loses as\nlittle utility as possible. For continuous query results however (e.g. real\nnumbers) the optimality result does not hold. Our contribution here is to show\nthat optimality is regained by using the Laplace mechanism for the obfuscation.\nThe technical apparatus involved includes the earlier discrete result by Ghosh\net al., recent work on abstract channels and their geometric representation as\nhyper-distributions, and the dual interpretations of distance between\ndistributions provided by the Kantorovich-Rubinstein Theorem.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 09:11:50 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 07:12:14 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Fernandes", "Natasha", ""], ["McIver", "Annabelle", ""], ["Morgan", "Carroll", ""]]}, {"id": "2105.07187", "submitter": "Carlos Pedro Gon\\c{c}alves", "authors": "Carlos Pedro Gon\\c{c}alves", "title": "Cyberattacks on Quantum Networked Computation and Communications --\n  Hacking the Superdense Coding Protocol on IBM's Quantum Computers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR cs.CY cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of automated gate specification for quantum communications\nand quantum networked computation opens up the way for malware designed at\ncorrupting the automation software, changing the automated quantum\ncommunications protocols and algorithms. We study two types of attacks on\nautomated quantum communications protocols and simulate these attacks on the\nsuperdense coding protocol, using remote access to IBM's Quantum Computers\navailable through IBM Q Experience to simulate these attacks on what would be a\nlow noise quantum communications network. The first type of attack leads to a\nhacker-controlled bijective transformation of the final measured strings, the\nsecond type of attack is a unitary scrambling attack that modifies the\nautomated gate specification to effectively scramble the final measurement,\ndisrupting quantum communications and taking advantage of quantum randomness\nupon measurement in a way that makes it difficult to distinguish from hardware\nmalfunction or from a sudden rise in environmental noise. We show that, due to\nquantum entanglement and symmetries, the second type of attack works as a way\nto strategically disrupt quantum communications networks and quantum networked\ncomputation in a way that makes it difficult to ascertain which node was\nattacked. The main findings are discussed in the wider setting of quantum\ncybersecurity and quantum networked computation, where ways of hacking\nincluding the role of insider threats are discussed.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 09:42:36 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Gon\u00e7alves", "Carlos Pedro", ""]]}, {"id": "2105.07244", "submitter": "Poushali Sengupta", "authors": "Poushali Sengupta and Subhankar Mishra", "title": "Fairly Private Through Group Tagging and Relation Impact", "comments": "Accepted at MDAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Privacy and Fairness both are very important nowadays. For most of the cases\nin the online service providing system, users have to share their personal\ninformation with the organizations. In return, the clients not only demand a\nhigh privacy guarantee to their sensitive data but also expected to be treated\nfairly irrespective of their age, gender, religion, race, skin color, or other\nsensitive protected attributes. Our work introduces a novel architecture that\nis balanced among the privacy-utility-fairness trade-off. The proposed\nmechanism applies Group Tagging Method and Fairly Iterative Shuffling (FIS)\nthat amplifies privacy through random shuffling and prevents linkage attack.\nThe algorithm introduces a fair classification problem by Relation Impact based\non Equalized Minimal FPR-FNR among the protected tagged group. For the count\nreport generation, the aggregator uses TF-IDF to add noise for providing\nlongitudinal Differential Privacy guarantee. Lastly, the mechanism boosts the\nutility through risk minimization function and obtain the optimal\nprivacy-utility budget of the system. In our work, we have done a case study on\ngender equality in the admission system and helps to obtain a satisfying result\nwhich implies that the proposed architecture achieves the group fairness and\noptimal privacy-utility trade-off for both the numerical and decision making\nQueries.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 15:19:43 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Sengupta", "Poushali", ""], ["Mishra", "Subhankar", ""]]}, {"id": "2105.07260", "submitter": "Zeyu Ding", "authors": "Zeyu Ding, Daniel Kifer, Sayed M. Saghaian N. E., Thomas Steinke,\n  Yuxin Wang, Yingtai Xiao, Danfeng Zhang", "title": "The Permute-and-Flip Mechanism is Identical to Report-Noisy-Max with\n  Exponential Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The permute-and-flip mechanism is a recently proposed differentially private\nselection algorithm that was shown to outperform the exponential mechanism. In\nthis paper, we show that permute-and-flip is equivalent to the well-known\nreport noisy max algorithm with exponential noise.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 16:33:32 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 14:52:30 GMT"}, {"version": "v3", "created": "Sat, 5 Jun 2021 21:33:00 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ding", "Zeyu", ""], ["Kifer", "Daniel", ""], ["E.", "Sayed M. Saghaian N.", ""], ["Steinke", "Thomas", ""], ["Wang", "Yuxin", ""], ["Xiao", "Yingtai", ""], ["Zhang", "Danfeng", ""]]}, {"id": "2105.07327", "submitter": "Hao Wang", "authors": "Hao Wang", "title": "Que Bian: An Electronic Medical Record Management System on Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Medical Record Management System is an important information management\nsystem in healthcare centers and hospitals. Information kept in such systems\nneed to be clean, correct and tamper-proof. In this paper, we take advantage of\nblockchains' tamper-proof and decentralization properties to develop a robust\nand secure electronic medical record management system. In particular we choose\nHyperLedger Fabric as our underlying technical architecture. HyperLedger Fabric\nyields higher throughput and lower latency compared with other blockchains,\nwhich is a perfect candidate for enterprise software development. Our system is\na novel innovation that can serve as an ideal replacement for conventional\nMedical Record Management System.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 01:12:53 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Wang", "Hao", ""]]}, {"id": "2105.07332", "submitter": "Virendra Sule", "authors": "Virendra Sule", "title": "A Complete algorithm for local inversion of maps: Application to\n  Cryptanalysis", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a map (function) $F(x):\\ftwo^n\\rightarrow\\ftwo^n$ and a given $y$ in the\nimage of $F$ the problem of \\emph{local inversion} of $F$ is to find all\ninverse images $x$ in $\\ftwo^n$ such that $y=F(x)$. In Cryptology, such a\nproblem arises in Cryptanalysis of One way Functions (OWFs). The well known\nTMTO attack in Cryptanalysis is a probabilistic algorithm for computing one\nsolution of local inversion using $O(\\sqrt N)$ order computation in offline as\nwell as online for $N=2^n$. This paper proposes a complete algorithm for\nsolving the local inversion problem which uses linear complexity for a unique\nsolution in a periodic orbit. The algorithm is shown to require an offline\ncomputation to solve a hard problem (possibly requiring exponential\ncomputation) and an online computation dependent on $y$ that of repeated\nforward evaluation $F(x)$ on points $x$ in $\\ff_{2^n}$ which is polynomial time\nat each evaluation. However the forward evaluation is repeated at most as many\nnumber of times as the Linear Complexity of the sequence $\\{y,F(y),\\ldots\\}$ to\nget one possible solution when this sequence is periodic. All other solutions\nare obtained in chains $\\{e,F(e),\\ldots\\}$ for all points $e$ in the Garden of\nEden (GOE) of the map $F$. Hence a solution $x$ exists iff either the former\nsequence is periodic or a solution occurs in a chain starting from a point in\nGOE. The online computation then turns out to be polynomial time $O(L^k)$ in\nthe linear complexity $L$ of the sequence to compute one possible solution in a\nperiodic orbit or $O(l)$ the chain length for a fixed $n$. Hence this is a\ncomplete algorithm for solving the problem of finding all rational solutions\n$x$ of the equation $F(x)=y$ for a given $y$ and a map $F$ in $\\ff_{2^n}$.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 02:27:56 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Sule", "Virendra", ""]]}, {"id": "2105.07334", "submitter": "Kenneth Co", "authors": "Kenneth T. Co, Luis Mu\\~noz-Gonz\\'alez, Leslie Kanthan, Emil C. Lupu", "title": "Real-time Detection of Practical Universal Adversarial Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Universal Adversarial Perturbations (UAPs) are a prominent class of\nadversarial examples that exploit the systemic vulnerabilities and enable\nphysically realizable and robust attacks against Deep Neural Networks (DNNs).\nUAPs generalize across many different inputs; this leads to realistic and\neffective attacks that can be applied at scale. In this paper we propose\nHyperNeuron, an efficient and scalable algorithm that allows for the real-time\ndetection of UAPs by identifying suspicious neuron hyper-activations. Our\nresults show the effectiveness of HyperNeuron on multiple tasks (image\nclassification, object detection), against a wide variety of universal attacks,\nand in realistic scenarios, like perceptual ad-blocking and adversarial\npatches. HyperNeuron is able to simultaneously detect both adversarial mask and\npatch UAPs with comparable or better performance than existing UAP defenses\nwhilst introducing a significantly reduced latency of only 0.86 milliseconds\nper image. This suggests that many realistic and practical universal attacks\ncan be reliably mitigated in real-time, which shows promise for the robust\ndeployment of machine learning systems.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 03:01:29 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 23:33:20 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Co", "Kenneth T.", ""], ["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["Kanthan", "Leslie", ""], ["Lupu", "Emil C.", ""]]}, {"id": "2105.07360", "submitter": "George Grispos", "authors": "George Grispos and Talon Flynn and William Glisson and Kim-Kwang\n  Raymond Choo", "title": "Investigating Protected Health Information Leakage from Android Medical\n  Applications", "comments": "Presented at the 5th EAI International Conference on Future Access\n  Enablers of Ubiquitous and Intelligent Infrastructures (EAI FABULOUS 2021),\n  Zagreb, Croatia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As smartphones and smartphone applications are widely used in a healthcare\ncontext (e.g., remote healthcare), these devices and applications may need to\ncomply with the Health Insurance Portability and Accountability Act (HIPAA) of\n1996. In other words, adequate safeguards to protect the user's sensitive\ninformation (e.g., personally identifiable information and/or medical history)\nare required to be enforced on such devices and applications. In this study, we\nforensically focus on the potential of recovering residual data from Android\nmedical applications, with the objective of providing an initial risk\nassessment of such applications. Our findings (e.g., documentation of the\nartifacts) also contribute to a better understanding of the types and location\nof evidential artifacts that can, potentially, be recovered from these\napplications in a digital forensic investigation.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 05:54:24 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Grispos", "George", ""], ["Flynn", "Talon", ""], ["Glisson", "William", ""], ["Choo", "Kim-Kwang Raymond", ""]]}, {"id": "2105.07381", "submitter": "Haoyu Ma", "authors": "Haoyu Ma, Tianlong Chen, Ting-Kuei Hu, Chenyu You, Xiaohui Xie,\n  Zhangyang Wang", "title": "Undistillable: Making A Nasty Teacher That CANNOT teach students", "comments": "ICLR 2021(Spotlight). Code is available at\n  https://github.com/VITA-Group/Nasty-Teacher", "journal-ref": "ICLR 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Distillation (KD) is a widely used technique to transfer knowledge\nfrom pre-trained teacher models to (usually more lightweight) student models.\nHowever, in certain situations, this technique is more of a curse than a\nblessing. For instance, KD poses a potential risk of exposing intellectual\nproperties (IPs): even if a trained machine learning model is released in\n'black boxes' (e.g., as executable software or APIs without open-sourcing\ncode), it can still be replicated by KD through imitating input-output\nbehaviors. To prevent this unwanted effect of KD, this paper introduces and\ninvestigates a concept called Nasty Teacher: a specially trained teacher\nnetwork that yields nearly the same performance as a normal one, but would\nsignificantly degrade the performance of student models learned by imitating\nit. We propose a simple yet effective algorithm to build the nasty teacher,\ncalled self-undermining knowledge distillation. Specifically, we aim to\nmaximize the difference between the output of the nasty teacher and a normal\npre-trained network. Extensive experiments on several datasets demonstrate that\nour method is effective on both standard KD and data-free KD, providing the\ndesirable KD-immunity to model owners for the first time. We hope our\npreliminary study can draw more awareness and interest in this new practical\nproblem of both social and legal importance.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 08:41:30 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Ma", "Haoyu", ""], ["Chen", "Tianlong", ""], ["Hu", "Ting-Kuei", ""], ["You", "Chenyu", ""], ["Xie", "Xiaohui", ""], ["Wang", "Zhangyang", ""]]}, {"id": "2105.07428", "submitter": "Xianjun Jiao", "authors": "Xianjun Jiao, Michael Mehari, Wei Liu, Muhammad Aslam, Ingrid Moerman", "title": "Openwifi CSI fuzzer for authorized sensing and covert channels", "comments": "Accepted by ACM WiSec 2021", "journal-ref": null, "doi": "10.1145/3448300.3468255", "report-no": null, "categories": "cs.CR cs.AR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  CSI (Channel State Information) of WiFi systems contains the environment\nchannel response between the transmitter and the receiver, so the\npeople/objects and their movement in between can be sensed. To get CSI, the\nreceiver performs channel estimation based on the pre-known training field of\nthe transmitted WiFi signal. CSI related technology is useful in many cases,\nbut it also brings concerns on privacy and security. In this paper, we open\nsourced a CSI fuzzer to enhance the privacy and security of WiFi CSI\napplications. It is built and embedded into the transmitter of openwifi, which\nis an open source full-stack WiFi chip design, to prevent unauthorized sensing\nwithout sacrificing the WiFi link performance. The CSI fuzzer imposes an\nartificial channel response to the signal before it is transmitted, so the CSI\nseen by the receiver will indicate the actual channel response combined with\nthe artificial response. Only the authorized receiver, that knows the\nartificial response, can calculate the actual channel response and perform the\nCSI sensing. Another potential application of the CSI fuzzer is covert channels\nbased on a set of pre-defined artificial response patterns. Our work resolves\nthe pain point of implementing the anti-sensing idea based on the commercial\noff-the-shelf WiFi devices.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 13:00:00 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 21:30:42 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Jiao", "Xianjun", ""], ["Mehari", "Michael", ""], ["Liu", "Wei", ""], ["Aslam", "Muhammad", ""], ["Moerman", "Ingrid", ""]]}, {"id": "2105.07436", "submitter": "Wei Cheng", "authors": "Wei Cheng, Yi Liu, Sylvain Guilley and Olivier Rioul", "title": "Attacking Masked Cryptographic Implementations: Information-Theoretic\n  Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Measuring the information leakage is critical for evaluating practical\nsecurity of cryptographic devices against side-channel analysis. More\nstraightforwardly, it is interesting to have an upper bound on success rate of\nany attack given a (fixed) number of side-channel measurements. Or conversely,\nwe wish to derive a lower bound on the number of queries for a given success\nrate of optimal attacks. In this paper, we derive several bounds in both\ndirections by using information-theoretic tools, particularly for cryptographic\nimplementations protected by masking schemes. We show that a generic upper\nbound on the probability of success, irrespective to specific attacks, is\nlinked to mutual information between side-channel measurements and the secret.\nMoreover, our numerical evaluation confirms that, the success rate of optimal\nmaximum likelihood distinguishers is tightly bounded given a fixed number of\nmeasurements.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 13:16:38 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Cheng", "Wei", ""], ["Liu", "Yi", ""], ["Guilley", "Sylvain", ""], ["Rioul", "Olivier", ""]]}, {"id": "2105.07447", "submitter": "Qin Wang", "authors": "Qin Wang and Rujia Li and Qi Wang and Shiping Chen", "title": "Non-Fungible Token (NFT): Overview, Evaluation, Opportunities and\n  Challenges", "comments": "Tech Report on NFT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Non-Fungible Token (NFT) market is mushrooming in the recent couple of\nyears. The concept of NFT originally comes from a token standard of Ethereum,\naiming to distinguish each token with distinguishable signs. This type of\ntokens can be bound with virtual/digital properties as their unique\nidentifications. With NFTs, all marked properties can be freely traded with\ncustomized values according to their ages, rarity, liquidity, etc. It has\ngreatly stimulated the prosperity of the decentralized application (DApp)\nmarket. At the time of writing (May 2021), the total money used on completed\nNFT sales has reached $34,530,649.86$ USD. The thousandfold return on its\nincreasing market draws huge attention worldwide. However, the development of\nthe NFT ecosystem is still in its early stage, and the technologies of NFTs are\npre-mature. Newcomers may get lost in their frenetic evolution due to the lack\nof systematic summaries. In this technical report, we explore the NFT\necosystems in several aspects. We start with an overview of state-of-the-art\nNFT solutions, then provide their technical components, protocols, standards,\nand desired proprieties. Afterward, we give a security evolution, with\ndiscussions on the perspectives of their design models, opportunities and\nchallenges. To the best of our knowledge, this is the first systematic study on\nthe current NFT ecosystems.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 14:50:26 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Wang", "Qin", ""], ["Li", "Rujia", ""], ["Wang", "Qi", ""], ["Chen", "Shiping", ""]]}, {"id": "2105.07459", "submitter": "Qin Wang", "authors": "Qin Wang and Rujia Li and Shiping Chen and Yang Xiang", "title": "Formal Security Analysis on dBFT Protocol of NEO", "comments": "Extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  NEO is one of the top public chains worldwide. We focus on its backbone\nconsensus protocol, called delegated Byzantine Fault Tolerance (dBFT). The dBFT\nprotocol has been adopted by a variety of blockchain systems such as ONT. dBFT\nclaims to guarantee the security when no more than $f = \\lfloor \\frac{n}{3}\n\\rfloor$ nodes are Byzantine, where $n$ is the total number of consensus\nparticipants. However, we identify attacks to break the claimed security. In\nthis paper, we show our results by providing a security analysis on its dBFT\nprotocol. First, we evaluate NEO's source code and formally present the\nprocedures of dBFT via the state machine replication (SMR) model. Next, we\nprovide a theoretical analysis with two example attacks. These attacks break\nthe security of dBFT with no more than $f$ nodes. Then, we provide\nrecommendations on how to fix the system against the identified attacks. The\nsuggested fixes have been accepted by the NEO official team. Finally, we\nfurther discuss the reasons causing such issues, the relationship with current\npermissioned blockchain systems, and the scope of potential influence.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 15:45:35 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Wang", "Qin", ""], ["Li", "Rujia", ""], ["Chen", "Shiping", ""], ["Xiang", "Yang", ""]]}, {"id": "2105.07501", "submitter": "Mohammad Sayad Haghighi", "authors": "Ghader Ebrahimpour, Mohammad Sayad Haghighi", "title": "Analysis of Bitcoin Vulnerability to Bribery Attacks Launched Through\n  Large Transactions", "comments": "This work is under review for formal publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin uses blockchain technology to maintain transactions order and\nprovides probabilistic guarantee to prevent double-spending, assuming that an\nattacker's computational power does not exceed %50 of the network power. In\nthis paper, we design a novel bribery attack and show that this guarantee can\nbe hugely undermined. Miners are assumed to be rational in this setup and they\nare given incentives that are dynamically calculated. In this attack, the\nadversary misuses the Bitcoin protocol to bribe miners and maximize their\ngained advantage. We will reformulate the bribery attack to propose a general\nmathematical foundation upon which we build multiple strategies. We show that,\nunlike Whale Attack, these strategies are practical. If the rationality\nassumption holds, this shows how vulnerable blockchain-based systems like\nBitcoin are. We suggest a soft fork on Bitcoin to fix this issue at the end.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 19:35:16 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Ebrahimpour", "Ghader", ""], ["Haghighi", "Mohammad Sayad", ""]]}, {"id": "2105.07511", "submitter": "Carlos E. Budde", "authors": "Carlos E. Budde, Mari\\\"elle Stoelinga", "title": "Efficient Algorithms for Quantitative Attack Tree Analysis", "comments": "Public version of CSF'21 paper, including an appendix with all proofs\n  of lemmas and theorems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Numerous analysis methods for quantitative attack tree analysis have been\nproposed. These algorithms compute relevant security metrics, i.e. performance\nindicators that quantify how good the security of a system is, such as the most\nlikely attack, the cheapest, or the most damaging one. This paper classifies\nattack trees in two dimensions: proper trees vs. directed acyclic graphs (i.e.\nwith shared subtrees); and static vs. dynamic gates. For each class, we propose\nnovel algorithms that work over a generic attribute domain, encompassing a\nlarge number of concrete security metrics defined on the attack tree semantics.\nWe also analyse the computational complexity of our methods.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 20:52:20 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 10:28:04 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Budde", "Carlos E.", ""], ["Stoelinga", "Mari\u00eblle", ""]]}, {"id": "2105.07527", "submitter": "Peter Hegedus Dr", "authors": "Tam\\'as Viszkok, P\\'eter Heged\\H{u}s, Rudolf Ferenc", "title": "Improving Vulnerability Prediction of JavaScript Functions Using Process\n  Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the growing number of cyber attacks against computer systems, we need\nto pay special attention to the security of our software systems. In order to\nmaximize the effectiveness, excluding the human component from this process\nwould be a huge breakthrough. The first step towards this is to automatically\nrecognize the vulnerable parts in our code. Researchers put a lot of effort\ninto creating machine learning models that could determine if a given piece of\ncode, or to be more precise, a selected function, contains any vulnerabilities\nor not. We aim at improving the existing models, building on previous results\nin predicting vulnerabilities at the level of functions in JavaScript code\nusing the well-known static source code metrics. In this work, we propose to\ninclude several so-called process metrics (e.g., code churn, number of\ndevelopers modifying a file, or the age of the changed source code) into the\nset of features, and examine how they affect the performance of the\nfunction-level JavaScript vulnerability prediction models. We can confirm that\nprocess metrics significantly improve the prediction power of such models. On\naverage, we observed a 8.4% improvement in terms of F-measure (from 0.764 to\n0.848), 3.5% improvement in terms of precision (from 0.953 to 0.988) and a 6.3%\nimprovement in terms of recall (from 0.697 to 0.760).\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 22:05:48 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Viszkok", "Tam\u00e1s", ""], ["Heged\u0171s", "P\u00e9ter", ""], ["Ferenc", "Rudolf", ""]]}, {"id": "2105.07533", "submitter": "Richard Jiang", "authors": "Richard Jiang, Paul Chazot, Danny Crookes, Ahmed Bouridane and M Emre\n  Celebi", "title": "Private Facial Diagnosis as an Edge Service for Parkinson's DBS\n  Treatment Valuation", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Facial phenotyping has recently been successfully exploited for medical\ndiagnosis as a novel way to diagnose a range of diseases, where facial\nbiometrics has been revealed to have rich links to underlying genetic or\nmedical causes. In this paper, taking Parkinson's Diseases (PD) as a case\nstudy, we proposed an Artificial-Intelligence-of-Things (AIoT) edge-oriented\nprivacy-preserving facial diagnosis framework to analyze the treatment of Deep\nBrain Stimulation (DBS) on PD patients. In the proposed framework, a new\nedge-based information theoretically secure framework is proposed to implement\nprivate deep facial diagnosis as a service over a privacy-preserving\nAIoT-oriented multi-party communication scheme, where partial homomorphic\nencryption (PHE) is leveraged to enable privacy-preserving deep facial\ndiagnosis directly on encrypted facial patterns. In our experiments with a\ncollected facial dataset from PD patients, for the first time, we demonstrated\nthat facial patterns could be used to valuate the improvement of PD patients\nundergoing DBS treatment. We further implemented a privacy-preserving deep\nfacial diagnosis framework that can achieve the same accuracy as the\nnon-encrypted one, showing the potential of our privacy-preserving facial\ndiagnosis as an trustworthy edge service for grading the severity of PD in\npatients.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 22:24:37 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Jiang", "Richard", ""], ["Chazot", "Paul", ""], ["Crookes", "Danny", ""], ["Bouridane", "Ahmed", ""], ["Celebi", "M Emre", ""]]}, {"id": "2105.07574", "submitter": "Jianzhi Lou", "authors": "Jianzhi Lou, Qiben Yan, Qing Hui, Huacheng Zeng", "title": "SoundFence: Securing Ultrasonic Sensors in Vehicles Using Physical-Layer\n  Defense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles (AVs), equipped with numerous sensors such as camera,\nLiDAR, radar, and ultrasonic sensor, are revolutionizing the transportation\nindustry. These sensors are expected to sense reliable information from a\nphysical environment, facilitating the critical decision-making process of the\nAVs. Ultrasonic sensors, which detect obstacles in a short distance, play an\nimportant role in assisted parking and blind spot detection events. However,\ndue to their weak security level, ultrasonic sensors are particularly\nvulnerable to signal injection attacks, when the attackers inject malicious\nacoustic signals to create fake obstacles and intentionally mislead the\nvehicles to make wrong decisions with disastrous aftermath. In this paper, we\nsystematically analyze the attack model of signal injection attacks toward\nmoving vehicles. By considering the potential threats, we propose SoundFence, a\nphysical-layer defense system which leverages the sensors' signal processing\ncapability without requiring any additional equipment. SoundFence verifies the\nbenign measurement results and detects signal injection attacks by analyzing\nsensor readings and the physical-layer signatures of ultrasonic signals. Our\nexperiment with commercial sensors shows that SoundFence detects most (more\nthan 95%) of the abnormal sensor readings with very few false alarms, and it\ncan also accurately distinguish the real echo from injected signals to identify\ninjection attacks.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 01:49:02 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 18:55:17 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Lou", "Jianzhi", ""], ["Yan", "Qiben", ""], ["Hui", "Qing", ""], ["Zeng", "Huacheng", ""]]}, {"id": "2105.07582", "submitter": "Alsharif Abuadbba Dr", "authors": "Keelan Evans, Alsharif Abuadbba, Mohiuddin Ahmed, Tingmin Wu, Mike\n  Johnstone, Surya Nepal", "title": "RAIDER: Reinforcement-aided Spear Phishing Detector", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spear Phishing is a harmful cyber-attack facing business and individuals\nworldwide. Considerable research has been conducted recently into the use of\nMachine Learning (ML) techniques to detect spear-phishing emails. ML-based\nsolutions may suffer from zero-day attacks; unseen attacks unaccounted for in\nthe training data. As new attacks emerge, classifiers trained on older data are\nunable to detect these new varieties of attacks resulting in increasingly\ninaccurate predictions. Spear Phishing detection also faces scalability\nchallenges due to the growth of the required features which is proportional to\nthe number of the senders within a receiver mailbox. This differs from\ntraditional phishing attacks which typically perform only a binary\nclassification between phishing and benign emails. Therefore, we devise a\npossible solution to these problems, named RAIDER: Reinforcement AIded Spear\nPhishing DEtectoR. A reinforcement-learning based feature evaluation system\nthat can automatically find the optimum features for detecting different types\nof attacks. By leveraging a reward and penalty system, RAIDER allows for\nautonomous features selection. RAIDER also keeps the number of features to a\nminimum by selecting only the significant features to represent phishing emails\nand detect spear-phishing attacks. After extensive evaluation of RAIDER over\n11,000 emails and across 3 attack scenarios, our results suggest that using\nreinforcement learning to automatically identify the significant features could\nreduce the dimensions of the required features by 55% in comparison to existing\nML-based systems. It also improves the accuracy of detecting spoofing attacks\nby 4% from 90% to 94%. In addition, RAIDER demonstrates reasonable detection\naccuracy even against a sophisticated attack named Known Sender in which\nspear-phishing emails greatly resemble those of the impersonated sender.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 02:42:54 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Evans", "Keelan", ""], ["Abuadbba", "Alsharif", ""], ["Ahmed", "Mohiuddin", ""], ["Wu", "Tingmin", ""], ["Johnstone", "Mike", ""], ["Nepal", "Surya", ""]]}, {"id": "2105.07612", "submitter": "Xiaoyu Fan", "authors": "Xiaoyu Fan, Guosai Wang, Kun Chen, Xu He, Wei Xu", "title": "PPCA: Privacy-preserving Principal Component Analysis Using Secure\n  Multiparty Computation(MPC)", "comments": "11 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Privacy-preserving data mining has become an important topic. People have\nbuilt several multi-party-computation (MPC)-based frameworks to provide\ntheoretically guaranteed privacy, the poor performance of real-world algorithms\nhave always been a challenge. Using Principal Component Analysis (PCA) as an\nexample, we show that by considering the unique performance characters of the\nMPC platform, we can design highly effective algorithm-level optimizations,\nsuch as replacing expensive operators and batching up. We achieve about\n200$\\times$ performance boost over existing privacy-preserving PCA algorithms\nwith the same level of privacy guarantee. Also, using real-world datasets, we\nshow that by combining multi-party data, we can achieve better training\nresults.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 05:05:24 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Fan", "Xiaoyu", ""], ["Wang", "Guosai", ""], ["Chen", "Kun", ""], ["He", "Xu", ""], ["Xu", "Wei", ""]]}, {"id": "2105.07646", "submitter": "Ling Cheng", "authors": "Ling Cheng, Feida Zhu, Huiwen Liu and Chunyan Miao", "title": "On Decentralization of Bitcoin: An Asset Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since its advent in 2009, Bitcoin, a cryptography-enabled peer-to-peer\ndigital payment system, has been gaining increasing attention from both\nacademia and industry. An effort designed to overcome a cluster of bottlenecks\ninherent in existing centralized financial systems, Bitcoin has always been\nchampioned by the crypto community as an example of the spirit of\ndecentralization. While the decentralized nature of Bitcoin's Proof-of-Work\nconsensus algorithm has often been discussed in great detail, no systematic\nstudy has so far been conducted to quantitatively measure the degree of\ndecentralization of Bitcoin from an asset perspective -- How decentralized is\nBitcoin as a financial asset? We present in this paper the first systematic\ninvestigation of the degree of decentralization for Bitcoin based on its entire\ntransaction history. We proposed both static and dynamic analysis of Bitcoin\ntransaction network with quantifiable decentralization measures developed based\non network analysis and market efficiency study. Case studies are also\nconducted to demonstrate the effectiveness of our proposed metrics.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 07:20:36 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Cheng", "Ling", ""], ["Zhu", "Feida", ""], ["Liu", "Huiwen", ""], ["Miao", "Chunyan", ""]]}, {"id": "2105.07692", "submitter": "Christopher Battarbee", "authors": "Christopher Battarbee, Delaram Kahrobaei and Siamak F. Shahandashti", "title": "Cryptanalysis of Semidirect Product Key Exchange Using Matrices Over\n  Non-Commutative Rings", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It was recently demonstrated that the Matrix Action Key Exchange (MAKE)\nalgorithm, a new type of key exchange protocol using the semidirect product of\nmatrix groups, is vulnerable to a linear algebraic attack if the matrices are\nover a commutative ring. In this note, we establish conditions under which\nprotocols using matrices over a non-commutative ring are also vulnerable to\nthis attack. We then demonstrate that group rings $R[G]$ are examples of\nnon-commutative rings that satisfy these conditions.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 09:24:46 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 13:10:49 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Battarbee", "Christopher", ""], ["Kahrobaei", "Delaram", ""], ["Shahandashti", "Siamak F.", ""]]}, {"id": "2105.07711", "submitter": "Spyridon Mastorakis", "authors": "Muhammad Adil and Mian Ahmad Jan and Spyridon Mastorakis and Houbing\n  Song and Muhammad Mohsin Jadoon and Safia Abbas and Ahmed Farouk", "title": "Hash-MAC-DSDV: Mutual Authentication for Intelligent IoT-Based\n  Cyber-Physical Systems", "comments": "Accepted by the IEEE Internet of Things Journal. The copyright is\n  with the IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-Physical Systems (CPS) connected in the form of Internet of Things\n(IoT) are vulnerable to various security threats, due to the\ninfrastructure-less deployment of IoT devices. Device-to-Device (D2D)\nauthentication of these networks ensures the integrity, authenticity, and\nconfidentiality of information in the deployed area. The literature suggests\ndifferent approaches to address security issues in CPS technologies. However,\nthey are mostly based on centralized techniques or specific system deployments\nwith higher cost of computation and communication. It is therefore necessary to\ndevelop an effective scheme that can resolve the security problems in CPS\ntechnologies of IoT devices. In this paper, a lightweight Hash-MAC-DSDV (Hash\nMedia Access Control Destination Sequence Distance Vector) routing scheme is\nproposed to resolve authentication issues in CPS technologies, connected in the\nform of IoT networks. For this purpose, a CPS of IoT devices (multi-WSNs) is\ndeveloped from the local-chain and public chain, respectively. The proposed\nscheme ensures D2D authentication by the Hash-MAC-DSDV mutual scheme, where the\nMAC addresses of individual devices are registered in the first phase and\nadvertised in the network in the second phase. The proposed scheme allows\nlegitimate devices to modify their routing table and unicast the one-way hash\nauthentication mechanism to transfer their captured data from source towards\nthe destination. Our evaluation results demonstrate that Hash- MAC-DSDV\noutweighs the existing schemes in terms of attack detection, energy consumption\nand communication metrics.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 10:05:08 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Adil", "Muhammad", ""], ["Jan", "Mian Ahmad", ""], ["Mastorakis", "Spyridon", ""], ["Song", "Houbing", ""], ["Jadoon", "Muhammad Mohsin", ""], ["Abbas", "Safia", ""], ["Farouk", "Ahmed", ""]]}, {"id": "2105.07722", "submitter": "Wadii Boulila Prof.", "authors": "Maha Driss, Daniah Hasan, Wadii Boulila, Jawad Ahmad", "title": "Microservices in IoT Security: Current Solutions, Research Challenges,\n  and Future Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, the Internet of Things (IoT) technology has led to the\nemergence of multiple smart applications in different vital sectors including\nhealthcare, education, agriculture, energy management, etc. IoT aims to\ninterconnect several intelligent devices over the Internet such as sensors,\nmonitoring systems, and smart appliances to control, store, exchange, and\nanalyze collected data. The main issue in IoT environments is that they can\npresent potential vulnerabilities to be illegally accessed by malicious users,\nwhich threatens the safety and privacy of gathered data. To face this problem,\nseveral recent works have been conducted using microservices-based architecture\nto minimize the security threats and attacks related to IoT data. By employing\nmicroservices, these works offer extensible, reusable, and reconfigurable\nsecurity features. In this paper, we aim to provide a survey about\nmicroservices-based approaches for securing IoT applications. This survey will\nhelp practitioners understand ongoing challenges and explore new and promising\nresearch opportunities in the IoT security field. To the best of our knowledge,\nthis paper constitutes the first survey that investigates the use of\nmicroservices technology for securing IoT applications.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 10:40:49 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Driss", "Maha", ""], ["Hasan", "Daniah", ""], ["Boulila", "Wadii", ""], ["Ahmad", "Jawad", ""]]}, {"id": "2105.07754", "submitter": "Xinjian Luo", "authors": "Xinjian Luo, Xiaokui Xiao, Yuncheng Wu, Juncheng Liu, Beng Chin Ooi", "title": "A Fusion-Denoising Attack on InstaHide with Data Augmentation", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  InstaHide is a state-of-the-art mechanism for protecting private training\nimages in collaborative learning. It works by mixing multiple private images\nand modifying them in such a way that their visual features are no longer\ndistinguishable to the naked eye, without significantly degrading the accuracy\nof training. In recent work, however, Carlini et al. show that it is possible\nto reconstruct private images from the encrypted dataset generated by\nInstaHide, by exploiting the correlations among the encrypted images.\nNevertheless, Carlini et al.'s attack relies on the assumption that each\nprivate image is used without modification when mixing up with other private\nimages. As a consequence, it could be easily defeated by incorporating data\naugmentation into InstaHide. This leads to a natural question: is InstaHide\nwith data augmentation secure?\n  This paper provides a negative answer to the above question, by present an\nattack for recovering private images from the outputs of InstaHide even when\ndata augmentation is present. The basic idea of our attack is to use a\ncomparative network to identify encrypted images that are likely to correspond\nto the same private image, and then employ a fusion-denoising network for\nrestoring the private image from the encrypted ones, taking into account the\neffects of data augmentation. Extensive experiments demonstrate the\neffectiveness of the proposed attack in comparison to Carlini et al.'s attack.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 11:58:16 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Luo", "Xinjian", ""], ["Xiao", "Xiaokui", ""], ["Wu", "Yuncheng", ""], ["Liu", "Juncheng", ""], ["Ooi", "Beng Chin", ""]]}, {"id": "2105.07845", "submitter": "Yasir K{\\i}l{\\i}\\c{c}", "authors": "Yasir Kilic", "title": "Shared data granularity: A latent dimension of privacy scoring over\n  online social networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Privacy scoring aims at measuring the privacy violation risk of a user over\nan online social network (OSN). Existing work in the field rely on possibly\nbiased or emotional survey data and focus only on personel purpose OSNs like\nFacebook. In contrast to existing work, in this thesis, we work with real-world\nOSN data collected from LinkedIn, the most popular professional-purpose OSN\n(ProOSN). Towards this end, we developed an extensive crawler to collect all\nrelevant profile data of 5,389 LinkedIn users, modelled these data using both\nrelational and graph databases and quantitatively analyzed all privacy risk\nscoring methods in the literature. Additionally, we propose a novel scoring\nmethod that consider the granularity of data an OSN user shares on her profile\npage. Extensive experimental evaluation of existing and proposed scoring\nmethods indicates the effectiveness of the proposed solution.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 06:00:51 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Kilic", "Yasir", ""]]}, {"id": "2105.07854", "submitter": "Filipo Sharevski", "authors": "Filipo Sharevski, Anna Slowinski, Peter Jachim, Emma Pieroni", "title": "\"Hey Alexa, What do You Know About the COVID-19 Vaccine?\" --\n  (Mis)perceptions of Mass Immunization Among Voice Assistant Users", "comments": "arXiv admin note: text overlap with arXiv:2104.04077", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we analyzed the perceived accuracy of COVID-19 vaccine\ninformation spoken back by Amazon Alexa. Unlike social media, Amazon Alexa\ndoesn't apply soft moderation to unverified content, allowing for use of\nthird-party malicious skills to arbitrarily phrase COVID-19 vaccine\ninformation. The results from a 210-participant study suggest that a\nthird-party malicious skill could successful reduce the perceived accuracy\namong the users of information as to who gets the vaccine first, vaccine\ntesting, and the side effects of the vaccine. We also found that the\nvaccine-hesitant participants are drawn to pessimistically rephrased Alexa\nresponses focused on the downsides of the mass immunization. We discuss\nsolutions for soft moderation against misperception-inducing or altogether\nCOVID-19 misinformation malicious third-party skills.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 15:26:48 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Sharevski", "Filipo", ""], ["Slowinski", "Anna", ""], ["Jachim", "Peter", ""], ["Pieroni", "Emma", ""]]}, {"id": "2105.07937", "submitter": "Paul Kantor", "authors": "Paul B. Kantor, Dennis E. Egan, Jonathan Bullinger, Katie McKeon,\n  James Wojtowicz", "title": "Confidence Assertions in Cyber-Security for an Information-Sharing\n  Environment", "comments": "50pp. CCICADA Technical Report", "journal-ref": null, "doi": null, "report-no": "CCICADA-TR/2017-001", "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Information sharing is vital in resisting cyberattacks, and the volume and\nseverity of these attacks is increasing very rapidly. Therefore responders must\ntriage incoming warnings in deciding how to act. This study asked a very\nspecific question: \"how can the addition of confidence information to alerts\nand warnings improve overall resistance to cyberattacks.\" We sought, in\nparticular, to identify current practices, and if possible, to identify some\n\"best practices.\" The research involved literature review and interviews with\nsubject matter experts at every level from system administrators to persons who\ndevelop broad principles of policy. An innovative Modified Online Delphi Panel\ntechnique was used to elicit judgments and recommendations from experts who\nwere able to speak with each other and vote anonymously to rank proposed\npractices.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 15:23:12 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Kantor", "Paul B.", ""], ["Egan", "Dennis E.", ""], ["Bullinger", "Jonathan", ""], ["McKeon", "Katie", ""], ["Wojtowicz", "James", ""]]}, {"id": "2105.07985", "submitter": "Franziska Boenisch", "authors": "Franziska Boenisch, Philip Sperl, Konstantin B\\\"ottinger", "title": "Gradient Masking and the Underestimated Robustness Threats of\n  Differential Privacy in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An important problem in deep learning is the privacy and security of neural\nnetworks (NNs). Both aspects have long been considered separately. To date, it\nis still poorly understood how privacy enhancing training affects the\nrobustness of NNs. This paper experimentally evaluates the impact of training\nwith Differential Privacy (DP), a standard method for privacy preservation, on\nmodel vulnerability against a broad range of adversarial attacks. The results\nsuggest that private models are less robust than their non-private\ncounterparts, and that adversarial examples transfer better among DP models\nthan between non-private and private ones. Furthermore, detailed analyses of DP\nand non-DP models suggest significant differences between their gradients.\nAdditionally, this work is the first to observe that an unfavorable choice of\nparameters in DP training can lead to gradient masking, and, thereby, results\nin a wrong sense of security.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 16:10:54 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Boenisch", "Franziska", ""], ["Sperl", "Philip", ""], ["B\u00f6ttinger", "Konstantin", ""]]}, {"id": "2105.08096", "submitter": "Luca Arnaboldi `", "authors": "Luca Arnaboldi and Charles Morisset", "title": "A Review of Intrusion Detection Systems and Their Evaluation in the IoT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intrusion Detection Systems (IDS) are key components for securing critical\ninfrastructures, capable of detecting malicious activities on networks or\nhosts. The procedure of implementing a IDS for Internet of Things (IoT)\nnetworks is not without challenges due to the variability of these systems and\nspecifically the difficulty in accessing data. The specifics of these very\nconstrained devices render the design of an IDS capable of dealing with the\nvaried attacks a very challenging problem and a very active research subject.\nIn the current state of literature, a number of approaches have been proposed\nto improve the efficiency of intrusion detection, catering to some of these\nlimitations, such as resource constraints and mobility. In this article, we\nreview works on IDS specifically for these kinds of devices from 2008 to 2018,\ncollecting a total of 51 different IDS papers. We summarise the current themes\nof the field, summarise the techniques employed to train and deploy the IDSs\nand provide a qualitative evaluations of these approaches. While these works\nprovide valuable insights and solutions for sub-parts of these constraints, we\ndiscuss the limitations of these solutions as a whole, in particular what kinds\nof attacks these approaches struggle to detect and the setup limitations that\nare unique to this kind of system. We find that although several paper claim\nnovelty of their approach little inter paper comparisons have been made, that\nthere is a dire need for sharing of datasets and almost no shared code\nrepositories, consequently raising the need for a thorough comparative\nevaluation.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 18:06:51 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Arnaboldi", "Luca", ""], ["Morisset", "Charles", ""]]}, {"id": "2105.08120", "submitter": "Sergey Afanasiev", "authors": "Sergey Afanasiev, Anastasiya Smirnova and Diana Kotereva", "title": "Itsy Bitsy SpiderNet: Fully Connected Residual Network for Fraud\n  Detection", "comments": "11 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the development of high technology, the scope of fraud is increasing,\nresulting in annual losses of billions of dollars worldwide. The preventive\nprotection measures become obsolete and vulnerable over time, so effective\ndetective tools are needed. In this paper, we propose a convolutional neural\nnetwork architecture SpiderNet designed to solve fraud detection problems. We\nnoticed that the principles of pooling and convolutional layers in neural\nnetworks are very similar to the way antifraud analysts work when conducting\ninvestigations. Moreover, the skip-connections used in neural networks make the\nusage of features of various power in antifraud models possible. Our\nexperiments have shown that SpiderNet provides better quality compared to\nRandom Forest and adapted for antifraud modeling problems 1D-CNN, 1D-DenseNet,\nF-DenseNet neural networks. We also propose new approaches for fraud feature\nengineering called B-tests and W-tests, which generalize the concepts of\nBenford's Law for fraud anomalies detection. Our results showed that B-tests\nand W-tests give a significant increase to the quality of our antifraud models.\nThe SpiderNet code is available at https://github.com/aasmirnova24/SpiderNet\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 19:16:32 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Afanasiev", "Sergey", ""], ["Smirnova", "Anastasiya", ""], ["Kotereva", "Diana", ""]]}, {"id": "2105.08233", "submitter": "Gang Qiao", "authors": "Gang Qiao, Weijie J. Su, Li Zhang", "title": "Oneshot Differentially Private Top-k Selection", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Being able to efficiently and accurately select the top-$k$ elements with\ndifferential privacy is an integral component of various private data analysis\ntasks. In this paper, we present the oneshot Laplace mechanism, which\ngeneralizes the well-known Report Noisy Max mechanism to reporting noisy\ntop-$k$ elements. We show that the oneshot Laplace mechanism with a noise level\nof $\\widetilde{O}(\\sqrt{k}/\\eps)$ is approximately differentially private.\nCompared to the previous peeling approach of running Report Noisy Max $k$\ntimes, the oneshot Laplace mechanism only adds noises and computes the top $k$\nelements once, hence much more efficient for large $k$. In addition, our proof\nof privacy relies on a novel coupling technique that bypasses the use of\ncomposition theorems. Finally, we present a novel application of efficient\ntop-$k$ selection in the classical problem of ranking from pairwise\ncomparisons.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 02:18:01 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 17:32:13 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Qiao", "Gang", ""], ["Su", "Weijie J.", ""], ["Zhang", "Li", ""]]}, {"id": "2105.08350", "submitter": "Sirui Guo", "authors": "Wenfa Qi, Wei Hu, Sirui Guo, Zongming Guo, Xiang Wang", "title": "Generic Reversible Visible Watermarking Via Regularized Graph Fourier\n  Transform Coding", "comments": "This manuscript is submitted to IEEE Transactions on Image Processing\n  on May 17th 2021. It has 13 pages, 10 figures and 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reversible visible watermarking (RVW) is an active copyright protection\nmechanism. It not only transparently superimposes copyright patterns on\nspecific positions of digital images or video frames to declare the copyright\nownership information, but also completely erases the visible watermark image\nand thus enables restoring the original host image without any distortion.\nHowever, existing RVW algorithms mostly construct the reversible mapping\nmechanism for a specific visible watermarking scheme, which is not general.\nHence, we propose a generic RVW framework to accommodate various visible\nwatermarking schemes, which is based on Regularized Graph Fourier Transform\n(GFT) coding. In particular, we obtain a reconstruction data packet -- the\ncompressed difference image between the watermarked image and the original host\nimage, which is embedded into the watermarked image via any conventional\nreversible data hiding method to facilitate the blind recovery of the host\nimage. The key is to achieve compact compression of the difference image for\nefficient embedding of the reconstruction data packet. To this end, we propose\nregularized GFT coding, where the difference image is smoothed via the graph\nLaplacian regularizer for more efficient compression and then encoded by\nmulti-resolution GFTs in an approximately optimal manner. Experimental results\nshow that the proposed method achieves the state-of-the-art performance with\nhigh data compression efficiency, which is applicable to both gray-scale and\ncolor images. In addition, the proposed generic framework accommodates various\nvisible watermarking algorithms, which demonstrates strong versatility.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 08:22:36 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Qi", "Wenfa", ""], ["Hu", "Wei", ""], ["Guo", "Sirui", ""], ["Guo", "Zongming", ""], ["Wang", "Xiang", ""]]}, {"id": "2105.08364", "submitter": "Xinwei Zhang", "authors": "Xinwei Zhang, Guyue Li, Junqing Zhang, Aiqun Hu, Zongyue Hou, Bin Xiao", "title": "Deep Learning-based Physical-Layer Secret Key Generation for FDD Systems", "comments": "13pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical-layer key generation (PKG) establishes cryptographic keys from\nhighly correlated measurements of wireless channels, which relies on reciprocal\nchannel characteristics between uplink and downlink, is a promising wireless\nsecurity technique for Internet of Things (IoT). However, it is challenging to\nextract common features in frequency division duplexing (FDD) systems as uplink\nand downlink transmissions operate at different frequency bands whose channel\nfrequency responses are not reciprocal any more. Existing PKG methods for FDD\nsystems have many limitations, i.e., high overhead and security problems. This\npaper proposes a novel PKG scheme that uses the feature mapping function\nbetween different frequency bands obtained by deep learning to make two users\ngenerate highly similar channel features in FDD systems. In particular, this is\nthe first time to apply deep learning for PKG in FDD systems. We first prove\nthe existence of the band feature mapping function for a given environment and\na feedforward network with a single hidden layer can approximate the mapping\nfunction. Then a Key Generation neural Network (KGNet) is proposed for\nreciprocal channel feature construction, and a key generation scheme based on\nthe KGNet is also proposed. Numerical results verify the excellent performance\nof the KGNet-based key generation scheme in terms of randomness, key generation\nratio, and key error rate, which proves that it is feasible to generate keys\nfor FDD systems with lower overhead and more secure functions compared to\nexisting methods.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 08:41:22 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Zhang", "Xinwei", ""], ["Li", "Guyue", ""], ["Zhang", "Junqing", ""], ["Hu", "Aiqun", ""], ["Hou", "Zongyue", ""], ["Xiao", "Bin", ""]]}, {"id": "2105.08395", "submitter": "Nikos Fotiou", "authors": "Nikos Fotiou, Vasilios A. Siris, George C. Polyzos", "title": "Enabling self-verifiable mutable content items in IPFS using\n  Decentralized Identifiers", "comments": "In: DI2F: Decentralising the Internet with IPFS and Filecoin, IFIP\n  Networking 2021 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In IPFS content identifiers are constructed based on the item's data\ntherefore the binding between an item's identifier and its data can be\ndeterministically verified. Nevertheless, once an item is modified, its\nidentifier also changes. Therefore when it comes to mutable content there is a\nneed for keeping track of the \"latest\" IPFS identifier. This is achieved using\nnaming protocols on top of IPFS, such as IPNS and DNSlink, that map a constant\nname to an IPFS identifier, allowing at the same time content owners to update\nthese mappings. Nevertheless, IPNS relies on a cryptographic key pair that\ncannot be rotated, and DNSlink does not provide content authenticity\nprotection. In this paper, we propose a naming protocol that combines DNSlink\nand decentralized identifiers to enable self-verifiable content items. Our\nprotocol provides content authenticity without imposing any security\nrequirement to DNSlink. Furthermore, our protocol prevent fake content even if\nattackers have access to the DNS server of the content owner or have access to\nthe content owner secret keys. Our proof of concept implementation shows that\nour protocol is feasible and can be used with existing IPFS tools.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 09:46:50 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Fotiou", "Nikos", ""], ["Siris", "Vasilios A.", ""], ["Polyzos", "George C.", ""]]}, {"id": "2105.08459", "submitter": "Simon Yusuf Enoch", "authors": "Simon Yusuf Enoch, Mengmeng Ge, Jin B. Hong, Dong Seong Kim", "title": "Model-based Cybersecurity Analysis: Past Work and Future Directions", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based evaluation in cybersecurity has a long history. Attack Graphs\n(AGs) and Attack Trees (ATs) were the earlier developed graphical security\nmodels for cybersecurity analysis. However, they have limitations (e.g.,\nscalability problem, state-space explosion problem, etc.) and lack the ability\nto capture other security features (e.g., countermeasures). To address the\nlimitations and to cope with various security features, a graphical security\nmodel named attack countermeasure tree (ACT) was developed to perform security\nanalysis by taking into account both attacks and countermeasures. In our\nresearch, we have developed different variants of a hierarchical graphical\nsecurity model to solve the complexity, dynamicity, and scalability issues\ninvolved with security models in the security analysis of systems. In this\npaper, we summarize and classify security models into the following;\ngraph-based, tree-based, and hybrid security models. We discuss the development\nof a hierarchical attack representation model (HARM) and different variants of\nthe HARM, its applications, and usability in a variety of domains including the\nInternet of Things (IoT), Cloud, Software-Defined Networking, and Moving Target\nDefenses. We provide the classification of the security metrics, including\ntheir discussions. Finally, we highlight existing problems and suggest future\nresearch directions in the area of graphical security models and applications.\nAs a result of this work, a decision-maker can understand which type of HARM\nwill suit their network or security analysis requirements.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 11:54:14 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 14:07:01 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Enoch", "Simon Yusuf", ""], ["Ge", "Mengmeng", ""], ["Hong", "Jin B.", ""], ["Kim", "Dong Seong", ""]]}, {"id": "2105.08511", "submitter": "Xing Tian", "authors": "Chris Xing Tian, Haoliang Li, Yufei Wang, Shiqi Wang", "title": "Privacy-Preserving Constrained Domain Generalization for Medical Image\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) have demonstrated unprecedented success for\nmedical imaging applications. However, due to the issue of limited dataset\navailability and the strict legal and ethical requirements for patient privacy\nprotection, the broad applications of medical imaging classification driven by\nDNN with large-scale training data have been largely hindered. For example,\nwhen training the DNN from one domain (e.g., with data only from one hospital),\nthe generalization capability to another domain (e.g., data from another\nhospital) could be largely lacking. In this paper, we aim to tackle this\nproblem by developing the privacy-preserving constrained domain generalization\nmethod, aiming to improve the generalization capability under the\nprivacy-preserving condition. In particular, We propose to improve the\ninformation aggregation process on the centralized server-side with a novel\ngradient alignment loss, expecting that the trained model can be better\ngeneralized to the \"unseen\" but related medical images. The rationale and\neffectiveness of our proposed method can be explained by connecting our\nproposed method with the Maximum Mean Discrepancy (MMD) which has been widely\nadopted as the distribution distance measurement. Experimental results on two\nchallenging medical imaging classification tasks indicate that our method can\nachieve better cross-domain generalization capability compared to the\nstate-of-the-art federated learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 15:21:13 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Tian", "Chris Xing", ""], ["Li", "Haoliang", ""], ["Wang", "Yufei", ""], ["Wang", "Shiqi", ""]]}, {"id": "2105.08587", "submitter": "Leila Karimi", "authors": "Leila Karimi, Mai Abdelhakim, James Joshi", "title": "Adaptive ABAC Policy Learning: A Reinforcement Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With rapid advances in computing systems, there is an increasing demand for\nmore effective and efficient access control (AC) approaches. Recently,\nAttribute Based Access Control (ABAC) approaches have been shown to be\npromising in fulfilling the AC needs of such emerging complex computing\nenvironments. An ABAC model grants access to a requester based on attributes of\nentities in a system and an authorization policy; however, its generality and\nflexibility come with a higher cost. Further, increasing complexities of\norganizational systems and the need for federated accesses to their resources\nmake the task of AC enforcement and management much more challenging. In this\npaper, we propose an adaptive ABAC policy learning approach to automate the\nauthorization management task. We model ABAC policy learning as a reinforcement\nlearning problem. In particular, we propose a contextual bandit system, in\nwhich an authorization engine adapts an ABAC model through a feedback control\nloop; it relies on interacting with users/administrators of the system to\nreceive their feedback that assists the model in making authorization\ndecisions. We propose four methods for initializing the learning model and a\nplanning approach based on attribute value hierarchy to accelerate the learning\nprocess. We focus on developing an adaptive ABAC policy learning model for a\nhome IoT environment as a running example. We evaluate our proposed approach\nover real and synthetic data. We consider both complete and sparse datasets in\nour evaluations. Our experimental results show that the proposed approach\nachieves performance that is comparable to ones based on supervised learning in\nmany scenarios and even outperforms them in several situations.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 15:18:02 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Karimi", "Leila", ""], ["Abdelhakim", "Mai", ""], ["Joshi", "James", ""]]}, {"id": "2105.08619", "submitter": "Ryan Sheatsley", "authors": "Ryan Sheatsley and Blaine Hoak and Eric Pauley and Yohan Beugin and\n  Michael J. Weisman and Patrick McDaniel", "title": "On the Robustness of Domain Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is vulnerable to adversarial examples-inputs designed to\ncause models to perform poorly. However, it is unclear if adversarial examples\nrepresent realistic inputs in the modeled domains. Diverse domains such as\nnetworks and phishing have domain constraints-complex relationships between\nfeatures that an adversary must satisfy for an attack to be realized (in\naddition to any adversary-specific goals). In this paper, we explore how domain\nconstraints limit adversarial capabilities and how adversaries can adapt their\nstrategies to create realistic (constraint-compliant) examples. In this, we\ndevelop techniques to learn domain constraints from data, and show how the\nlearned constraints can be integrated into the adversarial crafting process. We\nevaluate the efficacy of our approach in network intrusion and phishing\ndatasets and find: (1) up to 82% of adversarial examples produced by\nstate-of-the-art crafting algorithms violate domain constraints, (2) domain\nconstraints are robust to adversarial examples; enforcing constraints yields an\nincrease in model accuracy by up to 34%. We observe not only that adversaries\nmust alter inputs to satisfy domain constraints, but that these constraints\nmake the generation of valid adversarial examples far more challenging.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 15:49:55 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Sheatsley", "Ryan", ""], ["Hoak", "Blaine", ""], ["Pauley", "Eric", ""], ["Beugin", "Yohan", ""], ["Weisman", "Michael J.", ""], ["McDaniel", "Patrick", ""]]}, {"id": "2105.08671", "submitter": "Neel Kanwal", "authors": "Jiahui Geng, Neel Kanwal, Martin Gilje Jaatun, Chunming Rong", "title": "DID-eFed: Facilitating Federated Learning as a Service with\n  Decentralized Identities", "comments": "Paper accepted in EASE2021", "journal-ref": null, "doi": "10.1145/3463274.3463352", "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have entered the era of big data, and it is considered to be the \"fuel\"\nfor the flourishing of artificial intelligence applications. The enactment of\nthe EU General Data Protection Regulation (GDPR) raises concerns about\nindividuals' privacy in big data. Federated learning (FL) emerges as a\nfunctional solution that can help build high-performance models shared among\nmultiple parties while still complying with user privacy and data\nconfidentiality requirements. Although FL has been intensively studied and used\nin real applications, there is still limited research related to its prospects\nand applications as a FLaaS (Federated Learning as a Service) to interested 3rd\nparties. In this paper, we present a FLaaS system: DID-eFed, where FL is\nfacilitated by decentralized identities (DID) and a smart contract. DID enables\na more flexible and credible decentralized access management in our system,\nwhile the smart contract offers a frictionless and less error-prone process. We\ndescribe particularly the scenario where our DID-eFed enables the FLaaS among\nhospitals and research institutions.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 16:55:34 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 07:44:07 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Geng", "Jiahui", ""], ["Kanwal", "Neel", ""], ["Jaatun", "Martin Gilje", ""], ["Rong", "Chunming", ""]]}, {"id": "2105.08709", "submitter": "Ji Gao", "authors": "Ji Gao, Amin Karbasi, Mohammad Mahmoody", "title": "Learning and Certification under Instance-targeted Poisoning", "comments": "This is the full version of a paper appearing in The Conference on\n  Uncertainty in Artificial Intelligence (UAI) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study PAC learnability and certification under\ninstance-targeted poisoning attacks, where the adversary may change a fraction\nof the training set with the goal of fooling the learner at a specific target\ninstance. Our first contribution is to formalize the problem in various\nsettings, and explicitly discussing subtle aspects such as learner's randomness\nand whether (or not) adversary's attack can depend on it. We show that when the\nbudget of the adversary scales sublinearly with the sample complexity, PAC\nlearnability and certification are achievable. In contrast, when the\nadversary's budget grows linearly with the sample complexity, the adversary can\npotentially drive up the expected 0-1 loss to one. We further extend our\nresults to distribution-specific PAC learning in the same attack model and show\nthat proper learning with certification is possible for learning halfspaces\nunder Gaussian distribution. Finally, we empirically study the robustness of K\nnearest neighbour, logistic regression, multi-layer perceptron, and\nconvolutional neural network on real data sets, and test them against\ntargeted-poisoning attacks. Our experimental results show that many models,\nespecially state-of-the-art neural networks, are indeed vulnerable to these\nstrong attacks. Interestingly, we observe that methods with high standard\naccuracy might be more vulnerable to instance-targeted poisoning attacks.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 17:48:15 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Gao", "Ji", ""], ["Karbasi", "Amin", ""], ["Mahmoody", "Mohammad", ""]]}, {"id": "2105.08712", "submitter": "Asmit De", "authors": "Asmit De, Swaroop Ghosh", "title": "HeapSafe: Securing Unprotected Heaps in RISC-V", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RISC-V is a promising open-source architecture primarily targeted for\nembedded systems. Programs compiled using the RISC-V toolchain can run\nbare-metal on the system, and, as such, can be vulnerable to several memory\ncorruption vulnerabilities. In this work, we present HeapSafe, a lightweight\nhardware assisted heap-buffer protection scheme to mitigate heap overflow and\nuse-after-free vulnerabilities in a RISC-V SoC. The proposed scheme tags\npointers associated with heap buffers with metadata indices and enforces tag\npropagation for commonly used pointer operations. The HeapSafe hardware is\ndecoupled from the core and is designed as a configurable coprocessor and is\nresponsible for validating the heap buffer accesses. Benchmark results show a\n1.5X performance overhead and 1.59% area overhead, while being 22% faster than\na software protection. We further implemented a HeapSafe-nb, an asynchronous\nvalidation design, which improves performance by 27% over the synchronous\nHeapSafe.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 17:52:16 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["De", "Asmit", ""], ["Ghosh", "Swaroop", ""]]}, {"id": "2105.08713", "submitter": "Karim Banawan", "authors": "Karim Banawan and Ahmed Arafa and Sennur Ulukus", "title": "Timely Private Information Retrieval", "comments": "Accepted for presentation in ISIT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.NI eess.SP math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce the problem of \\emph{timely} private information retrieval (PIR)\nfrom $N$ non-colluding and replicated servers. In this problem, a user desires\nto retrieve a message out of $M$ messages from the servers, whose contents are\ncontinuously updating. The retrieval process should be executed in a timely\nmanner such that no information is leaked about the identity of the message. To\nassess the timeliness, we use the \\emph{age of information} (AoI) metric.\nInterestingly, the timely PIR problem reduces to an AoI minimization subject to\nPIR constraints under \\emph{asymmetric traffic}. We explicitly characterize the\noptimal tradeoff between the PIR rate and the AoI metric (peak AoI or average\nAoI) for the case of $N=2$, $M=3$. Further, we provide some structural insights\non the general problem with arbitrary $N$, $M$.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 17:53:00 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Banawan", "Karim", ""], ["Arafa", "Ahmed", ""], ["Ulukus", "Sennur", ""]]}, {"id": "2105.08714", "submitter": "Evan Shelhamer", "authors": "Dequan Wang, An Ju, Evan Shelhamer, David Wagner, Trevor Darrell", "title": "Fighting Gradients with Gradients: Dynamic Defenses against Adversarial\n  Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks optimize against models to defeat defenses. Existing\ndefenses are static, and stay the same once trained, even while attacks change.\nWe argue that models should fight back, and optimize their defenses against\nattacks at test time. We propose dynamic defenses, to adapt the model and input\nduring testing, by defensive entropy minimization (dent). Dent alters testing,\nbut not training, for compatibility with existing models and train-time\ndefenses. Dent improves the robustness of adversarially-trained defenses and\nnominally-trained models against white-box, black-box, and adaptive attacks on\nCIFAR-10/100 and ImageNet. In particular, dent boosts state-of-the-art defenses\nby 20+ points absolute against AutoAttack on CIFAR-10 at $\\epsilon_\\infty$ =\n8/255.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 17:55:07 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Wang", "Dequan", ""], ["Ju", "An", ""], ["Shelhamer", "Evan", ""], ["Wagner", "David", ""], ["Darrell", "Trevor", ""]]}, {"id": "2105.08741", "submitter": "Dominik Dold", "authors": "Josep Soler Garrido, Dominik Dold, Johannes Frank", "title": "Machine learning on knowledge graphs for context-aware security\n  monitoring", "comments": "Accepted for publication at IEEE-CSR 2021. Data is available on\n  https://github.com/dodo47/cyberML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning techniques are gaining attention in the context of intrusion\ndetection due to the increasing amounts of data generated by monitoring tools,\nas well as the sophistication displayed by attackers in hiding their activity.\nHowever, existing methods often exhibit important limitations in terms of the\nquantity and relevance of the generated alerts. Recently, knowledge graphs are\nfinding application in the cybersecurity domain, showing the potential to\nalleviate some of these drawbacks thanks to their ability to seamlessly\nintegrate data from multiple domains using human-understandable vocabularies.\nWe discuss the application of machine learning on knowledge graphs for\nintrusion detection and experimentally evaluate a link-prediction method for\nscoring anomalous activity in industrial systems. After initial unsupervised\ntraining, the proposed method is shown to produce intuitively well-calibrated\nand interpretable alerts in a diverse range of scenarios, hinting at the\npotential benefits of relational machine learning on knowledge graphs for\nintrusion detection purposes.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 18:00:19 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Garrido", "Josep Soler", ""], ["Dold", "Dominik", ""], ["Frank", "Johannes", ""]]}, {"id": "2105.08842", "submitter": "Ansgar Scherp", "authors": "Fabian Singhofer, Aygul Garifullina, Mathias Kern, Ansgar Scherp", "title": "rx-anon -- A Novel Approach on the De-Identification of Heterogeneous\n  Data based on a Modified Mondrian Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional approaches for data anonymization consider relational data and\ntextual data independently. We propose rx-anon, an anonymization approach for\nheterogeneous semi-structured documents composed of relational and textual\nattributes. We map sensitive terms extracted from the text to the structured\ndata. This allows us to use concepts like k-anonymity to generate a joined,\nprivacy-preserved version of the heterogeneous data input. We introduce the\nconcept of redundant sensitive information to consistently anonymize the\nheterogeneous data. To control the influence of anonymization over unstructured\ntextual data versus structured data attributes, we introduce a modified,\nparameterized Mondrian algorithm. The parameter $\\lambda$ allows to give\ndifferent weight on the relational and textual attributes during the\nanonymization process. We evaluate our approach with two real-world datasets\nusing a Normalized Certainty Penalty score, adapted to the problem of jointly\nanonymizing relational and textual data. The results show that our approach is\ncapable of reducing information loss by using the tuning parameter to control\nthe Mondrian partitioning while guaranteeing k-anonymity for relational\nattributes as well as for sensitive terms. As rx-anon is a framework approach,\nit can be reused and extended by other anonymization algorithms, privacy\nmodels, and textual similarity metrics.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 21:50:12 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Singhofer", "Fabian", ""], ["Garifullina", "Aygul", ""], ["Kern", "Mathias", ""], ["Scherp", "Ansgar", ""]]}, {"id": "2105.08886", "submitter": "Sabah Suhail", "authors": "Sabah Suhail, Raja Jurdak, Raimundas Matulevi\\v{c}ius, and Choong Seon\n  Hong", "title": "Securing Cyber-Physical Systems Through Blockchain-Based Digital Twins\n  and Threat Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of digitization and complexity of connectivity in\nCyber-Physical Systems (CPSs) calls for a mechanism that can evaluate the\nfunctionality and security of critical infrastructures. In this regard, Digital\nTwins (DTs) are revolutionizing the CPSs. Driven by asset-centric data, DTs are\nvirtual replicas of physical systems that mirror every facet of a product or\nprocess and can provide actionable insights through monitoring, optimization,\nand prediction. Furthermore, replication and simulation modes in DTs can\nprevent and detect security flaws in the CPS without obstructing the ongoing\noperations of the live system. However, such benefits of DTs are based on an\nassumption about data trust, integrity, and security. Data trustworthiness is\nconsidered to be more critical when it comes to the integration and\ninteroperability of multiple components or sub-components among different DTs\nowned by multiple stakeholders to provide an aggregated view of the complex\nphysical system. Moreover, analyzing the huge volume of data for creating\nactionable insights in real-time is another critical requirement that demands\nautomation. This article focuses on securing CPSs by integrating Artificial\nIntelligence (AI) and blockchain for intelligent and trusted DTs. We envision\nan AI-aided blockchain-based DT framework that can ensure anomaly prevention\nand detection in addition to responding against novel attack vectors in\nparallel with the normal ongoing operations of the live systems. We discuss the\napplicability of the proposed framework for the automotive industry as a CPS\nuse case. Finally, we identify challenges that impede the implementation of\nintelligence-driven architectures in CPS.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 02:11:43 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Suhail", "Sabah", ""], ["Jurdak", "Raja", ""], ["Matulevi\u010dius", "Raimundas", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2105.08899", "submitter": "Leo Yu Zhang Dr.", "authors": "Yushu Zhang, Xiangli Xiao, Leo Yu Zhang, Zhe Liu, and Jiwu Huang", "title": "CREAMS: Copyrighted Cloud Media Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of the big data era drives the media data owner to seek help from\nthe cloud platform for data hosting and sharing. Sharing media data through the\ncloud suffers three key security/privacy problems including the leakage of data\nprivacy, the infringement on the data owner's copyright, and the infringement\non the user's right. Existing techniques such as attribute-based encryption,\nproxy re-encryption, and asymmetric fingerprinting are insufficient to solve\nall three problems. In this work, we consider the scheme design of being\ncapable of addressing these three problems simultaneously. Associating the\nadditive homomorphic proxy re-encryption technique with the asymmetric\nfingerprinting based on user-side embedding, we bring forward two novel cloud\nmedia sharing schemes: CREAMS-I and CREAMS-II. Among them, CREAMS-II has better\nsecurity performance, while CREAMS-I has more outstanding cloud-side\nefficiency. It is demonstrated that both proposed schemes can solve the\nexisting three problems well and have advantages over existing peers. In\naddition, these two schemes can also be seen as an instantiation of\nprivacy-preserving outsourcing of asymmetric fingerprinting, from which the\nowner can reap substantial savings in local storage, communication, and\ncomputing resources. The feasibility of CREAMS-I and CREAMS-II is also verified\nby simulation.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 03:03:22 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Zhang", "Yushu", ""], ["Xiao", "Xiangli", ""], ["Zhang", "Leo Yu", ""], ["Liu", "Zhe", ""], ["Huang", "Jiwu", ""]]}, {"id": "2105.08902", "submitter": "Ahmet Kurt", "authors": "Ahmet Kurt, Suat Mercan, Omer Shlomovits, Enes Erdin, Kemal Akkaya", "title": "LNGate: Powering IoT with Next Generation Lightning Micro-payments using\n  Threshold Cryptography", "comments": "Author's version. To appear at 14th ACM Conference on Security and\n  Privacy in Wireless and Mobile Networks (WiSec 2021). arXiv admin note: text\n  overlap with arXiv:2012.10576", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Bitcoin has emerged as a revolutionary payment system with its decentralized\nledger concept however it has significant problems such as high transaction\nfees and long confirmation times. Lightning Network (LN), which was introduced\nmuch later, solves most of these problems with an innovative concept called\noff-chain payments. With this advancement, Bitcoin has become an attractive\nvenue to perform micro-payments which can also be adopted in many IoT\napplications (e.g. toll payments). Nevertheless, it is not feasible to host LN\nand Bitcoin on IoT devices due to the storage, memory, and processing\nrequirements. Therefore, in this paper, we propose an efficient and secure\nprotocol that enables an IoT device to use LN through an untrusted gateway\nnode. The gateway hosts LN and Bitcoin nodes and can open & close LN channels,\nsend LN payments on behalf of the IoT device. This delegation approach is\npowered by a (2,2)-threshold scheme that requires the IoT device and the LN\ngateway to jointly perform all LN operations which in turn secures both\nparties' funds. Specifically, we propose to thresholdize LN's Bitcoin public\nand private keys as well as its commitment points. With these and several other\nprotocol level changes, IoT device is protected against revoked state\nbroadcast, collusion, and ransom attacks. We implemented the proposed protocol\nby changing LN's source code and thoroughly evaluated its performance using a\nRaspberry Pi. Our evaluation results show that computational and communication\ndelays associated with the protocol are negligible. To the best of our\nknowledge, this is the first work that implemented threshold cryptography in\nLN.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 03:11:10 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 00:53:16 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Kurt", "Ahmet", ""], ["Mercan", "Suat", ""], ["Shlomovits", "Omer", ""], ["Erdin", "Enes", ""], ["Akkaya", "Kemal", ""]]}, {"id": "2105.08925", "submitter": "Di Chai", "authors": "Di Chai, Leye Wang, Lianzhi Fu, Junxue Zhang, Kai Chen, Qiang Yang", "title": "Federated Singular Vector Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the promulgation of data protection laws (e.g., GDPR in 2018), privacy\npreservation has become a general agreement in applications where cross-domain\nsensitive data are utilized. Out of many privacy-preserving techniques,\nfederated learning (FL) has received much attention as a bridge for secure data\nconnection and cooperation. Although FL's research works have surged, some\nclassical data modeling methods are not well accommodated in FL. In this paper,\nwe propose the first masking-based federated singular vector decomposition\nmethod, called FedSVD. FedSVD protects the raw data through a singular value\ninvariance mask, which can be further removed from the SVD results. Compared\nwith prior privacy-preserving SVD solutions, FedSVD has lossless results, high\nconfidentiality, and excellent scalability. We provide privacy proof showing\nthat FedSVD has guaranteed data confidentiality. Empirical experiments on\nreal-life datasets and synthetic data have verified the effectiveness of our\nmethod. The reconstruction error of FedSVD is around 0.000001% of the raw data,\nvalidating the lossless property of FedSVD. The scalability of FedSVD is nearly\nthe same as the standalone SVD algorithm. Hence, FedSVD can bring privacy\nprotection almost without sacrificing any computation time or communication\noverhead.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 04:51:12 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Chai", "Di", ""], ["Wang", "Leye", ""], ["Fu", "Lianzhi", ""], ["Zhang", "Junxue", ""], ["Chen", "Kai", ""], ["Yang", "Qiang", ""]]}, {"id": "2105.08955", "submitter": "Ataberk Olgun", "authors": "Ataberk Olgun, Minesh Patel, A. Giray Ya\\u{g}l{\\i}k\\c{c}{\\i}, Haocong\n  Luo, Jeremie S. Kim, Nisa Bostanc{\\i}, Nandita Vijaykumar, O\\u{g}uz Ergin,\n  Onur Mutlu", "title": "QUAC-TRNG: High-Throughput True Random Number Generation Using Quadruple\n  Row Activation in Commodity DRAM Chips", "comments": "15 pages, 14 figures. A shorter version of this work is to appear at\n  the 48th IEEE International Symposium on Computer Architecture (ISCA 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  True random number generators (TRNG) sample random physical processes to\ncreate large amounts of random numbers for various use cases, including\nsecurity-critical cryptographic primitives, scientific simulations, machine\nlearning applications, and even recreational entertainment. Unfortunately, not\nevery computing system is equipped with dedicated TRNG hardware, limiting the\napplication space and security guarantees for such systems. To open the\napplication space and enable security guarantees for the overwhelming majority\nof computing systems that do not necessarily have dedicated TRNG hardware, we\ndevelop QUAC-TRNG.\n  QUAC-TRNG exploits the new observation that a carefully-engineered sequence\nof DRAM commands activates four consecutive DRAM rows in rapid succession. This\nQUadruple ACtivation (QUAC) causes the bitline sense amplifiers to\nnon-deterministically converge to random values when we activate four rows that\nstore conflicting data because the net deviation in bitline voltage fails to\nmeet reliable sensing margins.\n  We experimentally demonstrate that QUAC reliably generates random values\nacross 136 commodity DDR4 DRAM chips from one major DRAM manufacturer. We\ndescribe how to develop an effective TRNG (QUAC-TRNG) based on QUAC. We\nevaluate the quality of our TRNG using NIST STS and find that QUAC-TRNG\nsuccessfully passes each test. Our experimental evaluations show that QUAC-TRNG\ngenerates true random numbers with a throughput of 3.44 Gb/s (per DRAM\nchannel), outperforming the state-of-the-art DRAM-based TRNG by 15.08x and\n1.41x for basic and throughput-optimized versions, respectively. We show that\nQUAC-TRNG utilizes DRAM bandwidth better than the state-of-the-art, achieving\nup to 2.03x the throughput of a throughput-optimized baseline when scaling bus\nfrequencies to 12 GT/s.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 06:58:46 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 11:17:00 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Olgun", "Ataberk", ""], ["Patel", "Minesh", ""], ["Ya\u011fl\u0131k\u00e7\u0131", "A. Giray", ""], ["Luo", "Haocong", ""], ["Kim", "Jeremie S.", ""], ["Bostanc\u0131", "Nisa", ""], ["Vijaykumar", "Nandita", ""], ["Ergin", "O\u011fuz", ""], ["Mutlu", "Onur", ""]]}, {"id": "2105.09057", "submitter": "Aashish Kolluri", "authors": "Aashish Kolluri, Teodora Baluta and Prateek Saxena", "title": "Private Hierarchical Clustering in Federated Networks", "comments": "18 pages, In Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing structural properties of social networks, such as identifying their\nclusters or finding their most central nodes, has many applications. However,\nthese applications are not supported by federated social networks that allow\nusers to store their social links locally on their end devices. In the\nfederated regime, users want access to personalized services while also keeping\ntheir social links private. In this paper, we take a step towards enabling\nanalytics on federated networks with differential privacy guarantees about\nprotecting the user links or contacts in the network. Specifically, we present\nthe first work to compute hierarchical cluster trees using local differential\nprivacy. Our algorithms for computing them are novel and come with theoretical\nbounds on the quality of the trees learned. The private hierarchical cluster\ntrees enable a service provider to query the community structure around a user\nat various granularities without the users having to share their raw contacts\nwith the provider. We demonstrate the utility of such queries by redesigning\nthe state-of-the-art social recommendation algorithms for the federated setup.\nOur recommendation algorithms significantly outperform the baselines which do\nnot use social contacts and are on par with the non-private algorithms that use\ncontacts.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 10:47:59 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Kolluri", "Aashish", ""], ["Baluta", "Teodora", ""], ["Saxena", "Prateek", ""]]}, {"id": "2105.09150", "submitter": "Roberto Metere", "authors": "Roberto Metere, Luca Arnaboldi", "title": "MetaCP: Cryptographic Protocol Design Tool for Formal Verification", "comments": "20 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MetaCP, a tool to aid the cryptographer throughout the process of\ndesigning and modelling a communication protocol suitable for formal\nverification. The crucial innovative aspect of the tool is its data-centric\napproach, where protocol specification is stored in a structured way rather\nthan in natural languages to facilitate its interpretation to multiple target\nlanguages. Previous work shows a single exporting plugin (for Tamarin) which\nrequired aftermath modifications. By improving the expressiveness of the\nspecification data structure we extend the tool to export to an additional\nformal language, i.e. ProVerif, as well as a C++ implementation. Starting with\nits modern graphical interface, MetaCP allows us to model the Diffie-Hellman\nkey exchange, traditionally referred to as a case study, in just a few minutes.\nUltimately, we use the formal tools to verify the executability and correctness\nof the automatically exported models. The design core of MetaCP is freely\navailable in an online demo that provides two further sample protocols,\nNeedham-Schroeder and Needham-Schroeder-Lowe, along with instructions to use\nthe tool to begin modelling from scratch and to export the model to desired\nexternal languages.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 14:14:13 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Metere", "Roberto", ""], ["Arnaboldi", "Luca", ""]]}, {"id": "2105.09157", "submitter": "Shiyi Yang", "authors": "Shiyi Yang, Nour Moustafa, Hui Guo", "title": "Hunter in the Dark: Deep Ensemble Networks for Discovering Anomalous\n  Activity from Smart Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern networked society, smart networks are indispensable to offer\nintelligent communications and automated services to end-users and\norganizations. Machine learning (ML)-based network intrusion detection system\n(NIDS) plays a critical role in safeguarding smart networks against novel cyber\nthreats. However, there are two challenges in the existing designs: 1)\nachieving an outstanding performance of threat detection often produces high\nfalse positives, leading to alert fatigue and 2) the interpretability of\ndetection results is low, making a difficulty of understanding cyber threats\nand taking prompt actions against them. To tackle these challenges, in this\npaper, we propose a cyber defense mechanism, namely DarkHunter, which includes\nthree new components: stream processor, detection engine and incident analyzer.\nThe stream processor converts raw network packets into data records, including\nstatistical features, which involve latent patterns of legitimates or anomalies\nto be effectively discovered using the detection engine. In this essence, the\ndetection engine leverages an efficient ensemble neural network (EnsembleNet)\nto accurately identify anomalous traffic. Finally, the incident analyzer\napplies a correlation analysis to filter out the mispredictions from\nEnsembleNet, traces each detected threat from its statistical representation\nback to its source traffic flow to enhance its intelligibility and prioritizes\nthe threats to be processed to minimize security risks. Our evaluations, based\non the UNSW-NB15 dataset, show that DarkHunter significantly outperforms some\nstate-of-the-art ML-based NIDSs by accomplishing higher accuracy, higher\ndetection rate, higher precision, higher F1 score while keeping a lower false\nalarm rate.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 14:19:56 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 09:10:53 GMT"}, {"version": "v3", "created": "Sun, 27 Jun 2021 08:26:26 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Yang", "Shiyi", ""], ["Moustafa", "Nour", ""], ["Guo", "Hui", ""]]}, {"id": "2105.09268", "submitter": "Maanak Gupta", "authors": "Jeffrey C Kimmell, Mahmoud Abdelsalam, Maanak Gupta", "title": "Analyzing Machine Learning Approaches for Online Malware Detection in\n  Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The variety of services and functionality offered by various cloud service\nproviders (CSP) have exploded lately. Utilizing such services has created\nnumerous opportunities for enterprises infrastructure to become cloud-based\nand, in turn, assisted the enterprises to easily and flexibly offer services to\ntheir customers. The practice of renting out access to servers to clients for\ncomputing and storage purposes is known as Infrastructure as a Service (IaaS).\nThe popularity of IaaS has led to serious and critical concerns with respect to\nthe cyber security and privacy. In particular, malware is often leveraged by\nmalicious entities against cloud services to compromise sensitive data or to\nobstruct their functionality. In response to this growing menace, malware\ndetection for cloud environments has become a widely researched topic with\nnumerous methods being proposed and deployed. In this paper, we present online\nmalware detection based on process level performance metrics, and analyze the\neffectiveness of different baseline machine learning models including, Support\nVector Classifier (SVC), Random Forest Classifier (RFC), KNearest Neighbor\n(KNN), Gradient Boosted Classifier (GBC), Gaussian Naive Bayes (GNB) and\nConvolutional Neural Networks (CNN). Our analysis conclude that neural network\nmodels can most accurately detect the impact malware have on the process level\nfeatures of virtual machines in the cloud, and therefore are best suited to\ndetect them. Our models were trained, validated, and tested by using a dataset\nof 40,680 malicious and benign samples. The dataset was complied by running\ndifferent families of malware (collected from VirusTotal) in a live cloud\nenvironment and collecting the process level features.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 17:28:12 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Kimmell", "Jeffrey C", ""], ["Abdelsalam", "Mahmoud", ""], ["Gupta", "Maanak", ""]]}, {"id": "2105.09369", "submitter": "Aidmar Wainakh", "authors": "Aidmar Wainakh and Fabrizio Ventola and Till M\\\"u{\\ss}ig and Jens Keim\n  and Carlos Garcia Cordero and Ephraim Zimmer and Tim Grube and Kristian\n  Kersting and Max M\\\"uhlh\\\"auser", "title": "User Label Leakage from Gradients in Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Federated learning enables multiple users to build a joint model by sharing\ntheir model updates (gradients), while their raw data remains local on their\ndevices. In contrast to the common belief that this provides privacy benefits,\nwe here add to the very recent results on privacy risks when sharing gradients.\nSpecifically, we propose Label Leakage from Gradients (LLG), a novel attack to\nextract the labels of the users' training data from their shared gradients. The\nattack exploits the direction and magnitude of gradients to determine the\npresence or absence of any label. LLG is simple yet effective, capable of\nleaking potential sensitive information represented by labels, and scales well\nto arbitrary batch sizes and multiple classes. We empirically and\nmathematically demonstrate the validity of our attack under different settings.\nMoreover, empirical results show that LLG successfully extracts labels with\nhigh accuracy at the early stages of model training. We also discuss different\ndefense mechanisms against such leakage. Our findings suggest that gradient\ncompression is a practical technique to prevent our attack.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 19:21:05 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 06:44:42 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 18:45:21 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Wainakh", "Aidmar", ""], ["Ventola", "Fabrizio", ""], ["M\u00fc\u00dfig", "Till", ""], ["Keim", "Jens", ""], ["Cordero", "Carlos Garcia", ""], ["Zimmer", "Ephraim", ""], ["Grube", "Tim", ""], ["Kersting", "Kristian", ""], ["M\u00fchlh\u00e4user", "Max", ""]]}, {"id": "2105.09400", "submitter": "Zhongshu Gu", "authors": "Pau-Chen Cheng, Kevin Eykholt, Zhongshu Gu, Hani Jamjoom, K. R.\n  Jayaram, Enriquillo Valdez, Ashish Verma", "title": "Separation of Powers in Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) enables collaborative training among mutually\ndistrusting parties. Model updates, rather than training data, are concentrated\nand fused in a central aggregation server. A key security challenge in FL is\nthat an untrustworthy or compromised aggregation process might lead to\nunforeseeable information leakage. This challenge is especially acute due to\nrecently demonstrated attacks that have reconstructed large fractions of\ntraining data from ostensibly \"sanitized\" model updates.\n  In this paper, we introduce TRUDA, a new cross-silo FL system, employing a\ntrustworthy and decentralized aggregation architecture to break down\ninformation concentration with regard to a single aggregator. Based on the\nunique computational properties of model-fusion algorithms, all exchanged model\nupdates in TRUDA are disassembled at the parameter-granularity and re-stitched\nto random partitions designated for multiple TEE-protected aggregators. Thus,\neach aggregator only has a fragmentary and shuffled view of model updates and\nis oblivious to the model architecture. Our new security mechanisms can\nfundamentally mitigate training reconstruction attacks, while still preserving\nthe final accuracy of trained models and keeping performance overheads low.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 21:00:44 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Cheng", "Pau-Chen", ""], ["Eykholt", "Kevin", ""], ["Gu", "Zhongshu", ""], ["Jamjoom", "Hani", ""], ["Jayaram", "K. R.", ""], ["Valdez", "Enriquillo", ""], ["Verma", "Ashish", ""]]}, {"id": "2105.09453", "submitter": "Yukui Luo", "authors": "Yukui Luo, Cheng Gongye, Yunsi Fei, Xiaolin Xu", "title": "DeepStrike: Remotely-Guided Fault Injection Attacks on DNN Accelerator\n  in Cloud-FPGA", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Field-programmable gate arrays (FPGAs) are widely adopted in clouds to\naccelerate Deep Neural Networks (DNN), such virtualization environments have\nposed many new security issues. This work investigates the integrity of DNN\nFPGA accelerators in clouds. It proposes DeepStrike, a remotely-guided attack\nbased on power glitching fault injections targeting DNN execution. We\ncharacterize the vulnerabilities of different DNN layers against fault\ninjections on FPGAs and leverage time-to-digital converter (TDC) sensors to\nprecisely control the timing of fault injections. Experimental results show\nthat our proposed attack can successfully disrupt the FPGA DSP kernel and\nmisclassify the target victim DNN application.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 01:59:54 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Luo", "Yukui", ""], ["Gongye", "Cheng", ""], ["Fei", "Yunsi", ""], ["Xu", "Xiaolin", ""]]}, {"id": "2105.09496", "submitter": "Umar Yahya PhD", "authors": "Cherinor Umaru Bah, Afzaal Hussain Seyal, and Umar Yahya", "title": "Combining PIN and Biometric Identifications as Enhancement to User\n  Authentication in Internet Banking", "comments": "7th Brunei International Conference on Engineering and Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Internet banking (IB) continues to face security concerns arising from\nillegal access to users accounts. Use of personal identification numbers (PIN)\nas a single authentication method for IB users is prone to insecurities such as\nphishing, hacking and shoulder surfing. Fingerprint matching (FPM) as an\nalternative to PIN equally has a downside as fingerprints reside on individual\nmobile devices. A survey we conducted from 170 IB respondents of 5 different\nbanks in Brunei established that majority (65%) of them preferred use of\nbiometric authentication methods. In this work, we propose a two-level\nintegrated authentication mechanism (2L-IAM). At the first level, the user logs\nin to their IB portal using either PIN or FPM. At the second level, user is\nauthenticated by means of face recognition (FR) should they initiate a\ntransaction classified as sensitive. The merits of the introduced 2L-IAM are\n3-fold: - (1) FR guarantees the identity of the rightful user irrespective of\nthe login device; (2) By classifying banking products sensitivity, the\nsensitive transactions are more effectively secured; (3) It is accommodative of\ndifferent users authentication preferences. Adoption of this framework could\nthus improve both users and banks experiences in terms of enhanced security and\nservice delivery respectively.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 03:43:18 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Bah", "Cherinor Umaru", ""], ["Seyal", "Afzaal Hussain", ""], ["Yahya", "Umar", ""]]}, {"id": "2105.09535", "submitter": "Shengling Wang", "authors": "Hongwei Shi, Shengling Wang, Qin Hu, and Xiuzhen Cheng", "title": "Micro Analysis of Natural Forking in Blockchain Based on Large Deviation\n  Theory", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural forking in blockchain refers to a phenomenon that there are a set of\nblocks at one block height at the same time, implying that various nodes have\ndifferent perspectives of the main chain. Natural forking might give rise to\nmultiple adverse impacts on blockchain, jeopardizing the performance and\nsecurity of the system consequently. However, the ongoing literature in\nanalyzing natural forking is mainly from the macro point of view, which is not\nsufficient to incisively understand this phenomenon. In this paper, we fill\nthis gap through leveraging the large deviation theory to conduct a microscopic\nstudy of natural forking, which resorts to investigating the instantaneous\ndifference between block generation and dissemination in blockchain. Our work\nis derived comprehensively and complementarily via a three-step process, where\nboth the natural forking probability and its decay rate are presented. Through\nsolid theoretical derivation and extensive numerical simulations, we find 1)\nthe probability of the mismatch between block generation and dissemination\nexceeding a given threshold dwindles exponentially with the increase of natural\nforking robustness related parameter or the difference between the block\ndissemination rate and block creation rate; 2) the natural forking robustness\nrelated parameter may emphasize a more dominant effect on accelerating the\nabortion of natural forking in some cases; 3) when the self-correlated block\ngeneration rate is depicted as the stationary autoregressive process with a\nscaling parameter, it is found that setting a lower scaling parameter may speed\nup the failure of natural forking. These findings are valuable since they offer\na fresh theoretical basis to engineer optimal countermeasures for thwarting\nnatural forking and thereby enlivening the blockchain network.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 06:24:16 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Shi", "Hongwei", ""], ["Wang", "Shengling", ""], ["Hu", "Qin", ""], ["Cheng", "Xiuzhen", ""]]}, {"id": "2105.09540", "submitter": "Xiaolin Chen", "authors": "Xiaolin Chen, Shuai Zhou, Kai Yang, Hao Fan, Zejin Feng, Zhong Chen,\n  Hu Wang, Yongji Wang", "title": "Fed-EINI: An Efficient and Interpretable Inference Framework for\n  Decision Tree Ensembles in Federated Learning", "comments": "10 pages, 5 figures, accepted by International Workshop on Federated\n  Learning for User Privacy and Data Confidentiality in Conjunction with ICML\n  2021(FL-ICML'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing concerns about data privacy and security drive an emerging\nfield of studying privacy-preserving machine learning from isolated data\nsources, i.e., federated learning. A class of federated learning, vertical\nfederated learning, where different parties hold different features for common\nusers, has a great potential of driving a more variety of business cooperation\namong enterprises in many fields. In machine learning, decision tree ensembles\nsuch as gradient boosting decision tree (GBDT) and random forest are widely\napplied powerful models with high interpretability and modeling efficiency.\nHowever, the interpretability is compromised in state-of-the-art vertical\nfederated learning frameworks such as SecureBoost with anonymous features to\navoid possible data breaches. To address this issue in the inference process,\nin this paper, we propose Fed-EINI to protect data privacy and allow the\ndisclosure of feature meaning by concealing decision paths with a\ncommunication-efficient secure computation method for inference outputs. The\nadvantages of Fed-EINI will be demonstrated through both theoretical analysis\nand extensive numerical results.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 06:40:05 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 08:09:39 GMT"}, {"version": "v3", "created": "Fri, 16 Jul 2021 08:07:13 GMT"}, {"version": "v4", "created": "Mon, 19 Jul 2021 13:17:56 GMT"}, {"version": "v5", "created": "Tue, 20 Jul 2021 14:25:09 GMT"}, {"version": "v6", "created": "Mon, 26 Jul 2021 13:10:19 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Chen", "Xiaolin", ""], ["Zhou", "Shuai", ""], ["Yang", "Kai", ""], ["Fan", "Hao", ""], ["Feng", "Zejin", ""], ["Chen", "Zhong", ""], ["Wang", "Hu", ""], ["Wang", "Yongji", ""]]}, {"id": "2105.09591", "submitter": "Fatih Turkmen", "authors": "Fadi Mohsen, Loran Oosterhaven, Fatih Turkmen", "title": "KotlinDetector: Towards Understanding the Implications of Using Kotlin\n  in Android Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Java programming language has been long used to develop native Android mobile\napplications. In the last few years many companies and freelancers have\nswitched into using Kotlin partially or entirely. As such, many projects are\nreleased as binaries and employ a mix of Java and Kotlin language constructs.\nYet, the true security and privacy implications of this shift have not been\nthoroughly studied. In this work, a state-of-the-art tool, KotlinDetector, is\ndeveloped to directly extract any Kotlin presence, percentages, and numerous\nlanguage features from Android Application Packages (APKs) by performing\nheuristic pattern scanning and invocation tracing. Our evaluation study shows\nthat the tool is considerably efficient and accurate. We further provide a use\ncase in which the output of the KotlinDetector is combined with the output of\nan existing vulnerability scanner tool called AndroBugs to infer any security\nand/or privacy implications.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 08:34:20 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Mohsen", "Fadi", ""], ["Oosterhaven", "Loran", ""], ["Turkmen", "Fatih", ""]]}, {"id": "2105.09666", "submitter": "Christian Pilato", "authors": "Christian Pilato, Luca Collini, Luca Cassano, Donatella Sciuto,\n  Siddharth Garg, Ramesh Karri", "title": "On the Optimization of Behavioral Logic Locking for High-Level Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The globalization of the electronics supply chain is requiring effective\nmethods to thwart reverse engineering and IP theft. Logic locking is a\npromising solution but there are still several open concerns. Even when applied\nat high level of abstraction, logic locking leads to large overhead without\nguaranteeing that the obfuscation metric is actually maximized. We propose a\nframework to optimize the use of behavioral logic locking for a given security\nmetric. We explore how to apply behavioral logic locking techniques during the\nHLS of IP cores. Operating on the chip behavior, our method is compatible with\ncommercial HLS tools, complementing existing industrial design flows. We offer\na framework where the designer can implement different meta-heuristics to\nexplore the design space and select where to apply logic locking. Our method\noptimizes a given security metric better than complete obfuscation, allows us\nto 1) obtain better protection, 2) reduce the obfuscation cost.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 10:53:20 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Pilato", "Christian", ""], ["Collini", "Luca", ""], ["Cassano", "Luca", ""], ["Sciuto", "Donatella", ""], ["Garg", "Siddharth", ""], ["Karri", "Ramesh", ""]]}, {"id": "2105.09685", "submitter": "Jaydeep Borkar", "authors": "Jaydeep Borkar, Pin-Yu Chen", "title": "Simple Transparent Adversarial Examples", "comments": "14 pages, 9 figures, Published at ICLR 2021 Workshop on Security and\n  Safety in Machine Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a rise in the use of Machine Learning as a Service (MLaaS)\nVision APIs as they offer multiple services including pre-built models and\nalgorithms, which otherwise take a huge amount of resources if built from\nscratch. As these APIs get deployed for high-stakes applications, it's very\nimportant that they are robust to different manipulations. Recent works have\nonly focused on typical adversarial attacks when evaluating the robustness of\nvision APIs. We propose two new aspects of adversarial image generation methods\nand evaluate them on the robustness of Google Cloud Vision API's optical\ncharacter recognition service and object detection APIs deployed in real-world\nsettings such as sightengine.com, picpurify.com, Google Cloud Vision API, and\nMicrosoft Azure's Computer Vision API. Specifically, we go beyond the\nconventional small-noise adversarial attacks and introduce secret embedding and\ntransparent adversarial examples as a simpler way to evaluate robustness. These\nmethods are so straightforward that even non-specialists can craft such\nattacks. As a result, they pose a serious threat where APIs are used for\nhigh-stakes applications. Our transparent adversarial examples successfully\nevade state-of-the art object detections APIs such as Azure Cloud Vision\n(attack success rate 52%) and Google Cloud Vision (attack success rate 36%).\n90% of the images have a secret embedded text that successfully fools the\nvision of time-limited humans but is detected by Google Cloud Vision API's\noptical character recognition. Complementing to current research, our results\nprovide simple but unconventional methods on robustness evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 11:54:26 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Borkar", "Jaydeep", ""], ["Chen", "Pin-Yu", ""]]}, {"id": "2105.09687", "submitter": "Gaurav Kasbekar", "authors": "Akash Gupta, Gaurav S. Kasbekar", "title": "Secure, Anonymity-Preserving and Lightweight Mutual Authentication and\n  Key Agreement Protocol for Home Automation IoT Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Home automation Internet of Things (IoT) systems have recently become a\ntarget for several types of attacks. In this paper, we present an\nauthentication and key agreement protocol for a home automation network based\non the ZigBee standard, which connects together a central controller and\nseveral end devices. Our scheme performs mutual authentication between end\ndevices and the controller, which is followed by device-to-device\ncommunication. The scheme achieves confidentiality, message integrity,\nanonymity, unlinkability, forward and backward secrecy, and availability. Our\nscheme uses only simple hash and XOR computations and symmetric key encryption,\nand hence is resource-efficient. We show using a detailed security analysis and\nnumerical results that our proposed scheme provides better security and\nanonymity, and is more efficient in terms of computation time, communication\ncost, and storage cost than schemes proposed in prior works.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 11:56:10 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 05:04:24 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Gupta", "Akash", ""], ["Kasbekar", "Gaurav S.", ""]]}, {"id": "2105.09840", "submitter": "Onur G\\\"unl\\\"u Dr.-Ing.", "authors": "Rebekka Schulz, Onur G\\\"unl\\\"u, Robert Elschner, Rafael F. Schaefer,\n  Carsten Schmidt-Langhorst, Colja Schubert, and Robert F. H. Fischer", "title": "Semantic Security for Indoor THz-Wireless Communication", "comments": "To appear in International Symposium on Wireless Communication\n  Systems 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR eess.SP math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Physical-layer security (PLS) for industrial indoor terahertz (THz) wireless\ncommunication applications is considered. We use a similar model as being\nemployed for additive white Gaussian noise (AWGN) wireless communication\nchannels. A cell communication and a directed communication scenario are\nanalyzed to illustrate the achievable semantic security guarantees for a\nwiretap channel with finite-blocklength THz-wireless communication links. We\nshow that weakly directed transmitter (Alice) antennas, which allow cell-type\ncommunication with multiple legitimate receivers (Bobs) without adaptation of\nthe alignment, result in large insecure regions. In the directed communication\nscenario, the resulting insecure regions are shown to cover a large volume of\nthe indoor environment only if the distance between Alice and Bob is large.\nThus, our results for the two selected scenarios reveal that there is a\nstringent trade-off between the targeted semantic security level and the number\nof reliably and securely accessible legitimate receivers. Furthermore, the\neffects of secrecy code parameters and antenna properties on the achievable\nsemantic security levels are illustrated to show directions for possible\nimprovements to guarantee practically-acceptable security levels with PLS\nmethods for industrial indoor THz-wireless communication applications.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 15:38:51 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 12:43:47 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Schulz", "Rebekka", ""], ["G\u00fcnl\u00fc", "Onur", ""], ["Elschner", "Robert", ""], ["Schaefer", "Rafael F.", ""], ["Schmidt-Langhorst", "Carsten", ""], ["Schubert", "Colja", ""], ["Fischer", "Robert F. H.", ""]]}, {"id": "2105.10041", "submitter": "Haihua Chen", "authors": "Haihua Chen, Ngan Tran, Anand Sagar Thumati, Jay Bhuyan, Junhua Ding", "title": "Data Curation and Quality Assurance for Machine Learning-based Cyber\n  Intrusion Detection", "comments": "23 pages, 4 figures, 3 tables, under review at the ACM Journal of\n  Data and Information Quality", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrusion detection is an essential task in the cyber threat environment.\nMachine learning and deep learning techniques have been applied for intrusion\ndetection. However, most of the existing research focuses on the model work but\nignores the fact that poor data quality has a direct impact on the performance\nof a machine learning system. More attention should be paid to the data work\nwhen building a machine learning-based intrusion detection system. This article\nfirst summarizes existing machine learning-based intrusion detection systems\nand the datasets used for building these systems. Then the data preparation\nworkflow and quality requirements for intrusion detection are discussed. To\nfigure out how data and models affect machine learning performance, we\nconducted experiments on 11 HIDS datasets using seven machine learning models\nand three deep learning models. The experimental results show that BERT and GPT\nwere the best algorithms for HIDS on all of the datasets. However, the\nperformance on different datasets varies, indicating the differences between\nthe data quality of these datasets. We then evaluate the data quality of the 11\ndatasets based on quality dimensions proposed in this paper to determine the\nbest characteristics that a HIDS dataset should possess in order to yield the\nbest possible result. This research initiates a data quality perspective for\nresearchers and practitioners to improve the performance of machine\nlearning-based intrusion detection.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 21:31:46 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Chen", "Haihua", ""], ["Tran", "Ngan", ""], ["Thumati", "Anand Sagar", ""], ["Bhuyan", "Jay", ""], ["Ding", "Junhua", ""]]}, {"id": "2105.10051", "submitter": "Jack Stokes", "authors": "Jack W. Stokes, Paul England, Kevin Kane", "title": "Preventing Machine Learning Poisoning Attacks Using Authentication and\n  Provenance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has successfully demonstrated new types of data poisoning\nattacks. To address this problem, some researchers have proposed both offline\nand online data poisoning detection defenses which employ machine learning\nalgorithms to identify such attacks. In this work, we take a different approach\nto preventing data poisoning attacks which relies on cryptographically-based\nauthentication and provenance to ensure the integrity of the data used to train\na machine learning model. The same approach is also used to prevent software\npoisoning and model poisoning attacks. A software poisoning attack maliciously\nalters one or more software components used to train a model. Once the model\nhas been trained it can also be protected against model poisoning attacks which\nseek to alter a model's predictions by modifying its underlying parameters or\nstructure. Finally, an evaluation set or test set can also be protected to\nprovide evidence if they have been modified by a second data poisoning attack.\nTo achieve these goals, we propose VAMP which extends the previously proposed\nAMP system, that was designed to protect media objects such as images, video\nfiles or audio clips, to the machine learning setting. We first provide\nrequirements for authentication and provenance for a secure machine learning\nsystem. Next, we demonstrate how VAMP's manifest meets these requirements to\nprotect a machine learning system's datasets, software components, and models.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 21:57:32 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Stokes", "Jack W.", ""], ["England", "Paul", ""], ["Kane", "Kevin", ""]]}, {"id": "2105.10053", "submitter": "James Cheney", "authors": "Sidahmed Benabderrahmane, Ghita Berrada, James Cheney, and Petko\n  Valtchev", "title": "A Rule Mining-Based Advanced Persistent Threats Detection System", "comments": "To appear, IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced persistent threats (APT) are stealthy cyber-attacks that are aimed\nat stealing valuable information from target organizations and tend to extend\nin time. Blocking all APTs is impossible, security experts caution, hence the\nimportance of research on early detection and damage limitation. Whole-system\nprovenance-tracking and provenance trace mining are considered promising as\nthey can help find causal relationships between activities and flag suspicious\nevent sequences as they occur. We introduce an unsupervised method that\nexploits OS-independent features reflecting process activity to detect\nrealistic APT-like attacks from provenance traces. Anomalous processes are\nranked using both frequent and rare event associations learned from traces.\nResults are then presented as implications which, since interpretable, help\nleverage causality in explaining the detected anomalies. When evaluated on\nTransparent Computing program datasets (DARPA), our method outperformed\ncompeting approaches.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 22:13:13 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Benabderrahmane", "Sidahmed", ""], ["Berrada", "Ghita", ""], ["Cheney", "James", ""], ["Valtchev", "Petko", ""]]}, {"id": "2105.10103", "submitter": "Lu Hou", "authors": "Lu Hou, Kan Zheng, Zhiming Liu, Xiaojun Xu", "title": "Design and Prototype Implementation of a Blockchain-Enabled LoRa System\n  With Edge Computing", "comments": null, "journal-ref": "IEEE INTERNET OF THINGS JOURNAL, VOL. 8, NO. 4, FEBRUARY 15, 2021", "doi": "10.1109/JIOT.2020.3027713", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Efficiency and security have become critical issues during the development of\nthe long-range (LoRa) system for Internet-of-Things (IoT) applications. The\ncentralized work method in the LoRa system, where all packages are processed\nand kept in the central cloud, cannot well exploit the resources in LoRa\ngateways and also makes it vulnerable to security risks, such as data\nfalsification or data loss. On the other hand, the blockchain has the potential\nto provide a decentralized and secure infrastructure for the LoRa system.\nHowever, there are significant challenges in deploying blockchain at LoRa\ngateways with limited edge computing abilities. This article proposes a design\nand implementation of the blockchain-enabled LoRa system with edge computing by\nusing the open-source Hyperledger Fabric, which is called as HyperLoRa.\nAccording to different features of LoRa data, a blockchain network with\nmultiple ledgers is designed, each of which stores a specific kind of LoRa\ndata. LoRa gateways can participate in the operations of the blockchain and\nshare the ledger that keep the time-critical network data with small size.\nThen, the edge computing abilities of LoRa gateways are utilized to handle the\njoin procedure and application packages processing. Furthermore, a HyperLoRa\nprototype is implemented on embedded hardware, which demonstrates the\nfeasibility of deploying the blockchain into LoRa gateways with limited\ncomputing and storage resources. Finally, various experiments are conducted to\nevaluate the performances of the proposed LoRa system.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 02:58:46 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Hou", "Lu", ""], ["Zheng", "Kan", ""], ["Liu", "Zhiming", ""], ["Xu", "Xiaojun", ""]]}, {"id": "2105.10107", "submitter": "Lu Hou", "authors": "Lu Hou, Xiaojun Xu, Kan Zheng, Xianbin Wang", "title": "An Intelligent Transaction Migration Scheme for RAFT-based Private\n  Blockchain in Internet of Things Applications", "comments": null, "journal-ref": null, "doi": "10.1109/LCOMM.2021.3079201", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The integration of multi-access edge computing (MEC) and RAFT consensus makes\nit feasible to deploy blockchain on trustful base stations and gateways to\nprovide efficient and tamper-proof edge data services for Internet of Things\n(IoT) applications. However, reducing the latency of storing data on blockchain\nremains a challenge, especially when an anomalytriggered data flow in a certain\narea exceeds the block generation speed. This letter proposes an intelligent\ntransaction migration scheme for RAFT-based private blockchain in IoT\napplications to migrate transactions in busy areas to idle regions\nintelligently. Simulation results show that the proposed scheme can apparently\nreduce the latency in high data flow circumstances.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 03:12:40 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Hou", "Lu", ""], ["Xu", "Xiaojun", ""], ["Zheng", "Kan", ""], ["Wang", "Xianbin", ""]]}, {"id": "2105.10227", "submitter": "Sani Abdullahi", "authors": "Sani M. Abdullahi and Sun Shuifa", "title": "Random Hash Code Generation for Cancelable Fingerprint Templates using\n  Vector Permutation and Shift-order Process", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cancelable biometric techniques have been used to prevent the compromise of\nbiometric data by generating and using their corresponding cancelable templates\nfor user authentication. However, the non-invertible distance preserving\ntransformation methods employed in various schemes are often vulnerable to\ninformation leakage since matching is performed in the transformed domain. In\nthis paper, we propose a non-invertible distance preserving scheme based on\nvector permutation and shift-order process. First, the dimension of feature\nvectors is reduced using kernelized principle component analysis (KPCA) prior\nto randomly permuting the extracted vector features. A shift-order process is\nthen applied to the generated features in order to achieve non-invertibility\nand combat similarity-based attacks. The generated hash codes are resilient to\ndifferent security and privacy attacks whilst fulfilling the major revocability\nand unlinkability requirements. Experimental evaluation conducted on 6 datasets\nof FVC2002 and FVC2004 reveals a high-performance accuracy of the proposed\nscheme better than other existing state-of-the-art schemes.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 09:37:54 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Abdullahi", "Sani M.", ""], ["Shuifa", "Sun", ""]]}, {"id": "2105.10235", "submitter": "Elisabeth Vogel", "authors": "Elisabeth Vogel, Zoya Dyka, Dan Klann and Peter Langend\\\"orfer", "title": "Resilience in the Cyber World: Definitions, Features and Models", "comments": "32 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Resilience is a feature that is gaining more and more attention in computer\nscience and computer engineering. However, the definition of resilience for the\ncyber landscape, especially embedded systems, is not yet clear. This paper\ndiscusses definitions of different authors, years and different application\nareas the field of computer science/computer engineering. We identify the core\nstatements that are more or less common to the majority of the definitions and\nbased on this we give a holistic definition using attributes for (cyber-)\nresilience. In order to pave a way towards resilience-engineering we discuss a\ntheoretical model of the life cycle of a (cyber-) resilient system that\nconsists of key actions presented in the literature. We adapt this model for\nembedded (cyber-) resilient systems.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 09:50:05 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Vogel", "Elisabeth", ""], ["Dyka", "Zoya", ""], ["Klann", "Dan", ""], ["Langend\u00f6rfer", "Peter", ""]]}, {"id": "2105.10399", "submitter": "Joshua Ellul", "authors": "Joshua Ellul and Gordon J. Pace", "title": "Towards External Calls for Blockchain and Distributed Ledger Technology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is widely accepted that blockchain systems cannot execute calls to\nexternal systems or services due to each node having to reach a deterministic\nstate. However, in this paper we show that this belief is preconceived by\ndemonstrating a method that enables blockchain and distributed ledger\ntechnologies to perform calls to external systems initiated from the\nblockchain/DLT itself.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 13:39:29 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 20:09:03 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Ellul", "Joshua", ""], ["Pace", "Gordon J.", ""]]}, {"id": "2105.10426", "submitter": "Yuedong Xu", "authors": "Huiwen Hu and Yuedong Xu", "title": "SCSGuard: Deep Scam Detection for Ethereum Smart Contracts", "comments": "6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart contract is the building block of blockchain systems that enables\nautomated peer-to-peer transactions and decentralized services. With the\nincreasing popularity of smart contracts, blockchain systems, in particular\nEthereum, have been the \"paradise\" of versatile fraud activities in which\nPonzi, Honeypot and Phishing are the prominent ones. Formal verification and\nsymbolic analysis have been employed to combat these destructive scams by\nanalyzing the codes and function calls, yet the vulnerability of each\n\\emph{individual} scam should be predefined discreetly. In this work, we\npresent SCSGuard, a novel deep learning scam detection framework that harnesses\nthe automatically extractable bytecodes of smart contracts as their new\nfeatures. We design a GRU network with attention mechanism to learn from the\n\\emph{N-gram bytecode} patterns, and determines whether a smart contract is\nfraudulent or not. Our framework is advantageous over the baseline algorithms\nin three aspects. Firstly, SCSGuard provides a unified solution to different\nscam genres, thus relieving the need of code analysis skills. Secondly, the\ninference of SCSGuard is faster than the code analysis by several order of\nmagnitudes. Thirdly, experimental results manifest that SCSGuard achieves high\naccuracy (0.92$\\sim$0.94), precision (0.94$\\sim$0.96\\%) and recall\n(0.97$\\sim$0.98) for both Ponzi and Honeypot scams under similar settings, and\nis potentially useful to detect new Phishing smart contracts.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 15:51:38 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Hu", "Huiwen", ""], ["Xu", "Yuedong", ""]]}, {"id": "2105.10440", "submitter": "Prajwol Kumar Nakarmi", "authors": "John Preu{\\ss} Mattsson, Prajwol Kumar Nakarmi", "title": "Nori: Concealing the Concealed Identifier in 5G", "comments": "9 pages, 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IMSI catchers have been a long standing and serious privacy problem in pre-5G\nmobile networks. To tackle this, 3GPP introduced the Subscription Concealed\nIdentifier (SUCI) and other countermeasures in 5G. In this paper, we analyze\nthe new SUCI mechanism and discover that it provides very poor anonymity when\nused with the variable length Network Specific Identifiers (NSI), which are\npart of the 5G standard. When applied to real-world name length data, we see\nthat SUCI only provides 1-anonymity, meaning that individual subscribers can\neasily be identified and tracked. We strongly recommend 3GPP and GSMA to\nstandardize and recommend the use of a padding mechanism for SUCI before\nvariable length identifiers get more commonly used. We further show that the\npadding schemes, commonly used for network traffic, are not optimal for padding\nof identifiers based on real names. We propose a new improved padding scheme\nthat achieves much less message expansion for a given $k$-anonymity.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 16:20:16 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 16:00:17 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Mattsson", "John Preu\u00df", ""], ["Nakarmi", "Prajwol Kumar", ""]]}, {"id": "2105.10464", "submitter": "David Cerezo S\\'anchez", "authors": "David Cerezo S\\'anchez", "title": "Pravuil: Global Consensus for a United World", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pravuil is a robust, secure, and scalable consensus protocol for a\npermissionless blockchain suitable for deployment in an adversarial environment\nsuch as the Internet. Pravuil circumvents previous shortcomings of other\nblockchains:\n  - Bitcoin's limited adoption problem: as transaction demand grows, payment\nconfirmation times grow much lower than other PoW blockchains\n  - higher transaction security at a lower cost\n  - more decentralisation than other permissionless blockchains\n  - impossibility of full decentralisation and the blockchain scalability\ntrilemma: decentralisation, scalability, and security can be achieved\nsimultaneously\n  - Sybil-resistance for free implementing the social optimum\n  - Pravuil goes beyond the economic limits of Bitcoin or other PoW/PoS\nblockchains, leading to a more valuable and stable crypto-currency\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 17:02:14 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["S\u00e1nchez", "David Cerezo", ""]]}, {"id": "2105.10545", "submitter": "Reza NasiriGerdeh", "authors": "Reza Nasirigerdeh, Reihaneh Torkzadehmahani, Julian Matschinske, Jan\n  Baumbach, Daniel Rueckert, Georgios Kaissis", "title": "HyFed: A Hybrid Federated Framework for Privacy-preserving Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Federated learning (FL) enables multiple clients to jointly train a global\nmodel under the coordination of a central server. Although FL is a\nprivacy-aware paradigm, where raw data sharing is not required, recent studies\nhave shown that FL might leak the private data of a client through the model\nparameters shared with the server or the other clients. In this paper, we\npresent the HyFed framework, which enhances the privacy of FL while preserving\nthe utility of the global model. HyFed provides developers with a generic API\nto develop federated, privacy-preserving algorithms. HyFed supports both\nsimulation and federated operation modes and its source code is publicly\navailable at https://github.com/tum-aimed/hyfed.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 19:30:43 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Nasirigerdeh", "Reza", ""], ["Torkzadehmahani", "Reihaneh", ""], ["Matschinske", "Julian", ""], ["Baumbach", "Jan", ""], ["Rueckert", "Daniel", ""], ["Kaissis", "Georgios", ""]]}, {"id": "2105.10566", "submitter": "Kartik Nayak", "authors": "Naama Ben-David and Kartik Nayak", "title": "Classifying Trusted Hardware via Unidirectional Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that Byzantine fault tolerant (BFT) consensus cannot be\nsolved in the classic asynchronous message passing model when one-third or more\nof the processes may be faulty. Since many modern applications require higher\nfault tolerance, this bound has been circumvented by introducing\nnon-equivocation mechanisms that prevent Byzantine processes from sending\nconflicting messages to other processes. The use of trusted hardware is a way\nto implement non-equivocation.\n  Several different trusted hardware modules have been considered in the\nliterature. In this paper, we study whether all trusted hardware modules are\nequivalent in the power that they provide to a system. We show that while they\ndo all prevent equivocation, we can partition trusted hardware modules into two\ndifferent power classes; those that employ shared memory primitives, and those\nthat do not. We separate these classes using a new notion we call\nunidirectionality, which describes a useful guarantee on the ability of\nprocesses to prevent network partitions. We show that shared-memory based\nhardware primitives provide unidirectionality, while others do not.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 20:46:06 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Ben-David", "Naama", ""], ["Nayak", "Kartik", ""]]}, {"id": "2105.10594", "submitter": "Jacob Imola", "authors": "Jacob Imola, Kamalika Chaudhuri", "title": "Privacy Amplification Via Bernoulli Sampling", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Balancing privacy and accuracy is a major challenge in designing\ndifferentially private machine learning algorithms. To improve this tradeoff,\nprior work has looked at privacy amplification methods which analyze how common\ntraining operations such as iteration and subsampling the data can lead to\nhigher privacy. In this paper, we analyze privacy amplification properties of a\nnew operation, sampling from the posterior, that is used in Bayesian inference.\nIn particular, we look at Bernoulli sampling from a posterior that is described\nby a differentially private parameter. We provide an algorithm to compute the\namplification factor in this setting, and establish upper and lower bounds on\nthis factor. Finally, we look at what happens when we draw k posterior samples\ninstead of one.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 22:34:32 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Imola", "Jacob", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "2105.10668", "submitter": "Ruggero Lanotte Dr", "authors": "Ruggero Lanotte, Massimo Merro, Andrei Munteanu", "title": "Runtime Enforcement of Programmable Logic Controllers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.FL cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of Industry 4.0, industrial facilities and critical\ninfrastructures are transforming into an ecosystem of heterogeneous physical\nand cyber components, such as programmable logic controllers, increasingly\ninterconnected and therefore exposed to cyber-physical attacks, i.e., security\nbreaches in cyberspace that may adversely affect the physical processes\nunderlying industrial control systems. In this paper, we propose a formal\napproach} based on runtime enforcement to ensure specification compliance in\nnetworks of controllers, possibly compromised by colluding malware that may\ntamper with actuator commands, sensor readings, and inter-controller\ncommunications. Our approach relies on an ad-hoc sub-class of Ligatti et al.'s\nedit automata to enforce controllers represented in Hennessy and Regan's Timed\nProcess Language. We define a synthesis algorithm that, given an alphabet $P$\nof observable actions and a regular timed correctness property $e$, returns a\nmonitor that enforces the property $e$ during the execution of any (potentially\ncorrupted) controller with alphabet $P$, and complying with the property $e$.\nOur monitors correct and suppress incorrect actions coming from corrupted\ncontrollers and emit actions in full autonomy when the controller under\nscrutiny is not able to do so in a correct manner. Besides classical\nrequirements, such as transparency and soundness, the proposed enforcement\nenjoys deadlock- and diverge-freedom of monitored controllers, together with\nscalability when dealing with networks of controllers. Finally, we test the\nproposed enforcement mechanism on a non-trivial case study, taken from the\ncontext of industrial water treatment systems, in which the controllers are\ninjected with different malware with different malicious goals.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 09:03:28 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Lanotte", "Ruggero", ""], ["Merro", "Massimo", ""], ["Munteanu", "Andrei", ""]]}, {"id": "2105.10707", "submitter": "Yifan Jia", "authors": "Yifan Jia, Jingyi Wang, Christopher M. Poskitt, Sudipta Chattopadhyay,\n  Jun Sun, Yuqi Chen", "title": "Adversarial Attacks and Mitigation for Anomaly Detectors of\n  Cyber-Physical Systems", "comments": "Accepted by the International Journal of Critical Infrastructure\n  Protection (IJCIP)", "journal-ref": "Int. J. Crit. Infrastructure Prot. 34:100452, 2021", "doi": "10.1016/j.ijcip.2021.100452", "report-no": null, "categories": "cs.CR cs.AI cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The threats faced by cyber-physical systems (CPSs) in critical infrastructure\nhave motivated research into a multitude of attack detection mechanisms,\nincluding anomaly detectors based on neural network models. The effectiveness\nof anomaly detectors can be assessed by subjecting them to test suites of\nattacks, but less consideration has been given to adversarial attackers that\ncraft noise specifically designed to deceive them. While successfully applied\nin domains such as images and audio, adversarial attacks are much harder to\nimplement in CPSs due to the presence of other built-in defence mechanisms such\nas rule checkers(or invariant checkers). In this work, we present an\nadversarial attack that simultaneously evades the anomaly detectors and rule\ncheckers of a CPS. Inspired by existing gradient-based approaches, our\nadversarial attack crafts noise over the sensor and actuator values, then uses\na genetic algorithm to optimise the latter, ensuring that the neural network\nand the rule checking system are both deceived.We implemented our approach for\ntwo real-world critical infrastructure testbeds, successfully reducing the\nclassification accuracy of their detectors by over 50% on average, while\nsimultaneously avoiding detection by rule checkers. Finally, we explore whether\nthese attacks can be mitigated by training the detectors on adversarial\nsamples.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 12:19:03 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Jia", "Yifan", ""], ["Wang", "Jingyi", ""], ["Poskitt", "Christopher M.", ""], ["Chattopadhyay", "Sudipta", ""], ["Sun", "Jun", ""], ["Chen", "Yuqi", ""]]}, {"id": "2105.10794", "submitter": "Farid Javani", "authors": "Farid Javani and Alan T. Sherman", "title": "AOT: Anonymization by Oblivious Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce AOT, an anonymous communication system based on mix network\narchitecture that uses oblivious transfer (OT) to deliver messages. Using OT to\ndeliver messages helps AOT resist blending ($n-1$) attacks and helps AOT\npreserve receiver anonymity, even if a covert adversary controls all nodes in\nAOT. AOT comprises three levels of nodes, where nodes at each level perform a\ndifferent function and can scale horizontally. The sender encrypts their\npayload and a tag, derived from a secret shared between the sender and\nreceiver, with the public key of a Level-2 node and sends them to a Level-1\nnode. On a public bulletin board, Level-3 nodes publish tags associated with\nmessages ready to be retrieved. Each receiver checks the bulletin board,\nidentifies tags, and receives the associated messages using OT. A receiver can\nreceive their messages even if the receiver is offline when messages are ready.\nThrough what we call a \"handshake\" process, communicants can use the AOT\nprotocol to establish shared secrets anonymously. Users play an active role in\ncontributing to the unlinkability of messages: periodically, users initiate\nrequests to AOT to receive dummy messages, such that an adversary cannot\ndistinguish real and dummy requests.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 19:00:01 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Javani", "Farid", ""], ["Sherman", "Alan T.", ""]]}, {"id": "2105.10857", "submitter": "Leo Yu Zhang Dr.", "authors": "Yong Wang, Zhuo Liu, Leo Yu Zhang, Fabio Pareschi, Gianluca Setti,\n  Guanrong Chen", "title": "From Chaos to Pseudo-Randomness: A Case Study on the 2D Coupled Map\n  Lattice", "comments": "10 pages, 11figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying chaos theory for secure digital communications is promising and it\nis well acknowledged that in such applications the underlying chaotic systems\nshould be carefully chosen. However, the requirements imposed on the chaotic\nsystems are usually heuristic, without theoretic guarantee for the resultant\ncommunication scheme. Among all the primitives for secure communications, it is\nwell-accepted that (pseudo) random numbers are most essential. Taking the\nwell-studied two-dimensional coupled map lattice (2D CML) as an example, this\npaper performs a theoretical study towards pseudo-random number generation with\nthe 2D CML. In so doing, an analytical expression of the Lyapunov exponent (LE)\nspectrum of the 2D CML is first derived. Using the LEs, one can configure\nsystem parameters to ensure the 2D CML only exhibits complex dynamic behavior,\nand then collect pseudo-random numbers from the system orbits. Moreover, based\non the observation that least significant bit distributes more evenly in the\n(pseudo) random distribution, an extraction algorithm E is developed with the\nproperty that, when applied to the orbits of the 2D CML, it can squeeze uniform\nbits. In implementation, if fixed-point arithmetic is used in binary format\nwith a precision of $z$ bits after the radix point, E can ensure that the\ndeviation of the squeezed bits is bounded by $2^{-z}$ . Further simulation\nresults demonstrate that the new method not only guide the 2D CML model to\nexhibit complex dynamic behavior, but also generate uniformly distributed\nindependent bits. In particular, the squeezed pseudo random bits can pass both\nNIST 800-22 and TestU01 test suites in various settings. This study thereby\nprovides a theoretical basis for effectively applying the 2D CML to secure\ncommunications.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 05:34:19 GMT"}, {"version": "v2", "created": "Sun, 11 Jul 2021 23:36:02 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wang", "Yong", ""], ["Liu", "Zhuo", ""], ["Zhang", "Leo Yu", ""], ["Pareschi", "Fabio", ""], ["Setti", "Gianluca", ""], ["Chen", "Guanrong", ""]]}, {"id": "2105.10879", "submitter": "Junghyun Lee", "authors": "Junghyun Lee, Eunsang Lee, Joon-Woo Lee, Yongjune Kim, Young-Sik Kim,\n  Jong-Seon No", "title": "Precise Approximation of Convolutional Neural Networks for\n  Homomorphically Encrypted Data", "comments": "Typos corrected, supplementary added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Homomorphic encryption is one of the representative solutions to\nprivacy-preserving machine learning (PPML) classification enabling the server\nto classify private data of clients while guaranteeing privacy. This work\nfocuses on PPML using word-wise fully homomorphic encryption (FHE). In order to\nimplement deep learning on word-wise homomorphic encryption (HE), the ReLU and\nmax-pooling functions should be approximated by some polynomials for\nhomomorphic operations. Most of the previous studies focus on HE-friendly\nnetworks, where the ReLU and max-pooling functions are approximated using\nlow-degree polynomials. However, for the classification of the CIFAR-10\ndataset, using a low-degree polynomial requires designing a new deep learning\nmodel and training. In addition, this approximation by low-degree polynomials\ncannot support deeper neural networks due to large approximation errors. Thus,\nwe propose a precise polynomial approximation technique for the ReLU and\nmax-pooling functions. Precise approximation using a single polynomial requires\nan exponentially high-degree polynomial, which results in a significant number\nof non-scalar multiplications. Thus, we propose a method to approximate the\nReLU and max-pooling functions accurately using a composition of minimax\napproximate polynomials of small degrees. If we replace the ReLU and\nmax-pooling functions with the proposed approximate polynomials, well-studied\ndeep learning models such as ResNet and VGGNet can still be used without\nfurther modification for PPML on FHE. Even pre-trained parameters can be used\nwithout retraining. We approximate the ReLU and max-pooling functions in the\nResNet-152 using the composition of minimax approximate polynomials of degrees\n15, 27, and 29. Then, we succeed in classifying the plaintext ImageNet dataset\nwith 77.52% accuracy, which is very close to the original model accuracy of\n78.31%.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 08:06:37 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 06:50:23 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 03:28:32 GMT"}, {"version": "v4", "created": "Mon, 14 Jun 2021 01:34:47 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Lee", "Junghyun", ""], ["Lee", "Eunsang", ""], ["Lee", "Joon-Woo", ""], ["Kim", "Yongjune", ""], ["Kim", "Young-Sik", ""], ["No", "Jong-Seon", ""]]}, {"id": "2105.10909", "submitter": "Lingjuan Lyu", "authors": "Lingjuan Lyu, Xuanli He, Fangzhao Wu, Lichao Sun", "title": "Killing Two Birds with One Stone: Stealing Model and Inferring Attribute\n  from BERT-based APIs", "comments": "paper under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advances in pre-trained models (e.g., BERT, XLNET and etc) have largely\nrevolutionized the predictive performance of various modern natural language\nprocessing tasks. This allows corporations to provide machine learning as a\nservice (MLaaS) by encapsulating fine-tuned BERT-based models as commercial\nAPIs. However, previous works have discovered a series of vulnerabilities in\nBERT- based APIs. For example, BERT-based APIs are vulnerable to both model\nextraction attack and adversarial example transferrability attack. However, due\nto the high capacity of BERT-based APIs, the fine-tuned model is easy to be\noverlearned, what kind of information can be leaked from the extracted model\nremains unknown and is lacking. To bridge this gap, in this work, we first\npresent an effective model extraction attack, where the adversary can\npractically steal a BERT-based API (the target/victim model) by only querying a\nlimited number of queries. We further develop an effective attribute inference\nattack to expose the sensitive attribute of the training data used by the\nBERT-based APIs. Our extensive experiments on benchmark datasets under various\nrealistic settings demonstrate the potential vulnerabilities of BERT-based\nAPIs.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 10:38:23 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Lyu", "Lingjuan", ""], ["He", "Xuanli", ""], ["Wu", "Fangzhao", ""], ["Sun", "Lichao", ""]]}, {"id": "2105.10917", "submitter": "Constantinos Patsakis", "authors": "Evangelos Mantas and Constantinos Patsakis", "title": "Who Watches the New Watchmen? The Challenges for Drone Digital Forensics\n  Investigations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The technological advance of drone technology has augmented the existing\ncapabilities of flying vehicles rendering them a valuable asset of the modern\nsociety. As more drones are expected to occupy the airspace in the near future,\nsecurity-related incidents, either malicious acts or accidents, will increase\nas well. The forensics analysis of a security incident is essential, as drones\nare flying above populated areas and have also been weaponised from radical\nforces and perpetrators. Thus, it is an imperative need to establish a Drone\nDigital Forensics Investigation Framework and standardise the processes of\ncollecting and processing such evidence. Although there are numerous drone\nplatforms in the market, the same principles apply to all of them; just like\nmobile phones. Nevertheless, due to the nature of drones, standardised\nforensics procedures to date do not manage to address the required processes\nand challenges that such investigations pose. Acknowledging this need, we\ndetail the unique characteristics of drones and the gaps in existing\nmethodologies and standards, showcasing that there are fundamental issues in\nterms of their forensics analysis from various perspectives, ranging from\noperational and procedural ones, and escalate to manufacturers, as well as\nlegal restrictions. The above creates a very complex environment where\ncoordinated actions must be made among the key stakeholders. Therefore, this\nwork paves the way to address these challenges by identifying the main issues,\ntheir origins, and the needs in the field by performing a thorough review of\nthe literature and a gap analysis.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 11:27:09 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Mantas", "Evangelos", ""], ["Patsakis", "Constantinos", ""]]}, {"id": "2105.10948", "submitter": "Javier Carnerero-Cano", "authors": "Javier Carnerero-Cano, Luis Mu\\~noz-Gonz\\'alez, Phillippa Spencer,\n  Emil C. Lupu", "title": "Regularization Can Help Mitigate Poisoning Attacks... with the Right\n  Hyperparameters", "comments": "Published at ICLR 2021 Workshop on Security and Safety in Machine\n  Learning Systems. arXiv admin note: text overlap with arXiv:2003.00040", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning algorithms are vulnerable to poisoning attacks, where a\nfraction of the training data is manipulated to degrade the algorithms'\nperformance. We show that current approaches, which typically assume that\nregularization hyperparameters remain constant, lead to an overly pessimistic\nview of the algorithms' robustness and of the impact of regularization. We\npropose a novel optimal attack formulation that considers the effect of the\nattack on the hyperparameters, modelling the attack as a \\emph{minimax bilevel\noptimization problem}. This allows to formulate optimal attacks, select\nhyperparameters and evaluate robustness under worst case conditions. We apply\nthis formulation to logistic regression using $L_2$ regularization, empirically\nshow the limitations of previous strategies and evidence the benefits of using\n$L_2$ regularization to dampen the effect of poisoning attacks.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 14:34:47 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Carnerero-Cano", "Javier", ""], ["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["Spencer", "Phillippa", ""], ["Lupu", "Emil C.", ""]]}, {"id": "2105.10997", "submitter": "Sergio L\\'opez Bernal", "authors": "Sergio L\\'opez Bernal, Alberto Huertas Celdr\\'an, Gregorio Mart\\'inez\n  P\\'erez", "title": "Neuronal Jamming Cyberattack over Invasive BCI Affecting the Resolution\n  of Tasks Requiring Visual Capabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Invasive Brain-Computer Interfaces (BCI) are extensively used in medical\napplication scenarios to record, stimulate, or inhibit neural activity with\ndifferent purposes. An example is the stimulation of some brain areas to reduce\nthe effects generated by Parkinson's disease. Despite the advances in recent\nyears, cybersecurity on BCI is an open challenge since attackers can exploit\nthe vulnerabilities of invasive BCIs to induce malicious stimulation or\ntreatment disruption, affecting neuronal activity. In this work, we design and\nimplement a novel neuronal cyberattack, called Neuronal Jamming (JAM), which\nprevents neurons from producing spikes. To implement and measure the JAM\nimpact, and due to the lack of realistic neuronal topologies in mammalians, we\nhave defined a use case with a Convolutional Neural Network (CNN) trained to\nallow a mouse to exit a particular maze. The resulting model has been\ntranslated to a neural topology, simulating a portion of a mouse's visual\ncortex. The impact of JAM on both biological and artificial networks is\nmeasured, analyzing how the attacks can both disrupt the spontaneous neural\nsignaling and the mouse's capacity to exit the maze. Besides, we compare the\nimpacts of both JAM and FLO (an existing neural cyberattack) demonstrating that\nJAM generates a higher impact in terms of neuronal spike rate. Finally, we\ndiscuss on whether and how JAM and FLO attacks could induce the effects of\nneurodegenerative diseases if the implanted BCI had a comprehensive electrode\ncoverage of the targeted brain regions.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 18:45:29 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Bernal", "Sergio L\u00f3pez", ""], ["Celdr\u00e1n", "Alberto Huertas", ""], ["P\u00e9rez", "Gregorio Mart\u00ednez", ""]]}, {"id": "2105.11061", "submitter": "Tolijan Trajanovski", "authors": "Tolijan Trajanovski, Ning Zhang", "title": "An Automated and Comprehensive Framework for IoT Botnet Detection and\n  Analysis (IoT-BDA)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of insecure Internet-connected devices gave rise to the IoT\nbotnets which can grow very large rapidly and may perform high-impact\ncyber-attacks. The related studies for tackling IoT botnets are concerned with\neither capturing or analysing IoT botnet samples, using honeypots and\nsandboxes, respectively. The lack of integration between the two implies that\nthe samples captured by the honeypots must be manually submitted for analysis,\nintroducing a delay during which a botnet may change its operation.\nFurthermore, the effectiveness of the proposed sandboxes is limited by the\npotential use of anti-analysis techniques and the inability to identify\nfeatures for effective detection and identification of IoT botnets. In this\npaper, we propose the IoT-BDA framework for automated capturing, analysis,\nidentification, and reporting of IoT botnets. The captured samples are analysed\nin real-time to identify indicators of compromise and attack, along with\nanti-analysis, persistence, and anti-forensics techniques. These features can\nhelp botnet detection and analysis, as well as infection remedy. The framework\nreports the findings to a blacklist and abuse service to facilitate botnet\nsuspension. We also describe the discovered anti-honeypot techniques and the\nmeasures applied to reduce the risk of honeypot detection. Over the period of\nseven months, the framework captured, analysed, and reported 4077 unique IoT\nbotnet samples. The analysis results show that IoT botnets may employ\npersistence, anti-analysis and anti-forensics techniques typical for\ntraditional botnets. The in-depth analysis also discovered IoT botnets using\ntechniques for evading network detection.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 01:58:07 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Trajanovski", "Tolijan", ""], ["Zhang", "Ning", ""]]}, {"id": "2105.11103", "submitter": "Tong Zhu", "authors": "Tong Zhu, Yan Meng, Haotian Hu, Xiaokuan Zhang, Minhui Xue, Haojin Zhu", "title": "Dissecting Click Fraud Autonomy in the Wild", "comments": "Accepted to ACM CCS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although the use of pay-per-click mechanisms stimulates the prosperity of the\nmobile advertisement network, fraudulent ad clicks result in huge financial\nlosses for advertisers. Extensive studies identify click fraud according to\nclick/traffic patterns based on dynamic analysis. However, in this study, we\nidentify a novel click fraud, named humanoid attack, which can circumvent\nexisting detection schemes by generating fraudulent clicks with similar\npatterns to normal clicks. We implement the first tool ClickScanner to detect\nhumanoid attacks on Android apps based on static analysis and variational\nAutoEncoder (VAE) with limited knowledge of fraudulent examples. We define\nnovel features to characterize the patterns of humanoid attacks in the apps'\nbytecode level. ClickScanner builds a data dependency graph (DDG) based on\nstatic analysis to extract these key features and form a feature vector. We\nthen propose a classification model only trained on benign datasets to overcome\nthe limited knowledge of humanoid attacks.\n  We leverage ClickScanner to conduct the first large-scale measurement on app\nmarkets (i.e.,120,000 apps from Google Play and Huawei AppGallery) and reveal\nseveral unprecedented phenomena. First, even for the top-rated 20,000 apps,\nClickScanner still identifies 157 apps as fraudulent, which shows the\nprevalence of humanoid attacks. Second, it is observed that the ad SDK-based\nattack (i.e., the fraudulent codes are in the third-party ad SDKs) is now a\ndominant attack approach. Third, the manner of attack is notably different\nacross apps of various categories and popularities. Finally, we notice there\nare several existing variants of the humanoid attack. Additionally, our\nmeasurements demonstrate the proposed ClickScanner is accurate and\ntime-efficient (i.e., the detection overhead is only 15.35% of those of\nexisting schemes).\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 05:54:27 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Zhu", "Tong", ""], ["Meng", "Yan", ""], ["Hu", "Haotian", ""], ["Zhang", "Xiaokuan", ""], ["Xue", "Minhui", ""], ["Zhu", "Haojin", ""]]}, {"id": "2105.11172", "submitter": "Ludovic Barman", "authors": "Ludovic Barman, Alexandre Dumur, Apostolos Pyrgelis, Jean-Pierre\n  Hubaux", "title": "Every Byte Matters: Traffic Analysis of Bluetooth Wearable Devices", "comments": "45 pages", "journal-ref": "Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 5, 2,\n  Article 54 (June 2021)", "doi": "10.1145/3463512", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wearable devices such as smartwatches, fitness trackers, and blood-pressure\nmonitors process, store, and communicate sensitive and personal information\nrelated to the health, life-style, habits and interests of the wearer. This\ndata is exchanged with a companion app running on a smartphone over a Bluetooth\nconnection. In this work, we investigate what can be inferred from the metadata\n(such as the packet timings and sizes) of encrypted Bluetooth communications\nbetween a wearable device and its connected smartphone. We show that a passive\neavesdropper can use traffic-analysis attacks to accurately recognize (a)\ncommunicating devices, even without having access to the MAC address, (b) human\nactions (e.g., monitoring heart rate, exercising) performed on wearable devices\nranging from fitness trackers to smartwatches, (c) the mere opening of specific\napplications on a Wear OS smartwatch (e.g., the opening of a medical app, which\ncan immediately reveal a condition of the wearer), (d) fine-grained actions\n(e.g., recording an insulin injection) within a specific application that helps\ndiabetic users to monitor their condition, and (e) the profile and habits of\nthe wearer by continuously monitoring her traffic over an extended period. We\nrun traffic-analysis attacks by collecting a dataset of Bluetooth traces of\nmultiple wearable devices, by designing features based on packet sizes and\ntimings, and by using machine learning to classify the encrypted traffic to\nactions performed by the wearer. Then, we explore standard defense strategies;\nwe show that these defenses do not provide sufficient protection against our\nattacks and introduce significant costs. Our research highlights the need to\nrethink how applications exchange sensitive information over Bluetooth, to\nminimize unnecessary data exchanges, and to design new defenses against\ntraffic-analysis tailored to the wearable setting.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 09:41:02 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Barman", "Ludovic", ""], ["Dumur", "Alexandre", ""], ["Pyrgelis", "Apostolos", ""], ["Hubaux", "Jean-Pierre", ""]]}, {"id": "2105.11217", "submitter": "Sidra Malik", "authors": "Sidra Malik, Naman Gupta, Volkan Dedeoglu, Salil S. Kanhere, Raja\n  Jurdak", "title": "TradeChain: Decoupling Traceability and Identity inBlockchain enabled\n  Supply Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we propose a privacy-preservation framework, TradeChain, which\ndecouples the trade events of participants using decentralised identities.\nTradeChain adopts the Self-Sovereign Identity (SSI) principles and makes the\nfollowing novel contributions: a) it incorporates two separate ledgers: a\npublic permissioned blockchain for maintaining identities and the permissioned\nblockchain for recording trade flows, b) it uses Zero Knowledge Proofs (ZKPs)\non traders' private credentials to prove multiple identities on trade ledger\nand c) allows data owners to define dynamic access rules for verifying\ntraceability information from the trade ledger using access tokens and\nCiphertext Policy Attribute-Based Encryption (CP-ABE). A proof of concept\nimplementation of TradeChain is presented on Hyperledger Indy and Fabric and an\nextensive evaluation of execution time, latency and throughput reveals minimal\noverheads.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 11:52:29 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Malik", "Sidra", ""], ["Gupta", "Naman", ""], ["Dedeoglu", "Volkan", ""], ["Kanhere", "Salil S.", ""], ["Jurdak", "Raja", ""]]}, {"id": "2105.11363", "submitter": "Yizheng Chen", "authors": "Yizheng Chen, Shiqi Wang, Yue Qin, Xiaojing Liao, Suman Jana, David\n  Wagner", "title": "Learning Security Classifiers with Verified Global Robustness Properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have proposed methods to train classifiers with local robustness\nproperties, which can provably eliminate classes of evasion attacks for most\ninputs, but not all inputs. Since data distribution shift is very common in\nsecurity applications, e.g., often observed for malware detection, local\nrobustness cannot guarantee that the property holds for unseen inputs at the\ntime of deploying the classifier. Therefore, it is more desirable to enforce\nglobal robustness properties that hold for all inputs, which is strictly\nstronger than local robustness.\n  In this paper, we present a framework and tools for training classifiers that\nsatisfy global robustness properties. We define new notions of global\nrobustness that are more suitable for security classifiers. We design a novel\nbooster-fixer training framework to enforce global robustness properties. We\nstructure our classifier as an ensemble of logic rules and design a new\nverifier to verify the properties. In our training algorithm, the booster\nincreases the classifier's capacity, and the fixer enforces verified global\nrobustness properties following counterexample guided inductive synthesis.\n  To the best of our knowledge, the only global robustness property that has\nbeen previously achieved is monotonicity. Several previous works have defined\nglobal robustness properties, but their training techniques failed to achieve\nverified global robustness. In comparison, we show that we can train\nclassifiers to satisfy different global robustness properties for three\nsecurity datasets, and even multiple properties at the same time, with modest\nimpact on the classifier's performance. For example, we train a Twitter spam\naccount classifier to satisfy five global robustness properties, with 5.4%\ndecrease in true positive rate, and 0.1% increase in false positive rate,\ncompared to a baseline XGBoost model that doesn't satisfy any property.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 15:46:20 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Chen", "Yizheng", ""], ["Wang", "Shiqi", ""], ["Qin", "Yue", ""], ["Liao", "Xiaojing", ""], ["Jana", "Suman", ""], ["Wagner", "David", ""]]}, {"id": "2105.11593", "submitter": "Guohua Xin", "authors": "Guangquan Xu, GuoHua Xin, Litao Jiao, Jian Liu, Shaoying Liu, Meiqi\n  Feng, and Xi Zheng", "title": "OFEI: A Semi-black-box Android Adversarial Sample Attack Framework\n  Against DLaaS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing popularity of Android devices, Android malware is seriously\nthreatening the safety of users. Although such threats can be detected by deep\nlearning as a service (DLaaS), deep neural networks as the weakest part of\nDLaaS are often deceived by the adversarial samples elaborated by attackers. In\nthis paper, we propose a new semi-black-box attack framework called\none-feature-each-iteration (OFEI) to craft Android adversarial samples. This\nframework modifies as few features as possible and requires less classifier\ninformation to fool the classifier. We conduct a controlled experiment to\nevaluate our OFEI framework by comparing it with the benchmark methods JSMF,\nGenAttack and pointwise attack. The experimental results show that our OFEI has\na higher misclassification rate of 98.25%. Furthermore, OFEI can extend the\ntraditional white-box attack methods in the image field, such as fast gradient\nsign method (FGSM) and DeepFool, to craft adversarial samples for Android.\nFinally, to enhance the security of DLaaS, we use two uncertainties of the\nBayesian neural network to construct the combined uncertainty, which is used to\ndetect adversarial samples and achieves a high detection rate of 99.28%.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 01:02:05 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Xu", "Guangquan", ""], ["Xin", "GuoHua", ""], ["Jiao", "Litao", ""], ["Liu", "Jian", ""], ["Liu", "Shaoying", ""], ["Feng", "Meiqi", ""], ["Zheng", "Xi", ""]]}, {"id": "2105.11665", "submitter": "Khizar Hameed", "authors": "Khizar Hameed, Mutaz Barika, Saurabh Garg, Muhammad Bilal Amin, Byeong\n  Kang", "title": "A Taxonomy Study on Securing Blockchain-based Industrial Applications:\n  An Overview, Application Perspectives, Requirements, Attacks,\n  Countermeasures, and Open Issues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain technology has taken on a leading role in today's industrial\napplications by providing salient features and showing significant performance\nsince its beginning. Blockchain began its journey from the concept of\ncryptocurrency and is now part of a range of core applications to achieve\nresilience and automation between various tasks. With the integration of\nBlockchain technology into different industrial applications, many application\ndesigns, security and privacy challenges present themselves, posing serious\nthreats to users and their data. Although several approaches have been proposed\nto address the specific security and privacy needs of targeted applications\nwith functional parameters, there is still a need for a research study on the\napplication, security and privacy challenges, and requirements of\nBlockchain-based industrial applications, along with possible security threats\nand countermeasures. This study presents a state-of-the-art survey of\nBlockchain-based Industry 4.0 applications, focusing on crucial application and\nsecurity and privacy requirements, as well as corresponding attacks on\nBlockchain systems with potential countermeasures. We also analyse and provide\nthe classification of different security and privacy techniques used in these\napplications to enhance the advancement of security features. Furthermore, we\nhighlight some open issues in industrial applications that help to design\nsecure Blockchain-based applications as future directions.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 04:51:34 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Hameed", "Khizar", ""], ["Barika", "Mutaz", ""], ["Garg", "Saurabh", ""], ["Amin", "Muhammad Bilal", ""], ["Kang", "Byeong", ""]]}, {"id": "2105.11751", "submitter": "Lachlan Urquhart Ph.D", "authors": "Jiahong Chen and Lachlan Urquhart", "title": "'They're all about pushing the products and shiny things rather than\n  fundamental security' Mapping Socio-technical Challenges in Securing the\n  Smart Home", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insecure connected devices can cause serious threats not just to smart home\nowners, but also the underlying infrastructural network as well. There has been\nincreasing academic and regulatory interest in addressing cybersecurity risks\nfrom both the standpoint of Internet of Things (IoT) vendors and that of\nend-users. In addition to the current data protection and network security\nlegal frameworks, for example, the UK government has initiated the 'Secure by\nDesign' campaign. While there has been work on how organisations and\nindividuals manage their own cybersecurity risks, it remains unclear to what\nextent IoT vendors are supporting end-users to perform day-to-day management of\nsuch risks in a usable way, and what is stopping the vendors from improving\nsuch support. We interviewed 13 experts in the field of IoT and identified\nthree main categories of barriers to making IoT products usably secure:\ntechnical, legal and organisational. In this paper we further discuss the\npolicymaking implications of these findings and make some recommendations.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 08:38:36 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Chen", "Jiahong", ""], ["Urquhart", "Lachlan", ""]]}, {"id": "2105.11805", "submitter": "Constantinos Patsakis", "authors": "Nikolaos Lykousas, Vasilios Koutsokostas, Fran Casino, and\n  Constantinos Patsakis", "title": "The Cynicism of Modern Cybercrime: Automating the Analysis of Surface\n  Web Marketplaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybercrime is continuously growing in numbers and becoming more\nsophisticated. Currently, there are various monetisation and money laundering\nmethods, creating a huge, underground economy worldwide. A clear indicator of\nthese activities is online marketplaces which allow cybercriminals to trade\ntheir stolen assets and services. While traditionally these marketplaces are\navailable through the dark web, several of them have emerged in the surface\nweb. In this work, we perform a longitudinal analysis of a surface web\nmarketplace. The information was collected through targeted web scrapping that\nallowed us to identify hundreds of merchants' profiles for the most widely used\nsurface web marketplaces. In this regard, we discuss the products traded in\nthese markets, their prices, their availability, and the exchange currency.\nThis analysis is performed in an automated way through a machine learning-based\npipeline, allowing us to quickly and accurately extract the needed information.\nThe outcomes of our analysis evince that illegal practices are leveraged in\nsurface marketplaces and that there are not effective mechanisms towards their\ntakedown at the time of writing.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 10:11:06 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Lykousas", "Nikolaos", ""], ["Koutsokostas", "Vasilios", ""], ["Casino", "Fran", ""], ["Patsakis", "Constantinos", ""]]}, {"id": "2105.11827", "submitter": "Alberto Sonnino", "authors": "George Danezis, Eleftherios Kokoris Kogias, Alberto Sonnino, Alexander\n  Spiegelman", "title": "Narwhal and Tusk: A DAG-based Mempool and Efficient BFT Consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose separating the task of transaction dissemination from transaction\nordering, to enable high-performance Byzantine fault-tolerant consensus in a\npermissioned setting. To this end, we design and evaluate a mempool protocol,\nNarwhal, specializing in high-throughput reliable dissemination and storage of\ncausal histories of transactions. Narwhal tolerates an asynchronous network and\nmaintains its performance despite failures. We demonstrate that composing\n\\Narwhal with a partially synchronous consensus protocol (HotStuff) yields\nsignificantly better throughput even in the presence of faults. However, loss\nof liveness during view-changes can result in high latency. To achieve overall\ngood performance when faults occur we propose Tusk, a zero-message overhead\nasynchronous consensus protocol embedded within Narwhal. We demonstrate its\nhigh performance under a variety of configurations and faults. Further, Narwhal\nis designed to easily scale-out using multiple workers at each validator, and\nwe demonstrate that there is no foreseeable limit to the throughput we can\nachieve for consensus, with a few seconds latency. As a summary of results, on\na Wide Area Network (WAN), Hotstuff over Narwhal achieves 170,000 tx/sec with a\n2.5-sec latency instead of 1,800 tx/sec with 1-sec latency of Hotstuff.\nAdditional workers increase throughput linearly to 600,000 tx/sec without any\nlatency increase. Tusk achieves 140,000 tx/sec with 4 seconds latency or 20x\nbetter than the state-of-the-art asynchronous protocol. Under faults, both\nNarwhal based protocols maintain high throughput, but the HotStuff variant\nsuffers from slightly higher latency.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 10:53:41 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 12:10:22 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Danezis", "George", ""], ["Kogias", "Eleftherios Kokoris", ""], ["Sonnino", "Alberto", ""], ["Spiegelman", "Alexander", ""]]}, {"id": "2105.11928", "submitter": "Katharina Kohls", "authors": "Katharina Kohls and Claudia Diaz", "title": "VerLoc: Verifiable Localization in Decentralized Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles the challenge of reliably determining the geo-location of\nnodes in decentralized networks, considering adversarial settings and without\ndepending on any trusted landmarks. In particular, we consider active\nadversaries that control a subset of nodes, announce false locations and\nstrategically manipulate measurements. To address this problem we propose,\nimplement and evaluate VerLoc, a system that allows verifying the claimed\ngeo-locations of network nodes in a fully decentralized manner. VerLoc securely\nschedules roundtrip time (RTT) measurements between randomly chosen pairs of\nnodes. Trilateration is then applied to the set of measurements to verify\nclaimed geo-locations. We evaluate VerLoc both with simulations and in the wild\nusing a prototype implementation integrated in the Nym network (currently run\nby thousands of nodes). We find that VerLoc can localize nodes in the wild with\na median error of 60km, and that in attack simulations it is capable of\ndetecting and filtering out adversarial timing manipulations for network setups\nwith up to 20% malicious nodes.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 13:32:51 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 10:42:35 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Kohls", "Katharina", ""], ["Diaz", "Claudia", ""]]}, {"id": "2105.11983", "submitter": "Majid Rafiei", "authors": "Majid Rafiei and Wil M.P. van der Aalst", "title": "Group-Based Privacy Preservation Techniques for Process Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Process mining techniques help to improve processes using event data. Such\ndata are widely available in information systems. However, they often contain\nhighly sensitive information. For example, healthcare information systems\nrecord event data that can be utilized by process mining techniques to improve\nthe treatment process, reduce patient's waiting times, improve resource\nproductivity, etc. However, the recorded event data include highly sensitive\ninformation related to treatment activities. Responsible process mining should\nprovide insights about the underlying processes, yet, at the same time, it\nshould not reveal sensitive information. In this paper, we discuss the\nchallenges regarding directly applying existing well-known group-based privacy\npreservation techniques, e.g., k-anonymity, l-diversity, etc, to event data. We\nprovide formal definitions of attack models and introduce an effective\ngroup-based privacy preservation technique for process mining. Our technique\ncovers the main perspectives of process mining including control-flow, time,\ncase, and organizational perspectives. The proposed technique provides\ninterpretable and adjustable parameters to handle different privacy aspects. We\nemploy real-life event data and evaluate both data utility and result utility\nto show the effectiveness of the privacy preservation technique. We also\ncompare this approach with other group-based approaches for privacy-preserving\nevent data publishing.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 14:37:20 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Rafiei", "Majid", ""], ["van der Aalst", "Wil M. P.", ""]]}, {"id": "2105.11991", "submitter": "Majid Rafiei", "authors": "Majid Rafiei and Wil M.P. van der Aalst", "title": "Privacy-Preserving Continuous Event Data Publishing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Process mining enables organizations to discover and analyze their actual\nprocesses using event data. Event data can be extracted from any information\nsystem supporting operational processes, e.g., SAP. Whereas the data inside\nsuch systems is protected using access control mechanisms, the extracted event\ndata contain sensitive information that needs to be protected. This creates a\nnew risk and a possible inhibitor for applying process mining. Therefore,\nprivacy issues in process mining become increasingly important. Several privacy\npreservation techniques have been introduced to mitigate possible attacks\nagainst static event data published only once. However, to keep the process\nmining results up-to-date, event data need to be published continuously. For\nexample, a new log is created at the end of each week. In this paper, we\nelaborate on the attacks which can be launched against continuously publishing\nanonymized event data by comparing different releases, so-called correspondence\nattacks. Particularly, we focus on group-based privacy preservation techniques\nand show that provided privacy requirements can be degraded exploiting\ncorrespondence attacks. We apply the continuous event data publishing scenario\nto existing real-life event logs and report the anonymity indicators before and\nafter launching the attacks.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 14:53:00 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Rafiei", "Majid", ""], ["van der Aalst", "Wil M. P.", ""]]}, {"id": "2105.12097", "submitter": "Abdul Rehman Javed", "authors": "Waqas Ahmed, Amir Rasool, Neeraj Kumar, Abdul RehmanJaved, Thippa\n  Reddy Gadekallu, Zunera Jalil, Natalia Kryvinska", "title": "Security in Next Generation Mobile Payment Systems: A Comprehensive\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cash payment is still king in several markets, accounting for more than 90\\\nof the payments in almost all the developing countries. The usage of mobile\nphones is pretty ordinary in this present era. Mobile phones have become an\ninseparable friend for many users, serving much more than just communication\ntools. Every subsequent person is heavily relying on them due to multifaceted\nusage and affordability. Every person wants to manage his/her daily\ntransactions and related issues by using his/her mobile phone. With the rise\nand advancements of mobile-specific security, threats are evolving as well. In\nthis paper, we provide a survey of various security models for mobile phones.\nWe explore multiple proposed models of the mobile payment system (MPS), their\ntechnologies and comparisons, payment methods, different security mechanisms\ninvolved in MPS, and provide analysis of the encryption technologies,\nauthentication methods, and firewall in MPS. We also present current challenges\nand future directions of mobile phone security.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 17:34:22 GMT"}, {"version": "v2", "created": "Sat, 10 Jul 2021 17:43:12 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Ahmed", "Waqas", ""], ["Rasool", "Amir", ""], ["Kumar", "Neeraj", ""], ["RehmanJaved", "Abdul", ""], ["Gadekallu", "Thippa Reddy", ""], ["Jalil", "Zunera", ""], ["Kryvinska", "Natalia", ""]]}, {"id": "2105.12224", "submitter": "Shuwen Deng", "authors": "Shuwen Deng and Bowen Huang and Jakub Szefer", "title": "Leaky Frontends: Micro-Op Cache and Processor Frontend Vulnerabilities", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates a new class of security vulnerabilities due to the\nMicro-Op Caches, also called Decode Stream Buffer, and other components in the\nprocessor frontend. The vulnerabilities presented in this work exploit multiple\npaths in the processor frontend that the micro-ops can take: through the\nMicro-Instruction Translation Engine (MITE), through the Decode Stream Buffer\n(DSB), or through the Loop Stream Detector (LSD). Each path has its own unique\ntiming and power signature, which leads to security vulnerabilities. The\nvulnerabilities can be used as side or covert channels for information leakage\nand can be exploited to create both timing and power attacks. As information\nleakage channels, the new vulnerabilities are orthogonal to the existing\nspeculative execution attacks and can be used as covert transmission channels\nin a new variant of speculative attacks that is demonstrated in this work. The\nvulnerabilities further affect Intel SGX enclaves, and this work shows how\ninformation can be leaked from SGX enclaves through the sharing of the frontend\npaths. The transmission rates for new attacks based on the vulnerabilities\npresented can be as high as 1410 Kbps (1.41 Mbps) with an almost 0% error rate.\nConsequently, this work demonstrates that multiple paths in the processor\nfrontend are a source of security vulnerabilities which have not been\nconsidered before and that focusing on just speculative execution attacks is\nnot sufficient to secure today's processors.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 21:35:56 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Deng", "Shuwen", ""], ["Huang", "Bowen", ""], ["Szefer", "Jakub", ""]]}, {"id": "2105.12266", "submitter": "Alexander La Cour", "authors": "Alexander S. La Cour, Khurram K. Afridi, G. Edward Suh", "title": "Wireless Charging Power Side-Channel Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that today's wireless charging interface is vulnerable to\npower side-channel attacks; a smartphone charging wirelessly leaks private\ninformation about its activity to the wireless charger (charging transmitter).\nWe present a website fingerprinting attack through the wireless charging\nside-channel for both iOS and Android devices. The attack monitors the current\ndrawn by the wireless charging transmitter while 20 webpages from the Alexa top\nsites list are loaded on a charging smartphone. We implement a classifier that\ncorrectly identifies unlabeled current traces with an accuracy of 87% on\naverage for an iPhone 11 and 95% on average for a Google Pixel 4. This\nrepresents a considerable security threat because wireless charging does not\nrequire any user permission if the phone is within the range of a charging\ntransmitter. To the best of our knowledge, this work represents the first to\nintroduce and demonstrate a power side-channel attack through wireless\ncharging. Additionally, this study compares the wireless charging side-channel\nwith the wired USB charging power side-channel, showing that they are\ncomparable. We find that the performance of the attack deteriorates as the\ncontents of websites change over time. Furthermore, we discover that the amount\nof information leakage through both wireless and wired charging interfaces\nheavily depends on the battery level; minimal information is leaked at low\nbattery levels.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 00:07:08 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 02:51:02 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["La Cour", "Alexander S.", ""], ["Afridi", "Khurram K.", ""], ["Suh", "G. Edward", ""]]}, {"id": "2105.12279", "submitter": "Ali Dorri", "authors": "Ali Dorri and Shailesh Mishra and Raja Jurdak", "title": "Vericom: A Verification and Communication Architecture for IoT-based\n  Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain has received tremendous attention as a secure, distributed, and\nanonymous framework for the Internet of Things (IoT). As a distributed system,\nblockchain trades off scalability for distribution, which limits the\ntechnologys adaptation for large scale networks such as IoT. All transactions\nand blocks must be broadcast and verified by all participants which limits\nscalability and incurs computational and communication overheads. The existing\nsolutions to scale blockchains have so far led to partial recentralization,\nlimiting the technologys original appeal. In this paper, we introduce a\ndistributed yet scalable Verification and Communication architecture for\nblockchain referred to as Vericom. Vericom concurrently achieves high\nscalability and distribution using hash function outputs to shift blockchains\nfrom broadcast to multicast communication. Unlike conventional blockchains\nwhere all nodes must verify new transactions/blocks, Vericom uses the hash of\nIoT traffic to randomly select a set of nodes to verify transactions/blocks\nwhich in turn reduces the processing overhead. Vericom incorporates two layers:\ni) transmission layer where a randomized multicasting method is introduced\nalong with a backbone network to route traffic, i.e., transactions and blocks,\nfrom the source to the destination, and ii) verification layer where a set of\nrandomly selected nodes are allocated to verify each transaction or block. The\nperformance evaluation shows that Vericom reduces the packet and processing\noverhead as compared with conventional blockchains. In the worst case, packet\noverhead in Vericom scales linearly with the number of nodes while the\nprocessing overhead remains scale-independent.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 00:56:10 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Dorri", "Ali", ""], ["Mishra", "Shailesh", ""], ["Jurdak", "Raja", ""]]}, {"id": "2105.12344", "submitter": "Jinyu Tian", "authors": "Jinyu Tian, Jiantao Zhou, and Jia Duan", "title": "Probabilistic Selective Encryption of Convolutional Neural Networks for\n  Hierarchical Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Model protection is vital when deploying Convolutional Neural Networks (CNNs)\nfor commercial services, due to the massive costs of training them. In this\nwork, we propose a selective encryption (SE) algorithm to protect CNN models\nfrom unauthorized access, with a unique feature of providing hierarchical\nservices to users. Our algorithm firstly selects important model parameters via\nthe proposed Probabilistic Selection Strategy (PSS). It then encrypts the most\nimportant parameters with the designed encryption method called Distribution\nPreserving Random Mask (DPRM), so as to maximize the performance degradation by\nencrypting only a very small portion of model parameters. We also design a set\nof access permissions, using which different amounts of the most important\nmodel parameters can be decrypted. Hence, different levels of model performance\ncan be naturally provided for users. Experimental results demonstrate that the\nproposed scheme could effectively protect the classification model VGG19 by\nmerely encrypting 8% parameters of convolutional layers. We also implement the\nproposed model protection scheme in the denoising model DnCNN, showcasing the\nhierarchical denoising services\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 06:15:58 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Tian", "Jinyu", ""], ["Zhou", "Jiantao", ""], ["Duan", "Jia", ""]]}, {"id": "2105.12363", "submitter": "Lun Wang", "authors": "Lun Wang, Dawn Song", "title": "Differentially Private Frequency Moments Estimation with Polylogarithmic\n  Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We prove that $\\mathbb{F}_p$ sketch, a well-celebrated streaming algorithm\nfor frequency moments estimation, is differentially private as is.\n$\\mathbb{F}_p$ sketch uses only polylogarithmic space, exponentially better\nthan existing DP baselines and only worse than the optimal non-private baseline\nby a logarithmic factor. The evaluation shows that $\\mathbb{F}_p$ sketch can\nachieve reasonable accuracy with strong privacy guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 07:11:05 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 05:00:22 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Wang", "Lun", ""], ["Song", "Dawn", ""]]}, {"id": "2105.12400", "submitter": "Fanchao Qi", "authors": "Fanchao Qi, Mukai Li, Yangyi Chen, Zhengyan Zhang, Zhiyuan Liu,\n  Yasheng Wang, Maosong Sun", "title": "Hidden Killer: Invisible Textual Backdoor Attacks with Syntactic Trigger", "comments": "Accepted by ACL-IJCNLP 2021 as a long paper. Camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Backdoor attacks are a kind of insidious security threat against machine\nlearning models. After being injected with a backdoor in training, the victim\nmodel will produce adversary-specified outputs on the inputs embedded with\npredesigned triggers but behave properly on normal inputs during inference. As\na sort of emergent attack, backdoor attacks in natural language processing\n(NLP) are investigated insufficiently. As far as we know, almost all existing\ntextual backdoor attack methods insert additional contents into normal samples\nas triggers, which causes the trigger-embedded samples to be detected and the\nbackdoor attacks to be blocked without much effort. In this paper, we propose\nto use the syntactic structure as the trigger in textual backdoor attacks. We\nconduct extensive experiments to demonstrate that the syntactic trigger-based\nattack method can achieve comparable attack performance (almost 100% success\nrate) to the insertion-based methods but possesses much higher invisibility and\nstronger resistance to defenses. These results also reveal the significant\ninsidiousness and harmfulness of textual backdoor attacks. All the code and\ndata of this paper can be obtained at https://github.com/thunlp/HiddenKiller.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 08:54:19 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 08:27:11 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Qi", "Fanchao", ""], ["Li", "Mukai", ""], ["Chen", "Yangyi", ""], ["Zhang", "Zhengyan", ""], ["Liu", "Zhiyuan", ""], ["Wang", "Yasheng", ""], ["Sun", "Maosong", ""]]}, {"id": "2105.12419", "submitter": "Heng Chang", "authors": "Heng Chang, Yu Rong, Tingyang Xu, Wenbing Huang, Honglei Zhang, Peng\n  Cui, Xin Wang, Wenwu Zhu, Junzhou Huang", "title": "Adversarial Attack Framework on Graph Embedding Models with Limited\n  Knowledge", "comments": "Journal extension of GF-Attack. arXiv admin note: text overlap with\n  arXiv:1908.01297", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the success of the graph embedding model in both academic and industry\nareas, the robustness of graph embedding against adversarial attack inevitably\nbecomes a crucial problem in graph learning. Existing works usually perform the\nattack in a white-box fashion: they need to access the predictions/labels to\nconstruct their adversarial loss. However, the inaccessibility of\npredictions/labels makes the white-box attack impractical to a real graph\nlearning system. This paper promotes current frameworks in a more general and\nflexible sense -- we demand to attack various kinds of graph embedding models\nwith black-box driven. We investigate the theoretical connections between graph\nsignal processing and graph embedding models and formulate the graph embedding\nmodel as a general graph signal process with a corresponding graph filter.\nTherefore, we design a generalized adversarial attacker: GF-Attack. Without\naccessing any labels and model predictions, GF-Attack can perform the attack\ndirectly on the graph filter in a black-box fashion. We further prove that\nGF-Attack can perform an effective attack without knowing the number of layers\nof graph embedding models. To validate the generalization of GF-Attack, we\nconstruct the attacker on four popular graph embedding models. Extensive\nexperiments validate the effectiveness of GF-Attack on several benchmark\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 09:18:58 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Chang", "Heng", ""], ["Rong", "Yu", ""], ["Xu", "Tingyang", ""], ["Huang", "Wenbing", ""], ["Zhang", "Honglei", ""], ["Cui", "Peng", ""], ["Wang", "Xin", ""], ["Zhu", "Wenwu", ""], ["Huang", "Junzhou", ""]]}, {"id": "2105.12477", "submitter": "Stephan Wiefling", "authors": "Johannes Kunke, Stephan Wiefling, Markus Ullmann, Luigi Lo Iacono", "title": "Evaluation of Account Recovery Strategies with FIDO2-based Passwordless\n  Authentication", "comments": "12 pages, 1 figure, 1 table", "journal-ref": "Open Identity Summit 2021 (OID '21), June 1-2, 2021. Pages 59-70", "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Threats to passwords are still very relevant due to attacks like phishing or\ncredential stuffing. One way to solve this problem is to remove passwords\ncompletely. User studies on passwordless FIDO2 authentication using security\ntokens demonstrated the potential to replace passwords. However, widespread\nacceptance of FIDO2 depends, among other things, on how user accounts can be\nrecovered when the security token becomes permanently unavailable. For this\nreason, we provide a heuristic evaluation of 12 account recovery mechanisms\nregarding their properties for FIDO2 passwordless authentication. Our results\nshow that the currently used methods have many drawbacks. Some even rely on\npasswords, taking passwordless authentication ad absurdum. Still, our\nevaluation identifies promising account recovery solutions and provides\nrecommendations for further studies.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 11:21:37 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Kunke", "Johannes", ""], ["Wiefling", "Stephan", ""], ["Ullmann", "Markus", ""], ["Iacono", "Luigi Lo", ""]]}, {"id": "2105.12479", "submitter": "Celia Cintas", "authors": "Celia Cintas, Skyler Speakman, Girmaw Abebe Tadesse, Victor Akinwande,\n  Edward McFowland III, Komminist Weldemariam", "title": "Pattern Detection in the Activation Space for Identifying Synthesized\n  Content", "comments": "The paper is under consideration at Pattern Recognition Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative Adversarial Networks (GANs) have recently achieved unprecedented\nsuccess in photo-realistic image synthesis from low-dimensional random noise.\nThe ability to synthesize high-quality content at a large scale brings\npotential risks as the generated samples may lead to misinformation that can\ncreate severe social, political, health, and business hazards. We propose\nSubsetGAN to identify generated content by detecting a subset of anomalous\nnode-activations in the inner layers of pre-trained neural networks. These\nnodes, as a group, maximize a non-parametric measure of divergence away from\nthe expected distribution of activations created from real data. This enable us\nto identify synthesised images without prior knowledge of their distribution.\nSubsetGAN efficiently scores subsets of nodes and returns the group of nodes\nwithin the pre-trained classifier that contributed to the maximum score. The\nclassifier can be a general fake classifier trained over samples from multiple\nsources or the discriminator network from different GANs. Our approach shows\nconsistently higher detection power than existing detection methods across\nseveral state-of-the-art GANs (PGGAN, StarGAN, and CycleGAN) and over different\nproportions of generated content.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 11:28:36 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 08:40:27 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Cintas", "Celia", ""], ["Speakman", "Skyler", ""], ["Tadesse", "Girmaw Abebe", ""], ["Akinwande", "Victor", ""], ["McFowland", "Edward", "III"], ["Weldemariam", "Komminist", ""]]}, {"id": "2105.12508", "submitter": "Francesco Croce", "authors": "Francesco Croce, Matthias Hein", "title": "Adversarial robustness against multiple $l_p$-threat models at the price\n  of one and how to quickly fine-tune robust models to another threat model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training (AT) in order to achieve adversarial robustness wrt\nsingle $l_p$-threat models has been discussed extensively. However, for\nsafety-critical systems adversarial robustness should be achieved wrt all\n$l_p$-threat models simultaneously. In this paper we develop a simple and\nefficient training scheme to achieve adversarial robustness against the union\nof $l_p$-threat models. Our novel $l_1+l_\\infty$-AT scheme is based on\ngeometric considerations of the different $l_p$-balls and costs as much as\nnormal adversarial training against a single $l_p$-threat model. Moreover, we\nshow that using our $l_1+l_\\infty$-AT scheme one can fine-tune with just 3\nepochs any $l_p$-robust model (for $p \\in \\{1,2,\\infty\\}$) and achieve multiple\nnorm adversarial robustness. In this way we boost the previous state-of-the-art\nreported for multiple-norm robustness by more than $6\\%$ on CIFAR-10 and report\nup to our knowledge the first ImageNet models with multiple norm robustness.\nMoreover, we study the general transfer of adversarial robustness between\ndifferent threat models and in this way boost the previous SOTA\n$l_1$-robustness on CIFAR-10 by almost $10\\%$.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 12:20:47 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Croce", "Francesco", ""], ["Hein", "Matthias", ""]]}, {"id": "2105.12581", "submitter": "Xing Li", "authors": "Xing Li, Xue Leng, Yan Chen", "title": "Securing Serverless Computing: Challenges, Solutions, and Opportunities", "comments": "7 pages, 3 figures, submitted to IEEE Network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Serverless computing is a new cloud service model that reduces both cloud\nproviders' and consumers' costs through extremely agile development, operation,\nand charging mechanisms and has been widely applied since its emergence.\nNevertheless, some characteristics of serverless computing, such as fragmented\napplication boundaries, have raised new security challenges. Considerable\nliterature work has been committed to addressing these challenges. Commercial\nand open-source serverless platforms implement many security measures to\nenhance serverless environments. This paper presents the first survey of\nserverless security that considers both literature work and industrial security\nmeasures. We summarize the primary security challenges, analyze corresponding\nsolutions from the literature and industry, and identify potential research\nopportunities. Then, we conduct a gap analysis of the academic and industrial\nsolutions as well as commercial and open-source serverless platforms' security\ncapabilities, and finally, we present a complete picture of current serverless\nsecurity research.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 11:46:17 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Li", "Xing", ""], ["Leng", "Xue", ""], ["Chen", "Yan", ""]]}, {"id": "2105.12592", "submitter": "Christiana Chamon", "authors": "Christiana Chamon and Laszlo Kish", "title": "Perspective -- On the thermodynamics of perfect unconditional security", "comments": null, "journal-ref": null, "doi": "10.1063/5.0057764", "report-no": null, "categories": "quant-ph cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A secure key distribution (exchange) scheme is unconditionally secure if it\nis unbreakable against arbitrary technological improvements of computing power\nand/or any development of new algorithms. There are only two families of\nexperimentally realized and tested unconditionally secure key distribution\ntechnologies: Quantum Key Distribution (QKD), the base of quantum cryptography,\nwhich utilizes quantum physical photonic features; and the\nKirchhoff-Law-Johnson-Noise (KLJN) system that is based on classical\nstatistical physics (fluctuation-dissipation theorem). The focus topic of this\npaper is the thermodynamical situation of the KLJN system. In all the original\nworks, the proposed KLJN schemes required thermal equilibrium between the\ndevices of the communicating parties to achieve perfect security. However,\nVadai, et al, in (Nature) Science Reports 5 (2015) 13653 shows a modified\nscheme, where there is a non-zero thermal noise energy flow between the\nparties, yet the system seems to resist all the known attack types. We\nintroduce a new attack type against their system. The new attack utilizes\ncoincidence events between the line current and voltages. We show that there is\nnon-zero information leak toward the Eavesdropper, even under idealized\nconditions. As soon as the thermal equilibrium is restored, the system becomes\nperfectly secure again. In conclusion, perfect unconditional security requires\nthermal equilibrium.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 14:50:04 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Chamon", "Christiana", ""], ["Kish", "Laszlo", ""]]}, {"id": "2105.12613", "submitter": "Tushar M. Jois", "authors": "Maximilian Zinkus, Tushar M. Jois, Matthew Green (Johns Hopkins\n  University)", "title": "Data Security on Mobile Devices: Current State of the Art, Open\n  Problems, and Proposed Solutions", "comments": "Please see https://securephones.io/ for the project's website", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present definitive evidence, analysis, and (where needed)\nspeculation to answer the questions, (1) Which concrete security measures in\nmobile devices meaningfully prevent unauthorized access to user data? (2) In\nwhat ways are modern mobile devices accessed by unauthorized parties? (3) How\ncan we improve modern mobile devices to prevent unauthorized access?\n  We examine the two major platforms in the mobile space, iOS and Android, and\nfor each we provide a thorough investigation of existing and historical\nsecurity features, evidence-based discussion of known security bypass\ntechniques, and concrete recommendations for remediation. We then aggregate and\nanalyze public records, documentation, articles, and blog postings to\ncategorize and discuss unauthorized bypass of security features by hackers and\nlaw enforcement alike. We provide in-depth analysis of the data potentially\naccessed via law enforcement methodologies from both mobile devices and\nassociated cloud services.\n  Our fact-gathering and analysis allow us to make a number of recommendations\nfor improving data security on these devices. The mitigations we propose can be\nlargely summarized as increasing coverage of sensitive data via strong\nencryption, but we detail various challenges and approaches towards this goal\nand others. It is our hope that this work stimulates mobile device development\nand research towards security and privacy, provides a unique reference of\ninformation, and acts as an evidence-based argument for the importance of\nreliable encryption to privacy, which we believe is both a human right and\nintegral to a functioning democracy.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 15:08:42 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Zinkus", "Maximilian", "", "Johns Hopkins\n  University"], ["Jois", "Tushar M.", "", "Johns Hopkins\n  University"], ["Green", "Matthew", "", "Johns Hopkins\n  University"]]}, {"id": "2105.12615", "submitter": "Jonathan Hehir", "authors": "Jonathan Hehir, Aleksandra Slavkovic, Xiaoyue Niu", "title": "Consistency of Privacy-Preserving Spectral Clustering under the\n  Stochastic Block Model", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CR cs.SI stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic block model (SBM) -- a network model featuring community\nstructure -- is often selected as the fundamental setting in which to analyze\nthe theoretical properties of community detection methods. We consider the\nproblem of privacy-preserving spectral clustering of SBMs under\n$\\varepsilon$-edge differential privacy (DP) for networks, and offer practical\ninterpretations from both the central-DP and local-DP perspectives. Using a\nrandomized response privacy mechanism called the edge-flip mechanism, we take a\nfirst step toward theoretical analysis of differentially private community\ndetection by demonstrating conditions under which this strong privacy guarantee\ncan be upheld while achieving spectral clustering convergence rates that match\nthe known rates without privacy. We prove the strongest theoretical results are\nachievable for dense networks (those with node degree linear in the number of\nnodes), while weak consistency is achievable under mild sparsity (node degree\ngreater than $n^{-1/2}$). We empirically demonstrate our results on a number of\nnetwork examples.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 15:09:46 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Hehir", "Jonathan", ""], ["Slavkovic", "Aleksandra", ""], ["Niu", "Xiaoyue", ""]]}, {"id": "2105.12697", "submitter": "Matej Zecevic", "authors": "Matej Ze\\v{c}evi\\'c, Devendra Singh Dhami and Kristian Kersting", "title": "Intriguing Parameters of Structural Causal Models", "comments": "Main paper: 9 pages, References: 2 pages, Supplement: 2 pages. Main\n  paper: 3 figures, Supplement: 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years there has been a lot of focus on adversarial attacks,\nespecially on deep neural networks. Here, we argue that they are more general\nin nature and can easily affect a larger class of models, e.g., any\ndifferentiable perturbed optimizers. We further show that such attacks can be\ndetermined by the hidden confounders in a domain, thus drawing a novel\nconnection between such attacks and causality. Establishing this causal\nperspective is characterized by the influence of the structural causal model's\ndata generating process on the subsequent optimization thereby exhibiting\nintriguing parameters of the former. We reveal the existence of such parameters\nfor three combinatorial optimization problems, namely linear assignment,\nshortest path and a real world problem of energy systems. Our empirical\nexamination also unveils worrisome consequences of these attacks on\ndifferentiable perturbed optimizers thereby highlighting the criticality of our\nfindings.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 17:19:22 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 09:13:12 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Ze\u010devi\u0107", "Matej", ""], ["Dhami", "Devendra Singh", ""], ["Kersting", "Kristian", ""]]}, {"id": "2105.12790", "submitter": "Javad Doliskani", "authors": "Javad Doliskani", "title": "Efficient Quantum Public-Key Encryption From Learning With Errors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Our main result is a quantum public-key encryption scheme based on the\nExtrapolated Dihedral Coset problem (EDCP) which is equivalent, under quantum\npolynomial-time reductions, to the Learning With Errors (LWE) problem. For\nlimited number of public keys (roughly linear in the security parameter), the\nproposed scheme is information-theoretically secure. For polynomial number of\npublic keys, breaking the scheme is as hard as solving the LWE problem. The\npublic keys in our scheme are quantum states of size $\\tilde{O}(n)$ qubits. The\nkey generation and decryption algorithms require $\\tilde{O}(n)$ qubit\noperations while the encryption algorithm takes $O(1)$ qubit operations.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 18:48:26 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Doliskani", "Javad", ""]]}, {"id": "2105.12935", "submitter": "Yunfei Meng", "authors": "Yunfei Meng and Zhiqiu Huang and Guohua Shen and Changbo Ke", "title": "SDN-based Runtime Security Enforcement Approach for Privacy Preservation\n  of Dynamic Web Service Composition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Aiming at the privacy preservation of dynamic Web service composition, this\npaper proposes a SDN-based runtime security enforcement approach for privacy\npreservation of dynamic Web service composition. The main idea of this approach\nis that the owner of service composition leverages the security policy model\n(SPM) to define the access control relationships that service composition must\ncomply with in the application plane, then SPM model is transformed into the\nlow-level security policy model (RSPM) containing the information of SDN data\nplane, and RSPM model is uploaded into the SDN controller. After uploading, the\nvirtual machine access control algorithm integrated in the SDN controller\nmonitors all of access requests towards service composition at runtime. Only\nthe access requests that meet the definition of RSPM model can be forwarded to\nthe target terminal. Any access requests that do not meet the definition of\nRSPM model will be automatically blocked by Openflow switches or deleted by SDN\ncontroller, Thus, this approach can effectively solve the problems of\nnetwork-layer illegal accesses, identity theft attacks and service leakages\nwhen Web service composition is running. In order to verify the feasibility of\nthis approach, this paper implements an experimental system by using POX\ncontroller and Mininet virtual network simulator, and evaluates the\neffectiveness and performance of this approach by using this system. The final\nexperimental results show that the method is completely effective, and the\nmethod can always get the correct calculation results in an acceptable time\nwhen the scale of RSPM model is gradually increasing.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 04:10:11 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Meng", "Yunfei", ""], ["Huang", "Zhiqiu", ""], ["Shen", "Guohua", ""], ["Ke", "Changbo", ""]]}, {"id": "2105.13114", "submitter": "Walt Woods", "authors": "Walt Woods", "title": "RL-GRIT: Reinforcement Learning for Grammar Inference", "comments": "13 pages, published at IEEE LangSec 2021\n  (https://langsec.org/spw21/papers.html). ArXiv version: lacking correct\n  'minted' package behavior, so some atoms may look a little off", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When working to understand usage of a data format, examples of the data\nformat are often more representative than the format's specification. For\nexample, two different applications might use very different JSON\nrepresentations, or two PDF-writing applications might make use of very\ndifferent areas of the PDF specification to realize the same rendered content.\nThe complexity arising from these distinct origins can lead to large,\ndifficult-to-understand attack surfaces, presenting a security concern when\nconsidering both exfiltration and data schizophrenia. Grammar inference can aid\nin describing the practical language generator behind examples of a data\nformat. However, most grammar inference research focuses on natural language,\nnot data formats, and fails to support crucial features such as type recursion.\nWe propose a novel set of mechanisms for grammar inference, RL-GRIT, and apply\nthem to understanding de facto data formats. After reviewing existing grammar\ninference solutions, it was determined that a new, more flexible scaffold could\nbe found in Reinforcement Learning (RL). Within this work, we lay out the many\nalgorithmic changes required to adapt RL from its traditional, sequential-time\nenvironment to the highly interdependent environment of parsing. The result is\nan algorithm which can demonstrably learn recursive control structures in\nsimple data formats, and can extract meaningful structure from fragments of the\nPDF format. Whereas prior work in grammar inference focused on either regular\nlanguages or constituency parsing, we show that RL can be used to surpass the\nexpressiveness of both classes, and offers a clear path to learning\ncontext-sensitive languages. The proposed algorithm can serve as a building\nblock for understanding the ecosystems of de facto data formats.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 23:48:39 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Woods", "Walt", ""]]}, {"id": "2105.13144", "submitter": "Varun Chandrasekaran", "authors": "Varun Chandrasekaran, Darren Edge, Somesh Jha, Amit Sharma, Cheng\n  Zhang, Shruti Tople", "title": "Causally Constrained Data Synthesis for Private Data Release", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making evidence based decisions requires data. However for real-world\napplications, the privacy of data is critical. Using synthetic data which\nreflects certain statistical properties of the original data preserves the\nprivacy of the original data. To this end, prior works utilize differentially\nprivate data release mechanisms to provide formal privacy guarantees. However,\nsuch mechanisms have unacceptable privacy vs. utility trade-offs. We propose\nincorporating causal information into the training process to favorably modify\nthe aforementioned trade-off. We theoretically prove that generative models\ntrained with additional causal knowledge provide stronger differential privacy\nguarantees. Empirically, we evaluate our solution comparing different models\nbased on variational auto-encoders (VAEs), and show that causal information\nimproves resilience to membership inference, with improvements in downstream\nutility.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 13:46:57 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Chandrasekaran", "Varun", ""], ["Edge", "Darren", ""], ["Jha", "Somesh", ""], ["Sharma", "Amit", ""], ["Zhang", "Cheng", ""], ["Tople", "Shruti", ""]]}, {"id": "2105.13287", "submitter": "Dung Nguyen", "authors": "Dung Nguyen and Anil Vullikanti", "title": "Differentially Private Densest Subgraph Detection", "comments": "Accepted by ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Densest subgraph detection is a fundamental graph mining problem, with a\nlarge number of applications. There has been a lot of work on efficient\nalgorithms for finding the densest subgraph in massive networks. However, in\nmany domains, the network is private, and returning a densest subgraph can\nreveal information about the network. Differential privacy is a powerful\nframework to handle such settings. We study the densest subgraph problem in the\nedge privacy model, in which the edges of the graph are private. We present the\nfirst sequential and parallel differentially private algorithms for this\nproblem. We show that our algorithms have an additive approximation guarantee.\nWe evaluate our algorithms on a large number of real-world networks, and\nobserve a good privacy-accuracy tradeoff when the network has high density.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 16:36:03 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 17:33:02 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Nguyen", "Dung", ""], ["Vullikanti", "Anil", ""]]}, {"id": "2105.13289", "submitter": "Li Yang", "authors": "Li Yang, Abdallah Moubayed, Abdallah Shami", "title": "MTH-IDS: A Multi-Tiered Hybrid Intrusion Detection System for Internet\n  of Vehicles", "comments": "Accepted and to appear in IEEE Internet of Things Journal; Code is\n  available at Github link:\n  https://github.com/Western-OC2-Lab/Intrusion-Detection-System-Using-Machine-Learning", "journal-ref": null, "doi": "10.1109/JIOT.2021.3084796", "report-no": null, "categories": "cs.CR cs.AI cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern vehicles, including connected vehicles and autonomous vehicles,\nnowadays involve many electronic control units connected through intra-vehicle\nnetworks to implement various functionalities and perform actions. Modern\nvehicles are also connected to external networks through vehicle-to-everything\ntechnologies, enabling their communications with other vehicles,\ninfrastructures, and smart devices. However, the improving functionality and\nconnectivity of modern vehicles also increase their vulnerabilities to\ncyber-attacks targeting both intra-vehicle and external networks due to the\nlarge attack surfaces. To secure vehicular networks, many researchers have\nfocused on developing intrusion detection systems (IDSs) that capitalize on\nmachine learning methods to detect malicious cyber-attacks. In this paper, the\nvulnerabilities of intra-vehicle and external networks are discussed, and a\nmulti-tiered hybrid IDS that incorporates a signature-based IDS and an\nanomaly-based IDS is proposed to detect both known and unknown attacks on\nvehicular networks. Experimental results illustrate that the proposed system\ncan detect various types of known attacks with 99.99% accuracy on the\nCAN-intrusion-dataset representing the intra-vehicle network data and 99.88%\naccuracy on the CICIDS2017 dataset illustrating the external vehicular network\ndata. For the zero-day attack detection, the proposed system achieves high\nF1-scores of 0.963 and 0.800 on the above two datasets, respectively. The\naverage processing time of each data packet on a vehicle-level machine is less\nthan 0.6 ms, which shows the feasibility of implementing the proposed system in\nreal-time vehicle systems. This emphasizes the effectiveness and efficiency of\nthe proposed IDS.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 17:36:35 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Yang", "Li", ""], ["Moubayed", "Abdallah", ""], ["Shami", "Abdallah", ""]]}, {"id": "2105.13347", "submitter": "Zhiyuan Yu", "authors": "Zhiyuan Yu, Zack Kaplan, Qiben Yan, Ning Zhang", "title": "Security and Privacy in the Emerging Cyber-Physical World: A Survey", "comments": "Accepted by IEEE Communications Surveys & Tutorials (2021)", "journal-ref": null, "doi": "10.1109/COMST.2021.3081450", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emergence of low-cost smart and connected IoT devices, the area of\ncyber-physical security is becoming increasingly important. Past research has\ndemonstrated new threat vectors targeting the transition process between the\ncyber and physical domains, where the attacker exploits the sensing system as\nan attack surface for signal injection or extraction of private information.\nRecently, there have been attempts to characterize an abstracted model for\nsignal injection, but they primarily focus on the path of signal processing.\nThis paper aims to systematize the existing research on security and privacy\nproblems arising from the interaction of cyber world and physical world, with\nthe context of broad CPS applications. The primary goals of the systematization\nare to (1) reveal the attack patterns and extract a general attack model of\nexisting work, (2) understand possible new attacks, and (3) motivate\ndevelopment of defenses against the emerging cyber-physical threats.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 17:52:17 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Yu", "Zhiyuan", ""], ["Kaplan", "Zack", ""], ["Yan", "Qiben", ""], ["Zhang", "Ning", ""]]}, {"id": "2105.13418", "submitter": "Masoumeh Shafieinejad", "authors": "Masoumeh Shafieinejad and Huseyin Inan and Marcello Hasegawa and\n  Robert Sim", "title": "On Privacy and Confidentiality of Communications in Organizational\n  Graphs", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learned models trained on organizational communication data, such as\nemails in an enterprise, carry unique risks of breaching confidentiality, even\nif the model is intended only for internal use. This work shows how\nconfidentiality is distinct from privacy in an enterprise context, and aims to\nformulate an approach to preserving confidentiality while leveraging principles\nfrom differential privacy. The goal is to perform machine learning tasks, such\nas learning a language model or performing topic analysis, using interpersonal\ncommunications in the organization, while not learning about confidential\ninformation shared in the organization. Works that apply differential privacy\ntechniques to natural language processing tasks usually assume independently\ndistributed data, and overlook potential correlation among the records.\nIgnoring this correlation results in a fictional promise of privacy. Naively\nextending differential privacy techniques to focus on group privacy instead of\nrecord-level privacy is a straightforward approach to mitigate this issue. This\napproach, although providing a more realistic privacy-guarantee, is\nover-cautious and severely impacts model utility. We show this gap between\nthese two extreme measures of privacy over two language tasks, and introduce a\nmiddle-ground solution. We propose a model that captures the correlation in the\nsocial network graph, and incorporates this correlation in the privacy\ncalculations through Pufferfish privacy principles.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 19:45:56 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Shafieinejad", "Masoumeh", ""], ["Inan", "Huseyin", ""], ["Hasegawa", "Marcello", ""], ["Sim", "Robert", ""]]}, {"id": "2105.13435", "submitter": "Wadii Boulila Prof.", "authors": "Kathryn-Ann Tait, Jan Sher Khan, Fehaid Alqahtani, Awais Aziz Shah,\n  Fadia Ali Khan, Mujeeb Ur Rehman, Wadii Boulila, Jawad Ahmad", "title": "Intrusion Detection using Machine Learning Techniques: An Experimental\n  Comparison", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to an exponential increase in the number of cyber-attacks, the need for\nimproved Intrusion Detection Systems (IDS) is apparent than ever. In this\nregard, Machine Learning (ML) techniques are playing a pivotal role in the\nearly classification of the attacks in case of intrusion detection within the\nsystem. However, due to a large number of algorithms available, the selection\nof the right method is a challenging task. To resolve this issue, this paper\nanalyses some of the current state-of-the-art intrusion detection methods and\ndiscusses their pros and cons. Further, a review of different ML methods is\ncarried out with four methods showing to be the most suitable one for\nclassifying attacks. Several algorithms are selected and investigated to\nevaluate the performance of IDS. These IDS classifies binary and multiclass\nattacks in terms of detecting whether or not the traffic has been considered as\nbenign or an attack. The experimental results demonstrate that binary\nclassification has greater consistency in their accuracy results which ranged\nfrom 0.9938 to 0.9977, while multiclass ranges from 0.9294 to 0.9983. However,\nit has been also observed that multiclass provides the best results with the\nalgorithm k-Nearest neighbor giving an accuracy score of 0.9983 while the\nbinary classification highest score is 0.9977 from Random Forest. The\nexperimental results demonstrate that multiclass classification produces better\nperformance in terms of intrusion detection by specifically differentiating\nbetween the attacks and allowing a more targeted response to an attack.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 20:21:28 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Tait", "Kathryn-Ann", ""], ["Khan", "Jan Sher", ""], ["Alqahtani", "Fehaid", ""], ["Shah", "Awais Aziz", ""], ["Khan", "Fadia Ali", ""], ["Rehman", "Mujeeb Ur", ""], ["Boulila", "Wadii", ""], ["Ahmad", "Jawad", ""]]}, {"id": "2105.13442", "submitter": "Grant Ho", "authors": "Grant Ho, Mayank Dhiman, Devdatta Akhawe, Vern Paxson, Stefan Savage,\n  Geoffrey M. Voelker, David Wagner", "title": "Hopper: Modeling and Detecting Lateral Movement (Extended Report)", "comments": "Usenix Security Symposium 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In successful enterprise attacks, adversaries often need to gain access to\nadditional machines beyond their initial point of compromise, a set of internal\nmovements known as lateral movement. We present Hopper, a system for detecting\nlateral movement based on commonly available enterprise logs. Hopper constructs\na graph of login activity among internal machines and then identifies\nsuspicious sequences of loginsthat correspond to lateral movement. To\nunderstand the larger context of each login, Hopper employs an inference\nalgorithm to identify the broader path(s) of movement that each login belongs\nto and the causal user responsible for performing a path's logins. Hopper then\nleverages this path inference algorithm, in conjunction with a set of detection\nrules and a new anomaly scoring algorithm, to surface the login paths most\nlikely to reflect lateral movement. On a 15-month enterprise dataset consisting\nof over 780 million internal logins, Hop-per achieves a 94.5% detection rate\nacross over 300 realistic attack scenarios, including one red team attack,\nwhile generating an average of <9 alerts per day. In contrast, to detect the\nsame number of attacks, prior state-of-the-art systems would need to generate\nnearly 8x as many false positives.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 20:37:56 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Ho", "Grant", ""], ["Dhiman", "Mayank", ""], ["Akhawe", "Devdatta", ""], ["Paxson", "Vern", ""], ["Savage", "Stefan", ""], ["Voelker", "Geoffrey M.", ""], ["Wagner", "David", ""]]}, {"id": "2105.13487", "submitter": "Andrea Flamini", "authors": "Andrea Flamini, Riccardo Longo, Alessio Meneghetti", "title": "Multidimensional Byzantine Agreement in a Synchronous Setting", "comments": "15 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we will present the Multidimensional Byzantine Agreement (MBA)\nProtocol, a leaderless Byzantine agreement protocol defined for complete and\nsynchronous networks that allows a network of nodes to reach consensus on a\nvector of relevant information regarding a set of observed events.\n  The consensus process is carried out in parallel on each component, and the\noutput is a vector whose components are either values with wide agreement in\nthe network (even if no individual node agrees on every value) or a special\nvalue $\\bot$ that signals irreconcilable disagreement. The MBA Protocol is\nprobabilistic and its execution halts with probability 1, and the number of\nsteps necessary to halt follows a Bernoulli-like distribution.\n  The design combines a Multidimensional Graded Consensus and a\nMultidimensional Binary Byzantine Agreement, the generalization to the\nmultidimensional case of two protocols by Micali and Feldman.\n  We prove the correctness and security of the protocol assuming a synchronous\nnetwork where less than a third of the nodes are malicious.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 22:51:10 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 14:59:26 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Flamini", "Andrea", ""], ["Longo", "Riccardo", ""], ["Meneghetti", "Alessio", ""]]}, {"id": "2105.13491", "submitter": "ElMouatez Billah Karbab", "authors": "ElMouatez Billah Karbab, Mourad Debbabi", "title": "Resilient and Adaptive Framework for Large Scale Android Malware\n  Fingerprinting using Deep Learning and NLP Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android malware detection is a significat problem that affects billions of\nusers using millions of Android applications (apps) in existing markets. This\npaper proposes PetaDroid, a framework for accurate Android malware detection\nand family clustering on top of static analyses. PetaDroid automatically adapts\nto Android malware and benign changes over time with resilience to common\nbinary obfuscation techniques. The framework employs novel techniques\nelaborated on top of natural language processing (NLP) and machine learning\ntechniques to achieve accurate, adaptive, and resilient Android malware\ndetection and family clustering. PetaDroid identifies malware using an ensemble\nof convolutional neural network (CNN) on proposed Inst2Vec features. The\nframework clusters the detected malware samples into malware family groups\nutilizing sample feature digests generated using deep neural auto-encoder. For\nchange adaptation, PetaDroid leverages the detection confidence probability\nduring deployment to automatically collect extension datasets and periodically\nuse them to build new malware detection models. Besides, PetaDroid uses\ncode-fragment randomization during the training to enhance the resiliency to\ncommon obfuscation techniques. We extensively evaluated PetaDroid on multiple\nreference datasets. PetaDroid achieved a high detection rate (98-99% f1-score)\nunder different evaluation settings with high homogeneity in the produced\nclusters (96%). We conducted a thorough quantitative comparison with\nstate-of-the-art solutions MaMaDroid, DroidAPIMiner, MalDozer, in which\nPetaDroid outperforms them under all the evaluation settings.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 22:57:55 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Karbab", "ElMouatez Billah", ""], ["Debbabi", "Mourad", ""]]}, {"id": "2105.13518", "submitter": "Jun Zhang", "authors": "Bing Bai, Jianyao Huang, Guan-Ru Qiao, You-Qi Nie, Weijie Tang, Tao\n  Chu, Jun Zhang, and Jian-Wei Pan", "title": "18.8 Gbps real-time quantum random number generator with a photonic\n  integrated chip", "comments": "5 pages, 4 figures. Accepted for publication in Applied Physics\n  Letters", "journal-ref": "Appl. Phys. Lett. 118, 264001 (2021)", "doi": "10.1063/5.0056027", "report-no": null, "categories": "quant-ph cs.CR physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum random number generators (QRNGs) can produce true random numbers.\nYet, the two most important QRNG parameters highly desired for practical\napplications, i.e., speed and size, have to be compromised during\nimplementations. Here, we present the fastest and miniaturized QRNG with a\nrecord real-time output rate as high as 18.8 Gbps by combining a photonic\nintegrated chip and the technology of optimized randomness extraction. We\nassemble the photonic integrated circuit designed for vacuum state QRNG\nimplementation, InGaAs homodyne detector and high-bandwidth transimpedance\namplifier into a single chip using hybrid packaging, which exhibits the\nexcellent characteristics of integration and high-frequency response. With a\nsample rate of 2.5 GSa/s in a 10-bit analog-to-digital converter and subsequent\nparalleled postprocessing in a field programmable gate array, the QRNG outputs\nultrafast random bitstreams via a fiber optic transceiver, whose real-time\nspeed is validated in a personal computer.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 00:30:43 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Bai", "Bing", ""], ["Huang", "Jianyao", ""], ["Qiao", "Guan-Ru", ""], ["Nie", "You-Qi", ""], ["Tang", "Weijie", ""], ["Chu", "Tao", ""], ["Zhang", "Jun", ""], ["Pan", "Jian-Wei", ""]]}, {"id": "2105.13530", "submitter": "George Kesidis", "authors": "Xi Li, David J. Miller, Zhen Xiang, George Kesidis", "title": "A BIC based Mixture Model Defense against Data Poisoning Attacks on\n  Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data Poisoning (DP) is an effective attack that causes trained classifiers to\nmisclassify their inputs.DP attacks significantly degrade a classifier's\naccuracy by covertly injecting attack samples into the training set. Broadly\napplicable to different classifier structures, without strong assumptions about\nthe attacker, we herein propose a novel Bayesian Information Criterion\n(BIC)-based mixture model defense against DP attacks that: 1) applies a mixture\nmodel both to well-fit potentially multi-modal class distributions and to\ncapture adversarial samples within a small subset of mixture components; 2)\njointly identifies poisoned components and samples by minimizing the BIC cost\nover all classes, with the identified poisoned data removed prior to classifier\ntraining. Our experimental results, for various classifier structures,\ndemonstrate the effectiveness and universality of our defense under strong DP\nattacks, as well as the superiority over other works.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 01:06:09 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Li", "Xi", ""], ["Miller", "David J.", ""], ["Xiang", "Zhen", ""], ["Kesidis", "George", ""]]}, {"id": "2105.13592", "submitter": "Asm Rizvi", "authors": "ASM Rizvi and John Heidemann", "title": "Chhoyhopper: A Moving Target Defense with IPv6", "comments": "3 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Services on the public Internet are frequently scanned, then subject to\nbrute-force and denial-of-service attacks. We would like to run such services\nstealthily, available to friends but hidden from adversaries. In this work, we\npropose a moving target defense named \"Chhoyhopper\" that utilizes the vast IPv6\naddress space to conceal publicly available services. The client and server to\nhop to different IPv6 addresses in a pattern based on a shared, pre-distributed\nsecret and the time-of-day. By hopping over a /64 prefix, services cannot be\nfound by active scanners, and passively observed information is useless after\ntwo minutes. We demonstrate our system with SSH, and show that it can be\nextended to other applications.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 05:18:49 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Rizvi", "ASM", ""], ["Heidemann", "John", ""]]}, {"id": "2105.13634", "submitter": "Eman Alashwali", "authors": "Eman Alashwali and Fatimah Alashwali", "title": "Saudi Parents' Security and Privacy Concerns about their Children's\n  Smart Device Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we investigate Saudi parents' security and privacy concerns\nregarding their children's smart device applications (apps). To this end, we\nconducted a survey and analysed 119 responses. Our results show that Saudi\nparents expressed a high level of concern regarding their children's security\nand privacy when using smart device apps. However, they expressed higher\nconcerns about apps' content than privacy issues such as apps' requests to\naccess sensitive data. Furthermore, parents' concerns are not in line with most\nof the children's installed apps, which contain apps inappropriate for their\nage, require parental guidance, and request access to sensitive data such as\nlocation. We also compare Saudi parents' practices and concerns with those\nreported by Western (mainly from the UK) and Chinese parents in previous\nreports. We find interesting patterns and establish new relationships.\nFurthermore, Saudi and Western parents show higher levels of privacy concerns\nthan Chinese parents. The low level of privacy concerns expressed by Chinese\nparents even after being informed about possible privacy implications could be\nrelated cultural or political reasons. Finally, we tested 14 security and\nprivacy practices and concerns against high vs. low socioeconomic classes\n(parents' education, technical background, and income) to find whether there\nare significant differences between high and low classes. Out of 42 tests (14\nproperties x 3 classes) we find significant differences between high and low\nclasses in 7 tests only. While this is a positive trend overall, it is\nimportant to work on bridging these gaps. The results of this paper provide key\nfindings to identify areas of improvements and recommendations, especially for\nSaudis, which can be used by parents, developers, researchers, regulators, and\npolicy makers.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 07:20:50 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Alashwali", "Eman", ""], ["Alashwali", "Fatimah", ""]]}, {"id": "2105.13637", "submitter": "Zhou Lu", "authors": "Daogao Liu, Zhou Lu", "title": "Curse of Dimensionality in Unconstrained Private Convex ERM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the lower bounds of differentially private empirical risk\nminimization for general convex functions in this paper. For convex generalized\nlinear models (GLMs), the well-known tight bound of DP-ERM in the constrained\ncase is $\\tilde{\\Theta}(\\frac{\\sqrt{p}}{\\epsilon n})$, while recently,\n\\cite{sstt21} find the tight bound of DP-ERM in the unconstrained case is\n$\\tilde{\\Theta}(\\frac{\\sqrt{\\text{rank}}}{\\epsilon n})$ where $p$ is the\ndimension, $n$ is the sample size and $\\text{rank}$ is the rank of the feature\nmatrix of the GLM objective function. As $\\text{rank}\\leq \\min\\{n,p\\}$, a\nnatural and important question arises that whether we can evade the curse of\ndimensionality for over-parameterized models where $n\\ll p$, for more general\nconvex functions beyond GLM. We answer this question negatively by giving the\nfirst and tight lower bound of unconstrained private ERM for the general convex\nfunction, matching the current upper bound\n$\\tilde{O}(\\frac{\\sqrt{p}}{n\\epsilon})$ for unconstrained private ERM. We also\ngive an $\\Omega(\\frac{p}{n\\epsilon})$ lower bound for unconstrained pure-DP ERM\nwhich recovers the result in the constrained case.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 07:28:24 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Liu", "Daogao", ""], ["Lu", "Zhou", ""]]}, {"id": "2105.13678", "submitter": "Qiong Li", "authors": "Yan Bingze, Li Qiong, Mao Haokun and Chen Nan", "title": "An efficient hybrid hash based privacy amplification algorithm for\n  quantum key distribution", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Privacy amplification (PA) is an essential part in a quantum key distribution\n(QKD) system, distilling a highly secure key from a partially secure string by\npublic negotiation between two parties. The optimization objectives of privacy\namplification for QKD are large block size, high throughput and low cost. For\nthe global optimization of these objectives, a novel privacy amplification\nalgorithm is proposed in this paper by combining multilinear-modular-hashing\nand modular arithmetic hashing. This paper proves the security of this hybrid\nhashing PA algorithm within the framework of both information theory and\ncomposition security theory. A scheme based on this algorithm is implemented\nand evaluated on a CPU platform. The results on a typical CV-QKD system\nindicate that the throughput of this scheme (261Mbps@2.6*10^8 input block size)\nis twice higher than the best existing scheme (140Mbps@1*10^8 input block\nsize). Moreover, This scheme is implemented on a mobile CPU platform instead of\na desktop CPU or a server CPU, which means that this algorithm has a better\nperformance with a much lower cost and power consumption.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 08:57:06 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 12:17:12 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Bingze", "Yan", ""], ["Qiong", "Li", ""], ["Haokun", "Mao", ""], ["Nan", "Chen", ""]]}, {"id": "2105.13697", "submitter": "Mingfu Xue", "authors": "Mingfu Xue, Zhiyu Wu, Jian Wang, Yushu Zhang, Weiqiang Liu", "title": "AdvParams: An Active DNN Intellectual Property Protection Technique via\n  Adversarial Perturbation Based Parameter Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A well-trained DNN model can be regarded as an intellectual property (IP) of\nthe model owner. To date, many DNN IP protection methods have been proposed,\nbut most of them are watermarking based verification methods where model owners\ncan only verify their ownership passively after the copyright of DNN models has\nbeen infringed. In this paper, we propose an effective framework to actively\nprotect the DNN IP from infringement. Specifically, we encrypt the DNN model's\nparameters by perturbing them with well-crafted adversarial perturbations. With\nthe encrypted parameters, the accuracy of the DNN model drops significantly,\nwhich can prevent malicious infringers from using the model. After the\nencryption, the positions of encrypted parameters and the values of the added\nadversarial perturbations form a secret key. Authorized user can use the secret\nkey to decrypt the model. Compared with the watermarking methods which only\npassively verify the ownership after the infringement occurs, the proposed\nmethod can prevent infringement in advance. Moreover, compared with most of the\nexisting active DNN IP protection methods, the proposed method does not require\nadditional training process of the model, which introduces low computational\noverhead. Experimental results show that, after the encryption, the test\naccuracy of the model drops by 80.65%, 81.16%, and 87.91% on Fashion-MNIST,\nCIFAR-10, and GTSRB, respectively. Moreover, the proposed method only needs to\nencrypt an extremely low number of parameters, and the proportion of the\nencrypted parameters of all the model's parameters is as low as 0.000205%. The\nexperimental results also indicate that, the proposed method is robust against\nmodel fine-tuning attack and model pruning attack. Moreover, for the adaptive\nattack where attackers know the detailed steps of the proposed method, the\nproposed method is also demonstrated to be robust.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 09:42:35 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Xue", "Mingfu", ""], ["Wu", "Zhiyu", ""], ["Wang", "Jian", ""], ["Zhang", "Yushu", ""], ["Liu", "Weiqiang", ""]]}, {"id": "2105.13698", "submitter": "Fan Huang", "authors": "Fan Huang", "title": "Network Activities Recognition and Analysis Based on Supervised Machine\n  Learning Classification Methods Using J48 and Na\\\"ive Bayes Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network activities recognition has always been a significant component of\nintrusion detection. However, with the increasing network traffic flow and\ncomplexity of network behavior, it is becoming more and more difficult to\nidentify the specific behavior quickly and accurately by user network\nmonitoring software. It also requires the system security staff to pay close\nattention to the latest intrusion monitoring technology and methods. All of\nthese greatly increase the difficulty and complexity of intrusion detection\ntasks. The application of machine learning methods based on supervised\nclassification technology would help to liberate the network security staff\nfrom the heavy and boring tasks. A finetuned model would accurately recognize\nuser behavior, which could provide persistent monitoring with a relative high\naccuracy and good adaptability. Finally, the results of network activities\nrecognition by J48 and Na\\\"ive Bayes algorithms are introduced and evaluated.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 09:44:14 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Huang", "Fan", ""]]}, {"id": "2105.13703", "submitter": "Christof Paar", "authors": "Susanne Engels and Falk Schellenberg and Christof Paar", "title": "SPFA: SFA on Multiple Persistent Faults", "comments": null, "journal-ref": null, "doi": "10.1109/FDTC51366.2020.00014", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For classical fault analysis, a transient fault is required to be injected\nduring runtime, e.g., only at a specific round. Instead, Persistent Fault\nAnalysis (PFA) introduces a powerful class of fault attacks that allows for a\nfault to be present throughout the whole execution. One limitation of original\nPFA as introduced by Zhang et al. at CHES'18 is that the faulty values need to\nbe known to the adversary. While this was addressed at a follow-up work at\nCHES'20, the solution is only applicable to a single faulty value. Instead, we\nuse the potency of Statistical Fault Analysis (SFA) in the persistent fault\nsetting, presenting Statistical Persistent Fault Analysis (SPFA) as a more\ngeneral approach of PFA. As a result, any or even a multitude of unknown faults\nthat cause an exploitable bias in the targeted round can be used to recover the\ncipher's secret key. Indeed, the undesired faults in the other rounds that\noccur due the persistent nature of the attack converge to a uniform\ndistribution as required by SFA. We verify the effectiveness of our attack\nagainst LED and AES.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 09:53:59 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Engels", "Susanne", ""], ["Schellenberg", "Falk", ""], ["Paar", "Christof", ""]]}, {"id": "2105.13725", "submitter": "Christof Paar", "authors": "Carina Wiesen and Steffen Becker and Nils Albartus Christof Paar and\n  Nikol Rummel", "title": "Promoting the Acquisition of Hardware Reverse Engineering Skills", "comments": null, "journal-ref": null, "doi": "10.1109/FIE43999.2019.9028668", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This full research paper focuses on skill acquisition in Hardware Reverse\nEngineering (HRE) - an important field of cyber security. HRE is a prevalent\ntechnique routinely employed by security engineers (i) to detect malicious\nhardware manipulations, (ii) to conduct VLSI failure analysis, (iii) to\nidentify IP infringements, and (iv) to perform competitive analyses. Even\nthough the scientific community and industry have a high demand for HRE\nexperts, there is a lack of educational courses. We developed a\nuniversity-level HRE course based on general cognitive psychological research\non skill acquisition, as research on the acquisition of HRE skills is lacking\nthus far. To investigate how novices acquire HRE skills in our course, we\nconducted two studies with students on different levels of prior knowledge. Our\nresults show that cognitive factors (e.g., working memory), and prior\nexperiences (e.g., in symmetric cryptography) influence the acquisition of HRE\nskills. We conclude by discussing implications for future HRE courses and by\noutlining ideas for future research that would lead to a more comprehensive\nunderstanding of skill acquisition in this important field of cyber security.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 10:45:17 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Wiesen", "Carina", ""], ["Becker", "Steffen", ""], ["Paar", "Nils Albartus Christof", ""], ["Rummel", "Nikol", ""]]}, {"id": "2105.13755", "submitter": "Peter Mell", "authors": "Peter Mell", "title": "The Generation of Security Scoring Systems Leveraging Human Expert\n  Opinion", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the existence of many security elements can be measured (e.g.,\nvulnerabilities, security controls, or privacy controls), it is challenging to\nmeasure their relative security impact. In the physical world we can often\nmeasure the impact of individual elements to a system. However, in cyber\nsecurity we often lack ground truth (i.e., the ability to directly measure\nsignificance). In this work we propose to solve this by leveraging human expert\nopinion to provide ground truth. Experts are iteratively asked to compare pairs\nof security elements to determine their relative significance. On the back end\nour knowledge encoding tool performs a form of binary insertion sort on a set\nof security elements using each expert as an oracle for the element\ncomparisons. The tool not only sorts the elements (note that equality may be\npermitted), but it also records the strength or degree of each relationship.\nThe output is a directed acyclic `constraint' graph that provides a total\nordering among the sets of equivalent elements. Multiple constraint graphs are\nthen unified together to form a single graph that is used to generate a scoring\nor prioritization system. For our empirical study, we apply this\ndomain-agnostic measurement approach to generate scoring/prioritization systems\nin the areas of vulnerability scoring, privacy control prioritization, and\ncyber security control evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 11:42:52 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Mell", "Peter", ""]]}, {"id": "2105.13756", "submitter": "Christof Paar", "authors": "Maik Ender and Amir Moradi and Christof Paar", "title": "The Unpatchable Silicon: A Full Break of the Bitstream Encryption of\n  Xilinx 7-Series FPGAs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The security of FPGAs is a crucial topic, as any vulnerability within the\nhardware can have severe consequences, if they are used in a secure design.\nSince FPGA designs are encoded in a bitstream, securing the bitstream is of the\nutmost importance. Adversaries have many motivations to recover and manipulate\nthe bitstream, including design cloning, IP theft, manipulation of the design,\nor design subversions e.g., through hardware Trojans. Given that FPGAs are\noften part of cyber-physical systems e.g., in aviation, medical, or industrial\ndevices, this can even lead to physical harm. Consequently, vendors have\nintroduced bitstream encryption, offering authenticity and confidentiality.\nEven though attacks against bitstream encryption have been proposed in the\npast, e.g., side-channel analysis and probing, these attacks require\nsophisticated equipment and considerable technical expertise. In this paper, we\nintroduce novel low-cost attacks against the Xilinx 7-Series (and Virtex-6)\nbitstream encryption, resulting in the total loss of authenticity and\nconfidentiality. We exploit a design flaw which piecewise leaks the decrypted\nbitstream. In the attack, the FPGA is used as a decryption oracle, while only\naccess to a configuration interface is needed. The attack does not require any\nsophisticated tools and, depending on the target system, can potentially be\nlaunched remotely. In addition to the attacks, we discuss several\ncountermeasures.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 11:47:59 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Ender", "Maik", ""], ["Moradi", "Amir", ""], ["Paar", "Christof", ""]]}, {"id": "2105.13769", "submitter": "Christof Paar", "authors": "Max Hoffmann, Falk Schellenberg, Christof Paar", "title": "ARMORY: Fully Automated and Exhaustive Fault Simulation on ARM-M\n  Binaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedded systems are ubiquitous. However, physical access of users and\nlikewise attackers makes them often threatened by fault attacks: a single fault\nduring the computation of a cryptographic primitive can lead to a total loss of\nsystem security. This can have serious consequences, e.g., in safetycritical\nsystems, including bodily harm and catastrophic technical failures. However,\ncountermeasures often focus on isolated fault models and high layers of\nabstraction. This leads to a dangerous sense of security, because exploitable\nfaults that are only visible at machine code level might not be covered by\ncountermeasures. In this work we present ARMORY, a fully automated open source\nframework for exhaustive fault simulation on binaries of the ubiquitous ARM-M\nclass. It allows engineers and analysts to efficiently scan a binary for\npotential weaknesses against arbitrary combinations of multi-variate fault\ninjections under a large variety of fault models. Using ARMORY, we demonstrate\nthe power of fully automated fault analysis and the dangerous implications of\napplying countermeasures without knowledge of physical addresses and offsets.\nWe exemplarily analyze two case studies, which are highly relevant for\npractice: a DFA on AES (cryptographic) and a secure bootloader\n(non-cryptographic). Our results show that indeed numerous exploitable faults\nfound by ARMORY which occur in the actual implementations are easily missed in\nmanual inspection. Crucially, most faults are only visible when taking machine\ncode information, i.e., addresses and offsets, into account. Surprisingly, we\nshow that a countermeasure that protects against one type of fault can actually\nlargely increase the vulnerability to other fault models. Our work demonstrates\nthe need for countermeasures that, at least in their evaluation, are not\nrestricted to isolated fault models and consider low-level information [...].\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 12:21:41 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Hoffmann", "Max", ""], ["Schellenberg", "Falk", ""], ["Paar", "Christof", ""]]}, {"id": "2105.13824", "submitter": "Mathias Morbitzer", "authors": "Mathias Morbitzer, Sergej Proskurin, Martin Radev, Marko Dorfhuber,\n  Erick Quintanar Salas", "title": "SEVerity: Code Injection Attacks against Encrypted Virtual Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern enterprises increasingly take advantage of cloud infrastructures. Yet,\noutsourcing code and data into the cloud requires enterprises to trust cloud\nproviders not to meddle with their data. To reduce the level of trust towards\ncloud providers, AMD has introduced Secure Encrypted Virtualization (SEV). By\nencrypting Virtual Machines (VMs), SEV aims to ensure data confidentiality,\ndespite a compromised or curious Hypervisor. The SEV Encrypted State (SEV-ES)\nextension additionally protects the VM's register state from unauthorized\naccess. Yet, both extensions do not provide integrity of the VM's memory, which\nhas already been abused to leak the protected data or to alter the VM's\ncontrol-flow. In this paper, we introduce the SEVerity attack; a missing puzzle\npiece in the series of attacks against the AMD SEV family. Specifically, we\nabuse the system's lack of memory integrity protection to inject and execute\narbitrary code within SEV-ES-protected VMs. Contrary to previous code execution\nattacks against the AMD SEV family, SEVerity neither relies on a specific CPU\nversion nor on any code gadgets inside the VM. Instead, SEVerity abuses the\nfact that SEV-ES prohibits direct memory access into the encrypted memory.\nSpecifically, SEVerity injects arbitrary code into the encrypted VM through I/O\nchannels and uses the Hypervisor to locate and trigger the execution of the\nencrypted payload. This allows us to sidestep the protection mechanisms of\nSEV-ES. Overall, our results demonstrate a success rate of 100% and hence\nhighlight that memory integrity protection is an obligation when encrypting\nVMs. Consequently, our work presents the final stroke in a series of attacks\nagainst AMD SEV and SEV-ES and renders the present implementation as incapable\nof protecting against a curious, vulnerable, or malicious Hypervisor.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 13:35:59 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Morbitzer", "Mathias", ""], ["Proskurin", "Sergej", ""], ["Radev", "Martin", ""], ["Dorfhuber", "Marko", ""], ["Salas", "Erick Quintanar", ""]]}, {"id": "2105.13910", "submitter": "Tore Frederiksen", "authors": "Tore Kasper Frederiksen", "title": "A Holistic Approach to Enhanced Security and Privacy in Digital Health\n  Passports", "comments": "21 pages, to be published at the IWAPS workshop in connection with\n  the ARES conference 2021", "journal-ref": null, "doi": "10.1145/3465481.3469212", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As governments around the world decide to deploy digital health passports as\na tool to curb the spread of Covid-19, it becomes increasingly important to\nconsider how these can be constructed with privacy-by-design.\n  In this paper we discuss the privacy and security issues of common approaches\nfor constructing digital health passports. We then show how to construct, and\ndeploy, secure and private digital health passports, in a simple and efficient\nmanner. We do so by using a protocol for distributed password-based token\nissuance, secret sharing and by leveraging modern smart phones' secure\nhardware.\n  Our solution only requires a constant amount of asymmetric cryptographic\noperations and a single round of communication between the user and the party\nverifying the user's digital health passport, and only two rounds between the\nuser and the server issuing the digital health passport.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 15:22:14 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 12:45:45 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Frederiksen", "Tore Kasper", ""]]}, {"id": "2105.13957", "submitter": "Edward Crowder", "authors": "Edward Crowder, Jay Lansiquot", "title": "Darknet Data Mining -- A Canadian Cyber-crime Perspective", "comments": "13 pages, 19 figures, Honours Bachelors Capstone Project. for\n  associated code, see https://github.com/crowdere/Darknet-Stack", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Exploring the darknet can be a daunting task; this paper explores the\napplication of data mining the darknet within a Canadian cybercrime\nperspective. Measuring activity through marketplace analysis and vendor\nattribution has proven difficult in the past. Observing different aspects of\nthe darknet and implementing methods of monitoring and collecting data in the\nhopes of connecting contributions to the darknet marketplaces to and from\nCanada. The significant findings include a small Canadian presence, measured\nthe product categories, and attribution of one cross-marketplace vendor through\ndata visualization. The results were made possible through a multi-stage\nprocessing pipeline, including data crawling, scraping, and parsing. The\nprimary future works include enhancing the pipeline to include other media,\nsuch as web forums, chatrooms, and emails. Applying machine learning models\nlike natural language processing or sentiment analysis could prove beneficial\nduring investigations.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 18:53:37 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Crowder", "Edward", ""], ["Lansiquot", "Jay", ""]]}, {"id": "2105.14170", "submitter": "Peiyuan Liu", "authors": "Jeremiah Blocki and Peiyuan Liu", "title": "Towards a Rigorous Statistical Analysis of Empirical Password Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the following problem: given $N$ independent\nsamples from an unknown distribution $\\mathcal{P}$ over passwords $pwd_1,pwd_2,\n\\ldots$ can we generate high confidence upper/lower bounds on the guessing\ncurve $\\lambda_G \\doteq \\sum_{i=1}^G p_i$ where $p_i=\\Pr[pwd_i]$ and the\npasswords are ordered such that $p_i \\geq p_{i+1}$. Intuitively, $\\lambda_G$\nrepresents the probability that an attacker who knows the distribution\n$\\mathcal{P}$ can guess a random password $pwd \\leftarrow \\mathcal{P}$ within\n$G$ guesses. Understanding how $\\lambda_G$ increases with the number of guesses\n$G$ can help quantify the damage of a password cracking attack and inform\npassword policies. Despite an abundance of large (breached) password datasets\nupper/lower bounding $\\lambda_G$ remains a challenging problem. We introduce\nseveral statistical techniques to derive tighter upper/lower bounds on the\nguessing curve $\\lambda_G$ which hold with high confidence. We apply our\ntechniques to analyze $9$ large password datasets finding that our new lower\nbounds dramatically improve upon prior work. Our empirical analysis shows that\neven state-of-the-art password cracking models are significantly less guess\nefficient than an attacker who knows the distribution. When $G$ is not too\nlarge we find that our upper/lower bounds on $\\lambda_G$ are both very close to\nthe empirical distribution which justifies the use of the empirical\ndistribution in settings where $G$ is not too large i.e., $G \\ll N$ closely\napproximates $\\lambda_G$. The analysis also highlights regions of the curve\nwhere we can, with high confidence, conclude that the empirical distribution\nsignificantly overestimates $\\lambda_G$. Our new statistical techniques yield\nsubstantially tighter upper/lower bounds on $\\lambda_G$ though there are still\nregions of the curve where the best upper/lower bounds diverge significantly.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 01:21:07 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Blocki", "Jeremiah", ""], ["Liu", "Peiyuan", ""]]}, {"id": "2105.14251", "submitter": "Yajin Zhou", "authors": "Lin Ma, Jinyan Xu, Jiadong Sun, Yajin Zhou, Xun Xie, Wenbo Shen, Rui\n  Chang, Kui Ren", "title": "Revisiting Challenges for Selective Data Protection of Real Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selective data protection is a promising technique to defend against the data\nleakage attack. In this paper, we revisit technical challenges that were\nneglected when applying this protection to real applications. These challenges\ninclude the secure input channel, granularity conflict, and sensitivity\nconflict. We summarize the causes of them and propose corresponding solutions.\nThen we design and implement a prototype system for selective data protection\nand evaluate the overhead using the RISC-V Spike simulator. The evaluation\ndemonstrates the efficiency (less than 3% runtime overhead with optimizations)\nand the security guarantees provided by our system.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 08:41:08 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Ma", "Lin", ""], ["Xu", "Jinyan", ""], ["Sun", "Jiadong", ""], ["Zhou", "Yajin", ""], ["Xie", "Xun", ""], ["Shen", "Wenbo", ""], ["Chang", "Rui", ""], ["Ren", "Kui", ""]]}, {"id": "2105.14273", "submitter": "Muhui Jiang", "authors": "Muhui Jiang, Tianyi Xu, Yajin Zhou, Yufeng Hu, Ming Zhong, Lei Wu,\n  Xiapu Luo, Kui Ren", "title": "Examiner: Automatically Locating Inconsistent Instructions Between Real\n  Devices and CPU Emulators for ARM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emulator is widely used to build dynamic analysis frameworks due to its\nfine-grained tracing capability, full system monitoring functionality, and\nscalability of running on different operating systemsand architectures.\nHowever, whether the emulator is consistent with real devices is unknown. To\nunderstand this problem, we aim to automatically locate inconsistent\ninstructions, which behave differently between emulators and real devices.\n  We target ARM architecture, which provides machine readable specification.\nBased on the specification, we propose a test case generator by designing and\nimplementing the first symbolic execution engine for ARM architecture\nspecification language (ASL). We generate 2,774,649 representative instruction\nstreams and conduct differential testing with these instruction streams between\nfour ARM real devices in different architecture versions (i.e., ARMv5, ARMv6,\nARMv7-a, and ARMv8-a) and the state-of-the-art emulators (i.e., QEMU). We\nlocate 155,642 inconsistent instruction streams, which cover 30% of all\ninstruction encodings and 47.8% of the instructions. We find undefined\nimplementation in ARM manual and implementation bugs of QEMU are the major\ncauses of inconsistencies. Furthermore, we discover four QEMU bugs, which are\nconfirmed and patched by thedevelopers, covering 13 instruction encodings\nincluding the most commonly used ones (e.g.,STR,BLX). With the inconsistent\ninstructions, we build three security applications and demonstrate\nthecapability of these instructions on detecting emulators, anti-emulation, and\nanti-fuzzing.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 11:29:53 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Jiang", "Muhui", ""], ["Xu", "Tianyi", ""], ["Zhou", "Yajin", ""], ["Hu", "Yufeng", ""], ["Zhong", "Ming", ""], ["Wu", "Lei", ""], ["Luo", "Xiapu", ""], ["Ren", "Kui", ""]]}, {"id": "2105.14295", "submitter": "Muhui Jiang", "authors": "Muhui Jiang, Lin Ma, Yajin Zhou, Qiang Liu, Cen Zhang, Zhi Wang, Xiapu\n  Luo, Lei Wu, Kui Ren", "title": "ECMO: Peripheral Transplantation to Rehost Embedded Linux Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic analysis based on the full-system emulator QEMU is widely used for\nvarious purposes. However, it is challenging to run firmware images of embedded\ndevices in QEMU, especially theprocess to boot the Linux kernel (we call this\nprocess rehosting the Linux kernel in this paper.) That's because embedded\ndevices usually use different system-on-chips (SoCs) from multiple vendors\nandonly a limited number of SoCs are currently supported in QEMU.\n  In this work, we propose a technique calledperipheral transplantation. The\nmain idea is to transplant the device drivers of designated peripherals into\nthe Linux kernel binary. By doing so, it can replace the peripherals in the\nkernel that are currently unsupported in QEMU with supported ones, thus making\nthe Linux kernel rehostable. After that, various applications can be built\nupon.\n  We implemented this technique inside a prototype system called ECMO and\napplied it to 824 firmware images, which consist of 17 kernel versions, 37\ndevice models, and 24 vendors. The resultshows that ECMO can successfully\ntransplant peripherals for all the 824 Linux kernels. Among them, 719 kernels\ncan be successfully rehosted, i.e., launching a user-space shell (87.3% success\nrate). The failed cases are mainly because the root file system format (ramfs)\nis not supported by the kernel. We further build three applications, i.e.,\nkernel crash analysis, rootkit forensic analysis, and kernel fuzzing, based on\nthe rehosted kernels to demonstrate the usage scenarios of ECMO.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 13:14:24 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Jiang", "Muhui", ""], ["Ma", "Lin", ""], ["Zhou", "Yajin", ""], ["Liu", "Qiang", ""], ["Zhang", "Cen", ""], ["Wang", "Zhi", ""], ["Luo", "Xiapu", ""], ["Wu", "Lei", ""], ["Ren", "Kui", ""]]}, {"id": "2105.14298", "submitter": "Dingding Wang", "authors": "Dingding Wang, Muhui Jiang, Rui Chang, Yajin Zhou, Baolei Hou, Xiapu\n  Luo, Lei Wu, Kui Ren", "title": "A Measurement Study on the (In)security of End-of-Life (EoL) Embedded\n  Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedded devices are becoming popular. Meanwhile, researchers are actively\nworking on improving the security of embedded devices. However, previous work\nignores the insecurity caused by a special category of devices, i.e., the\nEnd-of-Life (EoL in short) devices. Once a product becomes End-of-Life, vendors\ntend to no longer maintain its firmware or software, including providing bug\nfixes and security patches. This makes EoL devices susceptible to attacks. For\ninstance, a report showed that an EoL model with thousands of active devices\nwas exploited to redirect web traffic for malicious purposes. In this paper, we\nconduct the first measurement study to shed light on the (in)security of EoL\ndevices. To this end, our study performs two types of analysis, including the\naliveness analysis and the vulnerability analysis. The first one aims to detect\nthe scale of EoL devices that are still alive. The second one is to evaluate\nthe vulnerabilities existing in (active) EoL devices. We have applied our\napproach to a large number of EoL models from three vendors (i.e., D-Link,\nTp-Link, and Netgear) and detect the alive devices in a time period of ten\nmonths. Our study reveals some worrisome facts that were unknown by the\ncommunity. For instance, there exist more than 2 million active EoL devices.\nNearly 300,000 of them are still alive even after five years since they became\nEoL. Although vendors may release security patches after the EoL date, however,\nthe process is ad hoc and incomplete. As a result, more than 1 million active\nEoL devices are vulnerable, and nearly half of them are threatened by high-risk\nvulnerabilities. Attackers can achieve a minimum of 2.79 Tbps DDoS attack by\ncompromising a large number of active EoL devices. We believe these facts pose\na clear call for more attention to deal with the security issues of EoL\ndevices.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 13:33:52 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wang", "Dingding", ""], ["Jiang", "Muhui", ""], ["Chang", "Rui", ""], ["Zhou", "Yajin", ""], ["Hou", "Baolei", ""], ["Luo", "Xiapu", ""], ["Wu", "Lei", ""], ["Ren", "Kui", ""]]}, {"id": "2105.14344", "submitter": "Yaniv Agman", "authors": "Yaniv Agman (1), Danny Hendler (1) ((1) Department of Computer\n  Science, Ben-Gurion University of The Negev, Beer Sheva, Israel)", "title": "BPFroid: Robust Real Time Android Malware Detection Framework", "comments": "22 pages, 7 figures, submitted to ieee access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present BPFroid -- a novel dynamic analysis framework for Android that\nuses the eBPF technology of the Linux kernel to continuously monitor events of\nuser applications running on a real device. The monitored events are collected\nfrom different components of the Android software stack: internal kernel\nfunctions, system calls, native library functions, and the Java API framework.\nAs BPFroid hooks these events in the kernel, a malware is unable to trivially\nbypass monitoring. Moreover, using eBPF doesn't require any change to the\nAndroid system or the monitored applications. We also present an analytical\ncomparison of BPFroid to other malware detection methods and demonstrate its\nusage by developing novel signatures to detect suspicious behavior that are\nbased on it. These signatures are then evaluated using real apps. We also\ndemonstrate how BPFroid can be used to capture forensic artifacts for further\ninvestigation. Our results show that BPFroid successfully alerts in real time\nwhen a suspicious behavioral signature is detected, without incurring a\nsignificant runtime performance overhead.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 17:28:32 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Agman", "Yaniv", ""], ["Hendler", "Danny", ""]]}, {"id": "2105.14357", "submitter": "Kuntal Kumar Pal", "authors": "Kuntal Kumar Pal, Kazuaki Kashihara, Pratyay Banerjee, Swaroop Mishra,\n  Ruoyu Wang, Chitta Baral", "title": "Constructing Flow Graphs from Procedural Cybersecurity Texts", "comments": "13 pages, 5 pages, accepted in the Findings of ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Following procedural texts written in natural languages is challenging. We\nmust read the whole text to identify the relevant information or identify the\ninstruction flows to complete a task, which is prone to failures. If such texts\nare structured, we can readily visualize instruction-flows, reason or infer a\nparticular step, or even build automated systems to help novice agents achieve\na goal. However, this structure recovery task is a challenge because of such\ntexts' diverse nature. This paper proposes to identify relevant information\nfrom such texts and generate information flows between sentences. We built a\nlarge annotated procedural text dataset (CTFW) in the cybersecurity domain\n(3154 documents). This dataset contains valuable instructions regarding\nsoftware vulnerability analysis experiences. We performed extensive experiments\non CTFW with our LM-GNN model variants in multiple settings. To show the\ngeneralizability of both this task and our method, we also experimented with\nprocedural texts from two other domains (Maintenance Manual and Cooking), which\nare substantially different from cybersecurity. Our experiments show that Graph\nConvolution Network with BERT sentence embeddings outperforms BERT in all three\ndomains\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 19:06:35 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Pal", "Kuntal Kumar", ""], ["Kashihara", "Kazuaki", ""], ["Banerjee", "Pratyay", ""], ["Mishra", "Swaroop", ""], ["Wang", "Ruoyu", ""], ["Baral", "Chitta", ""]]}, {"id": "2105.14408", "submitter": "Qian Chen", "authors": "Qian Chen, Zilong Wang, Xiaodong Lin", "title": "PPT: A Privacy-Preserving Global Model Training Protocol for Federated\n  Learning in P2P Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of Federated Learning has emerged as a convergence of distributed\nmachine learning, information, and communication technology. It is vital to the\ndevelopment of distributed machine learning, which is expected to be fully\ndecentralized, robust, communication efficient, and secure. However, the\nfederated learning settings with a central server can't meet requirements in\nfully decentralized networks. In this paper, we propose a fully decentralized,\nefficient, and privacy-preserving global model training protocol, named PPT,\nfor federated learning in Peer-to-peer (P2P) Networks. PPT uses a one-hop\ncommunication form to aggregate local model update parameters and adopts the\nsymmetric cryptosystem to ensure security. It is worth mentioning that PPT\nmodifies the Eschenauer-Gligor (E-G) scheme to distribute keys for encryption.\nPPT also adopts Neighborhood Broadcast, Supervision and Report, and Termination\nas complementary mechanisms to enhance security and robustness. Through\nextensive analysis, we demonstrate that PPT resists various security threats\nand preserve user privacy. Ingenious experiments demonstrate the utility and\nefficiency as well.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 01:59:54 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Chen", "Qian", ""], ["Wang", "Zilong", ""], ["Lin", "Xiaodong", ""]]}, {"id": "2105.14427", "submitter": "Tianhao Wang", "authors": "Salil Vadhan, Tianhao Wang", "title": "Concurrent Composition of Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate a study of the composition properties of interactive\ndifferentially private mechanisms. An interactive differentially private\nmechanism is an algorithm that allows an analyst to adaptively ask queries\nabout a sensitive dataset, with the property that an adversarial analyst's view\nof the interaction is approximately the same regardless of whether or not any\nindividual's data is in the dataset. Previous studies of composition of\ndifferential privacy have focused on non-interactive algorithms, but\ninteractive mechanisms are needed to capture many of the intended applications\nof differential privacy and a number of the important differentially private\nprimitives.\n  We focus on concurrent composition, where an adversary can arbitrarily\ninterleave its queries to several differentially private mechanisms, which may\nbe feasible when differentially private query systems are deployed in practice.\nWe prove that when the interactive mechanisms being composed are pure\ndifferentially private, their concurrent composition achieves privacy\nparameters (with respect to pure or approximate differential privacy) that\nmatch the (optimal) composition theorem for noninteractive differential\nprivacy. We also prove a composition theorem for interactive mechanisms that\nsatisfy approximate differential privacy. That bound is weaker than even the\nbasic (suboptimal) composition theorem for noninteractive differential privacy,\nand we leave closing the gap as a direction for future research, along with\nunderstanding concurrent composition for other variants of differential\nprivacy.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 04:35:50 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Vadhan", "Salil", ""], ["Wang", "Tianhao", ""]]}, {"id": "2105.14512", "submitter": "Mishel Jain", "authors": "Mishel Jain, Priyanka Singh, Balasubramanian Raman", "title": "SHELBRS: Location Based Recommendation Services using Switchable\n  Homomorphic Encryption", "comments": "9 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Location-Based Recommendation Services (LBRS) has seen an unprecedented rise\nin its usage in recent years. LBRS facilitates a user by recommending services\nbased on his location and past preferences. However, leveraging such services\ncomes at a cost of compromising one's sensitive information like their shopping\npreferences, lodging places, food habits, recently visited places, etc. to the\nthird-party servers. Losing such information could be crucial and threatens\none's privacy. Nowadays, the privacy-aware society seeks solutions that can\nprovide such services, with minimized risks. Recently, a few privacy-preserving\nrecommendation services have been proposed that exploit the fully homomorphic\nencryption (FHE) properties to address the issue. Though, it reduced privacy\nrisks but suffered from heavy computational overheads that ruled out their\ncommercial applications. Here, we propose SHELBRS, a lightweight LBRS that is\nbased on switchable homomorphic encryption (SHE), which will benefit the users\nas well as the service providers. A SHE exploits both the additive as well as\nthe multiplicative homomorphic properties but with comparatively much lesser\nprocessing time as it's FHE counterpart. We evaluate the performance of our\nproposed scheme with the other state-of-the-art approaches without compromising\nsecurity.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 11:48:34 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Jain", "Mishel", ""], ["Singh", "Priyanka", ""], ["Raman", "Balasubramanian", ""]]}, {"id": "2105.14527", "submitter": "Denis Roio", "authors": "Denis Roio, Alberto Ibrisevic, Andrea D'Intino", "title": "Reflow: Zero Knowledge Multi Party Signatures with Application to\n  Distributed Authentication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Reflow is a novel signature scheme supporting unlinkable signatures by\nmultiple parties authenticated by means of zero-knowledge credentials. Reflow\nintegrates with blockchains and graph databases to ensure confidentiality and\nauthenticity of signatures made by disposable identities that can be verified\neven when credential issuing authorities are offline. We implement and evaluate\nReflow smart contracts for Zenroom and present an application to produce\nauthenticated material passports for resource-event-agent accounting systems\nbased on graph data structures. Reflow uses short and computationally efficient\nauthentication credentials and can easily scale signatures to include thousands\nof participants.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 13:07:09 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Roio", "Denis", ""], ["Ibrisevic", "Alberto", ""], ["D'Intino", "Andrea", ""]]}, {"id": "2105.14564", "submitter": "Danish Sattar", "authors": "Ramy Maarouf, Danish Sattar, and Ashraf Matrawy", "title": "Evaluating Resilience of Encrypted Traffic Classification Against\n  Adversarial Evasion Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and deep learning algorithms can be used to classify\nencrypted Internet traffic. Classification of encrypted traffic can become more\nchallenging in the presence of adversarial attacks that target the learning\nalgorithms. In this paper, we focus on investigating the effectiveness of\ndifferent evasion attacks and see how resilient machine and deep learning\nalgorithms are. Namely, we test C4.5 Decision Tree, K-Nearest Neighbor (KNN),\nArtificial Neural Network (ANN), Convolutional Neural Networks (CNN) and\nRecurrent Neural Networks (RNN). In most of our experimental results, deep\nlearning shows better resilience against the adversarial samples in comparison\nto machine learning. Whereas, the impact of the attack varies depending on the\ntype of attack.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 15:07:12 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Maarouf", "Ramy", ""], ["Sattar", "Danish", ""], ["Matrawy", "Ashraf", ""]]}, {"id": "2105.14565", "submitter": "JingKai Siow", "authors": "Yaqin Zhou, Jing Kai Siow, Chenyu Wang, Shangqing Liu, Yang Liu", "title": "SPI: Automated Identification of Security Patches via Commits", "comments": "Accepted By ACM Transactions on Software Engineering and Methodology\n  (TOSEM), Continuous Special Section: AI and SE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security patches in open-source software, providing security fixes to\nidentified vulnerabilities, are crucial in protecting against cyberattacks.\nDespite the National Vulnerability Database (NVD) publishes identified\nvulnerabilities, a vast majority of vulnerabilities and their corresponding\nsecurity patches remain beyond public exposure, e.g., in the open-source\nlibraries that are heavily relied on by developers. An extensive security\npatches dataset could help end-users such as security companies, e.g., building\na security knowledge base, or researchers, e.g., aiding in vulnerability\nresearch. To curate security patches including undisclosed patches at a large\nscale and low cost, we propose a deep neural-network-based approach built upon\ncommits of open-source repositories. We build security patch datasets that\ninclude 38,291 security-related commits and 1,045 CVE patches from four C\nlibraries. We manually verify each commit, among the 38,291 security-related\ncommits, to determine if they are security-related. We devise a deep\nlearning-based security patch identification system that consists of two neural\nnetworks: one commit-message neural network that utilizes pretrained word\nrepresentations learned from our commits dataset; and one code-revision neural\nnetwork that takes code before and after revision and learns the distinction on\nthe statement level. Our evaluation results show that our system outperforms\nSVM and K-fold stacking algorithm, achieving as high as 87.93% F1-score and\nprecision of 86.24%. We deployed our pipeline and learned model in an\nindustrial production environment to evaluate the generalization ability of our\napproach. The industrial dataset consists of 298,917 commits from 410 new\nlibraries that range from a wide functionality. Our experiment results and\nobservation proved that our approach identifies security patches effectively\namong open-sourced projects.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 15:09:40 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 14:00:38 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Zhou", "Yaqin", ""], ["Siow", "Jing Kai", ""], ["Wang", "Chenyu", ""], ["Liu", "Shangqing", ""], ["Liu", "Yang", ""]]}, {"id": "2105.14618", "submitter": "Lun Wang", "authors": "Lun Wang, Qi Pang, Shuai Wang and Dawn Song", "title": "FED-$\\chi^2$: Privacy Preserving Federated Correlation Test", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose the first secure federated $\\chi^2$-test protocol\nFed-$\\chi^2$. To minimize both the privacy leakage and the communication cost,\nwe recast $\\chi^2$-test to the second moment estimation problem and thus can\ntake advantage of stable projection to encode the local information in a short\nvector. As such encodings can be aggregated with only summation, secure\naggregation can be naturally applied to hide the individual updates. We\nformally prove the security guarantee of Fed-$\\chi^2$ that the joint\ndistribution is hidden in a subspace with exponential possible distributions.\nOur evaluation results show that Fed-$\\chi^2$ achieves negligible accuracy\ndrops with small client-side computation overhead. In several real-world case\nstudies, the performance of Fed-$\\chi^2$ is comparable to the centralized\n$\\chi^2$-test.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 20:29:59 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wang", "Lun", ""], ["Pang", "Qi", ""], ["Wang", "Shuai", ""], ["Song", "Dawn", ""]]}, {"id": "2105.14619", "submitter": "Noel Warford", "authors": "Noel Warford (1), Collins W. Munyendo (2), Ashna Mediratta (1), Adam\n  J. Aviv (2), and Michelle L. Mazurek (1) ((1) University of Maryland, (2) The\n  George Washington University)", "title": "Strategies and Perceived Risks of Sending Sensitive Documents", "comments": "25 pages, to appear in USENIX Security Symposium 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  People are frequently required to send documents, forms, or other materials\ncontaining sensitive data (e.g., personal information, medical records,\nfinancial data) to remote parties, sometimes without a formal procedure to do\nso securely. The specific transmission mechanisms end up relying on the\nknowledge and preferences of the parties involved. Through two online surveys\n($n=60$ and $n=250$), we explore the various methods used to transmit sensitive\ndocuments, as well as the perceived risk and satisfaction with those methods.\nWe find that users are more likely to recognize risk to data-at-rest after\nreceipt (but not at the sender, namely, themselves). When not using an online\nportal provided by the recipient, participants primarily envision transmitting\nsensitive documents in person or via email, and have little experience using\nsecure, privacy-preserving alternatives. Despite recognizing general risks,\nparticipants express high privacy satisfaction and convenience with actually\nexperienced situations. These results suggest opportunities to design new\nsolutions to promote securely sending sensitive materials, perhaps as new\nutilities within standard email workflows.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 20:31:55 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Warford", "Noel", ""], ["Munyendo", "Collins W.", ""], ["Mediratta", "Ashna", ""], ["Aviv", "Adam J.", ""], ["Mazurek", "Michelle L.", ""]]}, {"id": "2105.14638", "submitter": "Johannes Otterbach", "authors": "Samuel von Bau{\\ss}nern, Johannes Otterbach, Adrian Loy, Mathieu\n  Salzmann, Thomas Wollmann", "title": "DAAIN: Detection of Anomalous and Adversarial Input using Normalizing\n  Flows", "comments": "14 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Despite much recent work, detecting out-of-distribution (OOD) inputs and\nadversarial attacks (AA) for computer vision models remains a challenge. In\nthis work, we introduce a novel technique, DAAIN, to detect OOD inputs and AA\nfor image segmentation in a unified setting. Our approach monitors the inner\nworkings of a neural network and learns a density estimator of the activation\ndistribution. We equip the density estimator with a classification head to\ndiscriminate between regular and anomalous inputs. To deal with the\nhigh-dimensional activation-space of typical segmentation networks, we\nsubsample them to obtain a homogeneous spatial and layer-wise coverage. The\nsubsampling pattern is chosen once per monitored model and kept fixed for all\ninputs. Since the attacker has access to neither the detection model nor the\nsampling key, it becomes harder for them to attack the segmentation network, as\nthe attack cannot be backpropagated through the detector. We demonstrate the\neffectiveness of our approach using an ESPNet trained on the Cityscapes dataset\nas segmentation model, an affine Normalizing Flow as density estimator and use\nblue noise to ensure homogeneous sampling. Our model can be trained on a single\nGPU making it compute efficient and deployable without requiring specialized\naccelerators.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 22:07:13 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["von Bau\u00dfnern", "Samuel", ""], ["Otterbach", "Johannes", ""], ["Loy", "Adrian", ""], ["Salzmann", "Mathieu", ""], ["Wollmann", "Thomas", ""]]}, {"id": "2105.14644", "submitter": "Florian Jaeckle", "authors": "Florian Jaeckle and M. Pawan Kumar", "title": "Generating Adversarial Examples with Graph Neural Networks", "comments": "To be published in UAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recent years have witnessed the deployment of adversarial attacks to evaluate\nthe robustness of Neural Networks. Past work in this field has relied on\ntraditional optimization algorithms that ignore the inherent structure of the\nproblem and data, or generative methods that rely purely on learning and often\nfail to generate adversarial examples where they are hard to find. To alleviate\nthese deficiencies, we propose a novel attack based on a graph neural network\n(GNN) that takes advantage of the strengths of both approaches; we call it\nAdvGNN. Our GNN architecture closely resembles the network we wish to attack.\nDuring inference, we perform forward-backward passes through the GNN layers to\nguide an iterative procedure towards adversarial examples. During training, its\nparameters are estimated via a loss function that encourages the efficient\ncomputation of adversarial examples over a time horizon. We show that our\nmethod beats state-of-the-art adversarial attacks, including PGD-attack,\nMI-FGSM, and Carlini and Wagner attack, reducing the time required to generate\nadversarial examples with small perturbation norms by over 65\\%. Moreover,\nAdvGNN achieves good generalization performance on unseen networks. Finally, we\nprovide a new challenging dataset specifically designed to allow for a more\nillustrative comparison of adversarial attacks.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 22:46:41 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Jaeckle", "Florian", ""], ["Kumar", "M. Pawan", ""]]}, {"id": "2105.14695", "submitter": "Koji Nuida", "authors": "Takuto Odagawa and Koji Nuida", "title": "Halt Properties and Complexity Evaluations for Optimal DeepLLL Algorithm\n  Families", "comments": "20 pages; (v2) Abstract slightly revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DeepLLL algorithm (Schnorr, 1994) is a famous variant of LLL lattice basis\nreduction algorithm, and PotLLL algorithm (Fontein et al., 2014) and $S^2$LLL\nalgorithm (Yasuda and Yamaguchi, 2019) are recent polynomial-time variants of\nDeepLLL algorithm developed from cryptographic applications. However, the known\npolynomial bounds for computational complexity are shown only for parameter\n$\\delta < 1$; for \"optimal\" parameter $\\delta = 1$ which ensures the best\noutput quality, no polynomial bounds are known, and except for LLL algorithm,\nit is even not formally proved that the algorithm always halts within finitely\nmany steps. In this paper, we prove that these four algorithms always halt also\nwith optimal parameter $\\delta = 1$, and furthermore give explicit upper bounds\nfor the numbers of loops executed during the algorithms. Unlike the known bound\n(Akhavi, 2003) applicable to LLL algorithm only, our upper bounds are deduced\nin a unified way for all of the four algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 04:26:46 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 03:54:11 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Odagawa", "Takuto", ""], ["Nuida", "Koji", ""]]}, {"id": "2105.14756", "submitter": "AprilPyone MaungMaung", "authors": "AprilPyone MaungMaung and Hitoshi Kiya", "title": "A Protection Method of Trained CNN Model with Secret Key from\n  Unauthorized Access", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel method for protecting convolutional neural\nnetwork (CNN) models with a secret key set so that unauthorized users without\nthe correct key set cannot access trained models. The method enables us to\nprotect not only from copyright infringement but also the functionality of a\nmodel from unauthorized access without any noticeable overhead. We introduce\nthree block-wise transformations with a secret key set to generate learnable\ntransformed images: pixel shuffling, negative/positive transformation, and FFX\nencryption. Protected models are trained by using transformed images. The\nresults of experiments with the CIFAR and ImageNet datasets show that the\nperformance of a protected model was close to that of non-protected models when\nthe key set was correct, while the accuracy severely dropped when an incorrect\nkey set was given. The protected model was also demonstrated to be robust\nagainst various attacks. Compared with the state-of-the-art model protection\nwith passports, the proposed method does not have any additional layers in the\nnetwork, and therefore, there is no overhead during training and inference\nprocesses.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 07:37:33 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["MaungMaung", "AprilPyone", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "2105.14768", "submitter": "Wei Wang Dr.", "authors": "Zhiqing Luo, Wei Wang, Qianyi Huang, Tao Jiang, and Qian Zhang", "title": "Securing IoT Devices by Exploiting Backscatter Propagation Signatures", "comments": "arXiv admin note: substantial text overlap with arXiv:1810.07058", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The low-power radio technologies open up many opportunities to facilitate\nInternet-of-Things (IoT) into our daily life, while their minimalist design\nalso makes IoT devices vulnerable to many active attacks. Recent advances use\nan antenna array to extract fine-grained physical-layer signatures to identify\nthe attackers, which adds burdens in terms of energy and hardware cost to IoT\ndevices. In this paper, we present ShieldScatter, a lightweight system that\nattaches low-cost tags to single-antenna devices to shield the system from\nactive attacks. The key insight of ShieldScatter is to intentionally create\nmulti-path propagation signatures with the careful deployment of tags. These\nsignatures can be used to construct a sensitive profile to identify the\nlocation of the signals' arrival, and thus detect the threat. In addition, we\nalso design a tag-random scheme and a multiple receivers combination approach\nto detect a powerful attacker who has the strong priori knowledge of the\nlegitimate user. We prototype ShieldScatter with USRPs and tags to evaluate our\nsystem in various environments. The results show that even when the powerful\nattacker is close to the legitimate device, ShieldScatter can mitigate 95% of\nattack attempts while triggering false alarms on just 7% of legitimate traffic.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 08:01:41 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Luo", "Zhiqing", ""], ["Wang", "Wei", ""], ["Huang", "Qianyi", ""], ["Jiang", "Tao", ""], ["Zhang", "Qian", ""]]}, {"id": "2105.14783", "submitter": "Marie-Laure Zollinger", "authors": "Peter B. Roenne and Peter Y.A Ryan and Marie-Laure Zollinger", "title": "Electryo, In-person Voting with Transparent Voter Verifiability and\n  Eligibility Verifiability", "comments": "E-Vote-ID 2018 TUT Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selene is an e-voting protocol that allows voters to directly check their\nindividual vote, in cleartext, in the final tally via a tracker system, while\nproviding good coercion mitigation. This is in contrast to conventional,\nend-to-end verifiable schemes in which the voter verifies the presence of an\nencryption of her vote on the bulletin board. The Selene mechanism can be\napplied to many e-voting schemes, but here we present an application to the\npolling station context, resulting in a voter-verifiable electronic tally with\na paper audit trail. The system uses a smartcard-based public key system to\nprovide the individual verification and universal eligibility verifiability.\nThe paper record contains an encrypted link to the voter's identity, requiring\nstronger assumptions on ballot privacy than normal paper voting, but with the\nbenefit of providing good auditability and dispute resolution as well as\nsupporting (comparison) risk limiting audits.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 08:22:29 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Roenne", "Peter B.", ""], ["Ryan", "Peter Y. A", ""], ["Zollinger", "Marie-Laure", ""]]}, {"id": "2105.14785", "submitter": "Tianyu Pang", "authors": "Tianyu Pang, Huishuai Zhang, Di He, Yinpeng Dong, Hang Su, Wei Chen,\n  Jun Zhu, Tie-Yan Liu", "title": "Adversarial Training with Rectified Rejection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training (AT) is one of the most effective strategies for\npromoting model robustness, whereas even the state-of-the-art adversarially\ntrained models struggle to exceed 60% robust test accuracy on CIFAR-10 without\nadditional data, which is far from practical. A natural way to break this\naccuracy bottleneck is to introduce a rejection option, where confidence is a\ncommonly used certainty proxy. However, the vanilla confidence can overestimate\nthe model certainty if the input is wrongly classified. To this end, we propose\nto use true confidence (T-Con) (i.e., predicted probability of the true class)\nas a certainty oracle, and learn to predict T-Con by rectifying confidence. We\nprove that under mild conditions, a rectified confidence (R-Con) rejector and a\nconfidence rejector can be coupled to distinguish any wrongly classified input\nfrom correctly classified ones, even under adaptive attacks. We also quantify\nthat training R-Con to be aligned with T-Con could be an easier task than\nlearning robust classifiers. In our experiments, we evaluate our rectified\nrejection (RR) module on CIFAR-10, CIFAR-10-C, and CIFAR-100 under several\nattacks, and demonstrate that the RR module is well compatible with different\nAT frameworks on improving robustness, with little extra computation.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 08:24:53 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Pang", "Tianyu", ""], ["Zhang", "Huishuai", ""], ["He", "Di", ""], ["Dong", "Yinpeng", ""], ["Su", "Hang", ""], ["Chen", "Wei", ""], ["Zhu", "Jun", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2105.14803", "submitter": "Manish Shukla", "authors": "Rosni K Vasu, Sanjay Seetharaman, Shubham Malaviya, Manish Shukla,\n  Sachin Lodha", "title": "Gradient-based Data Subversion Attack Against Binary Classifiers", "comments": "26 pages, 3 Figures, 8 tables, adversarial attacks, data poisoning\n  attacks, label contamination, transferability of attack, susceptibility", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Machine learning based data-driven technologies have shown impressive\nperformances in a variety of application domains. Most enterprises use data\nfrom multiple sources to provide quality applications. The reliability of the\nexternal data sources raises concerns for the security of the machine learning\ntechniques adopted. An attacker can tamper the training or test datasets to\nsubvert the predictions of models generated by these techniques. Data poisoning\nis one such attack wherein the attacker tries to degrade the performance of a\nclassifier by manipulating the training data.\n  In this work, we focus on label contamination attack in which an attacker\npoisons the labels of data to compromise the functionality of the system. We\ndevelop Gradient-based Data Subversion strategies to achieve model degradation\nunder the assumption that the attacker has limited-knowledge of the victim\nmodel. We exploit the gradients of a differentiable convex loss function\n(residual errors) with respect to the predicted label as a warm-start and\nformulate different strategies to find a set of data instances to contaminate.\nFurther, we analyze the transferability of attacks and the susceptibility of\nbinary classifiers. Our experiments show that the proposed approach outperforms\nthe baselines and is computationally efficient.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 09:04:32 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Vasu", "Rosni K", ""], ["Seetharaman", "Sanjay", ""], ["Malaviya", "Shubham", ""], ["Shukla", "Manish", ""], ["Lodha", "Sachin", ""]]}, {"id": "2105.14818", "submitter": "Yacov Manevich", "authors": "Yacov Manevich, Artem Barger, Gal Assa", "title": "Redacting Transactions from Execute-Order-Validate Blockchains", "comments": "IEEE International Conference on Blockchain and Cryptocurrency 2021\n  conference: icbc2021.ieee-icbc.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As user privacy gains popularity and attention, and starts to shape relations\nbetween users and service providers, blockchain based solutions thrive for ways\nto relax immutability without sacrificing consistency. This work answers that\nneed and presents the first design for a redactable execute-order-validate\nblockchain, that grants users with the \\emph{right to be forgotten}. The design\nis easy to adopt, as we exemplify by implementing it on top of Hyperledger\nFabric. It modifies the block structure and extracts user data from the\nhash-chain without loosening any correctness or liveness criteria. We evaluate\nour design and show that it provides compliance with only a minimal performance\noverhead, making it a feasible add-on to any execute-order-validate blockchain\nsystem.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 09:31:24 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 13:58:12 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Manevich", "Yacov", ""], ["Barger", "Artem", ""], ["Assa", "Gal", ""]]}, {"id": "2105.14869", "submitter": "Rikke Bjerg Jensen", "authors": "Martin R. Albrecht, Jorge Blasco, Rikke Bjerg Jensen and Lenka\n  Marekov\\'a", "title": "Collective Information Security in Large-Scale Urban Protests: the Case\n  of Hong Kong", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Anti-Extradition Law Amendment Bill protests in Hong Kong present a rich\ncontext for exploring information security practices among protesters due to\ntheir large-scale urban setting and highly digitalised nature. We conducted\nin-depth, semi-structured interviews with 11 participants of these protests.\nResearch findings reveal how protesters favoured Telegram and relied on its\nsecurity for internal communication and organisation of on-the-ground\ncollective action; were organised in small private groups and large public\ngroups to enable collective action; adopted tactics and technologies that\nenable pseudonymity; and developed a variety of strategies to detect\ncompromises and to achieve forms of forward secrecy and post-compromise\nsecurity when group members were (presumed) arrested. We further show how group\nadministrators had assumed the roles of leaders in these 'leaderless' protests\nand were critical to collective protest efforts.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 10:46:56 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Albrecht", "Martin R.", ""], ["Blasco", "Jorge", ""], ["Jensen", "Rikke Bjerg", ""], ["Marekov\u00e1", "Lenka", ""]]}, {"id": "2105.14932", "submitter": "Qiumei Cheng", "authors": "Qiumei Cheng, Yi Shen, Dezhang Kong, Chunming Wu", "title": "STEP: Spatial-Temporal Network Security Event Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network security events prediction helps network operators to take response\nstrategies from a proactive perspective, and reduce the cost caused by network\nattacks, which is of great significance for maintaining the security of the\nentire network. Most of the existing event prediction methods rely on temporal\ncharacteristics and are dedicated to exploring time series predictions, but\nignoring the spatial relationship between hosts. This paper combines the\ntemporal and spatial characteristics of security events and proposes a\nspatial-temporal event prediction model, named STEP. In particular, STEP\nformulates the security events prediction into a spatial-temporal sequence\nprediction. STEP utilizes graph convolution operation to capture the spatial\ncharacteristics of hosts in the network, and adopts the long short term memory\n(LSTM) to capture the dynamic temporal dependency of events. This paper\nverifies the proposed STEP scheme on two public data sets. The experimental\nresults show that the prediction accuracy of security events under STEP is\nhigher than that of benchmark models such as LSTM, ConvLSTM. Besides, STEP\nachieves high prediction accuracy when we predict events from different lengths\nof sequence.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 12:57:16 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Cheng", "Qiumei", ""], ["Shen", "Yi", ""], ["Kong", "Dezhang", ""], ["Wu", "Chunming", ""]]}, {"id": "2105.14943", "submitter": "Christof Paar", "authors": "Steffen Becker and Carina Wiesen and Nils Albartus and Nikol Rummel\n  and Christof Paar", "title": "An Exploratory Study of Hardware Reverse Engineering Technical and\n  Cognitive Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the internals of Integrated Circuits (ICs), referred to as\nHardware Reverse Engineering (HRE), is of interest to both legitimate and\nmalicious parties. HRE is a complex process in which semi-automated steps are\ninterwoven with human sense-making processes. Currently, little is known about\nthe technical and cognitive processes which determine the success of HRE.\n  This paper performs an initial investigation on how reverse engineers solve\nproblems, how manual and automated analysis methods interact, and which\ncognitive factors play a role. We present the results of an exploratory\nbehavioral study with eight participants that was conducted after they had\ncompleted a 14-week training. We explored the validity of our findings by\ncomparing them with the behavior (strategies applied and solution time) of an\nHRE expert. The participants were observed while solving a realistic HRE task.\nWe tested cognitive abilities of our participants and collected large sets of\nbehavioral data from log files. By comparing the least and most efficient\nreverse engineers, we were able to observe successful strategies. Moreover, our\nanalyses suggest a phase model for reverse engineering, consisting of three\nphases. Our descriptive results further indicate that the cognitive factor\nWorking Memory (WM) might play a role in efficiently solving HRE problems. Our\nexploratory study builds the foundation for future research in this topic and\noutlines ideas for designing cognitively difficult countermeasures (\"cognitive\nobfuscation\") against HRE.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 13:21:52 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Becker", "Steffen", ""], ["Wiesen", "Carina", ""], ["Albartus", "Nils", ""], ["Rummel", "Nikol", ""], ["Paar", "Christof", ""]]}, {"id": "2105.14988", "submitter": "Douglas Stinson", "authors": "Navid Nasr Esfahani and Douglas R. Stinson", "title": "Asymmetric All-or-nothing Transforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we initiate a study of asymmetric all-or-nothing transforms\n(or asymmetric AONTs). A (symmetric) $t$-all-or-nothing transform is a\nbijective mapping defined on the set of $s$-tuples over a specified finite\nalphabet. It is required that knowledge of all but $t$ outputs leaves any $t$\ninputs completely undetermined. There have been numerous papers developing the\ntheory of AONTs as well as presenting various applications of AONTs in\ncryptography and information security.\n  In this paper, we replace the parameter $t$ by two parameters $t_o$ and\n$t_i$, where $t_i \\leq t_o$. The requirement is that knowledge of all but $t_o$\noutputs leaves any $t_i$ inputs completely undetermined. When $t_i < t_o$, we\nrefer to the AONT as asymmetric.\n  We give several constructions and bounds for various classes of asymmetric\nAONTs, especially those with $t_i = 1$ or $t_i = 2$. We pay particular\nattention to linear transforms, where the alphabet is a finite field\n$\\mathbb{F}_q$ and the mapping is linear.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 14:19:27 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Esfahani", "Navid Nasr", ""], ["Stinson", "Douglas R.", ""]]}, {"id": "2105.15007", "submitter": "Anamay Chaturvedi", "authors": "Anamay Chaturvedi, Matthew Jones, Huy L. Nguyen", "title": "Locally Private $k$-Means Clustering with Constant Multiplicative\n  Approximation and Near-Optimal Additive Error", "comments": "61 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given a data set of size $n$ in $d'$-dimensional Euclidean space, the\n$k$-means problem asks for a set of $k$ points (called centers) so that the sum\nof the $\\ell_2^2$-distances between points of a given data set of size $n$ and\nthe set of $k$ centers is minimized. Recent work on this problem in the locally\nprivate setting achieves constant multiplicative approximation with additive\nerror $\\tilde{O} (n^{1/2 + a} \\cdot k \\cdot \\max \\{\\sqrt{d}, \\sqrt{k} \\})$ and\nproves a lower bound of $\\Omega(\\sqrt{n})$ on the additive error for any\nsolution with a constant number of rounds. In this work we bridge the gap\nbetween the exponents of $n$ in the upper and lower bounds on the additive\nerror with two new algorithms. Given any $\\alpha>0$, our first algorithm\nachieves a multiplicative approximation guarantee which is at most a\n$(1+\\alpha)$ factor greater than that of any non-private $k$-means clustering\nalgorithm with $k^{\\tilde{O}(1/\\alpha^2)} \\sqrt{d' n} \\mbox{poly}\\log n$\nadditive error. Given any $c>\\sqrt{2}$, our second algorithm achieves $O(k^{1 +\n\\tilde{O}(1/(2c^2-1))} \\sqrt{d' n} \\mbox{poly} \\log n)$ additive error with\nconstant multiplicative approximation. Both algorithms go beyond the\n$\\Omega(n^{1/2 + a})$ factor that occurs in the additive error for arbitrarily\nsmall parameters $a$ in previous work, and the second algorithm in particular\nshows for the first time that it is possible to solve the locally private\n$k$-means problem in a constant number of rounds with constant factor\nmultiplicative approximation and polynomial dependence on $k$ in the additive\nerror arbitrarily close to linear.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 14:41:40 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Chaturvedi", "Anamay", ""], ["Jones", "Matthew", ""], ["Nguyen", "Huy L.", ""]]}, {"id": "2105.15010", "submitter": "Sizhe Chen", "authors": "Sizhe Chen, Zhehao Huang, Qinghua Tao, Xiaolin Huang", "title": "QueryNet: An Efficient Attack Framework with Surrogates Carrying\n  Multiple Identities", "comments": "QueryNet reduces queries by about an order of magnitude against SOTA\n  black-box attacks. 21 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are acknowledged as vulnerable to adversarial\nattacks, while the existing black-box attacks require extensive queries on the\nvictim DNN to achieve high success rates. For query-efficiency, surrogate\nmodels of the victim are adopted as transferable attackers in consideration of\ntheir Gradient Similarity (GS), i.e., surrogates' attack gradients are similar\nto the victim's ones to some extent. However, it is generally neglected to\nexploit their similarity on outputs, namely the Prediction Similarity (PS), to\nfilter out inefficient queries. To jointly utilize and also optimize\nsurrogates' GS and PS, we develop QueryNet, an efficient attack network that\ncan significantly reduce queries. QueryNet crafts several transferable\nAdversarial Examples (AEs) by surrogates, and then decides also by surrogates\non the most promising AE, which is then sent to query the victim. That is to\nsay, in QueryNet, surrogates are not only exploited as transferable attackers,\nbut also as transferability evaluators for AEs. The AEs are generated using\nsurrogates' GS and evaluated based on their FS, and therefore, the query\nresults could be back-propagated to optimize surrogates' parameters and also\ntheir architectures, enhancing both the GS and the FS. QueryNet has significant\nquery-efficiency, i.e., reduces queries by averagely about an order of\nmagnitude compared to recent SOTA methods according to our comprehensive and\nreal-world experiments: 11 victims (including 2 commercial models) on\nMNIST/CIFAR10/ImageNet, allowing only 8-bit image queries, and no access to the\nvictim's training data.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 14:45:10 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Chen", "Sizhe", ""], ["Huang", "Zhehao", ""], ["Tao", "Qinghua", ""], ["Huang", "Xiaolin", ""]]}, {"id": "2105.15035", "submitter": "Anum Talpur", "authors": "Anum Talpur and Mohan Gurusamy", "title": "Machine Learning for Security in Vehicular Networks: A Comprehensive\n  Survey", "comments": "Submitted in IEEE Communications Surveys & Tutorials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) has emerged as an attractive and viable technique to\nprovide effective solutions for a wide range of application domains. An\nimportant application domain is vehicular networks wherein ML-based approaches\nare found to be very useful to address various problems. The use of wireless\ncommunication between vehicular nodes and/or infrastructure makes it vulnerable\nto different types of attacks. In this regard, ML and its variants are gaining\npopularity to detect attacks and deal with different kinds of security issues\nin vehicular communication. In this paper, we present a comprehensive survey of\nML-based techniques for different security issues in vehicular networks. We\nfirst briefly introduce the basics of vehicular networks and different types of\ncommunications. Apart from the traditional vehicular networks, we also consider\nmodern vehicular network architectures. We propose a taxonomy of security\nattacks in vehicular networks and discuss various security challenges and\nrequirements. We classify the ML techniques developed in the literature\naccording to their use in vehicular network applications. We explain the\nsolution approaches and working principles of these ML techniques in addressing\nvarious security challenges and provide insightful discussion. The limitations\nand challenges in using ML-based methods in vehicular networks are discussed.\nFinally, we present observations and lessons learned before we conclude our\nwork.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 15:15:03 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Talpur", "Anum", ""], ["Gurusamy", "Mohan", ""]]}, {"id": "2105.15057", "submitter": "Zhixing Ye", "authors": "Zhixing Ye, Shaofei Qin, Sizhe Chen, Xiaolin Huang", "title": "Dominant Patterns: Critical Features Hidden in Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we find the existence of critical features hidden in Deep\nNeuralNetworks (DNNs), which are imperceptible but can actually dominate the\noutputof DNNs. We call these features dominant patterns. As the name suggests,\nfor a natural image, if we add the dominant pattern of a DNN to it, the output\nof this DNN is determined by the dominant pattern instead of the original\nimage, i.e., DNN's prediction is the same with the dominant pattern's. We\ndesign an algorithm to find such patterns by pursuing the insensitivity in the\nfeature space. A direct application of the dominant patterns is the Universal\nAdversarial Perturbations(UAPs). Numerical experiments show that the found\ndominant patterns defeat state-of-the-art UAP methods, especially in label-free\nsettings. In addition, dominant patterns are proved to have the potential to\nattack downstream tasks in which DNNs share the same backbone. We claim that\nDNN-specific dominant patterns reveal some essential properties of a DNN and\nare of great importance for its feature analysis and robustness enhancement.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 15:43:04 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Ye", "Zhixing", ""], ["Qin", "Shaofei", ""], ["Chen", "Sizhe", ""], ["Huang", "Xiaolin", ""]]}]