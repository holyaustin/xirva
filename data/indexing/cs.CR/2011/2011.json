[{"id": "2011.00083", "submitter": "Ziteng Sun", "authors": "Jayadev Acharya, Peter Kairouz, Yuhan Liu, Ziteng Sun", "title": "Estimating Sparse Discrete Distributions Under Local Privacy and\n  Communication Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.DS cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating sparse discrete distributions under\nlocal differential privacy (LDP) and communication constraints. We characterize\nthe sample complexity for sparse estimation under LDP constraints up to a\nconstant factor and the sample complexity under communication constraints up to\na logarithmic factor. Our upper bounds under LDP are based on the Hadamard\nResponse, a private coin scheme that requires only one bit of communication per\nuser. Under communication constraints, we propose public coin schemes based on\nrandom hashing functions. Our tight lower bounds are based on the recently\nproposed method of chi squared contractions.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 20:06:35 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 19:48:16 GMT"}, {"version": "v3", "created": "Fri, 19 Feb 2021 04:06:00 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Acharya", "Jayadev", ""], ["Kairouz", "Peter", ""], ["Liu", "Yuhan", ""], ["Sun", "Ziteng", ""]]}, {"id": "2011.00087", "submitter": "Canran Wang", "authors": "Canran Wang and Netanel Raviv", "title": "Low Latency Cross-Shard Transactions in Coded Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although blockchain, the supporting technology of Bitcoin and various\ncryptocurrencies, has offered a potentially effective framework for numerous\napplications, it still suffers from the adverse affects of the impossibility\ntriangle. Performance, security, and decentralization of blockchains normally\ndo not scale simultaneously with the number of participants in the network. The\nrecent introduction of error correcting codes in sharded blockchain by Li et\nal. partially settles this trilemma, boosting throughput without compromising\nsecurity and decentralization. In this paper, we improve the coded sharding\nscheme in three ways. First, we propose a novel 2-Dimensional Sharding\nstrategy, which inherently supports cross-shard transactions, alleviating the\nneed for complicated inter-shard communication protocols. Second, we employ\ndistributed storage techniques in the propagation of blocks, improving latency\nunder restricted bandwidth. Finally, we incorporate polynomial cryptographic\nprimitives of low degree, which brings coded blockchain techniques into the\nrealm of feasible real-world parameters.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 20:12:05 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Wang", "Canran", ""], ["Raviv", "Netanel", ""]]}, {"id": "2011.00101", "submitter": "Dongrui Wu", "authors": "Lubin Meng, Jian Huang, Zhigang Zeng, Xue Jiang, Shan Yu, Tzyy-Ping\n  Jung, Chin-Teng Lin, Ricardo Chavarriaga, Dongrui Wu", "title": "EEG-Based Brain-Computer Interfaces Are Vulnerable to Backdoor Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research and development of electroencephalogram (EEG) based brain-computer\ninterfaces (BCIs) have advanced rapidly, partly due to deeper understanding of\nthe brain and wide adoption of sophisticated machine learning approaches for\ndecoding the EEG signals. However, recent studies have shown that machine\nlearning algorithms are vulnerable to adversarial attacks. This article\nproposes to use narrow period pulse for poisoning attack of EEG-based BCIs,\nwhich is implementable in practice and has never been considered before. One\ncan create dangerous backdoors in the machine learning model by injecting\npoisoning samples into the training set. Test samples with the backdoor key\nwill then be classified into the target class specified by the attacker. What\nmost distinguishes our approach from previous ones is that the backdoor key\ndoes not need to be synchronized with the EEG trials, making it very easy to\nimplement. The effectiveness and robustness of the backdoor attack approach is\ndemonstrated, highlighting a critical security concern for EEG-based BCIs and\ncalling for urgent attention to address it.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 20:49:42 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 23:16:26 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Meng", "Lubin", ""], ["Huang", "Jian", ""], ["Zeng", "Zhigang", ""], ["Jiang", "Xue", ""], ["Yu", "Shan", ""], ["Jung", "Tzyy-Ping", ""], ["Lin", "Chin-Teng", ""], ["Chavarriaga", "Ricardo", ""], ["Wu", "Dongrui", ""]]}, {"id": "2011.00102", "submitter": "Peiyao Sheng", "authors": "Peiyao Sheng, Bowen Xue, Sreeram Kannan, Pramod Viswanath", "title": "ACeD: Scalable Data Availability Oracle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular method in practice offloads computation and storage in blockchains\nby relying on committing only hashes of off-chain data into the blockchain.\nThis mechanism is acknowledged to be vulnerable to a stalling attack: the\nblocks corresponding to the committed hashes may be unavailable at any honest\nnode. The straightforward solution of broadcasting all blocks to the entire\nnetwork sidesteps this data availability attack, but it is not scalable. In\nthis paper, we propose ACeD, a scalable solution to this data availability\nproblem with $O(1)$ communication efficiency, the first to the best of our\nknowledge.\n  The key innovation is a new protocol that requires each of the $N$ nodes to\nreceive only $O(1/N)$ of the block, such that the data is guaranteed to be\navailable in a distributed manner in the network. Our solution creatively\nintegrates coding-theoretic designs inside of Merkle tree commitments to\nguarantee efficient and tamper-proof reconstruction; this solution is distinct\nfrom Asynchronous Verifiable Information Dispersal (in guaranteeing efficient\nproofs of malformed coding) and Coded Merkle Tree (which only provides\nguarantees for random corruption as opposed to our guarantees for worst-case\ncorruption). We implement ACeD with full functionality in 6000 lines of Rust\ncode, integrate the functionality as a smart contract into Ethereum via a\nhigh-performance implementation demonstrating up to 10,000 transactions per\nsecond in throughput and 6000x reduction in gas cost on the Ethereum testnet\nKovan.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 20:51:11 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 19:59:00 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Sheng", "Peiyao", ""], ["Xue", "Bowen", ""], ["Kannan", "Sreeram", ""], ["Viswanath", "Pramod", ""]]}, {"id": "2011.00164", "submitter": "Fanhua Shang", "authors": "Tao Xu, Fanhua Shang, Yuanyuan Liu, Hongying Liu, Longjie Shen, Maoguo\n  Gong", "title": "Differentially Private ADMM Algorithms for Machine Learning", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study efficient differentially private alternating\ndirection methods of multipliers (ADMM) via gradient perturbation for many\nmachine learning problems. For smooth convex loss functions with (non)-smooth\nregularization, we propose the first differentially private ADMM (DP-ADMM)\nalgorithm with performance guarantee of $(\\epsilon,\\delta)$-differential\nprivacy ($(\\epsilon,\\delta)$-DP). From the viewpoint of theoretical analysis,\nwe use the Gaussian mechanism and the conversion relationship between R\\'enyi\nDifferential Privacy (RDP) and DP to perform a comprehensive privacy analysis\nfor our algorithm. Then we establish a new criterion to prove the convergence\nof the proposed algorithms including DP-ADMM. We also give the utility analysis\nof our DP-ADMM. Moreover, we propose an accelerated DP-ADMM (DP-AccADMM) with\nthe Nesterov's acceleration technique. Finally, we conduct numerical\nexperiments on many real-world datasets to show the privacy-utility tradeoff of\nthe two proposed algorithms, and all the comparative analysis shows that\nDP-AccADMM converges faster and has a better utility than DP-ADMM, when the\nprivacy budget $\\epsilon$ is larger than a threshold.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 01:37:24 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Xu", "Tao", ""], ["Shang", "Fanhua", ""], ["Liu", "Yuanyuan", ""], ["Liu", "Hongying", ""], ["Shen", "Longjie", ""], ["Gong", "Maoguo", ""]]}, {"id": "2011.00176", "submitter": "Guang Hua Dr.", "authors": "Guang Hua, Qingyi Wang, Dengpan Ye, Haijian Zhang", "title": "Reliability of Power System Frequency on Times-Stamping Digital\n  Recordings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power system frequency could be captured by digital recordings and extracted\nto compare with a reference database for forensic time-stamp verification. It\nis known as the electric network frequency (ENF) criterion, enabled by the\nproperties of random fluctuation and intra-grid consistency. In essence, this\nis a task of matching a short random sequence within a long reference, and the\nreliability of this criterion is mainly concerned with whether this match could\nbe unique and correct. In this paper, we comprehensively analyze the factors\naffecting the reliability of ENF matching, including length of test recording,\nlength of reference, temporal resolution, and signal-to-noise ratio (SNR). For\nsynthetic analysis, we incorporate the first-order autoregressive (AR) ENF\nmodel and propose an efficient time-frequency domain (TFD) noisy ENF synthesis\nmethod. Then, the reliability analysis schemes for both synthetic and\nreal-world data are respectively proposed. Through a comprehensive study we\nreveal that while the SNR is an important external factor to determine whether\ntime-stamp verification is viable, the length of test recording is the most\nimportant inherent factor, followed by the length of reference. However, the\ntemporal resolution has little impact on the matching process.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 03:13:16 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Hua", "Guang", ""], ["Wang", "Qingyi", ""], ["Ye", "Dengpan", ""], ["Zhang", "Haijian", ""]]}, {"id": "2011.00177", "submitter": "Maoqiang Wu", "authors": "Maoqiang Wu, Xinyue Zhang, Jiahao Ding, Hien Nguyen, Rong Yu, Miao\n  Pan, Stephen T. Wong", "title": "Evaluation of Inference Attack Models for Deep Learning on Medical Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has attracted broad interest in healthcare and medical\ncommunities. However, there has been little research into the privacy issues\ncreated by deep networks trained for medical applications. Recently developed\ninference attack algorithms indicate that images and text records can be\nreconstructed by malicious parties that have the ability to query deep\nnetworks. This gives rise to the concern that medical images and electronic\nhealth records containing sensitive patient information are vulnerable to these\nattacks. This paper aims to attract interest from researchers in the medical\ndeep learning community to this important problem. We evaluate two prominent\ninference attack models, namely, attribute inference attack and model inversion\nattack. We show that they can reconstruct real-world medical images and\nclinical reports with high fidelity. We then investigate how to protect\npatients' privacy using defense mechanisms, such as label perturbation and\nmodel perturbation. We provide a comparison of attack results between the\noriginal and the medical deep learning models with defenses. The experimental\nevaluations show that our proposed defense approaches can effectively reduce\nthe potential privacy leakage of medical deep learning from the inference\nattacks.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 03:18:36 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Wu", "Maoqiang", ""], ["Zhang", "Xinyue", ""], ["Ding", "Jiahao", ""], ["Nguyen", "Hien", ""], ["Yu", "Rong", ""], ["Pan", "Miao", ""], ["Wong", "Stephen T.", ""]]}, {"id": "2011.00253", "submitter": "Nikos Vasilakis", "authors": "Nikos Vasilakis (MIT), Cristian-Alexandru Staicu (CISPA Helmholtz\n  Center for Information Security), Grigoris Ntousakis (TU Crete), Konstantinos\n  Kallas (University of Pennsylvania), Ben Karel (Aarno Labs), Andr\\'e DeHon\n  (University of Pennsylvania), Michael Pradel (University of Stuttgart)", "title": "Mir: Automated Quantifiable Privilege Reduction Against Dynamic Library\n  Compromise in JavaScript", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Third-party libraries ease the development of large-scale software systems.\nHowever, they often execute with significantly more privilege than needed to\ncomplete their task. This additional privilege is often exploited at runtime\nvia dynamic compromise, even when these libraries are not actively malicious.\nMir addresses this problem by introducing a fine-grained read-write-execute\n(RWX) permission model at the boundaries of libraries. Every field of an\nimported library is governed by a set of permissions, which developers can\nexpress when importing libraries. To enforce these permissions during program\nexecution, Mir transforms libraries and their context to add runtime checks. As\npermissions can overwhelm developers, Mir's permission inference generates\ndefault permissions by analyzing how libraries are used by their consumers.\nApplied to 50 popular libraries, Mir's prototype for JavaScript demonstrates\nthat the RWX permission model combines simplicity with power: it is simple\nenough to automatically infer 99.33% of required permissions, it is expressive\nenough to defend against 16 real threats, it is efficient enough to be usable\nin practice (1.93% overhead), and it enables a novel quantification of\nprivilege reduction.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 11:56:47 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2021 16:08:27 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Vasilakis", "Nikos", "", "MIT"], ["Staicu", "Cristian-Alexandru", "", "CISPA Helmholtz\n  Center for Information Security"], ["Ntousakis", "Grigoris", "", "TU Crete"], ["Kallas", "Konstantinos", "", "University of Pennsylvania"], ["Karel", "Ben", "", "Aarno Labs"], ["DeHon", "Andr\u00e9", "", "University of Pennsylvania"], ["Pradel", "Michael", "", "University of Stuttgart"]]}, {"id": "2011.00319", "submitter": "Amirahmad Chapnevis", "authors": "Amirahmad Chapnevis, Babak Sadeghiyan", "title": "A Secure Two-Party Computation Protocol for Intersection Detection\n  between Two Convex Hulls", "comments": "11 Pages, 2 Tables, 40 formulas, and 6 figures This paper is\n  presented in CSICC2019, Computer Society of Iran Computer Conference, Sharif\n  University of Technology, Tehran 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intersection detection between three-dimensional bodies has various\napplications in computer graphics, video game development, robotics as well as\nmilitary industries. In some respects, entities do not want to disclose\nsensitive information about themselves, including their location. In this\npaper, we present a secure two-party protocol to determine the existence of an\nintersection between entities. The protocol presented in this paper allows for\nintersection detection in three-dimensional spaces in geometry. Our approach is\nto use an intersecting plane between two spaces to determine their separation\nor intersection. For this purpose, we introduce a computational geometry\nprotocol to determine the existence of an intersecting plane. In this paper, we\nfirst use the Minkowski difference to reduce the two-space problem into\none-space. Then, the separating set is obtained and the separation of two\nshapes is determined based on the inclusion of the center point. We then secure\nthe protocol by modifying the separating set computation method as a\nprivacy-preserver and changing the Minkowski difference method to achieve this\ngoal. The proposed protocol applies to any form of convex three-dimensional\nshape. The experiments successfully found a secure protocol for intersection\ndetection between two convex hulls in geometrical shapes such as the pyramid\nand cuboid.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 17:21:13 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 18:22:02 GMT"}, {"version": "v3", "created": "Fri, 21 May 2021 17:08:37 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Chapnevis", "Amirahmad", ""], ["Sadeghiyan", "Babak", ""]]}, {"id": "2011.00418", "submitter": "Xiaoguang Li", "authors": "Haonan Yan, Xiaoguang Li, Hui Li, Jiamin Li, Wenhai Sun and Fenghua Li", "title": "Monitoring-based Differential Privacy Mechanism Against Query-Flooding\n  Parameter Duplication Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public intelligent services enabled by machine learning algorithms are\nvulnerable to model extraction attacks that can steal confidential information\nof the learning models through public queries. Though there are some protection\noptions such as differential privacy (DP) and monitoring, which are considered\npromising techniques to mitigate this attack, we still find that the\nvulnerability persists. In this paper, we propose an adaptive query-flooding\nparameter duplication (QPD) attack. The adversary can infer the model\ninformation with black-box access and no prior knowledge of any model\nparameters or training data via QPD. We also develop a defense strategy using\nDP called monitoring-based DP (MDP) against this new attack. In MDP, we first\npropose a novel real-time model extraction status assessment scheme called\nMonitor to evaluate the situation of the model. Then, we design a method to\nguide the differential privacy budget allocation called APBA adaptively.\nFinally, all DP-based defenses with MDP could dynamically adjust the amount of\nnoise added in the model response according to the result from Monitor and\neffectively defends the QPD attack. Furthermore, we thoroughly evaluate and\ncompare the QPD attack and MDP defense performance on real-world models with DP\nand monitoring protection.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 04:21:48 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Yan", "Haonan", ""], ["Li", "Xiaoguang", ""], ["Li", "Hui", ""], ["Li", "Jiamin", ""], ["Sun", "Wenhai", ""], ["Li", "Fenghua", ""]]}, {"id": "2011.00467", "submitter": "Tejas Kulkarni", "authors": "Tejas Kulkarni, Joonas J\\\"alk\\\"o, Antti Koskela, Samuel Kaski and\n  Antti Honkela", "title": "Differentially Private Bayesian Inference for Generalized Linear Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generalized linear models (GLMs) such as logistic regression are among the\nmost widely used arms in data analyst's repertoire and often used on sensitive\ndatasets. A large body of prior works that investigate GLMs under differential\nprivacy (DP) constraints provide only private point estimates of the regression\ncoefficients, and are not able to quantify parameter uncertainty. In this work,\nwith logistic and Poisson regression as running examples, we introduce a\ngeneric noise-aware DP Bayesian inference method for a GLM at hand, given a\nnoisy sum of summary statistics. Quantifying uncertainty allows us to determine\nwhich of the regression coefficients are statistically significantly different\nfrom zero. We provide a previously unknown tight privacy analysis and\nexperimentally demonstrate that the posteriors obtained from our model, while\nadhering to strong privacy guarantees, are close to the non-private posteriors.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 10:38:22 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 15:05:08 GMT"}, {"version": "v3", "created": "Wed, 12 May 2021 08:57:39 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Kulkarni", "Tejas", ""], ["J\u00e4lk\u00f6", "Joonas", ""], ["Koskela", "Antti", ""], ["Kaski", "Samuel", ""], ["Honkela", "Antti", ""]]}, {"id": "2011.00512", "submitter": "Hanzhou Wu", "authors": "Xiangyu Zhao, Hanzhou Wu and Xinpeng Zhang", "title": "Watermarking Graph Neural Networks by Random Graphs", "comments": "https://hzwu.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many learning tasks require us to deal with graph data which contains rich\nrelational information among elements, leading increasing graph neural network\n(GNN) models to be deployed in industrial products for improving the quality of\nservice. However, they also raise challenges to model authentication. It is\nnecessary to protect the ownership of the GNN models, which motivates us to\npresent a watermarking method to GNN models in this paper. In the proposed\nmethod, an Erdos-Renyi (ER) random graph with random node feature vectors and\nlabels is randomly generated as a trigger to train the GNN to be protected\ntogether with the normal samples. During model training, the secret watermark\nis embedded into the label predictions of the ER graph nodes. During model\nverification, by activating a marked GNN with the trigger ER graph, the\nwatermark can be reconstructed from the output to verify the ownership. Since\nthe ER graph was randomly generated, by feeding it to a non-marked GNN, the\nlabel predictions of the graph nodes are random, resulting in a low false alarm\nrate (of the proposed work). Experimental results have also shown that, the\nperformance of a marked GNN on its original task will not be impaired.\nMoreover, it is robust against model compression and fine-tuning, which has\nshown the superiority and applicability.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 14:22:48 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 12:18:42 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Zhao", "Xiangyu", ""], ["Wu", "Hanzhou", ""], ["Zhang", "Xinpeng", ""]]}, {"id": "2011.00540", "submitter": "Huy Kang Kim", "authors": "Kyung Ho Park, Eunji Park, Huy Kang Kim", "title": "Unsupervised Intrusion Detection System for Unmanned Aerial Vehicle with\n  Less Labeling Effort", "comments": "14 pages, 4 tables, 3 figures, 5 equations, In Proceeding of WISA\n  2020 (THE 21ST WORLD CONFERENCE ON INFORMATION SECURITY APPLICATIONS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Along with the importance of safety, an IDS has become a significant task in\nthe real world. Prior studies proposed various intrusion detection models for\nthe UAV. Past rule-based approaches provided a concrete baseline IDS model, and\nthe machine learning-based method achieved a precise intrusion detection\nperformance on the UAV with supervised learning models. However, previous\nmethods have room for improvement to be implemented in the real world. Prior\nmethods required a large labeling effort on the dataset, and the model could\nnot identify attacks that were not trained before. To jump over these hurdles,\nwe propose an IDS with unsupervised learning. As unsupervised learning does not\nrequire labeling, our model let the practitioner not to label every type of\nattack from the flight data. Moreover, the model can identify an abnormal\nstatus of the UAV regardless of the type of attack. We trained an autoencoder\nwith the benign flight data only and checked the model provides a different\nreconstruction loss at the benign flight and the flight under attack. We\ndiscovered that the model produces much higher reconstruction loss with the\nflight under attack than the benign flight; thus, this reconstruction loss can\nbe utilized to recognize an intrusion to the UAV. With consideration of the\ncomputation overhead and the detection performance in the wild, we expect our\nmodel can be a concrete and practical baseline IDS on the UAV.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 15:52:22 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Park", "Kyung Ho", ""], ["Park", "Eunji", ""], ["Kim", "Huy Kang", ""]]}, {"id": "2011.00566", "submitter": "Hang Zhou", "authors": "Hang Zhou, Dongdong Chen, Jing Liao, Weiming Zhang, Kejiang Chen,\n  Xiaoyi Dong, Kunlin Liu, Gang Hua and Nenghai Yu", "title": "LG-GAN: Label Guided Adversarial Network for Flexible Targeted Attack of\n  Point Cloud-based Deep Networks", "comments": "CVPR 2020, code available at: https://github.com/RyanHangZhou/LG-GAN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have made tremendous progress in 3D point-cloud\nrecognition. Recent works have shown that these 3D recognition networks are\nalso vulnerable to adversarial samples produced from various attack methods,\nincluding optimization-based 3D Carlini-Wagner attack, gradient-based iterative\nfast gradient method, and skeleton-detach based point-dropping. However, after\na careful analysis, these methods are either extremely slow because of the\noptimization/iterative scheme, or not flexible to support targeted attack of a\nspecific category. To overcome these shortcomings, this paper proposes a novel\nlabel guided adversarial network (LG-GAN) for real-time flexible targeted point\ncloud attack. To the best of our knowledge, this is the first generation based\n3D point cloud attack method. By feeding the original point clouds and target\nattack label into LG-GAN, it can learn how to deform the point clouds to\nmislead the recognition network into the specific label only with a single\nforward pass. In detail, LGGAN first leverages one multi-branch adversarial\nnetwork to extract hierarchical features of the input point clouds, then\nincorporates the specified label information into multiple intermediate\nfeatures using the label encoder. Finally, the encoded features will be fed\ninto the coordinate reconstruction decoder to generate the target adversarial\nsample. By evaluating different point-cloud recognition models (e.g., PointNet,\nPointNet++ and DGCNN), we demonstrate that the proposed LG-GAN can support\nflexible targeted attack on the fly while guaranteeing good attack performance\nand higher efficiency simultaneously.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 17:17:10 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Zhou", "Hang", ""], ["Chen", "Dongdong", ""], ["Liao", "Jing", ""], ["Zhang", "Weiming", ""], ["Chen", "Kejiang", ""], ["Dong", "Xiaoyi", ""], ["Liu", "Kunlin", ""], ["Hua", "Gang", ""], ["Yu", "Nenghai", ""]]}, {"id": "2011.00575", "submitter": "Unnikrishnan Menon", "authors": "Unnikrishnan Menon and Anirudh Rajiv Menon and Atharva Hudlikar", "title": "A Novel Chaotic System for Text Encryption Optimized with Genetic\n  Algorithm", "comments": "7 pages, 5 figures, 1 table", "journal-ref": "International Journal of Advanced Computer Science and\n  Applications(IJACSA), 11(10), 2020", "doi": "10.14569/IJACSA.2020.0111005", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With meteoric developments in communication systems and data storage\ntechnologies, the need for secure data transmission is more crucial than ever.\nThe level of security provided by any cryptosystem relies on the sensitivity of\nthe private key, size of the key space as well as the trapdoor function being\nused. In order to satisfy the aforementioned constraints, there has been a\ngrowing interest over the past few years, in studying the behavior of chaotic\nsystems and their applications in various fields such as data encryption due to\ncharacteristics like randomness, unpredictability and sensitivity of the\ngenerated sequence to the initial value and its parameters. This paper utilizes\na novel 2D chaotic function that displays a uniform bifurcation over a large\nrange of parameters and exhibits high levels of chaotic behavior to generate a\nrandom sequence that is used to encrypt the input data. The proposed method\nuses a genetic algorithm to optimize the parameters of the map to enhance\nsecurity for any given textual data. Various analyses demonstrate an adequately\nlarge key space and the existence of multiple global optima indicating the\nnecessity of the proposed system and the security provided by it.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 17:56:57 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Menon", "Unnikrishnan", ""], ["Menon", "Anirudh Rajiv", ""], ["Hudlikar", "Atharva", ""]]}, {"id": "2011.00582", "submitter": "Jason Pittman", "authors": "Jason M. Pittman, Kyle Hoffpauir, Nathan Markle", "title": "Primer -- A Tool for Testing Honeypot Measures of Effectiveness", "comments": "4 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Honeypots are a deceptive technology used to capture malicious activity. The\ntechnology is useful for studying attacker behavior, tools, and techniques but\ncan be difficult to implement and maintain. Historically, a lack of measures of\neffectiveness prevented researchers from assessing honeypot implementations.\nThe consequence being ineffective implementations leading to poor performance,\nflawed imitation of legitimate services, and premature discovery by attackers.\nPreviously, we developed a taxonomy for measures of effectiveness in dynamic\nhoneypot implementations. The measures quantify a dynamic honeypot's\neffectiveness in fingerprinting its environment, capturing valid data from\nadversaries, deceiving adversaries, and intelligently monitoring itself and its\nsurroundings. As a step towards developing automated effectiveness testing,\nthis work introduces a tool for priming a target honeypot for evaluation. We\noutline the design of the tool and provide results in the form of quantitative\ncalibration data.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 18:24:07 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Pittman", "Jason M.", ""], ["Hoffpauir", "Kyle", ""], ["Markle", "Nathan", ""]]}, {"id": "2011.00675", "submitter": "Chang Xu", "authors": "Chang Xu, Jun Wang, Yuqing Tang, Francisco Guzman, Benjamin I. P.\n  Rubinstein, Trevor Cohn", "title": "A Targeted Attack on Black-Box Neural Machine Translation with Parallel\n  Data Poisoning", "comments": "In Proceedings of the 2021 World Wide Web Conference (WWW 2021)", "journal-ref": null, "doi": "10.1145/3442381.3450034", "report-no": null, "categories": "cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As modern neural machine translation (NMT) systems have been widely deployed,\ntheir security vulnerabilities require close scrutiny. Most recently, NMT\nsystems have been found vulnerable to targeted attacks which cause them to\nproduce specific, unsolicited, and even harmful translations. These attacks are\nusually exploited in a white-box setting, where adversarial inputs causing\ntargeted translations are discovered for a known target system. However, this\napproach is less viable when the target system is black-box and unknown to the\nadversary (e.g., secured commercial systems). In this paper, we show that\ntargeted attacks on black-box NMT systems are feasible, based on poisoning a\nsmall fraction of their parallel training data. We show that this attack can be\nrealised practically via targeted corruption of web documents crawled to form\nthe system's training data. We then analyse the effectiveness of the targeted\npoisoning in two common NMT training scenarios: the from-scratch training and\nthe pre-train & fine-tune paradigm. Our results are alarming: even on the\nstate-of-the-art systems trained with massive parallel data (tens of millions),\nthe attacks are still successful (over 50% success rate) under surprisingly low\npoisoning budgets (e.g., 0.006%). Lastly, we discuss potential defences to\ncounter such attacks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 01:52:46 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 05:10:33 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Xu", "Chang", ""], ["Wang", "Jun", ""], ["Tang", "Yuqing", ""], ["Guzman", "Francisco", ""], ["Rubinstein", "Benjamin I. P.", ""], ["Cohn", "Trevor", ""]]}, {"id": "2011.00718", "submitter": "Song Fang", "authors": "Song Fang and Quanyan Zhu", "title": "Fundamental Limits of Obfuscation for Linear Gaussian Dynamical Systems:\n  An Information-Theoretic Approach", "comments": "arXiv admin note: text overlap with arXiv:2008.04893", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.LG cs.SY eess.SP eess.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the fundamental limits of obfuscation in terms of\nprivacy-distortion tradeoffs for linear Gaussian dynamical systems via an\ninformation-theoretic approach. Particularly, we obtain analytical formulas\nthat capture the fundamental privacy-distortion tradeoffs when privacy masks\nare to be added to the outputs of the dynamical systems, while indicating\nexplicitly how to design the privacy masks in an optimal way: The privacy masks\nshould be colored Gaussian with power spectra shaped specifically based upon\nthe system and noise properties.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 20:05:50 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Fang", "Song", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2011.00720", "submitter": "Carlos Luna Dr.", "authors": "Guido De Luca and Carlos Luna", "title": "Towards a certified reference monitor of the Android 10 permission\n  system", "comments": "arXiv admin note: substantial text overlap with arXiv:1709.03652", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android is a platform for mobile devices that captures more than 85% of the\ntotal market-share. Currently, mobile devices allow people to develop multiple\ntasks in different areas. Regrettably, the benefits of using mobile devices are\ncounteracted by increasing security risks. The important and critical role of\nthese systems makes them a prime target for formal verification. In our\nprevious work (LNCS 10855, https://doi.org/10.1007/978-3-319-94460-9_16), we\nexhibited a formal specification of an idealized formulation of the permission\nmodel of version \\texttt{6} of Android. In this paper we present an enhanced\nversion of the model in the proof-assistant Coq, including the most relevant\nchanges concerning the permission system introduced on versions Nougat, Oreo,\nPie and 10. The properties that we had proved earlier for the security model\nhas been either revalidated or refuted, and new ones have been formulated and\nproved. Additionally, we make observations on the security of the most recent\nversions of Android. Using the programming language of Coq we have developed a\nfunctional implementation of a reference validation mechanism and certified its\ncorrectness. The formal development is about 23k LOC of Coq, including proofs.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 21:02:34 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["De Luca", "Guido", ""], ["Luna", "Carlos", ""]]}, {"id": "2011.00874", "submitter": "Bernd Pr\\\"unster", "authors": "Bernd Pr\\\"unster, Alexander Marsalek, Thomas Zefferer", "title": "Total Eclipse of the Heart -- Disrupting the InterPlanetary File System", "comments": "Submitted for peer review to the 30th USENIX Security Symposium\n  (USENIX Security 21). Published as part of responsible disclosure agreements\n  made in Spring 2020 (see also https://blog.ipfs.io/2020-10-30-dht-hardening/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer-to-peer networks are an attractive alternative to classical\nclient-server architectures in several fields of application such as\nvoice-over-IP telephony and file sharing. Recently, a new peer-to-peer solution\ncalled the InterPlanetary File System (IPFS) has attracted attention, which\npromises to re-decentralise the Web. Being increasingly used as a stand-alone\napplication, IPFS has also emerged as the technical backbone of various other\ndecentralised solutions and was even used to evade censorship. Decentralised\napplications serving millions of users rely on IPFS as one of their crucial\nbuilding blocks. This popularity makes IPFS attractive for large-scale attacks.\nWe have identified a conceptual issue in one of IPFS's core libraries and\ndemonstrate their exploitation by means of a successful end-to-end attack. We\nevaluated this attack against the IPFS reference implementation on the public\nIPFS network, which is used by the average user to share and consume IPFS\ncontent. Results obtained from mounting this attack on live IPFS nodes show\nthat arbitrary IPFS nodes can be eclipsed, i.e. isolated from the network, with\nmoderate effort and limited resources. Compared to similar works, we show that\nour attack scales linearly even beyond current network sizes and can disrupt\nthe entire public IPFS network with alarmingly low effort. The vulnerability\nset described in this paper has been assigned CVE-2020-10937. Responsible\ndisclosure procedures are currently being carried out and have led to\nmitigations being deployed, with additional fixes to be rolled out in future\nreleases.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 10:29:31 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Pr\u00fcnster", "Bernd", ""], ["Marsalek", "Alexander", ""], ["Zefferer", "Thomas", ""]]}, {"id": "2011.00976", "submitter": "Wen Huang", "authors": "Wen Huang, Shijie Zhou, Tianqing Zhu, Yongjian Liao", "title": "Improving Utility of Differentially Private Mechanisms through\n  Cryptography-based Technologies: a Survey", "comments": "18 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to successful applications of data analysis technologies in many fields,\nvarious institutions have accumulated a large amount of data to improve their\nservices. As the speed of data collection has increased dramatically over the\nlast few years, an increasing number of users are growing concerned about their\npersonal information. Therefore, privacy preservation has become an urgent\nproblem to be solved. Differential privacy as a strong privacy preservation\ntool has attracted significant attention. In this survey, we focus on improving\nutility of between differentially private mechanisms through technologies\nrelated to cryptography. In particular, we firstly focus on how to improve\nutility through anonymous communication. Then, we summarize how to improve\nutility by combining differentially private mechanisms with homomorphic\nencryption schemes. Next, we summarize hardness results of what is impossible\nto achieve for differentially private mechanisms' utility from the view of\ncryptography. Differential privacy borrowed intuitions from cryptography and\nstill benefits from the progress of cryptography. To summarize the\nstate-of-the-art and to benefit future researches, we are motivated to provide\nthis survey.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 13:53:10 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 04:59:37 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Huang", "Wen", ""], ["Zhou", "Shijie", ""], ["Zhu", "Tianqing", ""], ["Liao", "Yongjian", ""]]}, {"id": "2011.00985", "submitter": "Aristides Dasso Mr", "authors": "A. Dasso, A. Funes, D. Riesco, G. Montejano", "title": "Computing Power, Key Length and Cryptanalysis. An Unending Battle?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are several methods to measure computing power. On the other hand, Bit\nLength (BL) can be considered a metric to measure the strength of an asymmetric\nencryption method. We review here ways to determine the security, given an span\nof time, of a factoring-based encryption method, such as RSA, by establishing a\nrelation between the processing power needed to break a given encryption and\nthe given bit length used in the encryption. This relation would help us\nprovide an estimation of the time span that an encryption method for a given BL\nwill be secure from attacks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 14:03:14 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Dasso", "A.", ""], ["Funes", "A.", ""], ["Riesco", "D.", ""], ["Montejano", "G.", ""]]}, {"id": "2011.01032", "submitter": "Elisa Gorla", "authors": "M. Bigdeli, E. De Negri, M. M. Dizdarevic, E. Gorla, R. Minko, and S.\n  Tsakou", "title": "Semi-regular sequences and other random systems of equations", "comments": "27 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.AC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The security of multivariate cryptosystems and digital signature schemes\nrelies on the hardness of solving a system of polynomial equations over a\nfinite field. Polynomial system solving is also currently a bottleneck of\nindex-calculus algorithms to solve the elliptic and hyperelliptic curve\ndiscrete logarithm problem. The complexity of solving a system of polynomial\nequations is closely related to the cost of computing Groebner bases, since\ncomputing the solutions of a polynomial system can be reduced to finding a\nlexicographic Groebner basis for the ideal generated by the equations. Several\nalgorithms for computing such bases exist: We consider those based on repeated\nGaussian elimination of Macaulay matrices. In this paper, we analyze the case\nof random systems, where random systems means either semi-regular systems, or\nquadratic systems in n variables which contain a regular sequence of n\npolynomials. We provide explicit formulae for bounds on the solving degree of\nsemi-regular systems with m > n equations in n variables, for equations of\narbitrary degrees for m = n+1, and for any m for systems of quadratic or cubic\npolynomials. In the appendix, we provide a table of bounds for the solving\ndegree of semi-regular systems of m = n + k quadratic equations in n variables\nfor 2 <= k; n <= 100 and online we provide the values of the bounds for 2 <= k;\nn <= 500. For quadratic systems which contain a regular sequence of n\npolynomials, we argue that the Eisenbud-Green-Harris Conjecture, if true,\nprovides a sharp bound for their solving degree, which we compute explicitly.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 15:21:38 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Bigdeli", "M.", ""], ["De Negri", "E.", ""], ["Dizdarevic", "M. M.", ""], ["Gorla", "E.", ""], ["Minko", "R.", ""], ["Tsakou", "S.", ""]]}, {"id": "2011.01050", "submitter": "Elisa Gorla", "authors": "Elisa Gorla and Daniela Mueller and Christophe Petit", "title": "Stronger bounds on the cost of computing Groebner bases for HFE systems", "comments": "15 pages", "journal-ref": null, "doi": "10.1016/j.jsc.2020.07.011", "report-no": null, "categories": "cs.CR math.AC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give upper bounds for the solving degree and the last fall degree of the\npolynomial system associated to the HFE (Hidden Field Equations) cryptosystem.\nOur bounds improve the known bounds for this type of systems. We also present\nnew results on the connection between the solving degree and the last fall\ndegree and prove that, in some cases, the solving degree is independent of\ncoordinate changes.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 15:31:00 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Gorla", "Elisa", ""], ["Mueller", "Daniela", ""], ["Petit", "Christophe", ""]]}, {"id": "2011.01183", "submitter": "Ryan Sheatsley", "authors": "Ryan Sheatsley, Nicolas Papernot, Michael Weisman, Gunjan Verma,\n  Patrick McDaniel", "title": "Adversarial Examples in Constrained Domains", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms have been shown to be vulnerable to adversarial\nmanipulation through systematic modification of inputs (e.g., adversarial\nexamples) in domains such as image recognition. Under the default threat model,\nthe adversary exploits the unconstrained nature of images; each feature (pixel)\nis fully under control of the adversary. However, it is not clear how these\nattacks translate to constrained domains that limit which and how features can\nbe modified by the adversary (e.g., network intrusion detection). In this\npaper, we explore whether constrained domains are less vulnerable than\nunconstrained domains to adversarial example generation algorithms. We create\nan algorithm for generating adversarial sketches: targeted universal\nperturbation vectors which encode feature saliency within the envelope of\ndomain constraints. To assess how these algorithms perform, we evaluate them in\nconstrained (e.g., network intrusion detection) and unconstrained (e.g., image\nrecognition) domains. The results demonstrate that our approaches generate\nmisclassification rates in constrained domains that were comparable to those of\nunconstrained domains (greater than 95%). Our investigation shows that the\nnarrow attack surface exposed by constrained domains is still sufficiently\nlarge to craft successful adversarial examples; and thus, constraints do not\nappear to make a domain robust. Indeed, with as little as five randomly\nselected features, one can still generate adversarial examples.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 18:19:44 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Sheatsley", "Ryan", ""], ["Papernot", "Nicolas", ""], ["Weisman", "Michael", ""], ["Verma", "Gunjan", ""], ["McDaniel", "Patrick", ""]]}, {"id": "2011.01192", "submitter": "Yikai Wu", "authors": "David Pujol, Yikai Wu, Brandon Fain, Ashwin Machanavajjhala", "title": "Budget Sharing for Multi-Analyst Differential Privacy", "comments": "13 pages, 5 figures. Proceedings of the VLDB Endowment (PVLDB) Vol.\n  14 No. 10. To be presented at the International Conference on Very Large Data\n  Bases (VLDB) 2021", "journal-ref": "PVLDB, 14(10): 1805-1817, 2021", "doi": "10.14778/3467861.3467870", "report-no": null, "categories": "cs.DB cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Large organizations that collect data about populations (like the US Census\nBureau) release summary statistics that are used by multiple stakeholders for\nresource allocation and policy making problems. These organizations are also\nlegally required to protect the privacy of individuals from whom they collect\ndata. Differential Privacy (DP) provides a solution to release useful summary\ndata while preserving privacy. Most DP mechanisms are designed to answer a\nsingle set of queries. In reality, there are often multiple stakeholders that\nuse a given data release and have overlapping but not-identical queries. This\nintroduces a novel joint optimization problem in DP where the privacy budget\nmust be shared among different analysts.\n  We initiate study into the problem of DP query answering across multiple\nanalysts. To capture the competing goals and priorities of multiple analysts,\nwe formulate three desiderata that any mechanism should satisfy in this setting\n-- The Sharing Incentive, Non-Interference, and Adaptivity -- while still\noptimizing for overall error. We demonstrate how existing DP query answering\nmechanisms in the multi-analyst settings fail to satisfy at least one of the\ndesiderata. We present novel DP algorithms that provably satisfy all our\ndesiderata and empirically show that they incur low error on realistic tasks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 18:33:15 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 22:11:37 GMT"}, {"version": "v3", "created": "Sat, 12 Jun 2021 19:19:44 GMT"}, {"version": "v4", "created": "Wed, 16 Jun 2021 19:26:06 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Pujol", "David", ""], ["Wu", "Yikai", ""], ["Fain", "Brandon", ""], ["Machanavajjhala", "Ashwin", ""]]}, {"id": "2011.01267", "submitter": "Peter Snyder", "authors": "Jordan Jueckstock, Peter Snyder, Shaown Sarker, Alexandros Kapravelos,\n  Benjamin Livshits", "title": "There's No Trick, Its Just a Simple Trick: A Web-Compat and Privacy\n  Improving Approach to Third-party Web Storage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While much current web privacy research focuses on browser fingerprinting,\nthe boring fact is that the majority of current third-party web tracking is\nconducted using traditional, persistent-state identifiers. One possible\nexplanation for the privacy community's focus on fingerprinting is that to date\nbrowsers have faced a lose-lose dilemma when dealing with third-party stateful\nidentifiers: block state in third-party frames and break a significant number\nof webpages, or allow state in third-party frames and enable pervasive\ntracking. The alternative, middle-ground solutions that have been deployed all\ntrade privacy for compatibility, rely on manually curated lists, or depend on\nthe user to manage state and state-access themselves. This work furthers\nprivacy on the web by presenting a novel system for managing the lifetime of\nthird-party storage, \"page-length storage\". We compare page-length storage to\nexisting approaches for managing third-party state and find that page-length\nstorage has the privacy protections of the most restrictive current option\n(i.e., blocking third-party storage) but web-compatibility properties mostly\nsimilar to the least restrictive option (i.e., allowing all third-party\nstorage). This work further compares page-length storage to an alternative\nthird-party storage partitioning scheme and finds that page-length storage\nprovides superior privacy protections with comparable web-compatibility. We\nprovide a dataset of the privacy and compatibility behaviors observed when\napplying the compared third-party storage strategies on a crawl of the Tranco\n1k and the quantitative metrics used to demonstrate that page-length storage\nmatches or surpasses existing approaches. Finally, we provide an open-source\nimplementation of our page-length storage approach, implemented as patches\nagainst Chromium.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 19:19:08 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Jueckstock", "Jordan", ""], ["Snyder", "Peter", ""], ["Sarker", "Shaown", ""], ["Kapravelos", "Alexandros", ""], ["Livshits", "Benjamin", ""]]}, {"id": "2011.01367", "submitter": "Narasimha Veeraragavan", "authors": "Narasimha Raghavan Veeraragavan and Kaiwen Zhang", "title": "A position paper on GDPR compliance in sharded blockchains: rehash of\n  old ideas or new interesting challenges?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sharding has emerged as one of the common techniques to address the\nscalability problems of blockchain systems. To this end, various sharding\ntechniques for blockchain systems have been proposed in the literature. When\nsharded blockchains process personal data, the data controllers and the data\nprocessors associated with the sharded blockchains need to be compliant with\nthe General Data Protection Regulation (GDPR). To this end, this article makes\nthe first attempt to address the following key question: to what extent the\nexisting techniques developed by different communities such as the distributed\ncomputing community, the distributed systems community, the database community,\nidentity and access control community and the dependability community can be\nused by the data controllers and data processors for complying with the GDPR\nrequirements of data subject rights in sharded blockchains? As part of\nanswering this question, this article argues that there is a need for\ncross-disciplinary research towards finding optimal solutions for implementing\nthe data subject rights in sharded blockchains.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 22:48:48 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Veeraragavan", "Narasimha Raghavan", ""], ["Zhang", "Kaiwen", ""]]}, {"id": "2011.01457", "submitter": "Gadekallu Thippa Reddy", "authors": "Thippa Reddy Gadekallu, Manoj M K, Sivarama Krishnan S, Neeraj Kumar,\n  Saqib Hakak, Sweta Bhattacharya", "title": "Blockchain based Attack Detection on Machine Learning Algorithms for IoT\n  based E-Health Applications", "comments": "Accepted in IEEE IoT Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of machine learning (ML) algorithms are massively scaling-up\ndue to rapid digitization and emergence of new tecnologies like Internet of\nThings (IoT). In today's digital era, we can find ML algorithms being applied\nin the areas of healthcare, IoT, engineering, finance and so on. However, all\nthese algorithms need to be trained in order to predict/solve a particular\nproblem. There is high possibility of tampering the training datasets and\nproduce biased results. Hence, in this article, we have proposed blockchain\nbased solution to secure the datasets generated from IoT devices for E-Health\napplications. The proposed blockchain based solution uses using private cloud\nto tackle the aforementioned issue. For evaluation, we have developed a system\nthat can be used by dataset owners to secure their data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 03:59:27 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Gadekallu", "Thippa Reddy", ""], ["K", "Manoj M", ""], ["S", "Sivarama Krishnan", ""], ["Kumar", "Neeraj", ""], ["Hakak", "Saqib", ""], ["Bhattacharya", "Sweta", ""]]}, {"id": "2011.01468", "submitter": "Gadekallu Thippa Reddy", "authors": "Manoj MK, Gautam Srivastava, Siva Rama Krishnan Somayaji, Thippa Reddy\n  Gadekallu, Praveen Kumar Reddy Maddikunta, Sweta Bhattacharya", "title": "An Incentive Based Approach for COVID-19 using Blockchain Technology", "comments": "Accepted for presentation at IEEE GLOBECOM 2020", "journal-ref": null, "doi": "10.1109/GCWkshps50303.2020.9367469", "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current situation of COVID-19 demands novel solutions to boost healthcare\nservices and economic growth. A full-fledged solution that can help the\ngovernment and people retain their normal lifestyle and improve the economy is\ncrucial. By bringing into the picture a unique incentive-based approach, the\nstrain of government and the people can be greatly reduced. By providing\nincentives for actions such as voluntary testing, isolation, etc., the\ngovernment can better plan strategies for fighting the situation while people\nin need can benefit from the incentive offered. This idea of combining strength\nto battle against the virus can bring out newer possibilities that can give an\nupper hand in this war. As the unpredictable future develops, sharing and\nmaintaining COVID related data of every user could be the needed trigger to\nkick start the economy and blockchain paves the way for this solution with\ndecentralization and immutability of data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 04:25:36 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["MK", "Manoj", ""], ["Srivastava", "Gautam", ""], ["Somayaji", "Siva Rama Krishnan", ""], ["Gadekallu", "Thippa Reddy", ""], ["Maddikunta", "Praveen Kumar Reddy", ""], ["Bhattacharya", "Sweta", ""]]}, {"id": "2011.01473", "submitter": "Gadekallu Thippa Reddy", "authors": "Siva Rama Krishnan Somayaji, Mamoun Alazab, Manoj MK, Antonio\n  Bucchiarone, Chiranji Lal Chowdhary, Thippa Reddy Gadekallu", "title": "A Framework for Prediction and Storage of Battery Life in IoT Devices\n  using DNN and Blockchain", "comments": "Accepted for presentation at IEEE GLOBECOM 2020", "journal-ref": null, "doi": "10.1109/GCWkshps50303.2020.9367413", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As digitization increases, the need to automate various entities becomes\ncrucial for development. The data generated by the IoT devices need to be\nprocessed accurately and in a secure manner. The basis for the success of such\na scenario requires blockchain as a means of unalterable data storage to\nimprove the overall security and trust in the system. By providing trust in an\nautomated system, with real-time data updates to all stakeholders, an improved\nform of implementation takes the stage and can help reduce the stress of\nadaptability to complete automated systems. This research focuses on a use case\nwith respect to the real time Internet of Things (IoT) network which is\ndeployed at the beach of Chicago Park District. This real time data which is\ncollected from various sensors is then used to design a predictive model using\nDeep Neural Networks for estimating the battery life of IoT sensors that is\ndeployed at the beach. This proposed model could help the government to plan\nfor placing orders of replaceable batteries before time so that there can be an\nuninterrupted service. Since this data is sensitive and requires to be secured,\nthe predicted battery life value is stored in blockchain which would be a\ntamper-proof record of the data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 04:41:14 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Somayaji", "Siva Rama Krishnan", ""], ["Alazab", "Mamoun", ""], ["MK", "Manoj", ""], ["Bucchiarone", "Antonio", ""], ["Chowdhary", "Chiranji Lal", ""], ["Gadekallu", "Thippa Reddy", ""]]}, {"id": "2011.01509", "submitter": "Fangtian Zhong", "authors": "Fangtian Zhong and Xiuzhen Cheng and Dongxiao Yu and Bei Gong and\n  Shuaiwen Song and Jiguo Yu", "title": "MalFox: Camouflaged Adversarial Malware Example Generation Based on\n  Conv-GANs Against Black-Box Detectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is a thriving field currently stuffed with many practical\napplications and active research topics. It allows computers to learn from\nexperience and to understand the world in terms of a hierarchy of concepts,\nwith each being defined through its relations to simpler concepts. Relying on\nthe strong learning capabilities of deep learning, we propose a convolutional\ngenerative adversarial network-based (C-GAN) framework titled MalFox, targeting\nadversarial malware example generation against third-party black-box detectors.\nMalFox adopts a novel approach to confrontationally produce perturbation paths,\nwith each formed by up to three methods (namely Obfusmal, Stealmal, and\nHollowmal) to generate adversarial malware examples via changing the process of\nprogram execution in our implementation. To demonstrate the effectiveness of\nMalFox, we collect a large dataset consisting of both malware and benignware,\nand investigate the performance of MalFox in terms of accuracy, detection rate,\nand evasive rate of the generated adversarial malware examples. Our evaluation\nindicates that the accuracy can be as high as 99.01% which significantly\noutperforms the other 6 well-known learning models. Furthermore, the detection\nrate is dramatically decreased by 44.3% on average, and the average evasive\nrate is noticeably improved by up to 55.3%.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 06:59:09 GMT"}, {"version": "v2", "created": "Sat, 15 May 2021 08:03:31 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 01:21:48 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Zhong", "Fangtian", ""], ["Cheng", "Xiuzhen", ""], ["Yu", "Dongxiao", ""], ["Gong", "Bei", ""], ["Song", "Shuaiwen", ""], ["Yu", "Jiguo", ""]]}, {"id": "2011.01514", "submitter": "Shitong Zhu", "authors": "Shitong Zhu, Shasha Li, Zhongjie Wang, Xun Chen, Zhiyun Qian, Srikanth\n  V. Krishnamurthy, Kevin S. Chan, Ananthram Swami", "title": "You Do (Not) Belong Here: Detecting DPI Evasion Attacks with Context\n  Learning", "comments": "12 pages, 12 figures; accepted to ACM CoNEXT 2020", "journal-ref": null, "doi": "10.1145/3386367.3431311", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Deep Packet Inspection (DPI) middleboxes become increasingly popular, a\nspectrum of adversarial attacks have emerged with the goal of evading such\nmiddleboxes. Many of these attacks exploit discrepancies between the middlebox\nnetwork protocol implementations, and the more rigorous/complete versions\nimplemented at end hosts. These evasion attacks largely involve subtle\nmanipulations of packets to cause different behaviours at DPI and end hosts, to\ncloak malicious network traffic that is otherwise detectable. With recent\nautomated discovery, it has become prohibitively challenging to manually curate\nrules for detecting these manipulations. In this work, we propose CLAP, the\nfirst fully-automated, unsupervised ML solution to accurately detect and\nlocalize DPI evasion attacks. By learning what we call the packet context,\nwhich essentially captures inter-relationships across both (1) different\npackets in a connection; and (2) different header fields within each packet,\nfrom benign traffic traces only, CLAP can detect and pinpoint packets that\nviolate the benign packet contexts (which are the ones that are specially\ncrafted for evasion purposes). Our evaluations with 73 state-of-the-art DPI\nevasion attacks show that CLAP achieves an Area Under the Receiver Operating\nCharacteristic Curve (AUC-ROC) of 0.963, an Equal Error Rate (EER) of only\n0.061 in detection, and an accuracy of 94.6% in localization. These results\nsuggest that CLAP can be a promising tool for thwarting DPI evasion attacks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 07:18:47 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Zhu", "Shitong", ""], ["Li", "Shasha", ""], ["Wang", "Zhongjie", ""], ["Chen", "Xun", ""], ["Qian", "Zhiyun", ""], ["Krishnamurthy", "Srikanth V.", ""], ["Chan", "Kevin S.", ""], ["Swami", "Ananthram", ""]]}, {"id": "2011.01538", "submitter": "Samurdhi Karunaratne", "authors": "Samurdhi Karunaratne, Enes Krijestorac, Danijela Cabric", "title": "Penetrating RF Fingerprinting-based Authentication with a Generative\n  Adversarial Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical layer authentication relies on detecting unique imperfections in\nsignals transmitted by radio devices to isolate their fingerprint. Recently,\ndeep learning-based authenticators have increasingly been proposed to classify\ndevices using these fingerprints, as they achieve higher accuracies compared to\ntraditional approaches. However, it has been shown in other domains that adding\ncarefully crafted perturbations to legitimate inputs can fool such classifiers.\nThis can undermine the security provided by the authenticator. Unlike\nadversarial attacks applied in other domains, an adversary has no control over\nthe propagation environment. Therefore, to investigate the severity of this\ntype of attack in wireless communications, we consider an unauthorized\ntransmitter attempting to have its signals classified as authorized by a deep\nlearning-based authenticator. We demonstrate a reinforcement learning-based\nattack where the impersonator--using only the authenticator's binary\nauthentication decision--distorts its signals in order to penetrate the system.\nExtensive simulations and experiments on a software-defined radio testbed\nindicate that at appropriate channel conditions and bounded by a maximum\ndistortion level, it is possible to fool the authenticator reliably at more\nthan 90% success rate.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 07:42:39 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Karunaratne", "Samurdhi", ""], ["Krijestorac", "Enes", ""], ["Cabric", "Danijela", ""]]}, {"id": "2011.01665", "submitter": "Roberto Civino", "authors": "Riccardo Aragona and Roberto Civino", "title": "On the primitivity of Lai-Massey schemes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In symmetric cryptography, the round functions used as building blocks for\niterated block ciphers are often obtained as the composition of different\nlayers providing confusion and diffusion. The study of the conditions on such\nlayers which make the group generated by the round functions of a block cipher\na primitive group has been addressed in the past years, both in the case of\nSubstitution Permutation Networks and Feistel Networks, giving to block cipher\ndesigners the receipt to avoid the imprimitivity attack. In this paper a\nsimilar study is proposed on the subject of the Lai-Massey scheme, a framework\nwhich combines both Substitution Permutation Network and Feistel Network\nfeatures. Its resistance to the imprimitivity attack is obtained as a\nconsequence of a more general result in which the problem of proving the\nprimitivity of the Lai-Massey scheme is reduced to the simpler one of proving\nthe primitivity of the group generated by the round functions of a strictly\nrelated Substitution Permutation Network.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 12:41:43 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Aragona", "Riccardo", ""], ["Civino", "Roberto", ""]]}, {"id": "2011.01685", "submitter": "Joao Ceron", "authors": "Joao M. Ceron and Christian Scholten and Aiko Pras and Elmer\n  Lastdrager and Jair Santanna", "title": "Characterising attacks targeting low-cost routers: a MikroTik case study\n  (Extended)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attacks targeting network infrastructure devices pose a threat to the\nsecurity of the internet. An attack targeting such devices can affect an entire\nautonomous system. In recent years, malware such as VPNFilter, Navidade, and\nSonarDNS has been used to compromise low-cost routers and commit all sorts of\ncybercrimes from DDoS attacks to ransomware deployments. Routers of the type\nconcerned are used both to provide last-mile access for home users and to\nmanage interdomain routing (BGP). MikroTik is a particular brand of low-cost\nrouter. In our previous research, we found more than 4 million MikroTik routers\navailable on the internet. We have shown that these devices are also popular in\nInternet Exchange infrastructures. Despite their popularity, these devices are\nknown to have numerous vulnerabilities. In this paper, we extend our previous\nanalysis by presenting a long-term investigation of MikroTik-targeted attacks.\nBy using a highly interactive honeypot that we developed, we collected more\nthan 44 million packets over 120 days, from sensors deployed in Australia,\nBrazil, China, India, the Netherlands, and the United States. The incoming\ntraffic was classified on the basis of Common Vulnerabilities and Exposures to\ndetect attacks targeting MikroTik devices. That enabled us to identify a wide\nrange of activities on the system, such as cryptocurrency mining, DNS server\nredirection, and more than 3,000 successfully established tunnels used for\neavesdropping. Although this research focuses on Mikrotik devices, both the\nmethodology and the publicly available scripts can be easily applied to any\nother type of network device.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 13:20:28 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Ceron", "Joao M.", ""], ["Scholten", "Christian", ""], ["Pras", "Aiko", ""], ["Lastdrager", "Elmer", ""], ["Santanna", "Jair", ""]]}, {"id": "2011.01755", "submitter": "Frederick Morlock", "authors": "Frederick Morlock, Dingsu Wang", "title": "MAD-VAE: Manifold Awareness Defense Variational Autoencoder", "comments": "15 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep generative models such as Defense-GAN and Defense-VAE have made\nsignificant progress in terms of adversarial defenses of image classification\nneural networks, several methods have been found to circumvent these defenses.\nBased on Defense-VAE, in our research we introduce several methods to improve\nthe robustness of defense models. The methods introduced in this paper are\nstraight forward yet show promise over the vanilla Defense-VAE. With extensive\nexperiments on MNIST data set, we have demonstrated the effectiveness of our\nalgorithms against different attacks. Our experiments also include attacks on\nthe latent space of the defensive model. We also discuss the applicability of\nexisting adversarial latent space attacks as they may have a significant flaw.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 09:04:25 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Morlock", "Frederick", ""], ["Wang", "Dingsu", ""]]}, {"id": "2011.01767", "submitter": "Chen Wu", "authors": "Chen Wu, Xian Yang, Sencun Zhu, Prasenjit Mitra", "title": "Mitigating Backdoor Attacks in Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malicious clients can attack federated learning systems using malicious data,\nincluding backdoor samples, during the training phase. The compromised global\nmodel will perform well on the validation dataset designed for the task, but a\nsmall subset of data with backdoor patterns may trigger the model to make a\nwrong prediction. There has been an arms race between attackers who tried to\nconceal attacks and defenders who tried to detect attacks during the\naggregation stage of training on the server-side. In this work, we propose a\nnew and effective method to mitigate backdoor attacks after the training phase.\nSpecifically, we design a federated pruning method to remove redundant neurons\nin the network and then adjust the model's extreme weight values. Our\nexperiments conducted on distributed Fashion-MNIST show that our method can\nreduce the average attack success rate from 99.7% to 1.9% with a 5.5% loss of\ntest accuracy on the validation dataset. To minimize the pruning influence on\ntest accuracy, we can fine-tune after pruning, and the attack success rate\ndrops to 6.4%, with only a 1.7% loss of test accuracy. Further experiments\nunder Distributed Backdoor Attacks on CIFAR-10 also show promising results that\nthe average attack success rate drops more than 70% with less than 2% loss of\ntest accuracy on the validation dataset.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 18:39:28 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 19:53:17 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Wu", "Chen", ""], ["Yang", "Xian", ""], ["Zhu", "Sencun", ""], ["Mitra", "Prasenjit", ""]]}, {"id": "2011.01803", "submitter": "Ashish Kumar", "authors": "Ashish Kumar, N S Raghava", "title": "A novel group based cryptosystem based on electromagnetic rotor machine", "comments": "journal PAPER BASED ON ROTOR MACHINE , PUBLISHED IN Indian Journal of\n  Scientific Research, pp. 131-136 , 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an algorithm is aimed to make a cryptosystem for gray level\nimages based on voice features, secret sharing scheme and electromagnetic rotor\nmachine. Here, Shamir secret sharing (k n) threshold scheme is used to secure a\nkey along with voice features of (n k) users. Keystream is molded by\ncoefficients of a voice sample, using this key stream, rotor machines rotating\ncylinders positions are initialized and internal wiring is decided by pseudo\nrandom number of Henon chaotic map, where initial seed for chaotic system is\nchosen from keystream. And furthermore, shares of key stream are distributed\namong users. Speech processing is fused with electromagnetic machine to provide\nauthentication as well as group based encryption. Perceptual linear predication\n(PLP) coefficients are utilized for formation of secret key. Simulation\nexperiments and statistical analysis demonstrate that the proposed algorithm is\nsensitive to initial secret keystream, entropy, mean value analysis and\nhistogram of the encrypted image is admirable. Hence, the proposed scheme is\nresistible to any vulnerable situation.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 15:50:04 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Kumar", "Ashish", ""], ["Raghava", "N S", ""]]}, {"id": "2011.01805", "submitter": "Ehud Aharoni", "authors": "Ehud Aharoni (1), Allon Adir (1), Moran Baruch (1), Gilad Ezov (1),\n  Ariel Farkash (1), Lev Greenberg (1), Ramy Masalha (1), Dov Murik (1) and\n  Omri Soceanu (1) ((1) IBM Research)", "title": "Tile Tensors: A versatile data structure with descriptive shapes for\n  homomorphic encryption", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Moving from the theoretical promise of Fully Homomorphic Encryption (FHE) to\nreal-world applications with realistic and acceptable time and memory figures\nis an on-going challenge. After choosing an appropriate FHE scheme, and before\nimplementing privacy-preserving analytics, one needs an efficient packing\nmethod that will optimize use of the ciphertext slots, trading-off size,\nlatency, and throughput. We propose a solution to this challenge. We describe a\nmethod for efficiently working with tensors (multi-dimensional arrays) in a\nsystem that imposes tiles, i.e., fixed-size vectors. The tensors are packed\ninto tiles and then manipulated via operations on those tiles. We further show\na novel and concise notation for describing packing details.\n  Our method reinterprets the tiles as multi-dimensional arrays, and combines\nthem to cover enough space to hold the tensor. An efficient summation algorithm\ncan then sum over any dimension of this construct. We propose a descriptive\nnotation for the shape of this data structure that describes both the original\ntensor and how it is packed inside the tiles. Our solution can be used to\noptimize the performance of various algorithms such as consecutive matrix\nmultiplications or neural network inference with varying batch sizes. It can\nalso serve to enhance optimizations done by homomorphic encryption compilers.\nWe describe different applications that take advantage of this data structure\nthrough the proposed notation, experiment to evaluate the advantages through\ndifferent applications, and share our conclusions.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 15:54:35 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Aharoni", "Ehud", "", "IBM Research"], ["Adir", "Allon", "", "IBM Research"], ["Baruch", "Moran", "", "IBM Research"], ["Ezov", "Gilad", "", "IBM Research"], ["Farkash", "Ariel", "", "IBM Research"], ["Greenberg", "Lev", "", "IBM Research"], ["Masalha", "Ramy", "", "IBM Research"], ["Murik", "Dov", "", "IBM Research"], ["Soceanu", "Omri", "", "IBM Research"]]}, {"id": "2011.01963", "submitter": "Jinhyun So", "authors": "Jinhyun So, Basak Guler, A. Salman Avestimehr", "title": "A Scalable Approach for Privacy-Preserving Collaborative Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a collaborative learning scenario in which multiple data-owners\nwish to jointly train a logistic regression model, while keeping their\nindividual datasets private from the other parties. We propose COPML, a\nfully-decentralized training framework that achieves scalability and\nprivacy-protection simultaneously. The key idea of COPML is to securely encode\nthe individual datasets to distribute the computation load effectively across\nmany parties and to perform the training computations as well as the model\nupdates in a distributed manner on the securely encoded data. We provide the\nprivacy analysis of COPML and prove its convergence. Furthermore, we\nexperimentally demonstrate that COPML can achieve significant speedup in\ntraining over the benchmark protocols. Our protocol provides strong statistical\nprivacy guarantees against colluding parties (adversaries) with unbounded\ncomputational power, while achieving up to $16\\times$ speedup in the training\ntime against the benchmark protocols.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 19:09:55 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["So", "Jinhyun", ""], ["Guler", "Basak", ""], ["Avestimehr", "A. Salman", ""]]}, {"id": "2011.02019", "submitter": "Joao Ceron", "authors": "Joao M. Ceron and Justyna J. Chromik and Jair Santanna and Aiko Pras", "title": "Online Discoverability and Vulnerabilities of ICS/SCADA Devices in the\n  Netherlands", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On a regular basis, we read in the news about cyber-attacks on critical\ninfrastructures, such as power plants. Such infrastructures rely on the\nso-called Industrial Control Systems (ICS) / Supervisory Control And Data\nAcquisition (SCADA) networks. By hacking the devices in such systems and\nnetworks, attackers may take over the control of critical infrastructures, with\npotentially devastating consequences. This report focusses on critical\ninfrastructures in the Netherlands and investigates three main questions: 1)\nHow many ICS/SCADA devices located in the Netherlands can be easily found by\npotential attackers?, 2) How many of these devices are vulnerable to\ncyber-attacks?, and 3) What measures should be taken to prevent these devices\nfrom being hacked?\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 21:50:56 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Ceron", "Joao M.", ""], ["Chromik", "Justyna J.", ""], ["Santanna", "Jair", ""], ["Pras", "Aiko", ""]]}, {"id": "2011.02045", "submitter": "Kiran Raja Dr", "authors": "Sushma Venkatesh, Raghavendra Ramachandra, Kiran Raja, Christoph Busch", "title": "Face Morphing Attack Generation & Detection: A Comprehensive Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The vulnerability of Face Recognition System (FRS) to various kind of attacks\n(both direct and in-direct attacks) and face morphing attacks has received a\ngreat interest from the biometric community. The goal of a morphing attack is\nto subvert the FRS at Automatic Border Control (ABC) gates by presenting the\nElectronic Machine Readable Travel Document (eMRTD) or e-passport that is\nobtained based on the morphed face image. Since the application process for the\ne-passport in the majority countries requires a passport photo to be presented\nby the applicant, a malicious actor and the accomplice can generate the morphed\nface image and to obtain the e-passport. An e-passport with a morphed face\nimages can be used by both the malicious actor and the accomplice to cross the\nborder as the morphed face image can be verified against both of them. This can\nresult in a significant threat as a malicious actor can cross the border\nwithout revealing the track of his/her criminal background while the details of\naccomplice are recorded in the log of the access control system. This survey\naims to present a systematic overview of the progress made in the area of face\nmorphing in terms of both morph generation and morph detection. In this paper,\nwe describe and illustrate various aspects of face morphing attacks, including\ndifferent techniques for generating morphed face images but also the\nstate-of-the-art regarding Morph Attack Detection (MAD) algorithms based on a\nstringent taxonomy and finally the availability of public databases, which\nallow to benchmark new MAD algorithms in a reproducible manner. The outcomes of\ncompetitions/benchmarking, vulnerability assessments and performance evaluation\nmetrics are also provided in a comprehensive manner. Furthermore, we discuss\nthe open challenges and potential future works that need to be addressed in\nthis evolving field of biometrics.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 22:36:27 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Venkatesh", "Sushma", ""], ["Ramachandra", "Raghavendra", ""], ["Raja", "Kiran", ""], ["Busch", "Christoph", ""]]}, {"id": "2011.02091", "submitter": "Alexios Voulimeneas", "authors": "Alexios Voulimeneas, Dokyung Song, Per Larsen, Michael Franz, Stijn\n  Volckaert", "title": "dMVX: Secure and Efficient Multi-Variant Execution in a Distributed\n  Setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-variant execution (MVX) systems amplify the effectiveness of software\ndiversity techniques. The key idea is to run multiple diversified program\nvariants in lockstep while providing them with the same input and monitoring\ntheir run-time behavior for divergences. Thus, adversaries have to compromise\nall program variants simultaneously to mount an attack successfully. Recent\nwork proposed distributed, heterogeneous MVX systems that leverage different\nABIs and ISAs to increase the diversity between program variants further.\nHowever, existing distributed MVX system designs suffer from high performance\noverhead due to time-consuming network transactions for the MVX system's\noperations. This paper presents dMVX, a novel hybrid distributed MVX design,\nwhich incorporates new techniques that significantly reduce the overhead of MVX\nsystems in a distributed setting. Our key insight is that we can intelligently\nreduce the MVX operations that use expensive network transfers. First, we can\nlimit the monitoring of system calls that are not security-critical. Second, we\nobserve that, in many circumstances, we can also safely cache or avoid\nreplication operations needed for I/O related system calls. Our evaluation\nshows that dMVX reduces the performance degradation from over 50% to 3.1% for\nrealistic server benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 01:22:33 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Voulimeneas", "Alexios", ""], ["Song", "Dokyung", ""], ["Larsen", "Per", ""], ["Franz", "Michael", ""], ["Volckaert", "Stijn", ""]]}, {"id": "2011.02094", "submitter": "Ting Jiang", "authors": "Ting Jiang and Yang Zhang and Minhao Zhang and Ting Yu and Yizheng\n  Chen and Chenhao Lu and Ji Zhang and Zhao Li and Jun Gao and Shuigeng Zhou", "title": "A Survey on Contact Tracing: the Latest Advancements and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infectious diseases are caused by pathogenic microorganisms, such as\nbacteria, viruses, parasites or fungi, which can be spread, directly or\nindirectly, from one person to another. Infectious diseases pose a serious\nthreat to human health, especially COVID-19 that has became a serious worldwide\nhealth concern since the end of 2019. Contact tracing is the process of\nidentifying, assessing, and managing people who have been exposed to a disease\nto prevent its onward transmission. Contact tracing can help us better\nunderstand the transmission link of the virus, whereby better interrupting its\ntransmission. Given the worldwide pandemic of COVID-19, contact tracing has\nbecome one of the most critical measures to effectively curb the spread of the\nvirus. This paper presents a comprehensive survey on contact tracing, with a\ndetailed coverage of the recent advancements the models, digital technologies,\nprotocols and issues involved in contact tracing. The current challenges as\nwell as future directions of contact tracing technologies are also presented.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 01:43:16 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 09:10:11 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Jiang", "Ting", ""], ["Zhang", "Yang", ""], ["Zhang", "Minhao", ""], ["Yu", "Ting", ""], ["Chen", "Yizheng", ""], ["Lu", "Chenhao", ""], ["Zhang", "Ji", ""], ["Li", "Zhao", ""], ["Gao", "Jun", ""], ["Zhou", "Shuigeng", ""]]}, {"id": "2011.02142", "submitter": "Benjamin Rubinstein", "authors": "Chris Culnane, Benjamin I. P. Rubinstein, David Watts", "title": "Not fit for Purpose: A critical analysis of the 'Five Safes'", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adopted by government agencies in Australia, New Zealand and the UK as policy\ninstrument or as embodied into legislation, the 'Five Safes' framework aims to\nmanage risks of releasing data derived from personal information. Despite its\npopularity, the Five Safes has undergone little legal or technical critical\nanalysis. We argue that the Fives Safes is fundamentally flawed: from being\ndisconnected from existing legal protections and appropriation of notions of\nsafety without providing any means to prefer strong technical measures, to\nviewing disclosure risk as static through time and not requiring repeat\nassessment. The Five Safes provides little confidence that resulting data\nsharing is performed using 'safety' best practice or for purposes in service of\npublic interest.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 05:41:45 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Culnane", "Chris", ""], ["Rubinstein", "Benjamin I. P.", ""], ["Watts", "David", ""]]}, {"id": "2011.02152", "submitter": "Rotem Liss", "authors": "Rotem Liss, Tal Mor", "title": "From Practice to Theory: The \"Bright Illumination\" Attack on Quantum Key\n  Distribution Systems", "comments": "17 pages", "journal-ref": "In Proceedings of the International Conference on the Theory and\n  Practice of Natural Computing (TPNC 2020), pages 82-94. Lecture Notes in\n  Computer Science, vol 12494. Springer, Cham (2020)", "doi": "10.1007/978-3-030-63000-3_7", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \"Bright Illumination\" attack [Lydersen et al., Nat. Photon. 4, 686-689\n(2010)] is a practical attack, fully implementable against quantum key\ndistribution systems. In contrast to almost all developments in quantum\ninformation processing (for example, Shor's factorization algorithm, quantum\nteleportation, Bennett-Brassard (BB84) quantum key distribution, the\n\"Photon-Number Splitting\" attack, and many other examples), for which theory\nhas been proposed decades before a proper implementation, the \"Bright\nIllumination\" attack preceded any sign or hint of a theoretical prediction.\nHere we explain how the \"Reversed-Space\" methodology of attacks, complementary\nto the notion of \"quantum side-channel attacks\" (which is analogous to a\nsimilar term in \"classical\" - namely, non-quantum - computer security), has\nmissed the opportunity of predicting the \"Bright Illumination\" attack.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 06:50:26 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Liss", "Rotem", ""], ["Mor", "Tal", ""]]}, {"id": "2011.02167", "submitter": "Giorgia Azzurra Marson", "authors": "Sebastien Andreina, Giorgia Azzurra Marson, Helen M\\\"ollering, Ghassan\n  Karame", "title": "BaFFLe: Backdoor detection via Feedback-based Federated Learning", "comments": "11 pages, 5 figures; to appear in the 41st IEEE International\n  Conference on Distributed Computing Systems (ICDCS'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that federated learning (FL) is vulnerable to\npoisoning attacks that inject a backdoor into the global model. These attacks\nare effective even when performed by a single client, and undetectable by most\nexisting defensive techniques. In this paper, we propose Backdoor detection via\nFeedback-based Federated Learning (BAFFLE), a novel defense to secure FL\nagainst backdoor attacks. The core idea behind BAFFLE is to leverage data of\nmultiple clients not only for training but also for uncovering model poisoning.\nWe exploit the availability of diverse datasets at the various clients by\nincorporating a feedback loop into the FL process, to integrate the views of\nthose clients when deciding whether a given model update is genuine or not. We\nshow that this powerful construct can achieve very high detection rates against\nstate-of-the-art backdoor attacks, even when relying on straightforward methods\nto validate the model. Through empirical evaluation using the CIFAR-10 and\nFEMNIST datasets, we show that by combining the feedback loop with a method\nthat suspects poisoning attempts by assessing the per-class classification\nperformance of the updated model, BAFFLE reliably detects state-of-the-art\nbackdoor attacks with a detection accuracy of 100% and a false-positive rate\nbelow 5%. Moreover, we show that our solution can detect adaptive attacks aimed\nat bypassing the defense.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 07:44:51 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2021 13:19:04 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Andreina", "Sebastien", ""], ["Marson", "Giorgia Azzurra", ""], ["M\u00f6llering", "Helen", ""], ["Karame", "Ghassan", ""]]}, {"id": "2011.02235", "submitter": "Marc Ohm", "authors": "Marc Ohm, Lukas Kempf, Felix Boes, Michael Meier", "title": "Supporting the Detection of Software Supply Chain Attacks through\n  Unsupervised Signature Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trojanized software packages used in software supply chain attacks constitute\nan emerging threat. Unfortunately, there is still a lack of scalable approaches\nthat allow automated and timely detection of malicious software packages and\nthus most detections are based on manual labor and expertise. However, it has\nbeen observed that most attack campaigns comprise multiple packages that share\nthe same or similar malicious code. We leverage that fact to automatically\nreproduce manually identified clusters of known malicious packages that have\nbeen used in real world attacks, thus, reducing the need for expert knowledge\nand manual inspection. Our approach, AST Clustering using MCL to mimic\nExpertise (ACME), yields promising results with a $F_{1}$ score of 0.99.\nSignatures are automatically generated based on characteristic code fragments\nfrom clusters and are subsequently used to scan the whole npm registry for\nunreported malicious packages. We are able to identify and report six malicious\npackages that have been removed from npm consequentially. Therefore, our\napproach can support analysts by reducing manual labor and hence may be\nemployed to timely detect possible software supply chain attacks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 11:26:07 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 10:30:24 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Ohm", "Marc", ""], ["Kempf", "Lukas", ""], ["Boes", "Felix", ""], ["Meier", "Michael", ""]]}, {"id": "2011.02272", "submitter": "Mayank Vatsa", "authors": "Richa Singh, Mayank Vatsa, Nalini Ratha", "title": "Trustworthy AI", "comments": "ACM CODS-COMAD 2021 Tutorial", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern AI systems are reaping the advantage of novel learning methods. With\ntheir increasing usage, we are realizing the limitations and shortfalls of\nthese systems. Brittleness to minor adversarial changes in the input data,\nability to explain the decisions, address the bias in their training data, high\nopacity in terms of revealing the lineage of the system, how they were trained\nand tested, and under which parameters and conditions they can reliably\nguarantee a certain level of performance, are some of the most prominent\nlimitations. Ensuring the privacy and security of the data, assigning\nappropriate credits to data sources, and delivering decent outputs are also\nrequired features of an AI system. We propose the tutorial on Trustworthy AI to\naddress six critical issues in enhancing user and public trust in AI systems,\nnamely: (i) bias and fairness, (ii) explainability, (iii) robust mitigation of\nadversarial attacks, (iv) improved privacy and security in model building, (v)\nbeing decent, and (vi) model attribution, including the right level of credit\nassignment to the data sources, model architectures, and transparency in\nlineage.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 20:04:18 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Singh", "Richa", ""], ["Vatsa", "Mayank", ""], ["Ratha", "Nalini", ""]]}, {"id": "2011.02308", "submitter": "Muhammad Imran Khan", "authors": "Muhammad Imran Khan, Simon N. Foley, Barry O'Sullivan", "title": "Database Intrusion Detection Systems (DIDs): Insider Threat Detection\n  via Behavioural-based Anomaly Detection Systems -- A Brief Survey of Concepts\n  and Approaches", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the data security and privacy concerns is of insider threats, where\nlegitimate users of the system abuse the access privileges they hold. The\ninsider threat to data security means that an insider steals or leaks sensitive\npersonal information. Database Intrusion detection systems, specifically\nbehavioural-based database intrusion detection systems, have been shown\neffective in detecting insider attacks. This paper presents background concepts\non database intrusion detection systems in the context of detecting insider\nthreats and examines existing approaches in the literature on detecting\nmalicious accesses by an insider to Database Management Systems (DBMS).\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 14:12:03 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Khan", "Muhammad Imran", ""], ["Foley", "Simon N.", ""], ["O'Sullivan", "Barry", ""]]}, {"id": "2011.02309", "submitter": "Stephan Krenn", "authors": "Stefan Ruehrup and Stephan Krenn", "title": "Towards Privacy in Geographic Message Dissemination for Connected\n  Vehicles", "comments": null, "journal-ref": "2019 IEEE International Conference on Connected Vehicles and Expo,\n  ICCVE 2019", "doi": "10.1109/ICCVE45908.2019.8965198", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With geographic message dissemination, connected vehicles can be served with\ntraffic information in their proximity, thereby positively impacting road\nsafety, traffic management, or routing. Since such messages are typically\nrelevant in a small geographic area, servers only distribute messages to\naffected vehicles for efficiency reasons. One main challenge is to maintain\nscalability of the server infrastructure when collecting location updates from\nvehicles and determining the relevant group of vehicles when messages are\ndistributed to a geographic relevance area, while at the same time respecting\nthe individual user's privacy in accordance with legal regulations. In this\npaper, we present a framework for geographic message dissemination following\nthe privacy-by-design and privacy-by-default principles, without having to\naccept efficiency drawbacks compared to conventional server-client based\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 14:28:01 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Ruehrup", "Stefan", ""], ["Krenn", "Stephan", ""]]}, {"id": "2011.02313", "submitter": "Suthee Ruangwises", "authors": "Suthee Ruangwises, Toshiya Itoh", "title": "Physical ZKP for Connected Spanning Subgraph: Applications to Bridges\n  Puzzle and Other Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An undirected graph $G$ is known to both the prover $P$ and the verifier $V$,\nbut only $P$ knows a subgraph $H$ of $G$. Without revealing any information\nabout $H$, $P$ wants to convince $V$ that $H$ is a connected spanning subgraph\nof $G$, i.e. $H$ is connected and contains all vertices of $G$. In this paper,\nwe propose a physical protocol of zero-knowledge proof for this condition using\na deck of cards, which enables $P$ to physically show that $H$ satisfies the\ncondition without revealing it. We also show applications of this protocol to\nverify solutions of three well-known NP-complete problems: the Hamiltonian\ncycle problem, the maximum leaf spanning tree problem, and a logic puzzle\ncalled Bridges.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 10:51:00 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 13:36:32 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 17:33:40 GMT"}, {"version": "v4", "created": "Sun, 30 May 2021 15:50:24 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Ruangwises", "Suthee", ""], ["Itoh", "Toshiya", ""]]}, {"id": "2011.02352", "submitter": "Josep Domingo-Ferrer", "authors": "Josep Domingo-Ferrer, David S\\'anchez and Alberto Blanco-Justicia", "title": "The Limits of Differential Privacy (and its Misuse in Data Release and\n  Machine Learning)", "comments": "Communications of the ACM, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy (DP) is a neat privacy definition that can co-exist with\ncertain well-defined data uses in the context of interactive queries. However,\nDP is neither a silver bullet for all privacy problems nor a replacement for\nall previous privacy models. In fact, extreme care should be exercised when\ntrying to extend its use beyond the setting it was designed for. This paper\nreviews the limitations of DP and its misuse for individual data collection,\nindividual data release, and machine learning.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 15:32:48 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Domingo-Ferrer", "Josep", ""], ["S\u00e1nchez", "David", ""], ["Blanco-Justicia", "Alberto", ""]]}, {"id": "2011.02412", "submitter": "Bryan Ford", "authors": "Bryan Ford", "title": "Identity and Personhood in Digital Democracy: Evaluating Inclusion,\n  Equality, Security, and Privacy in Pseudonym Parties and Other Proofs of\n  Personhood", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.DC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital identity seems like a prerequisite for digital democracy: how can we\nensure \"one person, one vote\" online without identifying voters? But digital\nidentity solutions - ID checking, biometrics, self-sovereign identity, and\ntrust networks - all present flaws, leaving users vulnerable to exclusion,\nidentity loss or theft, and coercion. These flaws may be insurmountable because\ndigital identity is a cart pulling the horse. We cannot achieve digital\nidentity secure enough for the weight of digital democracy, until we build it\non a solid foundation of \"digital personhood.\" While identity is about\ndistinguishing one person from another through attributes or affiliations,\npersonhood is about giving all real people inalienable digital participation\nrights independent of identity, including protection against erosion of their\ndemocratic rights through identity loss, theft, coercion, or fakery.\n  We explore and analyze alternative approaches to \"proof of personhood\" that\nmay provide this missing foundation. Pseudonym parties marry the transparency\nof periodic physical-world events with the power of digital tokens between\nevents. These tokens represent limited-term but renewable claims usable for\npurposes such as online voting or liquid democracy, sampled juries or\ndeliberative polls, abuse-resistant social communication, or minting universal\nbasic income in a permissionless cryptocurrency. Enhancing pseudonym parties to\nprovide participants a moment of enforced physical security and privacy can\naddress coercion and vote-buying risks that plague today's E-voting systems. We\nalso examine other proposed approaches to proof of personhood, some of which\noffer conveniences such as all-online participation. These alternatives\ncurrently fall short of satisfying all the key digital personhood goals,\nunfortunately, but offer valuable insights into the challenges we face.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 17:08:54 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Ford", "Bryan", ""]]}, {"id": "2011.02587", "submitter": "Golam Kayas", "authors": "Golam Kayas, Mahmud Hossain, Jamie Payton, S. M. Riazul Islam", "title": "An Overview of UPnP-based IoT Security: Threats, Vulnerabilities, and\n  Prospective Solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in the development and increased availability of smart devices\nranging from small sensors to complex cloud infrastructures as well as various\nnetworking technologies and communication protocols have supported the rapid\nexpansion of Internet of Things deployments. The Universal Plug and Play (UPnP)\nprotocol has been widely accepted and used in the IoT domain to support\ninteractions among heterogeneous IoT devices, in part due to zero configuration\nimplementation which makes it feasible for use in large-scale networks. The\npopularity and ubiquity of UPnP to support IoT systems necessitate an\nexploration of security risks associated with the use of the protocol for IoT\ndeployments. In this work, we analyze security vulnerabilities of UPnP-based\nIoT systems and identify attack opportunities by the adversaries leveraging the\nvulnerabilities. Finally, we propose prospective solutions to secure UPnP-based\nIoT systems from adversarial operations.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 23:55:25 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Kayas", "Golam", ""], ["Hossain", "Mahmud", ""], ["Payton", "Jamie", ""], ["Islam", "S. M. Riazul", ""]]}, {"id": "2011.02607", "submitter": "Muhammad Rizwan Asghar", "authors": "Muhammad Rizwan Asghar, Steven Galbraith, Andrea Lanzi, Giovanni\n  Russello, Lukas Zobernig", "title": "Towards a Theory of Special-purpose Program Obfuscation", "comments": "A full version of our TrustCom 2020 work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Most recent theoretical literature on program obfuscation is based on notions\nlike Virtual Black Box (VBB) obfuscation and indistinguishability Obfuscation\n(iO). These notions are very strong and are hard to satisfy. Further, they\noffer far more protection than is typically required in practical applications.\nOn the other hand, the security notions introduced by software security\nresearchers are suitable for practical designs but are not formal or precise\nenough to enable researchers to provide a quantitative security assurance.\nHence, in this paper, we introduce a new formalism for practical program\nobfuscation that still allows rigorous security proofs. We believe our\nformalism will make it easier to analyse the security of obfuscation schemes.\nTo show the flexibility and power of our formalism, we give a number of\nexamples. Moreover, we explain the close relationship between our formalism and\nthe task of providing obfuscation challenges.\n  This is the full version of the paper. In this version, we also give a new\nrigorous analysis of several obfuscation techniques and we provide directions\nfor future research.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 01:45:26 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Asghar", "Muhammad Rizwan", ""], ["Galbraith", "Steven", ""], ["Lanzi", "Andrea", ""], ["Russello", "Giovanni", ""], ["Zobernig", "Lukas", ""]]}, {"id": "2011.02661", "submitter": "Robert Ramirez", "authors": "Robert B. Ramirez, Tomohiko Yano, Masaki Shimaoka, Kenichi Magata", "title": "Knowledge-Base Practicality for Cybersecurity Research Ethics Evaluation", "comments": "9 pages, To appear in Computer Security Symposium 2020 (CSS 2020).\n  Readers viewing this document after 10/19/2020 please refer to the most\n  recent version on arXiv.org. Proceedings to be made available at:\n  https://www.iwsec.org/css/2020/proceedings.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research ethics in Information and Communications Technology has seen a\nresurgence in popularity in recent years. Although a number of general ethics\nstandards have been issued, cyber security specifically has yet to see one.\nFurthermore, such standards are often abstract, lacking in guidance on specific\npractices. In this paper we compare peer-reviewed ethical analyses of condemned\nresearch papers to analyses derived from a knowledge base (KB) of concrete\ncyber security research ethics best practices. The KB we employ was compiled in\nprior work from a large random survey of research papers. We demonstrate\npreliminary evidence that such a KB can be used to yield comparable or more\nextensive ethical analyses of published cyber security research than expert\napplication of standards like the Menlo Report. We extend the ethical analyses\nof the reviewed manuscripts, and calculate measures of the efficiency with\nwhich the expert versus KB methods yield ethical insights.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 04:59:41 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Ramirez", "Robert B.", ""], ["Yano", "Tomohiko", ""], ["Shimaoka", "Masaki", ""], ["Magata", "Kenichi", ""]]}, {"id": "2011.02670", "submitter": "Takashi Yamakawa", "authors": "Nai-Hui Chia and Kai-Min Chung and Takashi Yamakawa", "title": "A Black-Box Approach to Post-Quantum Zero-Knowledge in Constant Rounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent seminal work, Bitansky and Shmueli (STOC '20) gave the first\nconstruction of a constant round zero-knowledge argument for NP secure against\nquantum attacks. However, their construction has several drawbacks compared to\nthe classical counterparts. Specifically, their construction only achieves\ncomputational soundness, requires strong assumptions of quantum hardness of\nlearning with errors (QLWE assumption) and the existence of quantum fully\nhomomorphic encryption (QFHE), and relies on non-black-box simulation. In this\npaper, we resolve these issues at the cost of weakening the notion of\nzero-knowledge to what is called $\\epsilon$-zero-knowledge. Concretely, we\nconstruct the following protocols:\n  - We construct a constant round interactive proof for NP that satisfies\nstatistical soundness and black-box $\\epsilon$-zero-knowledge against quantum\nattacks assuming the existence of collapsing hash functions, which is a quantum\ncounterpart of collision-resistant hash functions. Interestingly, this\nconstruction is just an adapted version of the classical protocol by Goldreich\nand Kahan (JoC '96) though the proof of $\\epsilon$-zero-knowledge property\nagainst quantum adversaries requires novel ideas.\n  - We construct a constant round interactive argument for NP that satisfies\ncomputational soundness and black-box $\\epsilon$-zero-knowledge against quantum\nattacks only assuming the existence of post-quantum one-way functions.\n  At the heart of our results is a new quantum rewinding technique that enables\na simulator to extract a committed message of a malicious verifier while\nsimulating verifier's internal state in an appropriate sense.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 05:40:05 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 04:15:24 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Chia", "Nai-Hui", ""], ["Chung", "Kai-Min", ""], ["Yamakawa", "Takashi", ""]]}, {"id": "2011.02673", "submitter": "Bingyu Gao", "authors": "Bingyu Gao, Haoyu Wang, Pengcheng Xia, Siwei Wu, Yajin Zhou, Xiapu\n  Luo, Graeth Tyson", "title": "Tracking Counterfeit Cryptocurrency End-to-end", "comments": "accepted to SIGMETRICS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The production of counterfeit money has a long history. It refers to the\ncreation of imitation currency that is produced without the legal sanction of\ngovernment. With the growth of the cryptocurrency ecosystem, there is expanding\nevidence that counterfeit cryptocurrency has also appeared. In this paper, we\nempirically explore the presence of counterfeit cryptocurrencies on Ethereum\nand measure their impact. By analyzing over 190K ERC-20 tokens (or\ncryptocurrencies) on Ethereum, we have identified 2, 117 counterfeit tokens\nthat target 94 of the 100 most popular cryptocurrencies. We perform an\nend-to-end characterization of the counterfeit token ecosystem, including their\npopularity, creators and holders, fraudulent behaviors and advertising\nchannels. Through this, we have identified two types of scams related to\ncounterfeit tokens and devised techniques to identify such scams. We observe\nthat over 7,104 victims were deceived in these scams, and the overall financial\nloss sums to a minimum of $ 17 million (74,271.7 ETH). Our findings demonstrate\nthe urgency to identify counterfeit cryptocurrencies and mitigate this threat.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 06:02:59 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Gao", "Bingyu", ""], ["Wang", "Haoyu", ""], ["Xia", "Pengcheng", ""], ["Wu", "Siwei", ""], ["Zhou", "Yajin", ""], ["Luo", "Xiapu", ""], ["Tyson", "Graeth", ""]]}, {"id": "2011.02796", "submitter": "Zhihua Tian", "authors": "Zhihua Tian, Rui Zhang, Xiaoyang Hou, Jian Liu, Kui Ren", "title": "FederBoost: Private Federated Learning for GBDT", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An emerging trend in machine learning and artificial intelligence is\nfederated learning (FL), which allows multiple participants to contribute\nvarious training data to train a better model. It promises to keep the training\ndata local for each participant, leading to low communication complexity and\nhigh privacy. However, there are still two problems in FL remain unsolved: (1)\nunable to handle vertically partitioned data, and (2) unable to support\ndecision trees. Existing FL solutions for vertically partitioned data or\ndecision trees require heavy cryptographic operations. In this paper, we\npropose a framework named FederBoost for private federated learning of gradient\nboosting decision trees (GBDT). It supports running GBDT over both horizontally\nand vertically partitioned data. The key observation for designing FederBoost\nis that the whole training process of GBDT relies on the order of the data\ninstead of the values. Consequently, vertical FederBoost does not require any\ncryptographic operation and horizontal FederBoost only requires lightweight\nsecure aggregation. We fully implement FederBoost and evaluate its utility and\nefficiency through extensive experiments performed on three public datasets.\nOur experimental results show that both vertical and horizontal FederBoost\nachieve the same level of AUC with centralized training where all data are\ncollected in a central server; and both of them can finish training within half\nan hour even in WAN.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 13:05:12 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Tian", "Zhihua", ""], ["Zhang", "Rui", ""], ["Hou", "Xiaoyang", ""], ["Liu", "Jian", ""], ["Ren", "Kui", ""]]}, {"id": "2011.02837", "submitter": "Junan Lin", "authors": "Junan Lin, Tal Mor", "title": "Quantum Candies and Quantum Cryptography", "comments": "To be presented at the 9th International Conference on the Theory and\n  Practice of Natural Computing (TPNC 2020; postponed and merged with TPNC\n  2021). The final authenticated publication is available online at\n  https://doi.org/10.1007/978-3-030-63000-3_6", "journal-ref": null, "doi": "10.1007/978-3-030-63000-3_6", "report-no": null, "categories": "physics.ed-ph cs.CR quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The field of quantum information is becoming more known to the general\npublic. However, effectively demonstrating the concepts underneath quantum\nscience and technology to the general public can be a challenging job. We\ninvestigate, extend, and much expand here \"quantum candies\" (invented by\nJacobs), a pedagogical model for intuitively describing some basic concepts in\nquantum information, including quantum bits, complementarity, the no-cloning\nprinciple, and entanglement. Following Jacob's quantum candies description of\nthe well known quantum key distribution protocol BB84, we explicitly\ndemonstrate various additional quantum cryptography protocols using quantum\ncandies in an approachable manner. The model we investigate can be a valuable\ntool for science and engineering educators who would like to help the general\npublic to gain more insights about quantum science and technology: most parts\nof this paper, including many protocols for quantum cryptography, are expected\nto be easily understandable by a layperson without any previous knowledge of\nmathematics, physics, or cryptography.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 21:01:08 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Lin", "Junan", ""], ["Mor", "Tal", ""]]}, {"id": "2011.02901", "submitter": "Helen Treharne", "authors": "Abideen Tetlay, Helen Treharne, Tom Ascroft, Sotiris Moschoyiannis", "title": "Lessons Learnt from a 2FA roll out within a higher education\n  organisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rolling out a new security mechanism in an organisation requires planning,\ngood communication, adoption from users, iterations of reflection on the\nchallenges experienced and how they were overcome. Our case study elicited\nusers' perceptions to reflect on the adoption and usage of the two factor\nauthentication (2FA) mechanism being rolled out within our higher education\norganisation. This was achieved using a mixed method research approach. Our\nqualitative analysis, using content and thematic coding, revealed that\ninitially SMS was the most popular 'second factor' and the main usability issue\nwith 2FA was the getting the authenticator app to work; this result was\nunexpected by the IT team and led to a change in how the technology was\nsubsequently rolled out to make the authenticator app the default primary\nsecond factor. Several lessons were learnt about the information users needed;\nthis included how to use the technology in different scenarios and also a wider\nappreciation of why the technology was beneficial to a user and the\norganisation. The case study also highlighted a positive impact on the security\nposture of the organisation which was measure using IT service request metrics.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 15:24:39 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Tetlay", "Abideen", ""], ["Treharne", "Helen", ""], ["Ascroft", "Tom", ""], ["Moschoyiannis", "Sotiris", ""]]}, {"id": "2011.02909", "submitter": "Luca Pasqualini", "authors": "Luca Pasqualini and Maurizio Parton", "title": "Pseudo Random Number Generation through Reinforcement Learning and\n  Recurrent Neural Networks", "comments": "14 pages, 11 figures. arXiv admin note: text overlap with\n  arXiv:1912.11531", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Pseudo-Random Number Generator (PRNG) is any algorithm generating a\nsequence of numbers approximating properties of random numbers. These numbers\nare widely employed in mid-level cryptography and in software applications.\nTest suites are used to evaluate PRNGs quality by checking statistical\nproperties of the generated sequences. These sequences are commonly represented\nbit by bit. This paper proposes a Reinforcement Learning (RL) approach to the\ntask of generating PRNGs from scratch by learning a policy to solve a partially\nobservable Markov Decision Process (MDP), where the full state is the period of\nthe generated sequence and the observation at each time step is the last\nsequence of bits appended to such state. We use a Long-Short Term Memory (LSTM)\narchitecture to model the temporal relationship between observations at\ndifferent time steps, by tasking the LSTM memory with the extraction of\nsignificant features of the hidden portion of the MDP's states. We show that\nmodeling a PRNG with a partially observable MDP and a LSTM architecture largely\nimproves the results of the fully observable feedforward RL approach introduced\nin previous work.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 10:53:23 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 14:55:48 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Pasqualini", "Luca", ""], ["Parton", "Maurizio", ""]]}, {"id": "2011.02959", "submitter": "Imdad Ullah", "authors": "Imdad Ullah", "title": "Joint optimisation of privacy and cost of in-app mobile user profiling\n  and targeted ads", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online mobile advertising ecosystems provide advertising and analytics\nservices that collect, aggregate, process and trade rich amount of consumer's\npersonal data and carries out interests-based ads targeting, which raised\nserious privacy risks and growing trends of users feeling uncomfortable while\nusing internet services. In this paper, we address user's privacy concerns by\ndeveloping an optimal dynamic optimisation cost-effective framework for\npreserving user privacy for profiling, ads-based inferencing, temporal apps\nusage behavioral patterns and interest-based ads targeting. A major challenge\nin solving this dynamic model is the lack of knowledge of time-varying updates\nduring profiling process. We formulate a mixed-integer optimisation problem and\ndevelop an equivalent problem to show that proposed algorithm does not require\nknowledge of time-varying updates in user behavior. Following, we develop an\nonline control algorithm to solve equivalent problem using Lyapunov\noptimisation and to overcome difficulty of solving nonlinear programming by\ndecomposing it into various cases and achieve trade-off between user privacy,\ncost and targeted ads. We carry out extensive experimentations and demonstrate\nproposed framework's applicability by implementing its critical components\nusing POC `System App'. We compare proposed framework with other privacy\nprotecting approaches and investigate that it achieves better privacy and\nfunctionality for various performance parameters.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 16:42:10 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Ullah", "Imdad", ""]]}, {"id": "2011.02980", "submitter": "Suthee Ruangwises", "authors": "Suthee Ruangwises", "title": "Using Five Cards to Encode Each Integer in $\\mathbb{Z}/6\\mathbb{Z}$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in secure multi-party computation using a deck of playing cards,\noften called card-based cryptography, dates back to 1989 when Den Boer\nintroduced the \"five-card trick\" to compute the logical AND function. Since\nthen, many protocols to compute different functions have been developed. In\nthis paper, we propose a new encoding scheme using five cards to encode each\ninteger in $\\mathbb{Z}/6\\mathbb{Z}$. Using this encoding scheme, we develop\nprotocols that can copy a commitment with 13 cards, add two integers with 10\ncards, and multiply two integers with 16 cards. All of our protocols are the\ncurrently best known protocols in terms of the required number of cards. Our\nencoding scheme can also be generalized to encode integers in\n$\\mathbb{Z}/n\\mathbb{Z}$ for other values of $n$ as well.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 17:12:09 GMT"}, {"version": "v2", "created": "Fri, 25 Dec 2020 20:57:44 GMT"}, {"version": "v3", "created": "Sun, 30 May 2021 15:53:09 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Ruangwises", "Suthee", ""]]}, {"id": "2011.03006", "submitter": "Adnan Siraj Rakin", "authors": "Adnan Siraj Rakin, Yukui Luo, Xiaolin Xu and Deliang Fan", "title": "Deep-Dup: An Adversarial Weight Duplication Attack Framework to Crush\n  Deep Neural Network in Multi-Tenant FPGA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide deployment of Deep Neural Networks (DNN) in high-performance cloud\ncomputing platforms has emerged field-programmable gate arrays (FPGA) as a\npopular choice of accelerator to boost performance due to its hardware\nreprogramming flexibility. To improve the efficiency of hardware resource\nutilization, growing efforts have been invested in FPGA virtualization,\nenabling the co-existence of multiple independent tenants in a shared FPGA\nchip. Such a multi-tenant FPGA setup for DNN acceleration potentially exposes\nthe DNN interference task under severe threat from malicious users. This work,\nto the best of our knowledge, is the first to explore DNN model vulnerabilities\nin multi-tenant FPGAs. We propose a novel adversarial attack framework:\nDeep-Dup, in which the adversarial tenant can inject faults to the DNN model of\nvictim tenant in FPGA. Specifically, she can aggressively overload the shared\npower distribution system of FPGA with malicious power-plundering circuits,\nachieving adversarial weight duplication (AWD) hardware attack that duplicates\ncertain DNN weight packages during data transmission between off-chip memory\nand on-chip buffer, with the objective to hijack DNN function of the victim\ntenant. Further, to identify the most vulnerable DNN weight packages for a\ngiven malicious objective, we propose a generic vulnerable weight package\nsearching algorithm, called Progressive Differential Evolution Search (P-DES),\nwhich is, for the first time, adaptive to both deep learning white-box and\nblack-box attack models. Unlike prior works only working in a deep learning\nwhite-box setup, our adaptiveness mainly comes from the fact that the proposed\nP-DES does not require any gradient information of DNN model.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 17:59:14 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Rakin", "Adnan Siraj", ""], ["Luo", "Yukui", ""], ["Xu", "Xiaolin", ""], ["Fan", "Deliang", ""]]}, {"id": "2011.03011", "submitter": "Dominic Seyler", "authors": "Dominic Seyler and Wei Liu and XiaoFeng Wang and ChengXiang Zhai", "title": "Towards Dark Jargon Interpretation in Underground Forums", "comments": null, "journal-ref": "ECIR 2021", "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dark jargons are benign-looking words that have hidden, sinister meanings and\nare used by participants of underground forums for illicit behavior. For\nexample, the dark term \"rat\" is often used in lieu of \"Remote Access Trojan\".\nIn this work we present a novel method towards automatically identifying and\ninterpreting dark jargons. We formalize the problem as a mapping from dark\nwords to \"clean\" words with no hidden meaning. Our method makes use of\ninterpretable representations of dark and clean words in the form of\nprobability distributions over a shared vocabulary. In our experiments we show\nour method to be effective in terms of dark jargon identification, as it\noutperforms another related method on simulated data. Using manual evaluation,\nwe show that our method is able to detect dark jargons in a real-world\nunderground forum dataset.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 18:08:32 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 00:32:12 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Seyler", "Dominic", ""], ["Liu", "Wei", ""], ["Wang", "XiaoFeng", ""], ["Zhai", "ChengXiang", ""]]}, {"id": "2011.03040", "submitter": "Ethan Rudd", "authors": "Ethan M. Rudd and Ahmed Abdallah", "title": "Training Transformers for Information Security Tasks: A Case Study on\n  Malicious URL Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) for information security (InfoSec) utilizes distinct\ndata types and formats which require different treatments during\noptimization/training on raw data. In this paper, we implement a\nmalicious/benign URL predictor based on a transformer architecture that is\ntrained from scratch. We show that in contrast to conventional natural language\nprocessing (NLP) transformers, this model requires a different training\napproach to work well. Specifically, we show that 1) pre-training on a massive\ncorpus of unlabeled URL data for an auto-regressive task does not readily\ntransfer to malicious/benign prediction but 2) that using an auxiliary\nauto-regressive loss improves performance when training from scratch. We\nintroduce a method for mixed objective optimization, which dynamically balances\ncontributions from both loss terms so that neither one of them dominates. We\nshow that this method yields performance comparable to that of several\ntop-performing benchmark classifiers.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 18:58:51 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Rudd", "Ethan M.", ""], ["Abdallah", "Ahmed", ""]]}, {"id": "2011.03083", "submitter": "Souvik Kundu", "authors": "Souvik Kundu, Mahdi Nazemi, Peter A. Beerel, Massoud Pedram", "title": "A Tunable Robust Pruning Framework Through Dynamic Network Rewiring of\n  DNNs", "comments": "8 pages, 4 figures, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a dynamic network rewiring (DNR) method to generate\npruned deep neural network (DNN) models that are robust against adversarial\nattacks yet maintain high accuracy on clean images. In particular, the\ndisclosed DNR method is based on a unified constrained optimization formulation\nusing a hybrid loss function that merges ultra-high model compression with\nrobust adversarial training. This training strategy dynamically adjusts\ninter-layer connectivity based on per-layer normalized momentum computed from\nthe hybrid loss function. In contrast to existing robust pruning frameworks\nthat require multiple training iterations, the proposed learning strategy\nachieves an overall target pruning ratio with only a single training iteration\nand can be tuned to support both irregular and structured channel pruning. To\nevaluate the merits of DNR, experiments were performed with two widely accepted\nmodels, namely VGG16 and ResNet-18, on CIFAR-10, CIFAR-100 as well as with\nVGG16 on Tiny-ImageNet. Compared to the baseline uncompressed models, DNR\nprovides over20x compression on all the datasets with no significant drop in\neither clean or adversarial classification accuracy. Moreover, our experiments\nshow that DNR consistently finds compressed models with better clean and\nadversarial image classification performance than what is achievable through\nstate-of-the-art alternatives.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 19:49:00 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 17:40:52 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Kundu", "Souvik", ""], ["Nazemi", "Mahdi", ""], ["Beerel", "Peter A.", ""], ["Pedram", "Massoud", ""]]}, {"id": "2011.03113", "submitter": "Rodrigo Miani", "authors": "Daniel Alves de Sousa, Elaine Ribeiro de Faria and Rodrigo Sanches\n  Miani", "title": "Evaluating the Performance of Twitter-based Exploit Detectors", "comments": "Paper accepted at the XX Brazilian Symposium on Information and\n  Computational Systems Security (SBSeg)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patch prioritization is a crucial aspect of information systems security, and\nknowledge of which vulnerabilities were exploited in the wild is a powerful\ntool to help systems administrators accomplish this task. The analysis of\nsocial media for this specific application can enhance the results and bring\nmore agility by collecting data from online discussions and applying machine\nlearning techniques to detect real-world exploits. In this paper, we use a\ntechnique that combines Twitter data with public database information to\nclassify vulnerabilities as exploited or not-exploited. We analyze the behavior\nof different classifying algorithms, investigate the influence of different\nantivirus data as ground truth, and experiment with various time window sizes.\nOur findings suggest that using a Light Gradient Boosting Machine (LightGBM)\ncan benefit the results, and for most cases, the statistics related to a tweet\nand the users who tweeted are more meaningful than the text tweeted. We also\ndemonstrate the importance of using ground-truth data from security companies\nnot mentioned in previous works.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 21:59:37 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["de Sousa", "Daniel Alves", ""], ["de Faria", "Elaine Ribeiro", ""], ["Miani", "Rodrigo Sanches", ""]]}, {"id": "2011.03141", "submitter": "Tomoyuki Morimae", "authors": "Tomoyuki Morimae", "title": "Quantum randomized encoding, verification of quantum computing,\n  no-cloning, and blind quantum computing", "comments": "26 pages, no figure", "journal-ref": null, "doi": null, "report-no": "YITP-20-140", "categories": "quant-ph cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized encoding is a powerful cryptographic primitive with various\napplications such as secure multiparty computation, verifiable computation,\nparallel cryptography, and complexity lower-bounds. Intuitively, randomized\nencoding $\\hat{f}$ of a function $f$ is another function such that $f(x)$ can\nbe recovered from $\\hat{f}(x)$, and nothing except for $f(x)$ is leaked from\n$\\hat{f}(x)$. Its quantum version, quantum randomized encoding, has been\nintroduced recently [Brakerski and Yuen, arXiv:2006.01085]. Intuitively,\nquantum randomized encoding $\\hat{F}$ of a quantum operation $F$ is another\nquantum operation such that, for any quantum state $\\rho$, $F(\\rho)$ can be\nrecovered from $\\hat{F}(\\rho)$, and nothing except for $F(\\rho)$ is leaked from\n$\\hat{F}(\\rho)$. In this paper, we show that if quantum randomized encoding of\nBB84 state generations is possible with an encoding operation $E$, then a\ntwo-round verification of quantum computing is possible with a classical\nverifier who can additionally do the operation $E$. One of the most important\ngoals in the field of the verification of quantum computing is to construct a\nverification protocol with a verifier as classical as possible. This result\ntherefore demonstrates a potential application of quantum randomized encoding\nto the verification of quantum computing: if we can find a good quantum\nrandomized encoding (in terms of the encoding complexity), then we can\nconstruct a good verification protocol of quantum computing. We, however, also\nshow that too good quantum randomized encoding is impossible: if quantum\nrandomized encoding with a classical encoding operation is possible, then the\nno-cloning is violated. We finally consider a natural modification of blind\nquantum computing protocols in such a way that the server gets the output like\nquantum randomized encoding. We show that the modified protocol is not secure.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 23:51:25 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Morimae", "Tomoyuki", ""]]}, {"id": "2011.03181", "submitter": "Manik Lal Das", "authors": "Tikam Alma and Manik Lal Das", "title": "Web Application Attack Detection using Deep Learning", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Modern web applications are dominated by HTTP/HTTPS messages that consist of\none or more headers, where most of the exploits and payloads can be injected by\nattackers. According to the OWASP, the 80 percent of the web attacks are done\nthrough HTTP/HTTPS requests queries. In this paper, we present a deep learning\nbased web application attacks detection model. The model uses auto-encoder that\ncan learn from the sequences of word and weight each word or character\naccording to them. The classification engine is trained on ECML-KDD dataset for\nclassification of anomaly queries with respect to specific attack type. The\nproposed web application detection engine is trained with anomaly and benign\nweb queries to achieve the accuracy of receiver operating characteristic curve\nof 1. The experimental results show that the proposed model can detect web\napplications attack successfully with low false positive rate.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 04:05:16 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Alma", "Tikam", ""], ["Das", "Manik Lal", ""]]}, {"id": "2011.03186", "submitter": "Chong Liu", "authors": "Chong Liu, Yuqing Zhu, Kamalika Chaudhuri, and Yu-Xiang Wang", "title": "Revisiting Model-Agnostic Private Learning: Faster Rates and Active\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Private Aggregation of Teacher Ensembles (PATE) framework is one of the\nmost promising recent approaches in differentially private learning. Existing\ntheoretical analysis shows that PATE consistently learns any VC-classes in the\nrealizable setting, but falls short in explaining its success in more general\ncases where the error rate of the optimal classifier is bounded away from zero.\nWe fill in this gap by introducing the Tsybakov Noise Condition (TNC) and\nestablish stronger and more interpretable learning bounds. These bounds provide\nnew insights into when PATE works and improve over existing results even in the\nnarrower realizable setting. We also investigate the compelling idea of using\nactive learning for saving privacy budget. The novel components in the proofs\ninclude a more refined analysis of the majority voting classifier -- which\ncould be of independent interest -- and an observation that the synthetic\n\"student\" learning problem is nearly realizable by construction under the\nTsybakov noise condition.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 04:35:32 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 08:19:15 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Liu", "Chong", ""], ["Zhu", "Yuqing", ""], ["Chaudhuri", "Kamalika", ""], ["Wang", "Yu-Xiang", ""]]}, {"id": "2011.03208", "submitter": "Leye Wang", "authors": "Leye Wang, Han Yu, Xiao Han", "title": "Federated Crowdsensing: Framework and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsensing is a promising sensing paradigm for smart city applications\n(e.g., traffic and environment monitoring) with the prevalence of smart mobile\ndevices and advanced network infrastructure. Meanwhile, as tasks are performed\nby individuals, privacy protection is one of the key issues in crowdsensing\nsystems. Traditionally, to alleviate users' privacy concerns, noises are added\nto participants' sensitive data (e.g., participants' locations) through\ntechniques such as differential privacy. However, this inevitably results in\nquality loss to the crowdsensing task. Recently, federated learning paradigm\nhas been proposed, which aims to achieve privacy preservation in machine\nlearning while ensuring that the learning quality suffers little or no loss.\nInspired by the federated learning paradigm, this article studies how federated\nlearning may benefit crowdsensing applications. In particular, we first propose\na federated crowdsensing framework, which analyzes the privacy concerns of each\ncrowdsensing stage (i.e., task creation, task assignment, task execution, and\ndata aggregation) and discuss how federated learning techniques may take\neffect. Finally, we summarize key challenges and opportunities in federated\ncrowdsensing.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 06:49:11 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Wang", "Leye", ""], ["Yu", "Han", ""], ["Han", "Xiao", ""]]}, {"id": "2011.03241", "submitter": "Osman Bi\\c{c}er", "authors": "Nandini Agrawal, R Prashanthi, Osman Bi\\c{c}er, Alptekin K\\\"up\\c{c}\\\"u", "title": "BlockSim-Net: A Network Based Blockchain Simulator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since its proposal by Eyal and Sirer (CACM '13), selfish mining attack on\nproof-of-work blockchains has been studied extensively in terms of both\nimproving its impact and defending against it. Before any defense is deployed\nin a real world blockchain system, it needs to be tested for security and\ndependability. However, real blockchain systems are too complex to conduct any\ntest on or benchmark the developed protocols. Some simulation environments have\nbeen proposed recently, such as BlockSim (Maher et al., '20). However, BlockSim\nis developed for the simulation of an entire network on a single CPU.\nTherefore, it is insufficient to capture the essence of a real blockchain\nnetwork, as it is not distributed and the complications such as propagation\ndelays that occur in reality cannot be simulated realistically enough. In this\nwork, we propose BlockSim-Net, a simple, efficient, high performance,\nnetwork-based blockchain simulator, to better reflect reality.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 09:12:00 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 11:58:10 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Agrawal", "Nandini", ""], ["Prashanthi", "R", ""], ["Bi\u00e7er", "Osman", ""], ["K\u00fcp\u00e7\u00fc", "Alptekin", ""]]}, {"id": "2011.03319", "submitter": "Chandrika Bhardwaj", "authors": "Chandrika Bhardwaj and Sanjiva Prasad", "title": "Secure Information Flow Connections", "comments": "arXiv admin note: text overlap with arXiv:1903.02835", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Denning's lattice model provided secure information flow analyses with an\nintuitive mathematical foundation: the lattice ordering determines permitted\nflows. We examine how this framework may be extended to support the flow of\ninformation between autonomous organisations, each employing possibly quite\ndifferent security lattices and information flow policies. We propose a\nconnection framework that permits different organisations to exchange\ninformation while maintaining both security of information flow as well as\ntheir autonomy in formulating and maintaining security policies. Our\nprescriptive framework is based on the rigorous mathematical framework of\nLagois connections proposed by Melton, together with a simple operational model\nfor transferring object data between domains. The merit of this formulation is\nthat it is simple, minimal, adaptable and intuitive. We show that our framework\nis semantically sound, by proving that the connections proposed preserve\nstandard correctness notions such as non-interference. We then illustrate how\nLagois theory also provides a robust framework and methodology for negotiating\nand maintaining secure agreements on information flow between autonomous\norganisations, even when either or both organisations change their security\nlattices. Composition and decomposition properties indicate support for a\nmodular approach to secure flow frameworks in complex organisations. We next\nshow that this framework extends naturally and conservatively to the\nDecentralised Labels Model of Myers et al. - a Lagois connection between the\nhierarchies of principals in two organisations naturally induces a Lagois\nconnection between the corresponding security label lattices, thus extending\nthe security guarantees ensured by the decentralised model to encompass\nbidirectional inter-organisational flows.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 08:35:41 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Bhardwaj", "Chandrika", ""], ["Prasad", "Sanjiva", ""]]}, {"id": "2011.03396", "submitter": "Giovanni Cherubin", "authors": "Konstantinos Chatzikokolakis, Giovanni Cherubin, Catuscia Palamidessi,\n  Carmela Troncoso", "title": "The Bayes Security Measure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security system designers favor worst-case security measures, such as those\nderived from differential privacy, due to the strong guarantees they provide.\nThese guarantees, on the downside, result on high penalties on the system's\nperformance. In this paper, we study the Bayes security measure. This measure\nquantifies the expected advantage over random guessing of an adversary that\nobserves the output of a mechanism. We show that the minimizer of this measure,\nwhich indicates its security lower bound, i) is independent from the prior on\nthe secrets, ii) can be estimated efficiently in black-box scenarios, and iii)\nit enables system designers to find low-risk security parameters without\nhurting utility. We provide a thorough comparison with respect to well-known\nmeasures, identifying the scenarios where our measure is advantageous for\ndesigners, which we illustrate empirically on relevant security and privacy\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 14:53:45 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Chatzikokolakis", "Konstantinos", ""], ["Cherubin", "Giovanni", ""], ["Palamidessi", "Catuscia", ""], ["Troncoso", "Carmela", ""]]}, {"id": "2011.03460", "submitter": "Wei Cui", "authors": "Wei Cui, Tong Dou, Shilu Yan", "title": "Threats and Opportunities: Blockchain Meets Quantum Computation", "comments": null, "journal-ref": "2020 39th Chinese Control Conference (CCC)", "doi": "10.23919/CCC50068.2020.9189608", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article considered deficiencies of the flourishing blockchain technology\nmanifested by the development of quantum computation. We show that the future\nblockchain technology would under constant threats from the following aspects:\n1) Speed up the generation of nonces; 2) Faster searching for hash collisions;\n3) Break the security of the classical encryption. We also demonstrate that\nincorporating some quantum properties into blockchain makes it more robust and\nmore efficient. For example people can establish a quantum-security blockchain\nsystem that utilizes quantum key distribution (QKD), and quantum\nsynchronization and detectable Byzantine agreement (DBA) can help the\nblockchain systems achieve faster consensus even if there exist a number of\nmalicious nodes.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 16:21:47 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Cui", "Wei", ""], ["Dou", "Tong", ""], ["Yan", "Shilu", ""]]}, {"id": "2011.03476", "submitter": "Daniel Park", "authors": "Daniel Park, Hannah Powers, Benji Prashker, Leland Liu and B\\\"ulent\n  Yener", "title": "Towards Obfuscated Malware Detection for Low Powered IoT Devices", "comments": "preprint. to appear at the International Conference on Machine\n  Learning Applications (ICMLA) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increased deployment of IoT and edge devices into commercial and\nuser networks, these devices have become a new threat vector for malware\nauthors. It is imperative to protect these devices as they become more\nprevalent in commercial and personal networks. However, due to their limited\ncomputational power and storage space, especially in the case of\nbattery-powered devices, it is infeasible to deploy state-of-the-art malware\ndetectors onto these systems. In this work, we propose using and extracting\nfeatures from Markov matrices constructed from opcode traces as a low cost\nfeature for unobfuscated and obfuscated malware detection. We empirically show\nthat our approach maintains a high detection rate while consuming less power\nthan similar work.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 17:10:26 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Park", "Daniel", ""], ["Powers", "Hannah", ""], ["Prashker", "Benji", ""], ["Liu", "Leland", ""], ["Yener", "B\u00fclent", ""]]}, {"id": "2011.03731", "submitter": "Hongyan Chang", "authors": "Hongyan Chang, Reza Shokri", "title": "On the Privacy Risks of Algorithmic Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic fairness and privacy are essential pillars of trustworthy machine\nlearning. Fair machine learning aims at minimizing discrimination against\nprotected groups by, for example, imposing a constraint on models to equalize\ntheir behavior across different groups. This can subsequently change the\ninfluence of training data points on the fair model, in a disproportionate way.\nWe study how this can change the information leakage of the model about its\ntraining data. We analyze the privacy risks of group fairness (e.g., equalized\nodds) through the lens of membership inference attacks: inferring whether a\ndata point is used for training a model. We show that fairness comes at the\ncost of privacy, and this cost is not distributed equally: the information\nleakage of fair models increases significantly on the unprivileged subgroups,\nwhich are the ones for whom we need fair learning. We show that the more biased\nthe training data is, the higher the privacy cost of achieving fairness for the\nunprivileged subgroups will be. We provide comprehensive empirical analysis for\ngeneral machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 09:15:31 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 01:45:56 GMT"}, {"version": "v3", "created": "Sun, 28 Mar 2021 08:36:27 GMT"}, {"version": "v4", "created": "Wed, 7 Apr 2021 05:43:22 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Chang", "Hongyan", ""], ["Shokri", "Reza", ""]]}, {"id": "2011.03732", "submitter": "Nhien-An Le-Khac", "authors": "Dennis Wijnberg and Nhien-An Le-Khac", "title": "Identifying interception possibilities for WhatsApp communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On a daily basis, law enforcement officers struggle with suspects using\nmobile communication applications for criminal activities. These mobile\napplications replaced SMS-messaging and evolved the last few years from\nplain-text data transmission and storage to an encrypted version. Regardless of\nthe benefits for all law abiding citizens, this is considered to be the\ndownside for criminal investigations. Normal smartphone, computer or network\ninvestigations do no longer provide the contents of the communication in\nreal-time when suspects are using apps like WhatsApp, Signal or Telegram. Among\nthem, WhatsApp is one of the most common smartphone applications for\ncommunication, both criminal as well as legal activities. Early 2016 WhatsApp\nintroduced end-to-end encryption for all users, immediately keeping law\nenforcement officers around the world in the dark. Existing research to\nrecuperate the position of law enforcement is limited to a single field of\ninvestigation and often limited to post mortem research on smartphone or\ncomputer while wiretapping is limited to metadata information. Therefore, it\nprovides only historical data or metadata while law enforcement officers want a\ncontinuous stream of live and substantive information. This paper identified\nthat gap in available scenarios for law enforcement investigations and\nidentified a gap in methods available for forensic acquiring and processing\nthese scenarios. In this paper, we propose a forensic approach to create\nreal-time insight in the WhatsApp communication. Our approach is based on the\nwiretapping, decrypting WhatsApp databases, open source intelligence and\nWhatsApp Web communication analysis. We also evaluate our method with different\nscenarios in WhatsApp forensics to prove its feasibility and efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 09:30:34 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Wijnberg", "Dennis", ""], ["Le-Khac", "Nhien-An", ""]]}, {"id": "2011.03779", "submitter": "Paul Hriljac", "authors": "Paul Hriljac", "title": "Constructing Cryptographic Multilinear Maps Using Affine Automorphisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The point of this paper is to use affine automorphisms from algebraic\ngeometry to build cryptographic multivariate mappings. We will construct groups\nG,H, both isomorphic to the cyclic group with a prime number of elements and\nmultilinear pairings from the k-fold product of G to H. The construction is\nreminiscent of techniques in multivariate encryption. We display several\ndifferent versions of the discrete logarithm problem for these groups. We show\nthat the efficient solution of some of these problems result in efficient\nalgorithms for inverting systems of multivariate polynomials corresponding to\naffine automorphisms, which implies that such problems are as computationally\ndifficult as breaking multivariate encryption.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 14:22:06 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Hriljac", "Paul", ""]]}, {"id": "2011.03814", "submitter": "Mohamed I. Ibrahem", "authors": "Mohamed I. Ibrahem, Mohamed Mahmoud, Mostafa M. Fouda, Fawaz Alsolami,\n  Waleed Alasmary, and Xuemin (Sherman) Shen", "title": "Privacy-Preserving and Efficient Data Collection Scheme for AMI Networks\n  Using Deep Learning", "comments": "16 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In advanced metering infrastructure (AMI), smart meters (SMs), which are\ninstalled at the consumer side, send fine-grained power consumption readings\nperiodically to the electricity utility for load monitoring and energy\nmanagement. Change and transmit (CAT) is an efficient approach to collect these\nreadings, where the readings are not transmitted when there is no enough change\nin consumption. However, this approach causes a privacy problem that is by\nanalyzing the transmission pattern of an SM, sensitive information on the house\ndwellers can be inferred. For instance, since the transmission pattern is\ndistinguishable when dwellers are on travel, attackers may analyze the pattern\nto launch a presence-privacy attack (PPA) to infer whether the dwellers are\nabsent from home. In this paper, we propose a scheme, called \"STDL\", for\nefficient collection of power consumption readings in AMI networks while\npreserving the consumers' privacy by sending spoofing transmissions (redundant\nreal readings) using a deep-learning approach. We first use a clustering\ntechnique and real power consumption readings to create a dataset for\ntransmission patterns using the CAT approach. Then, we train an attacker model\nusing deep-learning, and our evaluations indicate that the success rate of the\nattacker is about 91%. Finally, we train a deep-learning-based defense model to\nsend spoofing transmissions efficiently to thwart the PPA. Extensive\nevaluations are conducted, and the results indicate that our scheme can reduce\nthe attacker's success rate, to 13.52% in case he knows the defense model and\nto 3.15% in case he does not know the model, while still achieving high\nefficiency in terms of the number of readings that should be transmitted. Our\nmeasurements indicate that the proposed scheme can reduce the number of\nreadings that should be transmitted by about 41% compared to continuously\ntransmitting readings.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 17:24:16 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Ibrahem", "Mohamed I.", "", "Sherman"], ["Mahmoud", "Mohamed", "", "Sherman"], ["Fouda", "Mostafa M.", "", "Sherman"], ["Alsolami", "Fawaz", "", "Sherman"], ["Alasmary", "Waleed", "", "Sherman"], ["Xuemin", "", "", "Sherman"], ["Shen", "", ""]]}, {"id": "2011.03900", "submitter": "Yichen Wang", "authors": "T. Tony Cai, Yichen Wang, Linjun Zhang", "title": "The Cost of Privacy in Generalized Linear Models: Algorithms and Minimax\n  Lower Bounds", "comments": "56 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose differentially private algorithms for parameter estimation in both\nlow-dimensional and high-dimensional sparse generalized linear models (GLMs) by\nconstructing private versions of projected gradient descent. We show that the\nproposed algorithms are nearly rate-optimal by characterizing their statistical\nperformance and establishing privacy-constrained minimax lower bounds for GLMs.\nThe lower bounds are obtained via a novel technique, which is based on Stein's\nLemma and generalizes the tracing attack technique for privacy-constrained\nlower bounds. This lower bound argument can be of independent interest as it is\napplicable to general parametric models. Simulated and real data experiments\nare conducted to demonstrate the numerical performance of our algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 04:27:21 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 00:30:30 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Cai", "T. Tony", ""], ["Wang", "Yichen", ""], ["Zhang", "Linjun", ""]]}, {"id": "2011.03995", "submitter": "Yun William Yu", "authors": "Abbas Hammoud and Yun William Yu", "title": "Privacy-accuracy trade-offs in noisy digital exposure notifications", "comments": "11 pages, preprint submitted to conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the global spread of Covid-19 began to overwhelm the attempts of\ngovernments to conduct manual contact-tracing, there has been much interest in\nusing the power of mobile phones to automate the contact-tracing process\nthrough the development of exposure notification applications. The rough idea\nis simple: use Bluetooth or other data-exchange technologies to record contacts\nbetween users, enable users to report positive diagnoses, and alert users who\nhave been exposed to sick users. Of course, there are many privacy concerns\nassociated with this idea. Much of the work in this area has been concerned\nwith designing mechanisms for tracing contacts and alerting users that do not\nleak additional information about users beyond the existence of exposure\nevents. However, although designing practical protocols is of crucial\nimportance, it is essential to realize that notifying users about exposure\nevents may itself leak confidential information (e.g. that a particular contact\nhas been diagnosed). Luckily, while digital contact tracing is a relatively new\ntask, the generic problem of privacy and data disclosure has been studied for\ndecades. Indeed, the framework of differential privacy further permits provable\nquery privacy by adding random noise. In this article, we translate two results\nfrom statistical privacy and social recommendation algorithms to exposure\nnotification. We thus prove some naive bounds on the degree to which accuracy\nmust be sacrificed if exposure notification frameworks are to be made more\nprivate through the injection of noise.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 15:00:38 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Hammoud", "Abbas", ""], ["Yu", "Yun William", ""]]}, {"id": "2011.04065", "submitter": "Naman Patel", "authors": "Naman Patel, Prashanth Krishnamurthy, Siddharth Garg, Farshad Khorrami", "title": "Bait and Switch: Online Training Data Poisoning of Autonomous Driving\n  Systems", "comments": "To appear in the NeurIPS 2020 Workshop on Dataset Curation and\n  Security", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that by controlling parts of a physical environment in which a\npre-trained deep neural network (DNN) is being fine-tuned online, an adversary\ncan launch subtle data poisoning attacks that degrade the performance of the\nsystem. While the attack can be applied in general to any perception task, we\nconsider a DNN based traffic light classifier for an autonomous car that has\nbeen trained in one city and is being fine-tuned online in another city. We\nshow that by injecting environmental perturbations that do not modify the\ntraffic lights themselves or ground-truth labels, the adversary can cause the\ndeep network to learn spurious concepts during the online learning phase. The\nattacker can leverage the introduced spurious concepts in the environment to\ncause the model's accuracy to degrade during operation; therefore, causing the\nsystem to malfunction.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 20:04:43 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 16:29:50 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Patel", "Naman", ""], ["Krishnamurthy", "Prashanth", ""], ["Garg", "Siddharth", ""], ["Khorrami", "Farshad", ""]]}, {"id": "2011.04066", "submitter": "Abdul Moiz", "authors": "Abdul Moiz, Manar H. Alalfi", "title": "An Approach for the Identification of Information Leakage in Automotive\n  Infotainment systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advancements in the digitization world has revolutionized the automotive\nindustry. Today's modern cars are equipped with internet, computers that can\nprovide autonomous driving functionalities as well as infotainment systems that\ncan run mobile operating systems, like Android Auto and Apple CarPlay. Android\nAutomotive is Google's android operating system tailored to run natively on\nvehicle's infotainment systems, it allows third party apps to be installed and\nrun on vehicle's infotainment systems. Such apps may raise security concerns\nrelated to user's safety, security and privacy. This paper investigates\nsecurity concerns of in-vehicle apps, specifically, those related to inter\ncomponent communication (ICC) among these apps. ICC allows apps to share\ninformation via inter or intra apps components through a messaging object\ncalled intent. In case of insecure communication, Intent can be hijacked or\nspoofed by malicious apps and user's sensitive information can be leaked to\nhacker's database. We investigate the attack surface and vulnerabilities in\nthese apps and provide a static analysis approach and a tool to find data\nleakage vulnerabilities. The approach can also provide hints to mitigate these\nleaks. We evaluate our approach by analyzing a set of Android Auto apps\ndownloaded from Google Play store, and we report our validated results on\nvulnerabilities identified on those apps.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 20:10:37 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Moiz", "Abdul", ""], ["Alalfi", "Manar H.", ""]]}, {"id": "2011.04232", "submitter": "Kamalesh Palanisamy", "authors": "Kamalesh Palanisamy, Vivek Khimani, Moin Hussain Moti, Dimitris\n  Chatzopoulos", "title": "SplitEasy: A Practical Approach for Training ML models on Mobile Devices", "comments": "7 pages, 4 figures, Accepted at the ACM HotMobile workshop", "journal-ref": null, "doi": "10.1145/3446382.3448362", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern mobile devices, although resourceful, cannot train state-of-the-art\nmachine learning models without the assistance of servers, which require access\nto, potentially, privacy-sensitive user data. Split learning has recently\nemerged as a promising technique for training complex deep learning (DL) models\non low-powered mobile devices. The core idea behind this technique is to train\nthe sensitive layers of a DL model on mobile devices while offloading the\ncomputationally intensive layers to a server. Although a lot of works have\nalready explored the effectiveness of split learning in simulated settings, a\nusable toolkit for this purpose does not exist. In this work, we highlight the\ntheoretical and technical challenges that need to be resolved to develop a\nfunctional framework that trains ML models in mobile devices without\ntransferring raw data to a server. Focusing on these challenges, we propose\nSplitEasy, a framework for training ML models on mobile devices using split\nlearning. Using the abstraction provided by SplitEasy, developers can run\nvarious DL models under split learning setting by making minimal modifications.\nWe provide a detailed explanation of SplitEasy and perform experiments with six\nstate-of-the-art neural networks. We demonstrate how SplitEasy can train models\nthat cannot be trained solely by a mobile device while incurring nearly\nconstant time per data sample.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 07:41:43 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 18:58:24 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Palanisamy", "Kamalesh", ""], ["Khimani", "Vivek", ""], ["Moti", "Moin Hussain", ""], ["Chatzopoulos", "Dimitris", ""]]}, {"id": "2011.04295", "submitter": "Jade Nardi", "authors": "Sarah Bordage, Jade Nardi", "title": "Interactive Oracle Proofs of Proximity to Algebraic Geometry Codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC cs.CR math.AG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we initiate the study of proximity testing to Algebraic\nGeometry (AG) codes. An AG code $C = C(\\mathcal{C}, \\mathcal{P}, D)$ is a\nvector space associated to evaluations on $\\mathcal{P}$ of functions in the\nRiemann-Roch space $L_\\mathcal{C}(D)$. The problem of testing proximity to an\nerror-correcting code $C$ consists in distinguishing between the case where an\ninput word, given as an oracle, belongs to $C$ and the one where it is far from\nevery codeword of $C$. AG codes are good candidates to construct short proof\nsystems, but there exists no efficient proximity tests for them. We aim to fill\nthis gap.\n  We construct an Interactive Oracle Proof of Proximity (IOPP) for some\nfamilies of AG codes by generalizing an IOPP for Reed-Solomon codes introduced\nby Ben-Sasson, Bentov, Horesh and Riabzev, known as the FRI protocol. We\nidentify suitable requirements for designing efficient IOPP systems for AG\ncodes. Our approach relies on Kani's result that splits the Riemann-Roch space\nof any invariant divisor under a group action on a curve into several explicit\nRiemann-Roch spaces on the quotient curve. Under some hypotheses, a proximity\ntest to $C$ can thus be reduced to one to a simpler code $C'$. Iterating this\nprocess thoroughly, we end up with a membership test to a code with\nsignificantly smaller length. In addition to proposing the first proximity test\ntargeting AG codes, our IOPP admits quasilinear prover arithmetic complexity\nand sublinear verifier arithmetic complexity with constant soundness for\nmeaningful classes of AG codes. As a concrete instantiation, we study AG codes\non Kummer curves, which are potentially much longer than Reed-Solomon codes.\nFor this type of curves, we manage to extend our generic construction to reach\na strictly linear proving time and a strictly logarithmic verification time.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 10:10:15 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 21:38:24 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 08:09:21 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Bordage", "Sarah", ""], ["Nardi", "Jade", ""]]}, {"id": "2011.04322", "submitter": "Wei Jeng", "authors": "Hsu-Chun Hsiao, Chun-Ying Huang, Bing-Kai Hong, Shin-Ming Cheng,\n  Hsin-Yuan Hu, Chia-Chien Wu, Jian-Sin Lee, Shih-Hong Wang, Wei Jeng", "title": "An Empirical Evaluation of Bluetooth-based Decentralized Contact Tracing\n  in Crowds", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital contact tracing is being used by many countries to help contain\nCOVID-19's spread in a post-lockdown world. Among the various available\ntechniques, decentralized contact tracing that uses Bluetooth received signal\nstrength indication (RSSI) to detect proximity is considered less of a privacy\nrisk than approaches that rely on collecting absolute locations via GPS,\ncellular-tower history, or QR-code scanning. As of October 2020, there have\nbeen millions of downloads of such Bluetooth-based contract-tracing apps, as\nmore and more countries officially adopt them. However, the effectiveness of\nthese apps in the real world remains unclear due to a lack of empirical\nresearch that includes realistic crowd sizes and densities. This study aims to\nfill that gap, by empirically investigating the effectiveness of\nBluetooth-based contact tracing in crowd environments with a total of 80\nparticipants, emulating classrooms, moving lines, and other types of real-world\ngatherings. The results confirm that Bluetooth RSSI is unreliable for detecting\nproximity, and that this inaccuracy worsens in environments that are especially\ncrowded. In other words, this technique may be least useful when it is most in\nneed, and that it is fragile when confronted by low-cost jamming. Moreover,\ntechnical problems such as high energy consumption and phone overheating caused\nby the contact-tracing app were found to negatively influence users'\nwillingness to adopt it. On the bright side, however, Bluetooth RSSI may still\nbe useful for detecting coarse-grained contact events, for example, proximity\nof up to 20m lasting for an hour. Based on our findings, we recommend that\nexisting contact-tracing apps can be re-purposed to focus on coarse-grained\nproximity detection, and that future ones calibrate distance estimates and\nadjust broadcast frequencies based on auxiliary information.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 10:44:03 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 02:32:07 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Hsiao", "Hsu-Chun", ""], ["Huang", "Chun-Ying", ""], ["Hong", "Bing-Kai", ""], ["Cheng", "Shin-Ming", ""], ["Hu", "Hsin-Yuan", ""], ["Wu", "Chia-Chien", ""], ["Lee", "Jian-Sin", ""], ["Wang", "Shih-Hong", ""], ["Jeng", "Wei", ""]]}, {"id": "2011.04412", "submitter": "Chidimma Opara", "authors": "Chidimma Opara, Yingke Chen, Bo.wei", "title": "Look Before You Leap: Detecting Phishing Web Pages by Exploiting Raw URL\n  And HTML Characteristics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybercriminals resort to phishing as a simple and cost-effective medium to\nperpetrate cyber-attacks on today's Internet. Recent studies in phishing\ndetection are increasingly adopting automated feature selection over\ntraditional manually engineered features. This transition is due to the\ninability of existing traditional methods to extrapolate their learning to new\ndata. To this end, in this paper, we propose WebPhish, a deep learning\ntechnique using automatic feature selection extracted from the raw URL and HTML\nof a web page. This approach is the first of its kind, which uses the\nconcatenation of URL and HTML embedding feature vectors as input into a\nConvolutional Neural Network model to detect phishing attacks on web pages.\nExtensive experiments on a real-world dataset yielded an accuracy of 98\npercent, outperforming other state-of-the-art techniques. Also, WebPhish is a\nclient-side strategy that is completely language-independent and can conduct\nlightweight phishing detection regardless of the web page's textual language.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 00:41:54 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Opara", "Chidimma", ""], ["Chen", "Yingke", ""], ["wei", "Bo.", ""]]}, {"id": "2011.04551", "submitter": "Sarah Meiklejohn", "authors": "Sarah Meiklejohn, Pavel Kalinnikov, Cindy S. Lin, Martin Hutchinson,\n  Gary Belvin, Mariana Raykova, and Al Cutter", "title": "Think Global, Act Local: Gossip and Client Audits in Verifiable Data\n  Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there has been increasing recognition of the benefits of\nhaving services provide auditable logs of data, as demonstrated by the\ndeployment of Certificate Transparency and the development of other\ntransparency projects. Most proposed systems, however, rely on a gossip\nprotocol by which users can be assured that they have the same view of the log,\nbut the few gossip protocols that do exist today are not suited for near-term\ndeployment. Furthermore, they assume the presence of global sets of auditors,\nwho must be blindly trusted to correctly perform their roles, in order to\nachieve their stated transparency goals. In this paper, we address both of\nthese issues by proposing a gossip protocol and a verifiable registry, Mog, in\nwhich users can perform their own auditing themselves. We prove the security of\nour protocols and demonstrate via experimental evaluations that they are\nperformant in a variety of potential near-term deployments.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 16:50:07 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Meiklejohn", "Sarah", ""], ["Kalinnikov", "Pavel", ""], ["Lin", "Cindy S.", ""], ["Hutchinson", "Martin", ""], ["Belvin", "Gary", ""], ["Raykova", "Mariana", ""], ["Cutter", "Al", ""]]}, {"id": "2011.04743", "submitter": "Congzheng Song", "authors": "Congzheng Song, Alexander M. Rush, Vitaly Shmatikov", "title": "Adversarial Semantic Collisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study semantic collisions: texts that are semantically unrelated but\njudged as similar by NLP models. We develop gradient-based approaches for\ngenerating semantic collisions and demonstrate that state-of-the-art models for\nmany tasks which rely on analyzing the meaning and similarity of texts--\nincluding paraphrase identification, document retrieval, response suggestion,\nand extractive summarization-- are vulnerable to semantic collisions. For\nexample, given a target query, inserting a crafted collision into an irrelevant\ndocument can shift its retrieval rank from 1000 to top 3. We show how to\ngenerate semantic collisions that evade perplexity-based filtering and discuss\nother potential mitigations. Our code is available at\nhttps://github.com/csong27/collision-bert.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 20:42:01 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Song", "Congzheng", ""], ["Rush", "Alexander M.", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "2011.04789", "submitter": "Xianrui Meng", "authors": "Xianrui Meng, Joan Feigenbaum", "title": "Privacy-Preserving XGBoost Inference", "comments": "Extended abstract appears in Privacy-preserving Machine Learning\n  Workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although machine learning (ML) is widely used for predictive tasks, there are\nimportant scenarios in which ML cannot be used or at least cannot achieve its\nfull potential. A major barrier to adoption is the sensitive nature of\npredictive queries. Individual users may lack sufficiently rich datasets to\ntrain accurate models locally but also be unwilling to send sensitive queries\nto commercial services that vend such models. One central goal of\nprivacy-preserving machine learning (PPML) is to enable users to submit\nencrypted queries to a remote ML service, receive encrypted results, and\ndecrypt them locally. We aim at developing practical solutions for real-world\nprivacy-preserving ML inference problems. In this paper, we propose a\nprivacy-preserving XGBoost prediction algorithm, which we have implemented and\nevaluated empirically on AWS SageMaker. Experimental results indicate that our\nalgorithm is efficient enough to be used in real ML production environments.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 21:46:07 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 18:41:34 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2020 21:42:24 GMT"}, {"version": "v4", "created": "Tue, 24 Nov 2020 18:07:27 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Meng", "Xianrui", ""], ["Feigenbaum", "Joan", ""]]}, {"id": "2011.04919", "submitter": "Chunchi Liu", "authors": "Chunchi Liu, Minghui Xu, Hechuan Guo, Xiuzhen Cheng, Yinhao Xiao,\n  Dongxiao Yu, Bei Gong, Arkady Yerukhimovich, Shengling Wang and Weifeng Lv", "title": "Tokoin: A Coin-Based Accountable Access Control Scheme for Internet of\n  Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the prevalence of Internet of Things (IoT) applications, IoT devices\ninteract closely with our surrounding environments, bringing us unparalleled\nsmartness and convenience. However, the development of secure IoT solutions is\ngetting a long way lagged behind, making us exposed to common unauthorized\naccesses that may bring malicious attacks and unprecedented danger to our daily\nlife. Overprivilege attack, a widely reported phenomenon in IoT that accesses\nunauthorized or excessive resources, is notoriously hard to prevent, trace and\nmitigate. To tackle this challenge, we propose Tokoin-Based Access Control\n(TBAC), an accountable access control model enabled by blockchain and Trusted\nExecution Environment (TEE) technologies, to offer fine-graininess, strong\nauditability, and access procedure control for IoT. TBAC materializes the\nvirtual access power into a definite-amount and secure cryptographic coin\ntermed \"tokoin\" (token+coin), and manages it using atomic and accountable\nstate-transition functions in a blockchain. We also realize access procedure\ncontrol by mandating every tokoin a fine-grained access policy defining who is\nallowed to do what at when in where by how. The tokoin is peer-to-peer\ntransferable, and can be modified only by the resource owner when necessary. We\nfully implement TBAC with well-studied cryptographic primitives and blockchain\nplatforms and present a readily available APP for regular users. We also\npresent a case study to demonstrate how TBAC is employed to enable autonomous\nin-home cargo delivery while guaranteeing the access policy compliance and home\nowner's physical security by regulating the physical behaviors of the\ndeliveryman.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 05:56:36 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Liu", "Chunchi", ""], ["Xu", "Minghui", ""], ["Guo", "Hechuan", ""], ["Cheng", "Xiuzhen", ""], ["Xiao", "Yinhao", ""], ["Yu", "Dongxiao", ""], ["Gong", "Bei", ""], ["Yerukhimovich", "Arkady", ""], ["Wang", "Shengling", ""], ["Lv", "Weifeng", ""]]}, {"id": "2011.04948", "submitter": "Javad Ghareh Chamani", "authors": "Javad Ghareh Chamani (1), Dimitrios Papadopoulos (1) ((1) Hong Kong\n  University of Science and Technology)", "title": "Mitigating Leakage in Federated Learning with Trusted Hardware", "comments": "Presented at the Privacy Preserving Machine Learning Workshop\n  (PriML/PPML Joint Edition) at the 34th Conference on Neural Information\n  Processing Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In federated learning, multiple parties collaborate in order to train a\nglobal model over their respective datasets. Even though cryptographic\nprimitives (e.g., homomorphic encryption) can help achieve data privacy in this\nsetting, some partial information may still be leaked across parties if this is\ndone non-judiciously. In this work, we study the federated learning framework\nof SecureBoost [Cheng et al., FL@IJCAI'19] as a specific such example,\ndemonstrate a leakage-abuse attack based on its leakage profile, and\nexperimentally evaluate the effectiveness of our attack. We then propose two\nsecure versions relying on trusted execution environments. We implement and\nbenchmark our protocols to demonstrate that they are 1.2-5.4X faster in\ncomputation and need 5-49X less communication than SecureBoost.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 07:22:51 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 16:00:17 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 12:51:55 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Chamani", "Javad Ghareh", ""], ["Papadopoulos", "Dimitrios", ""]]}, {"id": "2011.05157", "submitter": "Tianjin Huang", "authors": "Tianjin Huang, Vlado Menkovski, Yulong Pei, Mykola Pechenizkiy", "title": "Bridging the Performance Gap between FGSM and PGD Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning achieves state-of-the-art performance in many tasks but exposes\nto the underlying vulnerability against adversarial examples. Across existing\ndefense techniques, adversarial training with the projected gradient decent\nattack (adv.PGD) is considered as one of the most effective ways to achieve\nmoderate adversarial robustness. However, adv.PGD requires too much training\ntime since the projected gradient attack (PGD) takes multiple iterations to\ngenerate perturbations. On the other hand, adversarial training with the fast\ngradient sign method (adv.FGSM) takes much less training time since the fast\ngradient sign method (FGSM) takes one step to generate perturbations but fails\nto increase adversarial robustness. In this work, we extend adv.FGSM to make it\nachieve the adversarial robustness of adv.PGD. We demonstrate that the large\ncurvature along FGSM perturbed direction leads to a large difference in\nperformance of adversarial robustness between adv.FGSM and adv.PGD, and\ntherefore propose combining adv.FGSM with a curvature regularization\n(adv.FGSMR) in order to bridge the performance gap between adv.FGSM and\nadv.PGD. The experiments show that adv.FGSMR has higher training efficiency\nthan adv.PGD. In addition, it achieves comparable performance of adversarial\nrobustness on MNIST dataset under white-box attack, and it achieves better\nperformance than adv.PGD under white-box attack and effectively defends the\ntransferable adversarial attack on CIFAR-10 dataset.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 09:08:54 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Huang", "Tianjin", ""], ["Menkovski", "Vlado", ""], ["Pei", "Yulong", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "2011.05163", "submitter": "Sandeep Dsouza", "authors": "Sandeep Dsouza, Victor Bahl, Lixiang Ao and Landon P. Cox", "title": "Amadeus: Scalable, Privacy-Preserving Live Video Analytics", "comments": "17 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart-city applications ranging from traffic management to public-safety\nalerts rely on live analytics of video from surveillance cameras in public\nspaces. However, a growing number of government regulations stipulate how data\ncollected from these cameras must be handled in order to protect citizens'\nprivacy. This paper describes Amadeus, which balances privacy and utility by\nredacting video in near realtime for smart-city applications. Our main insight\nis that whitelisting objects, or blocking by default, is crucial for scalable,\nprivacy-preserving video analytics. In the context of modern object detectors,\nwe prove that whitelisting reduces the risk of an object-detection error\nleading to a privacy violation, and helps Amadeus scale to a large and diverse\nset of applications. In particular, Amadeus utilizes whitelisting to generate\ncomposable encrypted object-specific live streams, which simultaneously meet\nthe requirements of multiple applications in a privacy-preserving fashion,\nwhile reducing the compute and streaming-bandwidth requirements at the edge.\nExperiments with our Amadeus prototype show that compared to blacklisting\nobjects, whitelisting yields significantly better privacy (up to ~28x) and\nbandwidth savings (up to ~5.5x). Additionally, our experiments also indicate\nthat the composable live streams generated by Amadeus are usable by real-world\napplications with minimum utility loss.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 05:28:31 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Dsouza", "Sandeep", ""], ["Bahl", "Victor", ""], ["Ao", "Lixiang", ""], ["Cox", "Landon P.", ""]]}, {"id": "2011.05218", "submitter": "Ruitao Feng", "authors": "Ruitao Feng, Jing Qiang Lim, Sen Chen, Shang-Wei Lin, Yang Liu", "title": "SeqMobile: A Sequence Based Efficient Android Malware Detection System\n  Using RNN on Mobile Devices", "comments": "ICECCS-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the proliferation of Android malware, the demand for an effective and\nefficient malware detection system is on the rise. The existing device-end\nlearning based solutions tend to extract limited syntax features (e.g.,\npermissions and API calls) to meet a certain time constraint of mobile devices.\nHowever, syntax features lack the semantics which can represent the potential\nmalicious behaviors and further result in more robust model with high accuracy\nfor malware detection. In this paper, we propose an efficient Android malware\ndetection system, named SeqMobile, which adopts behavior-based sequence\nfeatures and leverages customized deep neural networks on mobile devices\ninstead of the server. Different from the traditional sequence-based approaches\non server, to meet the performance demand, SeqMobile accepts three effective\nperformance optimization methods to reduce the time cost. To evaluate the\neffectiveness and efficiency of our system, we conduct experiments from the\nfollowing aspects 1) the detection accuracy of different recurrent neural\nnetworks; 2) the feature extraction performance on different mobile devices, 3)\nthe detection accuracy and prediction time cost of different sequence lengths.\nThe results unveil that SeqMobile can effectively detect malware with high\naccuracy. Moreover, our performance optimization methods have proven to improve\nthe performance of training and prediction by at least twofold. Additionally,\nto discover the potential performance optimization from the SOTA TensorFlow\nmodel optimization toolkit for our approach, we also provide an evaluation on\nthe toolkit, which can serve as a guidance for other systems leveraging on\nsequence-based learning approach. Overall, we conclude that our sequence-based\napproach, together with our performance optimization methods, enable us to\ndetect malware under the performance demands of mobile devices.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 16:18:39 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Feng", "Ruitao", ""], ["Lim", "Jing Qiang", ""], ["Chen", "Sen", ""], ["Lin", "Shang-Wei", ""], ["Liu", "Yang", ""]]}, {"id": "2011.05254", "submitter": "Yongwei Wang", "authors": "Yongwei Wang, Mingquan Feng, Rabab Ward, Z. Jane Wang, Lanjun Wang", "title": "Perception Improvement for Free: Exploring Imperceptible Black-box\n  Adversarial Attacks on Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to adversarial attacks. White-box\nadversarial attacks can fool neural networks with small adversarial\nperturbations, especially for large size images. However, keeping successful\nadversarial perturbations imperceptible is especially challenging for\ntransfer-based black-box adversarial attacks. Often such adversarial examples\ncan be easily spotted due to their unpleasantly poor visual qualities, which\ncompromises the threat of adversarial attacks in practice. In this study, to\nimprove the image quality of black-box adversarial examples perceptually, we\npropose structure-aware adversarial attacks by generating adversarial images\nbased on psychological perceptual models. Specifically, we allow higher\nperturbations on perceptually insignificant regions, while assigning lower or\nno perturbation on visually sensitive regions. In addition to the proposed\nspatial-constrained adversarial perturbations, we also propose a novel\nstructure-aware frequency adversarial attack method in the discrete cosine\ntransform (DCT) domain. Since the proposed attacks are independent of the\ngradient estimation, they can be directly incorporated with existing\ngradient-based attacks. Experimental results show that, with the comparable\nattack success rate (ASR), the proposed methods can produce adversarial\nexamples with considerably improved visual quality for free. With the\ncomparable perceptual quality, the proposed approaches achieve higher attack\nsuccess rates: particularly for the frequency structure-aware attacks, the\naverage ASR improves more than 10% over the baseline attacks.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 07:17:12 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Wang", "Yongwei", ""], ["Feng", "Mingquan", ""], ["Ward", "Rabab", ""], ["Wang", "Z. Jane", ""], ["Wang", "Lanjun", ""]]}, {"id": "2011.05296", "submitter": "Jonathan Passerat-Palmbach", "authors": "Veneta Haralampieva and Daniel Rueckert and Jonathan Passerat-Palmbach", "title": "A Systematic Comparison of Encrypted Machine Learning Solutions for\n  Image Classification", "comments": null, "journal-ref": "PPMLP'20: Proceedings of the 2020 Workshop on Privacy-Preserving\n  Machine Learning in Practice", "doi": "10.1145/3411501.3419432", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This work provides a comprehensive review of existing frameworks based on\nsecure computing techniques in the context of private image classification. The\nin-depth analysis of these approaches is followed by careful examination of\ntheir performance costs, in particular runtime and communication overhead.\n  To further illustrate the practical considerations when using different\nprivacy-preserving technologies, experiments were conducted using four\nstate-of-the-art libraries implementing secure computing at the heart of the\ndata science stack: PySyft and CrypTen supporting private inference via Secure\nMulti-Party Computation, TF-Trusted utilising Trusted Execution Environments\nand HE- Transformer relying on Homomorphic encryption.\n  Our work aims to evaluate the suitability of these frameworks from a\nusability, runtime requirements and accuracy point of view. In order to better\nunderstand the gap between state-of-the-art protocols and what is currently\navailable in practice for a data scientist, we designed three neural network\narchitecture to obtain secure predictions via each of the four aforementioned\nframeworks. Two networks were evaluated on the MNIST dataset and one on the\nMalaria Cell image dataset. We observed satisfying performances for TF-Trusted\nand CrypTen and noted that all frameworks perfectly preserved the accuracy of\nthe corresponding plaintext model.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 18:33:31 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 12:31:55 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Haralampieva", "Veneta", ""], ["Rueckert", "Daniel", ""], ["Passerat-Palmbach", "Jonathan", ""]]}, {"id": "2011.05315", "submitter": "Nicholas Carlini", "authors": "Nicholas Carlini, Samuel Deng, Sanjam Garg, Somesh Jha, Saeed\n  Mahloujifar, Mohammad Mahmoody, Shuang Song, Abhradeep Thakurta, Florian\n  Tramer", "title": "Is Private Learning Possible with Instance Encoding?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A private machine learning algorithm hides as much as possible about its\ntraining data while still preserving accuracy. In this work, we study whether a\nnon-private learning algorithm can be made private by relying on an\ninstance-encoding mechanism that modifies the training inputs before feeding\nthem to a normal learner. We formalize both the notion of instance encoding and\nits privacy by providing two attack models. We first prove impossibility\nresults for achieving a (stronger) model. Next, we demonstrate practical\nattacks in the second (weaker) attack model on InstaHide, a recent proposal by\nHuang, Song, Li and Arora [ICML'20] that aims to use instance encoding for\nprivacy.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 18:55:20 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 01:18:36 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Carlini", "Nicholas", ""], ["Deng", "Samuel", ""], ["Garg", "Sanjam", ""], ["Jha", "Somesh", ""], ["Mahloujifar", "Saeed", ""], ["Mahmoody", "Mohammad", ""], ["Song", "Shuang", ""], ["Thakurta", "Abhradeep", ""], ["Tramer", "Florian", ""]]}, {"id": "2011.05322", "submitter": "Liang Wang", "authors": "Deepak Sirone Jegan, Liang Wang, Siddhant Bhagat, Thomas Ristenpart,\n  Michael Swift", "title": "Guarding Serverless Applications with SecLambda", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an emerging application paradigm, serverless computing attracts attention\nfrom more and more attackers. Unfortunately, security tools for conventional\napplications cannot be easily ported to serverless, and existing serverless\nsecurity solutions are inadequate. In this paper, we present \\emph{SecLambda},\nan extensible security framework that leverages local function state and global\napplication state to perform sophisticated security tasks to protect an\napplication. We show how SecLambda can be used to achieve control flow\nintegrity, credential protection, and rate limiting in serverless applications.\nWe evaluate the performance overhead and security of SecLambda using realistic\nopen-source applications, and our results suggest that SecLambda can mitigate\nseveral attacks while introducing relatively low performance overhead.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 18:59:02 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Jegan", "Deepak Sirone", ""], ["Wang", "Liang", ""], ["Bhagat", "Siddhant", ""], ["Ristenpart", "Thomas", ""], ["Swift", "Michael", ""]]}, {"id": "2011.05411", "submitter": "Nguyen Truong", "authors": "Nguyen Truong, Kai Sun, Siyao Wang, Florian Guitton, Yike Guo", "title": "Privacy Preservation in Federated Learning: An insightful survey from\n  the GDPR Perspective", "comments": "21 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Along with the blooming of AI and Machine Learning-based applications and\nservices, data privacy and security have become a critical challenge.\nConventionally, data is collected and aggregated in a data centre on which\nmachine learning models are trained. This centralised approach has induced\nsevere privacy risks to personal data leakage, misuse, and abuse. Furthermore,\nin the era of the Internet of Things and big data in which data is essentially\ndistributed, transferring a vast amount of data to a data centre for processing\nseems to be a cumbersome solution. This is not only because of the difficulties\nin transferring and sharing data across data sources but also the challenges on\ncomplying with rigorous data protection regulations and complicated\nadministrative procedures such as the EU General Data Protection Regulation\n(GDPR). In this respect, Federated learning (FL) emerges as a prospective\nsolution that facilitates distributed collaborative learning without disclosing\noriginal training data whilst naturally complying with the GDPR. Recent\nresearch has demonstrated that retaining data and computation on-device in FL\nis not sufficient enough for privacy-guarantee. This is because ML model\nparameters exchanged between parties in an FL system still conceal sensitive\ninformation, which can be exploited in some privacy attacks. Therefore, FL\nsystems shall be empowered by efficient privacy-preserving techniques to comply\nwith the GDPR. This article is dedicated to surveying on the state-of-the-art\nprivacy-preserving techniques which can be employed in FL in a systematic\nfashion, as well as how these techniques mitigate data security and privacy\nrisks. Furthermore, we provide insights into the challenges along with\nprospective approaches following the GDPR regulatory guidelines that an FL\nsystem shall implement to comply with the GDPR.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 21:41:25 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 18:06:17 GMT"}, {"version": "v3", "created": "Sat, 23 Jan 2021 02:07:36 GMT"}, {"version": "v4", "created": "Sat, 30 Jan 2021 13:15:01 GMT"}, {"version": "v5", "created": "Thu, 18 Mar 2021 12:32:28 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Truong", "Nguyen", ""], ["Sun", "Kai", ""], ["Wang", "Siyao", ""], ["Guitton", "Florian", ""], ["Guo", "Yike", ""]]}, {"id": "2011.05442", "submitter": "Kenji Saito", "authors": "Hiroshi Watanabe, Kenji Saito, Satoshi Miyazaki, Toshiharu Okada,\n  Hiroyuki Fukuyama, Tsuneo Kato, Katsuo Taniguchi", "title": "Proof of Authenticity of Logistics Information with Passive RFID Tags\n  and Blockchain", "comments": "30 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In tracing the (robotically automated) logistics of large quantities of\ngoods, inexpensive passive RFID tags are preferred for cost reasons.\nAccordingly, security between such tags and readers have primarily been studied\namong many issues of RFID. However, the authenticity of data cannot be\nguaranteed if logistics services can give false information. Although the use\nof blockchain is often discussed, it is simply a recording system, so there is\na risk that false records may be written to it.\n  As a solution, we propose a design in which a digitally signing,\nlocation-constrained and tamper-evident reader atomically writes an evidence to\nblockchain along with its reading and writing a tag.\n  By semi-formal modeling, we confirmed that the confidentiality and integrity\nof the information can be maintained throughout the system, and digitally\nsigned data can be verified later despite possible compromise of private keys\nor signature algorithms, or expiration of public key certificates. We also\nintroduce a prototype design to show that our proposal is viable.\n  This makes it possible to trace authentic logistics information using\ninexpensive passive RFID tags. Furthermore, by abstracting the reader/writer as\na sensor/actuator, this model can be extended to IoT in general.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 22:45:49 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Watanabe", "Hiroshi", ""], ["Saito", "Kenji", ""], ["Miyazaki", "Satoshi", ""], ["Okada", "Toshiharu", ""], ["Fukuyama", "Hiroyuki", ""], ["Kato", "Tsuneo", ""], ["Taniguchi", "Katsuo", ""]]}, {"id": "2011.05530", "submitter": "Ramy E. Ali", "authors": "Ramy E. Ali, Jinhyun So, A. Salman Avestimehr", "title": "On Polynomial Approximations for Privacy-Preserving and Verifiable ReLU\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outsourcing neural network inference tasks to an untrusted cloud raises data\nprivacy and integrity concerns. To address these challenges, several\nprivacy-preserving and verifiable inference techniques have been proposed based\non replacing the non-polynomial activation functions such as the rectified\nlinear unit (ReLU) function with polynomial activation functions. Such\ntechniques usually require polynomials with integer coefficients or polynomials\nover finite fields. Motivated by such requirements, several works proposed\nreplacing the ReLU activation function with the square activation function. In\nthis work, we empirically show that the square function is not the best\ndegree-$2$ polynomial that can replace the ReLU function even when restricting\nthe polynomials to have integer coefficients. We instead propose a degree-$2$\npolynomial activation function with a first order term and empirically show\nthat it can lead to much better models. Our experiments on the CIFAR-$10$ and\nCIFAR-$100$ datasets on various architectures show that our proposed activation\nfunction improves the test accuracy by up to $9.4\\%$ compared to the square\nfunction.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 03:32:22 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 06:44:17 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 05:14:03 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Ali", "Ramy E.", ""], ["So", "Jinhyun", ""], ["Avestimehr", "A. Salman", ""]]}, {"id": "2011.05537", "submitter": "Lucas Rosenblatt", "authors": "Lucas Rosenblatt, Xiaoyan Liu, Samira Pouyanfar, Eduardo de Leon, Anuj\n  Desai, Joshua Allen", "title": "Differentially Private Synthetic Data: Applied Evaluations and\n  Enhancements", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning practitioners frequently seek to leverage the most\ninformative available data, without violating the data owner's privacy, when\nbuilding predictive models. Differentially private data synthesis protects\npersonal details from exposure, and allows for the training of differentially\nprivate machine learning models on privately generated datasets. But how can we\neffectively assess the efficacy of differentially private synthetic data? In\nthis paper, we survey four differentially private generative adversarial\nnetworks for data synthesis. We evaluate each of them at scale on five standard\ntabular datasets, and in two applied industry scenarios. We benchmark with\nnovel metrics from recent literature and other standard machine learning tools.\nOur results suggest some synthesizers are more applicable for different privacy\nbudgets, and we further demonstrate complicating domain-based tradeoffs in\nselecting an approach. We offer experimental learning on applied machine\nlearning scenarios with private internal data to researchers and practioners\nalike. In addition, we propose QUAIL, an ensemble-based modeling approach to\ngenerating synthetic data. We examine QUAIL's tradeoffs, and note circumstances\nin which it outperforms baseline differentially private supervised learning\nmodels under the same budget constraint.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 04:03:08 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Rosenblatt", "Lucas", ""], ["Liu", "Xiaoyan", ""], ["Pouyanfar", "Samira", ""], ["de Leon", "Eduardo", ""], ["Desai", "Anuj", ""], ["Allen", "Joshua", ""]]}, {"id": "2011.05578", "submitter": "Raouf Kerkouche", "authors": "Raouf Kerkouche, Gergely \\'Acs, Claude Castelluccia and Pierre\n  Genev\\`es", "title": "Compression Boosts Differentially Private Federated Learning", "comments": "arXiv admin note: text overlap with arXiv:2010.07808", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning allows distributed entities to train a common model\ncollaboratively without sharing their own data. Although it prevents data\ncollection and aggregation by exchanging only parameter updates, it remains\nvulnerable to various inference and reconstruction attacks where a malicious\nentity can learn private information about the participants' training data from\nthe captured gradients. Differential Privacy is used to obtain theoretically\nsound privacy guarantees against such inference attacks by noising the\nexchanged update vectors. However, the added noise is proportional to the model\nsize which can be very large with modern neural networks. This can result in\npoor model quality. In this paper, compressive sensing is used to reduce the\nmodel size and hence increase model quality without sacrificing privacy. We\nshow experimentally, using 2 datasets, that our privacy-preserving proposal can\nreduce the communication costs by up to 95% with only a negligible performance\npenalty compared to traditional non-private federated learning schemes.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 13:11:03 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Kerkouche", "Raouf", ""], ["\u00c1cs", "Gergely", ""], ["Castelluccia", "Claude", ""], ["Genev\u00e8s", "Pierre", ""]]}, {"id": "2011.05679", "submitter": "Francesc Serratosa", "authors": "Francesc Serratosa", "title": "Security in biometric systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The objective of biometric systems is to provide an identification mechanism.\nThis identification mechanism can be used to fulfil several objectives. The\nmost common, related to providing security to a resource, is usually\nauthentication or detection of authorized personnel and detection of\nunauthorized personnel. From the technical point of view, these two objectives\ncan be included in a single point since most functionalities are achieved by\nmaking searches of people previously identified in the database of the system\nin question. In the first case access is given to people entered in the\ndatabase and in the second case access is given to people who are not entered\nin the database. Although these are the two most common attacks there are also\nothers that we will discuss in this chapter. The structure of the chapter is as\nfollows. The first part of the chapter gives an overview of the basic types of\nattacks and describes the usual protection measures (Sections 1, 2 and 3). The\nsecond part of the chapter describes several attacks that can be made on\nsystems based on fingerprinting, face recognition, and iris recognition\n(Sections 4 and 5). Once the attack methodologies have been described, some\nspecific protection measures are also discussed (Sections 4 and 5). Finally,\nside channel attacks and their usefulness in combination with other possible\nattacks are described (Section 6).\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 10:16:06 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Serratosa", "Francesc", ""]]}, {"id": "2011.05850", "submitter": "Perry Deng", "authors": "Perry Deng, Mohammad Saidur Rahman, Matthew Wright", "title": "Detecting Adversarial Patches with Class Conditional Reconstruction\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Defending against physical adversarial attacks is a rapidly growing topic in\ndeep learning and computer vision. Prominent forms of physical adversarial\nattacks, such as overlaid adversarial patches and objects, share similarities\nwith digital attacks, but are easy for humans to notice. This leads us to\nexplore the hypothesis that adversarial detection methods, which have been\nshown to be ineffective against adaptive digital adversarial examples, can be\neffective against these physical attacks. We use one such detection method\nbased on autoencoder architectures, and perform adversarial patching\nexperiments on MNIST, SVHN, and CIFAR10 against a CNN architecture and two\nCapsNet architectures. We also propose two modifications to the EM-Routed\nCapsNet architecture, Affine Voting and Matrix Capsule Dropout, to improve its\nclassification performance. Our investigation shows that the detector retains\nsome of its effectiveness even against adaptive adversarial patch attacks. In\naddition, detection performance tends to decrease among all the architectures\nwith the increase of dataset complexity.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 15:34:28 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 01:28:55 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Deng", "Perry", ""], ["Rahman", "Mohammad Saidur", ""], ["Wright", "Matthew", ""]]}, {"id": "2011.05880", "submitter": "Gajraj Kuldeep", "authors": "Gajraj Kuldeep, Qi Zhang", "title": "Energy Concealment based Compressive Sensing Encryption for Perfect\n  Secrecy for IoT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent study has shown that compressive sensing (CS) based computationally\nsecure scheme using Gaussian or Binomial sensing matrix in resource-constrained\nIoT devices is vulnerable to ciphertext-only attack. Although the CS-based\nperfectly secure scheme has no such vulnerabilities, the practical realization\nof the perfectly secure scheme is challenging, because it requires an\nadditional secure channel to transmit the measurement norm. In this paper, we\ndevise a practical realization of a perfectly secure scheme by concealing\nenergy in which the requirement of an additional secure channel is removed.\nSince the generation of Gaussian sensing matrices is not feasible in\nresource-constrained IoT devices, approximate Gaussian sensing matrices are\ngenerated using linear feedback shift registers. We also demonstrate the\nimplementation feasibility of the proposed perfectly secure scheme in practice\nwithout additional complexity. Furthermore, the security analysis of the\nproposed scheme is performed and compared with the state-of-the-art compressive\nsensing based energy obfuscation scheme.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 16:21:06 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Kuldeep", "Gajraj", ""], ["Zhang", "Qi", ""]]}, {"id": "2011.05888", "submitter": "Gajraj Kuldeep", "authors": "Gajraj Kuldeep, Qi Zhang", "title": "Compressive Sensing based Multi-class Privacy-preserving Cloud Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we design the multi-class privacy$\\text{-}$preserving cloud\ncomputing scheme (MPCC) leveraging compressive sensing for compact sensor data\nrepresentation and secrecy for data encryption. The proposed scheme achieves\ntwo-class secrecy, one for superuser who can retrieve the exact sensor data,\nand the other for semi-authorized user who is only able to obtain the\nstatistical data such as mean, variance, etc. MPCC scheme allows\ncomputationally expensive sparse signal recovery to be performed at cloud\nwithout compromising the confidentiality of data to the cloud service\nproviders. In this way, it mitigates the issues in data transmission, energy\nand storage caused by massive IoT sensor data as well as the increasing\nconcerns about IoT data privacy in cloud computing. Compared with the\nstate-of-the-art schemes, we show that MPCC scheme not only has lower\ncomputational complexity at the IoT sensor device and data consumer, but also\nis proved to be secure against ciphertext-only attack.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 16:28:31 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Kuldeep", "Gajraj", ""], ["Zhang", "Qi", ""]]}, {"id": "2011.05905", "submitter": "Zhichuang Sun", "authors": "Zhichuang Sun, Ruimin Sun, Changming Liu, Amrita Roy Chowdhury, Somesh\n  Jha, Long Lu", "title": "ShadowNet: A Secure and Efficient System for On-device Model Inference", "comments": "single column, 21 pages (29 pages include appendix), 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increased usage of AI accelerators on mobile and edge devices,\non-device machine learning (ML) is gaining popularity. Consequently, thousands\nof proprietary ML models are being deployed on billions of untrusted devices.\nThis raises serious security concerns about model privacy. However, protecting\nthe model privacy without losing access to the AI accelerators is a challenging\nproblem. In this paper, we present a novel on-device model inference system,\nShadowNet. ShadowNet protects the model privacy with Trusted Execution\nEnvironment (TEE) while securely outsourcing the heavy linear layers of the\nmodel to the untrusted hardware accelerators. ShadowNet achieves this by\ntransforming the weights of the linear layers before outsourcing them and\nrestoring the results inside the TEE. The nonlinear layers are also kept secure\ninside the TEE. The transformation of the weights and the restoration of the\nresults are designed in a way that can be implemented efficiently. We have\nbuilt a ShadowNet prototype based on TensorFlow Lite and applied it on four\npopular CNNs, namely, MobileNets, ResNet-44, AlexNet and MiniVGG. Our\nevaluation shows that ShadowNet achieves strong security guarantees with\nreasonable performance, offering a practical solution for secure on-device\nmodel inference.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 16:50:08 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 18:28:55 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Sun", "Zhichuang", ""], ["Sun", "Ruimin", ""], ["Liu", "Changming", ""], ["Chowdhury", "Amrita Roy", ""], ["Jha", "Somesh", ""], ["Lu", "Long", ""]]}, {"id": "2011.05934", "submitter": "Di Wang", "authors": "Di Wang and Marco Gaboardi and Adam Smith and Jinhui Xu", "title": "Empirical Risk Minimization in the Non-interactive Local Model of\n  Differential Privacy", "comments": "Appeared at Journal of Machine Learning Research. The journal version\n  of arXiv:1802.04085, fixed a bug in arXiv:1812.06825", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we study the Empirical Risk Minimization (ERM) problem in the\nnon-interactive Local Differential Privacy (LDP) model. Previous research on\nthis problem \\citep{smith2017interaction} indicates that the sample complexity,\nto achieve error $\\alpha$, needs to be exponentially depending on the\ndimensionality $p$ for general loss functions. In this paper, we make two\nattempts to resolve this issue by investigating conditions on the loss\nfunctions that allow us to remove such a limit. In our first attempt, we show\nthat if the loss function is $(\\infty, T)$-smooth, by using the Bernstein\npolynomial approximation we can avoid the exponential dependency in the term of\n$\\alpha$. We then propose player-efficient algorithms with $1$-bit\ncommunication complexity and $O(1)$ computation cost for each player. The error\nbound of these algorithms is asymptotically the same as the original one. With\nsome additional assumptions, we also give an algorithm which is more efficient\nfor the server. In our second attempt, we show that for any $1$-Lipschitz\ngeneralized linear convex loss function, there is an $(\\epsilon, \\delta)$-LDP\nalgorithm whose sample complexity for achieving error $\\alpha$ is only linear\nin the dimensionality $p$. Our results use a polynomial of inner product\napproximation technique. Finally, motivated by the idea of using polynomial\napproximation and based on different types of polynomial approximations, we\npropose (efficient) non-interactive locally differentially private algorithms\nfor learning the set of k-way marginal queries and the set of smooth queries.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 17:48:00 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Wang", "Di", ""], ["Gaboardi", "Marco", ""], ["Smith", "Adam", ""], ["Xu", "Jinhui", ""]]}, {"id": "2011.05935", "submitter": "S.M. Riazul Islam PhD", "authors": "Lewis Nkenyereye, S. M. Riazul Islam, Mahmud Hossain, M.\n  Abdullah-Al-Wadud, and Atif Alamri", "title": "Blockchain-Enabled EHR Framework for Internet of Medical Things", "comments": "9 pages (CMC Journal, Tech Science Press)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Internet of Medical Things (IoMT) offers an infrastructure made of smart\nmedical equipment and software applications for health services. Through the\ninternet, the IoMT is capable of providing remote medical diagnosis and timely\nhealth services. The patients can use their smart devices to create, store and\nshare their electronic health records (EHR) with a variety of medical personnel\nincluding medical doctors and nurses. However, unless the underlying\ncombination within IoMT is secured, malicious users can intercept, modify and\neven delete the sensitive EHR data of patients. Patients also lose full control\nof their EHR since most health services within IoMT are constructed under a\ncentralized platform outsourced in the cloud. Therefore, it is appealing to\ndesign a decentralized, auditable and secure EHR system that guarantees\nabsolute access control for the patients while ensuring privacy and security.\nUsing the features of blockchain including decentralization, auditability and\nimmutability, we propose a secure EHR framework which is mainly maintained by\nthe medical centers. In this framework, the patients' EHR data are encrypted\nand stored in the servers of medical institutions while the corresponding hash\nvalues are kept on the blockchain. We make use of security primitives to offer\nauthentication, integrity and confidentiality of EHR data while access control\nand immutability is guaranteed by the blockchain technology. The security\nanalysis and performance evaluation of the proposed framework confirms its\nefficiency.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 17:50:03 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Nkenyereye", "Lewis", ""], ["Islam", "S. M. Riazul", ""], ["Hossain", "Mahmud", ""], ["Abdullah-Al-Wadud", "M.", ""], ["Alamri", "Atif", ""]]}, {"id": "2011.05973", "submitter": "Daniel Park", "authors": "Daniel Park and B\\\"ulent Yener", "title": "A survey on practical adversarial examples for malware classifiers", "comments": "preprint. to appear in the Reversing and Offensive-oriented Trends\n  Symposium(ROOTS) 2020", "journal-ref": null, "doi": "10.1145/3433667.3433670", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning based solutions have been very helpful in solving problems\nthat deal with immense amounts of data, such as malware detection and\nclassification. However, deep neural networks have been found to be vulnerable\nto adversarial examples, or inputs that have been purposefully perturbed to\nresult in an incorrect label. Researchers have shown that this vulnerability\ncan be exploited to create evasive malware samples. However, many proposed\nattacks do not generate an executable and instead generate a feature vector. To\nfully understand the impact of adversarial examples on malware detection, we\nreview practical attacks against malware classifiers that generate executable\nadversarial malware examples. We also discuss current challenges in this area\nof research, as well as suggestions for improvement and future research\ndirections.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 17:07:34 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Park", "Daniel", ""], ["Yener", "B\u00fclent", ""]]}, {"id": "2011.05976", "submitter": "Rui Zhao", "authors": "Rui Zhao", "title": "The Vulnerability of the Neural Networks Against Adversarial Examples in\n  Deep Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With further development in the fields of computer vision, network security,\nnatural language processing and so on so forth, deep learning technology\ngradually exposed certain security risks. The existing deep learning algorithms\ncannot effectively describe the essential characteristics of data, making the\nalgorithm unable to give the correct result in the face of malicious input.\nBased on current security threats faced by deep learning, this paper introduces\nthe problem of adversarial examples in deep learning, sorts out the existing\nattack and defense methods of the black box and white box, and classifies them.\nIt briefly describes the application of some adversarial examples in different\nscenarios in recent years, compares several defense technologies of adversarial\nexamples, and finally summarizes the problems in this research field and\nprospects for its future development. This paper introduces the common white\nbox attack methods in detail, and further compares the similarities and\ndifferences between the attack of the black and white box. Correspondingly, the\nauthor also introduces the defense methods, and analyzes the performance of\nthese methods against the black and white box attack.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 04:41:08 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 12:57:38 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Zhao", "Rui", ""]]}, {"id": "2011.06139", "submitter": "Josef Danial", "authors": "Josef Danial and Debayan Das and Anupam Golder and Santosh Ghosh and\n  Arijit Raychowdhury and Shreyas Sen", "title": "EM-X-DL: Efficient Cross-Device Deep Learning Side-Channel Attack with\n  Noisy EM Signatures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a Cross-device Deep-Learning based Electromagnetic\n(EM-X-DL) side-channel analysis (SCA), achieving >90% single-trace attack\naccuracy on AES-128, even in the presence of significantly lower\nsignal-to-noise ratio (SNR), compared to the previous works. With an\nintelligent selection of multiple training devices and proper choice of\nhyperparameters, the proposed 256-class deep neural network (DNN) can be\ntrained efficiently utilizing pre-processing techniques like PCA, LDA, and FFT\non the target encryption engine running on an 8-bit Atmel microcontroller.\nFinally, an efficient end-to-end SCA leakage detection and attack framework\nusing EM-X-DL demonstrates high confidence of an attacker with <20 averaged EM\ntraces.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 00:52:40 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Danial", "Josef", ""], ["Das", "Debayan", ""], ["Golder", "Anupam", ""], ["Ghosh", "Santosh", ""], ["Raychowdhury", "Arijit", ""], ["Sen", "Shreyas", ""]]}, {"id": "2011.06166", "submitter": "Sam McGuire", "authors": "Russell Impagliazzo, Sam McGuire", "title": "Comparing computational entropies below majority (or: When is the dense\n  model theorem false?)", "comments": "19 pages; to appear in ITCS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computational pseudorandomness studies the extent to which a random variable\n$\\bf{Z}$ looks like the uniform distribution according to a class of tests\n$\\cal{F}$. Computational entropy generalizes computational pseudorandomness by\nstudying the extent which a random variable looks like a \\emph{high entropy}\ndistribution. There are different formal definitions of computational entropy\nwith different advantages for different applications. Because of this, it is of\ninterest to understand when these definitions are equivalent.\n  We consider three notions of computational entropy which are known to be\nequivalent when the test class $\\cal{F}$ is closed under taking majorities.\nThis equivalence constitutes (essentially) the so-called \\emph{dense model\ntheorem} of Green and Tao (and later made explicit by Tao-Zeigler, Reingold et\nal., and Gowers). The dense model theorem plays a key role in Green and Tao's\nproof that the primes contain arbitrarily long arithmetic progressions and has\nsince been connected to a surprisingly wide range of topics in mathematics and\ncomputer science, including cryptography, computational complexity,\ncombinatorics and machine learning. We show that, in different situations where\n$\\cal{F}$ is \\emph{not} closed under majority, this equivalence fails. This in\nturn provides examples where the dense model theorem is \\emph{false}.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 02:22:21 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Impagliazzo", "Russell", ""], ["McGuire", "Sam", ""]]}, {"id": "2011.06191", "submitter": "Runhua Xu", "authors": "Runhua Xu and James Joshi", "title": "Revisiting Secure Computation Using Functional Encryption: Opportunities\n  and Research Directions", "comments": "15 pages, 2 figures, IEEE TPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Increasing incidents of security compromises and privacy leakage have raised\nserious privacy concerns related to cyberspace. Such privacy concerns have been\ninstrumental in the creation of several regulations and acts to restrict the\navailability and use of privacy-sensitive data. The secure computation problem,\ninitially and formally introduced as secure two-party computation by Andrew Yao\nin 1986, has been the focus of intense research in academia because of its\nfundamental role in building many of the existing privacy-preserving\napproaches. Most of the existing secure computation solutions rely on\ngarbled-circuits and homomorphic encryption techniques to tackle secure\ncomputation issues, including efficiency and security guarantees. However, it\nis still challenging to adopt these secure computation approaches in emerging\ncompute-intensive and data-intensive applications such as emerging machine\nlearning solutions. Recently proposed functional encryption scheme has shown\nits promise as an underlying secure computation foundation in recent\nprivacy-preserving machine learning approaches proposed. This paper revisits\nthe secure computation problem using emerging and promising functional\nencryption techniques and presents a comprehensive study. We first briefly\nsummarize existing conventional secure computation approaches built on\ngarbled-circuits, oblivious transfer, and homomorphic encryption techniques.\nThen, we elaborate on the unique characteristics and challenges of emerging\nfunctional encryption based secure computation approaches and outline several\nresearch directions.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 04:28:04 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 17:39:03 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Xu", "Runhua", ""], ["Joshi", "James", ""]]}, {"id": "2011.06201", "submitter": "V Lalitha", "authors": "Divija Swetha Gadiraju, V. Lalitha and Vaneet Aggarwal", "title": "Secure Regenerating Codes for Reducing Storage and Bootstrap Costs in\n  Sharded Blockchains", "comments": "8 pages, accepted for publication in IEEE Blockchain 2020. arXiv\n  admin note: text overlap with arXiv:1906.12140 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain is a distributed ledger with wide applications. Due to the\nincreasing storage requirement for blockchains, the computation can be afforded\nby only a few miners. Sharding has been proposed to scale blockchains so that\nstorage and transaction efficiency of the blockchain improves at the cost of\nsecurity guarantee. This paper aims to consider a new protocol,\nSecure-Repair-Blockchain (SRB), which aims to decrease the storage cost at the\nminers. In addition, SRB also decreases the bootstrapping cost, which allows\nfor new miners to easily join a sharded blockchain. In order to reduce storage,\ncoding-theoretic techniques are used in SRB. In order to decrease the amount of\ndata that is transferred to the new node joining a shard, the concept of exact\nrepair secure regenerating codes is used. The proposed blockchain protocol\nachieves lower storage than those that do not use coding, and achieves lower\nbootstrapping cost as compared to the different baselines.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 17:23:08 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Gadiraju", "Divija Swetha", ""], ["Lalitha", "V.", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "2011.06202", "submitter": "Emmanouil Vasileios Vlatakis Gkaragkounis", "authors": "Christos Tzamos, Emmanouil-Vasileios Vlatakis-Gkaragkounis, Ilias\n  Zadik", "title": "Optimal Private Median Estimation under Minimal Distributional\n  Assumptions", "comments": "49 pages, NeurIPS 2020, Spotlight talk", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CR cs.DS math.PR stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the fundamental task of estimating the median of an underlying\ndistribution from a finite number of samples, under pure differential privacy\nconstraints. We focus on distributions satisfying the minimal assumption that\nthey have a positive density at a small neighborhood around the median. In\nparticular, the distribution is allowed to output unbounded values and is not\nrequired to have finite moments. We compute the exact, up-to-constant terms,\nstatistical rate of estimation for the median by providing nearly-tight upper\nand lower bounds. Furthermore, we design a polynomial-time differentially\nprivate algorithm which provably achieves the optimal performance. At a\ntechnical level, our results leverage a Lipschitz Extension Lemma which allows\nus to design and analyze differentially private algorithms solely on\nappropriately defined \"typical\" instances of the samples.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 04:54:30 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Tzamos", "Christos", ""], ["Vlatakis-Gkaragkounis", "Emmanouil-Vasileios", ""], ["Zadik", "Ilias", ""]]}, {"id": "2011.06205", "submitter": "Chenye Wu", "authors": "Haoxiang Wang and Jiasheng Zhang and Chenbei Lu and Chenye Wu", "title": "Privacy Preserving in Non-Intrusive Load Monitoring: A Differential\n  Privacy Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Smart meter devices enable a better understanding of the demand at the\npotential risk of private information leakage. One promising solution to\nmitigating such risk is to inject noises into the meter data to achieve a\ncertain level of differential privacy. In this paper, we cast one-shot\nnon-intrusive load monitoring (NILM) in the compressive sensing framework, and\nbridge the gap between theoretical accuracy of NILM inference and differential\nprivacy's parameters. We then derive the valid theoretical bounds to offer\ninsights on how the differential privacy parameters affect the NILM\nperformance. Moreover, we generalize our conclusions by proposing the\nhierarchical framework to solve the multi-shot NILM problem. Numerical\nexperiments verify our analytical results and offer better physical insights of\ndifferential privacy in various practical scenarios. This also demonstrates the\nsignificance of our work for the general privacy preserving mechanism design.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 05:10:10 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Wang", "Haoxiang", ""], ["Zhang", "Jiasheng", ""], ["Lu", "Chenbei", ""], ["Wu", "Chenye", ""]]}, {"id": "2011.06211", "submitter": "S.M. Riazul Islam PhD", "authors": "Lewis Nkenyereye, S. M. Riazul Islam, Mahmud Hossain, M.\n  Abdullah-Al-Wadud, and Atif Alamri", "title": "Fog based Secure Framework for Personal Health Records Systems", "comments": "12 pages (CMC Journal, Tech Science Press)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rapid development of personal health records (PHR) systems enables an\nindividual to collect, create, store and share his PHR to authorized entities.\nHealth care systems within the smart city environment require a patient to\nshare his PRH data with a multitude of institutions' repositories located in\nthe cloud. The cloud computing paradigm cannot meet such a massive\ntransformative healthcare systems due to drawbacks including network latency,\nscalability and bandwidth. Fog computing relieves the burden of conventional\ncloud computing by availing intermediate fog nodes between the end users and\nthe remote servers. Aiming at a massive demand of PHR data within a ubiquitous\nsmart city, we propose a secure and fog assisted framework for PHR systems to\naddress security, access control and privacy concerns. Built under a fog-based\narchitecture, the proposed framework makes use of efficient key exchange\nprotocol coupled with ciphertext attribute based encryption (CP-ABE) to\nguarantee confidentiality and fine-grained access control within the system\nrespectively. We also make use of digital signature combined with CP-ABE to\nensure the system authentication and users privacy. We provide the analysis of\nthe proposed framework in terms of security and performance.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 05:27:12 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Nkenyereye", "Lewis", ""], ["Islam", "S. M. Riazul", ""], ["Hossain", "Mahmud", ""], ["Abdullah-Al-Wadud", "M.", ""], ["Alamri", "Atif", ""]]}, {"id": "2011.06257", "submitter": "Teik Guan Tan", "authors": "Teik Guan Tan and Pawel Szalachowski and Jianying Zhou", "title": "Securing Password Authentication for Web-based Applications", "comments": "23 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of passwords and the need to protect passwords are not going away.\nThe majority of websites that require authentication continue to support\npassword authentication. Even high-security applications such as Internet\nBanking portals, which deploy 2-factor authentication, rely on password\nauthentication as one of the authentication factors. However phishing attacks\ncontinue to plague password-based authentication despite aggressive efforts in\ndetection and takedown as well as comprehensive user awareness and training\nprograms.\n  There is currently no foolproof mechanism even for security-conscious\nwebsites to prevent users from being directed to fraudulent websites and having\ntheir passwords phished. In this paper, we apply a threat analysis on the web\npassword login process, and uncover a design vulnerability in the\nHTML<inputtype=\"password\"> field. This vulnerability can be exploited for\nphishing attacks as the web authentication process is not end-to-end secured\nfrom each input password field to the web server. We identify four properties\nthat encapsulate the requirements to stop web-based password phishing, and\npropose a secure protocol to be used with a new credential field that complies\nwith the four properties. We further analyze the proposed protocol through an\nabuse-case evaluation, discuss various deployment issues, and also perform a\ntest implementation to understand its data and execution overheads\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 08:30:42 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Tan", "Teik Guan", ""], ["Szalachowski", "Pawel", ""], ["Zhou", "Jianying", ""]]}, {"id": "2011.06260", "submitter": "Max Maass", "authors": "Max Maass, Alina St\\\"over, Henning Prid\\\"ohl, Sebastian Bretthauer,\n  Dominik Herrmann, Matthias Hollick, Indra Spiecker", "title": "Effective Notification Campaigns on the Web: A Matter of Trust, Framing,\n  and Support", "comments": "Published at USENIX Security '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Misconfigurations and outdated software are a major cause of compromised\nwebsites and data leaks. Past research has proposed and evaluated sending\nautomated security notifications to the operators of misconfigured websites,\nbut encountered issues with reachability, mistrust, and a perceived lack of\nimportance. In this paper, we seek to understand the determinants of effective\nnotifications. We identify a data protection misconfiguration that affects 12.7\n% of the 1.3 million websites we scanned and opens them up to legal liability.\nUsing a subset of 4754 websites, we conduct a multivariate randomized\ncontrolled notification experiment, evaluating contact medium, sender, and\nframing of the message. We also include a link to a public web-based\nself-service tool that is run by us in disguise and conduct an anonymous survey\nof the notified website owners (N=477) to understand their perspective.\n  We find that framing a misconfiguration as a problem of legal compliance can\nincrease remediation rates, especially when the notification is sent as a\nletter from a legal research group, achieving remediation rates of 76.3 %\ncompared to 33.9 % for emails sent by computer science researchers warning\nabout a privacy issue. Across all groups, 56.6 % of notified owners remediated\nthe issue, compared to 9.2 % in the control group. In conclusion, we present\nfactors that lead website owners to trust a notification, show what framing of\nthe notification brings them into action, and how they can be supported in\nremediating the issue.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 08:45:16 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Maass", "Max", ""], ["St\u00f6ver", "Alina", ""], ["Prid\u00f6hl", "Henning", ""], ["Bretthauer", "Sebastian", ""], ["Herrmann", "Dominik", ""], ["Hollick", "Matthias", ""], ["Spiecker", "Indra", ""]]}, {"id": "2011.06304", "submitter": "Mahdi Jafari Siavoshani", "authors": "Mahdi Jafari Siavoshani, Amir Hossein Khajepour, Amirmohammad Ziaei,\n  Amir Ali Gatmiri, Ali Taheri", "title": "Machine Learning Interpretability Meets TLS Fingerprinting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Protecting users' privacy over the Internet is of great importance. However,\ndue to the increasing complexity of network protocols and components, it\nbecomes harder and harder to maintain. Therefore, investigating and\nunderstanding how data is leaked from the information transport\nplatform/protocols can lead us to a more secure environment.\n  In this paper, we propose an iterative framework to find the most vulnerable\ninformation fields in a network protocol systematically. To this end, focusing\non the Transport Layer Security (TLS) protocol, we perform different\nmachine-learning-based fingerprinting attacks by collecting data from more than\n70 domains (websites) to understand how and where this information leakage\noccurs in the TLS protocol. Then, by employing the interpretation techniques\ndeveloped in the machine learning community, and using our framework, we find\nthe most vulnerable information fields in the TLS protocol. Our findings\ndemonstrate that the TLS handshake (which is mainly unencrypted), the TLS\nrecord length appears in the TLS application data header, and the\ninitialization vector (IV) field are among the most critical leaker parts in\nthis protocol, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 10:37:45 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Siavoshani", "Mahdi Jafari", ""], ["Khajepour", "Amir Hossein", ""], ["Ziaei", "Amirmohammad", ""], ["Gatmiri", "Amir Ali", ""], ["Taheri", "Ali", ""]]}, {"id": "2011.06325", "submitter": "Jack Li", "authors": "Jianhua Li, Jiong Jin, Lingjuan Lyu, Dong Yuan, Yingying Yang,\n  Longxiang Gao, Chao Shen", "title": "A Fast and Scalable Authentication Scheme in IoT for Smart Living", "comments": "15 pages, 7 figures, 3 tables, to appear in FGCS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous resource-limited smart objects (SOs) such as sensors and actuators\nhave been widely deployed in smart environments, opening new attack surfaces to\nintruders. The severe security flaw discourages the adoption of the Internet of\nthings in smart living. In this paper, we leverage fog computing and\nmicroservice to push certificate authority (CA) functions to the proximity of\ndata sources. Through which, we can minimize attack surfaces and authentication\nlatency, and result in a fast and scalable scheme in authenticating a large\nvolume of resource-limited devices. Then, we design lightweight protocols to\nimplement the scheme, where both a high level of security and low computation\nworkloads on SO (no bilinear pairing requirement on the client-side) is\naccomplished. Evaluations demonstrate the efficiency and effectiveness of our\nscheme in handling authentication and registration for a large number of nodes,\nmeanwhile protecting them against various threats to smart living. Finally, we\nshowcase the success of computing intelligence movement towards data sources in\nhandling complicated services.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 11:41:26 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Li", "Jianhua", ""], ["Jin", "Jiong", ""], ["Lyu", "Lingjuan", ""], ["Yuan", "Dong", ""], ["Yang", "Yingying", ""], ["Gao", "Longxiang", ""], ["Shen", "Chao", ""]]}, {"id": "2011.06350", "submitter": "Henry Clausen", "authors": "Henry Clausen, Robert Flood, David Aspinall", "title": "Traffic Generation using Containerization for Machine Learning", "comments": "This work was presented at the ACSAC DYNAMICS '19: DYnamic and Novel\n  Advances in Machine Learning and Intelligent Cyber Security Workshop in\n  December 09-10, 2019, San Juan, PR, and will be published in the\n  corresponding workshop proceedings. This document version is specifically for\n  publication on arXiv. 12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The design and evaluation of data-driven network intrusion detection methods\nare currently held back by a lack of adequate data, both in terms of benign and\nattack traffic. Existing datasets are mostly gathered in isolated lab\nenvironments containing virtual machines, to both offer more control over the\ncomputer interactions and prevent any malicious code from escaping. This\nprocedure however leads to datasets that lack four core properties:\nheterogeneity, ground truth traffic labels, large data size, and contemporary\ncontent. Here, we present a novel data generation framework based on Docker\ncontainers that addresses these problems systematically. For this, we arrange\nsuitable containers into relevant traffic communication scenarios and\nsubscenarios, which are subject to appropriate input randomization as well as\nWAN emulation. By relying on process isolation through containerization, we can\nmatch traffic events with individual processes, and achieve scalability and\nmodularity of individual traffic scenarios. We perform two experiments to\nassess the reproducability and traffic properties of our framework, and\ndemonstrate the usefulness of our framework on a traffic classification\nexample.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 12:45:53 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Clausen", "Henry", ""], ["Flood", "Robert", ""], ["Aspinall", "David", ""]]}, {"id": "2011.06376", "submitter": "Peichen Xie", "authors": "Peichen Xie, Xuanle Ren, Guangyu Sun", "title": "Customizing Trusted AI Accelerators for Efficient Privacy-Preserving\n  Machine Learning", "comments": "This work was carried out in 2019 and was accepted to DAC 2020 WIP\n  session", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The use of trusted hardware has become a promising solution to enable\nprivacy-preserving machine learning. In particular, users can upload their\nprivate data and models to a hardware-enforced trusted execution environment\n(e.g. an enclave in Intel SGX-enabled CPUs) and run machine learning tasks in\nit with confidentiality and integrity guaranteed. To improve performance, AI\naccelerators have been widely employed for modern machine learning tasks.\nHowever, how to protect privacy on an AI accelerator remains an open question.\nTo address this question, we propose a solution for efficient\nprivacy-preserving machine learning based on an unmodified trusted CPU and a\ncustomized trusted AI accelerator. We carefully leverage cryptographic\nprimitives to establish trust and protect the channel between the CPU and the\naccelerator. As a case study, we demonstrate our solution based on the\nopen-source versatile tensor accelerator. The result of evaluation shows that\nthe proposed solution provides efficient privacy-preserving machine learning at\na small design cost and moderate performance overhead.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 13:41:18 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Xie", "Peichen", ""], ["Ren", "Xuanle", ""], ["Sun", "Guangyu", ""]]}, {"id": "2011.06404", "submitter": "Rohit Chadha", "authors": "Gilles Barthe and Rohit Chadha and Paul Krogmeier and A. Prasad Sistla\n  and Mahesh Viswanathan", "title": "Deciding Accuracy of Differential Privacy Schemes", "comments": null, "journal-ref": null, "doi": "10.1145/3434289", "report-no": null, "categories": "cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is a mathematical framework for developing statistical\ncomputations with provable guarantees of privacy and accuracy. In contrast to\nthe privacy component of differential privacy, which has a clear mathematical\nand intuitive meaning, the accuracy component of differential privacy does not\nhave a generally accepted definition; accuracy claims of differential privacy\nalgorithms vary from algorithm to algorithm and are not instantiations of a\ngeneral definition. We identify program discontinuity as a common theme in\nexisting \\emph{ad hoc} definitions and introduce an alternative notion of\naccuracy parametrized by, what we call, {\\distance} -- the {\\distance} of an\ninput $x$ w.r.t., a deterministic computation $f$ and a distance $d$, is the\nminimal distance $d(x,y)$ over all $y$ such that $f(y)\\neq f(x)$. We show that\nour notion of accuracy subsumes the definition used in theoretical computer\nscience, and captures known accuracy claims for differential privacy\nalgorithms. In fact, our general notion of accuracy helps us prove better\nclaims in some cases. Next, we study the decidability of accuracy. We first\nshow that accuracy is in general undecidable. Then, we define a non-trivial\nclass of probabilistic computations for which accuracy is decidable\n(unconditionally, or assuming Schanuel's conjecture). We implement our decision\nprocedure and experimentally evaluate the effectiveness of our approach for\ngenerating proofs or counterexamples of accuracy for common algorithms from the\nliterature.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 14:17:51 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Barthe", "Gilles", ""], ["Chadha", "Rohit", ""], ["Krogmeier", "Paul", ""], ["Sistla", "A. Prasad", ""], ["Viswanathan", "Mahesh", ""]]}, {"id": "2011.06458", "submitter": "Jiasi Weng", "authors": "Jiasi Weng, Jian Weng, Chengjun Cai, Hongwei Huang, Cong Wang", "title": "Golden Grain: Building a Secure and Decentralized Model Marketplace for\n  MLaaS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  ML-as-a-service (MLaaS) becomes increasingly popular and revolutionizes the\nlives of people. A natural requirement for MLaaS is, however, to provide highly\naccurate prediction services. To achieve this, current MLaaS systems integrate\nand combine multiple well-trained models in their services. Yet, in reality,\nthere is no easy way for MLaaS providers, especially for startups, to collect\nsufficiently well-trained models from individual developers, due to the lack of\nincentives. In this paper, we aim to fill this gap by building up a model\nmarketplace, called as Golden Grain, to facilitate model sharing, which\nenforces the fair model-money swapping process between individual developers\nand MLaaS providers. Specifically, we deploy the swapping process on the\nblockchain, and further introduce a blockchain-empowered model benchmarking\nprocess for transparently determining the model prices according to their\nauthentic performances, so as to motivate the faithful contributions of\nwell-trained models. Especially, to ease the blockchain overhead for model\nbenchmarking, our marketplace carefully offloads the heavy computation and\ndesigns a secure off-chain on-chain interaction protocol based on a trusted\nexecution environment (TEE), for ensuring both the integrity and authenticity\nof benchmarking. We implement a prototype of our Golden Grain on the Ethereum\nblockchain, and conduct extensive experiments using standard benchmark datasets\nto demonstrate the practically affordable performance of our design.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 15:59:18 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 23:55:02 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2020 12:21:12 GMT"}, {"version": "v4", "created": "Fri, 11 Dec 2020 11:09:52 GMT"}, {"version": "v5", "created": "Mon, 3 May 2021 11:07:35 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Weng", "Jiasi", ""], ["Weng", "Jian", ""], ["Cai", "Chengjun", ""], ["Huang", "Hongwei", ""], ["Wang", "Cong", ""]]}, {"id": "2011.06479", "submitter": "Constantinos Patsakis", "authors": "Constantinos Patsakis and Anargyros Chrysanthou", "title": "Analysing the fall 2020 Emotet campaign", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we analyse the latest campaign of Emotet that had a\nsignificant impact in several countries worldwide. We leverage the data of a\nspecifically crafted dataset, which contains emails, documents, executables and\ndomains from the latest campaign. The goal is to analyse the attack vector, map\nthe infrastructure used in various stages of the campaign and perform a surface\nanalysis of Emotet's malicious payloads to assess their potential impact.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 16:31:37 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Patsakis", "Constantinos", ""], ["Chrysanthou", "Anargyros", ""]]}, {"id": "2011.06546", "submitter": "Claudio Chamon", "authors": "Claudio Chamon, Eduardo R. Mucciolo, and Andrei E. Ruckenstein", "title": "Reaching the speed limit of classical block ciphers via quantum-like\n  operator spreading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cond-mat.stat-mech quant-ph", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We cast encryption via classical block ciphers in terms of operator spreading\nin a dual space of Pauli strings, a formulation which allows us to characterize\nclassical ciphers by using tools well known in the analysis of quantum\nmany-body systems. We connect plaintext and ciphertext attacks to out-of-time\norder correlators (OTOCs) and quantify the quality of ciphers using measures of\ndelocalization in string space such as participation ratios and corresponding\nentropies obtained from the wave function amplitudes in string space. In\nparticular, we show that in Feistel ciphers the entropy saturates its bound to\nexponential precision for ciphers with 4 or more rounds, consistent with the\nclassic Luby-Rackoff result. The saturation of the string-space information\nentropy is accompanied by the vanishing of OTOCs. Together these signal\nirreversibility and chaos, which we take to be the defining properties of good\nclassical ciphers. More precisely, we define a good cipher by requiring that\nthe saturation of the entropy and the vanishing of OTOCs occurs to\nsuper-polynomial precision, implying that the cipher cannot be distinguished\nfrom a pseudorandom permutation with a polynomial number of queries. We argue\nthat this criterion can be satisfied by $n$-bit block ciphers implemented via\nrandom reversible circuits with ${\\cal O}(n \\log n)$ gates. These circuits are\ncomposed of layers of $n/3$ non-overlapping non-local random 3-bit gates. In\norder to reach this \"speed limit\" we employ a two-stage circuit: this first\nstage deploys a set of linear \"inflationary\" gates that accelerate the growth\nof small individual strings; followed by a second stage implemented via\nuniversal gates that exponentially proliferate the number of macroscopic\nstrings. We suggest that this two-stage construction would result in the\nscrambling of quantum states to similar precision and with circuits of similar\nsize.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 18:06:27 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 15:36:50 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Chamon", "Claudio", ""], ["Mucciolo", "Eduardo R.", ""], ["Ruckenstein", "Andrei E.", ""]]}, {"id": "2011.06690", "submitter": "Zhengyu Zhao", "authors": "Zhengyu Zhao and Zhuoran Liu and Martha Larson", "title": "Adversarial Robustness Against Image Color Transformation within\n  Parametric Filter Space", "comments": "Code is available at\n  https://github.com/ZhengyuZhao/ACE/tree/master/Journal_version. This work has\n  been submitted to the IEEE for possible publication. Copyright may be\n  transferred without notice, after which this version may no longer be\n  accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose Adversarial Color Enhancement (ACE), a novel approach to\ngenerating non-suspicious adversarial images by optimizing a color\ntransformation within a parametric filter space. The filter we use approximates\nhuman-understandable color curve adjustment, constraining ACE with a single,\ncontinuous function. This property gives rise to a principled adversarial\naction space explicitly controlled by filter parameters. Existing color\ntransformation attacks are not guided by a parametric space, and, consequently,\nadditional pixel-related constraints such as regularization and sampling are\nnecessary. These constraints make methodical analysis difficult. In this paper,\nwe carry out a systematic robustness analysis of ACE from both the attack and\ndefense perspectives by varying the bound of the color filter parameters. We\ninvestigate a general formulation of ACE and also a variant targeting\nparticularly appealing color styles, as achieved with popular image filters.\nFrom the attack perspective, we provide extensive experiments on the\nvulnerability of image classifiers, but also explore the vulnerability of\nsegmentation and aesthetic quality assessment algorithms, in both the white-box\nand black-box scenarios. From the defense perspective, more experiments provide\ninsight into the stability of ACE against input transformation-based defenses\nand show the potential of adversarial training for improving model robustness\nagainst ACE.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 23:51:37 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Zhao", "Zhengyu", ""], ["Liu", "Zhuoran", ""], ["Larson", "Martha", ""]]}, {"id": "2011.06725", "submitter": "Olakunle Ibitoye", "authors": "Olakunle Ibitoye, Ashraf Matrawy, and M. Omair Shafiq", "title": "A GAN-based Approach for Mitigating Inference Attacks in Smart Home\n  Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of smart, connected, always listening devices have\nintroduced significant privacy risks to users in a smart home environment.\nBeyond the notable risk of eavesdropping, intruders can adopt machine learning\ntechniques to infer sensitive information from audio recordings on these\ndevices, resulting in a new dimension of privacy concerns and attack variables\nto smart home users. Techniques such as sound masking and microphone jamming\nhave been effectively used to prevent eavesdroppers from listening in to\nprivate conversations. In this study, we explore the problem of adversaries\nspying on smart home users to infer sensitive information with the aid of\nmachine learning techniques. We then analyze the role of randomness in the\neffectiveness of sound masking for mitigating sensitive information leakage. We\npropose a Generative Adversarial Network (GAN) based approach for privacy\npreservation in smart homes which generates random noise to distort the\nunwanted machine learning-based inference. Our experimental results demonstrate\nthat GANs can be used to generate more effective sound masking noise signals\nwhich exhibit more randomness and effectively mitigate deep learning-based\ninference attacks while preserving the semantics of the audio samples.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 02:14:32 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Ibitoye", "Olakunle", ""], ["Matrawy", "Ashraf", ""], ["Shafiq", "M. Omair", ""]]}, {"id": "2011.06779", "submitter": "Innocent Onwuegbuzie Mr", "authors": "Onwuegbuzie Innocent Uzougbo, Samuel-Soma M. Ajibade, Fele Taiwo", "title": "An overview of wireless sensor network security attacks: Mode of\n  operation, severity and mitigation techniques", "comments": "14 Pages, 3 Figures, SSCS Conference 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wireless Sensor Network (WSN) is the network of the future. As it gradually\ngains ground by transforming our lives and environments into a Smart World, it\nwill definitely call for attention from selfish minded Attackers. The first\nsection of this paper introduces the Wireless Sensor Network, its constraints,\narchitecture, and mode of operation. It goes ahead to discuss the applications\nof WSN in health, agriculture, military, transportation, environment,\nindustries. However, WSN automatically inherits the security challenges of the\ntraditional network. The Network security goals which are Confidentiality,\nIntegrity, Availability, and Authentication sometimes called the CIA of Network\nsecurity is discussed with respect to WSN. This is followed by the security\nchallenges of WSN, these challenges are categorized into two (2), Passive and\nActive Attacks, Passive attack is interested in the message, data or\ninformation that traverses the network without hindering the network channel or\nmedium of communication while Active attack is interested in both the data as\nwell as compromising and if possible shutting down the communication channel in\norder to hinders the smooth running of the network. In line with these security\nchallenges, mitigation techniques are proffered to possibly prevent or lessen\nthe severity of the attacks as its almost impossible to stop attackers from\ncarrying out their malicious activities.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 06:33:02 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Uzougbo", "Onwuegbuzie Innocent", ""], ["Ajibade", "Samuel-Soma M.", ""], ["Taiwo", "Fele", ""]]}, {"id": "2011.06820", "submitter": "Michela Iezzi", "authors": "Michela Iezzi", "title": "Practical Privacy-Preserving Data Science With Homomorphic Encryption:\n  An Overview", "comments": "accepted, International Workshop on Privacy and Security of Big Data,\n  IEEE International Conference on Big Data 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy has gained a growing interest nowadays due to the increasing and\nunmanageable amount of produced confidential data. Concerns about the\npossibility of sharing data with third parties, to gain fruitful insights,\nbeset enterprise environments; value not only resides in data but also in the\nintellectual property of algorithms and models that offer analysis results.\nThis impasse locks both the availability of high-performance computing\nresources in the \"as-a-service\" paradigm and the exchange of knowledge with the\nscientific community in a collaborative view. Privacy-preserving data science\nenables the use of private data and algorithms without putting at risk their\nprivacy. Conventional encryption schemes are not able to work on encrypted data\nwithout decrypting them first. Homomorphic Encryption (HE) is a form of\nencryption that allows the computation of encrypted data while preserving the\nfeatures and the format of the plaintext. Against the background of interesting\nuse cases for the Central Bank of Italy, this article focuses on how HE and\ndata science can be leveraged for the design and development of\nprivacy-preserving enterprise applications. We propose a survey of main\nHomomorphic Encryption techniques and recent advances in the conubium between\ndata science and HE.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 09:20:27 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Iezzi", "Michela", ""]]}, {"id": "2011.06849", "submitter": "Georgios M. Nikolopoulos Ph. D", "authors": "Georgios M. Nikolopoulos and Marc Fischlin", "title": "Information-theoretically secure data origin authentication with quantum\n  and classical resources", "comments": "close to the version to be published in Cryptography", "journal-ref": "Cryptography 4 (4), 31 (2020)", "doi": "10.3390/cryptography4040031", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In conventional cryptography, information-theoretically secure message\nauthentication can be achieved by means of universal hash functions, and\nrequires that the two legitimate users share a random secret key, which is\ntwice as long as the message. We address the question as of whether quantum\nresources can offer any advantage over classical unconditionally secure message\nauthentication codes. It is shown that passive prepare-and-measure quantum\nmessage-authentication schemes cannot do better than their classical\ncounterparts. Subsequently we present an interactive entanglement-assisted\nscheme, which ideally allows for the authentication of classical messages with\na classical key, which is as long as the message.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 10:33:29 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Nikolopoulos", "Georgios M.", ""], ["Fischlin", "Marc", ""]]}, {"id": "2011.06933", "submitter": "Mustafa Abdallah", "authors": "Mustafa Abdallah, Daniel Woods, Parinaz Naghizadeh, Issa Khalil,\n  Timothy Cason, Shreyas Sundaram, Saurabh Bagchi", "title": "Morshed: Guiding Behavioral Decision-Makers towards Better Security\n  Investment in Interdependent Systems", "comments": "Accepted to appear at the 16th ACM Asia Conference on Computer and\n  Communications Security (ASIACCS), 2021. arXiv admin note: text overlap with\n  arXiv:2004.01958", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We model the behavioral biases of human decision-making in securing\ninterdependent systems and show that such behavioral decision-making leads to a\nsuboptimal pattern of resource allocation compared to non-behavioral (rational)\ndecision-making. We provide empirical evidence for the existence of such\nbehavioral bias model through a controlled subject study with 145 participants.\nWe then propose three learning techniques for enhancing decision-making in\nmulti-round setups. We illustrate the benefits of our decision-making model\nthrough multiple interdependent real-world systems and quantify the level of\ngain compared to the case in which the defenders are behavioral. We also show\nthe benefit of our learning techniques against different attack models. We\nidentify the effects of different system parameters on the degree of\nsuboptimality of security outcomes due to behavioral decision-making.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 18:23:55 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 18:51:03 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Abdallah", "Mustafa", ""], ["Woods", "Daniel", ""], ["Naghizadeh", "Parinaz", ""], ["Khalil", "Issa", ""], ["Cason", "Timothy", ""], ["Sundaram", "Shreyas", ""], ["Bagchi", "Saurabh", ""]]}, {"id": "2011.07018", "submitter": "Theresa Stadler", "authors": "Theresa Stadler, Bristena Oprisanu, Carmela Troncoso", "title": "Synthetic Data -- Anonymisation Groundhog Day", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthetic data has been advertised as a silver-bullet solution to\nprivacy-preserving data publishing that addresses the shortcomings of\ntraditional anonymisation techniques. The promise is that synthetic data drawn\nfrom generative models preserves the statistical properties of the original\ndataset but, at the same time, provides perfect protection against privacy\nattacks. In this work, we present the first quantitative evaluation of the\nprivacy gain of synthetic data publishing and compare it to that of previous\nanonymisation techniques.\n  Our evaluation of a wide range of state-of-the-art generative models\ndemonstrates that synthetic data either does not prevent inference attacks or\ndoes not retain data utility. In other words, we empirically show that\nsynthetic data suffers from the same limitations as traditional anonymisation\ntechniques.\n  Furthermore, we find that, in contrast to traditional anonymisation, the\nprivacy-utility tradeoff of synthetic data publishing is hard to predict.\nBecause it is impossible to predict what signals a synthetic dataset will\npreserve and what information will be lost, synthetic data leads to a highly\nvariable privacy gain and unpredictable utility loss. In summary, we find that\nsynthetic data is far from the holy grail of privacy-preserving data\npublishing.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 16:58:42 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 12:24:54 GMT"}, {"version": "v3", "created": "Thu, 10 Jun 2021 15:59:34 GMT"}, {"version": "v4", "created": "Thu, 8 Jul 2021 12:29:00 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Stadler", "Theresa", ""], ["Oprisanu", "Bristena", ""], ["Troncoso", "Carmela", ""]]}, {"id": "2011.07022", "submitter": "Xavier Bonnetain", "authors": "Xavier Bonnetain and Samuel Jaques", "title": "Quantum Period Finding against Symmetric Primitives in Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first complete implementation of the offline Simon's\nalgorithm, and estimate its cost to attack the MAC Chaskey, the block cipher\nPRINCE and the NIST lightweight candidate AEAD scheme Elephant.\n  These attacks require a reasonable amount of qubits, comparable to the number\nof qubits required to break RSA-2048. They are faster than other collision\nalgorithms, and the attacks against PRINCE and Chaskey are the most efficient\nknown to date. As Elephant has a key smaller than its state size, the algorithm\nis less efficient and ends up more expensive than exhaustive search.\n  We also propose an optimized quantum circuit for boolean linear algebra as\nwell as complete reversible implementations of PRINCE, Chaskey, spongent and\nKeccak which are of independent interest for quantum cryptanalysis.\n  We stress that our attacks could be applied in the future against today's\ncommunications, and recommend caution when choosing symmetric constructions for\ncases where long-term security is expected.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 17:12:49 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Bonnetain", "Xavier", ""], ["Jaques", "Samuel", ""]]}, {"id": "2011.07114", "submitter": "Xian Yeow Lee", "authors": "Xian Yeow Lee, Yasaman Esfandiari, Kai Liang Tan, Soumik Sarkar", "title": "Query-based Targeted Action-Space Adversarial Policies on Deep\n  Reinforcement Learning Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in computing resources have resulted in the increasing complexity of\ncyber-physical systems (CPS). As the complexity of CPS evolved, the focus has\nshifted from traditional control methods to deep reinforcement learning-based\n(DRL) methods for control of these systems. This is due to the difficulty of\nobtaining accurate models of complex CPS for traditional control. However, to\nsecurely deploy DRL in production, it is essential to examine the weaknesses of\nDRL-based controllers (policies) towards malicious attacks from all angles. In\nthis work, we investigate targeted attacks in the action-space domain, also\ncommonly known as actuation attacks in CPS literature, which perturbs the\noutputs of a controller. We show that a query-based black-box attack model that\ngenerates optimal perturbations with respect to an adversarial goal can be\nformulated as another reinforcement learning problem. Thus, such an adversarial\npolicy can be trained using conventional DRL methods. Experimental results\nshowed that adversarial policies that only observe the nominal policy's output\ngenerate stronger attacks than adversarial policies that observe the nominal\npolicy's input and output. Further analysis reveals that nominal policies whose\noutputs are frequently at the boundaries of the action space are naturally more\nrobust towards adversarial policies. Lastly, we propose the use of adversarial\ntraining with transfer learning to induce robust behaviors into the nominal\npolicy, which decreases the rate of successful targeted attacks by 50%.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 20:25:48 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 21:28:19 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Lee", "Xian Yeow", ""], ["Esfandiari", "Yasaman", ""], ["Tan", "Kai Liang", ""], ["Sarkar", "Soumik", ""]]}, {"id": "2011.07179", "submitter": "Huiwen Wu", "authors": "Huiwen Wu and Cen Chen and Li Wang", "title": "A Theoretical Perspective on Differentially Private Federated Multi-task\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the era of big data, the need to expand the amount of data through data\nsharing to improve model performance has become increasingly compelling. As a\nresult, effective collaborative learning models need to be developed with\nrespect to both privacy and utility concerns. In this work, we propose a new\nfederated multi-task learning method for effective parameter transfer with\ndifferential privacy to protect gradients at the client level. Specifically,\nthe lower layers of the networks are shared across all clients to capture\ntransferable feature representation, while top layers of the network are\ntask-specific for on-client personalization. Our proposed algorithm naturally\nresolves the statistical heterogeneity problem in federated networks. We are,\nto the best of knowledge, the first to provide both privacy and utility\nguarantees for such a proposed federated algorithm. The convergences are proved\nfor the cases with Lipschitz smooth objective functions under the non-convex,\nconvex, and strongly convex settings. Empirical experiment results on different\ndatasets have been conducted to demonstrate the effectiveness of the proposed\nalgorithm and verify the implications of the theoretical findings.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 00:53:16 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Wu", "Huiwen", ""], ["Chen", "Cen", ""], ["Wang", "Li", ""]]}, {"id": "2011.07222", "submitter": "Risul Islam", "authors": "Risul Islam, Md Omar Faruk Rokon, Ahmad Darki, Michalis Faloutsos", "title": "HackerScope: The Dynamics of a Massive Hacker Online Ecosystem", "comments": "8 pages, 7 figures, and 4 tables. In press of ASONAM'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Authors of malicious software are not hiding as much as one would assume:\nthey have a visible online footprint. Apart from online forums, this footprint\nappears in software development platforms, where authors create\npublicly-accessible malware repositories to share and collaborate. With the\nexception of a few recent efforts, the existence and the dynamics of this\ncommunity has received surprisingly limited attention. The goal of our work is\nto analyze this ecosystem of hackers in order to: (a) understand their\ncollaborative patterns, and (b) identify and profile its most influential\nauthors. We develop HackerScope, a systematic approach for analyzing the\ndynamics of this hacker ecosystem. Leveraging our targeted data collection, we\nconduct an extensive study of 7389 authors of malware repositories on GitHub,\nwhich we combine with their activity on four security forums. From a modeling\npoint of view, we study the ecosystem using three network representations: (a)\nthe author-author network, (b) the author-repository network, and (c)\ncross-platform egonets. Our analysis leads to the following key observations:\n(a) the ecosystem is growing at an accelerating rate as the number of new\nmalware authors per year triples every 2 years, (b) it is highly collaborative,\nmore so than the rest of GitHub authors, and (c) it includes influential and\nprofessional hackers. We find 30 authors maintain an online \"brand\" across\nGitHub and our security forums. Our study is a significant step towards using\npublic online information for understanding the malicious hacker community.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 05:19:54 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Islam", "Risul", ""], ["Rokon", "Md Omar Faruk", ""], ["Darki", "Ahmad", ""], ["Faloutsos", "Michalis", ""]]}, {"id": "2011.07226", "submitter": "Risul Islam", "authors": "Risul Islam, Md Omar Faruk Rokon, Evangelos E. Papalexakis, Michalis\n  Faloutsos", "title": "TenFor: A Tensor-Based Tool to Extract Interesting Events from Security\n  Forums", "comments": "8 pages, 5 figures, and 4 tables. In Press of ASONAM'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  How can we get a security forum to \"tell\" us its activities and events of\ninterest? We take a unique angle: we want to identify these activities without\nany a priori knowledge, which is a key difference compared to most of the\nprevious problem formulations. Despite some recent efforts, mining security\nforums to extract useful information has received relatively little attention,\nwhile most of them are usually searching for specific information. We propose\nTenFor, an unsupervised tensor-based approach, to systematically identify\nimportant events in a three-dimensional space: (a) user, (b) thread, and (c)\ntime. Our method consists of three high-level steps: (a) a tensor-based\nclustering across the three dimensions, (b) an extensive cluster profiling that\nuses both content and behavioral features, and (c) a deeper investigation,\nwhere we identify key users and threads within the events of interest. In\naddition, we implement our approach as a powerful and easy-to-use platform for\npractitioners. In our evaluation, we find that 83% of our clusters capture\nmeaningful events and we find more meaningful clusters compared to previous\napproaches. Our approach and our platform constitute an important step towards\ndetecting activities of interest from a forum in an unsupervised learning\nfashion in practice.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 05:59:07 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Islam", "Risul", ""], ["Rokon", "Md Omar Faruk", ""], ["Papalexakis", "Evangelos E.", ""], ["Faloutsos", "Michalis", ""]]}, {"id": "2011.07229", "submitter": "Dipankar Sarkar", "authors": "Dipankar Sarkar, Sumit Rai, Ankur Narang", "title": "CatFedAvg: Optimising Communication-efficiency and Classification\n  Accuracy in Federated Learning", "comments": "Supplementary material included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Federated learning has allowed the training of statistical models over remote\ndevices without the transfer of raw client data. In practice, training in\nheterogeneous and large networks introduce novel challenges in various aspects\nlike network load, quality of client data, security and privacy. Recent works\nin FL have worked on improving communication efficiency and addressing uneven\nclient data distribution independently, but none have provided a unified\nsolution for both challenges. We introduce a new family of Federated Learning\nalgorithms called CatFedAvg which not only improves the communication\nefficiency but improves the quality of learning using a category coverage\nmaximization strategy.\n  We use the FedAvg framework and introduce a simple and efficient step every\nepoch to collect meta-data about the client's training data structure which the\ncentral server uses to request a subset of weight updates. We explore two\ndistinct variations which allow us to further explore the tradeoffs between\ncommunication efficiency and model accuracy. Our experiments based on a vision\nclassification task have shown that an increase of 10% absolute points in\naccuracy using the MNIST dataset with 70% absolute points lower network\ntransfer over FedAvg. We also run similar experiments with Fashion MNIST,\nKMNIST-10, KMNIST-49 and EMNIST-47. Further, under extreme data imbalance\nexperiments for both globally and individual clients, we see the model\nperforming better than FedAvg. The ablation study further explores its\nbehaviour under varying data and client parameter conditions showcasing the\nrobustness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 06:52:02 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Sarkar", "Dipankar", ""], ["Rai", "Sumit", ""], ["Narang", "Ankur", ""]]}, {"id": "2011.07262", "submitter": "Md Sadek Ferdous", "authors": "Md. Atik Shahriar, Faisal Haque Bappy, A. K. M. Fakhrul Hossain,\n  Dayamoy Datta Saikat, Md Sadek Ferdous, Mohammad Jabed M. Chowdhury, Md\n  Zakirul Alam Bhuiyan", "title": "Modelling Attacks in Blockchain Systems using Petri Nets", "comments": "Accepted for publication at the 19th IEEE International Conference on\n  Trust, Security and Privacy in Computing and Communications (IEEE TrustCom\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain technology has evolved through many changes and modifications,\nsuch as smart-contracts since its inception in 2008. The popularity of a\nblockchain system is due to the fact that it offers a significant security\nadvantage over other traditional systems. However, there have been many attacks\nin various blockchain systems, exploiting different vulnerabilities and bugs,\nwhich caused a significant financial loss. Therefore, it is essential to\nunderstand how these attacks in blockchain occur, which vulnerabilities they\nexploit, and what threats they expose. Another concerning issue in this domain\nis the recent advancement in the quantum computing field, which imposes a\nsignificant threat to the security aspects of many existing secure systems,\nincluding blockchain, as they would invalidate many widely-used cryptographic\nalgorithms. Thus, it is important to examine how quantum computing will affect\nthese or other new attacks in the future. In this paper, we explore different\nvulnerabilities in current blockchain systems and analyse the threats that\nvarious theoretical and practical attacks in the blockchain expose. We then\nmodel those attacks using Petri nets concerning current systems and future\nquantum computers.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 10:48:57 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Shahriar", "Md. Atik", ""], ["Bappy", "Faisal Haque", ""], ["Hossain", "A. K. M. Fakhrul", ""], ["Saikat", "Dayamoy Datta", ""], ["Ferdous", "Md Sadek", ""], ["Chowdhury", "Mohammad Jabed M.", ""], ["Bhuiyan", "Md Zakirul Alam", ""]]}, {"id": "2011.07269", "submitter": "Cataldo Basile", "authors": "Daniele Canavese, Leonardo Regano, Cataldo Basile, Bart Coppens, Bjorn\n  De Sutter", "title": "Software Protection as a Risk Analysis Process", "comments": "This paper was submitted to ACM TOPS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last years have seen an increase of Man-at-the-End (MATE) attacks against\nsoftware applications, both in number and severity. However, MATE software\nprotections are dominated by fuzzy concepts and techniques, and\nsecurity-through-obscurity is omnipresent in this field. In this paper, we\npresent a rationale for adopting and standardizing the protection of software\nas a risk management process according to the NIST SP800-39 approach. We\nexamine the relevant aspects of formalizing and automating the risk management\nactivities, to instigate the necessary actions for adoption. We highlight the\nopen issues that the research community has to address. We discuss the benefits\nthat such an approach can bring to all stakeholders, from software developers\nto protections designers, and for the security of all the citizens. In\naddition, we present a Proof of Concept (PoC) of a decision support system that\nautomates the risk analysis methodology towards the protection of software\napplications. Despite being in an embryonic stage, the PoC proved during\nvalidation with industry experts that several aspects of the risk management\nprocess can already be formalized and that it is an excellent starting point\nfor building an industrial-grade decision support system.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 11:23:09 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 16:20:48 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Canavese", "Daniele", ""], ["Regano", "Leonardo", ""], ["Basile", "Cataldo", ""], ["Coppens", "Bart", ""], ["De Sutter", "Bjorn", ""]]}, {"id": "2011.07306", "submitter": "Pietro Tedeschi", "authors": "Pietro Tedeschi, Spiridon Bakiras, Roberto Di Pietro", "title": "SpreadMeNot: A Provably Secure and Privacy-Preserving Contact Tracing\n  Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A plethora of contact tracing apps have been developed and deployed in\nseveral countries around the world in the battle against Covid-19. However,\npeople are rightfully concerned about the security and privacy risks of such\napplications. To this end, the contribution of this work is twofold. First, we\npresent an in-depth analysis of the security and privacy characteristics of the\nmost prominent contact tracing protocols, under both passive and active\nadversaries. The results of our study indicate that all protocols are\nvulnerable to a variety of attacks, mainly due to the deterministic nature of\nthe underlying cryptographic protocols. Our second contribution is the design\nand implementation of SpreadMeNot, a novel contact tracing protocol that can\ndefend against most passive and active attacks, thus providing strong\n(provable) security and privacy guarantees that are necessary for such a\nsensitive application. Our detailed analysis, both formal and experimental,\nshows that SpreadMeNot satisfies security, privacy, and performance\nrequirements, hence being an ideal candidate for building a contact tracing\nsolution that can be adopted by the majority of the general public, as well as\nto serve as an open-source reference for further developments in the field.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 14:03:53 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 09:02:33 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Tedeschi", "Pietro", ""], ["Bakiras", "Spiridon", ""], ["Di Pietro", "Roberto", ""]]}, {"id": "2011.07323", "submitter": "Arsenia (Ersi) Chorti", "authors": "Arsenia Chorti", "title": "Brief Report on QoSec, Context Aware Security and the Role of Physical\n  Layer Security in 6G Wireless", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the security literature predominantly focuses on the core network, the\nenhancement of the security of the beyond fifth generation (B5G) access network\nbecomes of critical importance. Despite the strengthening of 5G security\nprotocols with respect to LTE, there are still open issues that have not yet\nbeen fully addressed. In parallel as we move gradually away from the standard\nclient-server networking paradigm and enter a new era of truly E2E quality of\nservice (QoS), service level agreements (SLAs) in the near future will be\nexpected to include guarantees about the quality of security (QoSec) as well.\nIncorporating context awareness in QoSec is projected to allow handle more\nefficiently aspects related to identifying the risk or threat level and the\nrequired security level. Finally, as novel sensing and intelligence\ncapabilities are envisioned in 6G, security solutions from the palette of\nphysical layer security can emerge, particularly for massive machine type\ncommunications involving large scale low-end IoT devices.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 15:41:58 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Chorti", "Arsenia", ""]]}, {"id": "2011.07355", "submitter": "Jamie Hayes", "authors": "Jamie Hayes, Krishnamurthy (Dj) Dvijotham, Yutian Chen, Sander\n  Dieleman, Pushmeet Kohli, Norman Casagrande", "title": "Towards transformation-resilient provenance detection of digital media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advancements in deep generative models have made it possible to synthesize\nimages, videos and audio signals that are difficult to distinguish from natural\nsignals, creating opportunities for potential abuse of these capabilities. This\nmotivates the problem of tracking the provenance of signals, i.e., being able\nto determine the original source of a signal. Watermarking the signal at the\ntime of signal creation is a potential solution, but current techniques are\nbrittle and watermark detection mechanisms can easily be bypassed by applying\npost-processing transformations (cropping images, shifting pitch in the audio\netc.). In this paper, we introduce ReSWAT (Resilient Signal Watermarking via\nAdversarial Training), a framework for learning transformation-resilient\nwatermark detectors that are able to detect a watermark even after a signal has\nbeen through several post-processing transformations. Our detection method can\nbe applied to domains with continuous data representations such as images,\nvideos or sound signals. Experiments on watermarking image and audio signals\nshow that our method can reliably detect the provenance of a signal, even if it\nhas been through several post-processing transformations, and improve upon\nrelated work in this setting. Furthermore, we show that for specific kinds of\ntransformations (perturbations bounded in the L2 norm), we can even get formal\nguarantees on the ability of our model to detect the watermark. We provide\nqualitative examples of watermarked image and audio samples in\nhttps://drive.google.com/open?id=1-yZ0WIGNu2Iez7UpXBjtjVgZu3jJjFga.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 18:08:07 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Hayes", "Jamie", "", "Dj"], ["Krishnamurthy", "", "", "Dj"], ["Dvijotham", "", ""], ["Chen", "Yutian", ""], ["Dieleman", "Sander", ""], ["Kohli", "Pushmeet", ""], ["Casagrande", "Norman", ""]]}, {"id": "2011.07400", "submitter": "Ivan De Oliveira Nunes", "authors": "Ivan De Oliveira Nunes, Sashidhar Jakkamsetti, Gene Tsudik", "title": "Tiny-CFA: A Minimalistic Approach for Control-Flow Attestation Using\n  Verified Proofs of Execution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of tiny trust anchors has received significant attention over the\npast decade, to secure low-end MCU-s that cannot afford expensive security\nmechanisms. In particular, hardware/software (hybrid) co-designs offer low\nhardware cost, while retaining similar security guarantees as (more expensive)\nhardware-based techniques. Hybrid trust anchors support security services, such\nas remote attestation, proofs of software update/erasure/reset, proofs of\nremote software execution, in resource-constrained MCU-s, e.g., MSP430 and AVR\nAtMega32. Despite these advances, detection of control-flow attacks in low-end\nMCU-s remains a challenge, since hardware requirements of the cheapest related\narchitectures are often more expensive than the MCU-s themselves. In this work,\nwe tackle this challenge by designing Tiny-CFA - a control-flow attestation\n(CFA) technique with a single hardware requirement - the ability to generate\nproofs of remote software execution (PoX). In turn, PoX can be implemented very\nefficiently and securely in low-end MCU-s. Consequently, our design achieves\nthe lowest hardware overhead of any CFA architecture (i.e., two orders of\nmagnitude cheaper), while relying on a formally verified PoX architecture as\nits sole hardware requirement. With respect to runtime overhead, Tiny-CFA also\nachieves better performance than prior CFA techniques based on code\ninstrumentation. We implement and evaluate Tiny-CFA, analyze its security, and\ndemonstrate its practicality using real-world publicly available applications.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 22:09:15 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 20:20:06 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Nunes", "Ivan De Oliveira", ""], ["Jakkamsetti", "Sashidhar", ""], ["Tsudik", "Gene", ""]]}, {"id": "2011.07429", "submitter": "Anbu Huang", "authors": "Anbu Huang", "title": "Dynamic backdoor attacks against federated learning", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is a new machine learning framework, which enables\nmillions of participants to collaboratively train machine learning model\nwithout compromising data privacy and security. Due to the independence and\nconfidentiality of each client, FL does not guarantee that all clients are\nhonest by design, which makes it vulnerable to adversarial attack naturally. In\nthis paper, we focus on dynamic backdoor attacks under FL setting, where the\ngoal of the adversary is to reduce the performance of the model on targeted\ntasks while maintaining a good performance on the main task, current existing\nstudies are mainly focused on static backdoor attacks, that is the poison\npattern injected is unchanged, however, FL is an online learning framework, and\nadversarial targets can be changed dynamically by attacker, traditional\nalgorithms require learning a new targeted task from scratch, which could be\ncomputationally expensive and require a large number of adversarial training\nexamples, to avoid this, we bridge meta-learning and backdoor attacks under FL\nsetting, in which case we can learn a versatile model from previous\nexperiences, and fast adapting to new adversarial tasks with a few of examples.\nWe evaluate our algorithm on different datasets, and demonstrate that our\nalgorithm can achieve good results with respect to dynamic backdoor attacks. To\nthe best of our knowledge, this is the first paper that focus on dynamic\nbackdoor attacks research under FL setting.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 01:32:58 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Huang", "Anbu", ""]]}, {"id": "2011.07483", "submitter": "Prabhat Kushwaha", "authors": "Michael John Jacobson, Jr. and Prabhat Kushwaha", "title": "Removable Weak Keys for Discrete Logarithm Based Cryptography", "comments": null, "journal-ref": "Journal of Cryptographic Engineering 2020", "doi": "10.1007/s13389-020-00250-7", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We describe a novel type of weak cryptographic private key that can exist in\nany discrete logarithm based public-key cryptosystem set in a group of prime\norder $p$ where $p-1$ has small divisors. Unlike the weak private keys based on\n\\textit{numerical size} (such as smaller private keys, or private keys lying in\nan interval) that will \\textit{always} exist in any DLP cryptosystems, our type\nof weak private keys occurs purely due to parameter choice of $p$, and hence,\ncan be removed with appropriate value of $p$. Using the theory of implicit\ngroup representations, we present algorithms that can determine whether a key\nis weak, and if so, recover the private key from the corresponding public key.\nWe analyze several elliptic curves proposed in the literature and in various\nstandards, giving counts of the number of keys that can be broken with\nrelatively small amounts of computation. Our results show that many of these\ncurves, including some from standards, have a considerable number of such weak\nprivate keys. We also use our methods to show that none of the 14 outstanding\nCerticom Challenge problem instances are weak in our sense, up to a certain\nweakness bound.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 09:17:11 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Jacobson,", "Michael John", "Jr."], ["Kushwaha", "Prabhat", ""]]}, {"id": "2011.07555", "submitter": "Pashmina Cameron", "authors": "Goutham Ramakrishnan, Aditya Nori, Hannah Murfet, Pashmina Cameron", "title": "Towards Compliant Data Management Systems for Healthcare ML", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The increasing popularity of machine learning approaches and the rising\nawareness of data protection and data privacy presents an opportunity to build\ntruly secure and trustworthy healthcare systems. Regulations such as GDPR and\nHIPAA present broad guidelines and frameworks, but the implementation can\npresent technical challenges. Compliant data management systems require\nenforcement of a number of technical and administrative safeguards. While\npolicies can be set for both safeguards there is limited availability to\nunderstand compliance in real time. Increasingly, machine learning\npractitioners are becoming aware of the importance of keeping track of\nsensitive data. With sensitivity over personally identifiable, health or\ncommercially sensitive information there would be value in understanding\nassessment of the flow of data in a more dynamic fashion. We review how data\nflows within machine learning projects in healthcare from source to storage to\nuse in training algorithms and beyond. Based on this, we design engineering\nspecifications and solutions for versioning of data. Our objective is to design\ntools to detect and track sensitive data across machines and users across the\nlife cycle of a project, prioritizing efficiency, consistency and ease of use.\nWe build a prototype of the solution that demonstrates the difficulties in this\ndomain. Together, these represent first efforts towards building a compliant\ndata management system for healthcare machine learning projects.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 15:27:51 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Ramakrishnan", "Goutham", ""], ["Nori", "Aditya", ""], ["Murfet", "Hannah", ""], ["Cameron", "Pashmina", ""]]}, {"id": "2011.07603", "submitter": "Shayan Moini", "authors": "Shayan Moini, Shanquan Tian, Jakub Szefer, Daniel Holcomb, and Russell\n  Tessier", "title": "Power Side-Channel Attacks on BNN Accelerators in Remote FPGAs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To lower cost and increase the utilization of Cloud Field-Programmable Gate\nArrays (FPGAs), researchers have recently been exploring the concept of\nmulti-tenant FPGAs, where multiple independent users simultaneously share the\nsame remote FPGA. Despite its benefits, multi-tenancy opens up the possibility\nof malicious users co-locating on the same FPGA as a victim user, and\nextracting sensitive information. This issue becomes especially serious when\nthe user is running a machine learning algorithm that is processing sensitive\nor private information. To demonstrate the dangers, this paper presents a\nremote, power-based side-channel attack on a deep neural network accelerator\nrunning in a variety of Xilinx FPGAs and also on Cloud FPGAs using Amazon Web\nServices (AWS) F1 instances. This work in particular shows how to remotely\nobtain voltage estimates as a deep neural network inference circuit executes,\nand how the information can be used to recover the inputs to the neural\nnetwork. The attack is demonstrated with a binarized convolutional neural\nnetwork used to recognize handwriting images from the MNIST handwritten digit\ndatabase. With the use of precise time-to-digital converters for remote voltage\nestimation, the MNIST inputs can be successfully recovered with a maximum\nnormalized cross-correlation of 79% between the input image and the recovered\nimage on local FPGA boards and 72% on AWS F1 instances. The attack requires no\nphysical access nor modifications to the FPGA hardware.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 18:54:01 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2021 03:52:10 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Moini", "Shayan", ""], ["Tian", "Shanquan", ""], ["Szefer", "Jakub", ""], ["Holcomb", "Daniel", ""], ["Tessier", "Russell", ""]]}, {"id": "2011.07633", "submitter": "Jinyuan Jia", "authors": "Jinyuan Jia, Binghui Wang, Xiaoyu Cao, Hongbin Liu, Neil Zhenqiang\n  Gong", "title": "Almost Tight L0-norm Certified Robustness of Top-k Predictions against\n  Adversarial Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Top-$k$ predictions are used in many real-world applications such as machine\nlearning as a service, recommender systems, and web searches. $\\ell_0$-norm\nadversarial perturbation characterizes an attack that arbitrarily modifies some\nfeatures of an input such that a classifier makes an incorrect prediction for\nthe perturbed input. $\\ell_0$-norm adversarial perturbation is easy to\ninterpret and can be implemented in the physical world. Therefore, certifying\nrobustness of top-$k$ predictions against $\\ell_0$-norm adversarial\nperturbation is important. However, existing studies either focused on\ncertifying $\\ell_0$-norm robustness of top-$1$ predictions or $\\ell_2$-norm\nrobustness of top-$k$ predictions. In this work, we aim to bridge the gap. Our\napproach is based on randomized smoothing, which builds a provably robust\nclassifier from an arbitrary classifier via randomizing an input. Our major\ntheoretical contribution is an almost tight $\\ell_0$-norm certified robustness\nguarantee for top-$k$ predictions. We empirically evaluate our method on\nCIFAR10 and ImageNet. For instance, our method can build a classifier that\nachieves a certified top-3 accuracy of 69.2\\% on ImageNet when an attacker can\narbitrarily perturb 5 pixels of a testing image.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 21:34:44 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Jia", "Jinyuan", ""], ["Wang", "Binghui", ""], ["Cao", "Xiaoyu", ""], ["Liu", "Hongbin", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "2011.07682", "submitter": "Scott Freitas", "authors": "Scott Freitas, Yuxiao Dong, Joshua Neil, Duen Horng Chau", "title": "A Large-Scale Database for Graph Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid emergence of graph representation learning, the construction\nof new large-scale datasets are necessary to distinguish model capabilities and\naccurately assess the strengths and weaknesses of each technique. By carefully\nanalyzing existing graph databases, we identify 3 critical components important\nfor advancing the field of graph representation learning: (1) large graphs, (2)\nmany graphs, and (3) class diversity. To date, no single graph database offers\nall of these desired properties. We introduce MalNet, the largest public graph\ndatabase ever constructed, representing a large-scale ontology of software\nfunction call graphs. MalNet contains over 1.2 million graphs, averaging over\n17k nodes and 39k edges per graph, across a hierarchy of 47 types and 696\nfamilies. Compared to the popular REDDIT-12K database, MalNet offers 105x more\ngraphs, 44x larger graphs on average, and 63x the classes. We provide a\ndetailed analysis of MalNet, discussing its properties and provenance. The\nunprecedented scale and diversity of MalNet offers exciting opportunities to\nadvance the frontiers of graph representation learning---enabling new\ndiscoveries and research into imbalanced classification, explainability and the\nimpact of class hardness. The database is publically available at\nwww.mal-net.org.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 01:50:21 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Freitas", "Scott", ""], ["Dong", "Yuxiao", ""], ["Neil", "Joshua", ""], ["Chau", "Duen Horng", ""]]}, {"id": "2011.07764", "submitter": "Navod Thilakarathne", "authors": "N.N.Thilakarathne, Dilani Wickramaaarachchi", "title": "Improved hierarchical role based access control model for cloud\n  computing", "comments": null, "journal-ref": "International Research Conference on Smart Computing and Systems\n  Engineering ( 2018 )", "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is considered as the one of the most dominant paradigm in\nfield of information technology which offers on demand cost effective services\nsuch as Software as a service (SAAS), Infrastructure as a service (IAAS) and\nPlatform as a service (PAAS).Promising all these services as it is, this cloud\ncomputing paradigm still associates number of challenges such as data security,\nabuse of cloud services, malicious insider and cyber-attacks. Among all these\nsecurity requirements of cloud computing access control is the one of the\nfundamental requirement in order to avoid unauthorized access to a system and\norganizational assets. Main purpose of this research is to review the existing\nmethods of cloud access control models and their variants pros and cons and to\nidentify further related research directions for developing an improved access\ncontrol model for public cloud data storage. We have presented detailed access\ncontrol requirement analysis for cloud computing and have identified important\ngaps, which are not fulfilled by conventional access control models. As the\noutcome of the study we have come up with an improved access control model with\nhybrid cryptographic schema and hybrid cloud architecture and practical\nimplementation of it. We have tested our model for security implications,\nperformance, functionality and data integrity to prove the validity. We have\nused AES and RSA cryptographic algorithms to implement the cryptographic schema\nand used public and private cloud to enforce our access control security and\nreliability.By validating and testing we have proved that our model can\nwithstand against most of the cyber attacks in real cloud environment. Hence it\nhas improved capabilities compared with other previous access control models\nthat we have reviewed through literature.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 07:49:32 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Thilakarathne", "N. N.", ""], ["Wickramaaarachchi", "Dilani", ""]]}, {"id": "2011.07793", "submitter": "Xiaoyu Wang", "authors": "Xiaoyu Wang, Lei Yu, Houhua He, Xiaorui Gong", "title": "MAAC: Novel Alert Correlation Method To Detect Multi-step Attack", "comments": "6 pages,4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the continuous improvement of attack methods, there are more and more\ndistributed, complex, targeted attacks, and attackers use combined methods to\nattack. Advanced cyber attacks include multiple stages to achieve the ultimate\ngoal. Traditional intrusion detection systems such as terminal security\nmanagement tools, firewalls, and other monitoring tools will generate a large\nnumber of alerts during the attack. These alerts include attack clues, as well\nas many false positives unrelated to attacks. Security analysts need to analyze\na large number of alerts and find useful clues from them, make correlations,\nand restore attack scenarios. However, most traditional security monitoring\ntools cannot correlate alerts from different sources, so many multi-step\nattacks are still completely unnoticed, requiring manual analysis by security\nanalysts like finding a needle in a haystack. We propose MMAC, a multi-step\nattack alert correlation algorithm, which reduces repeated alerts and combines\nmulti-stage attack paths based on alert semantics and attack stages. The\nevaluation results of the dataset and real scene show that MAAC can find and\nevaluate attack paths from a large number of alerts.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 08:51:03 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Wang", "Xiaoyu", ""], ["Yu", "Lei", ""], ["He", "Houhua", ""], ["Gong", "Xiaorui", ""]]}, {"id": "2011.07835", "submitter": "Bhagyashree Puranik", "authors": "Bhagyashree Puranik, Upamanyu Madhow, Ramtin Pedarsani", "title": "Adversarially Robust Classification based on GLRT", "comments": "Submitted to the International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are vulnerable to adversarial attacks that can often\ncause misclassification by introducing small but well designed perturbations.\nIn this paper, we explore, in the setting of classical composite hypothesis\ntesting, a defense strategy based on the generalized likelihood ratio test\n(GLRT), which jointly estimates the class of interest and the adversarial\nperturbation. We evaluate the GLRT approach for the special case of binary\nhypothesis testing in white Gaussian noise under $\\ell_{\\infty}$ norm-bounded\nadversarial perturbations, a setting for which a minimax strategy optimizing\nfor the worst-case attack is known. We show that the GLRT approach yields\nperformance competitive with that of the minimax approach under the worst-case\nattack, and observe that it yields a better robustness-accuracy trade-off under\nweaker attacks, depending on the values of signal components relative to the\nattack budget. We also observe that the GLRT defense generalizes naturally to\nmore complex models for which optimal minimax classifiers are not known.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 10:16:05 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Puranik", "Bhagyashree", ""], ["Madhow", "Upamanyu", ""], ["Pedarsani", "Ramtin", ""]]}, {"id": "2011.07862", "submitter": "Alexey Vishnyakov", "authors": "Alexey Vishnyakov and Alexey Nurmukhametov", "title": "Survey of Methods for Automated Code-Reuse Exploit Generation", "comments": null, "journal-ref": "Programming and Computer Software, 2021, Vol. 47, No. 4, pp.\n  271-297", "doi": "10.1134/S0361768821040071", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper provides a survey of methods and tools for automated code-reuse\nexploit generation. Such exploits use code that is already contained in a\nvulnerable program. The code-reuse approach allows one to exploit\nvulnerabilities in the presence of operating system protection that prohibits\ndata memory execution. This paper contains a description of various code-reuse\nmethods: return-to-libc attack, return-oriented programming, jump-oriented\nprogramming, and others. We define fundamental terms: gadget, gadget frame,\ngadget catalog. Moreover, we show that, in fact, a gadget is an instruction,\nand a set of gadgets defines a virtual machine. We can reduce an exploit\ncreation problem to code generation for this virtual machine. Each particular\nexecutable file defines a virtual machine instruction set. We provide a survey\nof methods for gadgets searching and determining their semantics (creating a\ngadget catalog). These methods allow one to get the virtual machine instruction\nset. If a set of gadgets is Turing-complete, then a compiler can use a gadget\ncatalog as a target architecture. However, some instructions can be absent.\nHence we discuss several approaches to replace missing instructions with\nmultiple gadgets. An exploit generation tool can chain gadgets by pattern\nsearching (regular expressions) or considering gadgets semantics. Furthermore,\nsome chaining methods use genetic algorithms, while others use SMT-solvers. We\ncompare existing open-source tools and propose a testing system rop-benchmark\nthat can be used to verify whether a generated chain successfully opens a\nshell.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 11:00:04 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 13:35:36 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Vishnyakov", "Alexey", ""], ["Nurmukhametov", "Alexey", ""]]}, {"id": "2011.07895", "submitter": "Min Yang", "authors": "Min Yang", "title": "TDACS: an ABAC and Trust-based Dynamic Access Control Scheme in Hadoop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The era of big data has promoted the vigorous development of many industries,\nboosting the full potential of holistic data-driven analysis. Hadoop has become\nthe primary choice for mainstream platforms used by stakeholders to process big\ndata. Thereafter, the security of Hadoop platform has arisen tremendous\nattention worldwide. In this paper, we mainly concentrate on enforcing access\ncontrol on users to ensure platform security. First, we leverage access proxy\nintegrated with attribute-based access control (ABAC) model to implement\nfront-end authorization, which can fully reflect and cope with the flexible\nnature of the complex access control process in Hadoop platform, as well as can\nrelease back-end resources from complex authorization process through access\nproxy. Moreover, in order to ensure the fine-granularity of authorization, the\naccess proxy maintains a list composed of trust threshold value provided by\neach resource according to its importance. The access proxy interacts with the\nblockchain network to obtain the user's trust evaluation value, which serves as\nan important basis for dynamic authorization determination. More specifically,\nblockchain network works together on-chain and off-chain modes. The user's\nhistorical behavior data is stored off-chain, and the corresponding hash value\nis anchored on-chain. Consequently, the user's trust value is evaluated based\non his historical behavior stored on the blockchain platform. Meanwhile, the\nauthenticity of user behavior data can be guaranteed, thereby ensuring the\nreliability of trust assessment results. Our experiment demonstrates that the\nproposed model can dynamically and flexibly adjust user permissions to ensure\nthe security of the platform, while time and money are consumed within a\nreasonable range.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 12:08:38 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Yang", "Min", ""]]}, {"id": "2011.07934", "submitter": "Panayiotis Danassis", "authors": "Panayiotis Danassis, Aleksei Triastcyn, Boi Faltings", "title": "Differential Privacy Meets Maximum-weight Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When it comes to large-scale multi-agent systems with a diverse set of\nagents, traditional differential privacy (DP) mechanisms are ill-matched\nbecause they consider a very broad class of adversaries, and they protect all\nusers, independent of their characteristics, by the same guarantee. Achieving a\nmeaningful privacy leads to pronounced reduction in solution quality. Such\nassumptions are unnecessary in many real-world applications for three key\nreasons: (i) users might be willing to disclose less sensitive information\n(e.g., city of residence, but not exact location), (ii) the attacker might\nposses auxiliary information (e.g., city of residence in a mobility-on-demand\nsystem, or reviewer expertise in a paper assignment problem), and (iii) domain\ncharacteristics might exclude a subset of solutions (an expert on auctions\nwould not be assigned to review a robotics paper, thus there is no need for\nindistinguishably between reviewers on different fields).\n  We introduce Piecewise Local Differential Privacy (PLDP), a privacy model\ndesigned to protect the utility function in applications where the attacker\npossesses additional information on the characteristics of the utility space.\nPLDP enables a high degree of privacy, while being applicable to real-world,\nunboundedly large settings. Moreover, we propose PALMA, a privacy-preserving\nheuristic for maximum-weight matching. We evaluate PALMA in a vehicle-passenger\nmatching scenario using real data and demonstrate that it provides strong\nprivacy, $\\varepsilon \\leq 3$ and a median of $\\varepsilon = 0.44$, and high\nquality matchings ($10.8\\%$ worse than the non-private optimal).\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 13:33:04 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Danassis", "Panayiotis", ""], ["Triastcyn", "Aleksei", ""], ["Faltings", "Boi", ""]]}, {"id": "2011.08069", "submitter": "Aastha Mehta", "authors": "Gilles Barthe, Roberta De Viti, Peter Druschel, Deepak Garg, Manuel\n  Gomez-Rodriguez, Pierfrancesco Ingo, Matthew Lentz, Aastha Mehta, Bernhard\n  Sch\\\"olkopf", "title": "PanCast: Listening to Bluetooth Beacons for Epidemic Risk Mitigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SI q-bio.PE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During the ongoing COVID-19 pandemic, there have been burgeoning efforts to\ndevelop and deploy smartphone apps to expedite contact tracing and risk\nnotification. Most of these apps track pairwise encounters between individuals\nvia Bluetooth and then use these tracked encounters to identify and notify\nthose who might have been in proximity of a contagious individual.\nUnfortunately, these apps have not yet proven sufficiently effective, partly\nowing to low adoption rates, but also due to the difficult tradeoff between\nutility and privacy and the fact that, in COVID-19, most individuals do not\ninfect anyone but a few superspreaders infect many in superspreading events. In\nthis paper, we proposePanCast, a privacy-preserving and inclusive system for\nepidemic risk assessment and notification that scales gracefully with adoption\nrates, utilizes location and environmental information to increase utility\nwithout tracking its users, and can be used to identify superspreading events.\nTo this end, rather than capturing pairwise encounters between smartphones, our\nsystem utilizes Bluetooth encounters between beacons placed in strategic\nlocations where superspreading events are most likely to occur and inexpensive,\nzero-maintenance, small devices that users can attach to their keyring. PanCast\nallows healthy individuals to use the system in a purely passive \"radio\" mode,\nand can assist and benefit from other digital and manual contact tracing\nsystems. Finally, PanCast can be gracefully dismantled at the end of the\npandemic, minimizing abuse from any malevolent government or entity.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 16:19:37 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Barthe", "Gilles", ""], ["De Viti", "Roberta", ""], ["Druschel", "Peter", ""], ["Garg", "Deepak", ""], ["Gomez-Rodriguez", "Manuel", ""], ["Ingo", "Pierfrancesco", ""], ["Lentz", "Matthew", ""], ["Mehta", "Aastha", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2011.08253", "submitter": "Isaac Sheff", "authors": "Isaac Sheff, Xinwen Wang, Robbert van Renesse, Andrew C. Myers", "title": "Heterogeneous Paxos: Technical Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In distributed systems, a group of $\\textit{learners}$ achieve\n$\\textit{consensus}$ when, by observing the output of some\n$\\textit{acceptors}$, they all arrive at the same value. Consensus is crucial\nfor ordering transactions in failure-tolerant systems. Traditional consensus\nalgorithms are homogeneous in three ways:\n  - all learners are treated equally,\n  - all acceptors are treated equally, and\n  - all failures are treated equally.\n  These assumptions, however, are unsuitable for cross-domain applications,\nincluding blockchains, where not all acceptors are equally trustworthy, and not\nall learners have the same assumptions and priorities. We present the first\nconsensus algorithm to be heterogeneous in all three respects. Learners set\ntheir own mixed failure tolerances over differently trusted sets of acceptors.\nWe express these assumptions in a novel $\\textit{Learner Graph}$, and\ndemonstrate sufficient conditions for consensus. We present\n$\\textit{Heterogeneous Paxos}$: an extension of Byzantine Paxos. Heterogeneous\nPaxos achieves consensus for any viable Learner Graph in best-case three\nmessage sends, which is optimal. We present a proof-of-concept implementation,\nand demonstrate how tailoring for heterogeneous scenarios can save resources\nand latency.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 20:16:34 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 22:40:14 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Sheff", "Isaac", ""], ["Wang", "Xinwen", ""], ["van Renesse", "Robbert", ""], ["Myers", "Andrew C.", ""]]}, {"id": "2011.08296", "submitter": "Szabolcs Tengely", "authors": "Kriszti\\'an Dsupin and Szabolcs Tengely", "title": "Discrete logarithm problem in some families of sandpile groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Biggs proposed the sandpile group of certain modified wheel graphs for\ncryptosystems relying on the difficulty of the discrete logarithm problem.\nBlackburn and independently Shokrieh showed that the discrete logarithm problem\nis efficiently solvable. We study Shokrieh's method in cases of graphs such\nthat the sandpile group is not cyclic, namely the square cycle graphs and the\nwheel graphs. Knowing generators of the group or the form of the pseudoinverse\nof the Laplacian matrix makes the problem more vulnerable. We also consider the\ndiscrete logarithm problem in case of the so-called subdivided banana graphs.\nIn certain cases the sandpile group is cyclic and a generator is known and one\ncan solve the discrete logarithm problem without computing the pseudoinverse of\nthe Laplacian matrix.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 21:42:38 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Dsupin", "Kriszti\u00e1n", ""], ["Tengely", "Szabolcs", ""]]}, {"id": "2011.08315", "submitter": "Omid Hajihassani", "authors": "Omid Hajihassani, Omid Ardakanian, Hamzeh Khazaei", "title": "Privacy-preserving Data Analysis through Representation Learning and\n  Transformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The abundance of data from the sensors embedded in mobile and Internet of\nThings (IoT) devices and the remarkable success of deep neural networks in\nuncovering hidden patterns in time series data have led to mounting privacy\nconcerns in recent years. In this paper, we aim to navigate the trade-off\nbetween data utility and privacy by learning low-dimensional representations\nthat are useful for data anonymization. We propose probabilistic\ntransformations in the latent space of a variational autoencoder to synthesize\ntime series data such that intrusive inferences are prevented while desired\ninferences can still be made with a satisfactory level of accuracy. We compare\nour technique with state-of-the-art autoencoder-based anonymization techniques\nand additionally show that it can anonymize data in real time on\nresource-constrained edge devices.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 22:32:30 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Hajihassani", "Omid", ""], ["Ardakanian", "Omid", ""], ["Khazaei", "Hamzeh", ""]]}, {"id": "2011.08326", "submitter": "Jean-Christophe Deneuville", "authors": "Nicolas Aragon, Marco Baldi, Jean-Christophe Deneuville, Karan\n  Khathuria, Edoardo Persichetti, Paolo Santini", "title": "Cryptanalysis of a code-based full-time signature", "comments": "18 pages, to appear in DCC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an attack against a code-based signature scheme based on the\nLyubashevsky protocol that was recently proposed by Song, Huang, Mu, Wu and\nWang (SHMWW). The private key in the SHMWW scheme contains columns coming in\npart from an identity matrix and in part from a random matrix. The existence of\ntwo types of columns leads to a strong bias in the distribution of set bits in\nproduced signatures. Our attack exploits such a bias to recover the private key\nfrom a bunch of collected signatures. We provide a theoretical analysis of the\nattack along with experimental evaluations, and we show that as few as 10\nsignatures are enough to be collected for successfully recovering the private\nkey. As for previous attempts of adapting Lyubashevsky's protocol to the case\nof code-based cryptography, the SHMWW scheme is thus proved unable to provide\nacceptable security. This confirms that devising secure code-based signature\nschemes with efficiency comparable to that of other post-quantum solutions\n(e.g., based on lattices) is still a challenging task.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 22:58:42 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 08:29:37 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Aragon", "Nicolas", ""], ["Baldi", "Marco", ""], ["Deneuville", "Jean-Christophe", ""], ["Khathuria", "Karan", ""], ["Persichetti", "Edoardo", ""], ["Santini", "Paolo", ""]]}, {"id": "2011.08420", "submitter": "Kaiwen Shen", "authors": "Kaiwen Shen, Chuhan Wang, Minglei Guo, Xiaofeng Zheng, Chaoyi Lu,\n  Baojun Liu, Yuxuan Zhao, Shuang Hao, Haixin Duan, Qingfeng Pan and Min Yang", "title": "Weak Links in Authentication Chains: A Large-scale Analysis of Email\n  Sender Spoofing Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a fundamental communicative service, email is playing an important role in\nboth individual and corporate communications, which also makes it one of the\nmost frequently attack vectors. An email's authenticity is based on an\nauthentication chain involving multiple protocols, roles and services, the\ninconsistency among which creates security threats. Thus, it depends on the\nweakest link of the chain, as any failed part can break the whole chain-based\ndefense. This paper systematically analyzes the transmission of an email and\nidentifies a series of new attacks capable of bypassing SPF, DKIM, DMARC and\nuser-interface protections. In particular, by conducting a \"cocktail\" joint\nattack, more realistic emails can be forged to penetrate the celebrated email\nservices, such as Gmail and Outlook. We conduct a large-scale experiment on 30\npopular email services and 23 email clients, and find that all of them are\nvulnerable to certain types of new attacks. We have duly reported the\nidentified vulnerabilities to the related email service providers, and received\npositive responses from 11 of them, including Gmail, Yahoo, iCloud and Alibaba.\nFurthermore, we propose key mitigating measures to defend against the new\nattacks. Therefore, this work is of great value for identifying email spoofing\nattacks and improving the email ecosystem's overall security.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 04:56:02 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Shen", "Kaiwen", ""], ["Wang", "Chuhan", ""], ["Guo", "Minglei", ""], ["Zheng", "Xiaofeng", ""], ["Lu", "Chaoyi", ""], ["Liu", "Baojun", ""], ["Zhao", "Yuxuan", ""], ["Hao", "Shuang", ""], ["Duan", "Haixin", ""], ["Pan", "Qingfeng", ""], ["Yang", "Min", ""]]}, {"id": "2011.08449", "submitter": "Yueyue Dai", "authors": "Yueyue Dai, Du Xu, Ke Zhang, Sabita Maharjan (Senior Member, IEEE) and\n  Yan Zhang (Fellow, IEEE)", "title": "Deep Reinforcement Learning and Permissioned Blockchain for Content\n  Caching in Vehicular Edge Computing and Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Vehicular Edge Computing (VEC) is a promising paradigm to enable huge amount\nof data and multimedia content to be cached in proximity to vehicles. However,\nhigh mobility of vehicles and dynamic wireless channel condition make it\nchallenge to design an optimal content caching policy. Further, with much\nsensitive personal information, vehicles may be not willing to caching their\ncontents to an untrusted caching provider. Deep Reinforcement Learning (DRL) is\nan emerging technique to solve the problem with high-dimensional and\ntime-varying features. Permission blockchain is able to establish a secure and\ndecentralized peer-to-peer transaction environment. In this paper, we integrate\nDRL and permissioned blockchain into vehicular networks for intelligent and\nsecure content caching. We first propose a blockchain empowered distributed\ncontent caching framework where vehicles perform content caching and base\nstations maintain the permissioned blockchain. Then, we exploit the advanced\nDRL approach to design an optimal content caching scheme with taking mobility\ninto account. Finally, we propose a new block verifier selection method,\nProof-of-Utility (PoU), to accelerate block verification process. Security\nanalysis shows that our proposed blockchain empowered content caching can\nachieve security and privacy protection. Numerical results based on a real\ndataset from Uber indicate that the DRL-inspired content caching scheme\nsignificantly outperforms two benchmark policies.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 06:04:21 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 15:24:06 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Dai", "Yueyue", "", "Senior Member, IEEE"], ["Xu", "Du", "", "Senior Member, IEEE"], ["Zhang", "Ke", "", "Senior Member, IEEE"], ["Maharjan", "Sabita", "", "Senior Member, IEEE"], ["Zhang", "Yan", "", "Fellow, IEEE"]]}, {"id": "2011.08456", "submitter": "Partha Sarathi Roy", "authors": "Priyanka Dutta and Willy Susilo and Dung Hoang Duong and Partha\n  Sarathi Roy", "title": "Collusion-Resistant Identity-based Proxy Re-Encryption: Lattice-based\n  Constructions in Standard Model", "comments": "arXiv admin note: substantial text overlap with arXiv:2005.06741", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of proxy re-encryption (PRE) dates back to the work of Blaze,\nBleumer, and Strauss in 1998. PRE offers delegation of decryption rights, i.e.,\nit securely enables the re-encryption of ciphertexts from one key to another,\nwithout relying on trusted parties. PRE allows a semi-trusted third party\ntermed as a ``proxy\" to securely divert encrypted files of user A (delegator)\nto user B (delegatee) without revealing any information about the underlying\nfiles to the proxy. To eliminate the necessity of having a costly certificate\nverification process, Green and Ateniese introduced an identity-based PRE\n(IB-PRE). The potential applicability of IB-PRE sprung up a long line of\nintensive research from its first instantiation. Unfortunately, till today,\nthere is no collusion-Resistant unidirectional IB-PRE secure in the standard\nmodel, which can withstand quantum attack. In this paper, we present the first\nconcrete constructions of collusion-Resistant unidirectional IB-PRE, for both\nselective and adaptive identity, which are secure in standard model based on\nthe hardness of learning with error problem.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 05:45:36 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Dutta", "Priyanka", ""], ["Susilo", "Willy", ""], ["Duong", "Dung Hoang", ""], ["Roy", "Partha Sarathi", ""]]}, {"id": "2011.08536", "submitter": "Christiane Kuhn", "authors": "Christiane Kuhn, Friederike Kitzing, Thorsten Strufe", "title": "SoK on Performance Bounds in Anonymous Communication", "comments": null, "journal-ref": "WPES'20: Proceedings of the 19th Workshop on Privacy in the\n  Electronic Society. 2020", "doi": "10.1145/3411497.3420218", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communicating anonymously comes at a cost - and large communities have been\nin a constant tug-of-war between the development of faster protocols, and the\nimprovement of security analyses. Thereby more intricate privacy goals emerged\nand more detailed bounds on the minimum overhead necessary to achieve them were\nproven. The entanglement of requirements, scenarios, and protocols complicates\nanalysis, and the published results are hardly comparable, due to deviating,\nyet specific choices of assumptions and goals (some explicit, most implicit).\nIn this paper, we systematize the field by harmonizing the models, comparing\nthe proven performance bounds, and contextualizing these theoretical results in\na broad set of proposed and implemented systems. By identifying inaccuracies,\nwe demonstrate that the attacks, on which the results are based, indeed break\nmuch weaker privacy goals than postulated, and tighten the bounds along the\nway. We further show the equivalence of two seemingly alternative bounds.\nFinally, we argue how several assumptions and requirements of the papers likely\nare of limited applicability in reality and suggest relaxations for future\nwork.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 10:05:55 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Kuhn", "Christiane", ""], ["Kitzing", "Friederike", ""], ["Strufe", "Thorsten", ""]]}, {"id": "2011.08538", "submitter": "Faheem Zafar", "authors": "Faheem Zafar, Abid Khan, Saif Ur Rehman Malik, Adeel Anjum, Mansoor\n  Ahmed", "title": "MobChain: Three-Way Collusion Resistance in Witness-Oriented Location\n  Proof Systems Using Distributed Consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Smart devices have accentuated the importance of geolocation information.\nGeolocation identification using smart devices has paved the path for\nincentive-based location-based services (LBS). A location proof is a digital\ncertificate of the geographical location of a user, which can be used to access\nvarious LBS. However, a user full control over a device allows the tampering of\nlocation proof. Initially, to resist false proofs, two-party trusted\ncentralized location proof systems (LPS) were introduced to aid the users in\ngenerating secure location proofs mutually. However, two-party protocols\nsuffered from the collusion attacks by the participants of the protocol.\nConsequently, many witness-oriented LPS have emerged to mitigate collusion\nattacks in two-party protocols. However, witness-oriented LPS presented the\npossibility of three-way collusion attacks (involving the user, location\nauthority, and the witness). The three-way collusion attacks are inevitable in\nall existing witness-oriented schemes. To mitigate the inability to resist\nthree-way collusion of existing schemes, in this paper, we introduce a\ndecentralized consensus protocol called as MobChain, where the selection of a\nwitness and location authority is achieved through a distributed consensus of\nnodes in an underlying P2P network of a private blockchain. The persistent\nprovenance data over the blockchain provides strong security guarantees, as a\nresult, the forging and manipulation become impractical. MobChain provides\nsecure location provenance architecture, relying on decentralized decision\nmaking for the selection of participants of the protocol to resist three-way\ncollusion problem. Our prototype implementation and comparison with the\nstate-of-the-art solutions show that MobChain is computationally efficient,\nhighly available while improving the security of LPS.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 10:12:59 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Zafar", "Faheem", ""], ["Khan", "Abid", ""], ["Malik", "Saif Ur Rehman", ""], ["Anjum", "Adeel", ""], ["Ahmed", "Mansoor", ""]]}, {"id": "2011.08579", "submitter": "Burak Hasircioglu", "authors": "Burak Hasircioglu, Deniz Gunduz", "title": "Private Wireless Federated Learning with Anonymous Over-the-Air\n  Computation", "comments": "To appear in IEEE International Conference on Acoustics, Speech and\n  Signal Processing (ICASSP) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In conventional federated learning (FL), differential privacy (DP) guarantees\ncan be obtained by injecting additional noise to local model updates before\ntransmitting to the parameter server (PS). In the wireless FL scenario, we show\nthat the privacy of the system can be boosted by exploiting over-the-air\ncomputation (OAC) and anonymizing the transmitting devices. In OAC, devices\ntransmit their model updates simultaneously and in an uncoded fashion,\nresulting in a much more efficient use of the available spectrum. We further\nexploit OAC to provide anonymity for the transmitting devices. The proposed\napproach improves the performance of private wireless FL by reducing the amount\nof noise that must be injected.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 11:53:58 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 21:37:31 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Hasircioglu", "Burak", ""], ["Gunduz", "Deniz", ""]]}, {"id": "2011.08598", "submitter": "Andrei Costin", "authors": "Tuomo Lahtinen and Lauri Sintonen and Hannu Turtiainen and Andrei\n  Costin", "title": "Feasibility Study on CCTV-aware Routing and Navigation for Privacy,\n  Anonymity, and Safety. Jyvaskyla -- Case-study of the First City to Benefit\n  from CCTV-aware Technology. (Preprint)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In order to withstand the ever-increasing invasion of privacy by CCTV cameras\nand technologies, on par CCTV-aware solutions must exist that provide privacy,\nsafety, and cybersecurity features. We argue that a first important step\ntowards such CCTV-aware solutions must be a mapping system that provides both\nprivacy and safety routing and navigation options. To the best of our\nknowledge, there are no mapping nor navigation systems that support privacy and\nsafety routing options. In this paper, we explore the feasibility of a\nCCTV-aware routing and navigation solution. The aim of this feasibility\nexploration is to understand what are the main impacts of CCTV on privacy, and\nwhat are the challenges and benefits to building such technology. We evaluate\nour approach on seven (7) pedestrian walking routes within the downtown area of\nthe city of Jyvaskyla, Finland. We first map a total of 450 CCTV cameras, and\nthen experiment with routing and navigation under several different\nconfigurations to coarsely model the possible cameras' parameters and coverage\nfrom the real-world. We report two main results. First, our preliminary\nfindings support the overall feasibility of our approach. Second, the results\nalso reveal a data-driven worrying reality for persons wishing to preserve\ntheir privacy/anonymity as their main living choice. When modelling cameras at\ntheir low performance end, a privacy-preserving route has on average a 1.5x\ndistance increase when compared to generic routing. When modelling cameras at\ntheir medium-to-high performance end, a privacy-preserving route has on average\na 5.0x distance increase, while in some cases there are no privacy-preserving\nroutes possible at all. These results further support and encourage both global\nmapping of CCTV cameras and refinements to camera modelling and underlying\ntechnology.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 12:45:40 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Lahtinen", "Tuomo", ""], ["Sintonen", "Lauri", ""], ["Turtiainen", "Hannu", ""], ["Costin", "Andrei", ""]]}, {"id": "2011.08648", "submitter": "Jing Yang", "authors": "Jing Yang, Fang-Wei Fu", "title": "New (k,l,m)-verifiable multi-secret sharing schemes based on XTR public\n  key system", "comments": "11 pages, 1 figure, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Secret sharing was proposed primarily in 1979 to solve the problem of key\ndistribution. In recent decades, researchers have proposed many improvement\nschemes. Among all these schemes, the verifiable multi-secret sharing (VMSS)\nschemes are studied sufficiently, which share multiple secrets simultaneously\nand perceive malicious dealer as well as participants. By pointing out that the\nschemes presented by Dehkordi and Mashhadi in 2008 cannot detect some vicious\nbehaviors of the dealer, we propose two new VMSS schemes by adding validity\ncheck in the verification phase to overcome this drawback. Our new schemes are\nbased on XTR public key system, and can realize $GF(p^{6})$ security by\ncomputations in $GF(p^{2})$ without explicit constructions of $GF(p^{6})$,\nwhere $p$ is a prime. Compared with the VMSS schemes using RSA and linear\nfeedback shift register (LFSR) public key cryptosystems, our schemes can\nachieve the same security level with shorter parameters by using trace\nfunction. What's more, our schemes are much simpler to operate than those\nschemes based on Elliptic Curve Cryptography (ECC). In addition, our schemes\nare dynamic and threshold changeable, which means that it is efficient to\nimplement our schemes according to the actual situation when participants,\nsecrets or the threshold needs to be changed.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 14:15:20 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Yang", "Jing", ""], ["Fu", "Fang-Wei", ""]]}, {"id": "2011.08738", "submitter": "David Saranchak", "authors": "Daniel L. Felps, Amelia D. Schwickerath, Joyce D. Williams, Trung N.\n  Vuong, Alan Briggs, Matthew Hunt, Evan Sakmar, David D. Saranchak, Tyler\n  Shumaker", "title": "Bootstrap Aggregation for Point-based Generalized Membership Inference\n  Attacks", "comments": "8 pages, 6 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An efficient scheme is introduced that extends the generalized membership\ninference attack to every point in a model's training data set. Our approach\nleverages data partitioning to create variable sized training sets for the\nreference models. We then train an attack model for every single training\nexample for a reference model configuration based upon output for each\nindividual point. This allows us to quantify the membership inference attack\nvulnerability of each training data point. Using this approach, we discovered\nthat smaller amounts of reference model training data led to a stronger attack.\nFurthermore, the reference models do not need to be of the same architecture as\nthe target model, providing additional attack efficiencies. The attack may also\nbe performed by an adversary even when they do not have the complete original\ndata set.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 16:16:18 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Felps", "Daniel L.", ""], ["Schwickerath", "Amelia D.", ""], ["Williams", "Joyce D.", ""], ["Vuong", "Trung N.", ""], ["Briggs", "Alan", ""], ["Hunt", "Matthew", ""], ["Sakmar", "Evan", ""], ["Saranchak", "David D.", ""], ["Shumaker", "Tyler", ""]]}, {"id": "2011.08742", "submitter": "Ra\\'ul Pardo", "authors": "Ra\\'ul Pardo, Willard Rafnsson, Christian Probst, Andrzej W\\k{a}sowski", "title": "Privug: Quantifying Leakage using Probabilistic Programming for Privacy\n  Risk Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disclosure of data analytics results has important scientific and commercial\njustifications. However, no data shall be disclosed without a diligent\ninvestigation of risks for privacy of subjects. Privug is a tool-supported\nmethod to explore information leakage properties of data analytics and\nanonymization programs. In Privug, we reinterpret a program probabilistically,\nusing off-the-shelf tools for Bayesian inference to perform\ninformation-theoretic analysis of the information flow. For privacy\nresearchers, Privug provides a fast, lightweight way to experiment with privacy\nprotection measures and mechanisms. We show that Privug is accurate, scalable,\nand applicable to a range of leakage analysis scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 16:19:43 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 17:40:32 GMT"}, {"version": "v3", "created": "Sun, 4 Apr 2021 13:37:46 GMT"}, {"version": "v4", "created": "Sat, 15 May 2021 16:34:25 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Pardo", "Ra\u00fal", ""], ["Rafnsson", "Willard", ""], ["Probst", "Christian", ""], ["W\u0105sowski", "Andrzej", ""]]}, {"id": "2011.08846", "submitter": "Md Sadek Ferdous", "authors": "Md. Saiful Islam Bhuiyan, Abdur Razzak, Md Sadek Ferdous, Mohammad\n  Jabed M. Chowdhury, Mohammad A. Hoque, Sasu Tarkoma", "title": "BONIK: A Blockchain Empowered Chatbot for Financial Transactions", "comments": "Accepted at the 19th IEEE International Conference on Trust, Security\n  and Privacy in Computing and Communications (TrustCom 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Chatbot is a popular platform to enable users to interact with a software\nor website to gather information or execute actions in an automated fashion. In\nrecent years, chatbots are being used for executing financial transactions,\nhowever, there are a number of security issues, such as secure authentication,\ndata integrity, system availability and transparency, that must be carefully\nhandled for their wide-scale adoption. Recently, the blockchain technology,\nwith a number of security advantages, has emerged as one of the foundational\ntechnologies with the potential to disrupt a number of application domains,\nparticularly in the financial sector. In this paper, we forward the idea of\nintegrating a chatbot with blockchain technology in the view to improve the\nsecurity issues in financial chatbots. More specifically, we present BONIK, a\nblockchain empowered chatbot for financial transactions, and discuss its\narchitecture and design choices. Furthermore, we explore the developed\nProof-of-Concept (PoC), evaluate its performance, analyse how different\nsecurity and privacy issues are mitigated using BONIK.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 07:51:52 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Bhuiyan", "Md. Saiful Islam", ""], ["Razzak", "Abdur", ""], ["Ferdous", "Md Sadek", ""], ["Chowdhury", "Mohammad Jabed M.", ""], ["Hoque", "Mohammad A.", ""], ["Tarkoma", "Sasu", ""]]}, {"id": "2011.08908", "submitter": "Thai Le", "authors": "Thai Le, Noseong Park, Dongwon Lee", "title": "SIENA: Stochastic Multi-Expert Neural Patcher", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network (NN) models that are solely trained to maximize the likelihood\nof an observed dataset are often vulnerable to adversarial attacks. Even though\nseveral methods have been proposed to enhance NN models' adversarial\nrobustness, they often require re-training from scratch. This leads to\nredundant computation, especially in the NLP domain where current\nstate-of-the-art models, such as BERT and ROBERTA, require great time and space\nresources. By borrowing ideas from Software Engineering, we, therefore, first\nintroduce the Neural Patching mechanism to improve adversarial robustness by\n\"patching\" only parts of a NN model. Then, we propose a novel neural patching\nalgorithm, SIENA, that transforms a textual NN model into a stochastic ensemble\nof multi-expert predictors by upgrading and re-training its last layer only.\nSIENA forces adversaries to attack not only one but multiple models that are\nspecialized in diverse sub-sets of features, labels, and instances so that the\nensemble model becomes more robust to adversarial attacks. By conducting\ncomprehensive experiments, we demonstrate that all of CNN, RNN, BERT, and\nROBERTA-based textual models, once patched by SIENA, witness an absolute\nincrease of as much as 20% in accuracy on average under 5 different white and\nblack-box attacks, outperforming 6 defensive baselines across 4 public NLP\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 19:58:03 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Le", "Thai", ""], ["Park", "Noseong", ""], ["Lee", "Dongwon", ""]]}, {"id": "2011.08936", "submitter": "Ramyad Hadidi", "authors": "Nima Shoghi Ghalehshahi, Ramyad Hadidi, Lee Jaewon, Jun Chen, Arthur\n  Siqueria, Rahul Rajan, Shaan Dhawan, Pooya Shoghi Ghalehshahi, Hyesoon Kim", "title": "Secure Location-Aware Authentication and Communication for Intelligent\n  Transportation Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent transportation systems (ITS) are expected to effectively create a\nstand-alone network for secure communication among autonomous agents. In such a\ndynamic and fast-changing network with high-speed agents, verifying the\nauthenticity and integrity of messages while taking preventive action (e.g.,\napplying brakes) within tens of milliseconds is one of the main challenges. In\nsuch a brief moment after receiving a message, the agent not only must verify\nthe integrity and authenticity of the received message but also needs to\nperform extra computations to localize the sender of the message for taking\nappropriate action (e.g., an immediate stop warning from a vehicle in front vs.\nrear). In this paper, we present an inherently location-aware and lightweight\nauthentication protocol by exploiting in situ visual localization (i.e., SLAM).\nIn this protocol, each agent displays its public key using visual\nauthentication beacons (e.g., QR codes). Thus, receiving agents not only can\nverify and authenticate the messages but also can easily localize the sender by\nkeeping a shortlist of observed visual beacons within their visual localization\nsystem with no additional computation cost. Compared to prior work, our\nlocation-aware protocol is scalable, does not depend on any infrastructure,\nremoves the high cost of post-message-delivery localization, and provides\ntrustworthiness guarantees for information that are beyond the reach of each\nagent sensors.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 20:44:52 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Ghalehshahi", "Nima Shoghi", ""], ["Hadidi", "Ramyad", ""], ["Jaewon", "Lee", ""], ["Chen", "Jun", ""], ["Siqueria", "Arthur", ""], ["Rajan", "Rahul", ""], ["Dhawan", "Shaan", ""], ["Ghalehshahi", "Pooya Shoghi", ""], ["Kim", "Hyesoon", ""]]}, {"id": "2011.08960", "submitter": "Ruixiang Tang", "authors": "Ruixiang Tang, Mengnan Du, Xia Hu", "title": "Deep Serial Number: Computational Watermarking for DNN Intellectual\n  Property Protection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce DSN (Deep Serial Number), a new watermarking\napproach that can prevent the stolen model from being deployed by unauthorized\nparties. Recently, watermarking in DNNs has emerged as a new research direction\nfor owners to claim ownership of DNN models. However, the verification schemes\nof existing watermarking approaches are vulnerable to various watermark\nattacks. Different from existing work that embeds identification information\ninto DNNs, we explore a new DNN Intellectual Property Protection mechanism that\ncan prevent adversaries from deploying the stolen deep neural networks.\nMotivated by the success of serial number in protecting conventional software\nIP, we introduce the first attempt to embed a serial number into DNNs.\nSpecifically, the proposed DSN is implemented in the knowledge distillation\nframework, where a private teacher DNN is first trained, then its knowledge is\ndistilled and transferred to a series of customized student DNNs. During the\ndistillation process, each customer DNN is augmented with a unique serial\nnumber, i.e., an encrypted 0/1 bit trigger pattern. Customer DNN works properly\nonly when a potential customer enters the valid serial number. The embedded\nserial number could be used as a strong watermark for ownership verification.\nExperiments on various applications indicate that DSN is effective in terms of\npreventing unauthorized application while not sacrificing the original DNN\nperformance. The experimental analysis further shows that DSN is resistant to\ndifferent categories of attacks.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 21:42:40 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Tang", "Ruixiang", ""], ["Du", "Mengnan", ""], ["Hu", "Xia", ""]]}, {"id": "2011.08969", "submitter": "Shoko Imaizumi", "authors": "Shoko Imaizumi, Yusuke Izawa, Ryoichi Hirasawa, and Hitoshi Kiya", "title": "A Reversible Data Hiding Method in Compressible Encrypted Images", "comments": "10 pages", "journal-ref": null, "doi": "10.1587/transfun.2020SMP0029", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a reversible data hiding (RDH) method in compressible encrypted\nimages called the encryption-then-compression (EtC) images. The proposed method\nallows us to not only embed a payload in encrypted images but also compress the\nencrypted images containing the payload. In addition, the proposed RDH method\ncan be applied to both plain images and encrypted ones, and the payload can be\nextracted flexibly in the encrypted domain or from the decrypted images.\nVarious RDH methods have been studied in the encrypted domain, but they are not\nconsidered to be two-domain data hiding, and the resultant images cannot be\ncompressed by using image coding standards, such as JPEG-LS and JPEG 2000. In\nour experiment, the proposed method shows high performance in terms of lossless\ncompression efficiency by using JPEG-LS and JPEG 2000, data hiding capacity,\nand marked image quality.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 22:10:33 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Imaizumi", "Shoko", ""], ["Izawa", "Yusuke", ""], ["Hirasawa", "Ryoichi", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "2011.09107", "submitter": "Levente Csikor PhD", "authors": "Levente Csikor, Vipul Ujawane, Dinil Mon Divakaran", "title": "On the Feasibility and Enhancement of the Tuple Space Explosion Attack\n  against Open vSwitch", "comments": "13 pages + bios in IEEE two-column journal style Submitted only to\n  arXiv!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Being a crucial part of networked systems, packet classification has to be\nhighly efficient; however, software switches in cloud environments still face\nperformance challenges. The recently proposed Tuple Space Explosion (TSE)\nattack exploits an algorithmic deficiency in Open vSwitch (OVS). In TSE,\nlegitimate low-rate attack traffic makes the cardinal linear search algorithm\nin the Tuple Space Search (TSS) algorithm to spend an unaffordable time for\nclassifying each packet resulting in a denial-of-service (DoS) for the rest of\nthe users. In this paper, we investigate the feasibility of TSE from multiple\nperspectives. Besides showing that TSE is still efficient in the newer version\nof OVS, we show that when the kernel datapath is compiled from a different\nsource, it can degrade its performance to ~1% of its baseline with less than 1\nMbps attack rate. Finally, we show that TSE is much less effective against\nOVS-DPDK with userspace datapath due to the enhanced ranking process in its TSS\nimplementation. Therefore, we propose TSE 2.0 to defeat the ranking process and\nachieve a complete DoS against OVS-DPDK. Furthermore, we present TSE 2.1, which\nachieves the same goal against OVS-DPDK running on multiple cores without\nsignificantly increasing the attack rate.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 06:13:08 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Csikor", "Levente", ""], ["Ujawane", "Vipul", ""], ["Divakaran", "Dinil Mon", ""]]}, {"id": "2011.09121", "submitter": "Mahdi Miraz", "authors": "Mahdi H. Miraz and Maaruf Ali", "title": "Integration of Blockchain and IoT: An Enhanced Security Perspective", "comments": "arXiv admin note: substantial text overlap with arXiv:1806.05242", "journal-ref": "Annals of Emerging Technologies in Computing (AETiC), Print ISSN:\n  2516-0281, Online ISSN: 2516-029X, pp. 52-63, Vol. 4, No. 4, 1st October\n  2020, Available: http://aetic.theiaer.org/archive/v4/v4n4/p6.html", "doi": "10.33166/AETiC.2020.04.006", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain (BC), a by-product of Bitcoin cryptocurrency, has gained immense\nand wide scale popularity for its applicability in various diverse domains -\nespecially in multifaceted non-monetary systems. By adopting cryptographic\ntechniques such as hashing and asymmetric encryption - along with distributed\nconsensus approach, a Blockchain based distributed ledger not only becomes\nhighly secure but also immutable and thus eliminates the need for any\nthird-party intermediators. On the contrary, innumerable IoT (Internet of\nThings) devices are increasingly being added to the network. This phenomenon\nposes higher risk in terms of security and privacy. It is thus extremely\nimportant to address the security aspects of the growing IoT ecosystem. This\npaper explores the applicability of BC for ensuring enhanced security and\nprivacy in the IoT ecosystem. Recent research articles and projects or\napplications were surveyed to assess the implementation of BC for IoT Security\nand identify associated challenges and propose solutions for BC enabled\nenhanced security for the IoT ecosystem.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 13:42:35 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Miraz", "Mahdi H.", ""], ["Ali", "Maaruf", ""]]}, {"id": "2011.09218", "submitter": "Stefano Bennati", "authors": "Stefano Bennati and Aleksandra Kovacevic", "title": "Privacy metrics for trajectory data based on k-anonymity, l-diversity\n  and t-closeness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobility patterns of vehicles and people provide powerful data sources for\nlocation-based services such as fleet optimization and traffic flow analysis.\nThese data, in particular pick-up/origin and drop-off/destination of vehicles,\ncarry high privacy risk due to the semantic context spatial-temporal data\nencompass. Therefore, location-based service providers must balance the value\nthey extract from trajectory data (utility), with protecting the privacy of the\nindividuals behind those trajectories. In order to optimize this trade-off,\nprivacy risks must be measured. Existing privacy measures for non-sequential\ndata are not suitable for trajectory data and this paper provides an answer to\nthis issue. We introduce a model of an adversary with imperfect knowledge that\nis based on the concept of equivalence classes. We then adapt standard privacy\nmeasures, i.e. k-anonymity, l-diversity and t-closeness to the peculiarities of\ntrajectory data. Our approach to measuring trajectory privacy provides a\ngeneral measure, independent of whether and what anonymization has been\napplied, which can be used to intuitively compare privacy of different\ndatasets. This work is of high relevance to all service providers acting as\nprocessors of trajectory data who want to manage privacy risks and optimize the\nprivacy vs. utility trade-off of their services.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 11:25:59 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 10:20:25 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Bennati", "Stefano", ""], ["Kovacevic", "Aleksandra", ""]]}, {"id": "2011.09260", "submitter": "Pavlos Papadopoulos", "authors": "Charalampos Stamatellis, Pavlos Papadopoulos, Nikolaos Pitropakis,\n  Sokratis Katsikas, William J Buchanan", "title": "A Privacy-Preserving Healthcare Framework Using Hyperledger Fabric", "comments": "MDPI Sensors (This article belongs to the Special Issue Security,\n  Trust and Privacy in New Computing Environments) URL:\n  https://www.mdpi.com/1424-8220/20/22/6587", "journal-ref": "Sensors 2020, 20(22), 6587", "doi": "10.3390/s20226587", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Electronic health record (EHR) management systems require the adoption of\neffective technologies when health information is being exchanged. Current\nmanagement approaches often face risks that may expose medical record storage\nsolutions to common security attack vectors. However, healthcare-oriented\nblockchain solutions can provide a decentralized, anonymous and secure EHR\nhandling approach. This paper presents PREHEALTH, a privacy-preserving EHR\nmanagement solution that uses distributed ledger technology and an Identity\nMixer (Idemix). The paper describes a proof-of-concept implementation that uses\nthe Hyperledger Fabric's permissioned blockchain framework. The proposed\nsolution is able to store patient records effectively whilst providing\nanonymity and unlinkability. Experimental performance evaluation results\ndemonstrate the scheme's efficiency and feasibility for real-world scale\ndeployment.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 13:15:55 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 10:04:11 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Stamatellis", "Charalampos", ""], ["Papadopoulos", "Pavlos", ""], ["Pitropakis", "Nikolaos", ""], ["Katsikas", "Sokratis", ""], ["Buchanan", "William J", ""]]}, {"id": "2011.09269", "submitter": "Alexey Vishnyakov", "authors": "Alexey Vishnyakov and Andrey Fedotov and Daniil Kuts and Alexander\n  Novikov and Darya Parygina and Eli Kobrin and Vlada Logunova and Pavel\n  Belecky and Shamil Kurmangaleev", "title": "Sydr: Cutting Edge Dynamic Symbolic Execution", "comments": "9 pages", "journal-ref": "2020 Ivannikov ISPRAS Open Conference (ISPRAS), IEEE, 2020, pp.\n  46-54", "doi": "10.1109/ISPRAS51486.2020.00014", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The security development lifecycle (SDL) is becoming an industry standard.\nDynamic symbolic execution (DSE) has enormous amount of applications in\ncomputer security (fuzzing, vulnerability discovery, reverse-engineering,\netc.). We propose several performance and accuracy improvements for dynamic\nsymbolic execution. Skipping non-symbolic instructions allows to build a path\npredicate 1.2--3.5 times faster. Symbolic engine simplifies formulas during\nsymbolic execution. Path predicate slicing eliminates irrelevant conjuncts from\nsolver queries. We handle each jump table (switch statement) as multiple\nbranches and describe the method for symbolic execution of multi-threaded\nprograms. The proposed solutions were implemented in Sydr tool. Sydr performs\ninversion of branches in path predicate. Sydr combines DynamoRIO dynamic binary\ninstrumentation tool with Triton symbolic engine. We evaluated Sydr features on\n64-bit Linux executables.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 13:32:54 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 11:14:12 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Vishnyakov", "Alexey", ""], ["Fedotov", "Andrey", ""], ["Kuts", "Daniil", ""], ["Novikov", "Alexander", ""], ["Parygina", "Darya", ""], ["Kobrin", "Eli", ""], ["Logunova", "Vlada", ""], ["Belecky", "Pavel", ""], ["Kurmangaleev", "Shamil", ""]]}, {"id": "2011.09285", "submitter": "Reza Fotohi", "authors": "Maryam Faraji-Biregani and Reza Fotohi", "title": "Secure communication between UAVs using a method based on smart agents\n  in unmanned aerial vehicles", "comments": "25 pages, 10 figures, 14 tables, JCR (Q2). J Supercomput (2020)", "journal-ref": null, "doi": "10.1007/s11227-020-03462-0", "report-no": null, "categories": "cs.CR cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicles (UAVs) can be deployed to monitor very large areas\nwithout the need for network infrastructure. UAVs communicate with each other\nduring flight and exchange information with each other. However, such\ncommunication poses security challenges due to its dynamic topology. To solve\nthese challenges, the proposed method uses two phases to counter malicious UAV\nattacks. In the first phase, we applied a number of rules and principles to\ndetect malicious UAVs. In this phase, we try to identify and remove malicious\nUAVs according to the behavior of UAVs in the network in order to prevent\nsending fake information to the investigating UAVs. In the second phase, a\nmobile agent based on a three-step negotiation process is used to eliminate\nmalicious UAVs. In this way, we use mobile agents to inform our normal neighbor\nUAVs so that they do not listen to the data generated by the malicious UAVs.\nTherefore, the mobile agent of each UAV uses reliable neighbors through a\nthree-step negotiation process so that they do not listen to the traffic\ngenerated by the malicious UAVs. The NS-3 simulator was used to demonstrate the\nefficiency of the SAUAV method. The proposed method is more efficient than\nCST-UAS, CS-AVN, HVCR, and BSUM-based methods in detection rate, false positive\nrate, false negative rate, packet delivery rate, and residual energy.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 10:33:39 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Faraji-Biregani", "Maryam", ""], ["Fotohi", "Reza", ""]]}, {"id": "2011.09290", "submitter": "Haiqin Weng", "authors": "Haiqin Weng, Juntao Zhang, Feng Xue, Tao Wei, Shouling Ji, Zhiyuan\n  Zong", "title": "Privacy Leakage of Real-World Vertical Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning enables mutually distrusting participants to\ncollaboratively learn a distributed machine learning model without revealing\nanything but the model's output. Generic federated learning has been studied\nextensively, and several learning protocols, as well as open-source frameworks,\nhave been developed. Yet, their over pursuit of computing efficiency and fast\nimplementation might diminish the security and privacy guarantees of\nparticipant's training data, about which little is known thus far.\n  In this paper, we consider an honest-but-curious adversary who participants\nin training a distributed ML model, does not deviate from the defined learning\nprotocol, but attempts to infer private training data from the legitimately\nreceived information. In this setting, we design and implement two practical\nattacks, reverse sum attack and reverse multiplication attack, neither of which\nwill affect the accuracy of the learned model. By empirically studying the\nprivacy leakage of two learning protocols, we show that our attacks are (1)\neffective - the adversary successfully steal the private training data, even\nwhen the intermediate outputs are encrypted to protect data privacy; (2)\nevasive - the adversary's malicious behavior does not deviate from the protocol\nspecification and deteriorate any accuracy of the target model; and (3) easy -\nthe adversary needs little prior knowledge about the data distribution of the\ntarget participant. We also experimentally show that the leaked information is\nas effective as the raw training data through training an alternative\nclassifier on the leaked information. We further discuss potential\ncountermeasures and their challenges, which we hope may lead to several\npromising research directions.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 14:02:04 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 07:42:52 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Weng", "Haiqin", ""], ["Zhang", "Juntao", ""], ["Xue", "Feng", ""], ["Wei", "Tao", ""], ["Ji", "Shouling", ""], ["Zong", "Zhiyuan", ""]]}, {"id": "2011.09350", "submitter": "Pavlos Papadopoulos", "authors": "Nick Angelou, Ayoub Benaissa, Bogdan Cebere, William Clark, Adam James\n  Hall, Michael A. Hoeh, Daniel Liu, Pavlos Papadopoulos, Robin Roehm, Robert\n  Sandmann, Phillipp Schoppmann, Tom Titcombe", "title": "Asymmetric Private Set Intersection with Applications to Contact Tracing\n  and Private Vertical Federated Machine Learning", "comments": "NeurIPS 2020 Workshop on Privacy Preserving Machine Learning (PPML\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a multi-language, cross-platform, open-source library for\nasymmetric private set intersection (PSI) and PSI-Cardinality (PSI-C). Our\nprotocol combines traditional DDH-based PSI and PSI-C protocols with\ncompression based on Bloom filters that helps reduce communication in the\nasymmetric setting. Currently, our library supports C++, C, Go, WebAssembly,\nJavaScript, Python, and Rust, and runs on both traditional hardware (x86) and\nbrowser targets. We further apply our library to two use cases: (i) a\nprivacy-preserving contact tracing protocol that is compatible with existing\napproaches, but improves their privacy guarantees, and (ii) privacy-preserving\nmachine learning on vertically partitioned data.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 15:38:59 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Angelou", "Nick", ""], ["Benaissa", "Ayoub", ""], ["Cebere", "Bogdan", ""], ["Clark", "William", ""], ["Hall", "Adam James", ""], ["Hoeh", "Michael A.", ""], ["Liu", "Daniel", ""], ["Papadopoulos", "Pavlos", ""], ["Roehm", "Robin", ""], ["Sandmann", "Robert", ""], ["Schoppmann", "Phillipp", ""], ["Titcombe", "Tom", ""]]}, {"id": "2011.09359", "submitter": "Nicolas Kourtellis Ph.D.", "authors": "Nicolas Kourtellis and Kleomenis Katevas and Diego Perino", "title": "FLaaS: Federated Learning as a Service", "comments": "7 pages, 4 figures, 7 subfigures, 34 references", "journal-ref": "In 1st Workshop on Distributed Machine Learning\n  (DistributedML'20), Dec. 1, 2020, Barcelona, Spain. ACM, New York, NY, USA, 7\n  pages", "doi": "10.1145/3426745.3431337", "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Federated Learning (FL) is emerging as a promising technology to build\nmachine learning models in a decentralized, privacy-preserving fashion. Indeed,\nFL enables local training on user devices, avoiding user data to be transferred\nto centralized servers, and can be enhanced with differential privacy\nmechanisms. Although FL has been recently deployed in real systems, the\npossibility of collaborative modeling across different 3rd-party applications\nhas not yet been explored. In this paper, we tackle this problem and present\nFederated Learning as a Service (FLaaS), a system enabling different scenarios\nof 3rd-party application collaborative model building and addressing the\nconsequent challenges of permission and privacy management, usability, and\nhierarchical model training. FLaaS can be deployed in different operational\nenvironments. As a proof of concept, we implement it on a mobile phone setting\nand discuss practical implications of results on simulated and real devices\nwith respect to on-device training CPU cost, memory footprint and power\nconsumed per FL model round. Therefore, we demonstrate FLaaS's feasibility in\nbuilding unique or joint FL models across applications for image object\ndetection in a few hours, across 100 devices.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 15:56:22 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Kourtellis", "Nicolas", ""], ["Katevas", "Kleomenis", ""], ["Perino", "Diego", ""]]}, {"id": "2011.09436", "submitter": "Gurcan Comert", "authors": "Gurcan Comert, Mashrur Chowdhury, David M. Nicol", "title": "Assessment of System-Level Cyber Attack Vulnerability for Connected and\n  Autonomous Vehicles Using Bayesian Networks", "comments": "21 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.SY eess.SY stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study presents a methodology to quantify vulnerability of cyber attacks\nand their impacts based on probabilistic graphical models for intelligent\ntransportation systems under connected and autonomous vehicles framework. Cyber\nattack vulnerabilities from various types and their impacts are calculated for\nintelligent signals and cooperative adaptive cruise control (CACC) applications\nbased on the selected performance measures. Numerical examples are given that\nshow impact of vulnerabilities in terms of average intersection queue lengths,\nnumber of stops, average speed, and delays. At a signalized network with and\nwithout redundant systems, vulnerability can increase average queues and delays\nby $3\\%$ and $15\\%$ and $4\\%$ and $17\\%$, respectively. For CACC application,\nimpact levels reach to $50\\%$ delay difference on average when low amount of\nspeed information is perturbed. When significantly different speed\ncharacteristics are inserted by an attacker, delay difference increases beyond\n$100\\%$ of normal traffic conditions.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 18:13:57 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Comert", "Gurcan", ""], ["Chowdhury", "Mashrur", ""], ["Nicol", "David M.", ""]]}, {"id": "2011.09480", "submitter": "Siddarth Koduru Joshi", "authors": "Zixin Huang, Siddarth Koduru Joshi, Djeylan Aktas, Cosmo Lupo, Armanda\n  O. Quintavalle, Natarajan Venkatachalam, S\\\"oren Wengerowsky, Martin\n  Lon\\v{c}ari\\'c, Sebastian Philipp Neumann, Bo Liu, \\v{Z}eljko Samec, Laurent\n  Kling, Mario Stip\\v{c}evi\\'c, Rupert Ursin, John G. Rarity", "title": "Experimental implementation of secure anonymous protocols on an\n  eight-user quantum network", "comments": "11 pages, 4 figures, 1 table, experimental work. ZH and SKJ\n  contributed equally to this work and are joint first authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anonymity in networked communication is vital for many privacy-preserving\ntasks. Secure key distribution alone is insufficient for high-security\ncommunications, often knowing who transmits a message to whom and when must\nalso be kept hidden from an adversary. Here we experimentally demonstrate 5\ninformation-theoretically secure anonymity protocols on an 8 user city-wide\nquantum network using polarisation-entangled photon pairs. At the heart of\nthese protocols is anonymous broadcasting, which is a cryptographic primitive\nthat allows one user to reveal one bit of information while keeping her\nidentity anonymous. For a network of $n$ users, the protocols retain anonymity\nfor the sender, given less than $n-2$ users are dishonest. This is one of the\nearliest implementations of genuine multi-user cryptographic protocols beyond\nstandard QKD. Our anonymous protocols enhance the functionality of any\nfully-connected Quantum Key Distribution network without trusted nodes.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 19:00:01 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Huang", "Zixin", ""], ["Joshi", "Siddarth Koduru", ""], ["Aktas", "Djeylan", ""], ["Lupo", "Cosmo", ""], ["Quintavalle", "Armanda O.", ""], ["Venkatachalam", "Natarajan", ""], ["Wengerowsky", "S\u00f6ren", ""], ["Lon\u010dari\u0107", "Martin", ""], ["Neumann", "Sebastian Philipp", ""], ["Liu", "Bo", ""], ["Samec", "\u017deljko", ""], ["Kling", "Laurent", ""], ["Stip\u010devi\u0107", "Mario", ""], ["Ursin", "Rupert", ""], ["Rarity", "John G.", ""]]}, {"id": "2011.09527", "submitter": "Liam Fowl", "authors": "Eitan Borgnia, Valeriia Cherepanova, Liam Fowl, Amin Ghiasi, Jonas\n  Geiping, Micah Goldblum, Tom Goldstein, Arjun Gupta", "title": "Strong Data Augmentation Sanitizes Poisoning and Backdoor Attacks\n  Without an Accuracy Tradeoff", "comments": "Authors ordered alphabetically", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data poisoning and backdoor attacks manipulate victim models by maliciously\nmodifying training data. In light of this growing threat, a recent survey of\nindustry professionals revealed heightened fear in the private sector regarding\ndata poisoning. Many previous defenses against poisoning either fail in the\nface of increasingly strong attacks, or they significantly degrade performance.\nHowever, we find that strong data augmentations, such as mixup and CutMix, can\nsignificantly diminish the threat of poisoning and backdoor attacks without\ntrading off performance. We further verify the effectiveness of this simple\ndefense against adaptive poisoning methods, and we compare to baselines\nincluding the popular differentially private SGD (DP-SGD) defense. In the\ncontext of backdoors, CutMix greatly mitigates the attack while simultaneously\nincreasing validation accuracy by 9%.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 20:18:50 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Borgnia", "Eitan", ""], ["Cherepanova", "Valeriia", ""], ["Fowl", "Liam", ""], ["Ghiasi", "Amin", ""], ["Geiping", "Jonas", ""], ["Goldblum", "Micah", ""], ["Goldstein", "Tom", ""], ["Gupta", "Arjun", ""]]}, {"id": "2011.09642", "submitter": "Sankha Dutta", "authors": "Sankha Baran Dutta, Hoda Naghibijouybari, Nael Abu-Ghazaleh, Andres\n  Marquez, and Kevin Barker", "title": "Leaky Buddies: Cross-Component Covert Channels on Integrated CPU-GPU\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphics Processing Units (GPUs) are a ubiquitous component across the range\nof today's computing platforms, from phones and tablets, through personal\ncomputers, to high-end server class platforms. With the increasing importance\nof graphics and video workloads, recent processors are shipped with GPU devices\nthat are integrated on the same chip. Integrated GPUs share some resources with\nthe CPU and as a result, there is a potential for microarchitectural attacks\nfrom the GPU to the CPU or vice versa. We believe this type of attack, crossing\nthe component boundary (GPU to CPU or vice versa) is novel, introducing unique\nchallenges, but also providing the attacker with new capabilities that must be\nconsidered when we design defenses against microarchitectrual attacks in these\nenvironments. Specifically, we consider the potential for covert channel\nattacks that arise either from shared microarchitectural components (such as\ncaches) or through shared contention domains (e.g., shared buses). We\nillustrate these two types of channels by developing two reliable covert\nchannel attacks. The first covert channel uses the shared LLC cache in Intel's\nintegrated GPU architectures. The second is a contention based channel\ntargeting the ring bus connecting the CPU and GPU to the LLC. Cross component\nchannels introduce a number of new challenges that we had to overcome since\nthey occur across heterogeneous components that use different computation\nmodels and are interconnected using asymmetric memory hierarchies. We also\nexploit GPU parallelism to increase the bandwidth of the communication, even\nwithout relying on a common clock. The LLC based channel achieves a bandwidth\nof 120 kbps with a low error rate of 2%, while the contention based channel\ndelivers up to 400 kbps with a 0.8% error rate.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 04:17:34 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Dutta", "Sankha Baran", ""], ["Naghibijouybari", "Hoda", ""], ["Abu-Ghazaleh", "Nael", ""], ["Marquez", "Andres", ""], ["Barker", "Kevin", ""]]}, {"id": "2011.09646", "submitter": "Silun Zhang", "authors": "Silun Zhang, Thomas Ohlson Timoudas, Munther Dahleh", "title": "Consensus with Preserved Privacy against Neighbor Collusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a privacy-preserving algorithm to solve the average\nconsensus problem based on Shamir's secret sharing scheme, in which a network\nof agents reach an agreement on their states without exposing their individual\nstate until an agreement is reached. Unlike other methods, the proposed\nalgorithm renders the network resistant to the collusion of any given number of\nneighbors (even with all neighbors' colluding). Another virtue of this work is\nthat such a method can protect the network consensus procedure from\neavesdropping.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 04:23:34 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Zhang", "Silun", ""], ["Timoudas", "Thomas Ohlson", ""], ["Dahleh", "Munther", ""]]}, {"id": "2011.09655", "submitter": "Di Chai", "authors": "Di Chai and Leye Wang and Kai Chen and Qiang Yang", "title": "FedEval: A Benchmark System with a Comprehensive Evaluation Model for\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an innovative solution for privacy-preserving machine learning (ML),\nfederated learning (FL) is attracting much attention from research and industry\nareas. While new technologies proposed in the past few years do evolve the FL\narea, unfortunately, the evaluation results presented in these works fall short\nin integrity and are hardly comparable because of the inconsistent evaluation\nmetrics and the lack of a common platform. In this paper, we propose a\ncomprehensive evaluation framework for FL systems. Specifically, we first\nintroduce the ACTPR model, which defines five metrics that cannot be excluded\nin FL evaluation, including Accuracy, Communication, Time efficiency, Privacy,\nand Robustness. Then we design and implement a benchmarking system called\nFedEval, which enables the systematic evaluation and comparison of existing\nworks under consistent experimental conditions. We then provide an in-depth\nbenchmarking study between the two most widely-used FL mechanisms, FedSGD and\nFedAvg. The benchmarking results show that FedSGD and FedAvg both have\nadvantages and disadvantages under the ACTPR model. For example, FedSGD is\nbarely influenced by the none independent and identically distributed (non-IID)\ndata problem, but FedAvg suffers from a decline in accuracy of up to 9% in our\nexperiments. On the other hand, FedAvg is more efficient than FedSGD regarding\ntime consumption and communication. Lastly, we excavate a set of take-away\nconclusions, which are very helpful for researchers in the FL area.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 04:59:51 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 16:08:13 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Chai", "Di", ""], ["Wang", "Leye", ""], ["Chen", "Kai", ""], ["Yang", "Qiang", ""]]}, {"id": "2011.09719", "submitter": "Chawin Sitawarin", "authors": "Chawin Sitawarin, Evgenios M. Kornaropoulos, Dawn Song, David Wagner", "title": "Adversarial Examples for $k$-Nearest Neighbor Classifiers Based on\n  Higher-Order Voronoi Diagrams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial examples are a widely studied phenomenon in machine learning\nmodels. While most of the attention has been focused on neural networks, other\npractical models also suffer from this issue. In this work, we propose an\nalgorithm for evaluating the adversarial robustness of $k$-nearest neighbor\nclassification, i.e., finding a minimum-norm adversarial example. Diverging\nfrom previous proposals, we take a geometric approach by performing a search\nthat expands outwards from a given input point. On a high level, the search\nradius expands to the nearby Voronoi cells until we find a cell that classifies\ndifferently from the input point. To scale the algorithm to a large $k$, we\nintroduce approximation steps that find perturbations with smaller norm,\ncompared to the baselines, in a variety of datasets. Furthermore, we analyze\nthe structural properties of a dataset where our approach outperforms the\ncompetition.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 08:49:10 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Sitawarin", "Chawin", ""], ["Kornaropoulos", "Evgenios M.", ""], ["Song", "Dawn", ""], ["Wagner", "David", ""]]}, {"id": "2011.09824", "submitter": "Yu Zhang", "authors": "Pengxin Guo, Yuancheng Xu, Baijiong Lin, Yu Zhang", "title": "Multi-Task Adversarial Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved impressive performance in various areas,\nbut they are shown to be vulnerable to adversarial attacks. Previous works on\nadversarial attacks mainly focused on the single-task setting. However, in real\napplications, it is often desirable to attack several models for different\ntasks simultaneously. To this end, we propose Multi-Task adversarial Attack\n(MTA), a unified framework that can craft adversarial examples for multiple\ntasks efficiently by leveraging shared knowledge among tasks, which helps\nenable large-scale applications of adversarial attacks on real-world systems.\nMore specifically, MTA uses a generator for adversarial perturbations which\nconsists of a shared encoder for all tasks and multiple task-specific decoders.\nThanks to the shared encoder, MTA reduces the storage cost and speeds up the\ninference when attacking multiple tasks simultaneously. Moreover, the proposed\nframework can be used to generate per-instance and universal perturbations for\ntargeted and non-targeted attacks. Experimental results on the Office-31 and\nNYUv2 datasets demonstrate that MTA can improve the quality of attacks when\ncompared with its single-task counterpart.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 13:56:58 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Guo", "Pengxin", ""], ["Xu", "Yuancheng", ""], ["Lin", "Baijiong", ""], ["Zhang", "Yu", ""]]}, {"id": "2011.09877", "submitter": "Zhuoran Liu", "authors": "Zhuoran Liu, Niels Samwel, L\\'eo Weissbart, Zhengyu Zhao, Dirk Lauret,\n  Lejla Batina, Martha Larson", "title": "Screen Gleaning: A Screen Reading TEMPEST Attack on Mobile Devices\n  Exploiting an Electromagnetic Side Channel", "comments": "To appear at NDSS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce screen gleaning, a TEMPEST attack in which the screen of a\nmobile device is read without a visual line of sight, revealing sensitive\ninformation displayed on the phone screen. The screen gleaning attack uses an\nantenna and a software-defined radio (SDR) to pick up the electromagnetic\nsignal that the device sends to the screen to display, e.g., a message with a\nsecurity code. This special equipment makes it possible to recreate the signal\nas a gray-scale image, which we refer to as an emage. Here, we show that it can\nbe used to read a security code. The screen gleaning attack is challenging\nbecause it is often impossible for a human viewer to interpret the emage\ndirectly. We show that this challenge can be addressed with machine learning,\nspecifically, a deep learning classifier. Screen gleaning will become\nincreasingly serious as SDRs and deep learning continue to rapidly advance. In\nthis paper, we demonstrate the security code attack and we propose a testbed\nthat provides a standard setup in which screen gleaning could be tested with\ndifferent attacker models. Finally, we analyze the dimensions of screen\ngleaning attacker models and discuss possible countermeasures with the\npotential to address them.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 15:02:37 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Liu", "Zhuoran", ""], ["Samwel", "Niels", ""], ["Weissbart", "L\u00e9o", ""], ["Zhao", "Zhengyu", ""], ["Lauret", "Dirk", ""], ["Batina", "Lejla", ""], ["Larson", "Martha", ""]]}, {"id": "2011.09939", "submitter": "Jianrui Xie", "authors": "Jianrui Xie", "title": "Further Results on Pure Summing Registers and Complementary Ones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We decide completely the cycle structure of pure summing register (PSR) and\ncomplementary summing register (CSR). Based on the state diagram of CSR, we\nderive an algorithm to generate de Bruijn cycles from CSR inspired by Tuvi\nEtzion's publication in 1984. We then point out the limitation in\ngeneralizations of extended representation we use in the algorithm proposed,\nwith a proof of the fact that only PSR and CSR contain pure cycles all dividing\nn+1.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 08:55:56 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Xie", "Jianrui", ""]]}, {"id": "2011.09982", "submitter": "Juan Ospina", "authors": "Juan Ospina, XiaoRui Liu, Charalambos Konstantinou, Yury Dvorkin", "title": "On the Feasibility of Load-Changing Attacks in Power Systems during the\n  COVID-19 Pandemic", "comments": "Accepted version of IEEE Access paper published under the Open Access\n  Publishing agreement. 19 pages, 17 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The electric power grid is a complex cyberphysical energy system (CPES) in\nwhich information and communication technologies (ICT) are integrated into the\noperations and services of the power grid infrastructure. The growing number of\nInternet-of-things (IoT) high-wattage appliances, such as air conditioners and\nelectric vehicles, being connected to the power grid, together with the high\ndependence of ICT and control interfaces, make CPES vulnerable to high-impact,\nlow-probability load-changing cyberattacks. Moreover, the side-effects of the\nCOVID-19 pandemic demonstrate a modification of electricity consumption\npatterns with utilities experiencing significant net-load and peak reductions.\nThese unusual sustained low load demand conditions could be leveraged by\nadversaries to cause frequency instabilities in CPES by compromising hundreds\nof thousands of IoT-connected high-wattage loads. This paper presents a\nfeasibility study of the impacts of load-changing attacks on CPES during the\nlow loading conditions caused by the lockdown measures implemented during the\nCOVID-19 pandemic. The load demand reductions caused by the lockdown measures\nare analyzed using dynamic mode decomposition (DMD), focusing on the\nMarch-to-July 2020 period and the New York region as the most impacted time\nperiod and location in terms of load reduction due to the lockdowns being in\nfull execution. Our feasibility study evaluates load-changing attack scenarios\nusing real load consumption data from the New York Independent System Operator\n(NYISO) and shows that an attacker with sufficient knowledge and resources\ncould be capable of producing frequency stability problems, with frequency\nexcursions going up to 60.5 Hz and 63.4 Hz, when no mitigation measures are\ntaken.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 17:32:51 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 15:53:14 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Ospina", "Juan", ""], ["Liu", "XiaoRui", ""], ["Konstantinou", "Charalambos", ""], ["Dvorkin", "Yury", ""]]}, {"id": "2011.10012", "submitter": "Brent Lagesse", "authors": "Jia Wang, Brent Lagesse", "title": "KeyGuard: Using Selective Encryption to Mitigate Keylogging in\n  Third-Party IME", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  As mobile devices become ubiquitous, people around the world have enjoyed the\nconvenience they have brought to our lives. At the same time, the increasing\nsecurity threats that rise from using mobile devices not only have caught\nattention from cyber security agencies but also have become a valid concern for\nmobile users. Keylogging is one of the mobile security threats caused by using\ninsecure third-party IME (input method editor) applications. Keylogging, as the\nname suggests, keeps track of user\\rq s key events performed on the device and\nstores all the events in a log. The log could include highly sensitive data\nsuch as credit card number, social security number, and passwords. This paper\npresents a novel solution by intercepting the keystroke events triggered by a\nuser and encrypting them before sending them to the third-party IME, making the\nthird-party IME unable to log what the users actually entered on the screen.\nInput will be decrypted when showing on text view on the underlying app. This\nsolution addresses the fundamental reason why an IME may leak sensitive\ninformation since an IME will no longer have access to the user\\rq s actual\nsensitive information, which will greatly reduce the chance of leaking\nsensitive information by using a third-party IME while maintaining the\nfunctionalities of the third-party IME at the same time.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 18:17:46 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Wang", "Jia", ""], ["Lagesse", "Brent", ""]]}, {"id": "2011.10017", "submitter": "Brent Lagesse", "authors": "Adedayo Odesile, Brent Lagesse", "title": "TrustSense: An energy efficient trust scheme for clustered wireless\n  sensor networks", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Designing security systems for wireless sensor networks presents a challenge\ndue to their relatively low computational resources. This has rendered many\ntraditional defense mechanisms based on cryptography infeasible for deployment\non such networks. Reputation and anomaly detection systems have been\nimplemented as viable alternatives, but existing implementations still struggle\nwith providing efficient security without a significant impact on energy\nconsumption. To address this trade-off between resource consumption and\nresiliency, we designed TrustSense, a reputation management protocol for\nclustered WSNs. It is a semi-centralized family of algorithms that combine\nperiodic trust updates, spatial correlation, and packet sequence validation at\nthe cluster-heads' hierarchy to relieve the sensor nodes of unnecessary opinion\nqueries and trust evaluation computation. We compared the efficiency of\nTrustSense with legacy reputation systems such as EigenTrust and the results of\nsimulations show a significant improvement in reliability and energy usage\nwhile maintaining an acceptable path length with varying numbers of malicious\nnodes. We believe the approach of combining different techniques from various\nclasses of intrusion detection systems unlocks several possibilities of\nachieving better results by more complex and versatile composition of these\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 18:34:31 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Odesile", "Adedayo", ""], ["Lagesse", "Brent", ""]]}, {"id": "2011.10121", "submitter": "Sudheesh Singanamalla", "authors": "Sudheesh Singanamalla, Suphanat Chunhapanya, Marek Vavru\\v{s}a, Tanya\n  Verma, Peter Wu, Marwan Fayed, Kurtis Heimerl, Nick Sullivan, Christopher\n  Wood", "title": "Oblivious DNS over HTTPS (ODoH): A Practical Privacy Enhancement to DNS", "comments": "16 pages, 7 figures, Under submission and Presented at IETF 109 MAPRG", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Domain Name System (DNS) is the foundation of a human-usable Internet,\nresponding to client queries for host-names with corresponding IP addresses and\nrecords. Traditional DNS is also unencrypted, and leaks user information to\nnetwork operators. Recent efforts to secure DNS using DNS over TLS (DoT) and\nDNS over HTTPS (DoH) have been gaining traction, ostensibly protecting traffic\nand hiding content from on-lookers. However, one of the criticisms of DoT and\nDoH is brought to bear by the small number of large-scale deployments (e.g.,\nComcast, Google, Cloudflare): DNS resolvers can associate query contents with\nclient identities in the form of IP addresses. Oblivious DNS over HTTPS(ODoH)\nsafeguards against this problem. In this paper we ask what it would take to\nmake ODoH practical? We describe ODoH, a practical DNS protocol aimed at\nresolving this issue by both protecting the client's content and identity. We\nimplement and deploy the protocol, and perform measurements to show that ODoH\nhas comparable performance to protocols like DoH and DoT which are gaining\nwidespread adoption, while improving client privacy, making ODoH a practical\nprivacy enhancing replacement for the usage of DNS.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 22:04:43 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Singanamalla", "Sudheesh", ""], ["Chunhapanya", "Suphanat", ""], ["Vavru\u0161a", "Marek", ""], ["Verma", "Tanya", ""], ["Wu", "Peter", ""], ["Fayed", "Marwan", ""], ["Heimerl", "Kurtis", ""], ["Sullivan", "Nick", ""], ["Wood", "Christopher", ""]]}, {"id": "2011.10180", "submitter": "Chaochao Chen", "authors": "Chaochao Chen, Jamie Cui, Guanfeng Liu, Jia Wu, Li Wang", "title": "Survey and Open Problems in Privacy Preserving Knowledge Graph: Merging,\n  Query, Representation, Completion and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graph (KG) has attracted more and more companies' attention for its\nability to connect different types of data in meaningful ways and support rich\ndata services. However, the data isolation problem limits the performance of KG\nand prevents its further development. That is, multiple parties have their own\nKGs but they cannot share with each other due to regulation or competition\nreasons. Therefore, how to conduct privacy preserving KG becomes an important\nresearch question to answer. That is, multiple parties conduct KG related tasks\ncollaboratively on the basis of protecting the privacy of multiple KGs. To\ndate, there is few work on solving the above KG isolation problem. In this\npaper, to fill this gap, we summarize the open problems for privacy preserving\nKG in data isolation setting and propose possible solutions for them.\nSpecifically, we summarize the open problems in privacy preserving KG from four\naspects, i.e., merging, query, representation, and completion. We present these\nproblems in details and propose possible technical solutions for them.\nMoreover, we present three privacy preserving KG-aware applications and simply\ndescribe how can our proposed techniques be applied into these applications.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 02:35:47 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Chen", "Chaochao", ""], ["Cui", "Jamie", ""], ["Liu", "Guanfeng", ""], ["Wu", "Jia", ""], ["Wang", "Li", ""]]}, {"id": "2011.10249", "submitter": "Tuo Li", "authors": "Tuo Li, Bradley Hopkins, Sri Parameswaran", "title": "SIMF: Single-Instruction Multiple-Flush Mechanism for Processor Temporal\n  Isolation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microarchitectural timing attacks are a type of information leakage attack,\nwhich exploit the time-shared microarchitectural components, such as caches,\ntranslation look-aside buffers (TLBs), branch prediction unit (BPU), and\nspeculative execution, in modern processors to leak critical information from a\nvictim process or thread. To mitigate such attacks, the mechanism for flushing\nthe on-core state is extensively used by operating-system-level solutions,\nsince on-core state is too expensive to partition. In these systems, the\nflushing operations are implemented in software (using cache maintenance\ninstructions), which severely limit the efficiency of timing attack protection.\n  To bridge this gap, we propose specialized hardware support, a\nsingle-instruction multiple-flush (SIMF) mechanism to flush the core-level\nstate, which consists of L1 caches, BPU, TLBs, and register file. We\ndemonstrate SIMF by implementing it as an ISA extension, i.e., flushx\ninstruction, in scalar in-order RISC-V processor. The resultant processor is\nprototyped on Xilinx ZCU102 FPGA and validated with state-of-art seL4\nmicrokernel, Linux kernel in multi-core scenarios, and a cache timing attack.\nOur evaluation shows that SIMF significantly alleviates the overhead of\nflushing by more than a factor of two in execution time and reduces dynamic\ninstruction count by orders-of-magnitude.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 07:48:27 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Li", "Tuo", ""], ["Hopkins", "Bradley", ""], ["Parameswaran", "Sri", ""]]}, {"id": "2011.10255", "submitter": "Mahmoud Khalifa Dr", "authors": "Mahmoud Khalifa, Fahad Algarni, Mohammad Ayoub Khan, Azmat Ullah,\n  Khalid Aloufic", "title": "A lightweight cryptography (LWC) framework to secure memory heap in\n  Internet of Things", "comments": "Alexandria Engineering Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The extensive networking of devices and the large amount of data generated\nfrom the Internet of Things (IoT) has brought security issues to the attention\nof the researcher. Java is the most common platform for embedded applications\nsuch as IoT, Wireless Sensors Networks (WSN), Near Field Communications (NFC)\nand Radio Frequency Identification (RFID). The object programming languages\nsuch as Java, SWIFT, PHP and C++ use garbage collection after any object run\nwhich creates security loophole for attacks such as Next Memory Address\nOccupation (NMAO), memory replay, Learning Tasks Behaviors (LTB). The security\nrisk increases in IoT when attacks exceeds the target device to the surrounding\nconnected devices. Inappropriate or wrong operations causes energy loss and\nincreased costs. In this paper, a security method to protect IoT system\noperation from memory heap penetration and address modification attack is\nproposed. The proposed method prevents directed attack by encrypting the object\nGarbage Collection at run time. To form a unique signature mechanism, the\nCryptographic Hash Function (CHF) which employs a specific one-way hash\nalgorithm. The proposed framework uses L-function based ECC and one-time Key\n(OTK) to secure the memory heap. Our method is used with open system where the\neffect on the operating system is not considered. The proposed method proved to\nbe powerful and efficient which can help in achieving higher levels of security\nacross several IoT applications, by enabling better detection of malicious\nattacks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 08:00:31 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Khalifa", "Mahmoud", ""], ["Algarni", "Fahad", ""], ["Khan", "Mohammad Ayoub", ""], ["Ullah", "Azmat", ""], ["Aloufic", "Khalid", ""]]}, {"id": "2011.10355", "submitter": "Pedro Reviriego", "authors": "Pedro Reviriego, Pablo Adell and Daniel Ting", "title": "HyperLogLog (HLL) Security: Inflating Cardinality Estimates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Counting the number of distinct elements on a set is needed in many\napplications, for example to track the number of unique users in Internet\nservices or the number of distinct flows on a network. In many cases, an\nestimate rather than the exact value is sufficient and thus many algorithms for\ncardinality estimation that significantly reduce the memory and computation\nrequirements have been proposed. Among them, Hyperloglog has been widely\nadopted in both software and hardware implementations. The security of\nHyperloglog has been recently studied showing that an attacker can create a set\nof elements that produces a cardinality estimate that is much smaller than the\nreal cardinality of the set. This set can be used for example to evade\ndetection systems that use Hyperloglog. In this paper, the security of\nHyperloglog is considered from the opposite angle: the attacker wants to create\na small set that when inserted on the Hyperloglog produces a large cardinality\nestimate. This set can be used to trigger false alarms in detection systems\nthat use Hyperloglog but more interestingly, it can be potentially used to\ninflate the visits to websites or the number of hits of online advertisements.\nOur analysis shows that an attacker can create a set with a number of elements\nequal to the number of registers used in the Hyperloglog implementation that\nproduces any arbitrary cardinality estimate. This has been validated in two\ncommercial implementations of Hyperloglog: Presto and Redis. Based on those\nresults, we also consider the protection of Hyperloglog against such an attack.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 11:43:33 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Reviriego", "Pedro", ""], ["Adell", "Pablo", ""], ["Ting", "Daniel", ""]]}, {"id": "2011.10389", "submitter": "Dominik Sisejkovic", "authors": "Dominik Sisejkovic, Farhad Merchant, Lennart M. Reimann, Harshit\n  Srivastava, Ahmed Hallawa and Rainer Leupers", "title": "Challenging the Security of Logic Locking Schemes in the Era of Deep\n  Learning: A Neuroevolutionary Approach", "comments": "25 pages, 17 figures, accepted at ACM JETC", "journal-ref": "ACM J. Emerg. Technol. Comput. Syst. 17, 3, Article 30 (May 2021),\n  26 pages", "doi": "10.1145/3431389", "report-no": null, "categories": "cs.CR cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Logic locking is a prominent technique to protect the integrity of hardware\ndesigns throughout the integrated circuit design and fabrication flow. However,\nin recent years, the security of locking schemes has been thoroughly challenged\nby the introduction of various deobfuscation attacks. As in most research\nbranches, deep learning is being introduced in the domain of logic locking as\nwell. Therefore, in this paper we present SnapShot: a novel attack on logic\nlocking that is the first of its kind to utilize artificial neural networks to\ndirectly predict a key bit value from a locked synthesized gate-level netlist\nwithout using a golden reference. Hereby, the attack uses a simpler yet more\nflexible learning model compared to existing work. Two different approaches are\nevaluated. The first approach is based on a simple feedforward fully connected\nneural network. The second approach utilizes genetic algorithms to evolve more\ncomplex convolutional neural network architectures specialized for the given\ntask. The attack flow offers a generic and customizable framework for attacking\nlocking schemes using machine learning techniques. We perform an extensive\nevaluation of SnapShot for two realistic attack scenarios, comprising both\nreference benchmark circuits as well as silicon-proven RISC-V core modules. The\nevaluation results show that SnapShot achieves an average key prediction\naccuracy of 82.60% for the selected attack scenario, with a significant\nperformance increase of 10.49 percentage points compared to the state of the\nart. Moreover, SnapShot outperforms the existing technique on all evaluated\nbenchmarks. The results indicate that the security foundation of common logic\nlocking schemes is build on questionable assumptions. The conclusions of the\nevaluation offer insights into the challenges of designing future logic locking\nschemes that are resilient to machine learning attacks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 13:03:19 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 08:49:19 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Sisejkovic", "Dominik", ""], ["Merchant", "Farhad", ""], ["Reimann", "Lennart M.", ""], ["Srivastava", "Harshit", ""], ["Hallawa", "Ahmed", ""], ["Leupers", "Rainer", ""]]}, {"id": "2011.10492", "submitter": "Thai Le", "authors": "Thai Le, Noseong Park, Dongwon Lee", "title": "A Sweet Rabbit Hole by DARCY: Using Honeypots to Detect Universal\n  Trigger's Adversarial Attacks", "comments": "Accepted to the 59th Annual Meeting of the Association for\n  Computational Linguistics (ACL) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Universal Trigger (UniTrigger) is a recently-proposed powerful\nadversarial textual attack method. Utilizing a learning-based mechanism,\nUniTrigger generates a fixed phrase that, when added to any benign inputs, can\ndrop the prediction accuracy of a textual neural network (NN) model to near\nzero on a target class. To defend against this attack that can cause\nsignificant harm, in this paper, we borrow the \"honeypot\" concept from the\ncybersecurity community and propose DARCY, a honeypot-based defense framework\nagainst UniTrigger. DARCY greedily searches and injects multiple trapdoors into\nan NN model to \"bait and catch\" potential attacks. Through comprehensive\nexperiments across four public datasets, we show that DARCY detects\nUniTrigger's adversarial attacks with up to 99% TPR and less than 2% FPR in\nmost cases, while maintaining the prediction accuracy (in F1) for clean inputs\nwithin a 1% margin. We also demonstrate that DARCY with multiple trapdoors is\nalso robust to a diverse set of attack scenarios with attackers' varying levels\nof knowledge and skills. Source code will be released upon the acceptance of\nthis paper.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 16:38:28 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 18:14:53 GMT"}, {"version": "v3", "created": "Thu, 6 May 2021 20:53:25 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Le", "Thai", ""], ["Park", "Noseong", ""], ["Lee", "Dongwon", ""]]}, {"id": "2011.10698", "submitter": "Shihong Fang", "authors": "Shihong Fang, Anna Choromanska", "title": "Backdoor Attacks on the DNN Interpretation System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability is crucial to understand the inner workings of deep neural\nnetworks (DNNs) and many interpretation methods generate saliency maps that\nhighlight parts of the input image that contribute the most to the prediction\nmade by the DNN. In this paper we design a backdoor attack that alters the\nsaliency map produced by the network for an input image only with injected\ntrigger that is invisible to the naked eye while maintaining the prediction\naccuracy. The attack relies on injecting poisoned data with a trigger into the\ntraining data set. The saliency maps are incorporated in the penalty term of\nthe objective function that is used to train a deep model and its influence on\nmodel training is conditioned upon the presence of a trigger. We design two\ntypes of attacks: targeted attack that enforces a specific modification of the\nsaliency map and untargeted attack when the importance scores of the top pixels\nfrom the original saliency map are significantly reduced. We perform empirical\nevaluation of the proposed backdoor attacks on gradient-based and gradient-free\ninterpretation methods for a variety of deep learning architectures. We show\nthat our attacks constitute a serious security threat when deploying deep\nlearning models developed by untrusty sources. Finally, in the Supplement we\ndemonstrate that the proposed methodology can be used in an inverted setting,\nwhere the correct saliency map can be obtained only in the presence of a\ntrigger (key), effectively making the interpretation system available only to\nselected users.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 01:54:45 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 01:49:42 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Fang", "Shihong", ""], ["Choromanska", "Anna", ""]]}, {"id": "2011.10718", "submitter": "Mohammad Javad Khojasteh", "authors": "Anshuka Rangi, Mohammad Javad Khojasteh and Massimo Franceschetti", "title": "Learning-based attacks in Cyber-Physical Systems: Exploration,\n  Detection, and Control Cost trade-offs", "comments": "To appear in L4DC 2021. First two authors contributed equally", "journal-ref": "Learning for Dynamics and Control 2021, PMLR", "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.LG cs.MA cs.SY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning-based attacks in linear systems, where the\ncommunication channel between the controller and the plant can be hijacked by a\nmalicious attacker. We assume the attacker learns the dynamics of the system\nfrom observations, then overrides the controller's actuation signal, while\nmimicking legitimate operation by providing fictitious sensor readings to the\ncontroller. On the other hand, the controller is on a lookout to detect the\npresence of the attacker and tries to enhance the detection performance by\ncarefully crafting its control signals. We study the trade-offs between the\ninformation acquired by the attacker from observations, the detection\ncapabilities of the controller, and the control cost. Specifically, we provide\ntight upper and lower bounds on the expected $\\epsilon$-deception time, namely\nthe time required by the controller to make a decision regarding the presence\nof an attacker with confidence at least $(1-\\epsilon\\log(1/\\epsilon))$. We then\nshow a probabilistic lower bound on the time that must be spent by the attacker\nlearning the system, in order for the controller to have a given expected\n$\\epsilon$-deception time. We show that this bound is also order optimal, in\nthe sense that if the attacker satisfies it, then there exists a learning\nalgorithm with the given order expected deception time. Finally, we show a\nlower bound on the expected energy expenditure required to guarantee detection\nwith confidence at least $1-\\epsilon \\log(1/\\epsilon)$.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 04:08:16 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 02:11:55 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Rangi", "Anshuka", ""], ["Khojasteh", "Mohammad Javad", ""], ["Franceschetti", "Massimo", ""]]}, {"id": "2011.10797", "submitter": "Nicolas Garcia Trillos", "authors": "Nicolas Garcia Trillos and Ryan Murray", "title": "Adversarial Classification: Necessary conditions and geometric flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a version of adversarial classification where an adversary is\nempowered to corrupt data inputs up to some distance $\\varepsilon$, using tools\nfrom variational analysis. In particular, we describe necessary conditions\nassociated with the optimal classifier subject to such an adversary. Using the\nnecessary conditions, we derive a geometric evolution equation which can be\nused to track the change in classification boundaries as $\\varepsilon$ varies.\nThis evolution equation may be described as an uncoupled system of differential\nequations in one dimension, or as a mean curvature type equation in higher\ndimension. In one dimension we rigorously prove that one can use the initial\nvalue problem starting from $\\varepsilon=0$, which is simply the Bayes\nclassifier, in order to solve for the global minimizer of the adversarial\nproblem. Numerical examples illustrating these ideas are also presented.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 14:14:12 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Trillos", "Nicolas Garcia", ""], ["Murray", "Ryan", ""]]}, {"id": "2011.10824", "submitter": "Adish Singla", "authors": "Amin Rakhsha, Goran Radanovic, Rati Devidze, Xiaojin Zhu, Adish Singla", "title": "Policy Teaching in Reinforcement Learning via Environment Poisoning\n  Attacks", "comments": "Journal version of ICML'20 paper. New theoretical results for jointly\n  poisoning rewards and transitions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a security threat to reinforcement learning where an attacker\npoisons the learning environment to force the agent into executing a target\npolicy chosen by the attacker. As a victim, we consider RL agents whose\nobjective is to find a policy that maximizes reward in infinite-horizon problem\nsettings. The attacker can manipulate the rewards and the transition dynamics\nin the learning environment at training-time, and is interested in doing so in\na stealthy manner. We propose an optimization framework for finding an optimal\nstealthy attack for different measures of attack cost. We provide lower/upper\nbounds on the attack cost, and instantiate our attacks in two settings: (i) an\noffline setting where the agent is doing planning in the poisoned environment,\nand (ii) an online setting where the agent is learning a policy with poisoned\nfeedback. Our results show that the attacker can easily succeed in teaching any\ntarget policy to the victim under mild conditions and highlight a significant\nsecurity threat to reinforcement learning agents in practice.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 16:54:45 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Rakhsha", "Amin", ""], ["Radanovic", "Goran", ""], ["Devidze", "Rati", ""], ["Zhu", "Xiaojin", ""], ["Singla", "Adish", ""]]}, {"id": "2011.10850", "submitter": "Honglei Zhang", "authors": "Honglei Zhang, Hu Wang, Yuanzhouhan Cao, Chunhua Shen, Yidong Li", "title": "Robust Watermarking Using Inverse Gradient Attention", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Watermarking is the procedure of encoding desired information into an image\nto resist potential noises while ensuring the embedded image has little\nperceptual perturbations from the original image. Recently, with the tremendous\nsuccesses gained by deep neural networks in various fields, digital\nwatermarking has attracted increasing number of attentions. The neglect of\nconsidering the pixel importance within the cover image of deep neural models\nwill inevitably affect the model robustness for information hiding. Targeting\nat the problem, in this paper, we propose a novel deep watermarking scheme with\nInverse Gradient Attention (IGA), combing the ideas of adversarial learning and\nattention mechanism to endow different importance to different pixels. With the\nproposed method, the model is able to spotlight pixels with more robustness for\nembedding data. Besides, from an orthogonal point of view, in order to increase\nthe model embedding capacity, we propose a complementary message coding module.\nEmpirically, extensive experiments show that the proposed model outperforms the\nstate-of-the-art methods on two prevalent datasets under multiple settings.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 19:08:23 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 02:51:09 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Zhang", "Honglei", ""], ["Wang", "Hu", ""], ["Cao", "Yuanzhouhan", ""], ["Shen", "Chunhua", ""], ["Li", "Yidong", ""]]}, {"id": "2011.10867", "submitter": "Can Bakiskan", "authors": "Can Bakiskan, Metehan Cekic, Ahmet Dundar Sezer, Upamanyu Madhow", "title": "A Neuro-Inspired Autoencoding Defense Against Adversarial Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Neural Networks (DNNs) are vulnerable to adversarial attacks: carefully\nconstructed perturbations to an image can seriously impair classification\naccuracy, while being imperceptible to humans. While there has been a\nsignificant amount of research on defending against such attacks, most defenses\nbased on systematic design principles have been defeated by appropriately\nmodified attacks. For a fixed set of data, the most effective current defense\nis to train the network using adversarially perturbed examples. In this paper,\nwe investigate a radically different, neuro-inspired defense mechanism,\nstarting from the observation that human vision is virtually unaffected by\nadversarial examples designed for machines. We aim to reject L^inf bounded\nadversarial perturbations before they reach a classifier DNN, using an encoder\nwith characteristics commonly observed in biological vision: sparse\novercomplete representations, randomness due to synaptic noise, and drastic\nnonlinearities. Encoder training is unsupervised, using standard dictionary\nlearning. A CNN-based decoder restores the size of the encoder output to that\nof the original image, enabling the use of a standard CNN for classification.\nOur nominal design is to train the decoder and classifier together in standard\nsupervised fashion, but we also consider unsupervised decoder training based on\na regression objective (as in a conventional autoencoder) with separate\nsupervised training of the classifier. Unlike adversarial training, all\ntraining is based on clean images.\n  Our experiments on the CIFAR-10 show performance competitive with\nstate-of-the-art defenses based on adversarial training, and point to the\npromise of neuro-inspired techniques for the design of robust neural networks.\nIn addition, we provide results for a subset of the Imagenet dataset to verify\nthat our approach scales to larger images.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 21:03:08 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 23:35:47 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Bakiskan", "Can", ""], ["Cekic", "Metehan", ""], ["Sezer", "Ahmet Dundar", ""], ["Madhow", "Upamanyu", ""]]}, {"id": "2011.10902", "submitter": "Kirill Korinsky", "authors": "Kirill A. Korinsky", "title": "Electt: running auditable and verifiable elections in untrusted\n  environments", "comments": "21 pages plus glossary because English languages are quite different\n  when we speak about the election", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system for running auditable and verifiable elections in\nuntrusted environments. Votes are anonymous since the order of candidates on a\nballot sheet is random. Tellers see only the position of the candidate. Voters\ncan check their vote. An election is auditable using blockchain log.\nThreshold-encryption, which is used to implement the quorum, prevents a\ndeadlock from occurring if a minority of candidates or observers tries to\nsabotage the election. Candidates and observers can indicate that the election\nwas free and fair by exposing their keys, which are used by the system to\ndecrypt each vote. Ballot sheets are encrypted by onion-routing, which has a\nlayer with the key of the election instance, so it's impossible for a quorum to\ndecode the results before they have announced their decision by exposing their\nkeys. A register of voters ensures that only verified voters can vote without\ncompromising their identity. If there any doubts about the identity of a voter,\ntheir vote can be excluded from the election, if a quorum agrees. This system\nis designed to scale from one instance to a distributed system that runs over\nan unlimited number of instances, which can be achieved using cloud instances\nor smartphones belonging to voters or tellers.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 00:58:34 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 21:34:48 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Korinsky", "Kirill A.", ""]]}, {"id": "2011.10947", "submitter": "Zhi Sun", "authors": "Zhi Sun, Sarankumar Balakrishnan, Lu Su, Arupjyoti Bhuyan, Pu Wang,\n  Chunming Qiao", "title": "Who is in Control? Practical Physical Layer Attack and Defense for\n  mmWave based Sensing in Autonomous Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the wide bandwidths in millimeter wave (mmWave) frequency band that\nresults in unprecedented accuracy, mmWave sensing has become vital for many\napplications, especially in autonomous vehicles (AVs). In addition, mmWave\nsensing has superior reliability compared to other sensing counterparts such as\ncamera and LiDAR, which is essential for safety-critical driving. Therefore, it\nis critical to understand the security vulnerabilities and improve the security\nand reliability of mmWave sensing in AVs. To this end, we perform the\nend-to-end security analysis of a mmWave-based sensing system in AVs, by\ndesigning and implementing practical physical layer attack and defense\nstrategies in a state-of-the-art mmWave testbed and an AV testbed in real-world\nsettings. Various strategies are developed to take control of the victim AV by\nspoofing its mmWave sensing module, including adding fake obstacles at\narbitrary locations and faking the locations of existing obstacles. Five\nreal-world attack scenarios are constructed to spoof the victim AV and force it\nto make dangerous driving decisions leading to a fatal crash. Field experiments\nare conducted to study the impact of the various attack scenarios using a\nLincoln MKZ-based AV testbed, which validate that the attacker can indeed\nassume control of the victim AV to compromise its security and safety. To\ndefend the attacks, we design and implement a challenge-response authentication\nscheme and a RF fingerprinting scheme to reliably detect aforementioned\nspoofing attacks.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 06:01:22 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Sun", "Zhi", ""], ["Balakrishnan", "Sarankumar", ""], ["Su", "Lu", ""], ["Bhuyan", "Arupjyoti", ""], ["Wang", "Pu", ""], ["Qiao", "Chunming", ""]]}, {"id": "2011.10954", "submitter": "Sihem Mesnager", "authors": "Kwang Ho Kim and Sihem Mesnager and Jong Hyok Choe and Dok Nam Lee", "title": "Preimages of $p-$Linearized Polynomials over $\\GF{p}$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linearized polynomials over finite fields have been intensively studied over\nthe last several decades. Interesting new applications of linearized\npolynomials to coding theory and finite geometry have been also highlighted in\nrecent years.\n  Let $p$ be any prime. Recently, preimages of the $p-$linearized polynomials\n$\\sum_{i=0}^{\\frac kl-1} X^{p^{li}}$ and $\\sum_{i=0}^{\\frac kl-1} (-1)^i\nX^{p^{li}}$ were explicitly computed over $\\GF{p^n}$ for any $n$. This paper\nextends that study to $p-$linearized polynomials over $\\GF{p}$, i.e.,\npolynomials of the shape $$L(X)=\\sum_{i=0}^t \\alpha_i X^{p^i},\n\\alpha_i\\in\\GF{p}.$$ Given a $k$ such that $L(X)$ divides $X-X^{p^k}$, the\npreimages of $L(X)$ can be explicitly computed over $\\GF{p^n}$ for any $n$.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 06:39:55 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Kim", "Kwang Ho", ""], ["Mesnager", "Sihem", ""], ["Choe", "Jong Hyok", ""], ["Lee", "Dok Nam", ""]]}, {"id": "2011.11097", "submitter": "Songze Li", "authors": "Songze Li, David Tse", "title": "TaiJi: Longest Chain Availability with BFT Fast Confirmation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most state machine replication protocols are either based on the 40-years-old\nByzantine Fault Tolerance (BFT) theory or the more recent Nakamoto's longest\nchain design. Longest chain protocols, designed originally in the Proof-of-Work\n(PoW) setting, are available under dynamic participation, but has probabilistic\nconfirmation with long latency dependent on the security parameter. BFT\nprotocols, designed for the permissioned setting, has fast deterministic\nconfirmation, but assume a fixed number of nodes always online. We present a\nnew construction which combines a longest chain protocol and a BFT protocol to\nget the best of both worlds. Using this construction, we design TaiJi, the\nfirst dynamically available PoW protocol which has almost deterministic\nconfirmation with latency independent of the security parameter. In contrast to\nprevious hybrid approaches which use a single longest chain to sample\nparticipants to run a BFT protocol, our native PoW construction uses many\nindependent longest chains to sample propose actions and vote actions for the\nBFT protocol. This design enables TaiJi to inherit the full dynamic\navailability of Bitcoin, as well as its full unpredictability, making it secure\nagainst fully-adaptive adversaries with up to 50% of online hash power.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 20:21:20 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Li", "Songze", ""], ["Tse", "David", ""]]}, {"id": "2011.11181", "submitter": "Sitan Chen", "authors": "Sitan Chen, Xiaoxiao Li, Zhao Song, Danyang Zhuo", "title": "On InstaHide, Phase Retrieval, and Sparse Matrix Factorization", "comments": "30 pages, to appear in ICLR 2021, v2: updated discussion of follow-up\n  work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we examine the security of InstaHide, a scheme recently\nproposed by [Huang, Song, Li and Arora, ICML'20] for preserving the security of\nprivate datasets in the context of distributed learning. To generate a\nsynthetic training example to be shared among the distributed learners,\nInstaHide takes a convex combination of private feature vectors and randomly\nflips the sign of each entry of the resulting vector with probability 1/2. A\nsalient question is whether this scheme is secure in any provable sense,\nperhaps under a plausible hardness assumption and assuming the distributions\ngenerating the public and private data satisfy certain properties.\n  We show that the answer to this appears to be quite subtle and closely\nrelated to the average-case complexity of a new multi-task, missing-data\nversion of the classic problem of phase retrieval. Motivated by this\nconnection, we design a provable algorithm that can recover private vectors\nusing only the public vectors and synthetic vectors generated by InstaHide,\nunder the assumption that the private and public vectors are isotropic\nGaussian.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 02:47:08 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 00:08:38 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Chen", "Sitan", ""], ["Li", "Xiaoxiao", ""], ["Song", "Zhao", ""], ["Zhuo", "Danyang", ""]]}, {"id": "2011.11202", "submitter": "Marcel Keller", "authors": "Marcel Keller and Ke Sun", "title": "Effectiveness of MPC-friendly Softmax Replacement", "comments": "6 pages, PPML/PriML workshop at NeurIPS 2020; updated accuracy\n  figures after bug fix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Softmax is widely used in deep learning to map some representation to a\nprobability distribution. As it is based on exp/log functions that are\nrelatively expensive in multi-party computation, Mohassel and Zhang (2017)\nproposed a simpler replacement based on ReLU to be used in secure computation.\nHowever, we could not reproduce the accuracy they reported for training on\nMNIST with three fully connected layers. Later works (e.g., Wagh et al., 2019\nand 2021) used the softmax replacement not for computing the output probability\ndistribution but for approximating the gradient in back-propagation. In this\nwork, we analyze the two uses of the replacement and compare them to softmax,\nboth in terms of accuracy and cost in multi-party computation. We found that\nthe replacement only provides a significant speed-up for a one-layer network\nwhile it always reduces accuracy, sometimes significantly. Thus we conclude\nthat its usefulness is limited and one should use the original softmax function\ninstead.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 04:14:32 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 12:32:48 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Keller", "Marcel", ""], ["Sun", "Ke", ""]]}, {"id": "2011.11212", "submitter": "James Bartusek", "authors": "James Bartusek, Andrea Coladangelo, Dakshita Khurana, Fermi Ma", "title": "On The Round Complexity of Two-Party Quantum Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the round complexity of maliciously-secure two-party quantum\ncomputation (2PQC) with setup, and obtain the following results:\n  - A three-message protocol (two-message if only one party receives output) in\nthe common random string (CRS) model assuming classical two-message oblivious\ntransfer (OT) with post-quantum malicious security. This round complexity is\noptimal for the sequential communication setting. Under the additional\nassumption of reusable malicious designated-verifier non-interactive\nzero-knowledge (MDV-NIZK) arguments for NP, our techniques give an MDV-NIZK for\nQMA. Each of the assumptions mentioned above is known from the quantum hardness\nof learning with errors (QLWE).\n  - A protocol with two simultaneous rounds of communication, in a quantum\npreprocessing model, assuming sub-exponential QLWE. In fact, we construct a\nthree-round protocol in the CRS model with only two rounds of online\ncommunication, which implies the above result. Along the way, we develop a new\ndelayed simulation technique that we call \"simulation via teleportation,\" which\nmay be useful in other settings.\n  In addition, we perform a preliminary investigation into barriers and\npossible approaches for two-round 2PQC in the CRS model, including an\nimpossibility result for a natural class of simulators, and a proof-of-concept\nconstruction from a strong form of quantum virtual black-box (VBB) obfuscation.\n  Prior to our work, maliciously-secure 2PQC required round complexity linear\nin the size of the quantum circuit.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 05:20:28 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 04:02:10 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Bartusek", "James", ""], ["Coladangelo", "Andrea", ""], ["Khurana", "Dakshita", ""], ["Ma", "Fermi", ""]]}, {"id": "2011.11487", "submitter": "Masoud Nosrati", "authors": "Masoud Nosrati and Ying Cai", "title": "Verifying the Correctness of Analytic Query Results", "comments": "IEEE Transactions on Knowledge and Data Engineering (12 Pages)", "journal-ref": null, "doi": "10.1109/TKDE.2020.3037313", "report-no": null, "categories": "cs.DB cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data outsourcing is a cost-effective solution for data owners to tackle\nissues such as large volumes of data, huge number of users, and intensive\ncomputation needed for data analysis. They can simply upload their databases to\na cloud and let it perform all management works, including query processing.\nOne problem with this service model is how query issuers can verify the query\nresults they receive are indeed correct. This concern is legitimate because, as\na third party, clouds may not be fully trustworthy, and as a large data center,\nclouds are ideal targets for hackers. There has been significant work on query\nresult verification, but most consider only simple queries where query results\ncan be attained by checking the raw data against the query conditions directly.\nIn this paper, we consider the problem of enabling users to verify the\ncorrectness of the results of analytic queries. Unlike simple queries, analytic\nqueries involve ranking functions to score a database, which makes it difficult\nto build data structures for verification purposes. We propose two approaches,\nnamely one-signature and multi-signature, and show that they work well on three\nrepresentative types of analytic queries, including top-k, range, and KNN\nqueries, through both analysis and experiments.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 14:09:12 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Nosrati", "Masoud", ""], ["Cai", "Ying", ""]]}, {"id": "2011.11558", "submitter": "Jos\\'e Antonio Perusqu\\'ia Cort\\'es", "authors": "Jos\\'e A. Perusqu\\'ia and Jim E. Griffin and Cristiano Villa", "title": "On a Bayesian Approach to Malware Detection and Classification through\n  $n$-gram Profiles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.CR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting and correctly classifying malicious executables has become one of\nthe major concerns in cyber security, especially because traditional detection\nsystems have become less effective with the increasing number and danger of\nthreats found nowadays. One way to differentiate benign from malicious\nexecutables is to leverage on their hexadecimal representation by creating a\nset of binary features that completely characterise each executable. In this\npaper we present a novel supervised learning Bayesian nonparametric approach\nfor binary matrices, that provides an effective probabilistic approach for\nmalware detection. Moreover, and due to the model's flexible assumptions, we\nare able to use it in a multi-class framework where the interest relies in\nclassifying malware into known families. Finally, a generalisation of the model\nwhich provides a deeper understanding of the behaviour across groups for each\nfeature is also developed.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 17:12:34 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Perusqu\u00eda", "Jos\u00e9 A.", ""], ["Griffin", "Jim E.", ""], ["Villa", "Cristiano", ""]]}, {"id": "2011.11632", "submitter": "Faiq Khalid", "authors": "Faiq Khalid, Syed Rafay Hasan, Sara Zia, Osman Hasan, Falah Awwad,\n  Muhammad Shafique", "title": "MacLeR: Machine Learning-based Run-Time Hardware Trojan Detection in\n  Resource-Constrained IoT Edge Devices", "comments": null, "journal-ref": "IEEE Transactions on Computer-Aided Design of Integrated Circuits\n  and Systems ( Volume: 39, Issue: 11, Nov. 2020)", "doi": "10.1109/TCAD.2020.3012236", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional learning-based approaches for run-time Hardware Trojan detection\nrequire complex and expensive on-chip data acquisition frameworks and thus\nincur high area and power overhead. To address these challenges, we propose to\nleverage the power correlation between the executing instructions of a\nmicroprocessor to establish a machine learning-based run-time Hardware Trojan\n(HT) detection framework, called MacLeR. To reduce the overhead of data\nacquisition, we propose a single power-port current acquisition block using\ncurrent sensors in time-division multiplexing, which increases accuracy while\nincurring reduced area overhead. We have implemented a practical solution by\nanalyzing multiple HT benchmarks inserted in the RTL of a system-on-chip (SoC)\nconsisting of four LEON3 processors integrated with other IPs like vga_lcd,\nRSA, AES, Ethernet, and memory controllers. Our experimental results show that\ncompared to state-of-the-art HT detection techniques, MacLeR achieves 10\\%\nbetter HT detection accuracy (i.e., 96.256%) while incurring a 7x reduction in\narea and power overhead (i.e., 0.025% of the area of the SoC and <0.07% of the\npower of the SoC). In addition, we also analyze the impact of process variation\nand aging on the extracted power profiles and the HT detection accuracy of\nMacLeR. Our analysis shows that variations in fine-grained power profiles due\nto the HTs are significantly higher compared to the variations in fine-grained\npower profiles caused by the process variations (PV) and aging effects.\nMoreover, our analysis demonstrates that, on average, the HT detection accuracy\ndrop in MacLeR is less than 1% and 9% when considering only PV and PV with\nworst-case aging, respectively, which is ~10x less than in the case of the\nstate-of-the-art ML-based HT detection technique.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 00:45:25 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Khalid", "Faiq", ""], ["Hasan", "Syed Rafay", ""], ["Zia", "Sara", ""], ["Hasan", "Osman", ""], ["Awwad", "Falah", ""], ["Shafique", "Muhammad", ""]]}, {"id": "2011.11637", "submitter": "Ilia Shumailov", "authors": "Yiren Zhao, Ilia Shumailov, Robert Mullins and Ross Anderson", "title": "Nudge Attacks on Point-Cloud DNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The wide adaption of 3D point-cloud data in safety-critical applications such\nas autonomous driving makes adversarial samples a real threat. Existing\nadversarial attacks on point clouds achieve high success rates but modify a\nlarge number of points, which is usually difficult to do in real-life\nscenarios. In this paper, we explore a family of attacks that only perturb a\nfew points of an input point cloud, and name them nudge attacks. We demonstrate\nthat nudge attacks can successfully flip the results of modern point-cloud\nDNNs. We present two variants, gradient-based and decision-based, showing their\neffectiveness in white-box and grey-box scenarios. Our extensive experiments\nshow nudge attacks are effective at generating both targeted and untargeted\nadversarial point clouds, by changing a few points or even a single point from\nthe entire point-cloud input. We find that with a single point we can reliably\nthwart predictions in 12--80% of cases, whereas 10 points allow us to further\nincrease this to 37--95%. Finally, we discuss the possible defenses against\nsuch attacks, and explore their limitations.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 18:04:02 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Zhao", "Yiren", ""], ["Shumailov", "Ilia", ""], ["Mullins", "Robert", ""], ["Anderson", "Ross", ""]]}, {"id": "2011.11660", "submitter": "Florian Tram\\`er", "authors": "Florian Tram\\`er and Dan Boneh", "title": "Differentially Private Learning Needs Better Features (or Much More\n  Data)", "comments": "ICLR 2021. Code available at\n  https://github.com/ftramer/Handcrafted-DP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that differentially private machine learning has not yet\nreached its \"AlexNet moment\" on many canonical vision tasks: linear models\ntrained on handcrafted features significantly outperform end-to-end deep neural\nnetworks for moderate privacy budgets. To exceed the performance of handcrafted\nfeatures, we show that private learning requires either much more private data,\nor access to features learned on public data from a similar domain. Our work\nintroduces simple yet strong baselines for differentially private learning that\ncan inform the evaluation of future progress in this area.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 19:00:52 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 18:17:16 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 02:56:42 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Tram\u00e8r", "Florian", ""], ["Boneh", "Dan", ""]]}, {"id": "2011.11749", "submitter": "Thomas Gross", "authors": "Thomas Gro{\\ss}", "title": "Validity and Reliability of the Scale Internet Users' Information\n  Privacy Concern (IUIPC) [Extended Version]", "comments": "Open Science Framework: https://osf.io/5pywm, 59 pages. This work was\n  supported by the ERC Grant CASCAde (GA no 716980)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Internet Users' Information Privacy Concerns (IUIPC-10) is one of the most\nendorsed privacy concern scales. It is widely used in the evaluation of human\nfactors of PETs and the investigation of the privacy paradox. Even though its\npredecessor Concern For Information Privacy (CFIP) has been evaluated\nindependently and the instrument itself seen some scrutiny, we are still\nmissing a dedicated confirmation of IUIPC-10, itself. We aim at closing this\ngap by systematically analyzing IUIPC's construct validity and reliability. We\nobtained three mutually independent samples with a total of $N = 1031$\nparticipants. We conducted a confirmatory factor analysis (CFA) on our main\nsample. Having found weaknesses, we established further factor analyses to\nassert the dimensionality of IUIPC-10. We proposed a respecified instrument\nIUIPC-8 with improved psychometric properties. Finally, we validated our\nfindings on a validation sample. While we could confirm the overall\nthree-dimensionality of IUIPC-10, we found that IUIPC-10 consistently failed\nconstruct validity and reliability evaluations, calling into question the\nunidimensionality of its sub-scales Awareness and Control. Our respecified\nscale IUIPC-8 offers a statistically significantly better model and outperforms\nIUIPC-10's construct validity and reliability. The disconfirming evidence on\nthe construct validity raises doubts how well IUIPC-10 measures the latent\nvariable information privacy concern. The sub-par reliability could yield\nspurious and erratic results as well as attenuate relations with other latent\nvariables, such as behavior. Thereby, the instrument could confound studies of\nhuman factors of PETs or the privacy paradox, in general.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 21:49:47 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Gro\u00df", "Thomas", ""]]}, {"id": "2011.11819", "submitter": "Ming Ding Dr.", "authors": "Bo Liu, Ming Ding, Sina Shaham, Wenny Rahayu, Farhad Farokhi, Zihuai\n  Lin", "title": "When Machine Learning Meets Privacy: A Survey and Outlook", "comments": "This work is accepted by ACM Computing Surveys", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The newly emerged machine learning (e.g. deep learning) methods have become a\nstrong driving force to revolutionize a wide range of industries, such as smart\nhealthcare, financial technology, and surveillance systems. Meanwhile, privacy\nhas emerged as a big concern in this machine learning-based artificial\nintelligence era. It is important to note that the problem of privacy\npreservation in the context of machine learning is quite different from that in\ntraditional data privacy protection, as machine learning can act as both friend\nand foe. Currently, the work on the preservation of privacy and machine\nlearning (ML) is still in an infancy stage, as most existing solutions only\nfocus on privacy problems during the machine learning process. Therefore, a\ncomprehensive study on the privacy preservation problems and machine learning\nis required. This paper surveys the state of the art in privacy issues and\nsolutions for machine learning. The survey covers three categories of\ninteractions between privacy and machine learning: (i) private machine\nlearning, (ii) machine learning aided privacy protection, and (iii) machine\nlearning-based privacy attack and corresponding protection schemes. The current\nresearch progress in each category is reviewed and the key challenges are\nidentified. Finally, based on our in-depth analysis of the area of privacy and\nmachine learning, we point out future research directions in this field.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 00:52:49 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Liu", "Bo", ""], ["Ding", "Ming", ""], ["Shaham", "Sina", ""], ["Rahayu", "Wenny", ""], ["Farokhi", "Farhad", ""], ["Lin", "Zihuai", ""]]}, {"id": "2011.11877", "submitter": "Ruizhe Zhang", "authors": "Baihe Huang, Zhao Song, Runzhou Tao, Ruizhe Zhang, Danyang Zhuo", "title": "InstaHide's Sample Complexity When Mixing Two Private Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR cs.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inspired by InstaHide challenge [Huang, Song, Li and Arora'20], [Chen, Song\nand Zhuo'20] recently provides one mathematical formulation of InstaHide attack\nproblem under Gaussian images distribution. They show that it suffices to use\n$O(n_{\\mathsf{priv}}^{k_{\\mathsf{priv}} - 2/(k_{\\mathsf{priv}} + 1)})$ samples\nto recover one private image in $n_{\\mathsf{priv}}^{O(k_{\\mathsf{priv}})} +\n\\mathrm{poly}(n_{\\mathsf{pub}})$ time for any integer $k_{\\mathsf{priv}}$,\nwhere $n_{\\mathsf{priv}}$ and $n_{\\mathsf{pub}}$ denote the number of images\nused in the private and the public dataset to generate a mixed image sample.\n  Under the current setup for the InstaHide challenge of mixing two private\nimages ($k_{\\mathsf{priv}} = 2$), this means $n_{\\mathsf{priv}}^{4/3}$ samples\nare sufficient to recover a private image. In this work, we show that\n$n_{\\mathsf{priv}} \\log ( n_{\\mathsf{priv}} )$ samples are sufficient\n(information-theoretically) for recovering all the private images.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 03:41:03 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Huang", "Baihe", ""], ["Song", "Zhao", ""], ["Tao", "Runzhou", ""], ["Zhang", "Ruizhe", ""], ["Zhuo", "Danyang", ""]]}, {"id": "2011.11922", "submitter": "Jiachen Sun", "authors": "Jiachen Sun, Karl Koenig, Yulong Cao, Qi Alfred Chen, Z. Morley Mao", "title": "On Adversarial Robustness of 3D Point Cloud Classification under\n  Adaptive Attacks", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D point clouds play pivotal roles in various safety-critical applications,\nsuch as autonomous driving, which desires the underlying deep neural networks\nto be robust to adversarial perturbations. Though a few defenses against\nadversarial point cloud classification have been proposed, it remains unknown\nwhether they are truly robust to adaptive attacks. To this end, we perform the\nfirst security analysis of state-of-the-art defenses and design adaptive\nevaluations on them. Our 100% adaptive attack success rates show that current\ncountermeasures are still vulnerable. Since adversarial training (AT) is\nbelieved as the most robust defense, we present the first in-depth study\nshowing how AT behaves in point cloud classification and identify that the\nrequired symmetric function (pooling operation) is paramount to the 3D model's\nrobustness under AT. Through our systematic analysis, we find that the\ndefault-used fixed pooling (e.g., MAX pooling) generally weakens AT's\neffectiveness in point cloud classification. Interestingly, we further discover\nthat sorting-based parametric pooling can significantly improve the models'\nrobustness. Based on above insights, we propose DeepSym, a deep symmetric\npooling operation, to architecturally advance the robustness to 47.0% under AT\nwithout sacrificing nominal accuracy, outperforming the original design and a\nstrong baseline by 28.5% ($\\sim 2.6 \\times$) and 6.5%, respectively, in\nPointNet.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 06:46:38 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 18:36:44 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Sun", "Jiachen", ""], ["Koenig", "Karl", ""], ["Cao", "Yulong", ""], ["Chen", "Qi Alfred", ""], ["Mao", "Z. Morley", ""]]}, {"id": "2011.12035", "submitter": "Emmanuel Baccelli", "authors": "Gabriele Restuccia, Hannes Tschofenig, Emmanuel Baccelli", "title": "Low-Power IoT Communication Security: On the Performance of DTLS and TLS\n  1.3", "comments": null, "journal-ref": "In proceedings of IFIP/IEEE PEMWN 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarly to elsewhere on the Internet, practical security in the Internet of\nThings (IoT) is achieved by combining an array of mechanisms, at work at all\nlayers of the protocol stack, in system software, and in hardware. Standard\nprotocols such as Datagram Transport Layer Security (DTLS 1.2) and Transport\nLayer Security (TLS 1.2) are often recommended to secure communications to/from\nIoT devices. Recently, the TLS 1.3 standard was released and DTLS 1.3 is in the\nfinal stages of standardization. In this paper, we give an overview of version\n1.3 of these protocols, and we provide the first experimental comparative\nperformance analysis of different implementations and various configurations of\nthese protocols, on real IoT devices based on low-power microcontrollers. We\nshow how different implementations lead to different compromises. We measure\nand compare bytes-over-the-air, memory footprint, and energy consumption. We\nshow that, when DTLS/TLS 1.3 requires more resources than DTLS/TLS 1.2, this\nadditional overhead is quite reasonable. We also observe that, in some\nconfigurations, DTLS/TLS 1.3 actually decreases overhead and resource\nconsumption. All in all, our study indicates that there is still room to\noptimize the existing implementations of these protocols.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 11:27:39 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 07:53:57 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Restuccia", "Gabriele", ""], ["Tschofenig", "Hannes", ""], ["Baccelli", "Emmanuel", ""]]}, {"id": "2011.12040", "submitter": "Andrew Mironov", "authors": "A. M. Mironov", "title": "New method of verifying cryptographic protocols based on the process\n  model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A cryptographic protocol (CP) is a distributed algorithm designed to provide\na secure communication in an insecure environment. CPs are used, for example,\nin electronic payments, electronic voting procedures, database access systems,\netc. Errors in the CPs can lead to great financial and social damage, therefore\nit is necessary to use mathematical methods to justify the correctness and\nsafety of the CPs. In this paper, a new mathematical model of a CP is\nintroduced, which allows one to describe both the CPs and their properties. It\nis shown how, on the base of this model, it is possible to solve the problems\nof verification of CPs.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 11:34:12 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Mironov", "A. M.", ""]]}, {"id": "2011.12052", "submitter": "Projjal Gupta", "authors": "Projjal Gupta", "title": "A decentralized approach towards secure firmware updates and testing\n  over commercial IoT Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet technologies have made a paradigm shift in the fields of computing\nand data science and one such paradigm defining change is the Internet of\nThings or IoT. Nowadays, thousands of household appliances use integrated smart\ndevices which allow remote monitoring and control and also allow intensive\ncomputational work such as high end AI-integrated smart security systems with\nsustained alerts for the user. The update process of these IoT devices usually\nlack the ability of checking the security of centralized servers, which may be\ncompromised and host malicious firmware files as it is presumed that the\nservers are secure during deployment. The solution for this problem can be\nsolved using a decentralized database to hold the hashes and the firmware. This\npaper discusses the possible implications of insecure servers used to host the\nfirmwares of commercial IoT products, and aims to provide a blockchain based\ndecentralized solution to host firmware files with the property of\nimmutability, and controlled access to the firmware upload functions so as to\nstop unauthorized use. The paper sheds light over possible hardware\nimplementations and the use of cryptographically secure components in such\nsecure architecture models.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 11:59:06 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Gupta", "Projjal", ""]]}, {"id": "2011.12248", "submitter": "Nitin Pundir", "authors": "Nitin Pundir, Mark Tehranipoor, Fahim Rahman", "title": "RanStop: A Hardware-assisted Runtime Crypto-Ransomware Detection\n  Technique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Among many prevailing malware, crypto-ransomware poses a significant threat\nas it financially extorts affected users by creating denial of access via\nunauthorized encryption of their documents as well as holding their documents\nhostage and financially extorting them. This results in millions of dollars of\nannual losses worldwide. Multiple variants of ransomware are growing in number\nwith capabilities of evasion from many anti-viruses and software-only malware\ndetection schemes that rely on static execution signatures. In this paper, we\npropose a hardware-assisted scheme, called RanStop, for early detection of\ncrypto-ransomware infection in commodity processors. RanStop leverages the\ninformation of hardware performance counters embedded in the performance\nmonitoring unit in modern processors to observe micro-architectural event sets\nand detects known and unknown crypto-ransomware variants. In this paper, we\ntrain a recurrent neural network-based machine learning architecture using long\nshort-term memory (LSTM) model for analyzing micro-architectural events in the\nhardware domain when executing multiple variants of ransomware as well as\nbenign programs. We create timeseries to develop intrinsic statistical features\nusing the information of related HPCs and improve the detection accuracy of\nRanStop and reduce noise by via LSTM and global average pooling. As an early\ndetection scheme, RanStop can accurately and quickly identify ransomware within\n2ms from the start of the program execution by analyzing HPC information\ncollected for 20 timestamps each 100us apart. This detection time is too early\nfor a ransomware to make any significant damage, if none. Moreover, validation\nagainst benign programs with behavioral (sub-routine-centric) similarity with\nthat of a crypto-ransomware shows that RanStop can detect ransomware with an\naverage of 97% accuracy for fifty random trials.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 17:44:07 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Pundir", "Nitin", ""], ["Tehranipoor", "Mark", ""], ["Rahman", "Fahim", ""]]}, {"id": "2011.12329", "submitter": "Dana Naous", "authors": "Dana Naous, Manus Bonner, Mathias Humbert, Christine Legner", "title": "Towards Mass Adoption of Contact Tracing Apps -- Learning from Users'\n  Preferences to Improve App Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Contact tracing apps have become one of the main approaches to control and\nslow down the spread of COVID-19 and ease up lockdown measures. While these\napps can be very effective in stopping the transmission chain and saving lives,\ntheir adoption remains under the expected critical mass. The public debate\nabout contact tracing apps emphasizes general privacy reservations and is\nconducted at an expert level, but lacks the user perspective related to actual\ndesigns. To address this gap, we explore user preferences for contact tracing\napps using market research techniques, and specifically conjoint analysis. Our\nmain contributions are empirical insights into individual and group\npreferences, as well as insights for prescriptive design. While our results\nconfirm the privacy-preserving design of most European contact tracing apps,\nthey also provide a more nuanced understanding of acceptable features. Based on\nmarket simulation and variation analysis, we conclude that adding\ngoal-congruent features will play an important role in fostering mass adoption.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 19:08:09 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Naous", "Dana", ""], ["Bonner", "Manus", ""], ["Humbert", "Mathias", ""], ["Legner", "Christine", ""]]}, {"id": "2011.12355", "submitter": "Eyal Perry", "authors": "Eyal Perry", "title": "Lethean Attack: An Online Data Poisoning Technique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data poisoning is an adversarial scenario where an attacker feeds a specially\ncrafted sequence of samples to an online model in order to subvert learning. We\nintroduce Lethean Attack, a novel data poisoning technique that induces\ncatastrophic forgetting on an online model. We apply the attack in the context\nof Test-Time Training, a modern online learning framework aimed for\ngeneralization under distribution shifts. We present the theoretical rationale\nand empirically compare it against other sample sequences that naturally induce\nforgetting. Our results demonstrate that using lethean attacks, an adversary\ncould revert a test-time training model back to coin-flip accuracy performance\nusing a short sample sequence.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 20:23:12 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Perry", "Eyal", ""]]}, {"id": "2011.12423", "submitter": "Hatem Hajri", "authors": "Manon C\\'esaire, Hatem Hajri, Sylvain Lamprier, and Patrick Gallinari", "title": "Stochastic sparse adversarial attacks", "comments": "The link to the codes is given:\n  https://github.com/SSAA3/stochastic-sparse-adv-attacks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces stochastic sparse adversarial attacks (SSAA), simple,\nfast and purely noise-based targeted and untargeted $L_0$ attacks of neural\nnetwork classifiers (NNC). SSAA are devised by exploiting a simple small-time\nexpansion idea widely used for Markov processes and offer new examples of $L_0$\nattacks whose studies have been limited. They are designed to solve the known\nscalability issue of the family of Jacobian-based saliency maps attacks to\nlarge datasets and they succeed in solving it. Experiments on small and large\ndatasets (CIFAR-10 and ImageNet) illustrate further advantages of SSAA in\ncomparison with the-state-of-the-art methods. For instance, in the untargeted\ncase, our method called Voting Folded Gaussian Attack (VFGA) scales efficiently\nto ImageNet and achieves a significantly lower $L_0$ score than SparseFool (up\nto $\\frac{2}{5}$ lower) while being faster. Moreover, VFGA achieves better\n$L_0$ scores on ImageNet than Sparse-RS when both attacks are fully successful\non a large number of samples. Codes are publicly available through the link\nhttps://github.com/SSAA3/stochastic-sparse-adv-attacks\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 22:07:51 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2021 22:02:27 GMT"}, {"version": "v3", "created": "Tue, 27 Jul 2021 10:51:29 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["C\u00e9saire", "Manon", ""], ["Hajri", "Hatem", ""], ["Lamprier", "Sylvain", ""], ["Gallinari", "Patrick", ""]]}, {"id": "2011.12546", "submitter": "Muna Al-Hawawreh", "authors": "Muna Al-Hawawreh, Elena Sitnikovas", "title": "Developing a Security Testbed for Industrial Internet of Things", "comments": null, "journal-ref": null, "doi": "10.1109/JIOT.2020.3032093", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While achieving security for Industrial Internet of Things (IIoT) is a\ncritical and non-trivial task, more attention is required for brownfield IIoT\nsystems. This is a consequence of long life cycles of their legacy devices\nwhich were initially designed without considering security and IoT\nconnectivity, but they are now becoming more connected and integrated with\nemerging IoT technologies and messaging communication protocols. Deploying\ntoday's methodologies and solutions in brownfield IIoT systems is not viable,\nas security solutions must co-exist and fit these systems requirements. This\nnecessitates a realistic standardized IIoT testbed that can be used as an\noptimal format to measure the credibility of security solutions of IIoT\nnetworks, analyze IIoT attack landscapes and extract threat intelligence.\nDeveloping a testbed for brownfield IIoT systems is considered a significant\nchallenge as these systems are comprised of legacy, heterogeneous devices,\ncommunication layers and applications that need to be implemented holistically\nto achieve high fidelity. In this paper, we propose a new generic end-to-end\nIIoT security testbed, with a particular focus on the brownfield system and\nprovide details of the testbed's architectural design and the implementation\nprocess. The proposed testbed can be easily reproduced and reconfigured to\nsupport the testing activities of new processes and various security scenarios.\nThe proposed testbed operation is demonstrated on different connected devices,\ncommunication protocols and applications. The experiments demonstrate that this\ntestbed is effective in terms of its operation and security testing. A\ncomparison with existing testbeds, including a table of features is provided.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 06:50:02 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Al-Hawawreh", "Muna", ""], ["Sitnikovas", "Elena", ""]]}, {"id": "2011.12623", "submitter": "Hangyu Zhu", "authors": "Hangyu Zhu, Rui Wang, Yaochu Jin, Kaitai Liang and Jianting Ning", "title": "Distributed Additive Encryption and Quantization for Privacy Preserving\n  Federated Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Homomorphic encryption is a very useful gradient protection technique used in\nprivacy preserving federated learning. However, existing encrypted federated\nlearning systems need a trusted third party to generate and distribute key\npairs to connected participants, making them unsuited for federated learning\nand vulnerable to security risks. Moreover, encrypting all model parameters is\ncomputationally intensive, especially for large machine learning models such as\ndeep neural networks. In order to mitigate these issues, we develop a\npractical, computationally efficient encryption based protocol for federated\ndeep learning, where the key pairs are collaboratively generated without the\nhelp of a third party. By quantization of the model parameters on the clients\nand an approximated aggregation on the server, the proposed method avoids\nencryption and decryption of the entire model. In addition, a threshold based\nsecret sharing technique is designed so that no one can hold the global private\nkey for decryption, while aggregated ciphertexts can be successfully decrypted\nby a threshold number of clients even if some clients are offline. Our\nexperimental results confirm that the proposed method significantly reduces the\ncommunication costs and computational complexity compared to existing encrypted\nfederated learning without compromising the performance and security.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 10:23:42 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Zhu", "Hangyu", ""], ["Wang", "Rui", ""], ["Jin", "Yaochu", ""], ["Liang", "Kaitai", ""], ["Ning", "Jianting", ""]]}, {"id": "2011.12644", "submitter": "Luis F. Abanto-Leon", "authors": "Luis F. Abanto-Leon and Andreas Baeuml and Gek Hong (Allyson) Sim and\n  Matthias Hollick and Arash Asadi", "title": "Stay Connected, Leave no Trace: Enhancing Security and Privacy in WiFi\n  via Obfuscating Radiometric Fingerprints", "comments": "ACM Sigmetrics 2021 / In Proc. ACM Meas. Anal. Comput. Syst., Vol. 4,\n  3, Article 44 (December 2020)", "journal-ref": null, "doi": "10.1145/3428329", "report-no": null, "categories": "cs.CR cs.CY cs.NI cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The intrinsic hardware imperfection of WiFi chipsets manifests itself in the\ntransmitted signal, leading to a unique radiometric fingerprint. This\nfingerprint can be used as an additional means of authentication to enhance\nsecurity. In fact, recent works propose practical fingerprinting solutions that\ncan be readily implemented in commercial-off-the-shelf devices. In this paper,\nwe prove analytically and experimentally that these solutions are highly\nvulnerable to impersonation attacks. We also demonstrate that such a unique\ndevice-based signature can be abused to violate privacy by tracking the user\ndevice, and, as of today, users do not have any means to prevent such privacy\nattacks other than turning off the device.\n  We propose RF-Veil, a radiometric fingerprinting solution that not only is\nrobust against impersonation attacks but also protects user privacy by\nobfuscating the radiometric fingerprint of the transmitter for non-legitimate\nreceivers. Specifically, we introduce a randomized pattern of phase errors to\nthe transmitted signal such that only the intended receiver can extract the\noriginal fingerprint of the transmitter. In a series of experiments and\nanalyses, we expose the vulnerability of adopting naive randomization to\nstatistical attacks and introduce countermeasures. Finally, we show the\nefficacy of RF-Veil experimentally in protecting user privacy and enhancing\nsecurity. More importantly, our proposed solution allows communicating with\nother devices, which do not employ RF-Veil.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 11:10:59 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 12:25:18 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Abanto-Leon", "Luis F.", "", "Allyson"], ["Baeuml", "Andreas", "", "Allyson"], ["Hong", "Gek", "", "Allyson"], ["Sim", "", ""], ["Hollick", "Matthias", ""], ["Asadi", "Arash", ""]]}, {"id": "2011.12709", "submitter": "Andrew McGough", "authors": "Amir Atapour-Abarghouei, Andrew Stephen McGough, David Stanley Wall", "title": "Resolving the cybersecurity Data Sharing Paradox to scale up\n  cybersecurity via a co-production approach towards data sharing", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As cybercriminals scale up their operations to increase their profits or\ninflict greater harm, we argue that there is an equal need to respond to their\nthreats by scaling up cybersecurity. To achieve this goal, we have to develop a\nco-productive approach towards data collection and sharing by overcoming the\ncybersecurity data sharing paradox. This is where we all agree on the\ndefinition of the problem and end goal (improving cybersecurity and getting rid\nof cybercrime), but we disagree about how to achieve it and fail to work\ntogether efficiently. At the core of this paradox is the observation that\npublic interests differ from private interests. As a result, industry and law\nenforcement take different approaches to the cybersecurity problem as they seek\nto resolve incidents in their own interests, which manifests in different data\nsharing practices between both and also other interested parties, such as\ncybersecurity researchers. The big question we ask is can these interests be\nreconciled to develop an interdisciplinary approach towards co-operation and\nsharing data. In essence, all three will have to co-own the problem in order to\nco-produce a solution. We argue that a few operational models with good\npractices exist that provide guides to a possible solution, especially multiple\nthird-party ownership organisations which consolidate, anonymise and analyse\ndata. To take this forward, we suggest the practical solution of organising\nco-productive data collection on a sectoral basis, but acknowledge that common\nstandards for data collection will also have to be developed and agreed upon.\nWe propose an initial set of best practices for building collaborations and\nsharing data and argue that these best practices need to be developed and\nstandardised in order to mitigate the paradox.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 22:23:31 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Atapour-Abarghouei", "Amir", ""], ["McGough", "Andrew Stephen", ""], ["Wall", "David Stanley", ""]]}, {"id": "2011.12713", "submitter": "Nima Safari", "authors": "N. Safari, S.M. Mazhari, C.Y. Chung, S.B. Ko", "title": "A Secure Deep Probabilistic Dynamic Thermal Line Rating Prediction", "comments": "The work is accepted for publication in Journal of Modern Power\n  Systems and Clean Energy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Accurate short-term prediction of overhead line (OHL) transmission ampacity\ncan directly affect the efficiency of power system operation and planning. Any\noverestimation of the dynamic thermal line rating (DTLR) can lead to lifetime\ndegradation and failure of OHLs, safety hazards, etc. This paper presents a\nsecure yet sharp probabilistic prediction model for the hour-ahead forecasting\nof the DTLR. The security of the proposed DTLR limits the frequency of DTLR\nprediction exceeding the actual DTLR. The model is based on an augmented deep\nlearning architecture that makes use of a wide range of predictors, including\nhistorical climatology data and latent variables obtained during DTLR\ncalculation. Furthermore, by introducing a customized cost function, the deep\nneural network is trained to consider the DTLR security based on the required\nprobability of exceedance while minimizing deviations of the predicted DTLRs\nfrom the actual values. The proposed probabilistic DTLR is developed and\nverified using recorded experimental data. The simulation results validate the\nsuperiority of the proposed DTLR compared to state-of-the-art prediction models\nusing well-known evaluation metrics.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 23:20:58 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Safari", "N.", ""], ["Mazhari", "S. M.", ""], ["Chung", "C. Y.", ""], ["Ko", "S. B.", ""]]}, {"id": "2011.12720", "submitter": "Rui Shu", "authors": "Rui Shu, Tianpei Xia, Laurie Williams, Tim Menzies", "title": "Omni: Automated Ensemble with Unexpected Models against Adversarial\n  Evasion Attack", "comments": "Submitted to EMSE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BACKGROUND: Machine learning-based security detection models have become\nprevalent in modern malware and intrusion detection systems. However, previous\nstudies show that such models are susceptible to adversarial evasion attacks.\nIn this type of attack, inputs (i.e., adversarial examples) are specially\ncrafted by intelligent malicious adversaries, with the aim of being\nmisclassified by existing state-of-the-art models (e.g., deep neural networks).\nOnce the attackers can fool a classifier to think that a malicious input is\nactually benign, they can render a machine learning-based malware or intrusion\ndetection system ineffective.\n  GOAL: To help security practitioners and researchers build a more robust\nmodel against adversarial evasion attack through the use of ensemble learning.\n  METHOD: We propose an approach called OMNI, the main idea of which is to\nexplore methods that create an ensemble of \"unexpected models\"; i.e., models\nwhose control hyperparameters have a large distance to the hyperparameters of\nan adversary's target model, with which we then make an optimized weighted\nensemble prediction.\n  RESULTS: In studies with five adversarial evasion attacks (FGSM, BIM, JSMA,\nDeepFool and Carlini-Wagner) on five security datasets (NSL-KDD, CIC-IDS-2017,\nCSE-CIC-IDS2018, CICAndMal2017 and the Contagio PDF dataset), we show that the\nimprovement rate of OMNI's prediction accuracy over attack accuracy is about\n53% (median value) across all datasets, with about 18% (median value) loss rate\nwhen comparing pre-attack accuracy and OMNI's prediction accuracy.\n  CONCLUSIONWhen using ensemble learning as a defense method against\nadversarial evasion attacks, we suggest to create ensemble with unexpected\nmodels who are distant from the attacker's expected model (i.e., target model)\nthrough methods such as hyperparameter optimization.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 20:02:40 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Shu", "Rui", ""], ["Xia", "Tianpei", ""], ["Williams", "Laurie", ""], ["Menzies", "Tim", ""]]}, {"id": "2011.12729", "submitter": "Vladimir Yussupov", "authors": "Vladimir Yussupov and Ghareeb Falazi and Uwe Breitenb\\\"ucher and Frank\n  Leymann", "title": "On the Serverless Nature of Blockchains and Smart Contracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although historically the term serverless was also used in the context of\npeer-to-peer systems, it is more frequently associated with the architectural\nstyle for developing cloud-native applications. From the developer's\nperspective, serverless architectures allow reducing management efforts since\napplications are composed using provider-managed components, e.g.,\nDatabase-as-a-Service (DBaaS) and Function-as-a-Service (FaaS) offerings.\nBlockchains are distributed systems designed to enable collaborative scenarios\ninvolving multiple untrusted parties. It seems that the decentralized\npeer-to-peer nature of blockchains makes it interesting to consider them in\nserverless architectures, since resource allocation and management tasks are\nnot required to be performed by users. Moreover, considering their useful\nproperties of ensuring transaction's immutability and facilitating accountable\ninteractions, blockchains might enhance the overall guarantees and capabilities\nof serverless architectures. Therefore, in this work, we analyze how the\nblockchain technology and smart contracts fit into the serverless picture and\nderive a set of scenarios in which they act as different component types in\nserverless architectures. Furthermore, we formulate the implementation\nrequirements that have to be fulfilled to successfully use blockchains and\nsmart contracts in these scenarios. Finally, we investigate which existing\ntechnologies enable these scenarios, and analyze their readiness and\nsuitability to fulfill the formulated requirements.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 10:51:56 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Yussupov", "Vladimir", ""], ["Falazi", "Ghareeb", ""], ["Breitenb\u00fccher", "Uwe", ""], ["Leymann", "Frank", ""]]}, {"id": "2011.12783", "submitter": "Peter Robinson", "authors": "Peter Robinson, Raghavendra Ramesh", "title": "General Purpose Atomic Crosschain Transactions", "comments": "9 pages, 3 figures. arXiv admin note: substantial text overlap with\n  arXiv:2005.09790", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The General Purpose Atomic Crosschain Transaction protocol allows composable\nprogramming across multiple Ethereum blockchains. It allows for inter-contract\nand inter-blockchain function calls that are both synchronous and atomic: if\none part fails, the whole call execution tree of function calls is rolled back.\nThe protocol operates on existing Ethereum blockchains without modification. It\nworks for both public permissioned and consortium blockchains. Additionally,\nthe protocol is expected to work across heterogeneous blockchains other than\nEthereum. This paper describes the protocol, analyses it in terms of Gas usage\nand Finalised Block Periods for three scenarios: reading a value from one\nblockchain to another, writing a value from one blockchain to another, and a\ntrade finance system involving five contracts on five blockchains with a\ncomplex call execution tree, and provides an initial security analysis that\nshows that the protocol has Safety and Liveness properties.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 01:37:01 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 07:48:35 GMT"}, {"version": "v3", "created": "Sat, 6 Mar 2021 01:18:10 GMT"}, {"version": "v4", "created": "Sun, 4 Jul 2021 22:11:39 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Robinson", "Peter", ""], ["Ramesh", "Raghavendra", ""]]}, {"id": "2011.12807", "submitter": "Thibault Maho", "authors": "Thibault Maho, Teddy Furon, Erwan Le Merrer", "title": "SurFree: a fast surrogate-free black-box attack", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning classifiers are critically prone to evasion attacks.\nAdversarial examples are slightly modified inputs that are then misclassified,\nwhile remaining perceptively close to their originals. Last couple of years\nhave witnessed a striking decrease in the amount of queries a black box attack\nsubmits to the target classifier, in order to forge adversarials. This\nparticularly concerns the black-box score-based setup, where the attacker has\naccess to top predicted probabilites: the amount of queries went from to\nmillions of to less than a thousand. This paper presents SurFree, a geometrical\napproach that achieves a similar drastic reduction in the amount of queries in\nthe hardest setup: black box decision-based attacks (only the top-1 label is\navailable). We first highlight that the most recent attacks in that setup,\nHSJA, QEBA and GeoDA all perform costly gradient surrogate estimations. SurFree\nproposes to bypass these, by instead focusing on careful trials along diverse\ndirections, guided by precise indications of geometrical properties of the\nclassifier decision boundaries. We motivate this geometric approach before\nperforming a head-to-head comparison with previous attacks with the amount of\nqueries as a first class citizen. We exhibit a faster distortion decay under\nlow query amounts (few hundreds to a thousand), while remaining competitive at\nhigher query budgets.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 15:08:19 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Maho", "Thibault", ""], ["Furon", "Teddy", ""], ["Merrer", "Erwan Le", ""]]}, {"id": "2011.12902", "submitter": "Ivan Evtimov", "authors": "Ivan Evtimov, Russel Howes, Brian Dolhansky, Hamed Firooz, Cristian\n  Canton Ferrer", "title": "Adversarial Evaluation of Multimodal Models under Realistic Gray Box\n  Assumption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work examines the vulnerability of multimodal (image + text) models to\nadversarial threats similar to those discussed in previous literature on\nunimodal (image- or text-only) models. We introduce realistic assumptions of\npartial model knowledge and access, and discuss how these assumptions differ\nfrom the standard \"black-box\"/\"white-box\" dichotomy common in current\nliterature on adversarial attacks. Working under various levels of these\n\"gray-box\" assumptions, we develop new attack methodologies unique to\nmultimodal classification and evaluate them on the Hateful Memes Challenge\nclassification task. We find that attacking multiple modalities yields stronger\nattacks than unimodal attacks alone (inducing errors in up to 73% of cases),\nand that the unimodal image attacks on multimodal classifiers we explored were\nstronger than character-based text augmentation attacks (inducing errors on\naverage in 45% and 30% of cases, respectively).\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 17:37:40 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 09:03:45 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 16:23:04 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Evtimov", "Ivan", ""], ["Howes", "Russel", ""], ["Dolhansky", "Brian", ""], ["Firooz", "Hamed", ""], ["Ferrer", "Cristian Canton", ""]]}, {"id": "2011.12978", "submitter": "Lan Wei", "authors": "Lan Wei, John Heidemann", "title": "Whac-A-Mole: Six Years of DNS Spoofing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DNS is important in nearly all interactions on the Internet. All large DNS\noperators use IP anycast, announcing servers in BGP from multiple physical\nlocations to reduce client latency and provide capacity. However, DNS is easy\nto spoof: third parties intercept and respond to queries for benign or\nmalicious purposes. Spoofing is of particular risk for services using anycast,\nsince service is already announced from multiple origins. In this paper, we\ndescribe methods to identify DNS spoofing, infer the mechanism being used, and\nidentify organizations that spoof from historical data. Our methods detect\novert spoofing and some covertly-delayed answers, although a very diligent\nadversarial spoofer can hide. We use these methods to study more than six years\nof data about root DNS servers from thousands of vantage points. We show that\nspoofing today is rare, occurring only in about 1.7% of observations. However,\nthe rate of DNS spoofing has more than doubled in less than seven years, and it\noccurs globally. Finally, we use data from B-Root DNS to validate our methods\nfor spoof detection, showing a true positive rate over 0.96. B-Root confirms\nthat spoofing occurs with both DNS injection and proxies, but proxies account\nfor nearly all spoofing we see.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 19:02:05 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Wei", "Lan", ""], ["Heidemann", "John", ""]]}, {"id": "2011.12996", "submitter": "Jayasree Sengupta", "authors": "Somnath Karmakar and Jayasree Sengupta and Sipra Das Bit", "title": "LEADER: Low Overhead Rank Attack Detection for Securing RPL based IoT", "comments": "9 pages, 9 figures, 4 tables. Accepted at 13th International\n  Conference on COMmunication Systems & NETworkS (COMSNETS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent times researchers have found several security vulnerabilities in\nthe Routing Protocol for Low power and Lossy network (RPL), amongst which rank\nattack is a predominant one causing detrimental effects on the network by\ncreating a fake topology. To address this concern, we propose a low-overhead\nrank attack detection scheme for non-storing mode of RPL used in IoT to deal\nwith both increased and decreased rank attacks. Accordingly, we have modified\nthe RPL Destination Oriented Directed Acyclic Graph (DODAG) formation algorithm\nto detect rank attacks during topology formation and maintenance. The\ndistributed module of the algorithm runs in all the participating nodes whereas\nthe centralized module runs in the sink. Unlike many existing schemes, instead\nof sending additional control message, we make the scheme low-overhead by\nsimply modifying the DAO control message. Additionally, a lightweight Message\nAuthentication Code (HMAC-LOCHA) is used to verify the integrity and\nauthenticity of the control messages exchanged between nodes and the sink. The\ncorrectness of the proposed scheme is established through a concrete proof\nusing multiple test case scenarios. Finally, the performance of the proposed\nscheme is evaluated both theoretically and through simulation in Contiki-based\nCooja simulator. Theoretical evaluation proves the energy efficiency of the\nscheme. Simulation results show that our scheme outperforms over a\nstate-of-the-art rank attack detection scheme in terms of detection accuracy,\nfalse positive or negative rate and energy consumption while also keeping\nacceptable network performance such as improved detection latency and at par\npacket delivery ratio.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 19:42:32 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Karmakar", "Somnath", ""], ["Sengupta", "Jayasree", ""], ["Bit", "Sipra Das", ""]]}, {"id": "2011.13213", "submitter": "Gabriele Costa", "authors": "Gabriele Costa and Andrea Valenza", "title": "Why Charles Can Pen-test: an Evolutionary Approach to Vulnerability\n  Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Discovering vulnerabilities in applications of real-world complexity is a\ndaunting task: a vulnerability may affect a single line of code, and yet it\ncompromises the security of the entire application. Even worse, vulnerabilities\nmay manifest only in exceptional circumstances that do not occur in the normal\noperation of the application. It is widely recognized that state-of-the-art\npenetration testing tools play a crucial role, and are routinely used, to dig\nup vulnerabilities. Yet penetration testing is still primarily a human-driven\nactivity, and its effectiveness still depends on the skills and ingenuity of\nthe security analyst driving the tool. In this paper, we propose a technique\nfor the automatic discovery of vulnerabilities in event-based systems, such as\nweb and mobile applications. Our approach is based on a collaborative,\nco-evolutionary and contract-driven search strategy that iteratively (i)\nexecutes a pool of test cases, (ii) identifies the most promising ones, and\n(iii) generates new test cases from them. The approach makes a synergistic\ncombination of evolutionary algorithms where several \"species\" contribute to\nsolving the problem: one species, the test species, evolves to find the target\ntest case, i.e., the set of instruction whose execution lead to the vulnerable\nstatement, whereas the other species, called contract species, evolve to select\nthe parameters for the procedure calls needed to trigger the vulnerability. To\nassess the effectiveness of our approach, we implemented a working prototype\nand ran it against both a case study and a benchmark web application. The\nexperimental results confirm that our tool automatically discovers and executes\na number of injection flaw attacks that are out of reach for state-of-the-art\nweb scanners.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 10:15:53 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 14:14:59 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Costa", "Gabriele", ""], ["Valenza", "Andrea", ""]]}, {"id": "2011.13240", "submitter": "Wolfgang Karl H\\\"ardle", "authors": "Min-Bin Lin, Kainat Khowaja, Cathy Yi-Hsuan Chen, Wolfgang Karl\n  H\\\"ardle", "title": "Blockchain mechanism and distributional characteristics of cryptos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR q-fin.GN", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the relationship between underlying blockchain mechanism of\ncryptocurrencies and its distributional characteristics. In addition to price,\nwe emphasise on using actual block size and block time as the operational\nfeatures of cryptos. We use distributional characteristics such as fourier\npower spectrum, moments, quantiles, global we optimums, as well as the measures\nfor long term dependencies, risk and noise to summarise the information from\ncrypto time series. With the hypothesis that the blockchain structure explains\nthe distributional characteristics of cryptos, we use characteristic based\nspectral clustering to cluster the selected cryptos into five groups. We\nscrutinise these clusters and find that indeed, the clusters of cryptos share\nsimilar mechanism such as origin of fork, difficulty adjustment frequency, and\nthe nature of block size. This paper provides crypto creators and users with a\nbetter understanding toward the connection between the blockchain protocol\ndesign and distributional characteristics of cryptos.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 11:23:30 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Lin", "Min-Bin", ""], ["Khowaja", "Kainat", ""], ["Chen", "Cathy Yi-Hsuan", ""], ["H\u00e4rdle", "Wolfgang Karl", ""]]}, {"id": "2011.13375", "submitter": "Ashish Hooda", "authors": "Athena Sayles, Ashish Hooda, Mohit Gupta, Rahul Chatterjee, Earlence\n  Fernandes", "title": "Invisible Perturbations: Physical Adversarial Examples Exploiting the\n  Rolling Shutter Effect", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Physical adversarial examples for camera-based computer vision have so far\nbeen achieved through visible artifacts -- a sticker on a Stop sign, colorful\nborders around eyeglasses or a 3D printed object with a colorful texture. An\nimplicit assumption here is that the perturbations must be visible so that a\ncamera can sense them. By contrast, we contribute a procedure to generate, for\nthe first time, physical adversarial examples that are invisible to human eyes.\nRather than modifying the victim object with visible artifacts, we modify light\nthat illuminates the object. We demonstrate how an attacker can craft a\nmodulated light signal that adversarially illuminates a scene and causes\ntargeted misclassifications on a state-of-the-art ImageNet deep learning model.\nConcretely, we exploit the radiometric rolling shutter effect in commodity\ncameras to create precise striping patterns that appear on images. To human\neyes, it appears like the object is illuminated, but the camera creates an\nimage with stripes that will cause ML models to output the attacker-desired\nclassification. We conduct a range of simulation and physical experiments with\nLEDs, demonstrating targeted attack rates up to 84%.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 16:34:47 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 02:36:24 GMT"}, {"version": "v3", "created": "Sun, 18 Apr 2021 16:21:42 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Sayles", "Athena", ""], ["Hooda", "Ashish", ""], ["Gupta", "Mohit", ""], ["Chatterjee", "Rahul", ""], ["Fernandes", "Earlence", ""]]}, {"id": "2011.13392", "submitter": "Abhishek Moitra", "authors": "Abhishek Moitra and Priyadarshini Panda", "title": "Exposing the Robustness and Vulnerability of Hybrid 8T-6T SRAM Memory\n  Architectures to Adversarial Attacks in Deep Neural Networks", "comments": "11 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning is able to solve a plethora of once impossible problems.\nHowever, they are vulnerable to input adversarial attacks preventing them from\nbeing autonomously deployed in critical applications. Several\nalgorithm-centered works have discussed methods to cause adversarial attacks\nand improve adversarial robustness of a Deep Neural Network (DNN). In this\nwork, we elicit the advantages and vulnerabilities of hybrid 6T-8T memories to\nimprove the adversarial robustness and cause adversarial attacks on DNNs. We\nshow that bit-error noise in hybrid memories due to erroneous 6T-SRAM cells\nhave deterministic behaviour based on the hybrid memory configurations (V_DD,\n8T-6T ratio). This controlled noise (surgical noise) can be strategically\nintroduced into specific DNN layers to improve the adversarial accuracy of\nDNNs. At the same time, surgical noise can be carefully injected into the DNN\nparameters stored in hybrid memory to cause adversarial attacks. To improve the\nadversarial robustness of DNNs using surgical noise, we propose a methodology\nto select appropriate DNN layers and their corresponding hybrid memory\nconfigurations to introduce the required surgical noise. Using this, we achieve\n2-8% higher adversarial accuracy without re-training against white-box attacks\nlike FGSM, than the baseline models (with no surgical noise introduced). To\ndemonstrate adversarial attacks using surgical noise, we design a novel,\nwhite-box attack on DNN parameters stored in hybrid memory banks that causes\nthe DNN inference accuracy to drop by more than 60% with over 90% confidence\nvalue. We support our claims with experiments, performed using benchmark\ndatasets-CIFAR10 and CIFAR100 on VGG19 and ResNet18 networks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 17:08:06 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Moitra", "Abhishek", ""], ["Panda", "Priyadarshini", ""]]}, {"id": "2011.13450", "submitter": "Fatemeh Tehranipoor", "authors": "Jack Edmonds and Fatemeh Tehranipoor", "title": "Attacks on Lightweight Hardware-Based Security Primitives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In today's digital age, the ease of data collection, transfer, and storage\ncontinue to shape modern society and the ways we interact with our world. The\nadvantages are numerous, but there is also an increased risk of information\nunintentionally falling into the wrong hands. Finding methods of protecting\nsensitive information at the hardware level is of utmost importance, and in\nthis paper, we aim to provide a survey on recent developments in attacks on\nlightweight hardware-based security primitives (LHSPs) designed to do just\nthat. Specifically, we provide an analysis of the attack resilience of these\nproposed LHSPs in an attempt to bring awareness to any vulnerabilities that may\nexist. We do this in the hope that it will encourage the continued development\nof attack countermeasures as well as completely new methods of data protection\nin order to prevent the discussed methods of attack from remaining viable in\nthe future. The types of LHSPs discussed include physical unclonable functions\n(PUFs) and true random number generators (TRNGs), with a primary emphasis\nplaced on PUFs.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 19:19:48 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Edmonds", "Jack", ""], ["Tehranipoor", "Fatemeh", ""]]}, {"id": "2011.13471", "submitter": "Tobias Pulls", "authors": "Tobias Pulls", "title": "Towards Effective and Efficient Padding Machines for Tor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tor recently integrated a circuit padding framework for creating padding\nmachines: defenses that work by defining state machines that inject dummy\ntraffic to protect against traffic analysis attacks like Website Fingerprinting\n(WF) attacks. In this paper, we explore the design of effective and efficient\npadding machines to defend against WF attacks. Through the use of carefully\ncrafted datasets, a circuit padding simulator, genetic programming, and manual\ntuning of padding machines we explore different aspects of what makes padding\nmachines effective and efficient defenses. Our final machine, named Interspace,\nis probabilistically-defined with a tweakable trade-off between efficiency and\neffectiveness against the state-of-the-art deep-learning WF attack Deep\nFingerprinting by Sirinam et al. We show that Interspace can be both more\neffective and efficient than WTF-PAD by Juarez et al. the padding machine that\ninspired the design of Tor's circuit padding framework. We end this paper by\nshowing how Interspace can be made less effective, identifying the promising\ntactic of probabilistically defined padding machines, and highlighting the need\nto further explore this tactic in more complex defenses.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 20:59:57 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Pulls", "Tobias", ""]]}, {"id": "2011.13486", "submitter": "James Bartusek", "authors": "James Bartusek and Andrea Coladangelo and Dakshita Khurana and Fermi\n  Ma", "title": "One-Way Functions Imply Secure Computation in a Quantum World", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that quantum-hard one-way functions imply simulation-secure quantum\noblivious transfer (QOT), which is known to suffice for secure computation of\narbitrary quantum functionalities. Furthermore, our construction only makes\nblack-box use of the quantum-hard one-way function.\n  Our primary technical contribution is a construction of extractable and\nequivocal quantum bit commitments from quantum-hard one-way functions in the\nstandard model. Instantiating the Bennet-Brassard-Cr\\'epeau-Skubiszewska\n(CRYPTO 91) framework with these commitments yields simulation-secure quantum\noblivious transfer.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 22:42:13 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Bartusek", "James", ""], ["Coladangelo", "Andrea", ""], ["Khurana", "Dakshita", ""], ["Ma", "Fermi", ""]]}, {"id": "2011.13564", "submitter": "Mingfu Xue", "authors": "Mingfu Xue, Yushu Zhang, Jian Wang, Weiqiang Liu", "title": "Intellectual Property Protection for Deep Learning Models: Taxonomy,\n  Methods, Attacks, and Evaluations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The training and creation of deep learning model is usually costly, thus it\ncan be regarded as an intellectual property (IP) of the model creator. However,\nmalicious users who obtain high-performance models may illegally copy,\nredistribute, or abuse the models without permission. To deal with such\nsecurity threats, a few deep neural networks (DNN) IP protection methods have\nbeen proposed in recent years. This paper attempts to provide a review of the\nexisting DNN IP protection works and also an outlook. First, we propose the\nfirst taxonomy for DNN IP protection methods in terms of six attributes:\nscenario, mechanism, capacity, type, function, and target models. Then, we\npresent a survey on existing DNN IP protection works in terms of the above six\nattributes, especially focusing on the challenges these methods face, whether\nthese methods can provide proactive protection, and their resistances to\ndifferent levels of attacks. After that, we analyze the potential attacks on\nDNN IP protection methods from the aspects of model modifications, evasion\nattacks, and active attacks. Besides, a systematic evaluation method for DNN IP\nprotection methods with respect to basic functional metrics, attack-resistance\nmetrics, and customized metrics for different application scenarios is given.\nLastly, future research opportunities and challenges on DNN IP protection are\npresented.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 05:42:35 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 10:10:22 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Xue", "Mingfu", ""], ["Zhang", "Yushu", ""], ["Wang", "Jian", ""], ["Liu", "Weiqiang", ""]]}, {"id": "2011.13696", "submitter": "Mingfu Xue", "authors": "Mingfu Xue, Chengxiang Yuan, Can He, Zhiyu Wu, Yushu Zhang, Zhe Liu,\n  Weiqiang Liu", "title": "Use the Spear as a Shield: A Novel Adversarial Example based\n  Privacy-Preserving Technique against Membership Inference Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the membership inference attack poses a serious threat to the\nprivacy of confidential training data of machine learning models. This paper\nproposes a novel adversarial example based privacy-preserving technique\n(AEPPT), which adds the crafted adversarial perturbations to the prediction of\nthe target model to mislead the adversary's membership inference model. The\nadded adversarial perturbations do not affect the accuracy of target model, but\ncan prevent the adversary from inferring whether a specific data is in the\ntraining set of the target model. Since AEPPT only modifies the original output\nof the target model, the proposed method is general and does not require\nmodifying or retraining the target model. Experimental results show that the\nproposed method can reduce the inference accuracy and precision of the\nmembership inference model to 50%, which is close to a random guess. Further,\nfor those adaptive attacks where the adversary knows the defense mechanism, the\nproposed AEPPT is also demonstrated to be effective. Compared with the\nstate-of-the-art defense methods, the proposed defense can significantly\ndegrade the accuracy and precision of membership inference attacks to 50%\n(i.e., the same as a random guess) while the performance and utility of the\ntarget model will not be affected.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 12:14:19 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Xue", "Mingfu", ""], ["Yuan", "Chengxiang", ""], ["He", "Can", ""], ["Wu", "Zhiyu", ""], ["Zhang", "Yushu", ""], ["Liu", "Zhe", ""], ["Liu", "Weiqiang", ""]]}, {"id": "2011.13740", "submitter": "Aditya Jyoti Paul", "authors": "Aditya Jyoti Paul", "title": "Recent Advances in Selective Image Encryption and its Indispensability\n  due to COVID-19", "comments": "6 pages, Published in IEEE RAICS 2020, see https://raics.in", "journal-ref": "2020 IEEE Recent Advances in Intelligent Computational Systems\n  (RAICS), 2020, pp. 201-206", "doi": "10.1109/RAICS51191.2020.9332513", "report-no": null, "categories": "cs.CR cs.CY cs.GR cs.IT cs.MM math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic serves as a grim reminder of the unexpected nature of\nthese outbreaks and gives rise to a unique set of research challenges in a\nvariety of fields. As people all over the world adjust to this new 'normal',\nwith most workplaces, from companies to educational institutions shifting\nonline, enormous surges in the transmission of images and videos have been\nobserved, creating record-breaking stresses on the internet backbone. At the\nsame time, maintaining the privacy and security of the users' data is of\nimmense importance, this is where fast and efficient image encryption\nalgorithms play a vital role. This paper discusses the calamitous effects of\nthe pandemic on the world population and how their changes in multimedia\nconsumption have led to an urgent need for the development and deployment of\nsecure and fast image encryption, especially selective image encryption\ntechniques. It carefully surveys the most recent advances in this field,\ndiscusses their real-world effects and finally explores some future research\navenues, to provide swift relief and recover from the disastrous effects of the\npandemic.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 14:02:54 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 02:11:48 GMT"}, {"version": "v3", "created": "Sat, 13 Feb 2021 10:21:00 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Paul", "Aditya Jyoti", ""]]}, {"id": "2011.13837", "submitter": "Massimo Bartoletti", "authors": "Massimo Bartoletti, Letterio Galletta, Maurizio Murgia", "title": "A theory of transaction parallelism in blockchains", "comments": "arXiv admin note: text overlap with arXiv:1905.04366", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized blockchain platforms have enabled the secure exchange of\ncrypto-assets without the intermediation of trusted authorities. To this\npurpose, these platforms rely on a peer-to-peer network of byzantine nodes,\nwhich collaboratively maintain an append-only ledger of transactions, called\nblockchain. Transactions represent the actions required by users, e.g. the\ntransfer of some units of crypto-currency to another user, or the execution of\na smart contract which distributes crypto-assets according to its internal\nlogic. Part of the nodes of the peer-to-peer network compete to append\ntransactions to the blockchain. To do so, they group the transactions sent by\nusers into blocks, and update their view of the blockchain state by executing\nthese transactions in the chosen order. Once a block of transactions is\nappended to the blockchain, the other nodes validate it, re-executing the\ntransactions in the same order. The serial execution of transactions does not\ntake advantage of the multi-core architecture of modern processors, so\ncontributing to limit the throughput. In this paper we develop a theory of\ntransaction parallelism for blockchains, which is based on static analysis of\ntransactions and smart contracts. We illustrate how blockchain nodes can use\nour theory to parallelize the execution of transactions. Initial experiments on\nEthereum show that our technique can improve the performance of nodes.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 17:06:11 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 18:12:31 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Bartoletti", "Massimo", ""], ["Galletta", "Letterio", ""], ["Murgia", "Maurizio", ""]]}, {"id": "2011.13925", "submitter": "Robert Ramirez", "authors": "Shun Inagaki, Robert Ramirez, Masaki Shimaoka, Kenichi Magata", "title": "Investigation on Research Ethics and Building a Benchmark", "comments": "8 pages, in Japanese (abstract is a translation). The Institute of\n  Electronics, Information and Communication Engineers, Niigata, Japan (Jan\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When dealing with leading edge cyber security research, especially when\noperating from the perspective of an attacker or a red team, it becomes\nnecessary for one to at times consider how ethics comes into play. There are\ncurrently no cyber security-specific ethics standards, which in particular is\none reason more adversarial cyber security research lags behind in Japan. In\nthis research, using machine learning and manual methods we extracted best\npractices for research ethics from past top conference papers. Using this\nknowledge we constructed an ethics knowledge base for cyber security research.\nSuch a knowledge base can be used to properly distinguish grey-area research so\nthat it is not wrongly forbidden. Using a decision tree-style user interface\nthat we created for our knowledge base, researchers may be able to efficiently\nidentify which aspects of their research require ethical consideration. In this\nwork, as a preliminary step we focused on only a portion of the areas of\nresearch covered by cyber security conferences, but our results are applicable\nto any area of research.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 09:18:03 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Inagaki", "Shun", ""], ["Ramirez", "Robert", ""], ["Shimaoka", "Masaki", ""], ["Magata", "Kenichi", ""]]}, {"id": "2011.13954", "submitter": "Chenxing Li", "authors": "Chenxing Li, Yang Yu, Andrew Chi-Chih Yao, Da Zhang, Xiliang Zhang", "title": "An authenticated and secure accounting system for international\n  emissions trading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.CR q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expanding multi-country emissions trading system is considered as crucial to\nfill the existing mitigation gap for the 2\\degree C climate target. Trustworthy\nemissions accounting is the cornerstone of such a system encompassing different\njurisdictions. However, traditional emissions measuring, reporting, and\nverification practices that support data authenticity might not be applicable\nas detailed data from large utilities and production facilities to be covered\nin the multi-country emissions trading system are usually highly sensitive and\nof severe national security concern. In this study, we propose a cryptographic\nframework for an authenticated and secure emissions accounting system that can\nresolve this data dilemma. We demonstrate that integrating a sequence of\ncryptographic protocols can preserve data authenticity and security for a\nstylized multi-country emissions trading system. We call for more research to\npromote applications of modern cryptography in future international climate\ngovernance to build trust and strengthen collaboration.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 19:00:44 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Li", "Chenxing", ""], ["Yu", "Yang", ""], ["Yao", "Andrew Chi-Chih", ""], ["Zhang", "Da", ""], ["Zhang", "Xiliang", ""]]}, {"id": "2011.13979", "submitter": "Enis Ulqinaku", "authors": "Ivo Sluganovic and Enis Ulqinaku and Aritra Dhar and Daniele Lain and\n  Srdjan Capkun and Ivan Martinovic", "title": "IntegriScreen: Visually Supervising Remote User Interactions on\n  Compromised Clients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remote services and applications that users access via their local clients\n(laptops or desktops) usually assume that, following a successful user\nauthentication at the beginning of the session, all subsequent communication\nreflects the user's intent. However, this is not true if the adversary gains\ncontrol of the client and can therefore manipulate what the user sees and what\nis sent to the remote server.\n  To protect the user's communication with the remote server despite a\npotentially compromised local client, we propose the concept of continuous\nvisual supervision by a second device equipped with a camera. Motivated by the\nrapid increase of the number of incoming devices with front-facing cameras,\nsuch as augmented reality headsets and smart home assistants, we build upon the\ncore idea that the user's actual intended input is what is shown on the\nclient's screen, despite what ends up being sent to the remote server. A\nstatically positioned camera enabled device can, therefore, continuously\nanalyze the client's screen to enforce that the client behaves honestly despite\npotentially being malicious.\n  We evaluate the present-day feasibility and deployability of this concept by\ndeveloping a fully functional prototype, running a host of experimental tests\non three different mobile devices, and by conducting a user study in which we\nanalyze participants' use of the system during various simulated attacks.\nExperimental evaluation indeed confirms the feasibility of the concept of\nvisual supervision, given that the system consistently detects over 98% of\nevaluated attacks, while study participants with little instruction detect the\nremaining attacks with high probability.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 20:05:29 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Sluganovic", "Ivo", ""], ["Ulqinaku", "Enis", ""], ["Dhar", "Aritra", ""], ["Lain", "Daniele", ""], ["Capkun", "Srdjan", ""], ["Martinovic", "Ivan", ""]]}, {"id": "2011.14024", "submitter": "Chun Ouyang", "authors": "Bemali Wickramanayake, Dakshi Kapugama Geeganage, Chun Ouyang, Yue Xu", "title": "A Survey of Online Card Payment Fraud Detection using Data Mining-based\n  Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Card payment fraud is a serious problem, and a roadblock for an optimally\nfunctioning digital economy, with cards (Debits and Credit) being the most\npopular digital payment method across the globe. Despite the occurrence of\nfraud could be relatively rare, the impact of fraud could be significant,\nespecially on the cardholder. In the research, there have been many attempts to\ndevelop methods of detecting potentially fraudulent transactions based on data\nmining techniques, predominantly exploiting the developments in the space of\nmachine learning over the last decade. This survey proposes a taxonomy based on\na review of existing research attempts and experiments, which mainly elaborates\nthe approaches taken by researchers to incorporate the (i) business impact of\nfraud (and fraud detection) into their work , (ii) the feature engineering\ntechniques that focus on cardholder behavioural profiling to separate\nfraudulent activities happening with the same card, and (iii) the adaptive\nefforts taken to address the changing nature of fraud. Further, there will be a\ncomparative performance evaluation of classification algorithms used and\nefforts of addressing class imbalance problem. Forty-five peer-reviewed papers\npublished in the domain of card fraud detection between 2009 and 2020 were\nintensively reviewed to develop this paper.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 23:07:38 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Wickramanayake", "Bemali", ""], ["Geeganage", "Dakshi Kapugama", ""], ["Ouyang", "Chun", ""], ["Xu", "Yue", ""]]}, {"id": "2011.14031", "submitter": "Fnu Devvrit", "authors": "Devvrit, Minhao Cheng, Cho-Jui Hsieh, Inderjit Dhillon", "title": "Voting based ensemble improves robustness of defensive models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing robust models against adversarial perturbations has been an active\narea of research and many algorithms have been proposed to train individual\nrobust models. Taking these pretrained robust models, we aim to study whether\nit is possible to create an ensemble to further improve robustness. Several\nprevious attempts tackled this problem by ensembling the soft-label prediction\nand have been proved vulnerable based on the latest attack methods. In this\npaper, we show that if the robust training loss is diverse enough, a simple\nhard-label based voting ensemble can boost the robust error over each\nindividual model. Furthermore, given a pool of robust models, we develop a\nprincipled way to select which models to ensemble. Finally, to verify the\nimproved robustness, we conduct extensive experiments to study how to attack a\nvoting-based ensemble and develop several new white-box attacks. On CIFAR-10\ndataset, by ensembling several state-of-the-art pre-trained defense models, our\nmethod can achieve a 59.8% robust accuracy, outperforming all the existing\ndefensive models without using additional data.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 00:08:45 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Devvrit", "", ""], ["Cheng", "Minhao", ""], ["Hsieh", "Cho-Jui", ""], ["Dhillon", "Inderjit", ""]]}, {"id": "2011.14045", "submitter": "Ran Wang", "authors": "Haojing Shen, Sihong Chen, Ran Wang and Xizhao Wang", "title": "Generalized Adversarial Examples: Attacks and Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most of the works follow such definition of adversarial example that is\nimperceptible to humans but can fool the deep neural networks (DNNs). Some\nworks find another interesting form of adversarial examples such as one which\nis unrecognizable to humans, but DNNs classify it as one class with high\nconfidence and adversarial patch. Based on this phenomenon, in this paper, from\nthe perspective of cognition of humans and machines, we propose a new\ndefinition of adversarial examples. We show that imperceptible adversarial\nexamples, unrecognizable adversarial examples, and adversarial patches are\nderivates of generalized adversarial examples. Then, we propose three types of\nadversarial attacks based on the generalized definition. Finally, we propose a\ndefence mechanism that achieves state-of-the-art performance. We construct a\nlossy compression function to filter out the redundant features generated by\nthe network. In this process, the perturbation produced by the attacker will be\nfiltered out. Therefore, the defence mechanism can effectively improve the\nrobustness of the model. The experiments show that our attack methods can\neffectively generate adversarial examples, and our defence method can\nsignificantly improve the adversarial robustness of DNNs compared with\nadversarial training. As far as we know, our defending method achieves the best\nperformance even though we do not adopt adversarial training.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 01:41:57 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Shen", "Haojing", ""], ["Chen", "Sihong", ""], ["Wang", "Ran", ""], ["Wang", "Xizhao", ""]]}, {"id": "2011.14051", "submitter": "Jing Li", "authors": "Jing Li, Ling Ren, Dongning Guo", "title": "Close Latency--Security Trade-off for the Nakamoto Consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin is a peer-to-peer electronic cash system invented by Nakamoto in\n2008. While it has attracted much research interest, its exact latency and\nsecurity properties remain open. Existing analyses provide security and latency\n(or confirmation time) guarantees that are too loose for practical use. In fact\nthe best known upper bounds are several orders of magnitude larger than a lower\nbound due to a well-known private-mining attack. This paper describes a\ncontinuous-time model for blockchains and develops a rigorous analysis that\nyields close upper and lower bounds for the latency--security trade-off. For\nexample, when the adversary controls 10\\% of the total mining power and the\nblock propagation delays are within 10 seconds, a Bitcoin block is secured with\nless than $10^{-3}$ error probability if it is confirmed after four hours, or\nwith less than $10^{-9}$ error probability if confirmed after ten hours. These\nconfirmation times are about two hours away from their corresponding lower\nbounds. To establish such close bounds, the blockchain security question is\nreduced to a race between the Poisson adversarial mining process and a renewal\nprocess formed by a certain species of honest blocks. The moment generation\nfunctions of relevant renewal times are derived in closed form. The general\nformulas from the analysis are then applied to study the latency--security\ntrade-off of several well-known proof-of-work longest-chain cryptocurrencies.\nGuidance is also provided on how to set parameters for different purposes.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 03:09:25 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 07:29:17 GMT"}, {"version": "v3", "created": "Mon, 31 May 2021 21:29:24 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Li", "Jing", ""], ["Ren", "Ling", ""], ["Guo", "Dongning", ""]]}, {"id": "2011.14067", "submitter": "Pantea Kiaei", "authors": "Pantea Kiaei, Cees-Bart Breunesse, Mohsen Ahmadi, Patrick Schaumont,\n  Jasper van Woudenberg", "title": "Rewrite to Reinforce: Rewriting the Binary to Apply Countermeasures\n  against Fault Injection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fault injection attacks can cause errors in software for malicious purposes.\nOftentimes, vulnerable points of a program are detected after its development.\nIt is therefore critical for the user of the program to be able to apply\nlast-minute security assurance to the executable file without having access to\nthe source code. In this work, we explore two methodologies based on binary\nrewriting that aid in injecting countermeasures in the binary file. The first\napproach injects countermeasures by reassembling the disassembly whereas the\nsecond approach leverages a full translation to a high-level IR and lowering\nthat back to the target architecture.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 04:37:29 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Kiaei", "Pantea", ""], ["Breunesse", "Cees-Bart", ""], ["Ahmadi", "Mohsen", ""], ["Schaumont", "Patrick", ""], ["van Woudenberg", "Jasper", ""]]}, {"id": "2011.14085", "submitter": "Ching-Chia Kao", "authors": "Ching-Chia Kao, Jhe-Bang Ko, Chun-Shien Lu", "title": "Deterministic Certification to Adversarial Attacks via Bernstein\n  Polynomial Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized smoothing has established state-of-the-art provable robustness\nagainst $\\ell_2$ norm adversarial attacks with high probability. However, the\nintroduced Gaussian data augmentation causes a severe decrease in natural\naccuracy. We come up with a question, \"Is it possible to construct a smoothed\nclassifier without randomization while maintaining natural accuracy?\". We find\nthe answer is definitely yes. We study how to transform any classifier into a\ncertified robust classifier based on a popular and elegant mathematical tool,\nBernstein polynomial. Our method provides a deterministic algorithm for\ndecision boundary smoothing. We also introduce a distinctive approach of\nnorm-independent certified robustness via numerical solutions of nonlinear\nsystems of equations. Theoretical analyses and experimental results indicate\nthat our method is promising for classifier smoothing and robustness\ncertification.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 08:27:42 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Kao", "Ching-Chia", ""], ["Ko", "Jhe-Bang", ""], ["Lu", "Chun-Shien", ""]]}, {"id": "2011.14107", "submitter": "Hui-Po Wang", "authors": "Hui-Po Wang, Ning Yu, Mario Fritz", "title": "Hijack-GAN: Unintended-Use of Pretrained, Black-Box GANs", "comments": "Accepted by CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Generative Adversarial Networks (GANs) show increasing performance and\nthe level of realism is becoming indistinguishable from natural images, this\nalso comes with high demands on data and computation. We show that\nstate-of-the-art GAN models -- such as they are being publicly released by\nresearchers and industry -- can be used for a range of applications beyond\nunconditional image generation. We achieve this by an iterative scheme that\nalso allows gaining control over the image generation process despite the\nhighly non-linear latent spaces of the latest GAN models. We demonstrate that\nthis opens up the possibility to re-use state-of-the-art, difficult to train,\npre-trained GANs with a high level of control even if only black-box access is\ngranted. Our work also raises concerns and awareness that the use cases of a\npublished GAN model may well reach beyond the creators' intention, which needs\nto be taken into account before a full public release. Code is available at\nhttps://github.com/a514514772/hijackgan.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 11:07:36 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 13:20:00 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Wang", "Hui-Po", ""], ["Yu", "Ning", ""], ["Fritz", "Mario", ""]]}, {"id": "2011.14117", "submitter": "Thomas Sutter", "authors": "Thomas Sutter", "title": "Simple Spyware: Androids Invisible Foreground Services and How to\n  (Ab)use Them", "comments": "9 pages, 2 figures, 3 listings, BlackHat Europe 2019 see\n  https://www.blackhat.com/eu-19/briefings/schedule/index.html#simple-spyware-androids-invisible-foreground-services-and-how-to-abuse-them-17738,\n  WhitePaper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  With the releases of Android Oreo and Pie, Android introduced some background\nexecution limitations for apps. Google restricted the execution of background\nservices to save energy and to prevent apps from running endlessly in the\nbackground. Moreover, access to the device's sensors was changed and a new\nconcept named foreground service has been introduced. Apps were no longer\nallowed to run background services in an idle state, preventing apps from using\nthe device's resources like the camera. These limitations, however, would not\naffect so-called foreground services because they show a permanently visible\nnotification to the user and could therefore be stopped by the user at any\ntime. Our research found out that flaws in the API exists, which allows\nstarting invisible foreground services, making the introduced limitations\nineffective. We will show that the found flaws allow attackers to use\nforeground services as a tool for spying on users.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 11:57:17 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Sutter", "Thomas", ""]]}, {"id": "2011.14159", "submitter": "Rui Morais", "authors": "Rui Morais, Paul Crocker, Simao Melo de Sousa", "title": "Delegated RingCT: faster anonymous transactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a modification to RingCT protocol with stealth addresses that\nmakes it compatible with Delegated Proof of Stake based consensus mechanisms\ncalled Delegated RingCT.\n  Our scheme has two building blocks: a customised version of an Integrated\nSignature and Encryption scheme composed of a public key encryption scheme and\ntwo signature schemes (a digital signature and a linkable ring signature); and\nnon-interactive zero knowledge proofs. We give a description of the scheme,\nsecurity proofs and a prototype implementation whose benchmarking is discussed.\n  Although Delegated RingCT doesn't have the same degree of anonymity as other\nRingCT constructions, we argue that the benefits that the compatibility with\nDPoS consensus mechanisms brings constitutes a reasonable trade-off for being\nable to develop an anonymous decentralised cryptocurrency that is faster and\nmore scalable than existing ones.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 16:17:04 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 09:52:43 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Morais", "Rui", ""], ["Crocker", "Paul", ""], ["de Sousa", "Simao Melo", ""]]}, {"id": "2011.14163", "submitter": "Steve Isaac", "authors": "Steve Isaac and Delaram Kahrobaei", "title": "A Closer Look at the Tropical Cryptography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine two public key exchange protocols proposed recently by Grigoriev\nand Shpilrain (arXiv:1811.06386), which use tropical algebra. We introduce a\nfast attack on the first protocol, and we show that the second protocol cannot\nbe implemented as described.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 16:26:39 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Isaac", "Steve", ""], ["Kahrobaei", "Delaram", ""]]}, {"id": "2011.14165", "submitter": "Massimo Bartoletti", "authors": "Massimo Bartoletti, Stefano Lande, Maurizio Murgia, Roberto Zunino", "title": "Verifying liquidity of recursive Bitcoin contracts", "comments": "arXiv admin note: text overlap with arXiv:2003.00296", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart contracts - computer protocols that regulate the exchange of\ncrypto-assets in trustless environments - have become popular with the spread\nof blockchain technologies. A landmark security property of smart contracts is\nliquidity: in a non-liquid contract, it may happen that some assets remain\nfrozen, i.e. not redeemable by anyone. The relevance of this issue is witnessed\nby recent liquidity attacks to Ethereum, which have frozen hundreds of USD\nmillions. We address the problem of verifying liquidity on BitML, a DSL for\nsmart contracts with a secure compiler to Bitcoin, featuring primitives for\ncurrency transfers, contract renegotiation and consensual recursion. Our main\nresult is a verification technique for liquidity. We first transform the\ninfinite-state semantics of BitML into a finite-state one, which focusses on\nthe behaviour of a chosen set of contracts, abstracting from the moves of the\ncontext. With respect to the chosen contracts, this abstraction is sound, i.e.\nif the abstracted contract is liquid, then also the concrete one is such. We\nthen verify liquidity by model-checking the finite-state abstraction. We\nimplement a toolchain that automatically verifies liquidity of BitML contracts\nand compiles them to Bitcoin, and we assess it through a benchmark of\nrepresentative contracts.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 16:32:54 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 08:41:38 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Bartoletti", "Massimo", ""], ["Lande", "Stefano", ""], ["Murgia", "Maurizio", ""], ["Zunino", "Roberto", ""]]}, {"id": "2011.14194", "submitter": "Thu Huong Truong", "authors": "Truong Thu Huong, Ta Phuong Bac, Dao M. Long, Bui D. Thang, Nguyen T.\n  Binh, Tran D. Luong, and Tran Kim Phuc", "title": "LocKedge: Low-Complexity Cyberattack Detection in IoT Edge Computing", "comments": "13 pages, 20 figures, submitted to IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things and its applications are becoming commonplace with more\ndevices, but always at risk of network security. It is therefore crucial for an\nIoT network design to identify attackers accurately, quickly and promptly. Many\nsolutions have been proposed, mainly concerning secure IoT architectures and\nclassification algorithms, but none of them have paid enough attention to\nreducing the complexity. Our proposal in this paper is an edge cloud\narchitecture that fulfills the detection task right at the edge layer, near the\nsource of the attacks for quick response, versatility, as well as reducing the\nworkload of the cloud. We also propose a multi attack detection mechanism\ncalled LocKedge Low Complexity Cyberattack Detection in IoT Edge Computing,\nwhich has low complexity for deployment at the edge zone while still\nmaintaining high accuracy. LocKedge is implemented in two manners: centralized\nand federated learning manners in order to verify the performance of the\narchitecture from different perspectives. The performance of our proposed\nmechanism is compared with that of other machine learning and deep learning\nmethods using the most updated BoT IoT data set. The results show that LocKedge\noutperforms other algorithms such as NN, CNN, RNN, KNN, SVM, KNN, RF and\nDecision Tree in terms of accuracy and NN in terms of complexity.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 18:49:43 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Huong", "Truong Thu", ""], ["Bac", "Ta Phuong", ""], ["Long", "Dao M.", ""], ["Thang", "Bui D.", ""], ["Binh", "Nguyen T.", ""], ["Luong", "Tran D.", ""], ["Phuc", "Tran Kim", ""]]}, {"id": "2011.14224", "submitter": "Rami Puzis", "authors": "Dor Farbiash, Rami Puzis", "title": "Cyberbiosecurity: DNA Injection Attack in Synthetic Biology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Today arbitrary synthetic DNA can be ordered online and delivered within\nseveral days. In order to regulate both intentional and unintentional\ngeneration of dangerous substances, most synthetic gene providers screen DNA\norders. A weakness in the Screening Framework Guidance for Providers of\nSynthetic Double-Stranded DNA allows screening protocols based on this guidance\nto be circumvented using a generic obfuscation procedure inspired by early\nmalware obfuscation techniques. Furthermore, accessibility and automation of\nthe synthetic gene engineering workflow, combined with insufficient\ncybersecurity controls, allow malware to interfere with biological processes\nwithin the victim's lab, closing the loop with the possibility of an exploit\nwritten into a DNA molecule presented by Ney et al. in USENIX Security'17. Here\nwe present an end-to-end cyberbiological attack, in which unwitting biologists\nmay be tricked into generating dangerous substances within their labs.\nConsequently, despite common biosecurity assumptions, the attacker does not\nneed to have physical contact with the generated substance. The most\nchallenging part of the attack, decoding of the obfuscated DNA, is executed\nwithin living cells while using primitive biological operations commonly\nemployed by biologists during in-vivo gene editing. This attack scenario\nunderlines the need to harden the synthetic DNA supply chain with protections\nagainst cyberbiological threats. To address these threats we propose an\nimproved screening protocol that takes into account in-vivo gene editing.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 22:08:16 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Farbiash", "Dor", ""], ["Puzis", "Rami", ""]]}, {"id": "2011.14341", "submitter": "Lukas Aumayr", "authors": "Lukas Aumayr, Esra Ceylan, Matteo Maffei, Pedro Moreno-Sanchez, Iosif\n  Salem and Stefan Schmid", "title": "Demand-Aware Payment Channel Networks", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper initiates the study of demand-aware payment channel networks:\noffchain cryptocurrency networks whose topology is optimized toward the demand\n(i.e., financial transactions) it currently serves. In particular, we present a\nmodel and optimization framework which allows to compute where to optimally\nestablish virtual payment channels: virtual payment channels allow to avoid\nintermediaries when routing payments, and hence to reduce fees and latency;\nhowever, establishing payment channels also comes at a cost.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 11:24:02 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Aumayr", "Lukas", ""], ["Ceylan", "Esra", ""], ["Maffei", "Matteo", ""], ["Moreno-Sanchez", "Pedro", ""], ["Salem", "Iosif", ""], ["Schmid", "Stefan", ""]]}, {"id": "2011.14365", "submitter": "Weifeng Zhu", "authors": "Jiazhu Dai, Weifeng Zhu, Xiangfeng Luo", "title": "A Targeted Universal Attack on Graph Convolutional Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-structured data exist in numerous applications in real life. As a\nstate-of-the-art graph neural network, the graph convolutional network (GCN)\nplays an important role in processing graph-structured data. However, a recent\nstudy reported that GCNs are also vulnerable to adversarial attacks, which\nmeans that GCN models may suffer malicious attacks with unnoticeable\nmodifications of the data. Among all the adversarial attacks on GCNs, there is\na special kind of attack method called the universal adversarial attack, which\ngenerates a perturbation that can be applied to any sample and causes GCN\nmodels to output incorrect results. Although universal adversarial attacks in\ncomputer vision have been extensively researched, there are few research works\non universal adversarial attacks on graph structured data. In this paper, we\npropose a targeted universal adversarial attack against GCNs. Our method\nemploys a few nodes as the attack nodes. The attack capability of the attack\nnodes is enhanced through a small number of fake nodes connected to them.\nDuring an attack, any victim node will be misclassified by the GCN as the\nattack node class as long as it is linked to them. The experiments on three\npopular datasets show that the average attack success rate of the proposed\nattack on any victim node in the graph reaches 83% when using only 3 attack\nnodes and 6 fake nodes. We hope that our work will make the community aware of\nthe threat of this type of attack and raise the attention given to its future\ndefense.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 13:19:53 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Dai", "Jiazhu", ""], ["Zhu", "Weifeng", ""], ["Luo", "Xiangfeng", ""]]}, {"id": "2011.14427", "submitter": "George Cazenavette V", "authors": "George Cazenavette, Calvin Murdock, Simon Lucey", "title": "Architectural Adversarial Robustness: The Case for Deep Pursuit", "comments": "11 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their unmatched performance, deep neural networks remain susceptible\nto targeted attacks by nearly imperceptible levels of adversarial noise. While\nthe underlying cause of this sensitivity is not well understood, theoretical\nanalyses can be simplified by reframing each layer of a feed-forward network as\nan approximate solution to a sparse coding problem. Iterative solutions using\nbasis pursuit are theoretically more stable and have improved adversarial\nrobustness. However, cascading layer-wise pursuit implementations suffer from\nerror accumulation in deeper networks. In contrast, our new method of deep\npursuit approximates the activations of all layers as a single global\noptimization problem, allowing us to consider deeper, real-world architectures\nwith skip connections such as residual networks. Experimentally, our approach\ndemonstrates improved robustness to adversarial noise.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 19:39:23 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Cazenavette", "George", ""], ["Murdock", "Calvin", ""], ["Lucey", "Simon", ""]]}, {"id": "2011.14469", "submitter": "Georgios Bakirtzis", "authors": "Cody Fleming, Carl Elks, Georgios Bakirtzis, Stephen C. Adams, Bryan\n  Carter, Peter A. Beling, Barry Horowitz", "title": "Cyber-Physical Security Through Resiliency: A Systems-centric Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical systems (CPS) are often defended in the same manner as\ninformation technology (IT) systems -- by using perimeter security. Multiple\nfactors make such defenses insufficient for CPS. Resiliency shows potential in\novercoming these shortfalls. Techniques for achieving resilience exist;\nhowever, methods and theory for evaluating resilience in CPS are lacking. We\nargue that such methods and theory should assist stakeholders in deciding where\nand how to apply design patterns for resilience. Such a problem potentially\ninvolves tradeoffs between different objectives and criteria, and such\ndecisions need to be driven by traceable, defensible, repeatable engineering\nevidence. Multi-criteria resiliency problems require a system-oriented approach\nthat evaluates systems in the presence of threats as well as potential design\nsolutions once vulnerabilities have been identified. We present a\nsystems-oriented view of cyber-physical security, termed Mission Aware, that is\nbased on a holistic understanding of mission goals, system dynamics, and risk.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 23:35:44 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Fleming", "Cody", ""], ["Elks", "Carl", ""], ["Bakirtzis", "Georgios", ""], ["Adams", "Stephen C.", ""], ["Carter", "Bryan", ""], ["Beling", "Peter A.", ""], ["Horowitz", "Barry", ""]]}, {"id": "2011.14572", "submitter": "Farhad Farokhi", "authors": "Farhad Farokhi", "title": "Gradient Sparsification Can Improve Performance of\n  Differentially-Private Convex Machine Learning", "comments": "Fixed typos and a mistake in the proof of Proposition 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use gradient sparsification to reduce the adverse effect of differential\nprivacy noise on performance of private machine learning models. To this aim,\nwe employ compressed sensing and additive Laplace noise to evaluate\ndifferentially-private gradients. Noisy privacy-preserving gradients are used\nto perform stochastic gradient descent for training machine learning models.\nSparsification, achieved by setting the smallest gradient entries to zero, can\nreduce the convergence speed of the training algorithm. However, by\nsparsification and compressed sensing, the dimension of communicated gradient\nand the magnitude of additive noise can be reduced. The interplay between these\neffects determines whether gradient sparsification improves the performance of\ndifferentially-private machine learning models. We investigate this\nanalytically in the paper. We prove that, for small privacy budgets,\ncompression can improve performance of privacy-preserving machine learning\nmodels. However, for large privacy budgets, compression does not necessarily\nimprove the performance. Intuitively, this is because the effect of\nprivacy-preserving noise is minimal in large privacy budget regime and thus\nimprovements from gradient sparsification cannot compensate for its slower\nconvergence.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 06:37:06 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 23:54:09 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Farokhi", "Farhad", ""]]}, {"id": "2011.14580", "submitter": "Thao Nguyen", "authors": "Badih Ghazi, Ravi Kumar, Pasin Manurangsi, Thao Nguyen", "title": "Robust and Private Learning of Halfspaces", "comments": "AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the trade-off between differential privacy and\nadversarial robustness under L2-perturbations in the context of learning\nhalfspaces. We prove nearly tight bounds on the sample complexity of robust\nprivate learning of halfspaces for a large regime of parameters. A highlight of\nour results is that robust and private learning is harder than robust or\nprivate learning alone. We complement our theoretical analysis with\nexperimental results on the MNIST and USPS datasets, for a learning algorithm\nthat is both differentially private and adversarially robust.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 06:59:20 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 23:20:21 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Ghazi", "Badih", ""], ["Kumar", "Ravi", ""], ["Manurangsi", "Pasin", ""], ["Nguyen", "Thao", ""]]}, {"id": "2011.14599", "submitter": "Claudio Soriente", "authors": "Jianyu Jiang, Claudio Soriente, Ghassan Karame", "title": "Monitoring Performance Metrics is not Enough to Detect Side-Channel\n  Attacks on Intel SGX", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Side-channel vulnerabilities of Intel SGX is driving the research community\ntowards designing low-overhead detection tools. The ones available to date are\ngrounded on the observation that attacks affect the performance of the victim\napplication (in terms of runtime, enclave interruptions, etc.), so they monitor\nthe potential victim and raise an alarm if the witnessed performance is\nanomalous.\n  We show that tools monitoring the performance of an enclave to detect\nside-channel attacks may not be effective. Our core intuition is that these\ntools are geared towards an adversary that interferes with the victim's\nexecution in order to extract the most number of secret bits (e.g., the entire\nsecret) in one or few runs. They cannot, however, detect an adversary that\nleaks smaller portions of the secret - as small as a single bit - at each\nexecution of the victim. In particular, by minimizing the information leaked at\neach run, the impact of the attack on the application's performance is\nsignificantly lessened, so that the detection tool notices no attack. By\nrepeating the attack multiple times, and each time leaking a different part of\nthe secret, the adversary can recover the whole secret and remain undetected.\n  Based on this intuition, we adapt attacks leveraging page-tables and L3 cache\nso to bypass available detection mechanisms. We show how an attacker can leak\nthe secret key used in an enclave running various cryptographic routines of\nlibgcrypt. Beyond cryptographic software, we also show how to leak predictions\nof enclaves running decision-tree routines of OpenCV.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 07:48:24 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Jiang", "Jianyu", ""], ["Soriente", "Claudio", ""], ["Karame", "Ghassan", ""]]}, {"id": "2011.14661", "submitter": "Yusuke Kawamoto", "authors": "Seira Hidano, Takao Murakami, Yusuke Kawamoto", "title": "TransMIA: Membership Inference Attacks Using Transfer Shadow Training", "comments": "IJCNN 2021 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Transfer learning has been widely studied and gained increasing popularity to\nimprove the accuracy of machine learning models by transferring some knowledge\nacquired in different training. However, no prior work has pointed out that\ntransfer learning can strengthen privacy attacks on machine learning models. In\nthis paper, we propose TransMIA (Transfer learning-based Membership Inference\nAttacks), which use transfer learning to perform membership inference attacks\non the source model when the adversary is able to access the parameters of the\ntransferred model. In particular, we propose a transfer shadow training\ntechnique, where an adversary employs the parameters of the transferred model\nto construct shadow models, to significantly improve the performance of\nmembership inference when a limited amount of shadow training data is available\nto the adversary. We evaluate our attacks using two real datasets, and show\nthat our attacks outperform the state-of-the-art that does not use our transfer\nshadow training technique. We also compare four combinations of the\nlearning-based/entropy-based approach and the fine-tuning/freezing approach,\nall of which employ our transfer shadow training technique. Then we examine the\nperformance of these four approaches based on the distributions of confidence\nvalues, and discuss possible countermeasures against our attacks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 10:03:43 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 13:20:40 GMT"}, {"version": "v3", "created": "Fri, 23 Apr 2021 14:50:44 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Hidano", "Seira", ""], ["Murakami", "Takao", ""], ["Kawamoto", "Yusuke", ""]]}, {"id": "2011.14754", "submitter": "Mostafa Haghi Kashani", "authors": "Sepideh Bazzaz Abkenar, Mostafa Haghi Kashani, Mohammad Akbari,\n  Ebrahim Mahdipour", "title": "Twitter Spam Detection: A Systematic Review", "comments": "18 pages, 12 figures, 14 tables, 91 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, with the rise of Internet access and mobile devices around the\nglobe, more people are using social networks for collaboration and receiving\nreal-time information. Twitter, the microblogging that is becoming a critical\nsource of communication and news propagation, has grabbed the attention of\nspammers to distract users. So far, researchers have introduced various defense\ntechniques to detect spams and combat spammer activities on Twitter. To\novercome this problem, in recent years, many novel techniques have been offered\nby researchers, which have greatly enhanced the spam detection performance.\nTherefore, it raises a motivation to conduct a systematic review about\ndifferent approaches of spam detection on Twitter. This review focuses on\ncomparing the existing research techniques on Twitter spam detection\nsystematically. Literature review analysis reveals that most of the existing\nmethods rely on Machine Learning-based algorithms. Among these Machine Learning\nalgorithms, the major differences are related to various feature selection\nmethods. Hence, we propose a taxonomy based on different feature selection\nmethods and analyses, namely content analysis, user analysis, tweet analysis,\nnetwork analysis, and hybrid analysis. Then, we present numerical analyses and\ncomparative studies on current approaches, coming up with open challenges that\nhelp researchers develop solutions in this topic.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 13:10:24 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 11:31:06 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Abkenar", "Sepideh Bazzaz", ""], ["Kashani", "Mostafa Haghi", ""], ["Akbari", "Mohammad", ""], ["Mahdipour", "Ebrahim", ""]]}, {"id": "2011.14804", "submitter": "Vipin Singh Sehrawat", "authors": "Vipin Singh Sehrawat, Foo Yee Yeo, and Yvo Desmedt", "title": "Extremal Set Theory and LWE Based Access Structure Hiding Verifiable\n  Secret Sharing with Malicious-Majority and Free Verification", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secret sharing allows distributing a secret among several parties such that\nonly authorized subsets, specified by an access structure, can reconstruct the\nsecret. Sehrawat and Desmedt (COCOON 2020) introduced hidden access structures,\nthat remain secret until some authorized subset of parties collaborate.\nHowever, their scheme assumes semi-honest parties and supports only restricted\naccess structures. We address these shortcomings by constructing an access\nstructure hiding verifiable secret sharing scheme that supports all monotone\naccess structures. It is the first secret sharing scheme to support cheater\nidentification and share verifiability in malicious-majority settings. The\nverification procedure of our scheme incurs no communication overhead. As the\nbuilding blocks of our scheme, we introduce and construct: (i) a set-system\nwith $> \\exp\\left(c\\frac{2(\\log h)^2}{(\\log\\log\nh)}\\right)+2\\exp\\left(c\\frac{(\\log h)^2}{(\\log\\log h)}\\right)$ subsets of a set\nof $h$ elements. Our set-system, $\\mathcal{H}$, is defined over $\\mathbb{Z}_m$,\nwhere $m$ is a non-prime-power. The size of each set in $\\mathcal{H}$ is\ndivisible by $m$ but the sizes of their pairwise intersections are not, unless\none set is a subset of another, (ii) a new variant of the learning with errors\n(LWE) problem, called PRIM-LWE, wherein the secret matrix is sampled such that\nits determinant is a generator of $\\mathbb{Z}_q^*$, where $q$ is the LWE\nmodulus. The security of our scheme relies on the hardness of the LWE problem,\nand its share size is $$(1+ o(1)) \\dfrac{2^{\\ell}}{\\sqrt{\\pi \\ell/2}}(2\nq^{\\varrho + 0.5} + \\sqrt{q} + \\mathrm{\\Theta}(h)),$$ where $\\varrho \\leq 1$ is\na constant and $\\ell$ is the total number of parties. We also provide\ndirections for future work to reduce the share size to\n  \\[\\leq \\dfrac{1}{3} \\left( (1+ o(1)) \\dfrac{2^{\\ell}}{\\sqrt{\\pi \\ell/2}}(2\nq^{\\varrho + 0.5} + 2\\sqrt{q}) \\right).\\]\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 14:03:55 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 11:48:10 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 09:31:23 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Sehrawat", "Vipin Singh", ""], ["Yeo", "Foo Yee", ""], ["Desmedt", "Yvo", ""]]}, {"id": "2011.14816", "submitter": "Christian Cachin", "authors": "Ignacio Amores-Sesar, Christian Cachin, Jovana Mi\\'ci\\'c", "title": "Security Analysis of Ripple Consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Ripple network is one of the most prominent blockchain platforms and its\nnative XRP token currently has one of the highest cryptocurrency market\ncapitalizations. The Ripple consensus protocol powers this network and is\ngenerally considered to a Byzantine fault-tolerant agreement protocol, which\ncan reach consensus in the presence of faulty or malicious nodes. In contrast\nto traditional Byzantine agreement protocols, there is no global knowledge of\nall participating nodes in Ripple consensus; instead, each node declares a list\nof other nodes that it trusts and from which it considers votes.\n  Previous work has brought up concerns about the liveness and safety of the\nconsensus protocol under the general assumptions stated initially by Ripple,\nand there is currently no appropriate understanding of its workings and its\nproperties in the literature. This paper closes this gap and makes two\ncontributions. It first provides a detailed, abstract description of the\nprotocol, which has been derived from the source code. Second, the paper points\nout that the abstract protocol may violate safety and liveness in several\nsimple executions under relatively benign network assumptions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 14:11:55 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Amores-Sesar", "Ignacio", ""], ["Cachin", "Christian", ""], ["Mi\u0107i\u0107", "Jovana", ""]]}, {"id": "2011.14818", "submitter": "Chandra Thapa", "authors": "Chandra Thapa and M.A.P. Chamikara and Seyit A. Camtepe", "title": "Advancements of federated learning towards privacy preservation: from\n  federated learning to split learning", "comments": "Authors' preprint version (before any peer-review) of a book chapter\n  to appear in the Book series \"Studies in Computational Intelligence\", Book\n  title \"Federated Learning Systems: Towards Next-generation AI\", Book eds.\n  Muhammad Habib ur Rehman and Mohamed Medhat Gaber, Publisher \"Springer Nature\n  Switzerland AG Gewerbestrasse 11, 6330 Cham, Switzerland.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the distributed collaborative machine learning (DCML) paradigm, federated\nlearning (FL) recently attracted much attention due to its applications in\nhealth, finance, and the latest innovations such as industry 4.0 and smart\nvehicles. FL provides privacy-by-design. It trains a machine learning model\ncollaboratively over several distributed clients (ranging from two to millions)\nsuch as mobile phones, without sharing their raw data with any other\nparticipant. In practical scenarios, all clients do not have sufficient\ncomputing resources (e.g., Internet of Things), the machine learning model has\nmillions of parameters, and its privacy between the server and the clients\nwhile training/testing is a prime concern (e.g., rival parties). In this\nregard, FL is not sufficient, so split learning (SL) is introduced. SL is\nreliable in these scenarios as it splits a model into multiple portions,\ndistributes them among clients and server, and trains/tests their respective\nmodel portions to accomplish the full model training/testing. In SL, the\nparticipants do not share both data and their model portions to any other\nparties, and usually, a smaller network portion is assigned to the clients\nwhere data resides. Recently, a hybrid of FL and SL, called splitfed learning,\nis introduced to elevate the benefits of both FL (faster training/testing time)\nand SL (model split and training). Following the developments from FL to SL,\nand considering the importance of SL, this chapter is designed to provide\nextensive coverage in SL and its variants. The coverage includes fundamentals,\nexisting findings, integration with privacy measures such as differential\nprivacy, open problems, and code implementation.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 05:01:33 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Thapa", "Chandra", ""], ["Chamikara", "M. A. P.", ""], ["Camtepe", "Seyit A.", ""]]}, {"id": "2011.14940", "submitter": "Sicong Zhou", "authors": "Lu Liu, Sicong Zhou, Huawei Huang, Zibin Zheng", "title": "From Technology to Society: An Overview of Blockchain-based DAO", "comments": "11 pages, 4 figures, 3 tables, submitted to IEEE OJ-CS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized Autonomous Organization (DAO) is believed to play a significant\nrole in our future society governed in a decentralized way. In this article, we\nfirst explain the definitions and preliminaries of DAO. Then, we conduct a\nliterature review of the existing studies of DAO published in the recent few\nyears. Through the literature review, we find out that a comprehensive survey\ntowards the state-of-the-art studies of DAO is still missing. To fill this gap,\nwe perform such an overview by identifying and classifying the most valuable\nproposals and perspectives closely related to the combination of DAO and\nblockchain technologies. We anticipate that this survey can help researchers,\nengineers, and educators acknowledge the cutting-edge development of\nblockchain-related DAO technologies.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 16:07:18 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 04:43:31 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Liu", "Lu", ""], ["Zhou", "Sicong", ""], ["Huang", "Huawei", ""], ["Zheng", "Zibin", ""]]}, {"id": "2011.14980", "submitter": "Alex B. Grilo", "authors": "Alex B. Grilo, Huijia Lin, Fang Song and Vinod Vaikuntanathan", "title": "Oblivious Transfer is in MiniQCrypt", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MiniQCrypt is a world where quantum-secure one-way functions exist, and\nquantum communication is possible. We construct an oblivious transfer (OT)\nprotocol in MiniQCrypt that achieves simulation-security in the plain model\nagainst malicious quantum polynomial-time adversaries, building on the\nfoundational work of Bennett, Brassard, Cr\\'epeau and Skubiszewska (CRYPTO\n1991). Combining the OT protocol with prior works, we obtain secure two-party\nand multi-party computation protocols also in MiniQCrypt. This is in contrast\nto the classical world, where it is widely believed that one-way functions\nalone do not give us OT.\n  In the common random string model, we achieve a constant-round universally\ncomposable (UC) OT protocol.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 16:51:17 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Grilo", "Alex B.", ""], ["Lin", "Huijia", ""], ["Song", "Fang", ""], ["Vaikuntanathan", "Vinod", ""]]}, {"id": "2011.15065", "submitter": "Olivier Nicole", "authors": "Olivier Nicole, Matthieu Lemerre, S\\'ebastien Bardin, Xavier Rival", "title": "No Crash, No Exploit: Automated Verification of Embedded Kernels", "comments": "Published in IEEE Real-Time and Embedded Technology and Applications\n  Symposium (RTAS'21)", "journal-ref": null, "doi": "10.1109/RTAS52030.2021.00011", "report-no": null, "categories": "cs.CR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The kernel is the most safety- and security-critical component of many\ncomputer systems, as the most severe bugs lead to complete system crash or\nexploit. It is thus desirable to guarantee that a kernel is free from these\nbugs using formal methods, but the high cost and expertise required to do so\nare deterrent to wide applicability. We propose a method that can verify both\nabsence of runtime errors (i.e. crashes) and absence of privilege escalation\n(i.e. exploits) in embedded kernels from their binary executables. The method\ncan verify the kernel runtime independently from the application, at the\nexpense of only a few lines of simple annotations. When given a specific\napplication, the method can verify simple kernels without any human\nintervention. We demonstrate our method on two different use cases: we use our\ntool to help the development of a new embedded real-time kernel, and we verify\nan existing industrial real-time kernel executable with no modification.\nResults show that the method is fast, simple to use, and can prevent real\nerrors and security vulnerabilities.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 18:03:28 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 21:47:51 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Nicole", "Olivier", ""], ["Lemerre", "Matthieu", ""], ["Bardin", "S\u00e9bastien", ""], ["Rival", "Xavier", ""]]}]