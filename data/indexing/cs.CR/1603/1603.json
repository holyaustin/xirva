[{"id": "1603.00087", "submitter": "Santiago Escobar", "authors": "Sonia Santiago and Santiago Escobar and Catherine Meadows and Jos\\'e\n  Meseguer", "title": "Effective Sequential Protocol Composition in Maude-NPA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protocols do not work alone, but together, one protocol relying on another to\nprovide needed services. Many of the problems in cryptographic protocols arise\nwhen such composition is done incorrectly or is not well understood. In this\npaper we discuss an extension to the Maude-NPA syntax and its operational\nsemantics to support dynamic sequential composition of protocols, so that\nprotocols can be specified separately and composed when desired. This allows\none to reason about many different compositions with minimal changes to the\nspecification, as well as improving, in terms of both performance and ease of\nspecification, on an earlier composition extension we presented in [18]. We\nshow how compositions can be defined and executed symbolically in Maude-NPA\nusing the compositional syntax and semantics. We also provide an experimental\nanalysis of the performance of Maude-NPA using the compositional syntax and\nsemantics, and compare it to the performance of a syntax and semantics for\ncomposition developed in earlier research. Finally, in the conclusion we give\nsome lessons learned about the best ways of extending narrowing-based state\nreachability tools, as well as comparison with related work and future plans.\n", "versions": [{"version": "v1", "created": "Mon, 29 Feb 2016 23:12:24 GMT"}], "update_date": "2016-03-02", "authors_parsed": [["Santiago", "Sonia", ""], ["Escobar", "Santiago", ""], ["Meadows", "Catherine", ""], ["Meseguer", "Jos\u00e9", ""]]}, {"id": "1603.00100", "submitter": "Masahiro Kaminaga", "authors": "Masahiro Kaminaga, Hideki Yoshikawa, Arimitsu Shikoda, Toshinori\n  Suzuki", "title": "Crashing Modulus Attack on Modular Squaring for Rabin Cryptosystem", "comments": "18 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Rabin cryptosystem has been proposed protect the unique ID (UID) in\nradio-frequency identification tags. The Rabin cryptosystem is a type of\nlightweight public key system that is theoretetically quite secure; however it\nis vulnerable to several side-channel attacks. In this paper, a crashing\nmodulus attack is presented as a new fault attack on modular squaring during\nRabin encryption. This attack requires only one fault in the public key if its\nperturbed public key can be factored. Our simulation results indicate that the\nattack is more than 50\\% successful with several faults in practical time. A\ncomplicated situation arises when reconstrucing the message, including the UID,\nfrom ciphertext, i.e., the message and the perturbed public key are not\nrelatively prime. We present a complete and mathematically rigorous message\nreconstruction algorithm for such a case. Moreover, we propose an exact formula\nto obtain a number of candidate messages. We show that the number is not\ngenerally equal to a power of two.\n", "versions": [{"version": "v1", "created": "Tue, 1 Mar 2016 00:00:54 GMT"}], "update_date": "2016-03-02", "authors_parsed": [["Kaminaga", "Masahiro", ""], ["Yoshikawa", "Hideki", ""], ["Shikoda", "Arimitsu", ""], ["Suzuki", "Toshinori", ""]]}, {"id": "1603.00182", "submitter": "Maurizio Naldi", "authors": "Maurizio Naldi and Giuseppe D'Acquisto", "title": "Protecting suppliers' private information: the case of stock levels and\n  the impact of correlated items", "comments": "13 pages, 5 figures. arXiv admin note: substantial text overlap with\n  arXiv:1509.06524", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A marketplace is defined where the private data of suppliers (e.g.,\nprosumers) are protected, so that neither their identity nor their level of\nstock is made known to end customers, while they can sell their products at a\nreduced price. A broker acts as an intermediary, which takes care of providing\nthe items missing to meet the customers' demand and allows end customers to\ntake advantages of reduced prices through the subscription of option contracts.\nFormulas are provided for the option price under three different probability\nmodels for the availability of items. Option pricing allows the broker to\npartially transfer its risk on end customers.\n", "versions": [{"version": "v1", "created": "Tue, 1 Mar 2016 08:28:55 GMT"}], "update_date": "2016-03-02", "authors_parsed": [["Naldi", "Maurizio", ""], ["D'Acquisto", "Giuseppe", ""]]}, {"id": "1603.00572", "submitter": "Kamlesh Hingwe", "authors": "Kamlesh Kumar Hingwe and S. Mary Saira Bhanu", "title": "Hierarchical Role-Based Access Control with Homomorphic Encryption for\n  Database as a Service", "comments": "11 Pages,4 figures, Proceedings of International Conference on ICT\n  for Sustainable Development", "journal-ref": null, "doi": "10.1007/978-981-10-0135-2_43", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Database as a service provides services for accessing and managing customers\ndata which provides ease of access, and the cost is less for these services.\nThere is a possibility that the DBaaS service provider may not be trusted, and\ndata may be stored on untrusted server. The access control mechanism can\nrestrict users from unauthorized access, but in cloud environment access\ncontrol policies are more flexible. However, an attacker can gather sensitive\ninformation for a malicious purpose by abusing the privileges as another user\nand so database security is compromised. The other problems associated with the\nDBaaS are to manage role hierarchy and secure session management for query\ntransaction in the database. In this paper, a role-based access control for the\nmultitenant database with role hierarchy is proposed. The query is granted with\nleast access privileges, and a session key is used for session management. The\nproposed work protects data from privilege escalation and SQL injection. It\nuses the partial homomorphic encryption (Paillier Encryption) for the\nencrypting the sensitive data. If a query is to perform any operation on\nsensitive data, then extra permissions are required for accessing sensitive\ndata. Data confidentiality and integrity are achieved using the role-based\naccess control with partial homomorphic encryption.\n", "versions": [{"version": "v1", "created": "Wed, 2 Mar 2016 04:22:31 GMT"}], "update_date": "2016-03-03", "authors_parsed": [["Hingwe", "Kamlesh Kumar", ""], ["Bhanu", "S. Mary Saira", ""]]}, {"id": "1603.00588", "submitter": "Shin-Ming Cheng", "authors": "Pin-Yu Chen and Ching-Chao Lin and Shin-Ming Cheng and Hsu-Chun Hsiao\n  and Chun-Ying Huang", "title": "Decapitation via Digital Epidemics: A Bio-Inspired Transmissive Attack", "comments": "To appear in June 2016 IEEE Communications Magazine, feature topic on\n  \"Bio-inspired Cyber Security for Communications and Networking\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evolution of communication technology and the proliferation of electronic\ndevices have rendered adversaries powerful means for targeted attacks via all\nsorts of accessible resources. In particular, owing to the intrinsic\ninterdependency and ubiquitous connectivity of modern communication systems,\nadversaries can devise malware that propagates through intermediate hosts to\napproach the target, which we refer to as transmissive attacks. Inspired by\nbiology, the transmission pattern of such an attack in the digital space much\nresembles the spread of an epidemic in real life. This paper elaborates\ntransmissive attacks, summarizes the utility of epidemic models in\ncommunication systems, and draws connections between transmissive attacks and\nepidemic models. Simulations, experiments, and ongoing research challenges on\ntransmissive attacks are also addressed.\n", "versions": [{"version": "v1", "created": "Wed, 2 Mar 2016 06:16:51 GMT"}], "update_date": "2016-03-03", "authors_parsed": [["Chen", "Pin-Yu", ""], ["Lin", "Ching-Chao", ""], ["Cheng", "Shin-Ming", ""], ["Hsiao", "Hsu-Chun", ""], ["Huang", "Chun-Ying", ""]]}, {"id": "1603.00707", "submitter": "Avishai Wool", "authors": "Eyal Itkin and Avishai Wool", "title": "A Security Analysis and Revised Security Extension for the Precision\n  Time Protocol", "comments": "An extended abstract (6 pages) is in the 2016 International IEEE\n  Symposium on Precision Clock Synchronization for Measurement, Control, and\n  Communication (ISPCS), Stockholm, Sweden, September 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Precision Time Protocol (PTP) aims to provide highly accurate and\nsynchronised clocks. Its defining standard, IEEE 1588, has a security section\n(\"Annex K\") which relies on symmetric-key secrecy. In this paper we present a\ndetailed threat analysis of the PTP standard, in which we highlight the\nsecurity properties that should be addressed by any security extension. During\nthis analysis we identify a sequence of new attacks and non-cryptographic\nnetwork-based defenses that mitigate them. We then suggest to replace Annex K's\nsymmetric cryptography by an efficient elliptic-curve Public-Key signatures. We\nimplemented all our attacks to demonstrate their effectiveness, and also\nimplemented and evaluated both the network and cryptographic defenses. Our\nresults show that the proposed schemes are extremely practical, and much more\nsecure than previous suggestions.\n", "versions": [{"version": "v1", "created": "Wed, 2 Mar 2016 13:45:24 GMT"}, {"version": "v2", "created": "Sun, 13 Mar 2016 10:48:31 GMT"}, {"version": "v3", "created": "Wed, 25 May 2016 14:46:03 GMT"}], "update_date": "2016-05-26", "authors_parsed": [["Itkin", "Eyal", ""], ["Wool", "Avishai", ""]]}, {"id": "1603.00747", "submitter": "Donghyuk Lee", "authors": "Yoongu Kim, Ross Daly, Jeremie Kim, Chris Fallin, Ji Hye Lee, Donghyuk\n  Lee, Chris Wilkerson, Konrad Lai, Onur Mutlu", "title": "RowHammer: Reliability Analysis and Security Implications", "comments": "This is the summary of the paper titled \"Flipping Bits in Memory\n  Without Accessing Them: An Experimental Study of DRAM Disturbance Errors\"\n  which appeared in ISCA in June 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As process technology scales down to smaller dimensions, DRAM chips become\nmore vulnerable to disturbance, a phenomenon in which different DRAM cells\ninterfere with each other's operation. For the first time in academic\nliterature, our ISCA paper exposes the existence of disturbance errors in\ncommodity DRAM chips that are sold and used today. We show that repeatedly\nreading from the same address could corrupt data in nearby addresses. More\nspecifically: When a DRAM row is opened (i.e., activated) and closed (i.e.,\nprecharged) repeatedly (i.e., hammered), it can induce disturbance errors in\nadjacent DRAM rows. This failure mode is popularly called RowHammer. We tested\n129 DRAM modules manufactured within the past six years (2008-2014) and found\n110 of them to exhibit RowHammer disturbance errors, the earliest of which\ndates back to 2010. In particular, all modules from the past two years\n(2012-2013) were vulnerable, which implies that the errors are a recent\nphenomenon affecting more advanced generations of process technology.\nImportantly, disturbance errors pose an easily-exploitable security threat\nsince they are a breach of memory protection, wherein accesses to one page\n(mapped to one row) modifies the data stored in another page (mapped to an\nadjacent row).\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 17:19:04 GMT"}], "update_date": "2016-03-03", "authors_parsed": [["Kim", "Yoongu", ""], ["Daly", "Ross", ""], ["Kim", "Jeremie", ""], ["Fallin", "Chris", ""], ["Lee", "Ji Hye", ""], ["Lee", "Donghyuk", ""], ["Wilkerson", "Chris", ""], ["Lai", "Konrad", ""], ["Mutlu", "Onur", ""]]}, {"id": "1603.00749", "submitter": "Sinong Wang", "authors": "Sinong Wang, Fang Liu, Ness Shroff", "title": "Non-additive Security Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have investigated the security game under non-additive utility functions.\n", "versions": [{"version": "v1", "created": "Wed, 2 Mar 2016 15:31:25 GMT"}, {"version": "v2", "created": "Thu, 3 Mar 2016 15:18:27 GMT"}, {"version": "v3", "created": "Fri, 9 Sep 2016 05:12:38 GMT"}, {"version": "v4", "created": "Fri, 16 Sep 2016 17:46:25 GMT"}, {"version": "v5", "created": "Wed, 21 Sep 2016 17:14:07 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Wang", "Sinong", ""], ["Liu", "Fang", ""], ["Shroff", "Ness", ""]]}, {"id": "1603.00893", "submitter": "Boxiang Dong", "authors": "Boxiang Dong, Hui Wendy Wang", "title": "Frequency-hiding Dependency-preserving Encryption for Outsourced\n  Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cloud paradigm enables users to outsource their data to computationally\npowerful third-party service providers for data management. Many data\nmanagement tasks rely on the data dependencies in the outsourced data. This\nraises an important issue of how the data owner can protect the sensitive\ninformation in the outsourced data while preserving the data dependencies. In\nthis paper, we consider functional dependency FD, an important type of data\ndependency. We design a FD-preserving encryption scheme, named F2, that enables\nthe service provider to discover the FDs from the encrypted dataset. We\nconsider the frequency analysis attack, and show that the F2 encryption scheme\ncan defend against the attack under Kerckhoff's principle with provable\nguarantee. Our empirical study demonstrates the efficiency and effectiveness of\nF2.\n", "versions": [{"version": "v1", "created": "Wed, 2 Mar 2016 21:20:16 GMT"}, {"version": "v2", "created": "Tue, 8 Mar 2016 15:16:00 GMT"}], "update_date": "2016-03-09", "authors_parsed": [["Dong", "Boxiang", ""], ["Wang", "Hui Wendy", ""]]}, {"id": "1603.00913", "submitter": "Jeremiah Blocki", "authors": "Jeremiah Blocki and Anirudh Sridhar", "title": "Client-CASH: Protecting Master Passwords against Offline Attacks", "comments": "ASIA CCS 2016. Full Version", "journal-ref": null, "doi": "10.1145/2897845.2897876", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline attacks on passwords are increasingly commonplace and dangerous. An\noffline adversary is limited only by the amount of computational resources he\nor she is willing to invest to crack a user's password. The danger is\ncompounded by the existence of authentication servers who fail to adopt proper\npassword storage practices like key-stretching. Password managers can help\nmitigate these risks by adopting key stretching procedures like hash iteration\nor memory hard functions to derive site specific passwords from the user's\nmaster password on the client-side. While key stretching can reduce the offline\nadversary's success rate, these procedures also increase computational costs\nfor a legitimate user. Motivated by the observation that most of the password\nguesses of the offline adversary will be incorrect, we propose a client side\ncost asymmetric secure hashing scheme (Client-CASH). Client-CASH randomizes the\nruntime of client-side key stretching procedure in a way that the expected\ncomputational cost of our key derivation function is greater when run with an\nincorrect master password. We make several contributions. First, we show how to\nintroduce randomness into a client-side key stretching algorithms through the\nuse of halting predicates which are selected randomly at the time of account\ncreation. Second, we formalize the problem of finding the optimal running time\ndistribution subject to certain cost constraints for the client and certain\nsecurity constrains on the halting predicates. Finally, we demonstrate that\nClient-CASH can reduce the adversary's success rate by up to $21\\%$. These\nresults demonstrate the promise of the Client-CASH mechanism.\n", "versions": [{"version": "v1", "created": "Wed, 2 Mar 2016 22:11:15 GMT"}], "update_date": "2016-03-04", "authors_parsed": [["Blocki", "Jeremiah", ""], ["Sridhar", "Anirudh", ""]]}, {"id": "1603.01244", "submitter": "Paul Rowe", "authors": "Paul D. Rowe", "title": "Principles of Layered Attestation", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems designed with measurement and attestation in mind are often layered,\nwith the lower layers measuring the layers above them. Attestations of such\nsystems, which we call layered attestations, must bundle together the results\nof a diverse set of application-specific measurements of various parts of the\nsystem. Some methods of layered attestation are more trustworthy than others,\nso it is important for system designers to understand the trust consequences of\ndifferent system configurations. This paper presents a formal framework for\nreasoning about layered attestations, and provides generic reusable principles\nfor achieving trustworthy results.\n", "versions": [{"version": "v1", "created": "Thu, 3 Mar 2016 20:04:18 GMT"}], "update_date": "2016-03-04", "authors_parsed": [["Rowe", "Paul D.", ""]]}, {"id": "1603.01315", "submitter": "Shin-Ming Cheng", "authors": "Shin-Ming Cheng and Pin-Yu Chen", "title": "Ecology-Based DoS Attack in Cognitive Radio Networks", "comments": "to appear in IEEE Symposium on Security and Privacy (IEEE S&P) 2016\n  Workshop on Bio-inspired Security, Trust, Assurance and Resilience", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive radio technology, which is designed to enhance spectrum\nutilization, depends on the success of opportunistic access, where secondary\nusers (SUs) exploit spectrum void unoccupied by primary users (PUs) for\ntransmissions. We note that the system behaviors are very similar to the\ninteractions among different species coexisting in an ecosystem. However, SUs\nof a selfish nature or of misleading information may make concurrent\ntransmissions with PUs for additional incentives, and thus disrupt the entire\necosystem. By exploiting this vulnerability, this paper proposes a novel\ndistributed denial-of-service (DoS) attack where invasive species, i.e.,\nmalicious users (MUs), induce originally normal-behaved SUs to execute\nconcurrent transmissions with PUs and thus collapse the cognitive radio\nnetwork. We adopt stochastic geometry to model the spatial distributions of\nPUs, SUs, and MUs for the analysis of the mutual interference among them. The\naccess strategy of each SU in the spectrum sharing ecosystem, which evolves\nwith the experienced payoffs and interference, is modeled by an evolutionary\ngame. Based on the evolutionary stable strategy concept, we could efficiently\nidentify the fragile operating region at which normal-behaved SUs are\neventually evolved to conduct concurrent transmissions and thus to cause the\nruin of the network.\n", "versions": [{"version": "v1", "created": "Thu, 3 Mar 2016 23:37:09 GMT"}], "update_date": "2016-03-07", "authors_parsed": [["Cheng", "Shin-Ming", ""], ["Chen", "Pin-Yu", ""]]}, {"id": "1603.01508", "submitter": "Robert Kleinberg", "authors": "Arpita Ghosh and Robert Kleinberg", "title": "Inferential Privacy Guarantees for Differentially Private Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The correlations and network structure amongst individuals in datasets\ntoday---whether explicitly articulated, or deduced from biological or\nbehavioral connections---pose new issues around privacy guarantees, because of\ninferences that can be made about one individual from another's data. This\nmotivates quantifying privacy in networked contexts in terms of \"inferential\nprivacy\"---which measures the change in beliefs about an individual's data from\nthe result of a computation---as originally proposed by Dalenius in the 1970's.\nInferential privacy is implied by differential privacy when data are\nindependent, but can be much worse when data are correlated; indeed, simple\nexamples, as well as a general impossibility theorem of Dwork and Naor,\npreclude the possibility of achieving non-trivial inferential privacy when the\nadversary can have arbitrary auxiliary information. In this paper, we ask how\ndifferential privacy guarantees translate to guarantees on inferential privacy\nin networked contexts: specifically, under what limitations on the adversary's\ninformation about correlations, modeled as a prior distribution over datasets,\ncan we deduce an inferential guarantee from a differential one?\n  We prove two main results. The first result pertains to distributions that\nsatisfy a natural positive-affiliation condition, and gives an upper bound on\nthe inferential privacy guarantee for any differentially private mechanism.\nThis upper bound is matched by a simple mechanism that adds Laplace noise to\nthe sum of the data. The second result pertains to distributions that have weak\ncorrelations, defined in terms of a suitable \"influence matrix\". The result\nprovides an upper bound for inferential privacy in terms of the differential\nprivacy parameter and the spectral norm of this matrix.\n", "versions": [{"version": "v1", "created": "Fri, 4 Mar 2016 15:50:24 GMT"}, {"version": "v2", "created": "Tue, 23 May 2017 18:52:06 GMT"}], "update_date": "2017-05-25", "authors_parsed": [["Ghosh", "Arpita", ""], ["Kleinberg", "Robert", ""]]}, {"id": "1603.01542", "submitter": "Vinod Kumar", "authors": "Vinod Kumar, S.K. Pandey, Rajendra Kumar", "title": "Centralized group key management scheme for secure multicast\n  communication without re-keying", "comments": "Wants to implement the method", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the secure group communication, data is transmitted in such a way that\nonly the group members are able to receive the messages. The main problem in\nthe solution using symmetric key is heavy re-keying cost. To reduce re-keying\ncost tree based architecture is used. But it requires extra overhead to balance\nthe key- tree in order to achieve logarithmic re-keying cost. The main\nchallenging issue in dynamic and secure multimedia multicast communication is\nto design a centralized group key management scheme with minimal computational,\ncommunicational and storages complexities without breaching security issues.\nSeveral authors have proposed different centralized group key management\nschemes, wherein one of them proposes reducing communicational complexity but\nincreases computational and storage costs however another proposes decreasing\nthe computational and storage costs which eventually breaches forward and\nbackward secrecy. In this paper we propose a comparatively more efficient\ncentralized group key management scheme that not only minimize the\ncomputational, communicational and storages complexities but also maintaining\nthe security at the optimal level. The message encryptions and decryptions\ncosts are also minimized. Further, we also provide an extended multicast\nscheme, in which the several requests towards leaving or joining the group can\nbe done by large number of members simultaneously. In order to obtain better\nperformance of multicast encryption, the symmetric-key and asymmetric-key\ncryptosystems may be combined.\n", "versions": [{"version": "v1", "created": "Fri, 4 Mar 2016 17:13:55 GMT"}, {"version": "v2", "created": "Thu, 17 Mar 2016 15:10:16 GMT"}], "update_date": "2016-03-18", "authors_parsed": [["Kumar", "Vinod", ""], ["Pandey", "S. K.", ""], ["Kumar", "Rajendra", ""]]}, {"id": "1603.01573", "submitter": "Va\\v{s}ek Chv\\'atal", "authors": "Va\\v{s}ek Chv\\'atal, Mark Goldsmith, and Nan Yang", "title": "McCulloch-Pitts brains and pseudorandom functions", "comments": "Supersedes arXiv:1311.6531 [math.DS]", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a pioneering classic, Warren McCulloch and Walter Pitts proposed a model\nof the central nervous system. Motivated by EEG recordings of normal brain\nactivity, Chv\\'atal and Goldsmith asked whether or not these dynamical systems\ncan be engineered to produce trajectories which are irregular, disorderly,\napparently unpredictable. We show that they cannot build weak pseudorandom\nfunctions.\n", "versions": [{"version": "v1", "created": "Fri, 4 Mar 2016 19:13:36 GMT"}], "update_date": "2016-03-07", "authors_parsed": [["Chv\u00e1tal", "Va\u0161ek", ""], ["Goldsmith", "Mark", ""], ["Yang", "Nan", ""]]}, {"id": "1603.01699", "submitter": "Dong Su", "authors": "Min Lyu, Dong Su, Ninghui Li", "title": "Understanding the Sparse Vector Technique for Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Sparse Vector Technique (SVT) is a fundamental technique for satisfying\ndifferential privacy and has the unique quality that one can output some query\nanswers without apparently paying any privacy cost. SVT has been used in both\nthe interactive setting, where one tries to answer a sequence of queries that\nare not known ahead of the time, and in the non-interactive setting, where all\nqueries are known. Because of the potential savings on privacy budget, many\nvariants for SVT have been proposed and employed in privacy-preserving data\nmining and publishing. However, most variants of SVT are actually not private.\nIn this paper, we analyze these errors and identify the misunderstandings that\nlikely contribute to them. We also propose a new version of SVT that provides\nbetter utility, and introduce an effective technique to improve the performance\nof SVT. These enhancements can be applied to improve utility in the interactive\nsetting. Through both analytical and experimental comparisons, we show that, in\nthe non-interactive setting (but not the interactive setting), the SVT\ntechnique is unnecessary, as it can be replaced by the Exponential Mechanism\n(EM) with better accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 5 Mar 2016 08:49:26 GMT"}, {"version": "v2", "created": "Sat, 17 Sep 2016 22:42:49 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Lyu", "Min", ""], ["Su", "Dong", ""], ["Li", "Ninghui", ""]]}, {"id": "1603.01887", "submitter": "Guy Rothblum", "authors": "Cynthia Dwork and Guy N. Rothblum", "title": "Concentrated Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Concentrated Differential Privacy, a relaxation of Differential\nPrivacy enjoying better accuracy than both pure differential privacy and its\npopular \"(epsilon,delta)\" relaxation without compromising on cumulative privacy\nloss over multiple computations.\n", "versions": [{"version": "v1", "created": "Sun, 6 Mar 2016 22:41:12 GMT"}, {"version": "v2", "created": "Wed, 16 Mar 2016 16:29:29 GMT"}], "update_date": "2016-03-17", "authors_parsed": [["Dwork", "Cynthia", ""], ["Rothblum", "Guy N.", ""]]}, {"id": "1603.02031", "submitter": "Vitaly Roman'kov", "authors": "Vitalii Roman'kov", "title": "How to make RSA and some other encryptions probabilistic", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new scheme of probabilistic subgroup-related encryption is introduced. Some\napplications of this scheme based on the RSA, Diffie-Hellman and ElGamal\nencryption algorithms are described. Security assumptions and main advantages\nof this scheme are discussed. We outline that this scheme is potentially\nsemantically secure under reasonable cryptographic assumptions.\n", "versions": [{"version": "v1", "created": "Mon, 7 Mar 2016 12:28:14 GMT"}], "update_date": "2016-03-08", "authors_parsed": [["Roman'kov", "Vitalii", ""]]}, {"id": "1603.02187", "submitter": "Goran Doychev", "authors": "Goran Doychev and Boris K\\\"opf", "title": "Rigorous Analysis of Software Countermeasures against Cache Attacks", "comments": "Version published in the Proceedings of PLDI'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CPU caches introduce variations into the execution time of programs that can\nbe exploited by adversaries to recover private information about users or\ncryptographic keys. Establishing the security of countermeasures against this\nthreat often requires intricate reasoning about the interactions of program\ncode, memory layout, and hardware architecture and has so far only been done\nfor restricted cases. In this paper we devise novel techniques that provide\nsupport for bit-level and arithmetic reasoning about memory accesses in the\npresence of dynamic memory allocation. These techniques enable us to perform\nthe first rigorous analysis of widely deployed software countermeasures against\ncache attacks on modular exponentiation, based on executable code.\n", "versions": [{"version": "v1", "created": "Mon, 7 Mar 2016 18:15:12 GMT"}, {"version": "v2", "created": "Thu, 13 Oct 2016 15:14:43 GMT"}, {"version": "v3", "created": "Thu, 11 May 2017 16:46:18 GMT"}], "update_date": "2017-05-12", "authors_parsed": [["Doychev", "Goran", ""], ["K\u00f6pf", "Boris", ""]]}, {"id": "1603.02211", "submitter": "Rajesh  Kumar", "authors": "Rajesh Kumar, Vir V Phoha, and Rahul Raina", "title": "Authenticating users through their arm movement patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose four continuous authentication designs by using the\ncharacteristics of arm movements while individuals walk. The first design uses\nacceleration of arms captured by a smartwatch's accelerometer sensor, the\nsecond design uses the rotation of arms captured by a smartwatch's gyroscope\nsensor, third uses the fusion of both acceleration and rotation at the\nfeature-level and fourth uses the fusion at score-level. Each of these designs\nis implemented by using four classifiers, namely, k nearest neighbors (k-NN)\nwith Euclidean distance, Logistic Regression, Multilayer Perceptrons, and\nRandom Forest resulting in a total of sixteen authentication mechanisms. These\nauthentication mechanisms are tested under three different environments, namely\nan intra-session, inter-session on a dataset of 40 users and an inter-phase on\na dataset of 12 users. The sessions of data collection were separated by at\nleast ten minutes, whereas the phases of data collection were separated by at\nleast three months. Under the intra-session environment, all of the twelve\nauthentication mechanisms achieve a mean dynamic false accept rate (DFAR) of 0%\nand dynamic false reject rate (DFRR) of 0%. For the inter-session environment,\nfeature level fusion-based design with classifier k-NN achieves the best error\nrates that are a mean DFAR of 2.2% and DFRR of 4.2%. The DFAR and DFRR\nincreased from 5.68% and 4.23% to 15.03% and 14.62% respectively when feature\nlevel fusion-based design with classifier k-NN was tested under the inter-phase\nenvironment on a dataset of 12 users.\n", "versions": [{"version": "v1", "created": "Mon, 7 Mar 2016 19:15:39 GMT"}], "update_date": "2016-03-08", "authors_parsed": [["Kumar", "Rajesh", ""], ["Phoha", "Vir V", ""], ["Raina", "Rahul", ""]]}, {"id": "1603.02308", "submitter": "Mrakus Roggenbach", "authors": "Irina Mariuca Asavoae, Jorge Blasco, Thomas M. Chen, Harsha Kumara\n  Kalutarage, Igor Muttik, Hoang Nga Nguyen, Markus Roggenbach, Siraj Ahmed\n  Shaikh", "title": "Towards Automated Android App Collusion Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android OS supports multiple communication methods between apps. This opens\nthe possibility to carry out threats in a collaborative fashion, c.f. the\nSoundcomber example from 2011. In this paper we provide a concise definition of\ncollusion and report on a number of automated detection approaches, developed\nin co-operation with Intel Security.\n", "versions": [{"version": "v1", "created": "Mon, 7 Mar 2016 21:46:28 GMT"}], "update_date": "2016-03-09", "authors_parsed": [["Asavoae", "Irina Mariuca", ""], ["Blasco", "Jorge", ""], ["Chen", "Thomas M.", ""], ["Kalutarage", "Harsha Kumara", ""], ["Muttik", "Igor", ""], ["Nguyen", "Hoang Nga", ""], ["Roggenbach", "Markus", ""], ["Shaikh", "Siraj Ahmed", ""]]}, {"id": "1603.02370", "submitter": "Hoi Fung Chau", "authors": "H. F. Chau, Qinan Wang and Cardythy Wong", "title": "Experimentally Feasible Quantum-Key-Distribution Scheme Using Qubit-Like\n  Qudits And Its Comparison With Existing Qubit- and Qudit-Based Protocols", "comments": "extensively revised, conclusions changed, 7 pages, 2 figures and 1\n  table, published in PRA", "journal-ref": "Phys. Rev. A 95, 022311 (2017)", "doi": "10.1103/PhysRevA.95.022311", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Chau introduced an experimentally feasible qudit-based\nquantum-key-distribution (QKD) scheme. In that scheme, one bit of information\nis phase encoded in the prepared state in a $2^n$-dimensional Hilbert space in\nthe form $(|i\\rangle\\pm|j\\rangle)/\\sqrt{2}$ with $n\\ge 2$. For each qudit\nprepared and measured in the same two-dimensional Hilbert subspace, one bit of\nraw secret key is obtained in the absence of transmission error. Here we show\nthat by modifying the basis announcement procedure, the same experimental setup\ncan generate $n$ bits of raw key for each qudit prepared and measured in the\nsame basis in the noiseless situation. The reason is that in addition to the\nphase information, each qudit also carries information on the Hilbert subspace\nused. The additional $(n-1)$ bits of raw key comes from a clever utilization of\nthis extra piece of information. We prove the unconditional security of this\nmodified protocol and compare its performance with other existing provably\nsecure qubit- and qudit-based protocols on market in the one-way classical\ncommunication setting. Interestingly, we find that for the case of $n=2$, the\nsecret key rate of this modified protocol using non-degenerate random quantum\ncode to perform one-way entanglement distillation is equal to that of the\nsix-state scheme.\n", "versions": [{"version": "v1", "created": "Tue, 8 Mar 2016 03:31:54 GMT"}, {"version": "v2", "created": "Thu, 9 Feb 2017 03:30:53 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Chau", "H. F.", ""], ["Wang", "Qinan", ""], ["Wong", "Cardythy", ""]]}, {"id": "1603.02640", "submitter": "Scott Stoller", "authors": "Scott D. Stoller and Thang Bui", "title": "Mining Hierarchical Temporal Roles with Multiple Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal role-based access control (TRBAC) extends role-based access control\nto limit the times at which roles are enabled. This paper presents a new\nalgorithm for mining high-quality TRBAC policies from timed ACLs (i.e., ACLs\nwith time limits in the entries) and optionally user attribute information.\nSuch algorithms have potential to significantly reduce the cost of migration\nfrom timed ACLs to TRBAC. The algorithm is parameterized by the policy quality\nmetric. We consider multiple quality metrics, including number of roles,\nweighted structural complexity (a generalization of policy size), and (when\nuser attribute information is available) interpretability, i.e., how well role\nmembership can be characterized in terms of user attributes. Ours is the first\nTRBAC policy mining algorithm that produces hierarchical policies, and the\nfirst that optimizes weighted structural complexity or interpretability. In\nexperiments with datasets based on real-world ACL policies, our algorithm is\nmore effective than previous algorithms at optimizing policy quality.\n", "versions": [{"version": "v1", "created": "Tue, 8 Mar 2016 19:51:15 GMT"}, {"version": "v2", "created": "Thu, 5 May 2016 14:23:55 GMT"}, {"version": "v3", "created": "Fri, 20 May 2016 18:02:41 GMT"}, {"version": "v4", "created": "Sat, 30 Jul 2016 17:16:11 GMT"}, {"version": "v5", "created": "Tue, 18 Apr 2017 01:41:49 GMT"}, {"version": "v6", "created": "Mon, 21 Aug 2017 19:01:35 GMT"}, {"version": "v7", "created": "Sun, 15 Oct 2017 23:43:34 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Stoller", "Scott D.", ""], ["Bui", "Thang", ""]]}, {"id": "1603.02671", "submitter": "Jalaj Upadhyay", "authors": "Maura B. Paterson and Douglas R. Stinson and Jalaj Upadhyay", "title": "Multi-prover Proof-of-Retrievability", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been considerable recent interest in \"cloud storage\" wherein a user\nasks a server to store a large file. One issue is whether the user can verify\nthat the server is actually storing the file, and typically a\nchallenge-response protocol is employed to convince the user that the file is\nindeed being stored correctly. The security of these schemes is phrased in\nterms of an extractor which will recover the file given any \"proving algorithm\"\nthat has a sufficiently high success probability. This forms the basis of\n\\emph{proof-of-retrievability} ($\\mathsf{PoR}$) systems.\n  In this paper, we study multiple server $\\mathsf{PoR}$ systems. We formalize\nsecurity definitions for two possible scenarios: (i) when a threshold of\nservers succeed with high enough probability (worst-case) and (ii) when the\naverage of the success probability of all the servers is above a threshold\n(average-case). We also motivate the study of confidentiality of the outsourced\nmessage. We give $\\mathsf{M}\\mbox{-}\\mathsf{PoR}$ schemes which are secure\nunder both these security definitions and provide reasonable confidentiality\nguarantees even when there is no restriction on the computational power of the\nservers. We also show how classical statistical techniques used by Paterson,\nStinson and Upadhyay (Journal of Mathematical Cryptology: 7(3)) can be extended\nto evaluate whether the responses of the provers are accurate enough to permit\nsuccessful extraction. We also look at one specific instantiation of our\nconstruction when instantiated with the unconditionally secure version of the\nShacham-Waters scheme (Asiacrypt, 2008). This scheme gives reasonable security\nand privacy guarantee. We show that, in the multi-server setting with\ncomputationally unbounded provers, one can overcome the limitation that the\nverifier needs to store as much secret information as the provers.\n", "versions": [{"version": "v1", "created": "Tue, 8 Mar 2016 20:52:02 GMT"}], "update_date": "2016-03-09", "authors_parsed": [["Paterson", "Maura B.", ""], ["Stinson", "Douglas R.", ""], ["Upadhyay", "Jalaj", ""]]}, {"id": "1603.02727", "submitter": "Boxiang Dong", "authors": "Boxiang Dong, Hui Wang", "title": "Efficient Authentication of Outsourced String Similarity Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing enables the outsourcing of big data analytics, where a third\nparty server is responsible for data storage and processing. In this paper, we\nconsider the outsourcing model that provides string similarity search as the\nservice. In particular, given a similarity search query, the service provider\nreturns all strings from the outsourced dataset that are similar to the query\nstring. A major security concern of the outsourcing paradigm is to authenticate\nwhether the service provider returns sound and complete search results. In this\npaper, we design AutoS3, an authentication mechanism of outsourced string\nsimilarity search. The key idea of AutoS3 is that the server returns a\nverification object VO to prove the result correctness. First, we design an\nauthenticated string indexing structure named MBtree for VO construction.\nSecond, we design two lightweight authentication methods named VS2 and EVS2\nthat can catch the service provider various cheating behaviors with cheap\nverification cost. Moreover, we generalize our solution for top k string\nsimilarity search. We perform an extensive set of experiment results on real\nworld datasets to demonstrate the efficiency of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 8 Mar 2016 22:40:41 GMT"}], "update_date": "2016-04-04", "authors_parsed": [["Dong", "Boxiang", ""], ["Wang", "Hui", ""]]}, {"id": "1603.02767", "submitter": "Abedelaziz  Mohaisen", "authors": "Jeffrey Spaulding and Shambhu Upadhyaya and Aziz Mohaisen", "title": "The Landscape of Domain Name Typosquatting: Techniques and\n  Countermeasures", "comments": "6 pages, 1 table, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With more than 294 million registered domain names as of late 2015, the\ndomain name ecosystem has evolved to become a cornerstone for the operation of\nthe Internet. Domain names today serve everyone, from individuals for their\nonline presence to big brands for their business operations. Such ecosystem\nthat facilitated legitimate business and personal uses has also fostered\n\"creative\" cases of misuse, including phishing, spam, hit and traffic stealing,\nonline scams, among others. As a first step towards this misuse, the\nregistration of a legitimately-looking domain is often required. For that,\ndomain typosquatting provides a great avenue to cybercriminals to conduct their\ncrimes.\n  In this paper, we review the landscape of domain name typosquatting,\nhighlighting models and advanced techniques for typosquatted domain names\ngeneration, models for their monetization, and the existing literature on\ncountermeasures. We further highlight potential fruitful directions on\ntechnical countermeasures that are lacking in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 9 Mar 2016 02:43:54 GMT"}], "update_date": "2016-03-10", "authors_parsed": [["Spaulding", "Jeffrey", ""], ["Upadhyaya", "Shambhu", ""], ["Mohaisen", "Aziz", ""]]}, {"id": "1603.02826", "submitter": "Osmanbey Uzunkol", "authors": "Mehmet Sabir Kiraz and Osmanbey Uzunkol", "title": "Still Wrong Use of Pairings in Cryptography", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several pairing-based cryptographic protocols are recently proposed with a\nwide variety of new novel applications including the ones in emerging\ntechnologies like cloud computing, internet of things (IoT), e-health systems\nand wearable technologies. There have been however a wide range of incorrect\nuse of these primitives. The paper of Galbraith, Paterson, and Smart (2006)\npointed out most of the issues related to the incorrect use of pairing-based\ncryptography. However, we noticed that some recently proposed applications\nstill do not use these primitives correctly. This leads to unrealizable,\ninsecure or too inefficient designs of pairing-based protocols. We observed\nthat one reason is not being aware of the recent advancements on solving the\ndiscrete logarithm problems in some groups. The main purpose of this article is\nto give an understandable, informative, and the most up-to-date criteria for\nthe correct use of pairing-based cryptography. We thereby deliberately avoid\nmost of the technical details and rather give special emphasis on the\nimportance of the correct use of bilinear maps by realizing secure\ncryptographic protocols. We list a collection of some recent papers having\nwrong security assumptions or realizability/efficiency issues. Finally, we give\na compact and an up-to-date recipe of the correct use of pairings.\n", "versions": [{"version": "v1", "created": "Wed, 9 Mar 2016 09:48:11 GMT"}, {"version": "v2", "created": "Wed, 30 Mar 2016 07:46:35 GMT"}, {"version": "v3", "created": "Wed, 23 Nov 2016 11:57:26 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Kiraz", "Mehmet Sabir", ""], ["Uzunkol", "Osmanbey", ""]]}, {"id": "1603.02964", "submitter": "Taroq Alshugran", "authors": "Tariq Alshugran, Julius Dichter", "title": "A Framework for Extracting and Modeling HIPAA Privacy Rules for\n  Healthcare Applications", "comments": null, "journal-ref": "Health Informatics - An Internation Journal, vol. 5, no. 1, pp.\n  1-10, 2016", "doi": "10.5121/hiij.2016.5101", "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some organizations use software applications to manage their customers'\npersonal, medical, or financial information. In the United States, those\nsoftware applications are obligated to preserve users' privacy and to comply\nwith the United States federal privacy laws and regulations. To formally\nguarantee compliance with those regulations, it is essential to extract and\nmodel the privacy rules from the text of the law using a formal framework. In\nthis work we propose a goal-oriented framework for modeling and extracting the\nprivacy requirements from regulatory text using natural language processing\ntechniques.\n", "versions": [{"version": "v1", "created": "Wed, 9 Mar 2016 16:57:18 GMT"}], "update_date": "2016-03-10", "authors_parsed": [["Alshugran", "Tariq", ""], ["Dichter", "Julius", ""]]}, {"id": "1603.03081", "submitter": "Jeffrey Pawlick", "authors": "Jeffrey Pawlick and Quanyan Zhu", "title": "Two-Party Privacy Games: How Users Perturb When Learners Preempt", "comments": "This conference paper was not accepted. It has been withdrawn because\n  it was subsequently revised and appears here arXiv:1608.02546", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet tracking technologies and wearable electronics provide a vast amount\nof data to machine learning algorithms. This stock of data stands to increase\nwith the developments of the internet of things and cyber-physical systems.\nClearly, these technologies promise benefits. But they also raise the risk of\nsensitive information disclosure. To mitigate this risk, machine learning\nalgorithms can add noise to outputs according to the formulations provided by\ndifferential privacy. At the same time, users can fight for privacy by\ninjecting noise into the data that they report. In this paper, we conceptualize\nthe interactions between privacy and accuracy and between user (input)\nperturbation and learner (output) perturbation in machine learning, using the\nframeworks of empirical risk minimization, differential privacy, and\nStackelberg games. In particular, we solve for the Stackelberg equilibrium for\nthe case of an averaging query. We find that, in equilibrium, either the users\nperturb their data before submission or the learner perturbs the machine\nlearning output, but never both. Specifically, the learner perturbs if and only\nif the number of users is greater than a threshold which increases with the\ndegree to which incentives are misaligned. Provoked by these conclusions - and\nby some observations from privacy ethics - we also suggest future directions.\nWhile other work in this area has studied privacy markets and mechanism design\nfor truthful reporting of user information, we take a different viewpoint by\nconsidering both user and learner perturbation. We hope that this effort will\nopen the door to future work in the area of differential privacy games.\n", "versions": [{"version": "v1", "created": "Wed, 9 Mar 2016 22:09:56 GMT"}, {"version": "v2", "created": "Wed, 10 Aug 2016 17:10:28 GMT"}], "update_date": "2016-08-11", "authors_parsed": [["Pawlick", "Jeffrey", ""], ["Zhu", "Quanyan", ""]]}, {"id": "1603.03086", "submitter": "Mikhail Kazdagli", "authors": "Mikhail Kazdagli, Ling Huang, Vijay Reddi, Mohit Tiwari", "title": "EMMA: A New Platform to Evaluate Hardware-based Mobile Malware Analyses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware-based malware detectors (HMDs) are a key emerging technology to\nbuild trustworthy computing platforms, especially mobile platforms. Quantifying\nthe efficacy of HMDs against malicious adversaries is thus an important\nproblem. The challenge lies in that real-world malware typically adapts to\ndefenses, evades being run in experimental settings, and hides behind benign\napplications. Thus, realizing the potential of HMDs as a line of defense - that\nhas a small and battery-efficient code base - requires a rigorous foundation\nfor evaluating HMDs.\n  To this end, we introduce EMMA - a platform to evaluate the efficacy of HMDs\nfor mobile platforms. EMMA deconstructs malware into atomic, orthogonal actions\nand introduces a systematic way of pitting different HMDs against a diverse\nsubset of malware hidden inside benign applications. EMMA drives both malware\nand benign programs with real user-inputs to yield an HMD's effective operating\nrange - i.e., the malware actions a particular HMD is capable of detecting. We\nshow that small atomic actions, such as stealing a Contact or SMS, have\nsurprisingly large hardware footprints, and use this insight to design HMD\nalgorithms that are less intrusive than prior work and yet perform 24.7%\nbetter. Finally, EMMA brings up a surprising new result - obfuscation\ntechniques used by malware to evade static analyses makes them more detectable\nusing HMDs.\n", "versions": [{"version": "v1", "created": "Wed, 9 Mar 2016 22:22:54 GMT"}, {"version": "v2", "created": "Fri, 11 Mar 2016 04:03:27 GMT"}], "update_date": "2016-03-14", "authors_parsed": [["Kazdagli", "Mikhail", ""], ["Huang", "Ling", ""], ["Reddi", "Vijay", ""], ["Tiwari", "Mohit", ""]]}, {"id": "1603.03404", "submitter": "Tianwei Zhang", "authors": "Tianwei Zhang, Yinqian Zhang, Ruby B. Lee", "title": "Memory DoS Attacks in Multi-tenant Clouds: Severity and Mitigation", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cloud computing, network Denial of Service (DoS) attacks are well studied\nand defenses have been implemented, but severe DoS attacks on a victim's\nworking memory by a single hostile VM are not well understood. Memory DoS\nattacks are Denial of Service (or Degradation of Service) attacks caused by\ncontention for hardware memory resources on a cloud server. Despite the strong\nmemory isolation techniques for virtual machines (VMs) enforced by the software\nvirtualization layer in cloud servers, the underlying hardware memory layers\nare still shared by the VMs and can be exploited by a clever attacker in a\nhostile VM co-located on the same server as the victim VM, denying the victim\nthe working memory he needs. We first show quantitatively the severity of\ncontention on different memory resources. We then show that a malicious cloud\ncustomer can mount low-cost attacks to cause severe performance degradation for\na Hadoop distributed application, and 38X delay in response time for an\nE-commerce website in the Amazon EC2 cloud.\n  Then, we design an effective, new defense against these memory DoS attacks,\nusing a statistical metric to detect their existence and execution throttling\nto mitigate the attack damage. We achieve this by a novel re-purposing of\nexisting hardware performance counters and duty cycle modulation for security,\nrather than for improving performance or power consumption. We implement a full\nprototype on the OpenStack cloud system. Our evaluations show that this defense\nsystem can effectively defeat memory DoS attacks with negligible performance\noverhead.\n", "versions": [{"version": "v1", "created": "Thu, 10 Mar 2016 20:16:52 GMT"}, {"version": "v2", "created": "Fri, 11 Mar 2016 04:46:07 GMT"}, {"version": "v3", "created": "Wed, 4 Oct 2017 16:43:59 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Zhang", "Tianwei", ""], ["Zhang", "Yinqian", ""], ["Lee", "Ruby B.", ""]]}, {"id": "1603.03409", "submitter": "Reza Tourani", "authors": "Reza Tourani, Travis Mick, Satyajayant Misra and Gaurav Panwar", "title": "Security, Privacy, and Access Control in Information-Centric Networking:\n  A Survey", "comments": "36 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Information-Centric Networking (ICN) is a new networking paradigm, which\nreplaces the widely used host-centric networking paradigm in communication\nnetworks (e.g., Internet, mobile ad hoc networks) with an information-centric\nparadigm, which prioritizes the delivery of named content, oblivious of the\ncontents origin. Content and client security are more intrinsic in the ICN\nparadigm versus the current host centric paradigm where they have been\ninstrumented as an after thought. By design, the ICN paradigm inherently\nsupports several security and privacy features, such as provenance and identity\nprivacy, which are still not effectively available in the host-centric\nparadigm. However, given its nascency, the ICN paradigm has several open\nsecurity and privacy concerns, some that existed in the old paradigm, and some\nnew and unique. In this article, we survey the existing literature in security\nand privacy research sub-space in ICN. More specifically, we explore three\nbroad areas: security threats, privacy risks, and access control enforcement\nmechanisms.\n  We present the underlying principle of the existing works, discuss the\ndrawbacks of the proposed approaches, and explore potential future research\ndirections. In the broad area of security, we review attack scenarios, such as\ndenial of service, cache pollution, and content poisoning. In the broad area of\nprivacy, we discuss user privacy and anonymity, name and signature privacy, and\ncontent privacy. ICN's feature of ubiquitous caching introduces a major\nchallenge for access control enforcement that requires special attention. In\nthis broad area, we review existing access control mechanisms including\nencryption-based, attribute-based, session-based, and proxy re-encryption-based\naccess control schemes. We conclude the survey with lessons learned and scope\nfor future work.\n", "versions": [{"version": "v1", "created": "Thu, 10 Mar 2016 20:28:10 GMT"}, {"version": "v2", "created": "Thu, 29 Sep 2016 22:27:39 GMT"}, {"version": "v3", "created": "Thu, 1 Jun 2017 22:46:02 GMT"}], "update_date": "2017-06-05", "authors_parsed": [["Tourani", "Reza", ""], ["Mick", "Travis", ""], ["Misra", "Satyajayant", ""], ["Panwar", "Gaurav", ""]]}, {"id": "1603.03501", "submitter": "Reza Tourani", "authors": "S. Misra, R. Tourani, F. Natividad, T. Mick, N. Majd, H. Huang", "title": "AccConF: An Access Control Framework for Leveraging In-Network Cached\n  Data in ICNs", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The fast-growing Internet traffic is increasingly becoming content-based and\ndriven by mobile users, with users more interested in data rather than its\nsource. This has precipitated the need for an information-centric Internet\narchitecture. Research in information-centric networks (ICNs) have resulted in\nnovel architectures, e.g., CCN/NDN, DONA, and PSIRP/PURSUIT; all agree on named\ndata based addressing and pervasive caching as integral design components. With\nnetwork-wide content caching, enforcement of content access control policies\nbecome non-trivial. Each caching node in the network needs to enforce access\ncontrol policies with the help of the content provider. This becomes\ninefficient and prone to unbounded latencies especially during provider\noutages.\n  In this paper, we propose an efficient access control framework for ICN,\nwhich allows legitimate users to access and use the cached content directly,\nand does not require verification/authentication by an online provider\nauthentication server or the content serving router. This framework would help\nreduce the impact of system down-time from server outages and reduce delivery\nlatency by leveraging caching while guaranteeing access only to legitimate\nusers. Experimental/simulation results demonstrate the suitability of this\nscheme for all users, but particularly for mobile users, especially in terms of\nthe security and latency overheads.\n", "versions": [{"version": "v1", "created": "Fri, 11 Mar 2016 01:33:15 GMT"}], "update_date": "2016-03-14", "authors_parsed": [["Misra", "S.", ""], ["Tourani", "R.", ""], ["Natividad", "F.", ""], ["Mick", "T.", ""], ["Majd", "N.", ""], ["Huang", "H.", ""]]}, {"id": "1603.03710", "submitter": "Jens Braband", "authors": "Jens Braband", "title": "Why 2 times 2 ain't necessarily 4 - at least not in IT security risk\n  assessment", "comments": "10 pages, 2 figures, 2 tables, submitted to SICHERHEIT2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a novel approach towards semi-quantitative IT security risk\nassessment has been proposed in the draft IEC 62443-3-2. This approach is\nanalyzed from several different angles, e.g. embedding into the overall\nstandard series, semantic and methodological aspects. As a result, several\nsystematic flaws in the approach are exposed. As a way forward, an alternative\napproach is proposed which blends together semi-quantitative risk assessment as\nwell as threat and risk analysis.\n", "versions": [{"version": "v1", "created": "Fri, 11 Mar 2016 18:13:08 GMT"}], "update_date": "2016-03-14", "authors_parsed": [["Braband", "Jens", ""]]}, {"id": "1603.03837", "submitter": "Gunupudi Rajesh Kumar Mr", "authors": "Gunupudi RajeshKumar, N Mangathayaru, G Narsimha", "title": "Intrusion Detection A Text Mining Based Approach", "comments": "13 pages, 4 figures, Special issue on Computing Applications and Data\n  Mining, Paper 01021609, International Journal of Computer Science and\n  Information Security (IJCSIS), Vol. 14 S1, February 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intrusion Detection is one of major threats for organization. The approach of\nintrusion detection using text processing has been one of research interests\nwhich is gaining significant importance from researchers. In text mining based\napproach for intrusion detection, system calls serve as source for mining and\npredicting possibility of intrusion or attack. When an application runs, there\nmight be several system calls which are initiated in the background. These\nsystem calls form the strong basis and the deciding factor for intrusion\ndetection. In this paper, we mainly discuss the approach for intrusion\ndetection by designing a distance measure which is designed by taking into\nconsideration the conventional Gaussian function and modified to suit the need\nfor similarity function. A Framework for intrusion detection is also discussed\nas part of this research.\n", "versions": [{"version": "v1", "created": "Sat, 12 Mar 2016 01:12:08 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["RajeshKumar", "Gunupudi", ""], ["Mangathayaru", "N", ""], ["Narsimha", "G", ""]]}, {"id": "1603.03977", "submitter": "Shuang Song", "authors": "Shuang Song, Yizhen Wang, Kamalika Chaudhuri", "title": "Pufferfish Privacy Mechanisms for Correlated Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern databases include personal and sensitive correlated data, such as\nprivate information on users connected together in a social network, and\nmeasurements of physical activity of single subjects across time. However,\ndifferential privacy, the current gold standard in data privacy, does not\nadequately address privacy issues in this kind of data.\n  This work looks at a recent generalization of differential privacy, called\nPufferfish, that can be used to address privacy in correlated data. The main\nchallenge in applying Pufferfish is a lack of suitable mechanisms. We provide\nthe first mechanism -- the Wasserstein Mechanism -- which applies to any\ngeneral Pufferfish framework. Since this mechanism may be computationally\ninefficient, we provide an additional mechanism that applies to some practical\ncases such as physical activity measurements across time, and is\ncomputationally efficient. Our experimental evaluations indicate that this\nmechanism provides privacy and utility for synthetic as well as real data in\ntwo separate domains.\n", "versions": [{"version": "v1", "created": "Sun, 13 Mar 2016 00:47:15 GMT"}, {"version": "v2", "created": "Tue, 23 Aug 2016 06:01:57 GMT"}, {"version": "v3", "created": "Sun, 12 Mar 2017 22:47:02 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Song", "Shuang", ""], ["Wang", "Yizhen", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "1603.04085", "submitter": "Michael Reiter", "authors": "Andrew Chi, Robert Cochran, Marie Nesfield, Michael K. Reiter and\n  Cynthia Sturton", "title": "Server-side verification of client behavior in cryptographic protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous exploits of client-server protocols and applications involve\nmodifying clients to behave in ways that untampered clients would not, such as\ncrafting malicious packets. In this paper, we demonstrate practical\nverification of a cryptographic protocol client's messaging behavior as being\nconsistent with the client program it is believed to be running. Moreover, we\naccomplish this without modifying the client in any way, and without knowing\nall of the client-side inputs driving its behavior. Our toolchain for verifying\na client's messages explores multiple candidate execution paths in the client\nconcurrently, an innovation that we show is both specifically useful for\ncryptographic protocol clients and more generally useful for client\napplications of other types, as well. In addition, our toolchain includes a\nnovel approach to symbolically executing the client software in multiple passes\nthat defers expensive functions until their inputs can be inferred and\nconcretized. We demonstrate client verification on OpenSSL to show that, e.g.,\nHeartbleed exploits can be detected without Heartbleed-specific filtering and\nwithin seconds of the first malicious packet, and that verification of\nlegitimate clients can keep pace with, e.g., Gmail workloads.\n", "versions": [{"version": "v1", "created": "Sun, 13 Mar 2016 22:39:02 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Chi", "Andrew", ""], ["Cochran", "Robert", ""], ["Nesfield", "Marie", ""], ["Reiter", "Michael K.", ""], ["Sturton", "Cynthia", ""]]}, {"id": "1603.04228", "submitter": "Juan Jos\\'e Berm\\'udez", "authors": "Juanjo Berm\\'udez", "title": "A practical multi-party computation algorithm for a secure distributed\n  online voting system", "comments": "7 pages, 6 tables, patent pending (WO 2015193524 A1)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an online voting architecture based on partitioning the election\nin small clusters of voters and using a new Multi-party Computation algorithm\nfor obtaining voting results from the clusters. This new algorithm has some\npractical advantages over other previously known algorithms and isn't bound to\nany specific cryptographic concept; so it can be adapted to future\ncryptographic exigencies. Compared with other online voting technologies, we\nsee that this new architecture is less vulnerable to hacker attacks and attacks\nfrom dishonest authorities, given that no sensitive information is stored in\nany public server and there is no need for any trustee to safeguard the\nlegality of the election process. Even in case of an attack succeeding, the\nrisks associated with the overall election are far lower than with any other\nvoting system. This architecture can also be combined with any other voting\nsystem, inheriting advantages from both systems.\n", "versions": [{"version": "v1", "created": "Mon, 14 Mar 2016 12:10:47 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Berm\u00fadez", "Juanjo", ""]]}, {"id": "1603.04264", "submitter": "Dipjyoti Paul", "authors": "Dipjyoti Paul, Monisankha Pal and Goutam Saha", "title": "Novel Speech Features for Improved Detection of Spoofing Attacks", "comments": "Presented in IEEE 2015 Annual IEEE India Conference (INDICON)", "journal-ref": null, "doi": "10.1109/INDICON.2015.7443805", "report-no": null, "categories": "cs.SD cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Now-a-days, speech-based biometric systems such as automatic speaker\nverification (ASV) are highly prone to spoofing attacks by an imposture. With\nrecent development in various voice conversion (VC) and speech synthesis (SS)\nalgorithms, these spoofing attacks can pose a serious potential threat to the\ncurrent state-of-the-art ASV systems. To impede such attacks and enhance the\nsecurity of the ASV systems, the development of efficient anti-spoofing\nalgorithms is essential that can differentiate synthetic or converted speech\nfrom natural or human speech. In this paper, we propose a set of novel speech\nfeatures for detecting spoofing attacks. The proposed features are computed\nusing alternative frequency-warping technique and formant-specific block\ntransformation of filter bank log energies. We have evaluated existing and\nproposed features against several kinds of synthetic speech data from ASVspoof\n2015 corpora. The results show that the proposed techniques outperform existing\napproaches for various spoofing attack detection task. The techniques\ninvestigated in this paper can also accurately classify natural and synthetic\nspeech as equal error rates (EERs) of 0% have been achieved.\n", "versions": [{"version": "v1", "created": "Mon, 14 Mar 2016 13:49:18 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Paul", "Dipjyoti", ""], ["Pal", "Monisankha", ""], ["Saha", "Goutam", ""]]}, {"id": "1603.04374", "submitter": "Phillip Lee", "authors": "Phillip Lee, Andrew Clark, Basel Alomair, Linda Bushnell, Radha\n  Poovendran", "title": "Adaptive Mitigation of Multi-Virus Propagation: A Passivity-Based\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware propagation poses a growing threat to networked systems such as\ncomputer networks and cyber-physical systems. Current approaches to defending\nagainst malware propagation are based on patching or filtering susceptible\nnodes at a fixed rate. When the propagation dynamics are unknown or uncertain,\nhowever, the static rate that is chosen may be either insufficient to remove\nall viruses or too high, incurring additional performance cost. In this paper,\nwe formulate adaptive strategies for mitigating multiple malware epidemics when\nthe propagation rate is unknown, using patching and filtering-based defense\nmechanisms. In order to identify conditions for ensuring that all viruses are\nasymptotically removed, we show that the malware propagation, patching, and\nfiltering processes can be modeled as coupled passive dynamical systems. We\nprove that the patching rate required to remove all viruses is bounded above by\nthe passivity index of the coupled system, and formulate the problem of\nselecting the minimum-cost mitigation strategy. Our results are evaluated\nthrough numerical study.\n", "versions": [{"version": "v1", "created": "Mon, 14 Mar 2016 18:07:45 GMT"}, {"version": "v2", "created": "Tue, 20 Sep 2016 19:16:30 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Lee", "Phillip", ""], ["Clark", "Andrew", ""], ["Alomair", "Basel", ""], ["Bushnell", "Linda", ""], ["Poovendran", "Radha", ""]]}, {"id": "1603.04386", "submitter": "Marko Cari\\'c M", "authors": "Marko Cari\\'c, Miodrag \\v{Z}ivkovi\\'c", "title": "On the number of equivalence classes of invertible Boolean functions\n  under action of permutation of variables on domain and range", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CR cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $V_n$ be the number of equivalence classes of invertible maps from\n$\\{0,1\\}^n$ to $\\{0,1\\}^n$, under action of permutation of variables on domain\nand range. So far, the values $V_n$ have been known for $n\\le 6$. This paper\ndescribes the procedure by which the values of $V_n$ are calculated for $n\\le\n30$.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 16:38:54 GMT"}, {"version": "v2", "created": "Wed, 6 Apr 2016 14:59:16 GMT"}], "update_date": "2016-04-07", "authors_parsed": [["Cari\u0107", "Marko", ""], ["\u017divkovi\u0107", "Miodrag", ""]]}, {"id": "1603.04865", "submitter": "Amit Dvir Dr.", "authors": "Amit Dvir, Yehonatan Zion, Jonathan Muehlstein, Ofir Pele, Chen Hajaj\n  and Ran Dubin", "title": "Robust Machine Learning for Encrypted Traffic Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Desktops and laptops can be maliciously exploited to violate privacy. In this\npaper, we consider the daily battle between the passive attacker who is\ntargeting a specific user against a user that may be adversarial opponent. In\nthis scenario, while the attacker tries to choose the best vector attack by\nsurreptitiously monitoring the victims encrypted network traffic in order to\nidentify users parameters such as the Operating System (OS), browser and apps.\nThe user may use tools such as a Virtual Private Network (VPN) or even change\nprotocols parameters to protect his/her privacy. We provide a large dataset of\nmore than 20,000 examples for this task. We run a comprehensive set of\nexperiments, that achieves high (above 85) classification accuracy, robustness\nand resilience to changes of features as a function of different network\nconditions at test time. We also show the effect of a small training set on the\naccuracy.\n", "versions": [{"version": "v1", "created": "Tue, 15 Mar 2016 20:00:54 GMT"}, {"version": "v2", "created": "Wed, 23 Mar 2016 07:00:32 GMT"}, {"version": "v3", "created": "Thu, 7 Apr 2016 05:40:25 GMT"}, {"version": "v4", "created": "Thu, 21 Jul 2016 06:34:20 GMT"}, {"version": "v5", "created": "Sun, 13 Aug 2017 08:38:04 GMT"}, {"version": "v6", "created": "Mon, 20 Jul 2020 09:42:42 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Dvir", "Amit", ""], ["Zion", "Yehonatan", ""], ["Muehlstein", "Jonathan", ""], ["Pele", "Ofir", ""], ["Hajaj", "Chen", ""], ["Dubin", "Ran", ""]]}, {"id": "1603.05086", "submitter": "Vladimir Edemskiy", "authors": "Zhixiong Chen, Vladimir Edemskiy", "title": "Linear complexity of quaternary sequences over Z_4 derived from\n  generalized cyclotomic classes modulo 2p", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We determine the exact values of the linear complexity of 2p-periodic\nquaternary sequences over Z_4 (the residue class ring modulo 4) defined from\nthe generalized cyclotomic classes modulo 2p in terms of the theory of of\nGalois rings of characteristic 4, where p is an odd prime. Compared to the case\nof quaternary sequences over the finite field of order 4, it is more dificult\nand complicated to consider the roots of polynomials in Z_4[X] due to the zero\ndivisors in Z_4 and hence brings some interesting twists. We answer an open\nproblem proposed by Kim, Hong and Song.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 19:23:03 GMT"}], "update_date": "2016-03-17", "authors_parsed": [["Chen", "Zhixiong", ""], ["Edemskiy", "Vladimir", ""]]}, {"id": "1603.05128", "submitter": "Jean-Pierre  Tillich", "authors": "Philippe Gaborit, Adrien Hauteville, Jean-Pierre Tillich", "title": "RankSynd a PRNG Based on Rank Metric", "comments": null, "journal-ref": "published with minor modifications in the proceedings Post-Quantum\n  Cryptography - 7th International Workshop, PQCrypto 2016, Fukuoka, Japan,\n  February 24-26, 2016, LNCS 9606, p18-28", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a pseudo-random generator based on the difficulty\nof the syndrome decoding problem for rank metric codes. We also study the\nresistance of this problem against a quantum computer. Our results show that\nwith rank metric it is possible to obtain fast PRNG with small public data,\nwithout considering additional structure for public matrices like\nquasi-cyclicity for Hamming distance.\n", "versions": [{"version": "v1", "created": "Wed, 16 Mar 2016 14:46:36 GMT"}], "update_date": "2016-03-17", "authors_parsed": [["Gaborit", "Philippe", ""], ["Hauteville", "Adrien", ""], ["Tillich", "Jean-Pierre", ""]]}, {"id": "1603.05226", "submitter": "Eshan Chattopadhyay", "authors": "Eshan Chattopadhyay, Xin Li", "title": "Explicit Non-Malleable Extractors, Multi-Source Extractors and Almost\n  Optimal Privacy Amplification Protocols", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We make progress in the following three problems: 1. Constructing optimal\nseeded non-malleable extractors; 2. Constructing optimal privacy amplification\nprotocols with an active adversary, for any security parameter; 3. Constructing\nextractors for independent weak random sources, when the min-entropy is\nextremely small (i.e., near logarithmic).\n  For the first two problems, the best known non-malleable extractors by\nChattopadhyay, Goyal and Li [CGL16], and by Cohen [Coh16a,Coh16b] all require\nseed length and min-entropy at least $\\log^2 (1/\\epsilon)$, where $\\epsilon$ is\nthe error of the extractor. As a result, the best known explicit privacy\namplification protocols with an active adversary, which achieve 2 rounds of\ncommunication and optimal entropy loss in [Li15c,CGL16], can only handle\nsecurity parameter up to $s=\\Omega(\\sqrt{k})$, where $k$ is the min-entropy of\nthe shared secret weak random source. For larger $s$ the best known protocol\nwith optimal entropy loss in [Li15c] requires $O(s/\\sqrt{k})$ rounds of\ncommunication.\n  In this paper we give an explicit non-malleable extractor that only requires\nseed length and min-entropy $\\log^{1+o(1)} (n/\\epsilon)$, which also yields a\n2-round privacy amplification protocol with optimal entropy loss for security\nparameter up to $s=k^{1-\\alpha}$ for any constant $\\alpha>0$.\n  For the third problem, previously the best known extractor which supports the\nsmallest min-entropy due to Li [Li13a], requires min-entropy $\\log^{2+\\delta}\nn$ and uses $O(1/\\delta)$ sources, for any constant $\\delta>0$. A very recent\nresult by Cohen and Schulman [CS16] improves this, and constructed explicit\nextractors that use $O(1/\\delta)$ sources for min-entropy $\\log^{1+\\delta} n$,\nany constant $\\delta>0$. In this paper we further improve their result, and\ngive an explicit extractor that uses $O(1)$ (an absolute constant) sources for\nmin-entropy $\\log^{1+o(1)} n$.\n", "versions": [{"version": "v1", "created": "Wed, 16 Mar 2016 19:24:59 GMT"}, {"version": "v2", "created": "Tue, 5 Apr 2016 00:33:12 GMT"}], "update_date": "2016-04-06", "authors_parsed": [["Chattopadhyay", "Eshan", ""], ["Li", "Xin", ""]]}, {"id": "1603.05240", "submitter": "Jonathan Harvey-Buschel", "authors": "Jonathan Harvey-Buschel and Can Kisagun", "title": "Bitcoin Mining Decentralization via Cost Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin mining presents a significant economic incentive for efficient\nhashing and broadcast of data, both parameters stemming from the Proofs of Work\nused to advance the network. This incentive has led to the development of\nBitcoin specific application specific integrated circuits and centralized\nmining pools, undermining the decentralized motivations behind Bitcoin's\ndesign. In addition, the imminent block reward halving threatens the\nprofitability of mining at any scale. Some work has been done in formal models\nfor miner profitability, but existing models do not account for conditions such\nas the pricing of off-peak power and diverse investment strategies regarding\nsunken costs. There is also a lack of formal study of how the profit model\nchanges as mining scales from the individual to the industrial level. Given the\nlack of analysis of these conditions, there are alternative models for\nprofitable or net zero mining that operate at smaller, and therefore more\ndesirable, scale.\n", "versions": [{"version": "v1", "created": "Wed, 16 Mar 2016 19:55:54 GMT"}], "update_date": "2016-03-17", "authors_parsed": [["Harvey-Buschel", "Jonathan", ""], ["Kisagun", "Can", ""]]}, {"id": "1603.05369", "submitter": "Kim-Kwang Raymond Choo", "authors": "Teing Yee Yang, Ali Dehghantanha, Kim-Kwang Raymond Choo, Zaiton Muda", "title": "Windows Instant Messaging App Forensics: Facebook and Skype as Case\n  Studies", "comments": null, "journal-ref": "PLoS ONE 11(3): e0150300 (2016)", "doi": "10.1371/journal.pone.0150300", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instant messaging (IM) has changed the way people communicate with each\nother. However, the interactive and instant nature of these applications (apps)\nmade them an attractive choice for malicious cyber activities such as phishing.\nThe forensic examination of IM apps for modern Windows 8.1 (or later) has been\nlargely unexplored, as the platform is relatively new. In this paper, we seek\nto determine the data remnants from the use of two popular Windows Store\napplication software for instant messaging, namely Facebook and Skype on a\nWindows 8.1 client machine. This research contributes to an in-depth\nunderstanding of the types of terrestrial artefacts that are likely to remain\nafter the use of instant messaging services and application software on a\ncontemporary Windows operating system. Potential artefacts detected during the\nresearch include data relating to the installation or uninstallation of the\ninstant messaging application software, log-in and log-off information, contact\nlists, conversations, and transferred files.\n", "versions": [{"version": "v1", "created": "Thu, 17 Mar 2016 06:48:13 GMT"}], "update_date": "2016-03-18", "authors_parsed": [["Yang", "Teing Yee", ""], ["Dehghantanha", "Ali", ""], ["Choo", "Kim-Kwang Raymond", ""], ["Muda", "Zaiton", ""]]}, {"id": "1603.05462", "submitter": "Aanjhan Ranganathan", "authors": "Aanjhan Ranganathan, Hildur \\'Olafsd\\'ottir, Srdjan Capkun", "title": "SPREE: Spoofing Resistant GPS Receiver", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global Positioning System (GPS) is used ubiquitously in a wide variety of\napplications ranging from navigation and tracking to modern smart grids and\ncommunication networks. However, it has been demonstrated that modern GPS\nreceivers are vulnerable to signal spoofing attacks. For example, today it is\npossible to change the course of a ship or force a drone to land in an hostile\narea by simply spoofing GPS signals. Several countermeasures have been proposed\nin the past to detect GPS spoofing attacks. These countermeasures offer\nprotection only against naive attackers. They are incapable of detecting strong\nattackers such as those capable of seamlessly taking over a GPS receiver, which\nis currently receiving legitimate satellite signals, and spoofing them to an\narbitrary location. Also, there is no hardware platform that can be used to\ncompare and evaluate the effectiveness of existing countermeasures in\nreal-world scenarios. In this work, we present SPREE, which is, to the best of\nour knowledge, the first GPS receiver capable of detecting all spoofing attacks\ndescribed in literature. Our novel spoofing detection technique called\nauxiliary peak tracking enables detection of even a strong attacker capable of\nexecuting the seamless takeover attack. We implement and evaluate our receiver\nagainst three different sets of GPS signal traces and show that SPREE\nconstrains even a strong attacker (capable of seamless takeover attack) from\nspoofing the receiver to a location not more than 1 km away from its true\nlocation. This is a significant improvement over modern GPS receivers that can\nbe spoofed to any arbitrary location. Finally, we release our implementation\nand datasets to the community for further research and development.\n", "versions": [{"version": "v1", "created": "Thu, 17 Mar 2016 13:00:41 GMT"}], "update_date": "2016-03-18", "authors_parsed": [["Ranganathan", "Aanjhan", ""], ["\u00d3lafsd\u00f3ttir", "Hildur", ""], ["Capkun", "Srdjan", ""]]}, {"id": "1603.05615", "submitter": "Michael Reiter", "authors": "Ziqiao Zhou, Michael K. Reiter and Yinqian Zhang", "title": "A software approach to defeating side channels in last-level caches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a software approach to mitigate access-driven side-channel attacks\nthat leverage last-level caches (LLCs) shared across cores to leak information\nbetween security domains (e.g., tenants in a cloud). Our approach dynamically\nmanages physical memory pages shared between security domains to disable\nsharing of LLC lines, thus preventing \"Flush-Reload\" side channels via LLCs. It\nalso manages cacheability of memory pages to thwart cross-tenant \"Prime-Probe\"\nattacks in LLCs. We have implemented our approach as a memory management\nsubsystem called CacheBar within the Linux kernel to intervene on such side\nchannels across container boundaries, as containers are a common method for\nenforcing tenant isolation in Platform-as-a-Service (PaaS) clouds. Through\nformal verification, principled analysis, and empirical evaluation, we show\nthat CacheBar achieves strong security with small performance overheads for\nPaaS workloads.\n", "versions": [{"version": "v1", "created": "Thu, 17 Mar 2016 19:02:56 GMT"}], "update_date": "2016-03-18", "authors_parsed": [["Zhou", "Ziqiao", ""], ["Reiter", "Michael K.", ""], ["Zhang", "Yinqian", ""]]}, {"id": "1603.05709", "submitter": "Amit Bhattacharjee Dr.", "authors": "Amit Kumar Bhattacharjee", "title": "Stochastic kinetics reveal imperative role of anisotropic interfacial\n  tension to determine morphology and evolution of nucleated droplets in\n  nematogenic films", "comments": "13 pages, 8 figures", "journal-ref": "Scientific Reports 7, Article number: 40059 (2017)", "doi": "10.1038/srep40059", "report-no": null, "categories": "cond-mat.soft cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For isotropic fluids, classical nucleation theory predicts the nucleation\nrate, barrier height and critical droplet size by accounting for the\ncompetition between bulk energy and interfacial tension. The nucleation process\nin liquid crystals is less understood. We numerically investigate nucleation in\nmonolayered nematogenic films using a mesoscopic framework, in particular, we\nstudy the mor- phology and kinetic pathway in spontaneous formation and growth\nof droplets of the stable phase in the metastable background. The parameter\n$\\kappa$ that quantifies the anisotropic elastic energy plays a central role in\ndetermining the geometric structure of the droplets. Noncircular nematic\ndroplets with homogeneous director orientation are nucleated in a background of\nsupercooled isotropic phase for small $\\kappa$. For large $\\kappa$, noncircular\ndroplets with integer topological charge, accompanied by a biaxial ring at the\nouter surface, are nucleated. The isotropic droplet shape in a superheated\nnematic background is found to depend on $\\kappa$ in a similar way. Identical\ngrowth laws are found in the two cases, although an unusual two-stage mechanism\nis observed in the nucleation of isotropic droplets. Temporal distributions of\nsuccessive events indicate the relevance of long-ranged elasticity-mediated\ninteractions within the isotropic domains. Implications for a theoretical\ndescription of nucleation in anisotropic fluids are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 17 Mar 2016 22:12:33 GMT"}, {"version": "v2", "created": "Mon, 28 Mar 2016 10:37:35 GMT"}, {"version": "v3", "created": "Wed, 18 May 2016 08:11:53 GMT"}, {"version": "v4", "created": "Mon, 11 Jul 2016 20:44:50 GMT"}, {"version": "v5", "created": "Mon, 31 Jul 2017 03:36:42 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Bhattacharjee", "Amit Kumar", ""]]}, {"id": "1603.06028", "submitter": "Ethan Rudd", "authors": "Ethan M. Rudd, Andras Rozsa, Manuel G\\\"unther, Terrance E. Boult", "title": "A Survey of Stealth Malware: Attacks, Mitigation Measures, and Steps\n  Toward Autonomous Open World Solutions", "comments": "Pre-Print of a manuscript Accepted to IEEE Communications Surveys and\n  Tutorials (COMST) on December 1, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As our professional, social, and financial existences become increasingly\ndigitized and as our government, healthcare, and military infrastructures rely\nmore on computer technologies, they present larger and more lucrative targets\nfor malware. Stealth malware in particular poses an increased threat because it\nis specifically designed to evade detection mechanisms, spreading dormant, in\nthe wild for extended periods of time, gathering sensitive information or\npositioning itself for a high-impact zero-day attack. Policing the growing\nattack surface requires the development of efficient anti-malware solutions\nwith improved generalization to detect novel types of malware and resolve these\noccurrences with as little burden on human experts as possible. In this paper,\nwe survey malicious stealth technologies as well as existing solutions for\ndetecting and categorizing these countermeasures autonomously. While machine\nlearning offers promising potential for increasingly autonomous solutions with\nimproved generalization to new malware types, both at the network level and at\nthe host level, our findings suggest that several flawed assumptions inherent\nto most recognition algorithms prevent a direct mapping between the stealth\nmalware recognition problem and a machine learning solution. The most notable\nof these flawed assumptions is the closed world assumption: that no sample\nbelonging to a class outside of a static training set will appear at query\ntime. We present a formalized adaptive open world framework for stealth malware\nrecognition and relate it mathematically to research from other machine\nlearning domains.\n", "versions": [{"version": "v1", "created": "Sat, 19 Mar 2016 01:23:45 GMT"}, {"version": "v2", "created": "Fri, 2 Dec 2016 19:00:50 GMT"}], "update_date": "2016-12-05", "authors_parsed": [["Rudd", "Ethan M.", ""], ["Rozsa", "Andras", ""], ["G\u00fcnther", "Manuel", ""], ["Boult", "Terrance E.", ""]]}, {"id": "1603.06113", "submitter": "Marvin K\\\"unnemann", "authors": "Benjamin Doerr and Marvin K\\\"unnemann", "title": "Improved Protocols and Hardness Results for the Two-Player\n  Cryptogenography Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cryptogenography problem, introduced by Brody, Jakobsen, Scheder, and\nWinkler (ITCS 2014), is to collaboratively leak a piece of information known to\nonly one member of a group (i)~without revealing who was the origin of this\ninformation and (ii)~without any private communication, neither during the\nprocess nor before. Despite several deep structural results, even the smallest\ncase of leaking one bit of information present at one of two players is not\nwell understood. Brody et al.\\ gave a 2-round protocol enabling the two players\nto succeed with probability $1/3$ and showed the hardness result that no\nprotocol can give a success probability of more than~$3/8$.\n  In this work, we show that neither bound is tight. Our new hardness result,\nobtained by a different application of the concavity method used also in the\nprevious work, states that a success probability better than 0.3672 is not\npossible. Using both theoretical and numerical approaches, we improve the lower\nbound to $0.3384$, that is, give a protocol leading to this success\nprobability. To ease the design of new protocols, we prove an equivalent\nformulation of the cryptogenography problem as solitaire vector splitting game.\nVia an automated game tree search, we find good strategies for this game. We\nthen translate the splits that occurred in this strategy into inequalities\nrelating position values and use an LP solver to find an optimal solution for\nthese inequalities. This gives slightly better game values, but more\nimportantly, it gives a more compact representation of the protocol and a way\nto easily verify the claimed quality of the protocol.\n  These improved bounds, as well as the large sizes and depths of the improved\nprotocols we find, suggests that finding good protocols for the\ncryptogenography problem as well as understanding their structure are harder\nthan what the simple problem formulation suggests.\n", "versions": [{"version": "v1", "created": "Sat, 19 Mar 2016 17:02:43 GMT"}], "update_date": "2016-03-22", "authors_parsed": [["Doerr", "Benjamin", ""], ["K\u00fcnnemann", "Marvin", ""]]}, {"id": "1603.06133", "submitter": "Eugene Panferov", "authors": "Eugene Panferov", "title": "An Observation About Passphrases: Syntax vs Entropy", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On the premise that we are using passwords composed of multiple English\nwords, we argue that using syntactically correct passphrases has no significant\nimpact on the security in comparison to randomly arranged collections of words.\nWe only analyze the contribution of the syntax itself. A comparison to the\nother kinds of passwords is out of the scope.\n", "versions": [{"version": "v1", "created": "Sat, 19 Mar 2016 19:23:05 GMT"}], "update_date": "2016-03-22", "authors_parsed": [["Panferov", "Eugene", ""]]}, {"id": "1603.06227", "submitter": "Swaroop Ghosh", "authors": "Nitin Rathi, Asmit De, Helia Naeimi and Swaroop Ghosh", "title": "Cache Bypassing and Checkpointing to Circumvent Data Security Attacks on\n  STTRAM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spin-Transfer Torque RAM (STTRAM) is promising for cache applications.\nHowever, it brings new data security issues that were absent in volatile memory\ncounterparts such as Static RAM (SRAM) and embedded Dynamic RAM (eDRAM). This\nis primarily due to the fundamental dependency of this memory technology on\nambient parameters such as magnetic field and temperature that can be exploited\nto tamper with the stored data. In this paper we propose three techniques to\nenable error free computation without stalling the system, (a) stalling where\nthe system is halted during attack; (b) cache bypass during gradually ramping\nattack where the last level cache (LLC) is bypassed and the upper level caches\ninteract directly with the main memory; and, (c) checkpointing along with\nbypass during sudden attack where the processor states are saved periodically\nand the LLC is written back at regular intervals. During attack the system goes\nback to the last checkpoint and the computation continues with bypassed cache.\nWe performed simulation for different duration and frequency of attack on\nSPLASH benchmark suite and the results show an average of 8% degradation in IPC\nfor a one-time attack lasting for 50% of the execution time. The energy\noverhead is 2% for an attack lasting for the entire duration of execution.\n", "versions": [{"version": "v1", "created": "Sun, 20 Mar 2016 15:29:37 GMT"}], "update_date": "2016-03-22", "authors_parsed": [["Rathi", "Nitin", ""], ["De", "Asmit", ""], ["Naeimi", "Helia", ""], ["Ghosh", "Swaroop", ""]]}, {"id": "1603.06289", "submitter": "Muhammad Ikram", "authors": "Muhammad Ikram, Hassan Jameel Asghar, Mohamed Ali Kaafar, Balachander\n  Krishnamurthy, Anirban Mahanti", "title": "Towards Seamless Tracking-Free Web: Improved Detection of Trackers via\n  One-class Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous tools have been developed to aggressively block the execution of\npopular JavaScript programs (JS) in Web browsers. Such blocking also affects\nfunctionality of webpages and impairs user experience. As a consequence, many\nprivacy preserving tools (PP-Tools) that have been developed to limit online\ntracking, often executed via JS, may suffer from poor performance and limited\nuptake. A mechanism that can isolate JS necessary for proper functioning of the\nwebsite from tracking JS would thus be useful. Through the use of a manually\nlabelled dataset composed of 2,612 JS, we show how current PP-Tools are\nineffective in finding the right balance between blocking tracking JS and\nallowing functional JS. To the best of our knowledge, this is the first study\nto assess the performance of current web PP-Tools.\n  To improve this balance, we examine the two classes of JS and hypothesize\nthat tracking JS share structural similarities that can be used to\ndifferentiate them from functional JS. The rationale of our approach is that\nweb developers often borrow and customize existing pieces of code in order to\nembed tracking (resp. functional) JS into their webpages. We then propose\none-class machine learning classifiers using syntactic and semantic features\nextracted from JS. When trained only on samples of tracking JS, our classifiers\nachieve an accuracy of 99%, where the best of the PP-Tools achieved an accuracy\nof 78%.\n  We further test our classifiers and several popular PP-Tools on a corpus of\n4K websites with 135K JS. The output of our best classifier on this data is\nbetween 20 to 64% different from the PP-Tools. We manually analyse a sample of\nthe JS for which our classifier is in disagreement with all other PP-Tools, and\nshow that our approach is not only able to enhance user web experience by\ncorrectly classifying more functional JS, but also discovers previously unknown\ntracking services.\n", "versions": [{"version": "v1", "created": "Sun, 20 Mar 2016 23:33:55 GMT"}], "update_date": "2016-03-22", "authors_parsed": [["Ikram", "Muhammad", ""], ["Asghar", "Hassan Jameel", ""], ["Kaafar", "Mohamed Ali", ""], ["Krishnamurthy", "Balachander", ""], ["Mahanti", "Anirban", ""]]}, {"id": "1603.06297", "submitter": "Chandra Sekhar Mr", "authors": "Mrudula S, ChandraMouli Reddy, Lakshmi Narayana, JayaPrakash, Chandra\n  Sekhar Vorugunti", "title": "Notes on \"An Effective ECC based User Access Control Scheme with\n  Attribute based Encryption for WSN\"", "comments": "AIMOC 2016 Jadavpur university", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of networking and communication technologies results in\namalgamation of 'Internet of Things' and 'Wireless sensor networks' to form\nWSNIT. WSNIT facilitates the WSN to connect dynamically to Internet and\nexchange the data with the external world. The critical data stored in sensor\nnodes related to patient health, environment can be accessed by attackers via\ninsecure internet. To counterattack this, there is a demand for data integrity\nand controlled data access by incorporating a highly secure and light weight\nauthentication schemes. In this context, Santanu et al had proposed an\nattribute based authentication framework for WSN and discussed on its security\nstrengths. In this paper, we do a thorough analysis on Santanu et al scheme, to\nshow that their scheme is susceptible to privileged insider attack and node\ncapture attack. We also demonstrate that Santanu et al scheme consists of major\ninconsistencies which restrict the protocol execution.\n", "versions": [{"version": "v1", "created": "Fri, 18 Mar 2016 08:33:29 GMT"}], "update_date": "2016-03-22", "authors_parsed": [["S", "Mrudula", ""], ["Reddy", "ChandraMouli", ""], ["Narayana", "Lakshmi", ""], ["JayaPrakash", "", ""], ["Vorugunti", "Chandra Sekhar", ""]]}, {"id": "1603.06542", "submitter": "Vassil Roussev", "authors": "Vassil Roussev, Andres Barreto, Irfan Ahmed", "title": "Forensic Acquisition of Cloud Drives", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing and cloud storage services, in particular, pose a new\nchallenge to digital forensic investigations. Currently, evidence acquisition\nfor such services still follows the traditional method of collecting artifacts\non a client device. This approach requires labor-intensive reverse engineering\nefforts, and ultimately results in an acquisition that is inherently\nincomplete. Specifically, it makes the incorrect assumption that all storage\ncontent for an account is fully replicated on the client; further, there are no\nmeans to acquire historical data in the form of document revisions, nor is\nthere a way to acquire cloud-native artifacts, such as Google Docs.\n  In this work, we introduce the concept of API-based evidence acquisition for\ncloud services, which addresses these concerns by utilizing the officially\nsupported API of the service. To demonstrate the utility of this approach, we\npresent a proof-of-concept acquisition tool, kumodd, which can acquire evidence\nfrom four major cloud drive providers: Google Drive, Microsoft OneDrive,\nDropbox, and Box. The implementation provides both command-line and web user\ninterfaces, and can be readily incorporated into established forensic\nprocesses.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2016 06:07:39 GMT"}], "update_date": "2016-03-22", "authors_parsed": [["Roussev", "Vassil", ""], ["Barreto", "Andres", ""], ["Ahmed", "Irfan", ""]]}, {"id": "1603.06597", "submitter": "Max Jakob Maa{\\ss}", "authors": "Dominik Herrmann, Max Maa{\\ss}, Hannes Federrath", "title": "Evaluating the Security of a DNS Query Obfuscation Scheme for Private\n  Web Surfing", "comments": "ICT Systems Security and Privacy Protection. Springer Berlin\n  Heidelberg, 2014. 205-219", "journal-ref": null, "doi": "10.1007/978-3-642-55415-5_17", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Domain Name System (DNS) does not provide query privacy. Query\nobfuscation schemes have been proposed to overcome this limitation, but, so\nfar, they have not been evaluated in a realistic setting. In this paper we\nevaluate the security of a random set range query scheme in a real-world web\nsurfing scenario. We demonstrate that the scheme does not sufficiently\nobfuscate characteristic query patterns, which can be used by an adversary to\ndetermine the visited websites. We also illustrate how to thwart the attack and\ndiscuss practical challenges. Our results suggest that previously published\nevaluations of range queries may give a false sense of the attainable security,\nbecause they do not account for any interdependencies between queries.\n", "versions": [{"version": "v1", "created": "Mon, 21 Mar 2016 20:11:14 GMT"}], "update_date": "2016-03-23", "authors_parsed": [["Herrmann", "Dominik", ""], ["Maa\u00df", "Max", ""], ["Federrath", "Hannes", ""]]}, {"id": "1603.06635", "submitter": "Riccardo Aragona", "authors": "Federico Giacon and Riccardo Aragona and Massimiliano Sala", "title": "A proof of security for a key-policy RS-ABE scheme", "comments": null, "journal-ref": "JP Journal of Algebra, Number Theory and Applications, Vol. 40,\n  No. 1, 2018", "doi": "10.17654/NT040010029", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A revocable-storage attribute-based encryption (RS-ABE) scheme is an\nencryption scheme which extends attribute-based encryption by intro- ducing\nuser revocation. A key-policy RS-ABE scheme links each key to an access\nstructure. We propose a new key-policy RS-ABE scheme whose security we prove in\nterm of indistinguishability under a chosen-plaintext attack (IND-CPA).\n", "versions": [{"version": "v1", "created": "Mon, 21 Mar 2016 22:12:40 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Giacon", "Federico", ""], ["Aragona", "Riccardo", ""], ["Sala", "Massimiliano", ""]]}, {"id": "1603.06675", "submitter": "Swaroop Ghosh", "authors": "Nitin Rathi, Helia Naeimi and Swaroop Ghosh", "title": "Side Channel Attacks on STTRAM and Low-Overhead Countermeasures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spin Transfer Torque RAM (STTRAM) is a promising candidate for Last Level\nCache (LLC) due to high endurance, high density and low leakage. One of the\nmajor disadvantages of STTRAM is high write latency and write current.\nAdditionally, the latency and current depends on the polarity of the data being\nwritten. These features introduce major security vulnerabilities and expose the\ncache memory to side channel attacks. In this paper we propose a novel side\nchannel attack model where the adversary can monitor the supply current of the\nmemory array to partially identify the sensitive cache data that is being read\nor written. We propose several low cost solutions such as short retention\nSTTRAM, 1-bit parity, multi-bit random write and constant current write driver\nto mitigate the attack. 1-bit parity reduces the number of distinct write\ncurrent states by 30% for 32-bit word and the current signature is further\nobfuscated by multi-bit random writes. The constant current write makes it more\nchallenging for the attacker to extract the entire word using a single supply\ncurrent signature.\n", "versions": [{"version": "v1", "created": "Tue, 22 Mar 2016 04:44:49 GMT"}], "update_date": "2016-03-23", "authors_parsed": [["Rathi", "Nitin", ""], ["Naeimi", "Helia", ""], ["Ghosh", "Swaroop", ""]]}, {"id": "1603.06830", "submitter": "Ajay Sharma Dr.", "authors": "Sonam Chauhan and Ajay Sharma", "title": "Fuzzy Commitment Scheme based on Reed Solomon Codes", "comments": "This paper requires a lot of improvements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conventional commitment scheme requires both commitment string and a\nvalid key for the sender to verify his commitment. Differ from the conventional\ncommitment scheme; fuzzy commitment scheme accepts the key that is similar to\nthe original key. The new opening key, not identical to the original key,\ndiffers from the initial key in some suitable metrics. The fuzziness in the\nfuzzy commitment scheme tolerate small amount of corruptions. The fuzzy\ncommitment scheme based on the cryptographic hash functions suffers security\nimperfections. Thus, this paper combines the fuzzy commitment scheme with the\nReed Solomon error correction codes, which are capable of correcting certain\nnumber of errors. As a result, Reed Solomon code proves better alternative for\nfuzzy commitment scheme than hash functions, as the Reed Solomon codes are more\nsecure than the hashing techniques. Moreover, the Fuzzy Commitment Scheme based\non Reed Solomon codes provides security at two levels that making it suitable\nfor securing data. This paper explore the efficiency of executing fuzzy\ncommitment scheme in conjunction with Reed Solomon code as a novel better\nalternative to the conventional commitment scheme.\n", "versions": [{"version": "v1", "created": "Tue, 22 Mar 2016 15:30:24 GMT"}, {"version": "v2", "created": "Wed, 6 Apr 2016 17:08:01 GMT"}], "update_date": "2016-04-07", "authors_parsed": [["Chauhan", "Sonam", ""], ["Sharma", "Ajay", ""]]}, {"id": "1603.06870", "submitter": "Weina Wang", "authors": "Weina Wang, Lei Ying and Junshan Zhang", "title": "The Value of Privacy: Strategic Data Subjects, Incentive Mechanisms and\n  Fundamental Limits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the value of data privacy in a game-theoretic model of trading\nprivate data, where a data collector purchases private data from strategic data\nsubjects (individuals) through an incentive mechanism. The private data of each\nindividual represents her knowledge about an underlying state, which is the\ninformation that the data collector desires to learn. Different from most of\nthe existing work on privacy-aware surveys, our model does not assume the data\ncollector to be trustworthy. Then, an individual takes full control of its own\ndata privacy and reports only a privacy-preserving version of her data.\n  In this paper, the value of $\\epsilon$ units of privacy is measured by the\nminimum payment of all nonnegative payment mechanisms, under which an\nindividual's best response at a Nash equilibrium is to report the data with a\nprivacy level of $\\epsilon$. The higher $\\epsilon$ is, the less private the\nreported data is. We derive lower and upper bounds on the value of privacy\nwhich are asymptotically tight as the number of data subjects becomes large.\nSpecifically, the lower bound assures that it is impossible to use less amount\nof payment to buy $\\epsilon$ units of privacy, and the upper bound is given by\nan achievable payment mechanism that we designed. Based on these fundamental\nlimits, we further derive lower and upper bounds on the minimum total payment\nfor the data collector to achieve a given learning accuracy target, and show\nthat the total payment of the designed mechanism is at most one individual's\npayment away from the minimum.\n", "versions": [{"version": "v1", "created": "Tue, 22 Mar 2016 17:05:27 GMT"}], "update_date": "2016-03-23", "authors_parsed": [["Wang", "Weina", ""], ["Ying", "Lei", ""], ["Zhang", "Junshan", ""]]}, {"id": "1603.07086", "submitter": "Kai Mindermann", "authors": "Kai Mindermann", "title": "Are easily usable security libraries possible and how should experts\n  work together to create them?", "comments": "ICSE 16 May 16-16 2016, Austin, TX, USA (CHASE)", "journal-ref": null, "doi": "10.1145/2897586.2897610", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to non-experts also developing security relevant applications it is\nnecessary to support them too. Some improvements in the current research may\nnot reach or impact these developers. Nonetheless these developers use security\nlibraries. There are findings that even their usage is not easily possible and\napplications are left vulnerable to supposedly treated threats. So it is\nimportant to improve the usability of the security libraries. This is itself is\nnot straightforward because of a required maturing process for example. By\ngetting together experts of different involved areas, especially cryptographic\nand API-usability experts, both of the problems can be tackled.\n", "versions": [{"version": "v1", "created": "Wed, 23 Mar 2016 08:06:08 GMT"}], "update_date": "2016-03-24", "authors_parsed": [["Mindermann", "Kai", ""]]}, {"id": "1603.07294", "submitter": "James Foulds", "authors": "James Foulds, Joseph Geumlek, Max Welling, Kamalika Chaudhuri", "title": "On the Theory and Practice of Privacy-Preserving Bayesian Data Analysis", "comments": "Updated to match the accepted UAI version. Generalized the ARE result\n  and included a more detailed proof. Improved some figures, etc", "journal-ref": "Proceedings of the 32nd Conference on Uncertainty in Artificial\n  Intelligence (UAI), 2016", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian inference has great promise for the privacy-preserving analysis of\nsensitive data, as posterior sampling automatically preserves differential\nprivacy, an algorithmic notion of data privacy, under certain conditions\n(Dimitrakakis et al., 2014; Wang et al., 2015). While this one posterior sample\n(OPS) approach elegantly provides privacy \"for free,\" it is data inefficient in\nthe sense of asymptotic relative efficiency (ARE). We show that a simple\nalternative based on the Laplace mechanism, the workhorse of differential\nprivacy, is as asymptotically efficient as non-private posterior inference,\nunder general assumptions. This technique also has practical advantages\nincluding efficient use of the privacy budget for MCMC. We demonstrate the\npracticality of our approach on a time-series analysis of sensitive military\nrecords from the Afghanistan and Iraq wars disclosed by the Wikileaks\norganization.\n", "versions": [{"version": "v1", "created": "Wed, 23 Mar 2016 18:31:05 GMT"}, {"version": "v2", "created": "Thu, 9 Jun 2016 00:00:10 GMT"}], "update_date": "2016-06-10", "authors_parsed": [["Foulds", "James", ""], ["Geumlek", "Joseph", ""], ["Welling", "Max", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "1603.07351", "submitter": "Christian Cachin", "authors": "Christian Cachin, Simon Schubert, Marko Vukoli\\'c", "title": "Non-determinism in Byzantine Fault-Tolerant Replication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Service replication distributes an application over many processes for\ntolerating faults, attacks, and misbehavior among a subset of the processes.\nThe established state-machine replication paradigm inherently requires the\napplication to be deterministic. This paper distinguishes three models for\ndealing with non-determinism in replicated services, where some processes are\nsubject to faults and arbitrary behavior (so-called Byzantine faults): first, a\nmodular approach that does not require any changes to the potentially\nnon-deterministic application (and neither access to its internal data);\nsecond, a master-slave approach, in which ties are broken by a leader and the\nother processes validate the choices of the leader; and finally, a treatment of\napplications that use cryptography and secret keys. Cryptographic operations\nand secrets must be treated specially because they require strong randomness to\nsatisfy their goals.\n  The paper also introduces two new protocols. The first uses the modular\napproach for filtering out non-de\\-ter\\-min\\-istic operations in an\napplication. It ensures that all correct processes produce the same outputs and\nthat their internal states do not diverge. The second protocol implements\ncryptographically secure randomness generation with a verifiable random\nfunction and is appropriate for certain security models. All protocols are\ndescribed in a generic way and do not assume a particular implementation of the\nunderlying consensus primitive.\n", "versions": [{"version": "v1", "created": "Wed, 23 Mar 2016 20:42:55 GMT"}, {"version": "v2", "created": "Mon, 19 Dec 2016 17:08:40 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Cachin", "Christian", ""], ["Schubert", "Simon", ""], ["Vukoli\u0107", "Marko", ""]]}, {"id": "1603.07370", "submitter": "Aykut Dengi", "authors": "Joseph Davis, Niranjan Kulkarni, Jinghua Yang, Aykut Dengi, Sarma\n  Vrudhula", "title": "Digital IP Protection Using Threshold Voltage Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a method to completely hide the functionality of a\ndigital standard cell. This is accomplished by a differential threshold logic\ngate (TLG). A TLG with $n$ inputs implements a subset of Boolean functions of\n$n$ variables that are linear threshold functions. The output of such a gate is\none if and only if an integer weighted linear arithmetic sum of the inputs\nequals or exceeds a given integer threshold. We present a novel architecture of\na TLG that not only allows a single TLG to implement a large number of complex\nlogic functions, which would require multiple levels of logic when implemented\nusing conventional logic primitives, but also allows the selection of that\nsubset of functions by assignment of the transistor threshold voltages to the\ninput transistors. To obfuscate the functionality of the TLG, weights of some\ninputs are set to zero by setting their device threshold to be a high $V_t$.\nThe threshold voltage of the remaining transistors is set to low $V_t$ to\nincrease their transconductance. The function of a TLG is not determined by the\ncell itself but rather the signals that are connected to its inputs. This makes\nit possible to hide the support set of the function by essentially removing\nsome variable from the support set of the function by selective assignment of\nhigh and low $V_t$ to the input transistors. We describe how a standard cell\nlibrary of TLGs can be mixed with conventional standard cells to realize\ncomplex logic circuits, whose function can never be discovered by reverse\nengineering. A 32-bit Wallace tree multiplier and a 28-bit 4-tap filter were\nsynthesized on an ST 65nm process, placed and routed, then simulated including\nextracted parastics with and without obfuscation. Both obfuscated designs had\nmuch lower area (25%) and much lower dynamic power (30%) than their\nnonobfuscated CMOS counterparts, operating at the same frequency.\n", "versions": [{"version": "v1", "created": "Wed, 23 Mar 2016 21:26:51 GMT"}], "update_date": "2016-03-25", "authors_parsed": [["Davis", "Joseph", ""], ["Kulkarni", "Niranjan", ""], ["Yang", "Jinghua", ""], ["Dengi", "Aykut", ""], ["Vrudhula", "Sarma", ""]]}, {"id": "1603.07399", "submitter": "Zhengjun Cao", "authors": "Zhengjun Cao and Lihua Liu", "title": "A note on \"achieving security, robust cheating resistance, and\n  high-efficiency for outsourcing large matrix multiplication computation to a\n  malicious cloud\"", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Lei et al.'s scheme [Information Sciences, 280 (2014),\n205-217] fails, because the verifying equation does not hold over the infinite\nfield R. For the field R, the computational errors should be considered\nseriously. We also remark that the incurred communication cost in the scheme\ncould be overtake the computational gain, which makes it somewhat artificial.\n", "versions": [{"version": "v1", "created": "Thu, 24 Mar 2016 00:32:46 GMT"}], "update_date": "2016-03-25", "authors_parsed": [["Cao", "Zhengjun", ""], ["Liu", "Lihua", ""]]}, {"id": "1603.07425", "submitter": "Shouhuai Xu", "authors": "Shouhuai Xu and Wenlian Lu and Li Xu", "title": "Push- and Pull-based Epidemic Spreading in Networks: Thresholds and\n  Deeper Insights", "comments": "This paper was submitted in October 2010, revised in April 2011, and\n  accepted in June 2011", "journal-ref": "ACM Transactions on Autonomous and Adaptive Systems (TAAS), 7(3):\n  Article 32 (2012)", "doi": null, "report-no": null, "categories": "cs.CR cs.SI math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the dynamics of computer virus (malware, worm) in cyberspace is\nan important problem that has attracted a fair amount of attention. Early\ninvestigations for this purpose adapted biological epidemic models, and thus\ninherited the so-called homogeneity assumption that each node is equally\nconnected to others. Later studies relaxed this often-unrealistic homogeneity\nassumption, but still focused on certain power-law networks. Recently,\nresearchers investigated epidemic models in {\\em arbitrary} networks (i.e., no\nrestrictions on network topology). However, all these models only capture {\\em\npush-based} infection, namely that an infectious node always actively attempts\nto infect its neighboring nodes. Very recently, the concept of {\\em pull-based}\ninfection was introduced but was not treated rigorously. Along this line of\nresearch, the present paper investigates push- and pull-based epidemic\nspreading dynamics in arbitrary networks, using a Non-linear Dynamical Systems\napproach. The paper advances the state of the art as follows: (1) It presents a\nmore general and powerful sufficient condition (also known as epidemic\nthreshold in the literature) under which the spreading will become stable. (2)\nIt gives both upper and lower bounds on the global mean infection rate,\nregardless of the stability of the spreading. (3) It offers insights into,\namong other things, the estimation of the global mean infection rate through\nlocalized monitoring of a small {\\em constant} number of nodes, {\\em without}\nknowing the values of the parameters.\n", "versions": [{"version": "v1", "created": "Thu, 24 Mar 2016 03:41:38 GMT"}], "update_date": "2016-03-25", "authors_parsed": [["Xu", "Shouhuai", ""], ["Lu", "Wenlian", ""], ["Xu", "Li", ""]]}, {"id": "1603.07432", "submitter": "Shouhuai Xu", "authors": "Zhenxin Zhan and Maochao Xu and Shouhuai Xu", "title": "Predicting Cyber Attack Rates with Extreme Values", "comments": null, "journal-ref": "IEEE Transactions on Information Forensics & Security, 10(8):\n  1666-1677 (2015)", "doi": null, "report-no": null, "categories": "cs.CR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is important to understand to what extent, and in what perspectives, cyber\nattacks can be predicted. Despite its evident importance, this problem was not\ninvestigated until very recently, when we proposed using the innovative\nmethodology of {\\em gray-box prediction}. This methodology advocates the use of\ngray-box models, which accommodate the statistical properties/phenomena\nexhibited by the data. Specifically, we showed that gray-box models that\naccommodate the Long-Range Dependence (LRD) phenomenon can predict the attack\nrate (i.e., the number of attacks per unit time) 1-hour ahead-of-time with an\naccuracy of 70.2-82.1\\%. To the best of our knowledge, this is the first result\nshowing the feasibility of prediction in this domain. We observe that the\nprediction errors are partly caused by the models' incapability in predicting\nthe large attack rates, which are called {\\em extreme values} in statistics.\nThis motivates us to analyze the {\\em extreme-value phenomenon}, by using two\ncomplementary approaches: the Extreme Value Theory (EVT) and the Time Series\nTheory (TST). In this paper, we show that EVT can offer long-term predictions\n(e.g., 24-hour ahead-of-time), while gray-box TST models can predict attack\nrates 1-hour ahead-of-time with an accuracy of 86.0-87.9\\%. We explore\nconnections between the two approaches, and point out future research\ndirections. Although our prediction study is based on specific cyber attack\ndata, our methodology can be equally applied to analyze any cyber attack data\nof its kind.\n", "versions": [{"version": "v1", "created": "Thu, 24 Mar 2016 04:25:12 GMT"}], "update_date": "2016-03-25", "authors_parsed": [["Zhan", "Zhenxin", ""], ["Xu", "Maochao", ""], ["Xu", "Shouhuai", ""]]}, {"id": "1603.07433", "submitter": "Shouhuai Xu", "authors": "Zhenxin Zhan and Maochao Xu and Shouhuai Xu", "title": "Characterizing Honeypot-Captured Cyber Attacks: Statistical Framework\n  and Case Study", "comments": null, "journal-ref": "IEEE Transactions on Information Forensics & Security (IEEE TIFS),\n  8(11): 1775-1789, (2013)", "doi": null, "report-no": null, "categories": "cs.CR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rigorously characterizing the statistical properties of cyber attacks is an\nimportant problem. In this paper, we propose the {\\em first} statistical\nframework for rigorously analyzing honeypot-captured cyber attack data. The\nframework is built on the novel concept of {\\em stochastic cyber attack\nprocess}, a new kind of mathematical objects for describing cyber attacks. To\ndemonstrate use of the framework, we apply it to analyze a low-interaction\nhoneypot dataset, while noting that the framework can be equally applied to\nanalyze high-interaction honeypot data that contains richer information about\nthe attacks. The case study finds, for the first time, that Long-Range\nDependence (LRD) is exhibited by honeypot-captured cyber attacks. The case\nstudy confirms that by exploiting the statistical properties (LRD in this\ncase), it is feasible to predict cyber attacks (at least in terms of attack\nrate) with good accuracy. This kind of prediction capability would provide\nsufficient early-warning time for defenders to adjust their defense\nconfigurations or resource allocations. The idea of \"gray-box\" (rather than\n\"black-box\") prediction is central to the utility of the statistical framework,\nand represents a significant step towards ultimately understanding (the degree\nof) the {\\em predictability} of cyber attacks.\n", "versions": [{"version": "v1", "created": "Thu, 24 Mar 2016 04:27:09 GMT"}], "update_date": "2016-03-25", "authors_parsed": [["Zhan", "Zhenxin", ""], ["Xu", "Maochao", ""], ["Xu", "Shouhuai", ""]]}, {"id": "1603.07438", "submitter": "Shouhuai Xu", "authors": "Zhenxin Zhan and Maochao Xu and Shouhuai Xu", "title": "A Characterization of Cybersecurity Posture from Network Telescope Data", "comments": null, "journal-ref": "Proceedings of the 6th International Conference Trusted Systems\n  (INTRUST'2014), pp 105-126", "doi": null, "report-no": null, "categories": "cs.CR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven understanding of cybersecurity posture is an important problem\nthat has not been adequately explored. In this paper, we analyze some real data\ncollected by CAIDA's network telescope during the month of March 2013. We\npropose to formalize the concept of cybersecurity posture from the perspectives\nof three kinds of time series: the number of victims (i.e., telescope IP\naddresses that are attacked), the number of attackers that are observed by the\ntelescope, and the number of attacks that are observed by the telescope.\nCharacterizing cybersecurity posture therefore becomes investigating the\nphenomena and statistical properties exhibited by these time series, and\nexplaining their cybersecurity meanings. For example, we propose the concept of\n{\\em sweep-time}, and show that sweep-time should be modeled by stochastic\nprocess, rather than random variable. We report that the number of attackers\n(and attacks) from a certain country dominates the total number of attackers\n(and attacks) that are observed by the telescope. We also show that\nsubstantially smaller network telescopes might not be as useful as a large\ntelescope.\n", "versions": [{"version": "v1", "created": "Thu, 24 Mar 2016 04:44:18 GMT"}], "update_date": "2016-03-25", "authors_parsed": [["Zhan", "Zhenxin", ""], ["Xu", "Maochao", ""], ["Xu", "Shouhuai", ""]]}, {"id": "1603.07439", "submitter": "Shouhuai Xu", "authors": "Yu-Zhong Chen and Zi-Gang Huang and Shouhuai Xu and Ying-Cheng Lai", "title": "Spatiotemporal patterns and predictability of cyberattacks", "comments": null, "journal-ref": "PLoS One 10(5): e0124472 (2015)", "doi": "10.1371/journal.pone.0124472", "report-no": null, "categories": "cs.CR physics.data-an physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A relatively unexplored issue in cybersecurity science and engineering is\nwhether there exist intrinsic patterns of cyberattacks. Conventional wisdom\nfavors absence of such patterns due to the overwhelming complexity of the\nmodern cyberspace. Surprisingly, through a detailed analysis of an extensive\ndata set that records the time-dependent frequencies of attacks over a\nrelatively wide range of consecutive IP addresses, we successfully uncover\nintrinsic spatiotemporal patterns underlying cyberattacks, where the term\n\"spatio\" refers to the IP address space. In particular, we focus on analyzing\n{\\em macroscopic} properties of the attack traffic flows and identify two main\npatterns with distinct spatiotemporal characteristics: deterministic and\nstochastic. Strikingly, there are very few sets of major attackers committing\nalmost all the attacks, since their attack \"fingerprints\" and target selection\nscheme can be unequivocally identified according to the very limited number of\nunique spatiotemporal characteristics, each of which only exists on a\nconsecutive IP region and differs significantly from the others. We utilize a\nnumber of quantitative measures, including the flux-fluctuation law, the Markov\nstate transition probability matrix, and predictability measures, to\ncharacterize the attack patterns in a comprehensive manner. A general finding\nis that the attack patterns possess high degrees of predictability, potentially\npaving the way to anticipating and, consequently, mitigating or even preventing\nlarge-scale cyberattacks using macroscopic approaches.\n", "versions": [{"version": "v1", "created": "Thu, 24 Mar 2016 04:57:11 GMT"}], "update_date": "2016-03-25", "authors_parsed": [["Chen", "Yu-Zhong", ""], ["Huang", "Zi-Gang", ""], ["Xu", "Shouhuai", ""], ["Lai", "Ying-Cheng", ""]]}, {"id": "1603.07538", "submitter": "Cornelius Diekmann", "authors": "Cornelius Diekmann, Lukas Schwaighofer, Georg Carle", "title": "Certifying Spoofing-Protection of Firewalls", "comments": "11th International Conference on Network and Service Management,\n  CNSM, Barcelona, Spain, November 2015", "journal-ref": null, "doi": "10.1109/CNSM.2015.7367354", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm to certify IP spoofing protection of firewall\nrulesets. The algorithm is machine-verifiably proven sound and its use is\ndemonstrated in real-world scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 24 Mar 2016 11:56:25 GMT"}], "update_date": "2016-03-25", "authors_parsed": [["Diekmann", "Cornelius", ""], ["Schwaighofer", "Lukas", ""], ["Carle", "Georg", ""]]}, {"id": "1603.07699", "submitter": "Andrei Khrennikov Yu", "authors": "Andrei Khrennikov and Ekaterina Yurova", "title": "Secure cloud computations: Description of (fully)homomorphic ciphers\n  within the P-adic model of encryption", "comments": "submitted to Journal of Mathematical Cryptology (JMC) in July 2015,\n  under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the description of homomorphic and fully\nhomomorphic ciphers in the $p$-adic model of encryption. This model describes a\nwide class of ciphers, but certainly not all. Homomorphic and fully homomorphic\nciphers are used to ensure the credibility of remote computing, including cloud\ntechnology. The model describes all homomorphic ciphers with respect to\narithmetic and coordinate-wise logical operations in the ring of $p$-adic\nintegers $Z_p$. We show that there are no fully homomorphic ciphers for each\npair of the considered set of arithmetic and coordinate-wise logical operations\non $Z_p$. We formulate the problem of constructing a fully homomorphic cipher\nas follows. We consider a homomorphic cipher with respect to operation \"$*$\" on\n$Z_p$. Then, we describe the complete set of operations \"$G$\", for which the\ncipher is homomorphic. As a result, we construct a fully homomorphic cipher\nwith respect to the operations \"$*$\" and \"$G$\". We give a description of all\noperations \"$G$\", for which we obtain fully homomorphic ciphers with respect to\nthe operations \"$+$\" and \"$G$\" from the homomorphic cipher constructed with\nrespect to the operation \"$+$\". We also present examples of such \"new\"\noperations.\n", "versions": [{"version": "v1", "created": "Thu, 24 Mar 2016 18:43:49 GMT"}], "update_date": "2016-03-25", "authors_parsed": [["Khrennikov", "Andrei", ""], ["Yurova", "Ekaterina", ""]]}, {"id": "1603.07711", "submitter": "Changsha Ma", "authors": "Changsha Ma, Zhisheng Yan, and Chang Wen Chen", "title": "Computationally Recoverable Camouflage: A Universal Model for\n  Privacy-Aware Location-Based Services", "comments": "The paper has been withdrawn by the author due to reorganization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the prevalence of location-based services (LBSs) supported by advanced\npositioning technology, there is a dramatic increase in the transmission of\nhigh-precision personal geographical data. Malicious use of these sensitive\ndata will threaten the privacy of LBS users. Although privacy research in LBSs\nhas received wide attention, related works are mostly focused on some specific\napplications. Due to high diversity of LBSs, it is critical to build a\nuniversal model that is able to handle privacy protection for broader range of\napplications. In this paper, we propose a Computationally Recoverable\nCamouflage (CRC) model, where LBS users can preserve privacy by reporting\ncamouflaged location information and are able to flexibly leverage between the\nservice quality and the achieved privacy in different applications by adjusting\nthe precision of the camouflage information. In particular, we propose a novel\ncamouflage algorithm with formal privacy guarantee that considers both location\ncontext and social context, enabling LBS users to scalably expose camouflage\ninformation in terms of two dimensions. Furthermore, we apply the Scalable\nCiphertext Policy Attribute-Based Encryption (SCP-ABE) algorithm to enforce\nfine-grained access control on the two-dimensional-scalable camouflage\ninformation. Through successful implementations on Android devices, we have\ndemonstrated the computational efficiency of the proposed CRC model.\n", "versions": [{"version": "v1", "created": "Thu, 24 Mar 2016 19:08:04 GMT"}, {"version": "v2", "created": "Wed, 1 Mar 2017 21:01:03 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Ma", "Changsha", ""], ["Yan", "Zhisheng", ""], ["Chen", "Chang Wen", ""]]}, {"id": "1603.07828", "submitter": "Bo-Wei Chen", "authors": "Bo-Wei Chen", "title": "Privacy-Preserved Big Data Analysis Based on Asymmetric Imputation\n  Kernels and Multiside Similarities", "comments": "Incomplete data analysis, partial similarity, multiside similarity,\n  privacy preservation, kernel ridge regression (KRR), missing values, data\n  imputation, kernel method, cloud computing, data analytics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study presents an efficient approach for incomplete data classification,\nwhere the entries of samples are missing or masked due to privacy preservation.\nTo deal with these incomplete data, a new kernel function with asymmetric\nintrinsic mappings is proposed in this study. Such a new kernel uses three-side\nsimilarities for kernel matrix formation. The similarity between a testing\ninstance and a training sample relies not only on their distance but also on\nthe relation between the testing sample and the centroid of the class, where\nthe training sample belongs. This reduces biased estimation compared with\ntypical methods when only one training sample is used for kernel matrix\nformation. Furthermore, centroid generation does not involve any clustering\nalgorithms. The proposed kernel is capable of performing data imputation by\nusing class-dependent averages. This enhances Fisher Discriminant Ratios and\ndata discriminability. Experiments on two open databases were carried out for\nevaluating the proposed method. The result indicated that the accuracy of the\nproposed method was higher than that of the baseline. These findings thereby\ndemonstrated the effectiveness of the proposed idea.\n", "versions": [{"version": "v1", "created": "Fri, 25 Mar 2016 06:04:30 GMT"}, {"version": "v2", "created": "Mon, 21 Nov 2016 14:20:34 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Chen", "Bo-Wei", ""]]}, {"id": "1603.07856", "submitter": "Christian Schaffner", "authors": "Thomas Santoli and Christian Schaffner", "title": "Using Simon's Algorithm to Attack Symmetric-Key Cryptographic Primitives", "comments": "14 pages, 2 figures. v3: final polished version, more formal\n  definitions added", "journal-ref": "Quantum Information & Computation, volume 17 no.1&2, pages 65-78,\n  2017", "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new connections between quantum information and the field of\nclassical cryptography. In particular, we provide examples where Simon's\nalgorithm can be used to show insecurity of commonly used cryptographic\nsymmetric-key primitives. Specifically, these examples consist of a quantum\ndistinguisher for the 3-round Feistel network and a forgery attack on CBC-MAC\nwhich forges a tag for a chosen-prefix message querying only other messages (of\nthe same length). We assume that an adversary has quantum-oracle access to the\nrespective classical primitives. Similar results have been achieved recently in\nindependent work by Kaplan et al. Our findings shed new light on the\npost-quantum security of cryptographic schemes and underline that classical\nsecurity proofs of cryptographic constructions need to be revisited in light of\nquantum attackers.\n", "versions": [{"version": "v1", "created": "Fri, 25 Mar 2016 09:22:41 GMT"}, {"version": "v2", "created": "Wed, 8 Jun 2016 19:03:51 GMT"}, {"version": "v3", "created": "Tue, 31 Jan 2017 12:10:16 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Santoli", "Thomas", ""], ["Schaffner", "Christian", ""]]}, {"id": "1603.07924", "submitter": "Harald Lampesberger", "authors": "Harald Lampesberger", "title": "An Incremental Learner for Language-Based Anomaly Detection in XML", "comments": "15 pages, 7 figures, accepted at the Third Workshop on\n  Language-Theoretic Security (LangSec)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Extensible Markup Language (XML) is a complex language, and consequently,\nXML-based protocols are susceptible to entire classes of implicit and explicit\nsecurity problems. Message formats in XML-based protocols are usually specified\nin XML Schema, and as a first-line defense, schema validation should reject\nmalformed input. However, extension points in most protocol specifications\nbreak validation. Extension points are wildcards and considered best practice\nfor loose composition, but they also enable an attacker to add unchecked\ncontent in a document, e.g., for a signature wrapping attack.\n  This paper introduces datatyped XML visibly pushdown automata (dXVPAs) as\nlanguage representation for mixed-content XML and presents an incremental\nlearner that infers a dXVPA from example documents. The learner generalizes XML\ntypes and datatypes in terms of automaton states and transitions, and an\ninferred dXVPA converges to a good-enough approximation of the true language.\nThe automaton is free from extension points and capable of stream validation,\ne.g., as an anomaly detector for XML-based protocols. For dealing with\nadversarial training data, two scenarios of poisoning are considered: a\npoisoning attack is either uncovered at a later time or remains hidden.\nUnlearning can therefore remove an identified poisoning attack from a dXVPA,\nand sanitization trims low-frequent states and transitions to get rid of hidden\nattacks. All algorithms have been evaluated in four scenarios, including a web\nservice implemented in Apache Axis2 and Apache Rampart, where attacks have been\nsimulated. In all scenarios, the learned automaton had zero false positives and\noutperformed traditional schema validation.\n", "versions": [{"version": "v1", "created": "Fri, 25 Mar 2016 14:24:43 GMT"}], "update_date": "2016-03-28", "authors_parsed": [["Lampesberger", "Harald", ""]]}, {"id": "1603.07926", "submitter": "Alexander Chepurnoy Mr.", "authors": "Alexander Chepurnoy, Mario Larangeira, Alexander Ojiganov", "title": "Rollerchain, a Blockchain With Safely Pruneable Full Blocks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin is the first successful decentralized global digital cash system. Its\nmining process requires intense computational resources, therefore its\nusefulness remains a disputable topic. We aim to solve three problems with\nBitcoin and other blockchain systems of today by repurposing their work. First,\nspace to store a blockchain is growing linearly with number of transactions.\nSecond, a honest node is forced to be irrational regarding storing full blocks\nby a way implementations are done. Third, a trustless bootstrapping process for\na new node involves downloading and processing all the transactions ever\nwritten into a blockchain.\n  In this paper we present a new consensus protocol for Bitcoin-like\npeer-to-peer systems where a right to generate a block is given to a party\nproviding non-interactive proofs of storing a subset of the past state\nsnapshots. Unlike the blockchain systems in use today, a network using our\nprotocol is safe if the nodes prune full blocks not needed for mining.\n  We extend the GKL model to describe our Proof-of-Work scheme and a\ntransactional model modifications needed for it. We provide a detailed analysis\nof our protocol and proofs of its security.\n", "versions": [{"version": "v1", "created": "Fri, 25 Mar 2016 14:38:17 GMT"}, {"version": "v2", "created": "Thu, 7 Apr 2016 09:33:42 GMT"}, {"version": "v3", "created": "Tue, 23 Aug 2016 22:19:26 GMT"}], "update_date": "2016-08-25", "authors_parsed": [["Chepurnoy", "Alexander", ""], ["Larangeira", "Mario", ""], ["Ojiganov", "Alexander", ""]]}, {"id": "1603.08028", "submitter": "Daniel Cullina", "authors": "Daniel Cullina, Kushagra Singhal, Negar Kiyavash, Prateek Mittal", "title": "On the Simultaneous Preservation of Privacy and Community Structure in\n  Anonymized Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of performing community detection on a network, while\nmaintaining privacy, assuming that the adversary has access to an auxiliary\ncorrelated network. We ask the question \"Does there exist a regime where the\nnetwork cannot be deanonymized perfectly, yet the community structure could be\nlearned?.\" To answer this question, we derive information theoretic converses\nfor the perfect deanonymization problem using the Stochastic Block Model and\nedge sub-sampling. We also provide an almost tight achievability result for\nperfect deanonymization.\n  We also evaluate the performance of percolation based deanonymization\nalgorithm on Stochastic Block Model data-sets that satisfy the conditions of\nour converse. Although our converse applies to exact deanonymization, the\nalgorithm fails drastically when the conditions of the converse are met.\nAdditionally, we study the effect of edge sub-sampling on the community\nstructure of a real world dataset. Results show that the dataset falls under\nthe purview of the idea of this paper. There results suggest that it may be\npossible to prove stronger partial deanonymizability converses, which would\nenable better privacy guarantees.\n", "versions": [{"version": "v1", "created": "Fri, 25 Mar 2016 20:45:32 GMT"}], "update_date": "2016-03-29", "authors_parsed": [["Cullina", "Daniel", ""], ["Singhal", "Kushagra", ""], ["Kiyavash", "Negar", ""], ["Mittal", "Prateek", ""]]}, {"id": "1603.08300", "submitter": "Shouhuai Xu", "authors": "Xiaohu Li and Paul Parker and Shouhuai Xu", "title": "A Stochastic Model for Quantitative Security Analyses of Networked\n  Systems", "comments": null, "journal-ref": "IEEE Transactions on Dependable and Secure Computing (IEEE TDSC),\n  8(1): 28-43 (2011)", "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional security analyses are often geared towards cryptographic\nprimitives or protocols. Although such analyses are necessary, they cannot\naddress a defender's need for insight into {\\em which aspects of a networked\nsystem having a significant impact on its security, and how to tune its\nconfigurations or parameters so as to improve security}. This question is known\nto be notoriously difficult to answer, and the state-of-the-art is that we know\nlittle about it. Towards ultimately addressing this question, this paper\npresents a stochastic model for quantifying security of networked systems. The\nresulting model captures two aspects of a networked system: (1) the strength of\ndeployed security mechanisms such as intrusion detection systems, and (2) the\nunderlying {\\em vulnerability graph}, which reflects how attacks may proceed.\nThe resulting model brings the following insights: (1) How should a defender\n\"tune\" system configurations (e.g., network topology) so as to improve\nsecurity? (2) How should a defender \"tune\" system parameters (e.g., by\nupgrading which security mechanisms) so as to improve security? (3) Under what\nconditions is the steady-state number of compromised entities of interest below\na given threshold with a high probability? Simulation studies are conducted to\nconfirm the analytic results, and to show the tightness of the bounds of\ncertain important metric that cannot be resolved analytically.\n", "versions": [{"version": "v1", "created": "Mon, 28 Mar 2016 04:23:28 GMT"}], "update_date": "2016-03-29", "authors_parsed": [["Li", "Xiaohu", ""], ["Parker", "Paul", ""], ["Xu", "Shouhuai", ""]]}, {"id": "1603.08304", "submitter": "Shouhuai Xu", "authors": "Maochao Xu and Shouhuai Xu", "title": "An Extended Stochastic Model for Quantitative Security Analysis of\n  Networked Systems", "comments": null, "journal-ref": "Internet Mathematics, 8(3): 288-320 (2012)", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative security analysis of networked computer systems is one of the\ndecades-long open problems in computer security. Recently, a promising approach\nwas proposed in \\cite{XuTDSC11}, which however made some strong assumptions\nincluding the exponential distribution of, and the independence between, the\nrelevant random variables. In this paper, we substantially weaken these\nassumptions while offering, in addition to the same types of analytical results\nas in \\cite{XuTDSC11}, methods for obtaining the desired security quantities in\npractice. Moreover, we investigate the problem from a higher-level abstraction,\nwhich also leads to both analytical results and practical methods for obtaining\nthe desired security quantities. These would represent a significant step\ntoward ultimately solving the problem of quantitative security analysis of\nnetworked computer systems.\n", "versions": [{"version": "v1", "created": "Mon, 28 Mar 2016 04:33:07 GMT"}], "update_date": "2016-03-29", "authors_parsed": [["Xu", "Maochao", ""], ["Xu", "Shouhuai", ""]]}, {"id": "1603.08305", "submitter": "Shouhuai Xu", "authors": "Gaofeng Da and Maochao Xu and Shouhuai Xu", "title": "A New Approach to Modeling and Analyzing Security of Networked Systems", "comments": "Proceedings of the 2014 Symposium on the Science of Security\n  (HotSoS'14)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling and analyzing security of networked systems is an important problem\nin the emerging Science of Security and has been under active investigation. In\nthis paper, we propose a new approach towards tackling the problem. Our\napproach is inspired by the {\\em shock model} and {\\em random environment}\ntechniques in the Theory of Reliability, while accommodating security\ningredients. To the best of our knowledge, our model is the first that can\naccommodate a certain degree of {\\em adaptiveness of attacks}, which\nsubstantially weakens the often-made independence and exponential attack\ninter-arrival time assumptions. The approach leads to a stochastic process\nmodel with two security metrics, and we attain some analytic results in terms\nof the security metrics.\n", "versions": [{"version": "v1", "created": "Mon, 28 Mar 2016 04:41:12 GMT"}], "update_date": "2016-03-29", "authors_parsed": [["Da", "Gaofeng", ""], ["Xu", "Maochao", ""], ["Xu", "Shouhuai", ""]]}, {"id": "1603.08307", "submitter": "Shouhuai Xu", "authors": "Maochao Xu and Gaofeng Da and Shouhuai Xu", "title": "Cyber Epidemic Models with Dependences", "comments": null, "journal-ref": "Internet Mathematics, 11:1, 62-92 (2015)", "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studying models of cyber epidemics over arbitrary complex networks can deepen\nour understanding of cyber security from a whole-system perspective. In this\npaper, we initiate the investigation of cyber epidemic models that accommodate\nthe {\\em dependences} between the cyber attack events. Due to the notorious\ndifficulty in dealing with such dependences, essentially all existing cyber\nepidemic models have assumed them away. Specifically, we introduce the idea of\nCopulas into cyber epidemic models for accommodating the dependences between\nthe cyber attack events. We investigate the epidemic equilibrium thresholds as\nwell as the bounds for both equilibrium and non-equilibrium infection\nprobabilities. We further characterize the side-effects of assuming away the\ndue dependences between the cyber attack events, by showing that the results\nthereof are unnecessarily restrictive or even incorrect.\n", "versions": [{"version": "v1", "created": "Mon, 28 Mar 2016 04:52:04 GMT"}], "update_date": "2016-03-29", "authors_parsed": [["Xu", "Maochao", ""], ["Da", "Gaofeng", ""], ["Xu", "Shouhuai", ""]]}, {"id": "1603.08309", "submitter": "Shouhuai Xu", "authors": "Shouhuai Xu and Wenlian Lu and Hualun Li", "title": "A Stochastic Model of Active Cyber Defense Dynamics", "comments": null, "journal-ref": "Internet Mathematics, 11:1, 23-71 (2015)", "doi": null, "report-no": null, "categories": "cs.CR cs.SI math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of active cyber defense has been proposed for years. However,\nthere are no mathematical models for characterizing the effectiveness of active\ncyber defense. In this paper, we fill the void by proposing a novel Markov\nprocess model that is native to the interaction between cyber attack and active\ncyber defense. Unfortunately, the native Markov process model cannot be tackled\nby the techniques we are aware of. We therefore simplify, via mean-field\napproximation, the Markov process model as a Dynamic System model that is\namenable to analysis. This allows us to derive a set of valuable analytical\nresults that characterize the effectiveness of four types of active cyber\ndefense dynamics. Simulations show that the analytical results are inherent to\nthe native Markov process model, and therefore justify the validity of the\nDynamic System model. We also discuss the side-effect of the mean-field\napproximation and its implications.\n", "versions": [{"version": "v1", "created": "Mon, 28 Mar 2016 05:11:58 GMT"}], "update_date": "2016-03-29", "authors_parsed": [["Xu", "Shouhuai", ""], ["Lu", "Wenlian", ""], ["Li", "Hualun", ""]]}, {"id": "1603.08312", "submitter": "Shouhuai Xu", "authors": "Wenlian Lu and Shouhuai Xu and Xinlei Yi", "title": "Optimizing Active Cyber Defense", "comments": null, "journal-ref": "Proceedings of the 4th Conference on Decision and Game Theory for\n  Security (GameSec'2013), pp 206-225", "doi": null, "report-no": null, "categories": "cs.CR cs.SI cs.SY math.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active cyber defense is one important defensive method for combating cyber\nattacks. Unlike traditional defensive methods such as firewall-based filtering\nand anti-malware tools, active cyber defense is based on spreading \"white\" or\n\"benign\" worms to combat against the attackers' malwares (i.e., malicious\nworms) that also spread over the network. In this paper, we initiate the study\nof {\\em optimal} active cyber defense in the setting of strategic attackers\nand/or strategic defenders. Specifically, we investigate infinite-time horizon\noptimal control and fast optimal control for strategic defenders (who want to\nminimize their cost) against non-strategic attackers (who do not consider the\nissue of cost). We also investigate the Nash equilibria for strategic defenders\nand attackers. We discuss the cyber security meanings/implications of the\ntheoretic results. Our study brings interesting open problems for future\nresearch.\n", "versions": [{"version": "v1", "created": "Mon, 28 Mar 2016 05:22:33 GMT"}], "update_date": "2016-03-29", "authors_parsed": [["Lu", "Wenlian", ""], ["Xu", "Shouhuai", ""], ["Yi", "Xinlei", ""]]}, {"id": "1603.08314", "submitter": "Shouhuai Xu", "authors": "Ren Zheng and Wenlian Lu and Shouhuai Xu", "title": "Active Cyber Defense Dynamics Exhibiting Rich Phenomena", "comments": "Proceedings of 2015 Symposium on the Science of Security (HotSoS'15)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI cs.SY math.DS physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet is a man-made complex system under constant attacks (e.g.,\nAdvanced Persistent Threats and malwares). It is therefore important to\nunderstand the phenomena that can be induced by the interaction between cyber\nattacks and cyber defenses. In this paper, we explore the rich phenomena that\ncan be exhibited when the defender employs active defense to combat cyber\nattacks. To the best of our knowledge, this is the first study that shows that\n{\\em active cyber defense dynamics} (or more generally, {\\em cybersecurity\ndynamics}) can exhibit the bifurcation and chaos phenomena. This has profound\nimplications for cyber security measurement and prediction: (i) it is\ninfeasible (or even impossible) to accurately measure and predict cyber\nsecurity under certain circumstances; (ii) the defender must manipulate the\ndynamics to avoid such {\\em unmanageable situations} in real-life defense\noperations.\n", "versions": [{"version": "v1", "created": "Mon, 28 Mar 2016 05:35:35 GMT"}], "update_date": "2016-03-29", "authors_parsed": [["Zheng", "Ren", ""], ["Lu", "Wenlian", ""], ["Xu", "Shouhuai", ""]]}, {"id": "1603.08379", "submitter": "Brian Ruttenberg", "authors": "Brian Ruttenberg, Lee Kellogg, Avi Pfeffer", "title": "Probabilistic Programming for Malware Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing lineages of malware is an important cyber-defense task.\nPerforming this task is difficult, however, due to the amount of malware data\nand obfuscation techniques by the authors. In this work, we formulate the\nlineage task as a probabilistic model, and use a novel probabilistic\nprogramming solution to jointly infer the lineage and creation times of\nfamilies of malware.\n", "versions": [{"version": "v1", "created": "Mon, 28 Mar 2016 13:40:29 GMT"}], "update_date": "2016-03-29", "authors_parsed": [["Ruttenberg", "Brian", ""], ["Kellogg", "Lee", ""], ["Pfeffer", "Avi", ""]]}, {"id": "1603.09090", "submitter": "Reto Schnyder", "authors": "Mohamed Baouch, Juan Antonio L\\'opez-Ramos, Reto Schnyder, Blas\n  Torrecillas", "title": "An active attack on a distributed Group Key Exchange system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce an active attack on a Group Key Exchange protocol\nby Burmester and Desmedt. The attacker obtains a copy of the shared key, which\nis created in a collaborative manner with the legal users in a communication\ngroup.\n", "versions": [{"version": "v1", "created": "Wed, 30 Mar 2016 09:13:20 GMT"}], "update_date": "2016-03-31", "authors_parsed": [["Baouch", "Mohamed", ""], ["L\u00f3pez-Ramos", "Juan Antonio", ""], ["Schnyder", "Reto", ""], ["Torrecillas", "Blas", ""]]}, {"id": "1603.09524", "submitter": "V.P. Binu", "authors": "V P Binu, A Sreekumar", "title": "Threshold Multi Secret Sharing Using Elliptic Curve and Pairing", "comments": "in IJIP volume 9 issue 4, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secret Sharing techniques are now the building blocks of several security\nprotocols. A (t;n) threshold secret sharing scheme is one in which t or more\nparticipant can join together to retrieve the secret.Traditional single secret\nsharing schemes are modified and generalized to share multiple secrets.Use of\nelliptic curve and pairing in secret sharing is gaining more importance.In this\npaper we propose a threshold multi secret sharing scheme where more than one\nsecret is shared.When the threshold number of participants collate, the multi\nsecret can be retrieved. The scheme make use of elliptic curve and bilinear\npairing.Verification of shares by the participants, shares consistency\nchecking, detection and identification of cheaters are the extended\ncapabilities achieved.The shared secrets are retrieved in single stage here,\nunlike the multi stage secret sharing scheme.The participants can be added very\neasily.The scheme is efficient and the number of public parameters are also\nless compared with the existing threshold multi secret sharing scheme based on\nthe elliptic curve.The dealer can easily modify the secret or add additional\nsecret by changing the public parameters of the scheme.This is the first\nproposal of a threshold multi secret sharing scheme with extended capabilities\nusing self pairing.\n", "versions": [{"version": "v1", "created": "Thu, 31 Mar 2016 11:03:09 GMT"}], "update_date": "2016-04-01", "authors_parsed": [["Binu", "V P", ""], ["Sreekumar", "A", ""]]}, {"id": "1603.09526", "submitter": "Peter Gutmann", "authors": "Peter Gutmann, Steven M. Bellovin, Matt Blaze, Ronald L. Rivest, Nigel\n  Smart", "title": "An IBE-based Signcryption Scheme for Group Key Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new crypto scheme whose title promises it to be so\nboring that no-one will bother reading past the abstract. Because of this, the\nremainder of the paper is left blank.\n", "versions": [{"version": "v1", "created": "Thu, 31 Mar 2016 11:09:46 GMT"}], "update_date": "2016-04-01", "authors_parsed": [["Gutmann", "Peter", ""], ["Bellovin", "Steven M.", ""], ["Blaze", "Matt", ""], ["Rivest", "Ronald L.", ""], ["Smart", "Nigel", ""]]}, {"id": "1603.09638", "submitter": "Berkay Celik", "authors": "Z. Berkay Celik, Patrick McDaniel, Rauf Izmailov, Nicolas Papernot,\n  Ryan Sheatsley, Raquel Alvarez, Ananthram Swami", "title": "Detection under Privileged Information", "comments": "A short version of this paper is accepted to ASIACCS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For well over a quarter century, detection systems have been driven by models\nlearned from input features collected from real or simulated environments. An\nartifact (e.g., network event, potential malware sample, suspicious email) is\ndeemed malicious or non-malicious based on its similarity to the learned model\nat runtime. However, the training of the models has been historically limited\nto only those features available at runtime. In this paper, we consider an\nalternate learning approach that trains models using \"privileged\"\ninformation--features available at training time but not at runtime--to improve\nthe accuracy and resilience of detection systems. In particular, we adapt and\nextend recent advances in knowledge transfer, model influence, and distillation\nto enable the use of forensic or other data unavailable at runtime in a range\nof security domains. An empirical evaluation shows that privileged information\nincreases precision and recall over a system with no privileged information: we\nobserve up to 7.7% relative decrease in detection error for fast-flux bot\ndetection, 8.6% for malware traffic detection, 7.3% for malware classification,\nand 16.9% for face recognition. We explore the limitations and applications of\ndifferent privileged information techniques in detection systems. Such\ntechniques provide a new means for detection systems to learn from data that\nwould otherwise not be available at runtime.\n", "versions": [{"version": "v1", "created": "Thu, 31 Mar 2016 15:28:45 GMT"}, {"version": "v2", "created": "Wed, 20 Jul 2016 13:59:01 GMT"}, {"version": "v3", "created": "Tue, 15 Nov 2016 01:17:06 GMT"}, {"version": "v4", "created": "Sat, 31 Mar 2018 02:12:21 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Celik", "Z. Berkay", ""], ["McDaniel", "Patrick", ""], ["Izmailov", "Rauf", ""], ["Papernot", "Nicolas", ""], ["Sheatsley", "Ryan", ""], ["Alvarez", "Raquel", ""], ["Swami", "Ananthram", ""]]}, {"id": "1603.09717", "submitter": "Florian Speelman", "authors": "Yfke Dulek, Christian Schaffner, Florian Speelman", "title": "Quantum homomorphic encryption for polynomial-sized circuits", "comments": null, "journal-ref": null, "doi": "10.4086/toc.2018.v014a007", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new scheme for quantum homomorphic encryption which is compact\nand allows for efficient evaluation of arbitrary polynomial-sized quantum\ncircuits. Building on the framework of Broadbent and Jeffery and recent results\nin the area of instantaneous non-local quantum computation, we show how to\nconstruct quantum gadgets that allow perfect correction of the errors which\noccur during the homomorphic evaluation of T gates on encrypted quantum data.\nOur scheme can be based on any classical (leveled) fully homomorphic encryption\n(FHE) scheme and requires no computational assumptions besides those already\nused by the classical scheme. The size of our quantum gadget depends on the\nspace complexity of the classical decryption function -- which aligns well with\nthe current efforts to minimize the complexity of the decryption function.\n  Our scheme (or slight variants of it) offers a number of additional\nadvantages such as ideal compactness, the ability to supply gadgets \"on\ndemand\", circuit privacy for the evaluator against passive adversaries, and a\nthree-round scheme for blind delegated quantum computation which puts only very\nlimited demands on the quantum abilities of the client.\n", "versions": [{"version": "v1", "created": "Thu, 31 Mar 2016 18:51:49 GMT"}, {"version": "v2", "created": "Fri, 24 Jun 2016 14:34:25 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Dulek", "Yfke", ""], ["Schaffner", "Christian", ""], ["Speelman", "Florian", ""]]}]