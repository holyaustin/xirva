[{"id": "1911.00038", "submitter": "Ziteng Sun", "authors": "Jayadev Acharya, Keith Bonawitz, Peter Kairouz, Daniel Ramage, Ziteng\n  Sun", "title": "Context-Aware Local Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local differential privacy (LDP) is a strong notion of privacy for individual\nusers that often comes at the expense of a significant drop in utility. The\nclassical definition of LDP assumes that all elements in the data domain are\nequally sensitive. However, in many applications, some symbols are more\nsensitive than others. This work proposes a context-aware framework of local\ndifferential privacy that allows a privacy designer to incorporate the\napplication's context into the privacy definition. For binary data domains, we\nprovide a universally optimal privatization scheme and highlight its\nconnections to Warner's randomized response (RR) and Mangat's improved\nresponse. Motivated by geolocation and web search applications, for $k$-ary\ndata domains, we consider two special cases of context-aware LDP:\nblock-structured LDP and high-low LDP. We study discrete distribution\nestimation and provide communication-efficient, sample-optimal schemes and\ninformation-theoretic lower bounds for both models. We show that using\ncontextual information can require fewer samples than classical LDP to achieve\nthe same accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 18:15:33 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 23:00:22 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Acharya", "Jayadev", ""], ["Bonawitz", "Keith", ""], ["Kairouz", "Peter", ""], ["Ramage", "Daniel", ""], ["Sun", "Ziteng", ""]]}, {"id": "1911.00126", "submitter": "Juncheng Li", "authors": "Juncheng B. Li, Shuhui Qu, Xinjian Li, Joseph Szurley, J. Zico Kolter,\n  Florian Metze", "title": "Adversarial Music: Real World Audio Adversary Against Wake-word\n  Detection System", "comments": "9 pages, In Proceedings of NeurIPS 2019 Conference", "journal-ref": "NIPS2019_9362, pages = {11908--11918}, year = {2019}, publisher =\n  {Curran Associates, Inc.}, url =\n  {http://papers.nips.cc/paper/9362-adversarial-music-real-world-audio-adversary-against-wake-word-detection-system.pdf}\n  }", "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice Assistants (VAs) such as Amazon Alexa or Google Assistant rely on\nwake-word detection to respond to people's commands, which could potentially be\nvulnerable to audio adversarial examples. In this work, we target our attack on\nthe wake-word detection system, jamming the model with some inconspicuous\nbackground music to deactivate the VAs while our audio adversary is present. We\nimplemented an emulated wake-word detection system of Amazon Alexa based on\nrecent publications. We validated our models against the real Alexa in terms of\nwake-word detection accuracy. Then we computed our audio adversaries with\nconsideration of expectation over transform and we implemented our audio\nadversary with a differentiable synthesizer. Next, we verified our audio\nadversaries digitally on hundreds of samples of utterances collected from the\nreal world. Our experiments show that we can effectively reduce the recognition\nF1 score of our emulated model from 93.4% to 11.0%. Finally, we tested our\naudio adversary over the air, and verified it works effectively against Alexa,\nreducing its F1 score from 92.5% to 11.0%.; We also verified that\nnon-adversarial music does not disable Alexa as effectively as our music at the\nsame sound level. To the best of our knowledge, this is the first real-world\nadversarial attack against a commercial-grade VA wake-word detection system.\nOur code and demo videos can be accessed at\n\\url{https://www.junchengbillyli.com/AdversarialMusic}\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 21:58:50 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 17:03:17 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2019 02:12:45 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Li", "Juncheng B.", ""], ["Qu", "Shuhui", ""], ["Li", "Xinjian", ""], ["Szurley", "Joseph", ""], ["Kolter", "J. Zico", ""], ["Metze", "Florian", ""]]}, {"id": "1911.00157", "submitter": "Jennifer Paykin", "authors": "Jennifer Paykin, Eric Mertens, Mark Tullsen, Luke Maurer, Beno\\^it\n  Razet, Alexander Bakst, and Scott Moore", "title": "Weird Machines as Insecure Compilation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weird machines---the computational models accessible by exploiting security\nvulnerabilities---arise from the difference between the model a programmer has\nin her head of how her program should run and the implementation that actually\nexecutes. Previous attempts to reason about or identify weird machines have\nviewed these models through the lens of formal computational structures such as\nstate machines and Turing machines. But because programmers rarely think about\nprograms in this way, it is difficult to effectively apply insights about weird\nmachines to improve security.\n  We present a new view of weird machines based on techniques from programming\nlanguages theory and secure compilation. Instead of an underspecified model\ndrawn from a programmers' head, we start with a program written in a high-level\nsource language that enforces security properties by design. Instead of state\nmachines to describe computation, we use the well-defined semantics of this\nsource language and a target language, into which the source program will be\ncompiled. Weird machines are the sets of behaviors that can be achieved by a\ncompiled source program in the target language that cannot be achieved in the\nsource language directly. That is, exploits are witnesses to insecure\ncompilation.\n  This paper develops a framework for characterizing weird machines as insecure\ncompilation, and illustrates the framework with examples of common exploits. We\nstudy the classes of security properties that exploits violate, the\ncompositionality of exploits in a compiler stack, and the weird machines and\nmitigations that arise.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 00:17:40 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Paykin", "Jennifer", ""], ["Mertens", "Eric", ""], ["Tullsen", "Mark", ""], ["Maurer", "Luke", ""], ["Razet", "Beno\u00eet", ""], ["Bakst", "Alexander", ""], ["Moore", "Scott", ""]]}, {"id": "1911.00169", "submitter": "Peilin Zheng", "authors": "Peilin Zheng and Zibin Zheng and Hong-ning Dai", "title": "XBlock-ETH: Extracting and Exploring Blockchain Data From Ethereum", "comments": "11 pages, blockchain dataset, Ethereum, http://xblock.pro/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain-based cryptocurrencies have received extensive attention recently.\nMassive data has been stored on permission-less blockchains. The analysis on\nmassive blockchain data can bring huge business values. However, the lack of\nwell-processed up-to-date blockchain datasets impedes big data analytics of\nblockchain data. To fill this gap, we collect and process the up-to-date\non-chain data from Ethereum, which is one of the most popular permission-less\nblockchains. We name these well-processed Ethereum datasets as XBlock-ETH,\nwhich consists of the data of blockchain transactions, smart contracts, and\ncryptocurrencies (i.e., tokens). The basic statistics and exploration of these\ndatasets are presented. We also outline the possible research opportunities.\nThe datasets with the raw data and codes have been publicly released online.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 01:02:55 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 05:05:51 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Zheng", "Peilin", ""], ["Zheng", "Zibin", ""], ["Dai", "Hong-ning", ""]]}, {"id": "1911.00227", "submitter": "Yuma Kinoshita", "authors": "Ayana Kawamura, Yuma Kinoshita, and Hitoshi Kiya", "title": "Privacy-Preserving Machine Learning Using EtC Images", "comments": "to be presented at IWAIT2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel privacy-preserving machine learning scheme\nwith encrypted images, called EtC (Encryption-then-Compression) images. Using\nmachine learning algorithms in cloud environments has been spreading in many\nfields. However, there are serious issues with it for end users, due to\nsemi-trusted cloud providers. Accordingly, we propose using EtC images, which\nhave been proposed for EtC systems with JPEG compression. In this paper, a\nnovel property of EtC images is considered under the use of z-score\nnormalization. It is demonstrated that the use of EtC images allows us not only\nto protect visual information of images, but also to preserve both the\nEuclidean distance and the inner product between vectors. In addition,\ndimensionality reduction is shown to can be applied to EtC images for fast and\naccurate matching. In an experiment, the proposed scheme is applied to a facial\nrecognition algorithm with classifiers for confirming the effectiveness of the\nscheme under the use of support vector machine (SVM) with the kernel trick.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 06:54:27 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Kawamura", "Ayana", ""], ["Kinoshita", "Yuma", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "1911.00248", "submitter": "Ma\\\"elle Kabir-Querrec", "authors": "Swe Geng, Georgia Giannopoulou, Ma\\\"elle Kabir-Querrec", "title": "Privacy Protection in Distributed Fingerprint-based Authentication", "comments": "This is an extended version of the paper with the same title which\n  has been accepted for publication at the Workshop on Privacy in the\n  Electronic Society (WPES 2019)", "journal-ref": null, "doi": "10.1145/3338498.3358648", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biometric authentication is getting increasingly popular due to the\nconvenience of using unique individual traits, such as fingerprints, palm\nveins, irises. Especially fingerprints are widely used nowadays due to the\navailability and low cost of fingerprint scanners. To avoid identity theft or\nimpersonation, fingerprint data is typically stored locally, e.g., in a trusted\nhardware module, in a single device that is used for user enrollment and\nauthentication. Local storage, however, limits the ability to implement\ndistributed applications, in which users can enroll their fingerprint once and\nuse it to access multiple physical locations and mobile applications\nafterwards.\n  In this paper, we present a distributed authentication system that stores\nfingerprint data in a server or cloud infrastructure in a privacy-preserving\nway. Multiple devices can be connected and perform user enrollment or\nverification. To secure the privacy and integrity of sensitive data, we employ\na cryptographic construct called fuzzy vault. We highlight challenges in\nimplementing fuzzy vault-based authentication, for which we propose and compare\nalternative solutions. We conduct a security analysis of our biometric\ncryptosystem, and as a proof of concept, we build an authentication system for\naccess control using resource-constrained devices (Raspberry Pis) connected to\nfingerprint scanners and the Microsoft Azure cloud environment. Furthermore, we\nevaluate the fingerprint matching algorithm against the well-known FVC2006\ndatabase and show that it can achieve comparable accuracy to widely-used\nmatching techniques that are not designed for privacy, while remaining\nefficient with an authentication time of few seconds.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 08:22:34 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Geng", "Swe", ""], ["Giannopoulou", "Georgia", ""], ["Kabir-Querrec", "Ma\u00eblle", ""]]}, {"id": "1911.00303", "submitter": "Ayoub Mars", "authors": "Ayoub Mars, Ahmad Abadleh, Wael Adi", "title": "Operator and Manufacturer Independent D2D Private Link for Future 5G\n  Networks", "comments": "6 pages, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct Mobile-to-Mobile communication mode known also as Device-to-Device\n(D2D) communication is expected to be supported in the 5G mobile system. D2D\ncommunication aims to improve system spectrum efficiency, overall system\nthroughput, energy efficiency and reduce the connection delay between devices.\nHowever, new security threats and challenges need to be considered regarding\ndevice and user authentication to avoid unauthorized access, abuse and attacks\non the whole system. In this paper, a strong standalone authentication\ntechnique therefore is proposed. It is based on combining users biometric\nidentities and a new clone-resistant device identity. The novel property of the\nproposal is that it is fully independent on both device manufacturer and mobile\nsystem operator. The biometric identity deploys user keystroke dynamics and\naccelerometer to generate user biometric identity by deploying a machine\nlearning technique. The proposed mobile device clone-resistant identity is\nbased on deploying a new concept of a pure digital clone-resistant structure\nwhich is both manufacturer and mobile operator-independent. When combining both\nidentities, a mutually authenticated D2D secured link between any two devices\ncan be established in addition to a strong user-device authentication.\nFurthermore, the concept does not allow the managing trusted authority to\nintercept users private links. Being an independent and standalone system, the\ntechnique would offer a broad spectrum of attractive future smart applications\nover the 5G mobile system infrastructure.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 11:16:06 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Mars", "Ayoub", ""], ["Abadleh", "Ahmad", ""], ["Adi", "Wael", ""]]}, {"id": "1911.00409", "submitter": "Fabien Pazuki", "authors": "Andrea Basso and Fabien Pazuki", "title": "On the supersingular GPST attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explain why the first Galbraith-Petit-Shani-Ti attack on the Supersingular\nIsogeny Diffie-Hellman and the Supersingular Isogeny Key Encapsulation fails in\nsome cases.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 14:42:56 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Basso", "Andrea", ""], ["Pazuki", "Fabien", ""]]}, {"id": "1911.00507", "submitter": "Yueqi Chen", "authors": "Shengjian Guo, Yueqi Chen, Peng Li, Yueqiang Cheng, Huibo Wang, Meng\n  Wu, and Zhiqiang Zuo", "title": "SpecuSym: Speculative Symbolic Execution for Cache Timing Leak Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CPU cache is a limited but crucial storage component in modern processors,\nwhereas the cache timing side-channel may inadvertently leak information\nthrough the physically measurable timing variance. Speculative execution, an\nessential processor optimization, and a source of such variances, can cause\nsevere detriment on deliberate branch mispredictions. Despite static analysis\ncould qualitatively verify the timing-leakage-free property under speculative\nexecution, it is incapable of producing endorsements including inputs and\nspeculated flows to diagnose leaks in depth. This work proposes a new symbolic\nexecution based method, SpecuSym, for precisely detecting cache timing leaks\nintroduced by speculative execution. Given a program (leakage-free in\nnon-speculative execution), SpecuSymsystematically explores the program state\nspace, models speculative behavior at conditional branches, and accumulates the\ncache side effects along with subsequent path explorations. During the dynamic\nexecution, SpecuSymconstructs leak predicates for memory visits according to\nthe specified cache model and conducts a constraint-solving based cache\nbehavior analysis to inspect the new cache behaviors. We have\nimplementedSpecuSymatop KLEE and evaluated it against 15 open-source\nbenchmarks. Experimental results show thatSpecuSymsuccessfully detected from 2\nto 61 leaks in 6 programs under 3 different cache settings and identified false\npositives in 2 programs reported by recent work.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 15:59:22 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 21:19:33 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Guo", "Shengjian", ""], ["Chen", "Yueqi", ""], ["Li", "Peng", ""], ["Cheng", "Yueqiang", ""], ["Wang", "Huibo", ""], ["Wu", "Meng", ""], ["Zuo", "Zhiqiang", ""]]}, {"id": "1911.00516", "submitter": "Martin Barrere", "authors": "Mart\\'in Barr\\`ere, Chris Hankin, Nicolas Nicolau, Demetrios G.\n  Eliades, Thomas Parisini", "title": "MaxSAT Evaluation 2019 -- Benchmark: Identifying Security-Critical\n  Cyber-Physical Components in Weighted AND/OR Graphs", "comments": "arXiv admin note: substantial text overlap with arXiv:1905.04796", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a MaxSAT benchmark focused on identifying critical nodes\nin AND/OR graphs. We use AND/OR graphs to model Industrial Control Systems\n(ICS) as they are able to semantically grasp intricate logical\ninterdependencies among ICS components. However, identifying critical nodes in\nAND/OR graphs is an NP-complete problem. We address this problem by efficiently\ntransforming the input AND/OR graph-based model into a weighted logical formula\nthat is then used to build and solve a Weighted Partial MaxSAT problem. The\nbenchmark includes 80 cases with AND/OR graphs of different size and\ncomposition as well as the optimal cost and solution for each case.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 17:24:16 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Barr\u00e8re", "Mart\u00edn", ""], ["Hankin", "Chris", ""], ["Nicolau", "Nicolas", ""], ["Eliades", "Demetrios G.", ""], ["Parisini", "Thomas", ""]]}, {"id": "1911.00563", "submitter": "Nguyen Phong Hoang", "authors": "Nguyen Phong Hoang, Arian Akhavan Niaki, Nikita Borisov, Phillipa\n  Gill, Michalis Polychronakis", "title": "Assessing the Privacy Benefits of Domain Name Encryption", "comments": "In Proceedings of the 15th ACM Asia Conference on Computer and\n  Communications Security (ASIA CCS '20), October 5-9, 2020, Taipei, Taiwan", "journal-ref": null, "doi": "10.1145/3320269.3384728", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Internet users have become more savvy about the potential for their\nInternet communication to be observed, the use of network traffic encryption\ntechnologies (e.g., HTTPS/TLS) is on the rise. However, even when encryption is\nenabled, users leak information about the domains they visit via DNS queries\nand via the Server Name Indication (SNI) extension of TLS. Two recent proposals\nto ameliorate this issue are DNS over HTTPS/TLS (DoH/DoT) and Encrypted SNI\n(ESNI). In this paper we aim to assess the privacy benefits of these proposals\nby considering the relationship between hostnames and IP addresses, the latter\nof which are still exposed. We perform DNS queries from nine vantage points\naround the globe to characterize this relationship. We quantify the privacy\ngain offered by ESNI for different hosting and CDN providers using two\ndifferent metrics, the k-anonymity degree due to co-hosting and the dynamics of\nIP address changes. We find that 20% of the domains studied will not gain any\nprivacy benefit since they have a one-to-one mapping between their hostname and\nIP address. On the other hand, 30% will gain a significant privacy benefit with\na k value greater than 100, since these domains are co-hosted with more than\n100 other domains. Domains whose visitors' privacy will meaningfully improve\nare far less popular, while for popular domains the benefit is not significant.\nAnalyzing the dynamics of IP addresses of long-lived domains, we find that only\n7.7% of them change their hosting IP addresses on a daily basis. We conclude by\ndiscussing potential approaches for website owners and hosting/CDN providers\nfor maximizing the privacy benefits of ESNI.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 19:33:37 GMT"}, {"version": "v2", "created": "Sat, 14 Mar 2020 00:48:18 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 16:37:44 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Hoang", "Nguyen Phong", ""], ["Niaki", "Arian Akhavan", ""], ["Borisov", "Nikita", ""], ["Gill", "Phillipa", ""], ["Polychronakis", "Michalis", ""]]}, {"id": "1911.00570", "submitter": "Sebastian Banescu", "authors": "William Zhang, Sebastian Banescu, Leonardo Passos, Steven Stewart,\n  Vijay Ganesh", "title": "MPro: Combining Static and Symbolic Analysis for Scalable Testing of\n  Smart Contract", "comments": null, "journal-ref": null, "doi": "10.1109/ISSRE.2019.00052", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart contracts are executable programs that enable the building of a\nprogrammable trust mechanism between multiple entities without the need of a\ntrusted third-party. Researchers have developed several security scanners in\nthe past couple of years. However, many of these analyzers either do not scale\nwell, or if they do, produce many false positives. This issue is exacerbated\nwhen bugs are triggered only after a series of interactions with the functions\nof the contract-under-test. A depth-n vulnerability, refers to a vulnerability\nthat requires invoking a specific sequence of n functions to trigger. Depth-n\nvulnerabilities are time-consuming to detect by existing automated analyzers,\nbecause of the combinatorial explosion of sequences of functions that could be\nexecuted on smart contracts.\n  In this paper, we present a technique to analyze depth-n vulnerabilities in\nan efficient and scalable way by combining symbolic execution and data\ndependency analysis. A significant advantage of combining symbolic with static\nanalysis is that it scales much better than symbolic alone and does not have\nthe problem of false positive that static analysis tools typically have. We\nhave implemented our technique in a tool called MPro, a scalable and automated\nsmart contract analyzer based on the existing symbolic analysis tool\nMythril-Classic and the static analysis tool Slither. We analyzed 100 randomly\nchosen smart contracts on MPro and our evaluation shows that MPro is about\nn-times faster than Mythril-Classic for detecting depth-n vulnerabilities,\nwhile preserving all the detection capabilities of Mythril-Classic.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 19:54:46 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 11:24:43 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2020 16:53:07 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Zhang", "William", ""], ["Banescu", "Sebastian", ""], ["Passos", "Leonardo", ""], ["Stewart", "Steven", ""], ["Ganesh", "Vijay", ""]]}, {"id": "1911.00602", "submitter": "William Croft", "authors": "William Lee Croft, J\\\"org-R\\\"udiger Sack, Wei Shi", "title": "Differential Privacy Via a Truncated and Normalized Laplace Mechanism", "comments": "This is a pre-print of an article published in Journal of Computer\n  Science and Technology. The final authenticated version is available online\n  at: https://doi.org/10.1007/s11390-020-0193-z", "journal-ref": null, "doi": "10.1007/s11390-020-0193-z", "report-no": null, "categories": "cs.DB cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When querying databases containing sensitive information, the privacy of\nindividuals stored in the database has to be guaranteed. Such guarantees are\nprovided by differentially private mechanisms which add controlled noise to the\nquery responses. However, most such mechanisms do not take into consideration\nthe valid range of the query being posed. Thus, noisy responses that fall\noutside of this range may potentially be produced. To rectify this and\ntherefore improve the utility of the mechanism, the commonly used Laplace\ndistribution can be truncated to the valid range of the query and then\nnormalized. However, such a data-dependent operation of normalization leaks\nadditional information about the true query response thereby violating the\ndifferential privacy guarantee.\n  Here, we propose a new method which preserves the differential privacy\nguarantee through a careful determination of an appropriate scaling parameter\nfor the Laplace distribution. We also generalize the privacy guarantee in the\ncontext of the Laplace distribution to account for data-dependent normalization\nfactors and study this guarantee for different classes of range constraint\nconfigurations. We provide derivations of the optimal scaling parameter (i.e.,\nthe minimal value that preserves differential privacy) for each class or\nprovide an approximation thereof. As a consequence of this work, one can use\nthe Laplace distribution to answer queries in a range-adherent and\ndifferentially private manner.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 22:05:52 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 14:31:30 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Croft", "William Lee", ""], ["Sack", "J\u00f6rg-R\u00fcdiger", ""], ["Shi", "Wei", ""]]}, {"id": "1911.00604", "submitter": "Sharif Abuadbba Dr", "authors": "Sharif Abuadbba, Ayman Ibaida, Ibrahim Khalil", "title": "IoTSign: Protecting Privacy and Authenticity of IoT using Discrete\n  Cosine Based Steganography", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remotely generated data by Intent of Things (IoT) has recently had a lot of\nattention for their huge benefits such as efficient monitoring and risk\nreduction. The transmitted streams usually consist of periodical streams (e.g.\nactivities) and highly private information (e.g. IDs). Despite the obvious\nbenefits, the concerns are the secrecy and the originality of the transferred\ndata. Surprisingly, although these concerns have been well studied for static\ndata, they have received only limited attention for streaming data. Therefore,\nthis paper introduces a new steganographic mechanism that provides (1) robust\nprivacy protection of secret information by concealing them arbitrarily in the\ntransported readings employing a random key, and (2) permanent proof of\noriginality for the normal streams. This model surpasses our previous works by\nemploying the Discrete Cosine Transform to expand the hiding capacity and\nreduce complexity. The resultant distortion has been accurately measured at all\nstages - the original, the stego, and the recovered forms - using a well-known\nmeasurement matrix called Percentage Residual Difference (PRD). After thorough\nexperiments on three types of streams (i.e. chemical, environmental and smart\nhomes), it has been proven that the original streams have not been affected (<\n1 %). Also, the mathematical analysis shows that the model has much lighter\n(i.e. linear) computational complexity O(n) compared to existing work.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 22:27:01 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Abuadbba", "Sharif", ""], ["Ibaida", "Ayman", ""], ["Khalil", "Ibrahim", ""]]}, {"id": "1911.00621", "submitter": "Andrea Fioraldi", "authors": "Andrea Fioraldi, Daniele Cono D'Elia, Emilio Coppa", "title": "WEIZZ: Automatic Grey-box Fuzzing for Structured Binary Formats", "comments": null, "journal-ref": "Proceedings of the 29th ACM SIGSOFT International Symposium on\n  Software Testing and Analysis, 2020", "doi": "10.1145/3395363.3397372", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzing technologies have evolved at a fast pace in recent years, revealing\nbugs in programs with ever increasing depth and speed. Applications working\nwith complex formats are however more difficult to take on, as inputs need to\nmeet certain format-specific characteristics to get through the initial parsing\nstage and reach deeper behaviors of the program. Unlike prior proposals based\non manually written format specifications, in this paper we present a technique\nto automatically generate and mutate inputs for unknown chunk-based binary\nformats. We propose a technique to identify dependencies between input bytes\nand comparison instructions, and later use them to assign tags that\ncharacterize the processing logic of the program. Tags become the building\nblock for structure-aware mutations involving chunks and fields of the input.\nWe show that our techniques performs comparably to structure-aware fuzzing\nproposals that require human assistance. Our prototype implementation WEIZZ\nrevealed 16 unknown bugs in widely used programs.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 00:49:26 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 12:44:32 GMT"}, {"version": "v3", "created": "Wed, 12 Aug 2020 07:46:45 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Fioraldi", "Andrea", ""], ["D'Elia", "Daniele Cono", ""], ["Coppa", "Emilio", ""]]}, {"id": "1911.00661", "submitter": "Ayan Mahalanobis", "authors": "Upendra Kapshikar and Ayan Mahalanobis", "title": "Niederreiter cryptosystems using quasi-cyclic codes that resist quantum\n  Fourier sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  McEliece and Niederreiter cryptosystems are robust and versatile\ncryptosystems. These cryptosystems work with many linear error-correcting\ncodes. They are popular these days because they can be quantum-secure. In this\npaper, we study the Niederreiter cryptosystem using quasi-cyclic codes. We\nprove, if these quasi-cyclic codes satisfy certain conditions, the\ncorresponding Niederreiter cryptosystem is resistant to the hidden subgroup\nproblem using weak quantum Fourier sampling. Though our work uses the weak\nFourier sampling, we argue that its conclusions should remain valid for the\nstrong Fourier sampling as well. Our proof requires the classification of\nfinite simple groups.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 06:12:23 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 06:31:55 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kapshikar", "Upendra", ""], ["Mahalanobis", "Ayan", ""]]}, {"id": "1911.00692", "submitter": "Rajakumar Arul", "authors": "Rajakumar Arul, Gunasekaran Raja, Alaa Omran Almagrabi, Mohammed Saeed\n  Alkatheiri, Chauhdary Sajjad Hussain and Ali Kashif Bashir", "title": "A Quantum Safe Key Hierarchy and Dynamic Security Association for\n  LTE/SAE in 5G Scenario", "comments": "9 PAGES, 9 FIGURES", "journal-ref": null, "doi": "10.1109/TII.2019.2949354", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millions of devices are going to participate in 5G producing a huge space for\nsecurity threats. The 5G specification goals require rigid and robust security\nprotocol against such threats. Quantum cryptography is a recently emerged term\nin which we test the robustness of security protocols against Quantum\ncomputers. Therefore, in this paper, we propose a security protocol called\nQuantum Key GRID for Authentication and Key Agreement (QKG-AKA) scheme for the\ndynamic security association. This scheme is efficiently deployed in Long Term\nEvolution (LTE) architecture without any significant modifications in the\nunderlying base system. The proposed QKG-AKA mechanism is analyzed for\nrobustness and proven safe against quantum computers. The simulation results\nand performance analysis show drastic improvement regarding security and key\nmanagement over existing schemes.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 10:41:13 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Arul", "Rajakumar", ""], ["Raja", "Gunasekaran", ""], ["Almagrabi", "Alaa Omran", ""], ["Alkatheiri", "Mohammed Saeed", ""], ["Hussain", "Chauhdary Sajjad", ""], ["Bashir", "Ali Kashif", ""]]}, {"id": "1911.00725", "submitter": "Jun Zhao", "authors": "Jun Zhao", "title": "On resilience and connectivity of secure wireless sensor networks under\n  node capture attacks", "comments": "published in IEEE Transactions on Information Forensics and Security", "journal-ref": null, "doi": "10.1109/TIFS.2016.2613841", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite much research on probabilistic key predistribution schemes for\nwireless sensor networks over the past decade, few formal analyses exist that\ndefine schemes' resilience to node-capture attacks precisely and under\nrealistic conditions. In this paper, we analyze the resilience of the\nq-composite key predistribution scheme, which mitigates the node capture\nvulnerability of the Eschenauer-Gligor scheme in the neighbor discovery phase.\nWe derive scheme parameters to have a desired level of resiliency, and obtain\noptimal parameters that defend against different adversaries as much as\npossible. We also show that this scheme can be easily enhanced to achieve the\nsame \"perfect resilience\" property as in the random pairwise key\npredistribution for attacks launched after neighbor discovery. Despite\nconsiderable attention to this scheme, much prior work explicitly or implicitly\nuses an incorrect computation for the probability of link compromise under\nnode-capture attacks and ignores real-world transmission constraints of sensor\nnodes. Moreover, we derive the critical network parameters to ensure\nconnectivity in both the absence and presence of node-capture attacks. We also\ninvestigate node replication attacks by analyzing the adversary's optimal\nstrategy.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 15:00:22 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Zhao", "Jun", ""]]}, {"id": "1911.00745", "submitter": "Jun Zhao", "authors": "Jun Zhao", "title": "Secure Connectivity of Wireless Sensor Networks Under Key\n  Predistribution with on/off Channels", "comments": "published in International Conference on Distributed Computing\n  Systems (ICDCS) 2017", "journal-ref": null, "doi": "10.1109/ICDCS.2017.186", "report-no": null, "categories": "cs.CR math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security is an important issue in wireless sensor networks (WSNs), which are\noften deployed in hostile environments. The q-composite key predistribution\nscheme has been recognized as a suitable approach to secure WSNs. Although the\nq-composite scheme has received much attention in the literature, there is\nstill a lack of rigorous analysis for secure WSNs operating under the\nq-composite scheme in consideration of the unreliability of links. One main\ndifficulty lies in analyzing the network topology whose links are not\nindependent. Wireless links can be unreliable in practice due to the presence\nof physical barriers between sensors or because of harsh environmental\nconditions severely impairing communications. In this paper, we resolve the\ndifficult challenge and investigate k-connectivity in secure WSNs operating\nunder the q-composite scheme with unreliable communication links modeled as\nindependent on/off channels, where k-connectivity ensures connectivity despite\nthe failure of any (k - 1) sensors or links, and connectivity means that any\ntwo sensors can find a path in between for secure communication. Specifically,\nwe derive the asymptotically exact probability and a zero-one law for\nk-connectivity. We further use the theoretical results to provide design\nguidelines for secure WSNs. Experimental results also confirm the validity of\nour analytical findings.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 16:04:02 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Zhao", "Jun", ""]]}, {"id": "1911.00753", "submitter": "Mohamed Hamidi", "authors": "Mohamed Hamidi and Mohamed El Haziti and Hocine Cherifi and Mohammed\n  El Hassouni", "title": "Hybrid blind robust image watermarking technique based on DFT-DCT and\n  Arnold transform", "comments": "34 page, 17 figures, published in Multimedia Tools and Applications\n  Springer, 2018", "journal-ref": "Multimedia Tools and Applications, 77(20), 27181-27214 (2018)", "doi": "10.1007/s11042-018-5913-9", "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a robust blind image watermarking method is proposed for\ncopyright protection of digital images. This hybrid method relies on combining\ntwo well-known transforms that are the discrete Fourier transform (DFT) and the\ndiscrete cosine transform (DCT). The motivation behind this combination is to\nenhance the imperceptibility and the robustness. The imperceptibility\nrequirement is achieved by using magnitudes of DFT coefficients while the\nrobustness improvement is ensured by applying DCT to the DFT coefficients\nmagnitude. The watermark is embedded by modifying the coefficients of the\nmiddle band of the DCT using a secret key. The security of the proposed method\nis enhanced by applying Arnold transform (AT) to the watermark before\nembedding. Experiments were conducted on natural and textured images. Results\nshow that, compared with state-of-the-art methods, the proposed method is\nrobust to a wide range of attacks while preserving high imperceptibility.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 16:58:15 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Hamidi", "Mohamed", ""], ["Haziti", "Mohamed El", ""], ["Cherifi", "Hocine", ""], ["Hassouni", "Mohammed El", ""]]}, {"id": "1911.00761", "submitter": "Jun Zhao", "authors": "Jun Zhao", "title": "Relations among different privacy notions", "comments": "Published in: IEEE 55th Annual Allerton Conference on Communication,\n  Control, and Computing (Allerton), UIUC, Illinois, US, October 2017", "journal-ref": null, "doi": "10.1109/ALLERTON.2017.8262821", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a comprehensive view of the relations among several privacy\nnotions: differential privacy (DP) [1], Bayesian differential privacy (BDP)\n[2], semantic privacy (SP) [3], and membership privacy (MP) [4]. The results\nare organized into two parts. In part one, we extend the notion of semantic\nprivacy (SP) to Bayesian semantic privacy (BSP) and show its essential\nequivalence with Bayesian differential privacy (BDP) in the quantitative sense.\nWe prove the relations between BDP, BSP, and SP as follows: $\\epsilon$-BDP\n$\\Longleftarrow$ $\\big(\\frac{1}{2}-\\frac{1}{e^{\\epsilon}+1}\\big)$-BSP, and\n$\\epsilon$-BDP $\\Longrightarrow$ $(e^{2\\epsilon}-1)$-BSP $\\Longrightarrow$\n$(e^{2\\epsilon}-1)$-SP. In addition, we obtain a minor result $\\epsilon$-DP\n$\\Longleftarrow$ $\\big(\\frac{1}{2}-\\frac{1}{e^{\\epsilon}+1}\\big)$-SP, which\nimproves the result of Kasiviswanathan and Smith [3] stating $\\epsilon$-DP\n$\\Longleftarrow$ $\\epsilon/6$-SP for $\\epsilon \\leq 1.35$. In part two, we\nestablish the relations between BDP and MP. First, $\\epsilon$-BDP\n$\\Longrightarrow$ $\\epsilon$-MP. Second, for a family of distributions that are\ndownward scalable in the sense of Li et al. [4], it is shown that\n$\\epsilon$-BDP $\\Longleftarrow$ $\\epsilon$-MP.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 18:05:47 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Zhao", "Jun", ""]]}, {"id": "1911.00763", "submitter": "Jun Zhao", "authors": "Jun Zhao", "title": "Composition Properties of Bayesian Differential Privacy", "comments": "Published in: 2017 IEEE 28th Annual International Symposium on\n  Personal, Indoor, and Mobile Radio Communications (PIMRC)", "journal-ref": null, "doi": "10.1109/PIMRC.2017.8292647", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is a rigorous privacy standard that has been applied to\na range of data analysis tasks. To broaden the application scenarios of\ndifferential privacy when data records have dependencies, the notion of\nBayesian differential privacy has been recently proposed. However, it is\nunknown whether Bayesian differential privacy preserves three nice properties\nof differential privacy: sequential composability, parallel composability, and\npost-processing. In this paper, we provide an affirmative answer to this\nquestion; i.e., Bayesian differential privacy still have these properties. The\nidea behind sequential composability is that if we have $m$ algorithms $Y_1,\nY_2, \\ldots, Y_m$, where $Y_{\\ell}$ is independently $\\epsilon_{\\ell}$-Bayesian\ndifferential private for ${\\ell}=1,2,\\ldots,m$, then by feeding the result of\n$Y_1$ into $Y_2$, the result of $Y_2$ into $Y_3$, and so on, we will finally\nhave an $\\sum_{\\ell=1}^m \\epsilon_{\\ell}$-Bayesian differential private\nalgorithm. For parallel composability, we consider the situation where a\ndatabase is partitioned into $m$ disjoint subsets. The $\\ell$-th subset is\ninput to a Bayesian differential private algorithm $Y_{\\ell}$, for\n${\\ell}=1,2,\\ldots,m$. Then the parallel composition of $Y_1$, $Y_2$, $\\ldots$,\n$Y_m$ will be $\\max_{\\ell=1}^m \\epsilon_{\\ell}$-Bayesian differential private.\nThe post-processing property means that a data analyst, without additional\nknowledge about the private database, cannot compute a function of the output\nof a Bayesian differential private algorithm and reduce its privacy guarantee.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 18:24:13 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Zhao", "Jun", ""]]}, {"id": "1911.00765", "submitter": "Jun Zhao", "authors": "Jun Zhao", "title": "Adaptive Statistical Learning with Bayesian Differential Privacy", "comments": "WPES '17 Proceedings of the 2017 on Workshop on Privacy in the\n  Electronic Society, held in conjunction with ACM SIGSAC 25th Annual\n  Conference on Computer and Communications Security (CCS), Dallas, Texas, US,\n  October 2017", "journal-ref": null, "doi": "10.1145/3139550.3139556", "report-no": null, "categories": "cs.LG cs.CR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In statistical learning, a dataset is often partitioned into two parts: the\ntraining set and the holdout (i.e., testing) set. For instance, the training\nset is used to learn a predictor, and then the holdout set is used for\nestimating the accuracy of the predictor on the true distribution. However,\noften in practice, the holdout dataset is reused and the estimates tested on\nthe holdout dataset are chosen adaptively based on the results of prior\nestimates, leading to that the predictor may become dependent of the holdout\nset. Hence, overfitting may occur, and the learned models may not generalize\nwell to the unseen datasets. Prior studies have established connections between\nthe stability of a learning algorithm and its ability to generalize, but the\ntraditional generalization is not robust to adaptive composition. Recently,\nDwork et al. in NIPS, STOC, and Science 2015 show that the holdout dataset from\ni.i.d. data samples can be reused in adaptive statistical learning, if the\nestimates are perturbed and coordinated using techniques developed for\ndifferential privacy, which is a widely used notion to quantify privacy. Yet,\nthe results of Dwork et al. are applicable to only the case of i.i.d. samples.\nIn contrast, correlations between data samples exist because of various\nbehavioral, social, and genetic relationships between users. Our results in\nadaptive statistical learning generalize the results of Dwork et al. for i.i.d.\ndata samples to arbitrarily correlated data. Specifically, we show that the\nholdout dataset from correlated samples can be reused in adaptive statistical\nlearning, if the estimates are perturbed and coordinated using techniques\ndeveloped for Bayesian differential privacy, which is a privacy notion recently\nintroduced by Yang et al. in SIGMOD 2015 to broaden the application scenarios\nof differential privacy when data records are correlated.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 18:45:31 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Zhao", "Jun", ""]]}, {"id": "1911.00772", "submitter": "Shadrokh Samavi", "authors": "Maedeh Jamali, Mahnoosh Bagheri, Nader Karimi, Shadrokh Samavi", "title": "Robustness and Imperceptibility Enhancement in Watermarked Images by\n  Color Transformation", "comments": "5 pages 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the effective methods for the preservation of copyright ownership of\ndigital media is watermarking. Different watermarking techniques try to set a\ntradeoff between robustness and transparency of the process. In this research\nwork, we have used color space conversion and frequency transform to achieve\nhigh robustness and transparency. Due to the distribution of image information\nin the RGB domain, we use the YUV color space, which concentrates the visual\ninformation in the Y channel. Embedding of the watermark is performed in the\nDCT coefficients of the specific wavelet subbands. Experimental results show\nhigh transparency and robustness of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 19:19:24 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Jamali", "Maedeh", ""], ["Bagheri", "Mahnoosh", ""], ["Karimi", "Nader", ""], ["Samavi", "Shadrokh", ""]]}, {"id": "1911.00783", "submitter": "Tolulope Odetola", "authors": "Tolulope A. Odetola and Hawzhin Raoof Mohammed and Syed Rafay Hasan", "title": "A Stealthy Hardware Trojan Exploiting the Architectural Vulnerability of\n  Deep Learning Architectures: Input Interception Attack (IIA)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning architectures (DLA) have shown impressive performance in\ncomputer vision, natural language processing and so on. Many DLA make use of\ncloud computing to achieve classification due to the high computation and\nmemory requirements. Privacy and latency concerns resulting from cloud\ncomputing has inspired the deployment of DLA on embedded hardware accelerators.\nTo achieve short time-to-market and have access to global experts,\nstate-of-the-art techniques of DLA deployment on hardware accelerators are\noutsourced to untrusted third parties. This outsourcing raises security\nconcerns as hardware Trojans can be inserted into the hardware design of the\nmapped DLA of the hardware accelerator. We argue that existing hardware Trojan\nattacks highlighted in literature have no qualitative means how definite they\nare of the triggering of the Trojan. Also, most inserted Trojans show a obvious\nspike in the number of hardware resources utilized on the accelerator at the\ntime of triggering the Trojan or when the payload is active. In this paper, we\nintroduce a hardware Trojan attack called Input Interception Attack (IIA). In\nthis attack, we make use of the statistical properties of layer-by-layer output\nto ensure that asides from being stealthy. Our IIA is able to trigger with some\nmeasure of definiteness. Moreover, this IIA attack is tested on DLA used to\nclassify MNIST and Cifar-10 data sets. The attacked design utilizes\napproximately up to 2% more LUTs respectively compared to the un-compromised\ndesigns. Finally, this paper discusses potential defensive mechanisms that\ncould be used to combat such hardware Trojans based attack in hardware\naccelerators for DLA.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 20:34:16 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 16:07:07 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Odetola", "Tolulope A.", ""], ["Mohammed", "Hawzhin Raoof", ""], ["Hasan", "Syed Rafay", ""]]}, {"id": "1911.00815", "submitter": "Eric Goodman", "authors": "Eric L. Goodman, Dirk Grunwald", "title": "A Streaming Analytics Language for Processing Cyber Data", "comments": "Machine Learning and Data Mining 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a domain-specific language called SAL(the Streaming Analytics\nLanguage) for processing data in a semi-streaming model. In particular we\nexamine the use case of processing netflow data in order to identify malicious\nactors within a network. Because of the large volume of data generated from\nnetworks, it is often only feasible to process the data with a single pass,\nutilizing a streaming (O(polylog n) space requirements) or semi-streaming\ncomputing model ( O(n polylog n) space requirements). Despite these\nconstraints, we are able to achieve an average of 0.87 for the AUC of the ROC\ncurve for a set of situations dealing with botnet detection. The implementation\nof an interpreter for SAL, which we call SAM (Streaming Analytics Machine),\nachieves scaling results that show improved throughput to 61 nodes (976 cores),\nwith an overall rate of 373,000 netflows per second or 32.2 billion per day.\nSAL provides a succinct way to describe common analyses that allow cyber\nanalysts to find data of interest, and SAM is a scalable interpreter of the\nlanguage.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 03:14:21 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Goodman", "Eric L.", ""], ["Grunwald", "Dirk", ""]]}, {"id": "1911.00868", "submitter": "Roberto Guanciale", "authors": "Roberto Guanciale and Musard Balliu and Mads Dam", "title": "InSpectre: Breaking and Fixing Microarchitectural Vulnerabilities by\n  Formal Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent Spectre attacks has demonstrated the fundamental insecurity of\ncurrent computer microarchitecture. The attacks use features like pipelining,\nout-of-order and speculation to extract arbitrary information about the memory\ncontents of a process. A comprehensive formal microarchitectural model capable\nof representing the forms of out-of-order and speculative behavior that can\nmeaningfully be implemented in a high performance pipelined architecture has\nnot yet emerged. Such a model would be very useful, as it would allow the\nexistence and non-existence of vulnerabilities, and soundness of\ncountermeasures to be formally established.\n  In this paper we present such a model targeting single core processors. The\nmodel is intentionally very general and provides an infrastructure to define\nmodels of real CPUs. It incorporates microarchitectural features that underpin\nall known Spectre vulnerabilities. We use the model to elucidate the security\nof existing and new vulnerabilities, as well as to formally analyze the\neffectiveness of proposed countermeasures. Specifically, we discover three new\n(potential) vulnerabilities, including a new variant of Spectre v4, a\nvulnerability on speculative fetching, and a vulnerability on out-of-order\nexecution, and analyze the effectiveness of three existing countermeasures:\nconstant time, Retpoline, and ARM's Speculative Store Bypass Safe (SSBS).\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 11:13:25 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 13:06:20 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Guanciale", "Roberto", ""], ["Balliu", "Musard", ""], ["Dam", "Mads", ""]]}, {"id": "1911.00870", "submitter": "Shai Rozenberg", "authors": "Shai Rozenberg, Gal Elidan, Ran El-Yaniv", "title": "MadNet: Using a MAD Optimization for Defending Against Adversarial\n  Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is concerned with the defense of deep models against adversarial\nattacks. Inspired by the certificate defense approach, we propose a maximal\nadversarial distortion (MAD) optimization method for robustifying deep\nnetworks. MAD captures the idea of increasing separability of class clusters in\nthe embedding space while decreasing the network sensitivity to small\ndistortions. Given a deep neural network (DNN) for a classification problem, an\napplication of MAD optimization results in MadNet, a version of the original\nnetwork, now equipped with an adversarial defense mechanism. MAD optimization\nis intuitive, effective and scalable, and the resulting MadNet can improve the\noriginal accuracy. We present an extensive empirical study demonstrating that\nMadNet improves adversarial robustness performance compared to state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 11:21:35 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 19:05:36 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Rozenberg", "Shai", ""], ["Elidan", "Gal", ""], ["El-Yaniv", "Ran", ""]]}, {"id": "1911.00895", "submitter": "Vitaly Roman'kov", "authors": "Vitaly Roman'kov", "title": "Cryptanalysis of a new version of the MOR scheme", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that an attack based on the linear decomposition method introduced by\nthe author can be efficiently applied to the new version of the MOR scheme\nproposed in \\cite{BMSS}. We draw attention to some inaccuracies in the\ndescription of this version. We show how the action of an exponent of a given\nautomorphism (for example, the action of its inverse) can be calculated, and we\nalso show how the unknown exponent of automorphism can be calculated if we go\nover to the corresponding linear transformation. This method can be applied to\ndifferent matrix groups over an arbitrary constructive field. It does not\ndepend on the specific properties of the underlined matrix group. The\nconsidered problem is reduced in probabilistic polynomial time to the similar\nproblem in small extensions of the underlined field.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 14:11:24 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Roman'kov", "Vitaly", ""]]}, {"id": "1911.00900", "submitter": "Wang Taotao", "authors": "Taotao Wang, Xiaoqian Bai, Hao Wang, Soung Chang Liew, and Shengli\n  Zhang", "title": "Game-Theoretical Analysis of Mining Strategy for Bitcoin-NG Blockchain\n  Protocol", "comments": "13 pages, 10 figures, accepted for publication in IEEE Systems\n  Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin-NG, a scalable blockchain protocol, divides each block into a key\nblock and many micro blocks to effectively improve the transaction processing\ncapacity. Bitcoin-NG has a special incentive mechanism (i.e. splitting\ntransaction fees to the current and the next leader) to maintain its security.\nHowever, this design of the incentive mechanism ignores the joint effect of\ntransaction fees, mint coins and mining duration lengths on the expected mining\nreward. In this paper, we identify the advanced mining attack that deliberately\nignores micro blocks to enlarge the mining duration length to increase the\nlikelihood of winning the mining race. We first show that an advanced mining\nattacker can maximize its expected reward by optimizing its mining duration\nlength. We then formulate a game-theoretical model in which multiple mining\nplayers perform advanced mining to compete with each other. We analyze the Nash\nequilibrium for the mining game. Our analytical and simulation results indicate\nthat all mining players in the mining game converge to having advanced mining\nat the equilibrium and have no incentives for deviating from the equilibrium;\nthe transaction processing capability of the Bitcoin-NG network at the\nequilibrium is decreased by advanced mining. Therefore, we conclude that the\nBitcoin-NG blockchain protocol is vulnerable to advanced mining attack. We\ndiscuss how to reduce the negative impact of advanced mining for Bitcoin-NG.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 14:37:44 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 02:15:53 GMT"}, {"version": "v3", "created": "Sat, 20 Jun 2020 09:58:07 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Wang", "Taotao", ""], ["Bai", "Xiaoqian", ""], ["Wang", "Hao", ""], ["Liew", "Soung Chang", ""], ["Zhang", "Shengli", ""]]}, {"id": "1911.00928", "submitter": "Mohammad Rahman", "authors": "Mohammad Ashiqur Rahman, Md Hasan Shahriar, Mohamadsaleh Jafari, Rahat\n  Masum", "title": "Novel Attacks against Contingency Analysis in Power Grids", "comments": "The paper is under review at a conference. Rahman and Shahriar are\n  the co-first authors of this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.LO cs.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Contingency Analysis (CA) is a core component of the Energy Management System\n(EMS) in the power grid. The goal of CA is to operate the power system in a\nsecure manner by analyzing the system subject to a contingency (e.g., the\noutage of a transmission line or a power generator) to determine the setpoints\nthat will allow system operation without violation of constraints. The analysis\nin CA is conducted based on the output from State Estimation (SE), another core\nEMS module. However, it is also shown that an adversary can alter certain power\nmeasurements to corrupt the system states estimated by SE without being\ndetected. Such a corrupted estimation can severely skew the results of the\ncontingency analysis as it will provide a fake model to deal with. In this\nresearch, we formally model necessary interdependency relationships and\nsystematically analyze these novel attacks on the contingency analysis. In\nparticular, this research focuses on Security Constrained Optimal Power Flow\n(SCOPF) that finds out the optimal economic dispatches considering a single\nline failure (based on the $n - 1$ contingency analysis) and transmission line\ncapacities. The proposed model is implemented and solved to find out potential\nthreat vectors (i.e., a set of measurements to be altered) that can evade CA so\nthat the system will face overloading situation on one or more transmission\nlines when some specific contingencies happen. We demonstrate our formal model\non an IEEE 14 bus system-based case study and verify the results with a\nstandard PowerWorld model. We further evaluate the model with respect to\nvarious attacks and grid characteristics.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 16:49:30 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Rahman", "Mohammad Ashiqur", ""], ["Shahriar", "Md Hasan", ""], ["Jafari", "Mohamadsaleh", ""], ["Masum", "Rahat", ""]]}, {"id": "1911.00950", "submitter": "Sari Sultan", "authors": "Sari Sultan and Ayed Salman", "title": "Calcium Vulnerability Scanner (CVS): A Deeper Look", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional vulnerability scanning methods are time-consuming and indecisive,\nand they negatively affect network performance by generating high network\ntraffic. In this paper, we present a novel vulnerability scanner that is\ntime-efficient, simple, accurate, and safe. We call it a Calcium Vulnerability\nScanner (CVS). Our contribution to vulnerability scanning are the following:\n(i) minimize its required time and network traffic: compared to current\ntechnologies, we reduced the former by an average of 79% and the latter by\n99.9%, (ii) increase its accuracy: compared to current technologies, we\nimproved this by an average of 2600%, and (iii) enable the scanner to learn\nfrom previous scans in order to reduce future scanning time and enhance\naccuracy: compared to current technologies, CVS reduced scanning time by an\naverage of 97%. CVS enables a new frontier in vulnerability scanning and allow\nfor scalable and efficient deployment of such tools in large-scale networks,\ncontainers, edge computing, and cloud computing.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 19:18:13 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Sultan", "Sari", ""], ["Salman", "Ayed", ""]]}, {"id": "1911.00953", "submitter": "Avisha Das", "authors": "Avisha Das, Shahryar Baki, Ayman El Aassal, Rakesh Verma, and Arthur\n  Dunbar", "title": "SOK: A Comprehensive Reexamination of Phishing Research from the\n  Security Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phishing and spear-phishing are typical examples of masquerade attacks since\ntrust is built up through impersonation for the attack to succeed. Given the\nprevalence of these attacks, considerable research has been conducted on these\nproblems along multiple dimensions. We reexamine the existing research on\nphishing and spear-phishing from the perspective of the unique needs of the\nsecurity domain, which we call security challenges: real-time detection, active\nattacker, dataset quality and base-rate fallacy. We explain these challenges\nand then survey the existing phishing/spear phishing solutions in their light.\nThis viewpoint consolidates the literature and illuminates several\nopportunities for improving existing solutions. We organize the existing\nliterature based on detection techniques for different attack vectors (e.g.,\nURLs, websites, emails) along with studies on user awareness. For detection\ntechniques, we examine properties of the dataset, feature extraction, detection\nalgorithms used, and performance evaluation metrics. This work can help guide\nthe development of more effective defenses for phishing, spear-phishing, and\nemail masquerade attacks of the future, as well as provide a framework for a\nthorough evaluation and comparison.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 19:43:20 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Das", "Avisha", ""], ["Baki", "Shahryar", ""], ["Aassal", "Ayman El", ""], ["Verma", "Rakesh", ""], ["Dunbar", "Arthur", ""]]}, {"id": "1911.00972", "submitter": "Tian Li", "authors": "Tian Li, Zaoxing Liu, Vyas Sekar, Virginia Smith", "title": "Privacy for Free: Communication-Efficient Learning with Differential\n  Privacy Using Sketches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication and privacy are two critical concerns in distributed learning.\nMany existing works treat these concerns separately. In this work, we argue\nthat a natural connection exists between methods for communication reduction\nand privacy preservation in the context of distributed machine learning. In\nparticular, we prove that Count Sketch, a simple method for data stream\nsummarization, has inherent differential privacy properties. Using these\nderived privacy guarantees, we propose a novel sketch-based framework\n(DiffSketch) for distributed learning, where we compress the transmitted\nmessages via sketches to simultaneously achieve communication efficiency and\nprovable privacy benefits. Our evaluation demonstrates that DiffSketch can\nprovide strong differential privacy guarantees (e.g., $\\varepsilon$= 1) and\nreduce communication by 20-50x with only marginal decreases in accuracy.\nCompared to baselines that treat privacy and communication separately,\nDiffSketch improves absolute test accuracy by 5%-50% while offering the same\nprivacy guarantees and communication compression.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 21:19:13 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 18:35:54 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Li", "Tian", ""], ["Liu", "Zaoxing", ""], ["Sekar", "Vyas", ""], ["Smith", "Virginia", ""]]}, {"id": "1911.01002", "submitter": "Ge Yao", "authors": "Ge Yao, Udaya Parampalli", "title": "Generalized NLFSR Transformation Algorithms and Cryptanalysis of the\n  Class of Espresso-like Stream Ciphers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lightweight stream ciphers are highly demanded in IoT applications. In order\nto optimize the hardware performance, a new class of stream cipher has been\nproposed. The basic idea is to employ a single Galois NLFSR with maximum period\nto construct the cipher. As a representative design of this kind of stream\nciphers, Espresso is based on a 256-bit Galois NLFSR initialized by a 128-bit\nkey. The $2^{256}-1$ maximum period is assured because the Galois NLFSR is\ntransformed from a maximum length LFSR. However, we propose a\nGalois-to-Fibonacci transformation algorithm and successfully transform the\nGalois NLFSR into a Fibonacci LFSR with a nonlinear output function. The\ntransformed cipher is broken by the standard algebraic attack and the R\\o\nnjom-Helleseth attack with complexity $\\mathcal{O}(2^{68.44})$ and\n$\\mathcal{O}(2^{66.86})$ respectively. The transformation algorithm is derived\nfrom a new Fibonacci-to-Galois transformation algorithm we propose in this\npaper. Compare to existing algorithms, proposed algorithms are more efficient\nand cover more general use cases. Moreover, the transformation result shows\nthat the Galois NLFSR used in any Espresso-like stream ciphers can be easily\ntransformed back into the original Fibonacci LFSR. Therefore, this kind of\ndesign should be avoided in the future.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 01:55:00 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Yao", "Ge", ""], ["Parampalli", "Udaya", ""]]}, {"id": "1911.01330", "submitter": "Daniel Diroff", "authors": "Daniel J. Diroff (Akvelon, Inc.)", "title": "Bitcoin Coin Selection with Leverage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new Bitcoin coin selection algorithm, \"coin selection with\nleverage\", which aims to improve upon cost savings than that of standard\nknapsack like approaches. Parameters to the new algorithm are available to be\ntuned at the users discretion to address other goals of coin selection. Our\napproach naturally fits as a replacement for the standard knapsack ingredient\nof full coin selection procedures.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 16:48:45 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 23:11:33 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Diroff", "Daniel J.", "", "Akvelon, Inc."]]}, {"id": "1911.01349", "submitter": "Weeam Alshangiti Mrs", "authors": "Weeam Alshangiti and Rafid Saad", "title": "Mice and Covert Channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Any secure network is only as secure as its weakest component. With overt\nchannels tightly secured and attackers have started focusing on optical,\naudible, magnetic, and thermal covert channels to access sensitive systems. In\nthis paper, we present a novel, reliable and bidirectional optical covert\nchannel which uses optical mice. In this channel, the photocell in the mouse is\nused as a receiver while the LED is used as a transmitter. Our multiple\nexperiments, which use mouse to mouse, mouse to camera and torch to mouse, show\nthat the transmission rate can go as high as 10 bits per second. Additionally,\nwe study the effects of infrared, distance and brightness on mouse input. We\nalso show that infrared mice are susceptible to a similar kind of attack.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 17:19:15 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Alshangiti", "Weeam", ""], ["Saad", "Rafid", ""]]}, {"id": "1911.01402", "submitter": "Xiaolan Gu", "authors": "Xiaolan Gu, Ming Li, Li Xiong, Yang Cao", "title": "Providing Input-Discriminative Protection for Local Differential Privacy", "comments": "This is a full version of our paper that appears in the 36th IEEE\n  International Conference on Data Engineering (ICDE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local Differential Privacy (LDP) provides provable privacy protection for\ndata collection without the assumption of the trusted data server. In the\nreal-world scenario, different data have different privacy requirements due to\nthe distinct sensitivity levels. However, LDP provides the same protection for\nall data. In this paper, we tackle the challenge of providing\ninput-discriminative protection to reflect the distinct privacy requirements of\ndifferent inputs. We first present the Input-Discriminative LDP (ID-LDP)\nprivacy notion and focus on a specific version termed MinID-LDP, which is shown\nto be a fine-grained version of LDP. Then, we focus on the application of\nfrequency estimation and develop the IDUE mechanism based on Unary Encoding for\nsingle-item input and the extended mechanism IDUE-PS (with Padding-and-Sampling\nprotocol) for item-set input. The results on both synthetic and real-world\ndatasets validate the correctness of our theoretical analysis and show that the\nproposed mechanisms satisfying MinID-LDP have better utility than the\nstate-of-the-art mechanisms satisfying LDP due to the input-discriminative\nprotection.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 18:48:04 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 18:42:41 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Gu", "Xiaolan", ""], ["Li", "Ming", ""], ["Xiong", "Li", ""], ["Cao", "Yang", ""]]}, {"id": "1911.01452", "submitter": "Matthew Joseph", "authors": "Kareem Amin, Matthew Joseph, and Jieming Mao", "title": "Pan-Private Uniformity Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A centrally differentially private algorithm maps raw data to differentially\nprivate outputs. In contrast, a locally differentially private algorithm may\nonly access data through public interaction with data holders, and this\ninteraction must be a differentially private function of the data. We study the\nintermediate model of pan-privacy. Unlike a locally private algorithm, a\npan-private algorithm receives data in the clear. Unlike a centrally private\nalgorithm, the algorithm receives data one element at a time and must maintain\na differentially private internal state while processing this stream.\n  First, we show that pure pan-privacy against multiple intrusions on the\ninternal state is equivalent to sequentially interactive local privacy. Next,\nwe contextualize pan-privacy against a single intrusion by analyzing the sample\ncomplexity of uniformity testing over domain $[k]$. Focusing on the dependence\non $k$, centrally private uniformity testing has sample complexity\n$\\Theta(\\sqrt{k})$, while noninteractive locally private uniformity testing has\nsample complexity $\\Theta(k)$. We show that the sample complexity of pure\npan-private uniformity testing is $\\Theta(k^{2/3})$. By a new $\\Omega(k)$ lower\nbound for the sequentially interactive setting, we also separate pan-private\nfrom sequentially interactive locally private and multi-intrusion pan-private\nuniformity testing.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 19:06:29 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 18:16:33 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 13:45:25 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Amin", "Kareem", ""], ["Joseph", "Matthew", ""], ["Mao", "Jieming", ""]]}, {"id": "1911.01471", "submitter": "Uchenna D Ani PhD", "authors": "Uchenna D Ani, Jeremy M Watson, Benjamin Green, Barnaby Craggs, and\n  Jason Nurse", "title": "Design Considerations for Building Credible Security Testbeds: A\n  Systematic Study of Industrial Control System Use Cases", "comments": "17 pages (including Appendix), 2 Figures, 4 Tables, A Research output\n  from the Analytical Lenses for Internet of Things Threats (ALIoTT) project", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a mapping framework for design factors and implementation\nprocess for building credible Industrial Control Systems (ICS) security\ntestbeds. The resilience of ICSs has become a critical concern to operators and\ngovernments following widely publicised cyber security events. The inability to\napply conventional Information Technology security practice to ICSs further\ncompounds challenges in adequately securing critical systems. To overcome these\nchallenges, and do so without impacting live environments, testbeds for the\nexploration, development and evaluation of security controls are widely used.\nHowever, how a testbed is designed and its attributes, can directly impact not\nonly its viability but also its credibility as a whole. Through a combined\nsystematic and thematic analysis and mapping of ICS security testbed design\nattributes, this paper suggests that the expertise of human experimenters,\ndesign objectives, the implementation approach, architectural coverage, core\ncharacteristics, and evaluation methods; are considerations that can help\nestablish or enhance confidence, trustworthiness and acceptance; thus,\ncredibility of ICS security testbeds.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 20:02:09 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Ani", "Uchenna D", ""], ["Watson", "Jeremy M", ""], ["Green", "Benjamin", ""], ["Craggs", "Barnaby", ""], ["Nurse", "Jason", ""]]}, {"id": "1911.01559", "submitter": "Ren Pang", "authors": "Ren Pang, Hua Shen, Xinyang Zhang, Shouling Ji, Yevgeniy Vorobeychik,\n  Xiapu Luo, Alex Liu, Ting Wang", "title": "A Tale of Evil Twins: Adversarial Inputs versus Poisoned Models", "comments": "Accepted as a full paper at ACM CCS 2020", "journal-ref": null, "doi": "10.1145/3372297.3417253", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their tremendous success in a range of domains, deep learning systems\nare inherently susceptible to two types of manipulations: adversarial inputs --\nmaliciously crafted samples that deceive target deep neural network (DNN)\nmodels, and poisoned models -- adversely forged DNNs that misbehave on\npre-defined inputs. While prior work has intensively studied the two attack\nvectors in parallel, there is still a lack of understanding about their\nfundamental connections: what are the dynamic interactions between the two\nattack vectors? what are the implications of such interactions for optimizing\nexisting attacks? what are the potential countermeasures against the enhanced\nattacks? Answering these key questions is crucial for assessing and mitigating\nthe holistic vulnerabilities of DNNs deployed in realistic settings.\n  Here we take a solid step towards this goal by conducting the first\nsystematic study of the two attack vectors within a unified framework.\nSpecifically, (i) we develop a new attack model that jointly optimizes\nadversarial inputs and poisoned models; (ii) with both analytical and empirical\nevidence, we reveal that there exist intriguing \"mutual reinforcement\" effects\nbetween the two attack vectors -- leveraging one vector significantly amplifies\nthe effectiveness of the other; (iii) we demonstrate that such effects enable a\nlarge design spectrum for the adversary to enhance the existing attacks that\nexploit both vectors (e.g., backdoor attacks), such as maximizing the attack\nevasiveness with respect to various detection methods; (iv) finally, we discuss\npotential countermeasures against such optimized attacks and their technical\nchallenges, pointing to several promising research directions.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 01:32:57 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 22:14:26 GMT"}, {"version": "v3", "created": "Sat, 21 Nov 2020 04:54:13 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Pang", "Ren", ""], ["Shen", "Hua", ""], ["Zhang", "Xinyang", ""], ["Ji", "Shouling", ""], ["Vorobeychik", "Yevgeniy", ""], ["Luo", "Xiapu", ""], ["Liu", "Alex", ""], ["Wang", "Ting", ""]]}, {"id": "1911.01601", "submitter": "Xin Wang", "authors": "Xin Wang, Junichi Yamagishi, Massimiliano Todisco, Hector Delgado,\n  Andreas Nautsch, Nicholas Evans, Md Sahidullah, Ville Vestman, Tomi Kinnunen,\n  Kong Aik Lee, Lauri Juvela, Paavo Alku, Yu-Huai Peng, Hsin-Te Hwang, Yu Tsao,\n  Hsin-Min Wang, Sebastien Le Maguer, Markus Becker, Fergus Henderson, Rob\n  Clark, Yu Zhang, Quan Wang, Ye Jia, Kai Onuma, Koji Mushika, Takashi Kaneda,\n  Yuan Jiang, Li-Juan Liu, Yi-Chiao Wu, Wen-Chin Huang, Tomoki Toda, Kou\n  Tanaka, Hirokazu Kameoka, Ingmar Steiner, Driss Matrouf, Jean-Francois\n  Bonastre, Avashna Govender, Srikanth Ronanki, Jing-Xuan Zhang, Zhen-Hua Ling", "title": "ASVspoof 2019: A large-scale public database of synthesized, converted\n  and replayed speech", "comments": "Accepted, Computer Speech and Language. This manuscript version is\n  made available under the CC-BY-NC-ND 4.0. For the published version on\n  Elsevier website, please visit https://doi.org/10.1016/j.csl.2020.101114", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CR cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speaker verification (ASV) is one of the most natural and\nconvenient means of biometric person recognition. Unfortunately, just like all\nother biometric systems, ASV is vulnerable to spoofing, also referred to as\n\"presentation attacks.\" These vulnerabilities are generally unacceptable and\ncall for spoofing countermeasures or \"presentation attack detection\" systems.\nIn addition to impersonation, ASV systems are vulnerable to replay, speech\nsynthesis, and voice conversion attacks. The ASVspoof 2019 edition is the first\nto consider all three spoofing attack types within a single challenge. While\nthey originate from the same source database and same underlying protocol, they\nare explored in two specific use case scenarios. Spoofing attacks within a\nlogical access (LA) scenario are generated with the latest speech synthesis and\nvoice conversion technologies, including state-of-the-art neural acoustic and\nwaveform model techniques. Replay spoofing attacks within a physical access\n(PA) scenario are generated through carefully controlled simulations that\nsupport much more revealing analysis than possible previously. Also new to the\n2019 edition is the use of the tandem detection cost function metric, which\nreflects the impact of spoofing and countermeasures on the reliability of a\nfixed ASV system. This paper describes the database design, protocol, spoofing\nattack implementations, and baseline ASV and countermeasure results. It also\ndescribes a human assessment on spoofed data in logical access. It was\ndemonstrated that the spoofing data in the ASVspoof 2019 database have varied\ndegrees of perceived quality and similarity to the target speakers, including\nspoofed data that cannot be differentiated from bona-fide utterances even by\nhuman subjects.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 03:51:37 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 12:25:16 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 13:56:32 GMT"}, {"version": "v4", "created": "Tue, 14 Jul 2020 09:01:31 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Wang", "Xin", ""], ["Yamagishi", "Junichi", ""], ["Todisco", "Massimiliano", ""], ["Delgado", "Hector", ""], ["Nautsch", "Andreas", ""], ["Evans", "Nicholas", ""], ["Sahidullah", "Md", ""], ["Vestman", "Ville", ""], ["Kinnunen", "Tomi", ""], ["Lee", "Kong Aik", ""], ["Juvela", "Lauri", ""], ["Alku", "Paavo", ""], ["Peng", "Yu-Huai", ""], ["Hwang", "Hsin-Te", ""], ["Tsao", "Yu", ""], ["Wang", "Hsin-Min", ""], ["Maguer", "Sebastien Le", ""], ["Becker", "Markus", ""], ["Henderson", "Fergus", ""], ["Clark", "Rob", ""], ["Zhang", "Yu", ""], ["Wang", "Quan", ""], ["Jia", "Ye", ""], ["Onuma", "Kai", ""], ["Mushika", "Koji", ""], ["Kaneda", "Takashi", ""], ["Jiang", "Yuan", ""], ["Liu", "Li-Juan", ""], ["Wu", "Yi-Chiao", ""], ["Huang", "Wen-Chin", ""], ["Toda", "Tomoki", ""], ["Tanaka", "Kou", ""], ["Kameoka", "Hirokazu", ""], ["Steiner", "Ingmar", ""], ["Matrouf", "Driss", ""], ["Bonastre", "Jean-Francois", ""], ["Govender", "Avashna", ""], ["Ronanki", "Srikanth", ""], ["Zhang", "Jing-Xuan", ""], ["Ling", "Zhen-Hua", ""]]}, {"id": "1911.01633", "submitter": "Sina Shaham", "authors": "Sina Shaham, Saba Rafieian, Ming Ding, Mahyar Shirvanimoghaddam, and\n  Zihuai Lin", "title": "On the Importance of Location Privacy for Users of Location Based\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Do people care about their location privacy while using location-based\nservice apps? This paper aims to answer this question and several other\nhypotheses through a survey, and review the privacy preservation techniques.\nOur results indicate that privacy is indeed an influential factor in the\nselection of location-based apps by users.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 06:03:16 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Shaham", "Sina", ""], ["Rafieian", "Saba", ""], ["Ding", "Ming", ""], ["Shirvanimoghaddam", "Mahyar", ""], ["Lin", "Zihuai", ""]]}, {"id": "1911.01769", "submitter": "Yiming Li", "authors": "Yiming Li, Peidong Liu, Yong Jiang, Shu-Tao Xia", "title": "Visual Privacy Protection via Mapping Distortion", "comments": "Accepted by the ICASSP 2021. The first two authors contributed\n  equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy protection is an important research area, which is especially\ncritical in this big data era. To a large extent, the privacy of visual\nclassification data is mainly in the mapping between the image and its\ncorresponding label, since this relation provides a great amount of information\nand can be used in other scenarios. In this paper, we propose the mapping\ndistortion based protection (MDP) and its augmentation-based extension (AugMDP)\nto protect the data privacy by modifying the original dataset. In the modified\ndataset generated by MDP, the image and its label are not consistent ($e.g.$, a\ncat-like image is labeled as the dog), whereas the DNNs trained on it can still\nachieve good performance on benign testing set. As such, this method can\nprotect privacy when the dataset is leaked. Extensive experiments are\nconducted, which verify the effectiveness and feasibility of our method. The\ncode for reproducing main results is available at\n\\url{https://github.com/PerdonLiu/Visual-Privacy-Protection-via-Mapping-Distortion}.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 13:41:45 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 15:35:15 GMT"}, {"version": "v3", "created": "Sun, 31 Jan 2021 15:08:57 GMT"}, {"version": "v4", "created": "Wed, 3 Feb 2021 09:39:37 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Li", "Yiming", ""], ["Liu", "Peidong", ""], ["Jiang", "Yong", ""], ["Xia", "Shu-Tao", ""]]}, {"id": "1911.01778", "submitter": "Qin Huang", "authors": "Qin Huang, Li Quan, Shengli Zhang", "title": "Downsampling and Transparent Coding for Blockchain", "comments": "8pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of blockchain, the huge history data limits the\nscalability of the blockchain. This paper proposes to downsample these data to\nreduce the storage overhead of nodes. These nodes keep good independency, if\ndownsampling follows the entropy of blockchain. Moreover, it demonstrates that\nthe entire blockchain history can be efficiently recovered through the\ncooperative decoding of a group of nodes like fountain codes, if reserved data\nover these nodes obey the soliton distribution. However, these data on nodes\nare uncoded (transparent). Thus, the proposed algorithm not only keeps\ndecentralization and security, but also has good scalability in independency\nand recovery.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 14:01:59 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 03:40:52 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Huang", "Qin", ""], ["Quan", "Li", ""], ["Zhang", "Shengli", ""]]}, {"id": "1911.01812", "submitter": "Zaoxing Liu", "authors": "Zaoxing Liu, Tian Li, Virginia Smith, Vyas Sekar", "title": "Enhancing the Privacy of Federated Learning with Sketching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In response to growing concerns about user privacy, federated learning has\nemerged as a promising tool to train statistical models over networks of\ndevices while keeping data localized. Federated learning methods run training\ntasks directly on user devices and do not share the raw user data with third\nparties. However, current methods still share model updates, which may contain\nprivate information (e.g., one's weight and height), during the training\nprocess. Existing efforts that aim to improve the privacy of federated learning\nmake compromises in one or more of the following key areas: performance\n(particularly communication cost), accuracy, or privacy. To better optimize\nthese trade-offs, we propose that \\textit{sketching algorithms} have a unique\nadvantage in that they can provide both privacy and performance benefits while\nmaintaining accuracy. We evaluate the feasibility of sketching-based federated\nlearning with a prototype on three representative learning models. Our initial\nfindings show that it is possible to provide strong privacy guarantees for\nfederated learning without sacrificing performance or accuracy. Our work\nhighlights that there exists a fundamental connection between privacy and\ncommunication in distributed settings, and suggests important open problems\nsurrounding the theoretical understanding, methodology, and system design of\npractical, private federated learning.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 14:38:18 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Liu", "Zaoxing", ""], ["Li", "Tian", ""], ["Smith", "Virginia", ""], ["Sekar", "Vyas", ""]]}, {"id": "1911.01830", "submitter": "Christian Eder", "authors": "Christian Eder", "title": "Breaking the Hidden Irreducible Polynomials Scheme", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2019 G\\'omez described a new public key cryptography scheme based on ideas\nfrom multivariate public key cryptography using hidden irreducible polynomials.\nWe show that the scheme's design has a flaw which lets an attacker recover the\nprivate key directly from the public key.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 14:48:56 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Eder", "Christian", ""]]}, {"id": "1911.01840", "submitter": "Fu Song", "authors": "Guangke Chen, Sen Chen, Lingling Fan, Xiaoning Du, Zhe Zhao, Fu Song,\n  Yang Liu", "title": "Who is Real Bob? Adversarial Attacks on Speaker Recognition Systems", "comments": "IEEE Symposium on Security and Privacy 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CR cs.LG cs.MM cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker recognition (SR) is widely used in our daily life as a biometric\nauthentication or identification mechanism. The popularity of SR brings in\nserious security concerns, as demonstrated by recent adversarial attacks.\nHowever, the impacts of such threats in the practical black-box setting are\nstill open, since current attacks consider the white-box setting only. In this\npaper, we conduct the first comprehensive and systematic study of the\nadversarial attacks on SR systems (SRSs) to understand their security weakness\nin the practical blackbox setting. For this purpose, we propose an adversarial\nattack, named FAKEBOB, to craft adversarial samples. Specifically, we formulate\nthe adversarial sample generation as an optimization problem, incorporated with\nthe confidence of adversarial samples and maximal distortion to balance between\nthe strength and imperceptibility of adversarial voices. One key contribution\nis to propose a novel algorithm to estimate the score threshold, a feature in\nSRSs, and use it in the optimization problem to solve the optimization problem.\nWe demonstrate that FAKEBOB achieves 99% targeted attack success rate on both\nopen-source and commercial systems. We further demonstrate that FAKEBOB is also\neffective on both open-source and commercial systems when playing over the air\nin the physical world. Moreover, we have conducted a human study which reveals\nthat it is hard for human to differentiate the speakers of the original and\nadversarial voices. Last but not least, we show that four promising defense\nmethods for adversarial attack from the speech recognition domain become\nineffective on SRSs against FAKEBOB, which calls for more effective defense\nmethods. We highlight that our study peeks into the security implications of\nadversarial attacks on SRSs, and realistically fosters to improve the security\nrobustness of SRSs.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 16:50:13 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 02:10:01 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Chen", "Guangke", ""], ["Chen", "Sen", ""], ["Fan", "Lingling", ""], ["Du", "Xiaoning", ""], ["Zhao", "Zhe", ""], ["Song", "Fu", ""], ["Liu", "Yang", ""]]}, {"id": "1911.01888", "submitter": "Michael Lomnitz", "authors": "Michael Lomnitz, Nina Lopatina, Paul Gamble, Zigfried Hampel-Arias,\n  Lucas Tindall, Felipe A. Mejia, Maria Alejandra Barrios", "title": "Reducing audio membership inference attack accuracy to chance: 4\n  defenses", "comments": "7 pages, 2 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is critical to understand the privacy and robustness vulnerabilities of\nmachine learning models, as their implementation expands in scope. In\nmembership inference attacks, adversaries can determine whether a particular\nset of data was used in training, putting the privacy of the data at risk.\nExisting work has mostly focused on image related tasks; we generalize this\ntype of attack to speaker identification on audio samples. We demonstrate\nattack precision of 85.9\\% and recall of 90.8\\% for LibriSpeech, and 78.3\\%\nprecision and 90.7\\% recall for VOiCES (Voices Obscured in Complex\nEnvironmental Settings). We find that implementing defenses such as prediction\nobfuscation, defensive distillation or adversarial training, can reduce attack\naccuracy to chance.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 21:18:40 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Lomnitz", "Michael", ""], ["Lopatina", "Nina", ""], ["Gamble", "Paul", ""], ["Hampel-Arias", "Zigfried", ""], ["Tindall", "Lucas", ""], ["Mejia", "Felipe A.", ""], ["Barrios", "Maria Alejandra", ""]]}, {"id": "1911.01921", "submitter": "Philip Sperl", "authors": "Philip Sperl, Ching-Yu Kao, Peng Chen, Konstantin B\\\"ottinger", "title": "DLA: Dense-Layer-Analysis for Adversarial Example Detection", "comments": null, "journal-ref": null, "doi": "10.1109/EuroSP48549.2020.00021", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years Deep Neural Networks (DNNs) have achieved remarkable results\nand even showed super-human capabilities in a broad range of domains. This led\npeople to trust in DNNs' classifications and resulting actions even in\nsecurity-sensitive environments like autonomous driving.\n  Despite their impressive achievements, DNNs are known to be vulnerable to\nadversarial examples. Such inputs contain small perturbations to intentionally\nfool the attacked model.\n  In this paper, we present a novel end-to-end framework to detect such attacks\nduring classification without influencing the target model's performance.\nInspired by recent research in neuron-coverage guided testing we show that\ndense layers of DNNs carry security-sensitive information. With a secondary DNN\nwe analyze the activation patterns of the dense layers during classification\nruntime, which enables effective and real-time detection of adversarial\nexamples.\n  Our prototype implementation successfully detects adversarial examples in\nimage, natural language, and audio processing. Thereby, we cover a variety of\ntarget DNNs, including Long Short Term Memory (LSTM) architectures. In\naddition, to effectively defend against state-of-the-art attacks, our approach\ngeneralizes between different sets of adversarial examples. Thus, our method\nmost likely enables us to detect even future, yet unknown attacks. Finally,\nduring white-box adaptive attacks, we show our method cannot be easily\nbypassed.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:31:23 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Sperl", "Philip", ""], ["Kao", "Ching-Yu", ""], ["Chen", "Peng", ""], ["B\u00f6ttinger", "Konstantin", ""]]}, {"id": "1911.01922", "submitter": "Mazen Alwadi", "authors": "Mazen Alwadi, Aziz Mohaisen, Amro Awad", "title": "Phoenix: Towards Persistently Secure, Recoverable, and NVM Friendly Tree\n  of Counters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging Non-Volatile Memories (NVMs) bring a unique challenge to the\nsecurity community, namely persistent security. As NVM-based memories are\nexpected to restore their data after recovery, the security metadata must be\nrecovered as well. However, persisting all affected security metadata on each\nmemory write would significantly degrade performance and exacerbate the write\nendurance problem. Moreover, recovery time can increase significantly (up to\nhours for practical memory sizes) when security metadata are not updated\nstrictly. Counter trees are used in state-of-the-art commercial secure\nprocessors, e.g., Intel's Safe Guard Extension (SGX). Counter trees have a\nunique challenge due to the inability to recover the whole tree from leaves.\nThus, to ensure recoverability, all updates to the tree must be persisted,\nwhich can be tens of additional writes on each write. The state-of-art scheme,\nAnubis, enables recoverability but incurs an additional write per cache\neviction, i.e., reduces lifetime to approximately half. Additionally, Anubis\ndegrades performance significantly in many cases. In this paper, we propose\nPhoenix, a practical novel scheme which relies on elegantly reproducing the\ncache content before a crash, however with minimal overheads. Our evaluation\nresults show that Phoenix reduces persisting security metadata overhead writes\nfrom 87\\% extra writes (for Anubis) to less than write-back compared to an\nencrypted system without recovery, thus improving the NVM lifetime by 2x.\nOverall Phoenix performance is better than the baseline, unlike Anubis which\nadds 7.9\\% (max of 35\\%) performance overhead.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:32:30 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Alwadi", "Mazen", ""], ["Mohaisen", "Aziz", ""], ["Awad", "Amro", ""]]}, {"id": "1911.02013", "submitter": "Jun Zhao", "authors": "Wubing Chen, Zhiying Xu, Shuyu Shi, Yang Zhao, Jun Zhao", "title": "A Survey of Blockchain Applications in Different Domains", "comments": "Published in Proceedings of the 2018 International Conference on\n  Blockchain Technology and Application (ICBTA)", "journal-ref": null, "doi": "10.1145/3301403.3301407", "report-no": null, "categories": "cs.CR cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchains have received much attention recently since they provide\ndecentralized approaches to the creation and management of value. Many banks,\nInternet companies, car manufacturers, and even governments worldwide have\nincorporated or started considering blockchains to improve the security,\nscalability, and efficiency of their services. In this paper, we survey\nblockchain applications in different areas. These areas include cryptocurrency,\nhealthcare, advertising, insurance, copyright protection, energy, and societal\napplications. Our work provides a timely summary for individuals and\norganizations interested in blockchains. We envision our study to motivate more\nblockchain applications.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 03:27:27 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Chen", "Wubing", ""], ["Xu", "Zhiying", ""], ["Shi", "Shuyu", ""], ["Zhao", "Yang", ""], ["Zhao", "Jun", ""]]}, {"id": "1911.02038", "submitter": "Miguel A. Arroyo", "authors": "Mohamed Tarek Ibn Ziad, Miguel A. Arroyo, Evgeny Manzhosov, Vasileios\n  P. Kemerlis, Simha Sethumadhavan", "title": "Using Name Confusion to Enhance Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel concept, called Name Confusion, and demonstrate how it\ncan be employed to thwart multiple classes of code-reuse attacks. By building\nupon Name Confusion, we derive Phantom Name System (PNS): a security protocol\nthat provides multiple names (addresses) to program instructions. Unlike the\nconventional model of virtual memory with a one-to-one mapping between\ninstructions and virtual memory addresses, PNS creates N mappings for the same\ninstruction, and randomly switches between them at runtime. PNS achieves fast\nrandomization, at the granularity of basic blocks, which mitigates a class of\nattacks known as (just-in-time) code-reuse.\n  If an attacker uses a memory safety-related vulnerability to cause any of the\ninstruction addresses to be different from the one chosen during a fetch, the\nexploited program will crash. We quantitatively evaluate how PNS mitigates\nreal-world code-reuse attacks by reducing the success probability of typical\nexploits to approximately $10^{-12}$. We implement PNS and validate it by\nrunning SPEC CPU2017 benchmark suite. We further verify its practicality by\nadding it to a RISC-V core on an FPGA. Lastly, PNS is mainly designed for\nresource constrained (wimpy) devices and has negligible performance overhead,\ncompared to commercially-available, state-of-the-art, hardware-based\nprotections.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 19:02:53 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 05:39:44 GMT"}, {"version": "v3", "created": "Wed, 26 Aug 2020 18:12:53 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Ziad", "Mohamed Tarek Ibn", ""], ["Arroyo", "Miguel A.", ""], ["Manzhosov", "Evgeny", ""], ["Kemerlis", "Vasileios P.", ""], ["Sethumadhavan", "Simha", ""]]}, {"id": "1911.02046", "submitter": "Xiaoyu Cao", "authors": "Xiaoyu Cao, Jinyuan Jia and Neil Zhenqiang Gong", "title": "Data Poisoning Attacks to Local Differential Privacy Protocols", "comments": "To appear in the 30th Usenix Security Symposium (Usenix Security\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local Differential Privacy (LDP) protocols enable an untrusted data collector\nto perform privacy-preserving data analytics. In particular, each user locally\nperturbs its data to preserve privacy before sending it to the data collector,\nwho aggregates the perturbed data to obtain statistics of interest. In the past\nseveral years, researchers from multiple communities -- such as security,\ndatabase, and theoretical computer science -- have proposed many LDP protocols.\nThese studies mainly focused on improving the utility of the LDP protocols.\nHowever, the security of LDP protocols is largely unexplored. In this work, we\naim to bridge this gap. We focus on LDP protocols for frequency estimation and\nheavy hitter identification, which are two basic data analytics tasks.\nSpecifically, we show that an attacker can inject fake users into an LDP\nprotocol and the fake users send carefully crafted data to the data collector\nsuch that the LDP protocol estimates high frequencies for arbitrary\nattacker-chosen items or identifies them as heavy hitters. We call our attacks\ndata poisoning attacks. We theoretically and/or empirically show the\neffectiveness of our attacks. We also explore three countermeasures against our\nattacks. Our experimental results show that they can effectively defend against\nour attacks in some scenarios but have limited effectiveness in others,\nhighlighting the needs for new defenses against our attacks.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 19:20:32 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 14:44:18 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Cao", "Xiaoyu", ""], ["Jia", "Jinyuan", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "1911.02142", "submitter": "Fabio Pierazzi Dr", "authors": "Fabio Pierazzi, Feargus Pendlebury, Jacopo Cortellazzi, Lorenzo\n  Cavallaro", "title": "Intriguing Properties of Adversarial ML Attacks in the Problem Space", "comments": "This arXiv version (v2) corresponds to the one published at IEEE\n  Symposium on Security & Privacy (Oakland), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research efforts on adversarial ML have investigated problem-space\nattacks, focusing on the generation of real evasive objects in domains where,\nunlike images, there is no clear inverse mapping to the feature space (e.g.,\nsoftware). However, the design, comparison, and real-world implications of\nproblem-space attacks remain underexplored. This paper makes two major\ncontributions. First, we propose a novel formalization for adversarial ML\nevasion attacks in the problem-space, which includes the definition of a\ncomprehensive set of constraints on available transformations, preserved\nsemantics, robustness to preprocessing, and plausibility. We shed light on the\nrelationship between feature space and problem space, and we introduce the\nconcept of side-effect features as the byproduct of the inverse feature-mapping\nproblem. This enables us to define and prove necessary and sufficient\nconditions for the existence of problem-space attacks. We further demonstrate\nthe expressive power of our formalization by using it to describe several\nattacks from related literature across different domains. Second, building on\nour formalization, we propose a novel problem-space attack on Android malware\nthat overcomes past limitations. Experiments on a dataset with 170K Android\napps from 2017 and 2018 show the practical feasibility of evading a\nstate-of-the-art malware classifier along with its hardened version. Our\nresults demonstrate that \"adversarial-malware as a service\" is a realistic\nthreat, as we automatically generate thousands of realistic and inconspicuous\nadversarial applications at scale, where on average it takes only a few minutes\nto generate an adversarial app. Our formalization of problem-space attacks\npaves the way to more principled research in this domain.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 23:39:55 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 20:05:29 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Pierazzi", "Fabio", ""], ["Pendlebury", "Feargus", ""], ["Cortellazzi", "Jacopo", ""], ["Cavallaro", "Lorenzo", ""]]}, {"id": "1911.02174", "submitter": "Ahmed Elmisery", "authors": "Ahmed M. Elmisery, Mirela Sertovic", "title": "Privacy Preserving Threat Hunting in Smart Home Environments", "comments": "In Proc. the International Conference on Advances in Cyber Security,\n  Penang, Malaysia, July 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent proliferation of smart home environments offers new and\ntransformative circumstances for various domains with a commitment to enhancing\nthe quality of life and experience. Most of these environments combine\ndifferent gadgets offered by multiple stakeholders in a dynamic and\ndecentralized manner, which in turn presents new challenges from the\nperspective of digital investigation. In addition, a plentiful amount of data\nrecords got generated because of the day to day interactions between these\ngadgets and homeowners, which poses difficulty in managing and analyzing such\ndata. The analysts should endorse new digital investigation approaches to\ntackle the current limitations in traditional approaches when used in these\nenvironments. The digital evidence in such environments can be found inside the\nrecords of logfiles that store the historical events occurred inside the smart\nhome. Threat hunting can leverage the collective nature of these gadgets to\ngain deeper insights into the best way for responding to new threats, which in\nturn can be valuable in reducing the impact of breaches. Nevertheless, this\napproach depends mainly on the readiness of smart homeowners to share their own\npersonal usage logs that have been extracted from their smart home\nenvironments. However, they might disincline to employ such service due to the\nsensitive nature of the information logged by their personal gateways. In this\npaper, we presented an approach to enable smart homeowners to share their usage\nlogs in a privacy preserving manner. A distributed threat hunting approach has\nbeen developed to permit the composition of diverse threat classes without\nrevealing the logged records to other involved parties. Furthermore, a scenario\nwas proposed to depict a proactive threat Intelligence sharing for the\ndetection of potential threats in smart home environments with some\nexperimental results.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 02:58:32 GMT"}, {"version": "v2", "created": "Sun, 19 Jan 2020 12:16:35 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Elmisery", "Ahmed M.", ""], ["Sertovic", "Mirela", ""]]}, {"id": "1911.02254", "submitter": "Chaoyue Niu", "authors": "Chaoyue Niu, Fan Wu, Shaojie Tang, Lifeng Hua, Rongfei Jia, Chengfei\n  Lv, Zhihua Wu, and Guihai Chen", "title": "Secure Federated Submodel Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning was proposed with an intriguing vision of achieving\ncollaborative machine learning among numerous clients without uploading their\nprivate data to a cloud server. However, the conventional framework requires\neach client to leverage the full model for learning, which can be prohibitively\ninefficient for resource-constrained clients and large-scale deep learning\ntasks. We thus propose a new framework, called federated submodel learning,\nwhere clients download only the needed parts of the full model, namely\nsubmodels, and then upload the submodel updates. Nevertheless, the \"position\"\nof a client's truly required submodel corresponds to her private data, and its\ndisclosure to the cloud server during interactions inevitably breaks the tenet\nof federated learning. To integrate efficiency and privacy, we have designed a\nsecure federated submodel learning scheme coupled with a private set union\nprotocol as a cornerstone. Our secure scheme features the properties of\nrandomized response, secure aggregation, and Bloom filter, and endows each\nclient with a customized plausible deniability, in terms of local differential\nprivacy, against the position of her desired submodel, thus protecting her\nprivate data. We further instantiated our scheme with the e-commerce\nrecommendation scenario in Alibaba, implemented a prototype system, and\nextensively evaluated its performance over 30-day Taobao user data. The\nanalysis and evaluation results demonstrate the feasibility and scalability of\nour scheme from model accuracy and convergency, practical communication,\ncomputation, and storage overheads, as well as manifest its remarkable\nadvantages over the conventional federated learning framework.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 08:49:23 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 14:07:41 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Niu", "Chaoyue", ""], ["Wu", "Fan", ""], ["Tang", "Shaojie", ""], ["Hua", "Lifeng", ""], ["Jia", "Rongfei", ""], ["Lv", "Chengfei", ""], ["Wu", "Zhihua", ""], ["Chen", "Guihai", ""]]}, {"id": "1911.02392", "submitter": "Zhifeng Jia", "authors": "Zhifeng Jia, Rui Chen and Jie Li", "title": "DeLottery: A Novel Decentralized Lottery System Based on Blockchain\n  Technology", "comments": "This paper contains 6 pages with 2 figures", "journal-ref": null, "doi": null, "report-no": "Report-no: C2007", "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we design DeLottery, a decentralized lottery system based on\nblock chain technology and smart contracts. Lottery is a classical form of\nentertainment and charity for centuries. Facing the bottleneck of the\ncombination between lottery and information technology, we use smart contracts\nand blockchain in decentralized, intelligent, and secure systems for lottery\nindustries. Moreover, we are inspired by the algorithm of RANDAO, an\noutstanding way of random number generation in blockchain scenario. The\ncomponents and the functions of the novel system are described in details. We\nimplement DeLottery in a blockchain network and show functioning procedure and\nsecurity of the proposed lottery system.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 13:57:03 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Jia", "Zhifeng", ""], ["Chen", "Rui", ""], ["Li", "Jie", ""]]}, {"id": "1911.02423", "submitter": "Dorjan Hitaj", "authors": "Fabio De Gaspari, Dorjan Hitaj, Giulio Pagnotta, Lorenzo De Carli,\n  Luigi V. Mancini", "title": "The Naked Sun: Malicious Cooperation Between Benign-Looking Processes", "comments": "15 pages, 6 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in machine learning has generated promising results in\nbehavioral malware detection. Behavioral modeling identifies malicious\nprocesses via features derived by their runtime behavior. Behavioral features\nhold great promise as they are intrinsically related to the functioning of each\nmalware, and are therefore considered difficult to evade. Indeed, while a\nsignificant amount of results exists on evasion of static malware features,\nevasion of dynamic features has seen limited work. This paper thoroughly\nexamines the robustness of behavioral malware detectors to evasion, focusing\nparticularly on anti-ransomware evasion. We choose ransomware as its behavior\ntends to differ significantly from that of benign processes, making it a\nlow-hanging fruit for behavioral detection (and a difficult candidate for\nevasion). Our analysis identifies a set of novel attacks that distribute the\noverall malware workload across a small set of cooperating processes to avoid\nthe generation of significant behavioral features. Our most effective attack\ndecreases the accuracy of a state-of-the-art classifier from 98.6% to 0% using\nonly 18 cooperating processes. Furthermore, we show our attacks to be effective\nagainst commercial ransomware detectors even in a black-box setting.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 15:04:07 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["De Gaspari", "Fabio", ""], ["Hitaj", "Dorjan", ""], ["Pagnotta", "Giulio", ""], ["De Carli", "Lorenzo", ""], ["Mancini", "Luigi V.", ""]]}, {"id": "1911.02459", "submitter": "Bogdan Kulynych", "authors": "Wouter Lueks, Bogdan Kulynych, Jules Fasquelle, Simon Le Bail-Collet,\n  Carmela Troncoso", "title": "zksk: A Library for Composable Zero-Knowledge Proofs", "comments": "Appears in 2019 Workshop on Privacy in the Electronic Society\n  (WPES'19)", "journal-ref": null, "doi": "10.1145/3338498.3358653", "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-knowledge proofs are an essential building block in many\nprivacy-preserving systems. However, implementing these proofs is tedious and\nerror-prone. In this paper, we present zksk, a well-documented Python library\nfor defining and computing sigma protocols: the most popular class of\nzero-knowledge proofs. In zksk, proofs compose: programmers can convert smaller\nproofs into building blocks that then can be combined into bigger proofs. zksk\nfeatures a modern Python-based domain-specific language. This makes possible to\ndefine proofs without learning a new custom language, and to benefit from the\nrich Python syntax and ecosystem. The library is available at\nhttps://github.com/spring-epfl/zksk\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 16:25:45 GMT"}, {"version": "v2", "created": "Sun, 10 Nov 2019 20:53:29 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Lueks", "Wouter", ""], ["Kulynych", "Bogdan", ""], ["Fasquelle", "Jules", ""], ["Bail-Collet", "Simon Le", ""], ["Troncoso", "Carmela", ""]]}, {"id": "1911.02621", "submitter": "Olakunle Ibitoye", "authors": "Olakunle Ibitoye, Rana Abou-Khamis, Ashraf Matrawy and M. Omair Shafiq", "title": "The Threat of Adversarial Attacks on Machine Learning in Network\n  Security -- A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Machine learning models have made many decision support systems to be faster,\nmore accurate and more efficient. However, applications of machine learning in\nnetwork security face more disproportionate threat of active adversarial\nattacks compared to other domains. This is because machine learning\napplications in network security such as malware detection, intrusion\ndetection, and spam filtering are by themselves adversarial in nature. In what\ncould be considered an arms race between attackers and defenders, adversaries\nconstantly probe machine learning systems with inputs which are explicitly\ndesigned to bypass the system and induce a wrong prediction. In this survey, we\nfirst provide a taxonomy of machine learning techniques, styles, and\nalgorithms. We then introduce a classification of machine learning in network\nsecurity applications. Next, we examine various adversarial attacks against\nmachine learning in network security and introduce two classification\napproaches for adversarial attacks in network security. First, we classify\nadversarial attacks in network security based on a taxonomy of network security\napplications. Secondly, we categorize adversarial attacks in network security\ninto a problem space vs. feature space dimensional classification model. We\nthen analyze the various defenses against adversarial attacks on machine\nlearning-based network security applications. We conclude by introducing an\nadversarial risk model and evaluate several existing adversarial attacks\nagainst machine learning in network security using the risk model. We also\nidentify where each attack classification resides within the adversarial risk\nmodel\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 20:29:56 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 10:29:05 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Ibitoye", "Olakunle", ""], ["Abou-Khamis", "Rana", ""], ["Matrawy", "Ashraf", ""], ["Shafiq", "M. Omair", ""]]}, {"id": "1911.02674", "submitter": "Abraham Westerbaan", "authors": "Abraham Westerbaan and Luuk Hendriks", "title": "Polymorphic Encryption and Pseudonymisation of IP Network Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a system, PEP3, for storage and retrieval of IP flow information\nin which the IP addresses are replaced by pseudonyms. Every eligible party gets\nits own set of pseudonyms. A single entity, the transcryptor, that is composed\nof five independent peers, is responsible for the generation of,\ndepseudonymisation of, and translation between different sets of pseudonyms.\nThese operations can be performed by any three of the five peers, preventing a\nsingle point of trust or failure. Using homomorphic aspects of ElGamal\nencryption the peers perform their operations on encrypted and --potentially--\npseudonymised IP addresses only, thereby never learning the (pseudonymised) IP\naddresses handled by the parties. Moreover, using Schnorr type proofs, the\nbehaviour of the peers can be verified, without revealing the (pseudonymised)\nIP addresses either. Hence the peers are central, but need not be fully\ntrusted. The design of our system, while easily modified to other settings, is\ntuned to the sheer volume of data presented by IP flow information.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 23:19:17 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 10:21:23 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Westerbaan", "Abraham", ""], ["Hendriks", "Luuk", ""]]}, {"id": "1911.02822", "submitter": "Seiichiro Tani", "authors": "Akinori Hosoyamada, Yu Sasaki, Seiichiro Tani, Keita Xagawa", "title": "Quantum Algorithm for the Multicollision Problem", "comments": "23 pages, 2 figures and 2 tables; a significantly revised version of\n  two conference papers (Asiacrypt 2017 [Cryptology ePrint Archive Report\n  2017/864] and PQCrypto 2019 [arXiv:1811.08097]) with additional time and\n  space complexity analyses and discussions", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current paper presents a new quantum algorithm for finding\nmulticollisions, often denoted by $\\ell$-collisions, where an $\\ell$-collision\nfor a function is a set of $\\ell$ distinct inputs that are mapped by the\nfunction to the same value. The tight bound of quantum query complexity for\nfinding a $2$-collisions of a random function has been revealed to be\n$\\Theta(N^{1/3})$, where $N$ is the size of the range of the function, but\nneither the lower nor upper bounds are known for general $\\ell$-collisions. The\npaper first integrates the results from existing research to derive several new\nobservations, e.g.,~$\\ell$-collisions can be generated only with $O(N^{1/2})$\nquantum queries for any integer constant $\\ell$. It then provides a quantum\nalgorithm that finds an $\\ell$-collision for a random function with the average\nquantum query complexity of $O(N^{(2^{\\ell-1}-1) / (2^{\\ell}-1)})$, which\nmatches the tight bound of $\\Theta(N^{1/3})$ for $\\ell=2$ and improves upon the\nknown bounds, including the above simple bound of $O(N^{1/2})$. More generally,\nthe algorithm achieves the average quantum query complexity of $O\\big(c_N \\cdot\nN^{({2^{\\ell-1}-1})/({ 2^{\\ell}-1})}\\big)$ and runs over $\\tilde{O}\\big(c_N\n\\cdot N^{({2^{\\ell-1}-1})/({ 2^{\\ell}-1})}\\big)$ qubits in $\\tilde{O}\\big(c_N\n\\cdot N^{({2^{\\ell-1}-1})/({ 2^{\\ell}-1})}\\big)$ expected time for a random\nfunction $F\\colon X\\to Y$ such that $|X| \\geq \\ell \\cdot |Y| / c_N$ for any\n$1\\le c_N \\in o(N^{{1}/({2^\\ell - 1})})$. With the same complexities, it is\nactually able to find a multiclaw for random functions, which is harder to find\nthan a multicollision.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 09:56:00 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Hosoyamada", "Akinori", ""], ["Sasaki", "Yu", ""], ["Tani", "Seiichiro", ""], ["Xagawa", "Keita", ""]]}, {"id": "1911.03078", "submitter": "Xu Li", "authors": "Xu Li, Jinghua Zhong, Xixin Wu, Jianwei Yu, Xunying Liu and Helen Meng", "title": "Adversarial Attacks on GMM i-vector based Speaker Verification Systems", "comments": "Accepted by ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.CR cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates the vulnerability of Gaussian Mixture Model (GMM)\ni-vector based speaker verification systems to adversarial attacks, and the\ntransferability of adversarial samples crafted from GMM i-vector based systems\nto x-vector based systems. In detail, we formulate the GMM i-vector system as a\nscoring function of enrollment and testing utterance pairs. Then we leverage\nthe fast gradient sign method (FGSM) to optimize testing utterances for\nadversarial samples generation. These adversarial samples are used to attack\nboth GMM i-vector and x-vector systems. We measure the system vulnerability by\nthe degradation of equal error rate and false acceptance rate. Experiment\nresults show that GMM i-vector systems are seriously vulnerable to adversarial\nattacks, and the crafted adversarial samples prove to be transferable and pose\nthreats to neuralnetwork speaker embedding based systems (e.g. x-vector\nsystems).\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 06:38:14 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 13:54:35 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Li", "Xu", ""], ["Zhong", "Jinghua", ""], ["Wu", "Xixin", ""], ["Yu", "Jianwei", ""], ["Liu", "Xunying", ""], ["Meng", "Helen", ""]]}, {"id": "1911.03129", "submitter": "Zhengyu Wu", "authors": "Zhengyu Wu, Ruhui Ma", "title": "A Novel Sybil Attack Detection Scheme Based on Edge Computing for Mobile\n  IoT Environment", "comments": "14 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of things (IoT) connects all items to the Internet through\ninformation-sensing devices to exchange information for intelligent\nidentification and management. Sybil attack is a famous and crippling attack in\nIoT. Most of the previous methods of detecting Sybil attacks in IoT mainly\nfocus on static IoT while there are very rare methods applicable to mobile IoT.\nIn this paper, a novel, lightweight, and distributive detection scheme based on\nedge computing is proposed for detecting Sybil attacks in mobile IoT. In the\nproposed scheme, a detection consists of two rounds. In each round, member\nnodes are required to send packets to edge nodes. Edge nodes calculate a\npossible interval of the received signal strength indication (RSSI) from the\nfirst round and check whether the RSSI from the second round is in the interval\nto detect Sybil attack. Extensive experimental studies are included to show\nthat the presented approach outperforms many existing approaches in terms of\ntrue detection and false detection rates. Moreover, experimental results show\nthat the fault tolerance design in the proposed approach greatly enhances the\ndetection scheme.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 08:47:29 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Wu", "Zhengyu", ""], ["Ma", "Ruhui", ""]]}, {"id": "1911.03183", "submitter": "Erik-Jan van Kesteren", "authors": "Erik-Jan van Kesteren, Chang Sun, Daniel L. Oberski, Michel Dumontier,\n  Lianne Ippel", "title": "Privacy-Preserving Generalized Linear Models using Distributed Block\n  Coordinate Descent", "comments": "Fully reproducible code for all results and images can be found at\n  https://github.com/vankesteren/privacy-preserving-glm, and the software\n  package can be found at https://github.com/vankesteren/privreg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Combining data from varied sources has considerable potential for knowledge\ndiscovery: collaborating data parties can mine data in an expanded feature\nspace, allowing them to explore a larger range of scientific questions.\nHowever, data sharing among different parties is highly restricted by legal\nconditions, ethical concerns, and / or data volume. Fueled by these concerns,\nthe fields of cryptography and distributed learning have made great progress\ntowards privacy-preserving and distributed data mining. However, practical\nimplementations have been hampered by the limited scope or computational\ncomplexity of these methods. In this paper, we greatly extend the range of\nanalyses available for vertically partitioned data, i.e., data collected by\nseparate parties with different features on the same subjects. To this end, we\npresent a novel approach for privacy-preserving generalized linear models, a\nfundamental and powerful framework underlying many prediction and\nclassification procedures. We base our method on a distributed block coordinate\ndescent algorithm to obtain parameter estimates, and we develop an extension to\ncompute accurate standard errors without additional communication cost. We\ncritically evaluate the information transfer for semi-honest collaborators and\nshow that our protocol is secure against data reconstruction. Through both\nsimulated and real-world examples we illustrate the functionality of our\nproposed algorithm. Without leaking information, our method performs as well on\nvertically partitioned data as existing methods on combined data -- all within\nmere minutes of computation time. We conclude that our method is a viable\napproach for vertically partitioned data analysis with a wide range of\nreal-world applications.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 11:07:07 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["van Kesteren", "Erik-Jan", ""], ["Sun", "Chang", ""], ["Oberski", "Daniel L.", ""], ["Dumontier", "Michel", ""], ["Ippel", "Lianne", ""]]}, {"id": "1911.03212", "submitter": "Michael Gruber", "authors": "Michael Gruber, Matthias Probst, Michael Tempelmeier", "title": "Statistical Ineffective Fault Analysis of GIMLI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ineffective Fault Analysis (SIFA) was introduced as a new approach to attack\nblock ciphers at CHES 2018. Since then, they have been proven to be a powerful\nclass of attacks, with an easy to achieve fault model. One of the main benefits\nof SIFA is to overcome detection-based and infection-based countermeasures. In\nthis paper we explain how the principles of SIFA can be applied to GIMLI, an\nauthenticated encryption cipher participating the NIST-LWC competition. We\nidentified two possible rounds during the intialization phase of GIMLI to mount\nour attack. If we attack the first location we are able to recover 3 bits of\nthe key uniquely and the parity of 8 key-bits organized in 3 sums using 180\nineffective faults per biased single intermediate bit. If we attack the second\nlocation we are able to recover 15 bits of the key uniquely and the parity of\n22 key-bits organized in 7 sums using 340 ineffective faults per biased\nintermediate bit. Furthermore, we investigated the influence of the fault model\non the rate of ineffective faults in GIMLI. Finally, we verify the efficiency\nof our attacks by means of simulation.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 12:17:31 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2019 02:35:41 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Gruber", "Michael", ""], ["Probst", "Matthias", ""], ["Tempelmeier", "Michael", ""]]}, {"id": "1911.03226", "submitter": "Panagiotis Papadopoulos", "authors": "Emmanouil Karampinakis, Michalis Pachilakis, Panagiotis Papadopoulos,\n  Antonis Krithinakis, Evangelos P. Markatos", "title": "The coin that never sleeps. The privacy preserving usage of Bitcoin in a\n  longitudinal analysis as a speculative asset", "comments": "7 pages, 5 figures, 24 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin is the first and undoubtedly most successful cryptocurrecny to date\nwith a market capitalization of more than 100 billion dollars. Today, Bitcoin\nhas more than 100,000 supporting merchants and more than 3 million active\nusers. Besides the trust it enjoys among people, Bitcoin lacks of a basic\nfeature a substitute currency must have: stability of value. Hence, although\nthe use of Bitcoin as a mean of payment is relative low, yet the wild ups and\ndowns of its value lure investors to use it as useful asset to yield a trading\nprofit. In this study, we explore this exact nature of Bitcoin aiming to shed\nlight in the newly emerged and rapid growing marketplace of cryptocurencies and\ncompare the investmet landscape and patterns with the most popular traditional\nstock market of Dow Jones. Our results show that most of Bitcoin addresses are\nused in the correct fashion to preserve security and privacy of the\ntransactions and that the 24/7 open market of Bitcoin is not affected by any\npolitical incidents of the offline world, in contrary with the traditional\nstock markets. Also, it seems that there are specific longitudes that lead the\ncryptocurrency in terms of bulk of transactions, but there is not the same\ncorrelation with the volume of the coins being transferred.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 13:18:47 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 13:10:20 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Karampinakis", "Emmanouil", ""], ["Pachilakis", "Michalis", ""], ["Papadopoulos", "Panagiotis", ""], ["Krithinakis", "Antonis", ""], ["Markatos", "Evangelos P.", ""]]}, {"id": "1911.03242", "submitter": "Zhuo Ma", "authors": "Yang Liu, Zhuo Ma, Ximeng Liu, Zhuzhu Wang, Siqi Ma, Ken Ren", "title": "Revocable Federated Learning: A Benchmark of Federated Forest", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A learning federation is composed of multiple participants who use the\nfederated learning technique to collaboratively train a machine learning model\nwithout directly revealing the local data. Nevertheless, the existing federated\nlearning frameworks have a serious defect that even a participant is revoked,\nits data are still remembered by the trained model. In a company-level\ncooperation, allowing the remaining companies to use a trained model that\ncontains the memories from a revoked company is obviously unacceptable, because\nit can lead to a big conflict of interest. Therefore, we emphatically discuss\nthe participant revocation problem of federated learning and design a revocable\nfederated random forest (RF) framework, RevFRF, to further illustrate the\nconcept of revocable federated learning. In RevFRF, we first define the\nsecurity problems to be resolved by a revocable federated RF. Then, a suite of\nhomomorphic encryption based secure protocols are designed for federated RF\nconstruction, prediction and revocation. Through theoretical analysis and\nexperiments, we show that the protocols can securely and efficiently implement\ncollaborative training of an RF and ensure that the memories of a revoked\nparticipant in the trained RF are securely removed.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 13:20:16 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Liu", "Yang", ""], ["Ma", "Zhuo", ""], ["Liu", "Ximeng", ""], ["Wang", "Zhuzhu", ""], ["Ma", "Siqi", ""], ["Ren", "Ken", ""]]}, {"id": "1911.03272", "submitter": "David Purser", "authors": "Marco Gaboardi, Kobbi Nissim and David Purser", "title": "The Complexity of Verifying Loop-Free Programs as Differentially Private", "comments": null, "journal-ref": "47th International Colloquium on Automata, Languages, and\n  Programming (ICALP 2020). Volume 168 of LIPIcs, pages 129:1-129:17. Schloss\n  Dagstuhl - Leibniz-Zentrum fur Informatik, 2020", "doi": "10.4230/LIPIcs.ICALP.2020.129", "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of verifying differential privacy for loop-free programs\nwith probabilistic choice. Programs in this class can be seen as randomized\nBoolean circuits, which we will use as a formal model to answer two different\nquestions: first, deciding whether a program satisfies a prescribed level of\nprivacy; second, approximating the privacy parameters a program realizes. We\nshow that the problem of deciding whether a program satisfies\n$\\varepsilon$-differential privacy is $coNP^{\\#P}$-complete. In fact, this is\nthe case when either the input domain or the output range of the program is\nlarge. Further, we show that deciding whether a program is\n$(\\varepsilon,\\delta)$-differentially private is $coNP^{\\#P}$-hard, and in\n$coNP^{\\#P}$ for small output domains, but always in $coNP^{\\#P^{\\#P}}$.\nFinally, we show that the problem of approximating the level of differential\nprivacy is both $NP$-hard and $coNP$-hard. These results complement previous\nresults by Murtagh and Vadhan showing that deciding the optimal composition of\ndifferentially private components is $\\#P$-complete, and that approximating the\noptimal composition of differentially private components is in $P$.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 14:07:30 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 11:14:18 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 10:20:51 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Gaboardi", "Marco", ""], ["Nissim", "Kobbi", ""], ["Purser", "David", ""]]}, {"id": "1911.03274", "submitter": "Xavier Renard", "authors": "Vincent Ballet, Xavier Renard, Jonathan Aigrain, Thibault Laugel,\n  Pascal Frossard, Marcin Detyniecki", "title": "Imperceptible Adversarial Attacks on Tabular Data", "comments": "presented at NeurIPS 2019 Workshop on Robust AI in Financial\n  Services: Data, Fairness, Explainability, Trustworthiness, and Privacy\n  (Robust AI in FS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security of machine learning models is a concern as they may face adversarial\nattacks for unwarranted advantageous decisions. While research on the topic has\nmainly been focusing on the image domain, numerous industrial applications, in\nparticular in finance, rely on standard tabular data. In this paper, we discuss\nthe notion of adversarial examples in the tabular domain. We propose a\nformalization based on the imperceptibility of attacks in the tabular domain\nleading to an approach to generate imperceptible adversarial examples.\nExperiments show that we can generate imperceptible adversarial examples with a\nhigh fooling rate.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 14:14:11 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 11:15:29 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Ballet", "Vincent", ""], ["Renard", "Xavier", ""], ["Aigrain", "Jonathan", ""], ["Laugel", "Thibault", ""], ["Frossard", "Pascal", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "1911.03298", "submitter": "Muhammad Baqer Mollah Mr.", "authors": "Muhammad Baqer Mollah, Jun Zhao, Dusit Niyato, Kwok-Yan Lam, Xin\n  Zhang, Amer M.Y.M. Ghias, Leong Hai Koh, Lei Yang", "title": "Blockchain for Future Smart Grid: A Comprehensive Survey", "comments": "26 pages, 13 figures, 5 tables", "journal-ref": "IEEE Internet of Things Journal, 2020", "doi": "10.1109/JIOT.2020.2993601", "report-no": null, "categories": "cs.CR cs.DC cs.NI cs.SI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of smart grid has been introduced as a new vision of the\nconventional power grid to figure out an efficient way of integrating green and\nrenewable energy technologies. In this way, Internet-connected smart grid, also\ncalled energy Internet, is also emerging as an innovative approach to ensure\nthe energy from anywhere at any time. The ultimate goal of these developments\nis to build a sustainable society. However, integrating and coordinating a\nlarge number of growing connections can be a challenging issue for the\ntraditional centralized grid system. Consequently, the smart grid is undergoing\na transformation to the decentralized topology from its centralized form. On\nthe other hand, blockchain has some excellent features which make it a\npromising application for smart grid paradigm. In this paper, we aim to provide\na comprehensive survey on application of blockchain in smart grid. As such, we\nidentify the significant security challenges of smart grid scenarios that can\nbe addressed by blockchain. Then, we present a number of blockchain-based\nrecent research works presented in different literatures addressing security\nissues in the area of smart grid. We also summarize several related practical\nprojects, trials, and products that have been emerged recently. Finally, we\ndiscuss essential research challenges and future directions of applying\nblockchain to smart grid security issues.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 14:51:39 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 07:42:41 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Mollah", "Muhammad Baqer", ""], ["Zhao", "Jun", ""], ["Niyato", "Dusit", ""], ["Lam", "Kwok-Yan", ""], ["Zhang", "Xin", ""], ["Ghias", "Amer M. Y. M.", ""], ["Koh", "Leong Hai", ""], ["Yang", "Lei", ""]]}, {"id": "1911.03306", "submitter": "Bahram Mohammadi", "authors": "Mohammed Gharib, Bahram Mohammadi, Shadi Hejareh Dastgerdi, Mohammad\n  Sabokrou", "title": "AutoIDS: Auto-encoder Based Method for Intrusion Detection System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intrusion Detection System (IDS) is one of the most effective solutions for\nproviding primary security services. IDSs are generally working based on attack\nsignatures or by detecting anomalies. In this paper, we have presented AutoIDS,\na novel yet efficient solution for IDS, based on a semi-supervised machine\nlearning technique. AutoIDS can distinguish abnormal packet flows from normal\nones by taking advantage of cascading two efficient detectors. These detectors\nare two encoder-decoder neural networks that are forced to provide a compressed\nand a sparse representation from the normal flows. In the test phase, failing\nthese neural networks on providing compressed or sparse representation from an\nincoming packet flow, means such flow does not comply with the normal traffic\nand thus it is considered as an intrusion. For lowering the computational cost\nalong with preserving the accuracy, a large number of flows are just processed\nby the first detector. In fact, the second detector is only used for difficult\nsamples which the first detector is not confident about them. We have evaluated\nAutoIDS on the NSL-KDD benchmark as a widely-used and well-known dataset. The\naccuracy of AutoIDS is 90.17\\% showing its superiority compared to the other\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 15:03:31 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Gharib", "Mohammed", ""], ["Mohammadi", "Bahram", ""], ["Dastgerdi", "Shadi Hejareh", ""], ["Sabokrou", "Mohammad", ""]]}, {"id": "1911.03356", "submitter": "Mohammad Hossein Manshaei", "authors": "Mehdi Fooladgar, Mohammad Hossein Manshaei, Murtuza Jadliwala,\n  Mohammad Ashiqur Rahman", "title": "On Incentive Compatible Role-based Reward Distribution in Algorand", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Algorand is a recent, open-source public or permissionless blockchain system\nthat employs a novel proof-of-stake byzantine consensus protocol to efficiently\nscale the distributed transaction agreement problem to billions of users. In\naddition to being more democratic and energy-efficient, compared to popular\nprotocols such as Bitcoin, Algorand also touts a much high transaction\nthroughput. This paper is the first attempt in the literature to study and\naddress this problem. By carefully modeling the participation costs and rewards\nreceived within a strategic interaction scenario, we first empirically show\nthat even a small number of nodes defecting to participate in the protocol\ntasks due to insufficiency of the available incentives can result in the\nAlgorand network failing to compute and add new blocks of transactions. We\nfurther show that this effect can be formalized by means of a mathematical\nmodel of interaction in Algorand given its participation costs and the current\n(or planned) reward distribution/sharing approach envisioned by the Algorand\nFoundation. Specifically, on analyzing this game model we observed that mutual\ncooperation under the currently proposed reward sharing approach is not a Nash\nequilibrium. This is a significant result which could threaten the success of\nan otherwise robust distributed consensus mechanism. We propose a novel reward\nsharing approach for Algorand and formally show that it is\nincentive-compatible, i.e., it can guarantee cooperation within a group of\nselfish Algorand users. Extensive numerical and Algorand simulation results\nfurther confirm our analytical findings. Moreover, these results show that for\na given distribution of stakes in the network, our reward sharing approach can\nguarantee cooperation with a significantly smaller reward per round.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 16:27:05 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Fooladgar", "Mehdi", ""], ["Manshaei", "Mohammad Hossein", ""], ["Jadliwala", "Murtuza", ""], ["Rahman", "Mohammad Ashiqur", ""]]}, {"id": "1911.03395", "submitter": "Bashir Mohammad Sabquat Bahar Talukder", "authors": "B. M. S. Bahar Talukder, Vineetha Menon, Biswajit Ray, Tempestt Neal,\n  and Md Tauhidur Rahman", "title": "Towards the Avoidance of Counterfeit Memory: Identifying the DRAM Origin", "comments": null, "journal-ref": "IEEE Hardware-Oriented Security and Trust Symposium (HOST), 2020", "doi": "10.1109/HOST45689.2020.9300125", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the globalization in the semiconductor supply chain, counterfeit\ndynamic random-access memory (DRAM) chips/modules have been spreading worldwide\nat an alarming rate. Deploying counterfeit DRAM modules into an electronic\nsystem can have severe consequences on security and reliability domains because\nof their sub-standard quality, poor performance, and shorter life span.\nBesides, studies suggest that a counterfeit DRAM can be more vulnerable to\nsophisticated attacks. However, detecting counterfeit DRAMs is very challenging\nbecause of their nature and ability to pass the initial testing. In this paper,\nwe propose a technique to identify the DRAM origin (i.e., the origin of the\nmanufacturer and the specification of individual DRAM) to detect and prevent\ncounterfeit DRAM modules. A silicon evaluation shows that the proposed method\nreliably identifies off-the-shelf DRAM modules from three major manufacturers.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 17:26:50 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Talukder", "B. M. S. Bahar", ""], ["Menon", "Vineetha", ""], ["Ray", "Biswajit", ""], ["Neal", "Tempestt", ""], ["Rahman", "Md Tauhidur", ""]]}, {"id": "1911.03563", "submitter": "Khaza Anuarul Hoque", "authors": "Samaikya Valluripally, Aniket Gulhane, Reshmi Mitra, Khaza Anuarul\n  Hoque, Prasad Calyam", "title": "Attack Trees for Security and Privacy in Social Virtual Reality Learning\n  Environments", "comments": "Accepted for publication in in the IEEE Consumer Communications &\n  Networking Conference (CCNC 2020)", "journal-ref": null, "doi": "10.1109/CCNC46108.2020.9045724", "report-no": null, "categories": "cs.CR cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social Virtual Reality Learning Environment (VRLE) is a novel edge computing\nplatform for collaboration amongst distributed users. Given that VRLEs are used\nfor critical applications (e.g., special education, public safety training), it\nis important to ensure security and privacy issues. In this paper, we present a\nnovel framework to obtain quantitative assessments of threats and\nvulnerabilities for VRLEs. Based on the use cases from an actual social VRLE\nviz., vSocial, we first model the security and privacy using the attack trees.\nSubsequently, these attack trees are converted into stochastic timed automata\nrepresentations that allow for rigorous statistical model checking. Such an\nanalysis helps us adopt pertinent design principles such as hardening,\ndiversity and principle of least privilege to enhance the resilience of social\nVRLEs. Through experiments in a vSocial case study, we demonstrate the\neffectiveness of our attack tree modeling with a reduction of 26% in\nprobability of loss of integrity (security) and 80% in privacy leakage\n(privacy) in before and after scenarios pertaining to the adoption of the\ndesign principles.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 22:25:21 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Valluripally", "Samaikya", ""], ["Gulhane", "Aniket", ""], ["Mitra", "Reshmi", ""], ["Hoque", "Khaza Anuarul", ""], ["Calyam", "Prasad", ""]]}, {"id": "1911.03623", "submitter": "Kommy Weldemariam Dr", "authors": "Reginald Bryant, Celia Cintas, Isaac Wambugu, Andrew Kinai, Komminist\n  Weldemariam", "title": "Analyzing Bias in Sensitive Personal Information Used to Train Financial\n  Models", "comments": "5 pages, 4 figures, IEEE Global Conference on Signal and Information\n  Processing (GlobalSIP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Bias in data can have unintended consequences that propagate to the design,\ndevelopment, and deployment of machine learning models. In the financial\nservices sector, this can result in discrimination from certain financial\ninstruments and services. At the same time, data privacy is of paramount\nimportance, and recent data breaches have seen reputational damage for large\ninstitutions. Presented in this paper is a trusted model-lifecycle management\nplatform that attempts to ensure consumer data protection, anonymization, and\nfairness. Specifically, we examine how datasets can be reproduced using deep\nlearning techniques to effectively retain important statistical features in\ndatasets whilst simultaneously protecting data privacy and enabling safe and\nsecure sharing of sensitive personal information beyond the current\nstate-of-practice.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 06:43:21 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Bryant", "Reginald", ""], ["Cintas", "Celia", ""], ["Wambugu", "Isaac", ""], ["Kinai", "Andrew", ""], ["Weldemariam", "Komminist", ""]]}, {"id": "1911.03653", "submitter": "Alberto Redondo", "authors": "Alberto Redondo and David Rios Insua", "title": "Protecting from Malware Obfuscation Attacks through Adversarial Risk\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware constitutes a major global risk affecting millions of users each\nyear. Standard algorithms in detection systems perform insufficiently when\ndealing with malware passed through obfuscation tools. We illustrate this\nstudying in detail an open source metamorphic software, making use of a hybrid\nframework to obtain the relevant features from binaries. We then provide an\nimproved alternative solution based on adversarial risk analysis which we\nillustrate describe with an example.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 10:02:41 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Redondo", "Alberto", ""], ["Insua", "David Rios", ""]]}, {"id": "1911.03674", "submitter": "Kommy Weldemariam Dr", "authors": "Samuel C. Maina, Reginald E. Bryant, William O. Goal, Robert-Florian\n  Samoilescu, Kush R. Varshney, Komminist Weldemariam", "title": "Preservation of Anomalous Subgroups On Machine Learning Transformed Data", "comments": "5 pages, 3 figures, 2 tables, submitted to icassp 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we investigate the effect of machine learning based\nanonymization on anomalous subgroup preservation. In particular, we train a\nbinary classifier to discover the most anomalous subgroup in a dataset by\nmaximizing the bias between the group's predicted odds ratio from the model and\nobserved odds ratio from the data. We then perform anonymization using a\nvariational autoencoder (VAE) to synthesize an entirely new dataset that would\nideally be drawn from the distribution of the original data. We repeat the\nanomalous subgroup discovery task on the new data and compare it to what was\nidentified pre-anonymization. We evaluated our approach using publicly\navailable datasets from the financial industry. Our evaluation confirmed that\nthe approach was able to produce synthetic datasets that preserved a high level\nof subgroup differentiation as identified initially in the original dataset.\nSuch a distinction was maintained while having distinctly different records\nbetween the synthetic and original dataset. Finally, we packed the above end to\nend process into what we call Utility Guaranteed Deep Privacy (UGDP) system.\nUGDP can be easily extended to onboard alternative generative approaches such\nas GANs to synthesize tabular data.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 12:09:53 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Maina", "Samuel C.", ""], ["Bryant", "Reginald E.", ""], ["Goal", "William O.", ""], ["Samoilescu", "Robert-Florian", ""], ["Varshney", "Kush R.", ""], ["Weldemariam", "Komminist", ""]]}, {"id": "1911.03748", "submitter": "Nathan Keller", "authors": "Nathan Keller and Ohad Klein", "title": "Quantum speedups need structure", "comments": "Unfortunately, our proof contains a serious flaw. Specifically, Lemma\n  5.3 does not prove the assertion it claims to prove and this collapses the\n  entire argument. We thank Paata Ivanishvili for pointing out the flaw, and\n  apologize to the community for posting an eventually incorrect proof", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR cs.DM math.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the following conjecture, raised by Aaronson and Ambainis in 2008:\nLet $f:\\{-1,1\\}^n \\rightarrow [-1,1]$ be a multilinear polynomial of degree\n$d$. Then there exists a variable $x_i$ whose influence on $f$ is at least\n$\\mathrm{poly}(\\mathrm{Var}(f)/d)$.\n  As was shown by Aaronson and Ambainis, this result implies the following\nwell-known conjecture on the power of quantum computing, dating back to 1999:\nLet $Q$ be a quantum algorithm that makes $T$ queries to a Boolean input and\nlet $\\epsilon,\\delta > 0$. Then there exists a deterministic classical\nalgorithm that makes $\\mathrm{poly}(T,1/\\epsilon,1/\\delta)$ queries to the\ninput and that approximates $Q$'s acceptance probability to within an additive\nerror $\\epsilon$ on a $1-\\delta$ fraction of inputs. In other words, any\nquantum algorithm can be simulated on most inputs by a classical algorithm\nwhich is only polynomially slower, in terms of query complexity.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 18:24:31 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 00:14:36 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Keller", "Nathan", ""], ["Klein", "Ohad", ""]]}, {"id": "1911.04014", "submitter": "Yuval Dagan", "authors": "Yuval Dagan, Vitaly Feldman", "title": "Interaction is necessary for distributed learning with privacy or\n  communication constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local differential privacy (LDP) is a model where users send privatized data\nto an untrusted central server whose goal it to solve some data analysis task.\nIn the non-interactive version of this model the protocol consists of a single\nround in which a server sends requests to all users then receives their\nresponses. This version is deployed in industry due to its practical advantages\nand has attracted significant research interest. Our main result is an\nexponential lower bound on the number of samples necessary to solve the\nstandard task of learning a large-margin linear separator in the\nnon-interactive LDP model. Via a standard reduction this lower bound implies an\nexponential lower bound for stochastic convex optimization and specifically,\nfor learning linear models with a convex, Lipschitz and smooth loss. These\nresults answer the questions posed in \\citep{SmithTU17,DanielyF18}. Our lower\nbound relies on a new technique for constructing pairs of distributions with\nnearly matching moments but whose supports can be nearly separated by a large\nmargin hyperplane. These lower bounds also hold in the model where\ncommunication from each user is limited and follow from a lower bound on\nlearning using non-adaptive \\emph{statistical queries}.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 00:06:17 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 09:04:56 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Dagan", "Yuval", ""], ["Feldman", "Vitaly", ""]]}, {"id": "1911.04020", "submitter": "Ya Xiao", "authors": "Ya Xiao, Qingying Hao, Danfeng (Daphne) Yao", "title": "Neural Cryptanalysis: Metrics, Methodology, and Applications in CPS\n  Ciphers", "comments": "8 pages, 8 figures, The 2019 IEEE Conference on Dependable and Secure\n  Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world cyber-physical systems (CPS) use proprietary cipher\nalgorithms. In this work, we describe an easy-to-use black-box security\nevaluation approach to measure the strength of proprietary ciphers without\nhaving to know the algorithms. We quantify the strength of a cipher by\nmeasuring how difficult it is for a neural network to mimic the cipher\nalgorithm. We define new metrics (e.g., cipher match rate, training data\ncomplexity and training time complexity) that are computed from neural networks\nto quantitatively represent the cipher strength. This measurement approach\nallows us to directly compare the security of ciphers. Our experimental\ndemonstration utilizes fully connected neural networks with multiple parallel\nbinary classifiers at the output layer. The results show that when compared\nwith round-reduced DES, the security strength of Hitag2 (a popular stream\ncipher used in the keyless entry of modern cars) is weaker than 3-round DES.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 00:36:38 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 19:45:11 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 02:05:35 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Xiao", "Ya", "", "Daphne"], ["Hao", "Qingying", "", "Daphne"], ["Danfeng", "", "", "Daphne"], ["Yao", "", ""]]}, {"id": "1911.04078", "submitter": "Kai Li", "authors": "Kai Li, Yuzhe Tang, Jiaqi Chen, Zhehu Yuan, Cheng Xu, Jianliang Xu", "title": "Cost-Effective Data Feeds to Blockchains via Workload-Adaptive Data\n  Replication", "comments": "Blockchain storage replication, Data feed, GRuB, 20 pages, Middleware\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feeding external data to a blockchain, a.k.a. data feed, is an essential task\nto enable blockchain interoperability and support emerging cross-domain\napplications, notably stablecoins. Given the data-intensive feeds in real life\n(e.g., high-frequency price updates) and the high cost in using blockchain,\nnamely Gas, it is imperative to reduce the Gas cost of data feeds. Motivated by\nthe constant-changing workloads in finance and other applications, this work\nfocuses on designing a dynamic, workload-aware approach for cost effectiveness\nin Gas. This design space is understudied in the existing blockchain research\nwhich has so far focused on static data placement.\n  This work presents GRuB, a cost-effective data feed that dynamically\nreplicates data between the blockchain and an off-chain cloud storage. GRuB's\ndata replication is workload-adaptive by monitoring the current workload and\nmaking online decisions w.r.t. data replication. A series of online algorithms\nare proposed that achieve the bounded worst-case cost in blockchain's Gas. GRuB\nruns the decision-making components on the untrusted cloud off-chain for lower\nGas costs, and employs a security protocol to authenticate the data transferred\nbetween the blockchain and cloud. The overall GRuB system can autonomously\nachieve low Gas costs with changing workloads.\n  We built a GRuB prototype functional with Ethereum and Google LevelDB, and\nsupported real applications in stablecoins. Under real workloads collected from\nthe Ethereum contract-call history and mixed workloads of YCSB, we\nsystematically evaluate GRuB's cost which shows a saving of Gas by 10% ~ 74%,\nwith comparison to the baselines of static data-placement.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 05:08:41 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 02:03:56 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 23:10:55 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Li", "Kai", ""], ["Tang", "Yuzhe", ""], ["Chen", "Jiaqi", ""], ["Yuan", "Zhehu", ""], ["Xu", "Cheng", ""], ["Xu", "Jianliang", ""]]}, {"id": "1911.04101", "submitter": "Asma Aloufi", "authors": "Asma Aloufi, Peizhao Hu", "title": "Collaborative Homomorphic Computation on Data Encrypted under Multiple\n  Keys", "comments": "8 pages, 2 figures, In International Workshop on Privacy Engineering\n  (IWPE'19), co-located with IEEE Symposium on Security and Privacy (S&P'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Homomorphic encryption (HE) is a promising cryptographic technique for\nenabling secure collaborative machine learning in the cloud. However, support\nfor homomorphic computation on ciphertexts under multiple keys is inefficient.\nCurrent solutions often require key setup before any computation or incur large\nciphertext size (at best, grow linearly to the number of involved keys). In\nthis paper, we proposed a new approach that leverages threshold and multi-key\nHE to support computations on ciphertexts under different keys. Our new\napproach removes the need for key setup between each client and the set of\nmodel owners. At the same time, this approach reduces the number of encrypted\nmodels to be offloaded to the cloud evaluator, and the ciphertext size with a\ndimension reduction from (N+1)x2 to 2x2. We present the details of each step\nand discuss the complexity and security of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 06:30:52 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Aloufi", "Asma", ""], ["Hu", "Peizhao", ""]]}, {"id": "1911.04104", "submitter": "Abdulaziz Alzubaidi", "authors": "Abdulaziz Alzubaidi, Jugal Kalita", "title": "Authentication of Smartphone Users Using Behavioral Biometrics", "comments": null, "journal-ref": "IEEE Communications Surveys & Tutorials ( Volume: 18 , Issue: 3 ,\n  thirdquarter 2016 )", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Smartphones and tablets have become ubiquitous in our daily lives.\nSmartphones, in particular, have become more than personal assistants. These\ndevices have provided new avenues for consumers to play, work, and socialize\nwhenever and wherever they want. Smartphones are small in size, so they are\neasy to handle and to stow and carry in users' pockets or purses. However,\nmobile devices are also susceptible to various problems. One of the greatest\nconcerns is the possibility of breach in security and privacy if the device is\nseized by an outside party. It is possible that threats can come from friends\nas well as strangers. Due to the size of smart devices, they can be easily lost\nand may expose details of users' private lives. In addition, this might enable\npervasive observation or imitation of one's movements and activities, such as\nsending messages to contacts, accessing private communication, shopping with a\ncredit card, and relaying information about where one has been. This paper\nhighlights the potential risks that occur when smartphones are stolen or\nseized, discusses the concept of continuous authentication, and analyzes\ncurrent approaches and mechanisms of behavioral biometrics with respect to\nmethodology, associated datasets and evaluation approaches.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 06:35:08 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Alzubaidi", "Abdulaziz", ""], ["Kalita", "Jugal", ""]]}, {"id": "1911.04124", "submitter": "Itay Tsabary", "authors": "Itay Tsabary, Alexander Spiegelman, Ittay Eyal", "title": "HEB: Hybrid Expenditure Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of Proof of Work (PoW) has culminated with the introduction of\ncryptocurrency blockchains like Bitcoin. These protocols require their\noperators, called miners, to expend computational resources and they reward\nthem with minted cryptocurrency tokens. The system is secure from attackers who\ncannot expend resources at a rate equivalent to that of all benign miners. But\nthe resource requirement is arbitrary - the product of the number of minted\ntokens and their real value. We present Hybrid Expenditure Blockchain (HEB), a\nnovel cryptocurrency PoW protocol that allows its designer to tune external\nexpenditure. To the best of our knowledge, this is the first tunable PoW\nprotocol. Despite the reduced resource expenditure, it maintains the security\nguarantees of pure PoW protocols against rational attacks. HEB has practical\nimplications, as global power expenditure on PoW blockchains exceeds that of a\nmedium-sized country. Applying HEB in operational PoW systems can significantly\nreduce their ecological footprint.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 08:04:45 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 07:03:13 GMT"}, {"version": "v3", "created": "Wed, 22 Jan 2020 11:46:37 GMT"}, {"version": "v4", "created": "Sat, 25 Jan 2020 19:30:21 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Tsabary", "Itay", ""], ["Spiegelman", "Alexander", ""], ["Eyal", "Ittay", ""]]}, {"id": "1911.04209", "submitter": "Qinbin Li", "authors": "Qinbin Li, Zhaomin Wu, Zeyi Wen, Bingsheng He", "title": "Privacy-Preserving Gradient Boosting Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gradient Boosting Decision Tree (GBDT) is a popular machine learning\nmodel for various tasks in recent years. In this paper, we study how to improve\nmodel accuracy of GBDT while preserving the strong guarantee of differential\nprivacy. Sensitivity and privacy budget are two key design aspects for the\neffectiveness of differential private models. Existing solutions for GBDT with\ndifferential privacy suffer from the significant accuracy loss due to too loose\nsensitivity bounds and ineffective privacy budget allocations (especially\nacross different trees in the GBDT model). Loose sensitivity bounds lead to\nmore noise to obtain a fixed privacy level. Ineffective privacy budget\nallocations worsen the accuracy loss especially when the number of trees is\nlarge. Therefore, we propose a new GBDT training algorithm that achieves\ntighter sensitivity bounds and more effective noise allocations. Specifically,\nby investigating the property of gradient and the contribution of each tree in\nGBDTs, we propose to adaptively control the gradients of training data for each\niteration and leaf node clipping in order to tighten the sensitivity bounds.\nFurthermore, we design a novel boosting framework to allocate the privacy\nbudget between trees so that the accuracy loss can be further reduced. Our\nexperiments show that our approach can achieve much better model accuracy than\nother baselines.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 12:20:24 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 16:24:01 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 02:38:31 GMT"}, {"version": "v4", "created": "Tue, 16 Mar 2021 06:25:41 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Li", "Qinbin", ""], ["Wu", "Zhaomin", ""], ["Wen", "Zeyi", ""], ["He", "Bingsheng", ""]]}, {"id": "1911.04226", "submitter": "Takao Murakami", "authors": "Takao Murakami, Koki Hamada, Yusuke Kawamoto, Takuma Hatano", "title": "Privacy-Preserving Multiple Tensor Factorization for Synthesizing\n  Large-Scale Location Traces with Cluster-Specific Features", "comments": "This is a full version of the paper accepted at PETS 2021 (The 21st\n  Privacy Enhancing Technologies Symposium)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread use of LBSs (Location-based Services), synthesizing\nlocation traces plays an increasingly important role in analyzing spatial big\ndata while protecting user privacy. In particular, a synthetic trace that\npreserves a feature specific to a cluster of users (e.g., those who commute by\ntrain, those who go shopping) is important for various geo-data analysis tasks\nand for providing a synthetic location dataset. Although location synthesizers\nhave been widely studied, existing synthesizers do not provide sufficient\nutility, privacy, or scalability, hence are not practical for large-scale\nlocation traces. To overcome this issue, we propose a novel location\nsynthesizer called PPMTF (Privacy-Preserving Multiple Tensor Factorization). We\nmodel various statistical features of the original traces by a transition-count\ntensor and a visit-count tensor. We factorize these two tensors simultaneously\nvia multiple tensor factorization, and train factor matrices via posterior\nsampling. Then we synthesize traces from reconstructed tensors, and perform a\nplausible deniability test for a synthetic trace. We comprehensively evaluate\nPPMTF using two datasets. Our experimental results show that PPMTF preserves\nvarious statistical features including cluster-specific features, protects user\nprivacy, and synthesizes large-scale location traces in practical time. PPMTF\nalso significantly outperforms the state-of-the-art methods in terms of utility\nand scalability at the same level of privacy.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 13:08:30 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 13:43:03 GMT"}, {"version": "v3", "created": "Sat, 21 Dec 2019 05:48:29 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2020 19:27:56 GMT"}, {"version": "v5", "created": "Mon, 2 Mar 2020 23:49:57 GMT"}, {"version": "v6", "created": "Sun, 31 May 2020 18:49:35 GMT"}, {"version": "v7", "created": "Thu, 19 Nov 2020 01:02:55 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Murakami", "Takao", ""], ["Hamada", "Koki", ""], ["Kawamoto", "Yusuke", ""], ["Hatano", "Takuma", ""]]}, {"id": "1911.04278", "submitter": "Giulio Zizzo", "authors": "Giulio Zizzo, Chris Hankin, Sergio Maffeis, Kevin Jones", "title": "Intrusion Detection for Industrial Control Systems: Evaluation Analysis\n  and Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are increasingly used in security applications for intrusion\ndetection on industrial control systems. In this work we examine two areas that\nmust be considered for their effective use. Firstly, is their vulnerability to\nadversarial attacks when used in a time series setting. Secondly, is potential\nover-estimation of performance arising from data leakage artefacts.\n  To investigate these areas we implement a long short-term memory (LSTM) based\nintrusion detection system (IDS) which effectively detects cyber-physical\nattacks on a water treatment testbed representing a strong baseline IDS.\n  For investigating adversarial attacks we model two different white box\nattackers. The first attacker is able to manipulate sensor readings on a subset\nof the Secure Water Treatment (SWaT) system. By creating a stream of\nadversarial data the attacker is able to hide the cyber-physical attacks from\nthe IDS. For the cyber-physical attacks which are detected by the IDS, the\nattacker required on average 2.48 out of 12 total sensors to be compromised for\nthe cyber-physical attacks to be hidden from the IDS. The second attacker model\nwe explore is an $L_{\\infty}$ bounded attacker who can send fake readings to\nthe IDS, but to remain imperceptible, limits their perturbations to the\nsmallest $L_{\\infty}$ value needed.\n  Additionally, we examine data leakage problems arising from tuning for $F_1$\nscore on the whole SWaT attack set and propose a method to tune detection\nparameters that does not utilise any attack data. If attack after-effects are\naccounted for then our new parameter tuning method achieved an $F_1$ score of\n0.811$\\pm$0.0103.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 17:27:33 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Zizzo", "Giulio", ""], ["Hankin", "Chris", ""], ["Maffeis", "Sergio", ""], ["Jones", "Kevin", ""]]}, {"id": "1911.04338", "submitter": "Dongrui Wu", "authors": "Xue Jiang and Xiao Zhang and Dongrui Wu", "title": "Active Learning for Black-Box Adversarial Attacks in EEG-Based\n  Brain-Computer Interfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.HC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has made significant breakthroughs in many fields, including\nelectroencephalogram (EEG) based brain-computer interfaces (BCIs). However,\ndeep learning models are vulnerable to adversarial attacks, in which\ndeliberately designed small perturbations are added to the benign input samples\nto fool the deep learning model and degrade its performance. This paper\nconsiders transferability-based black-box attacks, where the attacker trains a\nsubstitute model to approximate the target model, and then generates\nadversarial examples from the substitute model to attack the target model.\nLearning a good substitute model is critical to the success of these attacks,\nbut it requires a large number of queries to the target model. We propose a\nnovel framework which uses query synthesis based active learning to improve the\nquery efficiency in training the substitute model. Experiments on three\nconvolutional neural network (CNN) classifiers and three EEG datasets\ndemonstrated that our method can improve the attack success rate with the same\nnumber of queries, or, in other words, our method requires fewer queries to\nachieve a desired attack performance. To our knowledge, this is the first work\nthat integrates active learning and adversarial attacks for EEG-based BCIs.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 15:00:24 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Jiang", "Xue", ""], ["Zhang", "Xiao", ""], ["Wu", "Dongrui", ""]]}, {"id": "1911.04378", "submitter": "Robert J Walls", "authors": "Jacob T. Grycel, Robert J. Walls", "title": "DRAB-LOCUS: An Area-Efficient AES Architecture for Hardware Accelerator\n  Co-Location on FPGAs", "comments": "16 pages, initial submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced Encryption Standard (AES) implementations on Field Programmable Gate\nArrays (FPGA) commonly focus on maximizing throughput at the cost of utilizing\nhigh volumes of FPGA slice logic. High resource usage limits systems' abilities\nto implement other functions (such as video processing or machine learning)\nthat may want to share the same FPGA resources. In this paper, we address the\nshared resource challenge by proposing and evaluating a low-area, but\nhigh-throughput, AES architecture. In contrast to existing work, our\nDSP/RAM-Based Low-CLB Usage (DRAB-LOCUS) architecture leverages block RAM tiles\nand Digital Signal Processing (DSP) slices to implement the AES Sub Bytes, Mix\nColumns, and Add Round Key sub-round transformations, reducing resource usage\nby a factor of 3 over traditional approaches. To achieve area-efficiency, we\nbuilt an inner-pipelined architecture using the internal registers of block RAM\ntiles and DSP slices. Our DRAB-LOCUS architecture features a 12-stage pipeline\ncapable of producing 7.055 Gbps of interleaved encrypted or decrypted data, and\nonly uses 909 Look Up tables, 593 Flip Flops, 16 block RAMs, and 18 DSP slices\nin the target device.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 16:41:29 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Grycel", "Jacob T.", ""], ["Walls", "Robert J.", ""]]}, {"id": "1911.04429", "submitter": "Xiaoyun Wang", "authors": "Xiaoyun Wang, Xuanqing Liu, Cho-Jui Hsieh", "title": "GraphDefense: Towards Robust Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the robustness of graph convolutional networks\n(GCNs). Despite the good performance of GCNs on graph semi-supervised learning\ntasks, previous works have shown that the original GCNs are very unstable to\nadversarial perturbations. In particular, we can observe a severe performance\ndegradation by slightly changing the graph adjacency matrix or the features of\na few nodes, making it unsuitable for security-critical applications. Inspired\nby the previous works on adversarial defense for deep neural networks, and\nespecially adversarial training algorithm, we propose a method called\nGraphDefense to defend against the adversarial perturbations. In addition, for\nour defense method, we could still maintain semi-supervised learning settings,\nwithout a large label rate. We also show that adversarial training in features\nis equivalent to adversarial training for edges with a small perturbation. Our\nexperiments show that the proposed defense methods successfully increase the\nrobustness of Graph Convolutional Networks. Furthermore, we show that with\ncareful design, our proposed algorithm can scale to large graphs, such as\nReddit dataset.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 18:15:12 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Wang", "Xiaoyun", ""], ["Liu", "Xuanqing", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1911.04536", "submitter": "Fahad Ahmad", "authors": "Aysha Shabbir, Maryam Shabbir, Fahad Ahmad, Muhammad Rizwan", "title": "A New Approach: Cognitive Multi-Level Authentication (CMLA) in Nuclear\n  Command and Control", "comments": "We want to improve this version of research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nuclear monitoring must considered as high precedence against national\nsecurity. Now with the increasing nuclear threats it is crucial to ensure that\nmalicious entity never procure nuclear warheads. Which comprises the prevention\nof illegal or terrorist access to nuclear weapons. The disastrous damage that\ncould be the consequence of unauthorized unapproved utilization of nuclear\nweapon and from the expansion of nuclear technologies to unacceptable states\nhas driven the nuclear forces to spend epic measures of securing nuclear\nwarheads as well as the supporting materials infrastructure and industries. The\nprocedure of ratifying users credentials is known as authentication. Cognitive\nbased authentication is a type of authentication that is actually the\namalgamation of neuron biological and psychological techniques. This research\nis intended to provide human inspired Cognitive Multi-level Authentication\nutilizing the extensive quantum processing capabilities. Simulation is being\ndone on online Q U V I S quantum simulator using quantum cryptography B B 8 4\nalgorithm where the intended person is successfully authenticated while\nconsidering different scenarios. So the proposed scheme will come up with self\nlearning intellect based secure speedy and reliable authentication systems\nagainst nuclear command and control.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 19:39:05 GMT"}, {"version": "v2", "created": "Sun, 21 Mar 2021 21:15:44 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Shabbir", "Aysha", ""], ["Shabbir", "Maryam", ""], ["Ahmad", "Fahad", ""], ["Rizwan", "Muhammad", ""]]}, {"id": "1911.04560", "submitter": "Raimil Cruz", "authors": "Raimil Cruz and \\'Eric Tanter", "title": "Existential Types for Relaxed Noninterference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Information-flow security type systems ensure confidentiality by enforcing\nnoninterference: a program cannot leak private data to public channels.\nHowever, in practice, programs need to selectively declassify information about\nprivate data. Several approaches have provided a notion of relaxed\nnoninterference supporting selective and expressive declassification while\nretaining a formal security property. The labels-as-functions approach provides\nrelaxed noninterference by means of declassification policies expressed as\nfunctions. The labels-as-types approach expresses declassification policies\nusing type abstraction and faceted types, a pair of types representing the\nsecret and public facets of values. The original proposal of labels-as-types is\nformulated in an object-oriented setting where type abstraction is realized by\nsubtyping. The object-oriented approach however suffers from limitations due to\nits receiver-centric paradigm.\n  In this work, we consider an alternative approach to labels-as-types,\napplicable in non-object-oriented languages, which allows us to express\nadvanced declassification policies, such as extrinsic policies, based on a\ndifferent form of type abstraction: existential types. An existential type\nexposes abstract types and operations on these; we leverage this abstraction\nmechanism to express secrets that can be declassified using the provided\noperations. We formalize the approach in a core functional calculus with\nexistential types, define existential relaxed noninterference, and prove that\nwell-typed programs satisfy this form of type-based relaxed noninterference.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 20:53:47 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Cruz", "Raimil", ""], ["Tanter", "\u00c9ric", ""]]}, {"id": "1911.04606", "submitter": "Dongrui Wu", "authors": "Lubin Meng and Chin-Teng Lin and Tzyy-Ring Jung and Dongrui Wu", "title": "White-Box Target Attack for EEG-Based BCI Regression Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has achieved great success in many applications, including\nelectroencephalogram (EEG) based brain-computer interfaces (BCIs).\nUnfortunately, many machine learning models are vulnerable to adversarial\nexamples, which are crafted by adding deliberately designed perturbations to\nthe original inputs. Many adversarial attack approaches for classification\nproblems have been proposed, but few have considered target adversarial attacks\nfor regression problems. This paper proposes two such approaches. More\nspecifically, we consider white-box target attacks for regression problems,\nwhere we know all information about the regression model to be attacked, and\nwant to design small perturbations to change the regression output by a\npre-determined amount. Experiments on two BCI regression problems verified that\nboth approaches are effective. Moreover, adversarial examples generated from\nboth approaches are also transferable, which means that we can use adversarial\nexamples generated from one known regression model to attack an unknown\nregression model, i.e., to perform black-box attacks. To our knowledge, this is\nthe first study on adversarial attacks for EEG-based BCI regression problems,\nwhich calls for more attention on the security of BCI systems.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 14:52:12 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Meng", "Lubin", ""], ["Lin", "Chin-Teng", ""], ["Jung", "Tzyy-Ring", ""], ["Wu", "Dongrui", ""]]}, {"id": "1911.04708", "submitter": "Shingo Fujimoto", "authors": "Shingo Fujimoto, Yoshiki Higashikado, Takuma Takeuchi", "title": "ConnectionChain: Secure Interworking of Blockchains", "comments": "4 pages, 5 figures, posted for IEEE BCCA 2019", "journal-ref": null, "doi": "10.1109/IOTSMS48152.2019.8939267", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain is a core technology to manage the value of cryptocurrencies, or\nto record trails of important business trades. The Smart Contract on blockchain\nis expected to improve security on blockchain system with automated operation,\nbut it cannot be the solution when the application service required to operate\ntightly related blockchain ledgers as service business logic. This paper\nproposed the method to extend the functionality of traditional Smart Contract\non blockchain, and introduced the prototype system, named 'ConnectionChain'.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 07:35:10 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Fujimoto", "Shingo", ""], ["Higashikado", "Yoshiki", ""], ["Takeuchi", "Takuma", ""]]}, {"id": "1911.04831", "submitter": "Jonguk Kim", "authors": "Jonguk Kim, Jeong-Han Yun, Hyoung Chun Kim", "title": "Anomaly Detection for Industrial Control Systems Using\n  Sequence-to-Sequence Neural Networks", "comments": "Accepted to 5th Workshop on the Security of Industrial Control\n  Systems & of Cyber-Physical Systems (CyberICPS 2019) in conjunction with\n  ESORICS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes an anomaly detection method for operational data of\nindustrial control systems (ICSs). Sequence-to-sequence neural networks were\napplied to train and predict ICS operational data and interpret their\ntime-series characteristic. The proposed method requires only a normal dataset\nto understand ICS's normal state and detect outliers. This method was evaluated\nwith SWaT (secure water treatment) dataset, and 29 out of 36 attacks were\ndetected. The reported method also detects the attack points, and 25 out of 53\npoints were detected. This study provides a detailed analysis of false\npositives and false negatives of the experimental results.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 13:16:15 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Kim", "Jonguk", ""], ["Yun", "Jeong-Han", ""], ["Kim", "Hyoung Chun", ""]]}, {"id": "1911.04842", "submitter": "Ni Ding Dr", "authors": "Ni Ding and Farhad Farokhi", "title": "Developing Non-Stochastic Privacy-Preserving Policies Using\n  Agglomerative Clustering", "comments": "14 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a non-stochastic privacy-preserving problem in which an adversary\naims to infer sensitive information $S$ from publicly accessible data $X$\nwithout using statistics. We consider the problem of generating and releasing a\nquantization $\\hat{X}$ of $X$ to minimize the privacy leakage of $S$ to\n$\\hat{X}$ while maintaining a certain level of utility (or, inversely, the\nquantization loss). The variables $S$ and $S$ are treated as bounded and\nnon-probabilistic, but are otherwise general. We consider two existing\nnon-stochastic privacy measures, namely the maximum uncertainty reduction\n$L_0(S \\rightarrow \\hat{X})$ and the refined information $I_*(S; \\hat{X})$\n(also called the maximin information) of $S$. For each privacy measure, we\npropose a corresponding agglomerative clustering algorithm that converges to a\nlocally optimal quantization solution $\\hat{X}$ by iteratively merging elements\nin the alphabet of $X$. To instantiate the solution to this problem, we\nconsider two specific utility measures, the worst-case resolution of $X$ by\nobserving $\\hat{X}$ and the maximal distortion of the released data $\\hat{X}$.\nWe show that the value of the maximin information $I_*(S; \\hat{X})$ can be\ndetermined by dividing the confusability graph into connected subgraphs. Hence,\n$I_*(S; \\hat{X})$ can be reduced by merging nodes connecting subgraphs. The\nrelation to the probabilistic information-theoretic privacy is also studied by\nnoting that the G{\\'a}cs-K{\\\"o}rner common information is the stochastic\nversion of $I_*$ and indicates the attainability of statistical\nindistinguishability.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 13:40:05 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 09:29:09 GMT"}, {"version": "v3", "created": "Sun, 12 Jul 2020 23:09:54 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Ding", "Ni", ""], ["Farokhi", "Farhad", ""]]}, {"id": "1911.05144", "submitter": "Bogdan Groza", "authors": "Bogdan Groza, Tudor Andreica, Adriana Berdich, Pal-Stefan Murvay,\n  Horatiu Gurban", "title": "PRESTvO: PRivacy Enabled Smartphone-based access To vehicle On-board\n  units", "comments": "revised version, accepted for publication in IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3003574", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphones are quickly moving toward complementing or even replacing\ntraditional car keys. We advocate a role-based access control policy mixed with\nattributes that facilitates access to various functionalities of vehicular\non-board units from smartphones. We use a rights-based access control policy\nfor in-vehicle functionalities similar to the case of a file allocation table\nof a contemporary OS, in which read, write or execute operations can be\nperformed over various vehicle functions. Further, to assure the appropriate\nsecurity, we develop a protocol suite using identity-based cryptography and we\nrely on group signatures that preserve the anonymity of group members for\nassuring privacy and traceability. To prove the feasibility of our approach, we\ndevelop a proof-of-concept implementation with modern smartphones, aftermarket\nAndroid head-units and test computational feasibility on a real-world\nin-vehicle controller. Our implementation relies on state-of-the-art\ncryptography, including traditional building blocks and more modern\npairing-friendly curves, that facilitate the adoption of group signatures and\nidentity-based cryptography in automotive-based scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 21:04:52 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 04:51:53 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Groza", "Bogdan", ""], ["Andreica", "Tudor", ""], ["Berdich", "Adriana", ""], ["Murvay", "Pal-Stefan", ""], ["Gurban", "Horatiu", ""]]}, {"id": "1911.05147", "submitter": "Mansi Sood", "authors": "Mansi Sood, Osman Ya\\u{g}an", "title": "On the Strength of Connectivity of Inhomogeneous Random K-out Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.CO math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random graphs are an important tool for modelling and analyzing the\nunderlying properties of complex real-world networks. In this paper, we study a\nclass of random graphs known as the inhomogeneous random K-out graphs which\nwere recently introduced to analyze heterogeneous sensor networks secured by\nthe pairwise scheme. In this model, first, each of the $n$ nodes is classified\nas type-1 (respectively, type-2) with probability $0<\\mu<1$ (respectively,\n$1-\\mu)$ independently from each other. Next, each type-1 (respectively,\ntype-2) node draws 1 arc towards a node (respectively, $K_n$ arcs towards $K_n$\ndistinct nodes) selected uniformly at random, and then the orientation of the\narcs is ignored. From the literature on homogeneous K-out graphs wherein all\nnodes select $K_n$ neighbors (i.e., $\\mu=0$), it is known that when $K_n\n\\geq2$, the graph is $K_n$-connected asymptotically almost surely (a.a.s.) as\n$n$ gets large. In the inhomogeneous case (i.e., $\\mu>0$), it was recently\nestablished that achieving even 1-connectivity a.a.s. requires $K_n=\\omega(1)$.\nHere, we provide a comprehensive set of results to complement these existing\nresults. First, we establish a sharp zero-one law for $k$-connectivity, showing\nthat for the network to be $k$-connected a.a.s., we need to set $K_n =\n\\frac{1}{1-\\mu}(\\log n +(k-2)\\log\\log n + \\omega(1))$ for all $k=2, 3, \\ldots$.\nDespite such large scaling of $K_n$ being required for $k$-connectivity, we\nshow that the trivial condition of $K_n \\geq 2$ for all $n$ is sufficient to\nensure that inhomogeneous K-out graph has a connected component of size\n$n-O(1)$ whp.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 21:09:03 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 05:43:07 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Sood", "Mansi", ""], ["Ya\u011fan", "Osman", ""]]}, {"id": "1911.05164", "submitter": "Matthias W\\\"ahlisch", "authors": "Jasper Eumann, Raphael Hiesgen, Thomas C. Schmidt, Matthias W\\\"ahlisch", "title": "A Reproducibility Study of \"IP Spoofing Detection in Inter-Domain\n  Traffic\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IP spoofing enables reflection and amplification attacks, which cause major\nthreats to the current Internet infrastructure. IP packets with incorrect\nsource addresses would help to improve the situation. This is easy at the\nattacker's network, but very challenging at Internet eXchange Points (IXPs) or\nin transit networks. In this reproducibility study, we revisit the paper\n\\textit{Detection, Classification, and Analysis of Inter-Domain Traffic with\nSpoofed Source IP Addresses} published at ACM IMC 2017. Using data from a\ndifferent IXP and from a different time, we were not able to reproduce the\nresults. Unfortunately, our analysis shows that the current state of art does\nintroduce a methodology that does not comply with common real-world deployment.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 22:10:38 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Eumann", "Jasper", ""], ["Hiesgen", "Raphael", ""], ["Schmidt", "Thomas C.", ""], ["W\u00e4hlisch", "Matthias", ""]]}, {"id": "1911.05184", "submitter": "Qiao Zhang", "authors": "Qiao Zhang, Cong Wang, Chunsheng Xin and Hongyi Wu", "title": "CHEETAH: An Ultra-Fast, Approximation-Free, and Privacy-Preserved Neural\n  Network Framework based on Joint Obscure Linear and Nonlinear Computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning as a Service (MLaaS) is enabling a wide range of smart\napplications on end devices. However, such convenience comes with a cost of\nprivacy because users have to upload their private data to the cloud. This\nresearch aims to provide effective and efficient MLaaS such that the cloud\nserver learns nothing about user data and the users cannot infer the\nproprietary model parameters owned by the server. This work makes the following\ncontributions. First, it unveils the fundamental performance bottleneck of\nexisting schemes due to the heavy permutations in computing linear\ntransformation and the use of communication intensive Garbled Circuits for\nnonlinear transformation. Second, it introduces an ultra-fast secure MLaaS\nframework, CHEETAH, which features a carefully crafted secret sharing scheme\nthat runs significantly faster than existing schemes without accuracy loss.\nThird, CHEETAH is evaluated on the benchmark of well-known, practical deep\nnetworks such as AlexNet and VGG-16 on the MNIST and ImageNet datasets. The\nresults demonstrate more than 100x speedup over the fastest GAZELLE (Usenix\nSecurity'18), 2000x speedup over MiniONN (ACM CCS'17) and five orders of\nmagnitude speedup over CryptoNets (ICML'16). This significant speedup enables a\nwide range of practical applications based on privacy-preserved deep neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 23:08:45 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 23:58:21 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Zhang", "Qiao", ""], ["Wang", "Cong", ""], ["Xin", "Chunsheng", ""], ["Wu", "Hongyi", ""]]}, {"id": "1911.05193", "submitter": "Bogdan Penkovsky", "authors": "Michael Dubrovsky, Marshall Ball, Bogdan Penkovsky", "title": "Optical Proof of Work", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most cryptocurrencies rely on Proof-of-Work (PoW) \"mining\" for resistance to\nSybil and double-spending attacks, as well as a mechanism for currency\nissuance. Hashcash PoW has successfully secured the Bitcoin network since its\ninception, however, as the network has expanded to take on additional value\nstorage and transaction volume, Bitcoin PoW's heavy reliance on electricity has\ncreated scalability issues, environmental concerns, and systemic risks. Mining\nefforts have concentrated in areas with low electricity costs, creating single\npoints of failure. Although PoW security properties rely on imposing a\ntrivially verifiable economic cost on miners, there is no fundamental reason\nfor it to consist primarily of electricity cost. The authors propose a novel\nPoW algorithm, Optical Proof of Work (oPoW), to eliminate energy as the primary\ncost of mining. Proposed algorithm imposes economic difficulty on the miners,\nhowever, the cost is concentrated in hardware (capital expense-CAPEX) rather\nthan electricity (operating expenses-OPEX). The oPoW scheme involves minimal\nmodifications to Hashcash-like PoW schemes, inheriting safety/security\nproperties from such schemes.\n  Rapid growth and improvement in silicon photonics over the last two decades\nhas led to the commercialization of silicon photonic co-processors (integrated\ncircuits that use photons instead of electrons to perform specialized computing\ntasks) for low-energy deep learning. oPoW is optimized for this technology such\nthat miners are incentivized to use specialized, energy-efficient photonics for\ncomputation. Beyond providing energy savings, oPoW has the potential to improve\nnetwork scalability, enable decentralized mining outside of low electricity\ncost areas, and democratize issuance. Due to the CAPEX dominance of mining\ncosts, oPoW hashrate will be significantly less sensitive to underlying coin\nprice declines.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 23:11:45 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2020 19:13:42 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Dubrovsky", "Michael", ""], ["Ball", "Marshall", ""], ["Penkovsky", "Bogdan", ""]]}, {"id": "1911.05268", "submitter": "Rey Wiyatno", "authors": "Rey Reza Wiyatno, Anqi Xu, Ousmane Dia, Archy de Berker", "title": "Adversarial Examples in Modern Machine Learning: A Review", "comments": "Work in progress, 97 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has found that many families of machine learning models are\nvulnerable to adversarial examples: inputs that are specifically designed to\ncause the target model to produce erroneous outputs. In this survey, we focus\non machine learning models in the visual domain, where methods for generating\nand detecting such examples have been most extensively studied. We explore a\nvariety of adversarial attack methods that apply to image-space content, real\nworld adversarial attacks, adversarial defenses, and the transferability\nproperty of adversarial examples. We also discuss strengths and weaknesses of\nvarious methods of adversarial attack and defense. Our aim is to provide an\nextensive coverage of the field, furnishing the reader with an intuitive\nunderstanding of the mechanics of adversarial attack and defense mechanisms and\nenlarging the community of researchers studying this fundamental set of\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 03:09:40 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 23:07:01 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Wiyatno", "Rey Reza", ""], ["Xu", "Anqi", ""], ["Dia", "Ousmane", ""], ["de Berker", "Archy", ""]]}, {"id": "1911.05391", "submitter": "Jessica Velasco", "authors": "August Thio-ac, Erwin John Domingo, Ricca May Reyes, Nilo Arago, Romeo\n  Jr. Jorda and Jessica Velasco", "title": "Development of a Secure and Private Electronic Procurement System based\n  on Blockchain Implementation", "comments": null, "journal-ref": "International Journal of Advanced Trends in Computer Science and\n  Engineering (2019) 2626-2631", "doi": "10.30534/ijatcse/2019/115852019", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents the development of an online procurement system and the\nintegration of blockchain technology. Various tools such as PHP, JavaScript,\nHTML, CSS, and jQuery were used in designing the graphical, programming logic,\nand blockchain aspect of the system. Every page and function will have their\nrespective construction and result. In addition, the proposed system's flow of\nprocess and the methods on the testing and hosting of the site as well as the\ndifferent web development languages used in every part of the development and\ndesign process were presented. The proposed system was successfully and\nfunctionally developed starting from the execution of procurement proper, to\nthe placement of procured items or goods, and up to the signing of contracts by\nthe winner and the procurer. Lastly, features were added such as user profiles\nof the bidder and procurer.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 10:47:29 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Thio-ac", "August", ""], ["Domingo", "Erwin John", ""], ["Reyes", "Ricca May", ""], ["Arago", "Nilo", ""], ["Jorda", "Romeo Jr.", ""], ["Velasco", "Jessica", ""]]}, {"id": "1911.05399", "submitter": "Jessica Velasco", "authors": "August Thio-ac, Alfred Keanu Serut, Rayn Louise Torrejos, Keenan Dave\n  Rivo and Jessica Velasco", "title": "Blockchain-based System Evaluation: The Effectiveness of Blockchain on\n  E-Procurements", "comments": null, "journal-ref": "International Journal of Advanced Trends in Computer Science and\n  Engineering (2019) 2673-2676", "doi": "10.30534/ijatcse/2019/122852019", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Electronic systems tend to simplify the tedious traditional scheme and\nbasically focuses on the platform design and process organization. The\nintegrity of the output of an automated system is not left behind but the\npossibility of internal manipulation is still high. This paper presents the\ncurrent issues in company procurements and the solution in the form of\nblockchain technology. Several individuals and professionals were asked to\nevaluate a blockchain-based procurement system in comparison to the current\nelectronic (e-procurement) system. A blockchain-based system has the capability\nto hold transactional data with complete decentralization and eliminate the\ngrowing number of fraud cases in companies and organizations. This paper mainly\nfocuses on the effectiveness of a blockchain-based system in company\nprocurements.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 11:08:42 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Thio-ac", "August", ""], ["Serut", "Alfred Keanu", ""], ["Torrejos", "Rayn Louise", ""], ["Rivo", "Keenan Dave", ""], ["Velasco", "Jessica", ""]]}, {"id": "1911.05430", "submitter": "Emanuele D'Osualdo", "authors": "Emanuele D'Osualdo and Felix Stutz", "title": "Decidable Inductive Invariants for Verification of Cryptographic\n  Protocols with Unbounded Sessions", "comments": "16 pages + 23 pages appendix, 5 figures To appear in CONCUR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a theory of decidable inductive invariants for an infinite-state\nvariant of the Applied pi-calculus, with applications to automatic verification\nof stateful cryptographic protocols with unbounded sessions/nonces. Since the\nproblem is undecidable in general, we introduce depth-bounded protocols, a\nstrict generalisation of a class from the literature, for which our decidable\nanalysis is sound and complete. Our core contribution is a procedure to check\nthat an invariant is inductive, which implies that every reachable\nconfiguration satisfies it. Our invariants can capture security properties like\nsecrecy, can be inferred automatically, and represent an independently\ncheckable certificate of correctness.\n  We provide a prototype implementation and we report on its performance on\nsome textbook examples.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 12:45:28 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 09:15:53 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["D'Osualdo", "Emanuele", ""], ["Stutz", "Felix", ""]]}, {"id": "1911.05492", "submitter": "Jun Zhao", "authors": "Jun Zhao, Junshan Zhang", "title": "Preserving privacy enables \"co-existence equilibrium\" of competitive\n  diffusion in social networks", "comments": "published in IEEE Transactions on Signal and Information Processing\n  over Networks", "journal-ref": null, "doi": "10.1109/TSIPN.2017.2697819", "report-no": null, "categories": "cs.SI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of social media, different companies often promote competing\nproducts simultaneously for word-of-mouth diffusion and adoption by users in\nsocial networks. For such scenarios of competitive diffusion, prior studies\nshow that the weaker product will soon become extinct (i.e., \"winner takes\nall\"). It is intriguing to observe that in practice, however, competing\nproducts, such as iPhone and Android phone, often coexist in the market. This\ndiscrepancy may result from many factors such as the phenomenon that a user in\nthe real world may not spread its use of a product due to dissatisfaction of\nthe product or privacy protection. In this paper, we incorporate users' privacy\nfor spreading behavior into competitive diffusion of two products and develop a\nproblem formulation for privacy-aware competitive diffusion. Then, we prove\nthat privacy-preserving mechanisms can enable a \"coexistence equilibrium\"\n(i.e., two competing products coexist in the equilibrium) in competitive\ndiffusion over social networks. In addition to the rigorous analysis, we also\ndemonstrate our results with experiments over real network topologies.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 17:36:54 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Zhao", "Jun", ""], ["Zhang", "Junshan", ""]]}, {"id": "1911.05522", "submitter": "Tyler McCormick", "authors": "Wesley Lee and Tyler H. McCormick and Joshua Neil and Cole Sodja and\n  Yanran Cui", "title": "Anomaly Detection in Large Scale Networks with Latent Space Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.CR cs.SI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a real-time anomaly detection algorithm for directed activity on\nlarge, sparse networks. We model the propensity for future activity using a\ndynamic logistic model with interaction terms for sender- and receiver-specific\nlatent factors in addition to sender- and receiver-specific popularity scores;\ndeviations from this underlying model constitute potential anomalies. Latent\nnodal attributes are estimated via a variational Bayesian approach and may\nchange over time, representing natural shifts in network activity. Estimation\nis augmented with a case-control approximation to take advantage of the\nsparsity of the network and reduces computational complexity from $O(N^2)$ to\n$O(E)$, where $N$ is the number of nodes and $E$ is the number of observed\nedges. We run our algorithm on network event records collected from an\nenterprise network of over 25,000 computers and are able to identify a red team\nattack with half the detection rate required of the model without latent\ninteraction terms.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 14:57:20 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 18:20:46 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Lee", "Wesley", ""], ["McCormick", "Tyler H.", ""], ["Neil", "Joshua", ""], ["Sodja", "Cole", ""], ["Cui", "Yanran", ""]]}, {"id": "1911.05539", "submitter": "Nikos Fotiou", "authors": "Nikos Fotiou, Iakovos Pittaras, Vasilios A. Siris, George C. Polyzos", "title": "Enabling Opportunistic Users in Multi-Tenant IoT Systems using\n  Decentralized Identifiers and Permissioned Blockchains", "comments": "Proceedings of the 2nd International ACM Workshop on Security and\n  Privacy for the Internet-of-Things", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we leverage advances in decentralized identifiers and\npermissioned blockchains to build a flexible user authentication and\nauthorization mechanism that offers enhanced privacy, achieves fast revocation,\nand supports distributed \"policy decision points\" executed in mutually\nuntrusted entities. The proposed solution can be applied in multi-tenant \"IoT\nhubs\" that interconnect diverse IoT silos and enable authorization of \"guest\"\nusers, i.e., opportunistic users that have no trust relationship with the\nsystem, which has not encountered or known them before.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 15:20:16 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Fotiou", "Nikos", ""], ["Pittaras", "Iakovos", ""], ["Siris", "Vasilios A.", ""], ["Polyzos", "George C.", ""]]}, {"id": "1911.05542", "submitter": "Zhongliang Yang", "authors": "Zhongliang Yang, Ke Wang, Sai Ma, Yongfeng Huang, Xiangui Kang,\n  Xianfeng Zhao", "title": "IStego100K: Large-scale Image Steganalysis Dataset", "comments": "Accepted by IWDW2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to promote the rapid development of image steganalysis technology,\nin this paper, we construct and release a multivariable large-scale image\nsteganalysis dataset called IStego100K. It contains 208,104 images with the\nsame size of 1024*1024. Among them, 200,000 images (100,000 cover-stego image\npairs) are divided as the training set and the remaining 8,104 as testing set.\nIn addition, we hope that IStego100K can help researchers further explore the\ndevelopment of universal image steganalysis algorithms, so we try to reduce\nlimits on the images in IStego100K. For each image in IStego100K, the quality\nfactors is randomly set in the range of 75-95, the steganographic algorithm is\nrandomly selected from three well-known steganographic algorithms, which are\nJ-uniward, nsF5 and UERD, and the embedding rate is also randomly set to be a\nvalue of 0.1-0.4. In addition, considering the possible mismatch between\ntraining samples and test samples in real environment, we add a test set\n(DS-Test) whose source of samples are different from the training set. We hope\nthat this test set can help to evaluate the robustness of steganalysis\nalgorithms. We tested the performance of some latest steganalysis algorithms on\nIStego100K, with specific results and analysis details in the experimental\npart. We hope that the IStego100K dataset will further promote the development\nof universal image steganalysis technology. The description of IStego100K and\ninstructions for use can be found at https://github.com/YangzlTHU/IStego100K\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 15:25:45 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Yang", "Zhongliang", ""], ["Wang", "Ke", ""], ["Ma", "Sai", ""], ["Huang", "Yongfeng", ""], ["Kang", "Xiangui", ""], ["Zhao", "Xianfeng", ""]]}, {"id": "1911.05566", "submitter": "Nikos Fotiou", "authors": "Nikos Fotiou, Vasilios A Siris, George C. Polyzos, Mario Marchese,\n  Franco Davoli, Luca Boero", "title": "Exploiting Satellite Broadcast despite HTTPS", "comments": "to appear in Proc. of the 2019 IEEE Global Communications Conference\n  (GLOBECOM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HTTPS enhances end-user privacy and is often preferred or enforced by\nover-the-top content providers, but renders inoperable all intermediate network\nfunctions operating above the transport layer, including caching,\ncontent/protocol optimization, and security filtering tools. These functions\nare crucial for the optimization of integrated satellite-terrestrial networks.\nAdditionally, due to the use of end-to-end and per-session encryption keys, the\nadvantages of a satellite's wide-area broadcasting capabilities are limited or\neven negated completely. This paper investigates two solutions for authorized\nTLS interception that involve TLS splitting. We present how these solutions can\nbe incorporated into integrated satellite-terrestrial networks and we discuss\ntheir trade-offs in terms of deployment, performance, and privacy. Furthermore,\nwe design a solution that leverages satellite broadcast transmission even in\nthe presence of TLS (i.e. with the use of HTTPS) by exploiting application\nlayer encryption in the path between the satellite terminal and the TLS server.\nOur findings indicate that even if no other operation than TLS splitting is\nperformed, TLS handshake time, which involves roundtrips through possibly a\nGeosynchronous satellite, can be reduced by up to 94%. Moreover, by combining\nan application layer encryption solution with TLS splitting, broadcast\ntransmissions can be exploited\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 15:54:51 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Fotiou", "Nikos", ""], ["Siris", "Vasilios A", ""], ["Polyzos", "George C.", ""], ["Marchese", "Mario", ""], ["Davoli", "Franco", ""], ["Boero", "Luca", ""]]}, {"id": "1911.05664", "submitter": "Ali Jahanshahi", "authors": "Ali Jahanshahi", "title": "A Brief Review on Some Architectures Providing Support for DIFT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Dynamic Information Flow Tracking (DIFT) is a technique to track potential\nsecurity vulnerabilities in software and hardware systems at run time. The last\nfifteen years have seen a lot of research work on DIFT, including both\nhardware-based and software-based implementations for different types of\nprocessor architectures. This survey briefly reviews some hardware\narchitectures that provide DIFT support. Starting from introducing different\napproaches for hardware based DIFT, this survey focuses on integrated/in-core\narchitectures. Protection schemes, including tagging system, tag propagation,\nand tag checking for each architecture will be discussed. The survey is\norganized in such a way that it illustrates the evolution of integrated DIFT\narchitectures, each architecture tries to improve the precious proposed\narchitectures generality/versatility weaknesses. However, improving security\nwhile providing generality and versatility is kind of trade-offs. This survey\ncompares the architectures from different aspects to show the trade-offs\nclearer.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 19:54:25 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Jahanshahi", "Ali", ""]]}, {"id": "1911.05673", "submitter": "Daniel Moghimi", "authors": "Daniel Moghimi, Berk Sunar, Thomas Eisenbarth, Nadia Heninger", "title": "TPM-FAIL: TPM meets Timing and Lattice Attacks", "comments": "The 29th USENIX Security Symposium (Usenix SEC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trusted Platform Module (TPM) serves as a hardware-based root of trust that\nprotects cryptographic keys from privileged system and physical adversaries. In\nthis work, we perform a black-box timing analysis of TPM 2.0 devices deployed\non commodity computers. Our analysis reveals that some of these devices feature\nsecret-dependent execution times during signature generation based on elliptic\ncurves. In particular, we discovered timing leakage on an Intel firmware-based\nTPM as well as a hardware TPM. We show how this information allows an attacker\nto apply lattice techniques to recover 256-bit private keys for ECDSA and\nECSchnorr signatures. On Intel fTPM, our key recovery succeeds after about\n1,300 observations and in less than two minutes. Similarly, we extract the\nprivate ECDSA key from a hardware TPM manufactured by STMicroelectronics, which\nis certified at Common Criteria (CC) EAL 4+, after fewer than 40,000\nobservations. We further highlight the impact of these vulnerabilities by\ndemonstrating a remote attack against a StrongSwan IPsec VPN that uses a TPM to\ngenerate the digital signatures for authentication. In this attack, the remote\nclient recovers the server's private authentication key by timing only 45,000\nauthentication handshakes via a network connection.\n  The vulnerabilities we have uncovered emphasize the difficulty of correctly\nimplementing known constant-time techniques, and show the importance of\nevolutionary testing and transparent evaluation of cryptographic\nimplementations. Even certified devices that claim resistance against attacks\nrequire additional scrutiny by the community and industry, as we learn more\nabout these attacks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 17:53:56 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Moghimi", "Daniel", ""], ["Sunar", "Berk", ""], ["Eisenbarth", "Thomas", ""], ["Heninger", "Nadia", ""]]}, {"id": "1911.05692", "submitter": "Ahmad Shawahna", "authors": "Basem AL-Madani, Ahmad Shawahna, and Mohammad Qureshi", "title": "Anomaly Detection for Industrial Control Networks using Machine Learning\n  with the help from the Inter-Arrival Curves", "comments": "14 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial Control Networks (ICN) such as Supervisory Control and Data\nAcquisition (SCADA) systems are widely used in industries for monitoring and\ncontrolling physical processes. These industries include power generation and\nsupply, gas and oil production and delivery, water and waste management,\ntelecommunication and transport facilities. The integration of internet exposes\nthese systems to cyber threats. The consequences of compromised ICN are\ndetermine for a country economic and functional sustainability. Therefore,\nenforcing security and ensuring correctness operation became one of the biggest\nconcerns for Industrial Control Systems (ICS), and need to be addressed. In\nthis paper, we propose an anomaly detection approach for ICN using the physical\nproperties of the system. We have developed operational baseline of electricity\ngeneration process and reduced the feature set using greedy and genetic feature\nselection algorithms. The classification is done based on Support Vector\nMachine (SVM), k-Nearest Neighbor (k-NN), and C4.5 decision tree with the help\nfrom the inter-arrival curves. The results show that the proposed approach\nsuccessfully detects anomalies with a high degree of accuracy. In addition,\nthey proved that SVM and C4.5 produces accurate results even for high\nsensitivity attacks when they used with the inter-arrival curves. As compared\nto this, k-NN is unable to produce good results for low and medium sensitivity\nattacks test cases.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 01:25:45 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["AL-Madani", "Basem", ""], ["Shawahna", "Ahmad", ""], ["Qureshi", "Mohammad", ""]]}, {"id": "1911.05771", "submitter": "Maede Zolanvari", "authors": "Maede Zolanvari, Marcio A. Teixeira, Lav Gupta, Khaled M. Khan, Raj\n  Jain", "title": "Machine Learning Based Network Vulnerability Analysis of Industrial\n  Internet of Things", "comments": null, "journal-ref": "in IEEE Internet of Things Journal, vol. 6, no. 4, pp. 6822-6834,\n  Aug. 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is critical to secure the Industrial Internet of Things (IIoT) devices\nbecause of potentially devastating consequences in case of an attack. Machine\nlearning and big data analytics are the two powerful leverages for analyzing\nand securing the Internet of Things (IoT) technology. By extension, these\ntechniques can help improve the security of the IIoT systems as well. In this\npaper, we first present common IIoT protocols and their associated\nvulnerabilities. Then, we run a cyber-vulnerability assessment and discuss the\nutilization of machine learning in countering these susceptibilities. Following\nthat, a literature review of the available intrusion detection solutions using\nmachine learning models is presented. Finally, we discuss our case study, which\nincludes details of a real-world testbed that we have built to conduct\ncyber-attacks and to design an intrusion detection system (IDS). We deploy\nbackdoor, command injection, and Structured Query Language (SQL) injection\nattacks against the system and demonstrate how a machine learning based anomaly\ndetection system can perform well in detecting these attacks. We have evaluated\nthe performance through representative metrics to have a fair point of view on\nthe effectiveness of the methods.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 19:25:53 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Zolanvari", "Maede", ""], ["Teixeira", "Marcio A.", ""], ["Gupta", "Lav", ""], ["Khan", "Khaled M.", ""], ["Jain", "Raj", ""]]}, {"id": "1911.05798", "submitter": "Sruti Bhagavatula", "authors": "Matius Chairani, Mathieu Chevalley, Abderrahmane Lazraq, Sruti\n  Bhagavatula", "title": "By the user, for the user: A user-centric approach to quantifying the\n  privacy of websites", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Third-party tracking is common on almost all commercially operated websites.\nPrior work has studied in detail the extent of third-party tracking on the web,\ndetection of third-party trackers, and defending against third-party tracking.\nExisting research and tools have also attempted to inform web users of trackers\nand the extent of their privacy violations. However, existing tools do not take\ninto account users' perceptions of and understanding of the extent of trackers\non the web. Taking these factors into account is important for the usability of\nsuch tools so that users can be aware and protect themselves to a reasonable\nand necessary extent that aligns with their overall comfort with trackers. In\nthis paper, we elicit user perceptions and preferences about different trackers\non various websites through an online survey of 43 users. We use this data to\nbootstrap a privacy scoring system. This scoring system weights the usage of\ntrackers and the dispersion of user data within a page to third parties, with\nthe type of website being visited. Our work presents a proof-of-concept\nmethodology and tool to calculate a user-centric privacy score with preliminary\nbootstrap user data. We conclude with concrete future directions.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 20:17:36 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 15:54:27 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Chairani", "Matius", ""], ["Chevalley", "Mathieu", ""], ["Lazraq", "Abderrahmane", ""], ["Bhagavatula", "Sruti", ""]]}, {"id": "1911.05808", "submitter": "Eric Rothstein-Morris", "authors": "Eric Rothstein-Morris, Sun Jun, and Sudipta Chattopadhyay", "title": "Systematic Classification of Attackers via Bounded Model Checking", "comments": "23 pages", "journal-ref": "VMCAI 2020 - 21st International Conference on Verification, Model\n  Checking, and Abstract Interpretation", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the problem of verification of systems in the presence\nof attackers using bounded model checking. Given a system and a set of security\nrequirements, we present a methodology to generate and classify attackers,\nmapping them to the set of requirements that they can break. A naive approach\nsuffers from the same shortcomings of any large model checking problem, i.e.,\nmemory shortage and exponential time. To cope with these shortcomings, we\ndescribe two sound heuristics based on cone-of-influence reduction and on\nlearning, which we demonstrate empirically by applying our methodology to a set\nof hardware benchmark systems.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 20:44:24 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Rothstein-Morris", "Eric", ""], ["Jun", "Sun", ""], ["Chattopadhyay", "Sudipta", ""]]}, {"id": "1911.05879", "submitter": "Gayathri Radhabai Gopinathan Nair", "authors": "Gayathri R G, Atul Sajjanhar, Yong Xiang", "title": "Image-Based Feature Representation for Insider Threat Classification", "comments": "8 pages, 5 figures", "journal-ref": "Applied Sciences, vol. 10, no. 14, p. 4945, 2020", "doi": "10.3390/app10144945", "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insiders are the trusted entities in the organization, but poses threat to\nthe with access to sensitive information network and resources. The insider\nthreat detection is a well studied problem in security analytics. Identifying\nthe features from data sources and using them with the right data analytics\nalgorithms makes various kinds of threat analysis possible. The insider threat\nanalysis is mainly done using the frequency based attributes extracted from the\nraw data available from data sources. In this paper, we propose an image-based\nfeature representation of the daily resource usage pattern of users in the\norganization. The features extracted from the audit files of the organization\nare represented as gray scale images. Hence, these images are used to represent\nthe resource access patterns and thereby the behavior of users. Classification\nmodels are applied to the representative images to detect anomalous behavior of\ninsiders. The images are classified to malicious and non-malicious. The\neffectiveness of the proposed representation is evaluated using the CMU CERT\ndata V4.2, and state-of-art image classification models like Mobilenet, VGG and\nResNet. The experimental results showed improved accuracy. The comparison with\nexisting works show a performance improvement in terms of high recall and\nprecision values.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 03:00:55 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["G", "Gayathri R", ""], ["Sajjanhar", "Atul", ""], ["Xiang", "Yong", ""]]}, {"id": "1911.05927", "submitter": "Amin Sakzad", "authors": "Shangqi Lai, Xingliang Yuan, Amin Sakzad, Mahsa Salehi, Joseph K. Liu,\n  and Dongxi Liu", "title": "Enabling Efficient Privacy-Assured Outlier Detection over Encrypted\n  Incremental Datasets", "comments": "To appear in IEEE Internet of Things Journal", "journal-ref": null, "doi": "10.1109/JIOT.2019.2949374", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier detection is widely used in practice to track the anomaly on\nincremental datasets such as network traffic and system logs. However, these\ndatasets often involve sensitive information, and sharing the data to third\nparties for anomaly detection raises privacy concerns. In this paper, we\npresent a privacy-preserving outlier detection protocol (PPOD) for incremental\ndatasets. The protocol decomposes the outlier detection algorithm into several\nphases and recognises the necessary cryptographic operations in each phase. It\nrealises several cryptographic modules via efficient and interchangeable\nprotocols to support the above cryptographic operations and composes them in\nthe overall protocol to enable outlier detection over encrypted datasets. To\nsupport efficient updates, it integrates the sliding window model to\nperiodically evict the expired data in order to maintain a constant update\ntime. We build a prototype of PPOD and systematically evaluates the\ncryptographic modules and the overall protocols under various parameter\nsettings. Our results show that PPOD can handle encrypted incremental datasets\nwith a moderate computation and communication cost.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 04:01:42 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Lai", "Shangqi", ""], ["Yuan", "Xingliang", ""], ["Sakzad", "Amin", ""], ["Salehi", "Mahsa", ""], ["Liu", "Joseph K.", ""], ["Liu", "Dongxi", ""]]}, {"id": "1911.05994", "submitter": "Suthee Ruangwises", "authors": "Suthee Ruangwises, Toshiya Itoh", "title": "Securely Computing the $n$-Variable Equality Function with $2n$ Cards", "comments": "A preliminary version of this paper has appeared at TAMC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in the area of secure multi-party computation using a deck of\nplaying cards, often called card-based cryptography, started from the\nintroduction of the five-card trick protocol to compute the logical AND\nfunction by den Boar in 1989. Since then, many card-based protocols to compute\nvarious functions have been developed. In this paper, we propose two new\nprotocols that securely compute the $n$-variable equality function (determining\nwhether all inputs are equal) $E: \\{0,1\\}^n \\rightarrow \\{0,1\\}$ using $2n$\ncards. The first protocol can be generalized to compute any doubly symmetric\nfunction $f: \\{0,1\\}^n \\rightarrow \\mathbb{Z}$ using $2n$ cards, and any\nsymmetric function $f: \\{0,1\\}^n \\rightarrow \\mathbb{Z}$ using $2n+2$ cards.\nThe second protocol can be generalized to compute the $k$-candidate\n$n$-variable equality function $E: (\\mathbb{Z}/k\\mathbb{Z})^n \\rightarrow\n\\{0,1\\}$ using $2 \\lceil \\lg k \\rceil n$ cards.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 08:38:36 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 12:01:13 GMT"}, {"version": "v3", "created": "Wed, 4 Nov 2020 02:20:10 GMT"}, {"version": "v4", "created": "Thu, 26 Nov 2020 19:47:10 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Ruangwises", "Suthee", ""], ["Itoh", "Toshiya", ""]]}, {"id": "1911.06260", "submitter": "Hanan Hindy", "authors": "Joshua Talbot, Przemek Pikula, Craig Sweetmore, Samuel Rowe, Hanan\n  Hindy, Christos Tachtatzis, Robert Atkinson and Xavier Bellekens", "title": "A Security Perspective on Unikernels", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cloud-based infrastructures have grown in popularity over the last decade\nleveraging virtualisation, server, storage, compute power and network\ncomponents to develop flexible applications. The requirements for instantaneous\ndeployment and reduced costs have led the shift from virtual machine deployment\nto containerisation, increasing the overall flexibility of applications and\nincreasing performances. However, containers require a fully fleshed operating\nsystem to execute, increasing the attack surface of an application. Unikernels,\non the other hand, provide a lightweight memory footprint, ease of application\npackaging and reduced start-up times. Moreover, Unikernels reduce the attack\nsurface due to the self-contained environment only enabling low-level features.\nIn this work, we provide an exhaustive description of the unikernel ecosystem;\nwe demonstrate unikernel vulnerabilities and further discuss the security\nimplications of Unikernel-enabled environments through different use-cases.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 17:35:18 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Talbot", "Joshua", ""], ["Pikula", "Przemek", ""], ["Sweetmore", "Craig", ""], ["Rowe", "Samuel", ""], ["Hindy", "Hanan", ""], ["Tachtatzis", "Christos", ""], ["Atkinson", "Robert", ""], ["Bellekens", "Xavier", ""]]}, {"id": "1911.06285", "submitter": "Isaac Corley", "authors": "Isaac Corley, Jonathan Lwowski, Justin Hoffman", "title": "DomainGAN: Generating Adversarial Examples to Attack Domain Generation\n  Algorithm Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Domain Generation Algorithms (DGAs) are frequently used to generate numerous\ndomains for use by botnets. These domains are often utilized as rendezvous\npoints for servers that malware has command and control over. There are many\nalgorithms that are used to generate domains, however many of these algorithms\nare simplistic and easily detected by traditional machine learning techniques.\nIn this paper, three variants of Generative Adversarial Networks (GANs) are\noptimized to generate domains which have similar characteristics of benign\ndomains, resulting in domains which greatly evade several state-of-the-art deep\nlearning based DGA classifiers. We additionally provide a detailed analysis\ninto offensive usability for each variant with respect to repeated and existing\ndomain collisions. Finally, we fine-tune the state-of-the-art DGA classifiers\nby adding GAN generated samples to their original training datasets and analyze\nthe changes in performance. Our results conclude that GAN based DGAs are\nsuperior in evading DGA classifiers in comparison to traditional DGAs, and of\nthe variants, the Wasserstein GAN with Gradient Penalty (WGANGP) is the highest\nperforming DGA for uses both offensively and defensively.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 18:12:36 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 19:48:07 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 19:08:31 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Corley", "Isaac", ""], ["Lwowski", "Jonathan", ""], ["Hoffman", "Justin", ""]]}, {"id": "1911.06304", "submitter": "Abdullah Al Farooq", "authors": "Abdullah Al Farooq, Jessica Marquard, Kripa George, Thomas Moyer", "title": "Detecting Safety and Security Faults in PLC Systems with Data Provenance", "comments": null, "journal-ref": "2019 IEEE International Symposium on Technologies for Homeland\n  Security", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programmable Logic Controllers are an integral component for managing many\ndifferent industrial processes (e.g., smart building management, power\ngeneration, water and wastewater management, and traffic control systems), and\nmanufacturing and control industries (e.g., oil and natural gas, chemical,\npharmaceutical, pulp and paper, food and beverage, automotive, and aerospace).\nDespite being used widely in many critical infrastructures, PLCs use protocols\nwhich make these control systems vulnerable to many common attacks, including\nman-in-the-middle attacks, denial of service attacks, and memory corruption\nattacks (e.g., array, stack, and heap overflows, integer overflows, and pointer\ncorruption). In this paper, we propose PLC-PROV, a system for tracking the\ninputs and outputs of the control system to detect violations in the safety and\nsecurity policies of the system. We consider a smart building as an example of\na PLC-based system and show how PLC-PROV can be applied to ensure that the\ninputs and outputs are consistent with the intended safety and security\npolicies.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 18:46:06 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Farooq", "Abdullah Al", ""], ["Marquard", "Jessica", ""], ["George", "Kripa", ""], ["Moyer", "Thomas", ""]]}, {"id": "1911.06400", "submitter": "Xiao Fan Liu", "authors": "Zeng-Xian Lin, Xiao Fan Liu", "title": "Tracking the circulation routes of fresh coins in Bitcoin: A way of\n  identifying coin miners with transaction network structural properties", "comments": "in Chinese", "journal-ref": "Journal of Nanjing University of Information Science &\n  Technology(Natural Science Edition), 2018(4): 450-455", "doi": "10.13878/j.cnki.jnuist.2018.04.009", "report-no": null, "categories": "q-fin.GN cs.CR cs.IR econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin draws the highest degree of attention among cryptocurrencies, while\ncoin mining is one of the most important fashion of profiting in the Bitcoin\necosystem. This paper constructs fresh coin circulation networks by tracking\nthe fresh coin transfer routes with transaction referencing in Bitcoin\nblockchain. This paper proposes a heuristic algorithm to identifying coin\nminers by comparing coin circulation networks from different mining pools and\nthereby inferring the common profit distribution schemes of Bitcoin mining\npools. Furthermore, this paper characterizes the increasing trend of Bitcoin\nminer numbers during recent years.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 07:43:39 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Lin", "Zeng-Xian", ""], ["Liu", "Xiao Fan", ""]]}, {"id": "1911.06479", "submitter": "Shufei Zhang Mr", "authors": "Shufei Zhang and Kaizhu Huang and Zenglin Xu", "title": "On Model Robustness Against Adversarial Examples", "comments": "some theoretical bounds need to be revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the model robustness against adversarial examples, referred to as\nsmall perturbed input data that may however fool many state-of-the-art deep\nlearning models. Unlike previous research, we establish a novel theory\naddressing the robustness issue from the perspective of stability of the loss\nfunction in the small neighborhood of natural examples. We propose to exploit\nan energy function to describe the stability and prove that reducing such\nenergy guarantees the robustness against adversarial examples. We also show\nthat the traditional training methods including adversarial training with the\n$l_2$ norm constraint (AT) and Virtual Adversarial Training (VAT) tend to\nminimize the lower bound of our proposed energy function. We make an analysis\nshowing that minimization of such lower bound can however lead to insufficient\nrobustness within the neighborhood around the input sample. Furthermore, we\ndesign a more rational method with the energy regularization which proves to\nachieve better robustness than previous methods. Through a series of\nexperiments, we demonstrate the superiority of our model on both supervised\ntasks and semi-supervised tasks. In particular, our proposed adversarial\nframework achieves the best performance compared with previous adversarial\ntraining methods on benchmark datasets MNIST, CIFAR-10, and SVHN. Importantly,\nthey demonstrate much better robustness against adversarial examples than all\nthe other comparison methods.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 05:02:25 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 05:26:51 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Zhang", "Shufei", ""], ["Huang", "Kaizhu", ""], ["Xu", "Zenglin", ""]]}, {"id": "1911.06502", "submitter": "Kazuhiro Takemoto", "authors": "Hokuto Hirano, Kazuhiro Takemoto", "title": "Simple iterative method for generating targeted universal adversarial\n  perturbations", "comments": "4 pages, 3 figures, 1 table", "journal-ref": "Algorithms 13, 268 (2020)", "doi": "10.3390/a13110268", "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are vulnerable to adversarial attacks. In\nparticular, a single perturbation known as the universal adversarial\nperturbation (UAP) can foil most classification tasks conducted by DNNs. Thus,\ndifferent methods for generating UAPs are required to fully evaluate the\nvulnerability of DNNs. A realistic evaluation would be with cases that consider\ntargeted attacks; wherein the generated UAP causes DNN to classify an input\ninto a specific class. However, the development of UAPs for targeted attacks\nhas largely fallen behind that of UAPs for non-targeted attacks. Therefore, we\npropose a simple iterative method to generate UAPs for targeted attacks. Our\nmethod combines the simple iterative method for generating non-targeted UAPs\nand the fast gradient sign method for generating a targeted adversarial\nperturbation for an input. We applied the proposed method to state-of-the-art\nDNN models for image classification and proved the existence of almost\nimperceptible UAPs for targeted attacks; further, we demonstrated that such\nUAPs are easily generatable.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 08:02:20 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 05:53:03 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Hirano", "Hokuto", ""], ["Takemoto", "Kazuhiro", ""]]}, {"id": "1911.06589", "submitter": "Stefan Marksteiner", "authors": "Stefan Marksteiner, Zhendong Ma", "title": "Approaching the Automation of Cyber Security Testing of Connected\n  Vehicles", "comments": "3 pages, 1 figure, Central European Cybersecurity Conference 2019\n  (CECC2019), Munich", "journal-ref": null, "doi": "10.1145/3360664.3360729", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advancing digitalization of vehicles and automotive systems bears many\nadvantages for creating and enhancing comfort and safety-related systems\nranging from drive-by-wire, inclusion of advanced displays, entertainment\nsystems up to sophisticated driving assistance and autonomous driving. It,\nhowever, also contains the inherent risk of being used for purposes that are\nnot intended for, raging from small non-authorized customizations to the\npossibility of full-scale cyberattacks that affect several vehicles to whole\nfleets and vital systems such as steering and engine control. To prevent such\nconditions and mitigate cybersecurity risks from affecting the safety of road\ntraffic, testing cybersecurity must be adopted into automotive testing at a\nlarge scale. Currently, the manual penetration testing processes cannot uphold\nthe increasing demand due to time and cost to test complex systems. We propose\nan approach for an architecture that (semi-)automates automotive cybersecurity\ntest, allowing for more economic testing and therefore keeping up to the rising\ndemand induced by new vehicle functions as well as the development towards\nconnected and autonomous vehicles.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 12:34:55 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Marksteiner", "Stefan", ""], ["Ma", "Zhendong", ""]]}, {"id": "1911.06594", "submitter": "Stefan Marksteiner", "authors": "Stefan Marksteiner, Rudolf Ramler, Hannes Sochor", "title": "Integrating Threat Modeling and Automated Test Case Generation into\n  Industrialized Software Security Testing", "comments": "3 pages, 1 figure, Central European Cybersecurity Conference 2019\n  (CECC2019), Munich", "journal-ref": null, "doi": "10.1145/3360664.3362698", "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial Internet of Things (IIoT) application provide a whole new set of\npossibilities to drive efficiency of industrial production forward. However,\nwith the higher degree of integration among systems, comes a plethora of\nnewthreats to the latter, as they are not yet designed to be broadly reachable\nand interoperable. To mitigate these vast amount of new threats, systematic and\nautomated test methods are necessary. This comprehensiveness can be achieved by\nthorough threat modeling. In order to automate security test, we present an\napproach to automate the testing process from threat modeling onward, closing\nthe gap between threat modeling and automated test case generation.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 12:55:56 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Marksteiner", "Stefan", ""], ["Ramler", "Rudolf", ""], ["Sochor", "Hannes", ""]]}, {"id": "1911.06607", "submitter": "Charith Perera", "authors": "Yasar Majib, Charith Perera", "title": "Context Aware Family Dynamics based Internet of Things Access Control\n  Towards Better Child Safety", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, children are increasingly connected to the Internet and consume\ncontent and services through various means. It has been a challenge for less\ntech-savvy parents to protect children from harmful content and services.\nInternet of Things (IoT) has made the situation much worse as IoT devices allow\nchildren to connect to the Internet in novel ways (e.g., connected\nrefrigerators, TVs, and so on). In this paper, we propose mySafeHome, an\napproach which utilises family dynamics to provide a more natural, and\nintuitive access control mechanism to protect children from harmful content and\nservices in the context of IoT. In mySafeHome, access control dynamically\nadapts based on the physical distance between family members. For example, a\nparticular type of content can only be consumed, through TV, by children if the\nparents are in the same room (or hearing distance). mySafeHome allows parents\nto assess a given content by themselves. Our approach also aims to create\ngranular levels of access control (e.g., block / limit certain content,\nfeatures, services, on certain devices when the parents are not in the\nvicinity). We developed a prototype using OpenHAB and several smart home\ndevices to demonstrate the proposed approach. We believe that our approach also\nfacilitates the creation of better relationships between family members. A demo\ncan be viewed here: http://safehome.technology/demo.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 19:44:42 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Majib", "Yasar", ""], ["Perera", "Charith", ""]]}, {"id": "1911.06742", "submitter": "C\\'ecilia Lancien", "authors": "C\\'ecilia Lancien, Christian Majenz", "title": "Weak approximate unitary designs and applications to quantum encryption", "comments": "20 pages. Published version", "journal-ref": "Quantum 4, 313 (2020)", "doi": "10.22331/q-2020-08-28-313", "report-no": null, "categories": "quant-ph cs.CR math.FA math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unitary $t$-designs are the bread and butter of quantum information theory\nand beyond. An important issue in practice is that of efficiently constructing\ngood approximations of such unitary $t$-designs. Building on results by Aubrun\n(Comm. Math. Phys. 2009), we prove that sampling $d^t\\mathrm{poly}(t,\\log d,\n1/\\epsilon)$ unitaries from an exact $t$-design provides with positive\nprobability an $\\epsilon$-approximate $t$-design, if the error is measured in\none-to-one norm distance of the corresponding $t$-twirling channels. As an\napplication, we give a partially derandomized construction of a quantum\nencryption scheme that has roughly the same key size and security as the\nquantum one-time pad, but possesses the additional property of being\nnon-malleable against adversaries without quantum side information.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 16:50:35 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 10:22:46 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Lancien", "C\u00e9cilia", ""], ["Majenz", "Christian", ""]]}, {"id": "1911.06790", "submitter": "Samson Zhou", "authors": "Mohammad Hassan Ameri, Jeremiah Blocki, Samson Zhou", "title": "Computationally Data-Independent Memory Hard Functions", "comments": "To appear at ITCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory hard functions (MHFs) are an important cryptographic primitive that\nare used to design egalitarian proofs of work and in the construction of\nmoderately expensive key-derivation functions resistant to brute-force attacks.\nBroadly speaking, MHFs can be divided into two categories: data-dependent\nmemory hard functions (dMHFs) and data-independent memory hard functions\n(iMHFs). iMHFs are resistant to certain side-channel attacks as the memory\naccess pattern induced by the honest evaluation algorithm is independent of the\npotentially sensitive input e.g., password. While dMHFs are potentially\nvulnerable to side-channel attacks (the induced memory access pattern might\nleak useful information to a brute-force attacker), they can achieve higher\ncumulative memory complexity (CMC) in comparison than an iMHF. In this paper,\nwe introduce the notion of computationally data-independent memory hard\nfunctions (ciMHFs). Intuitively, we require that memory access pattern induced\nby the (randomized) ciMHF evaluation algorithm appears to be independent from\nthe standpoint of a computationally bounded eavesdropping attacker --- even if\nthe attacker selects the initial input. We then ask whether it is possible to\ncircumvent known upper bound for iMHFs and build a ciMHF with CMC\n$\\Omega(N^2)$. Surprisingly, we answer the question in the affirmative when the\nciMHF evaluation algorithm is executed on a two-tiered memory architecture\n(RAM/Cache).\n  See paper for the full abstract.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 18:17:56 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Ameri", "Mohammad Hassan", ""], ["Blocki", "Jeremiah", ""], ["Zhou", "Samson", ""]]}, {"id": "1911.06811", "submitter": "Noga Agmon", "authors": "Noga Agmon", "title": "Thesis Deployment Optimization of IoT Devices through Attack Graph\n  Analysis", "comments": "Master's thesis, based on arXiv:1904.05853", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of things (IoT) has become an integral part of our life at both\nwork and home. However, these IoT devices are prone to vulnerability exploits\ndue to their low cost, low resources, the diversity of vendors, and proprietary\nfirmware. Moreover, short range communication protocols (e.g., Bluetooth or\nZigBee) open additional opportunities for the lateral movement of an attacker\nwithin an organization. Thus, the type and location of IoT devices may\nsignificantly change the level of network security of the organizational\nnetwork. In this work, we quantify the level of network security based on an\naugmented attack graph analysis that accounts for the physical location of IoT\ndevices and their communication capabilities. We use the depth-first branch and\nbound (DFBnB) heuristic search algorithm to solve two optimization problems:\nFull Deployment with Minimal Risk (FDMR) and Maximal Utility without Risk\nDeterioration (MURD). An admissible heuristic is proposed to accelerate the\nsearch. The proposed method is evaluated using a real network with simulated\ndeployment of IoT devices. The results demonstrate (1) the contribution of the\naugmented attack graphs to quantifying the impact of IoT devices deployed\nwithin the organization on security, and (2) the effectiveness of the optimized\nIoT deployment.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 20:34:37 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Agmon", "Noga", ""]]}, {"id": "1911.06879", "submitter": "Albert Cheu", "authors": "Victor Balcer and Albert Cheu", "title": "Separating Local & Shuffled Differential Privacy via Histograms", "comments": "14 pages, two tables. Accepted to ITC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in differential privacy has highlighted the shuffled model as a\npromising avenue to compute accurate statistics while keeping raw data in\nusers' hands. We present a protocol in this model that estimates histograms\nwith error independent of the domain size. This implies an arbitrarily large\ngap in sample complexity between the shuffled and local models. On the other\nhand, the models are equivalent when we impose the constraints of pure\ndifferential privacy and single-message randomizers.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 21:22:57 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 16:28:00 GMT"}, {"version": "v3", "created": "Thu, 19 Dec 2019 18:40:11 GMT"}, {"version": "v4", "created": "Tue, 14 Apr 2020 00:00:46 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Balcer", "Victor", ""], ["Cheu", "Albert", ""]]}, {"id": "1911.07100", "submitter": "Sanjay Kariyappa", "authors": "Sanjay Kariyappa, Moinuddin K Qureshi", "title": "Defending Against Model Stealing Attacks with Adaptive Misinformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are susceptible to model stealing attacks, which\nallows a data-limited adversary with no knowledge of the training dataset to\nclone the functionality of a target model, just by using black-box query\naccess. Such attacks are typically carried out by querying the target model\nusing inputs that are synthetically generated or sampled from a surrogate\ndataset to construct a labeled dataset. The adversary can use this labeled\ndataset to train a clone model, which achieves a classification accuracy\ncomparable to that of the target model. We propose \"Adaptive Misinformation\" to\ndefend against such model stealing attacks. We identify that all existing model\nstealing attacks invariably query the target model with Out-Of-Distribution\n(OOD) inputs. By selectively sending incorrect predictions for OOD queries, our\ndefense substantially degrades the accuracy of the attacker's clone model (by\nup to 40%), while minimally impacting the accuracy (<0.5%) for benign users.\nCompared to existing defenses, our defense has a significantly better security\nvs accuracy trade-off and incurs minimal computational overhead.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 21:13:33 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Kariyappa", "Sanjay", ""], ["Qureshi", "Moinuddin K", ""]]}, {"id": "1911.07116", "submitter": "Ruoxi Jia", "authors": "Min Du, Ruoxi Jia, Dawn Song", "title": "Robust Anomaly Detection and Backdoor Attack Detection Via Differential\n  Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier detection and novelty detection are two important topics for anomaly\ndetection. Suppose the majority of a dataset are drawn from a certain\ndistribution, outlier detection and novelty detection both aim to detect data\nsamples that do not fit the distribution. Outliers refer to data samples within\nthis dataset, while novelties refer to new samples. In the meantime, backdoor\npoisoning attacks for machine learning models are achieved through injecting\npoisoning samples into the training dataset, which could be regarded as\n\"outliers\" that are intentionally added by attackers. Differential privacy has\nbeen proposed to avoid leaking any individual's information, when aggregated\nanalysis is performed on a given dataset. It is typically achieved by adding\nrandom noise, either directly to the input dataset, or to intermediate results\nof the aggregation mechanism. In this paper, we demonstrate that applying\ndifferential privacy can improve the utility of outlier detection and novelty\ndetection, with an extension to detect poisoning samples in backdoor attacks.\nWe first present a theoretical analysis on how differential privacy helps with\nthe detection, and then conduct extensive experiments to validate the\neffectiveness of differential privacy in improving outlier detection, novelty\ndetection, and backdoor attack detection.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 23:32:20 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Du", "Min", ""], ["Jia", "Ruoxi", ""], ["Song", "Dawn", ""]]}, {"id": "1911.07205", "submitter": "Wenxiao Wang", "authors": "Xinyun Chen, Wenxiao Wang, Chris Bender, Yiming Ding, Ruoxi Jia, Bo\n  Li, Dawn Song", "title": "REFIT: A Unified Watermark Removal Framework For Deep Learning Systems\n  With Limited Data", "comments": "ACM Asia Conference on Computer and Communications Security\n  (AsiaCCS), 2021. Early version in ICML 2019 Workshop on Security and Privacy\n  of Machine Learning. The first two authors contribute equally", "journal-ref": null, "doi": "10.1145/3433210.3453079", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks from scratch could be computationally expensive\nand requires a lot of training data. Recent work has explored different\nwatermarking techniques to protect the pre-trained deep neural networks from\npotential copyright infringements. However, these techniques could be\nvulnerable to watermark removal attacks. In this work, we propose REFIT, a\nunified watermark removal framework based on fine-tuning, which does not rely\non the knowledge of the watermarks, and is effective against a wide range of\nwatermarking schemes. In particular, we conduct a comprehensive study of a\nrealistic attack scenario where the adversary has limited training data, which\nhas not been emphasized in prior work on attacks against watermarking schemes.\nTo effectively remove the watermarks without compromising the model\nfunctionality under this weak threat model, we propose two techniques that are\nincorporated into our fine-tuning framework: (1) an adaption of the elastic\nweight consolidation (EWC) algorithm, which is originally proposed for\nmitigating the catastrophic forgetting phenomenon; and (2) unlabeled data\naugmentation (AU), where we leverage auxiliary unlabeled data from other\nsources. Our extensive evaluation shows the effectiveness of REFIT against\ndiverse watermark embedding schemes. In particular, both EWC and AU\nsignificantly decrease the amount of labeled training data needed for effective\nwatermark removal, and the unlabeled data samples used for AU do not\nnecessarily need to be drawn from the same distribution as the benign data for\nmodel evaluation. The experimental results demonstrate that our fine-tuning\nbased watermark removal attacks could pose real threats to the copyright of\npre-trained models, and thus highlight the importance of further investigating\nthe watermarking problem and proposing more robust watermark embedding schemes\nagainst the attacks.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 10:30:08 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 06:39:35 GMT"}, {"version": "v3", "created": "Thu, 25 Mar 2021 08:34:02 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Chen", "Xinyun", ""], ["Wang", "Wenxiao", ""], ["Bender", "Chris", ""], ["Ding", "Yiming", ""], ["Jia", "Ruoxi", ""], ["Li", "Bo", ""], ["Song", "Dawn", ""]]}, {"id": "1911.07399", "submitter": "Xijie Huang", "authors": "Xijie Huang, Moustafa Alzantot, Mani Srivastava", "title": "NeuronInspect: Detecting Backdoors in Neural Networks via Output\n  Explanations", "comments": "8 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved state-of-the-art performance on various\ntasks. However, lack of interpretability and transparency makes it easier for\nmalicious attackers to inject trojan backdoor into the neural networks, which\nwill make the model behave abnormally when a backdoor sample with a specific\ntrigger is input. In this paper, we propose NeuronInspect, a framework to\ndetect trojan backdoors in deep neural networks via output explanation\ntechniques. NeuronInspect first identifies the existence of backdoor attack\ntargets by generating the explanation heatmap of the output layer. We observe\nthat generated heatmaps from clean and backdoored models have different\ncharacteristics. Therefore we extract features that measure the attributes of\nexplanations from an attacked model namely: sparse, smooth and persistent. We\ncombine these features and use outlier detection to figure out the outliers,\nwhich is the set of attack targets. We demonstrate the effectiveness and\nefficiency of NeuronInspect on MNIST digit recognition dataset and GTSRB\ntraffic sign recognition dataset. We extensively evaluate NeuronInspect on\ndifferent attack scenarios and prove better robustness and effectiveness over\nstate-of-the-art trojan backdoor detection techniques Neural Cleanse by a great\nmargin.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 02:27:10 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Huang", "Xijie", ""], ["Alzantot", "Moustafa", ""], ["Srivastava", "Mani", ""]]}, {"id": "1911.07486", "submitter": "Max Maass", "authors": "Mikhail Fomichev, Max Maass, Matthias Hollick", "title": "Zero-Interaction Security -- Towards Sound Experimental Validation", "comments": "6 Pages. Companion article to arXiv:1901.07255 [cs.CR], dataset at\n  https://zenodo.org/record/2537721", "journal-ref": "ACM GetMobile, Vol. 23 Issue 2 (June 2019), p. 16-21", "doi": "10.1145/3372300.3372304", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reproducibility and realistic datasets are crucial for advancing research.\nUnfortunately, they are often neglected as valid scientific contributions in\nmany young disciplines, with computer science being no exception. In this\narticle, we show the challenges encountered when reproducing the work of\nothers, collecting realistic data in the wild, and ensuring that our own work\nis reproducible in turn. The presented findings are based on our study\ninvestigating the limits of zero-interaction security (ZIS) -- a novel concept,\nleveraging sensor data collected by Internet of Things (IoT) devices to pair or\nauthenticate devices. In particular, we share our experiences in reproducing\nfive state-of-the-art ZIS schemes, collecting a comprehensive dataset of sensor\ndata from the real world, evaluating these schemes on the collected data, and\nreleasing the data, code, and documentation to facilitate reproducibility of\nour results. In our discussion, we outline general considerations when\nconducting similar studies and give specific examples of technical and\nmethodological issues that we experienced. We hope that our findings will raise\nawareness about the importance of reproducibility and realistic datasets in\ncomputer science and inform future research.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 08:46:49 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Fomichev", "Mikhail", ""], ["Maass", "Max", ""], ["Hollick", "Matthias", ""]]}, {"id": "1911.07523", "submitter": "Ramtine Tofighi-Shirazi", "authors": "Ramtine Tofighi-Shirazi (TL), Irina Mariuca Asavoae (TL), Philippe\n  Elbaz-Vincent (IF)", "title": "Fine-Grained Static Detection of Obfuscation Transforms Using\n  Ensemble-Learning and Semantic Reasoning", "comments": "Software Security, Protection, and Reverse Engineering Workshop\n  (SSPREW9), Dec 2019, San Juan, United States", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to efficiently detect the software protections used is at a prime\nto facilitate the selection and application of adequate deob-fuscation\ntechniques. We present a novel approach that combines semantic reasoning\ntechniques with ensemble learning classification for the purpose of providing a\nstatic detection framework for obfuscation transformations. By contrast to\nexisting work, we provide a methodology that can detect multiple layers of\nobfuscation, without depending on knowledge of the underlying functionality of\nthe training-set used. We also extend our work to detect constructions of\nobfuscation transformations, thus providing a fine-grained methodology. To that\nend, we provide several studies for the best practices of the use of machine\nlearning techniques for a scalable and efficient model. According to our\nexperimental results and evaluations on obfuscators such as Tigress and OLLVM,\nour models have up to 91% accuracy on state-of-the-art obfuscation\ntransformations. Our overall accuracies for their constructions are up to 100%.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 10:16:38 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Tofighi-Shirazi", "Ramtine", "", "TL"], ["Asavoae", "Irina Mariuca", "", "TL"], ["Elbaz-Vincent", "Philippe", "", "IF"]]}, {"id": "1911.07546", "submitter": "Andrea Coladangelo", "authors": "Andrea Coladangelo, Thomas Vidick, Tina Zhang", "title": "Non-interactive zero-knowledge arguments for QMA, with preprocessing", "comments": "68 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of non-interactive zero-knowledge (NIZK) arguments for\nlanguages in QMA. Our first main result is the following: if Learning With\nErrors (LWE) is hard for quantum computers, then any language in QMA has an\nNIZK argument with preprocessing. The preprocessing in our argument system\nconsists of (i) the generation of a CRS and (ii) a single\n(instance-independent) quantum message from verifier to prover. The\ninstance-dependent phase of our argument system involves only a single\nclassical message from prover to verifier. Importantly, verification in our\nprotocol is entirely classical, and the verifier needs not have quantum memory;\nits only quantum actions are in the preprocessing phase. Our second\ncontribution is to extend the notion of a classical proof of knowledge to the\nquantum setting. We introduce the notions of arguments and proofs of quantum\nknowledge (AoQK/PoQK), and we show that our non-interactive argument system\nsatisfies the definition of an AoQK. In particular, we explicitly construct an\nextractor which can recover a quantum witness from any prover which is\nsuccessful in our protocol. Finally, we show that any language in QMA has an\n(interactive) proof of quantum knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 11:14:42 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 07:49:49 GMT"}, {"version": "v3", "created": "Tue, 14 Jan 2020 12:49:19 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Coladangelo", "Andrea", ""], ["Vidick", "Thomas", ""], ["Zhang", "Tina", ""]]}, {"id": "1911.07567", "submitter": "Gustavo Grieco Dr.", "authors": "Alex Groce and Josselin Feist and Gustavo Grieco and Michael Colburn", "title": "What are the Actual Flaws in Important Smart Contracts (and How Can We\n  Find Them)?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important problem in smart contract security is understanding the\nlikelihood and criticality of discovered, or potential, weaknesses in\ncontracts. In this paper we provide a summary of Ethereum smart contract audits\nperformed for 23 professional stakeholders, avoiding the common problem of\nreporting issues mostly prevalent in low-quality contracts. These audits were\nperformed at a leading company in blockchain security, using both open-source\nand proprietary tools, as well as human code analysis performed by professional\nsecurity engineers. We categorize 246 individual defects, making it possible to\ncompare the severity and frequency of different vulnerability types, compare\nsmart contract and non-smart contract flaws, and to estimate the efficacy of\nautomated vulnerability detection approaches.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 11:57:22 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 16:53:38 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Groce", "Alex", ""], ["Feist", "Josselin", ""], ["Grieco", "Gustavo", ""], ["Colburn", "Michael", ""]]}, {"id": "1911.07583", "submitter": "Chris Mitchell", "authors": "Chris J Mitchell", "title": "The impact of quantum computing on real-world security: A 5G case study", "comments": "The latest version corrects a couple of minor errors and adds a\n  further reference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a detailed analysis of the impact of quantum computing on\nthe security of 5G mobile telecommunications. This involves considering how\ncryptography is used in 5G, and how the security of the system would be\naffected by the advent of quantum computing. This leads naturally to the\nspecification of a series of simple, phased, recommended changes intended to\nensure that the security of 5G (as well as 3G and 4G) is not badly damaged if\nand when large scale quantum computing becomes a practical reality. By\nexploiting backwards-compatibility features of the 5G security system design,\nwe are able to propose a novel multi-phase approach to upgrading security that\nallows for a simple and smooth migration to a post-quantum-secure system.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 12:27:26 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 09:57:33 GMT"}, {"version": "v3", "created": "Fri, 13 Dec 2019 12:05:49 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Mitchell", "Chris J", ""]]}, {"id": "1911.07649", "submitter": "Panagiotis Papadopoulos", "authors": "Panagiotis Papadopoulos, I\\~nigo Querejeta-Azurmendi, Jiexin Zhang,\n  Matteo Varvello, Antonio Nappa, Benjamin Livshits", "title": "ZKSENSE: a Privacy-Preserving Mechanism for Bot Detection in Mobile\n  Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies show that 20.4% of the internet traffic originates from\nautomated agents. To identify and block such ill-intentioned traffic,\nmechanisms that verify the humanness of the user are widely deployed across the\ninternet. CAPTCHA is the most popular among such mechanisms. Original CAPTCHAs\nrequire extra user effort (e.g., solving mathematical or image-based puzzles),\nwhich severely harms user's experience, especially on mobile, and provide only\nsporadic verification of their humanness. More recent solutions like Google's\nreCAPTCHA v3 leverage attestation data (e.g., user behavioral data, device\nfingerprints) shared with a remote server, thus raising significant privacy\nconcerns. To address all of the above, we present ZKSENSE: the first zero\nknowledge proof-based humanness attestation system designed for mobile devices.\nContrary to state-of-the-art systems, ZKSENSE assesses humanness continuously\non the background in a privacy preserving way. ZKSENSE achieves that by\nclassifying the motion sensor outputs of the mobile device based on a model\ntrained by using both publicly available sensor data and data collected from a\nsmall group of volunteers. The classification result is enclosed in a zero\nknowledge proof of humanness that can be safely shared with an attestation\nservice such as Privacy Pass. We implement ZKSENSE as an Android service to\ndemonstrate its effectiveness and practicability. In our evaluation, we show\nthat ZKSENSE verifies the humanness of the users asynchronously, on the\nbackground, without degrading their experience or jeopardizing user privacy,\nwhile it achieves 91% accuracy across a variety of attack scenarios. On a two\nyears old Samsung S9, each attestation takes around 3 seconds in total (when\nvisual CAPTCHAs need 9.8 seconds) and consumes a negligible amount of battery.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 14:04:11 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 11:14:17 GMT"}, {"version": "v3", "created": "Thu, 4 Jun 2020 12:56:13 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Papadopoulos", "Panagiotis", ""], ["Querejeta-Azurmendi", "I\u00f1igo", ""], ["Zhang", "Jiexin", ""], ["Varvello", "Matteo", ""], ["Nappa", "Antonio", ""], ["Livshits", "Benjamin", ""]]}, {"id": "1911.07657", "submitter": "Minjia Shi", "authors": "Minjia Shi, Tor Helleseth and Patrick Sole", "title": "Two-weight codes over the integers modulo a prime power", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $p$ be a prime number. Irreducible cyclic codes of length $p^2-1$ and\ndimension $2$ over the integers modulo $p^h$ are shown to have exactly two\nnonzero Hamming weights. The construction uses the Galois ring of\ncharacteristic $p^h$ and order $p^{2h}.$ When the check polynomial is\nprimitive, the code meets the Griesmer bound of (Shiromoto, Storme) (2012). By\npuncturing some projective codes are constructed. Those in length $p+1$ meet a\nSingleton-like bound of (Shiromoto , 2000). An infinite family of strongly\nregular graphs is constructed as coset graphs of the duals of these projective\ncodes. A common cover of all these graphs, for fixed $p$, is provided by\nconsidering the Hensel lifting of these cyclic codes over the $p$-adic numbers.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 02:01:54 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Shi", "Minjia", ""], ["Helleseth", "Tor", ""], ["Sole", "Patrick", ""]]}, {"id": "1911.07658", "submitter": "Michael Kissner", "authors": "Michael Kissner", "title": "Hacking Neural Networks: A Short Introduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large chunk of research on the security issues of neural networks is\nfocused on adversarial attacks. However, there exists a vast sea of simpler\nattacks one can perform both against and with neural networks. In this article,\nwe give a quick introduction on how deep learning in security works and explore\nthe basic methods of exploitation, but also look at the offensive capabilities\ndeep learning enabled tools provide. All presented attacks, such as\nbackdooring, GPU-based buffer overflows or automated bug hunting, are\naccompanied by short open-source exercises for anyone to try out.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 14:15:58 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 12:35:02 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Kissner", "Michael", ""]]}, {"id": "1911.07672", "submitter": "Rolando La Placa", "authors": "Prabhanjan Ananth and Rolando L. La Placa", "title": "Secure Quantum Extraction Protocols", "comments": "Accepted at TCC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge extraction, typically studied in the classical setting, is at the\nheart of several cryptographic protocols. We introduce the notion of secure\nquantum extraction protocols. A secure quantum extraction protocol for an NP\nrelation $\\mathcal{R}$ is a classical interactive protocol between a sender and\na receiver, where the sender gets the instance $z$ and a witness $w$, while the\nreceiver only gets the instance $z$. For any efficient quantum adversarial\nsender (who follows the protocol but can choose its own randomness), there\nexists a quantum extractor that can extract a witness $w'$ such that $(z,w')\n\\in \\mathcal{R}$ while a malicious receiver should not be able to output any\nvalid witness. We study and construct two types of secure quantum extraction\nprotocols.\n  (1) Quantum extraction protocols secure against quantum malicious receivers\nbased on quantum fully homomorphic encryption satisfying some mild properties\nand quantum hardness of learning with errors. In this construction, we\nintroduce a non black box technique in the quantum setting. All previous\nextraction techniques in the quantum setting were solely based on quantum\nrewinding.\n  (2) Quantum extraction protocols secure against classical malicious receivers\nbased on quantum hardness of learning with errors.\n  As an application, based on the quantum hardness of learning with errors, we\npresent a construction of constant round quantum zero-knowledge argument\nsystems for NP that guarantee security even against quantum malicious\nverifiers; however, our soundness only holds against classical probabilistic\npolynomial time adversaries. Prior to our work, such protocols were known\nbased, additionally, on the assumptions of decisional Diffie-Hellman (or other\ncryptographic assumptions that do not hold against polynomial time quantum\nalgorithms).\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 14:50:15 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 22:45:16 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Ananth", "Prabhanjan", ""], ["La Placa", "Rolando L.", ""]]}, {"id": "1911.07689", "submitter": "Miodrag Mihaljevic", "authors": "Miodrag J. Mihaljevic", "title": "A Blockchain Consensus Protocol Based on Dedicated Time-Memory-Data\n  Trade-Off", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A problem of developing the consensus protocols in public blockchain systems\nwhich spend a combination of energy and space resources is addressed. A\ntechnique is proposed that provides a flexibility for selection of the energy\nand space resources which should be spent by a player participating in the\nconsensus procedure. The technique originates from the cryptographic\ntime-memory-data trade-off approaches for cryptanalysis. The proposed technique\navoids the limitations of Proof-of-Work (PoW) and Proof-of Space (PoS) which\nrequire spending of only energy and space, respectively. Also, it provides a\nflexibility for adjusting the resources spending to the system budget. The\nproposed consensus technique is based on a puzzle where the problem of\ninverting one-way function is solved employing a dedicated Time-Memory-Data\nTrade-Off (TMD-TO) paradigm. The algorithms of the consensus protocol are\nproposed which employ certain unconstrained and constrained TMD-TO based\ninversions. Security of the proposed technique is considered based on the\nprobability that the honest pool of nodes generate a longer extension of the\nblockchain before its update, and a condition on the employed parameters in\norder to achieve desired security have been derived. Implementation complexity\nof the proposed consensus protocol is discussed and compared with the\ncomplexities when PoW and PoS are employed.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:11:20 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Mihaljevic", "Miodrag J.", ""]]}, {"id": "1911.07707", "submitter": "Rahul Gopinath", "authors": "Rahul Gopinath, Andreas Zeller", "title": "Building Fast Fuzzers", "comments": "12 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzing is one of the key techniques for evaluating the robustness of\nprograms against attacks. Fuzzing has to be effective in producing inputs that\ncover functionality and find vulnerabilities. But it also has to be efficient\nin producing such inputs quickly. Random fuzzers are very efficient, as they\ncan quickly generate random inputs; but they are not very effective, as the\nlarge majority of inputs generated is syntactically invalid. Grammar-based\nfuzzers make use of a grammar (or another model for the input language) to\nproduce syntactically correct inputs, and thus can quickly cover input space\nand associated functionality. Existing grammar-based fuzzers are surprisingly\ninefficient, though: Even the fastest grammar fuzzer Dharma still produces\ninputs about a thousand times slower than the fastest random fuzzer. So far,\none can have an effective or an efficient fuzzer, but not both.\n  In this paper, we describe how to build fast grammar fuzzers from the ground\nup, treating the problem of fuzzing from a programming language implementation\nperspective. Starting with a Python textbook approach, we adopt and adapt\noptimization techniques from functional programming and virtual machine\nimplementation techniques together with other novel domain-specific\noptimizations in a step-by-step fashion. In our F1 prototype fuzzer, these\nimprove production speed by a factor of 100--300 over the fastest grammar\nfuzzer Dharma. As F1 is even 5--8 times faster than a lexical random fuzzer, we\ncan find bugs faster and test with much larger valid inputs than previously\npossible.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:35:16 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Gopinath", "Rahul", ""], ["Zeller", "Andreas", ""]]}, {"id": "1911.07726", "submitter": "Man-Ki Yoon", "authors": "Man-Ki Yoon, Jung-Eun Kim, Richard Bradford, Zhong Shao", "title": "TaskShuffler++: Real-Time Schedule Randomization for Reducing Worst-Case\n  Vulnerability to Timing Inference Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a schedule randomization algorithm that reduces the\nvulnerability of real-time systems to timing inference attacks which attempt to\nlearn the timing of task execution. It utilizes run-time information readily\navailable at each scheduling decision point to increase the level of\nuncertainty in task schedules, while preserving the original schedulability.\nThe randomization algorithm significantly reduces an adversary's best chance to\ncorrectly predict what tasks would run at arbitrary times. This paper also\nproposes an information-theoretic measure that can quantify the worst-case\nvulnerability, from the defender's perspective, of an arbitrary real-time\nschedule.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 15:52:11 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Yoon", "Man-Ki", ""], ["Kim", "Jung-Eun", ""], ["Bradford", "Richard", ""], ["Shao", "Zhong", ""]]}, {"id": "1911.07782", "submitter": "Alex B. Grilo", "authors": "Anne Broadbent and Alex B. Grilo", "title": "QMA-hardness of Consistency of Local Density Matrices with Applications\n  to Quantum Zero-Knowledge", "comments": "Title changed to highlight the QMA-hardness proof of CLDM.\n  Improvement on the presentation of the paper (including self-contained proofs\n  of results needed from Grilo, Slofstra, and Yuen'19). The extended abstract\n  of this paper appears in the proceedings of FOCS'2020", "journal-ref": null, "doi": "10.1109/FOCS46700.2020.00027", "report-no": null, "categories": "quant-ph cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide several advances to the understanding of the class of Quantum\nMerlin-Arthur proof systems (QMA), the quantum analogue of NP. Our central\ncontribution is proving a longstanding conjecture that the Consistency of Local\nDensity Matrices (CLDM) problem is QMA-hard under Karp reductions. The input of\nCLDM consists of local reduced density matrices on sets of at most k qubits,\nand the problem asks if there is an n-qubit global quantum state that is\nconsistent with all of the k-qubit local density matrices. The containment of\nthis problem in QMA and the QMA-hardness under Turing reductions were proved by\nLiu [APPROX-RANDOM 2006]. Liu also conjectured that CLDM is QMA-hard under Karp\nreductions, which is desirable for applications, and we finally prove this\nconjecture. We establish this result using the techniques of simulatable codes\nof Grilo, Slofstra, and Yuen [FOCS 2019], simplifying their proofs and\ntailoring them to the context of QMA.\n  In order to develop applications of CLDM, we propose a framework that we call\nlocally simulatable proofs for QMA: this provides QMA proofs that can be\nefficiently verified by probing only k qubits and, furthermore, the reduced\ndensity matrix of any k-qubit subsystem of an accepting witness can be computed\nin polynomial time, independently of the witness. Within this framework, we\nshow advances in quantum zero-knowledge. We show the first commit-and-open\ncomputational zero-knowledge proof system for all of QMA, as a quantum analogue\nof a \"sigma\" protocol. We then define a Proof of Quantum Knowledge, which\nguarantees that a prover is effectively in possession of a quantum witness in\nan interactive proof, and show that our zero-knowledge proof system satisfies\nthis definition. Finally, we show that our proof system can be used to\nestablish that QMA has a quantum non-interactive zero-knowledge proof system in\nthe secret parameter setting.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 17:30:11 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 15:43:10 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Broadbent", "Anne", ""], ["Grilo", "Alex B.", ""]]}, {"id": "1911.07828", "submitter": "Zhilong Wang", "authors": "Zhilong Wang, Peng Liu", "title": "GPT Conjecture: Understanding the Trade-offs between Granularity,\n  Performance and Timeliness in Control-Flow Integrity", "comments": "Rephase the equation 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance/security trade-off is widely noticed in CFI research, however, we\nobserve that not every CFI scheme is subject to the trade-off. Motivated by the\nkey observation, we ask three questions. Although the three questions probably\ncannot be directly answered, they are inspiring. We find that a deeper\nunderstanding of the nature of the trade-off will help answer the three\nquestions. Accordingly, we proposed the GPT conjecture to pinpoint the\ntrade-off in designing CFI schemes, which says that at most two out of three\nproperties (fine granularity, acceptable performance, and preventive\nprotection) could be achieved.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 18:45:16 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 22:27:38 GMT"}, {"version": "v3", "created": "Sun, 10 Jan 2021 05:08:56 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Wang", "Zhilong", ""], ["Liu", "Peng", ""]]}, {"id": "1911.07921", "submitter": "Chris Mesterharm", "authors": "Rauf Izmailov and Peter Lin and Chris Mesterharm and Samyadeep Basu", "title": "Privacy Leakage Avoidance with Switching Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider membership inference attacks, one of the main privacy issues in\nmachine learning. These recently developed attacks have been proven successful\nin determining, with confidence better than a random guess, whether a given\nsample belongs to the dataset on which the attacked machine learning model was\ntrained. Several approaches have been developed to mitigate this privacy\nleakage but the tradeoff performance implications of these defensive mechanisms\n(i.e., accuracy and utility of the defended machine learning model) are not\nwell studied yet. We propose a novel approach of privacy leakage avoidance with\nswitching ensembles (PASE), which both protects against current membership\ninference attacks and does that with very small accuracy penalty, while\nrequiring acceptable increase in training and inference time. We test our PASE\nmethod, along with the the current state-of-the-art PATE approach, on three\ncalibration image datasets and analyze their tradeoffs.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 20:33:44 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Izmailov", "Rauf", ""], ["Lin", "Peter", ""], ["Mesterharm", "Chris", ""], ["Basu", "Samyadeep", ""]]}, {"id": "1911.07936", "submitter": "Efe Bozkir", "authors": "Efe Bozkir, Ali Burak \\\"Unal, Mete Akg\\\"un, Enkelejda Kasneci, Nico\n  Pfeifer", "title": "Privacy Preserving Gaze Estimation using Synthetic Images via a\n  Randomized Encoding Based Framework", "comments": "In Symposium on Eye Tracking Research and Applications (ETRA '20).\n  Authors' copy of the published paper, refer to the doi for the definitive\n  version", "journal-ref": null, "doi": "10.1145/3379156.3391364", "report-no": null, "categories": "cs.CV cs.CR cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eye tracking is handled as one of the key technologies for applications that\nassess and evaluate human attention, behavior, and biometrics, especially using\ngaze, pupillary, and blink behaviors. One of the challenges with regard to the\nsocial acceptance of eye tracking technology is however the preserving of\nsensitive and personal information. To tackle this challenge, we employ a\nprivacy-preserving framework based on randomized encoding to train a Support\nVector Regression model using synthetic eye images privately to estimate the\nhuman gaze. During the computation, none of the parties learn about the data or\nthe result that any other party has. Furthermore, the party that trains the\nmodel cannot reconstruct pupil, blinks or visual scanpath. The experimental\nresults show that our privacy-preserving framework is capable of working in\nreal-time, with the same accuracy as compared to non-private version and could\nbe extended to other eye tracking related problems.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 12:52:09 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 13:57:04 GMT"}, {"version": "v3", "created": "Mon, 6 Apr 2020 21:09:16 GMT"}, {"version": "v4", "created": "Tue, 13 Jul 2021 13:04:07 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Bozkir", "Efe", ""], ["\u00dcnal", "Ali Burak", ""], ["Akg\u00fcn", "Mete", ""], ["Kasneci", "Enkelejda", ""], ["Pfeifer", "Nico", ""]]}, {"id": "1911.07963", "submitter": "Ziteng Sun", "authors": "Ziteng Sun, Peter Kairouz, Ananda Theertha Suresh, H. Brendan McMahan", "title": "Can You Really Backdoor Federated Learning?", "comments": "To appear at the 2nd International Workshop on Federated Learning for\n  Data Privacy and Confidentiality at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The decentralized nature of federated learning makes detecting and defending\nagainst adversarial attacks a challenging task. This paper focuses on backdoor\nattacks in the federated learning setting, where the goal of the adversary is\nto reduce the performance of the model on targeted tasks while maintaining good\nperformance on the main task. Unlike existing works, we allow non-malicious\nclients to have correctly labeled samples from the targeted tasks. We conduct a\ncomprehensive study of backdoor attacks and defenses for the EMNIST dataset, a\nreal-life, user-partitioned, and non-iid dataset. We observe that in the\nabsence of defenses, the performance of the attack largely depends on the\nfraction of adversaries present and the \"complexity'' of the targeted task.\nMoreover, we show that norm clipping and \"weak'' differential privacy mitigate\nthe attacks without hurting the overall performance. We have implemented the\nattacks and defenses in TensorFlow Federated (TFF), a TensorFlow framework for\nfederated learning. In open-sourcing our code, our goal is to encourage\nresearchers to contribute new attacks and defenses and evaluate them on\nstandard federated datasets.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 21:25:03 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 19:00:11 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Sun", "Ziteng", ""], ["Kairouz", "Peter", ""], ["Suresh", "Ananda Theertha", ""], ["McMahan", "H. Brendan", ""]]}, {"id": "1911.07989", "submitter": "Micah Goldblum", "authors": "Ping-Yeh Chiang, Jonas Geiping, Micah Goldblum, Tom Goldstein, Renkun\n  Ni, Steven Reich, Ali Shafahi", "title": "WITCHcraft: Efficient PGD attacks with random step size", "comments": "Authors contributed equally and are listed in alphabetical order", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  State-of-the-art adversarial attacks on neural networks use expensive\niterative methods and numerous random restarts from different initial points.\nIterative FGSM-based methods without restarts trade off performance for\ncomputational efficiency because they do not adequately explore the image space\nand are highly sensitive to the choice of step size. We propose a variant of\nProjected Gradient Descent (PGD) that uses a random step size to improve\nperformance without resorting to expensive random restarts. Our method, Wide\nIterative Stochastic crafting (WITCHcraft), achieves results superior to the\nclassical PGD attack on the CIFAR-10 and MNIST data sets but without additional\ncomputational cost. This simple modification of PGD makes crafting attacks more\neconomical, which is important in situations like adversarial training where\nattacks need to be crafted in real time.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 22:40:08 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Chiang", "Ping-Yeh", ""], ["Geiping", "Jonas", ""], ["Goldblum", "Micah", ""], ["Goldstein", "Tom", ""], ["Ni", "Renkun", ""], ["Reich", "Steven", ""], ["Shafahi", "Ali", ""]]}, {"id": "1911.08040", "submitter": "Alvin Chan", "authors": "Alvin Chan and Yew-Soon Ong", "title": "Poison as a Cure: Detecting & Neutralizing Variable-Sized Backdoor\n  Attacks in Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning models have recently shown to be vulnerable to backdoor\npoisoning, an insidious attack where the victim model predicts clean images\ncorrectly but classifies the same images as the target class when a trigger\npoison pattern is added. This poison pattern can be embedded in the training\ndataset by the adversary. Existing defenses are effective under certain\nconditions such as a small size of the poison pattern, knowledge about the\nratio of poisoned training samples or when a validated clean dataset is\navailable. Since a defender may not have such prior knowledge or resources, we\npropose a defense against backdoor poisoning that is effective even when those\nprerequisites are not met. It is made up of several parts: one to extract a\nbackdoor poison signal, detect poison target and base classes, and filter out\npoisoned from clean samples with proven guarantees. The final part of our\ndefense involves retraining the poisoned model on a dataset augmented with the\nextracted poison signal and corrective relabeling of poisoned samples to\nneutralize the backdoor. Our approach has shown to be effective in defending\nagainst backdoor attacks that use both small and large-sized poison patterns on\nnine different target-base class pairs from the CIFAR10 dataset.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 01:59:59 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Chan", "Alvin", ""], ["Ong", "Yew-Soon", ""]]}, {"id": "1911.08075", "submitter": "Zhao-Xu Ji", "authors": "Zhaoxu Ji, Peiru Fan, Huanguo Zhang, Houzhen Wang", "title": "Greenberger-Horne-Zeilinger-based quantum private comparison protocol\n  with bit-flipping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By introducing a semi-honest third party (TP), we propose in this paper a\nnovel QPC protocol using (n+1)- qubit (n \\ge 2) Greenberger-Horne-Zeilinger\n(GHZ) states as information carriers. The parameter n not only determines the\nnumber of qubits contained in a GHZ state, but also determines the probability\nthat TP can successfully steal the participants' data and the qubit efficiency.\nIn the proposed protocol, we do not employ any other quantum technologies\n(e.g., entanglement swapping and unitary operation) except necessary\ntechnologies such as preparing quantum states and quantum measurements, which\ncan reduce the need for quantum devices. We use the keys generated by quantum\nkey distribution and bit-flipping for privacy protection, and decoy photons for\neavesdropping checking, making both external and internal attacks invalid.\nSpecifically, for external attacks, we take several well-known attack means\n(e.g., the intercept-resend attack and the measurement-resend attack) as\nexamples to show that the attackers outside the protocol can not steal the\nparticipants' data successfully, in which we provide the security proof of the\nprotocol against the entanglement-measurement attack. For internal attacks, we\nshow that TP cannot steal the participants' data and the participants cannot\nsteal each other's data. We also show that the existing attack means against\nQPC protocols are invalid for our protocol.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 03:22:28 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 03:22:50 GMT"}, {"version": "v3", "created": "Wed, 19 Aug 2020 05:42:57 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Ji", "Zhaoxu", ""], ["Fan", "Peiru", ""], ["Zhang", "Huanguo", ""], ["Wang", "Houzhen", ""]]}, {"id": "1911.08083", "submitter": "Peter Robinson", "authors": "Peter Robinson", "title": "Application Level Authentication for Ethereum Private Blockchain Atomic\n  Crosschain Transactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Atomic Crosschain Transaction technology allows composable programming across\nprivate Ethereum blockchains. It allows for inter-contract and inter-blockchain\nfunction calls that are both synchronous and atomic: if one part fails, the\nwhole call graph of function calls is rolled back. Traditional Ethereum\ncontract functions can limit which accounts can call them by specialised\napplication program logic. This is important as it allows application\ndevelopers to specify which callers can execute functions that update contract\nstate. In this paper we introduce the strategy required to restrict which\ncontracts on one blockchain can call a function in a contract that is deployed\non another blockchain. We show that validating the Originating Blockchain Id\n(the blockchain the crosschain function call started on), From Blockchain Id,\nand From Account provides contracts with certainty that a function call came\nfrom a specific contract on a specific blockchain.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 03:56:31 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Robinson", "Peter", ""]]}, {"id": "1911.08090", "submitter": "Sarfaraz Hussein", "authors": "Javier Echauz, Keith Kenemer, Sarfaraz Hussein, Jay Dhaliwal, Saurabh\n  Shintre, Slawomir Grzonkowski and Andrew Gardner", "title": "Deep Detector Health Management under Adversarial Campaigns", "comments": "International Journal of Prognostics and Health Management, Special\n  Issue: PHM Applications of Deep Learning and Emerging Analytics, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are vulnerable to adversarial inputs that induce\nseemingly unjustifiable errors. As automated classifiers are increasingly used\nin industrial control systems and machinery, these adversarial errors could\ngrow to be a serious problem. Despite numerous studies over the past few years,\nthe field of adversarial ML is still considered alchemy, with no practical\nunbroken defenses demonstrated to date, leaving PHM practitioners with few\nmeaningful ways of addressing the problem. We introduce turbidity detection as\na practical superset of the adversarial input detection problem, coping with\nadversarial campaigns rather than statistically invisible one-offs. This\nperspective is coupled with ROC-theoretic design guidance that prescribes an\ninexpensive domain adaptation layer at the output of a deep learning model\nduring an attack campaign. The result aims to approximate the Bayes optimal\nmitigation that ameliorates the detection model's degraded health. A\nproactively reactive type of prognostics is achieved via Monte Carlo simulation\nof various adversarial campaign scenarios, by sampling from the model's own\nturbidity distribution to quickly deploy the correct mitigation during a\nreal-world campaign.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 04:33:05 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Echauz", "Javier", ""], ["Kenemer", "Keith", ""], ["Hussein", "Sarfaraz", ""], ["Dhaliwal", "Jay", ""], ["Shintre", "Saurabh", ""], ["Grzonkowski", "Slawomir", ""], ["Gardner", "Andrew", ""]]}, {"id": "1911.08101", "submitter": "Shih-Han Hung", "authors": "Gorjan Alagic, Andrew M. Childs, Alex B. Grilo, Shih-Han Hung", "title": "Non-interactive classical verification of quantum computation", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent breakthrough, Mahadev constructed an interactive protocol that\nenables a purely classical party to delegate any quantum computation to an\nuntrusted quantum prover. In this work, we show that this same task can in fact\nbe performed non-interactively and in zero-knowledge.\n  Our protocols result from a sequence of significant improvements to the\noriginal four-message protocol of Mahadev. We begin by making the first message\ninstance-independent and moving it to an offline setup phase. We then establish\na parallel repetition theorem for the resulting three-message protocol, with an\nasymptotically optimal rate. This, in turn, enables an application of the\nFiat-Shamir heuristic, eliminating the second message and giving a\nnon-interactive protocol. Finally, we employ classical non-interactive\nzero-knowledge (NIZK) arguments and classical fully homomorphic encryption\n(FHE) to give a zero-knowledge variant of this construction. This yields the\nfirst purely classical NIZK argument system for QMA, a quantum analogue of NP.\n  We establish the security of our protocols under standard assumptions in\nquantum-secure cryptography. Specifically, our protocols are secure in the\nQuantum Random Oracle Model, under the assumption that Learning with Errors is\nquantumly hard. The NIZK construction also requires circuit-private FHE.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 05:13:25 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 17:03:45 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Alagic", "Gorjan", ""], ["Childs", "Andrew M.", ""], ["Grilo", "Alex B.", ""], ["Hung", "Shih-Han", ""]]}, {"id": "1911.08134", "submitter": "Stefan Hristozov", "authors": "Stefan Hristozov, Manuel Huber, Georg Sigl", "title": "Protecting RESTful IoT Devices from Battery Exhaustion DoS Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many IoT use cases involve constrained battery-powered devices offering\nservices in a RESTful manner to their communication partners. Such services may\ninvolve, e.g., costly computations or actuator/sensor usage, which may have\nsignificant influence on the power consumption of the service Providers. Remote\nattackers may excessively use those services in order to exhaust the Providers'\nbatteries, which is a form of a Denial of Service (DoS) attack. Previous work\nproposed solutions based on lightweight symmetric authentication. These\nsolutions scale poorly due to requiring pre-shared keys and do not provide\nprotection against compromised service Requesters. In contrast, we consider\nmore powerful attackers even capable of compromising legit Requesters. We\npropose a method that combines attacker detection and throttling, conducted by\na third trusted Backend, with a lightweight authentication protocol. For\nattacker detection and throttling, we propose a novel approach using rate\nlimitation algorithms. In addition, we propose and formally verify two\nauthentication protocols suitable for different, widely used IoT network\ntopologies. Our protocols ensure service availability for benign Requesters\neven if Providers are under a battery exhaustion attack. The protocols do\nneither require pre-shared keys between Requesters and Providers, nor the usage\nof asymmetric cryptography and public key infrastructures on the Provider. This\nmakes our protocols suitable for a variety of IoT deployments involving\nconstrained devices and constrained networks. We demonstrate the feasibility of\nour method through a simulation and a proof of concept implementation.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 07:34:52 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Hristozov", "Stefan", ""], ["Huber", "Manuel", ""], ["Sigl", "Georg", ""]]}, {"id": "1911.08278", "submitter": "Thomas Hardjono", "authors": "Thomas Hardjono, George Howard, Eric Scace, Mizan Chowdury, Lucas\n  Novak, Meghan Gaudet, Justin Anderson, Nicole d'avis, Christopher Kulis,\n  Edward Sweeney, Chandler Vaughan", "title": "Towards an Open and Scalable Music Metadata Layer", "comments": "19 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  One of the significant issues in the music supply chain today is the lack of\nconsistent, complete and authoritative information or metadata regarding the\ncreation of a given musical work. In many cases multiple entities in the music\nsupply chain have each created their own version of the metadata for a musical\nwork, often by manually re-entering the same information or through scraping\ndata from other sites. In such cases, the effort to synchronize or to correct\nthe information becomes manually laborious and error-prone. Furthermore,\nconfidential information regarding the legal ownership of the musical work is\noften commingled in the same metadata, making the entire database proprietary\nand thus closed. In this paper we explore an alternative model for creation\nmetadata following the open access paradigm found in other industries, such as\nin book publishing, library systems and in the automotive parts supply chain.\nThe vision is to create a new music metadata layer for creation metadata that\nis open, scalable and provides an authoritative source of information that is\navailable to all entities in the music supply chain globally.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 02:23:07 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Hardjono", "Thomas", ""], ["Howard", "George", ""], ["Scace", "Eric", ""], ["Chowdury", "Mizan", ""], ["Novak", "Lucas", ""], ["Gaudet", "Meghan", ""], ["Anderson", "Justin", ""], ["d'avis", "Nicole", ""], ["Kulis", "Christopher", ""], ["Sweeney", "Edward", ""], ["Vaughan", "Chandler", ""]]}, {"id": "1911.08339", "submitter": "Jonathan Ullman", "authors": "Alexander Edmonds and Aleksandar Nikolov and Jonathan Ullman", "title": "The Power of Factorization Mechanisms in Local and Central Differential\n  Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give new characterizations of the sample complexity of answering linear\nqueries (statistical queries) in the local and central models of differential\nprivacy:\n  *In the non-interactive local model, we give the first approximate\ncharacterization of the sample complexity. Informally our bounds are tight to\nwithin polylogarithmic factors in the number of queries and desired accuracy.\nOur characterization extends to agnostic learning in the local model.\n  *In the central model, we give a characterization of the sample complexity in\nthe high-accuracy regime that is analogous to that of Nikolov, Talwar, and\nZhang (STOC 2013), but is both quantitatively tighter and has a dramatically\nsimpler proof.\n  Our lower bounds apply equally to the empirical and population estimation\nproblems. In both cases, our characterizations show that a particular\nfactorization mechanism is approximately optimal, and the optimal sample\ncomplexity is bounded from above and below by well studied factorization norms\nof a matrix associated with the queries.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:17:18 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Edmonds", "Alexander", ""], ["Nikolov", "Aleksandar", ""], ["Ullman", "Jonathan", ""]]}, {"id": "1911.08364", "submitter": "Amir Atapour Abarghouei", "authors": "Amir Atapour-Abarghouei, Stephen Bonner and Andrew Stephen McGough", "title": "Volenti non fit injuria: Ransomware and its Victims", "comments": "2019 IEEE International Conference on Big Data 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent growth in the number of malicious activities on the internet,\ncybersecurity research has seen a boost in the past few years. However, as\ncertain variants of malware can provide highly lucrative opportunities for bad\nactors, significant resources are dedicated to innovations and improvements by\nvast criminal organisations. Among these forms of malware, ransomware has\nexperienced a significant recent rise as it offers the perpetrators great\nfinancial incentive. Ransomware variants operate by removing system access from\nthe user by either locking the system or encrypting some or all of the data,\nand subsequently demanding payment or ransom in exchange for returning system\naccess or providing a decryption key to the victim. Due to the ubiquity of\nsensitive data in many aspects of modern life, many victims of such attacks, be\nthey an individual home user or operators of a business, are forced to pay the\nransom to regain access to their data, which in many cases does not happen as\nrenormalisation of system operations is never guaranteed. As the problem of\nransomware does not seem to be subsiding, it is very important to investigate\nthe underlying forces driving and facilitating such attacks in order to create\npreventative measures. As such, in this paper, we discuss and provide further\ninsight into variants of ransomware and their victims in order to understand\nhow and why they have been targeted and what can be done to prevent or mitigate\nthe effects of such attacks.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:50:04 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Atapour-Abarghouei", "Amir", ""], ["Bonner", "Stephen", ""], ["McGough", "Andrew Stephen", ""]]}, {"id": "1911.08384", "submitter": "Sam Ainsworth", "authors": "Sam Ainsworth and Timothy M. Jones", "title": "MuonTrap: Preventing Cross-Domain Spectre-Like Attacks by Capturing\n  Speculative State", "comments": null, "journal-ref": null, "doi": "10.1109/ISCA45697.2020.00022", "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The disclosure of the Spectre speculative-execution attacks in January 2018\nhas left a severe vulnerability that systems are still struggling with how to\npatch. The solutions that currently exist tend to have incomplete coverage,\nperform badly, or have highly undesirable edge cases that cause application\ndomains to break.\n  MuonTrap allows processors to continue to speculate, avoiding significant\nreductions in performance, without impacting security. We instead prevent the\npropagation of any state based on speculative execution, by placing the results\nof speculative cache accesses into a small, fast L0 filter cache, that is\nnon-inclusive, non-exclusive with the rest of the cache hierarchy. This\nisolates all parts of the system that can't be quickly cleared on any change in\nthreat domain.\n  MuonTrap uses these speculative filter caches, which are cleared on context\nand protection-domain switches, along with a series of extensions to the cache\ncoherence protocol and prefetcher. This renders systems immune to cross-domain\ninformation leakage via Spectre and a host of similar attacks based on\nspeculative execution, with low performance impact and few changes to the CPU\ndesign.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 16:32:11 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 12:16:16 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Ainsworth", "Sam", ""], ["Jones", "Timothy M.", ""]]}, {"id": "1911.08515", "submitter": "Danilo Francati", "authors": "Danilo Francati, Giuseppe Ateniese, Abdoulaye Faye, Andrea Maria\n  Milazzo, Angelo Massimo Perillo, Luca Schiatti, Giuseppe Giordano", "title": "Audita: A Blockchain-based Auditing Framework for Off-chain Storage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cloud changed the way we manage and store data. Today, cloud storage\nservices offer clients an infrastructure that allows them a convenient source\nto store, replicate, and secure data online. However, with these new\ncapabilities also come limitations, such as lack of transparency, limited\ndecentralization, and challenges with privacy and security. And, as the need\nfor more agile, private and secure data solutions continues to grow\nexponentially, rethinking the current structure of cloud storage is\nmission-critical for enterprises. By leveraging and building upon blockchain's\nunique attributes, including immutability, security to the data element level,\ndistributed (no single point of failure), we have developed a solution\nprototype that allows data to be reliably stored while simultaneously being\nsecured, with tamper-evident auditability, via blockchain. The result, Audita,\nis a flexible solution that assures data protection and solves challenges such\nas scalability and privacy. Audita works via an augmented blockchain network of\nparticipants that include storage-nodes and block-creators. In addition, it\nprovides an automatic and fair challenge system to assure that data is\ndistributed and reliably and provably stored. While the prototype is built on\nQuorum, the solution framework can be used with any blockchain platform. The\nbenefit is a system that is built to grow along with the data needs of\nenterprises, while continuing to build the network via incentives and solving\nfor issues such as auditing and outsourcing.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 19:22:50 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 12:31:13 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Francati", "Danilo", ""], ["Ateniese", "Giuseppe", ""], ["Faye", "Abdoulaye", ""], ["Milazzo", "Andrea Maria", ""], ["Perillo", "Angelo Massimo", ""], ["Schiatti", "Luca", ""], ["Giordano", "Giuseppe", ""]]}, {"id": "1911.08516", "submitter": "Shahid Alam", "authors": "Shahid Alam, Abdulaziz Ravshanbekov", "title": "Sieving Fake News From Genuine: A Synopsis", "comments": "Published in the Proceedings of the International Conference on All\n  Aspects of Cyber Security 2019, pp: 67-71", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the rise of social media, it has become easier to disseminate fake news\nfaster and cheaper, compared to traditional news media, such as television and\nnewspapers. Recently this phenomenon has attracted lot of public attention,\nbecause it is causing significant social and financial impacts on their lives\nand businesses. Fake news are responsible for creating false, deceptive,\nmisleading, and suspicious information that can greatly effect the outcome of\nan event. This paper presents a synopsis that explains what are fake news with\nexamples and also discusses some of the current machine learning techniques,\nspecifically natural language processing (NLP) and deep learning, for\nautomatically predicting and detecting fake news. Based on this synopsis, we\nrecommend that there is a potential of using NLP and deep learning to improve\nautomatic detection of fake news, but with the right set of data and features.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 19:24:07 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Alam", "Shahid", ""], ["Ravshanbekov", "Abdulaziz", ""]]}, {"id": "1911.08520", "submitter": "Ghada Almashaqbeh", "authors": "Ghada Almashaqbeh, Allison Bishop, Justin Cappos", "title": "MicroCash: Practical Concurrent Processing of Micropayments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Micropayments are increasingly being adopted by a large number of\napplications. However, processing micropayments individually can be expensive,\nwith transaction fees exceeding the payment value itself. By aggregating these\nsmall transactions into a few larger ones, and using cryptocurrencies, today's\ndecentralized probabilistic micropayment schemes can reduce these fees.\nUnfortunately, existing solutions force micropayments to be issued\nsequentially, thus to support fast issuance rates a customer needs to create a\nlarge number of escrows, which bloats the blockchain. Moreover, these schemes\nincur a large computation and bandwidth overhead, which limit their\napplicability in large-scale systems.\n  In this paper, we propose MicroCash, the first decentralized probabilistic\nframework that supports concurrent micropayments. MicroCash introduces a novel\nescrow setup that enables a customer to concurrently issue payment tickets at a\nfast rate using a single escrow. MicroCash is also cost effective because it\nallows for ticket exchange using only one round of communication, and it\naggregates the micropayments using a lottery protocol that requires only secure\nhashing. Our experiments show that MicroCash can process thousands of tickets\nper second, which is around 1.7-4.2x times the rate of a state-of-the-art\nsequential micropayment system. Moreover, MicroCash supports any ticket issue\nrate over any period using only one escrow, while the sequential scheme would\nneed more than 1000 escrows per second to permit high rates. This enables our\nsystem to further reduce transaction fees and data on the blockchain by around\n50%.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 19:29:31 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Almashaqbeh", "Ghada", ""], ["Bishop", "Allison", ""], ["Cappos", "Justin", ""]]}, {"id": "1911.08565", "submitter": "Simone Raponi", "authors": "Simone Raponi, Roberto Di Pietro", "title": "A Longitudinal Study on Web-sites Password Management (in)Security:\n  Evidence and Remedies", "comments": "arXiv admin note: substantial text overlap with arXiv:1804.07016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single-factor password-based authentication is generally the norm to access\non-line Web-sites. While single-factor authentication is well known to be a\nweak form of authentication, a further concern arises when considering the\npossibility for an attacker to recover the user passwords by leveraging the\nloopholes in the password recovery mechanisms. Indeed, the adoption by a\nWeb-site of a poor password management system makes useless even the most\nrobust password chosen by the registered users. In this paper, building on the\nresults of our previous work, we study the possible attacks to on-line password\nrecovery systems analyzing the mechanisms implemented by some of the most\npopular Web-sites. In detail, we provide several contributions: (i) we revise\nand detail the attacker model; (ii) we provide an updated analysis with respect\nto a preliminary study we carried out in December 2017; (iii) we perform a\nbrand new analysis of the current top 200 Alexa's Web-sites of five major EU\ncountries; and, (iv) we propose \\sol, a working open-source module that could\nbe adopted by any Web-site to provide registered users with a password recovery\nmechanism to prevent mail service provider-level attacks. Overall, it is\nstriking to notice how the analyzed Web-sites have made little (if any) effort\nto become compliant with the GDPR regulation, showing that the objective to\nhave basic user protection mechanisms in place---despite the fines threatened\nby GDPR---is still far, mainly because of sub-standard security management\npractices. Finally, it is worth noting that while this study has been focused\non EU registered Web-sites, the proposed solution has, instead, general\napplicability.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 13:54:03 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 07:36:36 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Raponi", "Simone", ""], ["Di Pietro", "Roberto", ""]]}, {"id": "1911.08619", "submitter": "Shuwen Deng", "authors": "Shuwen Deng, Wenjie Xiong, Jakub Szefer", "title": "A Benchmark Suite for Evaluating Caches' Vulnerability to Timing Attacks", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timing-based side or covert channels in processor caches continue to present\na threat to computer systems, and they are the key to many of the recent\nSpectre and Meltdown attacks. Based on improvements to an existing three-step\nmodel for cache timing-based attacks, this work presents 88 Strong types of\ntheoretical timing-based vulnerabilities in processor caches. To understand and\nevaluate all possible types of vulnerabilities in processor caches, this work\nfurther presents and implements a new benchmark suite which can be used to test\nto which types of cache timing-based attacks a given processor or cache design\nis vulnerable. In total, there are 1094 automatically-generated test programs\nwhich cover the 88 theoretical vulnerabilities. The benchmark suite generates\nthe Cache Timing Vulnerability Score which can be used to evaluate how\nvulnerable a specific cache implementation is to different attacks. A smaller\nCache Timing Vulnerability Score means the design is more secure, and the\nscores among different machines can be easily compared. Evaluation is conducted\non commodity Intel and AMD processors and shows the differences in processor\nimplementations can result in different types of attacks that they are\nvulnerable to. Beyond testing commodity processors, the benchmarks and the\nCache Timing Vulnerability Score can be used to help designers of new secure\nprocessor caches evaluate their design's susceptibility to cache timing-based\nattacks.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 22:38:16 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Deng", "Shuwen", ""], ["Xiong", "Wenjie", ""], ["Szefer", "Jakub", ""]]}, {"id": "1911.08644", "submitter": "Hiromu Yakura", "authors": "Hiromu Yakura, Youhei Akimoto, Jun Sakuma", "title": "Generate (non-software) Bugs to Fool Classifiers", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In adversarial attacks intended to confound deep learning models, most\nstudies have focused on limiting the magnitude of the modification so that\nhumans do not notice the attack. On the other hand, during an attack against\nautonomous cars, for example, most drivers would not find it strange if a small\ninsect image were placed on a stop sign, or they may overlook it. In this\npaper, we present a systematic approach to generate natural adversarial\nexamples against classification models by employing such natural-appearing\nperturbations that imitate a certain object or signal. We first show the\nfeasibility of this approach in an attack against an image classifier by\nemploying generative adversarial networks that produce image patches that have\nthe appearance of a natural object to fool the target model. We also introduce\nan algorithm to optimize placement of the perturbation in accordance with the\ninput image, which makes the generation of adversarial examples fast and likely\nto succeed. Moreover, we experimentally show that the proposed approach can be\nextended to the audio domain, for example, to generate perturbations that sound\nlike the chirping of birds to fool a speech classifier.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 00:43:07 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Yakura", "Hiromu", ""], ["Akimoto", "Youhei", ""], ["Sakuma", "Jun", ""]]}, {"id": "1911.08774", "submitter": "Yulong Zeng", "authors": "Xuepeng Fan, Peng Li, Yulong Zeng, and Xiaoping Zhou", "title": "Implement Liquid Democracy on Ethereum: A Fast Algorithm for Realtime\n  Self-tally Voting System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the liquid democracy problem, where each voter can either directly\nvote to a candidate or delegate his voting power to a proxy. We consider the\nimplementation of liquid democracy on the blockchain through Ethereum smart\ncontract and to be compatible with the realtime self-tallying property, where\nthe contract itself can record ballots and update voting status upon receiving\neach voting massage. A challenge comes due to the gas fee limitation of\nEthereum mainnet, that the number of instruction for processing a voting\nmassage can not exceed a certain amount, which restrict the application\nscenario with respect to algorithms whose time complexity is linear to the\nnumber of voters. We propose a fast algorithm to overcome the challenge, such\nthat i) shifts the on-chain initialization to off-chain and ii) the on-chain\ncomplexity for processing each voting massage is O(\\log n), where n is the\nnumber of voters.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 09:00:24 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 10:44:53 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Fan", "Xuepeng", ""], ["Li", "Peng", ""], ["Zeng", "Yulong", ""], ["Zhou", "Xiaoping", ""]]}, {"id": "1911.08803", "submitter": "Oguzhan Ersoy", "authors": "Oguzhan Ersoy, Stefanie Roos and Zekeriya Erkin", "title": "How to profit from payments channels", "comments": "Financial Cryptography and Data Security (FC) 2020", "journal-ref": null, "doi": null, "report-no": "02: A typo in one of the authors name is corrected", "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Payment channel networks like Bitcoin's Lightning network are an auspicious\napproach for realizing high transaction throughput and almost-instant\nconfirmations in blockchain networks. However, the ability to successfully make\npayments in such networks relies on the willingness of participants to lock\ncollateral in the network. In Lightning, the key financial incentive is to lock\ncollateral are small fees for routing payments for other participants. While\nusers can choose these fees, currently, they mainly stick to the default fees.\nBy providing insights on beneficial choices for fees, we aim to incentivize\nusers to lock more collateral and improve the effectiveness of the network.\n  In this paper, we consider a node $\\mathbf{A}$ that given the network\ntopology and the channel details selects where to establish channels and how\nmuch fee to charge such that its financial gain is maximized. We formalize the\noptimization problem and show that it is NP-hard. We design a greedy algorithm\nto approximate the optimal solution. In each step, our greedy algorithm selects\na node which maximizes the total reward concerning the number of shortest paths\npassing through $\\mathbf{A}$ and channel fees. Our simulation study leverages\nreal-world data set to quantify the impact of our gain optimization and\nindicates that our strategy is at least a factor two better than other\nstrategies.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 10:30:27 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 19:23:21 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Ersoy", "Oguzhan", ""], ["Roos", "Stefanie", ""], ["Erkin", "Zekeriya", ""]]}, {"id": "1911.08813", "submitter": "Muhammad Arsath K F", "authors": "Muhammad Arsath K F, Vinod Ganesan, Rahul Bodduna, and Chester Rebeiro", "title": "PARAM: A Microprocessor Hardened for Power Side-Channel Attack\n  Resistance", "comments": "10 pages, 13 figures, IEEE International Symposium on Hardware\n  Oriented Security and Trust (HOST) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The power consumption of a microprocessor is a huge channel for information\nleakage. While the most popular exploitation of this channel is to recover\ncryptographic keys from embedded devices, other applications such as mobile app\nfingerprinting, reverse engineering of firmware, and password recovery are\ngrowing threats. Countermeasures proposed so far are tuned to specific\napplications, such as crypto-implementations. They are not scalable to the\nlarge number and variety of applications that typically run on a general\npurpose microprocessor.\n  In this paper, we investigate the design of a microprocessor, called PARAM\nwith increased resistance to power based side-channel attacks. To design PARAM,\nwe start with identifying the most leaking modules in an open-source RISC V\nprocessor. We evaluate the leakage in these modules and then add suitable\ncountermeasures. The countermeasures depend on the cause of leakage in each\nmodule and can vary from simple modifications of the HDL code ensuring secure\ntranslation by the EDA tools, to obfuscating data and address lines thus\nbreaking correlation with the processor's power consumption. The resultant\nprocessor is instantiated on the SASEBO-GIII FPGA board and found to resist\nDifferential Power Analysis even after one million power traces. Compared to\ncontemporary countermeasures for power side-channel attacks, overheads in area\nand frequency are minimal.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 10:48:56 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["F", "Muhammad Arsath K", ""], ["Ganesan", "Vinod", ""], ["Bodduna", "Rahul", ""], ["Rebeiro", "Chester", ""]]}, {"id": "1911.08834", "submitter": "Ajith Suresh", "authors": "Arpita Patra, Pratik Sarkar, Ajith Suresh", "title": "Fast Actively Secure OT Extension for Short Secrets", "comments": null, "journal-ref": "24th Annual Network and Distributed System Security Symposium,\n  (NDSS) 2017, San Diego, California, USA, February 26 - March 1, 2017", "doi": "10.14722/ndss.2017.23089", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Oblivious Transfer (OT) is one of the most fundamental cryptographic\nprimitives with wide-spread application in general secure multi-party\ncomputation (MPC) as well as in a number of tailored and special-purpose\nproblems of interest such as private set intersection (PSI), private\ninformation retrieval (PIR), contract signing to name a few. Often the\ninstantiations of OT require prohibitive communication and computation\ncomplexity. OT extension protocols are introduced to compute a very large\nnumber of OTs referred to as extended OTs at the cost of a small number of OTs\nreferred to as seed OTs.\n  We present a fast OT extension protocol for small secrets in the active\nsetting. Our protocol when used to produce 1-out-of-n OTs outperforms all the\nknown actively secure OT extensions. Our protocol is built on the semi-honest\nsecure extension protocol of Kolesnikov and Kumaresan of CRYPTO'13 (referred to\nas KK13 protocol henceforth) which is the best known OT extension for short\nsecrets.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 11:23:40 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Patra", "Arpita", ""], ["Sarkar", "Pratik", ""], ["Suresh", "Ajith", ""]]}, {"id": "1911.09058", "submitter": "Omid Poursaeed", "authors": "Omid Poursaeed, Tianxing Jiang, Yordanos Goshu, Harry Yang, Serge\n  Belongie, Ser-Nam Lim", "title": "Fine-grained Synthesis of Unrestricted Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for generating unrestricted adversarial examples\nby manipulating fine-grained aspects of image generation. Unlike existing\nunrestricted attacks that typically hand-craft geometric transformations, we\nlearn stylistic and stochastic modifications leveraging state-of-the-art\ngenerative models. This allows us to manipulate an image in a controlled,\nfine-grained manner without being bounded by a norm threshold. Our approach can\nbe used for targeted and non-targeted unrestricted attacks on classification,\nsemantic segmentation and object detection models. Our attacks can bypass\ncertified defenses, yet our adversarial images look indistinguishable from\nnatural images as verified by human evaluation. Moreover, we demonstrate that\nadversarial training with our examples improves performance of the model on\nclean images without requiring any modifications to the architecture. We\nperform experiments on LSUN, CelebA-HQ and COCO-Stuff as high resolution\ndatasets to validate efficacy of our proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 17:42:12 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 16:53:26 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Poursaeed", "Omid", ""], ["Jiang", "Tianxing", ""], ["Goshu", "Yordanos", ""], ["Yang", "Harry", ""], ["Belongie", "Serge", ""], ["Lim", "Ser-Nam", ""]]}, {"id": "1911.09148", "submitter": "Srivatsan Ravi Mr", "authors": "Giulio Malavolta and Pedro Moreno-Sanchez and Aniket Kate and Matteo\n  Maffei and Srivatsan Ravi", "title": "Concurrency and Privacy with Payment-Channel Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Permissionless blockchains protocols such as Bitcoin are inherently limited\nin transaction throughput and latency. Current efforts to address this key\nissue focus on off-chain payment channels that can be combined in a\nPayment-Channel Network (PCN) to enable an unlimited number of payments without\nrequiring to access the blockchain other than to register the initial and final\ncapacity of each channel. While this approach paves the way for low latency and\nhigh throughput of payments, its deployment in practice raises several privacy\nconcerns as well as technical challenges related to the inherently concurrent\nnature of payments, such as race conditions and deadlocks, that have been\nunderstudied so far. In this work, we lay the foundations for privacy and\nconcurrency in PCNs, presenting a formal definition in the Universal\nComposability framework as well as practical and provably secure solutions. In\nparticular, we present Fulgor and Rayo. Fulgor is the first payment protocol\nfor PCNs that provides provable privacy guarantees for PCNs and is fully\ncompatible with the Bitcoin scripting system. However, Fulgor is a blocking\nprotocol and therefore prone to deadlocks of concurrent payments as in\ncurrently available PCNs. Instead, Rayo is the first protocol for PCNs that\nenforces non-blocking progress (i.e., at least one of the concurrent payments\nterminates). We show through a new impossibility result that non-blocking\nprogress necessarily comes at the cost of weaker privacy. At the core of Fulgor\nand Rayo is Multi-Hop HTLC, a new smart contract, compatible with the Bitcoin\nscripting system, that provides conditional payments while reducing running\ntime and communication overhead with respect to previous approaches.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 19:54:54 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Malavolta", "Giulio", ""], ["Moreno-Sanchez", "Pedro", ""], ["Kate", "Aniket", ""], ["Maffei", "Matteo", ""], ["Ravi", "Srivatsan", ""]]}, {"id": "1911.09176", "submitter": "Luowen Qian", "authors": "Kai-Min Chung, Tai-Ning Liao, Luowen Qian", "title": "Lower Bounds for Function Inversion with Quantum Advice", "comments": "ITC full version", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.CR cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Function inversion is the problem that given a random function $f: [M] \\to\n[N]$, we want to find pre-image of any image $f^{-1}(y)$ in time $T$. In this\nwork, we revisit this problem under the preprocessing model where we can\ncompute some auxiliary information or advice of size $S$ that only depends on\n$f$ but not on $y$. It is a well-studied problem in the classical settings,\nhowever, it is not clear how quantum algorithms can solve this task any better\nbesides invoking Grover's algorithm, which does not leverage the power of\npreprocessing.\n  Nayebi et al. proved a lower bound $ST^2 \\ge \\tilde\\Omega(N)$ for quantum\nalgorithms inverting permutations, however, they only consider algorithms with\nclassical advice. Hhan et al. subsequently extended this lower bound to fully\nquantum algorithms for inverting permutations. In this work, we give the same\nasymptotic lower bound to fully quantum algorithms for inverting functions for\nfully quantum algorithms under the regime where $M = O(N)$.\n  In order to prove these bounds, we generalize the notion of quantum random\naccess code, originally introduced by Ambainis et al., to the setting where we\nare given a list of (not necessarily independent) random variables, and we wish\nto compress them into a variable-length encoding such that we can retrieve a\nrandom element just using the encoding with high probability. As our main\ntechnical contribution, we give a nearly tight lower bound (for a wide\nparameter range) for this generalized notion of quantum random access codes,\nwhich may be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 21:13:26 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 05:23:57 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Chung", "Kai-Min", ""], ["Liao", "Tai-Ning", ""], ["Qian", "Luowen", ""]]}, {"id": "1911.09215", "submitter": "Saba Eskandarian", "authors": "Saba Eskandarian, Henry Corrigan-Gibbs, Matei Zaharia, Dan Boneh", "title": "Express: Lowering the Cost of Metadata-hiding Communication with\n  Cryptographic Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing systems for metadata-hiding messaging that provide cryptographic\nprivacy properties have either high communication costs, high computation\ncosts, or both. In this paper, we introduce Express, a metadata-hiding\ncommunication system that significantly reduces both communication and\ncomputation costs. Express is a two-server system that provides cryptographic\nsecurity against an arbitrary number of malicious clients and one malicious\nserver. In terms of communication, Express only incurs a constant-factor\noverhead per message sent regardless of the number of users, whereas previous\ncryptographically-secure systems Pung and Riposte had communication costs\nproportional to roughly the square root of the number of users. In terms of\ncomputation, Express only uses symmetric key cryptographic primitives and makes\nboth practical and asymptotic improvements on protocols employed by prior work.\nThese improvements enable Express to increase message throughput, reduce\nlatency, and consume over 100x less bandwidth than Pung and Riposte, dropping\nthe end to end cost of running a realistic whistleblowing application by 6x.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 23:29:55 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 15:44:05 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Eskandarian", "Saba", ""], ["Corrigan-Gibbs", "Henry", ""], ["Zaharia", "Matei", ""], ["Boneh", "Dan", ""]]}, {"id": "1911.09222", "submitter": "Saba Eskandarian", "authors": "Saba Eskandarian, Mihai Christodorescu, Payman Mohassel", "title": "Privacy-Preserving Payment Splitting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Widely used payment splitting apps allow members of a group to keep track of\ndebts between members by sending charges for expenses paid by one member on\nbehalf of others. While offering a great deal of convenience, these apps gain\naccess to sensitive data on users' financial transactions. In this paper, we\npresent a payment splitting app that hides all transaction data within a group\nfrom the service provider, provides privacy protections between users in a\ngroup, and provides integrity against malicious users or even a malicious\nserver.\n  The core protocol proceeds in a series of rounds in which users either submit\nreal data or cover traffic, and the server blindly updates balances, informs\nusers of charges, and computes integrity checks on user-submitted data. Our\nprotocol requires no cryptographic operations on the server, and after a\ngroup's initial setup, the only cryptographic tool users need is AES.\n  We implement the payment splitting protocol as an Android app and the\naccompanying server. We find that, for realistic group sizes, it requires fewer\nthan 50 milliseconds per round of computation on a user's phone and the server\nrequires fewer than 300 microseconds per round for each group, meaning that our\nprotocol enjoys excellent performance and scalability properties.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 23:53:23 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Eskandarian", "Saba", ""], ["Christodorescu", "Mihai", ""], ["Mohassel", "Payman", ""]]}, {"id": "1911.09262", "submitter": "Yao Sun", "authors": "Yao Sun, Aayush Rajasekaran", "title": "An Interleaving Hybrid Consensus Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Unity Interleave, a new consensus algorithm for public\nblockchain settings. It is an eventual consistency protocol merging the\nProof-of-Work (PoW) and Proof-of-Stake (PoS) into a coherent stochastic\nprocess. It builds upon research previously done for the Unity protocol,\nimproving security while maintaining fairness and scalability.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 03:12:44 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Sun", "Yao", ""], ["Rajasekaran", "Aayush", ""]]}, {"id": "1911.09305", "submitter": "Hung Dang", "authors": "Hung Dang and Ee-Chien Chang", "title": "Self-Expiring Data Capsule using Trusted Execution Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data privacy is unarguably of extreme importance. Nonetheless, there exist\nvarious daunting challenges to safe-guarding data privacy. These challenges\nstem from the fact that data owners have little control over their data once it\nhas transgressed their local storage and been managed by third parties whose\ntrustworthiness is questionable at times. Our work seeks to enhance data\nprivacy by constructing a self-expiring data capsule. Sensitive data is\nencapsulated into a capsule which is associated with an access policy an\nexpiring condition. The former indicates eligibility of functions that can\naccess the data, and the latter dictates when the data should become\ninaccessible to anyone, including the previously eligible functions. Access to\nthe data capsule, as well as its dismantling once the expiring condition is\nmet, are governed by a committee of independent and mutually distrusting nodes.\nThe pivotal contribution of our work is an integration of hardware primitive,\nstate machine replication and threshold secret sharing in the design of the\nself-expiring data encapsulation framework. We implement the proposed framework\nin a system called TEEKAP. Our empirical experiments conducted on a realistic\ndeployment setting with the access control committee spanning across four\ngeographical regions reveal that TEEKAP can process access requests at scale\nwith sub-second latency.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 06:17:55 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Dang", "Hung", ""], ["Chang", "Ee-Chien", ""]]}, {"id": "1911.09312", "submitter": "Tianwei Zhang", "authors": "Tianwei Zhang and Jun Jiang and Yinqian Zhang", "title": "Revisiting and Evaluating Software Side-channel Vulnerabilities and\n  Countermeasures in Cryptographic Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We systematize software side-channel attacks with a focus on vulnerabilities\nand countermeasures in the cryptographic implementations. Particularly, we\nsurvey past research literature to categorize vulnerable implementations, and\nidentify common strategies to eliminate them. We then evaluate popular\nlibraries and applications, quantitatively measuring and comparing the\nvulnerability severity, response time and coverage. Based on these\ncharacterizations and evaluations, we offer some insights for side-channel\nresearchers, cryptographic software developers and users. We hope our study can\ninspire the side-channel research community to discover new vulnerabilities,\nand more importantly, to fortify applications against them.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 07:09:40 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 15:54:08 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Zhang", "Tianwei", ""], ["Jiang", "Jun", ""], ["Zhang", "Yinqian", ""]]}, {"id": "1911.09329", "submitter": "Lavish Saluja", "authors": "Lavish Saluja, Ashutosh Bhatia", "title": "Zero Knowledge Proof based authentication protocol using graph\n  isomorphism", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We live in an era of information and it is very important to handle the\nexchange of information. While sending data to an authorized source, we need to\nprotect it from unauthorized sources, changes, and authentication. ZKP\ntechnique can be used in designing secure authentication systems that dont\ninvolve any direct exchange of information between the claimant and the\nverifier thus preventing any possible leak of personal information. We propose\na Zero-Knowledge Proof (ZKP) algorithm based on isomorphic graphs. We suggest\nmost of the computations should be carried out on the users' web browser\nwithout revealing the password to the server at any point in time. Instead, it\nwill generate random graphs and their permutations based on the login ID and\npassword.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 08:13:47 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Saluja", "Lavish", ""], ["Bhatia", "Ashutosh", ""]]}, {"id": "1911.09404", "submitter": "Martin Barrere", "authors": "Mart\\'in Barr\\`ere, Chris Hankin, Demetrios G. Eliades, Nicolas\n  Nicolau, Thomas Parisini", "title": "Assessing Cyber-Physical Security in Industrial Control Systems", "comments": "10 pages, 10 figures. Keywords: security metrics, cyber-physical\n  security, AND-OR graphs, hypergraphs, MAX-SAT resolution, ICS, CPS", "journal-ref": "6th International Symposium for ICS & SCADA Cyber Security\n  Research 2019 (ICS-CSR), pp. 49-58 (2019)", "doi": "10.14236/ewic/icscsr19.7", "report-no": null, "categories": "cs.CR cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last years, Industrial Control Systems (ICS) have become\nincreasingly exposed to a wide range of cyber-physical threats. Efficient\nmodels and techniques able to capture their complex structure and identify\ncritical cyber-physical components are therefore essential. AND/OR graphs have\nproven very useful in this context as they are able to semantically grasp\nintricate logical interdependencies among ICS components. However, identifying\ncritical nodes in AND/OR graphs is an NP-complete problem. In addition, ICS\nsettings normally involve various cyber and physical security measures that\nsimultaneously protect multiple ICS components in overlapping manners, which\nmakes this problem even harder. In this paper, we present an extended security\nmetric based on AND/OR hypergraphs which efficiently identifies the set of\ncritical ICS components and security measures that should be compromised, with\nminimum cost (effort) for an attacker, in order to disrupt the operation of\nvital ICS assets. Our approach relies on MAX-SAT techniques, which we have\nincorporated in META4ICS, a Java-based security metric analyser for ICS. We\nalso provide a thorough performance evaluation that shows the feasibility of\nour method. Finally, we illustrate our methodology through a case study in\nwhich we analyse the security posture of a realistic Water Transport Network\n(WTN).\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 11:02:48 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Barr\u00e8re", "Mart\u00edn", ""], ["Hankin", "Chris", ""], ["Eliades", "Demetrios G.", ""], ["Nicolau", "Nicolas", ""], ["Parisini", "Thomas", ""]]}, {"id": "1911.09432", "submitter": "Istv\\'an Andr\\'as Seres", "authors": "Ferenc Beres, Istvan Andras Seres, Andras A. Benczur", "title": "A Cryptoeconomic Traffic Analysis of Bitcoin's Lightning Network", "comments": "Cryptoeconomic Systems (CES) '20 Journal & Conference 7-8 March 2020,\n  MIT, Cambridge, MA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lightning Network (LN) is designed to amend the scalability and privacy\nissues of Bitcoin. It's a payment channel network where Bitcoin transactions\nare issued off chain, onion routed through a private payment path with the aim\nto settle transactions in a faster, cheaper, and private manner, as they're not\nrecorded in a costly-to-maintain, slow, and public ledger. In this work, we\ndesign a traffic simulator to empirically study LN's transaction fees and\nprivacy provisions. The simulator relies on publicly available data of the\nnetwork structure and generates transactions under assumptions we attempt to\nvalidate based on information spread by certain blog posts of LN node owners.\nOur findings on the estimated revenue from transaction fees are in line with\nwidespread opinion that participation is economically irrational for the\nmajority of large routing nodes who currently hold the network together. Either\ntraffic or transaction fees must increase by orders of magnitude to make\npayment routing economically viable. We give worst-case estimates for the\npotential fee increase by assuming strong price competition among the routers.\nWe estimate how current channel structures and pricing policies respond to a\npotential increase in traffic, how reduction in locked funds on channels would\naffect the network, and show examples of nodes who are estimated to operate\nwith economically feasible revenue. Even if transactions are onion routed,\nstrong statistical evidence on payment source and destination can be inferred,\nas many transaction paths only consist of a single intermediary by the side\neffect of LN's small-world nature. Based on our simulation experiments, we\nquantitatively characterize the privacy shortcomings of current LN operation,\nand propose a method to inject additional hops in routing paths to demonstrate\nhow privacy can be strengthened with very little additional transactional cost.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 12:12:18 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 07:43:19 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 17:39:24 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Beres", "Ferenc", ""], ["Seres", "Istvan Andras", ""], ["Benczur", "Andras A.", ""]]}, {"id": "1911.09508", "submitter": "Szilvia Lestyan", "authors": "Mina Remeli, Szilvia Lestyan, Gergely Acs, and Gergely Biczok", "title": "Automatic Driver Identification from In-Vehicle Network Logs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data generated by cars is growing at an unprecedented scale. As cars\ngradually become part of the Internet of Things (IoT) ecosystem, several\nstakeholders discover the value of in-vehicle network logs containing the\nmeasurements of the multitude of sensors deployed within the car. This wealth\nof data is also expected to be exploitable by third parties for the purpose of\nprofiling drivers in order to provide personalized, valueadded services.\nAlthough several prior works have successfully demonstrated the feasibility of\ndriver re-identification using the in-vehicle network data captured on the\nvehicle's CAN (Controller Area Network) bus, they inferred the identity of the\ndriver only from known sensor signals (such as the vehicle's speed, brake pedal\nposition, steering wheel angle, etc.) extracted from the CAN messages. However,\ncar manufacturers intentionally do not reveal exact signal location and\nsemantics within CAN logs. We show that the inference of driver identity is\npossible even with off-the-shelf machine learning techniques without\nreverse-engineering the CAN protocol. We demonstrate our approach on a dataset\nof 33 drivers and show that a driver can be re-identified and distinguished\nfrom other drivers with an accuracy of 75-85%.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 15:28:08 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Remeli", "Mina", ""], ["Lestyan", "Szilvia", ""], ["Acs", "Gergely", ""], ["Biczok", "Gergely", ""]]}, {"id": "1911.09564", "submitter": "Kwang-Sung Jun", "authors": "Kwang-Sung Jun, Francesco Orabona", "title": "Parameter-Free Locally Differentially Private Stochastic Subgradient\n  Descent", "comments": "to appear at Privacy in Machine Learning (PriML) workshop, NeurIPS'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of minimizing a convex risk with stochastic\nsubgradients guaranteeing $\\epsilon$-locally differentially private\n($\\epsilon$-LDP). While it has been shown that stochastic optimization is\npossible with $\\epsilon$-LDP via the standard SGD (Song et al., 2013), its\nconvergence rate largely depends on the learning rate, which must be tuned via\nrepeated runs. Further, tuning is detrimental to privacy loss since it\nsignificantly increases the number of gradient requests. In this work, we\npropose BANCO (Betting Algorithm for Noisy COins), the first $\\epsilon$-LDP SGD\nalgorithm that essentially matches the convergence rate of the tuned SGD\nwithout any learning rate parameter, reducing privacy loss and saving privacy\nbudget.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 15:58:17 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Jun", "Kwang-Sung", ""], ["Orabona", "Francesco", ""]]}, {"id": "1911.09575", "submitter": "Anca Jurcut Dr.", "authors": "Guerrino Mazzarolo, Anca Delia Jurcut", "title": "Insider threats in Cyber Security: The enemy within the gates", "comments": null, "journal-ref": "EUROPEAN CYBERSECURITY JOURNAL, February 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insider threats have become reality for civilian firms such as Tesla, which\nexperienced sabotage and intellectual property theft, and Capital One, which\nsuffered from fraud. Even greater social impact was caused by the data breach\nat the US Department of Defense, perpetrated by well-known attackers Chelsea\nManning and Edward Snowden, whose espionage and hacktivist activities are\nwidely known. The dramatic increase of such incidents in recent years and the\nincalculable damage committed by insiders must serve as a warning for all\nmembers of the cyber security community. It is no longer acceptable to continue\nto underestimate the problem of insider threats. Firms, organizations,\ninstitutions and governments need to lead and embrace a cultural change in\ntheir security posture. Through the adoption of an Insider Threat Program that\nengages all the strategic branches (including HR, Legal, Information Assurance,\nCyber Security and Intelligence), coordinated by the chief information security\nofficer and supported by c-level executive, it is possible to implement a\nframework that can prevent, detect, and respond to disloyal and/or\nunintentional insider threats. Hence, defending your enterprise from insider\nthreats is a vital part of information security best practices. It is essential\nthat your company highly valuable classified data and assets are protected from\nits greatest threat: the enemy within the gates.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 16:09:21 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Mazzarolo", "Guerrino", ""], ["Jurcut", "Anca Delia", ""]]}, {"id": "1911.09586", "submitter": "Akbar Siami Namin", "authors": "Faranak Abri and Sima Siami-Namini and Mahdi Adl Khanghah and Fahimeh\n  Mirza Soltani and Akbar Siami Namin", "title": "The Performance of Machine and Deep Learning Classifiers in Detecting\n  Zero-Day Vulnerabilities", "comments": "8 pages, 2 figures, 3 tables, IEEE BigData 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of zero-day attacks and vulnerabilities is a challenging\nproblem. It is of utmost importance for network administrators to identify them\nwith high accuracy. The higher the accuracy is, the more robust the defense\nmechanism will be. In an ideal scenario (i.e., 100% accuracy) the system can\ndetect zero-day malware without being concerned about mistakenly tagging benign\nfiles as malware or enabling disruptive malicious code running as\nnone-malicious ones. This paper investigates different machine learning\nalgorithms to find out how well they can detect zero-day malware. Through the\nexamination of 34 machine/deep learning classifiers, we found that the random\nforest classifier offered the best accuracy. The paper poses several research\nquestions regarding the performance of machine and deep learning algorithms\nwhen detecting zero-day malware with zero rates for false positive and false\nnegative.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 16:25:44 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Abri", "Faranak", ""], ["Siami-Namini", "Sima", ""], ["Khanghah", "Mahdi Adl", ""], ["Soltani", "Fahimeh Mirza", ""], ["Namin", "Akbar Siami", ""]]}, {"id": "1911.09642", "submitter": "Hooman Mohajeri Moghaddam", "authors": "Hooman Mohajeri Moghaddam, Arsalan Mosenia", "title": "Anonymizing Masses: Practical Light-weight Anonymity at the Network\n  Level", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an era of pervasive online surveillance, Internet users are in need of\nbetter anonymity solutions for online communications without sacrificing\nperformance. Existing overlay anonymity tools, such as the Tor network, suffer\nfrom performance limitations and recent proposals to embed anonymity into\nInternet protocols face fundamental deployment challenges. In this paper, we\nintroduce Practical Anonymity at the NEtwork Level (PANEL), a practical\nlight-weight anonymity solution based on hardware switching. We implement a\nprototype of PANEL on a high-performance hardware switch (namely, Barefoot\nTofino) using P4 network programming language, and examine the validity and\nperformance of the prototype. Based on our empirical results, PANEL achieves\n96% of the actual throughput of the switch and adds a low-latency overhead\n(e.g., 3% overhead in Skype calls), while offering partial deployablility and\ntransparency (i.e., PANEL requires neither client-side nor server-side\nmodifications).\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 17:58:53 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Moghaddam", "Hooman Mohajeri", ""], ["Mosenia", "Arsalan", ""]]}, {"id": "1911.09716", "submitter": "Sumaya Almanee", "authors": "Sumaya Almanee, Arda Unal, Mathias Payer, Joshua Garcia", "title": "Too Quiet in the Library: An Empirical Study of Security Updates in\n  Android Apps' Native Code", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android apps include third-party native libraries to increase performance and\nto reuse functionality. Native code is directly executed from apps through the\nJava Native Interface or the Android Native Development Kit. Android developers\nadd precompiled native libraries to their projects, enabling their use.\nUnfortunately, developers often struggle or simply neglect to update these\nlibraries in a timely manner. This results in the continuous use of outdated\nnative libraries with unpatched security vulnerabilities years after patches\nbecame available.\n  To further understand such phenomena, we study the security updates in native\nlibraries in the most popular 200 free apps on Google Play from Sept. 2013 to\nMay 2020. A core difficulty we face in this study is the identification of\nlibraries and their versions. Developers often rename or modify libraries,\nmaking their identification challenging. We create an approach called LibRARIAN\n(LibRAry veRsion IdentificAtioN) that accurately identifies native libraries\nand their versions as found in Android apps based on our novel similarity\nmetric bin2sim. LibRARIAN leverages different features extracted from libraries\nbased on their metadata and identifying strings in read-only sections.\n  We discovered 53/200 popular apps (26.5%) with vulnerable versions with known\nCVEs between Sept. 2013 and May 2020, with 14 of those apps remaining\nvulnerable. We find that app developers took, on average, 528.71 days to apply\nsecurity patches, while library developers release a security patch after 54.59\ndays - a 10 times slower rate of update.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 19:29:42 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 03:19:26 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Almanee", "Sumaya", ""], ["Unal", "Arda", ""], ["Payer", "Mathias", ""], ["Garcia", "Joshua", ""]]}, {"id": "1911.09777", "submitter": "Stacey Truex", "authors": "Stacey Truex, Ling Liu, Mehmet Emre Gursoy, Wenqi Wei, Lei Yu", "title": "Effects of Differential Privacy and Data Skewness on Membership\n  Inference Vulnerability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Membership inference attacks seek to infer the membership of individual\ntraining instances of a privately trained model. This paper presents a\nmembership privacy analysis and evaluation system, called MPLens, with three\nunique contributions. First, through MPLens, we demonstrate how membership\ninference attack methods can be leveraged in adversarial machine learning.\nSecond, through MPLens, we highlight how the vulnerability of pre-trained\nmodels under membership inference attack is not uniform across all classes,\nparticularly when the training data itself is skewed. We show that risk from\nmembership inference attacks is routinely increased when models use skewed\ntraining data. Finally, we investigate the effectiveness of differential\nprivacy as a mitigation technique against membership inference attacks. We\ndiscuss the trade-offs of implementing such a mitigation strategy with respect\nto the model complexity, the learning task complexity, the dataset complexity\nand the privacy parameter settings. Our empirical results reveal that (1)\nminority groups within skewed datasets display increased risk for membership\ninference and (2) differential privacy presents many challenging trade-offs as\na mitigation technique to membership inference risk.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 22:54:40 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Truex", "Stacey", ""], ["Liu", "Ling", ""], ["Gursoy", "Mehmet Emre", ""], ["Wei", "Wenqi", ""], ["Yu", "Lei", ""]]}, {"id": "1911.09824", "submitter": "Ren Bing", "authors": "Shengwen Yang, Bing Ren, Xuhui Zhou, Liping Liu", "title": "Parallel Distributed Logistic Regression for Vertical Federated Learning\n  without Third-Party Coordinator", "comments": "IJCAI-19 Workshop on Federated Machine Learning for User Privacy and\n  Data Confidentiality (IJCAI (FML)) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning is a new distributed learning mechanism which allows model\ntraining on a large corpus of decentralized data owned by different data\nproviders, without sharing or leakage of raw data. According to the\ncharacteristics of data dis-tribution, it could be usually classified into\nthree categories: horizontal federated learning, vertical federated learning,\nand federated transfer learning. In this paper we present a solution for\nparallel dis-tributed logistic regression for vertical federated learning. As\ncompared with existing works, the role of third-party coordinator is removed in\nour proposed solution. The system is built on the pa-rameter server\narchitecture and aims to speed up the model training via utilizing a cluster of\nservers in case of large volume of training data. We also evaluate the\nperformance of the parallel distributed model training and the experimental\nresults show the great scalability of the system.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 02:57:01 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Yang", "Shengwen", ""], ["Ren", "Bing", ""], ["Zhou", "Xuhui", ""], ["Liu", "Liping", ""]]}, {"id": "1911.09853", "submitter": "Sheikh Rabiul Islam", "authors": "Sheikh Rabiul Islam, William Eberle, Sheikh K. Ghafoor, Ambareen\n  Siraj, and Mike Rogers", "title": "Domain Knowledge Aided Explainable Artificial Intelligence for Intrusion\n  Detection and Response", "comments": "Accepted to be published in the Proceedings of the AAAI 2020 Spring\n  Symposium on Combining Machine Learning and Knowledge Engineering in Practice\n  (AAAI-MAKE 2020). Stanford University, Palo Alto, California, USA, March\n  23-25, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) has become an integral part of modern-day\nsecurity solutions for its ability to learn very complex functions and handling\n\"Big Data\". However, the lack of explainability and interpretability of\nsuccessful AI models is a key stumbling block when trust in a model's\nprediction is critical. This leads to human intervention, which in turn results\nin a delayed response or decision. While there have been major advancements in\nthe speed and performance of AI-based intrusion detection systems, the response\nis still at human speed when it comes to explaining and interpreting a specific\nprediction or decision. In this work, we infuse popular domain knowledge (i.e.,\nCIA principles) in our model for better explainability and validate the\napproach on a network intrusion detection test case. Our experimental results\nsuggest that the infusion of domain knowledge provides better explainability as\nwell as a faster decision or response. In addition, the infused domain\nknowledge generalizes the model to work well with unknown attacks, as well as\nopens the path to adapt to a large stream of network traffic from numerous IoT\ndevices.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 04:36:46 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 18:11:36 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Islam", "Sheikh Rabiul", ""], ["Eberle", "William", ""], ["Ghafoor", "Sheikh K.", ""], ["Siraj", "Ambareen", ""], ["Rogers", "Mike", ""]]}, {"id": "1911.09870", "submitter": "Huy Kang Kim", "authors": "Kyung Ho Park, Huy Kang Kim", "title": "This Car is Mine!: Automobile Theft Countermeasure Leveraging Driver\n  Identification with Generative Adversarial Networks", "comments": "6 pages, 3 figures, 3 tables, In Proceedings of the escar Asia 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a car becomes more connected, a countermeasure against automobile theft\nhas become a significant task in the real world. To respond to automobile\ntheft, data mining, biometrics, and additional authentication methods are\nproposed. Among current countermeasures, data mining method is one of the\nefficient ways to capture the owner driver's unique characteristics. To\nidentify the owner driver from thieves, previous works applied various\nalgorithms toward driving data. Such data mining methods utilized supervised\nlearning, thus required labeled data set. However, it is unrealistic to gather\nand apply the thief's driving pattern. To overcome this problem, we propose\ndriver identification method with GAN. GAN has merit to build identification\nmodel by learning the owner driver's data only. We trained GAN only with owner\ndriver's data and used trained discriminator to identify the owner driver. From\nactual driving data, we evaluated our identification model recognizes the owner\ndriver well. By ensembling various driver authentication methods with the\nproposed model, we expect industry can develop automobile theft countermeasures\navailable in the real world.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 06:00:18 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Park", "Kyung Ho", ""], ["Kim", "Huy Kang", ""]]}, {"id": "1911.09872", "submitter": "Ghazaleh Beigi", "authors": "Ghazaleh Beigi, Ahmadreza Mosallanezhad, Ruocheng Guo, Hamidreza\n  Alvari, Alexander Nou, Huan Liu", "title": "Privacy-Aware Recommendation with Private-Attribute Protection using\n  Adversarial Learning", "comments": "The Thirteenth ACM International Conference on Web Search and Data\n  Mining (WSDM 2020)", "journal-ref": null, "doi": "10.1145/3336191.3371832", "report-no": null, "categories": "cs.SI cs.CR cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation is one of the critical applications that helps users find\ninformation relevant to their interests. However, a malicious attacker can\ninfer users' private information via recommendations. Prior work obfuscates\nuser-item data before sharing it with recommendation system. This approach does\nnot explicitly address the quality of recommendation while performing data\nobfuscation. Moreover, it cannot protect users against private-attribute\ninference attacks based on recommendations. This work is the first attempt to\nbuild a Recommendation with Attribute Protection (RAP) model which\nsimultaneously recommends relevant items and counters private-attribute\ninference attacks. The key idea of our approach is to formulate this problem as\nan adversarial learning problem with two main components: the private attribute\ninference attacker, and the Bayesian personalized recommender. The attacker\nseeks to infer users' private-attribute information according to their items\nlist and recommendations. The recommender aims to extract users' interests\nwhile employing the attacker to regularize the recommendation process.\nExperiments show that the proposed model both preserves the quality of\nrecommendation service and protects users against private-attribute inference\nattacks.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 06:22:21 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Beigi", "Ghazaleh", ""], ["Mosallanezhad", "Ahmadreza", ""], ["Guo", "Ruocheng", ""], ["Alvari", "Hamidreza", ""], ["Nou", "Alexander", ""], ["Liu", "Huan", ""]]}, {"id": "1911.09881", "submitter": "Marcel Kneib", "authors": "Marcel Kneib, Oleg Schell, Christopher Huth", "title": "On the Robustness of Signal Characteristic-Based Sender Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicles become more vulnerable to remote attackers in modern days due to\ntheir increasing connectivity and range of functionality. Such increased attack\nvectors enable adversaries to access a vehicle Electronic Control Unit (ECU).\nAs of today in-vehicle access can cause drastic consequences, because the most\ncommonly used in-vehicle bus technology, the Controller Area Network (CAN),\nlacks sender identification. With low limits on bandwidth and payload, as well\nas resource constrains on hardware, usage of cryptographic measures is limited.\nAs an alternative, sender identification methods were presented, identifying\nthe sending ECU on the basis of its analog message signal. While prior works\nshowed promising results on the security and feasibility for those approaches,\nthe potential changes in signals over a vehicle's lifetime have only been\npartly addressed. This paper closes this gap. We conduct a 4~months measurement\ncampaign containing more than 80,000 frames from a real vehicle. The data\nreflects different driving situations, different seasons and weather\nconditions, a 19-week break, and a car repair altering the physical CAN\nproperties. We demonstrate the impact of temperature dependencies, analyze the\nsignal changes and define strategies for their handling. In the evaluation, the\nidentification rate can be increased from 91.23% to 99.98% by a targeted\nupdating of the system parameters. At the same time, the detection of\nintrusions can be improved from 76.83% to 99.74%, while no false positives\noccured during evaluation. Lastly, we show how to increase the overall\nperformance of such systems by double monitoring the bus at different\npositions.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 06:41:15 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Kneib", "Marcel", ""], ["Schell", "Oleg", ""], ["Huth", "Christopher", ""]]}, {"id": "1911.09903", "submitter": "Alperen Kantarc{\\i}", "authors": "Rumeysa Bulut, Alperen Kantarc{\\i}, Safa Keskin, \\c{S}erif Bahtiyar", "title": "Blockchain-Based Electronic Voting System for Elections in Turkey", "comments": "4 pages, 4 figures, IEEE style", "journal-ref": "2019 4th International Conference on Computer Science and\n  Engineering (UBMK) (2019) 183-188", "doi": "10.1109/UBMK.2019.8907102", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional elections satisfy neither citizens nor political authorities in\nrecent years. They are not fully secure since it is easy to attack votes. It\nthreatens also privacy and transparency of voters. Additionally, it takes too\nmuch time to count the votes. This paper proposes a solution using Blockchain\nto eliminate all the disadvantages of conventional elections. Security and data\nintegrity of votes are absolutely provided theoretically. Voter privacy is\nanother requirement that is ensured in the system. Lastly, the waiting time for\nresults decreased significantly in the proposed Blockchain voting system.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 07:40:34 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Bulut", "Rumeysa", ""], ["Kantarc\u0131", "Alperen", ""], ["Keskin", "Safa", ""], ["Bahtiyar", "\u015eerif", ""]]}, {"id": "1911.09945", "submitter": "Chaitanya Joshi Dr.", "authors": "Chaitanya Joshi, David Rios Insua, Jesus Rios", "title": "Insider threat modeling: An adversarial risk analysis approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Insider threats entail major security issues in geopolitics, cyber risk\nmanagement and business organization. The game theoretic models proposed so far\ndo not take into account some important factors such as the organisational\nculture and whether the attacker was detected or not. They also fail to model\nthe defensive mechanisms already put in place by an organisation to mitigate an\ninsider attack. We propose two new models which incorporate these settings and\nhence are more realistic. %Most earlier work in the field has focused on\n%standard game theoretic approaches to find the solutions. We use the\nadversarial risk analysis (ARA) approach to find the solution to our models.\nARA does not assume common knowledge and solves the problem from the point of\nview of one of the players, taking into account their knowledge and\nuncertainties regarding the choices available to them, to their adversaries,\nthe possible outcomes, their utilities and their opponents' utilities. Our\nmodels and the ARA solutions are general and can be applied to most insider\nthreat scenarios. A data security example illustrates the discussion.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 09:46:51 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Joshi", "Chaitanya", ""], ["Insua", "David Rios", ""], ["Rios", "Jesus", ""]]}, {"id": "1911.09964", "submitter": "C\\'elestin Matte", "authors": "C\\'elestin Matte, Nataliia Bielova, Cristiana Santos", "title": "Do Cookie Banners Respect my Choice? Measuring Legal Compliance of\n  Banners from IAB Europe's Transparency and Consent Framework", "comments": null, "journal-ref": "IEEE S&P 2020", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As a result of the GDPR and the ePrivacy Directive, European users encounter\ncookie banners on almost every website. Many of such banners are implemented by\nConsent Management Providers (CMPs), who respect the IAB Europe's Transparency\nand Consent Framework (TCF). Via cookie banners, CMPs collect and disseminate\nuser consent to third parties. In this work, we systematically study IAB\nEurope's TCF and analyze consent stored behind the user interface of TCF cookie\nbanners. We analyze the GDPR and the ePrivacy Directive to identify legal\nviolations in implementations of cookie banners based on the storage of consent\nand detect such violations by crawling 22 949 European websites. With two\nautomatic and semi-automatic crawl campaigns, we detect violations, and we find\nthat: 141 websites register positive consent even if the user has not made\ntheir choice; 236 websites nudge the users towards accepting consent by\npre-selecting options; and 27 websites store a positive consent even if the\nuser has explicitly opted out. Performing extensive tests on 560 websites, we\nfind at least one violation in 54% of them. Finally, we provide a browser\nextension to facilitate manual detection of violations for regular users and\nData Protection Authorities.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 10:43:55 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 10:01:36 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Matte", "C\u00e9lestin", ""], ["Bielova", "Nataliia", ""], ["Santos", "Cristiana", ""]]}, {"id": "1911.10035", "submitter": "Philip Stark", "authors": "Philip B. Stark", "title": "Sets of Half-Average Nulls Generate Risk-Limiting Audits: SHANGRLA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Risk-limiting audits (RLAs) for many social choice functions can be reduced\nto testing sets of null hypotheses of the form \"the average of this list is not\ngreater than 1/2\" for a collection of finite lists of nonnegative numbers. Such\nsocial choice functions include majority, super-majority, plurality,\nmulti-winner plurality, Instant Runoff Voting (IRV), Borda count, approval\nvoting, and STAR-Voting, among others. The audit stops without a full hand\ncount iff all the null hypotheses are rejected. The nulls can be tested in many\nways. Ballot-polling is particularly simple; two new ballot-polling\nrisk-measuring functions for sampling without replacement are given.\nBallot-level comparison audits transform each null into an equivalent assertion\nthat the mean of re-scaled tabulation errors is not greater than 1/2. In turn,\nthat null can then be tested using the same statistical methods used for ballot\npolling---but applied to different finite lists of nonnegative numbers.\nSHANGRLA comparison audits are more efficient than previous comparison audits\nfor two reasons: (i) for most social choice functions, the conditions tested\nare both necessary and sufficient for the reported outcome to be correct, while\nprevious methods tested conditions that were sufficient but not necessary, and\n(ii) the tests avoid a conservative approximation. The SHANGRLA abstraction\nsimplifies stratified audits, including audits that combine ballot polling with\nballot-level comparisons, producing sharper audits than the \"SUITE\" approach.\nSHANGRLA works with the \"phantoms to evil zombies\" strategy to treat missing\nballot cards and missing or redacted cast vote records. That also facilitates\nsampling from \"ballot-style manifests,\" which can dramatically improve\nefficiency when the audited contests do not appear on every ballot card.\nOpen-source software implementing SHANGRLA ballot-level comparison audits is\navailable.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 13:32:46 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 06:38:43 GMT"}, {"version": "v3", "created": "Sat, 1 Feb 2020 21:51:34 GMT"}, {"version": "v4", "created": "Tue, 24 Mar 2020 20:48:56 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Stark", "Philip B.", ""]]}, {"id": "1911.10071", "submitter": "Aleksei Triastcyn", "authors": "Aleksei Triastcyn, Boi Faltings", "title": "Federated Learning with Bayesian Differential Privacy", "comments": "Accepted at 2019 IEEE International Conference on Big Data (IEEE Big\n  Data 2019). 10 pages, 2 figures, 4 tables. arXiv admin note: text overlap\n  with arXiv:1901.09697", "journal-ref": null, "doi": "10.1109/BigData47090.2019.9005465", "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of reinforcing federated learning with formal privacy\nguarantees. We propose to employ Bayesian differential privacy, a relaxation of\ndifferential privacy for similarly distributed data, to provide sharper privacy\nloss bounds. We adapt the Bayesian privacy accounting method to the federated\nsetting and suggest multiple improvements for more efficient privacy budgeting\nat different levels. Our experiments show significant advantage over the\nstate-of-the-art differential privacy bounds for federated learning on image\nclassification tasks, including a medical application, bringing the privacy\nbudget below 1 at the client level, and below 0.1 at the instance level. Lower\namounts of noise also benefit the model accuracy and reduce the number of\ncommunication rounds.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 14:54:04 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Triastcyn", "Aleksei", ""], ["Faltings", "Boi", ""]]}, {"id": "1911.10100", "submitter": "Rui Zhang", "authors": "Rui Zhang and Quanyan Zhu", "title": "FlipIn: A Game-Theoretic Cyber Insurance Framework for\n  Incentive-Compatible Cyber Risk Management of Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) is highly vulnerable to emerging Advanced Persistent\nThreats (APTs) that are often operated by well-resourced adversaries. Achieving\nperfect security for IoT networks is often cost-prohibitive if not impossible.\nCyber insurance is a valuable mechanism to mitigate cyber risks for IoT\nsystems. In this work, we propose a bi-level game-theoretic framework called\nFlipIn to design incentive-compatible and welfare-maximizing cyber insurance\ncontracts. The framework captures the strategic interactions among APT\nattackers, IoT defenders, and cyber insurance insurers, and incorporates\ninfluence networks to assess the systemic cyber risks of interconnected IoT\ndevices. The FlipIn framework formulates a game over networks within a\nprincipal-agent problem of moral-hazard type to design a cyber risk-aware\ninsurance contract. We completely characterize the equilibrium solutions of the\nbi-level games for a network of distributed defenders and a semi-homogeneous\ncentralized defender and show that the optimal insurance contracts cover half\nof the defenders' losses. Our framework predicts the risk compensation of\ndefenders and the Peltzman effect of insurance. We study a centralized security\nmanagement scenario and its decentralized counterpart, and leverage numerical\nexperiments to show that network connectivity plays an important role in the\nsecurity of the IoT devices and the insurability of both distributed and\ncentralized defenders.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 15:54:46 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Zhang", "Rui", ""], ["Zhu", "Quanyan", ""]]}, {"id": "1911.10113", "submitter": "Mohammed K Alzaylaee Dr", "authors": "Mohammed K. Alzaylaee, Suleiman Y. Yerima and Sakir Sezer", "title": "DL-Droid: Deep learning based android malware detection using real\n  devices", "comments": null, "journal-ref": null, "doi": "10.1016/j.cose.2019.101663", "report-no": null, "categories": "cs.CR cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Android operating system has been the most popular for smartphones and\ntablets since 2012. This popularity has led to a rapid raise of Android malware\nin recent years. The sophistication of Android malware obfuscation and\ndetection avoidance methods have significantly improved, making many\ntraditional malware detection methods obsolete. In this paper, we propose\nDL-Droid, a deep learning system to detect malicious Android applications\nthrough dynamic analysis using stateful input generation. Experiments performed\nwith over 30,000 applications (benign and malware) on real devices are\npresented. Furthermore, experiments were also conducted to compare the\ndetection performance and code coverage of the stateful input generation method\nwith the commonly used stateless approach using the deep learning system. Our\nstudy reveals that DL-Droid can achieve up to 97.8% detection rate (with\ndynamic features only) and 99.6% detection rate (with dynamic + static\nfeatures) respectively which outperforms traditional machine learning\ntechniques. Furthermore, the results highlight the significance of enhanced\ninput generation for dynamic analysis as DL-Droid with the state-based input\ngeneration is shown to outperform the existing state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:16:15 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Alzaylaee", "Mohammed K.", ""], ["Yerima", "Suleiman Y.", ""], ["Sezer", "Sakir", ""]]}, {"id": "1911.10137", "submitter": "Uri Stemmer", "authors": "Haim Kaplan, Katrina Ligett, Yishay Mansour, Moni Naor, Uri Stemmer", "title": "Privately Learning Thresholds: Closing the Exponential Gap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sample complexity of learning threshold functions under the\nconstraint of differential privacy. It is assumed that each labeled example in\nthe training data is the information of one individual and we would like to\ncome up with a generalizing hypothesis $h$ while guaranteeing differential\nprivacy for the individuals. Intuitively, this means that any single labeled\nexample in the training data should not have a significant effect on the choice\nof the hypothesis. This problem has received much attention recently; unlike\nthe non-private case, where the sample complexity is independent of the domain\nsize and just depends on the desired accuracy and confidence, for private\nlearning the sample complexity must depend on the domain size $X$ (even for\napproximate differential privacy). Alon et al. (STOC 2019) showed a lower bound\nof $\\Omega(\\log^*|X|)$ on the sample complexity and Bun et al. (FOCS 2015)\npresented an approximate-private learner with sample complexity\n$\\tilde{O}\\left(2^{\\log^*|X|}\\right)$. In this work we reduce this gap\nsignificantly, almost settling the sample complexity. We first present a new\nupper bound (algorithm) of $\\tilde{O}\\left(\\left(\\log^*|X|\\right)^2\\right)$ on\nthe sample complexity and then present an improved version with sample\ncomplexity $\\tilde{O}\\left(\\left(\\log^*|X|\\right)^{1.5}\\right)$.\n  Our algorithm is constructed for the related interior point problem, where\nthe goal is to find a point between the largest and smallest input elements. It\nis based on selecting an input-dependent hash function and using it to embed\nthe database into a domain whose size is reduced logarithmically; this results\nin a new database, an interior point of which can be used to generate an\ninterior point in the original database in a differentially private manner.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:58:25 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Kaplan", "Haim", ""], ["Ligett", "Katrina", ""], ["Mansour", "Yishay", ""], ["Naor", "Moni", ""], ["Stemmer", "Uri", ""]]}, {"id": "1911.10143", "submitter": "Taihong Xiao", "authors": "Taihong Xiao, Yi-Hsuan Tsai, Kihyuk Sohn, Manmohan Chandraker,\n  Ming-Hsuan Yang", "title": "Adversarial Learning of Privacy-Preserving and Task-Oriented\n  Representations", "comments": null, "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Data privacy has emerged as an important issue as data-driven deep learning\nhas been an essential component of modern machine learning systems. For\ninstance, there could be a potential privacy risk of machine learning systems\nvia the model inversion attack, whose goal is to reconstruct the input data\nfrom the latent representation of deep networks. Our work aims at learning a\nprivacy-preserving and task-oriented representation to defend against such\nmodel inversion attacks. Specifically, we propose an adversarial reconstruction\nlearning framework that prevents the latent representations decoded into\noriginal input data. By simulating the expected behavior of adversary, our\nframework is realized by minimizing the negative pixel reconstruction loss or\nthe negative feature reconstruction (i.e., perceptual distance) loss. We\nvalidate the proposed method on face attribute prediction, showing that our\nmethod allows protecting visual privacy with a small decrease in utility\nperformance. In addition, we show the utility-privacy trade-off with different\nchoices of hyperparameter for negative perceptual distance loss at training,\nallowing service providers to determine the right level of privacy-protection\nwith a certain utility performance. Moreover, we provide an extensive study\nwith different selections of features, tasks, and the data to further analyze\ntheir influence on privacy protection.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 17:06:28 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Xiao", "Taihong", ""], ["Tsai", "Yi-Hsuan", ""], ["Sohn", "Kihyuk", ""], ["Chandraker", "Manmohan", ""], ["Yang", "Ming-Hsuan", ""]]}, {"id": "1911.10167", "submitter": "Marco Avella", "authors": "Marco Avella-Medina", "title": "Privacy-preserving parametric inference: a case for robust statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is a cryptographically-motivated approach to privacy\nthat has become a very active field of research over the last decade in\ntheoretical computer science and machine learning. In this paradigm one assumes\nthere is a trusted curator who holds the data of individuals in a database and\nthe goal of privacy is to simultaneously protect individual data while allowing\nthe release of global characteristics of the database. In this setting we\nintroduce a general framework for parametric inference with differential\nprivacy guarantees. We first obtain differentially private estimators based on\nbounded influence M-estimators by leveraging their gross-error sensitivity in\nthe calibration of a noise term added to them in order to ensure privacy. We\nthen show how a similar construction can also be applied to construct\ndifferentially private test statistics analogous to the Wald, score and\nlikelihood ratio tests. We provide statistical guarantees for all our proposals\nvia an asymptotic analysis. An interesting consequence of our results is to\nfurther clarify the connection between differential privacy and robust\nstatistics. In particular, we demonstrate that differential privacy is a weaker\nstability requirement than infinitesimal robustness, and show that robust\nM-estimators can be easily randomized in order to guarantee both differential\nprivacy and robustness towards the presence of contaminated data. We illustrate\nour results both on simulated and real data.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 17:59:58 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Avella-Medina", "Marco", ""]]}, {"id": "1911.10178", "submitter": "Ferdinando Fioretto", "authors": "Ferdinando Fioretto, Lesia Mitridati, Pascal Van Hentenryck", "title": "PPSM: A Privacy-Preserving Stackelberg Mechanism: Privacy Guarantees for\n  the Coordination of Sequential Electricity and Gas Markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a differentially private mechanism to protect the\ninformation exchanged during the coordination of the sequential market-clearing\nof electricity and natural gas systems. The coordination between these\nsequential and interdependent markets represents a classic Stackelberg game and\nrelies on the exchange of sensitive information between the system agents,\nincluding the supply and demand bids in each market or the characteristics of\nthe systems. The paper is motivated by the observation that traditional\ndifferential privacy mechanisms are unsuitable for the problem of interest: The\nperturbation introduced by these mechanisms fundamentally changes the\nunderlying optimization problem and even leads to unsatisfiable instances. To\nremedy such limitation, the paper introduces the Privacy-Preserving Stackelberg\nMechanism (PPSM), a framework that enforces the notions of consistency and\nfidelity of the privacy-preserving information to the original problem\nobjective. The PPSM has strong properties: It complies with the notion of\ndifferential privacy and ensures that the outcomes of the privacy-preserving\ncoordination mechanisms are close-to-optimality for each agent. The fidelity\nproperty is analyzed by providing theoretical guarantees on the cost of privacy\nof PPSM and experimental results on several gas and electricity market\nbenchmarks based on a real case study demonstrate the effectiveness of the\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 18:28:35 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Fioretto", "Ferdinando", ""], ["Mitridati", "Lesia", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "1911.10186", "submitter": "Amit Kumar Sikder", "authors": "Amit Kumar Sikder, Leonardo Babun, Z. Berkay Celik, Abbas Acar,\n  Hidayet Aksu, Patrick McDaniel, Engin Kirda, A. Selcuk Uluagac", "title": "KRATOS: Multi-User Multi-Device-Aware Access Control System for the\n  Smart Home", "comments": "Accepted in the 13th ACM Conference on Security and Privacy in\n  Wireless and Mobile Networks (ACM WiSec 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a smart home system, multiple users have access to multiple devices,\ntypically through a dedicated app installed on a mobile device. Traditional\naccess control mechanisms consider one unique trusted user that controls the\naccess to the devices. However, multi-user multi-device smart home settings\npose fundamentally different challenges to traditional single-user systems. For\ninstance, in a multi-user environment, users have conflicting, complex, and\ndynamically changing demands on multiple devices, which cannot be handled by\ntraditional access control techniques. To address these challenges, in this\npaper, we introduce Kratos, a novel multiuser and multi-device-aware access\ncontrol mechanism that allows smart home users to flexibly specify their access\ncontrol demands. Kratos has three main components: user interaction module,\nbackend server, and policy manager. Users can specify their desired access\ncontrol settings using the interaction module which are translated into access\ncontrol policies in the backend server. The policy manager analyzes these\npolicies and initiates negotiation between users to resolve conflicting demands\nand generates final policies. We implemented Kratos and evaluated its\nperformance on real smart home deployments featuring multi-user scenarios with\na rich set of configurations (309 different policies including 213 demand\nconflicts and 24 restriction policies). These configurations included five\ndifferent threats associated with access control mechanisms. Our extensive\nevaluations show that Kratos is very effective in resolving conflicting access\ncontrol demands with minimal overhead and robust against different attacks.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 18:42:33 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 17:51:38 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Sikder", "Amit Kumar", ""], ["Babun", "Leonardo", ""], ["Celik", "Z. Berkay", ""], ["Acar", "Abbas", ""], ["Aksu", "Hidayet", ""], ["McDaniel", "Patrick", ""], ["Kirda", "Engin", ""], ["Uluagac", "A. Selcuk", ""]]}, {"id": "1911.10187", "submitter": "Saad Quader", "authors": "Erica Blum, Aggelos Kiayias, Cristopher Moore, Saad Quader, and\n  Alexander Russell", "title": "Linear Consistency for Proof-of-Stake Blockchains", "comments": "The full version accompanying the paper in SODA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The blockchain data structure maintained via the longest-chain\nrule---popularized by Bitcoin---is a powerful algorithmic tool for consensus\nalgorithms. Such algorithms achieve consistency for blocks in the chain as a\nfunction of their depth from the end of the chain. While the analysis of\nBitcoin guarantees consistency with error $2^{-k}$ for blocks of depth $O(k)$,\nthe state-of-the-art of proof-of-stake (PoS) blockchains suffers from a\nquadratic dependence on $k$: these protocols, exemplified by Ouroboros (Crypto\n2017), Ouroboros Praos (Eurocrypt 2018) and Sleepy Consensus (Asiacrypt 2017),\ncan only establish that depth $\\Theta(k^2)$ is sufficient. Whether this\nquadratic gap is an intrinsic limitation of PoS---due to issues such as the\nnothing-at-stake problem---has been an urgent open question, as deployed PoS\nblockchains further rely on consistency for protocol correctness.\n  We give an axiomatic theory of blockchain dynamics that permits rigorous\nreasoning about the longest-chain rule and achieve, in broad generality,\n$\\Theta(k)$ dependence on depth in order to achieve consistency error $2^{-k}$.\nIn particular, for the first time, we show that PoS protocols can match\nproof-of-work protocols for linear consistency. We analyze the associated\nstochastic process, give a recursive relation for the critical functionals of\nthis process, and derive tail bounds in both i.i.d. and martingale settings via\nassociated generating functions.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 18:45:27 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Blum", "Erica", ""], ["Kiayias", "Aggelos", ""], ["Moore", "Cristopher", ""], ["Quader", "Saad", ""], ["Russell", "Alexander", ""]]}, {"id": "1911.10201", "submitter": "YenLung Lai", "authors": "Yen-Lung Lai", "title": "Secure Sketch for All Noisy Sources (Noisy)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Secure sketch produces public information of its input $w$ without revealing\nit, yet, allows the exact recovery of $w$ given another value $w'$ that is\nclose to $w$. Therefore, it can be used to reliably reproduce any error-prone\nsecret (i.e., biometrics) stored in secret storage. However, some sources have\nlower entropy compared to the error itself, formally called \"more error than\nentropy\", a standard secure sketch cannot show its security promise perfectly\nto these kind of sources. This paper focuses on secure sketch. We propose a\nconcrete construction for secure sketch. We show security to all noisy sources,\nincluding the trivial source with zero min-entropy. In addition, our\nconstruction comes with efficient recovery algorithm operates in polynomial\ntime in the sketch size, which can tolerate high number of error rate arbitrary\nclose to 1/2. Above result acts in conjunction to our derivation on the\nsolution to two NP-complete coding problems, suggesting P=NP.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 02:34:19 GMT"}, {"version": "v2", "created": "Sun, 19 Jan 2020 15:37:50 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Lai", "Yen-Lung", ""]]}, {"id": "1911.10312", "submitter": "Yansong Gao Dr", "authors": "Yansong Gao, Yeonjae Kim, Bao Gia Doan, Zhi Zhang, Gongxuan Zhang,\n  Surya Nepal, Damith C. Ranasinghe, Hyoungshick Kim", "title": "Design and Evaluation of a Multi-Domain Trojan Detection Method on Deep\n  Neural Networks", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work corroborates a run-time Trojan detection method exploiting STRong\nIntentional Perturbation of inputs, is a multi-domain Trojan detection defence\nacross Vision, Text and Audio domains---thus termed as STRIP-ViTA.\nSpecifically, STRIP-ViTA is the first confirmed Trojan detection method that is\ndemonstratively independent of both the task domain and model architectures. We\nhave extensively evaluated the performance of STRIP-ViTA over: i) CIFAR10 and\nGTSRB datasets using 2D CNNs, and a public third party Trojaned model for\nvision tasks; ii) IMDB and consumer complaint datasets using both LSTM and 1D\nCNNs for text tasks; and speech command dataset using both 1D CNNs and 2D CNNs\nfor audio tasks. Experimental results based on 28 tested Trojaned models\ndemonstrate that STRIP-ViTA performs well across all nine architectures and\nfive datasets. In general, STRIP-ViTA can effectively detect Trojan inputs with\nsmall false acceptance rate (FAR) with an acceptable preset false rejection\nrate (FRR). In particular, for vision tasks, we can always achieve a 0% FRR and\nFAR. By setting FRR to be 3%, average FAR of 1.1% and 3.55% are achieved for\ntext and audio tasks, respectively. Moreover, we have evaluated and shown the\neffectiveness of STRIP-ViTA against a number of advanced backdoor attacks\nwhilst other state-of-the-art methods lose effectiveness in front of one or all\nof these advanced backdoor attacks.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 04:20:38 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Gao", "Yansong", ""], ["Kim", "Yeonjae", ""], ["Doan", "Bao Gia", ""], ["Zhang", "Zhi", ""], ["Zhang", "Gongxuan", ""], ["Nepal", "Surya", ""], ["Ranasinghe", "Damith C.", ""], ["Kim", "Hyoungshick", ""]]}, {"id": "1911.10433", "submitter": "Thomas Hardjono", "authors": "Thomas Hardjono, Alex Pentland", "title": "Empowering Artists, Songwriters & Musicians in a Data Cooperative\n  through Blockchains and Smart Contracts", "comments": "4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Over the last decade there has been a continuing decline in social trust on\nthe part of individuals with regards to the handling and fair use of personal\ndata, digital assets and other related rights in general. At the same time,\nthere has been a change in the employment patterns for many people through the\nemergence of the gig economy. These gig workers include artists, songwriters\nand musicians in the music industry. We discuss the notion of the data\ncooperative with fiduciary responsibilities to its members, which is similar in\npurpose to credit unions in the financial sector. A data cooperative for\nartists and musicians allows the community to share IT resources, such as data\nstorage, analytics processing, blockchains and distributed ledgers. A\ncooperative can also employ smart contracts to remedy the various challenges\ncurrently faced by the music industry with regards to the license tracking\nmanagement.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 23:30:02 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Hardjono", "Thomas", ""], ["Pentland", "Alex", ""]]}, {"id": "1911.10461", "submitter": "Leonardo Babun", "authors": "Leonardo Babun, Z. Berkay Celik, Patrick McDaniel, A. Selcuk Uluagac", "title": "Real-time Analysis of Privacy-(un)aware IoT Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users trust IoT apps to control and automate their smart devices. These apps\nnecessarily have access to sensitive data to implement their functionality.\nHowever, users lack visibility into how their sensitive data is used (or\nleaked), and they often blindly trust the app developers. In this paper, we\npresent IoTWatcH, a novel dynamic analysis tool that uncovers the privacy risks\nof IoT apps in real-time. We designed and built IoTWatcH based on an IoT\nprivacy survey that considers the privacy needs of IoT users. IoTWatcH provides\nusers with a simple interface to specify their privacy preferences with an IoT\napp. Then, in runtime, it analyzes both the data that is sent out of the IoT\napp and its recipients using Natural Language Processing (NLP) techniques.\nMoreover, IoTWatcH informs the users with its findings to make them aware of\nthe privacy risks with the IoT app. We implemented IoTWatcH on real IoT\napplications. Specifically, we analyzed 540 IoT apps to train the NLP model and\nevaluate its effectiveness. IoTWatcH successfully classifies IoT app data sent\nto external parties to correct privacy labels with an average accuracy of\n94.25%, and flags IoT apps that leak privacy data to unauthorized parties.\nFinally, IoTWatcH yields minimal overhead to an IoT app's execution, on average\n105 ms additional latency.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 05:15:53 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Babun", "Leonardo", ""], ["Celik", "Z. Berkay", ""], ["McDaniel", "Patrick", ""], ["Uluagac", "A. Selcuk", ""]]}, {"id": "1911.10499", "submitter": "Milan Lopuha\\\"a-Zwakenberg", "authors": "Milan Lopuha\\\"a-Zwakenberg, Zitao Li, Boris \\v{S}kori\\'c and Ninghui\n  Li", "title": "Improving Frequency Estimation under Local Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local Differential Privacy protocols are stochastic protocols used in data\naggregation when individual users do not trust the data aggregator with their\nprivate data. In such protocols there is a fundamental tradeoff between user\nprivacy and aggregator utility. In the setting of frequency estimation,\nestablished bounds on this tradeoff are either nonquantitative, or far from\nwhat is known to be attainable. In this paper, we use information-theoretical\nmethods to significantly improve established bounds. We also show that the new\nbounds are attainable for binary inputs. Furthermore, our methods lead to\nimproved frequency estimators, which we experimentally show to outperform\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 10:51:43 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 08:02:53 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Lopuha\u00e4-Zwakenberg", "Milan", ""], ["Li", "Zitao", ""], ["\u0160kori\u0107", "Boris", ""], ["Li", "Ninghui", ""]]}, {"id": "1911.10541", "submitter": "Yuval Dagan", "authors": "Yuval Dagan and Vitaly Feldman", "title": "PAC learning with stable and private predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study binary classification algorithms for which the prediction on any\npoint is not too sensitive to individual examples in the dataset. Specifically,\nwe consider the notions of uniform stability (Bousquet and Elisseeff, 2001) and\nprediction privacy (Dwork and Feldman, 2018). Previous work on these notions\nshows how they can be achieved in the standard PAC model via simple aggregation\nof models trained on disjoint subsets of data. Unfortunately, this approach\nleads to a significant overhead in terms of sample complexity. Here we\ndemonstrate several general approaches to stable and private prediction that\neither eliminate or significantly reduce the overhead. Specifically, we\ndemonstrate that for any class $C$ of VC dimension $d$ there exists a\n$\\gamma$-uniformly stable algorithm for learning $C$ with excess error $\\alpha$\nusing $\\tilde O(d/(\\alpha\\gamma) + d/\\alpha^2)$ samples. We also show that this\nbound is nearly tight. For $\\epsilon$-differentially private prediction we give\ntwo new algorithms: one using $\\tilde O(d/(\\alpha^2\\epsilon))$ samples and\nanother one using $\\tilde O(d^2/(\\alpha\\epsilon) + d/\\alpha^2)$ samples. The\nbest previously known bounds for these problems are $O(d/(\\alpha^2\\gamma))$ and\n$O(d/(\\alpha^3\\epsilon))$, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 14:48:29 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 09:11:58 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Dagan", "Yuval", ""], ["Feldman", "Vitaly", ""]]}, {"id": "1911.10637", "submitter": "Patrick Leu", "authors": "Patrick Leu, Ivan Puddu, Aanjhan Ranganathan, Srdjan Capkun", "title": "I Send, Therefore I Leak: Information Leakage in Low-Power Wide Area\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-power wide area networks (LPWANs), such as LoRa, are fast emerging as the\npreferred networking technology for large-scale Internet of Things deployments\n(e.g., smart cities). Due to long communication range and ultra low power\nconsumption, LPWAN-enabled sensors are today being deployed in a variety of\napplication scenarios where sensitive information is wirelessly transmitted. In\nthis work, we study the privacy guarantees of LPWANs, in particular LoRa. We\nshow that, although the event-based duty cycling of radio communication, i.e.,\ntransmission of radio signals only when an event occurs, saves power, it\ninherently leaks information. This information leakage is independent of the\nimplemented crypto primitives. We identify two types of information leakage and\nshow that it is hard to completely prevent leakage without incurring\nsignificant additional communication and computation costs.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 23:14:11 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Leu", "Patrick", ""], ["Puddu", "Ivan", ""], ["Ranganathan", "Aanjhan", ""], ["Capkun", "Srdjan", ""]]}, {"id": "1911.10671", "submitter": "Bogdan Groza", "authors": "Bogdan Groza, Lucian Popa, Pal-Stefan Murvay", "title": "CANTO -- Covert AutheNtication with Timing channels over Optimized\n  traffic flows for CAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous research works have endorsed the use of delays and clock skews for\ndetecting intrusions or fingerprinting ECUs on the CAN bus. Similar techniques\nhave been also proposed for establishing a time-covert cryptographic\nauthentication channel, in this way cleverly removing the need for\ncryptographic material inside the limited payload of CAN frames. The main\nshortcoming of such works is the limited security level that can be achieved\nunder normal CAN-bus traffic. In this work we endeavour to test the limits of\nthe achievable security level by relying on optimization algorithms for\nscheduling CAN frames. Under practical bus allocations that are based on\nreal-world scenarios, we are able to extract around 4--5 bits of authentication\ndata from each frame which leads to an efficient intrusion detection and\nauthentication mechanism. By accumulating covert channel data over several\nconsecutive frames, we can achieve higher security levels that are in line with\ncurrent security demands. To prove the correctness of our approach, we present\nexperiments on state-of-the-art automotive-grade controllers (Infineon Aurix)\nand bus measurements with the use of industry standard tools, i.e., CANoe.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 02:48:33 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Groza", "Bogdan", ""], ["Popa", "Lucian", ""], ["Murvay", "Pal-Stefan", ""]]}, {"id": "1911.10695", "submitter": "Yuzhe Yang", "authors": "Minghao Guo, Yuzhe Yang, Rui Xu, Ziwei Liu, Dahua Lin", "title": "When NAS Meets Robustness: In Search of Robust Architectures against\n  Adversarial Attacks", "comments": "CVPR 2020. First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in adversarial attacks uncover the intrinsic vulnerability of\nmodern deep neural networks. Since then, extensive efforts have been devoted to\nenhancing the robustness of deep networks via specialized learning algorithms\nand loss functions. In this work, we take an architectural perspective and\ninvestigate the patterns of network architectures that are resilient to\nadversarial attacks. To obtain the large number of networks needed for this\nstudy, we adopt one-shot neural architecture search, training a large network\nfor once and then finetuning the sub-networks sampled therefrom. The sampled\narchitectures together with the accuracies they achieve provide a rich basis\nfor our study. Our \"robust architecture Odyssey\" reveals several valuable\nobservations: 1) densely connected patterns result in improved robustness; 2)\nunder computational budget, adding convolution operations to direct connection\nedge is effective; 3) flow of solution procedure (FSP) matrix is a good\nindicator of network robustness. Based on these observations, we discover a\nfamily of robust architectures (RobNets). On various datasets, including CIFAR,\nSVHN, Tiny-ImageNet, and ImageNet, RobNets exhibit superior robustness\nperformance to other widely used architectures. Notably, RobNets substantially\nimprove the robust accuracy (~5% absolute gains) under both white-box and\nblack-box attacks, even with fewer parameter numbers. Code is available at\nhttps://github.com/gmh14/RobNets.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 04:14:02 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 06:07:55 GMT"}, {"version": "v3", "created": "Thu, 26 Mar 2020 01:37:40 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Guo", "Minghao", ""], ["Yang", "Yuzhe", ""], ["Xu", "Rui", ""], ["Liu", "Ziwei", ""], ["Lin", "Dahua", ""]]}, {"id": "1911.10719", "submitter": "Masaharu Kataoka", "authors": "Yohei Yoshimoto and Masaharu Kataoka and Yoshimasa Takabatake and\n  Tomohiro I and Kilho Shin and Hiroshi Sakamoto", "title": "Faster Privacy-Preserving Computation of Edit Distance with Moves", "comments": "to appear in WALCOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an efficient two-party protocol for securely computing the\nsimilarity of strings w.r.t. an extended edit distance measure. Here, two\nparties possessing strings $x$ and $y$, respectively, want to jointly compute\nan approximate value for $\\mathrm{EDM}(x,y)$, the minimum number of edit\noperations including substring moves needed to transform $x$ into $y$, without\nrevealing any private information. Recently, the first secure two-party\nprotocol for this was proposed, based on homomorphic encryption, but this\napproach is not suitable for long strings due to its high communication and\nround complexities. In this paper, we propose an improved algorithm that\nsignificantly reduces the round complexity without sacrificing its\ncryptographic strength. We examine the performance of our algorithm for DNA\nsequences compared to previous one.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 06:35:10 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 06:39:01 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Yoshimoto", "Yohei", ""], ["Kataoka", "Masaharu", ""], ["Takabatake", "Yoshimasa", ""], ["I", "Tomohiro", ""], ["Shin", "Kilho", ""], ["Sakamoto", "Hiroshi", ""]]}, {"id": "1911.11034", "submitter": "Ram Shankar Siva Kumar", "authors": "Ram Shankar Siva Kumar (1), David O Brien (2), Kendra Albert (3),\n  Salom\\'e Vilj\\\"oen (2), Jeffrey Snover (1) ((1) Microsoft, (2) Berkman Klein\n  Center for Internet and Society at Harvard University, (3) Harvard Law\n  School)", "title": "Failure Modes in Machine Learning Systems", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last two years, more than 200 papers have been written on how machine\nlearning (ML) systems can fail because of adversarial attacks on the algorithms\nand data; this number balloons if we were to incorporate papers covering\nnon-adversarial failure modes. The spate of papers has made it difficult for ML\npractitioners, let alone engineers, lawyers, and policymakers, to keep up with\nthe attacks against and defenses of ML systems. However, as these systems\nbecome more pervasive, the need to understand how they fail, whether by the\nhand of an adversary or due to the inherent design of a system, will only\nbecome more pressing. In order to equip software developers, security incident\nresponders, lawyers, and policy makers with a common vernacular to talk about\nthis problem, we developed a framework to classify failures into \"Intentional\nfailures\" where the failure is caused by an active adversary attempting to\nsubvert the system to attain her goals; and \"Unintentional failures\" where the\nfailure is because an ML system produces an inherently unsafe outcome. After\ndeveloping the initial version of the taxonomy last year, we worked with\nsecurity and ML teams across Microsoft, 23 external partners, standards\norganization, and governments to understand how stakeholders would use our\nframework. Throughout the paper, we attempt to highlight how machine learning\nfailure modes are meaningfully different from traditional software failures\nfrom a technology and policy perspective.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 16:37:28 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Kumar", "Ram Shankar Siva", ""], ["Brien", "David O", ""], ["Albert", "Kendra", ""], ["Vilj\u00f6en", "Salom\u00e9", ""], ["Snover", "Jeffrey", ""]]}, {"id": "1911.11052", "submitter": "Patrick Leu", "authors": "Patrick Leu, Mridula Singh, Marc Roeschlin, Kenneth G. Paterson,\n  Srdjan Capkun", "title": "Message Time of Arrival Codes: A Fundamental Primitive for Secure\n  Distance Measurement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure distance measurement and therefore secure Time-of-Arrival (ToA)\nmeasurement is critical for applications such as contactless payments,\npassive-keyless entry and start systems, and navigation systems. This paper\ninitiates the study of Message Time of Arrival Codes (MTACs) and their\nsecurity. MTACs represent a core primitive in the construction of systems for\nsecure ToA measurement. By surfacing MTACs in this way, we are able for the\nfirst time to formally define the security requirements of physical-layer\nmeasures that protect ToA measurement systems against attacks. Our viewpoint\nalso enables us to provide a unified presentation of existing MTACs (such as\nthose proposed in distance-bounding protocols and in a secure distance\nmeasurement standard) and to propose basic principles for protecting ToA\nmeasurement systems against attacks that remain unaddressed by existing\nmechanisms. We also use our perspective to systematically explore the tradeoffs\nbetween security and performance that apply to all signal modulation techniques\nenabling ToA measurements.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 17:02:31 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Leu", "Patrick", ""], ["Singh", "Mridula", ""], ["Roeschlin", "Marc", ""], ["Paterson", "Kenneth G.", ""], ["Capkun", "Srdjan", ""]]}, {"id": "1911.11078", "submitter": "Mridula Singh", "authors": "Mridula Singh, Patrick Leu, AbdelRahman Abdou, Srdjan Capkun", "title": "UWB-ED: Distance Enlargement Attack Detection in Ultra-Wideband", "comments": null, "journal-ref": "USENIX Security 2019", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile autonomous systems, robots, and cyber-physical systems rely on\naccurate positioning information. To conduct distance-measurement, two devices\nexchange signals and, knowing these signals propagate at the speed of light,\nthe time of arrival is used for distance estimations. Existing\ndistance-measurement techniques are incapable of protecting against adversarial\ndistance enlargement---a highly devastating tactic in which the adversary\nreissues a delayed version of the signals transmitted between devices, after\ndistorting the authentic signal to prevent the receiver from identifying it.\nThe adversary need not break crypto, nor compromise any upper-layer security\nprotocols for mounting this attack. No known solution currently exists to\nprotect against distance enlargement. We present \\textit{Ultra-Wideband\nEnlargement Detection} (UWB-ED), a new modulation technique to detect distance\nenlargement attacks, and securely verify distances between two mutually trusted\ndevices. We analyze UWB-ED under an adversary that injects signals to\nblock/modify authentic signals. We show how UWB-ED is a good candidate for\n802.15.4z Low Rate Pulse and the 5G standard.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 17:33:55 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Singh", "Mridula", ""], ["Leu", "Patrick", ""], ["Abdou", "AbdelRahman", ""], ["Capkun", "Srdjan", ""]]}, {"id": "1911.11212", "submitter": "Richard Dosselmann", "authors": "Richard Dosselmann, Mehdi Sadeqi, Howard J. Hamilton", "title": "A Tutorial on Computing $t$-Closeness", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a tutorial of the computation of $t$-closeness. An\nestablished model in the domain of privacy preserving data publishing,\n$t$-closeness is a measure of the earth mover's distance between two\ndistributions of an anonymized database table. This tutorial includes three\nexamples that showcase the full computation of $t$-closeness in terms of both\nnumerical and categorical attributes. Calculations are carried out using the\ndefinition of the earth mover's distance and weighted order distance. This\npaper includes detailed explanations and calculations not found elsewhere in\nthe literature. An efficient algorithm to calculate the $t$-closeness of a\ntable is also presented.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 20:24:24 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Dosselmann", "Richard", ""], ["Sadeqi", "Mehdi", ""], ["Hamilton", "Howard J.", ""]]}, {"id": "1911.11276", "submitter": "Sherif Saad", "authors": "Sherif Saad, Farhan Mahmood, William Briguglio, and Haytham Elmiligi", "title": "JSLess: A Tale of a Fileless Javascript Memory-Resident Malware", "comments": "International Conference on Information Security Practice and\n  Experience,2019", "journal-ref": "ISPEC 2019: Information Security Practice and Experience pp\n  113-131", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New computing paradigms, modern feature-rich programming languages and\noff-the-shelf software libraries enabled the development of new sophisticated\nmalware families. Evidence of this phenomena is the recent growth of fileless\nmalware attacks. Fileless malware or memory resident malware is an example of\nan Advanced Volatile Threat (AVT). In a fileless malware attack, the malware\nwrites itself directly onto the main memory (RAM) of the compromised device\nwithout leaving any trace on the compromised device's file system. For this\nreason, fileless malware presents a difficult challenge for traditional malware\ndetection tools and in particular signature-based detection. Moreover, fileless\nmalware forensics and reverse engineering are nearly impossible using\ntraditional methods. The majority of fileless malware attacks in the wild take\nadvantage of MS PowerShell, however, fileless malware are not limited to MS\nPowerShell. In this paper, we designed and implemented a fileless malware by\ntaking advantage of new features in Javascript and HTML5. The proposed fileless\nmalware could infect any device that supports Javascript and HTML5. It serves\nas a proof-of-concept (PoC) to demonstrate the threats of fileless malware in\nweb applications. We used the proposed fileless malware to evaluate existing\nmethods and techniques for malware detection in web applications. We tested the\nproposed fileless malware with several free and commercial malware detection\ntools that apply both static and dynamic analysis. The proposed fileless\nmalware bypassed all the anti-malware detection tools included in our study. In\nour analysis, we discussed the limitations of existing approaches/tools and\nsuggested possible detection and mitigation techniques.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 23:36:03 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Saad", "Sherif", ""], ["Mahmood", "Farhan", ""], ["Briguglio", "William", ""], ["Elmiligi", "Haytham", ""]]}, {"id": "1911.11278", "submitter": "Keyvan Ramezanpour", "authors": "Keyvan Ramezanpour, Paul Ampadu and William Diehl", "title": "RS-Mask: Random Space Masking as an Integrated Countermeasure against\n  Power and Fault Analysis", "comments": "12 pages, 12 figures, 2020 IEEE International Symposium on Hardware\n  Oriented Security and Trust (HOST)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While modern masking schemes provide provable security against passive\nside-channel analysis (SCA), such as power analysis, single faults can be\nemployed to recover the secret key of ciphers even in masked implementations.\nIn this paper, we propose random space masking (RS-Mask) as a countermeasure\nagainst both power analysis and statistical fault analysis (SFA) techniques. In\nthe RS-Mask scheme, the distribution of all sensitive variables, faulty and/or\ncorrect values is uniform, and it therefore protects the implementations\nagainst any SFA technique that exploits the distribution of intermediate\nvariables, including fault sensitivity analysis (FSA), statistical ineffective\nfault analysis (SIFA) and fault intensity map analysis (FIMA). We implement\nRS-Mask on AES, and show that a SIFA attack is not able to identify the correct\nkey. We additionally show that an FPGA implementation of AES, protected with\nRS-Mask, is resistant to power analysis SCA using Welch's t-test. The area of\nthe RS-Masked AES is about 3.5 times that of an unprotected AES implementation\nof similar architecture, and about 2 times that of a known FPGA SCA-resistant\nAES implementation. Finally, we introduce infective RS-Mask that provides\nsecurity against differential techniques, such as differential fault analysis\n(DFA) and differential fault intensity analysis (DFIA), with a slight increase\nin overhead.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 23:44:39 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Ramezanpour", "Keyvan", ""], ["Ampadu", "Paul", ""], ["Diehl", "William", ""]]}, {"id": "1911.11279", "submitter": "Muhammad R. A. Khandaker PhD", "authors": "Christantus O. Nnamani, Muhammad R. A. Khandaker, and Mathini\n  Sellathurai", "title": "UAV-Aided Jamming for Secure Ground Communication with Unknown\n  Eavesdropper Location", "comments": "Submitted to IEEE Access. Contents may be subject to copyright to\n  IEEE", "journal-ref": "in IEEE Access, vol. 8, pp. 72881-72892, 2020", "doi": "10.1109/ACCESS.2020.2986025", "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates unmanned aerial vehicle (UAV)-aided jamming technique\nfor enabling physical layer keyless security in scenarios where the exact\neavesdropper location is unknown. We assume that the unknown eavesdropper\nlocation is within an ellipse characterizing the coverage region of the\ntransmitter. By sequentially optimizing the transmit power, the flight path of\nthe UAV and its jamming power, we aim at maximizing the average secrecy rate\nwith arbitrary eavesdropper location. Simulation results demonstrate that the\noptimal flight path obtains better secrecy rate performance compared to that\nusing direct UAV flight path encasing the transmitter and the legitimate\nreceiver. Most importantly, even with the unknown eavesdropper location, we\nobtained a secrecy rate that is comparable to a scenario when the\neavesdropper's location is known. However, the average secrecy rate with the\nunknown eavesdropper location varies depending on the proximity of the\neavesdropper to the known location of the transmitter. We also observe that due\nto the UAV-aided jamming, the average secrecy rate stabilizes at some point\neven though the average received envelope power of the eavesdropper increases.\nThis essentially demonstrates the effectiveness of the proposed scheme.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 23:45:12 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Nnamani", "Christantus O.", ""], ["Khandaker", "Muhammad R. A.", ""], ["Sellathurai", "Mathini", ""]]}, {"id": "1911.11284", "submitter": "Ehsan Aghaei", "authors": "Ehsan Aghaei, Gursel Serpen", "title": "Host-based anomaly detection using Eigentraces feature extraction and\n  one-class classification on system call trace data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a methodology for host-based anomaly detection using a\nsemi-supervised algorithm namely one-class classifier combined with a PCA-based\nfeature extraction technique called Eigentraces on system call trace data. The\none-class classification is based on generating a set of artificial data using\na reference distribution and combining the target class probability function\nwith artificial class density function to estimate the target class density\nfunction through the Bayes formulation. The benchmark dataset, ADFA-LD, is\nemployed for the simulation study. ADFA-LD dataset contains thousands of system\ncall traces collected during various normal and attack processes for the Linux\noperating system environment. In order to pre-process and to extract features,\nwindowing on the system call trace data followed by the principal component\nanalysis which is named as Eigentraces is implemented. The target class\nprobability function is modeled separately by Radial Basis Function neural\nnetwork and Random Forest machine learners for performance comparison purposes.\nThe simulation study showed that the proposed intrusion detection system offers\nhigh performance for detecting anomalies and normal activities with respect to\na set of well-accepted metrics including detection rate, accuracy, and missed\nand false alarm rates.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 23:55:00 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Aghaei", "Ehsan", ""], ["Serpen", "Gursel", ""]]}, {"id": "1911.11287", "submitter": "Alessio Meneghetti", "authors": "Alessio Meneghetti, Massimiliano Sala, Daniele Taufer", "title": "A new ECDLP-based PoW model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We lay the foundations for a blockchain scheme, whose consensus is reached\nvia a proof of work algorithm based on the solution of consecutive discrete\nlogarithm problems over the point group of elliptic curves. In the considered\narchitecture, the curves are pseudorandomly determined by block creators,\nchosen to be cryptographically secure and changed every epoch. Given the\ncurrent state of the chain and a prescribed set of transactions, the curve\nselection is fully rigid, therefore trust is needed neither in miners nor in\nthe scheme proposers.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 00:06:40 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 17:39:52 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Meneghetti", "Alessio", ""], ["Sala", "Massimiliano", ""], ["Taufer", "Daniele", ""]]}, {"id": "1911.11377", "submitter": "Robert Podschwadt", "authors": "Daniel Takabi, Robert Podschwadt, Jeff Druce, Curt Wu, Kevin Procopio", "title": "Privacy preserving Neural Network Inference on Encrypted Data with GPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning as a Service (MLaaS) has become a growing trend in recent\nyears and several such services are currently offered. MLaaS is essentially a\nset of services that provides machine learning tools and capabilities as part\nof cloud computing services. In these settings, the cloud has pre-trained\nmodels that are deployed and large computing capacity whereas the clients can\nuse these models to make predictions without having to worry about maintaining\nthe models and the service. However, the main concern with MLaaS is the privacy\nof the client's data.\n  Although there have been several proposed approaches in the literature to run\nmachine learning models on encrypted data, the performance is still far from\nbeing satisfactory for practical use. In this paper, we aim to accelerate the\nperformance of running machine learning on encrypted data using combination of\nFully Homomorphic Encryption (FHE), Convolutional Neural Networks (CNNs) and\nGraphics Processing Units (GPUs). We use a number of optimization techniques,\nand efficient GPU-based implementation to achieve high performance. We evaluate\na CNN whose architecture is similar to AlexNet to classify homomorphically\nencrypted samples from the Cars Overhead With Context (COWC) dataset. To the\nbest of our knowledge, it is the first time such a complex network and large\ndataset is evaluated on encrypted data. Our approach achieved reasonable\nclassification accuracy of 95% for the COWC dataset. In terms of performance,\nour results show that we could achieve several thousands times speed up when we\nimplement GPU-accelerated FHE operations on encrypted floating point numbers.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 07:36:38 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Takabi", "Daniel", ""], ["Podschwadt", "Robert", ""], ["Druce", "Jeff", ""], ["Wu", "Curt", ""], ["Procopio", "Kevin", ""]]}, {"id": "1911.11592", "submitter": "Harsh Singh", "authors": "Harsh Jot Singh and Abdelhakim Senhaji Hafid", "title": "Transaction Confirmation Time Prediction in Ethereum Blockchain Using\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain offers a decentralized, immutable, transparent system of records.\nIt offers a peer-to-peer network of nodes with no centralised governing entity\nmaking it unhackable and therefore, more secure than the traditional\npaper-based or centralised system of records like banks etc. While there are\ncertain advantages to the paper-based recording approach, it does not work well\nwith digital relationships where the data is in constant flux. Unlike\ntraditional channels, governed by centralized entities, blockchain offers its\nusers a certain level of anonymity by providing capabilities to interact\nwithout disclosing their personal identities and allows them to build trust\nwithout a third-party governing entity. Due to the aforementioned\ncharacteristics of blockchain, more and more users around the globe are\ninclined towards making a digital transaction via blockchain than via\nrudimentary channels. Therefore, there is a dire need for us to gain insight on\nhow these transactions are processed by the blockchain and how much time it may\ntake for a peer to confirm a transaction and add it to the blockchain network.\nThis paper presents a novel approach that would allow one to estimate the time,\nin block time or otherwise, it would take for a mining node to accept and\nconfirm a transaction to a block using machine learning. The paper also aims to\ncompare the predictive accuracy of two machine learning regression models-\nRandom Forest Regressor and Multilayer Perceptron against previously proposed\nstatistical regression model under a set evaluation criterion. The objective is\nto determine whether machine learning offers a more accurate predictive model\nthan conventional statistical models. The proposed model results in improved\naccuracy in prediction.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 17:20:27 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Singh", "Harsh Jot", ""], ["Hafid", "Abdelhakim Senhaji", ""]]}, {"id": "1911.11607", "submitter": "Weijie J. Su", "authors": "Zhiqi Bu and Jinshuo Dong and Qi Long and Weijie J. Su", "title": "Deep Learning with Gaussian Differential Privacy", "comments": "To appear in Harvard Data Science Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are often trained on datasets that contain sensitive\ninformation such as individuals' shopping transactions, personal contacts, and\nmedical records. An increasingly important line of work therefore has sought to\ntrain neural networks subject to privacy constraints that are specified by\ndifferential privacy or its divergence-based relaxations. These privacy\ndefinitions, however, have weaknesses in handling certain important primitives\n(composition and subsampling), thereby giving loose or complicated privacy\nanalyses of training neural networks. In this paper, we consider a recently\nproposed privacy definition termed \\textit{$f$-differential privacy} [18] for a\nrefined privacy analysis of training neural networks. Leveraging the appealing\nproperties of $f$-differential privacy in handling composition and subsampling,\nthis paper derives analytically tractable expressions for the privacy\nguarantees of both stochastic gradient descent and Adam used in training deep\nneural networks, without the need of developing sophisticated techniques as [3]\ndid. Our results demonstrate that the $f$-differential privacy framework allows\nfor a new privacy analysis that improves on the prior analysis~[3], which in\nturn suggests tuning certain parameters of neural networks for a better\nprediction accuracy without violating the privacy budget. These theoretically\nderived improvements are confirmed by our experiments in a range of tasks in\nimage classification, text classification, and recommender systems. Python code\nto calculate the privacy cost for these experiments is publicly available in\nthe \\texttt{TensorFlow Privacy} library.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 15:08:58 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 03:11:37 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 16:09:13 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Bu", "Zhiqi", ""], ["Dong", "Jinshuo", ""], ["Long", "Qi", ""], ["Su", "Weijie J.", ""]]}, {"id": "1911.11616", "submitter": "Yantao Lu", "authors": "Yantao Lu, Yunhan Jia, Jianyu Wang, Bai Li, Weiheng Chai, Lawrence\n  Carin, Senem Velipasalar", "title": "Enhancing Cross-task Black-Box Transferability of Adversarial Examples\n  with Dispersion Reduction", "comments": "arXiv admin note: substantial text overlap with arXiv:1905.03333", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are known to be vulnerable to carefully crafted adversarial\nexamples, and these malicious samples often transfer, i.e., they remain\nadversarial even against other models. Although great efforts have been delved\ninto the transferability across models, surprisingly, less attention has been\npaid to the cross-task transferability, which represents the real-world\ncybercriminal's situation, where an ensemble of different defense/detection\nmechanisms need to be evaded all at once. In this paper, we investigate the\ntransferability of adversarial examples across a wide range of real-world\ncomputer vision tasks, including image classification, object detection,\nsemantic segmentation, explicit content detection, and text detection. Our\nproposed attack minimizes the ``dispersion'' of the internal feature map, which\novercomes existing attacks' limitation of requiring task-specific loss\nfunctions and/or probing a target model. We conduct evaluation on open source\ndetection and segmentation models as well as four different computer vision\ntasks provided by Google Cloud Vision (GCV) APIs, to show how our approach\noutperforms existing attacks by degrading performance of multiple CV tasks by a\nlarge margin with only modest perturbations linf=16.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 23:08:17 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Lu", "Yantao", ""], ["Jia", "Yunhan", ""], ["Wang", "Jianyu", ""], ["Li", "Bai", ""], ["Chai", "Weiheng", ""], ["Carin", "Lawrence", ""], ["Velipasalar", "Senem", ""]]}, {"id": "1911.11675", "submitter": "Valdemar \\v{S}v\\'abensk\\'y", "authors": "Valdemar \\v{S}v\\'abensk\\'y, Jan Vykopal, Pavel \\v{C}eleda", "title": "What Are Cybersecurity Education Papers About? A Systematic Literature\n  Review of SIGCSE and ITiCSE Conferences", "comments": "ACM SIGCSE 2020 conference, 7 pages, 3 figures, 1 table", "journal-ref": null, "doi": "10.1145/3328778.3366816", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybersecurity is now more important than ever, and so is education in this\nfield. However, the cybersecurity domain encompasses an extensive set of\nconcepts, which can be taught in different ways and contexts. To understand the\nstate of the art of cybersecurity education and related research, we examine\npapers from the ACM SIGCSE and ACM ITiCSE conferences. From 2010 to 2019, a\ntotal of 1,748 papers were published at these conferences, and 71 of them focus\non cybersecurity education. The papers discuss courses, tools, exercises, and\nteaching approaches. For each paper, we map the covered topics, teaching\ncontext, evaluation methods, impact, and the community of authors. We\ndiscovered that the technical topic areas are evenly covered (the most\nprominent being secure programming, network security, and offensive security),\nand human aspects, such as privacy and social engineering, are present as well.\nThe interventions described in SIGCSE and ITiCSE papers predominantly focus on\ntertiary education in the USA. The subsequent evaluation mostly consists of\ncollecting students' subjective perceptions via questionnaires. However, less\nthan a third of the papers provide supplementary materials for other educators,\nand none of the authors published their dataset. Our results provide\norientation in the area, a synthesis of trends, and implications for further\nresearch. Therefore, they are relevant for instructors, researchers, and anyone\nnew in the field of cybersecurity education. The information we collected and\nsynthesized from individual papers are organized in a publicly available\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 16:17:07 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["\u0160v\u00e1bensk\u00fd", "Valdemar", ""], ["Vykopal", "Jan", ""], ["\u010celeda", "Pavel", ""]]}, {"id": "1911.11746", "submitter": "Alison Jenkins", "authors": "Alison Jenkins", "title": "Defending Against Adversarial Machine Learning", "comments": "adversarial machine learning, accuracy, probability, feature mask,\n  genetic algorithm, authorship attribution system, GEFeS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An Adversarial System to attack and an Authorship Attribution System (AAS) to\ndefend itself against the attacks are analyzed. Defending a system against\nattacks from an adversarial machine learner can be done by randomly switching\nbetween models for the system, by detecting and reacting to changes in the\ndistribution of normal inputs, or by using other methods. Adversarial machine\nlearning is used to identify a system that is being used to map system inputs\nto outputs. Three types of machine learners are using for the model that is\nbeing attacked. The machine learners that are used to model the system being\nattacked are a Radial Basis Function Support Vector Machine, a Linear Support\nVector Machine, and a Feedforward Neural Network. The feature masks are evolved\nusing accuracy as the fitness measure. The system defends itself against\nadversarial machine learning attacks by identifying inputs that do not match\nthe probability distribution of normal inputs. The system also defends itself\nagainst adversarial attacks by randomly switching between the feature masks\nbeing used to map system inputs to outputs.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:28:47 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Jenkins", "Alison", ""]]}, {"id": "1911.11770", "submitter": "Bert-Jan Butijn", "authors": "Bert-Jan Butijn, Damian A. Tamburri, Willem-Jan Van Den Heuvel", "title": "Blockchains: a Systematic Multivocal Literature Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Blockchain technology has gained tremendous popularity both in practice and\nacademia. The goal of this article is to develop a coherent overview of the\nstate of the art in blockchain technology, using a\nsystematic(i.e.,protocol-based, replicable), multivocal (i.e., featuring both\nwhite and grey literature alike) literature review, to (1) define blockchain\ntechnology (2) elaborate on its architecture options and (3) trade-offs, as\nwell as understanding (4) the current applications and challenges, as evident\nfrom the state of the art. We derive a systematic definition of blockchain\ntechnology, based on a formal concept analysis. Further on, we flesh out an\noverview of blockchain technology elaborated by means of Grounded-Theory.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 12:14:42 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Butijn", "Bert-Jan", ""], ["Tamburri", "Damian A.", ""], ["Heuvel", "Willem-Jan Van Den", ""]]}, {"id": "1911.11815", "submitter": "Xiaoyu Cao", "authors": "Minghong Fang, Xiaoyu Cao, Jinyuan Jia and Neil Zhenqiang Gong", "title": "Local Model Poisoning Attacks to Byzantine-Robust Federated Learning", "comments": "The paper was submitted to Usenix Security Symposium in February 2019\n  and will appear in Usenix Security Symposium 2020; fixing an error in Theorem\n  1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In federated learning, multiple client devices jointly learn a machine\nlearning model: each client device maintains a local model for its local\ntraining dataset, while a master device maintains a global model via\naggregating the local models from the client devices. The machine learning\ncommunity recently proposed several federated learning methods that were\nclaimed to be robust against Byzantine failures (e.g., system failures,\nadversarial manipulations) of certain client devices. In this work, we perform\nthe first systematic study on local model poisoning attacks to federated\nlearning. We assume an attacker has compromised some client devices, and the\nattacker manipulates the local model parameters on the compromised client\ndevices during the learning process such that the global model has a large\ntesting error rate. We formulate our attacks as optimization problems and apply\nour attacks to four recent Byzantine-robust federated learning methods. Our\nempirical results on four real-world datasets show that our attacks can\nsubstantially increase the error rates of the models learnt by the federated\nlearning methods that were claimed to be robust against Byzantine failures of\nsome client devices. We generalize two defenses for data poisoning attacks to\ndefend against our local model poisoning attacks. Our evaluation results show\nthat one defense can effectively defend against our attacks in some cases, but\nthe defenses are not effective enough in other cases, highlighting the need for\nnew defenses against our local model poisoning attacks to federated learning.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 20:10:04 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 20:59:34 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Fang", "Minghong", ""], ["Cao", "Xiaoyu", ""], ["Jia", "Jinyuan", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "1911.11881", "submitter": "Yifei Fan", "authors": "Chao Tang, Yifei Fan, Anthony Yezzi", "title": "An Adaptive View of Adversarial Robustness from Test-time Smoothing\n  Defense", "comments": "NeurIPS-2019 Workshop on Safety and Robustness in Decision Making", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The safety and robustness of learning-based decision-making systems are under\nthreats from adversarial examples, as imperceptible perturbations can mislead\nneural networks to completely different outputs. In this paper, we present an\nadaptive view of the issue via evaluating various test-time smoothing defense\nagainst white-box untargeted adversarial examples. Through controlled\nexperiments with pretrained ResNet-152 on ImageNet, we first illustrate the\nnon-monotonic relation between adversarial attacks and smoothing defenses. Then\nat the dataset level, we observe large variance among samples and show that it\nis easy to inflate accuracy (even to 100%) or build large-scale (i.e., with\nsize ~10^4) subsets on which a designated method outperforms others by a large\nmargin. Finally at the sample level, as different adversarial examples require\ndifferent degrees of defense, the potential advantages of iterative methods are\nalso discussed. We hope this paper reveal useful behaviors of test-time\ndefenses, which could help improve the evaluation process for adversarial\nrobustness in the future.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 23:45:25 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Tang", "Chao", ""], ["Fan", "Yifei", ""], ["Yezzi", "Anthony", ""]]}, {"id": "1911.11932", "submitter": "Michel Kinsy", "authors": "Mihailo Isakov, Vijay Gadepally, Karen M. Gettings, Michel A. Kinsy", "title": "Survey of Attacks and Defenses on Edge-Deployed Neural Networks", "comments": null, "journal-ref": "In the 2019 IEEE High Performance Extreme Computing Conference\n  (HPEC), 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network (DNN) workloads are quickly moving from datacenters onto\nedge devices, for latency, privacy, or energy reasons. While datacenter\nnetworks can be protected using conventional cybersecurity measures, edge\nneural networks bring a host of new security challenges. Unlike classic IoT\napplications, edge neural networks are typically very compute and memory\nintensive, their execution is data-independent, and they are robust to noise\nand faults. Neural network models may be very expensive to develop, and can\npotentially reveal information about the private data they were trained on,\nrequiring special care in distribution. The hidden states and outputs of the\nnetwork can also be used in reconstructing user inputs, potentially violating\nusers' privacy. Furthermore, neural networks are vulnerable to adversarial\nattacks, which may cause misclassifications and violate the integrity of the\noutput. These properties add challenges when securing edge-deployed DNNs,\nrequiring new considerations, threat models, priorities, and approaches in\nsecurely and privately deploying DNNs to the edge. In this work, we cover the\nlandscape of attacks on, and defenses, of neural networks deployed in edge\ndevices and provide a taxonomy of attacks and defenses targeting edge DNNs.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 03:31:04 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Isakov", "Mihailo", ""], ["Gadepally", "Vijay", ""], ["Gettings", "Karen M.", ""], ["Kinsy", "Michel A.", ""]]}, {"id": "1911.11934", "submitter": "Michel Kinsy", "authors": "Lake Bu, Mihailo Isakov, Michel A. Kinsy", "title": "A Secure and Robust Scheme for Sharing Confidential Information in IoT\n  Systems", "comments": null, "journal-ref": "Ad Hoc Networks, vol. 92, 2019 - Special Issue on Security of\n  IoT-enabled Infrastructures in Smart Cities", "doi": "10.1016/j.adhoc.2018.09.007", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Internet of Things (IoT) systems with security demands, there is often a\nneed to distribute sensitive information (such as encryption keys, digital\nsignatures, or login credentials, etc.) among the devices, so that it can be\nretrieved for confidential purposes at a later moment. However, this\ninformation cannot be entrusted to any one device, since the failure of that\ndevice or an attack on it will jeopardize the security of the entire network.\nEven if the information is divided among devices, there is still the danger\nthat an attacker can compromise a group of devices and expose the sensitive\ninformation. In this work, we design and implement a secure and robust scheme\nto enable the distribution of sensitive information in IoT networks. The\nproposed approach has two important properties: (1) it uses Threshold Secret\nSharing (TSS) to split the information into pieces distributed among all\ndevices in the system - and so the information can only be retrieved\ncollaboratively by groups of devices; and (2) it ensures the privacy and\nintegrity of the information, even when attackers hijack a large number of\ndevices and use them in concert - specifically, all the compromised devices can\nbe identified, the confidentiality of information is kept, and authenticity of\nthe secret can be guaranteed.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 03:40:51 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Bu", "Lake", ""], ["Isakov", "Mihailo", ""], ["Kinsy", "Michel A.", ""]]}, {"id": "1911.11937", "submitter": "Monowar Hasan", "authors": "Monowar Hasan, Sibin Mohan, Rodolfo Pellizzoni, Rakesh B. Bobba", "title": "Period Adaptation for Continuous Security Monitoring in Multicore\n  Real-Time Systems", "comments": "Accepted for publication DATE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a design-time framework (named HYDRA-C) for integrating security\ntasks into partitioned real-time systems (RTS) running on multicore platforms.\nOur goal is to opportunistically execute security monitoring mechanisms in a\n'continuous' manner -- i.e., as often as possible, across cores, to ensure that\nsecurity tasks run with as few interruptions as possible. Our framework will\nallow designers to integrate security mechanisms without perturbing existing\nreal-time (RT) task properties or execution order. We demonstrate the framework\nusing a proof-of-concept implementation with intrusion detection mechanisms as\nsecurity tasks. We develop and use both, (a) a custom intrusion detection\nsystem (IDS), as well as (b) Tripwire -- an open source data integrity checking\ntool. These are implemented on a realistic rover platform designed using an ARM\nmulticore chip. We compare the performance of HYDRA-C with a state-of-the-art\nRT security integration approach for multicore-based RTS and find that our\nmethod can, on average, detect intrusions 19.05% faster without impacting the\nperformance of RT tasks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 03:52:34 GMT"}, {"version": "v2", "created": "Sat, 14 Mar 2020 14:58:13 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Hasan", "Monowar", ""], ["Mohan", "Sibin", ""], ["Pellizzoni", "Rodolfo", ""], ["Bobba", "Rakesh B.", ""]]}, {"id": "1911.11946", "submitter": "Pratik Vaishnavi", "authors": "Pratik Vaishnavi, Tianji Cong, Kevin Eykholt, Atul Prakash, Amir\n  Rahmati", "title": "Can Attention Masks Improve Adversarial Robustness?", "comments": "Version presented at AAAI-20 workshop on Engineering Dependable and\n  Secure Machine Learning Systems (EDSMLS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are known to be susceptible to adversarial\nexamples. Adversarial examples are maliciously crafted inputs that are designed\nto fool a model, but appear normal to human beings. Recent work has shown that\npixel discretization can be used to make classifiers for MNIST highly robust to\nadversarial examples. However, pixel discretization fails to provide\nsignificant protection on more complex datasets. In this paper, we take the\nfirst step towards reconciling these contrary findings. Focusing on the\nobservation that discrete pixelization in MNIST makes the background completely\nblack and foreground completely white, we hypothesize that the important\nproperty for increasing robustness is the elimination of image background using\nattention masks before classifying an object. To examine this hypothesis, we\ncreate foreground attention masks for two different datasets, GTSRB and\nMS-COCO. Our initial results suggest that using attention mask leads to\nimproved robustness. On the adversarially trained classifiers, we see an\nadversarial robustness increase of over 20% on MS-COCO.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 04:26:35 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 22:55:53 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Vaishnavi", "Pratik", ""], ["Cong", "Tianji", ""], ["Eykholt", "Kevin", ""], ["Prakash", "Atul", ""], ["Rahmati", "Amir", ""]]}, {"id": "1911.11972", "submitter": "Aron Laszka", "authors": "Taha Eghtesad, Yevgeniy Vorobeychik, Aron Laszka", "title": "Adversarial Deep Reinforcement Learning based Adaptive Moving Target\n  Defense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Moving target defense (MTD) is a proactive defense approach that aims to\nthwart attacks by continuously changing the attack surface of a system (e.g.,\nchanging host or network configurations), thereby increasing the adversary's\nuncertainty and attack cost. To maximize the impact of MTD, a defender must\nstrategically choose when and what changes to make, taking into account both\nthe characteristics of its system as well as the adversary's observed\nactivities. Finding an optimal strategy for MTD presents a significant\nchallenge, especially when facing a resourceful and determined adversary who\nmay respond to the defender's actions. In this paper, we propose a multi-agent\npartially-observable Markov Decision Process model of MTD and formulate a\ntwo-player general-sum game between the adversary and the defender. Based on an\nestablished model of adaptive MTD, we propose a multi-agent reinforcement\nlearning framework based on the double oracle algorithm to solve the game. In\nthe experiments, we show the effectiveness of our framework in finding optimal\npolicies.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 06:13:20 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 04:32:49 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Eghtesad", "Taha", ""], ["Vorobeychik", "Yevgeniy", ""], ["Laszka", "Aron", ""]]}, {"id": "1911.12046", "submitter": "Pan Wang", "authors": "Pan Wang, Shuhang Li, Feng Ye, Zixuan Wang and Moxuan Zhang", "title": "PacketCGAN: Exploratory Study of Class Imbalance for Encrypted Traffic\n  Classification Using CGAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With more and more adoption of Deep Learning (DL) in the field of image\nprocessing, computer vision and NLP, researchers have begun to apply DL to\ntackle with encrypted traffic classification problems. Although these methods\ncan automatically extract traffic features to overcome the difficulty of\ntraditional classification methods like DPI in terms of feature engineering, a\nlarge amount of data is needed to learn the characteristics of various types of\ntraffic. Therefore, the performance of classification model always\nsignificantly depends on the quality of datasets. Nevertheless, the building of\ndatasets is a time-consuming and costly task, especially encrypted traffic\ndata. Apparently, it is often more difficult to collect a large amount of\ntraffic samples of those unpopular encrypted applications than well-known,\nwhich leads to the problem of class imbalance between major and minor encrypted\napplications in datasets. In this paper, we proposed a novel traffic data\naugmenting method called PacketCGAN using Conditional GAN. As a generative\nmodel, PacketCGAN exploit the benefit of CGAN to generate specified traffic to\naddress the problem of the datasets' imbalance. As a proof of concept, three\nclassical DL models like Convolutional Neural Network (CNN) were adopted and\ndesigned to classify four encrypted traffic datasets augmented by Random Over\nSampling (ROS), SMOTE(Synthetic Minority Over-sampling Techinique) , vanilla\nGAN and PacketCGAN respectively based on two public datasets: ISCX2012 and\nUSTC-TFC2016. The experimental evaluation results demonstrate that DL based\nencrypted traffic classifier over dataset augmented by PacketCGAN can achieve\nbetter performance than the others.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 09:46:48 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Wang", "Pan", ""], ["Li", "Shuhang", ""], ["Ye", "Feng", ""], ["Wang", "Zixuan", ""], ["Zhang", "Moxuan", ""]]}, {"id": "1911.12060", "submitter": "Jun Zhao", "authors": "Jun Zhao, Teng Wang, Tao Bai, Kwok-Yan Lam, Zhiying Xu, Shuyu Shi,\n  Xuebin Ren, Xinyu Yang, Yang Liu, Han Yu", "title": "Reviewing and Improving the Gaussian Mechanism for Differential Privacy", "comments": "23 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CY cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy provides a rigorous framework to quantify data privacy,\nand has received considerable interest recently. A randomized mechanism\nsatisfying $(\\epsilon, \\delta)$-differential privacy (DP) roughly means that,\nexcept with a small probability $\\delta$, altering a record in a dataset cannot\nchange the probability that an output is seen by more than a multiplicative\nfactor $e^{\\epsilon} $. A well-known solution to $(\\epsilon, \\delta)$-DP is the\nGaussian mechanism initiated by Dwork et al. [1] in 2006 with an improvement by\nDwork and Roth [2] in 2014, where a Gaussian noise amount $\\sqrt{2\\ln\n\\frac{2}{\\delta}} \\times \\frac{\\Delta}{\\epsilon}$ of [1] or $\\sqrt{2\\ln\n\\frac{1.25}{\\delta}} \\times \\frac{\\Delta}{\\epsilon}$ of [2] is added\nindependently to each dimension of the query result, for a query with\n$\\ell_2$-sensitivity $\\Delta$. Although both classical Gaussian mechanisms\n[1,2] assume $0 < \\epsilon \\leq 1$, our review finds that many studies in the\nliterature have used the classical Gaussian mechanisms under values of\n$\\epsilon$ and $\\delta$ where the added noise amounts of [1,2] do not achieve\n$(\\epsilon,\\delta)$-DP. We obtain such result by analyzing the optimal noise\namount $\\sigma_{DP-OPT}$ for $(\\epsilon,\\delta)$-DP and identifying $\\epsilon$\nand $\\delta$ where the noise amounts of classical mechanisms are even less than\n$\\sigma_{DP-OPT}$.\n  Since $\\sigma_{DP-OPT}$ has no closed-form expression and needs to be\napproximated in an iterative manner, we propose Gaussian mechanisms by deriving\nclosed-form upper bounds for $\\sigma_{DP-OPT}$. Our mechanisms achieve\n$(\\epsilon,\\delta)$-DP for any $\\epsilon$, while the classical mechanisms [1,2]\ndo not achieve $(\\epsilon,\\delta)$-DP for large $\\epsilon$ given $\\delta$.\nMoreover, the utilities of our mechanisms improve those of [1,2] and are close\nto that of the optimal yet more computationally expensive Gaussian mechanism.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 10:26:50 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 04:13:50 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Zhao", "Jun", ""], ["Wang", "Teng", ""], ["Bai", "Tao", ""], ["Lam", "Kwok-Yan", ""], ["Xu", "Zhiying", ""], ["Shi", "Shuyu", ""], ["Ren", "Xuebin", ""], ["Yang", "Xinyu", ""], ["Liu", "Yang", ""], ["Yu", "Han", ""]]}, {"id": "1911.12069", "submitter": "Davide Cozzolino", "authors": "Davide Cozzolino and Justus Thies and Andreas R\\\"ossler and Matthias\n  Nie{\\ss}ner and Luisa Verdoliva", "title": "SpoC: Spoofing Camera Fingerprints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to the fast progress in synthetic media generation, creating realistic\nfalse images has become very easy. Such images can be used to wrap \"rich\" fake\nnews with enhanced credibility, spawning a new wave of high-impact, high-risk\nmisinformation campaigns. Therefore, there is a fast-growing interest in\nreliable detectors of manipulated media. The most powerful detectors, to date,\nrely on the subtle traces left by any device on all images acquired by it. In\nparticular, due to proprietary in-camera processes, like demosaicing or\ncompression, each camera model leaves trademark traces that can be exploited\nfor forensic analyses. The absence or distortion of such traces in the target\nimage is a strong hint of manipulation. In this paper, we challenge such\ndetectors to gain better insight into their vulnerabilities. This is an\nimportant study in order to build better forgery detectors able to face\nmalicious attacks. Our proposal consists of a GAN-based approach that injects\ncamera traces into synthetic images. Given a GAN-generated image, we insert the\ntraces of a specific camera model into it and deceive state-of-the-art\ndetectors into believing the image was acquired by that model. Likewise, we\ndeceive independent detectors of synthetic GAN images into believing the image\nis real. Experiments prove the effectiveness of the proposed method in a wide\narray of conditions. Moreover, no prior information on the attacked detectors\nis needed, but only sample images from the target camera.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 10:41:19 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 09:51:53 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Cozzolino", "Davide", ""], ["Thies", "Justus", ""], ["R\u00f6ssler", "Andreas", ""], ["Nie\u00dfner", "Matthias", ""], ["Verdoliva", "Luisa", ""]]}, {"id": "1911.12080", "submitter": "Mohamed Nabeel", "authors": "Euijin Choo, Mohamed Nabeel, Mashael Alsabah, Issa Khalil, Ting Yu,\n  Wei Wang", "title": "DeviceWatch: Identifying Compromised Mobile Devices through Network\n  Traffic Analysis and Graph Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to identify compromised mobile devices from a\nnetwork administrator's point of view. Intuitively, inadvertent users (and thus\ntheir devices) who download apps through untrustworthy markets are often\nallured to install malicious apps through in-app advertisement or phishing. We\nthus hypothesize that devices sharing a similar set of apps will have a similar\nprobability of being compromised, resulting in the association between a device\nbeing compromised and apps in the device. Our goal is to leverage such\nassociations to identify unknown compromised devices (i.e., devices possibly\nhaving yet currently not having known malicious apps) using the\nguilt-by-association principle. Admittedly, such associations could be quite\nweak as it is often hard, if not impossible, for an app to automatically\ndownload and install other apps without explicit initiation from a user. We\ndescribe how we can magnify such weak associations between devices and apps by\ncarefully choosing parameters when applying graph-based inferences. We\nempirically show the effectiveness of our approach with a comprehensive study\non the mobile network traffic provided by a major mobile service provider.\nConcretely, we achieve nearly 98\\% accuracy in terms of AUC (area under the ROC\ncurve). Given the relatively weak nature of association, we further conduct\nin-depth analysis of the different behavior of a graph-inference approach, by\ncomparing it to active DNS data. Moreover, we validate our results by showing\nthat detected compromised devices indeed present undesirable behavior in terms\nof their privacy leakage and network infrastructure accessed.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 11:16:48 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Choo", "Euijin", ""], ["Nabeel", "Mohamed", ""], ["Alsabah", "Mashael", ""], ["Khalil", "Issa", ""], ["Yu", "Ting", ""], ["Wang", "Wei", ""]]}, {"id": "1911.12095", "submitter": "Georgios Konstantopoulos Mr", "authors": "Georgios Konstantopoulos", "title": "Plasma Cash: Towards more efficient Plasma constructions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Plasma is a framework for scalable off-chain computation. We describe and\nevaluate Plasma Cash, an improved Plasma construction which leverages\nnon-fungible tokens and Sparse Merkle Trees to reduce the data storage and\nbandwidth requirements for users. We analyze the cryptoeconomic exit and\nchallenge mechanisms used to keep user funds secured, even when the Plasma Cash\nchain's consensus algorithm is compromised. A reference implementation is\nprovided for evaluation. Finally, we briefly discuss further improvements that\ncan be made to the Plasma Cash protocol such as arbitrary denomination\npayments, less user data checking, fast and optimistic exits.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 11:50:07 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Konstantopoulos", "Georgios", ""]]}, {"id": "1911.12139", "submitter": "Tobias Fiebig", "authors": "Tobias Fiebig", "title": "Moving Fast and Breaking Things: How to stop crashing more than twice", "comments": "Position Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Moving fast, and breaking things\", instead of \"being safe and secure\", is\nthe credo of the IT industry. In this paper, we take a look at how we keep\nfalling for the same security issues, and what we can learn from aviation\nsafety to learn building and operating IT systems securely. We find that\ncomputer security should adopt the idea of safety. This entails not only\nbuilding systems that are operating as desired in the presence of an active\nattacker, but also building them in a way that they remain secure and\noperational in the presence of any failure. Furthermore, we propose a 'clean\nslate policy design' to counter the current state of verbose, hardly followed\nbest practices, together with an incident handling and reporting structure\nsimilar to that found in aviation safety.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 12:38:23 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Fiebig", "Tobias", ""]]}, {"id": "1911.12318", "submitter": "Joshua Gans", "authors": "Neil Gandal and Joshua S. Gans", "title": "More (or Less) Economic Limits of the Blockchain", "comments": "14 pages, 2 Figures", "journal-ref": "Now published by Palgrave in an edited volume 2021", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends the blockchain sustainability framework of Budish (2018)\nto consider proof of stake (in addition to proof of work) consensus mechanisms\nand permissioned (where the number of nodes are fixed) networks. It is\ndemonstrated that an economically sustainable network will involve the same\ncost regardless of whether it is proof of work or proof of stake although in\nthe later the cost will take the form of illiquid financial resources. In\naddition, it is shown that regulating the number of nodes (as in a permissioned\nnetwork) does not lead to additional cost savings that cannot otherwise be\nachieved via a setting of block rewards in a permissionless (i.e., free entry)\nnetwork. This suggests that permissioned networks will not be able to economize\non costs relative to permissionless networks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 17:52:29 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 13:01:25 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Gandal", "Neil", ""], ["Gans", "Joshua S.", ""]]}, {"id": "1911.12322", "submitter": "Avital Shafran", "authors": "Avital Shafran, Gil Segev, Shmuel Peleg, Yedid Hoshen", "title": "Crypto-Oriented Neural Architecture Design", "comments": "Full version (shorter version published in ICASSP'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As neural networks revolutionize many applications, significant privacy\nconflicts between model users and providers emerge. The cryptography community\ndeveloped a variety of techniques for secure computation to address such\nprivacy issues. As generic techniques for secure computation are typically\nprohibitively ineffective, many efforts focus on optimizing their underlying\ncryptographic tools. Differently, we propose to optimize the initial design of\ncrypto-oriented neural architectures and provide a novel Partial Activation\nlayer. The proposed layer is much faster for secure computation. Evaluating our\nmethod on three state-of-the-art architectures (SqueezeNet, ShuffleNetV2, and\nMobileNetV2) demonstrates significant improvement to the efficiency of secure\ninference on common evaluation metrics.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 17:57:42 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 17:48:31 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 06:42:31 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Shafran", "Avital", ""], ["Segev", "Gil", ""], ["Peleg", "Shmuel", ""], ["Hoshen", "Yedid", ""]]}, {"id": "1911.12332", "submitter": "Thanh Bui", "authors": "Thanh Bui and Siddharth Rao and Markku Antikainen and Tuomas Aura", "title": "XSS Vulnerabilities in Cloud-Application Add-Ons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud-application add-ons are microservices that extend the functionality of\nthe core applications. Many application vendors have opened their APIs for\nthird-party developers and created marketplaces for add-ons (also add-ins or\napps). This is a relatively new phenomenon, and its effects on the application\nsecurity have not been widely studied. It seems likely that some of the add-ons\nhave lower code quality than the core applications themselves and, thus, may\nbring in security vulnerabilities. We found that many such add-ons are\nvulnerable to cross-site scripting (XSS). The attacker can take advantage of\nthe document-sharing and messaging features of the cloud applications to send\nmalicious input to them. The vulnerable add-ons then execute client-side\nJavaScript from the carefully crafted malicious input. In a major analysis\neffort, we systematically studied 300 add-ons for three popular application\nsuites, namely Microsoft Office Online, G Suite and Shopify, and discovered a\nsignificant percentage of vulnerable add-ons in each marketplace. We present\nthe results of this study, as well as analyze the add-on architectures to\nunderstand how the XSS vulnerabilities can be exploited and how the threat can\nbe mitigated.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 18:22:51 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Bui", "Thanh", ""], ["Rao", "Siddharth", ""], ["Antikainen", "Markku", ""], ["Aura", "Tuomas", ""]]}, {"id": "1911.12457", "submitter": "Hadis Mohseni", "authors": "Sina Hojjatinia, Sajad Hamzenejadi, and Hadis Mohseni", "title": "Android Botnet Detection using Convolutional Neural Networks", "comments": "submitted to conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, Android devices are able to provide various services. They support\napplications for different purposes such as entertainment, business, health,\neducation, and banking services. Because of the functionality and popularity of\nAndroid devices as well as the open-source policy of Android OS, they have\nbecome a suitable target for attackers. Android Botnet is one of the most\ndangerous malwares because an attacker called Botmaster can control that\nremotely to perform destructive attacks. A number of researchers have used\ndifferent well-known Machine Learning (ML) methods to recognize Android Botnets\nfrom benign applications. However, these conventional methods are not able to\ndetect new sophisticated Android Botnets. In this paper, we propose a novel\nmethod based on Android permissions and Convolutional Neural Networks (CNNs) to\nclassify Botnets and benign Android applications. Being the first developed\nmethod that uses CNNs for this aim, we also proposed a novel method to\nrepresent each application as an image which is constructed based on the\nco-occurrence of used permissions in that application. The proposed CNN is a\nbinary classifier that is trained using these images. Evaluating the proposed\nmethod on 5450 Android applications consist of Botnet and benign samples, the\nobtained results show the accuracy of 97.2% and recall of 96% which is a\npromising result just using Android permissions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 23:03:49 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Hojjatinia", "Sina", ""], ["Hamzenejadi", "Sajad", ""], ["Mohseni", "Hadis", ""]]}, {"id": "1911.12560", "submitter": "Jierui Lin", "authors": "Jierui Lin, Min Du, Jian Liu", "title": "Free-riders in Federated Learning: Attacks and Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a recently proposed paradigm that enables multiple\nclients to collaboratively train a joint model. It allows clients to train\nmodels locally, and leverages the parameter server to generate a global model\nby aggregating the locally submitted gradient updates at each round. Although\nthe incentive model for federated learning has not been fully developed, it is\nsupposed that participants are able to get rewards or the privilege to use the\nfinal global model, as a compensation for taking efforts to train the model.\nTherefore, a client who does not have any local data has the incentive to\nconstruct local gradient updates in order to deceive for rewards. In this\npaper, we are the first to propose the notion of free rider attacks, to explore\npossible ways that an attacker may construct gradient updates, without any\nlocal training data. Furthermore, we explore possible defenses that could\ndetect the proposed attacks, and propose a new high dimensional detection\nmethod called STD-DAGMM, which particularly works well for anomaly detection of\nmodel parameters. We extend the attacks and defenses to consider more free\nriders as well as differential privacy, which sheds light on and calls for\nfuture research in this field.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 07:13:48 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Lin", "Jierui", ""], ["Du", "Min", ""], ["Liu", "Jian", ""]]}, {"id": "1911.12562", "submitter": "Guozhu Meng", "authors": "Yingzhe He and Guozhu Meng and Kai Chen and Xingbo Hu and Jinwen He", "title": "Towards Security Threats of Deep Learning Systems: A Survey", "comments": "28 pages, 6 figures", "journal-ref": "IEEE Transactions on Software Engineering 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has gained tremendous success and great popularity in the past\nfew years. However, deep learning systems are suffering several inherent\nweaknesses, which can threaten the security of learning models. Deep learning's\nwide use further magnifies the impact and consequences. To this end, lots of\nresearch has been conducted with the purpose of exhaustively identifying\nintrinsic weaknesses and subsequently proposing feasible mitigation. Yet few\nare clear about how these weaknesses are incurred and how effective these\nattack approaches are in assaulting deep learning. In order to unveil the\nsecurity weaknesses and aid in the development of a robust deep learning\nsystem, we undertake an investigation on attacks towards deep learning, and\nanalyze these attacks to conclude some findings in multiple views. In\nparticular, we focus on four types of attacks associated with security threats\nof deep learning: model extraction attack, model inversion attack, poisoning\nattack and adversarial attack. For each type of attack, we construct its\nessential workflow as well as adversary capabilities and attack goals. Pivot\nmetrics are devised for comparing the attack approaches, by which we perform\nquantitative and qualitative analyses. From the analysis, we have identified\nsignificant and indispensable factors in an attack vector, e.g., how to reduce\nqueries to target models, what distance should be used for measuring\nperturbation. We shed light on 18 findings covering these approaches' merits\nand demerits, success probability, deployment complexity and prospects.\nMoreover, we discuss other potential security weaknesses and possible\nmitigation which can inspire relevant research in this area.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 07:16:05 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 17:27:53 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["He", "Yingzhe", ""], ["Meng", "Guozhu", ""], ["Chen", "Kai", ""], ["Hu", "Xingbo", ""], ["He", "Jinwen", ""]]}, {"id": "1911.12593", "submitter": "Aziz Mohaisen", "authors": "David Mohaisen and Songqing Chen", "title": "Computer Systems Have 99 Problems, Let's Not Make Machine Learning\n  Another One", "comments": "5 pages; 0 figures; 0 tables. To appear in IEEE TPS 2019 (vision\n  track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques are finding many applications in computer\nsystems, including many tasks that require decision making: network\noptimization, quality of service assurance, and security. We believe machine\nlearning systems are here to stay, and to materialize on their potential we\nadvocate a fresh look at various key issues that need further attention,\nincluding security as a requirement and system complexity, and how machine\nlearning systems affect them. We also discuss reproducibility as a key\nrequirement for sustainable machine learning systems, and leads to pursuing it.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 08:43:01 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Mohaisen", "David", ""], ["Chen", "Songqing", ""]]}, {"id": "1911.12704", "submitter": "Claire Bowen", "authors": "Claire McKay Bowen and Joshua Snoke", "title": "Comparative Study of Differentially Private Synthetic Data Algorithms\n  from the NIST PSCR Differential Privacy Synthetic Data Challenge", "comments": "32 pages (27 main, 5 references), 3 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentially private synthetic data generation offers a recent solution to\nrelease analytically useful data while preserving the privacy of individuals in\nthe data. In order to utilize these algorithms for public policy decisions,\npolicymakers need an accurate understanding of these algorithms' comparative\nperformance. Correspondingly, data practitioners require standard metrics for\nevaluating the analytic qualities of the synthetic data. In this paper, we\npresent an in-depth evaluation of several differentially private synthetic data\nalgorithms using actual differentially private synthetic data sets created by\ncontestants in the 2018-2019 National Institute of Standards and Technology\nPublic Safety Communications Research (NIST PSCR) Division's ``Differential\nPrivacy Synthetic Data Challenge.'' We offer analyses of these algorithms based\non both the accuracy of the data they created and their usability by potential\ndata providers. We frame the methods used in the NIST PSCR data challenge\nwithin the broader differentially private synthetic data literature. We\nimplement additional utility metrics, including two of our own, on the\ndifferentially private synthetic data and compare mechanism utility on three\ncategories. Our comparative assessment of the differentially private data\nsynthesis methods and the quality metrics shows the relative usefulness, the\ngeneral strengths and weaknesses, and offers preferred choices of algorithms\nand metrics. Finally we describe the implications of our evaluation for\npolicymakers seeking to implement differentially private synthetic data\nalgorithms on future data products.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 13:38:17 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 14:28:10 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 13:38:52 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Bowen", "Claire McKay", ""], ["Snoke", "Joshua", ""]]}, {"id": "1911.12757", "submitter": "Roberto Metere", "authors": "Luca Arnaboldi, Ricardo M. Czekster, Roberto Metere, Charles Morisset", "title": "Modelling Load-Changing Attacks in Cyber-Physical Systems", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-Physical Systems (CPS) are present in many settings addressing a myriad\nof purposes. Examples are Internet-of-Things (IoT) or sensing software embedded\nin appliances or even specialised meters that measure and respond to\nelectricity demands in smart grids. Due to their pervasive nature, they are\nusually chosen as recipients for larger scope cyber-security attacks. Those\npromote system-wide disruptions and are directed towards one key aspect such as\nconfidentiality, integrity, availability or a combination of those\ncharacteristics. Our paper focuses on a particular and distressing attack where\ncoordinated malware infected IoT units are maliciously employed to\nsynchronously turn on or off high-wattage appliances, affecting the grid's\nprimary control management. Our model could be extended to larger (smart)\ngrids, Active Buildings as well as similar infrastructures. Our approach models\nCoordinated Load-Changing Attacks (CLCA) also referred as GridLock or BlackIoT,\nagainst a theoretical power grid, containing various types of power plants. It\nemploys Continuous-Time Markov Chains where elements such as Power Plants and\nBotnets are modelled under normal or attack situations to evaluate the effect\nof CLCA in power reliant infrastructures. We showcase our modelling approach in\nthe scenario of a power supplier (e.g. power plant) being targeted by a botnet.\nWe demonstrate how our modelling approach can quantify the impact of a botnet\nattack and be abstracted for any CPS system involving power load management in\na smart grid. Our results show that by prioritising the type of power-plants,\nthe impact of the attack may change: in particular, we find the most impacting\nattack times and show how different strategies impact their success. We also\nfind the best power generator to use depending on the current demand and\nstrength of attack.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 15:49:38 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 11:52:11 GMT"}, {"version": "v3", "created": "Tue, 17 Dec 2019 10:02:52 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Arnaboldi", "Luca", ""], ["Czekster", "Ricardo M.", ""], ["Metere", "Roberto", ""], ["Morisset", "Charles", ""]]}, {"id": "1911.12777", "submitter": "Peeter Laud", "authors": "Peeter Laud and Alisa Pankova", "title": "Interpreting Epsilon of Differential Privacy in Terms of Advantage in\n  Guessing or Approximating Sensitive Attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are numerous methods of achieving $\\epsilon$-differential privacy (DP).\nThe question is what is the appropriate value of $\\epsilon$, since there is no\ncommon agreement on a \"sufficiently small\" $\\epsilon$, and its goodness depends\non the query as well as the data. In this paper, we show how to compute\n$\\epsilon$ that corresponds to $\\delta$, defined as the adversary's advantage\nin probability of guessing some specific property of the output. The attacker's\ngoal can be stated as Boolean expression over guessing particular attributes,\npossibly within some precision. The attributes combined in this way should be\nindependent. We assume that both the input and the output distributions have\ncorresponding probability density functions, or probability mass functions.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 16:24:51 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Laud", "Peeter", ""], ["Pankova", "Alisa", ""]]}, {"id": "1911.12834", "submitter": "Xiaolan Gu", "authors": "Xiaolan Gu, Ming Li, Yueqiang Cheng, Li Xiong, Yang Cao", "title": "PCKV: Locally Differentially Private Correlated Key-Value Data\n  Collection with Optimized Utility", "comments": "The paper was submitted to Usenix Security Symposium in August 2019\n  and will appear in Usenix Security Symposium 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data collection under local differential privacy (LDP) has been mostly\nstudied for homogeneous data. Real-world applications often involve a mixture\nof different data types such as key-value pairs, where the frequency of keys\nand mean of values under each key must be estimated simultaneously. For\nkey-value data collection with LDP, it is challenging to achieve a good\nutility-privacy tradeoff since the data contains two dimensions and a user may\npossess multiple key-value pairs. There is also an inherent correlation between\nkey and values which if not harnessed, will lead to poor utility. In this\npaper, we propose a locally differentially private key-value data collection\nframework that utilizes correlated perturbations to enhance utility. We\ninstantiate our framework by two protocols PCKV-UE (based on Unary Encoding)\nand PCKV-GRR (based on Generalized Randomized Response), where we design an\nadvanced Padding-and-Sampling mechanism and an improved mean estimator which is\nnon-interactive. Due to our correlated key and value perturbation mechanisms,\nthe composed privacy budget is shown to be less than that of independent\nperturbation of key and value, which enables us to further optimize the\nperturbation parameters via budget allocation. Experimental results on both\nsynthetic and real-world datasets show that our proposed protocols achieve\nbetter utility for both frequency and mean estimations under the same LDP\nguarantees than state-of-the-art mechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 19:14:55 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Gu", "Xiaolan", ""], ["Li", "Ming", ""], ["Cheng", "Yueqiang", ""], ["Xiong", "Li", ""], ["Cao", "Yang", ""]]}, {"id": "1911.12862", "submitter": "Muhammad Junaid Farooq", "authors": "Timothy Kieras and Muhammad Junaid Farooq and Quanyan Zhu", "title": "RIoTS: Risk Analysis of IoT Supply Chain Threats", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Securing the supply chain of information and communications technology (ICT)\nhas recently emerged as a critical concern for national security and integrity.\nWith the proliferation of Internet of Things (IoT) devices and their increasing\nrole in controlling real world infrastructure, there is a need to analyze risks\nin networked systems beyond established security analyses. Existing methods in\nliterature typically leverage attack and fault trees to analyze malicious\nactivity and its impact. In this paper, we develop RIoTS, a security risk\nassessment framework borrowing from system reliability theory to incorporate\nthe supply chain. We also analyze the impact of grouping within suppliers that\nmay pose hidden risks to the systems from malicious supply chain actors. The\nresults show that the proposed analysis is able to reveal hidden threats posed\nto the IoT ecosystem from potential supplier collusion.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 20:58:25 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Kieras", "Timothy", ""], ["Farooq", "Muhammad Junaid", ""], ["Zhu", "Quanyan", ""]]}, {"id": "1911.12929", "submitter": "YongJie Ye", "authors": "YongJie Ye, Jingjing Zhang, Weigang Wu, Xiapu Luo, Jiannong Cao", "title": "Boros: Secure Cross-Channel Transfers via Channel Hub", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The payment channel, which allows two parties to perform micropayments\nwithout involving the blockchain, has become a promising proposal to improve\nthe scalability of decentralized ledgers such as Bitcoin and Ethereum. Payment\nchannels have been extended to the payment network, through which users can\nutilize existing channels as intermediary links to route coins to others.\nHowever, routing payments through multiple channels bears nontrivial overheads.\nIt requires every intermediary channel to lock a portion of its available\ncapacity until the payment is settled. This may lead to deadlock in a\nconcurrent situation. The intermediary nodes in a payment path may also charge\nfees for routing a payment. The longer the routing path, the more serious the\nabove problems.\n  In this paper, we design and develop a novel off-chain system to shorten the\nrouting path for the payment network. In particular, we propose the channel\nhub, which is an extension of the payment hub, to allows transferring coins\ndirectly from one payment channel to another within the same hub. That is, the\nchannel hub can be viewed as a shortcut device for the underlying payment\nnetwork. We design a new protocol named Boros to perform secure off-chain\ncross-channel transfers through the channel hub. We not only present the\nsecurity definition of the Boros protocol formally but also prove its security\nusing the UC-framework. To demonstrate the feasibility of the Boros protocol,\nwe develop a proof-of-concept prototype running on the Ethereum. Our evaluation\nshows that our system can effectively shorten the off-chain routing path.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 02:41:39 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Ye", "YongJie", ""], ["Zhang", "Jingjing", ""], ["Wu", "Weigang", ""], ["Luo", "Xiapu", ""], ["Cao", "Jiannong", ""]]}, {"id": "1911.12942", "submitter": "Wang Taotao", "authors": "Taotao Wang, Soung Chang Liew, Shengli Zhang", "title": "When Blockchain Meets AI: Optimal Mining Strategy Achieved By Machine\n  Learning", "comments": "This work was accepted for publication in International Journal of\n  Intelligent Systems, pp 1-13, Jan, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work applies reinforcement learning (RL) from the AI machine learning\nfield to derive an optimal Bitcoin-like blockchain mining strategy without\nknowing the details of the blockchain network model. Previously, the most\nprofitable mining strategy was believed to be honest mining encoded in the\ndefault blockchain protocol. It was shown later that it is possible to gain\nmore mining rewards by deviating from honest mining. In particular, the mining\nproblem can be formulated as a Markov Decision Process (MDP) which can be\nsolved to give the optimal mining strategy. However, solving the mining MDP\nrequires knowing the values of various parameters that characterize the\nblockchain network model. In real blockchain networks, these parameter values\nare not easy to obtain and may change over time. This hinders the use of the\nMDP model-based solution. In this work, we employ RL to dynamically learn a\nmining strategy with performance approaching that of the optimal mining\nstrategy by observing and interacting with the network. Since the mining MDP\nproblem has a non-linear objective function (rather than linear functions of\nstandard MDP problems), we design a new multi-dimensional RL algorithm to solve\nthe problem. Experimental results indicate that, without knowing the parameter\nvalues of the mining MDP model, our multi-dimensional RL mining algorithm can\nstill achieve the optimal performance over time-varying blockchain networks.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 03:46:28 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 04:19:42 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2021 05:38:55 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Wang", "Taotao", ""], ["Liew", "Soung Chang", ""], ["Zhang", "Shengli", ""]]}, {"id": "1911.12968", "submitter": "A.J. Santos", "authors": "A.J. Santos", "title": "Recognition of Blockchain-based Multisignature E-Awards", "comments": "Paper presented at Ankara Yildirim Beyazit University International\n  Arbitration Symposium on 25 April 2019. Applied computing Law", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With blockchain technology, information is recorded in a permanent\ndistributed ledger that is maintained by multiple computers in a peer-to-peer\nnetwork. There is no central authority that can alter records or change network\nconsensus rules. Such technology could be utilized for voting, title transfers,\nissuance of company shares, document notarization, but currently, the most\npopular use-case are virtual currencies. An interesting feature that some\nvirtual currencies have is a multisignature (multisig) protocol that requires\nthe electronic signatures from more than one private key to initiate a transfer\nof funds. Raw data of a multisig transaction may be recognized as an arbitral\naward under the New York Convention, where the law of England is the lex\narbitri and parties have opted-out of a reasoned award.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 06:41:07 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Santos", "A. J.", ""]]}, {"id": "1911.13119", "submitter": "Julien Lavauzelle", "authors": "Julien Lavauzelle and Pierre Loidreau and Ba-Duc Pham", "title": "RAMESSES, a Rank Metric Encryption Scheme with Short Keys", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a rank metric code-based encryption scheme with key and ciphertext\nsizes comparable to that of isogeny-based cryptography for an equivalent\nsecurity level. The system also benefits from efficient encryption and\ndecryption algorithms, which rely on linear algebra operations over finite\nfields of moderate sizes. The security only relies on rank metric decoding\nproblems, and does not require to hide the structure of a code. Based on the\ncurrent knowledge, those problems cannot be efficiently solved by a quantum\ncomputer. Finally, the proposed scheme admits a failure probability that can be\nprecisely controlled and made as low as possible.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 14:23:18 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Lavauzelle", "Julien", ""], ["Loidreau", "Pierre", ""], ["Pham", "Ba-Duc", ""]]}, {"id": "1911.13193", "submitter": "Julian Renner", "authors": "Julian Renner, Thomas Jerkovits, Hannes Bartz, Sven Puchinger, Pierre\n  Loidreau, Antonia Wachter-Zeh", "title": "Randomized Decoding of Gabidulin Codes Beyond the Unique Decoding Radius", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of decoding Gabidulin codes beyond their unique\nerror-correction radius. The complexity of this problem is of importance to\nassess the security of some rank-metric code-based cryptosystems. We propose an\napproach that introduces row or column erasures to decrease the rank of the\nerror in order to use any proper polynomial-time Gabidulin code error-erasure\ndecoding algorithm. This approach improves on generic rank-metric decoders by\nan exponential factor.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 17:00:40 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 09:29:14 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 09:40:49 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Renner", "Julian", ""], ["Jerkovits", "Thomas", ""], ["Bartz", "Hannes", ""], ["Puchinger", "Sven", ""], ["Loidreau", "Pierre", ""], ["Wachter-Zeh", "Antonia", ""]]}]