[{"id": "2006.00076", "submitter": "Zhuojia Shen", "authors": "Zhuojia Shen, Komail Dharsee, John Criswell", "title": "Fast Execute-Only Memory for Embedded Systems", "comments": "8 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remote code disclosure attacks threaten embedded systems as they allow\nattackers to steal intellectual property or to find reusable code for use in\ncontrol-flow hijacking attacks. Execute-only memory (XOM) prevents remote code\ndisclosures, but existing XOM solutions either require a memory management unit\nthat is not available on ARM embedded systems or incur significant overhead.\n  We present PicoXOM: a fast and novel XOM system for ARMv7-M and ARMv8-M\ndevices which leverages ARM's Data Watchpoint and Tracing unit along with the\nprocessor's simplified memory protection hardware. On average, PicoXOM incurs\n0.33% performance overhead and 5.89% code size overhead on two benchmark suites\nand five real-world applications.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 20:56:28 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 20:25:30 GMT"}, {"version": "v3", "created": "Fri, 4 Sep 2020 17:02:19 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Shen", "Zhuojia", ""], ["Dharsee", "Komail", ""], ["Criswell", "John", ""]]}, {"id": "2006.00097", "submitter": "Liang Wang", "authors": "Liang Wang, Hyojoon Kim, Prateek Mittal, Jennifer Rexford", "title": "Programmable In-Network Obfuscation of Traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in programmable switch hardware offer a fresh opportunity to\nprotect user privacy. This paper presents PINOT, a lightweight in-network\nanonymity solution that runs at line rate within the memory and processing\nconstraints of hardware switches. PINOT encrypts a client's IPv4 address with\nan efficient encryption scheme to hide the address from downstream ASes and the\ndestination server. PINOT is readily deployable, requiring no end-user software\nor cooperation from networks other than the trusted network where it runs. We\nimplement a PINOT prototype on the Barefoot Tofino switch, deploy PINOT in a\ncampus network, and present results on protecting user identity against public\nDNS, NTP, and WireGuard VPN services.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 22:11:26 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Wang", "Liang", ""], ["Kim", "Hyojoon", ""], ["Mittal", "Prateek", ""], ["Rexford", "Jennifer", ""]]}, {"id": "2006.00165", "submitter": "Ashraf Tantawy", "authors": "Ashraf Tantawy, Sherif Abdelwahed, and Abdelkarim Erradi", "title": "Cyber LOPA: An Integrated Approach for the Design of Dependable and\n  Secure Cyber Physical Systems", "comments": "Main Content: Title adjusted, Related work moved to end, added\n  references, Sec IV (prev. sec V): expanded discussion, design and Alg. 1\n  updated | Sec V (prev. sec VI): Expanded discussion, Table V Expanded.\n  Editorial: Fig 1 redrawn horiz., Eq (4)(5) math notation changed, same\n  content. Eq (25) expanded, Page-wide eq. not ref as fig (shift by 1 of fig\n  num), Fig 4 iterative design values shown", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safety risk assessment is an essential process to ensure a dependable\nCyber-Physical System (CPS) design. Traditional risk assessment considers only\nphysical failures. For modern CPS, failures caused by cyber attacks are on the\nrise. The focus of latest research effort is on safety-security lifecycle\nintegration and the expansion of modeling formalism for risk assessment to\nincorporate security failures. The interaction between safety and security and\nits impact on the overall system design, as well as the reliability loss\nresulting from ignoring security failures are some of the overlooked research\nquestions. This paper addresses these research questions by presenting a new\nsafety design method named Cyber Layer Of Protection Analysis (CLOPA) that\nextends existing LOPA framework to include failures caused by cyber attacks.\nThe proposed method provides a rigorous mathematical formulation that expresses\nquantitatively the trade-off between designing a highly-reliable versus a\nhighly-secure CPS. We further propose a co-design lifecycle process that\nintegrates the safety and security risk assessment processes. We evaluate the\nproposed CLOPA approach and the integrated lifecycle on a practical case study\nof a process reactor controlled by an industrial control testbed, and provide a\ncomparison between the proposed CLOPA and current LOPA risk assessment\npractice.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 03:53:18 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 18:53:26 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 12:32:14 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Tantawy", "Ashraf", ""], ["Abdelwahed", "Sherif", ""], ["Erradi", "Abdelkarim", ""]]}, {"id": "2006.00310", "submitter": "Ahmed Raoof", "authors": "Ahmed Raoof, Chung-Horng Lung, Ashraf Matrawy", "title": "Introducing Network Coding to RPL: The Chained Secure Mode (CSM)", "comments": "4 pages, 6 figures, 1 table, Accepted at The 19th IEEE International\n  Symposium on Network Computing and Applications (NCA 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current standard of Routing Protocol for Low Power and Lossy Networks\n(RPL) incorporates three modes of security: the Unsecured Mode (UM),\nPreinstalled Secure Mode (PSM), and the Authenticated Secure Mode (ASM). While\nthe PSM and ASM are intended to protect against external routing attacks and\nsome replay attacks (through an optional replay protection mechanism), recent\nresearch showed that RPL in PSM is still vulnerable to many routing attacks,\nboth internal and external. In this paper, we propose a novel secure mode for\nRPL, the Chained Secure Mode (CSM), based on the concept of intraflow Network\nCoding. The main goal of CSM is to enhance RPL resilience against replay\nattacks, with the ability to mitigate some of them. The security and\nperformance of a proof-of-concept prototype of CSM were evaluated and compared\nagainst RPL in UM and PSM (with and without the optional replay protection) in\nthe presence of Neighbor attack as an example. It showed that CSM has better\nperformance and more enhanced security compared to both the UM and PSM with the\nreplay protection. On the other hand, it showed a need for a proper recovery\nmechanism for the case of losing a control message.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 16:24:07 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 23:18:42 GMT"}, {"version": "v3", "created": "Thu, 26 Nov 2020 16:45:11 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Raoof", "Ahmed", ""], ["Lung", "Chung-Horng", ""], ["Matrawy", "Ashraf", ""]]}, {"id": "2006.00505", "submitter": "Brandon Reagen", "authors": "Brandon Reagen, Wooseok Choi, Yeongil Ko, Vincent Lee, Gu-Yeon Wei,\n  Hsien-Hsin S. Lee, David Brooks", "title": "Cheetah: Optimizing and Accelerating Homomorphic Encryption for Private\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the application of deep learning continues to grow, so does the amount of\ndata used to make predictions. While traditionally, big-data deep learning was\nconstrained by computing performance and off-chip memory bandwidth, a new\nconstraint has emerged: privacy. One solution is homomorphic encryption (HE).\nApplying HE to the client-cloud model allows cloud services to perform\ninference directly on the client's encrypted data. While HE can meet privacy\nconstraints, it introduces enormous computational challenges and remains\nimpractically slow in current systems.\n  This paper introduces Cheetah, a set of algorithmic and hardware\noptimizations for HE DNN inference to achieve plaintext DNN inference speeds.\nCheetah proposes HE-parameter tuning optimization and operator scheduling\noptimizations, which together deliver 79x speedup over the state-of-the-art.\nHowever, this still falls short of plaintext inference speeds by almost four\norders of magnitude. To bridge the remaining performance gap, Cheetah further\nproposes an accelerator architecture that, when combined with the algorithmic\noptimizations, approaches plaintext DNN inference speeds. We evaluate several\ncommon neural network models (e.g., ResNet50, VGG16, and AlexNet) and show that\nplaintext-level HE inference for each is feasible with a custom accelerator\nconsuming 30W and 545mm^2.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 12:33:13 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 19:51:50 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Reagen", "Brandon", ""], ["Choi", "Wooseok", ""], ["Ko", "Yeongil", ""], ["Lee", "Vincent", ""], ["Wei", "Gu-Yeon", ""], ["Lee", "Hsien-Hsin S.", ""], ["Brooks", "David", ""]]}, {"id": "2006.00514", "submitter": "Fedor Ivanov", "authors": "Fedor Ivanov, Eugenii Krouk", "title": "New Code-Based Cryptosystem with Arbitrary Error Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  McEliece cryptosystem represents a smart open key system based on the\nhardness of the decoding of an arbitrary linear code, which is believed to be\nable to resist the advent of quantum computers. But the original McEliece\ncryptosystem, based on Goppa codes, has just very limited interest in practice,\npartly because it requires a very large public key. In this paper we propose a\nnew general way to reduce the public key size. Unlike most papers on reducing\nkey length of the cryptosystem, where original Goppa codes are substituted by\nsome other codes, we suggest a new method of key size reduction which is\ncode-independent.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 12:55:56 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Ivanov", "Fedor", ""], ["Krouk", "Eugenii", ""]]}, {"id": "2006.00529", "submitter": "Georgios Magklaras", "authors": "Georgios Magklaras, Lucia Nikolaia Lopez Bojorquez", "title": "A review of information security aspects of the emerging COVID-19\n  contact tracing mobile phone applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper discusses the aspects of data reliability and user privacy for the\nemerging practice of mobile phone based contact tracing for the COVID-19\npandemic. Various countries and large technology companies have already used or\nplan to design and use mobile phone based solutions, in an effort to urgently\nexpedite the process of identifying people who may have been exposed to the\ndisease and limit its spread to the general population. However, serious\nconcerns have been raised both in terms of the validity of the collected data\nas well as the extent to which implemented approaches can breach the privacy of\nthe mobile phone users. This review examines the weaknesses of existing\nimplementations and concludes with specific recommendations that can contribute\ntowards increasing the safety of infrastructures that collect and process this\nkind of information, as well as the adoption and acceptance of these solutions\nfrom the public.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 14:10:14 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Magklaras", "Georgios", ""], ["Bojorquez", "Lucia Nikolaia Lopez", ""]]}, {"id": "2006.00548", "submitter": "Gursel Serpen", "authors": "Firas Abbaas and Gursel Serpen", "title": "Evaluation of biometric user authentication using an ensemble classifier\n  with face and voice recognition", "comments": "11 pages, 8 Figures and 14 Tables. Accepted for publication in\n  Journal of Information Assurance and Security", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a biometric user authentication system based on an\nensemble design that employs face and voice recognition classifiers. The design\napproach entails development and performance evaluation of individual\nclassifiers for face and voice recognition and subsequent integration of the\ntwo within an ensemble framework. Performance evaluation employed three\nbenchmark datasets, which are NIST Feret face, Yale Extended face, and ELSDSR\nvoice. Performance evaluation of the ensemble design on the three benchmark\ndatasets indicates that the bimodal authentication system offers significant\nimprovements for accuracy, precision, true negative rate, and true positive\nrate metrics at or above 99% while generating minimal false positive and\nnegative rates of less than 1%.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 15:57:11 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Abbaas", "Firas", ""], ["Serpen", "Gursel", ""]]}, {"id": "2006.00577", "submitter": "Alessandro Ecclesie Agazzi", "authors": "Alessandro Ecclesie Agazzi", "title": "Phishing and Spear Phishing: examples in Cyber Espionage and techniques\n  to protect against them", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phishing attacks have become the most used technique in the online scams,\ninitiating more than 91% of cyberattacks, from 2012 onwards. This study reviews\nhow Phishing and Spear Phishing attacks are carried out by the phishers,\nthrough 5 steps which magnify the outcome, increasing the chance of success.\nThe focus will be also given on four different layers of protection against\nthese social engineering attacks, showing their strengths and weaknesses; the\nfirst and second layers consist of automated tools and decision-aid tools. the\nthird one is users' knowledge and expertise to deal with potential threats. The\nlast layer, defined as \"external\", will underline the importance of having a\nMulti-factor authentication, an effective way to provide an enhanced security,\ncreating a further layer of protection against Phishing and Spear Phishing.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 18:10:09 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Agazzi", "Alessandro Ecclesie", ""]]}, {"id": "2006.00618", "submitter": "Masoud Erfani", "authors": "Mohamad Khedmati, Masoud Erfani, Mohammad GhasemiGol", "title": "Applying support vector data description for fraud detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fraud detection is an important topic that applies to various enterprises\nsuch as banking and financial sectors, insurance, government agencies, law\nenforcement, and more. Fraud attempts have been risen remarkably in current\nyears, shaping fraud detection an essential topic for research. One of the main\nchallenges in fraud detection is acquiring fraud samples which is a complex and\nchallenging task. In order to deal with this challenge, we apply one-class\nclassification methods such as SVDD which does not need the fraud samples for\ntraining. Also, we present our algorithm REDBSCAN which is an extension of\nDBSCAN to reduce the number of samples and select those that keep the shape of\ndata. The results obtained by the implementation of the proposed method\nindicated that the fraud detection process was improved in both performance and\nspeed.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 21:31:32 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Khedmati", "Mohamad", ""], ["Erfani", "Masoud", ""], ["GhasemiGol", "Mohammad", ""]]}, {"id": "2006.00653", "submitter": "Nengkun Yu", "authors": "Peng Yan, and Nengkun Yu", "title": "The QQUIC Transport Protocol: Quantum assisted UDP Internet Connections", "comments": "Comments are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum key distribution, initialized in 1984, is a commercialized secure\ncommunication method which enables two parties to produce shared random secret\nkey by the nature of quantum mechanics. We propose QQUIC (Quantum assisted\nQuick UDP Internet Connections) transport protocol, which modifies the famous\nQUIC transport protocol by employing the quantum key distribution instead of\nthe original classical algorithms in the key exchanging stage. Thanks to the\nprovable security of quantum key distribution, the security of QQUIC key does\nnot depend on computational assumptions. Maybe surprisingly, QQUIC can reduce\nthe network latency in some circumstance even comparing with QUIC. To achieve\nthis, the attached quantum connections are used as the dedicated lines for key\ngeneration.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 00:44:58 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Yan", "Peng", ""], ["Yu", "Nengkun", ""]]}, {"id": "2006.00676", "submitter": "Md Hasan Shahriar", "authors": "Md Hasan Shahriar, Nur Imtiazul Haque, Mohammad Ashiqur Rahman, and\n  Miguel Alonso Jr", "title": "G-IDS: Generative Adversarial Networks Assisted Intrusion Detection\n  System", "comments": "10 pages, 4 figures, accepted in IEEE COMPSAC-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The boundaries of cyber-physical systems (CPS) and the Internet of Things\n(IoT) are converging together day by day to introduce a common platform on\nhybrid systems. Moreover, the combination of artificial intelligence (AI) with\nCPS creates a new dimension of technological advancement. All these\nconnectivity and dependability are creating massive space for the attackers to\nlaunch cyber attacks. To defend against these attacks, intrusion detection\nsystem (IDS) has been widely used. However, emerging CPS technologies suffer\nfrom imbalanced and missing sample data, which makes the training of IDS\ndifficult. In this paper, we propose a generative adversarial network (GAN)\nbased intrusion detection system (G-IDS), where GAN generates synthetic\nsamples, and IDS gets trained on them along with the original ones. G-IDS also\nfixes the difficulties of imbalanced or missing data problems. We model a\nnetwork security dataset for an emerging CPS using NSL KDD-99 dataset and\nevaluate our proposed model's performance using different metrics. We find that\nour proposed G-IDS model performs much better in attack detection and model\nstabilization during the training process than a standalone IDS.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 02:42:46 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Shahriar", "Md Hasan", ""], ["Haque", "Nur Imtiazul", ""], ["Rahman", "Mohammad Ashiqur", ""], ["Alonso", "Miguel", "Jr"]]}, {"id": "2006.00790", "submitter": "Aythami Morales", "authors": "Alejandro Acien and Aythami Morales and Ruben Vera-Rodriguez and\n  Julian Fierrez", "title": "Smartphone Sensors for Modeling Human-Computer Interaction: General\n  Outlook and Research Datasets for User Authentication", "comments": null, "journal-ref": "IEEE Intl. Workshop on Consumer Devices and Systems (CDS), 2020,\n  Madrid, Spain", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we list the sensors commonly available in modern smartphones\nand provide a general outlook of the different ways these sensors can be used\nfor modeling the interaction between human and smartphones. We then provide a\ntaxonomy of applications that can exploit the signals originated by these\nsensors in three different dimensions, depending on the main information\ncontent embedded in the signals exploited in the application: neuromotor\nskills, cognitive functions, and behaviors/routines. We then summarize a\nrepresentative selection of existing research datasets in this area, with\nspecial focus on applications related to user authentication, including key\nfeatures and a selection of the main research results obtained on them so far.\nThen, we perform the experimental work using the HuMIdb database (Human Mobile\nInteraction database), a novel multimodal mobile database that includes 14\nmobile sensors captured from 600 participants. We evaluate a biometric\nauthentication system based on simple linear touch gestures using a Siamese\nNeural Network architecture. Very promising results are achieved with\naccuracies up to 87% for person authentication based on a simple and fast touch\ngesture.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 08:24:25 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Acien", "Alejandro", ""], ["Morales", "Aythami", ""], ["Vera-Rodriguez", "Ruben", ""], ["Fierrez", "Julian", ""]]}, {"id": "2006.00860", "submitter": "Inken Hagestedt", "authors": "Inken Hagestedt (1), Michael Backes (1), Andreas Bulling (2) ((1)\n  CISPA Helmholtz Center for Information Security, (2) University of Stuttgart)", "title": "Adversarial Attacks on Classifiers for Eye-based User Modelling", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": "10.1145/3379157.3390511", "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ever-growing body of work has demonstrated the rich information content\navailable in eye movements for user modelling, e.g. for predicting users'\nactivities, cognitive processes, or even personality traits. We show that\nstate-of-the-art classifiers for eye-based user modelling are highly vulnerable\nto adversarial examples: small artificial perturbations in gaze input that can\ndramatically change a classifier's predictions. We generate these adversarial\nexamples using the Fast Gradient Sign Method (FGSM) that linearises the\ngradient to find suitable perturbations. On the sample task of eye-based\ndocument type recognition we study the success of different adversarial attack\nscenarios: with and without knowledge about classifier gradients (white-box vs.\nblack-box) as well as with and without targeting the attack to a specific\nclass, In addition, we demonstrate the feasibility of defending against\nadversarial attacks by adding adversarial examples to a classifier's training\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 11:42:04 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Hagestedt", "Inken", ""], ["Backes", "Michael", ""], ["Bulling", "Andreas", ""]]}, {"id": "2006.01043", "submitter": "Xiaoyi Chen", "authors": "Xiaoyi Chen, Ahmed Salem, Michael Backes, Shiqing Ma, Yang Zhang", "title": "BadNL: Backdoor Attacks Against NLP Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) has progressed rapidly during the past decade and ML\nmodels have been deployed in various real-world applications. Meanwhile,\nmachine learning models have been shown to be vulnerable to various security\nand privacy attacks. One attack that has attracted a great deal of attention\nrecently is the backdoor attack. Specifically, the adversary poisons the target\nmodel training set, to mislead any input with an added secret trigger to a\ntarget class, while keeping the accuracy for original inputs unchanged.\n  Previous backdoor attacks mainly focus on computer vision tasks. In this\npaper, we present the first systematic investigation of the backdoor attack\nagainst models designed for natural language processing (NLP) tasks.\nSpecifically, we propose three methods to construct triggers in the NLP\nsetting, including Char-level, Word-level, and Sentence-level triggers. Our\nAttacks achieve an almost perfect success rate without jeopardizing the\noriginal model utility. For instance, using the word-level triggers, our\nbackdoor attack achieves 100% backdoor accuracy with only a drop of 0.18%,\n1.26%, and 0.19% in the models utility, for the IMDB, Amazon, and Stanford\nSentiment Treebank datasets, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 16:17:14 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Chen", "Xiaoyi", ""], ["Salem", "Ahmed", ""], ["Backes", "Michael", ""], ["Ma", "Shiqing", ""], ["Zhang", "Yang", ""]]}, {"id": "2006.01072", "submitter": "Chenxing Li", "authors": "Chenxing Li, Fan Long, Guang Yang", "title": "GHAST: Breaking Confirmation Delay Barrier in Nakamoto Consensus via\n  Adaptive Weighted Blocks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Initiated from Nakamoto's Bitcoin system, blockchain technology has\ndemonstrated great capability of building secure consensus among decentralized\nparties at Internet-scale, i.e., without relying on any centralized trusted\nparty. Nowadays, blockchain systems find applications in various fields. But\nthe performance is increasingly becoming a bottleneck, especially when\npermissionless participation is retained for full decentralization.\n  In this work, we present a new consensus protocol named GHAST (Greedy\nHeaviest Adaptive Sub-Tree) which organizes blocks in a Tree-Graph structure\n(i.e., a directed acyclic graph (DAG) with a tree embedded) that allows fast\nand concurrent block generation. GHAST protocol simultaneously achieves a\nlogarithmically bounded liveness guarantee and low confirmation latency. More\nspecifically, for maximum latency $d$ and adversarial computing power bounded\naway from 50\\%, GHAST guarantees confirmation with confidence $\\ge\n1-\\varepsilon$ after a time period of $O(d\\cdot \\log(1/\\varepsilon))$. When\nthere is no observable attack, GHAST only needs $3d$ time to achieve\nconfirmation at the same confidence level as six-block-confirmation in Bitcoin,\nwhile it takes roughly $360d$ in Bitcoin.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 16:53:29 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Li", "Chenxing", ""], ["Long", "Fan", ""], ["Yang", "Guang", ""]]}, {"id": "2006.01085", "submitter": "Henry Yuen", "authors": "Zvika Brakerski, Henry Yuen", "title": "Quantum Garbled Circuits", "comments": "66 pages. Updated the erroneous claim from v1 about the complexity of\n  information-theoretic QRE as matching the classical case. Added an\n  application of QRE to zero-knowledge for QMA", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a garbling scheme for quantum circuits, thus achieving a\ndecomposable randomized encoding scheme for quantum computation. Specifically,\nwe show how to compute an encoding of a given quantum circuit and quantum\ninput, from which it is possible to derive the output of the computation and\nnothing else. In the classical setting, garbled circuits (and randomized\nencodings in general) are a versatile cryptographic tool with many applications\nsuch as secure multiparty computation, delegated computation, depth-reduction\nof cryptographic primitives, complexity lower-bounds, and more. However, a\nquantum analogue for garbling general circuits was not known prior to this\nwork. We hope that our quantum randomized encoding scheme can similarly be\nuseful for applications in quantum computing and cryptography.\n  To illustrate the usefulness of quantum randomized encoding, we use it to\ndesign a conceptually-simple zero-knowledge (ZK) proof system for the\ncomplexity class $\\mathbf{QMA}$. Our protocol has the so-called $\\Sigma$ format\nwith a single-bit challenge, and allows the inputs to be delayed to the last\nround. The only previously-known ZK $\\Sigma$-protocol for $\\mathbf{QMA}$ is due\nto Broadbent and Grilo (FOCS 2020), which does not have the aforementioned\nproperties.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 17:07:01 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 17:02:22 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Brakerski", "Zvika", ""], ["Yuen", "Henry", ""]]}, {"id": "2006.01181", "submitter": "Mohammad Ghafari", "authors": "Mohammad Ghafari, Pascal Gadient, Oscar Nierstrasz", "title": "Security Smells in Android", "comments": "2017 IEEE 17th International Working Conference on Source Code\n  Analysis and Manipulation (SCAM)", "journal-ref": null, "doi": "10.1109/SCAM.2017.24", "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ubiquity of smartphones, and their very broad capabilities and usage,\nmake the security of these devices tremendously important. Unfortunately,\ndespite all progress in security and privacy mechanisms, vulnerabilities\ncontinue to proliferate. Research has shown that many vulnerabilities are due\nto insecure programming practices. However, each study has often dealt with a\nspecific issue, making the results less actionable for practitioners. To\npromote secure programming practices, we have reviewed related research, and\nidentified avoidable vulnerabilities in Android-run devices and the \"security\ncode smells\" that indicate their presence. In particular, we explain the\nvulnerabilities, their corresponding smells, and we discuss how they could be\neliminated or mitigated during development. Moreover, we develop a lightweight\nstatic analysis tool and discuss the extent to which it successfully detects\nseveral vulnerabilities in about 46,000 apps hosted by the official Android\nmarket.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 18:16:39 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Ghafari", "Mohammad", ""], ["Gadient", "Pascal", ""], ["Nierstrasz", "Oscar", ""]]}, {"id": "2006.01264", "submitter": "Chaoting Xuan", "authors": "Chaoting Xuan", "title": "An End-to-End Encryption Solution for Enterprise Content Applications", "comments": "6 pages (includes references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The content host services (like Dropbox, OneDrive, and Google Drive) used by\nenterprise customers are deployed either on premise or in cloud. Because users\nmay store business-sensitive data (contents) in these hosting services, they\nmay want to protect their data from disclosure to anyone else, even IT\nadministrators. Unfortunately, even contents (files) are encrypted in the\nhosting services, they sometimes are still accessible to IT administrators\ntoday. The sensitive data could be exposed to public if the IT administrator\nturns malicious (like disgruntled employee) or his account is compromised by\nhackers.\n  We propose an end-to-end encryption (E2EE) solution to address this\nchallenge. The user data is encrypted at client side (mobile device) and\nremains encrypted in transit and at rest on server. Specifically, we design a\nnew method to allow master secret recover and escrow, while protecting them\nfrom being accessed by malicious administrators. In addition, we present a\ncontent (file) encryption scheme that achieves privacy, and granular access\ncontrol. And it can be seamlessly integrated with major content host services\nused by business users today.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 21:03:26 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Xuan", "Chaoting", ""]]}, {"id": "2006.01300", "submitter": "Hanieh Hashemi", "authors": "Hanieh Hashemi, Yongqin Wang, Murali Annavaram", "title": "DarKnight: A Data Privacy Scheme for Training and Inference of Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protecting the privacy of input data is of growing importance as machine\nlearning methods reach new application domains. In this paper, we provide a\nunified training and inference framework for large DNNs while protecting input\nprivacy and computation integrity. Our approach called DarKnight uses a novel\ndata blinding strategy using matrix masking to create input obfuscation within\na trusted execution environment (TEE). Our rigorous mathematical proof\ndemonstrates that our blinding process provides information-theoretic privacy\nguarantee by bounding information leakage. The obfuscated data can then be\noffloaded to any GPU for accelerating linear operations on blinded data. The\nresults from linear operations on blinded data are decoded before performing\nnon-linear operations within the TEE. This cooperative execution allows\nDarKnight to exploit the computational power of GPUs to perform linear\noperations while exploiting TEEs to protect input privacy. We implement\nDarKnight on an Intel SGX TEE augmented with a GPU to evaluate its performance.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 22:40:57 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 21:01:26 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Hashemi", "Hanieh", ""], ["Wang", "Yongqin", ""], ["Annavaram", "Murali", ""]]}, {"id": "2006.01342", "submitter": "Warit Sirichotedumrong", "authors": "Warit Sirichotedumrong and Hitoshi Kiya", "title": "A GAN-Based Image Transformation Scheme for Privacy-Preserving Deep\n  Neural Networks", "comments": "To be appeared on 28th European Signal Processing Conference (EUSIPCO\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel image transformation scheme using generative adversarial\nnetworks (GANs) for privacy-preserving deep neural networks (DNNs). The\nproposed scheme enables us not only to apply images without visual information\nto DNNs, but also to enhance robustness against ciphertext-only attacks (COAs)\nincluding DNN-based attacks. In this paper, the proposed transformation scheme\nis demonstrated to be able to protect visual information on plain images, and\nthe visually-protected images are directly applied to DNNs for\nprivacy-preserving image classification. Since the proposed scheme utilizes\nGANs, there is no need to manage encryption keys. In an image classification\nexperiment, we evaluate the effectiveness of the proposed scheme in terms of\nclassification accuracy and robustness against COAs.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 01:57:21 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Sirichotedumrong", "Warit", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "2006.01418", "submitter": "Gleb Naumenko", "authors": "Antoine Riard and Gleb Naumenko", "title": "Time-Dilation Attacks on the Lightning Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Lightning Network (LN) is a widely-used network of payment channels enabling\nfaster and cheaper Bitcoin transactions. In this paper, we outline three ways\nan attacker can steal funds from honest LN users. The attacks require dilating\nthe time for victims to become aware of new blocks by eclipsing (isolating)\nvictims from the network and delaying block delivery. While our focus is on the\nLN, time-dilation attacks may be relevant to any second-layer protocol that\nrelies on a timely reaction.\n  According to our measurements, it is currently possible to steal the total\nchannel capacity by keeping a node eclipsed for as little as 2 hours. Since\ntrust-minimized Bitcoin light clients currently connect to a very limited\nnumber of random nodes, running just 500 Sybil nodes allows an attacker to\nEclipse 47\\% of newly deployed light clients (and hence prime them for an\nattack). As for the victims running a full node, since they are often used by\nlarge hubs or service providers, an attacker may justify the higher Eclipse\nattack cost by stealing all their available liquidity.\n  In addition, time-dilation attacks neither require access to hashrate nor\npurchasing from a victim. Thus, this class of attacks is a more practical way\nof stealing funds via Eclipse attacks than previously anticipated\ndouble-spending.\n  We argue that simple detection techniques based on the slow block arrival\nalone are not effective, and implementing more sophisticated detection is not\ntrivial. We suggest that a combination of anti-Eclipse/anti-Sybil measures are\ncrucial for mitigating time-dilation attacks.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 06:50:14 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Riard", "Antoine", ""], ["Naumenko", "Gleb", ""]]}, {"id": "2006.01427", "submitter": "Daniel Reijsbergen", "authors": "Daniel Reijsbergen, Pawel Szalachowski, Junming Ke, Zengpeng Li,\n  Jianying Zhou", "title": "LaKSA: A Probabilistic Proof-of-Stake Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Large-scale Known-committee Stake-based Agreement (LaKSA), a\nchain-based Proof-of-Stake protocol that is dedicated, but not limited, to\ncryptocurrencies. LaKSA minimizes interactions between nodes through\nlightweight committee voting, resulting in a simpler, more robust, and more\nscalable proposal than competing systems. It also mitigates other drawbacks of\nprevious systems, such as high reward variance and long confirmation times.\nLaKSA can support large numbers of nodes by design, and provides probabilistic\nsafety guarantees in which a client makes commit decisions by calculating the\nprobability that a transaction is reverted based on its blockchain view. We\npresent a thorough analysis of LaKSA and report on its implementation and\nevaluation. Furthermore, our new technique of proving safety can be applied\nmore broadly to other Proof-of-Stake protocols.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 07:15:10 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 19:56:14 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Reijsbergen", "Daniel", ""], ["Szalachowski", "Pawel", ""], ["Ke", "Junming", ""], ["Li", "Zengpeng", ""], ["Zhou", "Jianying", ""]]}, {"id": "2006.01442", "submitter": "Bilal Ali Ahmad Mr", "authors": "Bilal Ali Ahmad", "title": "Real time Detection of Spectre and Meltdown Attacks Using Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently discovered Spectre and meltdown attacks affects almost all\nprocessors by leaking confidential information to other processes through\nside-channel attacks. These vulnerabilities expose design flaws in the\narchitecture of modern CPUs. To fix these design flaws, it is necessary to make\nchanges in the hardware of modern processors which is a non-trivial task.\nSoftware mitigation techniques for these vulnerabilities cause significant\nperformance degradation. In order to mitigate against Spectre and Meltdown\nattacks while retaining the performance benefits of modern processors, in this\npaper, we present a real-time detection mechanism for Spectre and Meltdown\nattacks by identifying the misuse of speculative execution and side-channel\nattacks. We use hardware performance counters and software events to monitor\nactivity related to speculative execution, branch prediction, and cache\ninterference. We use various machine learning models to analyze these events.\nThese events produce a very distinctive pattern while the system is under\nattack; machine learning models are able to detect Meltdown and Spectre attacks\nunder realistic load conditions with an accuracy of over 99%.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 08:16:02 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Ahmad", "Bilal Ali", ""]]}, {"id": "2006.01449", "submitter": "Chen Hajaj", "authors": "Chen Hajaj, Nitay Hason, Nissim Harel, Amit Dvir", "title": "Less is More: Robust and Novel Features for Malicious Domain Detection", "comments": "30 pages, 7 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malicious domains are increasingly common and pose a severe cybersecurity\nthreat. Specifically, many types of current cyber attacks use URLs for attack\ncommunications (e.g., C\\&C, phishing, and spear-phishing). Despite the\ncontinuous progress in detecting these attacks, many alarming problems remain\nopen, such as the weak spots of the defense mechanisms. Since machine learning\nhas become one of the most prominent methods of malware detection, A robust\nfeature selection mechanism is proposed that results in malicious domain\ndetection models that are resistant to evasion attacks. This mechanism exhibits\nhigh performance based on empirical data. This paper makes two main\ncontributions: First, it provides an analysis of robust feature selection based\non widely used features in the literature. Note that even though the feature\nset dimensional space is reduced by half (from nine to four features), the\nperformance of the classifier is still improved (an increase in the model's\nF1-score from 92.92\\% to 95.81\\%). Second, it introduces novel features that\nare robust to the adversary's manipulation. Based on an extensive evaluation of\nthe different feature sets and commonly used classification models, this paper\nshows that models that are based on robust features are resistant to malicious\nperturbations, and at the same time useful for classifying non-manipulated\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 08:40:37 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Hajaj", "Chen", ""], ["Hason", "Nitay", ""], ["Harel", "Nissim", ""], ["Dvir", "Amit", ""]]}, {"id": "2006.01607", "submitter": "Vladimir Shpilrain", "authors": "Mariya Bessonov, Dima Grigoriev, Vladimir Shpilrain", "title": "Probability theory and public-key cryptography", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short note, we address a common misconception at the interface of\nprobability theory and public-key cryptography.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 13:46:53 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Bessonov", "Mariya", ""], ["Grigoriev", "Dima", ""], ["Shpilrain", "Vladimir", ""]]}, {"id": "2006.01722", "submitter": "Zhenyuan Li", "authors": "Zhenyuan Li, Qi Alfred Chen, Runqing Yang, Yan Chen", "title": "Threat Detection and Investigation with System-level Provenance Graphs:\n  A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of information technology, the border of the cyberspace\ngets much broader, exposing more and more vulnerabilities to attackers.\nTraditional mitigation-based defence strategies are challenging to cope with\nthe current complicated situation. Security practitioners urgently need better\ntools to describe and modelling attacks for defence.\n  The provenance graph seems like an ideal method for threat modelling with\npowerful semantic expression ability and attacks historic correlation ability.\nIn this paper, we firstly introduce the basic concepts about system-level\nprovenance graph and proposed typical system architecture for provenance\ngraph-based threat detection and investigation. A comprehensive provenance\ngraph-based threat detection system can be divided into three modules, namely,\n\"data collection module\", \"data management module\", and \"threat detection\nmodules\". Each module contains several components and involves many research\nproblem. We systematically analyzed the algorithms and design details involved.\nBy comparison, we give the strategy of technology selection. Moreover, we\npointed out the shortcomings of the existing work for future improvement.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 15:50:08 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 05:08:12 GMT"}, {"version": "v3", "created": "Sun, 13 Dec 2020 11:07:30 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Li", "Zhenyuan", ""], ["Chen", "Qi Alfred", ""], ["Yang", "Runqing", ""], ["Chen", "Yan", ""]]}, {"id": "2006.01751", "submitter": "Jinani Sooriyaarachchi Ms", "authors": "Jinani Sooriyaarachchi, Suranga Seneviratne, Kanchana Thilakarathna,\n  and Albert Y. Zomaya", "title": "MusicID: A Brainwave-based User Authentication System for Internet of\n  Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose MusicID, an authentication solution for smart devices that uses\nmusic-induced brainwave patterns as a behavioral biometric modality. We\nexperimentally evaluate MusicID using data collected from real users whilst\nthey are listening to two forms of music; a popular English song and\nindividual's favorite song. We show that an accuracy over 98% for user\nidentification and an accuracy over 97% for user verification can be achieved\nby using data collected from a 4-electrode commodity brainwave headset. We\nfurther show that a single electrode is able to provide an accuracy of\napproximately 85% and the use of two electrodes provides an accuracy of\napproximately 95%. As already shown by commodity brain-sensing headsets for\nmeditation applications, we believe including dry EEG electrodes in\nsmart-headsets is feasible and MusicID has the potential of providing an entry\npoint and continuous authentication framework for upcoming surge of\nsmart-devices mainly driven by Augmented Reality (AR)/Virtual Reality (VR)\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 16:23:49 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Sooriyaarachchi", "Jinani", ""], ["Seneviratne", "Suranga", ""], ["Thilakarathna", "Kanchana", ""], ["Zomaya", "Albert Y.", ""]]}, {"id": "2006.01758", "submitter": "Peter Vitols", "authors": "Henri Aare, Peter Vitols", "title": "The Ritva Blockchain: Enabling Confidential Transactions at Scale", "comments": "The paper has been updated to address the editorial comments. arXiv\n  admin note: substantial text overlap with arXiv:1905.06460, arXiv:1811.12628\n  by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The distributed ledger technology has been widely hailed as the break-through\ntechnology. It has realised a great number of application scenarios, and\nimproved workflow of many domains. Nonetheless, there remain a few major\nconcerns in adopting and deploying the distributed ledger technology at scale.\nIn this white paper, we tackle two of them, namely the throughput scalability\nand confidentiality protection for transactions. We learn from the existing\nbody of research, and build a scale-out blockchain platform that champions\nprivacy called RVChain. RVChain takes advantage of trusted execution\nenvironment to offer confidentiality protection for transactions, and scales\nthe throughput of the network in proportion with the number of network\nparticipants by supporting parallel shadow chains.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 01:48:11 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Aare", "Henri", ""], ["Vitols", "Peter", ""]]}, {"id": "2006.01818", "submitter": "Haw-Minn Lu", "authors": "Haw-minn Lu, Adrian Kwong, Jose Unpingco", "title": "Securing Your Collaborative Jupyter Notebooks in the Cloud using\n  Container and Load Balancing Services", "comments": "Accepted and submitted to 19th Python in Science Conference. (SciPy\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Jupyter has become the go-to platform for developing data applications but\ndata and security concerns, especially when dealing with healthcare, have\nbecome paramount for many institutions and applications dealing with sensitive\ninformation. How then can we continue to enjoy the data analysis and machine\nlearning opportunities provided by Jupyter and the Python ecosystem while\nguaranteeing auditable compliance with security and privacy concerns? We will\ndescribe the architecture and implementation of a cloud based platform based on\nJupyter that integrates with Amazon Web Services (AWS) and uses containerized\nservices without exposing the platform to the vulnerabilities present in\nKubernetes and JupyterHub. This architecture addresses the HIPAA requirements\nto ensure both security and privacy of data. The architecture uses an AWS\nservice to provide JSON Web Tokens (JWT) for authentication as well as network\ncontrol. Furthermore, our architecture enables secure collaboration and sharing\nof Jupyter notebooks. Even though our platform is focused on Jupyter notebooks\nand JupyterLab, it also supports R-Studio and bespoke applications that share\nthe same authentication mechanisms. Further, the platform can be extended to\nother cloud services other than AWS.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 17:52:32 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Lu", "Haw-minn", ""], ["Kwong", "Adrian", ""], ["Unpingco", "Jose", ""]]}, {"id": "2006.01849", "submitter": "Sean McKeown", "authors": "Joel Chacon, Sean McKeown, Richard Macfarlane", "title": "Towards Identifying Human Actions, Intent, and Severity of APT Attacks\n  Applying Deception Techniques -- An Experiment", "comments": null, "journal-ref": null, "doi": "10.1109/CyberSecurity49315.2020.9138859", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attacks by Advanced Persistent Threats (APTs) have been shown to be difficult\nto detect using traditional signature- and anomaly-based intrusion detection\napproaches. Deception techniques such as decoy objects, often called honey\nitems, may be deployed for intrusion detection and attack analysis, providing\nan alternative to detect APT behaviours. This work explores the use of honey\nitems to classify intrusion interactions, differentiating automated attacks\nfrom those which need some human reasoning and interaction towards APT\ndetection. Multiple decoy items are deployed on honeypots in a virtual honey\nnetwork, some as breadcrumbs to detect indications of a structured manual\nattack. Monitoring functionality was created around Elastic Stack with a Kibana\ndashboard created to display interactions with various honey items. APT type\nmanual intrusions are simulated by an experienced pentesting practitioner\ncarrying out simulated attacks. Interactions with honey items are evaluated in\norder to determine their suitability for discriminating between automated tools\nand direct human intervention. The results show that it is possible to\ndifferentiate automatic attacks from manual structured attacks; from the nature\nof the interactions with the honey items. The use of honey items found in the\nhoneypot, such as in later parts of a structured attack, have been shown to be\nsuccessful in classification of manual attacks, as well as towards providing an\nindication of severity of the attacks\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 18:00:45 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Chacon", "Joel", ""], ["McKeown", "Sean", ""], ["Macfarlane", "Richard", ""]]}, {"id": "2006.01888", "submitter": "Zhuoran Liu", "authors": "Zhuoran Liu and Martha Larson", "title": "Adversarial Item Promotion: Vulnerabilities at the Core of Top-N\n  Recommenders that Use Images to Address Cold Start", "comments": "Our code is available at https://github.com/liuzrcc/AIP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  E-commerce platforms provide their customers with ranked lists of recommended\nitems matching the customers' preferences. Merchants on e-commerce platforms\nwould like their items to appear as high as possible in the top-N of these\nranked lists. In this paper, we demonstrate how unscrupulous merchants can\ncreate item images that artificially promote their products, improving their\nrankings. Recommender systems that use images to address the cold start problem\nare vulnerable to this security risk. We describe a new type of attack,\nAdversarial Item Promotion (AIP), that strikes directly at the core of Top-N\nrecommenders: the ranking mechanism itself. Existing work on adversarial images\nin recommender systems investigates the implications of conventional attacks,\nwhich target deep learning classifiers. In contrast, our AIP attacks are\nembedding attacks that seek to push features representations in a way that\nfools the ranker (not a classifier) and directly lead to item promotion. We\nintroduce three AIP attacks insider attack, expert attack, and semantic attack,\nwhich are defined with respect to three successively more realistic attack\nmodels. Our experiments evaluate the danger of these attacks when mounted\nagainst three representative visually-aware recommender algorithms in a\nframework that uses images to address cold start. We also evaluate potential\ndefenses, including adversarial training and find that common,\ncurrently-existing, techniques do not eliminate the danger of AIP attacks. In\nsum, we show that using images to address cold start opens recommender systems\nto potential threats with clear practical implications.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 19:12:13 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 11:46:09 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2020 13:05:48 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Liu", "Zhuoran", ""], ["Larson", "Martha", ""]]}, {"id": "2006.01906", "submitter": "Jonathan Le Roux", "authors": "Tejas Jayashankar, Jonathan Le Roux, Pierre Moulin", "title": "Detecting Audio Attacks on ASR Systems with Dropout Uncertainty", "comments": "Accepted for publication at Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CR cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various adversarial audio attacks have recently been developed to fool\nautomatic speech recognition (ASR) systems. We here propose a defense against\nsuch attacks based on the uncertainty introduced by dropout in neural networks.\nWe show that our defense is able to detect attacks created through optimized\nperturbations and frequency masking on a state-of-the-art end-to-end ASR\nsystem. Furthermore, the defense can be made robust against attacks that are\nimmune to noise reduction. We test our defense on Mozilla's CommonVoice\ndataset, the UrbanSound dataset, and an excerpt of the LibriSpeech dataset,\nshowing that it achieves high detection accuracy in a wide range of scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 19:40:38 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 01:41:59 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Jayashankar", "Tejas", ""], ["Roux", "Jonathan Le", ""], ["Moulin", "Pierre", ""]]}, {"id": "2006.01939", "submitter": "Chinmaya Patnayak", "authors": "Chinmaya Patnayak, Pradipta Roy, Bibekanand Patnaik", "title": "A New Chaos and Permutation Based Algorithm for Image and Video\n  Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Images and video sequences carry large volumes of highly correlated and\nredundant data. Applications like military and telecommunication require\nencryption methods to protect the data from unwanted access. This requirement\nin most cases needs to be realized in real-time. In this paper, we propose a\nfast new Fiestal-structured approach for image and video encryption based on a\nchaotic random sequence generator and a Permutation-Inverse Permutation (PIP)\npixel transform. This approach utilizes mathematical functions and transforms\nwith low complexity. The algorithm at the same time, ensures no drastic pay off\nin terms of encryption quality. This renders the algorithm with promising scope\nfor real time applications and easy hardware implementation. MATLAB simulation\nof the algorithm establishes its high quality of encryption in terms of\nelevated entropy values and negligible correlation of the encrypted data with\nthe original. Simulation results also show high sensitivity to slight variation\nin keys ensuring high security.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 20:54:39 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Patnayak", "Chinmaya", ""], ["Roy", "Pradipta", ""], ["Patnaik", "Bibekanand", ""]]}, {"id": "2006.01944", "submitter": "Jason Huang", "authors": "Aditya Dhar, Jason Huang", "title": "Designing Differentially Private Estimators in High Dimensions", "comments": "9 pages, 3 figures, presented at the ICML 2020 Workshop on Economics\n  of Privacy and Data Labor", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study differentially private mean estimation in a high-dimensional\nsetting. Existing differential privacy techniques applied to large dimensions\nlead to computationally intractable problems or estimators with excessive\nprivacy loss. Recent work in high-dimensional robust statistics has identified\ncomputationally tractable mean estimation algorithms with asymptotic\ndimension-independent error guarantees. We incorporate these results to develop\na strict bound on the global sensitivity of the robust mean estimator. This\nyields a computationally tractable algorithm for differentially private mean\nestimation in high dimensions with dimension-independent privacy loss. Finally,\nwe show on synthetic data that our algorithm significantly outperforms classic\ndifferential privacy methods, overcoming barriers to high-dimensional\ndifferential privacy.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 21:17:30 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 01:05:12 GMT"}, {"version": "v3", "created": "Sat, 18 Jul 2020 17:01:13 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Dhar", "Aditya", ""], ["Huang", "Jason", ""]]}, {"id": "2006.01977", "submitter": "Vidal Attias", "authors": "Vidal Attias, Luigi Vigneri, Vassil Dimitrov", "title": "Preventing Denial of Service Attacks in IoT Networks through Verifiable\n  Delay Functions", "comments": null, "journal-ref": "GLOBECOM 2020 - 2020 IEEE Global Communications Conference, 1-6", "doi": "10.1109/GLOBECOM42002.2020.9322260", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Permissionless distributed ledgers provide a promising approach to deal with\nthe Internet of Things (IoT) paradigm. Since IoT devices mostly generate data\ntransactions and micropayments, distributed ledgers that use fees to regulate\nthe network access are not an optimal choice. In this paper, we study a feeless\narchitecture developed by IOTA and designed specifically for the IoT. Due to\nthe lack of fees, malicious nodes can exploit this feature to generate an\nunbounded number of transactions and perform a denial of service attacks. We\npropose to mitigate these attacks through verifiable delay functions. These\nfunctions, which are non-parallelizable, hard to compute, and easy to verify,\nhave been formulated only recently. In our work, we design a denial of service\nprevention mechanism which addresses network heterogeneity, limited node\ncomputational capabilities, and hardware-specific implementation optimizations.\nVerifiable delay functions have mostly been studied from a theoretical point of\nview, but little has been done in tangible applications. Hence, this paper can\nbe considered as a pioneer work in the field, since it builds a bridge between\nthis theoretical mathematical framework and a real-world problem.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 23:18:45 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Attias", "Vidal", ""], ["Vigneri", "Luigi", ""], ["Dimitrov", "Vassil", ""]]}, {"id": "2006.01980", "submitter": "Baekjin Kim", "authors": "Young Hun Jung, Baekjin Kim, Ambuj Tewari", "title": "On the Equivalence between Online and Private Learnability beyond Binary\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alon et al. [2019] and Bun et al. [2020] recently showed that online\nlearnability and private PAC learnability are equivalent in binary\nclassification. We investigate whether this equivalence extends to multi-class\nclassification and regression. First, we show that private learnability implies\nonline learnability in both settings. Our extension involves studying a novel\nvariant of the Littlestone dimension that depends on a tolerance parameter and\non an appropriate generalization of the concept of threshold functions beyond\nbinary classification. Second, we show that while online learnability continues\nto imply private learnability in multi-class classification, current proof\ntechniques encounter significant hurdles in the regression setting. While the\nequivalence for regression remains open, we provide non-trivial sufficient\nconditions for an online learnable class to also be privately learnable.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 23:30:41 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 01:25:59 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Jung", "Young Hun", ""], ["Kim", "Baekjin", ""], ["Tewari", "Ambuj", ""]]}, {"id": "2006.01994", "submitter": "Chase Smith", "authors": "Chase Smith, Alex Rusnak", "title": "Dynamic Merkle B-tree with Efficient Proofs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and define a recursive Merkle structure with q-mercurial\ncommitments, in order to create a concise B-Merkle tree. This Merkle B-Tree\nbuilds on previous work of q-ary Merkle trees which use concise, constant size,\nq-mercurial commitments for intranode proofs. Although these q-ary trees reduce\nthe branching factor and height, they still have their heights based on the key\nlength, and are forced to fixed heights. Instead of basing nodes on q-ary\nprefix trees, the B Merkle Tree incorporates concise intranode commitments\nwithin a self-balancing tree. The tree is based on the ordering of elements,\nwhich requires extra information to determine element placement, but it enables\nsignificantly smaller proof sizes. This allows for much lower tree heights\n(directed by the order of elements, not the size of the key), and therefore\ncreates smaller and more efficient proofs and operations. Additionally, the B\nMerkle Tree is defined with subset queries that feature similar communication\ncosts to non-membership proofs. Our scheme has the potential to benefit\noutsourced database models, like blockchain, which use authenticated data\nstructures and database indices to ensure immutability and integrity of data.\nWe present potential applications in key-value stores, relational databases,\nand, in part, Merkle forests.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 00:40:37 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 00:08:18 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 01:59:05 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Smith", "Chase", ""], ["Rusnak", "Alex", ""]]}, {"id": "2006.02147", "submitter": "Riccardo Aragona", "authors": "Riccardo Aragona, Roberto Civino, Norberto Gavioli, Marco Pugliese", "title": "An Authenticated Key Scheme over Elliptic Curves for Topological\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nodes of sensor networks may be resource-constrained devices, often having a\nlimited lifetime, making sensor networks remarkably dynamic environments.\nManaging a cryptographic protocol on such setups may require a disproportionate\neffort when it comes to update the secret parameters of new nodes that enter\nthe network in place of dismantled sensors. For this reason, the designers of\nschemes for sensor network are always concerned with the need of scalable and\nadaptable solutions. In this work, we present a novel elliptic-curve based\nsolution, derived from the previously released cryptographic protocol TAKS,\nwhich addresses this issue. We give a formal description of the scheme, built\non a two-dimensional vector space over a prime field and over elliptic curves,\nwhere node topology is more relevant than node identity, allowing a dynamic\nhandling of the network and reducing the cost of network updates. We also study\nsome security concerns and their relation to the related discrete logarithm\nproblem over elliptic curves.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 10:22:40 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 09:27:10 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Aragona", "Riccardo", ""], ["Civino", "Roberto", ""], ["Gavioli", "Norberto", ""], ["Pugliese", "Marco", ""]]}, {"id": "2006.02231", "submitter": "Suranga Seneviratne", "authors": "Naveen Karunanayake, Jathushan Rajasegaran, Ashanie Gunathillake,\n  Suranga Seneviratne, Guillaume Jourjon", "title": "A Multi-modal Neural Embeddings Approach for Detecting Mobile\n  Counterfeit Apps: A Case Study on Google Play Store", "comments": "arXiv admin note: substantial text overlap with arXiv:1804.09882", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfeit apps impersonate existing popular apps in attempts to misguide\nusers to install them for various reasons such as collecting personal\ninformation or spreading malware. Many counterfeits can be identified once\ninstalled, however even a tech-savvy user may struggle to detect them before\ninstallation. To this end, this paper proposes to leverage the recent advances\nin deep learning methods to create image and text embeddings so that\ncounterfeit apps can be efficiently identified when they are submitted for\npublication. We show that a novel approach of combining content embeddings and\nstyle embeddings outperforms the baseline methods for image similarity such as\nSIFT, SURF, and various image hashing methods. We first evaluate the\nperformance of the proposed method on two well-known datasets for evaluating\nimage similarity methods and show that content, style, and combined embeddings\nincrease precision@k and recall@k by 10%-15% and 12%-25%, respectively when\nretrieving five nearest neighbours. Second, specifically for the app\ncounterfeit detection problem, combined content and style embeddings achieve\n12% and 14% increase in precision@k and recall@k, respectively compared to the\nbaseline methods. Third, we present an analysis of approximately 1.2 million\napps from Google Play Store and identify a set of potential counterfeits for\ntop-10,000 popular apps. Under a conservative assumption, we were able to find\n2,040 potential counterfeits that contain malware in a set of 49,608 apps that\nshowed high similarity to one of the top-10,000 popular apps in Google Play\nStore. We also find 1,565 potential counterfeits asking for at least five\nadditional dangerous permissions than the original app and 1,407 potential\ncounterfeits having at least five extra third party advertisement libraries.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 07:10:21 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Karunanayake", "Naveen", ""], ["Rajasegaran", "Jathushan", ""], ["Gunathillake", "Ashanie", ""], ["Seneviratne", "Suranga", ""], ["Jourjon", "Guillaume", ""]]}, {"id": "2006.02241", "submitter": "Shishir Nagaraja", "authors": "Shishir Nagaraja", "title": "Unlinking super-linkers: the topology of epidemic response (Covid-19)", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR physics.soc-ph q-bio.PE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A key characteristic of the spread of infectious diseases is their ability to\nuse efficient transmission paths within contact graphs. This enables the\npathogen to maximise infection rates and spread within a target population. In\nthis work, we devise techniques to localise infections and decrease infection\nrates based on a principled analysis of disease transmission paths within\nhuman-contact networks (proximity graphs). Experimental results of disease\nspreading shows that that at low visibility rates contact tracing slows disease\nspreading. However to stop disease spreading, contact tracing requires both\nsignificant visibility (at least 60%) into the proximity graph and the ability\nto place half of the population under isolation. We find that pro-actively\nisolating super-links -- key proximity encounters -- has significant benefits:\ntargeted isolation of a fourth of the population based on 35% visibility into\nthe proximity graph prevents an epidemic outbreak. It turns out that isolating\nsuper-spreaders is more effective than contact tracing and testing but less\neffective than targeting super-links. We highlight the important role of\ntopology in epidemic outbreaks. We argue that proactive innoculation of a\npopulation by disabling super-links and super-spreaders may have an important\ncomplimentary role alongside contact tracing and testing as part of a\nsophisticated public-health response to epidemic outbreaks.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 08:25:34 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 09:23:09 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Nagaraja", "Shishir", ""]]}, {"id": "2006.02397", "submitter": "Jordan Awan", "authors": "Jordan Awan and Zhanrui Cai", "title": "Approximate Co-Sufficient Sampling for Goodness-of-fit Tests and\n  Synthetic Data", "comments": "35 pages double spaced, before references", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CR stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Co-sufficient sampling refers to resampling the data conditional on a\nsufficient statistic, a useful technique for statistical problems such as\ngoodness-of-fit tests, model selection, and confidence interval construction;\nit is also a powerful tool to generate synthetic data which limits the\ndisclosure risk of sensitive data. However, sampling from such conditional\ndistributions is both technically and computationally challenging, and is\ninapplicable in models without low-dimensional sufficient statistics.\n  We study an indirect inference approach to approximate co-sufficient\nsampling, which only requires an efficient statistic rather than a sufficient\nstatistic. Given an efficient estimator, we prove that the expected KL\ndivergence goes to zero between the true conditional distribution and the\nresulting approximate distribution. We also propose a one-step approximate\nsolution to the optimization problem that preserves the original estimator with\nan error of $o_p(n^{-1/2})$, which suffices for asymptotic optimality. The\none-step method is easily implemented, highly computationally efficient, and\napplicable to a wide variety of models, only requiring the ability to sample\nfrom the model and compute an efficient statistic. We implement our methods via\nsimulations to tackle problems in synthetic data, hypothesis testing, and\ndifferential privacy.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 17:12:11 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 19:15:28 GMT"}, {"version": "v3", "created": "Fri, 12 Feb 2021 18:12:09 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Awan", "Jordan", ""], ["Cai", "Zhanrui", ""]]}, {"id": "2006.02398", "submitter": "Yongheng Chen", "authors": "Rui Zhong, Yongheng Chen, Hong Hu, Hangfan Zhang, Wenke Lee and\n  Dinghao Wu", "title": "SQUIRREL: Testing Database Management Systems with Language Validity and\n  Coverage Feedback", "comments": "In Proceedings of the 27th ACM Conference on Computer and\n  Communications Security (CCS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzing is an increasingly popular technique for verifying software\nfunctionalities and finding security vulnerabilities. However, current\nmutation-based fuzzers cannot effectively test database management systems\n(DBMSs), which strictly check inputs for valid syntax and semantics.\nGeneration-based testing can guarantee the syntax correctness of the inputs,\nbut it does not utilize any feedback, like code coverage, to guide the path\nexploration.\n  In this paper, we develop Squirrel, a novel fuzzing framework that considers\nboth language validity and coverage feedback to test DBMSs. We design an\nintermediate representation (IR) to maintain SQL queries in a structural and\ninformative manner. To generate syntactically correct queries, we perform\ntype-based mutations on IR, including statement insertion, deletion and\nreplacement. To mitigate semantic errors, we analyze each IR to identify the\nlogical dependencies between arguments, and generate queries that satisfy these\ndependencies. We evaluated Squirrel on four popular DBMSs: SQLite, MySQL,\nPostgreSQL and MariaDB. Squirrel found 51 bugs in SQLite, 7 in MySQL and 5 in\nMariaDB. 52 of the bugs are fixed with 12 CVEs assigned. In our experiment,\nSquirrel achieves 2.4x-243.9x higher semantic correctness than state-of-the-art\nfuzzers, and explores 2.0x-10.9x more new edges than mutation-based tools.\nThese results show that Squirrel is effective in finding memory errors of\ndatabase management systems.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 17:14:44 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Zhong", "Rui", ""], ["Chen", "Yongheng", ""], ["Hu", "Hong", ""], ["Zhang", "Hangfan", ""], ["Lee", "Wenke", ""], ["Wu", "Dinghao", ""]]}, {"id": "2006.02456", "submitter": "Pavlos Papadopoulos", "authors": "Will Abramson, Adam James Hall, Pavlos Papadopoulos, Nikolaos\n  Pitropakis, William J Buchanan", "title": "A Distributed Trust Framework for Privacy-Preserving Machine Learning", "comments": "To be published in the proceedings of the 17th International\n  Conference on Trust, Privacy and Security in Digital Business - TrustBus2020", "journal-ref": "17th International Conference TrustBus 2020", "doi": "10.1007/978-3-030-58986-8_14", "report-no": "TrustBus 2020, LNCS 12395, pp. 205--220, 2020", "categories": "cs.CR cs.CY cs.DC cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When training a machine learning model, it is standard procedure for the\nresearcher to have full knowledge of both the data and model. However, this\nengenders a lack of trust between data owners and data scientists. Data owners\nare justifiably reluctant to relinquish control of private information to third\nparties. Privacy-preserving techniques distribute computation in order to\nensure that data remains in the control of the owner while learning takes\nplace. However, architectures distributed amongst multiple agents introduce an\nentirely new set of security and trust complications. These include data\npoisoning and model theft. This paper outlines a distributed infrastructure\nwhich is used to facilitate peer-to-peer trust between distributed agents;\ncollaboratively performing a privacy-preserving workflow. Our outlined\nprototype sets industry gatekeepers and governance bodies as credential\nissuers. Before participating in the distributed learning workflow, malicious\nactors must first negotiate valid credentials. We detail a proof of concept\nusing Hyperledger Aries, Decentralised Identifiers (DIDs) and Verifiable\nCredentials (VCs) to establish a distributed trust architecture during a\nprivacy-preserving machine learning experiment. Specifically, we utilise secure\nand authenticated DID communication channels in order to facilitate a federated\nlearning workflow related to mental health care data.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 18:06:13 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Abramson", "Will", ""], ["Hall", "Adam James", ""], ["Papadopoulos", "Pavlos", ""], ["Pitropakis", "Nikolaos", ""], ["Buchanan", "William J", ""]]}, {"id": "2006.02471", "submitter": "Julio C. S. Reis", "authors": "Julio C. S. Reis, Philipe de Freitas Melo, Kiran Garimella, Fabr\\'icio\n  Benevenuto", "title": "Can WhatsApp Benefit from Debunked Fact-Checked Stories to Reduce\n  Misinformation?", "comments": "This is a preprint version of an accepted manuscript on The Harvard\n  Kennedy School (HKS) Misinformation Review. Please, consider to cite it\n  instead of this one", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  WhatsApp was alleged to be widely used to spread misinformation and\npropaganda during elections in Brazil and India. Due to the private encrypted\nnature of the messages on WhatsApp, it is hard to track the dissemination of\nmisinformation at scale. In this work, using public WhatsApp data, we observe\nthat misinformation has been largely shared on WhatsApp public groups even\nafter they were already fact-checked by popular fact-checking agencies. This\nrepresents a significant portion of misinformation spread in both Brazil and\nIndia in the groups analyzed. We posit that such misinformation content could\nbe prevented if WhatsApp had a means to flag already fact-checked content. To\nthis end, we propose an architecture that could be implemented by WhatsApp to\ncounter such misinformation. Our proposal respects the current end-to-end\nencryption architecture on WhatsApp, thus protecting users' privacy while\nproviding an approach to detect the misinformation that benefits from\nfact-checking efforts.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 18:28:57 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 03:11:38 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Reis", "Julio C. S.", ""], ["Melo", "Philipe de Freitas", ""], ["Garimella", "Kiran", ""], ["Benevenuto", "Fabr\u00edcio", ""]]}, {"id": "2006.02562", "submitter": "Mohammad Mohammadinodoushan", "authors": "Mohammad Mohammadinodoushan", "title": "Implementation of password manager with sram-based physical unclonable\n  function", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Hacking password databases is one of the most frequently reported\ncyber-attacks. Current password management systems are based on known and\npublic algorithms. Also, many studies have shown that users select weak\npasswords. Thus, with the emergence of new powerful computing devices, the\npasswords based on known algorithms can be disclosed. Using physical unclonable\nfunctions (PUFs) for increasing the security level of password management\nsystems is a quite recent method that is proposed to solve this problem. In\nthis method, Addressable PUF Generator (APG) is added to the conventional\npassword management systems. This report is aimed at implementing the password\ngeneration scheme using SRAM-based PUF. The bit error is indeed the main issue\nwith using PUFs is addresses in this paper. To solve this issue, Ternary\nAddresseble PUF Generator is used.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 22:13:54 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 22:33:38 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Mohammadinodoushan", "Mohammad", ""]]}, {"id": "2006.02735", "submitter": "Sungho Lee", "authors": "Sungho Lee, Minsu Kim, Jemin Lee, Ruei-Hau Hsu, Tony Q. S. Quek", "title": "Is Blockchain Suitable for Data Freshness? -- Age-of-Information\n  Perspective", "comments": "7 pages, 6 figures; This paper is under review in IEEE Network\n  Magazine", "journal-ref": null, "doi": "10.1109/MNET.011.2000044", "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in blockchain have led to a significant interest in\ndeveloping blockchain-based applications. While data can be retained in\nblockchains, the stored values can be deleted or updated. From a user viewpoint\nthat searches for the data, it is unclear whether the discovered data from the\nblockchain storage is relevant for real-time decision-making process for\nblockchain-based application. The data freshness issue serves as a critical\nfactor especially in dynamic networks handling real-time information. In\ngeneral, transactions to renew the data require additional processing time\ninside the blockchain network, which is called ledger-commitment latency. Due\nto this problem, some users may receive outdated data. As a result, it is\nimportant to investigate if blockchain is suitable for providing real-time data\nservices. In this article, we first describe blockchain-enabled (BCE) networks\nwith Hyperledger Fabric (HLF). Then, we define age of information (AoI) of BCE\nnetworks and investigate the influential factors in this AoI. Analysis and\nexperiments are conducted to support our proposed framework. Lastly, we\nconclude by discussing some future challenges.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 09:48:40 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Lee", "Sungho", ""], ["Kim", "Minsu", ""], ["Lee", "Jemin", ""], ["Hsu", "Ruei-Hau", ""], ["Quek", "Tony Q. S.", ""]]}, {"id": "2006.02758", "submitter": "Muhammad Zuhair Qadir", "authors": "Muhammad Zuhair Qadir, Atif Nisar Jilani, Hassam Ullah Sheikh", "title": "Automatic Feature Extraction, Categorization and Detection of Malicious\n  Code in Android Applications", "comments": "published paper in ijins journal", "journal-ref": "International Journal of Information and Network Security (IJINS)\n  2014", "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since Android has become a popular software platform for mobile devices\nrecently; they offer almost the same functionality as personal computers.\nMalwares have also become a big concern. As the number of new Android\napplications tends to be rapidly increased in the near future, there is a need\nfor automatic malware detection quickly and efficiently. In this paper, we\ndefine a simple static analysis approach to first extract the features of the\nandroid application based on intents and categories the application into a\nknown major category and later on mapping it with the permissions requested by\nthe application and also comparing it with the most obvious intents of\ncategory. As a result, getting to know which apps are using features which they\nare not supposed to use or they do not need.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 10:35:48 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Qadir", "Muhammad Zuhair", ""], ["Jilani", "Atif Nisar", ""], ["Sheikh", "Hassam Ullah", ""]]}, {"id": "2006.02775", "submitter": "Salah Harb", "authors": "Salah Harb, M. Omair Ahmad, M.N.S Swamy", "title": "Design and Hardware Implementation of a Separable Image Steganographic\n  Scheme Using Public-key Cryptosystem", "comments": "14 pages, 5 figures, conference", "journal-ref": null, "doi": "10.5121/csit.2020.100521", "report-no": null, "categories": "cs.CR eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel and efficient hardware implementation of\nsteganographic cryptosystem based on a public-key cryptography is proposed.\nDigital images are utilized as carriers of secret data between sender and\nreceiver parties in the communication channel. The proposed public-key\ncryptosystem offers a separable framework that allows to embed or extract\nsecret data and encrypt or decrypt the carrier using the public-private key\npair, independently. Paillier cryptographic system is adopted to encrypt and\ndecrypt pixels of the digital image. To achieve efficiency, a proposed\nefficient parallel montgomery exponentiation core is designed and implemented\nfor performing the underlying field operations in the Paillier cryptosystem.\nThe hardware implementation results of the proposed steganographic cryptosystem\nshow an efficiency in terms of area (resources), performance (speed) and power\nconsumption. Our steganographic cryptosystem represents a small footprint\nmaking it well-suited for the embedded systems and real-time processing engines\nin applications such as medical scanning devices, autopilot cars and drones.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 11:08:24 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Harb", "Salah", ""], ["Ahmad", "M. Omair", ""], ["Swamy", "M. N. S", ""]]}, {"id": "2006.02894", "submitter": "Derian Boer", "authors": "Derian Boer and Stefan Kramer", "title": "Secure Sum Outperforms Homomorphic Encryption in (Current) Collaborative\n  Deep Learning", "comments": "submitted to Journal of Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) approaches are achieving extraordinary results in a wide\nrange of domains but often require a massive collection of private data. Hence,\nmethods for training neural networks on the joint data of different data\nowners, that keep each party's input confidential, are called for. We address\nthe setting of horizontally distributed data in deep learning, where the\nparticipants' vulnerable intermediate results have to be processed in a\nprivacy-preserving manner. The predominant scheme for this setting is based on\nhomomorphic encryption (HE), and it is widely considered to be without\nalternative. In contrast to this, we demonstrate that a carefully chosen, less\ncomplex and computationally less expensive secure sum protocol in conjunction\nwith default secure channels exhibits superior properties in terms of both\ncollusion-resistance and runtime. Finally, we discuss several open research\nquestions in the context of collaborative DL, which possibly might lead back to\nHE-based solutions.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 23:03:32 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Boer", "Derian", ""], ["Kramer", "Stefan", ""]]}, {"id": "2006.02930", "submitter": "Jinghua Yu", "authors": "Jinghua Yu, Stefan Wagner, Feng Luo", "title": "Data-Flow-Based Extension of the System-Theoretic Process Analysis for\n  Security (STPA-Sec)", "comments": "8 pages, 5 figures, submitted to IEEE Systems Journal", "journal-ref": "PeerJ Computer Science 7:e362, 2021", "doi": "10.7717/peerj-cs.362", "report-no": null, "categories": "cs.CR cs.SE cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security analysis is an essential activity in security engineering to\nidentify potential system vulnerabilities and achieve security requirements in\nthe early design phases. Due to the increasing complexity of modern systems,\ntraditional approaches, which only consider component failures and simple\ncause-and-effect linkages, lack the power to identify insecure incidents caused\nby complex interactions among physical systems, human and social entities. By\ncontrast, a top-down System-Theoretic Process Analysis for Security (STPA-Sec)\napproach views losses as resulting from interactions, focuses on controlling\nsystem vulnerabilities instead of external threats and is applicable for\ncomplex socio-technical systems. In this paper, we proposed an extension of\nSTPA-Sec based on data flow structures to overcome STPA-Sec's limitations and\nachieve security constraints of information-critical systems systematically. We\nanalyzed a Bluetooth digital key system of a vehicle by using both the proposed\nand the original approach to investigate the relationship and differences\nbetween both approaches as well as their applicability and highlights. To\nconclude, the proposed approach can identify more information-related problems\nwith technical details and be used with other STPA-based approaches to\nco-design systems in multi-disciplines under the unified STPA process\nframework.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 15:17:12 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Yu", "Jinghua", ""], ["Wagner", "Stefan", ""], ["Luo", "Feng", ""]]}, {"id": "2006.02931", "submitter": "Yi Liu", "authors": "Yi Liu, Xingliang Yuan, Zehui Xiong, Jiawen Kang, Xiaofei Wang, Dusit\n  Niyato", "title": "Federated Learning for 6G Communications: Challenges, Methods, and\n  Future Directions", "comments": null, "journal-ref": null, "doi": "10.23919/JCC.2020.09.009", "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the 5G communication networks are being widely deployed worldwide, both\nindustry and academia have started to move beyond 5G and explore 6G\ncommunications. It is generally believed that 6G will be established on\nubiquitous Artificial Intelligence (AI) to achieve data-driven Machine Learning\n(ML) solutions in heterogeneous and massive-scale networks. However,\ntraditional ML techniques require centralized data collection and processing by\na central server, which is becoming a bottleneck of large-scale implementation\nin daily life due to significantly increasing privacy concerns. Federated\nlearning, as an emerging distributed AI approach with privacy preservation\nnature, is particularly attractive for various wireless applications,\nespecially being treated as one of the vital solutions to achieve ubiquitous AI\nin 6G. In this article, we first introduce the integration of 6G and federated\nlearning and provide potential federated learning applications for 6G. We then\ndescribe key technical challenges, the corresponding federated learning\nmethods, and open problems for future research on federated learning in the\ncontext of 6G communications.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 15:17:19 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 18:19:57 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Liu", "Yi", ""], ["Yuan", "Xingliang", ""], ["Xiong", "Zehui", ""], ["Kang", "Jiawen", ""], ["Wang", "Xiaofei", ""], ["Niyato", "Dusit", ""]]}, {"id": "2006.02932", "submitter": "Danilo Gligoroski", "authors": "Katrine Wist, Malene Helsem, Danilo Gligoroski", "title": "Vulnerability Analysis of 2500 Docker Hub Images", "comments": "Accepted as a full paper the 19th International Conference on\n  Security & Management (SAM'20), July 27-30, 2020, USA. This is extended\n  summary of the Master Thesis written under the supervision of prof. Danilo\n  Gligoroski by Katrine Wist and Malene Helsem, \"An Extensive Analysis of the\n  Current Vulnerability Landscape in Docker Hub Images\", Norwegian University\n  of Science and Technology (NTNU), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of container technology has skyrocketed during the last few years,\nwith Docker as the leading container platform. Docker's online repository for\npublicly available container images, called Docker Hub, hosts over 3.5 million\nimages at the time of writing, making it the world's largest community of\ncontainer images. We perform an extensive vulnerability analysis of 2500 Docker\nimages. It is of particular interest to perform this type of analysis because\nthe vulnerability landscape is a rapidly changing category, the vulnerability\nscanners are constantly developed and updated, new vulnerabilities are\ndiscovered, and the volume of images on Docker Hub is increasing every day. Our\nmain findings reveal that (1) the number of newly introduced vulnerabilities on\nDocker Hub is rapidly increasing; (2) certified images are the most vulnerable;\n(3) official images are the least vulnerable; (4) there is no correlation\nbetween the number of vulnerabilities and image features (i.e., number of\npulls, number of stars, and days since the last update); (5) the most severe\nvulnerabilities originate from two of the most popular scripting languages,\nJavaScript and Python; and (6) Python 2.x packages and jackson-databind\npackages contain the highest number of severe vulnerabilities. We perceive our\nstudy as the most extensive vulnerability analysis published in the open\nliterature in the last couple of years.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 15:17:30 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 09:08:32 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 10:14:34 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Wist", "Katrine", ""], ["Helsem", "Malene", ""], ["Gligoroski", "Danilo", ""]]}, {"id": "2006.02956", "submitter": "Julio Stern", "authors": "Marcos Vinicius M. Silva, Marcos Antonio Simplicio Jr., Roberto\n  Augusto Castellanos Pfeiffer, Julio Michael Stern", "title": "A Fair, Traceable, Auditable and Participatory Randomization Tool for\n  Legal Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world scenarios require the random selection of one or more\nindividuals from a pool of eligible candidates. One example of especial social\nrelevance refers to the legal system, in which the jurors and judges are\ncommonly picked according to some probability distribution aiming to avoid\nbiased decisions. In this scenario, ensuring auditability of the random drawing\nprocedure is imperative to promote confidence in its fairness. With this goal\nin mind, this article describes a protocol for random drawings specially\ndesigned for use in legal systems. The proposed design combines the following\nproperties: security by design, ensuring the fairness of the random draw as\nlong as at least one participant behaves honestly; auditability by any\ninterested party, even those having no technical background, using only public\ninformation; and statistical robustness, supporting drawings where candidates\nmay have distinct probability distributions. Moreover, it is capable of\ninviting and engaging as participating stakeholders the main interested parties\nof a legal process, in a way that promotes process transparency, public trust\nand institutional resilience. An open-source implementation is also provided as\nsupplementary material.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 15:38:15 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Silva", "Marcos Vinicius M.", ""], ["Simplicio", "Marcos Antonio", "Jr."], ["Pfeiffer", "Roberto Augusto Castellanos", ""], ["Stern", "Julio Michael", ""]]}, {"id": "2006.03044", "submitter": "Sam Werner", "authors": "Dragos I. Ilie, Sam M. Werner, Iain Stewart, William J. Knottenbelt", "title": "Unstable Throughput: When the Difficulty Algorithm Breaks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Proof-of-Work blockchains, difficulty algorithms serve the crucial purpose\nof maintaining a stable transaction throughput by dynamically adjusting the\nblock difficulty in response to the miners' constantly changing computational\npower. Blockchains that may experience severe hash rate fluctuations need\ndifficulty algorithms that quickly adapt the mining difficulty. However,\nwithout careful design, the system could be gamed by miners using coin-hopping\nstrategies to manipulate the block difficulty for profit. Such miner behavior\nresults in an unreliable system due to the unstable processing of transactions.\n  We provide an empirical analysis of how Bitcoin Cash's difficulty algorithm\ndesign leads to cyclicality in block solve times as a consequence of a positive\nfeedback loop. In response, we mathematically derive a difficulty algorithm\nusing a negative exponential filter which prohibits the formation of positive\nfeedback and exhibits additional desirable properties, such as history\nagnosticism. We compare the described algorithm to that of Bitcoin Cash in a\nsimulated mining environment and verify that the former would eliminate the\nsevere oscillations in transaction throughput.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 17:53:14 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 14:43:39 GMT"}, {"version": "v3", "created": "Fri, 30 Apr 2021 10:21:09 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Ilie", "Dragos I.", ""], ["Werner", "Sam M.", ""], ["Stewart", "Iain", ""], ["Knottenbelt", "William J.", ""]]}, {"id": "2006.03205", "submitter": "Kallol Krishna Karmakar", "authors": "Vijay Varadharajan, Kallol Karmakar, Uday Tupakula, Michael Hitchens", "title": "Towards a Trust Aware Network Slice based End to End Services for\n  Virtualised Infrastructures", "comments": "Submitted to ESORICS 2020 (under review). 24 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future communication networks such as 5G are expected to support end-to-end\ndelivery of services for several vertical markets with diverging requirements.\nNetwork slicing is a key construct that is used to provide end to end logical\nvirtual networks running on a common virtualised infrastructure, which are\nmutually isolated. Having different network slices operating over the same 5G\ninfrastructure creates several challenges in security and trust. This paper\naddresses the fundamental issue of trust of a network slice. It presents a\ntrust model and property-based trust attestation mechanisms which can be used\nto evaluate the trust of the virtual network functions that compose the network\nslice. The proposed model helps to determine the trust of the virtual network\nfunctions as well as the properties that should be satisfied by the virtual\nplatforms (both at boot and run time) on which these network functions are\ndeployed for them to be trusted. We present a logic-based language that defines\nsimple rules for the specification of properties and the conditions under which\nthese properties are evaluated to be satisfied for trusted virtualised\nplatforms. The proposed trust model and mechanisms enable the service providers\nto determine the trustworthiness of the network services as well as the users\nto develop trustworthy applications. .\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 02:27:11 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Varadharajan", "Vijay", ""], ["Karmakar", "Kallol", ""], ["Tupakula", "Uday", ""], ["Hitchens", "Michael", ""]]}, {"id": "2006.03317", "submitter": "Ashutosh Bhatia Dr.", "authors": "Sreelakshmi K. K., Ashutosh Bhatia, Ankit Agrawal", "title": "Securing IoT Applications using Blockchain: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) has become a guiding technology behind\nautomation and smart computing. One of the major concerns with the IoT systems\nis the lack of privacy and security preserving schemes for controlling access\nand ensuring the security of the data. A majority of security issues arise\nbecause of the centralized architecture of IoT systems. Another concern is the\nlack of proper authentication and access control schemes to moderate access to\ninformation generated by the IoT devices. So the question that arises is how to\nensure the identity of the equipment or the communicating node. The answer to\nsecure operations in a trustless environment brings us to the decentralized\nsolution of Blockchain. A lot of research has been going on in the area of\nconvergence of IoT and Blockchain, and it has resulted in some remarkable\nprogress in addressing some of the significant issues in the IoT arena. This\nwork reviews the challenges and threats in the IoT environment and how\nintegration with Blockchain can resolve some of them.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 09:08:11 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["K.", "Sreelakshmi K.", ""], ["Bhatia", "Ashutosh", ""], ["Agrawal", "Ankit", ""]]}, {"id": "2006.03463", "submitter": "Ilia Shumailov", "authors": "Ilia Shumailov, Yiren Zhao, Daniel Bates, Nicolas Papernot, Robert\n  Mullins, Ross Anderson", "title": "Sponge Examples: Energy-Latency Attacks on Neural Networks", "comments": "Accepted at 6th IEEE European Symposium on Security and Privacy\n  (EuroS&P)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The high energy costs of neural network training and inference led to the use\nof acceleration hardware such as GPUs and TPUs. While this enabled us to train\nlarge-scale neural networks in datacenters and deploy them on edge devices, the\nfocus so far is on average-case performance. In this work, we introduce a novel\nthreat vector against neural networks whose energy consumption or decision\nlatency are critical. We show how adversaries can exploit carefully crafted\n$\\boldsymbol{sponge}~\\boldsymbol{examples}$, which are inputs designed to\nmaximise energy consumption and latency.\n  We mount two variants of this attack on established vision and language\nmodels, increasing energy consumption by a factor of 10 to 200. Our attacks can\nalso be used to delay decisions where a network has critical real-time\nperformance, such as in perception for autonomous vehicles. We demonstrate the\nportability of our malicious inputs across CPUs and a variety of hardware\naccelerator chips including GPUs, and an ASIC simulator. We conclude by\nproposing a defense strategy which mitigates our attack by shifting the\nanalysis of energy consumption in hardware from an average-case to a worst-case\nperspective.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 14:10:09 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 14:17:37 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Shumailov", "Ilia", ""], ["Zhao", "Yiren", ""], ["Bates", "Daniel", ""], ["Papernot", "Nicolas", ""], ["Mullins", "Robert", ""], ["Anderson", "Ross", ""]]}, {"id": "2006.03504", "submitter": "Jiangnan Li", "authors": "Jiangnan Li, Yingyuan Yang, Jinyuan Stella Sun", "title": "SearchFromFree: Adversarial Measurements for Machine Learning-based\n  Energy Theft Detection", "comments": "This paper has been accepted by the IEEE International Conference on\n  Communications, Control, and Computing Technologies for Smart Grids\n  (SmartGridComm) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy theft causes large economic losses to utility companies around the\nworld. In recent years, energy theft detection approaches based on machine\nlearning (ML) techniques, especially neural networks, become popular in the\nresearch literature and achieve state-of-the-art detection performance.\nHowever, in this work, we demonstrate that the well-perform ML models for\nenergy theft detection are highly vulnerable to adversarial attacks. In\nparticular, we design an adversarial measurement generation algorithm that\nenables the attacker to report extremely low power consumption measurements to\nthe utilities while bypassing the ML energy theft detection. We evaluate our\napproach with three kinds of neural networks based on a real-world smart meter\ndataset. The evaluation result demonstrates that our approach can significantly\ndecrease the ML models' detection accuracy, even for black-box attackers.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 19:25:38 GMT"}, {"version": "v2", "created": "Sun, 30 Aug 2020 19:30:35 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Li", "Jiangnan", ""], ["Yang", "Yingyuan", ""], ["Sun", "Jinyuan Stella", ""]]}, {"id": "2006.03556", "submitter": "Adam Aviv", "authors": "Raina Samuel and Philipp Markert and Adam J. Aviv and Iulian Neamtiu", "title": "Knock, Knock. Who's There? On the Security of LG's Knock Codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knock Codes are a knowledge-based unlock authentication scheme used on LG\nsmartphones where a user enters a code by tapping or \"knocking\" a sequence on a\n2x2 grid. While a lesser used authentication method, as compared to PINs or\nAndroid patterns, there is likely a large number of Knock Code users; we\nestimate, 700,000--2,500,000 in the US alone. In this paper, we studied Knock\nCodes security asking participants to select codes on mobile devices in three\nsettings: a control treatment, a blocklist treatment, and a treatment with a\nlarger, 2x3 grid. We find that Knock Codes are significantly weaker than other\ndeployed authentication, e.g., PINs or Android patterns. In a simulated\nattacker setting, 2x3 grids offered no additional security, but blocklisting\nwas more beneficial, making Knock Codes' security similar to Android patterns.\nParticipants expressed positive perceptions of Knock Codes, but usability was\nchallenged. SUS values were \"marginal\" or \"ok\" across treatments. Based on\nthese findings, we recommend deploying blacklists for selecting a Knock Code\nbecause it improves security but has limited impact on usability perceptions.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 17:10:01 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 14:20:19 GMT"}, {"version": "v3", "created": "Fri, 26 Jun 2020 15:58:29 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Samuel", "Raina", ""], ["Markert", "Philipp", ""], ["Aviv", "Adam J.", ""], ["Neamtiu", "Iulian", ""]]}, {"id": "2006.03566", "submitter": "Basheer Al-Duwairi Dr.", "authors": "Basheer Al-Duwairi, Moath Jarrah and Ahmed Shatnawi", "title": "PASSVM: A Highly Accurate Online Fast Flux Detection System", "comments": "Submitted to Journal of Network and Systems Management", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast Flux service networks (FFSNs) are used by adversaries to achieve a high\nresilient technique for their malicious servers while keeping them hidden from\ndirect access. In this technique, a large number of botnet machines, that are\nknown as flux agents, work as proxies to relay the traffic between end users\nand a malicious mothership server which is controlled by an adversary. Various\nmechanisms have been proposed for detecting FFSNs. Such mechanisms depend on\ncollecting a large amount of DNS traffic traces and require a considerable\namount of time to identify fast flux domains. In this paper, we propose an\nefficient AI-based online fast flux detection system that performs highly\naccurate and extremely fast detection of fast flux domains. The proposed\nsystem, called PASSVM, is based on features that are associated with DNS\nresponse messages of a given domain name. The approach relies on features that\nare stored in two local databases, in addition to features that are extracted\nfrom the response DNS messages itself. The information in the databases are\nobtained from Censys search engine and IP Geolocation service. PASSVM is\nevaluated using three types of artificial neural networks which are: Multilayer\nPerceptron (MLP), Radial Basis Function Network (RBF), and Support Vector\nMachines (SVM). Results show that SVM with RBF kernel outperformed the other\ntwo methods with an accuracy of 99.557% and a detection time of less than 18\nms.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 17:22:28 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Al-Duwairi", "Basheer", ""], ["Jarrah", "Moath", ""], ["Shatnawi", "Ahmed", ""]]}, {"id": "2006.03568", "submitter": "Zhuangkun Wei", "authors": "Zhuangkun Wei, Chengyao Sun, Bin Li, Weisi Guo", "title": "Graph Layer Security: Encrypting Information via Common Networked\n  Physics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of low-cost Internet of Things (IoT) devices has led to a\nrace between wireless security and channel attacks. Traditional cryptography\nrequires high-computational power and is not suitable for low-power IoT\nscenarios. Whist, recently developed physical layer security (PLS) can exploit\ncommon wireless channel state information (CSI), its sensitivity to channel\nestimation makes them vulnerable from attacks. In this work, we exploit an\nalternative common physics shared between IoT transceivers: the monitored\nchannel-irrelevant physical networked dynamics (e.g., water/oil/gas/electrical\nsignal-flows). Leveraging this, we propose for the first time, graph layer\nsecurity (GLS), by exploiting the dependency in physical dynamics among network\nnodes for information encryption and decryption. A graph Fourier transform\n(GFT) operator is used to characterize such dependency into a graph-bandlimted\nsubspace, which allows the generations of channel-irrelevant cipher keys by\nmaximizing the secrecy rate. We evaluate our GLS against designed active and\npassive attackers, using IEEE 39-Bus system. Results demonstrate that, GLS is\nnot reliant on wireless CSI, and can combat attackers that have partial\nnetworked dynamic knowledge (realistic access to full dynamic and critical\nnodes remains challenging). We believe this novel GLS has widespread\napplicability in secure health monitoring and for Digital Twins in adversarial\nradio environments.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 17:28:03 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 19:55:22 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Wei", "Zhuangkun", ""], ["Sun", "Chengyao", ""], ["Li", "Bin", ""], ["Guo", "Weisi", ""]]}, {"id": "2006.03596", "submitter": "Tanweer Alam", "authors": "Tanweer Alam, Mohamed Benaida", "title": "Blockchain, Fog and IoT Integrated Framework: Review, Architecture and\n  Evaluation", "comments": null, "journal-ref": "Technology Reports of Kansai University, Vol 62(2), 2020", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the next-generation computing, the role of cloud, internet, and smart\ndevices will be capacious. Nowadays we all are familiar with the word smart.\nThis word is used a number of times in our daily life. The Internet of Things\n(IoT) will produce remarkable different kinds of information from different\nresources. It can store and process big data in the cloud. The fogging acts as\nan interface between cloud and IoT. The IoT nodes are also known as fog nodes,\nthese nodes are able to access anywhere within the range of the network. The\nblockchain is a novel approach to record the transactions in a sequence\nsecurely. Developing new blockchains based integrated framework in the\narchitecture of the IoT is one of the emerging approaches to solving the issue\nof communication security among the IoT public nodes. This research explores a\nnovel approach to integrate blockchain technology with the fog and IoT networks\nand provides communication security to the internet of smart devices. The\nframework is tested and implemented in the IoT network. The results are found\npositive.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 14:38:18 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Alam", "Tanweer", ""], ["Benaida", "Mohamed", ""]]}, {"id": "2006.03637", "submitter": "Stacey Truex", "authors": "Stacey Truex, Ling Liu, Ka-Ho Chow, Mehmet Emre Gursoy, Wenqi Wei", "title": "LDP-Fed: Federated Learning with Local Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents LDP-Fed, a novel federated learning system with a formal\nprivacy guarantee using local differential privacy (LDP). Existing LDP\nprotocols are developed primarily to ensure data privacy in the collection of\nsingle numerical or categorical values, such as click count in Web access logs.\nHowever, in federated learning model parameter updates are collected\niteratively from each participant and consist of high dimensional, continuous\nvalues with high precision (10s of digits after the decimal point), making\nexisting LDP protocols inapplicable. To address this challenge in LDP-Fed, we\ndesign and develop two novel approaches. First, LDP-Fed's LDP Module provides a\nformal differential privacy guarantee for the repeated collection of model\ntraining parameters in the federated training of large-scale neural networks\nover multiple individual participants' private datasets. Second, LDP-Fed\nimplements a suite of selection and filtering techniques for perturbing and\nsharing select parameter updates with the parameter server. We validate our\nsystem deployed with a condensed LDP protocol in training deep neural networks\non public data. We compare this version of LDP-Fed, coined CLDP-Fed, with other\nstate-of-the-art approaches with respect to model accuracy, privacy\npreservation, and system capabilities.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 19:15:13 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Truex", "Stacey", ""], ["Liu", "Ling", ""], ["Chow", "Ka-Ho", ""], ["Gursoy", "Mehmet Emre", ""], ["Wei", "Wenqi", ""]]}, {"id": "2006.03684", "submitter": "Damien Desfontaines", "authors": "Damien Desfontaines, James Voss, Bryant Gipson, Chinmoy Mandayam", "title": "Differentially private partition selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many data analysis operations can be expressed as a GROUP BY query on an\nunbounded set of partitions, followed by a per-partition aggregation. To make\nsuch a query differentially private, adding noise to each aggregation is not\nenough: we also need to make sure that the set of partitions released is also\ndifferentially private.\n  This problem is not new, and it was recently formally introduced as\ndifferentially private set union. In this work, we continue this area of study,\nand focus on the common setting where each user is associated with a single\npartition. In this setting, we propose a simple, optimal differentially private\nmechanism that maximizes the number of released partitions. We discuss\nimplementation considerations, as well as the possible extension of this\napproach to the setting where each user contributes to a fixed, small number of\npartitions.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 21:03:01 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 22:26:25 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Desfontaines", "Damien", ""], ["Voss", "James", ""], ["Gipson", "Bryant", ""], ["Mandayam", "Chinmoy", ""]]}, {"id": "2006.03686", "submitter": "Yun-Cheng Tsai", "authors": "Jun-Hao Chen and Samuel Yen-Chi Chen and Yun-Cheng Tsai and\n  Chih-Shiang Shur", "title": "Adversarial Robustness of Deep Convolutional Candlestick Learner", "comments": "arXiv admin note: text overlap with arXiv:2005.06731", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) has been applied extensively in a wide range of fields.\nHowever, it has been shown that DL models are susceptible to a certain kinds of\nperturbations called \\emph{adversarial attacks}. To fully unlock the power of\nDL in critical fields such as financial trading, it is necessary to address\nsuch issues. In this paper, we present a method of constructing perturbed\nexamples and use these examples to boost the robustness of the model. Our\nalgorithm increases the stability of DL models for candlestick classification\nwith respect to perturbations in the input data.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 02:58:04 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Chen", "Jun-Hao", ""], ["Chen", "Samuel Yen-Chi", ""], ["Tsai", "Yun-Cheng", ""], ["Shur", "Chih-Shiang", ""]]}, {"id": "2006.03707", "submitter": "Peter Bajcsy", "authors": "Peter Bajcsy and Nicholas J. Schaub and Michael Majurski", "title": "Scientific Calculator for Designing Trojan Detectors in Neural Networks", "comments": "Presented at AAAI FSS-20: Artificial Intelligence in Government and\n  Public Sector, Washington, DC, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This work presents a web-based interactive neural network (NN) calculator and\na NN inefficiency measurement that has been investigated for the purpose of\ndetecting trojans embedded in NN models. This NN Calculator is designed on top\nof TensorFlow Playground with in-memory storage of data and NN graphs plus\ncoefficients. It is \"like a scientific calculator\" with analytical,\nvisualization, and output operations performed on training datasets and NN\narchitectures. The prototype is aaccessible at\nhttps://pages.nist.gov/nn-calculator. The analytical capabilities include a\nnovel measurement of NN inefficiency using modified Kullback-Liebler (KL)\ndivergence applied to histograms of NN model states, as well as a\nquantification of the sensitivity to variables related to data and NNs. Both NN\nCalculator and KL divergence are used to devise a trojan detector approach for\na variety of trojan embeddings. Experimental results document desirable\nproperties of the KL divergence measurement with respect to NN architectures\nand dataset perturbations, as well as inferences about embedded trojans.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 21:54:07 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 00:09:39 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Bajcsy", "Peter", ""], ["Schaub", "Nicholas J.", ""], ["Majurski", "Michael", ""]]}, {"id": "2006.03833", "submitter": "Gabriele Ciravegna Dr.", "authors": "Stefano Melacci, Gabriele Ciravegna, Angelo Sotgiu, Ambra Demontis,\n  Battista Biggio, Marco Gori, Fabio Roli", "title": "Domain Knowledge Alleviates Adversarial Attacks in Multi-Label\n  Classifiers", "comments": "Submitted to IEEE TPAMI journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks on machine learning-based classifiers, along with defense\nmechanisms, have been widely studied in the context of single-label\nclassification problems. In this paper, we shift the attention to multi-label\nclassification, where the availability of domain knowledge on the relationships\namong the considered classes may offer a natural way to spot incoherent\npredictions, i.e., predictions associated to adversarial examples lying outside\nof the training data distribution. We explore this intuition in a framework in\nwhich first-order logic knowledge is converted into constraints and injected\ninto a semi-supervised learning problem. Within this setting, the constrained\nclassifier learns to fulfill the domain knowledge over the marginal\ndistribution, and can naturally reject samples with incoherent predictions.\nEven though our method does not exploit any knowledge of attacks during\ntraining, our experimental analysis surprisingly unveils that domain-knowledge\nconstraints can help detect adversarial examples effectively, especially if\nsuch constraints are not known to the attacker.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 10:24:54 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 09:02:06 GMT"}, {"version": "v3", "created": "Thu, 15 Apr 2021 13:26:41 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Melacci", "Stefano", ""], ["Ciravegna", "Gabriele", ""], ["Sotgiu", "Angelo", ""], ["Demontis", "Ambra", ""], ["Biggio", "Battista", ""], ["Gori", "Marco", ""], ["Roli", "Fabio", ""]]}, {"id": "2006.03841", "submitter": "Marco Guarnieri", "authors": "Marco Guarnieri, Boris K\\\"opf, Jan Reineke, Pepe Vila", "title": "Hardware-Software Contracts for Secure Speculation", "comments": "Camera ready version that will appear in the proceedings of the 42nd\n  IEEE Symposium on Security and Privacy (IEEE S&P 2021). A technical report\n  containing a full formalization and proofs of all results is available at\n  arXiv:2006.03841v2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the discovery of Spectre, a large number of hardware mechanisms for\nsecure speculation has been proposed. Intuitively, more defensive mechanisms\nare less efficient but can securely execute a larger class of programs, while\nmore permissive mechanisms may offer more performance but require more\ndefensive programming. Unfortunately, there are no hardware-software contracts\nthat would turn this intuition into a basis for principled co-design. In this\npaper, we put forward a framework for specifying such contracts, and we\ndemonstrate its expressiveness and flexibility. On the hardware side, we use\nthe framework to provide the first formalization and comparison of the security\nguarantees provided by a representative class of mechanisms for secure\nspeculation. On the software side, we use the framework to characterize program\nproperties that guarantee secure co-design in two scenarios traditionally\ninvestigated in isolation: (1) ensuring that a benign program does not leak\ninformation while computing on confidential data, and (2) ensuring that a\npotentially malicious program cannot read outside of its designated sandbox.\nFinally, we show how the properties corresponding to both scenarios can be\nchecked based on existing tools for software verification, and we use them to\nvalidate our findings on executable code.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 10:52:42 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 11:35:43 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 08:23:27 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Guarnieri", "Marco", ""], ["K\u00f6pf", "Boris", ""], ["Reineke", "Jan", ""], ["Vila", "Pepe", ""]]}, {"id": "2006.03845", "submitter": "Mathias Soeken", "authors": "Thomas H\\\"aner and Mathias Soeken", "title": "Lowering the T-depth of Quantum Circuits By Reducing the Multiplicative\n  Depth Of Logic Networks", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multiplicative depth of a logic network over the gate basis $\\{\\land,\n\\oplus, \\neg\\}$ is the largest number of $\\land$ gates on any path from a\nprimary input to a primary output in the network. We describe a dynamic\nprogramming based logic synthesis algorithm to reduce the multiplicative depth\nin logic networks. It makes use of cut enumeration, tree balancing, and\nexclusive sum-of-products (ESOP) representations. Our algorithm has\napplications to cryptography and quantum computing, as a reduction in the\nmultiplicative depth directly translates to a lower $T$-depth of the\ncorresponding quantum circuit. Our experimental results show improvements in\n$T$-depth over state-of-the-art methods and over several hand-optimized quantum\ncircuits for instances of AES, SHA, and floating-point arithmetic.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 11:08:06 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["H\u00e4ner", "Thomas", ""], ["Soeken", "Mathias", ""]]}, {"id": "2006.03854", "submitter": "Dmitrii Ustiugov", "authors": "Dmitrii Ustiugov, Plamen Petrov, M.R. Siavash Katebzadeh, Boris Grot", "title": "Bankrupt Covert Channel: Turning Network Predictability into\n  Vulnerability", "comments": "Published in WOOT 2020 co-located with USENIX Security 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen a surge in the number of data leaks despite aggressive\ninformation-containment measures deployed by cloud providers. When attackers\nacquire sensitive data in a secure cloud environment, covert communication\nchannels are a key tool to exfiltrate the data to the outside world. While the\nbulk of prior work focused on covert channels within a single CPU, they require\nthe spy (transmitter) and the receiver to share the CPU, which might be\ndifficult to achieve in a cloud environment with hundreds or thousands of\nmachines.\n  This work presents Bankrupt, a high-rate highly clandestine channel that\nenables covert communication between the spy and the receiver running on\ndifferent nodes in an RDMA network. In Bankrupt, the spy communicates with the\nreceiver by issuing RDMA network packets to a private memory region allocated\nto it on a different machine (an intermediary). The receiver similarly\nallocates a separate memory region on the same intermediary, also accessed via\nRDMA. By steering RDMA packets to a specific set of remote memory addresses,\nthe spy causes deep queuing at one memory bank, which is the finest addressable\ninternal unit of main memory. This exposes a timing channel that the receiver\ncan listen on by issuing probe packets to addresses mapped to the same bank but\nin its own private memory region. Bankrupt channel delivers 74Kb/s throughput\nin CloudLab's public cloud while remaining undetectable to the existing\nmonitoring capabilities, such as CPU and NIC performance counters.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 12:48:30 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 20:19:06 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Ustiugov", "Dmitrii", ""], ["Petrov", "Plamen", ""], ["Katebzadeh", "M. R. Siavash", ""], ["Grot", "Boris", ""]]}, {"id": "2006.03870", "submitter": "Andrei Costin", "authors": "Hannu Turtiainen and Andrei Costin and Timo Hamalainen and Tuomo\n  Lahtinen", "title": "Towards large-scale, automated, accurate detection of CCTV camera\n  objects using computer vision. Applications and implications for privacy,\n  safety, and cybersecurity. (Preprint)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In order to withstand the ever-increasing invasion of privacy by CCTV cameras\nand technologies, on par CCTV-aware solutions must exist that provide privacy,\nsafety, and cybersecurity features. We argue that a first important step\ntowards such CCTV-aware solutions must be a mapping system (e.g., Google Maps,\nOpenStreetMap) that provides both privacy and safety routing and navigation\noptions. However, this in turn requires that the mapping system contains\nupdated information on CCTV cameras' exact geo-location, coverage area, and\npossibly other meta-data (e.g., resolution, facial recognition features,\noperator). Such information is however missing from current mapping systems,\nand there are several ways to fix this. One solution is to perform CCTV camera\ndetection on geo-location tagged images, e.g., street view imagery on various\nplatforms, user images publicly posted in image sharing platforms such as\nFlickr. Unfortunately, to the best of our knowledge, there are no computer\nvision models for CCTV camera object detection as well as no mapping system\nthat supports privacy and safety routing options.\n  To close these gaps, with this paper we introduce the first and only computer\nvision MS COCO-compatible models that are able to accurately detect CCTV and\nvideo surveillance cameras in images and video frames. To this end, our best\ndetectors were built using 8387 images that were manually reviewed and\nannotated to contain 10419 CCTV camera instances, and achieve an accuracy of up\nto 98.7%. Moreover, we build and evaluate multiple models, present a\ncomprehensive comparison of their performance, and outline core challenges\nassociated with such research.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 13:49:09 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 21:15:10 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Turtiainen", "Hannu", ""], ["Costin", "Andrei", ""], ["Hamalainen", "Timo", ""], ["Lahtinen", "Tuomo", ""]]}, {"id": "2006.03873", "submitter": "Jamie Hayes", "authors": "Jamie Hayes", "title": "Unique properties of adversarially trained linear classifiers on\n  Gaussian data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are vulnerable to adversarial perturbations, that\nwhen added to an input, can cause high confidence misclassifications. The\nadversarial learning research community has made remarkable progress in the\nunderstanding of the root causes of adversarial perturbations. However, most\nproblems that one may consider important to solve for the deployment of machine\nlearning in safety critical tasks involve high dimensional complex manifolds\nthat are difficult to characterize and study. It is common to develop\nadversarially robust learning theory on simple problems, in the hope that\ninsights will transfer to `real world datasets'. In this work, we discuss a\nsetting where this approach fails. In particular, we show with a linear\nclassifier, it is always possible to solve a binary classification problem on\nGaussian data under arbitrary levels of adversarial corruption during training,\nand that this property is not observed with non-linear classifiers on the\nCIFAR-10 dataset.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 14:06:38 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Hayes", "Jamie", ""]]}, {"id": "2006.03918", "submitter": "Massimo Bartoletti", "authors": "Massimo Bartoletti and Stefano Lande and Roberto Zunino", "title": "Bitcoin covenants unchained", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covenants are linguistic primitives that extend the Bitcoin script language,\nallowing transactions to constrain the scripts of the redeeming ones. Advocated\nas a way of improving the expressiveness of Bitcoin contracts while preserving\nthe simplicity of the UTXO design, various forms of covenants have been\nproposed over the years. A common drawback of the existing descriptions is the\nlack of formalization, making it difficult to reason about properties and\nsupported use cases. In this paper we propose a formal model of covenants,\nwhich can be implemented with minor modifications to Bitcoin. We use our model\nto specify some complex Bitcoin contracts, and we discuss how to exploit\ncovenants to design high-level language primitives for Bitcoin contracts.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 17:04:00 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 13:14:19 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Bartoletti", "Massimo", ""], ["Lande", "Stefano", ""], ["Zunino", "Roberto", ""]]}, {"id": "2006.03921", "submitter": "Marcin Plata", "authors": "Marcin Plata, Piotr Syga", "title": "Robust watermarking with double detector-discriminator approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a novel deep framework for a watermarking - a\ntechnique of embedding a transparent message into an image in a way that allows\nretrieving the message from a (perturbed) copy, so that copyright infringement\ncan be tracked. For this technique, it is essential to extract the information\nfrom the image even after imposing some digital processing operations on it.\nOur framework outperforms recent methods in the context of robustness against\nnot only spectrum of attacks (e.g. rotation, resizing, Gaussian smoothing) but\nalso against compression, especially JPEG. The bit accuracy of our method is at\nleast 0.86 for all types of distortions. We also achieved 0.90 bit accuracy for\nJPEG while recent methods provided at most 0.83. Our method retains high\ntransparency and capacity as well. Moreover, we present our double\ndetector-discriminator approach - a scheme to detect and discriminate if the\nimage contains the embedded message or not, which is crucial for real-life\nwatermarking systems and up to now was not investigated using neural networks.\nWith this, we design a testing formula to validate our extended approach and\ncompared it with a common procedure. We also present an alternative method of\nbalancing between image quality and robustness on attacks which is easily\napplicable to the framework.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 17:15:45 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Plata", "Marcin", ""], ["Syga", "Piotr", ""]]}, {"id": "2006.03930", "submitter": "Christopher Deloglos", "authors": "Christopher Deloglos, Carl Elks, and Ashraf Tantawy", "title": "An Attacker Modeling Framework for the Assessment of Cyber-Physical\n  Systems Security", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-54549-9_10", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing attacker behavior with respect to Cyber-Physical Systems is\nimportant to assuring the security posture and resilience of these systems.\nClassical cyber vulnerability assessment approaches rely on the knowledge and\nexperience of cyber-security experts to conduct security analyses and can be\ninconsistent where the experts' knowledge and experience are lacking. This\npaper proposes a flexible attacker modeling framework that aids in the security\nanalysis process by simulating a diverse set of attacker behaviors to predict\nattack progression and provide consistent system vulnerability analysis. The\nmodel proposes an expanded architecture of vulnerability databases to maximize\nits effectiveness and consistency in detecting CPS vulnerabilities while being\ncompatible with existing vulnerability databases. The model has the power to be\nimplemented and simulated against an actual or virtual CPS. Execution of the\nattacker model is demonstrated against a simulated industrial control system\narchitecture, resulting in a probabilistic prediction of attacker behavior.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 18:16:36 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 21:17:51 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Deloglos", "Christopher", ""], ["Elks", "Carl", ""], ["Tantawy", "Ashraf", ""]]}, {"id": "2006.03986", "submitter": "Zahra Pooranian", "authors": "Zahra Pooranian, Mauro Conti, Hamed Haddadi, Rahim Tafazolli", "title": "Online Advertising Security: Issues, Taxonomy, and Future Directions", "comments": "31 pages, 13 figures, 5 tables, IEEE Communications Surveys &\n  Tutorials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Online advertising has become the backbone of the Internet economy by\nrevolutionizing business marketing. It provides a simple and efficient way for\nadvertisers to display their advertisements to specific individual users, and\nover the last couple of years has contributed to an explosion in the income\nstream for several web-based businesses. For example, Google's income from\nadvertising grew 51.6% between 2016 and 2018, to $136.8 billion. This\nexponential growth in advertising revenue has motivated fraudsters to exploit\nthe weaknesses of the online advertising model to make money, and researchers\nto discover new security vulnerabilities in the model, to propose\ncountermeasures and to forecast future trends in research. Motivated by these\nconsiderations, this paper presents a comprehensive review of the security\nthreats to online advertising systems. We begin by introducing the motivation\nfor online advertising system, explain how it differs from traditional\nadvertising networks, introduce terminology, and define the current online\nadvertising architecture. We then devise a comprehensive taxonomy of attacks on\nonline advertising to raise awareness among researchers about the\nvulnerabilities of online advertising ecosystem. We discuss the limitations and\neffectiveness of the countermeasures that have been developed to secure\nentities in the advertising ecosystem against these attacks. To complete our\nwork, we identify some open issues and outline some possible directions for\nfuture research towards improving security methods for online advertising\nsystems.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 21:54:34 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 10:47:54 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Pooranian", "Zahra", ""], ["Conti", "Mauro", ""], ["Haddadi", "Hamed", ""], ["Tafazolli", "Rahim", ""]]}, {"id": "2006.03995", "submitter": "Keyvan Ramezanpour", "authors": "Keyvan Ramezanpour, Paul Ampadu, William Diehl", "title": "SCARL: Side-Channel Analysis with Reinforcement Learning on the Ascon\n  Authenticated Cipher", "comments": "25 pages, 11 figures, submitted to ACM JETC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing side-channel analysis techniques require a leakage model, in the\nform of a prior knowledge or a set of training data, to establish a\nrelationship between the secret data and the measurements. We introduce\nside-channel analysis with reinforcement learning (SCARL) capable of extracting\ndata-dependent features of the measurements in an unsupervised learning\napproach without requiring a prior knowledge on the leakage model. SCARL\nconsists of an auto-encoder to encode the information of power measurements\ninto an internal representation, and a reinforcement learning algorithm to\nextract information about the secret data. We employ a reinforcement learning\nalgorithm with actor-critic networks, to identify the proper leakage model that\nresults in maximum inter-cluster separation of the auto-encoder representation.\nSCARL assumes that the lower order components of a generic non-linear leakage\nmodel have larger contribution to the leakage of sensitive data. On a\nlightweight implementation of the Ascon authenticated cipher on the Artix-7\nFPGA, SCARL is able to recover the secret key using 24K power traces during the\nkey insertion, or Initialization Stage, of the cipher. We also demonstrate that\nclassical techniques such as DPA and CPA fail to identify the correct key using\ntraditional linear leakage models and more than 40K power traces.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 23:36:16 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Ramezanpour", "Keyvan", ""], ["Ampadu", "Paul", ""], ["Diehl", "William", ""]]}, {"id": "2006.04008", "submitter": "Nibraas Khan", "authors": "Nibraas Khan, Ruj Haan, George Boktor, Michael McComas, and Ramin\n  Daneshi", "title": "Steganography GAN: Cracking Steganography with Cycle Generative\n  Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For as long as humans have participated in the act of communication,\nconcealing information in those communicative mediums has manifested into an\nart of its own. Crytographic messages, through written language or images, are\na means of concealment, usually reserved for highly sensitive or compromising\ninformation. Specifically, the field of Cryptography is the construction and\nanalysis of protocols that prevent third parties from understanding private\nmessages. Steganography is related to Cryptography in that the goal is to\nobscure information using some method or algorithm, but the most important\ndifference is that the information and the method of concealing information\nwithin Steganography both involve images--more precisely, the embedding of one\nimage or piece of information into another image. Ever since the creation of\ncovert communication methods, steps have been taken to crack cryptography and\nsteganography algorithms. The desire for this rises from both human curiosity\nand the need to counteract adverse uses, such as encoding harmful media in\ninconspicuous media (phishing attack). In this paper, we succeed in cracking\nthe Least Significant Bit (LSB) steganography algorithm using Cycle Generative\nAdversarial Networks (CycleGANs) and Bayesian Optimization and compare the use\nof CycleGANs against Convolutional Autoencoders. The results of our experiments\nhighlight the promising nature of CycleGANs in cracking steganography and open\nseveral possible avenues of research.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 01:01:22 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Khan", "Nibraas", ""], ["Haan", "Ruj", ""], ["Boktor", "George", ""], ["McComas", "Michael", ""], ["Daneshi", "Ramin", ""]]}, {"id": "2006.04098", "submitter": "Shamal Faily", "authors": "Shamal Faily and Riccardo Scandariato and Adam Shostack and Laurens\n  Sion and Duncan Ki-Aries", "title": "Contextualisation of Data Flow Diagrams for security analysis", "comments": "Workshop pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data flow diagrams (DFDs) are popular for sketching systems for subsequent\nthreat modelling. Their limited semantics make reasoning about them difficult,\nbut enriching them endangers their simplicity and subsequent ease of take up.\nWe present an approach for reasoning about tainted data flows in design-level\nDFDs by putting them in context with other complementary usability and\nrequirements models. We illustrate our approach using a pilot study, where\ntainted data flows were identified without any augmentations to either the DFD\nor its complementary models.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 09:32:41 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Faily", "Shamal", ""], ["Scandariato", "Riccardo", ""], ["Shostack", "Adam", ""], ["Sion", "Laurens", ""], ["Ki-Aries", "Duncan", ""]]}, {"id": "2006.04125", "submitter": "Sudipta Paul Ms.", "authors": "Poushali Sengupta, Sudipta Paul, Subhankar Mishra", "title": "BUDS: Balancing Utility and Differential Privacy by Shuffling", "comments": "11 pages, 3 images, 3 tables, Accepted to 11th ICCCNT, 2020, IIT KGP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Balancing utility and differential privacy by shuffling or \\textit{BUDS} is\nan approach towards crowd-sourced, statistical databases, with strong privacy\nand utility balance using differential privacy theory. Here, a novel algorithm\nis proposed using one-hot encoding and iterative shuffling with the loss\nestimation and risk minimization techniques, to balance both the utility and\nprivacy. In this work, after collecting one-hot encoded data from different\nsources and clients, a step of novel attribute shuffling technique using\niterative shuffling (based on the query asked by the analyst) and loss\nestimation with an updation function and risk minimization produces a utility\nand privacy balanced differential private report. During empirical test of\nbalanced utility and privacy, BUDS produces $\\epsilon = 0.02$ which is a very\npromising result. Our algorithm maintains a privacy bound of $\\epsilon = ln\n[t/((n_1 - 1)^S)]$ and loss bound of $c' \\bigg|e^{ln[t/((n_1 - 1)^S)]} -\n1\\bigg|$.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 11:39:13 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Sengupta", "Poushali", ""], ["Paul", "Sudipta", ""], ["Mishra", "Subhankar", ""]]}, {"id": "2006.04219", "submitter": "Lei Jiang", "authors": "Qian Lou and Song Bian and Lei Jiang", "title": "AutoPrivacy: Automated Layer-wise Parameter Selection for Secure Neural\n  Network Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid Privacy-Preserving Neural Network (HPPNN) implementing linear layers\nby Homomorphic Encryption (HE) and nonlinear layers by Garbled Circuit (GC) is\none of the most promising secure solutions to emerging Machine Learning as a\nService (MLaaS). Unfortunately, a HPPNN suffers from long inference latency,\ne.g., $\\sim100$ seconds per image, which makes MLaaS unsatisfactory. Because\nHE-based linear layers of a HPPNN cost $93\\%$ inference latency, it is critical\nto select a set of HE parameters to minimize computational overhead of linear\nlayers. Prior HPPNNs over-pessimistically select huge HE parameters to maintain\nlarge noise budgets, since they use the same set of HE parameters for an entire\nnetwork and ignore the error tolerance capability of a network.\n  In this paper, for fast and accurate secure neural network inference, we\npropose an automated layer-wise parameter selector, AutoPrivacy, that leverages\ndeep reinforcement learning to automatically determine a set of HE parameters\nfor each linear layer in a HPPNN. The learning-based HE parameter selection\npolicy outperforms conventional rule-based HE parameter selection policy.\nCompared to prior HPPNNs, AutoPrivacy-optimized HPPNNs reduce inference latency\nby $53\\%\\sim70\\%$ with negligible loss of accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 18:21:12 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 21:08:58 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Lou", "Qian", ""], ["Bian", "Song", ""], ["Jiang", "Lei", ""]]}, {"id": "2006.04281", "submitter": "Felipe Voloch", "authors": "Jose Felipe Voloch", "title": "Commitment Schemes and Diophantine Equations", "comments": "Invited talk at ANTS XIV", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by questions in cryptography, we look for diophantine equations\nthat are hard to solve but for which determining the number of solutions is\neasy.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 22:13:35 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Voloch", "Jose Felipe", ""]]}, {"id": "2006.04384", "submitter": "Sara Rouhani", "authors": "Sara Rouhani, Rafael Belchior, Rui S. Cruz, Ralph Deters", "title": "Distributed Attribute-Based Access Control System Using a Permissioned\n  Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auditing provides an essential security control in computer systems, by\nkeeping track of all access attempts, including both legitimate and illegal\naccess attempts. This phase can be useful to the context of audits, where\neventual misbehaving parties can be held accountable. Blockchain technology can\nprovide trusted auditability required for access control systems. In this\npaper, we propose a distributed \\ac{ABAC} system based on blockchain to provide\ntrusted auditing of access attempts. Besides auditability, our system presents\na level of transparency that both access requestors and resource owners can\nbenefit from it. We present a system architecture with an implementation based\non Hyperledger Fabric, achieving high efficiency and low computational\noverhead. The proposed solution is validated through a use case of independent\ndigital libraries. Detailed performance analysis of our implementation is\npresented, taking into account different consensus mechanisms and databases.\nThe experimental evaluation shows that our presented system can process 5,000\naccess control requests with the send rate of 200 per second and a latency of\n0.3 seconds.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 07:07:57 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Rouhani", "Sara", ""], ["Belchior", "Rafael", ""], ["Cruz", "Rui S.", ""], ["Deters", "Ralph", ""]]}, {"id": "2006.04487", "submitter": "Ashish Kundu", "authors": "Ashish Kundu, Arun Ayachitula, Nagamani Sistla", "title": "Similarities and Learnings from Ancient Literature on Blockchain\n  Consensus and Integrity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we have studied how the text of an ancient literature on how\ntheir integrity has been preserved for several centuries. Specifically, The\nVedas is an ancient literature, which has its text remained preserved without\nany corruption for thousands of years. As we studied the system that protects\nthe integrity of the text, pronunciation and semantics of the The Vedas, we\ndiscovered a number of similarities it has with the current concept of\nblockchain technology. It is surprising that the notion of de-centralized trust\nand mathematical encodings have existed since thousands of years in order to\nprotect this work of literature. We have presented our findings and analysis of\nthe similarities. There are also certain technical mechanisms that The Vedic\nintegrity system uses, which can be used to enhance the current digital\nblockchain platforms in terms of its security and robustness.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 11:32:47 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Kundu", "Ashish", ""], ["Ayachitula", "Arun", ""], ["Sistla", "Nagamani", ""]]}, {"id": "2006.04522", "submitter": "Mina Doosti", "authors": "Mina Doosti, Niraj Kumar, Mahshid Delavar, and Elham Kashefi", "title": "Client-Server Identification Protocols with Quantum PUF", "comments": "46 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, major progress has been made towards the realisation of the quantum\ninternet to enable a broad range of applications that would be out of reach for\nclassical internet. Most of these applications such as delegated quantum\ncomputation require running a secure identification protocol between a\nlow-resource and a high-resource party to provide secure communication.\nPhysical Unclonable Functions (PUFs) have been shown as resource-efficient\nhardware solutions for providing secure identification schemes in both\nclassical and quantum settings. In this work, we propose two identification\nprotocols based on quantum PUFs (qPUFs) as defined by Arapinis et al. In the\nfirst protocol, the low-resource party wishes to prove its identity to the\nhigh-resource party and in the second protocol, it is vice versa. Unlike\nexisting identification protocols based on Quantum Read-out PUFs which rely on\nthe security against a specific family of attacks, our protocols provide\nprovable exponential security against any Quantum Polynomial-Time (QPT)\nadversary with resource-efficient parties. We provide a comprehensive\ncomparison between the two proposed protocols in terms of resources such as\nquantum memory and computing ability required in both parties as well as the\ncommunication overhead between them. A stand-out feature of our second protocol\nis secure identification of a high-resource party by running a purely classical\nverification algorithm. This is achieved by delegating quantum operations to\nthe high-resource party and utilising the resulting classical outcomes for\nidentification.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 12:35:09 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Doosti", "Mina", ""], ["Kumar", "Niraj", ""], ["Delavar", "Mahshid", ""], ["Kashefi", "Elham", ""]]}, {"id": "2006.04593", "submitter": "Th\\'eo Ryffel", "authors": "Th\\'eo Ryffel, Pierre Tholoniat, David Pointcheval and Francis Bach", "title": "ARIANN: Low-Interaction Privacy-Preserving Deep Learning via Function\n  Secret Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose AriaNN, a low-interaction privacy-preserving framework for private\nneural network training and inference on sensitive data. Our semi-honest\n2-party computation protocol leverages function secret sharing, a recent\nlightweight cryptographic protocol that allows us to achieve an efficient\nonline phase. We design optimized primitives for the building blocks of neural\nnetworks such as ReLU, MaxPool and BatchNorm. For instance, we perform private\ncomparison for ReLU operations with a single message of the size of the input\nduring the online phase, and with preprocessing keys close to 4X smaller than\nprevious work. Last, we propose an extension to support n-party private\nfederated learning. We implement our framework as an extensible system on top\nof PyTorch that leverages CPU and GPU hardware acceleration for cryptographic\nand machine learning operations. We evaluate our end-to-end system for private\ninference and training on standard neural networks such as AlexNet, VGG16 or\nResNet18 between distant servers. We show that computation rather than\ncommunication is the main bottleneck and that using GPUs together with reduced\nkey size is a promising solution to overcome this barrier.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 13:40:27 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 16:18:50 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Ryffel", "Th\u00e9o", ""], ["Tholoniat", "Pierre", ""], ["Pointcheval", "David", ""], ["Bach", "Francis", ""]]}, {"id": "2006.04622", "submitter": "Jamie Hayes", "authors": "Jamie Hayes", "title": "Provable trade-offs between private & robust machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Historically, machine learning methods have not been designed with security\nin mind. In turn, this has given rise to adversarial examples, carefully\nperturbed input samples aimed to mislead detection at test time, which have\nbeen applied to attack spam and malware classification, and more recently to\nattack image classification. Consequently, an abundance of research has been\ndevoted to designing machine learning methods that are robust to adversarial\nexamples. Unfortunately, there are desiderata besides robustness that a secure\nand safe machine learning model must satisfy, such as fairness and privacy.\nRecent work by Song et al. (2019) has shown, empirically, that there exists a\ntrade-off between robust and private machine learning models. Models designed\nto be robust to adversarial examples often overfit on training data to a larger\nextent than standard (non-robust) models. If a dataset contains private\ninformation, then any statistical test that separates training and test data by\nobserving a model's outputs can represent a privacy breach, and if a model\noverfits on training data, these statistical tests become easier.\n  In this work, we identify settings where standard models will provably\noverfit to a larger extent in comparison to robust models, and as empirically\nobserved in previous works, settings where the opposite behavior occurs. Thus,\nit is not necessarily the case that privacy must be sacrificed to achieve\nrobustness. The degree of overfitting naturally depends on the amount of data\navailable for training. We go on to formally characterize how the training set\nsize factors into the privacy risks exposed by training a robust model.\nFinally, we empirically show our findings hold on image classification\nbenchmark datasets, such as CIFAR-10.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 14:20:12 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Hayes", "Jamie", ""]]}, {"id": "2006.04627", "submitter": "Tiago Diadami Perez", "authors": "Tiago D. Perez and Samuel Pagliarini", "title": "A Survey on Split Manufacturing: Attacks, Defenses, and Challenges", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2020.3029339", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In today's integrated circuit (IC) ecosystem, owning a foundry is not\neconomically viable, and therefore most IC design houses are now working under\na fabless business model. In order to overcome security concerns associated\nwith the outsorcing of IC fabrication, the Split Manufacturing technique was\nproposed. In Split Manufacturing, the Front End of Line (FEOL) layers\n(transistors and lower metal layers) are fabricated at an untrusted high-end\nfoundry, while the Back End of Line (BEOL) layers (higher metal layers) are\nmanufactured at a trusted low-end foundry. This approach hides the BEOL\nconnections from the untrusted foundry, thus preventing overproduction and\npiracy threats. However, many works demonstrate that BEOL connections can be\nderived by exploiting layout characteristics that are introduced by heuristics\nemployed in typical floorplanning, placement, and routing algorithms. Since\nstraightforward Split Manufacturing may not afford a desirable security level,\nmany authors propose defense techniques to be used along with Split\nManufacturing. In our survey, we present a detailed overview of the technique,\nthe many types of attacks towards Split Manufacturing, as well as possible\ndefense techniques described in the literature. For the attacks, we present a\nconcise discussion on the different threat models and assumptions, while for\nthe defenses we classify the studies into three categories: proximity\nperturbation, wire lifting, and layout obfuscation. The main outcome of our\nsurvey is to highlight the discrepancy between many studies -- some claim\nnetlists can be reconstructed with near perfect precision, while others claim\nmarginal success in retrieving BEOL connections. Finally, we also discuss\nfuture trends and challenges inherent to Split Manufacturing, including the\nfundamental difficulty of evaluating the efficiency of the technique.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 14:24:49 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 07:54:40 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 11:06:44 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Perez", "Tiago D.", ""], ["Pagliarini", "Samuel", ""]]}, {"id": "2006.04654", "submitter": "Subhashis Banerjee", "authors": "Prashant Agrawal, Anubhutie Singh, Malavika Raghavan, Subodh Sharma,\n  Subhashis Banerjee", "title": "An operational architecture for privacy-by-design in public service\n  applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Governments around the world are trying to build large data registries for\neffective delivery of a variety of public services. However, these efforts are\noften undermined due to serious concerns over privacy risks associated with\ncollection and processing of personally identifiable information. While a rich\nset of special-purpose privacy-preserving techniques exist in computer science,\nthey are unable to provide end-to-end protection in alignment with legal\nprinciples in the absence of an overarching operational architecture to ensure\npurpose limitation and protection against insider attacks. This either leads to\nweak privacy protection in large designs, or adoption of overly defensive\nstrategies to protect privacy by compromising on utility.\n  In this paper, we present an operational architecture for privacy-by-design\nbased on independent regulatory oversight stipulated by most data protection\nregimes, regulated access control, purpose limitation and data minimisation. We\nbriefly discuss the feasibility of implementing our architecture based on\nexisting techniques. We also present some sample case studies of\nprivacy-preserving design sketches of challenging public service applications.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 14:57:29 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Agrawal", "Prashant", ""], ["Singh", "Anubhutie", ""], ["Raghavan", "Malavika", ""], ["Sharma", "Subodh", ""], ["Banerjee", "Subhashis", ""]]}, {"id": "2006.04693", "submitter": "Yang Zhao", "authors": "Leong Mei Han, Yang Zhao, Jun Zhao", "title": "Blockchain-Based Differential Privacy Cost Management System", "comments": "This paper appears in ACM ASIA Conference on Computer and\n  Communications Security (ACMASIACCS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy preservation is a big concern for various sectors. To protect\nindividual user data, one emerging technology is differential privacy. However,\nit still has limitations for datasets with frequent queries, such as the fast\naccumulation of privacy cost. To tackle this limitation, this paper explores\nthe integration of a secured decentralised ledger, blockchain. Blockchain will\nbe able to keep track of all noisy responses generated with differential\nprivacy algorithm and allow for certain queries to reuse old responses. In this\npaper, a demo of a proposed blockchain-based privacy management system is\ndesigned as an interactive decentralised web application (DApp). The demo\ncreated illustrates that leveraging on blockchain will allow the total privacy\ncost accumulated to decrease significantly.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 15:47:14 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Han", "Leong Mei", ""], ["Zhao", "Yang", ""], ["Zhao", "Jun", ""]]}, {"id": "2006.04695", "submitter": "Yang Zhao", "authors": "Hans Albert Lianto, Yang Zhao, Jun Zhao", "title": "Attacks to Federated Learning: Responsive Web User Interface to Recover\n  Training Data from User Gradients", "comments": "This paper appears in ACM ASIA Conference on Computer and\n  Communications Security (ACMASIACCS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local differential privacy (LDP) is an emerging privacy standard to protect\nindividual user data. One scenario where LDP can be applied is federated\nlearning, where each user sends in his/her user gradients to an aggregator who\nuses these gradients to perform stochastic gradient descent. In a case where\nthe aggregator is untrusted and LDP is not applied to each user gradient, the\naggregator can recover sensitive user data from these gradients. In this paper,\nwe present a new interactive web demo showcasing the power of local\ndifferential privacy by visualizing federated learning with local differential\nprivacy. Moreover, the live demo shows how LDP can prevent untrusted\naggregators from recovering sensitive training data. A measure called the\nexp-hamming recovery is also created to show the extent of how much data the\naggregator can recover.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 15:50:26 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 12:30:42 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Lianto", "Hans Albert", ""], ["Zhao", "Yang", ""], ["Zhao", "Jun", ""]]}, {"id": "2006.04747", "submitter": "Lie He", "authors": "Lie He and Sai Praneeth Karimireddy and Martin Jaggi", "title": "Secure Byzantine-Robust Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Increasingly machine learning systems are being deployed to edge servers and\ndevices (e.g. mobile phones) and trained in a collaborative manner. Such\ndistributed/federated/decentralized training raises a number of concerns about\nthe robustness, privacy, and security of the procedure. While extensive work\nhas been done in tackling with robustness, privacy, or security individually,\ntheir combination has rarely been studied. In this paper, we propose a secure\ntwo-server protocol that offers both input privacy and Byzantine-robustness. In\naddition, this protocol is communication-efficient, fault-tolerant and enjoys\nlocal differential privacy.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 16:55:15 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 22:37:16 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["He", "Lie", ""], ["Karimireddy", "Sai Praneeth", ""], ["Jaggi", "Martin", ""]]}, {"id": "2006.04754", "submitter": "Felix Beierle", "authors": "Zolt\\'an Andr\\'as Lux and Dirk Thatmann and Sebastian Zickau and Felix\n  Beierle", "title": "Distributed-Ledger-based Authentication with Decentralized Identifiers\n  and Verifiable Credentials", "comments": "Accepted for publication at the 2nd Conference on Blockchain Research\n  & Applications for Innovative Networks and Services (BRAINS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authentication with username and password is becoming an inconvenient process\nfor the user. End users typically have little control over their personal\nprivacy, and data breaches effecting millions of users have already happened\nseveral times. We have implemented a proof of concept decentralized OpenID\nConnect Provider by marrying it with Self-Sovereign Identity, which gives users\nthe freedom to choose from a very large pool of identity providers instead of\njust a select few corporations, thus enabling the democratization of the highly\ncentralized digital identity landscape. Furthermore, we propose a verifiable\ncredential powered decentralized Public Key Infrastructure using distributed\nledger technologies, which creates a straightforward and verifiable way for\nretrieving digital certificates.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 17:09:34 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Lux", "Zolt\u00e1n Andr\u00e1s", ""], ["Thatmann", "Dirk", ""], ["Zickau", "Sebastian", ""], ["Beierle", "Felix", ""]]}, {"id": "2006.04806", "submitter": "Ruimin Sun", "authors": "Ruimin Sun, Alejandro Mera, Long Lu, David Choffnes", "title": "SoK: Attacks on Industrial Control Logic and Formal Verification-Based\n  Defenses", "comments": "18 pages w/ ref, Sok, PLC, ICS, CPS, attack, formal verification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programmable Logic Controllers (PLCs) play a critical role in the industrial\ncontrol systems. Vulnerabilities in PLC programs might lead to attacks causing\ndevastating consequences to the critical infrastructure, as shown in Stuxnet\nand similar attacks. In recent years, we have seen an exponential increase in\nvulnerabilities reported for PLC control logic. Looking back on past research,\nwe found extensive studies explored control logic modification attacks, as well\nas formal verification-based security solutions. We performed systematization\non these studies, and found attacks that can compromise a full chain of control\nand evade detection. However, the majority of the formal verification research\ninvestigated ad-hoc techniques targeting PLC programs. We discovered challenges\nin every aspect of formal verification, rising from (1) the ever-expanding\nattack surface from evolved system design, (2) the real-time constraint during\nthe program execution, and (3) the barrier in security evaluation given\nproprietary and vendor-specific dependencies on different techniques. Based on\nthe knowledge systematization, we provide a set of recommendations for future\nresearch directions, and we highlight the need of defending security issues\nbesides safety issues.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 14:20:19 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 04:21:37 GMT"}, {"version": "v3", "created": "Tue, 23 Mar 2021 16:24:15 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Sun", "Ruimin", ""], ["Mera", "Alejandro", ""], ["Lu", "Long", ""], ["Choffnes", "David", ""]]}, {"id": "2006.05023", "submitter": "Samson Zhou", "authors": "Jeremiah Blocki, Ben Harsha, Samson Zhou", "title": "On the Economics of Offline Password Cracking", "comments": "IEEE Symposium on Security and Privacy (S&P) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an economic model of an offline password cracker which allows us\nto make quantitative predictions about the fraction of accounts that a rational\npassword attacker would crack in the event of an authentication server breach.\nWe apply our economic model to analyze recent massive password breaches at\nYahoo!, Dropbox, LastPass and AshleyMadison. All four organizations were using\nkey-stretching to protect user passwords. In fact, LastPass' use of\nPBKDF2-SHA256 with $10^5$ hash iterations exceeds 2017 NIST minimum\nrecommendation by an order of magnitude. Nevertheless, our analysis paints a\nbleak picture: the adopted key-stretching levels provide insufficient\nprotection for user passwords. In particular, we present strong evidence that\nmost user passwords follow a Zipf's law distribution, and characterize the\nbehavior of a rational attacker when user passwords are selected from a Zipf's\nlaw distribution. We show that there is a finite threshold which depends on the\nZipf's law parameters that characterizes the behavior of a rational attacker --\nif the value of a cracked password (normalized by the cost of computing the\npassword hash function) exceeds this threshold then the adversary's optimal\nstrategy is always to continue attacking until each user password has been\ncracked. In all cases (Yahoo!, Dropbox, LastPass and AshleyMadison) we find\nthat the value of a cracked password almost certainly exceeds this threshold\nmeaning that a rational attacker would crack all passwords that are selected\nfrom the Zipf's law distribution (i.e., most user passwords). This prediction\nholds even if we incorporate an aggressive model of diminishing returns for the\nattacker (e.g., the total value of $500$ million cracked passwords is less than\n$100$ times the total value of $5$ million passwords).\n  See paper for full abstract.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 02:53:13 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Blocki", "Jeremiah", ""], ["Harsha", "Ben", ""], ["Zhou", "Samson", ""]]}, {"id": "2006.05042", "submitter": "Chenglu Jin", "authors": "Priyanka Mahesh, Akash Tiwari, Chenglu Jin, Panganamala R. Kumar, A.\n  L. Narasimha Reddy, Satish T.S. Bukkapatanam, Nikhil Gupta, Ramesh Karri", "title": "A Survey of Cybersecurity of Digital Manufacturing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Industry 4.0 concept promotes a digital manufacturing (DM) paradigm that\ncan enhance quality and productivity, that reduces inventory and the lead-time\nfor delivering custom, batch-of-one products based on achieving convergence of\nAdditive, Subtractive, and Hybrid manufacturing machines, Automation and\nRobotic Systems, Sensors, Computing, and Communication Networks, Artificial\nIntelligence, and Big Data. A DM system consists of embedded electronics,\nsensors, actuators, control software, and inter-connectivity to enable the\nmachines and the components within them to exchange data with other machines,\ncomponents therein, the plant operators, the inventory managers, and customers.\nThis paper presents the cybersecurity risks in the emerging DM context,\nassesses the impact on manufacturing, and identifies approaches to secure DM.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 04:32:49 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 12:16:38 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 16:35:02 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Mahesh", "Priyanka", ""], ["Tiwari", "Akash", ""], ["Jin", "Chenglu", ""], ["Kumar", "Panganamala R.", ""], ["Reddy", "A. L. Narasimha", ""], ["Bukkapatanam", "Satish T. S.", ""], ["Gupta", "Nikhil", ""], ["Karri", "Ramesh", ""]]}, {"id": "2006.05059", "submitter": "Mustafa Kishk", "authors": "Hesham Elsawy, Mustafa A. Kishk, Mohamed-Slim Alouini", "title": "Spatial Firewalls: Quarantining Malware Epidemics in Large Scale Massive\n  Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Billions of wireless devices are foreseen to participate in big data\naggregation and smart automation in order to interface the cyber and physical\nworlds. Such large-scale ultra-dense wireless connectivity is vulnerable to\nmalicious software (malware) epidemics. Malware worms can exploit multi-hop\nwireless connectivity to stealthily diffuse throughout the wireless network\nwithout being noticed to security servers at the core network. Compromised\ndevices can then be used by adversaries to remotely launch cyber attacks that\ncause large-scale critical physical damage and threaten public safety. This\narticle overviews the types, threats, and propagation models for malware\nepidemics in large-scale wireless networks (LSWN). Then, the article proposes a\nnovel and cost efficient countermeasure against malware epidemics in LSWN,\ndenoted as spatial firewalls. It is shown that equipping a strategically\nselected small portion (i.e., less than 10\\%) of the devices with\nstate-of-the-art security mechanisms is sufficient to create spatially secured\nzones that quarantine malware epidemics. Quarantined infected devices are then\ncured by on-demand localized software patching. To this end, several firewall\ndeployment strategies are discussed and compared.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 05:32:14 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 08:30:04 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Elsawy", "Hesham", ""], ["Kishk", "Mustafa A.", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "2006.05148", "submitter": "Chihoon Hwang", "authors": "MyungJae Shin, Chihoon Hwang, Joongheon Kim, Jihong Park, Mehdi Bennis\n  and Seong-Lyun Kim", "title": "XOR Mixup: Privacy-Preserving Data Augmentation for One-Shot Federated\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User-generated data distributions are often imbalanced across devices and\nlabels, hampering the performance of federated learning (FL). To remedy to this\nnon-independent and identically distributed (non-IID) data problem, in this\nwork we develop a privacy-preserving XOR based mixup data augmentation\ntechnique, coined XorMixup, and thereby propose a novel one-shot FL framework,\ntermed XorMixFL. The core idea is to collect other devices' encoded data\nsamples that are decoded only using each device's own data samples. The\ndecoding provides synthetic-but-realistic samples until inducing an IID\ndataset, used for model training. Both encoding and decoding procedures follow\nthe bit-wise XOR operations that intentionally distort raw samples, thereby\npreserving data privacy. Simulation results corroborate that XorMixFL achieves\nup to 17.6% higher accuracy than Vanilla FL under a non-IID MNIST dataset.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 09:43:41 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Shin", "MyungJae", ""], ["Hwang", "Chihoon", ""], ["Kim", "Joongheon", ""], ["Park", "Jihong", ""], ["Bennis", "Mehdi", ""], ["Kim", "Seong-Lyun", ""]]}, {"id": "2006.05167", "submitter": "Sara Asgari", "authors": "Sara Asgari and Babak Sadeghiyan", "title": "Towards Generating Benchmark Datasets for Worm Infection Studies", "comments": null, "journal-ref": null, "doi": "10.1109/IST50524.2020.9345845", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Worm origin identification and propagation path reconstruction are among the\nessential problems in digital forensics. Until now, several methods have been\nproposed for this purpose. However, evaluating these methods is a big challenge\nbecause there are no suitable datasets containing both normal background\ntraffic and worm traffic to evaluate these methods. In this paper, we\ninvestigate different methods of generating such datasets and suggest a\ntechnique for this purpose. ReaSE is a tool for the creation of realistic\nsimulation environments. However, it needs some modifications to be suitable\nfor generating the datasets. So we make required modifications to it. Then, we\ngenerate several datasets for Slammer, Code Red I, Code Red II and modified\nversions of these worms in different scenarios using our technique and make\nthem publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 10:21:21 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 12:17:09 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 12:44:30 GMT"}, {"version": "v4", "created": "Sat, 30 Jan 2021 16:56:33 GMT"}, {"version": "v5", "created": "Sun, 21 Feb 2021 20:07:23 GMT"}, {"version": "v6", "created": "Sun, 30 May 2021 17:25:08 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Asgari", "Sara", ""], ["Sadeghiyan", "Babak", ""]]}, {"id": "2006.05201", "submitter": "Antoine Rondelet", "authors": "Antoine Rondelet", "title": "A note on anonymous credentials using BLS signatures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this note, we remark that the aggregation property of the BLS signature\nscheme yields an efficient Content Extraction Signature (CES). This\nconstruction can be used to build digital credentials that support selective\ndisclosure in various settings. Interestingly, this construction is efficient\nand well suited to build credential issuance schemes with various applications\nin the client-server or in the distributed ledger models. Finally, we sketch a\nprotocol that combines the CES with the use of a NIZK which allows to prove\npredicate satisfaction on claims extracted from a credential, while keeping the\ndata secret.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 11:54:41 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Rondelet", "Antoine", ""]]}, {"id": "2006.05263", "submitter": "Goutam Paul", "authors": "Nayana Das and Goutam Paul", "title": "Improving the Security of \"Measurement-Device-Independent Quantum\n  Communication without Encryption\"", "comments": null, "journal-ref": "Science Bulletin, Volume 65, Issue 24, 30 December 2020, Pages\n  2048-2049", "doi": "10.1016/j.scib.2020.09.015", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recently in 2018, Niu et al. proposed a measurement-device-independent\nquantum secure direct communication protocol using Einstein-Podolsky-Rosen\npairs and generalized it to a quantum dialogue protocol (Niu et al., Science\nbulletin 63.20, 2018). By analyzing these protocols we find some security\nissues in both these protocols. In this work, we show that both the protocols\nare not secure against information leakage, and a third party can get half of\nthe secret information without any active attack. We also propose suitable\nmodifications of these protocols to improve the security.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 13:56:46 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 15:15:43 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Das", "Nayana", ""], ["Paul", "Goutam", ""]]}, {"id": "2006.05390", "submitter": "David Galindo", "authors": "Marcin Abram, David Galindo, Daniel Honerkamp, Jonathan Ward, Jin-Mann\n  Wong", "title": "Democratising blockchain: A minimal agency consensus model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel consensus protocol based on a hybrid approach, that\ncombines a directed acyclic graph (DAG) and a classical chain of blocks. This\narchitecture allows us to enforce collective block construction, minimising the\nmonopolistic power of the round-leader. In this way, we decrease the\npossibility for collusion among senders and miners, as well as miners\nthemselves, allowing the use of more incentive compatible and fair pricing\nstrategies. We investigate these possibilities alongside the ability to use the\nDAG structure to minimise the risk of transaction censoring. We conclude by\nproviding preliminary benchmarks of our protocol and by exploring further\nresearch directions.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 16:39:10 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Abram", "Marcin", ""], ["Galindo", "David", ""], ["Honerkamp", "Daniel", ""], ["Ward", "Jonathan", ""], ["Wong", "Jin-Mann", ""]]}, {"id": "2006.05535", "submitter": "Sina Sajadmanesh", "authors": "Sina Sajadmanesh and Daniel Gatica-Perez", "title": "Locally Private Graph Neural Networks", "comments": "Accepted at ACM CCS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have demonstrated superior performance in\nlearning node representations for various graph inference tasks. However,\nlearning over graph data can raise privacy concerns when nodes represent people\nor human-related variables that involve sensitive or personal information.\nWhile numerous techniques have been proposed for privacy-preserving deep\nlearning over non-relational data, there is less work addressing the privacy\nissues pertained to applying deep learning algorithms on graphs. In this paper,\nwe study the problem of node data privacy, where graph nodes have potentially\nsensitive data that is kept private, but they could be beneficial for a central\nserver for training a GNN over the graph. To address this problem, we develop a\nprivacy-preserving, architecture-agnostic GNN learning algorithm with formal\nprivacy guarantees based on Local Differential Privacy (LDP). Specifically, we\npropose an LDP encoder and an unbiased rectifier, by which the server can\ncommunicate with the graph nodes to privately collect their data and\napproximate the GNN's first layer. To further reduce the effect of the injected\nnoise, we propose to prepend a simple graph convolution layer, called KProp,\nwhich is based on the multi-hop aggregation of the nodes' features acting as a\ndenoising mechanism. Finally, we propose a robust training framework, in which\nwe benefit from KProp's denoising capability to increase the accuracy of\ninference in the presence of noisy labels. Extensive experiments conducted over\nreal-world datasets demonstrate that our method can maintain a satisfying level\nof accuracy with low privacy loss.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 22:36:06 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 07:55:22 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 20:08:35 GMT"}, {"version": "v4", "created": "Tue, 20 Oct 2020 01:02:09 GMT"}, {"version": "v5", "created": "Mon, 28 Dec 2020 18:52:45 GMT"}, {"version": "v6", "created": "Thu, 21 Jan 2021 12:14:26 GMT"}, {"version": "v7", "created": "Mon, 3 May 2021 13:27:36 GMT"}, {"version": "v8", "created": "Thu, 17 Jun 2021 23:42:14 GMT"}, {"version": "v9", "created": "Tue, 6 Jul 2021 19:00:21 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Sajadmanesh", "Sina", ""], ["Gatica-Perez", "Daniel", ""]]}, {"id": "2006.05594", "submitter": "Shaolei Ren", "authors": "Fangfang Yang and Shaolei Ren", "title": "Adversarial Attacks on Brain-Inspired Hyperdimensional Computing-Based\n  Classifiers", "comments": "14 pages and 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being an emerging class of in-memory computing architecture, brain-inspired\nhyperdimensional computing (HDC) mimics brain cognition and leverages random\nhypervectors (i.e., vectors with a dimensionality of thousands or even more) to\nrepresent features and to perform classification tasks. The unique hypervector\nrepresentation enables HDC classifiers to exhibit high energy efficiency, low\ninference latency and strong robustness against hardware-induced bit errors.\nConsequently, they have been increasingly recognized as an appealing\nalternative to or even replacement of traditional deep neural networks (DNNs)\nfor local on device classification, especially on low-power Internet of Things\ndevices. Nonetheless, unlike their DNN counterparts, state-of-the-art designs\nfor HDC classifiers are mostly security-oblivious, casting doubt on their\nsafety and immunity to adversarial inputs. In this paper, we study for the\nfirst time adversarial attacks on HDC classifiers and highlight that HDC\nclassifiers can be vulnerable to even minimally-perturbed adversarial samples.\nConcretely, using handwritten digit classification as an example, we construct\na HDC classifier and formulate a grey-box attack problem, where an attacker's\ngoal is to mislead the target HDC classifier to produce erroneous prediction\nlabels while keeping the amount of added perturbation noise as little as\npossible. Then, we propose a modified genetic algorithm to generate adversarial\nsamples within a reasonably small number of queries. Our results show that\nadversarial images generated by our algorithm can successfully mislead the HDC\nclassifier to produce wrong prediction labels with a high probability (i.e.,\n78% when the HDC classifier uses a fixed majority rule for decision). Finally,\nwe also present two defense strategies -- adversarial training and retraining--\nto strengthen the security of HDC classifiers.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 01:09:30 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Yang", "Fangfang", ""], ["Ren", "Shaolei", ""]]}, {"id": "2006.05609", "submitter": "Sudipta Paul Ms.", "authors": "Poushali Sengupta, Sudipta Paul, Subhankar Mishra", "title": "Learning With Differential Privacy", "comments": "25 pages, Accepted to - \"\"Handbook of Research on Cyber Crime and\n  Information Privacy\"\" as a book chapter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The leakage of data might have been an extreme effect on the personal level\nif it contains sensitive information. Common prevention methods like\nencryption-decryption, endpoint protection, intrusion detection system are\nprone to leakage. Differential privacy comes to the rescue with a proper\npromise of protection against leakage, as it uses a randomized response\ntechnique at the time of collection of the data which promises strong privacy\nwith better utility. Differential privacy allows one to access the forest of\ndata by describing their pattern of groups without disclosing any individual\ntrees. The current adaption of differential privacy by leading tech companies\nand academia encourages authors to explore the topic in detail. The different\naspects of differential privacy, it's application in privacy protection and\nleakage of information, a comparative discussion, on the current research\napproaches in this field, its utility in the real world as well as the\ntrade-offs - will be discussed.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 02:04:13 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 14:11:44 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Sengupta", "Poushali", ""], ["Paul", "Sudipta", ""], ["Mishra", "Subhankar", ""]]}, {"id": "2006.05648", "submitter": "Scott Freitas", "authors": "Scott Freitas, Duen Horng Chau", "title": "Evaluating Graph Vulnerability and Robustness using TIGER", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of network robustness is a critical tool in the characterization\nand understanding of complex interconnected systems such as transportation,\ninfrastructure, communication, and computer networks. Through analyzing and\nunderstanding the robustness of these networks we can:(1) quantify network\nvulnerability and robustness,(2) augment a network's structure to resist\nattacks and recover from failure, and (3) control the dissemination of entities\non the network (e.g., viruses, propaganda). While significant research has been\nconducted on all of these tasks, no comprehensive open-source toolbox currently\nexists to assist researchers and practitioners in this important topic. This\nlack of available tools hinders reproducibility and examination of existing\nwork, development of new research, and dissemination of new ideas. We\ncontribute TIGER, an open-sourced Python toolbox to address these challenges.\nTIGER contains 22 graph robustness measures with both original and fast\napproximate versions; 17 failure and attack strategies; 15 heuristic and\noptimization based defense techniques; and 4 simulation tools. By democratizing\nthe tools required to study network robustness, our goal is to assist\nresearchers and practitioners in analyzing their own networks; and facilitate\nthe development of new research in the field. TIGER is open-sourced at:\nhttps://github.com/safreita1/TIGER\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 04:21:43 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Freitas", "Scott", ""], ["Chau", "Duen Horng", ""]]}, {"id": "2006.05650", "submitter": "Luowen Qian", "authors": "Kai-Min Chung, Siyao Guo, Qipeng Liu, Luowen Qian", "title": "Tight Quantum Time-Space Tradeoffs for Function Inversion", "comments": "Minor updates from FOCS review comments", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In function inversion, we are given a function $f: [N] \\mapsto [N]$, and want\nto prepare some advice of size $S$, such that we can efficiently invert any\nimage in time $T$. This is a well studied problem with profound connections to\ncryptography, data structures, communication complexity, and circuit lower\nbounds. Investigation of this problem in the quantum setting was initiated by\nNayebi, Aaronson, Belovs, and Trevisan (2015), who proved a lower bound of\n$ST^2 = \\tilde\\Omega(N)$ for random permutations against classical advice,\nleaving open an intriguing possibility that Grover's search can be sped up to\ntime $\\tilde O(\\sqrt{N/S})$. Recent works by Hhan, Xagawa, and Yamakawa (2019),\nand Chung, Liao, and Qian (2019) extended the argument for random functions and\nquantum advice, but the lower bound remains $ST^2 = \\tilde\\Omega(N)$.\n  In this work, we prove that even with quantum advice, $ST + T^2 =\n\\tilde\\Omega(N)$ is required for an algorithm to invert random functions. This\ndemonstrates that Grover's search is optimal for $S = \\tilde O(\\sqrt{N})$,\nruling out any substantial speed-up for Grover's search even with quantum\nadvice. Further improvements to our bounds would imply new classical circuit\nlower bounds, as shown by Corrigan-Gibbs and Kogan (2019).\n  To prove this result, we develop a general framework for establishing quantum\ntime-space lower bounds. We further demonstrate the power of our framework by\nproving quantum time-space lower bounds for Yao's box problem and salted\ncryptography.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 04:23:26 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 19:44:59 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Chung", "Kai-Min", ""], ["Guo", "Siyao", ""], ["Liu", "Qipeng", ""], ["Qian", "Luowen", ""]]}, {"id": "2006.05660", "submitter": "Thomas Espitau", "authors": "Thomas Espitau, Paul Kirchner", "title": "The nearest-colattice algorithm", "comments": "19 pages, presented at the Algorithmic Number Theory Symposium (ANTS\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we exhibit a hierarchy of polynomial time algorithms solving\napproximate variants of the Closest Vector Problem (CVP). Our first\ncontribution is a heuristic algorithm achieving the same distance tradeoff as\nHSVP algorithms, namely $\\approx\n  \\beta^{\\frac{n}{2\\beta}}\\textrm{covol}(\\Lambda)^{\\frac{1}{n}}$ for a random\nlattice $\\Lambda$ of rank $n$. Compared to the so-called Kannan's embedding\ntechnique, our algorithm allows using precomputations and can be used for\nefficient batch CVP instances. This implies that some attacks on lattice-based\nsignatures lead to very cheap forgeries, after a precomputation. Our second\ncontribution is a proven reduction from approximating the closest vector with a\nfactor $\\approx n^{\\frac32}\\beta^{\\frac{3n}{2\\beta}}$ to the Shortest Vector\nProblem (SVP) in dimension $\\beta$.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 05:26:09 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 01:44:59 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Espitau", "Thomas", ""], ["Kirchner", "Paul", ""]]}, {"id": "2006.05812", "submitter": "Praneeth Vepakomma", "authors": "Ramesh Raskar, Greg Nadeau, John Werner, Rachel Barbar, Ashley Mehra,\n  Gabriel Harp, Markus Leopoldseder, Bryan Wilson, Derrick Flakoll, Praneeth\n  Vepakomma, Deepti Pahwa, Robson Beaudry, Emelin Flores, Maciej Popielarz,\n  Akanksha Bhatia, Andrea Nuzzo, Matt Gee, Jay Summet, Rajeev Surati, Bikram\n  Khastgir, Francesco Maria Benedetti, Kristen Vilcans, Sienna Leis, Khahlil\n  Louisy", "title": "COVID-19 Contact-Tracing Mobile Apps: Evaluation and Assessment for\n  Decision Makers", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of groups, from governments to non-profits, have quickly acted to\ninnovate the contact-tracing process: they are designing, building, and\nlaunching contact-tracing apps in response to the COVID-19 crisis. A diverse\nrange of approaches exist, creating challenging choices for officials looking\nto implement contact-tracing technology in their community and raising concerns\nabout these choices among citizens asked to participate in contact tracing. We\nare frequently asked how to evaluate and differentiate between the options for\ncontact-tracing applications. Here, we share the questions we ask about app\nfeatures and plans when reviewing the many contact-tracing apps appearing on\nthe global stage.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 02:08:02 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Raskar", "Ramesh", ""], ["Nadeau", "Greg", ""], ["Werner", "John", ""], ["Barbar", "Rachel", ""], ["Mehra", "Ashley", ""], ["Harp", "Gabriel", ""], ["Leopoldseder", "Markus", ""], ["Wilson", "Bryan", ""], ["Flakoll", "Derrick", ""], ["Vepakomma", "Praneeth", ""], ["Pahwa", "Deepti", ""], ["Beaudry", "Robson", ""], ["Flores", "Emelin", ""], ["Popielarz", "Maciej", ""], ["Bhatia", "Akanksha", ""], ["Nuzzo", "Andrea", ""], ["Gee", "Matt", ""], ["Summet", "Jay", ""], ["Surati", "Rajeev", ""], ["Khastgir", "Bikram", ""], ["Benedetti", "Francesco Maria", ""], ["Vilcans", "Kristen", ""], ["Leis", "Sienna", ""], ["Louisy", "Khahlil", ""]]}, {"id": "2006.05914", "submitter": "Jonas H\\\"ochst", "authors": "Lars Baumg\\\"artner (1), Alexandra Dmitrienko (3), Bernd Freisleben\n  (2), Alexander Gruler (2), Jonas H\\\"ochst (1 and 2), Joshua K\\\"uhlberg (1),\n  Mira Mezini (1), Richard Mitev (1), Markus Miettinen (1), Anel Muhamedagic\n  (1), Thien Duc Nguyen (1), Alvar Penning (2), Dermot Frederik Pustelnik (1),\n  Filipp Roos (3), Ahmad-Reza Sadeghi (1), Michael Schwarz (2), Christian Uhl\n  (2) ((1) TU Darmstadt, (2) Philipps-Universit\\\"at Marburg, (3) JMU\n  W\\\"urzburg)", "title": "Mind the GAP: Security & Privacy Risks of Contact Tracing Apps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Google and Apple have jointly provided an API for exposure notification in\norder to implement decentralized contract tracing apps using Bluetooth Low\nEnergy, the so-called \"Google/Apple Proposal\", which we abbreviate by \"GAP\". We\ndemonstrate that in real-world scenarios the current GAP design is vulnerable\nto (i) profiling and possibly de-anonymizing infected persons, and (ii)\nrelay-based wormhole attacks that basically can generate fake contacts with the\npotential of affecting the accuracy of an app-based contact tracing system. For\nboth types of attack, we have built tools that can easily be used on mobile\nphones or Raspberry Pis (e.g., Bluetooth sniffers). The goal of our work is to\nperform a reality check towards possibly providing empirical real-world\nevidence for these two privacy and security risks. We hope that our findings\nprovide valuable input for developing secure and privacy-preserving digital\ncontact tracing systems.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 16:05:05 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 13:27:07 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Baumg\u00e4rtner", "Lars", "", "1 and 2"], ["Dmitrienko", "Alexandra", "", "1 and 2"], ["Freisleben", "Bernd", "", "1 and 2"], ["Gruler", "Alexander", "", "1 and 2"], ["H\u00f6chst", "Jonas", "", "1 and 2"], ["K\u00fchlberg", "Joshua", ""], ["Mezini", "Mira", ""], ["Mitev", "Richard", ""], ["Miettinen", "Markus", ""], ["Muhamedagic", "Anel", ""], ["Nguyen", "Thien Duc", ""], ["Penning", "Alvar", ""], ["Pustelnik", "Dermot Frederik", ""], ["Roos", "Filipp", ""], ["Sadeghi", "Ahmad-Reza", ""], ["Schwarz", "Michael", ""], ["Uhl", "Christian", ""]]}, {"id": "2006.05930", "submitter": "Ayush Jain", "authors": "Yuqiao Zhang, Ayush Jain, Pinchen Cui, Ziqi Zhou and Ujjwal Guin", "title": "A Novel Topology-Guided Attack and Its Countermeasure Towards Secure\n  Logic Locking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The outsourcing of the design and manufacturing of integrated circuits (ICs)\nin the current horizontal semiconductor integration flow has posed various\nsecurity threats due to the presence of untrusted entities, such as\noverproduction of ICs, sale of out-of-specification/rejected ICs, and piracy of\nIntellectual Properties (IPs). Consequently, logic locking emerged as one of\nthe prominent design for trust techniques. Unfortunately, these locking\ntechniques are now inclined to achieve complete Boolean satisfiability (SAT)\nresiliency after the seminal work published in [47]. In this paper, we propose\na novel oracle-less attack that is based on the topological analysis of the\nlocked netlist even though it is SAT-resilient. The attack relies on\nidentifying and constructing unit functions with a hypothesis key to be\nsearched in the entire netlist to find its replica. The proposed graph search\nalgorithm efficiently finds the duplicate functions in the netlist, making it a\nself-referencing attack. This proposed attack is extremely efficient and can\ndetermine the secret key within a few minutes. We have also proposed a\ncountermeasure to make the circuit resilient against this topology-guided\nattack to progress towards a secure logic locking technique.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 16:32:50 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 19:55:14 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Zhang", "Yuqiao", ""], ["Jain", "Ayush", ""], ["Cui", "Pinchen", ""], ["Zhou", "Ziqi", ""], ["Guin", "Ujjwal", ""]]}, {"id": "2006.06036", "submitter": "Federico Franzoni", "authors": "Federico Franzoni, Ivan Abellan, Vanesa Daza", "title": "Leveraging Bitcoin Testnet for Bidirectional Botnet Command and Control\n  Systems", "comments": "19 pages, 0 figures, Conference: Financial Cryptography and Data\n  Security 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past twenty years, the number of devices connected to the Internet\ngrew exponentially. Botnets benefited from this rise to increase their size and\nthe magnitude of their attacks. However, they still have a weak point in their\nCommand & Control (C&C) system, which is often based on centralized services or\nrequire a complex infrastructure to keep operating without being taken down by\nauthorities. The recent spread of blockchain technologies may give botnets a\npowerful tool to make them very hard to disrupt. Recent research showed how it\nis possible to embed C&C messages in Bitcoin transactions, making them nearly\nimpossible to block. Nevertheless, transactions have a cost and allow very\nlimited amounts of data to be transmitted. Because of that, only messages from\nthe botmaster to the bots are sent via Bitcoin, while bots are assumed to\ncommunicate through external channels. Furthermore, for the same reason,\nBitcoin-based messages are sent in clear. In this paper we show how, using\nBitcoin Testnet, it is possible to overcome these limitations and implement a\ncost-free, bidirectional, and encrypted C&C channel between the botmaster and\nthe bots. We propose a communication protocol and analyze its viability in real\nlife. Our results show that this approach would enable a botmaster to build a\nrobust and hard-to-disrupt C&C system at virtually no cost, thus representing a\nrealistic threat for which countermeasures should be devised.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 19:09:21 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Franzoni", "Federico", ""], ["Abellan", "Ivan", ""], ["Daza", "Vanesa", ""]]}, {"id": "2006.06045", "submitter": "Jason Jaskolka", "authors": "Jason Jaskolka", "title": "Evaluating the Exploitability of Implicit Interactions in Distributed\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit interactions refer to those interactions among the components of a\nsystem that may be unintended and/or unforeseen by the system designers. As\nsuch, they represent cybersecurity vulnerabilities that can be exploited to\nmount cyber-attacks causing serious and destabilizing system effects. In this\npaper, we study implicit interactions in distributed systems specified using\nthe algebraic modeling framework known as Communicating Concurrent Kleene\nAlgebra (C$^2$KA). To identify and defend against a range of possible attack\nscenarios, we develop a new measure of exploitability for implicit interactions\nto aid in evaluating the threat posed by the existence of such vulnerabilities\nin system designs for launching cyber-attacks. The presented approach is based\non the modeling and analysis of the influence and response of the system agents\nand their C$^2$KA specifications. We also demonstrate the applicability of the\nproposed approach using a prototype tool that supports the automated analysis.\nThe rigorous, practical techniques presented here enable cybersecurity\nvulnerabilities in the designs of distributed systems to be more easily\nidentified, assessed, and then mitigated, offering significant improvements to\noverall system resilience, dependability, and security.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 19:59:52 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Jaskolka", "Jason", ""]]}, {"id": "2006.06061", "submitter": "Chris Finlay", "authors": "Ryan Campbell, Chris Finlay, Adam M Oberman", "title": "Deterministic Gaussian Averaged Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deterministic method to compute the Gaussian average of neural\nnetworks used in regression and classification. Our method is based on an\nequivalence between training with a particular regularized loss, and the\nexpected values of Gaussian averages. We use this equivalence to certify models\nwhich perform well on clean data but are not robust to adversarial\nperturbations. In terms of certified accuracy and adversarial robustness, our\nmethod is comparable to known stochastic methods such as randomized smoothing,\nbut requires only a single model evaluation during inference.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 20:53:31 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Campbell", "Ryan", ""], ["Finlay", "Chris", ""], ["Oberman", "Adam M", ""]]}, {"id": "2006.06069", "submitter": "Yingtong Dou", "authors": "Yingtong Dou, Guixiang Ma, Philip S. Yu, Sihong Xie", "title": "Robust Spammer Detection by Nash Reinforcement Learning", "comments": "Accepted by KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online reviews provide product evaluations for customers to make decisions.\nUnfortunately, the evaluations can be manipulated using fake reviews (\"spams\")\nby professional spammers, who have learned increasingly insidious and powerful\nspamming strategies by adapting to the deployed detectors. Spamming strategies\nare hard to capture, as they can be varying quickly along time, different\nacross spammers and target products, and more critically, remained unknown in\nmost cases. Furthermore, most existing detectors focus on detection accuracy,\nwhich is not well-aligned with the goal of maintaining the trustworthiness of\nproduct evaluations. To address the challenges, we formulate a minimax game\nwhere the spammers and spam detectors compete with each other on their\npractical goals that are not solely based on detection accuracy. Nash\nequilibria of the game lead to stable detectors that are agnostic to any mixed\ndetection strategies. However, the game has no closed-form solution and is not\ndifferentiable to admit the typical gradient-based algorithms. We turn the game\ninto two dependent Markov Decision Processes (MDPs) to allow efficient\nstochastic optimization based on multi-armed bandit and policy gradient. We\nexperiment on three large review datasets using various state-of-the-art\nspamming and detection strategies and show that the optimization algorithm can\nreliably find an equilibrial detector that can robustly and effectively prevent\nspammers with any mixed spamming strategies from attaining their practical\ngoal. Our code is available at https://github.com/YingtongDou/Nash-Detect.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 21:18:07 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 14:48:36 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 23:10:49 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Dou", "Yingtong", ""], ["Ma", "Guixiang", ""], ["Yu", "Philip S.", ""], ["Xie", "Sihong", ""]]}, {"id": "2006.06070", "submitter": "Mohammad Saidur Rahman", "authors": "Mohammad Saidur Rahman", "title": "Optimizing Smart Grid Aggregators and Measuring Degree of Privacy in a\n  Distributed Trust Based Anonymous Aggregation System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A smart grid is an advanced method for supplying electricity to the consumers\nalleviating the limitations of the existing system. It causes frequent meter\nreading transmission from the end-user to the supplier. This frequent data\ntransmission poses privacy risks. Several works have been proposed to solve\nthis problem but cannot ensure privacy at the optimal level. This work is based\non a distributed trust-based data aggregation system leveraging a secret\nsharing mechanism. In this work, we show that {\\em three aggregators} are\nenough for ensuring consumer's privacy in a distributed trust-based system. We\nleverage the idea of anonymity in our research and show that neither an active\nattacker nor a passive attacker can breach consumer's privacy. We show proof of\nour concept mathematically and in a cryptographic game based mechanism. We name\nour new proposed system \\emph{\"Distributed Trust Based Anonymous System\n(DTBAS)\"}.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 21:20:30 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Rahman", "Mohammad Saidur", ""]]}, {"id": "2006.06079", "submitter": "Saba Eskandarian", "authors": "Saba Eskandarian", "title": "Fast Privacy-Preserving Punch Cards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loyalty programs in the form of punch cards that can be redeemed for benefits\nhave long been a ubiquitous element of the consumer landscape. However, their\nincreasingly popular digital equivalents, while providing more convenience and\nbetter bookkeeping, pose a considerable privacy risk. This paper introduces a\nprivacy-preserving punch card protocol that allows firms to digitize their\nloyalty programs without forcing customers to submit to corporate surveillance.\nWe also present a number of extensions that allow our scheme to provide other\nprivacy-preserving customer loyalty features.\n  Compared to the best prior work, we achieve a $14\\times$ reduction in the\ncomputation and a $11\\times$ reduction in the communication required to perform\na \"hole punch,\" a $55\\times$ reduction in the communication required to redeem\na punch card, and a $128\\times$ reduction in the computation time required to\nredeem a card. Much of our performance improvement can be attributed to\nremoving the reliance on pairings or range proofs present in prior work, which\nhas only addressed this problem in the context of more general loyalty systems.\nBy tailoring our scheme to punch cards and related loyalty systems, we\ndemonstrate that we can reduce communication and computation costs by orders of\nmagnitude.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 21:49:15 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 18:40:23 GMT"}, {"version": "v3", "created": "Fri, 19 Feb 2021 17:40:52 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Eskandarian", "Saba", ""]]}, {"id": "2006.06122", "submitter": "Franco Palau", "authors": "Franco Palau, Carlos Catania, Jorge Guerra, Sebastian Garcia, and\n  Maria Rigaki", "title": "DNS Tunneling: A Deep Learning based Lexicographical Detection Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Domain Name Service is a trusted protocol made for name resolution, but\nduring past years some approaches have been developed to use it for data\ntransfer. DNS Tunneling is a method where data is encoded inside DNS queries,\nallowing information exchange through the DNS. This characteristic is\nattractive to hackers who exploit DNS Tunneling method to establish\nbidirectional communication with machines infected with malware with the\nobjective of exfiltrating data or sending instructions in an obfuscated way. To\ndetect these threats fast and accurately, the present work proposes a detection\napproach based on a Convolutional Neural Network (CNN) with a minimal\narchitecture complexity. Due to the lack of quality datasets for evaluating DNS\nTunneling connections, we also present a detailed construction and description\nof a novel dataset that contains DNS Tunneling domains generated with five\nwell-known DNS tools. Despite its simple architecture, the resulting CNN model\ncorrectly detected more than 92% of total Tunneling domains with a false\npositive rate close to 0.8%.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 00:10:13 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 23:28:51 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Palau", "Franco", ""], ["Catania", "Carlos", ""], ["Guerra", "Jorge", ""], ["Garcia", "Sebastian", ""], ["Rigaki", "Maria", ""]]}, {"id": "2006.06131", "submitter": "Zhiyi Zhang", "authors": "Zhiyi Zhang, Yu Guan, Xinyu Ma, Tianyuan Yu, Lixia Zhang", "title": "Sovereign: User-Controlled Smart Homes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart homes made up of Internet of Things (IoT) devices have seen wide\ndeployment in recent years, with most, if not all, of them controlled by remote\nservers in the cloud. Such designs raise security and privacy concerns for end\nusers. We believe that the current situation has largely resulted from lacking\na systematic home IoT framework to support localized end user control.\n  To let end users take back the control of smart homes, we propose Sovereign,\nan IoT system framework that allows users to securely control home IoT systems\nwithout depending on a cloud backend. Unlike existing solutions, Sovereign\nnetworks home IoT devices and applications using named data with\napplication-level semantics; the names are then used to construct security\nmechanisms. Users define security policies and these policies are then executed\nby the localized security modules. We implement Sovereign as a pub/sub based\ndevelopment platform together with a prototype local IoT controller. Our\npreliminary evaluation shows that Sovereign provides an easy-to-use systematic\nsolution to secure smart homes under user control without imposing noticeable\noverhead.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 00:44:09 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 18:38:55 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Zhang", "Zhiyi", ""], ["Guan", "Yu", ""], ["Ma", "Xinyu", ""], ["Yu", "Tianyuan", ""], ["Zhang", "Lixia", ""]]}, {"id": "2006.06148", "submitter": "Jan Kallberg", "authors": "Jan Kallberg, Stephen S. Hamilton", "title": "Resiliency by Retrograded Communication- The Revival of Shortwave as a\n  Military Communication Channel", "comments": "3600 words, submitted to IEEE venue 06/10/20 (2020-06-10)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the last three decades, the great powers have become increasingly\ndependent on satellite communication (SATCOM), very high frequency (VHF), and\nultra-high frequency (UHF) providing high bandwidth line of sight (LOS)\ncommunications. These military communication channels lack resilience because\nan EW campaign can affect both VHF and SATCOM simultaneously. The 1940s\npreferred spectrum, high frequency (HF), with its different propagation\npatterns, offers an opportunity for military communication resiliency in the\n21st century. The concept of retrograding could give an operational advantage\nand create the ability to sustain communication in electronic warfare (EW)\nsaturated environment.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 01:54:04 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Kallberg", "Jan", ""], ["Hamilton", "Stephen S.", ""]]}, {"id": "2006.06197", "submitter": "Emmanuel Thome", "authors": "Fabrice Boudot (XLIM), Pierrick Gaudry (CARAMBA, LORIA), Aurore\n  Guillevic (CARAMBA, LORIA), Nadia Heninger (UC San Diego), Emmanuel Thom\\'e\n  (CARAMBA, LORIA), Paul Zimmermann (CARAMBA, LORIA)", "title": "Comparing the difficulty of factorization and discrete logarithm: a\n  240-digit experiment", "comments": null, "journal-ref": "The 40th Annual International Cryptology Conference (Crypto 2020),\n  Aug 2020, Santa Barbara, USA, United States", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on two new records: the factorization of RSA-240, a 795-bit number,\nand a discrete logarithm computation over a 795-bit prime field. Previous\nrecords were the factorization of RSA-768 in 2009 and a 768-bit discrete\nlogarithm computation in 2016. Our two computations at the 795-bit level were\ndone using the same hardware and software, and show that computing a discrete\nlogarithm is not much harder than a factorization of the same size. Moreover,\nthanks to algorithmic variants and well-chosen parameters, our computations\nwere significantly less expensive than anticipated based on previous\nrecords.The last page of this paper also reports on the factorization of\nRSA-250.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 05:17:58 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Boudot", "Fabrice", "", "XLIM"], ["Gaudry", "Pierrick", "", "CARAMBA, LORIA"], ["Guillevic", "Aurore", "", "CARAMBA, LORIA"], ["Heninger", "Nadia", "", "UC San Diego"], ["Thom\u00e9", "Emmanuel", "", "CARAMBA, LORIA"], ["Zimmermann", "Paul", "", "CARAMBA, LORIA"]]}, {"id": "2006.06290", "submitter": "Thilo Krachenfels", "authors": "Thilo Krachenfels, Heiko Lohrke, Jean-Pierre Seifert, Enrico Dietz,\n  Sven Frohmann, Heinz-Wilhelm H\\\"ubers", "title": "Evaluation of Low-Cost Thermal Laser Stimulation for Data Extraction and\n  Key Readout", "comments": null, "journal-ref": null, "doi": "10.1007/s41635-019-00083-9", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent attacks using thermal laser stimulation (TLS) have shown that it is\npossible to extract cryptographic keys from the battery-backed memory on\nstate-of-the-art field-programmable gate arrays (FPGAs). However, the\nprofessional failure analysis microscopes usually employed for these attacks\ncost in the order of 500k to 1M dollars. In this work, we evaluate the use of a\ncheaper commercial laser fault injection station retrofitted with a suitable\namplifier and light source to enable TLS. We demonstrate that TLS attacks are\npossible at a hardware cost of around 100k dollars. This constitutes a\nreduction of the resources required by the attacker by a factor of at least\nfive. We showcase two actual attacks: data extraction from the SRAM memory of a\nlow-power microcontroller and decryption key extraction from a 20-nm technology\nFPGA device. The strengths and weaknesses of our low-cost approach are then\ndiscussed in comparison with the conventional failure analysis equipment\napproach. In general, this work demonstrates that TLS backside attacks are\navailable at a much lower cost than previously expected.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 09:55:55 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Krachenfels", "Thilo", ""], ["Lohrke", "Heiko", ""], ["Seifert", "Jean-Pierre", ""], ["Dietz", "Enrico", ""], ["Frohmann", "Sven", ""], ["H\u00fcbers", "Heinz-Wilhelm", ""]]}, {"id": "2006.06296", "submitter": "Felix Lorenz", "authors": "Felix Lorenz, Lauritz Thamsen, Andreas Wilke, Ilja Behnke, Jens\n  Waldm\\\"uller-Littke, Ilya Komarov, Odej Kao, Manfred Paeschke", "title": "Fingerprinting Analog IoT Sensors for Secret-Free Authentication", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Especially in context of critical urban infrastructures, trust in IoT data is\nof utmost importance. While most technology stacks provide means for\nauthentication and encryption of device-to-cloud traffic, there are currently\nno mechanisms to rule out physical tampering with an IoT device's sensors.\nAddressing this gap, we introduce a new method for extracting a hardware\nfingerprint of an IoT sensor which can be used for secret-free authentication.\nBy comparing the fingerprint against reference measurements recorded prior to\ndeployment, we can tell whether the sensing hardware connected to the IoT\ndevice has been changed by environmental effects or with malicious intent. Our\napproach exploits the characteristic behavior of analog circuits, which is\nrevealed by applying a fixed-frequency alternating current to the sensor, while\nrecording its output voltage. To demonstrate the general feasibility of our\nmethod, we apply it to four commercially available temperature sensors using\nlaboratory equipment and evaluate the accuracy. The results indicate that with\na sensible configuration of the two hyperparameters we can identify individual\nsensors with high probability, using only a few recordings from the target\ndevice.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 10:03:24 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Lorenz", "Felix", ""], ["Thamsen", "Lauritz", ""], ["Wilke", "Andreas", ""], ["Behnke", "Ilja", ""], ["Waldm\u00fcller-Littke", "Jens", ""], ["Komarov", "Ilya", ""], ["Kao", "Odej", ""], ["Paeschke", "Manfred", ""]]}, {"id": "2006.06356", "submitter": "Suzanne Wetstein", "authors": "Gerda Bortsova, Cristina Gonz\\'alez-Gonzalo, Suzanne C. Wetstein,\n  Florian Dubost, Ioannis Katramados, Laurens Hogeweg, Bart Liefers, Bram van\n  Ginneken, Josien P.W. Pluim, Mitko Veta, Clara I. S\\'anchez, and Marleen de\n  Bruijne", "title": "Adversarial Attack Vulnerability of Medical Image Analysis Systems:\n  Unexplored Factors", "comments": "First three authors contributed equally", "journal-ref": "Medical Image Analysis. Available online 18 Jun 2021", "doi": "10.1016/j.media.2021.102141", "report-no": null, "categories": "cs.CR cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks are considered a potentially serious security threat for\nmachine learning systems. Medical image analysis (MedIA) systems have recently\nbeen argued to be vulnerable to adversarial attacks due to strong financial\nincentives and the associated technological infrastructure.\n  In this paper, we study previously unexplored factors affecting adversarial\nattack vulnerability of deep learning MedIA systems in three medical domains:\nophthalmology, radiology, and pathology. We focus on adversarial black-box\nsettings, in which the attacker does not have full access to the target model\nand usually uses another model, commonly referred to as surrogate model, to\ncraft adversarial examples. We consider this to be the most realistic scenario\nfor MedIA systems.\n  Firstly, we study the effect of weight initialization (ImageNet vs. random)\non the transferability of adversarial attacks from the surrogate model to the\ntarget model. Secondly, we study the influence of differences in development\ndata between target and surrogate models. We further study the interaction of\nweight initialization and data differences with differences in model\narchitecture. All experiments were done with a perturbation degree tuned to\nensure maximal transferability at minimal visual perceptibility of the attacks.\n  Our experiments show that pre-training may dramatically increase the\ntransferability of adversarial examples, even when the target and surrogate's\narchitectures are different: the larger the performance gain using\npre-training, the larger the transferability. Differences in the development\ndata between target and surrogate models considerably decrease the performance\nof the attack; this decrease is further amplified by difference in the model\narchitecture. We believe these factors should be considered when developing\nsecurity-critical MedIA systems planned to be deployed in clinical practice.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 12:19:39 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 08:36:29 GMT"}, {"version": "v3", "created": "Thu, 17 Jun 2021 12:50:56 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Bortsova", "Gerda", ""], ["Gonz\u00e1lez-Gonzalo", "Cristina", ""], ["Wetstein", "Suzanne C.", ""], ["Dubost", "Florian", ""], ["Katramados", "Ioannis", ""], ["Hogeweg", "Laurens", ""], ["Liefers", "Bart", ""], ["van Ginneken", "Bram", ""], ["Pluim", "Josien P. W.", ""], ["Veta", "Mitko", ""], ["S\u00e1nchez", "Clara I.", ""], ["de Bruijne", "Marleen", ""]]}, {"id": "2006.06419", "submitter": "Ningyu He", "authors": "Ru Ji, Ningyu He, Lei Wu, Haoyu Wang, Guangdong Bai, Yao Guo", "title": "DEPOSafe: Demystifying the Fake Deposit Vulnerability in Ethereum Smart\n  Contracts", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptocurrency has seen an explosive growth in recent years, thanks to the\nevolvement of blockchain technology and its economic ecosystem. Besides\nBitcoin, thousands of cryptocurrencies have been distributed on blockchains,\nwhile hundreds of cryptocurrency exchanges are emerging to facilitate the\ntrading of digital assets. At the same time, it also attracts the attentions of\nattackers. Fake deposit, as one of the most representative attacks\n(vulnerabilities) related to exchanges and tokens, has been frequently observed\nin the blockchain ecosystem, causing large financial losses. However, besides a\nfew security reports, our community lacks of the understanding of this\nvulnerability, for example its scale and the impacts. In this paper, we take\nthe first step to demystify the fake deposit vulnerability. Based on the\nessential patterns we have summarized, we implement DEPOSafe, an automated tool\nto detect and verify (exploit) the fake deposit vulnerability in ERC-20 smart\ncontracts. DEPOSafe incorporates several key techniques including symbolic\nexecution based static analysis and behavior modeling based dynamic\nverification. By applying DEPOSafe to 176,000 ERC-20 smart contracts, we have\nidentified over 7,000 vulnerable contracts that may suffer from two types of\nattacks. Our findings demonstrate the urgency to identify and prevent the fake\ndeposit vulnerability.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 13:30:35 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Ji", "Ru", ""], ["He", "Ningyu", ""], ["Wu", "Lei", ""], ["Wang", "Haoyu", ""], ["Bai", "Guangdong", ""], ["Guo", "Yao", ""]]}, {"id": "2006.06493", "submitter": "Nataniel Ruiz", "authors": "Nataniel Ruiz, Sarah Adel Bargal, Stan Sclaroff", "title": "Protecting Against Image Translation Deepfakes by Leaking Universal\n  Perturbations from Black-Box Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we develop efficient disruptions of black-box image translation\ndeepfake generation systems. We are the first to demonstrate black-box deepfake\ngeneration disruption by presenting image translation formulations of attacks\ninitially proposed for classification models. Nevertheless, a naive adaptation\nof classification black-box attacks results in a prohibitive number of queries\nfor image translation systems in the real-world. We present a frustratingly\nsimple yet highly effective algorithm Leaking Universal Perturbations (LUP),\nthat significantly reduces the number of queries needed to attack an image. LUP\nconsists of two phases: (1) a short leaking phase where we attack the network\nusing traditional black-box attacks and gather information on successful\nattacks on a small dataset and (2) and an exploitation phase where we leverage\nsaid information to subsequently attack the network with improved efficiency.\nOur attack reduces the total number of queries necessary to attack GANimation\nand StarGAN by 30%.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 15:02:27 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Ruiz", "Nataniel", ""], ["Bargal", "Sarah Adel", ""], ["Sclaroff", "Stan", ""]]}, {"id": "2006.06535", "submitter": "Sicong Liu", "authors": "Sicong Liu, Junzhao Du, Anshumali Shrivastava, Lin Zhong", "title": "Privacy Adversarial Network: Representation Learning for Mobile Data\n  Privacy", "comments": null, "journal-ref": null, "doi": "10.1145/3369816", "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The remarkable success of machine learning has fostered a growing number of\ncloud-based intelligent services for mobile users. Such a service requires a\nuser to send data, e.g. image, voice and video, to the provider, which presents\na serious challenge to user privacy. To address this, prior works either\nobfuscate the data, e.g. add noise and remove identity information, or send\nrepresentations extracted from the data, e.g. anonymized features. They\nstruggle to balance between the service utility and data privacy because\nobfuscated data reduces utility and extracted representation may still reveal\nsensitive information.\n  This work departs from prior works in methodology: we leverage adversarial\nlearning to a better balance between privacy and utility. We design a\n\\textit{representation encoder} that generates the feature representations to\noptimize against the privacy disclosure risk of sensitive information (a\nmeasure of privacy) by the \\textit{privacy adversaries}, and concurrently\noptimize with the task inference accuracy (a measure of utility) by the\n\\textit{utility discriminator}. The result is the privacy adversarial network\n(\\systemname), a novel deep model with the new training algorithm, that can\nautomatically learn representations from the raw data.\n  Intuitively, PAN adversarially forces the extracted representations to only\nconvey the information required by the target task. Surprisingly, this\nconstitutes an implicit regularization that actually improves task accuracy. As\na result, PAN achieves better utility and better privacy at the same time! We\nreport extensive experiments on six popular datasets and demonstrate the\nsuperiority of \\systemname compared with alternative methods reported in prior\nwork.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 09:42:04 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Liu", "Sicong", ""], ["Du", "Junzhao", ""], ["Shrivastava", "Anshumali", ""], ["Zhong", "Lin", ""]]}, {"id": "2006.06561", "submitter": "Saeedreza Shehnepoor", "authors": "Saeedreza Shehnepoor, Roberto Togneri, Wei Liu, Mohammed Bennamoun", "title": "ScoreGAN: A Fraud Review Detector based on Multi Task Learning of\n  Regulated GAN with Data Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The promising performance of Deep Neural Networks (DNNs) in text\nclassification, has attracted researchers to use them for fraud review\ndetection. However, the lack of trusted labeled data has limited the\nperformance of the current solutions in detecting fraud reviews. The Generative\nAdversarial Network (GAN) as a semi-supervised method has demonstrated to be\neffective for data augmentation purposes. The state-of-the-art solutions\nutilize GANs to overcome the data scarcity problem. However, they fail to\nincorporate the behavioral clues in fraud generation. Additionally,\nstate-of-the-art approaches overlook the possible bot-generated reviews in the\ndataset. Finally, they also suffer from a common limitation in scalability and\nstability of the GAN, slowing down the training procedure. In this work, we\npropose ScoreGAN for fraud review detection that makes use of both review text\nand review rating scores in the generation and detection process. Scores are\nincorporated through Information Gain Maximization (IGM) into the loss function\nfor three reasons. One is to generate score-correlated reviews based on the\nscores given to the generator. Second, the generated reviews are employed to\ntrain the discriminator, so the discriminator can correctly label the possible\nbot-generated reviews through joint representations learned from the\nconcatenation of GLobal Vector for Word representation (GLoVe) extracted from\nthe text and the score. Finally, it can be used to improve the stability and\nscalability of the GAN. Results show that the proposed framework outperformed\nthe existing state-of-the-art framework, namely FakeGAN, in terms of AP by 7\\%,\nand 5\\% on the Yelp and TripAdvisor datasets, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 16:15:06 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 14:18:15 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Shehnepoor", "Saeedreza", ""], ["Togneri", "Roberto", ""], ["Liu", "Wei", ""], ["Bennamoun", "Mohammed", ""]]}, {"id": "2006.06618", "submitter": "Gautam Kamath", "authors": "Sourav Biswas, Yihe Dong, Gautam Kamath, Jonathan Ullman", "title": "CoinPress: Practical Private Mean and Covariance Estimation", "comments": "Code is available at https://github.com/twistedcubic/coin-press", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.DS cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present simple differentially private estimators for the mean and\ncovariance of multivariate sub-Gaussian data that are accurate at small sample\nsizes. We demonstrate the effectiveness of our algorithms both theoretically\nand empirically using synthetic and real-world datasets---showing that their\nasymptotic error rates match the state-of-the-art theoretical bounds, and that\nthey concretely outperform all previous methods. Specifically, previous\nestimators either have weak empirical accuracy at small sample sizes, perform\npoorly for multivariate data, or require the user to provide strong a priori\nestimates for the parameters.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 17:17:28 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Biswas", "Sourav", ""], ["Dong", "Yihe", ""], ["Kamath", "Gautam", ""], ["Ullman", "Jonathan", ""]]}, {"id": "2006.06721", "submitter": "Kathrin Grosse", "authors": "Kathrin Grosse, Taesung Lee, Battista Biggio, Youngja Park, Michael\n  Backes, Ian Molloy", "title": "Backdoor Smoothing: Demystifying Backdoor Attacks on Deep Neural\n  Networks", "comments": "17 pages, 7 figures, under submission, (major revision from previous\n  version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backdoor attacks aim to mislead machine-learning models to output an\nattacker-specified class when presented a specific trigger at test time. These\nattacks require poisoning the training data or compromising the learning\nalgorithm, e.g., by injecting poisoning samples containing the trigger into the\ntraining set, along with the desired class label. Despite the increasing number\nof studies on backdoor attacks and defenses, the underlying factors affecting\nthe success of backdoor attacks, along with their impact on the learning\nalgorithm, are not yet well understood. In this work, we aim to shed light on\nthis issue. In particular, we unveil that backdoor attacks work by inducing a\nsmoother decision function around the triggered samples -- a phenomenon which\nwe refer to as \\textit{backdoor smoothing}. We quantify backdoor smoothing by\ndefining a measure that evaluates the uncertainty associated to the predictions\nof a classifier around the input samples.\n  Our experiments show that smoothness increases when the trigger is added to\nthe input samples, and that the phenomenon is more pronounced for more\nsuccessful attacks.\n  However, our experiments also show that patterns fulfilling backdoor\nsmoothing can be crafted\n  even without poisoning the training data.\n  Although our measure may not be directly exploited as a defense mechanism, it\nunveils an important phenomenon which may pave the way towards understanding\nthe limitations of current defenses that rely on a smooth decision output for\nbackdoors.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 18:28:54 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 07:31:59 GMT"}, {"version": "v3", "created": "Thu, 10 Jun 2021 14:58:34 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Grosse", "Kathrin", ""], ["Lee", "Taesung", ""], ["Biggio", "Battista", ""], ["Park", "Youngja", ""], ["Backes", "Michael", ""], ["Molloy", "Ian", ""]]}, {"id": "2006.06783", "submitter": "Shuang Song", "authors": "Shuang Song, Thomas Steinke, Om Thakkar, Abhradeep Thakurta", "title": "Evading Curse of Dimensionality in Unconstrained Private GLMs via\n  Private Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the well-studied problem of differentially private empirical risk\nminimization (ERM). We show that for unconstrained convex generalized linear\nmodels (GLMs), one can obtain an excess empirical risk of $\\tilde\nO\\left(\\sqrt{{\\texttt{rank}}}/\\epsilon n\\right)$, where ${\\texttt{rank}}$ is\nthe rank of the feature matrix in the GLM problem, $n$ is the number of data\nsamples, and $\\epsilon$ is the privacy parameter. This bound is attained via\ndifferentially private gradient descent (DP-GD). Furthermore, via the first\nlower bound for unconstrained private ERM, we show that our upper bound is\ntight. In sharp contrast to the constrained ERM setting, there is no dependence\non the dimensionality of the ambient model space ($p$). (Notice that\n${\\texttt{rank}}\\leq \\min\\{n, p\\}$.) Besides, we obtain an analogous excess\npopulation risk bound which depends on ${\\texttt{rank}}$ instead of $p$.\n  For the smooth non-convex GLM setting (i.e., where the objective function is\nnon-convex but preserves the GLM structure), we further show that DP-GD attains\na dimension-independent convergence of $\\tilde\nO\\left(\\sqrt{{\\texttt{rank}}}/\\epsilon n\\right)$ to a\nfirst-order-stationary-point of the underlying objective.\n  Finally, we show that for convex GLMs, a variant of DP-GD commonly used in\npractice (which involves clipping the individual gradients) also exhibits the\nsame dimension-independent convergence to the minimum of a well-defined\nobjective. To that end, we provide a structural lemma that characterizes the\neffect of clipping on the optimization profile of DP-GD.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 20:07:09 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 21:04:41 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Song", "Shuang", ""], ["Steinke", "Thomas", ""], ["Thakkar", "Om", ""], ["Thakurta", "Abhradeep", ""]]}, {"id": "2006.06806", "submitter": "Benjamin Tan", "authors": "Benjamin Tan, Ramesh Karri, Nimisha Limaye, Abhrajit Sengupta, Ozgur\n  Sinanoglu, Md Moshiur Rahman, Swarup Bhunia, Danielle Duvalsaint, R.D.\n  (Shawn) Blanton, Amin Rezaei, Yuanqi Shen, Hai Zhou, Leon Li, Alex Orailoglu,\n  Zhaokun Han, Austin Benedetti, Luciano Brignone, Muhammad Yasin, Jeyavijayan\n  Rajendran, Michael Zuzak, Ankur Srivastava, Ujjwal Guin, Chandan Karfa, Kanad\n  Basu, Vivek V. Menon, Matthew French, Peilin Song, Franco Stellari, Gi-Joon\n  Nam, Peter Gadfort, Alric Althoff, Joseph Tostenrude, Saverio Fazzari, Eric\n  Breckenfeld, Kenneth Plaks", "title": "Benchmarking at the Frontier of Hardware Security: Lessons from Logic\n  Locking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrated circuits (ICs) are the foundation of all computing systems. They\ncomprise high-value hardware intellectual property (IP) that are at risk of\npiracy, reverse-engineering, and modifications while making their way through\nthe geographically-distributed IC supply chain. On the frontier of hardware\nsecurity are various design-for-trust techniques that claim to protect designs\nfrom untrusted entities across the design flow. Logic locking is one technique\nthat promises protection from the gamut of threats in IC manufacturing. In this\nwork, we perform a critical review of logic locking techniques in the\nliterature, and expose several shortcomings. Taking inspiration from other\ncybersecurity competitions, we devise a community-led benchmarking exercise to\naddress the evaluation deficiencies. In reflecting on this process, we shed new\nlight on deficiencies in evaluation of logic locking and reveal important\nfuture directions. The lessons learned can guide future endeavors in other\nareas of hardware security.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 20:45:49 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Tan", "Benjamin", "", "Shawn"], ["Karri", "Ramesh", "", "Shawn"], ["Limaye", "Nimisha", "", "Shawn"], ["Sengupta", "Abhrajit", "", "Shawn"], ["Sinanoglu", "Ozgur", "", "Shawn"], ["Rahman", "Md Moshiur", "", "Shawn"], ["Bhunia", "Swarup", "", "Shawn"], ["Duvalsaint", "Danielle", "", "Shawn"], ["D.", "R.", "", "Shawn"], ["Blanton", "", ""], ["Rezaei", "Amin", ""], ["Shen", "Yuanqi", ""], ["Zhou", "Hai", ""], ["Li", "Leon", ""], ["Orailoglu", "Alex", ""], ["Han", "Zhaokun", ""], ["Benedetti", "Austin", ""], ["Brignone", "Luciano", ""], ["Yasin", "Muhammad", ""], ["Rajendran", "Jeyavijayan", ""], ["Zuzak", "Michael", ""], ["Srivastava", "Ankur", ""], ["Guin", "Ujjwal", ""], ["Karfa", "Chandan", ""], ["Basu", "Kanad", ""], ["Menon", "Vivek V.", ""], ["French", "Matthew", ""], ["Song", "Peilin", ""], ["Stellari", "Franco", ""], ["Nam", "Gi-Joon", ""], ["Gadfort", "Peter", ""], ["Althoff", "Alric", ""], ["Tostenrude", "Joseph", ""], ["Fazzari", "Saverio", ""], ["Breckenfeld", "Eric", ""], ["Plaks", "Kenneth", ""]]}, {"id": "2006.06815", "submitter": "Jayati Dev", "authors": "Jayati Dev", "title": "Discussing Privacy and Surveillance on Twitter: A Case Study of COVID-19", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.14162.38083", "report-no": null, "categories": "cs.CY cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technology is uniquely positioned to help us analyze large amounts of\ninformation to provide valuable insight during widespread public health\nconcerns, like the ongoing COVID-19 pandemic. In fact, information technology\ncompanies like Apple and Google have recently launched tools for contact\ntracing-the ability to process location data to determine the people who have\nbeen in contact with a possible patient, in order to contain the spread of the\nvirus. While China and Singapore have successfully led the effort, more and\nmore countries are now implementing such surveillance systems, raising\npotential privacy concerns about this long term surveillance. For example, it\nis not clear what happens to the information post-pandemic because people are\nmore likely to share their information during a global crisis without\ngovernments having to elaborate on their data policies. Digital Ethnography on\nTwitter, which has over 330 million users worldwide, with a majority in the\nUnited States where the pandemic has the worst effects provides a unique\nopportunity to learn about real-time opinions of the general public about\ncurrent affairs in a rather naturalistic setting. Consequently, it might be\nuseful to highlight the privacy concerns of users, should they exist, through\nanalysis of Twitter data and information sharing policies during unprecedented\npublic health outbreaks. This will allow governments to protect their citizens\nboth during and after health emergencies.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 20:56:55 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Dev", "Jayati", ""]]}, {"id": "2006.06841", "submitter": "Goutham Ramakrishnan", "authors": "Goutham Ramakrishnan, Aws Albarghouthi", "title": "Backdoors in Neural Models of Source Code", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to a range of adversaries. A particularly\npernicious class of vulnerabilities are backdoors, where model predictions\ndiverge in the presence of subtle triggers in inputs. An attacker can implant a\nbackdoor by poisoning the training data to yield a desired target prediction on\ntriggered inputs. We study backdoors in the context of deep-learning for source\ncode. (1) We define a range of backdoor classes for source-code tasks and show\nhow to poison a dataset to install such backdoors. (2) We adapt and improve\nrecent algorithms from robust statistics for our setting, showing that\nbackdoors leave a spectral signature in the learned representation of source\ncode, thus enabling detection of poisoned data. (3) We conduct a thorough\nevaluation on different architectures and languages, showing the ease of\ninjecting backdoors and our ability to eliminate them.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 21:35:24 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Ramakrishnan", "Goutham", ""], ["Albarghouthi", "Aws", ""]]}, {"id": "2006.06895", "submitter": "Sekhar Rajendran", "authors": "Sekhar Rajendran, Zhi Sun, Feng Lin and Kui Ren", "title": "Injecting Reliable Radio Frequency Fingerprints Using Metasurface for\n  The Internet of Things", "comments": "Keywords: Physical layer Security with Reconfigurable Intelligent\n  Surface, Intelligent Reflective Surface, RF-Fingerprint, IoT security,\n  Internet of things, Channel Robust; 13 pages, 11 figures, This paper is\n  submitted to IEEE TIFS", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Internet of Things, where billions of devices with limited resources are\ncommunicating with each other, security has become a major stumbling block\naffecting the progress of this technology. Existing authentication\nschemes-based on digital signatures have overhead costs associated with them in\nterms of computation time, battery power, bandwidth, memory, and related\nhardware costs. Radio frequency fingerprint (RFF), utilizing the unique\ndevice-based information, can be a promising solution for IoT. However,\ntraditional RFFs have become obsolete because of low reliability and reduced\nuser capability. Our proposed solution, Metasurface RF-Fingerprinting Injection\n(MeRFFI), is to inject a carefully-designed radio frequency fingerprint into\nthe wireless physical layer that can increase the security of a stationary IoT\ndevice with minimal overhead. The injection of fingerprint is implemented using\na low cost metasurface developed and fabricated in our lab, which is designed\nto make small but detectable perturbations in the specific frequency band in\nwhich the IoT devices are communicating. We have conducted comprehensive system\nevaluations including distance, orientation, multiple channels where the\nfeasibility, effectiveness, and reliability of these fingerprints are\nvalidated. The proposed MeRFFI system can be easily integrated into the\nexisting authentication schemes. The security vulnerabilities are analyzed for\nsome of the most threatening wireless physical layer-based attacks.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 01:02:33 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 12:57:51 GMT"}, {"version": "v3", "created": "Sat, 5 Dec 2020 21:39:09 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Rajendran", "Sekhar", ""], ["Sun", "Zhi", ""], ["Lin", "Feng", ""], ["Ren", "Kui", ""]]}, {"id": "2006.06933", "submitter": "Victor Rivera", "authors": "Victor Rivera", "title": "Formal Verification of Access Control Model for My Health Record System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  My Health Record system is the Australian Government's digital health record\nsystem that holds My Health Record. My Health Record is a secure online health\nrecord containing consumers' health information. The system aims to provide\nhealth care professionals with access to key health information, e.g. listing\nmedicines, allergies and key diagnoses; radiology and pathology test results.\nThe system (previously named Personally Controlled Electronic Health Record)\nenables consumers to decide how to share information with any of their health\ncare providers who are registered and connected to the system. The My Health\nRecord system operates under the Australian legislative framework My Health\nRecords Act 2012. The Act establishes, inter alia, a privacy framework\nspecifying which entities can collect, use and disclose certain information in\nthe system and the penalties that can be imposed on improper collection, use\nand disclosure of this information. This paper presents the formal\nspecification (from the legislation) and verification of the My Health Record\nregarding how consumers can control who access the information, and how the\nsystem adheres to such access. We rely on the correct-by-construction Event-B\nmethod to prove control and access properties of the system.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 03:47:59 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Rivera", "Victor", ""]]}, {"id": "2006.06993", "submitter": "Shailja Thakur", "authors": "Shailja Thakur, Carlos Moreno, Sebastian Fischmeister", "title": "CANOA: CAN Origin Authentication Through Power Side-Channel Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of any sender authentication mechanism in place makes CAN\n(Controller Area Network) vulnerable to security threats. For instance, an\nattacker can impersonate an ECU (Electronic Control Unit) on the bus and send\nspoofed messages unobtrusively with the identifier of the impersonated ECU. To\naddress this problem, we propose a novel sender authentication technique that\nuses power consumption measurements of the ECU to authenticate the sender of a\nmessage. When an ECU is transmitting, its power requirement is affected, and a\ncharacteristic pattern appears in its power consumption. Our technique exploits\nthe power consumption of each ECU during the transmission of a message to\ndetermine whether the message actually originated from the purported sender. We\nevaluate our approach in both a lab setup and a real vehicle. We also evaluate\nour approach against factors that can impact the power consumption measurement\nof the ECU. The results of the evaluation show that the proposed technique is\napplicable in a broad range of operating conditions with reasonable\ncomputational power requirements and attaining good accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 08:14:05 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Thakur", "Shailja", ""], ["Moreno", "Carlos", ""], ["Fischmeister", "Sebastian", ""]]}, {"id": "2006.07026", "submitter": "Chien-Lun Chen", "authors": "Chien-Lun Chen, Leana Golubchik, Marco Paolieri", "title": "Backdoor Attacks on Federated Meta-Learning", "comments": "13 pages, 19 figures, NeurIPS Workshop on Scalability, Privacy, and\n  Security in Federated Learning (NeurIPS-SpicyFL), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning allows multiple users to collaboratively train a shared\nclassification model while preserving data privacy. This approach, where model\nupdates are aggregated by a central server, was shown to be vulnerable to\npoisoning backdoor attacks: a malicious user can alter the shared model to\narbitrarily classify specific inputs from a given class. In this paper, we\nanalyze the effects of backdoor attacks on federated meta-learning, where users\ntrain a model that can be adapted to different sets of output classes using\nonly a few examples. While the ability to adapt could, in principle, make\nfederated learning frameworks more robust to backdoor attacks (when new\ntraining examples are benign), we find that even 1-shot~attacks can be very\nsuccessful and persist after additional training. To address these\nvulnerabilities, we propose a defense mechanism inspired by matching networks,\nwhere the class of an input is predicted from the similarity of its features\nwith a support set of labeled examples. By removing the decision logic from the\nmodel shared with the federation, success and persistence of backdoor attacks\nare greatly reduced.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 09:23:24 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 16:15:58 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Chen", "Chien-Lun", ""], ["Golubchik", "Leana", ""], ["Paolieri", "Marco", ""]]}, {"id": "2006.07134", "submitter": "Antti Koskela", "authors": "Antti Koskela, Joonas J\\\"alk\\\"o, Lukas Prediger and Antti Honkela", "title": "Tight Differential Privacy for Discrete-Valued Mechanisms and for the\n  Subsampled Gaussian Mechanism Using FFT", "comments": "41 pages, 5 figures", "journal-ref": "AISTATS (2021) 3358-3366", "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a numerical accountant for evaluating the tight\n$(\\varepsilon,\\delta)$-privacy loss for algorithms with discrete one\ndimensional output. The method is based on the privacy loss distribution\nformalism and it uses the recently introduced fast Fourier transform based\naccounting technique. We carry out an error analysis of the method in terms of\nmoment bounds of the privacy loss distribution which leads to rigorous lower\nand upper bounds for the true $(\\varepsilon,\\delta)$-values. As an application,\nwe present a novel approach to accurate privacy accounting of the subsampled\nGaussian mechanism. This completes the previously proposed analysis by giving\nstrict lower and upper bounds for the privacy parameters. We demonstrate the\nperformance of the accountant on the binomial mechanism and show that our\napproach allows decreasing noise variance up to 75 percent at equal privacy\ncompared to existing bounds in the literature. We also illustrate how to\ncompute tight bounds for the exponential mechanism applied to counting queries.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 12:46:42 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 09:54:50 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 11:49:45 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Koskela", "Antti", ""], ["J\u00e4lk\u00f6", "Joonas", ""], ["Prediger", "Lukas", ""], ["Honkela", "Antti", ""]]}, {"id": "2006.07218", "submitter": "Aur\\'elien Bellet", "authors": "C\\'esar Sabater, Aur\\'elien Bellet, Jan Ramon", "title": "Distributed Differentially Private Averaging with Improved Utility and\n  Robustness to Malicious Parties", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from data owned by several parties, as in federated learning, raises\nchallenges regarding the privacy guarantees provided to participants and the\ncorrectness of the computation in the presence of malicious parties. We tackle\nthese challenges in the context of distributed averaging, an essential building\nblock of distributed and federated learning. Our first contribution is a novel\ndistributed differentially private protocol which naturally scales with the\nnumber of parties. The key idea underlying our protocol is to exchange\ncorrelated Gaussian noise along the edges of a network graph, complemented by\nindependent noise added by each party. We analyze the differential privacy\nguarantees of our protocol and the impact of the graph topology, showing that\nwe can match the accuracy of the trusted curator model even when each party\ncommunicates with only a logarithmic number of other parties chosen at random.\nThis is in contrast with protocols in the local model of privacy (with lower\naccuracy) or based on secure aggregation (where all pairs of users need to\nexchange messages). Our second contribution is to enable users to prove the\ncorrectness of their computations without compromising the efficiency and\nprivacy guarantees of the protocol. Our construction relies on standard\ncryptographic primitives like commitment schemes and zero knowledge proofs.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 14:21:10 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Sabater", "C\u00e9sar", ""], ["Bellet", "Aur\u00e9lien", ""], ["Ramon", "Jan", ""]]}, {"id": "2006.07267", "submitter": "Wanrong Zhang", "authors": "Wanrong Zhang, Shruti Tople, Olga Ohrimenko", "title": "Leakage of Dataset Properties in Multi-Party Machine Learning", "comments": "Published in USENIX Security Symposium, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure multi-party machine learning allows several parties to build a model\non their pooled data to increase utility while not explicitly sharing data with\neach other. We show that such multi-party computation can cause leakage of\nglobal dataset properties between the parties even when parties obtain only\nblack-box access to the final model. In particular, a ``curious'' party can\ninfer the distribution of sensitive attributes in other parties' data with high\naccuracy. This raises concerns regarding the confidentiality of properties\npertaining to the whole dataset as opposed to individual data records. We show\nthat our attack can leak population-level properties in datasets of different\ntypes, including tabular, text, and graph data. To understand and measure the\nsource of leakage, we consider several models of correlation between a\nsensitive attribute and the rest of the data. Using multiple machine learning\nmodels, we show that leakage occurs even if the sensitive attribute is not\nincluded in the training data and has a low correlation with other attributes\nor the target variable.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 15:29:03 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 17:40:32 GMT"}, {"version": "v3", "created": "Thu, 17 Jun 2021 22:00:51 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Zhang", "Wanrong", ""], ["Tople", "Shruti", ""], ["Ohrimenko", "Olga", ""]]}, {"id": "2006.07272", "submitter": "Georgios Damaskinos", "authors": "Georgios Damaskinos, Celestine Mendler-D\\\"unner, Rachid Guerraoui,\n  Nikolaos Papandreou, Thomas Parnell", "title": "Differentially Private Stochastic Coordinate Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we tackle the challenge of making the stochastic coordinate\ndescent algorithm differentially private. Compared to the classical gradient\ndescent algorithm where updates operate on a single model vector and controlled\nnoise addition to this vector suffices to hide critical information about\nindividuals, stochastic coordinate descent crucially relies on keeping\nauxiliary information in memory during training. This auxiliary information\nprovides an additional privacy leak and poses the major challenge addressed in\nthis work. Driven by the insight that under independent noise addition, the\nconsistency of the auxiliary information holds in expectation, we present\nDP-SCD, the first differentially private stochastic coordinate descent\nalgorithm. We analyze our new method theoretically and argue that decoupling\nand parallelizing coordinate updates is essential for its utility. On the\nempirical side we demonstrate competitive performance against the popular\nstochastic gradient descent alternative (DP-SGD) while requiring significantly\nless tuning.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 15:40:46 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 09:23:19 GMT"}, {"version": "v3", "created": "Mon, 7 Dec 2020 16:51:49 GMT"}, {"version": "v4", "created": "Sun, 14 Mar 2021 11:36:13 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Damaskinos", "Georgios", ""], ["Mendler-D\u00fcnner", "Celestine", ""], ["Guerraoui", "Rachid", ""], ["Papandreou", "Nikolaos", ""], ["Parnell", "Thomas", ""]]}, {"id": "2006.07345", "submitter": "Kashif Inayat", "authors": "Shahbano, Muhammad Abdullah and Kashif Inayat", "title": "Robust Baggage Detection and Classification Based on Local\n  Tri-directional Pattern", "comments": null, "journal-ref": "International Journal of Internet Technology and Secured\n  Transactions (2021)", "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent decades, the automatic video surveillance system has gained\nsignificant importance in computer vision community. The crucial objective of\nsurveillance is monitoring and security in public places. In the traditional\nLocal Binary Pattern, the feature description is somehow inaccurate, and the\nfeature size is large enough. Therefore, to overcome these shortcomings, our\nresearch proposed a detection algorithm for a human with or without carrying\nbaggage. The Local tri-directional pattern descriptor is exhibited to extract\nfeatures of different human body parts including head, trunk, and limbs. Then\nwith the help of support vector machine, extracted features are trained and\nevaluated. Experimental results on INRIA and MSMT17 V1 datasets show that\nLtriDP outperforms several state-of-the-art feature descriptors and validate\nits effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 17:33:21 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 13:41:09 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 04:14:21 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Shahbano", "", ""], ["Abdullah", "Muhammad", ""], ["Inayat", "Kashif", ""]]}, {"id": "2006.07350", "submitter": "Kashif Inayat", "authors": "Usama Khalid, Muhammad Abdullah and Kashif Inayat", "title": "Exploiting ML algorithms for Efficient Detection and Prevention of\n  JavaScript-XSS Attacks in Android Based Hybrid Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development and analysis of mobile applications in term of security have\nbecome an active research area from many years as many apps are vulnerable to\ndifferent attacks. Especially the concept of hybrid applications has emerged in\nthe last three years where applications are developed in both native and web\nlanguages because the use of web languages raises certain security risks in\nhybrid mobile applications as it creates possible channels where malicious code\ncan be injected inside the application. WebView is an important component in\nhybrid mobile applications which used to implements a sandbox mechanism to\nprotect the local resources of smartphone devices from un-authorized access of\nJavaScript. However, the WebView application program interfaces (APIs) also\nhave security issues. For example, an attacker can attack the hybrid\napplication via JavaScript code by bypassing the sandbox security through\naccessing the public methods of the applications. Cross-site scripting (XSS) is\none of the most popular malicious code injection technique for accessing the\npublic methods of the application through JavaScript. This research proposes a\nframework for detection and prevention of XSS attacks in hybrid applications\nusing state-of-the-art machine learning (ML) algorithms. The detection of the\nattacks have been perform by exploiting the registered Java object features.\nThe dataset and the sample hybrid applications have been developed using the\nandroid studio. Then the widely used toolkit, RapidMiner, has been used for\nempirical analysis. The results reveal that the ensemble based Random Forest\nalgorithm outperforms other algorithms and achieves both the accuracy and\nF-measures as high as of 99%.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 17:39:26 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 06:37:37 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Khalid", "Usama", ""], ["Abdullah", "Muhammad", ""], ["Inayat", "Kashif", ""]]}, {"id": "2006.07421", "submitter": "Chaofei Yang", "authors": "Chaofei Yang, Lei Ding, Yiran Chen, Hai Li", "title": "Defending against GAN-based Deepfake Attacks via Transformation-aware\n  Adversarial Faces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deepfake represents a category of face-swapping attacks that leverage machine\nlearning models such as autoencoders or generative adversarial networks.\nAlthough the concept of the face-swapping is not new, its recent technical\nadvances make fake content (e.g., images, videos) more realistic and\nimperceptible to Humans. Various detection techniques for Deepfake attacks have\nbeen explored. These methods, however, are passive measures against Deepfakes\nas they are mitigation strategies after the high-quality fake content is\ngenerated. More importantly, we would like to think ahead of the attackers with\nrobust defenses. This work aims to take an offensive measure to impede the\ngeneration of high-quality fake images or videos. Specifically, we propose to\nuse novel transformation-aware adversarially perturbed faces as a defense\nagainst GAN-based Deepfake attacks. Different from the naive adversarial faces,\nour proposed approach leverages differentiable random image transformations\nduring the generation. We also propose to use an ensemble-based approach to\nenhance the defense robustness against GAN-based Deepfake variants under the\nblack-box setting. We show that training a Deepfake model with adversarial\nfaces can lead to a significant degradation in the quality of synthesized\nfaces. This degradation is twofold. On the one hand, the quality of the\nsynthesized faces is reduced with more visual artifacts such that the\nsynthesized faces are more obviously fake or less convincing to human\nobservers. On the other hand, the synthesized faces can easily be detected\nbased on various metrics.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 18:51:57 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Yang", "Chaofei", ""], ["Ding", "Lei", ""], ["Chen", "Yiran", ""], ["Li", "Hai", ""]]}, {"id": "2006.07489", "submitter": "Leonidas Spinoulas", "authors": "Leonidas Spinoulas, Mohamed Hussein, David Geissb\\\"uhler, Joe Mathai,\n  Oswin G.Almeida, Guillaume Clivaz, S\\'ebastien Marcel, and Wael AbdAlmageed", "title": "Multispectral Biometrics System Framework: Application to Presentation\n  Attack Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a general framework for building a biometrics system\ncapable of capturing multispectral data from a series of sensors synchronized\nwith active illumination sources. The framework unifies the system design for\ndifferent biometric modalities and its realization on face, finger and iris\ndata is described in detail. To the best of our knowledge, the presented design\nis the first to employ such a diverse set of electromagnetic spectrum bands,\nranging from visible to long-wave-infrared wavelengths, and is capable of\nacquiring large volumes of data in seconds. Having performed a series of data\ncollections, we run a comprehensive analysis on the captured data using a\ndeep-learning classifier for presentation attack detection. Our study follows a\ndata-centric approach attempting to highlight the strengths and weaknesses of\neach spectral band at distinguishing live from fake samples.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 22:09:35 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Spinoulas", "Leonidas", ""], ["Hussein", "Mohamed", ""], ["Geissb\u00fchler", "David", ""], ["Mathai", "Joe", ""], ["Almeida", "Oswin G.", ""], ["Clivaz", "Guillaume", ""], ["Marcel", "S\u00e9bastien", ""], ["AbdAlmageed", "Wael", ""]]}, {"id": "2006.07498", "submitter": "Leonidas Spinoulas", "authors": "Leonidas Spinoulas, Hengameh Mirzaalian, Mohamed Hussein, and Wael\n  AbdAlmageed", "title": "Multi-Modal Fingerprint Presentation Attack Detection: Evaluation On A\n  New Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fingerprint presentation attack detection is becoming an increasingly\nchallenging problem due to the continuous advancement of attack preparation\ntechniques, which generate realistic-looking fake fingerprint presentations. In\nthis work, rather than relying on legacy fingerprint images, which are widely\nused in the community, we study the usefulness of multiple recently introduced\nsensing modalities. Our study covers front-illumination imaging using\nshort-wave-infrared, near-infrared, and laser illumination; and\nback-illumination imaging using near-infrared light. Toward studying the\neffectiveness of each of these unconventional sensing modalities and their\nfusion for liveness detection, we conducted a comprehensive analysis using a\nfully convolutional deep neural network framework. Our evaluation compares\ndifferent combination of the new sensing modalities to legacy data from one of\nour collections as well as the public LivDet2015 dataset, showing the\nsuperiority of the new sensing modalities in most cases. It also covers the\ncases of known and unknown attacks and the cases of intra-dataset and\ninter-dataset evaluations. Our results indicate that the power of our approach\nstems from the nature of the captured data rather than the employed\nclassification framework, which justifies the extra cost for hardware-based (or\nhybrid) solutions. We plan to publicly release one of our dataset collections.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 22:38:23 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 08:09:44 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Spinoulas", "Leonidas", ""], ["Mirzaalian", "Hengameh", ""], ["Hussein", "Mohamed", ""], ["AbdAlmageed", "Wael", ""]]}, {"id": "2006.07533", "submitter": "Yihao Huang", "authors": "Yihao Huang, Felix Juefei-Xu, Run Wang, Qing Guo, Lei Ma, Xiaofei Xie,\n  Jianwen Li, Weikai Miao, Yang Liu, Geguang Pu", "title": "FakePolisher: Making DeepFakes More Detection-Evasive by Shallow\n  Reconstruction", "comments": "9 pages, accepted by ACM MM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At this moment, GAN-based image generation methods are still imperfect, whose\nupsampling design has limitations in leaving some certain artifact patterns in\nthe synthesized image. Such artifact patterns can be easily exploited (by\nrecent methods) for difference detection of real and GAN-synthesized images.\nHowever, the existing detection methods put much emphasis on the artifact\npatterns, which can become futile if such artifact patterns were reduced.\nTowards reducing the artifacts in the synthesized images, in this paper, we\ndevise a simple yet powerful approach termed FakePolisher that performs shallow\nreconstruction of fake images through a learned linear dictionary, intending to\neffectively and efficiently reduce the artifacts introduced during image\nsynthesis. The comprehensive evaluation on 3 state-of-the-art DeepFake\ndetection methods and fake images generated by 16 popular GAN-based fake image\ngeneration techniques, demonstrates the effectiveness of our technique.Overall,\nthrough reducing artifact patterns, our technique significantly reduces the\naccuracy of the 3 state-of-the-art fake image detection methods, i.e., 47% on\naverage and up to 93% in the worst case.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 01:48:15 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 12:10:08 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 07:27:28 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Huang", "Yihao", ""], ["Juefei-Xu", "Felix", ""], ["Wang", "Run", ""], ["Guo", "Qing", ""], ["Ma", "Lei", ""], ["Xie", "Xiaofei", ""], ["Li", "Jianwen", ""], ["Miao", "Weikai", ""], ["Liu", "Yang", ""], ["Pu", "Geguang", ""]]}, {"id": "2006.07676", "submitter": "Yingyuan Yang", "authors": "Yingyuan Yang, Xueli Huang, Jiangnan Li, and Jinyuan Sun", "title": "EchoIA: Implicit Authentication System Based on User Feedback", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit authentication (IA) transparently authenticates users by utilizing\ntheir behavioral data sampled from various sensors. Identifying the\nillegitimate user through constantly analyzing current users' behavior, IA adds\nanother layer of protection to the smart device. Due to the diversity of human\nbehavior, the existing research works tend to simultaneously utilize many\ndifferent features to identify users, which is less efficient. Irrelevant\nfeatures may increase system delay and reduce the authentication accuracy.\nHowever, dynamically choosing the best suitable features for each user\n(personal features) requires a massive calculation, especially in the real\nenvironment. In this paper, we proposed EchoIA to find personal features with a\nsmall amount of calculation by utilizing user feedback. In the authentication\nphase, our approach maintains the transparency, which is the major advantage of\nIA. In the past two years, we conducted a comprehensive experiment to evaluate\nEchoIA. We compared it with other state-of-the-art IA schemes in the aspect of\nauthentication accuracy and efficiency. The experiment results show that EchoIA\nhas better authentication accuracy (93\\%) and less energy consumption (23-hour\nbattery lifetimes) than other IA schemes.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 16:33:44 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 03:52:15 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Yang", "Yingyuan", ""], ["Huang", "Xueli", ""], ["Li", "Jiangnan", ""], ["Sun", "Jinyuan", ""]]}, {"id": "2006.07697", "submitter": "Subhash Lakshminarayana", "authors": "Subhash Lakshminarayana, E. Veronica Belmega, and H. Vincent Poor", "title": "Moving-Target Defense Against Cyber-Physical Attacks in Power Grids via\n  Game Theory", "comments": "arXiv admin note: substantial text overlap with arXiv:1908.02392", "journal-ref": "IEEE Transactions on Smart Grid 2021", "doi": null, "report-no": null, "categories": "cs.CR cs.IT cs.SY eess.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a moving target defense (MTD) strategy to detect\ncoordinated cyber-physical attacks (CCPAs) against power grids. The main idea\nof the proposed approach is to invalidate the knowledge that the attackers use\nto mask the effects of their physical attack by actively perturbing the grid's\ntransmission line reactances via distributed flexible AC transmission system\n(D-FACTS) devices. The proposed MTD design consists of two parts. First, we\nidentify the subset of links for D-FACTS device deployment that enables the\ndefender to detect CCPAs against any link in the system. Then, in order to\nminimize the defense cost during the system's operational time, we formulate a\nzero-sum game to identify the best subset of links to perturb (which will\nprovide adequate protection) against a strategic attacker. The Nash equilibrium\nrobust solution is computed via exponential weights, which does not require\ncomplete knowledge of the game but only the observed payoff at each iteration.\nExtensive simulations performed using the MATPOWER simulator on IEEE bus\nsystems verify the effectiveness of our approach in detecting CCPAs and\nreducing the operator's defense cost.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 18:48:30 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 08:28:35 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Lakshminarayana", "Subhash", ""], ["Belmega", "E. Veronica", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2006.07700", "submitter": "Ihsen Alouani", "authors": "Amira Guesmi, Ihsen Alouani, Khaled Khasawneh, Mouna Baklouti, Tarek\n  Frikha, Mohamed Abid, Nael Abu-Ghazaleh", "title": "Defensive Approximation: Securing CNNs using Approximate Computing", "comments": "ACM International Conference on Architectural Support for Programming\n  Languages and Operating Systems (ASPLOS 2021)", "journal-ref": null, "doi": "10.1145/3445814.3446747", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, an increasing number of machine-learning and deep\nlearning structures, such as Convolutional Neural Networks (CNNs), have been\napplied to solving a wide range of real-life problems. However, these\narchitectures are vulnerable to adversarial attacks. In this paper, we propose\nfor the first time to use hardware-supported approximate computing to improve\nthe robustness of machine learning classifiers. We show that our approximate\ncomputing implementation achieves robustness across a wide range of attack\nscenarios. Specifically, for black-box and grey-box attack scenarios, we show\nthat successful adversarial attacks against the exact classifier have poor\ntransferability to the approximate implementation. Surprisingly, the robustness\nadvantages also apply to white-box attacks where the attacker has access to the\ninternal implementation of the approximate classifier. We explain some of the\npossible reasons for this robustness through analysis of the internal operation\nof the approximate implementation. Furthermore, our approximate computing model\nmaintains the same level in terms of classification accuracy, does not require\nretraining, and reduces resource utilization and energy consumption of the CNN.\nWe conducted extensive experiments on a set of strong adversarial attacks; We\nempirically show that the proposed implementation increases the robustness of a\nLeNet-5 and an Alexnet CNNs by up to 99% and 87%, respectively for strong\ngrey-box adversarial attacks along with up to 67% saving in energy consumption\ndue to the simpler nature of the approximate logic. We also show that a\nwhite-box attack requires a remarkably higher noise budget to fool the\napproximate classifier, causing an average of 4db degradation of the PSNR of\nthe input image relative to the images that succeed in fooling the exact\nclassifier\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 18:58:25 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 20:38:12 GMT"}, {"version": "v3", "created": "Thu, 29 Jul 2021 08:52:10 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Guesmi", "Amira", ""], ["Alouani", "Ihsen", ""], ["Khasawneh", "Khaled", ""], ["Baklouti", "Mouna", ""], ["Frikha", "Tarek", ""], ["Abid", "Mohamed", ""], ["Abu-Ghazaleh", "Nael", ""]]}, {"id": "2006.07709", "submitter": "Jonathan Ullman", "authors": "Matthew Jagielski and Jonathan Ullman and Alina Oprea", "title": "Auditing Differentially Private Machine Learning: How Private is Private\n  SGD?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate whether Differentially Private SGD offers better privacy in\npractice than what is guaranteed by its state-of-the-art analysis. We do so via\nnovel data poisoning attacks, which we show correspond to realistic privacy\nattacks. While previous work (Ma et al., arXiv 2019) proposed this connection\nbetween differential privacy and data poisoning as a defense against data\npoisoning, our use as a tool for understanding the privacy of a specific\nmechanism is new. More generally, our work takes a quantitative, empirical\napproach to understanding the privacy afforded by specific implementations of\ndifferentially private algorithms that we believe has the potential to\ncomplement and influence analytical work on differential privacy.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 20:00:18 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Jagielski", "Matthew", ""], ["Ullman", "Jonathan", ""], ["Oprea", "Alina", ""]]}, {"id": "2006.07757", "submitter": "Fan Yang", "authors": "Hu Ding, Fan Yang, Jiawei Huang", "title": "Defending SVMs against Poisoning Attacks: the Hardness and DBSCAN\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial machine learning has attracted a great amount of attention in\nrecent years. In a poisoning attack, the adversary can inject a small number of\nspecially crafted samples into the training data which make the decision\nboundary severely deviate and cause unexpected misclassification. Due to the\ngreat importance and popular use of support vector machines (SVM), we consider\ndefending SVM against poisoning attacks in this paper. We study two commonly\nused strategies for defending: designing robust SVM algorithms and data\nsanitization. Though several robust SVM algorithms have been proposed before,\nmost of them either are in lack of adversarial-resilience, or rely on strong\nassumptions about the data distribution or the attacker's behavior. Moreover,\nthe research on their complexities is still quite limited. We are the first, to\nthe best of our knowledge, to prove that even the simplest hard-margin\none-class SVM with outliers problem is NP-complete, and has no fully PTAS\nunless P$=$NP (that means it is hard to achieve an even approximate algorithm).\nFor the data sanitization defense, we link it to the intrinsic dimensionality\nof data; in particular, we provide a sampling theorem in doubling metrics for\nexplaining the effectiveness of DBSCAN (as a density-based outlier removal\nmethod) for defending against poisoning attacks. In our empirical experiments,\nwe compare several defenses including the DBSCAN and robust SVM methods, and\ninvestigate the influences from the intrinsic dimensionality and data density\nto their performances.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 01:19:38 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 02:30:47 GMT"}, {"version": "v3", "created": "Thu, 10 Sep 2020 12:46:48 GMT"}, {"version": "v4", "created": "Wed, 16 Sep 2020 06:01:23 GMT"}, {"version": "v5", "created": "Sat, 20 Feb 2021 12:36:59 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Ding", "Hu", ""], ["Yang", "Fan", ""], ["Huang", "Jiawei", ""]]}, {"id": "2006.07817", "submitter": "Shangwei Guo", "authors": "Shangwei Guo, Tianwei Zhang, Tao Xiang, and Yang Liu", "title": "Differentially Private Decentralized Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized learning has received great attention for its high efficiency\nand performance. In such systems, every participant constantly exchanges\nparameters with each other to train a shared model, which can put him at the\nrisk of data privacy leakage. Differential Privacy (DP) has been adopted to\nenhance the Stochastic Gradient Descent (SGD) algorithm. However, these\napproaches mainly focus on single-party learning, or centralized learning in\nthe synchronous mode.\n  In this paper, we design a novel DP-SGD algorithm for decentralized learning\nsystems. The key contribution of our solution is a \\emph{topology-aware}\noptimization strategy, which leverages the unique network characteristics of\ndecentralized systems to effectively reduce the noise scale and improve the\nmodel usability. Besides, we design a novel learning protocol for both\nsynchronous and asynchronous decentralized systems by restricting the\nsensitivity of the SGD algorithm and maximizing the noise reduction. We\nformally analyze and prove the DP requirement of our proposed algorithms.\nExperimental evaluations demonstrate that our algorithm achieves a better\ntrade-off between usability and privacy than prior works.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 06:42:21 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Guo", "Shangwei", ""], ["Zhang", "Tianwei", ""], ["Xiang", "Tao", ""], ["Liu", "Yang", ""]]}, {"id": "2006.07908", "submitter": "Akbar Siami Namin", "authors": "Moitrayee Chatterjee and Prerit Datta and Faranak Abri and Akbar Siami\n  Namin and Keith S. Jones", "title": "Launching Stealth Attacks using Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing offers users scalable platforms and low resource cost. At the\nsame time, the off-site location of the resources of this service model makes\nit more vulnerable to certain types of adversarial actions. Cloud computing has\nnot only gained major user base, but also, it has the features that attackers\ncan leverage to remain anonymous and stealth. With convenient access to data\nand technology, cloud has turned into an attack platform among other\nutilization. This paper reports our study to show that cyber attackers heavily\nabuse the public cloud platforms to setup their attack environments and launch\nstealth attacks. The paper first reviews types of attacks launched through\ncloud environment. It then reports case studies through which the processes of\nlaunching cyber attacks using clouds are demonstrated.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 14:20:13 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Chatterjee", "Moitrayee", ""], ["Datta", "Prerit", ""], ["Abri", "Faranak", ""], ["Namin", "Akbar Siami", ""], ["Jones", "Keith S.", ""]]}, {"id": "2006.07914", "submitter": "Akbar Siami Namin", "authors": "Moitrayee Chatterjee and Prerit Datta and Faranak Abri and Akbar Siami\n  Namin and Keith S. Jones", "title": "Cloud as an Attack Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an exploratory study of responses from $75$ security professionals\nand ethical hackers in order to understand how they abuse cloud platforms for\nattack purposes. The participants were recruited at the Black Hat and DEF CON\nconferences. We presented the participants' with various attack scenarios and\nasked them to explain the steps they would have carried out for launching the\nattack in each scenario. Participants' responses were studied to understand\nattackers' mental models, which would improve our understanding of necessary\nsecurity controls and recommendations regarding precautionary actions to\ncircumvent the exploitation of clouds for malicious activities. We observed\nthat in 93.78% of the responses, participants are abusing cloud services to\nestablish their attack environment and launch attacks.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 14:32:45 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Chatterjee", "Moitrayee", ""], ["Datta", "Prerit", ""], ["Abri", "Faranak", ""], ["Namin", "Akbar Siami", ""], ["Jones", "Keith S.", ""]]}, {"id": "2006.07934", "submitter": "Yuanjiang Cao", "authors": "Yuanjiang Cao, Xiaocong Chen, Lina Yao, Xianzhi Wang and Wei Emma\n  Zhang", "title": "Adversarial Attacks and Detection on Reinforcement Learning-Based\n  Interactive Recommender Systems", "comments": null, "journal-ref": null, "doi": "10.1145/3397271.3401196", "report-no": null, "categories": "cs.LG cs.CR cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks pose significant challenges for detecting adversarial\nattacks at an early stage. We propose attack-agnostic detection on\nreinforcement learning-based interactive recommendation systems. We first craft\nadversarial examples to show their diverse distributions and then augment\nrecommendation systems by detecting potential attacks with a deep\nlearning-based classifier based on the crafted data. Finally, we study the\nattack strength and frequency of adversarial examples and evaluate our model on\nstandard datasets with multiple crafting methods. Our extensive experiments\nshow that most adversarial attacks are effective, and both attack strength and\nattack frequency impact the attack performance. The strategically-timed attack\nachieves comparative attack performance with only 1/3 to 1/2 attack frequency.\nBesides, our black-box detector trained with one crafting method has the\ngeneralization ability over several crafting methods.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 15:41:47 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Cao", "Yuanjiang", ""], ["Chen", "Xiaocong", ""], ["Yao", "Lina", ""], ["Wang", "Xianzhi", ""], ["Zhang", "Wei Emma", ""]]}, {"id": "2006.07942", "submitter": "Linan Huang", "authors": "Linan Huang and Quanyan Zhu", "title": "Duplicity Games for Deception Design with an Application to Insider\n  Threat Mitigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent incidents such as the Colonial Pipeline ransomware attack and the\nSolarWinds hack have shown that traditional defense techniques are becoming\ninsufficient to deter adversaries of growing sophistication. Proactive and\ndeceptive defenses are an emerging class of methods to defend against zero-day\nand advanced attacks. This work develops a new game-theoretic framework called\nthe duplicity game to design deception mechanisms that consist of a generator,\nan incentive modulator, and a trust manipulator, referred to as the GMM\nmechanism. We formulate a mathematical programming problem to compute the\noptimal GMM mechanism, quantify the upper limit of enforceable security\npolicies, and characterize conditions on user's identifiability and\nmanageability for cyber attribution and user management. We develop a\nseparation principle that decouples the design of the modulator from the GMM\nmechanism and an equivalence principle that turns the joint design of the\ngenerator and the manipulator into the single design of the manipulator. A case\nstudy of dynamic honeypot configurations is presented to mitigate insider\nthreats. The numerical experiments corroborate the results that the optimal GMM\nmechanism can elicit desirable actions from both selfish and adversarial\ninsiders and consequently improve the security posture of the insider network.\nIn particular, a proper modulator can reduce the utility misalignment between\nthe players and achieve win-win situations for the selfish insider and the\ndefender. Meanwhile, we observe that the defender always benefits from faking\nthe percentage of honeypots when the optimal generator is presented.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 16:13:43 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 03:14:50 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Huang", "Linan", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2006.07986", "submitter": "Sanghamitra Dutta", "authors": "Sanghamitra Dutta, Praveen Venkatesh, Piotr Mardziel, Anupam Datta,\n  Pulkit Grover", "title": "Fairness Under Feature Exemptions: Counterfactual and Observational\n  Measures", "comments": "Journal version (Shorter version was accepted at AAAI 2020 as an oral\n  presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.CY cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing use of AI in highly consequential domains, the\nquantification and removal of bias with respect to protected attributes, such\nas gender, race, etc., is becoming increasingly important. While quantifying\nbias is essential, sometimes the needs of a business (e.g., hiring) may require\nthe use of certain features that are critical in a way that any bias that can\nbe explained by them might need to be exempted. E.g., a standardized test-score\nmay be a critical feature that should be weighed strongly in hiring even if\nbiased, whereas other features, such as zip code may be used only to the extent\nthat they do not discriminate. In this work, we propose a novel\ninformation-theoretic decomposition of the total bias (in a counterfactual\nsense) into a non-exempt component that quantifies the part of the bias that\ncannot be accounted for by the critical features, and an exempt component which\nquantifies the remaining bias. This decomposition allows one to check if the\nbias arose purely due to the critical features (inspired from the business\nnecessity defense of disparate impact law) and also enables selective removal\nof the non-exempt component if desired. We arrive at this decomposition through\nexamples that lead to a set of desirable properties (axioms) that any measure\nof non-exempt bias should satisfy. We demonstrate that our proposed\ncounterfactual measure satisfies all of them. Our quantification bridges ideas\nof causality, Simpson's paradox, and a body of work from information theory\ncalled Partial Information Decomposition. We also obtain an impossibility\nresult showing that no observational measure of non-exempt bias can satisfy all\nof the desirable properties, which leads us to relax our goals and examine\nobservational measures that satisfy only some of these properties. We then\nperform case studies to show how one can train models while reducing non-exempt\nbias.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 19:14:00 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Dutta", "Sanghamitra", ""], ["Venkatesh", "Praveen", ""], ["Mardziel", "Piotr", ""], ["Datta", "Anupam", ""], ["Grover", "Pulkit", ""]]}, {"id": "2006.08016", "submitter": "Aron Laszka", "authors": "Go Yamamoto, Aron Laszka, Fuhito Kojima", "title": "Equilibrium of Blockchain Miners with Dynamic Asset Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We model and analyze blockchain miners who seek to maximize the compound\nreturn of their mining businesses. The analysis of the optimal strategies finds\na new equilibrium point among the miners and the mining pools, which predicts\nthe market share of each miner or mining pool. The cost of mining determines\nthe share of each miner or mining pool at equilibrium. We conclude that neither\nminers nor mining pools who seek to maximize their compound return will have a\nfinancial incentive to occupy more than 50% of the hash rate if the cost of\nmining is at the same level for all. However, if there is an outstandingly\ncost-efficient miner, then the market share of this miner may exceed 50% in the\nequilibrium, which can threaten the viability of the entire ecosystem.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 20:52:31 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 04:06:36 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Yamamoto", "Go", ""], ["Laszka", "Aron", ""], ["Kojima", "Fuhito", ""]]}, {"id": "2006.08039", "submitter": "Olof Mogren", "authors": "John Martinsson, Edvin Listo Zec, Daniel Gillblad, Olof Mogren", "title": "Adversarial representation learning for synthetic replacement of private\n  attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data privacy is an increasingly important aspect of many real-world Data\nsources that contain sensitive information may have immense potential which\ncould be unlocked using the right privacy enhancing transformations, but\ncurrent methods often fail to produce convincing output. Furthermore, finding\nthe right balance between privacy and utility is often a tricky trade-off. In\nthis work, we propose a novel approach for data privatization, which involves\ntwo steps: in the first step, it removes the sensitive information, and in the\nsecond step, it replaces this information with an independent random sample.\nOur method builds on adversarial representation learning which ensures strong\nprivacy by training the model to fool an increasingly strong adversary. While\nprevious methods only aim at obfuscating the sensitive information, we find\nthat adding new random information in its place strengthens the provided\nprivacy and provides better utility at any given level of privacy. The result\nis an approach that can provide stronger privatization on image data, and yet\nbe preserving both the domain and the utility of the inputs, entirely\nindependent of the downstream task.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 22:07:19 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 22:24:39 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 06:27:57 GMT"}, {"version": "v4", "created": "Mon, 30 Nov 2020 15:00:51 GMT"}, {"version": "v5", "created": "Mon, 8 Feb 2021 13:53:41 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Martinsson", "John", ""], ["Zec", "Edvin Listo", ""], ["Gillblad", "Daniel", ""], ["Mogren", "Olof", ""]]}, {"id": "2006.08060", "submitter": "Sean McKeown", "authors": "Sean McKeown, Gordon Russell", "title": "Forensic Considerations for the High Efficiency Image File Format (HEIF)", "comments": "8 pages, conference paper pre-print", "journal-ref": null, "doi": "10.1109/CyberSecurity49315.2020.9138890", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The High Efficiency File Format (HEIF) was adopted by Apple in 2017 as their\nfavoured means of capturing images from their camera application, with Android\ndevices such as the Galaxy S10 providing support more recently. The format is\npositioned to replace JPEG as the de facto image compression file type, touting\nmany modern features and better compression ratios over the aging standard.\nHowever, while millions of devices across the world are already able to produce\nHEIF files, digital forensics research has not given the format much attention.\nAs HEIF is a complex container format, much different from traditional still\npicture formats, this leaves forensics practitioners exposed to risks of\npotentially mishandling evidence. This paper describes the forensically\nrelevant features of the HEIF format, including those which could be used to\nhide data, or cause issues in an investigation, while also providing commentary\non the state of software support for the format. Finally, suggestions for\ncurrent best-practice are provided, before discussing the requirements of a\nforensically robust HEIF analysis tool.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 00:27:12 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 09:57:03 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["McKeown", "Sean", ""], ["Russell", "Gordon", ""]]}, {"id": "2006.08064", "submitter": "Keval Doshi", "authors": "Keval Doshi, Yasin Yilmaz and Suleyman Uludag", "title": "Timely Detection and Mitigation of Stealthy DDoS Attacks via IoT\n  Networks", "comments": "Submitted to IEEE Transactions on Dependable and Secure Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) networks consist of sensors, actuators, mobile and\nwearable devices that can connect to the Internet. With billions of such\ndevices already in the market which have significant vulnerabilities, there is\na dangerous threat to the Internet services and also some cyber-physical\nsystems that are also connected to the Internet. Specifically, due to their\nexisting vulnerabilities IoT devices are susceptible to being compromised and\nbeing part of a new type of stealthy Distributed Denial of Service (DDoS)\nattack, called Mongolian DDoS, which is characterized by its widely distributed\nnature and small attack size from each source. This study proposes a novel\nanomaly-based Intrusion Detection System (IDS) that is capable of timely\ndetecting and mitigating this emerging type of DDoS attacks. The proposed IDS's\ncapability of detecting and mitigating stealthy DDoS attacks with even very low\nattack size per source is demonstrated through numerical and testbed\nexperiments.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 00:54:49 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Doshi", "Keval", ""], ["Yilmaz", "Yasin", ""], ["Uludag", "Suleyman", ""]]}, {"id": "2006.08131", "submitter": "Ruixiang Tang", "authors": "Ruixiang Tang, Mengnan Du, Ninghao Liu, Fan Yang, Xia Hu", "title": "An Embarrassingly Simple Approach for Trojan Attack in Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread use of deep neural networks (DNNs) in high-stake\napplications, the security problem of the DNN models has received extensive\nattention. In this paper, we investigate a specific security problem called\ntrojan attack, which aims to attack deployed DNN systems relying on the hidden\ntrigger patterns inserted by malicious hackers. We propose a training-free\nattack approach which is different from previous work, in which trojaned\nbehaviors are injected by retraining model on a poisoned dataset. Specifically,\nwe do not change parameters in the original model but insert a tiny trojan\nmodule (TrojanNet) into the target model. The infected model with a malicious\ntrojan can misclassify inputs into a target label when the inputs are stamped\nwith the special triggers. The proposed TrojanNet has several nice properties\nincluding (1) it activates by tiny trigger patterns and keeps silent for other\nsignals, (2) it is model-agnostic and could be injected into most DNNs,\ndramatically expanding its attack scenarios, and (3) the training-free\nmechanism saves massive training efforts comparing to conventional trojan\nattack methods. The experimental results show that TrojanNet can inject the\ntrojan into all labels simultaneously (all-label trojan attack) and achieves\n100% attack success rate without affecting model accuracy on original tasks.\nExperimental analysis further demonstrates that state-of-the-art trojan\ndetection algorithms fail to detect TrojanNet attack. The code is available at\nhttps://github.com/trx14/TrojanNet.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 04:58:28 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 04:27:39 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Tang", "Ruixiang", ""], ["Du", "Mengnan", ""], ["Liu", "Ninghao", ""], ["Yang", "Fan", ""], ["Hu", "Xia", ""]]}, {"id": "2006.08249", "submitter": "Jorge Toro-Pozo", "authors": "David Basin, Ralf Sasse, Jorge Toro-Pozo", "title": "The EMV Standard: Break, Fix, Verify", "comments": "Accepted for IEEE S&P 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  EMV is the international protocol standard for smartcard payment and is used\nin over 9 billion cards worldwide. Despite the standard's advertised security,\nvarious issues have been previously uncovered, deriving from logical flaws that\nare hard to spot in EMV's lengthy and complex specification, running over 2,000\npages. We formalize a comprehensive symbolic model of EMV in Tamarin, a\nstate-of-the-art protocol verifier. Our model is the first that supports a\nfine-grained analysis of all relevant security guarantees that EMV is intended\nto offer. We use our model to automatically identify flaws that lead to two\ncritical attacks: one that defrauds the cardholder and a second that defrauds\nthe merchant. First, criminals can use a victim's Visa contactless card to make\npayments for amounts that require cardholder verification, without knowledge of\nthe card's PIN. We built a proof-of-concept Android application and\nsuccessfully demonstrated this attack on real-world payment terminals. Second,\ncriminals can trick the terminal into accepting an unauthentic offline\ntransaction, which the issuing bank should later decline, after the criminal\nhas walked away with the goods. This attack is possible for implementations\nfollowing the standard, although we did not test it on actual terminals for\nethical reasons. Finally, we propose and verify improvements to the standard\nthat prevent these attacks, as well as any other attacks that violate the\nconsidered security properties. The proposed improvements can be easily\nimplemented in the terminals and do not affect the cards in circulation.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 09:41:25 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 13:21:23 GMT"}, {"version": "v3", "created": "Wed, 17 Feb 2021 14:21:04 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Basin", "David", ""], ["Sasse", "Ralf", ""], ["Toro-Pozo", "Jorge", ""]]}, {"id": "2006.08255", "submitter": "Masoud Hayeri Khyavi", "authors": "Masoud Hayeri Khyavi", "title": "ISMS role in the improvement of digital forensics related process in\n  SOC's", "comments": "8 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organizations concerned about digital or computer forensics capability which\nestablishes procedures and records to support a prosecution for computer crimes\ncould benefit from implementing an ISO 27001: 2013-compliant (ISMS Information\nSecurity Management System). A certified ISMS adds credibility to information\ngathered in a digital forensics investigation; certification shows that the\norganization has an outsider which verifies that the correct procedures are in\nplace and being followed. A certified ISMS is a valuable tool either when\nprosecuting an intruder or when a customer or other stakeholder seeks damages\nagainst the organization. SOC (Security Operation Center) as an organization or\na security unit which handles a large volume of information requires a\nmanagement complement, where ISMS would be a good choice. This idea will help\nfinding solutions for problems related to digital forensics for non-cloud and\ncloud digital forensics, including Problems associated with the absence of\nstandardization amongst different CSPs (Cloud service providers).\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 09:45:32 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Khyavi", "Masoud Hayeri", ""]]}, {"id": "2006.08265", "submitter": "Dingfan Chen", "authors": "Dingfan Chen, Tribhuvanesh Orekondy, Mario Fritz", "title": "GS-WGAN: A Gradient-Sanitized Approach for Learning Differentially\n  Private Generators", "comments": "NeurIPS 2020, 18 pages", "journal-ref": "Advances in Neural Information Processing Systems 33 (NeurIPS\n  2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide-spread availability of rich data has fueled the growth of machine\nlearning applications in numerous domains. However, growth in domains with\nhighly-sensitive data (e.g., medical) is largely hindered as the private nature\nof data prohibits it from being shared. To this end, we propose\nGradient-sanitized Wasserstein Generative Adversarial Networks (GS-WGAN), which\nallows releasing a sanitized form of the sensitive data with rigorous privacy\nguarantees. In contrast to prior work, our approach is able to distort gradient\ninformation more precisely, and thereby enabling training deeper models which\ngenerate more informative samples. Moreover, our formulation naturally allows\nfor training GANs in both centralized and federated (i.e., decentralized) data\nscenarios. Through extensive experiments, we find our approach consistently\noutperforms state-of-the-art approaches across multiple metrics (e.g., sample\nquality) and datasets.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 10:01:01 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 13:54:11 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Chen", "Dingfan", ""], ["Orekondy", "Tribhuvanesh", ""], ["Fritz", "Mario", ""]]}, {"id": "2006.08296", "submitter": "Mahdi Rezaei", "authors": "Zahra Noury and Mahdi Rezaei", "title": "Deep-CAPTCHA: a deep learning based CAPTCHA solver for vulnerability\n  assessment", "comments": "Version 2.0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CAPTCHA is a human-centred test to distinguish a human operator from bots,\nattacking programs, or other computerised agents that tries to imitate human\nintelligence. In this research, we investigate a way to crack visual CAPTCHA\ntests by an automated deep learning based solution. The goal of this research\nis to investigate the weaknesses and vulnerabilities of the CAPTCHA generator\nsystems; hence, developing more robust CAPTCHAs, without taking the risks of\nmanual try and fail efforts. We develop a Convolutional Neural Network called\nDeep-CAPTCHA to achieve this goal. The proposed platform is able to investigate\nboth numerical and alphanumerical CAPTCHAs. To train and develop an efficient\nmodel, we have generated a dataset of 500,000 CAPTCHAs to train our model. In\nthis paper, we present our customised deep neural network model, we review the\nresearch gaps, the existing challenges, and the solutions to cope with the\nissues. Our network's cracking accuracy leads to a high rate of 98.94% and\n98.31% for the numerical and the alpha-numerical test datasets, respectively.\nThat means more works is required to develop robust CAPTCHAs, to be\nnon-crackable against automated artificial agents. As the outcome of this\nresearch, we identify some efficient techniques to improve the security of the\nCAPTCHAs, based on the performance analysis conducted on the Deep-CAPTCHA\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 11:44:43 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 19:55:33 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Noury", "Zahra", ""], ["Rezaei", "Mahdi", ""]]}, {"id": "2006.08339", "submitter": "Zhongliang Yang", "authors": "Zhongliang Yang, Baitao Gong, Yamin Li, Jinshuai Yang, Zhiwen Hu,\n  Yongfeng Huang", "title": "Graph-Stega: Semantic Controllable Steganographic Text Generation Guided\n  by Knowledge Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing text generative steganographic methods are based on\ncoding the conditional probability distribution of each word during the\ngeneration process, and then selecting specific words according to the secret\ninformation, so as to achieve information hiding. Such methods have their\nlimitations which may bring potential security risks. Firstly, with the\nincrease of embedding rate, these models will choose words with lower\nconditional probability, which will reduce the quality of the generated\nsteganographic texts; secondly, they can not control the semantic expression of\nthe final generated steganographic text. This paper proposes a new text\ngenerative steganography method which is quietly different from the existing\nmodels. We use a Knowledge Graph (KG) to guide the generation of steganographic\nsentences. On the one hand, we hide the secret information by coding the path\nin the knowledge graph, but not the conditional probability of each generated\nword; on the other hand, we can control the semantic expression of the\ngenerated steganographic text to a certain extent. The experimental results\nshow that the proposed model can guarantee both the quality of the generated\ntext and its semantic expression, which is a supplement and improvement to the\ncurrent text generation steganography.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 06:53:21 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Yang", "Zhongliang", ""], ["Gong", "Baitao", ""], ["Li", "Yamin", ""], ["Yang", "Jinshuai", ""], ["Hu", "Zhiwen", ""], ["Huang", "Yongfeng", ""]]}, {"id": "2006.08444", "submitter": "Anas AbuDaqa", "authors": "Anas AbuDaqa, Amjad Abu-Hassan, Muhammad Imam", "title": "Taxonomy and Practical Evaluation of Primality Testing Algorithms", "comments": "20 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern cryptography algorithms are commonly used to ensure information\nsecurity. Prime numbers are needed in many asymmetric cryptography algorithms.\nFor example, RSA algorithm selects two large prime numbers and multiplies to\neach other to obtain a large composite number whose factorization is very\ndifficult. Producing a prime number is not an easy task as they are not\ndistributed regularly through integers. Primality testing algorithms are used\nto determine whether a particular number is prime or composite. In this paper,\nan intensive survey is thoroughly conducted among the several primality testing\nalgorithms showing the pros and cons, the time complexity, and a brief summary\nof each algorithm. Besides, an implementation of these algorithms is\naccomplished using Java and Python as programming languages to evaluate the\nefficiency of both the algorithms and the programming languages.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 14:40:50 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["AbuDaqa", "Anas", ""], ["Abu-Hassan", "Amjad", ""], ["Imam", "Muhammad", ""]]}, {"id": "2006.08513", "submitter": "Jona Harris", "authors": "Jona Harris and Aviv Zohar", "title": "Flood & Loot: A Systemic Attack On The Lightning Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lightning Network promises to alleviate Bitcoin's known scalability\nproblems. The operation of such second layer approaches relies on the ability\nof participants to turn to the blockchain to claim funds at any time, which is\nassumed to happen rarely. One of the risks that was identified early on is that\nof a wide systemic attack on the protocol, in which an attacker triggers the\nclosure of many Lightning channels at once. The resulting high volume of\ntransactions in the blockchain will not allow for the proper settlement of all\ndebts, and attackers may get away with stealing some funds. This paper explores\nthe details of such an attack and evaluates its cost and overall impact on\nBitcoin and the Lightning Network. Specifically, we show that an attacker is\nable to simultaneously cause victim nodes to overload the Bitcoin blockchain\nwith requests and to steal funds that were locked in channels. We go on to\nexamine the interaction of Lightning nodes with the fee estimation mechanism\nand show that the attacker can continuously lower the fee of transactions that\nwill later be used by the victim in its attempts to recover funds - eventually\nreaching a state in which only low fractions of the block are available for\nlightning transactions. Our attack is made easier even further as the Lightning\nprotocol allows the attacker to increase the fee offered by his own\ntransactions. We continue to empirically show that the vast majority of nodes\nagree to channel opening requests from unknown sources and are therefore\nsusceptible to this attack. We highlight differences between various\nimplementations of the Lightning Network protocol and review the susceptibility\nof each one to the attack. Finally, we propose mitigation strategies to lower\nthe systemic attack risk of the network.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 16:16:03 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 15:59:57 GMT"}, {"version": "v3", "created": "Mon, 10 Aug 2020 17:01:15 GMT"}, {"version": "v4", "created": "Thu, 27 Aug 2020 15:36:03 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Harris", "Jona", ""], ["Zohar", "Aviv", ""]]}, {"id": "2006.08524", "submitter": "Peter Mell", "authors": "Peter Mell and Assane Gueye", "title": "A Suite of Metrics for Calculating the Most Significant Security\n  Relevant Software Flaw Types", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Common Weakness Enumeration (CWE) is a prominent list of software\nweakness types. This list is used by vulnerability databases to describe the\nunderlying security flaws within analyzed vulnerabilities. This linkage opens\nthe possibility of using the analysis of software vulnerabilities to identify\nthe most significant weaknesses that enable those vulnerabilities. We\naccomplish this through creating mashup views combining CWE weakness taxonomies\nwith vulnerability analysis data. The resulting graphs have CWEs as nodes,\nedges derived from multiple CWE taxonomies, and nodes adorned with\nvulnerability analysis information (propagated from children to parents). Using\nthese graphs, we develop a suite of metrics to identify the most significant\nweakness types (using the perspectives of frequency, impact, exploitability,\nand overall severity).\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 16:34:05 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Mell", "Peter", ""], ["Gueye", "Assane", ""]]}, {"id": "2006.08538", "submitter": "Yan Feng", "authors": "Yan Feng, Baoyuan Wu, Yanbo Fan, Li Liu, Zhifeng Li, Shutao Xia", "title": "Boosting Black-Box Attack with Partially Transferred Conditional\n  Adversarial Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies black-box adversarial attacks against deep neural networks\n(DNNs), where the attacker can only access the query feedback returned by the\nattacked DNN model, while other information such as model parameters or the\ntraining datasets are unknown. One promising approach to improve attack\nperformance is utilizing the adversarial transferability between some white-box\nsurrogate models and the target model (i.e., the attacked model). However, due\nto the possible differences on model architectures and training datasets\nbetween surrogate and target models, dubbed \"surrogate biases\", the\ncontribution of adversarial transferability to improving the attack performance\nmay be weakened. To tackle this issue, we innovatively propose a black-box\nattack method by developing a novel mechanism of adversarial transferability,\nwhich is robust to the surrogate biases. The general idea is transferring\npartial parameters of the conditional adversarial distribution (CAD) of\nsurrogate models, while learning the untransferred parameters based on queries\nto the target model, to keep the flexibility to adjust the CAD of the target\nmodel on any new benign sample. Extensive experiments on benchmark datasets and\nattacking against real-world API demonstrate the superior attack performance of\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 16:45:27 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 02:26:36 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2020 06:28:19 GMT"}, {"version": "v4", "created": "Thu, 18 Mar 2021 08:56:09 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Feng", "Yan", ""], ["Wu", "Baoyuan", ""], ["Fan", "Yanbo", ""], ["Liu", "Li", ""], ["Li", "Zhifeng", ""], ["Xia", "Shutao", ""]]}, {"id": "2006.08568", "submitter": "Ssu-Hsin Yu", "authors": "Ssu-Hsin Yu", "title": "PrivyTRAC: Privacy and Security Preserving Contact Tracing System", "comments": "11 pages, 5 figures; submitted to EmergencyComm 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphone location-based methods have been proposed and implemented as an\neffective alternative to traditional labor intensive contact tracing methods.\nHowever, there are serious privacy and security concerns that may impede\nwide-spread adoption in many societies. Furthermore, these methods rely solely\non proximity to patients, based on Bluetooth or GPS signal for example,\nignoring lingering effects of virus, including COVID-19, present in the\nenvironment. This results in inaccurate risk assessment and incomplete contact\ntracing. A new system concept, called PrivyTRAC, preserves user privacy,\nincreases security and improves accuracy of smartphone contact tracing.\nPrivyTRAC enhances users' and patients' privacy by letting users conduct\nself-evaluation based on the risk maps download to their smartphones. No user\ninformation is transmitted to external locations or devices, and no personally\nidentifiable patient information is embedded in the risk maps as they are\nprocessed anonymized and aggregated locations of confirmed patients. The risk\nmaps consider both spatial proximity and temporal effects to improve the\naccuracy of the infection risk estimation. Experiments conducted in the paper\nillustrate improvement of PrivyTRAC over proximity based methods in terms of\ntrue and false positives. An approach to further improve infection risk\nestimation by incorporating both positive and negative local test results from\ncontacts of confirmed cases is also described.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 17:32:38 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Yu", "Ssu-Hsin", ""]]}, {"id": "2006.08598", "submitter": "Lun Wang", "authors": "Lun Wang and Qi Pang and Dawn Song", "title": "Towards practical differentially private causal graph discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal graph discovery refers to the process of discovering causal relation\ngraphs from purely observational data. Like other statistical data, a causal\ngraph might leak sensitive information about participants in the dataset. In\nthis paper, we present a differentially private causal graph discovery\nalgorithm, Priv-PC, which improves both utility and running time compared to\nthe state-of-the-art. The design of Priv-PC follows a novel paradigm called\nsieve-and-examine which uses a small amount of privacy budget to filter out\n\"insignificant\" queries, and leverages the remaining budget to obtain highly\naccurate answers for the \"significant\" queries. We also conducted the first\nsensitivity analysis for conditional independence tests including conditional\nKendall's tau and conditional Spearman's rho. We evaluated Priv-PC on 4 public\ndatasets and compared with the state-of-the-art. The results show that Priv-PC\nachieves 10.61 to 32.85 times speedup and better utility.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 18:30:41 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Wang", "Lun", ""], ["Pang", "Qi", ""], ["Song", "Dawn", ""]]}, {"id": "2006.08604", "submitter": "Akbar Siami Namin", "authors": "Shuvalaxmi Dass and Akbar Siami Namin", "title": "Vulnerability Coverage for Secure Configuration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel idea on adequacy testing called ``{vulnerability\ncoverage}.'' The introduced coverage measure examines the underlying software\nfor the presence of certain classes of vulnerabilities often found in the\nNational Vulnerability Database (NVD) website. The thoroughness of the test\ninput generation procedure is performed through the adaptation of evolutionary\nalgorithms namely Genetic Algorithms (GA) and Particle Swarm Optimization\n(PSO). The methodology utilizes the Common Vulnerability Scoring System (CVSS),\na free and open industry standard for assessing the severity of computer system\nsecurity vulnerabilities, as a fitness measure for test inputs generation. The\noutcomes of these evolutionary algorithms are then evaluated in order to\nidentify the vulnerabilities that match a class of vulnerability patterns for\ntesting purposes.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 14:47:57 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Dass", "Shuvalaxmi", ""], ["Namin", "Akbar Siami", ""]]}, {"id": "2006.08614", "submitter": "Sahil Suneja", "authors": "Sahil Suneja, Yunhui Zheng, Yufan Zhuang, Jim Laredo, Alessandro\n  Morari", "title": "Learning to map source code to software vulnerability using\n  code-as-a-graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the applicability of Graph Neural Networks in learning the nuances\nof source code from a security perspective. Specifically, whether signatures of\nvulnerabilities in source code can be learned from its graph representation, in\nterms of relationships between nodes and edges. We create a pipeline we call\nAI4VA, which first encodes a sample source code into a Code Property Graph. The\nextracted graph is then vectorized in a manner which preserves its semantic\ninformation. A Gated Graph Neural Network is then trained using several such\ngraphs to automatically extract templates differentiating the graph of a\nvulnerable sample from a healthy one. Our model outperforms static analyzers,\nclassic machine learning, as well as CNN and RNN-based deep learning models on\ntwo of the three datasets we experiment with. We thus show that a code-as-graph\nencoding is more meaningful for vulnerability detection than existing\ncode-as-photo and linear sequence encoding approaches. (Submitted Oct 2019,\nPaper #28, ICST)\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 16:05:27 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Suneja", "Sahil", ""], ["Zheng", "Yunhui", ""], ["Zhuang", "Yufan", ""], ["Laredo", "Jim", ""], ["Morari", "Alessandro", ""]]}, {"id": "2006.08669", "submitter": "Reza Shokri", "authors": "Hongyan Chang, Ta Duy Nguyen, Sasi Kumar Murakonda, Ehsan Kazemi, Reza\n  Shokri", "title": "On Adversarial Bias and the Robustness of Fair Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing prediction accuracy can come at the expense of fairness. Towards\nminimizing discrimination against a group, fair machine learning algorithms\nstrive to equalize the behavior of a model across different groups, by imposing\na fairness constraint on models. However, we show that giving the same\nimportance to groups of different sizes and distributions, to counteract the\neffect of bias in training data, can be in conflict with robustness. We analyze\ndata poisoning attacks against group-based fair machine learning, with the\nfocus on equalized odds. An adversary who can control sampling or labeling for\na fraction of training data, can reduce the test accuracy significantly beyond\nwhat he can achieve on unconstrained models. Adversarial sampling and\nadversarial labeling attacks can also worsen the model's fairness gap on test\ndata, even though the model satisfies the fairness constraint on training data.\nWe analyze the robustness of fair machine learning through an empirical\nevaluation of attacks on multiple algorithms and benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 18:17:44 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Chang", "Hongyan", ""], ["Nguyen", "Ta Duy", ""], ["Murakonda", "Sasi Kumar", ""], ["Kazemi", "Ehsan", ""], ["Shokri", "Reza", ""]]}, {"id": "2006.08723", "submitter": "Prajoy Podder", "authors": "Subrato Bharati, Prajoy Podder, M. Rubaiyat Hossain Mondal, Md. Robiul\n  Alam Robel", "title": "Threats and Countermeasures of Cyber Security in Direct and Remote\n  Vehicle Communication Systems", "comments": "12 pages, 7 figures", "journal-ref": "Journal of Information Assurance and Security (ISSN 1554-1010),\n  Volume 15 (2020), pp. 153-164, MIR Labs, www.mirlabs.net/jias/index.html", "doi": null, "report-no": null, "categories": "cs.CR cs.IT eess.SP math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traffic management, road safety, and environmental impact are important\nissues in the modern world. These challenges are addressed by the application\nof sensing, control and communication methods of intelligent transportation\nsystems (ITS). A part of ITS is a vehicular ad-hoc network (VANET) which means\na wireless network of vehicles. However, communication among vehicles in a\nVANET exposes several security threats which need to be studied and addressed.\nIn this review, firstly, the basic flow of VANET is illustrated focusing on its\ncommunication methods, architecture, characteristics, standards, and security\nfacilities. Next, the attacks and threats for VANET are discussed. Moreover,\nthe authentication systems are described by which vehicular networks can be\nprotected from fake messages and malicious nodes. Security threats and counter\nmeasures are discussed for different remote vehicle communication methods\nnamely, remote keyless entry system, dedicated short range communication,\ncellular scheme, Zigbee, Bluetooth, radio frequency identification, WiFi,\nWiMAX, and different direct vehicle communication methods namely on-board\ndiagnosis and universal serial bus.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 17:30:25 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Bharati", "Subrato", ""], ["Podder", "Prajoy", ""], ["Mondal", "M. Rubaiyat Hossain", ""], ["Robel", "Md. Robiul Alam", ""]]}, {"id": "2006.08733", "submitter": "Zahra Ghodsi", "authors": "Zahra Ghodsi, Akshaj Veldanda, Brandon Reagen, Siddharth Garg", "title": "CryptoNAS: Private Inference on a ReLU Budget", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning as a service has given raise to privacy concerns surrounding\nclients' data and providers' models and has catalyzed research in private\ninference (PI): methods to process inferences without disclosing inputs.\nRecently, researchers have adapted cryptographic techniques to show PI is\npossible, however all solutions increase inference latency beyond practical\nlimits. This paper makes the observation that existing models are ill-suited\nfor PI and proposes a novel NAS method, named CryptoNAS, for finding and\ntailoring models to the needs of PI. The key insight is that in PI operator\nlatency cost are non-linear operations (e.g., ReLU) dominate latency, while\nlinear layers become effectively free. We develop the idea of a ReLU budget as\na proxy for inference latency and use CryptoNAS to build models that maximize\naccuracy within a given budget. CryptoNAS improves accuracy by 3.4% and latency\nby 2.4x over the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 20:06:05 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 16:52:51 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Ghodsi", "Zahra", ""], ["Veldanda", "Akshaj", ""], ["Reagen", "Brandon", ""], ["Garg", "Siddharth", ""]]}, {"id": "2006.08749", "submitter": "Sean McKeown", "authors": "Clemens Krueger, Sean McKeown", "title": "Using Amazon Alexa APIs as a Source of Digital Evidence", "comments": null, "journal-ref": null, "doi": "10.1109/CyberSecurity49315.2020.9138849", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the release of Amazon Alexa and the first Amazon Echo device, the\ncompany revolutionised the smart home. It allowed their users to communicate\nwith, and control, their smart home ecosystem purely using voice commands.\nHowever, this also means that Amazon processes and stores a large amount of\npersonal data about their users, as these devices are always present and always\nlistening in peoples' private homes. That makes this data a valuable source of\nevidence for investigators performing digital forensics. The Alexa Voice\nService uses a series of APIs for communication between clients and the Amazon\ncloud. These APIs return a wide range of data related to the functionality of\nthe device used.\n  The first goal of this research was to clarify exactly what kind of\ninformation about the user is stored and accessible through these APIs. To do\nthis, a combination of literature review and exploratory analysis was used to\nestablish a list of all relevant APIs. Then, possible artefacts and conclusions\nto be drawn from their responses were identified and presented. Lastly, the\nperspective of the users was taken, and options for improving their privacy\nwere reviewed. Specifically, the history of interaction between the user and\nAlexa is available through multiple APIs, and there are several options to\ndelete it. It was determined that these options have different behaviours and\nthat most of them do not remove all data related to user interaction.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 20:40:14 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 10:03:39 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Krueger", "Clemens", ""], ["McKeown", "Sean", ""]]}, {"id": "2006.08811", "submitter": "Charles Gon\\c{c}alves", "authors": "Charles F. Gon\\c{c}alves, Daniel S. Menasch\\'e, Alberto Avritzer, Nuno\n  Antunes, Marco Vieira", "title": "A Model-Based Approach to Anomaly Detection Trading Detection Time and\n  False Alarm Rate", "comments": "2020 Mediterranean Communication and Computer Networking Conference\n  (MedComNet)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity and ubiquity of modern computing systems is a fertile ground\nfor anomalies, including security and privacy breaches. In this paper, we\npropose a new methodology that addresses the practical challenges to implement\nanomaly detection approaches. Specifically, it is challenging to define normal\nbehavior comprehensively and to acquire data on anomalies in diverse cloud\nenvironments. To tackle those challenges, we focus on anomaly detection\napproaches based on system performance signatures. In particular, performance\nsignatures have the potential of detecting zero-day attacks, as those\napproaches are based on detecting performance deviations and do not require\ndetailed knowledge of attack history. The proposed methodology leverages an\nanalytical performance model and experimentation and allows to control the rate\nof false positives in a principled manner. The methodology is evaluated using\nthe TPCx-V workload, which was profiled during a set of executions using\nresource exhaustion anomalies that emulate the effects of anomalies affecting\nsystem performance. The proposed approach was able to successfully detect the\nanomalies, with a low number of false positives (precision 90%-98%).\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 22:49:57 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Gon\u00e7alves", "Charles F.", ""], ["Menasch\u00e9", "Daniel S.", ""], ["Avritzer", "Alberto", ""], ["Antunes", "Nuno", ""], ["Vieira", "Marco", ""]]}, {"id": "2006.08817", "submitter": "Yingyuan Yang", "authors": "Yingyuan Yang, Xueli Huang, Jiangnan Li, and Jinyuan Sun", "title": "BubbleMap: Privilege Mapping for Behavior-based Implicit Authentication\n  Systems", "comments": "12 pages. arXiv admin note: substantial text overlap with\n  arXiv:1808.00638", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit authentication (IA) is gaining popularity over recent years due to\nits use of user behavior as the main input, relieving users from explicit\nactions such as remembering and entering passwords. Various IA schemes have\nbeen proposed based on different behavioral and contextual features such as\ngait, touch, and GPS. However, existing IA schemes suffer from false positives,\ni.e., falsely accepting an adversary, and false negatives, i.e., falsely\nrejecting the legitimate user, more so than the more mature explicit\nauthentication counterpart, due to users' behavior change. To deal with this\nproblem, we propose BubbleMap (BMap), a framework that can be seamlessly\nincorporated into any existing IA system to balance between security (reducing\nfalse positives) and usability (reducing false negatives) as well as improving\nauthentication accuracy. To evaluate the proposed framework, we implemented\nBMap on four state-of-the-art IA systems. We also conducted a comprehensive\nexperiment in a real-world environment spanned two years and eight months. Most\nof the experimental results show that BMap can greatly enhance the IA schemes'\nperformances in terms of authentication accuracy, security and usability, with\na small amount of penalty on energy consumption.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 23:18:24 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Yang", "Yingyuan", ""], ["Huang", "Xueli", ""], ["Li", "Jiangnan", ""], ["Sun", "Jinyuan", ""]]}, {"id": "2006.08839", "submitter": "Ensar Seker", "authors": "Ensar Seker", "title": "Hash Cracking Benchmarking of Replacement Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explain our methodology to identify replacement patterns.\nThe main purpose of this article is to show that with replacement methods on\nplain texts, it is possible to have more success rates when trying to\nrecovering hashed passwords.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 13:26:51 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Seker", "Ensar", ""]]}, {"id": "2006.08915", "submitter": "Liya Xu", "authors": "Liya Xu, Mingzhu Ge, Weili Wu", "title": "Edge computing based incentivizing mechanism for mobile blockchain in\n  IOT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining in the blockchain requires high computing power to solve the hash\npuzzle for example proof-of-work puzzle. It takes high cost to achieve the\ncalculation of this problem in devices of IOT, especially the mobile devices of\nIOT. It consequently restricts the application of blockchain in mobile\nenvironment. However, edge computing can be utilized to solve the problem for\ninsufficient computing power of mobile devices in IOT. Edge servers can recruit\nmany mobile devices to contribute computing power together to mining and share\nthe reward of mining with these recruited mobile devices. In this paper, we\npropose an incentivizing mechanism based on edge computing for mobile\nblockchain. We design a two-stage Stackelberg Game to jointly optimize the\nreward of edge servers and recruited mobile devices. The edge server as the\nleader sets the expected fee for the recruited mobile devices in Stage I. The\nmobile device as a follower provides its computing power to mine according to\nthe expected fee in Stage. It proves that this game can obtain a uniqueness\nNash Equilibrium solution under the same or different expected fee. In the\nsimulation experiment, we obtain a result curve of the profit for the edge\nserver with the different ratio between the computing power from the edge\nserver and mobile devices. In addition, the proposed scheme has been compared\nwith the MDG scheme for the profit of the edge server. The experimental results\nshow that the profit of the proposed scheme is more than that of the MDG scheme\nunder the same total computing power.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 04:14:24 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 14:40:57 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Xu", "Liya", ""], ["Ge", "Mingzhu", ""], ["Wu", "Weili", ""]]}, {"id": "2006.09108", "submitter": "Jinghua Yu", "authors": "Jinghua Yu, Stefan Wagner, Feng Luo", "title": "An STPA-based Approach for Systematic Security Analysis of In-vehicle\n  Diagnostic and Software Update Systems", "comments": "6 pages, 7 figures, submitted to FISITA 2020 World Congress", "journal-ref": null, "doi": null, "report-no": "F2020-VES-020, FISITA Web Congress 2020", "categories": "cs.CR cs.SE cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The in-vehicle diagnostic and software update system, which supports remote\ndiagnostic and Over-The-Air (OTA) software updates, is a critical attack goal\nin automobiles. Adversaries can inject malicious software into vehicles or\nsteal sensitive information through communication channels. Therefore, security\nanalysis, which identifies potential security issues, needs to be conducted in\nsystem design. However, existing security analyses of in-vehicle systems are\nthreat-oriented, which start with threat identification and assess risks by\nbrainstorming. In this paper, a system-oriented approach is proposed on the\nbasis of the System-Theoretic Process Analysis (STPA). The proposed approach\nextends the original STPA from the perspective of data flows and is applicable\nfor information-flow-based systems. Besides, we propose a general model for\nin-vehicle diagnostic and software update systems and use it to establish a\nsecurity analysis guideline. In comparison with threat-oriented approaches, the\nproposed approach shifts from focusing on threats to system vulnerabilities and\nseems to be efficient to prevent the system from known or even unknown threats.\nFurthermore, as an extension of the STPA, which has been proven to be\napplicable to high level designs, the proposed approach can be well integrated\ninto high-level analyses and perform co-design in different disciplines within\na unified STPA framework.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 12:34:17 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Yu", "Jinghua", ""], ["Wagner", "Stefan", ""], ["Luo", "Feng", ""]]}, {"id": "2006.09171", "submitter": "Fu Song", "authors": "Pengfei Gao, Hongyi Xie, Fu Song, Taolue Chen", "title": "A Hybrid Approach to Formal Verification of Higher-Order Masked\n  Arithmetic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Side-channel attacks, which are capable of breaking secrecy via side-channel\ninformation, pose a growing threat to the implementation of cryptographic\nalgorithms. Masking is an effective countermeasure against side-channel attacks\nby removing the statistical dependence between secrecy and power consumption\nvia randomization. However, designing efficient and effective masked\nimplementations turns out to be an error-prone task. Current techniques for\nverifying whether masked programs are secure are limited in their applicability\nand accuracy, especially when they are applied. To bridge this gap, in this\narticle, we first propose a sound type system, equipped with an efficient type\ninference algorithm, for verifying masked arithmetic programs against\nhigher-order attacks. We then give novel model-counting based and\npattern-matching based methods which are able to precisely determine whether\nthe potential leaky observable sets detected by the type system are genuine or\nsimply spurious. We evaluate our approach on various implementations of\narithmetic cryptographicprograms.The experiments confirm that our approach out\nperforms the state-of-the-art base lines in terms of applicability, accuracy\nand efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 14:22:18 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Gao", "Pengfei", ""], ["Xie", "Hongyi", ""], ["Song", "Fu", ""], ["Chen", "Taolue", ""]]}, {"id": "2006.09271", "submitter": "Edward Raff", "authors": "Edward Raff, Charles Nicholas", "title": "A Survey of Machine Learning Methods and Challenges for Windows Malware\n  Classification", "comments": "To appear in NeurIPS 2020 Workshop: ML Retrospectives, Surveys &\n  Meta-Analyses (ML-RSA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware classification is a difficult problem, to which machine learning\nmethods have been applied for decades. Yet progress has often been slow, in\npart due to a number of unique difficulties with the task that occur through\nall stages of the developing a machine learning system: data collection,\nlabeling, feature creation and selection, model selection, and evaluation. In\nthis survey we will review a number of the current methods and challenges\nrelated to malware classification, including data collection, feature\nextraction, and model construction, and evaluation. Our discussion will include\nthoughts on the constraints that must be considered for machine learning based\nsolutions in this domain, and yet to be tackled problems for which machine\nlearning could also provide a solution. This survey aims to be useful both to\ncybersecurity practitioners who wish to learn more about how machine learning\ncan be applied to the malware problem, and to give data scientists the\nnecessary background into the challenges in this uniquely complicated space.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 17:46:12 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 16:35:36 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Raff", "Edward", ""], ["Nicholas", "Charles", ""]]}, {"id": "2006.09272", "submitter": "Abdallah Moubayed", "authors": "Abdallah Moubayed and Emad Aqeeli and Abdallah Shami", "title": "Ensemble-based Feature Selection and Classification Model for DNS\n  Typo-squatting Detection", "comments": "6 pages, 2 figures, 6 tables, Accepted in 2020 IEEE CANADIAN\n  CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (CCECE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain Name System (DNS) plays in important role in the current IP-based\nInternet architecture. This is because it performs the domain name to IP\nresolution. However, the DNS protocol has several security vulnerabilities due\nto the lack of data integrity and origin authentication within it. This paper\nfocuses on one particular security vulnerability, namely typo-squatting.\nTypo-squatting refers to the registration of a domain name that is extremely\nsimilar to that of an existing popular brand with the goal of redirecting users\nto malicious/suspicious websites. The danger of typo-squatting is that it can\nlead to information threat, corporate secret leakage, and can facilitate fraud.\nThis paper builds on our previous work in [1], which only proposed\nmajority-voting based classifier, by proposing an ensemble-based feature\nselection and bagging classification model to detect DNS typo-squatting attack.\nExperimental results show that the proposed framework achieves high accuracy\nand precision in identifying the malicious/suspicious typo-squatting domains (a\nloss of at most 1.5% in accuracy and 5% in precision when compared to the model\nthat used the complete feature set) while having a lower computational\ncomplexity due to the smaller feature set (a reduction of more than 50% in\nfeature set size).\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 14:07:19 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Moubayed", "Abdallah", ""], ["Aqeeli", "Emad", ""], ["Shami", "Abdallah", ""]]}, {"id": "2006.09276", "submitter": "Hawzhin Mohammed", "authors": "Hawzhin Mohammed, Tolulope A. Odetola, Syed Rafay Hasan", "title": "How Secure is Distributed Convolutional Neural Network on IoT Edge\n  Devices?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNN) has found successful adoption in many\napplications. The deployment of CNN on resource-constrained edge devices have\nproved challenging. CNN distributed deployment across different edge devices\nhas been adopted. In this paper, we propose Trojan attacks on CNN deployed\nacross a distributed edge network across different nodes. We propose five\nstealthy attack scenarios for distributed CNN inference. These attacks are\ndivided into trigger and payload circuitry. These attacks are tested on deep\nlearning models (LeNet, AlexNet). The results show how the degree of\nvulnerability of individual layers and how critical they are to the final\nclassification.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 16:10:09 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Mohammed", "Hawzhin", ""], ["Odetola", "Tolulope A.", ""], ["Hasan", "Syed Rafay", ""]]}, {"id": "2006.09287", "submitter": "Daniele Ucci", "authors": "Daniele Ucci, Roberto Perdisci, Jaewoo Lee, Mustaque Ahamad", "title": "Building a Collaborative Phone Blacklisting System with Local\n  Differential Privacy", "comments": "15 pages, 10 figures, 7 algorithms", "journal-ref": null, "doi": "10.1145/3427228.3427239", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spam phone calls have been rapidly growing from nuisance to an increasingly\neffective scam delivery tool. To counter this increasingly successful attack\nvector, a number of commercial smartphone apps that promise to block spam phone\ncalls have appeared on app stores, and are now used by hundreds of thousands or\neven millions of users. However, following a business model similar to some\nonline social network services, these apps often collect call records or other\npotentially sensitive information from users' phones with little or no formal\nprivacy guarantees.\n  In this paper, we study whether it is possible to build a practical\ncollaborative phone blacklisting system that makes use of local differential\nprivacy (LDP) mechanisms to provide clear privacy guarantees. We analyze the\nchallenges and trade-offs related to using LDP, evaluate our LDP-based system\non real-world user-reported call records collected by the FTC, and show that it\nis possible to learn a phone blacklist using a reasonable overall privacy\nbudget and at the same time preserve users' privacy while maintaining utility\nfor the learned blacklist.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 16:30:19 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Ucci", "Daniele", ""], ["Perdisci", "Roberto", ""], ["Lee", "Jaewoo", ""], ["Ahamad", "Mustaque", ""]]}, {"id": "2006.09290", "submitter": "Vineet Sahula", "authors": "Arjun Singh Chauhan and Vineet Sahula and Atanendu Sekhar Mandal", "title": "Novel Randomized Placement for FPGA Based Robust ROPUF with Improved\n  Uniqueness", "comments": null, "journal-ref": "Journal of Electronic Testing volume 35, pages 581 to 601 (2019)", "doi": "10.1007/s10836-019-05849-1", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The physical unclonable functions (PUF) are used to provide software as well\nas hardware security for the cyber-physical systems. They have been used for\nperforming significant cryptography tasks such as generating keys, device\nauthentication, securing against IP piracy, and to produce the root of trust as\nwell. However, they lack in reliability metric. We present a novel approach for\nimproving the reliability as well as the uniqueness of the field programmable\ngated arrays (FPGAs) based ring oscillator PUF and derive a random number,\nconsuming very small area (< 1%) concerning look-up tables (LUTs). We use\nfrequency profiling method for distributing frequency variations in ring\noscillators (RO), spatially placed all across the FPGA floor. We are able to\nspot suitable locations for RO mapping, which leads to enhanced ROPUF\nreliability. We have evaluated the proposed methodology on Xilinx -7 series\nFPGAs and tested the robustness against environmental variations, e.g.\ntemperature and supply voltage variations, simultaneously. The proposed\napproach achieves significant improvement (i) in uniqueness value upto 49:90%,\nwithin 0.1% of the theoretical value (ii) in the reliability value upto 99:70%,\nwhich signifies that less than 1 bit flipping has been observed on average, and\n(iii) in randomness, signified by passing NIST test suite. The response\ngenerated through the ROPUF passes all the applicable relevant tests of NIST\nuniformity statistical test suite.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 10:23:52 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Chauhan", "Arjun Singh", ""], ["Sahula", "Vineet", ""], ["Mandal", "Atanendu Sekhar", ""]]}, {"id": "2006.09293", "submitter": "Reza Fotohi", "authors": "Reza Fotohi, Eslam Nazemi, Fereidoon Shams Aliee", "title": "An agent-based self-protective method to secure communication between\n  UAVs in unmanned aerial vehicle networks", "comments": "35 pages, 12 figures, 14 tables, Journal", "journal-ref": "Vehicular Communications. 2020 May 28:100267", "doi": "10.1016/j.vehcom.2020.100267", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  UAVNs (unmanned aerial vehicle networks) may become vulnerable to threats and\nattacks due to their characteristic features such as highly dynamic network\ntopology, open-air wireless environments, and high mobility. Since previous\nwork has focused on classical and metaheuristic-based approaches, none of these\napproaches have a self-adaptive approach. In this paper, the challenges and\nweaknesses of previous methods are examined in the form of a table.\nFurthermore, we propose an agent-based self-protective method (ASP-UAVN) for\nUAVNs that is based on the Human Immune System (HIS). In ASP-UAS, the safest\nroute from the source UAV to the destination UAV is chosen according to a\nself-protective system. In this method, a multi-agent system using an\nArtificial Immune System (AIS) is employed to detect the attacking UAV and\nchoose the safest route. In the proposed ASP-UAVN, the route request packet\n(RREQ) is initially transmitted from the source UAV to the destination UAV to\ndetect the existing routes. Then, once the route reply packet (RREP) is\nreceived, a self-protective method using agents and the knowledge base is\nemployed to choose the safest route and detect the attacking UAVs. The proposed\nASP-UAVN has been validated and evaluated in two ways: simulation and\ntheoretical analysis. The results of simulation evaluation and theory analysis\nshowed that the ASP-UAS increases the Packet Delivery Rate (PDR) by more than\n17.4, 20.8, and 25.91%, and detection rate by more than 17.2, 23.1, and 29.3%,\nand decreases the Packet Loss Rate (PLR) by more than 14.4, 16.8, and 20.21%,\nthe false-positive and false-negative rate by more than 16.5, 25.3, and 31.21%\nthose of SUAS-HIS, SFA and BRUIDS methods, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 10:12:37 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Fotohi", "Reza", ""], ["Nazemi", "Eslam", ""], ["Aliee", "Fereidoon Shams", ""]]}, {"id": "2006.09337", "submitter": "Mahesh Banavar", "authors": "Blaine Ayotte, Mahesh K. Banavar, Daqing Hou, Stephanie Schuckers", "title": "Fast Free-text Authentication via Instance-based Keystroke Dynamics", "comments": "Paper accepted to IEEE Transactions on Biometrics, Behavior, and\n  Identity Science (TBIOM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keystroke dynamics study the way in which users input text via their\nkeyboards. Having the ability to differentiate users, typing behaviors can\nunobtrusively form a component of a behavioral biometric recognition system to\nimprove existing account security. Keystroke dynamics systems on free-text data\nhave previously required 500 or more characters to achieve reasonable\nperformance. In this paper, we propose a novel instance-based graph comparison\nalgorithm called the instance-based tail area density (ITAD) metric to reduce\nthe number of keystrokes required to authenticate users. Additionally, commonly\nused features in the keystroke dynamics literature, such as monographs and\ndigraphs, are all found to be useful in informing who is typing. The usefulness\nof these features for authentication is determined using a random forest\nclassifier and validated across two publicly available datasets. Scores from\nthe individual features are fused to form a single matching score. With the\nfused matching score and our ITAD metric, we achieve equal error rates (EERs)\nfor 100 and 200 testing digraphs of 9.7% and 7.8% for the Clarkson II dataset,\nimproving upon state-of-the-art of 35.3% and 15.3%.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 17:21:17 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Ayotte", "Blaine", ""], ["Banavar", "Mahesh K.", ""], ["Hou", "Daqing", ""], ["Schuckers", "Stephanie", ""]]}, {"id": "2006.09352", "submitter": "Benjamin Coleman", "authors": "Benjamin Coleman and Anshumali Shrivastava", "title": "A One-Pass Private Sketch for Most Machine Learning Tasks", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy (DP) is a compelling privacy definition that explains\nthe privacy-utility tradeoff via formal, provable guarantees. Inspired by\nrecent progress toward general-purpose data release algorithms, we propose a\nprivate sketch, or small summary of the dataset, that supports a multitude of\nmachine learning tasks including regression, classification, density\nestimation, near-neighbor search, and more. Our sketch consists of randomized\ncontingency tables that are indexed with locality-sensitive hashing and\nconstructed with an efficient one-pass algorithm. We prove competitive error\nbounds for DP kernel density estimation. Existing methods for DP kernel density\nestimation scale poorly, often exponentially slower with an increase in\ndimensions. In contrast, our sketch can quickly run on large, high-dimensional\ndatasets in a single pass. Exhaustive experiments show that our generic sketch\ndelivers a similar privacy-utility tradeoff when compared to existing DP\nmethods at a fraction of the computation cost. We expect that our sketch will\nenable differential privacy in distributed, large-scale machine learning\nsettings.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 17:47:48 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Coleman", "Benjamin", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "2006.09475", "submitter": "Arnaud Grivet S\\'ebert", "authors": "Arnaud Grivet S\\'ebert, Rafael Pinot, Martin Zuber, C\\'edric\n  Gouy-Pailler, Renaud Sirdey", "title": "SPEED: Secure, PrivatE, and Efficient Deep learning", "comments": "32 pages, 3 figures. Mach Learn (2021)", "journal-ref": null, "doi": "10.1007/s10994-021-05970-3", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a deep learning framework able to deal with strong privacy\nconstraints. Based on collaborative learning, differential privacy and\nhomomorphic encryption, the proposed approach advances state-of-the-art of\nprivate deep learning against a wider range of threats, in particular the\nhonest-but-curious server assumption. We address threats from both the\naggregation server, the global model and potentially colluding data holders.\nBuilding upon distributed differential privacy and a homomorphic argmax\noperator, our method is specifically designed to maintain low communication\nloads and efficiency. The proposed method is supported by carefully crafted\ntheoretical results. We provide differential privacy guarantees from the point\nof view of any entity having access to the final model, including colluding\ndata holders, as a function of the ratio of data holders who kept their noise\nsecret. This makes our method practical to real-life scenarios where data\nholders do not trust any third party to process their datasets nor the other\ndata holders. Crucially the computational burden of the approach is maintained\nreasonable, and, to the best of our knowledge, our framework is the first one\nto be efficient enough to investigate deep learning applications while\naddressing such a large scope of threats. To assess the practical usability of\nour framework, experiments have been carried out on image datasets in a\nclassification context. We present numerical results that show that the\nlearning procedure is both accurate and private.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 19:31:52 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 17:57:30 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["S\u00e9bert", "Arnaud Grivet", ""], ["Pinot", "Rafael", ""], ["Zuber", "Martin", ""], ["Gouy-Pailler", "C\u00e9dric", ""], ["Sirdey", "Renaud", ""]]}, {"id": "2006.09511", "submitter": "Nampoina Andriamilanto", "authors": "Nampoina Andriamilanto, Tristan Allard, Ga\\\"etan Le Guelvouit,\n  Alexandre Garel", "title": "A Large-scale Empirical Analysis of Browser Fingerprints Properties for\n  Web Authentication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern browsers give access to several attributes that can be collected to\nform a browser fingerprint. Although browser fingerprints have primarily been\nstudied as a web tracking tool, they can contribute to improve the current\nstate of web security by augmenting web authentication mechanisms. In this\npaper, we investigate the adequacy of browser fingerprints for web\nauthentication. We make the link between the digital fingerprints that\ndistinguish browsers, and the biological fingerprints that distinguish Humans,\nto evaluate browser fingerprints according to properties inspired by biometric\nauthentication factors. These properties include their distinctiveness, their\nstability through time, their collection time, their size, and the accuracy of\na simple verification mechanism. We assess these properties on a large-scale\ndataset of 4,145,408 fingerprints composed of 216 attributes, and collected\nfrom 1,989,365 browsers. We show that, by time-partitioning our dataset, more\nthan 81.3% of our fingerprints are shared by a single browser. Although browser\nfingerprints are known to evolve, an average of 91% of the attributes of our\nfingerprints stay identical between two observations, even when separated by\nnearly 6 months. About their performance, we show that our fingerprints weigh a\ndozen of kilobytes, and take a few seconds to collect. Finally, by processing a\nsimple verification mechanism, we show that it achieves an equal error rate of\n0.61%. We enrich our results with the analysis of the correlation between the\nattributes, and of their contribution to the evaluated properties. We conclude\nthat our browser fingerprints carry the promise to strengthen web\nauthentication mechanisms.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 20:47:39 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Andriamilanto", "Nampoina", ""], ["Allard", "Tristan", ""], ["Guelvouit", "Ga\u00ebtan Le", ""], ["Garel", "Alexandre", ""]]}, {"id": "2006.09531", "submitter": "Behnood Momenzadeh", "authors": "Behnood Momenzadeh, Shakthidhar Gopavaram, Sanchari Das, and L Jean\n  Camp", "title": "Bayesian Evaluation of User App Choices in the Presence of Risk\n  Communication on Android Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the age of ubiquitous technologies, security- and privacy-focused choices\nhave turned out to be a significant concern for individuals and organizations.\nRisks of such pervasive technologies are extensive and often misaligned with\nuser risk perception, thus failing to help users in taking privacy-aware\ndecisions. Researchers usually try to find solutions for coherently extending\ntrust into our often inscrutable electronic networked environment. To enable\nsecurity- and privacy-focused decision-making, we mainly focused on the realm\nof the mobile marketplace, examining how risk indicators can help people choose\nmore secure and privacy-preserving apps. We performed a naturalistic experiment\nwith N=60 participants, where we asked them to select applications on Android\ntablets with accurate real-time marketplace data. We found that, in aggregate,\napp selections changed to be more risk-averse in the presence of user\nrisk-perception-aligned visual indicators. Our study design and research\npropose practical and usable interactions that enable more informed, risk-aware\ncomparisons for individuals during app selections. We include an explicit\nargument for the role of human decision-making during app selection, beyond the\ncurrent trend of using machine learning to automate privacy preferences after\nselection during run-time.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 21:44:34 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 18:19:02 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Momenzadeh", "Behnood", ""], ["Gopavaram", "Shakthidhar", ""], ["Das", "Sanchari", ""], ["Camp", "L Jean", ""]]}, {"id": "2006.09532", "submitter": "Anuj Dubey", "authors": "Anuj Dubey, Rosario Cammarota, Aydin Aysu", "title": "BoMaNet: Boolean Masking of an Entire Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on stealing machine learning (ML) models from inference engines\nwith physical side-channel attacks warrant an urgent need for effective\nside-channel defenses. This work proposes the first $\\textit{fully-masked}$\nneural network inference engine design.\n  Masking uses secure multi-party computation to split the secrets into random\nshares and to decorrelate the statistical relation of secret-dependent\ncomputations to side-channels (e.g., the power draw). In this work, we\nconstruct secure hardware primitives to mask $\\textit{all}$ the linear and\nnon-linear operations in a neural network. We address the challenge of masking\ninteger addition by converting each addition into a sequence of XOR and AND\ngates and by augmenting Trichina's secure Boolean masking style. We improve the\ntraditional Trichina's AND gates by adding pipelining elements for better\nglitch-resistance and we architect the whole design to sustain a throughput of\n1 masked addition per cycle.\n  We implement the proposed secure inference engine on a Xilinx Spartan-6\n(XC6SLX75) FPGA. The results show that masking incurs an overhead of 3.5\\% in\nlatency and 5.9$\\times$ in area. Finally, we demonstrate the security of the\nmasked design with 2M traces.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 21:45:08 GMT"}, {"version": "v2", "created": "Sat, 18 Jul 2020 23:22:17 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Dubey", "Anuj", ""], ["Cammarota", "Rosario", ""], ["Aysu", "Aydin", ""]]}, {"id": "2006.09539", "submitter": "Ren Pang", "authors": "Ren Pang, Xinyang Zhang, Shouling Ji, Xiapu Luo, Ting Wang", "title": "AdvMind: Inferring Adversary Intent of Black-Box Attacks", "comments": "Accepted as a full paper at KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are inherently susceptible to adversarial attacks\neven under black-box settings, in which the adversary only has query access to\nthe target models. In practice, while it may be possible to effectively detect\nsuch attacks (e.g., observing massive similar but non-identical queries), it is\noften challenging to exactly infer the adversary intent (e.g., the target class\nof the adversarial example the adversary attempts to craft) especially during\nearly stages of the attacks, which is crucial for performing effective\ndeterrence and remediation of the threats in many scenarios.\n  In this paper, we present AdvMind, a new class of estimation models that\ninfer the adversary intent of black-box adversarial attacks in a robust and\nprompt manner. Specifically, to achieve robust detection, AdvMind accounts for\nthe adversary adaptiveness such that her attempt to conceal the target will\nsignificantly increase the attack cost (e.g., in terms of the number of\nqueries); to achieve prompt detection, AdvMind proactively synthesizes\nplausible query results to solicit subsequent queries from the adversary that\nmaximally expose her intent. Through extensive empirical evaluation on\nbenchmark datasets and state-of-the-art black-box attacks, we demonstrate that\non average AdvMind detects the adversary intent with over 75% accuracy after\nobserving less than 3 query batches and meanwhile increases the cost of\nadaptive attacks by over 60%. We further discuss the possible synergy between\nAdvMind and other defense methods against black-box adversarial attacks,\npointing to several promising research directions.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 22:04:31 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Pang", "Ren", ""], ["Zhang", "Xinyang", ""], ["Ji", "Shouling", ""], ["Luo", "Xiapu", ""], ["Wang", "Ting", ""]]}, {"id": "2006.09615", "submitter": "Zhen Sun", "authors": "Zhen Sun, Roei Schuster, Vitaly Shmatikov", "title": "De-Anonymizing Text by Fingerprinting Language Generation", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Components of machine learning systems are not (yet) perceived as security\nhotspots. Secure coding practices, such as ensuring that no execution paths\ndepend on confidential inputs, have not yet been adopted by ML developers. We\ninitiate the study of code security of ML systems by investigating how nucleus\nsampling---a popular approach for generating text, used for applications such\nas auto-completion---unwittingly leaks texts typed by users. Our main result is\nthat the series of nucleus sizes for many natural English word sequences is a\nunique fingerprint. We then show how an attacker can infer typed text by\nmeasuring these fingerprints via a suitable side channel (e.g., cache access\ntimes), explain how this attack could help de-anonymize anonymous texts, and\ndiscuss defenses.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 02:49:15 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 04:47:25 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Sun", "Zhen", ""], ["Schuster", "Roei", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "2006.09628", "submitter": "Rishabh Poddar", "authors": "Rishabh Poddar and Ganesh Ananthanarayanan and Srinath Setty and\n  Stavros Volos and Raluca Ada Popa", "title": "Visor: Privacy-Preserving Video Analytics as a Cloud Service", "comments": "USENIX Security 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video-analytics-as-a-service is becoming an important offering for cloud\nproviders. A key concern in such services is privacy of the videos being\nanalyzed. While trusted execution environments (TEEs) are promising options for\npreventing the direct leakage of private video content, they remain vulnerable\nto side-channel attacks.\n  We present Visor, a system that provides confidentiality for the user's video\nstream as well as the ML models in the presence of a compromised cloud platform\nand untrusted co-tenants. Visor executes video pipelines in a hybrid TEE that\nspans both the CPU and GPU. It protects the pipeline against side-channel\nattacks induced by data-dependent access patterns of video modules, and also\naddresses leakage in the CPU-GPU communication channel. Visor is up to\n$1000\\times$ faster than na\\\"ive oblivious solutions, and its overheads\nrelative to a non-oblivious baseline are limited to $2\\times$--$6\\times$.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 03:25:11 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 04:37:24 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Poddar", "Rishabh", ""], ["Ananthanarayanan", "Ganesh", ""], ["Setty", "Srinath", ""], ["Volos", "Stavros", ""], ["Popa", "Raluca Ada", ""]]}, {"id": "2006.09769", "submitter": "Andrea Valenza", "authors": "Andrea Valenza, Gabriele Costa, Alessandro Armando", "title": "Never Trust Your Victim: Weaponizing Vulnerabilities in Security\n  Scanners", "comments": "Accepted at RAID 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first step of every attack is reconnaissance, i.e., to acquire\ninformation about the target. A common belief is that there is almost no risk\nin scanning a target from a remote location. In this paper we falsify this\nbelief by showing that scanners are exposed to the same risks as their targets.\nOur methodology is based on a novel attacker model where the scan author\nbecomes the victim of a counter-strike. We developed a working prototype,\ncalled RevOK, and we applied it to 78 scanning systems. Out of them, 36 were\nfound vulnerable to XSS. Remarkably, RevOK also found a severe vulnerability in\nMetasploit Pro, a mainstream penetration testing tool.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 10:42:46 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Valenza", "Andrea", ""], ["Costa", "Gabriele", ""], ["Armando", "Alessandro", ""]]}, {"id": "2006.09809", "submitter": "Jiska Classen", "authors": "Jan Ruge, Jiska Classen, Francesco Gringoli, Matthias Hollick", "title": "Frankenstein: Advanced Wireless Fuzzing to Exploit New Bluetooth\n  Escalation Targets", "comments": "To be published at USENIX Security", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless communication standards and implementations have a troubled history\nregarding security. Since most implementations and firmwares are closed-source,\nfuzzing remains one of the main methods to uncover Remote Code Execution (RCE)\nvulnerabilities in deployed systems. Generic over-the-air fuzzing suffers from\nseveral shortcomings, such as constrained speed, limited repeatability, and\nrestricted ability to debug. In this paper, we present Frankenstein, a fuzzing\nframework based on advanced firmware emulation, which addresses these\nshortcomings. Frankenstein brings firmware dumps \"back to life\", and provides\nfuzzed input to the chip's virtual modem. The speed-up of our new fuzzing\nmethod is sufficient to maintain interoperability with the attached operating\nsystem, hence triggering realistic full-stack behavior. We demonstrate the\npotential of Frankenstein by finding three zero-click vulnerabilities in the\nBroadcom and Cypress Bluetooth stack, which is used in most Apple devices, many\nSamsung smartphones, the Raspberry Pis, and many others.\n  Given RCE on a Bluetooth chip, attackers may escalate their privileges beyond\nthe chip's boundary. We uncover a Wi-Fi/Bluetooth coexistence issue that\ncrashes multiple operating system kernels and a design flaw in the Bluetooth\n5.2 specification that allows link key extraction from the host. Turning off\nBluetooth will not fully disable the chip, making it hard to defend against RCE\nattacks. Moreover, when testing our chip-based vulnerabilities on those\ndevices, we find BlueFrag, a chip-independent Android RCE.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 12:29:14 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Ruge", "Jan", ""], ["Classen", "Jiska", ""], ["Gringoli", "Francesco", ""], ["Hollick", "Matthias", ""]]}, {"id": "2006.09990", "submitter": "Leandros Maglaras A", "authors": "Stavros Kassaras, Leandros Maglaras", "title": "ZKPs: Does This Make The Cut? Recent Advances and Success of\n  Zero-Knowledge Security Protocols", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How someone can get health insurance without sharing his health information?\nHow you can get a loan without disclosing your credit score? There is a method\nto certify certain attributes of various data, either this is health metrics or\nfinance information, without revealing the data itself or any other kind of\npersonal data. This method is known as zero-knowledge proofs. Zero-Knowledge\ntechniques are mathematical methods used to verify things without sharing or\nrevealing underlying data. Zero-Knowledge protocols have vast applications from\nsimple identity schemes and blockchains to defense research programs and\nnuclear arms control\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 16:46:47 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Kassaras", "Stavros", ""], ["Maglaras", "Leandros", ""]]}, {"id": "2006.10013", "submitter": "Bartosz W\\'ojcik", "authors": "Bartosz W\\'ojcik, Pawe{\\l} Morawiecki, Marek \\'Smieja, Tomasz\n  Krzy\\.zek, Przemys{\\l}aw Spurek, Jacek Tabor", "title": "Adversarial Examples Detection and Analysis with Layer-wise Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a mechanism for detecting adversarial examples based on data\nrepresentations taken from the hidden layers of the target network. For this\npurpose, we train individual autoencoders at intermediate layers of the target\nnetwork. This allows us to describe the manifold of true data and, in\nconsequence, decide whether a given example has the same characteristics as\ntrue data. It also gives us insight into the behavior of adversarial examples\nand their flow through the layers of a deep neural network. Experimental\nresults show that our method outperforms the state of the art in supervised and\nunsupervised settings.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 17:17:54 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["W\u00f3jcik", "Bartosz", ""], ["Morawiecki", "Pawe\u0142", ""], ["\u015amieja", "Marek", ""], ["Krzy\u017cek", "Tomasz", ""], ["Spurek", "Przemys\u0142aw", ""], ["Tabor", "Jacek", ""]]}, {"id": "2006.10091", "submitter": "Junyi Li", "authors": "Junyi Li, Heng Huang", "title": "Faster Secure Data Mining via Distributed Homomorphic Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the rising privacy demand in data mining, Homomorphic Encryption (HE)\nis receiving more and more attention recently for its capability to do\ncomputations over the encrypted field. By using the HE technique, it is\npossible to securely outsource model learning to the not fully trustful but\npowerful public cloud computing environments. However, HE-based training scales\nbadly because of the high computation complexity. It is still an open problem\nwhether it is possible to apply HE to large-scale problems. In this paper, we\npropose a novel general distributed HE-based data mining framework towards one\nstep of solving the scaling problem. The main idea of our approach is to use\nthe slightly more communication overhead in exchange of shallower computational\ncircuit in HE, so as to reduce the overall complexity. We verify the efficiency\nand effectiveness of our new framework by testing over various data mining\nalgorithms and benchmark data-sets. For example, we successfully train a\nlogistic regression model to recognize the digit 3 and 8 within around 5\nminutes, while a centralized counterpart needs almost 2 hours.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 18:14:30 GMT"}], "update_date": "2020-06-20", "authors_parsed": [["Li", "Junyi", ""], ["Huang", "Heng", ""]]}, {"id": "2006.10196", "submitter": "Cong Dong", "authors": "Cong Dong, Zhigang Lu, Zelin Cui, Baoxu Liu and Kai Chen", "title": "MBTree: Detecting Encryption RAT Communication Using Malicious Behavior\n  Tree", "comments": "Accepted in IEEE Transactions on Information Forensics and Security\n  (TIFS)", "journal-ref": null, "doi": "10.1109/TIFS.2021.3071595", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network trace signature matching is one reliable approach to detect active\nRemote Control Trojan, (RAT). Compared to statistical-based detection of\nmalicious network traces in the face of known RATs, the signature-based method\ncan achieve more stable performance and thus more reliability. However, with\nthe development of encrypted technologies and disguise tricks, current methods\nsuffer inaccurate signature descriptions and inflexible matching mechanisms. In\nthis paper, we propose to tackle above problems by presenting MBTree, an\napproach to detect encryption RATs Command and Control (C&C) communication\nbased on host-level network trace behavior. MBTree first models the RAT network\nbehaviors as the malicious set by automatically building the multiple level\ntree, MLTree from distinctive network traces of each sample. Then, MBTree\nemploys a detection algorithm to detect malicious network traces that are\nsimilar to any MLTrees in the malicious set. To illustrate the effectiveness of\nour proposed method, we adopt theoretical analysis of MBTree from the\nprobability perspective. In addition, we have implemented MBTree to evaluate it\non five datasets which are reorganized in a sophisticated manner for\ncomprehensive assessment. The experimental results demonstrate the accurate and\nrobust of MBTree, especially in the face of new emerging benign applications.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 23:32:50 GMT"}, {"version": "v2", "created": "Sat, 26 Dec 2020 05:51:47 GMT"}, {"version": "v3", "created": "Tue, 6 Apr 2021 08:40:11 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Dong", "Cong", ""], ["Lu", "Zhigang", ""], ["Cui", "Zelin", ""], ["Liu", "Baoxu", ""], ["Chen", "Kai", ""]]}, {"id": "2006.10280", "submitter": "Ivan Homoliak Ph.D.", "authors": "Qingze Hum, Wei Jin Tan, Shi Ying Tey, Latasha Lenus, Ivan Homoliak,\n  Yun Lin, Jun Sun", "title": "CoinWatch: A Clone-Based Approach For Detecting Vulnerabilities in\n  Cryptocurrencies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptocurrencies have become very popular in recent years. Thousands of new\ncryptocurrencies have emerged, proposing new and novel techniques that improve\non Bitcoin's core innovation of the blockchain data structure and consensus\nmechanism. However, cryptocurrencies are a major target for cyber-attacks, as\nthey can be sold on exchanges anonymously and most cryptocurrencies have their\ncodebases publicly available. One particular issue is the prevalence of code\nclones in cryptocurrencies, which may amplify security threats. If a\nvulnerability is found in one cryptocurrency, it might be propagated into other\ncloned cryptocurrencies. In this work, we propose a systematic remedy to this\nproblem, and we propose CoinWatch (CW). Given a reported vulnerability at the\ninput, CW uses the code evolution analysis and a clone detection technique for\nindication of cryptocurrencies that might be vulnerable. We applied CW on 1094\ncryptocurrencies using 4 CVEs and obtained 786 true vulnerabilities present in\n384 projects, which were confirmed with developers and successfully reported as\nCVE extensions.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 05:09:19 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 13:14:44 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Hum", "Qingze", ""], ["Tan", "Wei Jin", ""], ["Tey", "Shi Ying", ""], ["Lenus", "Latasha", ""], ["Homoliak", "Ivan", ""], ["Lin", "Yun", ""], ["Sun", "Jun", ""]]}, {"id": "2006.10284", "submitter": "Savio Sciancalepore", "authors": "Gabriele Oligeri, Savio Sciancalepore, Roberto Di Pietro", "title": "GNSS Spoofing Detection via Opportunistic IRIDIUM Signals", "comments": "Accepted for the 13th Conference on Security and Privacy in Wireless\n  and Mobile Networks (WISEC), 2020", "journal-ref": null, "doi": "10.1145/3395351.3399350", "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the privately-own IRIDIUM satellite constellation, to\nprovide a location service that is independent of the GNSS. In particular, we\napply our findings to propose a new GNSS spoofing detection solution,\nexploiting unencrypted IRIDIUM Ring Alert (IRA) messages that are broadcast by\nIRIDIUM satellites. We firstly reverse-engineer many parameters of the IRIDIUM\nsatellite constellation, such as the satellites speed, packet interarrival\ntimes, maximum satellite coverage, satellite pass duration, and the satellite\nbeam constellation, to name a few. Later, we adopt the aforementioned\nstatistics to create a detailed model of the satellite network. Subsequently,\nwe propose a solution to detect unintended deviations of a target user from his\npath, due to GNSS spoofing attacks. We show that our solution can be used\nefficiently and effectively to verify the position estimated from standard GNSS\nsatellite constellation, and we provide constraints and parameters to fit\nseveral application scenarios. All the results reported in this paper, while\nshowing the quality and viability of our proposal, are supported by real data.\nIn particular, we have collected and analyzed hundreds of thousands of IRA\nmessages, thanks to a measurement campaign lasting several days. All the\ncollected data ($1000+$ hours) have been made available to the research\ncommunity. Our solution is particularly suitable for unattended scenarios such\nas deserts, rural areas, or open seas, where standard spoofing detection\ntechniques resorting to crowd-sourcing cannot be used due to deployment\nlimitations. Moreover, contrary to competing solutions, our approach does not\nresort to physical-layer information, dedicated hardware, or multiple receiving\nstations, while exploiting only a single receiving antenna and\npublicly-available IRIDIUM transmissions. Finally, novel research directions\nare also highlighted.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 05:34:04 GMT"}], "update_date": "2020-06-20", "authors_parsed": [["Oligeri", "Gabriele", ""], ["Sciancalepore", "Savio", ""], ["Di Pietro", "Roberto", ""]]}, {"id": "2006.10289", "submitter": "Miroslav Dimitrov", "authors": "Miroslav Dimitrov", "title": "On the Design of Chaos-Based S-boxes", "comments": null, "journal-ref": "IEEE Access ( Volume: 8 ), 24 June 2020", "doi": "10.1109/ACCESS.2020.3004526", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Substitution boxes (S-boxes) are critical nonlinear elements to achieve\ncryptanalytic resistance of modern block and stream ciphers. Given their\nimportance, a rich variety of S-box construction strategies exists. In this\npaper, S-boxes generated by using chaotic functions (CF) are analyzed to\nmeasure their actual resistance to linear cryptanalysis. The aforementioned\npapers emphasize on the average nonlinearity of the S-box coordinates only,\nignoring the rest of the S-box components in the process. Thus, the majority of\nthose studies should be re-evaluated. Integrating such S-boxes in a given\ncryptosystem should be done with a considerable caution. Furthermore, we show\nthat in the context of nonlinearity optimization problem the profit of using\nchaos structures is negligible. By using two heuristic methods and starting\nfrom pseudo-random S-boxes, we repeatedly reached S-boxes, which significantly\noutperform all previously published CF-based S-boxes, in those cryptographic\nterms, which the aforementioned papers utilize for comparison. Moreover, we\nhave linked the multi-armed bandit problem to the problem of maximizing an\nS-box average coordinate nonlinearity value, which further allowed us to reach\nnear-optimal average coordinate nonlinearity values significantly greater than\nthose known in literature.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 05:55:30 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Dimitrov", "Miroslav", ""]]}, {"id": "2006.10306", "submitter": "Regio Michelin", "authors": "Nadeem Ahmed, Regio A. Michelin, Wanli Xue, Sushmita Ruj, Robert\n  Malaney, Salil S. Kanhere, Aruna Seneviratne, Wen Hu, Helge Janicke, Sanjay\n  Jha", "title": "A Survey of COVID-19 Contact Tracing Apps", "comments": "Paper has been accepted for publication in IEEE Access. Currently\n  available on IEEE ACCESS early access (see DOI)", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3010226", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent outbreak of COVID-19 has taken the world by surprise, forcing\nlockdowns and straining public health care systems. COVID-19 is known to be a\nhighly infectious virus, and infected individuals do not initially exhibit\nsymptoms, while some remain asymptomatic. Thus, a non-negligible fraction of\nthe population can, at any given time, be a hidden source of transmissions. In\nresponse, many governments have shown great interest in smartphone contact\ntracing apps that help automate the difficult task of tracing all recent\ncontacts of newly identified infected individuals. However, tracing apps have\ngenerated much discussion around their key attributes, including system\narchitecture, data management, privacy, security, proximity estimation, and\nattack vulnerability. In this article, we provide the first comprehensive\nreview of these much-discussed tracing app attributes. We also present an\noverview of many proposed tracing app examples, some of which have been\ndeployed countrywide, and discuss the concerns users have reported regarding\ntheir usage. We close by outlining potential research directions for\nnext-generation app design, which would facilitate improved tracing and\nsecurity performance, as well as wide adoption by the population at large.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 06:53:41 GMT"}, {"version": "v2", "created": "Sun, 5 Jul 2020 23:31:30 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 00:46:21 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Ahmed", "Nadeem", ""], ["Michelin", "Regio A.", ""], ["Xue", "Wanli", ""], ["Ruj", "Sushmita", ""], ["Malaney", "Robert", ""], ["Kanhere", "Salil S.", ""], ["Seneviratne", "Aruna", ""], ["Hu", "Wen", ""], ["Janicke", "Helge", ""], ["Jha", "Sanjay", ""]]}, {"id": "2006.10318", "submitter": "Junjie Shen", "authors": "Junjie Shen, Jun Yeon Won, Zeyuan Chen, Qi Alfred Chen", "title": "Drift with Devil: Security of Multi-Sensor Fusion based Localization in\n  High-Level Autonomous Driving under GPS Spoofing (Extended Version)", "comments": "This is an extended version of our paper, which appears in USENIX\n  Security 2020. For attack demos, see our project website:\n  https://sites.google.com/view/cav-sec/fusionripper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For high-level Autonomous Vehicles (AV), localization is highly security and\nsafety critical. One direct threat to it is GPS spoofing, but fortunately, AV\nsystems today predominantly use Multi-Sensor Fusion (MSF) algorithms that are\ngenerally believed to have the potential to practically defeat GPS spoofing.\nHowever, no prior work has studied whether today's MSF algorithms are indeed\nsufficiently secure under GPS spoofing, especially in AV settings. In this\nwork, we perform the first study to fill this critical gap. As the first study,\nwe focus on a production-grade MSF with both design and implementation level\nrepresentativeness, and identify two AV-specific attack goals, off-road and\nwrong-way attacks.\n  To systematically understand the security property, we first analyze the\nupper-bound attack effectiveness, and discover a take-over effect that can\nfundamentally defeat the MSF design principle. We perform a cause analysis and\nfind that such vulnerability only appears dynamically and\nnon-deterministically. Leveraging this insight, we design FusionRipper, a novel\nand general attack that opportunistically captures and exploits take-over\nvulnerabilities. We evaluate it on 6 real-world sensor traces, and find that\nFusionRipper can achieve at least 97% and 91.3% success rates in all traces for\noff-road and wrong-way attacks respectively. We also find that it is highly\nrobust to practical factors such as spoofing inaccuracies. To improve the\npracticality, we further design an offline method that can effectively identify\nattack parameters with over 80% average success rates for both attack goals,\nwith the cost of at most half a day. We also discuss promising defense\ndirections.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 07:20:17 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 18:18:26 GMT"}, {"version": "v3", "created": "Wed, 12 Aug 2020 17:14:00 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Shen", "Junjie", ""], ["Won", "Jun Yeon", ""], ["Chen", "Zeyuan", ""], ["Chen", "Qi Alfred", ""]]}, {"id": "2006.10517", "submitter": "Ce Ju", "authors": "Ce Ju, Ruihui Zhao, Jichao Sun, Xiguang Wei, Bo Zhao, Yang Liu,\n  Hongshan Li, Tianjian Chen, Xinwei Zhang, Dashan Gao, Ben Tan, Han Yu,\n  Chuning He and Yuan Jin", "title": "Privacy-Preserving Technology to Help Millions of People: Federated\n  Prediction Model for Stroke Prevention", "comments": "4 pages, 3 figures, 1 table, Accepted for Workshop on Federated\n  Learning for Data Privacy and Confidentiality in Conjunction with IJCAI 2020\n  (FL-IJCAI'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prevention of stroke with its associated risk factors has been one of the\npublic health priorities worldwide. Emerging artificial intelligence technology\nis being increasingly adopted to predict stroke. Because of privacy concerns,\npatient data are stored in distributed electronic health record (EHR)\ndatabases, voluminous clinical datasets, which prevent patient data from being\naggregated and restrains AI technology to boost the accuracy of stroke\nprediction with centralized training data. In this work, our scientists and\nengineers propose a privacy-preserving scheme to predict the risk of stroke and\ndeploy our federated prediction model on cloud servers. Our system of federated\nprediction model asynchronously supports any number of client connections and\narbitrary local gradient iterations in each communication round. It adopts\nfederated averaging during the model training process, without patient data\nbeing taken out of the hospitals during the whole process of model training and\nforecasting. With the privacy-preserving mechanism, our federated prediction\nmodel trains over all the healthcare data from hospitals in a certain city\nwithout actual data sharing among them. Therefore, it is not only secure but\nalso more accurate than any single prediction model that trains over the data\nonly from one single hospital. Especially for small hospitals with few\nconfirmed stroke cases, our federated model boosts model performance by 10%~20%\nin several machine learning metrics. To help stroke experts comprehend the\nadvantage of our prediction system more intuitively, we developed a mobile app\nthat collects the key information of patients' statistics and demonstrates\nperformance comparisons between the federated prediction model and the single\nprediction model during the federated training process.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 08:51:23 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 02:51:30 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Ju", "Ce", ""], ["Zhao", "Ruihui", ""], ["Sun", "Jichao", ""], ["Wei", "Xiguang", ""], ["Zhao", "Bo", ""], ["Liu", "Yang", ""], ["Li", "Hongshan", ""], ["Chen", "Tianjian", ""], ["Zhang", "Xinwei", ""], ["Gao", "Dashan", ""], ["Tan", "Ben", ""], ["Yu", "Han", ""], ["He", "Chuning", ""], ["Jin", "Yuan", ""]]}, {"id": "2006.10521", "submitter": "Song Gao", "authors": "Jinmeng Rao, Song Gao, Yuhao Kang, Qunying Huang", "title": "LSTM-TrajGAN: A Deep Learning Approach to Trajectory Privacy Protection", "comments": "16 pages, 7 figures, in the Proceedings of the 11th International\n  Conference on Geographic Information Science (GIScience 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prevalence of location-based services contributes to the explosive growth\nof individual-level trajectory data and raises public concerns about privacy\nissues. In this research, we propose a novel LSTM-TrajGAN approach, which is an\nend-to-end deep learning model to generate privacy-preserving synthetic\ntrajectory data for data sharing and publication. We design a loss metric\nfunction TrajLoss to measure the trajectory similarity losses for model\ntraining and optimization. The model is evaluated on the\ntrajectory-user-linking task on a real-world semantic trajectory dataset.\nCompared with other common geomasking methods, our model can better prevent\nusers from being re-identified, and it also preserves essential spatial,\ntemporal, and thematic characteristics of the real trajectory data. The model\nbetter balances the effectiveness of trajectory privacy protection and the\nutility for spatial and temporal analyses, which offers new insights into the\nGeoAI-powered privacy protection.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 03:04:19 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Rao", "Jinmeng", ""], ["Gao", "Song", ""], ["Kang", "Yuhao", ""], ["Huang", "Qunying", ""]]}, {"id": "2006.10559", "submitter": "Pengtao Xie", "authors": "Ishika Singh, Haoyi Zhou, Kunlin Yang, Meng Ding, Bill Lin, Pengtao\n  Xie", "title": "Differentially-private Federated Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search, which aims to automatically search for\narchitectures (e.g., convolution, max pooling) of neural networks that maximize\nvalidation performance, has achieved remarkable progress recently. In many\napplication scenarios, several parties would like to collaboratively search for\na shared neural architecture by leveraging data from all parties. However, due\nto privacy concerns, no party wants its data to be seen by other parties. To\naddress this problem, we propose federated neural architecture search (FNAS),\nwhere different parties collectively search for a differentiable architecture\nby exchanging gradients of architecture variables without exposing their data\nto other parties. To further preserve privacy, we study differentially-private\nFNAS (DP-FNAS), which adds random noise to the gradients of architecture\nvariables. We provide theoretical guarantees of DP-FNAS in achieving\ndifferential privacy. Experiments show that DP-FNAS can search\nhighly-performant neural architectures while protecting the privacy of\nindividual parties. The code is available at\nhttps://github.com/UCSD-AI4H/DP-FNAS\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 20:53:52 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 21:48:41 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Singh", "Ishika", ""], ["Zhou", "Haoyi", ""], ["Yang", "Kunlin", ""], ["Ding", "Meng", ""], ["Lin", "Bill", ""], ["Xie", "Pengtao", ""]]}, {"id": "2006.10587", "submitter": "Yisroel Mirsky Dr.", "authors": "Yisroel Mirsky, Tomer Golomb, Yuval Elovici", "title": "Lightweight Collaborative Anomaly Detection for the IoT using Blockchain", "comments": "Preprint of accepted publication, June 2020: Journal of Parallel and\n  Distributed Computing, Elsevier, ISSN: 0743-7315", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their rapid growth and deployment, the Internet of things (IoT) have\nbecome a central aspect of our daily lives. Unfortunately, IoT devices tend to\nhave many vulnerabilities which can be exploited by an attacker. Unsupervised\ntechniques, such as anomaly detection, can be used to secure these devices in a\nplug-and-protect manner.\n  However, anomaly detection models must be trained for a long time in order to\ncapture all benign behaviors. Furthermore, the anomaly detection model is\nvulnerable to adversarial attacks since, during the training phase, all\nobservations are assumed to be benign. In this paper, we propose (1) a novel\napproach for anomaly detection and (2) a lightweight framework that utilizes\nthe blockchain to ensemble an anomaly detection model in a distributed\nenvironment.\n  Blockchain framework incrementally updates a trusted anomaly detection model\nvia self-attestation and consensus among the IoT devices. We evaluate our\nmethod on a distributed IoT simulation platform, which consists of 48 Raspberry\nPis. The simulation demonstrates how the approach can enhance the security of\neach device and the security of the network as a whole.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 14:50:08 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Mirsky", "Yisroel", ""], ["Golomb", "Tomer", ""], ["Elovici", "Yuval", ""]]}, {"id": "2006.10591", "submitter": "Anca Jurcut Dr.", "authors": "A. Jurcut, T. Niculcea, P. Ranaweera and A. LeKhac", "title": "Security Considerations for Internet of Things: A Survey", "comments": null, "journal-ref": "SN Computer Science (2020) 1:193, Springer Nature Singapore Pte\n  Ltd 2020", "doi": "10.1007/s42979-020-00201-3", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interconnecting \"things\" and devices that take the form of wearables,\nsensors, actuators, mobiles, computers, meters, or even vehicles is a critical\nrequirement for the current era. These internetworked connections are serving\nthe emerging applications home and building automation, smart cities and\ninfrastructure, smart industries, and smart-everything. However, the security\nof these connected Internet of things (IoT) plays a centric role with no margin\nfor error. After a review of the relevant, online literature on the topic and\nafter looking at the market trends and developments, one can notice that there\nare still concerns with regard to security in IoT products and services. This\npaper is focusing on a survey on IoT security and aims to highlight the most\nsignificant problems related to safety and security in the IoT ecosystems. This\nsurvey identifies the general threat and attack vectors against IoT devices\nwhile highlighting the flaws and weak points that can lead to breaching the\nsecurity. Furthermore, this paper presents solutions for remediation of the\ncompromised security, as well as methods for risk mitigation, with prevention\nand improvement suggestions.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 14:55:05 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Jurcut", "A.", ""], ["Niculcea", "T.", ""], ["Ranaweera", "P.", ""], ["LeKhac", "A.", ""]]}, {"id": "2006.10615", "submitter": "Silvia Sebasti\\'an", "authors": "Silvia Sebasti\\'an and Juan Caballero", "title": "AVClass2: Massive Malware Tag Extraction from AV Labels", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tags can be used by malware repositories and analysis services to enable\nsearches for samples of interest across different dimensions. Automatically\nextracting tags from AV labels is an efficient approach to categorize and index\nmassive amounts of samples. Recent tools like AVClass and Euphony have\ndemonstrated that, despite their noisy nature, it is possible to extract family\nnames from AV labels. However, beyond the family name, AV labels contain much\nvaluable information such as malware classes, file properties, and behaviors.\n  This work presents AVClass2, an automatic malware tagging tool that given the\nAV labels for a potentially massive number of samples, extracts clean tags that\ncategorize the samples. AVClass2 uses, and helps building, an open taxonomy\nthat organizes concepts in AV labels, but is not constrained to a predefined\nset of tags. To keep itself updated as AV vendors introduce new tags, it\nprovides an update module that automatically identifies new taxonomy entries,\nas well as tagging and expansion rules that capture relations between tags. We\nhave evaluated AVClass2 on 42M and showed how it enables advanced malware\nsearches and to maintain an updated knowledge base of malware concepts in AV\nlabels.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 15:36:22 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 12:28:41 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Sebasti\u00e1n", "Silvia", ""], ["Caballero", "Juan", ""]]}, {"id": "2006.10719", "submitter": "Paul-Olivier Dehaye", "authors": "Paul-Olivier Dehaye, Joel Reardon", "title": "SwissCovid: a critical analysis of risk assessment by Swiss authorities", "comments": "v2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ahead of the rollout of the SwissCovid contact tracing app, an official\npublic security test was performed. During this audit, Prof. Serge Vaudenay and\nDr. Martin Vuagnoux described a large set of problems with the app, including a\nnew variation of a known false-positive attack, leveraging a cryptographic\nweakness in the Google and Apple Exposure Notification framework to tamper with\nthe emitted Bluetooth beacons. Separately, the first author described a\nre-identification attack leveraging rogue apps or SDKs. The response from the\nSwiss cybersecurity agency and the Swiss public health authority was to claim\nthese various attacks were unlikely as they required physical proximity of the\nattacker with the target (although it was admitted the attacker could be\nfurther than two meters). The physical presence of the attacker in Switzerland\nwas deemed significant as it would imply such attackers would fall under the\nSwiss Criminal Code. We show through one example that a much larger variety of\nadversaries must be considered in the scenarios originally described and that\nthese attacks can be done by adversaries without any physical presence in\nSwitzerland. This goes directly against official findings of Swiss public\nauthorities evaluating the risks associated with SwissCovid. To move the\ndiscussion further along, we briefly discuss the growth of the attack surface\nand harms with COVID-19 and SwissCovid prevalence in the population. While the\nfocus of this article is on Switzerland, we emphasize the core technical\nfindings and cybersecurity concerns are of relevance to many contact tracing\nefforts.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 17:50:28 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 07:15:02 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Dehaye", "Paul-Olivier", ""], ["Reardon", "Joel", ""]]}, {"id": "2006.10843", "submitter": "Alaa Awad Abdellatif", "authors": "Alaa Awad Abdellatif, Abeer Z. Al-Marridi, Amr Mohamed, Aiman Erbad,\n  Carla Fabiana Chiasserini, and Ahmed Refaey", "title": "SSHealth: Toward Secure, Blockchain-Enabled Healthcare Systems", "comments": null, "journal-ref": "IEEE Network, 2020", "doi": "10.1109/MNET.011.1900553", "report-no": null, "categories": "cs.CY cs.CR cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The future of healthcare systems is being shaped by incorporating emerged\ntechnological innovations to drive new models for patient care. By acquiring,\nintegrating, analyzing, and exchanging medical data at different system levels,\nnew practices can be introduced, offering a radical improvement to healthcare\nservices. This paper presents a novel smart and secure Healthcare system\n(ssHealth), which, leveraging advances in edge computing and blockchain\ntechnologies, permits epidemics discovering, remote monitoring, and fast\nemergency response. The proposed system also allows for secure medical data\nexchange among local healthcare entities, thus realizing the integration of\nmultiple national and international entities and enabling the correlation of\ncritical medical events for, e.g., emerging epidemics management and control.\nIn particular, we develop a blockchain-based architecture and enable a flexible\nconfiguration thereof, which optimize medical data sharing between different\nhealth entities and fulfil the diverse levels of Quality of Service (QoS) that\nssHealth may require. Finally, we highlight the benefits of the proposed\nssHealth system and possible directions for future research.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 20:34:56 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Abdellatif", "Alaa Awad", ""], ["Al-Marridi", "Abeer Z.", ""], ["Mohamed", "Amr", ""], ["Erbad", "Aiman", ""], ["Chiasserini", "Carla Fabiana", ""], ["Refaey", "Ahmed", ""]]}, {"id": "2006.10861", "submitter": "Luca Invernizzi", "authors": "Ivan Petrov, Luca Invernizzi, Elie Bursztein", "title": "CoinPolice:Detecting Hidden Cryptojacking Attacks with Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Traffic monetization is a crucial component of running most for-profit online\nbusinesses. One of its latest incarnations is cryptocurrency mining, where a\nwebsite instructs the visitor's browser to participate in building a\ncryptocurrency ledger (e.g., Bitcoin, Monero) in exchange for a small reward in\nthe same currency. In its essence, this practice trades the user's electric\nbill (or battery level) for cryptocurrency. With user consent, this exchange\ncan be a legitimate funding source - for example, UNICEF has collected over 27k\ncharity donations on a website dedicated to this purpose, thehopepage.org.\nRegrettably, this practice also easily lends itself to abuse: in this form,\ncalled cryptojacking, attacks surreptitiously mine in the users browser, and\nprofits are collected either by website owners or by hackers that planted the\nmining script into a vulnerable page. Cryptojackers have been bettering their\nevasion techniques, incorporating in their toolkits domain fluxing, content\nobfuscation, the use of WebAssembly, and throttling. Whereas most\nstate-of-the-art defenses address multiple of these evasion techniques, none is\nresistant against all. In this paper, we offer a novel detection method,\nCoinPolice, that is robust against all of the aforementioned evasion\ntechniques. CoinPolice flips throttling against cryptojackers, artificially\nvarying the browser's CPU power to observe the presence of throttling. Based on\na deep neural network classifier, CoinPolice can detect 97.87% of hidden miners\nwith a low false positive rate (0.74%). We compare CoinPolice performance with\nthe current state of the art and show our approach outperforms it when\ndetecting aggressively throttled miners. Finally, we deploy Coinpolice to\nperform the largest-scale cryptoming investigation to date, identifying 6700\nsites that monetize traffic in this fashion.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 21:28:29 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 00:26:37 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Petrov", "Ivan", ""], ["Invernizzi", "Luca", ""], ["Bursztein", "Elie", ""]]}, {"id": "2006.10915", "submitter": "Wei Xie", "authors": "Keqi Wang, Wei Xie, Wencen Wu, Bo Wang, Jinxiang Pei, Mike Baker, Qi\n  Zhou", "title": "Simulation-Based Digital Twin Development for Blockchain Enabled\n  End-to-End Industrial Hemp Supply Chain Risk Management", "comments": "11 pages, 2 figures, 2020 Winter Simulation Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the passage of the 2018 U.S. Farm Bill, Industrial Hemp production is\nmoved from limited pilot programs to a regulated agriculture production system.\nHowever, Industrial Hemp Supply Chain (IHSC) faces critical challenges,\nincluding: high complexity and variability, very limited production knowledge,\nlack of data and information tracking. In this paper, we propose\nblockchain-enabled IHSC and develop a preliminary simulation-based digital twin\nfor this distributed cyber-physical system (CPS) to support the process\nlearning and risk management. Basically, we develop a two-layer blockchain with\nproof of authority smart contract, which can track the data and key\ninformation, improve the supply chain transparency, and leverage local\nauthorities and state regulators to ensure the quality control verification.\nThen, we introduce a stochastic simulation-based digital twin for IHSC risk\nmanagement, which can characterize the process spatial-temporal causal\ninterdependencies and dynamic evolution to guide risk control and decision\nmaking. Our empirical study demonstrates the promising performance of proposed\nplatform.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 01:20:50 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Wang", "Keqi", ""], ["Xie", "Wei", ""], ["Wu", "Wencen", ""], ["Wang", "Bo", ""], ["Pei", "Jinxiang", ""], ["Baker", "Mike", ""], ["Zhou", "Qi", ""]]}, {"id": "2006.10919", "submitter": "Ali Davody", "authors": "Ali Davody, David Ifeoluwa Adelani, Thomas Kleinbauer and Dietrich\n  Klakow", "title": "Robust Differentially Private Training of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentially private stochastic gradient descent (DPSGD) is a variation of\nstochastic gradient descent based on the Differential Privacy (DP) paradigm\nwhich can mitigate privacy threats arising from the presence of sensitive\ninformation in training data. One major drawback of training deep neural\nnetworks with DPSGD is a reduction in the model's accuracy. In this paper, we\npropose an alternative method for preserving data privacy based on introducing\nnoise through learnable probability distributions, which leads to a significant\nimprovement in the utility of the resulting private models. We also demonstrate\nthat normalization layers have a large beneficial impact on the performance of\ndeep neural networks with noisy parameters. In particular, we show that\ncontrary to general belief, a large amount of random noise can be added to the\nweights of neural networks without harming the performance, once the networks\nare augmented with normalization layers. We hypothesize that this robustness is\na consequence of the scale invariance property of normalization operators.\nBuilding on these observations, we propose a new algorithmic technique for\ntraining deep neural networks under very low privacy budgets by sampling\nweights from Gaussian distributions and utilizing batch or layer normalization\ntechniques to prevent performance degradation. Our method outperforms previous\napproaches, including DPSGD, by a substantial margin on a comprehensive set of\nexperiments on Computer Vision and Natural Language Processing tasks. In\nparticular, we obtain a 20 percent accuracy improvement over DPSGD on the MNIST\nand CIFAR10 datasets with DP-privacy budgets of $\\varepsilon = 0.05$ and\n$\\varepsilon = 2.0$, respectively. Our code is available online:\nhttps://github.com/uds-lsv/SIDP.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 01:43:52 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Davody", "Ali", ""], ["Adelani", "David Ifeoluwa", ""], ["Kleinbauer", "Thomas", ""], ["Klakow", "Dietrich", ""]]}, {"id": "2006.10933", "submitter": "Ruoxi Sun", "authors": "Ruoxi Sun, Wei Wang, Minhui Xue, Gareth Tyson, Seyit Camtepe, Damith\n  C. Ranasinghe", "title": "An Empirical Assessment of Global COVID-19 Contact Tracing Applications", "comments": null, "journal-ref": "In proceedings of the 43rd International Conference on Software\n  Engineering (ICSE 2021)", "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid spread of COVID-19 has made manual contact tracing difficult. Thus,\nvarious public health authorities have experimented with automatic contact\ntracing using mobile applications (or \"apps\"). These apps, however, have raised\nsecurity and privacy concerns. In this paper, we propose an automated security\nand privacy assessment tool, COVIDGUARDIAN, which combines identification and\nanalysis of Personal Identification Information (PII), static program analysis\nand data flow analysis, to determine security and privacy weaknesses.\nFurthermore, in light of our findings, we undertake a user study to investigate\nconcerns regarding contact tracing apps. We hope that COVIDGUARDIAN, and the\nissues raised through responsible disclosure to vendors, can contribute to the\nsafe deployment of mobile contact tracing. As part of this, we offer concrete\nguidelines, and highlight gaps between user requirements and app performance.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 02:12:56 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 10:25:30 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 03:51:34 GMT"}, {"version": "v4", "created": "Tue, 24 Nov 2020 11:46:02 GMT"}, {"version": "v5", "created": "Wed, 25 Nov 2020 11:09:58 GMT"}, {"version": "v6", "created": "Fri, 22 Jan 2021 08:36:28 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Sun", "Ruoxi", ""], ["Wang", "Wei", ""], ["Xue", "Minhui", ""], ["Tyson", "Gareth", ""], ["Camtepe", "Seyit", ""], ["Ranasinghe", "Damith C.", ""]]}, {"id": "2006.10972", "submitter": "Seunghoon Lee", "authors": "Jeremiah Blocki, Seunghoon Lee, Samson Zhou", "title": "On the Security of Proofs of Sequential Work in a Post-Quantum World", "comments": "45 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Proof of Sequential Work (PoSW) allows a prover to convince a\nresource-bounded verifier that the prover invested a substantial amount of\nsequential time to perform some underlying computation. PoSWs have many\napplications including time-stamping, blockchain design, and universally\nverifiable CPU benchmarks. Mahmoody, Moran, and Vadhan (ITCS 2013) gave the\nfirst construction of a PoSW in the random oracle model though the construction\nrelied on expensive depth-robust graphs. In a recent breakthrough, Cohen and\nPietrzak (EUROCRYPT 2018) gave an efficient PoSW construction that does not\nrequire expensive depth-robust graphs.\n  In the classical parallel random oracle model, it is straightforward to argue\nthat any successful PoSW attacker must produce a long $\\mathcal{H}$-sequence\nand that any malicious party running in sequential time $T-1$ will fail to\nproduce an $\\mathcal{H}$-sequence of length $T$ except with negligible\nprobability. In this paper, we prove that any quantum attacker running in\nsequential time $T-1$ will fail to produce an $\\mathcal{H}$-sequence except\nwith negligible probability -- even if the attacker submits a large batch of\nquantum queries in each round. The proof is substantially more challenging and\nhighlights the power of Zhandry's recent compressed oracle technique (CRYPTO\n2019). We further extend this result to establish post-quantum security of a\nnon-interactive PoSW obtained by applying the Fiat-Shamir transform to Cohen\nand Pietrzak's efficient construction (EUROCRYPT 2018).\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 06:07:34 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 20:25:37 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 17:09:50 GMT"}, {"version": "v4", "created": "Tue, 18 May 2021 17:06:55 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Blocki", "Jeremiah", ""], ["Lee", "Seunghoon", ""], ["Zhou", "Samson", ""]]}, {"id": "2006.10985", "submitter": "Quentin Bramas", "authors": "Fran\\c{c}ois Bonnet (TITECH), Quentin Bramas (ICube, ICUBE-R\\'eseaux),\n  Xavier D\\'efago (TITECH)", "title": "Stateless Distributed Ledgers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In public distributed ledger technologies (DLTs), such as Blockchains, nodes\ncan join and leave the network at any time. A major challenge occurs when a new\nnode joining the network wants to retrieve the current state of the ledger.\nIndeed, that node may receive conflicting information from honest and Byzantine\nnodes, making it difficult to identify the current state. In this paper, we are\ninterested in protocols that are stateless, i.e., a new joining node should be\nable to retrieve the current state of the ledger just using a fixed amount of\ndata that characterizes the ledger (such as the genesis block in Bitcoin). We\ndefine three variants of stateless DLTs: weak, strong, and probabilistic. Then,\nwe analyze this property for DLTs using different types of consensus.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 07:22:35 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Bonnet", "Fran\u00e7ois", "", "TITECH"], ["Bramas", "Quentin", "", "ICube, ICUBE-R\u00e9seaux"], ["D\u00e9fago", "Xavier", "", "TITECH"]]}, {"id": "2006.11103", "submitter": "Arthur Drichel", "authors": "Arthur Drichel, Ulrike Meyer, Samuel Sch\\\"uppen, Dominik Teubert", "title": "Analyzing the Real-World Applicability of DGA Classifiers", "comments": "Accepted at The 15th International Conference on Availability,\n  Reliability and Security (ARES 2020)", "journal-ref": "In The 15th International Conference on Availability, Reliability\n  and Security (ARES 2020), ACM, 11 pages", "doi": "10.1145/3407023.3407030", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separating benign domains from domains generated by DGAs with the help of a\nbinary classifier is a well-studied problem for which promising performance\nresults have been published. The corresponding multiclass task of determining\nthe exact DGA that generated a domain enabling targeted remediation measures is\nless well studied. Selecting the most promising classifier for these tasks in\npractice raises a number of questions that have not been addressed in prior\nwork so far. These include the questions on which traffic to train in which\nnetwork and when, just as well as how to assess robustness against adversarial\nattacks. Moreover, it is unclear which features lead a classifier to a decision\nand whether the classifiers are real-time capable. In this paper, we address\nthese issues and thus contribute to bringing DGA detection classifiers closer\nto practical use. In this context, we propose one novel classifier based on\nresidual neural networks for each of the two tasks and extensively evaluate\nthem as well as previously proposed classifiers in a unified setting. We not\nonly evaluate their classification performance but also compare them with\nrespect to explainability, robustness, and training and classification speed.\nFinally, we show that our newly proposed binary classifier generalizes well to\nother networks, is time-robust, and able to identify previously unknown DGAs.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 12:34:05 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Drichel", "Arthur", ""], ["Meyer", "Ulrike", ""], ["Sch\u00fcppen", "Samuel", ""], ["Teubert", "Dominik", ""]]}, {"id": "2006.11130", "submitter": "Josh Kalin", "authors": "Josh Kalin, David Noever, Gerry Dozier", "title": "Systematic Attack Surface Reduction For Deployed Sentiment Analysis\n  Models", "comments": "11 pages, 4 figures, 6th International Conference on Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work proposes a structured approach to baselining a model, identifying\nattack vectors, and securing the machine learning models after deployment. This\nmethod for securing each model post deployment is called the BAD (Build,\nAttack, and Defend) Architecture. Two implementations of the BAD architecture\nare evaluated to quantify the adversarial life cycle for a black box Sentiment\nAnalysis system. As a challenging diagnostic, the Jigsaw Toxic Bias dataset is\nselected as the baseline in our performance tool. Each implementation of the\narchitecture will build a baseline performance report, attack a common\nweakness, and defend the incoming attack. As an important note: each attack\nsurface demonstrated in this work is detectable and preventable. The goal is to\ndemonstrate a viable methodology for securing a machine learning model in a\nproduction setting.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 13:41:38 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Kalin", "Josh", ""], ["Noever", "David", ""], ["Dozier", "Gerry", ""]]}, {"id": "2006.11165", "submitter": "Jinyuan Jia", "authors": "Zaixi Zhang and Jinyuan Jia and Binghui Wang and Neil Zhenqiang Gong", "title": "Backdoor Attacks to Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we propose the first backdoor attack to graph neural networks\n(GNN). Specifically, we propose a \\emph{subgraph based backdoor attack} to GNN\nfor graph classification. In our backdoor attack, a GNN classifier predicts an\nattacker-chosen target label for a testing graph once a predefined subgraph is\ninjected to the testing graph. Our empirical results on three real-world graph\ndatasets show that our backdoor attacks are effective with a small impact on a\nGNN's prediction accuracy for clean testing graphs. Moreover, we generalize a\nrandomized smoothing based certified defense to defend against our backdoor\nattacks. Our empirical results show that the defense is effective in some cases\nbut ineffective in other cases, highlighting the needs of new defenses for our\nbackdoor attacks.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 14:51:01 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 17:17:33 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Zhang", "Zaixi", ""], ["Jia", "Jinyuan", ""], ["Wang", "Binghui", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "2006.11204", "submitter": "Tsubasa Takahashi", "authors": "Tsubasa Takahashi, Shun Takagi, Hajime Ono, Tatsuya Komatsu", "title": "Differentially Private Variational Autoencoders with Term-wise Gradient\n  Aggregation", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies how to learn variational autoencoders with a variety of\ndivergences under differential privacy constraints. We often build a VAE with\nan appropriate prior distribution to describe the desired properties of the\nlearned representations and introduce a divergence as a regularization term to\nclose the representations to the prior. Using differentially private SGD\n(DP-SGD), which randomizes a stochastic gradient by injecting a dedicated noise\ndesigned according to the gradient's sensitivity, we can easily build a\ndifferentially private model. However, we reveal that attaching several\ndivergences increase the sensitivity from O(1) to O(B) in terms of batch size\nB. That results in injecting a vast amount of noise that makes it hard to\nlearn. To solve the above issue, we propose term-wise DP-SGD that crafts\nrandomized gradients in two different ways tailored to the compositions of the\nloss terms. The term-wise DP-SGD keeps the sensitivity at O(1) even when\nattaching the divergence. We can therefore reduce the amount of noise. In our\nexperiments, we demonstrate that our method works well with two pairs of the\nprior distribution and the divergence.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 16:12:28 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Takahashi", "Tsubasa", ""], ["Takagi", "Shun", ""], ["Ono", "Hajime", ""], ["Komatsu", "Tatsuya", ""]]}, {"id": "2006.11211", "submitter": "Miklos Z. Racz", "authors": "Miklos Z. Racz, Jacob Richey", "title": "Rumor source detection with multiple observations under adaptive\n  diffusions", "comments": "30 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work, motivated by anonymous messaging platforms, has introduced\nadaptive diffusion protocols which can obfuscate the source of a rumor: a\n\"snapshot adversary\" with access to the subgraph of \"infected\" nodes can do no\nbetter than randomly guessing the entity of the source node. What happens if\nthe adversary has access to multiple independent snapshots? We study this\nquestion when the underlying graph is the infinite $d$-regular tree. We show\nthat (1) a weak form of source obfuscation is still possible in the case of two\nindependent snapshots, but (2) already with three observations there is a\nsimple algorithm that finds the rumor source with constant probability,\nregardless of the adaptive diffusion protocol. We also characterize the\ntradeoff between local spreading and source obfuscation for adaptive diffusion\nprotocols (under a single snapshot). These results raise questions about the\nrobustness of anonymity guarantees when spreading information in social\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 16:27:26 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Racz", "Miklos Z.", ""], ["Richey", "Jacob", ""]]}, {"id": "2006.11233", "submitter": "Elliot Fairweather", "authors": "Elliot Fairweather, Rudolf Wittner, Martin Chapman, Petr Holub, Vasa\n  Curcin", "title": "Non-repudiable provenance for clinical decision support systems", "comments": "Accepted at International Provenance & Annotation Workshop (IPAW),\n  June 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Provenance templates are now a recognised methodology for the construction of\ndata provenance records. Each template defines the provenance of a\ndomain-specific action in abstract form, which may then be instantiated as\nrequired by a single call to the provenance template service. As data\nreliability and trustworthiness becomes a critical issue in an increasing\nnumber of domains, there is a corresponding need to ensure that the provenance\nof that data is non-repudiable. In this paper we contribute two new,\ncomplementary modules to our template model and implementation to produce\nnon-repudiable data provenance. The first, a module that traces the operation\nof the provenance template service itself, and records a provenance trace of\nthe construction of an object-level document, at the level of individual\nservice calls. The second, a non-repudiation module that generates evidence for\nthe data recorded about each call, annotates the service trace accordingly, and\nsubmits a representation of that evidence to a provider-agnostic notary\nservice. We evaluate the applicability of our approach in the context of a\nclinical decision support system. We first define a policy to ensure the\nnon-repudiation of evidence with respect to a security threat analysis in order\nto demonstrate the suitability of our solution. We then select three use cases\nfrom within a particular system, Consult, with contrasting data provenance\nrecording requirements and analyse the subsequent performance of our prototype\nimplementation against three different notary providers.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 17:13:08 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Fairweather", "Elliot", ""], ["Wittner", "Rudolf", ""], ["Chapman", "Martin", ""], ["Holub", "Petr", ""], ["Curcin", "Vasa", ""]]}, {"id": "2006.11356", "submitter": "Stacy Hobson", "authors": "Stacy Hobson, Michael Hind, Aleksandra Mojsilovic, Kush R. Varshney", "title": "Trust and Transparency in Contact Tracing Applications", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The global outbreak of COVID-19 has led to focus on efforts to manage and\nmitigate the continued spread of the disease. One of these efforts include the\nuse of contact tracing to identify people who are at-risk of developing the\ndisease through exposure to an infected person. Historically, contact tracing\nhas been primarily manual but given the exponential spread of the virus that\ncauses COVID-19, there has been significant interest in the development and use\nof digital contact tracing solutions to supplement the work of human contact\ntracers. The collection and use of sensitive personal details by these\napplications has led to a number of concerns by the stakeholder groups with a\nvested interest in these solutions. We explore digital contact tracing\nsolutions in detail and propose the use of a transparent reporting mechanism,\nFactSheets, to provide transparency of and support trust in these applications.\nWe also provide an example FactSheet template with questions that are specific\nto the contact tracing application domain.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 20:29:24 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Hobson", "Stacy", ""], ["Hind", "Michael", ""], ["Mojsilovic", "Aleksandra", ""], ["Varshney", "Kush R.", ""]]}, {"id": "2006.11446", "submitter": "Nidhi Rastogi", "authors": "Nidhi Rastogi, Sharmishtha Dutta, Mohammed J. Zaki, Alex Gittens, and\n  Charu Aggarwal", "title": "MALOnt: An Ontology for Malware Threat Intelligence", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.16426.64962", "report-no": null, "categories": "cs.CR cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Malware threat intelligence uncovers deep information about malware, threat\nactors, and their tactics, Indicators of Compromise(IoC), and vulnerabilities\nin different platforms from scattered threat sources. This collective\ninformation can guide decision making in cyber defense applications utilized by\nsecurity operation centers(SoCs). In this paper, we introduce an open-source\nmalware ontology - MALOnt that allows the structured extraction of information\nand knowledge graph generation, especially for threat intelligence. The\nknowledge graph that uses MALOnt is instantiated from a corpus comprising\nhundreds of annotated malware threat reports. The knowledge graph enables the\nanalysis, detection, classification, and attribution of cyber threats caused by\nmalware. We also demonstrate the annotation process using MALOnt on exemplar\nthreat intelligence reports. A work in progress, this research is part of a\nlarger effort towards auto-generation of knowledge graphs (KGs)for gathering\nmalware threat intelligence from heterogeneous online resources.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 00:25:07 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Rastogi", "Nidhi", ""], ["Dutta", "Sharmishtha", ""], ["Zaki", "Mohammed J.", ""], ["Gittens", "Alex", ""], ["Aggarwal", "Charu", ""]]}, {"id": "2006.11496", "submitter": "Tzonelih Hwang", "authors": "Chun-Hao Chang, Yu-Chin Lu, Tzonelih Hwang", "title": "Measure-resend authenticated semi-quantum key distribution with single\n  photons", "comments": "10 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Yu et al. and Li et al. have proposed the measure-resend protocols of\nauthenticated semi-quantum key distribution (ASQKD). A new measure-resend ASQKD\nprotocol is proposed in this paper, which requires a lower burden of quantum\nresource, needs fewer bits of the pre-shared key, and even provides better\nqubit efficiency than their protocols. The security proof shows the robustness\nof the proposed protocol under the collective attack.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 05:03:07 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Chang", "Chun-Hao", ""], ["Lu", "Yu-Chin", ""], ["Hwang", "Tzonelih", ""]]}, {"id": "2006.11522", "submitter": "Mayra Samaniego Mrs", "authors": "Mayra Samaniego, Sara Hosseinzadeh Kassani, Cristian Espana, Ralph\n  Deters", "title": "Access Control Management for Computer-Aided Diagnosis Systems using\n  Blockchain", "comments": "5 pages, 7 figures, 1 table, 2020 IEEE International Conference on\n  Smart Internet of Things (SmartIoT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer-Aided Diagnosis (CAD) systems have emerged to support clinicians in\ninterpreting medical images. CAD systems are traditionally combined with\nartificial intelligence (AI), computer vision, and data augmentation to\nevaluate suspicious structures in medical images. This evaluation generates\nvast amounts of data. Traditional CAD systems belong to a single institution\nand handle data access management centrally. However, the advent of CAD systems\nfor research among multiple institutions demands distributed access management.\nThis research proposes a blockchain-based solution to enable distributed data\naccess management in CAD systems. This solution has been developed as a\ndistributed application (DApp) using Ethereum in a consortium network.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 08:42:20 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Samaniego", "Mayra", ""], ["Kassani", "Sara Hosseinzadeh", ""], ["Espana", "Cristian", ""], ["Deters", "Ralph", ""]]}, {"id": "2006.11601", "submitter": "Chee Seng Chan", "authors": "Lixin Fan, Kam Woh Ng, Ce Ju, Tianyu Zhang, Chang Liu, Chee Seng Chan,\n  Qiang Yang", "title": "Rethinking Privacy Preserving Deep Learning: How to Evaluate and Thwart\n  Privacy Attacks", "comments": "under review, 36 pages (updated Eq. 3 and Fig. 8)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates capabilities of Privacy-Preserving Deep Learning\n(PPDL) mechanisms against various forms of privacy attacks. First, we propose\nto quantitatively measure the trade-off between model accuracy and privacy\nlosses incurred by reconstruction, tracing and membership attacks. Second, we\nformulate reconstruction attacks as solving a noisy system of linear equations,\nand prove that attacks are guaranteed to be defeated if condition (2) is\nunfulfilled. Third, based on theoretical analysis, a novel Secret Polarization\nNetwork (SPN) is proposed to thwart privacy attacks, which pose serious\nchallenges to existing PPDL methods. Extensive experiments showed that model\naccuracies are improved on average by 5-20% compared with baseline mechanisms,\nin regimes where data privacy are satisfactorily protected.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 15:48:57 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 14:45:58 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Fan", "Lixin", ""], ["Ng", "Kam Woh", ""], ["Ju", "Ce", ""], ["Zhang", "Tianyu", ""], ["Liu", "Chang", ""], ["Chan", "Chee Seng", ""], ["Yang", "Qiang", ""]]}, {"id": "2006.11604", "submitter": "Sandesh Kamath K", "authors": "Sandesh Kamath, Amit Deshpande, K V Subrahmanyam", "title": "How do SGD hyperparameters in natural training affect adversarial\n  robustness?", "comments": "Preliminary version presented in ICML 2019 Workshop on \"Understanding\n  and Improving Generalization in Deep Learning\" as \"On Adversarial Robustness\n  of Small vs Large Batch Training\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning rate, batch size and momentum are three important hyperparameters in\nthe SGD algorithm. It is known from the work of Jastrzebski et al.\narXiv:1711.04623 that large batch size training of neural networks yields\nmodels which do not generalize well. Yao et al. arXiv:1802.08241 observe that\nlarge batch training yields models that have poor adversarial robustness. In\nthe same paper, the authors train models with different batch sizes and compute\nthe eigenvalues of the Hessian of loss function. They observe that as the batch\nsize increases, the dominant eigenvalues of the Hessian become larger. They\nalso show that both adversarial training and small-batch training leads to a\ndrop in the dominant eigenvalues of the Hessian or lowering its spectrum. They\ncombine adversarial training and second order information to come up with a new\nlarge-batch training algorithm and obtain robust models with good\ngeneralization. In this paper, we empirically observe the effect of the SGD\nhyperparameters on the accuracy and adversarial robustness of networks trained\nwith unperturbed samples. Jastrzebski et al. considered training models with a\nfixed learning rate to batch size ratio. They observed that higher the ratio,\nbetter is the generalization. We observe that networks trained with constant\nlearning rate to batch size ratio, as proposed in Jastrzebski et al., yield\nmodels which generalize well and also have almost constant adversarial\nrobustness, independent of the batch size. We observe that momentum is more\neffective with varying batch sizes and a fixed learning rate than with constant\nlearning rate to batch size ratio based SGD training.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 16:04:44 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Kamath", "Sandesh", ""], ["Deshpande", "Amit", ""], ["Subrahmanyam", "K V", ""]]}, {"id": "2006.11657", "submitter": "Rahmadi Trimananda", "authors": "Rahmadi Trimananda, Ali Younis, Thomas Kwa, Brian Demsky, and Harry Xu", "title": "Securing Smart Home Edge Devices against Compromised Cloud Servers", "comments": "This is the technical report for the poster abstract titled Poster:\n  Securing Smart Home Devices against Compromised Cloud Servers published at\n  the 3rd USENIX Workshop on Hot Topics in Edge Computing (HotEdge) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart home IoT systems often rely on cloud-based servers for communication\nbetween components. Although there exists a body of work on IoT security, most\nof it focuses on securing clients (i.e., IoT devices). However, cloud servers\ncan also be compromised. Existing approaches do not typically protect smart\nhome systems against compromised cloud servers.\n  This paper presents FIDELIUS: a runtime system for secure cloud-based storage\nand communication even in the presence of compromised servers. FIDELIUS's\ndesign is tailored for smart home systems that have intermittent Internet\naccess. In particular, it supports local control of smart home devices in the\nevent that communication with the cloud is lost, and provides a consistency\nmodel using transactions to mitigate inconsistencies that can arise due to\nnetwork partitions. We have implemented FIDELIUS, developed a smart home\nbenchmark that uses FIDELIUS, and measured FIDELIUS's performance and power\nconsumption. Our experiments show that compared to the commercial Particle.io\nframework, FIDELIUS reduces more than 50% of the data communication time and\nincreases battery life by 2X. Compared to PyORAM, an alternative (ORAM-based)\noblivious storage implementation, FIDELIUS has 4-7X faster access times with\n25-43X less data transferred.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 21:09:32 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 02:17:18 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Trimananda", "Rahmadi", ""], ["Younis", "Ali", ""], ["Kwa", "Thomas", ""], ["Demsky", "Brian", ""], ["Xu", "Harry", ""]]}, {"id": "2006.11776", "submitter": "Adel Bibi", "authors": "Modar Alfadly, Adel Bibi, Emilio Botero, Salman Alsubaihi and Bernard\n  Ghanem", "title": "Network Moments: Extensions and Sparse-Smooth Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impressive performance of deep neural networks (DNNs) has immensely\nstrengthened the line of research that aims at theoretically analyzing their\neffectiveness. This has incited research on the reaction of DNNs to noisy\ninput, namely developing adversarial input attacks and strategies that lead to\nrobust DNNs to these attacks. To that end, in this paper, we derive exact\nanalytic expressions for the first and second moments (mean and variance) of a\nsmall piecewise linear (PL) network (Affine, ReLU, Affine) subject to Gaussian\ninput. In particular, we generalize the second-moment expression of Bibi et al.\nto arbitrary input Gaussian distributions, dropping the zero-mean assumption.\nWe show that the new variance expression can be efficiently approximated\nleading to much tighter variance estimates as compared to the preliminary\nresults of Bibi et al. Moreover, we experimentally show that these expressions\nare tight under simple linearizations of deeper PL-DNNs, where we investigate\nthe effect of the linearization sensitivity on the accuracy of the moment\nestimates. Lastly, we show that the derived expressions can be used to\nconstruct sparse and smooth Gaussian adversarial attacks (targeted and\nnon-targeted) that tend to lead to perceptually feasible input attacks.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 11:36:41 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Alfadly", "Modar", ""], ["Bibi", "Adel", ""], ["Botero", "Emilio", ""], ["Alsubaihi", "Salman", ""], ["Ghanem", "Bernard", ""]]}, {"id": "2006.11801", "submitter": "Victor Kebande", "authors": "Victor R. Kebande, Joseph Bugeja, Jan A. Persson", "title": "Internet of Threats Introspection in Dynamic Intelligent Virtual Sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Continued ubiquity of communication infrastructure across Internet of Things\n(IoT) ecosystems has seen persistent advances of dynamic, intelligent,\nvirtualised sensing and actuation. This has led to effective interaction across\nthe connected ecosystem of -things. Furthermore, this has enabled the creation\nof smart environments that has created the need for the development of\ndifferent IoT protocols that support the relaying of information across\nbillions of electronic devices over the Internet. That notwithstanding, the\nphenomenon of virtual sensors that are supported by IoT technologies like\nWireless Sensor Networks (WSNs), RFID, WIFI, Bluetooth, ZigBee, IEEE 802.15.4,\netc., emulates physical sensors, and enables more efficient resource management\nthrough the dynamic allocation of virtual sensor resources. A distinctive\nexample of this has been the proposition of the Dynamic Intelligent Virtual\nSensors (DIVS). This DIVS concept is a novel proposition that allows sensing to\nbe done by the use of logical instances through the use of labeled data. This\nallows for making accurate predictions during data fusion. However, a potential\nsecurity attack on DIVS may end up providing false labels during the User\nFeedback Process (UFP), which may interfere with the accuracy of DIVS. This\npaper investigates the threat landscape in DIVS when employed in IoT\necosystems, in order to identify the extent to which the severity of these\nthreats may hinder accurate prediction of DIVS in IoT, based on labeled data.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 13:52:42 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Kebande", "Victor R.", ""], ["Bugeja", "Joseph", ""], ["Persson", "Jan A.", ""]]}, {"id": "2006.11804", "submitter": "Roba Darwish", "authors": "Roba Darwish and Kambiz Ghazinour", "title": "Photos and Tags: A Method to Evaluate Privacy Behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online Social Networking Sites attracted a massive number of users over the\npast decade but also raised privacy concerns with the amount of personal\ninformation disclosed. Studies have shown that 25% of the users are not aware\nof privacy settings provided by these sites or do not know how to change them.\nThis paper investigates an approach towards understanding users' privacy\nbehavior on social media, e.g. Facebook, through studying faces, tags and photo\nprivacy settings. It classifies users based on their privacy selections and\nproposes a system for monitoring and recommending stronger privacy settings. An\napplication is developed, and our case study examines the effectiveness of our\nmodel.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 14:03:37 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Darwish", "Roba", ""], ["Ghazinour", "Kambiz", ""]]}, {"id": "2006.11847", "submitter": "Muhammad Mustafa", "authors": "Temadher Alassiry Al-Maadeed, Iqtadar Hussain, Amir Anees, M. T.\n  Mustafa", "title": "An image encryption algorithm based on chaotic Lorenz system and novel\n  primitive polynomial S-boxes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.NT math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the chaotic cryptosystems are gaining more attention due to their\nefficiency, the assurance of robustness and high sensitivity corresponding to\ninitial conditions. In literature, on one hand there are many encryption\nalgorithms that only guarantee security while on the other hand there are\nschemes based on chaotic systems that only promise the uncertainty. Due to\nthese limitations, each of these approaches cannot adequately encounter the\nchallenges of current scenario. Here we take a unified approach and propose an\nimage encryption algorithm based on Lorenz chaotic system and primitive\nirreducible polynomial S-boxes. First, we propose 16 different S-boxes based on\nprojective general linear group and 16 primitive irreducible polynomials of\nGalois field of order 256, and then utilize these S-boxes with combination of\nchaotic map in image encryption scheme. Three chaotic sequences can be produced\nby the Lorenz chaotic system corresponding to variables $x$, $y$ and $z$. We\nconstruct a new pseudo random chaotic sequence $k_i$ based on $x$, $y$ and $z$.\nThe plain image is encrypted by the use of chaotic sequence $k_i$ and XOR\noperation to get a ciphered image. To demonstrate the strength of presented\nimage encryption, some renowned analyses as well as MATLAB simulations are\nperformed.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 16:58:00 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Al-Maadeed", "Temadher Alassiry", ""], ["Hussain", "Iqtadar", ""], ["Anees", "Amir", ""], ["Mustafa", "M. T.", ""]]}, {"id": "2006.11890", "submitter": "Zhaohan Xi", "authors": "Zhaohan Xi, Ren Pang, Shouling Ji, Ting Wang", "title": "Graph Backdoor", "comments": "USENIX Security Symposium 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One intriguing property of deep neural networks (DNNs) is their inherent\nvulnerability to backdoor attacks -- a trojan model responds to\ntrigger-embedded inputs in a highly predictable manner while functioning\nnormally otherwise. Despite the plethora of prior work on DNNs for continuous\ndata (e.g., images), the vulnerability of graph neural networks (GNNs) for\ndiscrete-structured data (e.g., graphs) is largely unexplored, which is highly\nconcerning given their increasing use in security-sensitive domains. To bridge\nthis gap, we present GTA, the first backdoor attack on GNNs. Compared with\nprior work, GTA departs in significant ways: graph-oriented -- it defines\ntriggers as specific subgraphs, including both topological structures and\ndescriptive features, entailing a large design spectrum for the adversary;\ninput-tailored -- it dynamically adapts triggers to individual graphs, thereby\noptimizing both attack effectiveness and evasiveness; downstream model-agnostic\n-- it can be readily launched without knowledge regarding downstream models or\nfine-tuning strategies; and attack-extensible -- it can be instantiated for\nboth transductive (e.g., node classification) and inductive (e.g., graph\nclassification) tasks, constituting severe threats for a range of\nsecurity-critical applications. Through extensive evaluation using benchmark\ndatasets and state-of-the-art models, we demonstrate the effectiveness of GTA.\nWe further provide analytical justification for its effectiveness and discuss\npotential countermeasures, pointing to several promising research directions.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 19:45:30 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 01:22:01 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 01:49:50 GMT"}, {"version": "v4", "created": "Tue, 23 Feb 2021 02:37:59 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Xi", "Zhaohan", ""], ["Pang", "Ren", ""], ["Ji", "Shouling", ""], ["Wang", "Ting", ""]]}, {"id": "2006.11928", "submitter": "Minhui Xue", "authors": "Jialin Wen, Benjamin Zi Hao Zhao, Minhui Xue, Alina Oprea and Haifeng\n  Qian", "title": "With Great Dispersion Comes Greater Resilience: Efficient Poisoning\n  Attacks and Defenses for Linear Regression Models", "comments": "Accepted to IEEE Transactions on Information Forensics and Security\n  (TIFS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of third parties in the machine learning pipeline, the service\nprovider in \"Machine Learning as a Service\" (MLaaS), or external data\ncontributors in online learning, or the retraining of existing models, the need\nto ensure the security of the resulting machine learning models has become an\nincreasingly important topic. The security community has demonstrated that\nwithout transparency of the data and the resulting model, there exist many\npotential security risks, with new risks constantly being discovered.\n  In this paper, we focus on one of these security risks -- poisoning attacks.\nSpecifically, we analyze how attackers may interfere with the results of\nregression learning by poisoning the training datasets. To this end, we analyze\nand develop a new poisoning attack algorithm. Our attack, termed Nopt, in\ncontrast with previous poisoning attack algorithms, can produce larger errors\nwith the same proportion of poisoning data-points. Furthermore, we also\nsignificantly improve the state-of-the-art defense algorithm, termed TRIM,\nproposed by Jagielsk et al. (IEEE S&P 2018), by incorporating the concept of\nprobability estimation of clean data-points into the algorithm. Our new defense\nalgorithm, termed Proda, demonstrates an increased effectiveness in reducing\nerrors arising from the poisoning dataset through optimizing ensemble models.\nWe highlight that the time complexity of TRIM had not been estimated; however,\nwe deduce from their work that TRIM can take exponential time complexity in the\nworst-case scenario, in excess of Proda's logarithmic time. The performance of\nboth our proposed attack and defense algorithms is extensively evaluated on\nfour real-world datasets of housing prices, loans, health care, and bike\nsharing services. We hope that our work will inspire future research to develop\nmore robust learning algorithms immune to poisoning attacks.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 22:36:42 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 06:01:18 GMT"}, {"version": "v3", "created": "Mon, 3 Aug 2020 09:16:37 GMT"}, {"version": "v4", "created": "Tue, 4 May 2021 08:06:15 GMT"}, {"version": "v5", "created": "Wed, 19 May 2021 07:51:43 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Wen", "Jialin", ""], ["Zhao", "Benjamin Zi Hao", ""], ["Xue", "Minhui", ""], ["Oprea", "Alina", ""], ["Qian", "Haifeng", ""]]}, {"id": "2006.11929", "submitter": "Lynsay Shepherd", "authors": "Harjinder Singh Lallie, Lynsay A. Shepherd, Jason R. C. Nurse, Arnau\n  Erola, Gregory Epiphaniou, Carsten Maple, Xavier Bellekens", "title": "Cyber Security in the Age of COVID-19: A Timeline and Analysis of\n  Cyber-Crime and Cyber-Attacks during the Pandemic", "comments": "20 pages, 6 figures", "journal-ref": "Computers & Security 2021", "doi": "10.1016/j.cose.2021.102248", "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic was a remarkable unprecedented event which altered the\nlives of billions of citizens globally resulting in what became commonly\nreferred to as the new-normal in terms of societal norms and the way we live\nand work. Aside from the extraordinary impact on society and business as a\nwhole, the pandemic generated a set of unique cyber-crime related circumstances\nwhich also affected society and business. The increased anxiety caused by the\npandemic heightened the likelihood of cyber-attacks succeeding corresponding\nwith an increase in the number and range of cyber-attacks.\n  This paper analyses the COVID-19 pandemic from a cyber-crime perspective and\nhighlights the range of cyber-attacks experienced globally during the pandemic.\nCyber-attacks are analysed and considered within the context of key global\nevents to reveal the modus-operandi of cyber-attack campaigns. The analysis\nshows how following what appeared to be large gaps between the initial outbreak\nof the pandemic in China and the first COVID-19 related cyber-attack, attacks\nsteadily became much more prevalent to the point that on some days, 3 or 4\nunique cyber-attacks were being reported. The analysis proceeds to utilise the\nUK as a case study to demonstrate how cyber-criminals leveraged key events and\ngovernmental announcements to carefully craft and design cyber-crime campaigns.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 22:53:47 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Lallie", "Harjinder Singh", ""], ["Shepherd", "Lynsay A.", ""], ["Nurse", "Jason R. C.", ""], ["Erola", "Arnau", ""], ["Epiphaniou", "Gregory", ""], ["Maple", "Carsten", ""], ["Bellekens", "Xavier", ""]]}, {"id": "2006.11946", "submitter": "Daniel Genkin", "authors": "Takeshi Sugawara, Benjamin Cyr, Sara Rampazzi, Daniel Genkin, Kevin Fu", "title": "Light Commands: Laser-Based Audio Injection Attacks on\n  Voice-Controllable Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new class of signal injection attacks on microphones by\nphysically converting light to sound. We show how an attacker can inject\narbitrary audio signals to a target microphone by aiming an amplitude-modulated\nlight at the microphone's aperture. We then proceed to show how this effect\nleads to a remote voice-command injection attack on voice-controllable systems.\nExamining various products that use Amazon's Alexa, Apple's Siri, Facebook's\nPortal, and Google Assistant, we show how to use light to obtain control over\nthese devices at distances up to 110 meters and from two separate buildings.\nNext, we show that user authentication on these devices is often lacking,\nallowing the attacker to use light-injected voice commands to unlock the\ntarget's smartlock-protected front doors, open garage doors, shop on e-commerce\nwebsites at the target's expense, or even unlock and start various vehicles\nconnected to the target's Google account (e.g., Tesla and Ford). Finally, we\nconclude with possible software and hardware defenses against our attacks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 00:07:57 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Sugawara", "Takeshi", ""], ["Cyr", "Benjamin", ""], ["Rampazzi", "Sara", ""], ["Genkin", "Daniel", ""], ["Fu", "Kevin", ""]]}, {"id": "2006.11996", "submitter": "Rasoul Jahanshahi", "authors": "Rasoul Jahanshahi, Adam Doup\\'e, Manuel Egele", "title": "You shall not pass: Mitigating SQL Injection Attacks on Legacy Web\n  Applications", "comments": "Accepted in ASIACCS 2020", "journal-ref": null, "doi": "10.1145/3320269.3384760", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SQL injection (SQLi) attacks pose a significant threat to the security of web\napplications. Existing approaches do not support object-oriented programming\nthat renders these approaches unable to protect the real-world web apps such as\nWordpress, Joomla, or Drupal against SQLi attacks. We propose a novel hybrid\nstatic-dynamic analysis for PHP web applications that limits each PHP function\nfor accessing the database. Our tool, SQLBlock, reduces the attack surface of\nthe vulnerable PHP functions in a web application to a set of query descriptors\nthat demonstrate the benign functionality of the PHP function. We implement\nSQLBlock as a plugin for MySQL and PHP. Our approach does not require any\nmodification to the web app. W evaluate SQLBlock on 11 SQLi vulnerabilities in\nWordpress, Joomla, Drupal, Magento, and their plugins. We demonstrate that\nSQLBlock successfully prevents all 11 SQLi exploits with negligible performance\noverhead (i.e., a maximum of 3% on a heavily-loaded web server)\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 04:01:42 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 22:52:55 GMT"}, {"version": "v3", "created": "Sun, 12 Jul 2020 00:45:47 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Jahanshahi", "Rasoul", ""], ["Doup\u00e9", "Adam", ""], ["Egele", "Manuel", ""]]}, {"id": "2006.12018", "submitter": "Pratiksha Thaker", "authors": "Pratiksha Thaker and Mihai Budiu and Parikshit Gopalan and Udi Wieder\n  and Matei Zaharia", "title": "Overlook: Differentially Private Exploratory Visualization for Big Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data exploration systems that provide differential privacy must manage a\nprivacy budget that measures the amount of privacy lost across multiple\nqueries. One effective strategy to manage the privacy budget is to compute a\none-time private synopsis of the data, to which users can make an unlimited\nnumber of queries. However, existing systems using synopses are built for\noffline use cases, where a set of queries is known ahead of time and the system\ncarefully optimizes a synopsis for it. The synopses that these systems build\nare costly to compute and may also be costly to store.\n  We introduce Overlook, a system that enables private data exploration at\ninteractive latencies for both data analysts and data curators. The key idea in\nOverlook is a virtual synopsis that can be evaluated incrementally, without\nextra space storage or expensive precomputation. Overlook simply executes\nqueries using an existing engine, such as a SQL DBMS, and adds noise to their\nresults. Because Overlook's synopses do not require costly precomputation or\nstorage, data curators can also use Overlook to explore the impact of privacy\nparameters interactively. Overlook offers a rich visual query interface based\non the open source Hillview system. Overlook achieves accuracy comparable to\nexisting synopsis-based systems, while offering better performance and removing\nthe need for extra storage.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 05:56:16 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Thaker", "Pratiksha", ""], ["Budiu", "Mihai", ""], ["Gopalan", "Parikshit", ""], ["Wieder", "Udi", ""], ["Zaharia", "Matei", ""]]}, {"id": "2006.12031", "submitter": "Itay Tsabary", "authors": "Itay Tsabary, Matan Yechieli, Alex Manuskin, Ittay Eyal", "title": "MAD-HTLC: Because HTLC is Crazy-Cheap to Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart Contracts and transactions allow users to implement elaborate\nconstructions on cryptocurrency blockchains like Bitcoin and Ethereum. Many of\nthese constructions, including operational payment channels and atomic swaps,\nuse a building block called Hashed Time-Locked Contract (HTLC).\n  In this work, we distill from HTLC a specification (HTLC-Spec), and present\nan implementation called Mutual-Assured-Destruction Hashed Time-Locked Contract\n(MAD-HTLC). MAD-HTLC employs a novel approach of utilizing the existing\nblockchain operators, called miners, as part of the design. If a user\nmisbehaves, MAD-HTLC incentivizes the miners to confiscate all her funds. We\nprove MAD-HTLC's security using the UC framework and game-theoretic analysis.\nWe demonstrate MAD-HTLC's efficacy and analyze its overhead by instantiating it\non Bitcoin's and Ethereum's operational blockchains.\n  Notably, current miner software makes only little effort to optimize revenue,\nsince the advantage is relatively small. However, as the demand grows and other\nrevenue components shrink, miners are more motivated to fully optimize their\nfund intake. By patching the standard Bitcoin client, we demonstrate such\noptimization is easy to implement, making the miners natural enforcers of\nMAD-HTLC.\n  Finally, we extend previous results regarding HTLC vulnerability to bribery\nattacks. An attacker can incentivize miners to prefer her transactions by\noffering high transaction fees. We demonstrate this attack can be easily\nimplemented by patching the Bitcoin client, and use game-theoretic tools to\nqualitatively tighten the known cost bound of such bribery attacks in presence\nof rational miners. We identify bribe opportunities occurring on the Bitcoin\nand Ethereum main networks where a few dollars bribe could yield tens of\nthousands of dollars in reward (e.g., \\$2 for over \\$25K).\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 06:58:24 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 12:14:36 GMT"}, {"version": "v3", "created": "Thu, 25 Mar 2021 09:59:57 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Tsabary", "Itay", ""], ["Yechieli", "Matan", ""], ["Manuskin", "Alex", ""], ["Eyal", "Ittay", ""]]}, {"id": "2006.12047", "submitter": "Kevin Morio", "authors": "Kevin Morio, Robert K\\\"unnemann", "title": "Verifying Accountability for Unbounded Sets of Participants", "comments": "22 pages, Full version of the corresponding CSF 2021 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Little can be achieved in the design of security protocols without trusting\nat least some participants. This trust should be justified or, at the very\nleast, subject to examination. One way to strengthen trustworthiness is to hold\nparties accountable for their actions, as this provides a strong incentive to\nrefrain from malicious behavior. This has led to an increased interest in\naccountability in the design of security protocols.\n  In this work, we combine the accountability definition of K\\\"unnemann,\nEsiyok, and Backes, with the notion of case tests to extend its applicability\nto protocols with unbounded sets of participants. We propose a general\nconstruction of verdict functions and a set of verification conditions that\nachieve soundness and completeness.\n  Expressing the verification conditions in terms of trace properties allows us\nto extend Tamarin -- a protocol verification tool -- with the ability to\nanalyze and verify accountability properties in a highly automated way. In\ncontrast to prior work, our approach is significantly more flexible and\napplicable to a wider range of protocols.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 07:43:18 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 20:16:00 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Morio", "Kevin", ""], ["K\u00fcnnemann", "Robert", ""]]}, {"id": "2006.12056", "submitter": "Joseph O. Eichenhofer", "authors": "Joseph O. Eichenhofer and Elisa Heymann and Barton P. Miller and\n  Arnold Kang", "title": "An In-Depth Security Assessment of Maritime Container Terminal Software\n  Systems", "comments": "18 pages, 9 figures, submitted to IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attacks on software systems occur world-wide on a daily basis targeting\nindividuals, corporations, and governments alike. The systems that facilitate\nmaritime shipping are at risk of serious disruptions, and these disruptions can\nstem from vulnerabilities in the software and processes used in these systems.\nThese vulnerabilities leave such systems open to cyber-attack. Assessments of\nthe security of maritime shipping systems have focused on identifying risks but\nhave not taken the critical (and expensive) next step of actually identifying\nvulnerabilities present in these systems. While such risk assessments are\nimportant, they have not provided the detailed identification of security\nissues in the systems that control these ports and their terminals. In\nresponse, we formed a key collaboration between an experienced academic\ncybersecurity team and a well-known commercial software provider that manages\nmaritime shipping. We performed an analysis of the information flow involved in\nthe maritime shipping process, and then executed an in-depth vulnerability\nassessment of the software that manages freight systems. In this paper, we show\nthe flow of information involved in the freight shipping process and explain\nhow we performed the in-depth assessment, summarizing our findings. Like every\nlarge software system, maritime shipping systems have vulnerabilities.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 08:12:38 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Eichenhofer", "Joseph O.", ""], ["Heymann", "Elisa", ""], ["Miller", "Barton P.", ""], ["Kang", "Arnold", ""]]}, {"id": "2006.12069", "submitter": "Leonardo Horn Iwaya", "authors": "Leonardo Horn Iwaya, Aakash Ahmad, M. Ali Babar", "title": "Security and Privacy for mHealth and uHealth Systems: a Systematic\n  Mapping Study", "comments": "29 pages, 10 figures, in IEEE Access, 2020", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3015962", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increased adoption of mobile health (mHealth) and ubiquitous health\n(uHealth) systems empower users with handheld devices and embedded sensors for\na broad range of healthcare services. However, m/uHealth systems face\nsignificant challenges related to data security and privacy that must be\naddressed to increase the pervasiveness of such systems. This study aims to\nsystematically identify, classify, compare, and evaluate state-of-the-art on\nsecurity and privacy of m/uHealth systems. We conducted a systematic mapping\nstudy (SMS) based on 365 qualitatively selected studies to (i) classify the\ntypes, frequency, and demography of published research and (ii) synthesize and\ncategorize research themes, (iii) recurring challenges, (iv) prominent\nsolutions (i.e., research outcomes) and their (v) reported evaluations (i.e.,\npractical validations). Results suggest that the existing research on security\nand privacy of m/uHealth systems primarily focuses on select group of control\nfamilies (compliant with NIST800-53), protection of systems and information,\naccess control, authentication, individual participation, and privacy\nauthorisation. In contrast, areas of data governance, security and privacy\npolicies, and program management are under-represented, although these are\ncritical to most of the organizations that employ m/uHealth systems. Most\nresearch proposes new solutions with limited validation, reflecting a lack of\nevaluation of security and privacy of m/uHealth in the real world. Empirical\nresearch, development, and validation of m/uHealth security and privacy is\nstill incipient, which may discourage practitioners from readily adopting\nsolutions from the literature. This SMS facilitates knowledge transfer,\nenabling researchers and practitioners to engineer security and privacy for\nemerging and next generation of m/uHealth systems.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 08:44:49 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Iwaya", "Leonardo Horn", ""], ["Ahmad", "Aakash", ""], ["Babar", "M. Ali", ""]]}, {"id": "2006.12101", "submitter": "Tsubasa Takahashi", "authors": "Shun Takagi, Tsubasa Takahashi, Yang Cao, Masatoshi Yoshikawa", "title": "P3GM: Private High-Dimensional Data Release via Privacy Preserving\n  Phased Generative Model", "comments": "Accepted at ICDE 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we release a massive volume of sensitive data while mitigating\nprivacy risks? Privacy-preserving data synthesis enables the data holder to\noutsource analytical tasks to an untrusted third party. The state-of-the-art\napproach for this problem is to build a generative model under differential\nprivacy, which offers a rigorous privacy guarantee. However, the existing\nmethod cannot adequately handle high dimensional data. In particular, when the\ninput dataset contains a large number of features, the existing techniques\nrequire injecting a prohibitive amount of noise to satisfy differential\nprivacy, which results in the outsourced data analysis meaningless. To address\nthe above issue, this paper proposes privacy-preserving phased generative model\n(P3GM), which is a differentially private generative model for releasing such\nsensitive data. P3GM employs the two-phase learning process to make it robust\nagainst the noise, and to increase learning efficiency (e.g., easy to\nconverge). We give theoretical analyses about the learning complexity and\nprivacy loss in P3GM. We further experimentally evaluate our proposed method\nand demonstrate that P3GM significantly outperforms existing solutions.\nCompared with the state-of-the-art methods, our generated samples look fewer\nnoises and closer to the original data in terms of data diversity. Besides, in\nseveral data mining tasks with synthesized data, our model outperforms the\ncompetitors in terms of accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 09:47:54 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 01:51:02 GMT"}, {"version": "v3", "created": "Wed, 4 Nov 2020 07:52:58 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Takagi", "Shun", ""], ["Takahashi", "Tsubasa", ""], ["Cao", "Yang", ""], ["Yoshikawa", "Masatoshi", ""]]}, {"id": "2006.12135", "submitter": "Divyam Madaan", "authors": "Divyam Madaan, Jinwoo Shin, Sung Ju Hwang", "title": "Learning to Generate Noise for Multi-Attack Robustness", "comments": "Accepted to ICML 2021. Code available at\n  https://github.com/divyam3897/MNG_AC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial learning has emerged as one of the successful techniques to\ncircumvent the susceptibility of existing methods against adversarial\nperturbations. However, the majority of existing defense methods are tailored\nto defend against a single category of adversarial perturbation (e.g.\n$\\ell_\\infty$-attack). In safety-critical applications, this makes these\nmethods extraneous as the attacker can adopt diverse adversaries to deceive the\nsystem. Moreover, training on multiple perturbations simultaneously\nsignificantly increases the computational overhead during training. To address\nthese challenges, we propose a novel meta-learning framework that explicitly\nlearns to generate noise to improve the model's robustness against multiple\ntypes of attacks. Its key component is Meta Noise Generator (MNG) that outputs\noptimal noise to stochastically perturb a given sample, such that it helps\nlower the error on diverse adversarial perturbations. By utilizing samples\ngenerated by MNG, we train a model by enforcing the label consistency across\nmultiple perturbations. We validate the robustness of models trained by our\nscheme on various datasets and against a wide variety of perturbations,\ndemonstrating that it significantly outperforms the baselines across multiple\nperturbations with a marginal computational cost.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 10:44:05 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 17:36:33 GMT"}, {"version": "v3", "created": "Sun, 20 Jun 2021 06:47:26 GMT"}, {"version": "v4", "created": "Thu, 24 Jun 2021 18:41:57 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Madaan", "Divyam", ""], ["Shin", "Jinwoo", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "2006.12143", "submitter": "Elias Rohrer", "authors": "Elias Rohrer and Florian Tschorsch", "title": "Counting Down Thunder: Timing Attacks on Privacy in Payment Channel\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lightning Network is a scaling solution for Bitcoin that promises to\nenable rapid and private payment processing. In Lightning, multi-hop payments\nare secured by utilizing Hashed Time-Locked Contracts (HTLCs) and encrypted on\nthe network layer by an onion routing scheme to avoid information leakage to\nintermediate nodes. In this work, we however show that the privacy guarantees\nof the Lightning Network may be subverted by an on-path adversary conducting\ntiming attacks on the HTLC state negotiation messages. To this end, we provide\nestimators that enable an adversary to reduce the anonymity set and infer the\nlikeliest payment endpoints. We developed a proof-of-concept measurement node\nthat shows the feasibility of attaining time differences and evaluate the\nadversarial success in model-based network simulations. We find that\ncontrolling a small number malicious nodes is sufficient to observe a large\nshare of all payments, emphasizing the relevance of the on-path adversary\nmodel. Moreover, we show that adversaries of different magnitudes could employ\ntiming-based attacks to deanonymize payment endpoints with high precision and\nrecall.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 11:06:57 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Rohrer", "Elias", ""], ["Tschorsch", "Florian", ""]]}, {"id": "2006.12239", "submitter": "Daniel Katz", "authors": "Tor Helleseth, Daniel J. Katz, and Chunlei Li", "title": "The resolution of Niho's last conjecture concerning sequences, codes,\n  and Boolean functions", "comments": "27 pages; Sage code with verification of decomposition in Lemma 5.2\n  included as an ancillary file", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CR cs.IT math.CO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new method is used to resolve a long-standing conjecture of Niho concerning\nthe crosscorrelation spectrum of a pair of maximum length linear recursive\nsequences of length $2^{2 m}-1$ with relative decimation $d=2^{m+2}-3$, where\n$m$ is even. The result indicates that there are at most five distinct\ncrosscorrelation values. Equivalently, the result indicates that there are at\nmost five distinct values in the Walsh spectrum of the power permutation\n$f(x)=x^d$ over a finite field of order $2^{2 m}$ and at most five distinct\nnonzero weights in the cyclic code of length $2^{2 m}-1$ with two primitive\nnonzeros $\\alpha$ and $\\alpha^d$. The method used to obtain this result proves\nconstraints on the number of roots that certain seventh degree polynomials can\nhave on the unit circle of a finite field. The method also works when $m$ is\nodd, in which case the associated crosscorrelation and Walsh spectra have at\nmost six distinct values.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 13:35:47 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 18:04:39 GMT"}, {"version": "v3", "created": "Fri, 5 Mar 2021 00:02:19 GMT"}, {"version": "v4", "created": "Thu, 8 Jul 2021 20:54:16 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Helleseth", "Tor", ""], ["Katz", "Daniel J.", ""], ["Li", "Chunlei", ""]]}, {"id": "2006.12247", "submitter": "Eran Segalis", "authors": "Eran Segalis, Eran Galili", "title": "OGAN: Disrupting Deepfakes with an Adversarial Attack that Survives\n  Training", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in autoencoders and generative models have given rise to\neffective video forgery methods, used for generating so-called \"deepfakes\".\nMitigation research is mostly focused on post-factum deepfake detection and not\non prevention. We complement these efforts by introducing a novel class of\nadversarial attacks---training-resistant attacks---which can disrupt\nface-swapping autoencoders whether or not its adversarial images have been\nincluded in the training set of said autoencoders. We propose the Oscillating\nGAN (OGAN) attack, a novel attack optimized to be training-resistant, which\nintroduces spatial-temporal distortions to the output of face-swapping\nautoencoders. To implement OGAN, we construct a bilevel optimization problem,\nwhere we train a generator and a face-swapping model instance against each\nother. Specifically, we pair each input image with a target distortion, and\nfeed them into a generator that produces an adversarial image. This image will\nexhibit the distortion when a face-swapping autoencoder is applied to it. We\nsolve the optimization problem by training the generator and the face-swapping\nmodel simultaneously using an iterative process of alternating optimization.\nNext, we analyze the previously published Distorting Attack and show it is\ntraining-resistant, though it is outperformed by our suggested OGAN. Finally,\nwe validate both attacks using a popular implementation of FaceSwap, and show\nthat they transfer across different target models and target faces, including\nfaces the adversarial attacks were not trained on. More broadly, these results\ndemonstrate the existence of training-resistant adversarial attacks,\npotentially applicable to a wide range of domains.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 17:18:29 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 11:47:30 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Segalis", "Eran", ""], ["Galili", "Eran", ""]]}, {"id": "2006.12306", "submitter": "Sangjun Park", "authors": "Sangjun Park, Haeung Choi and Heung-No Lee", "title": "Time-Variant Proof-of-Work Using Error-Correction Codes", "comments": "13pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The protocol for cryptocurrencies can be divided into three parts, namely\nconsensus, wallet, and networking overlay. The aim of the consensus part is to\nbring trustless rational peer-to-peer nodes to an agreement to the current\nstatus of the blockchain. The status must be updated through valid\ntransactions. A proof-of-work (PoW) based consensus mechanism has been proven\nto be secure and robust owing to its simple rule and has served as a firm\nfoundation for cryptocurrencies such as Bitcoin and Ethereum. Specialized\nmining devices have emerged, as rational miners aim to maximize profit, and\ncaused two problems: i) the re-centralization of a mining market and ii) the\nhuge energy spending in mining. In this paper, we aim to propose a new PoW\ncalled Error-Correction Codes PoW (ECCPoW) where the error-correction codes and\ntheir decoder can be utilized for PoW. In ECCPoW, puzzles can be intentionally\ngenerated to vary from block to block, leading to a time-variant puzzle\ngeneration mechanism. This mechanism is useful in repressing the emergence of\nthe specialized mining devices. It can serve as a solution to the two problems\nof recentralization and energy spending.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 14:38:19 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Park", "Sangjun", ""], ["Choi", "Haeung", ""], ["Lee", "Heung-No", ""]]}, {"id": "2006.12338", "submitter": "Vladimir Dvorkin", "authors": "Vladimir Dvorkin and Ferdinando Fioretto and Pascal Van Hentenryck and\n  Jalal Kazempour and Pierre Pinson", "title": "Differentially Private Convex Optimization with Feasibility Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper develops a novel differentially private framework to solve convex\noptimization problems with sensitive optimization data and complex physical or\noperational constraints. Unlike standard noise-additive algorithms, that act\nprimarily on the problem data, objective or solution, and disregard the problem\nconstraints, this framework requires the optimization variables to be a\nfunction of the noise and exploits a chance-constrained problem reformulation\nwith formal feasibility guarantees. The noise is calibrated to provide\ndifferential privacy for identity and linear queries on the optimization\nsolution. For many applications, including resource allocation problems, the\nproposed framework provides a trade-off between the expected optimality loss\nand the variance of optimization results.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 15:30:52 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Dvorkin", "Vladimir", ""], ["Fioretto", "Ferdinando", ""], ["Van Hentenryck", "Pascal", ""], ["Kazempour", "Jalal", ""], ["Pinson", "Pierre", ""]]}, {"id": "2006.12352", "submitter": "Ashutosh Bhatia Dr.", "authors": "Ashutosh Bhatiaa, Ankit AgrawalaAyush Bahugunaa, Kamlesh Tiwaria, K.\n  Haribabua, Deepak Vishwakarmab", "title": "A Survey on Analyzing Encrypted Network Traffic of Mobile Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the years, use of smartphones has come to dominate several areas,\nimproving our lives, offering us convenience, and reshaping our daily work\ncircumstances. Beyond traditional use for communication, they are used for many\nperipheral tasks such as gaming, browsing, and shopping. A significant amount\nof traffic over the Internet belongs to the applications running over mobile\ndevices. Applications encrypt their communication to ensure the privacy and\nsecurity of the user's data. However, it has been found that the amount and\nnature of incoming and outgoing traffic to a mobile device could reveal a\nsignificant amount of information that can be used to identify the activities\nperformed and to profile the user. To that end, researchers are trying to\ndevelop techniques to classify encrypted mobile traffic at different levels of\ngranularity, with the objectives of performing mobile user profiling, network\nperformance optimization, $etc.$ This paper proposes a framework to categorize\nthe research works on analyzing encrypted network traffic related to mobile\ndevices. After that, we provide an extensive review of state of the art based\non the proposed framework.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 15:49:45 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Bhatiaa", "Ashutosh", ""], ["Bahugunaa", "Ankit AgrawalaAyush", ""], ["Tiwaria", "Kamlesh", ""], ["Haribabua", "K.", ""], ["Vishwakarmab", "Deepak", ""]]}, {"id": "2006.12388", "submitter": "Ariah Klages-Mundt", "authors": "Ariah Klages-Mundt, Dominik Harz, Lewis Gudgeon, Jun-You Liu, Andreea\n  Minca", "title": "Stablecoins 2.0: Economic Foundations and Risk-based Models", "comments": null, "journal-ref": null, "doi": "10.1145/3419614.3423261", "report-no": null, "categories": "econ.GN cs.CR cs.MA q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stablecoins are one of the most widely capitalized type of cryptocurrency.\nHowever, their risks vary significantly according to their design and are often\npoorly understood. We seek to provide a sound foundation for stablecoin theory,\nwith a risk-based functional characterization of the economic structure of\nstablecoins. First, we match existing economic models to the disparate set of\ncustodial systems. Next, we characterize the unique risks that emerge in\nnon-custodial stablecoins and develop a model framework that unifies existing\nmodels from economics and computer science. We further discuss how this\nmodeling framework is applicable to a wide array of cryptoeconomic systems,\nincluding cross-chain protocols, collateralized lending, and decentralized\nexchanges. These unique risks yield unanswered research questions that will\nform the crux of research in decentralized finance going forward.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 16:17:58 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 17:30:15 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 01:27:48 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Klages-Mundt", "Ariah", ""], ["Harz", "Dominik", ""], ["Gudgeon", "Lewis", ""], ["Liu", "Jun-You", ""], ["Minca", "Andreea", ""]]}, {"id": "2006.12555", "submitter": "Karthika Subramani", "authors": "Karthika Subramani, Roberto Perdisci and Maria Konte", "title": "IXmon: Detecting and Analyzing DRDoS Attacks at Internet Exchange Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed reflective denial of service (DRDoS) attacks are a popular choice\namong adversaries. In fact, one of the largest DDoS attacks ever recorded,\nreaching a peak of 1.3Tbps against GitHub, was a memcached-based DRDoS attack.\nMore recently, a record-breaking 2.3Tbps attack against Amazon AWS was due to a\nCLDAP-based DRDoS attack. Although reflective attacks have been known for\nyears, DRDoS attacks are unfortunately still popular and largely unmitigated.\nIn this paper, we study in-the-wild DRDoS attacks observed from a large\nInternet exchange point (IXP) and provide a number of security-relevant\nmeasurements and insights.\n  To enable this study, we first developed IXmon, an open-source DRDoS\ndetection system specifically designed for deployment at large IXP-like network\nconnectivity providers and peering hubs. We deployed IXmon at Southern\nCrossroads (SoX), an IXP-like hub that provides both peering and upstream\nInternet connectivity services to more than 20 research and education (R&E)\nnetworks in the South-East United States. In a period of about 21 months, IXmon\ndetected more than 900 DRDoS attacks towards 31 different victim ASes. An\nanalysis of the real-world DRDoS attacks detected by our system shows that most\nDRDoS attacks are short lived, lasting only a few minutes, but that\nlarge-volume, long-lasting, and highly-distributed attacks against R&E networks\nare not uncommon. We then use the results of our analysis to discuss possible\nattack mitigation approaches that can be deployed at the IXP level, before the\nattack traffic overwhelms the victim's network bandwidth.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 18:31:01 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 17:32:52 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Subramani", "Karthika", ""], ["Perdisci", "Roberto", ""], ["Konte", "Maria", ""]]}, {"id": "2006.12557", "submitter": "Avi Schwarzschild", "authors": "Avi Schwarzschild, Micah Goldblum, Arjun Gupta, John P Dickerson, Tom\n  Goldstein", "title": "Just How Toxic is Data Poisoning? A Unified Benchmark for Backdoor and\n  Data Poisoning Attacks", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data poisoning and backdoor attacks manipulate training data in order to\ncause models to fail during inference. A recent survey of industry\npractitioners found that data poisoning is the number one concern among threats\nranging from model stealing to adversarial attacks. However, it remains unclear\nexactly how dangerous poisoning methods are and which ones are more effective\nconsidering that these methods, even ones with identical objectives, have not\nbeen tested in consistent or realistic settings. We observe that data poisoning\nand backdoor attacks are highly sensitive to variations in the testing setup.\nMoreover, we find that existing methods may not generalize to realistic\nsettings. While these existing works serve as valuable prototypes for data\npoisoning, we apply rigorous tests to determine the extent to which we should\nfear them. In order to promote fair comparison in future work, we develop\nstandardized benchmarks for data poisoning and backdoor attacks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 18:34:08 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 21:59:59 GMT"}, {"version": "v3", "created": "Thu, 17 Jun 2021 14:10:57 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Schwarzschild", "Avi", ""], ["Goldblum", "Micah", ""], ["Gupta", "Arjun", ""], ["Dickerson", "John P", ""], ["Goldstein", "Tom", ""]]}, {"id": "2006.12665", "submitter": "Chaitanya Prakash Bapat", "authors": "Chaitanya Bapat", "title": "Blockchain for Academic Credentials", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Academic credentials are documents that attest to successful completion of\nany test, exam or act as a validation of an individual's skill. Currently, the\ndomain of academic credential management suffers from large time consumption,\nhigh cost, dependence on third-party and a lack of transparency. A blockchain\nbased solution tries to resolve these pain-points by allowing any recruiter or\ncompany to verify the user credentials without dependence on any centralized\nthird party. Our decentralized application is based off of BlockCerts, an MIT\nproject that acts as an open standard for blockchain credentials. The project\ntalks about the implementation details of the decentralized application built\nfor BlockCerts Wallet. It is an attempt to leverage the power of the blockchain\ntechnology as a global notary for the verification of digital records.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 23:42:20 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Bapat", "Chaitanya", ""]]}, {"id": "2006.12698", "submitter": "Saichethan Reddy", "authors": "Saichethan Miriyala Reddy and Saisree Miriyala", "title": "Security and Privacy Preserving Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commercial companies that collect user data on a large scale have been the\nmain beneficiaries of this trend since the success of deep learning techniques\nis directly proportional to the amount of data available for training. Massive\ndata collection required for deep learning presents obvious privacy issues.\nUsers personal, highly sensitive data such as photos and voice recordings are\nkept indefinitely by the companies that collect it. Users can neither delete it\nnor restrict the purposes for which it is used. So, data privacy has been a\nvery important concern for governments and companies these days. It gives rise\nto a very interesting challenge since on the one hand, we are pushing further\nand further for high-quality models and accessible data, but on the other hand,\nwe need to keep data safe from both intentional and accidental leakage. The\nmore personal the data is it is more restricted it means some of the most\nimportant social issues cannot be addressed using machine learning because\nresearchers do not have access to proper training data. But by learning how to\nmachine learning that protects privacy we can make a huge difference in solving\nmany social issues like curing disease etc. Deep neural networks are\nsusceptible to various inference attacks as they remember information about\ntheir training data. In this chapter, we introduce differential privacy, which\nensures that different kinds of statistical analyses dont compromise privacy\nand federated learning, training a machine learning model on a data to which we\ndo not have access to.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 01:53:46 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 09:34:12 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Reddy", "Saichethan Miriyala", ""], ["Miriyala", "Saisree", ""]]}, {"id": "2006.12784", "submitter": "Yueqiang Cheng", "authors": "Yuankun Zhu, Yueqiang Cheng, Husheng Zhou, Yantao Lu", "title": "Hermes Attack: Steal DNN Models with Lossless Inference Accuracy", "comments": "The paper will appear in Usenix Security Symposium 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) models become one of the most valuable enterprise\nassets due to their critical roles in all aspects of applications. With the\ntrend of privatization deployment of DNN models, the data leakage of the DNN\nmodels is becoming increasingly serious and widespread. All existing\nmodel-extraction attacks can only leak parts of targeted DNN models with low\naccuracy or high overhead. In this paper, we first identify a new attack\nsurface -- unencrypted PCIe traffic, to leak DNN models. Based on this new\nattack surface, we propose a novel model-extraction attack, namely Hermes\nAttack, which is the first attack to fully steal the whole victim DNN model.\nThe stolen DNN models have the same hyper-parameters, parameters, and\nsemantically identical architecture as the original ones. It is challenging due\nto the closed-source CUDA runtime, driver, and GPU internals, as well as the\nundocumented data structures and the loss of some critical semantics in the\nPCIe traffic. Additionally, there are millions of PCIe packets with numerous\nnoises and chaos orders. Our Hermes Attack addresses these issues by huge\nreverse engineering efforts and reliable semantic reconstruction, as well as\nskillful packet selection and order correction. We implement a prototype of the\nHermes Attack, and evaluate two sequential DNN models (i.e., MINIST and VGG)\nand one consequential DNN model (i.e., ResNet) on three NVIDIA GPU platforms,\ni.e., NVIDIA Geforce GT 730, NVIDIA Geforce GTX 1080 Ti, and NVIDIA Geforce RTX\n2080 Ti. The evaluation results indicate that our scheme is able to efficiently\nand completely reconstruct ALL of them with making inferences on any one image.\nEvaluated with Cifar10 test dataset that contains 10,000 images, the experiment\nresults show that the stolen models have the same inference accuracy as the\noriginal ones (i.e., lossless inference accuracy).\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 06:38:01 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 16:21:57 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Zhu", "Yuankun", ""], ["Cheng", "Yueqiang", ""], ["Zhou", "Husheng", ""], ["Lu", "Yantao", ""]]}, {"id": "2006.12810", "submitter": "Unai Rioja", "authors": "Unai Rioja, Servio Paguada, Lejla Batina and Igor Armendariz", "title": "The uncertainty of Side-Channel Analysis: A way to leverage from\n  heuristics", "comments": "30 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performing a comprehensive side-channel analysis evaluation of small embedded\ndevices is a process known for its variability and complexity. In real-world\nexperimental setups, the results are largely influenced by a huge amount of\nparameters that are not easily adjusted without trial and error and are heavily\nrelying on the experience of professional security analysts. In this paper, we\nadvocate the use of an existing statistical methodology called Six Sigma\n(6{\\sigma}) for side-channel analysis optimization for this purpose. This\nwell-known methodology is commonly used in other industrial fields, such as\nproduction and quality engineering, to reduce the variability of industrial\nprocesses. We propose a customized Six Sigma methodology, which enables even a\nless-experienced security analysis to select optimal values for the different\nvariables that are critical for the side-channel analysis procedure. Moreover,\nwe show how our methodology helps in improving different phases in the\nside-channel analysis process.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 08:00:57 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Rioja", "Unai", ""], ["Paguada", "Servio", ""], ["Batina", "Lejla", ""], ["Armendariz", "Igor", ""]]}, {"id": "2006.12831", "submitter": "Yupeng Hu", "authors": "Yupeng Hu, Zhe Jin, Wenjia Li, Yang Xiang, Jiliang Zhang", "title": "SIAT: A Systematic Inter-Component Communication Analysis Technology for\n  Detecting Threats on Android", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the design and implementation of a Systematic\nInter-Component Communication Analysis Technology (SIAT) consisting of two key\nmodules: \\emph{Monitor} and \\emph{Analyzer}. As an extension to the Android\noperating system at framework layer, the \\emph{Monitor} makes the first attempt\nto revise the taint tag approach named TaintDroid both at method-level and\nfile-level, to migrate it to the app-pair ICC paths identification through\nsystemwide tracing and analysis of taint in intent both at the data flow and\ncontrol flow. By taking over the taint logs offered by the \\emph{Monitor}, the\n\\emph{Analyzer} can build the accurate and integrated ICC models adopted to\nidentify the specific threat models with the detection algorithms and\npredefined rules. Meanwhile, we employ the models' deflation technology to\nimprove the efficiency of the \\emph{Analyzer}. We implement the SIAT with\nAndroid Open Source Project and evaluate its performance through extensive\nexperiments on well-known datasets and real-world apps. The experimental\nresults show that, compared to state-of-the-art approaches, the SIAT can\nachieve about 25\\%$\\sim$200\\% accuracy improvements with 1.0 precision and 0.98\nrecall at the cost of negligible runtime overhead. Moreover, the SIAT can\nidentify two undisclosed cases of bypassing that prior technologies cannot\ndetect and quite a few malicious ICC threats in real-world apps with lots of\ndownloads on the Google Play market.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 08:47:34 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Hu", "Yupeng", ""], ["Jin", "Zhe", ""], ["Li", "Wenjia", ""], ["Xiang", "Yang", ""], ["Zhang", "Jiliang", ""]]}, {"id": "2006.12834", "submitter": "Francesco Croce", "authors": "Francesco Croce, Maksym Andriushchenko, Naman D. Singh, Nicolas\n  Flammarion, Matthias Hein", "title": "Sparse-RS: a versatile framework for query-efficient sparse black-box\n  adversarial attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse adversarial perturbations received much less attention in the\nliterature compared to $l_2$- and $l_\\infty$-attacks. However, it is equally\nimportant to accurately assess the robustness of a model against sparse\nperturbations. Motivated by this goal, we propose a versatile framework based\non random search, Sparse-RS, for score-based sparse targeted and untargeted\nattacks in the black-box setting. Sparse-RS does not rely on substitute models\nand achieves state-of-the-art success rate and query efficiency for multiple\nsparse attack models: $l_0$-bounded perturbations, adversarial patches, and\nadversarial frames. Unlike existing methods, the $l_0$-version of untargeted\nSparse-RS achieves almost 100% success rate on ImageNet by perturbing only 0.1%\nof the total number of pixels, outperforming all existing white-box attacks\nincluding $l_0$-PGD. Moreover, our untargeted Sparse-RS achieves very high\nsuccess rates even for the challenging settings of $20\\times20$ adversarial\npatches and $2$-pixel wide adversarial frames for $224\\times224$ images.\nFinally, we show that Sparse-RS can be applied for universal adversarial\npatches where it significantly outperforms transfer-based approaches. The code\nof our framework is available at https://github.com/fra31/sparse-rs.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 08:50:37 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 11:03:16 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Croce", "Francesco", ""], ["Andriushchenko", "Maksym", ""], ["Singh", "Naman D.", ""], ["Flammarion", "Nicolas", ""], ["Hein", "Matthias", ""]]}, {"id": "2006.13016", "submitter": "Quanshi Zhang", "authors": "Hao Zhang, Yiting Chen, Haotian Ma, Xu Cheng, Qihan Ren, Liyao Xiang,\n  Jie Shi, Quanshi Zhang", "title": "Rotation-Equivariant Neural Networks for Privacy Protection", "comments": "arXiv admin note: text overlap with arXiv:2003.08365", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to prevent leaking input information from intermediate-layer\nfeatures, this paper proposes a method to revise the traditional neural network\ninto the rotation-equivariant neural network (RENN). Compared to the\ntraditional neural network, the RENN uses d-ary vectors/tensors as features, in\nwhich each element is a d-ary number. These d-ary features can be rotated\n(analogous to the rotation of a d-dimensional vector) with a random angle as\nthe encryption process. Input information is hidden in this target phase of\nd-ary features for attribute obfuscation. Even if attackers have obtained\nnetwork parameters and intermediate-layer features, they cannot extract input\ninformation without knowing the target phase. Hence, the input privacy can be\neffectively protected by the RENN. Besides, the output accuracy of RENNs only\ndegrades mildly compared to traditional neural networks, and the computational\ncost is significantly less than the homomorphic encryption.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 08:00:14 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Zhang", "Hao", ""], ["Chen", "Yiting", ""], ["Ma", "Haotian", ""], ["Cheng", "Xu", ""], ["Ren", "Qihan", ""], ["Xiang", "Liyao", ""], ["Shi", "Jie", ""], ["Zhang", "Quanshi", ""]]}, {"id": "2006.13039", "submitter": "Lun Wang", "authors": "Lun Wang, Ruoxi Jia and Dawn Song", "title": "D2P-Fed: Differentially Private Federated Learning With Efficient\n  Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the discrete Gaussian based differentially private\nfederated learning (D2P-Fed), a unified scheme to achieve both differential\nprivacy (DP) and communication efficiency in federated learning (FL). In\nparticular, compared with the only prior work taking care of both aspects,\nD2P-Fed provides stronger privacy guarantee, better composability and smaller\ncommunication cost. The key idea is to apply the discrete Gaussian noise to the\nprivate data transmission. We provide complete analysis of the privacy\nguarantee, communication cost and convergence rate of D2P-Fed. We evaluated\nD2P-Fed on INFIMNIST and CIFAR10. The results show that D2P-Fed outperforms\nthe-state-of-the-art by 4.7% to 13.0% in terms of model accuracy while saving\none third of the communication cost.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 06:46:11 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 19:30:40 GMT"}, {"version": "v3", "created": "Sun, 1 Nov 2020 22:22:17 GMT"}, {"version": "v4", "created": "Mon, 16 Nov 2020 03:20:21 GMT"}, {"version": "v5", "created": "Sat, 2 Jan 2021 22:02:32 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Wang", "Lun", ""], ["Jia", "Ruoxi", ""], ["Song", "Dawn", ""]]}, {"id": "2006.13041", "submitter": "Deepesh Data", "authors": "Deepesh Data and Suhas Diggavi", "title": "Byzantine-Resilient High-Dimensional Federated Learning", "comments": "33 pages; title change; improved bound on the approximation error by\n  the factor of H", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study stochastic gradient descent (SGD) with local iterations in the\npresence of malicious/Byzantine clients, motivated by the federated learning.\nThe clients, instead of communicating with the central server in every\niteration, maintain their local models, which they update by taking several SGD\niterations based on their own datasets and then communicate the net update with\nthe server, thereby achieving communication-efficiency. Furthermore, only a\nsubset of clients communicate with the server, and this subset may be different\nat different synchronization times. The Byzantine clients may collaborate and\nsend arbitrary vectors to the server to disrupt the learning process. To combat\nthe adversary, we employ an efficient high-dimensional robust mean estimation\nalgorithm from Steinhardt et al.~\\cite[ITCS 2018]{Resilience_SCV18} at the\nserver to filter-out corrupt vectors; and to analyze the outlier-filtering\nprocedure, we develop a novel matrix concentration result that may be of\nindependent interest.\n  We provide convergence analyses for strongly-convex and non-convex smooth\nobjectives in the heterogeneous data setting, where different clients may have\ndifferent local datasets, and we do not make any probabilistic assumptions on\ndata generation. We believe that ours is the first Byzantine-resilient\nalgorithm and analysis with local iterations. We derive our convergence results\nunder minimal assumptions of bounded variance for SGD and bounded gradient\ndissimilarity (which captures heterogeneity among local datasets). We also\nextend our results to the case when clients compute full-batch gradients.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 03:54:36 GMT"}, {"version": "v2", "created": "Sun, 16 Aug 2020 21:24:14 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Data", "Deepesh", ""], ["Diggavi", "Suhas", ""]]}, {"id": "2006.13051", "submitter": "Hanrui Wang", "authors": "Hanrui Wang, Xingbo Dong, Zhe Jin, Andrew Beng Jin Teoh, Massimo\n  Tistarelli", "title": "Interpretable security analysis of cancellable biometrics using\n  constrained-optimized similarity-based attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cancellable biometrics (CB) schemes, template security is achieved by\napplying, mainly non-linear, transformations to the biometric template. The\ntransformation is designed to preserve the template distance/similarity in the\ntransformed domain. Despite its effectiveness, the security issues attributed\nto similarity preservation property of CB are underestimated. Dong et al.\n[BTAS'19], exploited the similarity preservation trait of CB and proposed a\nsimilarity-based attack with high successful attack rate. The similarity-based\nattack utilizes preimage that are generated from the protected biometric\ntemplate for impersonation and perform cross matching. In this paper, we\npropose a constrained optimization similarity-based attack (CSA), which is\nimproved upon Dong's genetic algorithm enabled similarity-based attack (GASA).\nThe CSA applies algorithm-specific equality or inequality relations as\nconstraints, to optimize preimage generation. We interpret the effectiveness of\nCSA from the supervised learning perspective. We identify such constraints then\nconduct extensive experiments to demonstrate CSA against CB with LFW face\ndataset. The results suggest that CSA is effective to breach IoM hashing and\nBioHashing security, and outperforms GASA significantly. Inferring from the\nabove results, we further remark that, other than IoM and BioHashing, CSA is\ncritical to other CB schemes as far as the constraints can be formulated.\nFurthermore, we reveal the correlation of hash code size and the attack\nperformance of CSA.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 14:23:25 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 08:39:37 GMT"}, {"version": "v3", "created": "Thu, 17 Jun 2021 07:21:48 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Wang", "Hanrui", ""], ["Dong", "Xingbo", ""], ["Jin", "Zhe", ""], ["Teoh", "Andrew Beng Jin", ""], ["Tistarelli", "Massimo", ""]]}, {"id": "2006.13086", "submitter": "Jordan Holland", "authors": "Jordan Holland, Ross Teixeira, Paul Schmitt, Kevin Borgolte, Jennifer\n  Rexford, Nick Feamster, Jonathan Mayer", "title": "Classifying Network Vendors at Internet Scale", "comments": "11 Pages, 2 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a method to create a large, labeled dataset of\nvisible network device vendors across the Internet by mapping network-visible\nIP addresses to device vendors. We use Internet-wide scanning, banner grabs of\nnetwork-visible devices across the IPv4 address space, and clustering\ntechniques to assign labels to more than 160,000 devices. We subsequently probe\nthese devices and use features extracted from the responses to train a\nclassifier that can accurately classify device vendors. Finally, we demonstrate\nhow this method can be used to understand broader trends across the Internet by\npredicting device vendors in traceroutes from CAIDA's Archipelago measurement\nsystem and subsequently examining vendor distributions across these\ntraceroutes.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 15:21:44 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 17:15:15 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Holland", "Jordan", ""], ["Teixeira", "Ross", ""], ["Schmitt", "Paul", ""], ["Borgolte", "Kevin", ""], ["Rexford", "Jennifer", ""], ["Feamster", "Nick", ""], ["Mayer", "Jonathan", ""]]}, {"id": "2006.13087", "submitter": "Marko Vukoli\\'c", "authors": "Marko Vukolic", "title": "On the Interoperability of Decentralized Exposure Notification Systems", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report summarizes the requirements and proposes a high-level solution\nfor interoperability across recently proposed COVID-19 exposure notification\nefforts. Our focus is on interoperability across exposure notification (EN)\napplications which are based on the decentralized Bluetooth Low Energy (BLE)\nprotocol driven by Google/Apple Exposure Notifications API (including DP3T and\nsimilar protocols). We distinguish different interoperability use cases, such\nas worldwide public EN interoperability, as well as interoperability in the\nenterprise EN systems. This report also proposes an API and a backend\nimplementation architecture for EN interoperability. Finally, we propose using\na permissioned blockchain-based solution for managing EN backend certificates\nand configurations (without storing any users' data on the blockchain) for\nhelping address EN interoperability challenges across different vendors.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 15:24:14 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Vukolic", "Marko", ""]]}, {"id": "2006.13353", "submitter": "Daniel Genkin", "authors": "Stephan van Schaik, Marina Minkin, Andrew Kwong, Daniel Genkin, Yuval\n  Yarom", "title": "CacheOut: Leaking Data on Intel CPUs via Cache Evictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent transient-execution attacks, such as RIDL, Fallout, and ZombieLoad,\ndemonstrated that attackers can leak information while it transits through\nmicroarchitectural buffers. Named Microarchitectural Data Sampling (MDS) by\nIntel, these attacks are likened to \"drinking from the firehose\", as the\nattacker has little control over what data is observed and from what origin.\nUnable to prevent the buffers from leaking, Intel issued countermeasures via\nmicrocode updates that overwrite the buffers when the CPU changes security\ndomains.\n  In this work we present CacheOut, a new microarchitectural attack that is\ncapable of bypassing Intel's buffer overwrite countermeasures. We observe that\nas data is being evicted from the CPU's L1 cache, it is often transferred back\nto the leaky CPU buffers where it can be recovered by the attacker. CacheOut\nimproves over previous MDS attacks by allowing the attacker to choose which\ndata to leak from the CPU's L1 cache, as well as which part of a cache line to\nleak. We demonstrate that CacheOut can leak information across multiple\nsecurity boundaries, including those between processes, virtual machines, user\nand kernel space, and from SGX enclaves.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 21:56:39 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["van Schaik", "Stephan", ""], ["Minkin", "Marina", ""], ["Kwong", "Andrew", ""], ["Genkin", "Daniel", ""], ["Yarom", "Yuval", ""]]}, {"id": "2006.13354", "submitter": "Muhammad Ajmal Azad Dr", "authors": "Muhammad Ajmal Azad, Junaid Arshad, Ali Akmal, Farhan Riaz, Sidrah\n  Abdullah, Muhammad Imran, and Farhan Ahmad", "title": "A First Look at Privacy Analysis of COVID-19 Contact Tracing Mobile\n  Applications", "comments": "submitted to IEEE IOT JOurnal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's smartphones are equipped with a large number of powerful value-added\nsensors and features such as a low power Bluetooth sensor, powerful embedded\nsensors such as the digital compass, accelerometer, GPS sensors, Wi-Fi\ncapabilities, microphone, humidity sensors, health tracking sensors, and a\ncamera, etc. These value-added sensors have revolutionized the lives of the\nhuman being in many ways such, as tracking the health of the patients and\nmovement of doctors, tracking employees movement in large manufacturing units,\nand monitoring the environment, etc. These embedded sensors could also be used\nfor large-scale personal, group, and community sensing applications especially\ntracing the spread of certain diseases. Governments and regulators are turning\nto use these features to trace the people thought to have symptoms of certain\ndiseases or virus e.g. COVID-19. The outbreak of COVID-19 in December 2019, has\nseen a surge of the mobile applications for tracing, tracking and isolating the\npersons showing COVID-19 symptoms to limit the spread of disease to the larger\ncommunity. The use of embedded sensors could disclose private information of\nthe users thus potentially bring threat to the privacy and security of users.\nIn this paper, we analyzed a large set of smartphone applications that have\nbeen designed to contain the spread of the COVID-19 virus and bring the people\nback to normal life. Specifically, we have analyzed what type of permission\nthese smartphone apps require, whether these permissions are necessary for the\ntrack and trace, how data from the user devices is transported to the analytic\ncenter, and analyzing the security measures these apps have deployed to ensure\nthe privacy and security of users.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 21:57:00 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 14:16:08 GMT"}, {"version": "v3", "created": "Sun, 16 Aug 2020 09:09:56 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Azad", "Muhammad Ajmal", ""], ["Arshad", "Junaid", ""], ["Akmal", "Ali", ""], ["Riaz", "Farhan", ""], ["Abdullah", "Sidrah", ""], ["Imran", "Muhammad", ""], ["Ahmad", "Farhan", ""]]}, {"id": "2006.13362", "submitter": "Yuxiang Luo", "authors": "Yuxiang Luo, Cheng Zhang, Yunqi Zhang, Chaoshun Zuo, Dong Xuan,\n  Zhiqiang Lin, Adam C. Champion, and Ness Shroff", "title": "ACOUSTIC-TURF: Acoustic-based Privacy-Preserving COVID-19 Contact\n  Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.SD cs.SI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new privacy-preserving, automated contact tracing\nsystem, ACOUSTIC-TURF, to fight COVID-19 using acoustic signals sent from\nubiquitous mobile devices. At a high level, ACOUSTIC-TURF adaptively broadcasts\ninaudible ultrasonic signals with randomly generated IDs in the vicinity.\nSimultaneously, the system receives other ultrasonic signals sent from nearby\n(e.g., 6 feet) users. In such a system, individual user IDs are not disclosed\nto others and the system can accurately detect encounters in physical proximity\nwith 6-foot granularity. We have implemented a prototype of ACOUSTIC-TURF on\nAndroid and evaluated its performance in terms of acoustic-signal-based\nencounter detection accuracy and power consumption at different ranges and\nunder various occlusion scenarios. Experimental results show that ACOUSTIC-TURF\ncan detect multiple contacts within a 6-foot range for mobile phones placed in\npockets and outside pockets. Furthermore, our acoustic-signal-based system\nachieves greater precision than wireless-signal-based approaches when contact\ntracing is performed through walls. ACOUSTIC-TURF correctly determines that\npeople on opposite sides of a wall are not in contact with one another, whereas\nthe Bluetooth-based approaches detect nonexistent contacts among them.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 22:17:36 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Luo", "Yuxiang", ""], ["Zhang", "Cheng", ""], ["Zhang", "Yunqi", ""], ["Zuo", "Chaoshun", ""], ["Xuan", "Dong", ""], ["Lin", "Zhiqiang", ""], ["Champion", "Adam C.", ""], ["Shroff", "Ness", ""]]}, {"id": "2006.13364", "submitter": "Shanto Roy", "authors": "Md Whaiduzzaman, Md. Razon Hossain, Ahmedur Rahman Shovon, Shanto Roy,\n  Aron Laszka, Rajkumar Buyya, and Alistair Barros", "title": "A Privacy-preserving Mobile and Fog Computing Framework to Trace and\n  Prevent COVID-19 Community Transmission", "comments": "12 pages, 9 figures, 1 table, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To slow down the spread of COVID-19, governments around the world are trying\nto identify infected people and to contain the virus by enforcing isolation and\nquarantine. However, it is difficult to trace people who came into contact with\nan infected person, which causes widespread community transmission and mass\ninfection. To address this problem, we develop an e-government Privacy\nPreserving Mobile and Fog computing framework entitled PPMF that can trace\ninfected and suspected cases nationwide. We use personal mobile devices with\ncontact tracing app and two types of stationary fog nodes, named Automatic Risk\nCheckers (ARC) and Suspected User Data Uploader Node (SUDUN), to trace\ncommunity transmission alongside maintaining user data privacy. Each user's\nmobile device receives a Unique Encrypted Reference Code (UERC) when\nregistering on the central application. The mobile device and the central\napplication both generate Rotational Unique Encrypted Reference Code (RUERC),\nwhich broadcasted using the Bluetooth Low Energy (BLE) technology. The ARCs are\nplaced at the entry points of buildings, which can immediately detect if there\nare positive or suspected cases nearby. If any confirmed case is found, the\nARCs broadcast pre-cautionary messages to nearby people without revealing the\nidentity of the infected person. The SUDUNs are placed at the health centers\nthat report test results to the central cloud application. The reported data is\nlater used to map between infected and suspected cases. Therefore, using our\nproposed PPMF framework, governments can let organizations continue their\neconomic activities without complete lockdown.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 22:24:44 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Whaiduzzaman", "Md", ""], ["Hossain", "Md. Razon", ""], ["Shovon", "Ahmedur Rahman", ""], ["Roy", "Shanto", ""], ["Laszka", "Aron", ""], ["Buyya", "Rajkumar", ""], ["Barros", "Alistair", ""]]}, {"id": "2006.13462", "submitter": "Chang Xu", "authors": "Yao Cheng, Chang Xu, Zhen Hai, Yingjiu Li", "title": "DeepMnemonic: Password Mnemonic Generation via Deep Attentive\n  Encoder-Decoder Model", "comments": "Published in IEEE Transactions on Dependable and Secure Computing\n  (TDSC)", "journal-ref": null, "doi": "10.1109/TDSC.2020.2987025", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strong passwords are fundamental to the security of password-based user\nauthentication systems. In recent years, much effort has been made to evaluate\npassword strength or to generate strong passwords. Unfortunately, the usability\nor memorability of the strong passwords has been largely neglected. In this\npaper, we aim to bridge the gap between strong password generation and the\nusability of strong passwords. We propose to automatically generate textual\npassword mnemonics, i.e., natural language sentences, which are intended to\nhelp users better memorize passwords. We introduce \\textit{DeepMnemonic}, a\ndeep attentive encoder-decoder framework which takes a password as input and\nthen automatically generates a mnemonic sentence for the password. We conduct\nextensive experiments to evaluate DeepMnemonic on the real-world data sets. The\nexperimental results demonstrate that DeepMnemonic outperforms a well-known\nbaseline for generating semantically meaningful mnemonic sentences. Moreover,\nthe user study further validates that the generated mnemonic sentences by\nDeepMnemonic are useful in helping users memorize strong passwords.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 04:05:48 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Cheng", "Yao", ""], ["Xu", "Chang", ""], ["Hai", "Zhen", ""], ["Li", "Yingjiu", ""]]}, {"id": "2006.13488", "submitter": "Farhad Farokhi", "authors": "Farhad Farokhi", "title": "Distributionally-Robust Machine Learning Using Locally\n  Differentially-Private Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider machine learning, particularly regression, using\nlocally-differentially private datasets. The Wasserstein distance is used to\ndefine an ambiguity set centered at the empirical distribution of the dataset\ncorrupted by local differential privacy noise. The ambiguity set is shown to\ncontain the probability distribution of unperturbed, clean data. The radius of\nthe ambiguity set is a function of the privacy budget, spread of the data, and\nthe size of the problem. Hence, machine learning with locally-differentially\nprivate datasets can be rewritten as a distributionally-robust optimization.\nFor general distributions, the distributionally-robust optimization problem can\nrelaxed as a regularized machine learning problem with the Lipschitz constant\nof the machine learning model as a regularizer. For linear and logistic\nregression, this regularizer is the dual norm of the model parameters. For\nGaussian data, the distributionally-robust optimization problem can be solved\nexactly to find an optimal regularizer. This approach results in an entirely\nnew regularizer for training linear regression models. Training with this novel\nregularizer can be posed as a semi-definite program. Finally, the performance\nof the proposed distributionally-robust machine learning training is\ndemonstrated on practical datasets.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 05:12:10 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Farokhi", "Farhad", ""]]}, {"id": "2006.13499", "submitter": "Shahryar Baki", "authors": "Shahryar Baki and Rakesh M. Verma and Arjun Mukherjee and Omprakash\n  Gnawali", "title": "Less is More: Exploiting Social Trust to Increase the Effectiveness of a\n  Deception Attack", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber attacks such as phishing, IRS scams, etc., still are successful in\nfooling Internet users. Users are the last line of defense against these\nattacks since attackers seem to always find a way to bypass security systems.\nUnderstanding users' reason about the scams and frauds can help security\nproviders to improve users security hygiene practices. In this work, we study\nthe users' reasoning and the effectiveness of several variables within the\ncontext of the company representative fraud. Some of the variables that we\nstudy are: 1) the effect of using LinkedIn as a medium for delivering the\nphishing message instead of using email, 2) the effectiveness of natural\nlanguage generation techniques in generating phishing emails, and 3) how some\nsimple customizations, e.g., adding sender's contact info to the email, affect\nparticipants perception. The results obtained from the within-subject study\nshow that participants are not prepared even for a well-known attack - company\nrepresentative fraud. Findings include: approximately 65% mean detection rate\nand insights into how the success rate changes with the facade and\ncorrespondent (sender/receiver) information. A significant finding is that a\nsmaller set of well-chosen strategies is better than a large `mess' of\nstrategies. We also find significant differences in how males and females\napproach the same company representative fraud. Insights from our work could\nhelp defenders in developing better strategies to evaluate their defenses and\nin devising better training strategies.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 05:57:57 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Baki", "Shahryar", ""], ["Verma", "Rakesh M.", ""], ["Mukherjee", "Arjun", ""], ["Gnawali", "Omprakash", ""]]}, {"id": "2006.13501", "submitter": "Yingxue Zhou", "authors": "Yingxue Zhou, Xiangyi Chen, Mingyi Hong, Zhiwei Steven Wu, Arindam\n  Banerjee", "title": "Private Stochastic Non-Convex Optimization: Adaptive Algorithms and\n  Tighter Generalization Bounds", "comments": "In the current version, we drop the experimental results on CIFAR-10\n  dataset due to an implementation error", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study differentially private (DP) algorithms for stochastic non-convex\noptimization. In this problem, the goal is to minimize the population loss over\na $p$-dimensional space given $n$ i.i.d. samples drawn from a distribution. We\nimprove upon the population gradient bound of ${\\sqrt{p}}/{\\sqrt{n}}$ from\nprior work and obtain a sharper rate of $\\sqrt[4]{p}/\\sqrt{n}$. We obtain this\nrate by providing the first analyses on a collection of private gradient-based\nmethods, including adaptive algorithms DP RMSProp and DP Adam. Our proof\ntechnique leverages the connection between differential privacy and adaptive\ndata analysis to bound gradient estimation error at every iterate, which\ncircumvents the worse generalization bound from the standard uniform\nconvergence argument. Finally, we evaluate the proposed algorithms on two\npopular deep learning tasks and demonstrate the empirical advantages of DP\nadaptive gradient methods over standard DP SGD.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 06:01:24 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 20:25:35 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Zhou", "Yingxue", ""], ["Chen", "Xiangyi", ""], ["Hong", "Mingyi", ""], ["Wu", "Zhiwei Steven", ""], ["Banerjee", "Arindam", ""]]}, {"id": "2006.13598", "submitter": "Alexander Nilsson", "authors": "Alexander Nilsson, Pegah Nikbakht Bideh, Joakim Brorsson", "title": "A Survey of Published Attacks on Intel SGX", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intel Software Guard Extensions (SGX) provides a trusted execution\nenvironment (TEE) to run code and operate sensitive data. SGX provides runtime\nhardware protection where both code and data are protected even if other code\ncomponents are malicious. However, recently many attacks targeting SGX have\nbeen identified and introduced that can thwart the hardware defence provided by\nSGX. In this paper we present a survey of all attacks specifically targeting\nIntel SGX that are known to the authors, to date. We categorized the attacks\nbased on their implementation details into 7 different categories. We also look\ninto the available defence mechanisms against identified attacks and categorize\nthe available types of mitigations for each presented attack.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 10:20:56 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Nilsson", "Alexander", ""], ["Bideh", "Pegah Nikbakht", ""], ["Brorsson", "Joakim", ""]]}, {"id": "2006.13726", "submitter": "Xingjun Ma", "authors": "Linxi Jiang, Xingjun Ma, Zejia Weng, James Bailey, Yu-Gang Jiang", "title": "Imbalanced Gradients: A New Cause of Overestimated Adversarial\n  Robustness", "comments": "17 pages, 7 figues", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating the robustness of a defense model is a challenging task in\nadversarial robustness research. Obfuscated gradients, a type of gradient\nmasking, have previously been found to exist in many defense methods and cause\na false signal of robustness. In this paper, we identify a more subtle\nsituation called \\emph{Imbalanced Gradients} that can also cause overestimated\nadversarial robustness. The phenomenon of imbalanced gradients occurs when the\ngradient of one term of the margin loss dominates and pushes the attack towards\nto a suboptimal direction. To exploit imbalanced gradients, we formulate a\n\\emph{Margin Decomposition (MD)} attack that decomposes a margin loss into\nindividual terms and then explores the attackability of these terms separately\nvia a two-stage process. We examine 12 state-of-the-art defense models, and\nfind that models exploiting label smoothing easily cause imbalanced gradients,\nand on which our MD attacks can decrease their PGD robustness (evaluated by PGD\nattack) by over 23%. For 6 out of the 12 defenses, our attack can reduce their\nPGD robustness by at least 9%. The results suggest that imbalanced gradients\nneed to be carefully addressed for more reliable adversarial robustness.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 13:41:37 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 05:56:02 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Jiang", "Linxi", ""], ["Ma", "Xingjun", ""], ["Weng", "Zejia", ""], ["Bailey", "James", ""], ["Jiang", "Yu-Gang", ""]]}, {"id": "2006.13742", "submitter": "Joon Sern Lee", "authors": "Joon Sern Lee, Gui Peng David Yam, Jin Hao Chan", "title": "PhishGAN: Data Augmentation and Identification of Homoglpyh Attacks", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": "10.1109/CCCI49893.2020.9256804", "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Homoglyph attacks are a common technique used by hackers to conduct phishing.\nDomain names or links that are visually similar to actual ones are created via\npunycode to obfuscate the attack, making the victim more susceptible to\nphishing. For example, victims may mistake \"|inkedin.com\" for \"linkedin.com\"\nand in the process, divulge personal details to the fake website. Current State\nof The Art (SOTA) typically make use of string comparison algorithms (e.g.\nLevenshtein Distance), which are computationally heavy. One reason for this is\nthe lack of publicly available datasets thus hindering the training of more\nadvanced Machine Learning (ML) models. Furthermore, no one font is able to\nrender all types of punycode correctly, posing a significant challenge to the\ncreation of a dataset that is unbiased toward any particular font. This coupled\nwith the vast number of internet domains pose a challenge in creating a dataset\nthat can capture all possible variations. Here, we show how a conditional\nGenerative Adversarial Network (GAN), PhishGAN, can be used to generate images\nof hieroglyphs, conditioned on non-homoglpyh input text images. Practical\nchanges to current SOTA were required to facilitate the generation of more\nvaried homoglyph text-based images. We also demonstrate a workflow of how\nPhishGAN together with a Homoglyph Identifier (HI) model can be used to\nidentify the domain the homoglyph was trying to imitate. Furthermore, we\ndemonstrate how PhishGAN's ability to generate datasets on the fly facilitate\nthe quick adaptation of cybersecurity systems to detect new threats as they\nemerge.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 13:59:09 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 03:18:57 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2020 09:04:11 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Lee", "Joon Sern", ""], ["Yam", "Gui Peng David", ""], ["Chan", "Jin Hao", ""]]}, {"id": "2006.13813", "submitter": "Mohammad Abdur Razzaque Dr.", "authors": "Vishal A. Thakor, M.A. Razzaque, and Muhammad R. A. Khandaker", "title": "Lightweight Cryptography for IoT: A State-of-the-Art", "comments": "This paper has beend submitted to IEEE Access Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the emergence of 5G, Internet of Things (IoT) has become a center of\nattraction for almost all industries due to its wide range of applications from\nvarious domains. The explosive growth of industrial control processes and the\nindustrial IoT, imposes unprecedented vulnerability to cyber threats in\ncritical infrastructure through the interconnected systems. This new security\nthreats could be minimized by lightweight cryptography, a sub-branch of\ncryptography, especially derived for resource-constrained devices such as RFID\ntags, smart cards, wireless sensors, etc. More than four dozens of lightweight\ncryptography algorithms have been proposed, designed for specific\napplication(s). These algorithms exhibit diverse hardware and software\nperformances in different circumstances. This paper presents the performance\ncomparison along with their reported cryptanalysis, mainly for lightweight\nblock ciphers, and further shows new research directions to develop novel\nalgorithms with right balance of cost, performance and security\ncharacteristics.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 15:38:16 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Thakor", "Vishal A.", ""], ["Razzaque", "M. A.", ""], ["Khandaker", "Muhammad R. A.", ""]]}, {"id": "2006.13920", "submitter": "Hsun Lee", "authors": "Hsun Lee, Hsu-Chun Hsiao", "title": "Practical and Verifiable Electronic Sortition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing verifiable e-sortition systems are impractical due to\ncomputationally expensive verification (linear to the duration of the\nregistration phase, T) or the ease of being denial of service. Based on the\nadvance in verifiable delay functions, we propose a verifiable e-sortition\nscheme whose result can be efficiently verified in constant time with respect\nto T. We present the preliminary design and implementation, and explore future\ndirections to further enhance practicability.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 17:49:21 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Lee", "Hsun", ""], ["Hsiao", "Hsu-Chun", ""]]}, {"id": "2006.13977", "submitter": "David Stutz", "authors": "David Stutz, Nandhini Chandramoorthy, Matthias Hein, Bernt Schiele", "title": "Bit Error Robustness for Energy-Efficient DNN Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network (DNN) accelerators received considerable attention in\npast years due to saved energy compared to mainstream hardware. Low-voltage\noperation of DNN accelerators allows to further reduce energy consumption\nsignificantly, however, causes bit-level failures in the memory storing the\nquantized DNN weights. In this paper, we show that a combination of robust\nfixed-point quantization, weight clipping, and random bit error training\n(RandBET) improves robustness against random bit errors in (quantized) DNN\nweights significantly. This leads to high energy savings from both low-voltage\noperation as well as low-precision quantization. Our approach generalizes\nacross operating voltages and accelerators, as demonstrated on bit errors from\nprofiled SRAM arrays. We also discuss why weight clipping alone is already a\nquite effective way to achieve robustness against bit errors. Moreover, we\nspecifically discuss the involved trade-offs regarding accuracy, robustness and\nprecision: Without losing more than 1% in accuracy compared to a normally\ntrained 8-bit DNN, we can reduce energy consumption on CIFAR-10 by 20%. Higher\nenergy savings of, e.g., 30%, are possible at the cost of 2.5% accuracy, even\nfor 4-bit DNNs.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 18:23:10 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 16:00:52 GMT"}, {"version": "v3", "created": "Fri, 9 Apr 2021 15:24:12 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Stutz", "David", ""], ["Chandramoorthy", "Nandhini", ""], ["Hein", "Matthias", ""], ["Schiele", "Bernt", ""]]}, {"id": "2006.13981", "submitter": "Soumyabrata Dev", "authors": "Mahmoud Said Elsayed, Nhien-An Le-Khac, Soumyabrata Dev, and Anca\n  Delia Jurcut", "title": "DDoSNet: A Deep-Learning Model for Detecting Network Attacks", "comments": "Published in Proc. IEEE World of Wireless, Mobile and Multimedia\n  networks (WoWMoM) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software-Defined Networking (SDN) is an emerging paradigm, which evolved in\nrecent years to address the weaknesses in traditional networks. The significant\nfeature of the SDN, which is achieved by disassociating the control plane from\nthe data plane, facilitates network management and allows the network to be\nefficiently programmable. However, the new architecture can be susceptible to\nseveral attacks that lead to resource exhaustion and prevent the SDN controller\nfrom supporting legitimate users. One of these attacks, which nowadays is\ngrowing significantly, is the Distributed Denial of Service (DDoS) attack. DDoS\nattack has a high impact on crashing the network resources, making the target\nservers unable to support the valid users. The current methods deploy Machine\nLearning (ML) for intrusion detection against DDoS attacks in the SDN network\nusing the standard datasets. However, these methods suffer several drawbacks,\nand the used datasets do not contain the most recent attack patterns - hence,\nlacking in attack diversity.\n  In this paper, we propose DDoSNet, an intrusion detection system against DDoS\nattacks in SDN environments. Our method is based on Deep Learning (DL)\ntechnique, combining the Recurrent Neural Network (RNN) with autoencoder. We\nevaluate our model using the newly released dataset CICDDoS2019, which contains\na comprehensive variety of DDoS attacks and addresses the gaps of the existing\ncurrent datasets. We obtain a significant improvement in attack detection, as\ncompared to other benchmarking methods. Hence, our model provides great\nconfidence in securing these networks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 18:27:39 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Elsayed", "Mahmoud Said", ""], ["Le-Khac", "Nhien-An", ""], ["Dev", "Soumyabrata", ""], ["Jurcut", "Anca Delia", ""]]}, {"id": "2006.13990", "submitter": "Filipo Sharevski", "authors": "Filipo Sharevski, Peter Jachim", "title": "WikipediaBot: Automated Adversarial Manipulation of Wikipedia Articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an automated adversarial mechanism called WikipediaBot.\nWikipediaBot allows an adversary to create and control a bot infrastructure for\nthe purpose of adversarial edits of Wikipedia articles. The WikipediaBot is a\nself-contained mechanism with modules for generating credentials for Wikipedia\neditors, bypassing login protections, and a production of contextually-relevant\nadversarial edits for target Wikipedia articles that evade conventional\ndetection. The contextually-relevant adversarial edits are generated using an\nadversarial Markov chain that incorporates a linguistic manipulation attack\nknown as MIM or malware-induced misperceptions. Because the nefarious use of\nWikipediaBot could result in harmful damages to the integrity of wide range of\nWikipedia articles, we provide an elaborate discussion about the implications,\ndetection, and defenses Wikipedia could employ to address the threat of\nautomated adversarial manipulations and acts of Wikipedia vandalism.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 18:47:23 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Sharevski", "Filipo", ""], ["Jachim", "Peter", ""]]}, {"id": "2006.14026", "submitter": "Matthew Jagielski", "authors": "Matthew Jagielski, Giorgio Severi, Niklas Pousette Harger, Alina Oprea", "title": "Subpopulation Data Poisoning Attacks", "comments": "May12 update: add sever + backdoor defenses, comparison to witches'\n  brew attack, better comparison to related work, transferability of\n  representations for cmatch", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems are deployed in critical settings, but they might\nfail in unexpected ways, impacting the accuracy of their predictions. Poisoning\nattacks against machine learning induce adversarial modification of data used\nby a machine learning algorithm to selectively change its output when it is\ndeployed. In this work, we introduce a novel data poisoning attack called a\n\\emph{subpopulation attack}, which is particularly relevant when datasets are\nlarge and diverse. We design a modular framework for subpopulation attacks,\ninstantiate it with different building blocks, and show that the attacks are\neffective for a variety of datasets and machine learning models. We further\noptimize the attacks in continuous domains using influence functions and\ngradient optimization methods. Compared to existing backdoor poisoning attacks,\nsubpopulation attacks have the advantage of inducing misclassification in\nnaturally distributed data points at inference time, making the attacks\nextremely stealthy. We also show that our attack strategy can be used to\nimprove upon existing targeted attacks. We prove that, under some assumptions,\nsubpopulation attacks are impossible to defend against, and empirically\ndemonstrate the limitations of existing defenses against our attacks,\nhighlighting the difficulty of protecting machine learning against this threat.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 20:20:52 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 04:45:18 GMT"}, {"version": "v3", "created": "Wed, 12 May 2021 17:53:39 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Jagielski", "Matthew", ""], ["Severi", "Giorgio", ""], ["Harger", "Niklas Pousette", ""], ["Oprea", "Alina", ""]]}, {"id": "2006.14042", "submitter": "Huiying Li", "authors": "Huiying Li, Shawn Shan, Emily Wenger, Jiayun Zhang, Haitao Zheng, Ben\n  Y. Zhao", "title": "Blacklight: Defending Black-Box Adversarial Attacks on Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vulnerability of deep neural networks (DNNs) to adversarial examples is\nwell documented. Under the strong white-box threat model, where attackers have\nfull access to DNN internals, recent work has produced continual advancements\nin defenses, often followed by more powerful attacks that break them.\nMeanwhile, research on the more realistic black-box threat model has focused\nalmost entirely on reducing the query-cost of attacks, making them increasingly\npractical for ML models already deployed today.\n  This paper proposes and evaluates Blacklight, a new defense against black-box\nadversarial attacks. Blacklight targets a key property of black-box attacks: to\ncompute adversarial examples, they produce sequences of highly similar images\nwhile trying to minimize the distance from some initial benign input. To detect\nan attack, Blacklight computes for each query image a compact set of one-way\nhash values that form a probabilistic fingerprint. Variants of an image produce\nnearly identical fingerprints, and fingerprint generation is robust against\nmanipulation. We evaluate Blacklight on 5 state-of-the-art black-box attacks,\nacross a variety of models and classification tasks. While the most efficient\nattacks take thousands or tens of thousands of queries to complete, Blacklight\nidentifies them all, often after only a handful of queries. Blacklight is also\nrobust against several powerful countermeasures, including an optimal black-box\nattack that approximates white-box attacks in efficiency. Finally, Blacklight\nsignificantly outperforms the only known alternative in both detection coverage\nof attack queries and resistance against persistent attackers.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 20:52:24 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Li", "Huiying", ""], ["Shan", "Shawn", ""], ["Wenger", "Emily", ""], ["Zhang", "Jiayun", ""], ["Zheng", "Haitao", ""], ["Zhao", "Ben Y.", ""]]}, {"id": "2006.14109", "submitter": "Nikolay Laptev", "authors": "Paulo Tanaka, Sameet Sapra, Nikolay Laptev", "title": "Scalable Data Classification for Security and Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content based data classification is an open challenge. Traditional Data Loss\nPrevention (DLP)-like systems solve this problem by fingerprinting the data in\nquestion and monitoring endpoints for the fingerprinted data. With a large\nnumber of constantly changing data assets in Facebook, this approach is both\nnot scalable and ineffective in discovering what data is where. This paper is\nabout an end-to-end system built to detect sensitive semantic types within\nFacebook at scale and enforce data retention and access controls automatically.\n  The approach described here is our first end-to-end privacy system that\nattempts to solve this problem by incorporating data signals, machine learning,\nand traditional fingerprinting techniques to map out and classify all data\nwithin Facebook. The described system is in production achieving a 0.9+ average\nF2 scores across various privacy classes while handling a large number of data\nassets across dozens of data stores.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 00:19:34 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 22:44:47 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 16:28:04 GMT"}, {"version": "v4", "created": "Wed, 1 Jul 2020 19:40:55 GMT"}, {"version": "v5", "created": "Mon, 6 Jul 2020 20:03:21 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Tanaka", "Paulo", ""], ["Sapra", "Sameet", ""], ["Laptev", "Nikolay", ""]]}, {"id": "2006.14147", "submitter": "M. Caner Tol", "authors": "M. Caner Tol, Berk Gulmezoglu, Koray Yurtseven and Berk Sunar", "title": "FastSpec: Scalable Generation and Detection of Spectre Gadgets Using\n  Neural Embeddings", "comments": "IEEE European Symposium on Security and Privacy 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several techniques have been proposed to detect vulnerable Spectre gadgets in\nwidely deployed commercial software. Unfortunately, detection techniques\nproposed so far rely on hand-written rules which fall short in covering subtle\nvariations of known Spectre gadgets as well as demand a huge amount of time to\nanalyze each conditional branch in software. Moreover, detection tool\nevaluations are based only on a handful of these gadgets, as it requires\narduous effort to craft new gadgets manually.\n  In this work, we employ both fuzzing and deep learning techniques to automate\nthe generation and detection of Spectre gadgets. We first create a diverse set\nof Spectre-V1 gadgets by introducing perturbations to the known gadgets. Using\nmutational fuzzing, we produce a data set with more than 1 million Spectre-V1\ngadgets which is the largest Spectre gadget data set built to date. Next, we\nconduct the first empirical usability study of Generative Adversarial Networks\n(GANs) in the context of assembly code generation without any human\ninteraction. We introduce SpectreGAN which leverages masking implementation of\nGANs for both learning the gadget structures and generating new gadgets. This\nprovides the first scalable solution to extend the variety of Spectre gadgets.\n  Finally, we propose FastSpec which builds a classifier with the generated\nSpectre gadgets based on a novel high dimensional Neural Embeddings technique\n(BERT). For the case studies, we demonstrate that FastSpec discovers potential\ngadgets with a high success rate in OpenSSL libraries and Phoronix benchmarks.\nFurther, FastSpec offers much greater flexibility and time-related performance\ngain compared to the existing tools and therefore can be used for gadget\ndetection in large-scale software.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 03:08:20 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 15:56:58 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Tol", "M. Caner", ""], ["Gulmezoglu", "Berk", ""], ["Yurtseven", "Koray", ""], ["Sunar", "Berk", ""]]}, {"id": "2006.14170", "submitter": "Lingjuan Lyu", "authors": "Lingjuan Lyu, Yitong Li, Xuanli He, Tong Xiao", "title": "Towards Differentially Private Text Representations", "comments": "Accepted to SIGIR'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most deep learning frameworks require users to pool their local data or model\nupdates to a trusted server to train or maintain a global model. The assumption\nof a trusted server who has access to user information is ill-suited in many\napplications. To tackle this problem, we develop a new deep learning framework\nunder an untrusted server setting, which includes three modules: (1) embedding\nmodule, (2) randomization module, and (3) classifier module. For the\nrandomization module, we propose a novel local differentially private (LDP)\nprotocol to reduce the impact of privacy parameter $\\epsilon$ on accuracy, and\nprovide enhanced flexibility in choosing randomization probabilities for LDP.\nAnalysis and experiments show that our framework delivers comparable or even\nbetter performance than the non-private framework and existing LDP protocols,\ndemonstrating the advantages of our LDP protocol.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 04:42:18 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Lyu", "Lingjuan", ""], ["Li", "Yitong", ""], ["He", "Xuanli", ""], ["Xiao", "Tong", ""]]}, {"id": "2006.14231", "submitter": "Noe Elisa Nnko", "authors": "Noe Elisa, Longzhi Yang, Fei Chao, Yi Cao", "title": "A framework of blockchain-based secure and privacy-preserving\n  E-government system", "comments": "11 pages", "journal-ref": null, "doi": "10.1007/s11276-018-1883-0", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic government (e-government) uses information and communication\ntechnologies to deliver public services to individuals and organisations\neffectively, efficiently and transparently. E-government is one of the most\ncomplex systems which needs to be distributed, secured and privacy-preserved,\nand the failure of these can be very costly both economically and socially.\nMost of the existing e-government systems such as websites and electronic\nidentity management systems (eIDs) are centralized at duplicated servers and\ndatabases. A centralized management and validation system may suffer from a\nsingle point of failure and make the system a target to cyber attacks such as\nmalware, denial of service attacks (DoS), and distributed denial of service\nattacks (DDoS). The blockchain technology enables the implementation of highly\nsecure and privacy-preserving decentralized systems where transactions are not\nunder the control of any third party organizations. Using the blockchain\ntechnology, exiting data and new data are stored in a sealed compartment of\nblocks (i.e., ledger) distributed across the network in a verifiable and\nimmutable way. Information security and privacy are enhanced by the blockchain\ntechnology in which data are encrypted and distributed across the entire\nnetwork. This paper proposes a framework of a decentralized e-government\npeer-to-peer (p2p) system using the blockchain technology, which can ensure\nboth information security and privacy while simultaneously increasing the trust\nof the public sectors. In addition, a prototype of the proposed system is\npresented, with the support of a theoretical and qualitative analysis of the\nsecurity and privacy implications of such system.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 07:58:54 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Elisa", "Noe", ""], ["Yang", "Longzhi", ""], ["Chao", "Fei", ""], ["Cao", "Yi", ""]]}, {"id": "2006.14234", "submitter": "Noe Elisa Nnko", "authors": "Noe Elisa, Longzhi Yang, Honglei Li, Fei Chao, Nitin Naik", "title": "Consortium Blockchain for Security and Privacy-Preserving in\n  E-government Systems", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since its inception as a solution for secure cryptocurrencies sharing in\n2008, the blockchain technology has now become one of the core technologies for\nsecure data sharing and storage over trustless and decentralised peer-to-peer\nsystems. E-government is amongst the systems that stores sensitive information\nabout citizens, businesses and other affiliates, and therefore becomes the\ntarget of cyber attackers. The existing e-government systems are centralised\nand thus subject to single point of failure. This paper proposes a secure and\ndecentralised e-government system based on the consortium blockchain\ntechnology, which is a semi-public and decentralised blockchain system\nconsisting of a group of pre-selected entities or organisations in charge of\nconsensus and decisions making for the benefit of the whole network of peers.\nIn addition, a number of e-government nodes are pre-selected to perform the\ntasks of user and transaction validation before being added to the blockchain\nnetwork. Accordingly, e-government users of the consortium blockchain network\nare given the rights to create, submit, access, and review transactions.\nPerformance evaluation on single transaction time and transactions processed\nper second demonstrate the practicability of the proposed consortium\nblockchain-based e-government system for secure information sharing amongst all\nstakeholders.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 08:04:53 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Elisa", "Noe", ""], ["Yang", "Longzhi", ""], ["Li", "Honglei", ""], ["Chao", "Fei", ""], ["Naik", "Nitin", ""]]}, {"id": "2006.14329", "submitter": "David Butler", "authors": "David Butler, Chris Hicks, James Bell, Carsten Maple, Jon Crowcroft", "title": "Differentially Private Health Tokens for Estimating COVID-19 Risk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the fight against Covid-19, many governments and businesses are in the\nprocess of evaluating, trialling and even implementing so-called immunity\npassports. Also known as antibody or health certificates, there is a clear\ndemand for any technology that could allow people to return to work and other\ncrowded places without placing others at risk. One of the major criticisms of\nsuch systems is that they could be misused to unfairly discriminate against\nthose without immunity, allowing the formation of an `immuno-privileged' class\nof people. In this work we are motivated to explore an alternative technical\nsolution that is non-discriminatory by design. In particular we propose health\ntokens -- randomised health certificates which, using methods from differential\nprivacy, allow individual test results to be randomised whilst still allowing\nuseful aggregate risk estimates to be calculated. We show that health tokens\ncould mitigate immunity-based discrimination whilst still presenting a viable\nmechanism for estimating the collective transmission risk posed by small groups\nof users. We evaluate the viability of our approach in the context of\nidentity-free and identity-binding use cases and then consider a number of\npossible attacks. Our experimental results show that for groups of size 500 or\nmore, the error associated with our method can be as low as 0.03 on average and\nthus the aggregated results can be useful in a number of identity-free\ncontexts. Finally, we present the results of our open-source prototype which\ndemonstrates the practicality of our solution.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 12:02:16 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 12:09:01 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Butler", "David", ""], ["Hicks", "Chris", ""], ["Bell", "James", ""], ["Maple", "Carsten", ""], ["Crowcroft", "Jon", ""]]}, {"id": "2006.14352", "submitter": "Simon Yusuf Enoch", "authors": "Simon Yusuf Enoch, Zhibin Huang, Chun Yong Moon, Donghwan Lee, Myung\n  Kil Ahn, and Dong Seong Kim", "title": "HARMer: Cyber-attacks Automation and Evaluation", "comments": "19 pages, journal", "journal-ref": "IEEE Access, 8, 129397-129414 (2020)", "doi": "10.1109/ACCESS.2020.3009748", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing growth of cyber-attack incidences, it is important to\ndevelop innovative and effective techniques to assess and defend networked\nsystems against cyber attacks. One of the well-known techniques for this is\nperforming penetration testing which is carried by a group of security\nprofessionals (i.e, red team). Penetration testing is also known to be\neffective to find existing and new vulnerabilities, however, the quality of\nsecurity assessment can be depending on the quality of the red team members and\ntheir time and devotion to the penetration testing. In this paper, we propose a\nnovel automation framework for cyber-attacks generation named `HARMer' to\naddress the challenges with respect to manual attack execution by the red team.\nOur novel proposed framework, design, and implementation is based on a scalable\ngraphical security model called Hierarchical Attack Representation Model\n(HARM). (1) We propose the requirements and the key phases for the automation\nframework. (2) We propose security metrics-based attack planning strategies\nalong with their algorithms. (3) We conduct experiments in a real enterprise\nnetwork and Amazon Web Services. The results show how the different phases of\nthe framework interact to model the attackers' operations. This framework will\nallow security administrators to automatically assess the impact of various\nthreats and attacks in an automated manner.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 12:52:10 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 03:23:21 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 23:00:39 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Enoch", "Simon Yusuf", ""], ["Huang", "Zhibin", ""], ["Moon", "Chun Yong", ""], ["Lee", "Donghwan", ""], ["Ahn", "Myung Kil", ""], ["Kim", "Dong Seong", ""]]}, {"id": "2006.14360", "submitter": "Lauren Watson", "authors": "Lauren Watson, Benedek Rozemberczki, Rik Sarkar", "title": "Stability Enhanced Privacy and Applications in Private Stochastic\n  Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Private machine learning involves addition of noise while training, resulting\nin lower accuracy. Intuitively, greater stability can imply greater privacy and\nimprove this privacy-utility tradeoff. We study this role of stability in\nprivate empirical risk minimization, where differential privacy is achieved by\noutput perturbation, and establish a corresponding theoretical result showing\nthat for strongly-convex loss functions, an algorithm with uniform stability of\n$\\beta$ implies a bound of $O(\\sqrt{\\beta})$ on the scale of noise required for\ndifferential privacy.\n  The result applies to both explicit regularization and to implicitly\nstabilized ERM, such as adaptations of Stochastic Gradient Descent that are\nknown to be stable. Thus, it generalizes recent results that improve privacy\nthrough modifications to SGD, and establishes stability as the unifying\nperspective. It implies new privacy guarantees for optimizations with uniform\nstability guarantees, where a corresponding differential privacy guarantee was\npreviously not known. Experimental results validate the utility of stability\nenhanced privacy in several problems, including application of elastic nets and\nfeature selection.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 13:04:18 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Watson", "Lauren", ""], ["Rozemberczki", "Benedek", ""], ["Sarkar", "Rik", ""]]}, {"id": "2006.14425", "submitter": "Robert Baillie", "authors": "Robert Baillie, Andrew Fiori (University of Lethbridge), Samuel S.\n  Wagstaff Jr. (Purdue University)", "title": "Strengthening the Baillie-PSW primality test", "comments": "25 pages", "journal-ref": "Mathematics of Computation, Volume 90, Number 330, July 2021, p.\n  1931", "doi": "10.1090/mcom/3616", "report-no": null, "categories": "math.NT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Baillie-PSW primality test combines Fermat and Lucas probable prime\ntests. It reports that a number is either composite or probably prime. No odd\ncomposite integer has been reported to pass this combination of primality tests\nif the parameters are chosen in an appropriate way. Here, we describe a\nsignificant strengthening of this test that comes at almost no additional\ncomputational cost. This is achieved by including in the test what we call\nLucas-V pseudoprimes, of which there are only five less than $10^{15}$.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 14:04:54 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 14:43:52 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Baillie", "Robert", "", "University of Lethbridge"], ["Fiori", "Andrew", "", "University of Lethbridge"], ["Wagstaff", "Samuel S.", "Jr.", "Purdue University"]]}, {"id": "2006.14580", "submitter": "Emily Wenger", "authors": "Emily Wenger, Josephine Passananti, Arjun Bhagoji, Yuanshun Yao,\n  Haitao Zheng, Ben Y. Zhao", "title": "Backdoor Attacks Against Deep Learning Systems in the Physical World", "comments": "Accepted to the 2021 Conference on Computer Vision and Pattern\n  Recognition (CVPR 2021); 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Backdoor attacks embed hidden malicious behaviors into deep learning models,\nwhich only activate and cause misclassifications on model inputs containing a\nspecific trigger. Existing works on backdoor attacks and defenses, however,\nmostly focus on digital attacks that use digitally generated patterns as\ntriggers. A critical question remains unanswered: can backdoor attacks succeed\nusing physical objects as triggers, thus making them a credible threat against\ndeep learning systems in the real world? We conduct a detailed empirical study\nto explore this question for facial recognition, a critical deep learning task.\nUsing seven physical objects as triggers, we collect a custom dataset of 3205\nimages of ten volunteers and use it to study the feasibility of physical\nbackdoor attacks under a variety of real-world conditions. Our study reveals\ntwo key findings. First, physical backdoor attacks can be highly successful if\nthey are carefully configured to overcome the constraints imposed by physical\nobjects. In particular, the placement of successful triggers is largely\nconstrained by the target model's dependence on key facial features. Second,\nfour of today's state-of-the-art defenses against (digital) backdoors are\nineffective against physical backdoors, because the use of physical objects\nbreaks core assumptions used to construct these defenses. Our study confirms\nthat (physical) backdoor attacks are not a hypothetical phenomenon but rather\npose a serious real-world threat to critical classification tasks. We need new\nand more robust defenses against backdoors in the physical world.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 17:26:20 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 22:12:56 GMT"}, {"version": "v3", "created": "Wed, 14 Apr 2021 16:41:55 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Wenger", "Emily", ""], ["Passananti", "Josephine", ""], ["Bhagoji", "Arjun", ""], ["Yao", "Yuanshun", ""], ["Zheng", "Haitao", ""], ["Zhao", "Ben Y.", ""]]}, {"id": "2006.14765", "submitter": "Tingmin Wu", "authors": "Tingmin Wu, Wanlun Ma, Sheng Wen, Xin Xia, Cecile Paris, Surya Nepal,\n  Yang Xiang", "title": "Analysis of Trending Topics and Text-based Channels of Information\n  Delivery in Cybersecurity", "comments": "13 pages (main content) + 4 pages (references and appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer users are generally faced with difficulties in making correct\nsecurity decisions. While an increasingly fewer number of people are trying or\nwilling to take formal security training, online sources including news,\nsecurity blogs, and websites are continuously making security knowledge more\naccessible. Analysis of cybersecurity texts can provide insights into the\ntrending topics and identify current security issues as well as how cyber\nattacks evolve over time. These in turn can support researchers and\npractitioners in predicting and preparing for these attacks. Comparing\ndifferent sources may facilitate the learning process for normal users by\npersisting the security knowledge gained from different cybersecurity context.\nPrior studies neither systematically analysed the wide-range of digital sources\nnor provided any standardisation in analysing the trending topics from recent\nsecurity texts. Although LDA has been widely adopted in topic generation, its\ngenerated topics cannot cover the cybersecurity concepts completely and\nconsiderably overlap. To address this issue, we propose a semi-automated\nclassification method to generate comprehensive security categories instead of\nLDA-generated topics. We further compare the identified 16 security categories\nacross different sources based on their popularity and impact. We have revealed\nseveral surprising findings. (1) The impact reflected from cyber-security texts\nstrongly correlates with the monetary loss caused by cybercrimes. (2) For most\ncategories, security blogs share the largest popularity and largest\nabsolute/relative impact over time. (3) Websites deliver security information\nwithout caring about timeliness much, where one third of the articles do not\nspecify the date and the rest have a time lag in posting emerging security\nissues.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 03:00:04 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Wu", "Tingmin", ""], ["Ma", "Wanlun", ""], ["Wen", "Sheng", ""], ["Xia", "Xin", ""], ["Paris", "Cecile", ""], ["Nepal", "Surya", ""], ["Xiang", "Yang", ""]]}, {"id": "2006.14782", "submitter": "Gurpriya Kaur Bhatia", "authors": "Gurpriya Kaur Bhatia and Shubham Gupta and Alpana Dubey and\n  Ponnurangam Kumaraguru", "title": "WorkerRep: Immutable Reputation System For Crowdsourcing Platform Based\n  on Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Crowdsourcing is a process wherein an individual or an organisation utilizes\nthe talent pool present over the Internet to accomplish their task. The\nexisting crowdsourcing platforms and their reputation computation are\ncentralised and hence prone to various attacks or malicious manipulation of the\ndata by the central entity. A few distributed crowdsourcing platforms have been\nproposed but they lack a robust reputation mechanism. So we propose a\ndecentralised crowdsourcing platform having an immutable reputation mechanism\nto tackle these problems. It is built on top of Ethereum network and does not\nrequire the user to trust a third party for a non malicious experience. It also\nutilizes IOTAs consensus mechanism which reduces the cost for task evaluation\nsignificantly.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 03:37:41 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Bhatia", "Gurpriya Kaur", ""], ["Gupta", "Shubham", ""], ["Dubey", "Alpana", ""], ["Kumaraguru", "Ponnurangam", ""]]}, {"id": "2006.14864", "submitter": "William Buchanan Prof", "authors": "Will Abramson, Nicole E. van Deursen, William J Buchanan", "title": "Trust-by-Design: Evaluating Issues and Perceptions within Clinical\n  Passporting", "comments": null, "journal-ref": "Blockchain in Healthcare Today, 3 (2020)", "doi": "10.30953/bhty.v3.140", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A substantial administrative burden is placed on healthcare professionals as\nthey manage and progress through their careers. Identity verification,\npre-employment screening and appraisals: the bureaucracy associated with each\nof these processes takes precious time out of a healthcare professional's day.\nTime that could have been spent focused on patient care. In the midst of the\nCOVID-19 crisis, it is more important than ever to optimize these\nprofessionals' time. This paper presents the synthesis of a design workshop\nheld at the Royal College of Physicians of Edinburgh (RCPE) and subsequent\ninterviews with healthcare professionals. The main research question posed is\nwhether these processes can be re-imagined using digital technologies,\nspecifically Self-Sovereign Identity? A key contribution in the paper is the\ndevelopment of a set of user-led requirements and design principles for\nidentity systems used within healthcare. These are then contrasted with the\ndesign principles found in the literature. The results of this study confirm\nthe need and potential of professionalising identity and credential management\nthroughout a healthcare professional's career.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 08:49:44 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Abramson", "Will", ""], ["van Deursen", "Nicole E.", ""], ["Buchanan", "William J", ""]]}, {"id": "2006.14890", "submitter": "Dr Gregory Epiphaniou", "authors": "Carsten Maple and Peter Davies and Kerstin Eder and Chris Hankin and\n  Greg Chance and Gregory Epiphaniou", "title": "CyRes -- Avoiding Catastrophic Failure in Connected and Autonomous\n  Vehicles (Extended Abstract)", "comments": "7 pages, extended abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches to cyber security and regulation in the automotive sector\ncannot achieve the quality of outcome necessary to ensure the safe mass\ndeployment of advanced vehicle technologies and smart mobility systems. Without\nsustainable resilience hard-fought public trust will evaporate, derailing\nemerging global initiatives to improve the efficiency, safety and environmental\nimpact of future transport. This paper introduces an operational cyber\nresilience methodology, CyRes, that is suitable for standardisation. The CyRes\nmethodology itself is capable of being tested in court or by publicly appointed\nregulators. It is designed so that operators understand what evidence should be\nproduced by it and are able to measure the quality of that evidence. The\nevidence produced is capable of being tested in court or by publicly appointed\nregulators. Thus, the real-world system to which the CyRes methodology has been\napplied is capable of operating at all times and in all places with a legally\nand socially acceptable value of negative consequence.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 09:59:52 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 15:12:59 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 10:54:33 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Maple", "Carsten", ""], ["Davies", "Peter", ""], ["Eder", "Kerstin", ""], ["Hankin", "Chris", ""], ["Chance", "Greg", ""], ["Epiphaniou", "Gregory", ""]]}, {"id": "2006.14969", "submitter": "Matteo Busi", "authors": "Carmine Abate and Matteo Busi and Stelios Tsampas", "title": "Fully Abstract and Robust Compilation and How to Reconcile the Two,\n  Abstractly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most prominent formal criterion for secure compilation is full\nabstraction, the preservation and reflection of contextual equivalence. Recent\nwork introduced robust compilation, defined as the preservation of robust\nsatisfaction of hyperproperties, i.e., their satisfaction against arbitrary\nattackers. In this paper, we initially set out to compare these two approaches\nto secure compilation. To that end, we provide an exact description of the\nhyperproperties that are robustly satisfied by programs compiled with a fully\nabstract compiler, and show that they can be meaningless or trivial. We then\npropose a novel criterion for secure compilation formulated in the framework of\nMathematical Operational Semantics (MOS), guaranteeing both full abstraction\nand the preservation of robust satisfaction of hyperproperties in a more\nsensible manner.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 13:15:35 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 16:29:29 GMT"}, {"version": "v3", "created": "Fri, 18 Jun 2021 22:16:01 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Abate", "Carmine", ""], ["Busi", "Matteo", ""], ["Tsampas", "Stelios", ""]]}, {"id": "2006.15007", "submitter": "Aria Shahverdi", "authors": "Aria Shahverdi, Mahammad Shirinov, Dana Dachman-Soled", "title": "Database Reconstruction from Noisy Volumes: A Cache Side-Channel Attack\n  on SQLite", "comments": "Source code :\n  https://github.com/ariashahverdi/database_reconstruction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate the feasibility of database reconstruction under a cache\nside-channel attack on SQLite. Specifically, we present a Flush+Reload attack\non SQLite that obtains approximate (or \"noisy\") volumes of range queries made\nto a private database. We then present several algorithms that, taken together,\nreconstruct nearly the exact database in varied experimental conditions, given\nthese approximate volumes. Our reconstruction algorithms employ novel\ntechniques for the approximate/noisy setting, including a noise-tolerant\nclique-finding algorithm, a \"Match & Extend\" algorithm for extrapolating\nvolumes that are omitted from the clique, and a \"Noise Reduction Step\" that\nmakes use of a closest vector problem (CVP) solver to improve the overall\naccuracy of the reconstructed database. The time complexity of our attacks\ngrows quickly with the size of the range of the queried attribute, but scales\nwell to large databases. Experimental results show that we can reconstruct\ndatabases of size 100,000 and ranges of size 12 with error percentage of 0.11 %\nin under 12 hours on a personal laptop.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 14:21:36 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 23:14:01 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 23:27:16 GMT"}, {"version": "v4", "created": "Sun, 20 Jun 2021 20:03:03 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Shahverdi", "Aria", ""], ["Shirinov", "Mahammad", ""], ["Dachman-Soled", "Dana", ""]]}, {"id": "2006.15074", "submitter": "Afsah Anwar", "authors": "Afsah Anwar and Ahmed Abusnaina and Songqing Chen and Frank Li and\n  David Mohaisen", "title": "Cleaning the NVD: Comprehensive Quality Assessment, Improvements, and\n  Analyses", "comments": "13 pages, 5 figures, 16 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vulnerability databases are vital sources of information on emergent software\nsecurity concerns. Security professionals, from system administrators to\ndevelopers to researchers, heavily depend on these databases to track\nvulnerabilities and analyze security trends. How reliable and accurate are\nthese databases though?\n  In this paper, we explore this question with the National Vulnerability\nDatabase (NVD), the U.S. government's repository of vulnerability information\nthat arguably serves as the industry standard. Through a systematic\ninvestigation, we uncover inconsistent or incomplete data in the NVD that can\nimpact its practical uses, affecting information such as the vulnerability\npublication dates, names of vendors and products affected, vulnerability\nseverity scores, and vulnerability type categorizations. We explore the extent\nof these discrepancies and identify methods for automated corrections. Finally,\nwe demonstrate the impact that these data issues can pose by comparing analyses\nusing the original and our rectified versions of the NVD. Ultimately, our\ninvestigation of the NVD not only produces an improved source of vulnerability\ninformation, but also provides important insights and guidance for the security\ncommunity on the curation and use of such data sources.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 16:07:35 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Anwar", "Afsah", ""], ["Abusnaina", "Ahmed", ""], ["Chen", "Songqing", ""], ["Li", "Frank", ""], ["Mohaisen", "David", ""]]}, {"id": "2006.15117", "submitter": "Jingyun Jia", "authors": "Jingyun Jia, Philip K. Chan", "title": "MMF: A loss extension for feature learning in open set recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open set recognition (OSR) is the problem of classifying the known classes,\nmeanwhile identifying the unknown classes when the collected samples cannot\nexhaust all the classes. There are many applications for the OSR problem. For\ninstance, the frequently emerged new malware classes require a system that can\nclassify the known classes and identify the unknown malware classes. In this\npaper, we propose an add-on extension for loss functions in neural networks to\naddress the OSR problem. Our loss extension leverages the neural network to\nfind polar representations for the known classes so that the representations of\nthe known and the unknown classes become more effectively separable. Our\ncontributions include: First, we introduce an extension that can be\nincorporated into different loss functions to find more discriminative\nrepresentations. Second, we show that the proposed extension can significantly\nimprove the performances of two different types of loss functions on datasets\nfrom two different domains. Third, we show that with the proposed extension,\none loss function outperforms the others in terms of training time and model\naccuracy.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 17:22:11 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 21:37:12 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Jia", "Jingyun", ""], ["Chan", "Philip K.", ""]]}, {"id": "2006.15270", "submitter": "Kallol Krishna Karmakar", "authors": "Vijay Varadharajan and Uday Tupakula and Kallol Karmakar", "title": "Software Enabled Security Architecture and Mechanisms for Securing 5G\n  Network Services", "comments": "20 Pages. Submitted to Esorics 2020 (Under Review)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 5G network systems are evolving and have complex network infrastructures.\nThere is a great deal of work in this area focused on meeting the stringent\nservice requirements for the 5G networks. Within this context, security\nrequirements play a critical role as 5G networks can support a range of\nservices such as healthcare services, financial and critical infrastructures.\n3GPP and ETSI have been developing security frameworks for 5G networks. Our\nwork in 5G security has been focusing on the design of security architecture\nand mechanisms enabling dynamic establishment of secure and trusted end to end\nservices as well as development of mechanisms to proactively detect and\nmitigate security attacks in virtualised network infrastructures. The focus of\nthis paper is on the latter, namely the facilities and mechanisms, and the\ndesign of a security architecture providing facilities and mechanisms to detect\nand mitigate specific security attacks. We have developed and implemented a\nsimplified version of the security architecture using Software Defined Networks\n(SDN) and Network Function Virtualisation (NFV) technologies. The specific\nsecurity functions developed in this architecture can be directly integrated\ninto the 5G core network facilities enhancing its security. We describe the\ndesign and implementation of the security architecture and demonstrate how it\ncan efficiently mitigate specific types of attacks.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 03:38:16 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Varadharajan", "Vijay", ""], ["Tupakula", "Uday", ""], ["Karmakar", "Kallol", ""]]}, {"id": "2006.15272", "submitter": "Kallol Krishna Karmakar", "authors": "Uday Tupakula and Vijay Varadharajan and Kallol Krishna Karmakar", "title": "Software Enabled Security Architecture for Counteracting Attacks in\n  Control Systems", "comments": "8 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasingly Industrial Control Systems (ICS) systems are being connected to\nthe Internet to minimise the operational costs and provide additional\nflexibility. These control systems such as the ones used in power grids,\nmanufacturing and utilities operate continually and have long lifespans\nmeasured in decades rather than years as in the case of IT systems. Such\nindustrial control systems require uninterrupted and safe operation. However,\nthey can be vulnerable to a variety of attacks, as successful attacks on\ncritical control infrastructures could have devastating consequences to the\nsafety of human lives as well as a nation's security and prosperity.\nFurthermore, there can be a range of attacks that can target ICS and it is not\neasy to secure these systems against all known attacks let alone unknown ones.\nIn this paper, we propose a software enabled security architecture using\nSoftware Defined Networking (SDN) and Network Function Virtualisation (NFV)\nthat can enhance the capability to secure industrial control systems. We have\ndesigned such an SDN/NFV enabled security architecture and developed a Control\nSystem Security Application (CSSA) in SDN Controller for enhancing security in\nICS against certain specific attacks namely denial of service attacks, from\nunpatched vulnerable control system components and securing the communication\nflows from the legacy devices that do not support any security functionality.\nIn this paper, we discuss the prototype implementation of the proposed\narchitecture and the results obtained from our analysis.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 03:54:19 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Tupakula", "Uday", ""], ["Varadharajan", "Vijay", ""], ["Karmakar", "Kallol Krishna", ""]]}, {"id": "2006.15275", "submitter": "Akond Rahman PhD", "authors": "Md. Shazibul Islam Shamim and Farzana Ahamed Bhuiyan and Akond Rahman", "title": "XI Commandments of Kubernetes Security: A Systematization of Knowledge\n  Related to Kubernetes Security Practices", "comments": "Keywords: containers, devops, devsecops, grey literature, kubernetes,\n  practices, review, security, systematization of knowledge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kubernetes is an open-source software for automating management of\ncomputerized services. Organizations, such as IBM, Capital One and Adidas use\nKubernetes to deploy and manage their containers, and have reported benefits\nrelated to deployment frequency. Despite reported benefits, Kubernetes\ndeployments are susceptible to security vulnerabilities, such as those that\noccurred at Tesla in 2018. A systematization of Kubernetes security practices\ncan help practitioners mitigate vulnerabilities in their Kubernetes\ndeployments. The goal of this paper is to help practitioners in securing their\nKubernetes installations through a systematization of knowledge related to\nKubernetes security practices. We systematize knowledge by applying qualitative\nanalysis on 104 Internet artifacts. We identify 11 security practices that\ninclude (i) implementation of role-based access control (RBAC) authorization to\nprovide least privilege, (ii) applying security patches to keep Kubernetes\nupdated, and (iii) implementing pod and network specific security policies.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 03:57:48 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Shamim", "Md. Shazibul Islam", ""], ["Bhuiyan", "Farzana Ahamed", ""], ["Rahman", "Akond", ""]]}, {"id": "2006.15340", "submitter": "Hanan Hindy", "authors": "Hanan Hindy, Ethan Bayne, Miroslav Bures, Robert Atkinson, Christos\n  Tachtatzis, Xavier Bellekens", "title": "Machine Learning Based IoT Intrusion Detection System: An MQTT Case\n  Study (MQTT-IoT-IDS2020 Dataset)", "comments": "14 pages, 5 figures, to be published in the proceeding of the 12th\n  International Network Conference 2020 (INC2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) is one of the main research fields in the\nCybersecurity domain. This is due to (a) the increased dependency on automated\ndevice, and (b) the inadequacy of general purpose Intrusion Detection Systems\n(IDS) to be deployed for special purpose networks usage. Numerous lightweight\nprotocols are being proposed for IoT devices communication usage. One of the\ndistinguishable IoT machine-to-machine communication protocols is Message\nQueuing Telemetry Transport (MQTT) protocol. However, as per the authors best\nknowledge, there are no available IDS datasets that include MQTT benign or\nattack instances and thus, no IDS experimental results available. In this\npaper, the effectiveness of six Machine Learning (ML) techniques to detect\nMQTT-based attacks is evaluated. Three abstraction levels of features are\nassessed, namely, packet-based, unidirectional flow, and bidirectional flow\nfeatures. An MQTT simulated dataset is generated and used for the training and\nevaluation processes. The dataset is released with an open access licence to\nhelp the research community further analyse the accompanied challenges. The\nexperimental results demonstrated the adequacy of the proposed ML models to\nsuit MQTT-based networks IDS requirements. Moreover, the results emphasise on\nthe importance of using flow-based features to discriminate MQTT-based attacks\nfrom benign traffic, while packet-based features are sufficient for traditional\nnetworking attacks.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 11:31:57 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 15:39:29 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 12:18:48 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Hindy", "Hanan", ""], ["Bayne", "Ethan", ""], ["Bures", "Miroslav", ""], ["Atkinson", "Robert", ""], ["Tachtatzis", "Christos", ""], ["Bellekens", "Xavier", ""]]}, {"id": "2006.15343", "submitter": "Hanan Hindy", "authors": "Hanan Hindy, Christos Tachtatzis, Robert Atkinson, David Brosset,\n  Miroslav Bures, Ivan Andonovic, Craig Michie, Xavier Bellekens", "title": "Leveraging Siamese Networks for One-Shot Intrusion Detection Model", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of supervised Machine Learning (ML) to enhance Intrusion Detection\nSystems has been the subject of significant research. Supervised ML is based\nupon learning by example, demanding significant volumes of representative\ninstances for effective training and the need to re-train the model for every\nunseen cyber-attack class. However, retraining the models in-situ renders the\nnetwork susceptible to attacks owing to the time-window required to acquire a\nsufficient volume of data. Although anomaly detection systems provide a\ncoarse-grained defence against unseen attacks, these approaches are\nsignificantly less accurate and suffer from high false-positive rates. Here, a\ncomplementary approach referred to as 'One-Shot Learning', whereby a limited\nnumber of examples of a new attack-class is used to identify a new attack-class\n(out of many) is detailed. The model grants a new cyber-attack classification\nwithout retraining. A Siamese Network is trained to differentiate between\nclasses based on pairs similarities, rather than features, allowing to identify\nnew and previously unseen attacks. The performance of a pre-trained model to\nclassify attack-classes based only on one example is evaluated using three\ndatasets. Results confirm the adaptability of the model in classifying unseen\nattacks and the trade-off between performance and the need for distinctive\nclass representation.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 11:40:01 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Hindy", "Hanan", ""], ["Tachtatzis", "Christos", ""], ["Atkinson", "Robert", ""], ["Brosset", "David", ""], ["Bures", "Miroslav", ""], ["Andonovic", "Ivan", ""], ["Michie", "Craig", ""], ["Bellekens", "Xavier", ""]]}, {"id": "2006.15344", "submitter": "Hanan Hindy", "authors": "Hanan Hindy, Robert Atkinson, Christos Tachtatzis, Jean-No\\\"el Colin,\n  Ethan Bayne, Xavier Bellekens", "title": "Utilising Deep Learning Techniques for Effective Zero-Day Attack\n  Detection", "comments": "18 pages, 4 figures", "journal-ref": "Electronics 2020, 9, 1684", "doi": "10.3390/electronics9101684", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) and Deep Learning (DL) have been used for building\nIntrusion Detection Systems (IDS). The increase in both the number and sheer\nvariety of new cyber-attacks poses a tremendous challenge for IDS solutions\nthat rely on a database of historical attack signatures. Therefore, the\nindustrial pull for robust IDSs that are capable of flagging zero-day attacks\nis growing. Current outlier-based zero-day detection research suffers from high\nfalse-negative rates, thus limiting their practical use and performance. This\npaper proposes an autoencoder implementation for detecting zero-day attacks.\nThe aim is to build an IDS model with high recall while keeping the miss rate\n(false-negatives) to an acceptable minimum. Two well-known IDS datasets are\nused for evaluation-CICIDS2017 and NSL-KDD. In order to demonstrate the\nefficacy of our model, we compare its results against a One-Class Support\nVector Machine (SVM). The manuscript highlights the performance of a One-Class\nSVM when zero-day attacks are distinctive from normal behaviour. The proposed\nmodel benefits greatly from autoencoders encoding-decoding capabilities. The\nresults show that autoencoders are well-suited at detecting complex zero-day\nattacks. The results demonstrate a zero-day detection accuracy of [89-99%] for\nthe NSL-KDD dataset and [75-98%] for the CICIDS2017 dataset. Finally, the paper\noutlines the observed trade-off between recall and fallout.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 11:40:30 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 15:00:25 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Hindy", "Hanan", ""], ["Atkinson", "Robert", ""], ["Tachtatzis", "Christos", ""], ["Colin", "Jean-No\u00ebl", ""], ["Bayne", "Ethan", ""], ["Bellekens", "Xavier", ""]]}, {"id": "2006.15429", "submitter": "Xiangyi Chen", "authors": "Xiangyi Chen, Zhiwei Steven Wu, Mingyi Hong", "title": "Understanding Gradient Clipping in Private SGD: A Geometric Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are increasingly popular in many machine learning\napplications where the training data may contain sensitive information. To\nprovide formal and rigorous privacy guarantee, many learning systems now\nincorporate differential privacy by training their models with (differentially)\nprivate SGD. A key step in each private SGD update is gradient clipping that\nshrinks the gradient of an individual example whenever its L2 norm exceeds some\nthreshold. We first demonstrate how gradient clipping can prevent SGD from\nconverging to stationary point. We then provide a theoretical analysis that\nfully quantifies the clipping bias on convergence with a disparity measure\nbetween the gradient distribution and a geometrically symmetric distribution.\nOur empirical evaluation further suggests that the gradient distributions along\nthe trajectory of private SGD indeed exhibit symmetric structure that favors\nconvergence. Together, our results provide an explanation why private SGD with\ngradient clipping remains effective in practice despite its potential clipping\nbias. Finally, we develop a new perturbation-based technique that can provably\ncorrect the clipping bias even for instances with highly asymmetric gradient\ndistributions.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 19:08:12 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 03:09:28 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Chen", "Xiangyi", ""], ["Wu", "Zhiwei Steven", ""], ["Hong", "Mingyi", ""]]}, {"id": "2006.15433", "submitter": "Fang Liu", "authors": "Dong Wang and Fang Liu", "title": "Privacy Risk and Preservation For COVID-19 Contact Tracing Apps", "comments": "To appear in CHANCE 33(2): special issue on COVID-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact tracing in the COVID-19 pandemic is key to prevent the further spread\nof COVID-19. Countries and regions around the world have developed and deployed\nor are considering adopting contact-tracing software or mobile apps. While\ncontact tracing apps and software play an important role in the pandemic, red\nflags have been raised regarding the privacy risk associated with contact\ntracing. In this short paper, we provide an overview on the GPS and Bluetooth\nbased contact-tracing apps in the framework of both centralized and\ndecentralized models, examine the associated privacy risk and the effectiveness\nof the privacy-preserving measures adopted in different apps.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 19:42:30 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Wang", "Dong", ""], ["Liu", "Fang", ""]]}, {"id": "2006.15449", "submitter": "Kovila  P.L. Coopamootoo", "authors": "Magdalene Ng, Kovila P.L. Coopamootoo, Ehsan Toreini, Mhairi Aitken,\n  Karen Elliot, Aad van Moorsel", "title": "Simulating the Effects of Social Presence on Trust, Privacy Concerns &\n  Usage Intentions in Automated Bots for Finance", "comments": "In Publication for 5th IEEE European Symposium on Security & Privacy\n  Workshops (EuroSPW)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FinBots are chatbots built on automated decision technology, aimed to\nfacilitate accessible banking and to support customers in making financial\ndecisions. Chatbots are increasing in prevalence, sometimes even equipped to\nmimic human social rules, expectations and norms, decreasing the necessity for\nhuman-to-human interaction. As banks and financial advisory platforms move\ntowards creating bots that enhance the current state of consumer trust and\nadoption rates, we investigated the effects of chatbot vignettes with and\nwithout socio-emotional features on intention to use the chatbot for financial\nsupport purposes. We conducted a between-subject online experiment with N = 410\nparticipants. Participants in the control group were provided with a vignette\ndescribing a secure and reliable chatbot called XRO23, whereas participants in\nthe experimental group were presented with a vignette describing a secure and\nreliable chatbot that is more human-like and named Emma. We found that Vignette\nEmma did not increase participants' trust levels nor lowered their privacy\nconcerns even though it increased perception of social presence. However, we\nfound that intention to use the presented chatbot for financial support was\npositively influenced by perceived humanness and trust in the bot. Participants\nwere also more willing to share financially-sensitive information such as\naccount number, sort code and payments information to XRO23 compared to Emma -\nrevealing a preference for a technical and mechanical FinBot in information\nsharing. Overall, this research contributes to our understanding of the\nintention to use chatbots with different features as financial technology, in\nparticular that socio-emotional support may not be favoured when designed\nindependently of financial function.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 21:31:53 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 16:15:45 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Ng", "Magdalene", ""], ["Coopamootoo", "Kovila P. L.", ""], ["Toreini", "Ehsan", ""], ["Aitken", "Mhairi", ""], ["Elliot", "Karen", ""], ["van Moorsel", "Aad", ""]]}, {"id": "2006.15632", "submitter": "Mingsong Chen", "authors": "Yunfei Song, Tian Liu, Tongquan Wei, Xiangfeng Wang, Zhe Tao, Mingsong\n  Chen", "title": "FDA3 : Federated Defense Against Adversarial Attacks for Cloud-Based\n  IIoT Applications", "comments": null, "journal-ref": "IEEE Transactions on Industrial Informatics, 2020", "doi": "10.1109/TII.2020.3005969", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Along with the proliferation of Artificial Intelligence (AI) and Internet of\nThings (IoT) techniques, various kinds of adversarial attacks are increasingly\nemerging to fool Deep Neural Networks (DNNs) used by Industrial IoT (IIoT)\napplications. Due to biased training data or vulnerable underlying models,\nimperceptible modifications on inputs made by adversarial attacks may result in\ndevastating consequences. Although existing methods are promising in defending\nsuch malicious attacks, most of them can only deal with limited existing attack\ntypes, which makes the deployment of large-scale IIoT devices a great\nchallenge. To address this problem, we present an effective federated defense\napproach named FDA3 that can aggregate defense knowledge against adversarial\nexamples from different sources. Inspired by federated learning, our proposed\ncloud-based architecture enables the sharing of defense capabilities against\ndifferent attacks among IIoT devices. Comprehensive experimental results show\nthat the generated DNNs by our approach can not only resist more malicious\nattacks than existing attack-specific adversarial training methods, but also\ncan prevent IIoT applications from new attacks.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 15:17:15 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Song", "Yunfei", ""], ["Liu", "Tian", ""], ["Wei", "Tongquan", ""], ["Wang", "Xiangfeng", ""], ["Tao", "Zhe", ""], ["Chen", "Mingsong", ""]]}, {"id": "2006.15673", "submitter": "Ferdinando Fioretto", "authors": "Ferdinando Fioretto, Pascal Van Hentenryck, Keyu Zhu", "title": "Differential Privacy of Hierarchical Census Data: An Optimization\n  Approach", "comments": "Corrected a claim in the Introduction and a typo in Model 1", "journal-ref": "Artificial Intelligence 296 (2021): 103475", "doi": "10.1016/j.artint.2021.103475", "report-no": null, "categories": "cs.DB cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is motivated by applications of a Census Bureau interested in\nreleasing aggregate socio-economic data about a large population without\nrevealing sensitive information about any individual. The released information\ncan be the number of individuals living alone, the number of cars they own, or\ntheir salary brackets. Recent events have identified some of the privacy\nchallenges faced by these organizations. To address them, this paper presents a\nnovel differential-privacy mechanism for releasing hierarchical counts of\nindividuals. The counts are reported at multiple granularities (e.g., the\nnational, state, and county levels) and must be consistent across all levels.\nThe core of the mechanism is an optimization model that redistributes the noise\nintroduced to achieve differential privacy in order to meet the consistency\nconstraints between the hierarchical levels. The key technical contribution of\nthe paper shows that this optimization problem can be solved in polynomial time\nby exploiting the structure of its cost functions. Experimental results on very\nlarge, real datasets show that the proposed mechanism provides improvements of\nup to two orders of magnitude in terms of computational efficiency and accuracy\nwith respect to other state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 18:19:55 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 20:02:56 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Fioretto", "Ferdinando", ""], ["Van Hentenryck", "Pascal", ""], ["Zhu", "Keyu", ""]]}, {"id": "2006.15725", "submitter": "Birhanu Eshete", "authors": "Abdullah Ali, Birhanu Eshete", "title": "Best-Effort Adversarial Approximation of Black-Box Malware Classifiers", "comments": "24 pages, 19 figures, 5 tables, to appear in the proceedings of the\n  16th EAI International Conference on Security and Privacy in Communication\n  Networks (SECURECOMM'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An adversary who aims to steal a black-box model repeatedly queries the model\nvia a prediction API to learn a function that approximates its decision\nboundary. Adversarial approximation is non-trivial because of the enormous\ncombinations of model architectures, parameters, and features to explore. In\nthis context, the adversary resorts to a best-effort strategy that yields the\nclosest approximation. This paper explores best-effort adversarial\napproximation of a black-box malware classifier in the most challenging\nsetting, where the adversary's knowledge is limited to a prediction label for a\ngiven input. Beginning with a limited input set for the black-box classifier,\nwe leverage feature representation mapping and cross-domain transferability to\napproximate a black-box malware classifier by locally training a substitute.\nOur approach approximates the target model with different feature types for the\ntarget and the substitute model while also using non-overlapping data for\ntraining the target, training the substitute, and the comparison of the two. We\nevaluate the effectiveness of our approach against two black-box classifiers\ntrained on Windows Portable Executables (PEs). Against a Convolutional Neural\nNetwork (CNN) trained on raw byte sequences of PEs, our approach achieves a 92%\naccurate substitute (trained on pixel representations of PEs), and nearly 90%\nprediction agreement between the target and the substitute model. Against a\n97.8% accurate gradient boosted decision tree trained on static PE features,\nour 91% accurate substitute agrees with the black-box on 90% of predictions,\nsuggesting the strength of our purely black-box approximation.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 21:47:30 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Ali", "Abdullah", ""], ["Eshete", "Birhanu", ""]]}, {"id": "2006.15744", "submitter": "Akbar Rafiey", "authors": "Akbar Rafiey, Yuichi Yoshida", "title": "Fast and Private Submodular and $k$-Submodular Functions Maximization\n  with Matroid Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of maximizing nonnegative monotone submodular functions under a\ncertain constraint has been intensively studied in the last decade, and a wide\nrange of efficient approximation algorithms have been developed for this\nproblem. Many machine learning problems, including data summarization and\ninfluence maximization, can be naturally modeled as the problem of maximizing\nmonotone submodular functions. However, when such applications involve\nsensitive data about individuals, their privacy concerns should be addressed.\nIn this paper, we study the problem of maximizing monotone submodular functions\nsubject to matroid constraints in the framework of differential privacy. We\nprovide $(1-\\frac{1}{\\mathrm{e}})$-approximation algorithm which improves upon\nthe previous results in terms of approximation guarantee. This is done with an\nalmost cubic number of function evaluations in our algorithm.\n  Moreover, we study $k$-submodularity, a natural generalization of\nsubmodularity. We give the first $\\frac{1}{2}$-approximation algorithm that\npreserves differential privacy for maximizing monotone $k$-submodular functions\nsubject to matroid constraints. The approximation ratio is asymptotically tight\nand is obtained with an almost linear number of function evaluations.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 23:18:58 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Rafiey", "Akbar", ""], ["Yoshida", "Yuichi", ""]]}, {"id": "2006.15824", "submitter": "Tianbo Gu", "authors": "Jinyue Song, Tianbo Gu, Yunjie Ge, Prasant Mohapatra", "title": "Smart Contract-based Computing ResourcesTrading in Edge Computing", "comments": "8 pages, 9 figures, to appear in the 2020 Annual IEEE International\n  Symposium on Personal, Indoor and Mobile Radio Communications (IEEE PIMRC\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there is an emerging trend that some computing services are\nmoving from cloud to the edge of the networks. Compared to cloud computing,\nedge computing can provide services with faster response, lower expense, and\nmore security. The massive idle computing resources closing to the edge also\nenhance the deployment of edge services. Instead of using cloud services from\nsome primary providers, edge computing provides people with a great chance to\nactively join the market of computing resources. However, edge computing also\nhas some critical impediments that we have to overcome.\n  In this paper, we design an edge computing service platform that can receive\nand distribute the computing resources from the end-users in a decentralized\nway. Without centralized trade control, we propose a novel hierarchical smart\ncontract-based decentralized technique to establish the trading trust among\nusers and provide flexible smart contract interfaces to satisfy users. Our\nsystem also considers and resolves a variety of security and privacy challenges\nwhen utilizing the encryption and distributed access control mechanism. We\nimplement our system and conduct extensive experiments to show the feasibility\nand effectiveness of our proposed system.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 06:09:07 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Song", "Jinyue", ""], ["Gu", "Tianbo", ""], ["Ge", "Yunjie", ""], ["Mohapatra", "Prasant", ""]]}, {"id": "2006.15826", "submitter": "Tianbo Gu", "authors": "Tianbo Gu, Allaukik Abhishek, Hao Fu, Huanle Zhang, Debraj Basu,\n  Prasant Mohapatra", "title": "Towards Learning-automation IoT Attack Detection through Reinforcement\n  Learning", "comments": "11 pages, 8 figures, 2 tables, to appear in the 21st IEEE\n  International Symposium on a World of Wireless, Mobile and Multimedia\n  Networks (IEEE WoWMoM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a massive number of the Internet of Things (IoT) devices are deployed, the\nsecurity and privacy issues in IoT arouse more and more attention. The IoT\nattacks are causing tremendous loss to the IoT networks and even threatening\nhuman safety. Compared to traditional networks, IoT networks have unique\ncharacteristics, which make the attack detection more challenging. First, the\nheterogeneity of platforms, protocols, software, and hardware exposes various\nvulnerabilities. Second, in addition to the traditional high-rate attacks, the\nlow-rate attacks are also extensively used by IoT attackers to obfuscate the\nlegitimate and malicious traffic. These low-rate attacks are challenging to\ndetect and can persist in the networks. Last, the attackers are evolving to be\nmore intelligent and can dynamically change their attack strategies based on\nthe environment feedback to avoid being detected, making it more challenging\nfor the defender to discover a consistent pattern to identify the attack.\n  In order to adapt to the new characteristics in IoT attacks, we propose a\nreinforcement learning-based attack detection model that can automatically\nlearn and recognize the transformation of the attack pattern. Therefore, we can\ncontinuously detect IoT attacks with less human intervention. In this paper, we\nexplore the crucial features of IoT traffics and utilize the entropy-based\nmetrics to detect both the high-rate and low-rate IoT attacks. Afterward, we\nleverage the reinforcement learning technique to continuously adjust the attack\ndetection threshold based on the detection feedback, which optimizes the\ndetection and the false alarm rate. We conduct extensive experiments over a\nreal IoT attack dataset and demonstrate the effectiveness of our IoT attack\ndetection framework.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 06:12:45 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Gu", "Tianbo", ""], ["Abhishek", "Allaukik", ""], ["Fu", "Hao", ""], ["Zhang", "Huanle", ""], ["Basu", "Debraj", ""], ["Mohapatra", "Prasant", ""]]}, {"id": "2006.15827", "submitter": "Tianbo Gu", "authors": "Tianbo Gu, Zheng Fang, Allaukik Abhishek, Hao Fu, Pengfei Hu, Prasant\n  Mohapatra", "title": "IoTGaze: IoT Security Enforcement via Wireless Context Analysis", "comments": "9 pages, 11 figures, 3 tables, to appear in the IEEE International\n  Conference on Computer Communications (IEEE INFOCOM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) has become the most promising technology for service\nautomation, monitoring, and interconnection, etc. However, the security and\nprivacy issues caused by IoT arouse concerns. Recent research focuses on\naddressing security issues by looking inside platform and apps. In this work,\nwe creatively change the angle to consider security problems from a wireless\ncontext perspective. We propose a novel framework called IoTGaze, which can\ndiscover potential anomalies and vulnerabilities in the IoT system via wireless\ntraffic analysis. By sniffing the encrypted wireless traffic, IoTGaze can\nautomatically identify the sequential interaction of events between apps and\ndevices. We discover the temporal event dependencies and generate the Wireless\nContext for the IoT system. Meanwhile, we extract the IoT Context, which\nreflects user's expectation, from IoT apps' descriptions and user interfaces.\nIf the wireless context does not match the expected IoT context, IoTGaze\nreports an anomaly. Furthermore, IoTGaze can discover the vulnerabilities\ncaused by the inter-app interaction via hidden channels, such as temperature\nand illuminance. We provide a proof-of-concept implementation and evaluation of\nour framework on the Samsung SmartThings platform. The evaluation shows that\nIoTGaze can effectively discover anomalies and vulnerabilities, thereby greatly\nenhancing the security of IoT systems.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 06:14:06 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Gu", "Tianbo", ""], ["Fang", "Zheng", ""], ["Abhishek", "Allaukik", ""], ["Fu", "Hao", ""], ["Hu", "Pengfei", ""], ["Mohapatra", "Prasant", ""]]}, {"id": "2006.15877", "submitter": "Abigail Goldsteen", "authors": "Abigail Goldsteen, Gilad Ezov, Ariel Farkash", "title": "Reducing Risk of Model Inversion Using Privacy-Guided Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models often pose a threat to the privacy of individuals\nwhose data is part of the training set. Several recent attacks have been able\nto infer sensitive information from trained models, including model inversion\nor attribute inference attacks. These attacks are able to reveal the values of\ncertain sensitive features of individuals who participated in training the\nmodel. It has also been shown that several factors can contribute to an\nincreased risk of model inversion, including feature influence. We observe that\nnot all features necessarily share the same level of privacy or sensitivity. In\nmany cases, certain features used to train a model are considered especially\nsensitive and therefore propitious candidates for inversion. We present a\nsolution for countering model inversion attacks in tree-based models, by\nreducing the influence of sensitive features in these models. This is an avenue\nthat has not yet been thoroughly investigated, with only very nascent previous\nattempts at using this as a countermeasure against attribute inference. Our\nwork shows that, in many cases, it is possible to train a model in different\nways, resulting in different influence levels of the various features, without\nnecessarily harming the model's accuracy. We are able to utilize this fact to\ntrain models in a manner that reduces the model's reliance on the most\nsensitive features, while increasing the importance of less sensitive features.\nOur evaluation confirms that training models in this manner reduces the risk of\ninference for those features, as demonstrated through several black-box and\nwhite-box attacks.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 09:02:16 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Goldsteen", "Abigail", ""], ["Ezov", "Gilad", ""], ["Farkash", "Ariel", ""]]}, {"id": "2006.15904", "submitter": "Hazel Murray", "authors": "Hazel Murray and David Malone", "title": "Multi-armed bandit approach to password guessing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-armed bandit is a mathematical interpretation of the problem a\ngambler faces when confronted with a number of different machines (bandits).\nThe gambler wants to explore different machines to discover which machine\noffers the best rewards, but simultaneously wants to exploit the most\nprofitable machine. A password guesser is faced with a similar dilemma. They\nhave lists of leaked password sets, dictionaries of words, and demographic\ninformation about the users, but they don't know which dictionary will reap the\nbest rewards. In this paper we provide a framework for using the multi-armed\nbandit problem in the context of the password guesser and use some examples to\nshow that it can be effective.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 09:50:55 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 10:43:50 GMT"}, {"version": "v3", "created": "Wed, 5 Aug 2020 16:59:09 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Murray", "Hazel", ""], ["Malone", "David", ""]]}, {"id": "2006.15998", "submitter": "Gaurav Kumar Agarwal", "authors": "Gaurav Kumar Agarwal, Mohammed Karmoose, Suhas Diggavi, Christina\n  Fragouli, Paulo Tabuada", "title": "Distortion based Light-weight Security for Cyber-Physical Systems", "comments": "arXiv admin note: substantial text overlap with arXiv:1809.04580", "journal-ref": "Transactions in Automatic Control 2020", "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Cyber-Physical Systems (CPS), inference based on communicated data is of\ncritical significance as it can be used to manipulate or damage the control\noperations by adversaries. This calls for efficient mechanisms for secure\ntransmission of data since control systems are becoming increasingly\ndistributed over larger geographical areas. Distortion based security, recently\nproposed as one candidate for secure transmissions in CPS, is not only more\nappropriate for these applications but also quite frugal in terms of prior\nrequirements on shared keys. In this paper, we propose distortion-based metrics\nto protect CPS communication and show that it is possible to confuse\nadversaries with just a few bits of pre-shared keys. In particular, we will\nshow that a linear dynamical system can communicate its state in a manner that\nprevents an eavesdropper from accurately learning the state.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 23:41:41 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Agarwal", "Gaurav Kumar", ""], ["Karmoose", "Mohammed", ""], ["Diggavi", "Suhas", ""], ["Fragouli", "Christina", ""], ["Tabuada", "Paulo", ""]]}, {"id": "2006.16057", "submitter": "Rammal Aftab", "authors": "Maria Yaseen, Rammal Aftab Ahmed, Rimsha Mahrukh", "title": "Forgery Detection in a Questioned Hyperspectral Document Image using\n  K-means Clustering", "comments": "5 pages,6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperspectral imaging allows for analysis of images in several hundred of\nspectral bands depending on the spectral resolution of the imaging sensor.\nHyperspectral document image is the one which has been captured by a\nhyperspectral camera so that the document can be observed in the different\nbands on the basis of their unique spectral signatures. To detect the forgery\nin a document various Ink mismatch detection techniques based on hyperspectral\nimaging have presented vast potential in differentiating visually similar inks.\nInks of different materials exhibit different spectral signature even if they\nhave the same color. Hyperspectral analysis of document images allows\nidentification and discrimination of visually similar inks. Based on this\nanalysis forensic experts can identify the authenticity of the document. In\nthis paper an extensive ink mismatch detection technique is presented which\nuses KMean Clustering to identify different inks on the basis of their unique\nspectral response and separates them into different clusters.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 13:51:24 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Yaseen", "Maria", ""], ["Ahmed", "Rammal Aftab", ""], ["Mahrukh", "Rimsha", ""]]}, {"id": "2006.16111", "submitter": "Volodymyr Sokolov", "authors": "Anatoly Bessalov, Evgeniy Grubiyan, Volodymyr Sokolov, Pavlo\n  Skladannyi", "title": "3- and 5-Isogenies of Supersingular Edwards Curves", "comments": null, "journal-ref": "Cybersecurity: Education, Science, Technique (ISSN: 2663-4023),\n  no. 8(4), 2020", "doi": "10.28925/2663-4023.2020.8.621", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  An analysis is made of the properties and conditions for the existence of 3-\nand 5-isogenies of complete and quadratic supersingular Edwards curves. For the\nencapsulation of keys based on the SIDH algorithm, it is proposed to use\nisogeny of minimal odd degrees 3 and 5, which allows bypassing the problem of\nsingular points of the 2nd and 4th orders, characteristic of 2-isogenies. A\nreview of the main properties of the classes of complete, quadratic, and\ntwisted Edwards curves over a simple field is given. Equations for the isogeny\nof odd degrees are reduced to a form adapted to curves in the form of\nWeierstrass. To do this, use the modified law of addition of curve points in\nthe generalized Edwards form, which preserves the horizontal symmetry of the\ncurve return points. Examples of the calculation of 3- and 5-isogenies of\ncomplete Edwards supersingular curves over small simple fields are given, and\nthe properties of the isogeny composition for their calculation with\nlarge-order kernels are discussed. Equations are obtained for upper complexity\nestimates for computing isogeny of odd degrees 3 and 5 in the classes of\ncomplete and quadratic Edwards curves in projective coordinates; algorithms are\nconstructed for calculating 3- and 5-isogenies of Edwards curves with\ncomplexity 6M + 4S and 12M + 5S, respectively. The conditions for the existence\nof supersingular complete and quadratic Edwards curves of order 4x3mx5n and\n8x3mx5n are found. Some parameters of the cryptosystem are determined when\nimplementing the SIDH algorithm at the level of quantum security of 128 bits.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 15:21:51 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Bessalov", "Anatoly", ""], ["Grubiyan", "Evgeniy", ""], ["Sokolov", "Volodymyr", ""], ["Skladannyi", "Pavlo", ""]]}, {"id": "2006.16176", "submitter": "Lichao Sun", "authors": "Lichao Sun", "title": "Natural Backdoor Attack on Text Data", "comments": "under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, advanced NLP models have seen a surge in the usage of various\napplications. This raises the security threats of the released models. In\naddition to the clean models' unintentional weaknesses, {\\em i.e.,} adversarial\nattacks, the poisoned models with malicious intentions are much more dangerous\nin real life. However, most existing works currently focus on the adversarial\nattacks on NLP models instead of positioning attacks, also named\n\\textit{backdoor attacks}. In this paper, we first propose the \\textit{natural\nbackdoor attacks} on NLP models. Moreover, we exploit the various attack\nstrategies to generate trigger on text data and investigate different types of\ntriggers based on modification scope, human recognition, and special cases.\nLast, we evaluate the backdoor attacks, and the results show the excellent\nperformance of with 100\\% backdoor attacks success rate and sacrificing of\n0.83\\% on the text classification task.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 16:40:14 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 19:06:19 GMT"}, {"version": "v3", "created": "Fri, 11 Sep 2020 14:02:48 GMT"}, {"version": "v4", "created": "Fri, 15 Jan 2021 14:07:09 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Sun", "Lichao", ""]]}, {"id": "2006.16179", "submitter": "Ram Shankar Siva Kumar", "authors": "Ram Shankar Siva Kumar, Jonathon Penney, Bruce Schneier, Kendra Albert", "title": "Legal Risks of Adversarial Machine Learning Research", "comments": "Accepted at ICML 2020 Workshop on Law & Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial Machine Learning is booming with ML researchers increasingly\ntargeting commercial ML systems such as those used in Facebook, Tesla,\nMicrosoft, IBM, Google to demonstrate vulnerabilities. In this paper, we ask,\n\"What are the potential legal risks to adversarial ML researchers when they\nattack ML systems?\" Studying or testing the security of any operational system\npotentially runs afoul the Computer Fraud and Abuse Act (CFAA), the primary\nUnited States federal statute that creates liability for hacking. We claim that\nAdversarial ML research is likely no different. Our analysis show that because\nthere is a split in how CFAA is interpreted, aspects of adversarial ML attacks,\nsuch as model inversion, membership inference, model stealing, reprogramming\nthe ML system and poisoning attacks, may be sanctioned in some jurisdictions\nand not penalized in others. We conclude with an analysis predicting how the US\nSupreme Court may resolve some present inconsistencies in the CFAA's\napplication in Van Buren v. United States, an appeal expected to be decided in\n2021. We argue that the court is likely to adopt a narrow construction of the\nCFAA, and that this will actually lead to better adversarial ML security\noutcomes in the long term.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 16:45:15 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Kumar", "Ram Shankar Siva", ""], ["Penney", "Jonathon", ""], ["Schneier", "Bruce", ""], ["Albert", "Kendra", ""]]}, {"id": "2006.16345", "submitter": "Andrea Mondelli", "authors": "Andrea Mondelli, Paul Gazzillo and Yan Solihin", "title": "SeMPE: Secure Multi Path Execution Architecture for Removing Conditional\n  Branch Side Channels", "comments": "This paper is currently under submission. We arXiv our paper to\n  establish credit for inventing this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most prevalent source of side channel vulnerabilities is the\nsecret-dependent behavior of conditional branches (SDBCB). The state-of-the-art\nsolution relies on Constant-Time Expressions, which require high programming\neffort and incur high performance overheads. In this paper, we propose SeMPE,\nan approach that relies on architecture support to eliminate SDBCB without\nrequiring much programming effort while incurring low performance overheads.\nThe key idea is that when a secret-dependent branch is encountered, the SeMPE\nmicroarchitecture fetches, executes, and commits both paths of the branch,\npreventing the adversary from inferring secret values from the branching\nbehavior of the program. To enable that, SeMPE relies on an architecture that\nis capable of safely executing both branch paths sequentially. Through\nmicrobenchmarks and an evaluation of a real-world library, we show that SeMPE\nincurs near ideal execution time overheads, which is the sum of the execution\ntime of all branch paths of secret-dependent branches. SeMPE outperforms code\ngenerated by FaCT, a constant-time expression language, by up to a factor of\n18x.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 20:06:53 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 06:44:07 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Mondelli", "Andrea", ""], ["Gazzillo", "Paul", ""], ["Solihin", "Yan", ""]]}, {"id": "2006.16374", "submitter": "George Dimitoglou", "authors": "John N. Brewer III, George Dimitoglou", "title": "Evaluation of Attack Vectors and Risks in Automobiles and Road\n  Infrastructure", "comments": null, "journal-ref": null, "doi": "10.1109/CSCI49370.2019.00021", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The evolution of smart automobiles and vehicles within the Internet of Things\n(IoT) - particularly as that evolution leads toward a proliferation of\ncompletely autonomous vehicles - has sparked considerable interest in the\nsubject of vehicle/automotive security. While the attack surface is wide, there\nare patterns of exploitable vulnerabilities. In this study we reviewed,\nclassified according to their attack surface, and evaluated some of the common\nvehicle and infrastructure attack vectors identified in the literature. To\nremediate these attack vectors, specific technical recommendations have been\nprovided as a way towards secure deployments of smart automobiles and\ntransportation infrastructures.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 20:53:35 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Brewer", "John N.", "III"], ["Dimitoglou", "George", ""]]}, {"id": "2006.16380", "submitter": "Sanchari Das", "authors": "Ploy Unchit, Sanchari Das, Andrew Kim, L. Jean Camp", "title": "Quantifying Susceptibility to Spear Phishing in a High School\n  Environment Using Signal Detection Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spear phishing is a deceptive attack that uses social engineering to obtain\nconfidential information through targeted victimization. It is distinguished by\nits use of social cues and personalized information to target specific victims.\nPrevious work on resilience to spear phishing has focused on convenience\nsamples, with a disproportionate focus on students. In contrast, here, we\nreport on an evaluation of a high school community. We engaged 57 high school\nstudents and faculty members (12 high school students, 45 staff members) as\nparticipants in research utilizing signal detection theory (SDT). Through\nscenario-based analysis, participants tasked with distinguishing phishing\nemails from authentic emails. The results revealed an overconfidence bias in\nself-detection from the participants, regardless of their technical background.\nThese findings are critical for evaluating the decision-making of\nunderrepresented populations and protecting people from potential spear\nphishing attacks by examining human susceptibility.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 20:59:54 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 12:02:05 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Unchit", "Ploy", ""], ["Das", "Sanchari", ""], ["Kim", "Andrew", ""], ["Camp", "L. Jean", ""]]}, {"id": "2006.16385", "submitter": "Wenxin Ding", "authors": "Wenxin Ding, Nihar B. Shah, Weina Wang", "title": "On the Privacy-Utility Tradeoff in Peer-Review Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major impediment to research on improving peer review is the unavailability\nof peer-review data, since any release of such data must grapple with the\nsensitivity of the peer review data in terms of protecting identities of\nreviewers from authors. We posit the need to develop techniques to release\npeer-review data in a privacy-preserving manner. Identifying this problem, in\nthis paper we propose a framework for privacy-preserving release of certain\nconference peer-review data -- distributions of ratings, miscalibration, and\nsubjectivity -- with an emphasis on the accuracy (or utility) of the released\ndata. The crux of the framework lies in recognizing that a part of the data\npertaining to the reviews is already available in public, and we use this\ninformation to post-process the data released by any privacy mechanism in a\nmanner that improves the accuracy (utility) of the data while retaining the\nprivacy guarantees. Our framework works with any privacy-preserving mechanism\nthat operates via releasing perturbed data. We present several positive and\nnegative theoretical results, including a polynomial-time algorithm for\nimproving on the privacy-utility tradeoff.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 21:08:21 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Ding", "Wenxin", ""], ["Shah", "Nihar B.", ""], ["Wang", "Weina", ""]]}, {"id": "2006.16469", "submitter": "Fnu Suya", "authors": "Fnu Suya, Saeed Mahloujifar, Anshuman Suri, David Evans, Yuan Tian", "title": "Model-Targeted Poisoning Attacks with Provable Convergence", "comments": "32 pages, code available at:\n  https://github.com/suyeecav/model-targeted-poisoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a poisoning attack, an adversary with control over a small fraction of the\ntraining data attempts to select that data in a way that induces a corrupted\nmodel that misbehaves in favor of the adversary. We consider poisoning attacks\nagainst convex machine learning models and propose an efficient poisoning\nattack designed to induce a specified model. Unlike previous model-targeted\npoisoning attacks, our attack comes with provable convergence to {\\it any}\nattainable target classifier. The distance from the induced classifier to the\ntarget classifier is inversely proportional to the square root of the number of\npoisoning points. We also provide a lower bound on the minimum number of\npoisoning points needed to achieve a given target classifier. Our method uses\nonline convex optimization, so finds poisoning points incrementally. This\nprovides more flexibility than previous attacks which require a priori\nassumption about the number of poisoning points. Our attack is the first\nmodel-targeted poisoning attack that provides provable convergence for convex\nmodels, and in our experiments, it either exceeds or matches state-of-the-art\nattacks in terms of attack success rate and distance to the target model.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 01:56:35 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 13:40:37 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Suya", "Fnu", ""], ["Mahloujifar", "Saeed", ""], ["Suri", "Anshuman", ""], ["Evans", "David", ""], ["Tian", "Yuan", ""]]}, {"id": "2006.16535", "submitter": "You Wu", "authors": "You Wu, Xuehai Qian", "title": "A Case for Reversible Coherence Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the first Reversible Coherence Protocol (RCP), a new protocol\ndesigned from ground up that enables invisible speculative load. RCP takes a\nbold approach by including the speculative loads and merge/purge operation in\nthe interface between processor and cache coherence, and allowing them to\nparticipate in the coherence protocol. It means, speculative load, ordinary\nload/store, and merge/purge can all affect the state of a given cache line. RCP\nis the first coherence protocol that enables the commit and squash of the\nspeculative load among distributed cache components in a general memory\nhierarchy. RCP incurs an average slowdown of (3.0%,8.3%,7.4%) on\n(SPEC2006,SPEC2017,PARSEC), which is lower compared to (26.5%,12%,18.3%) in\nInvisiSpec and (3.2%,9.4%,24.2%) in CleanupSpec. The coherence traffic overhead\nis on average 46%, compared to 40% and 27% of InvisiSpec and CleanupSpec,\nrespectively. Even with higher traffic overhead (~46%), the performance\noverhead of RCP is lower than InvisiSpec and comparable to CleanupSpec. It\nreveals a key advantage of RCP: the coherence actions triggered by the merge\nand purge operations are not in the critical path of the execution and can be\nperformed in the cache hierarchy concurrently with processor execution\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 05:16:51 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2021 01:11:12 GMT"}, {"version": "v3", "created": "Sat, 10 Jul 2021 00:21:42 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wu", "You", ""], ["Qian", "Xuehai", ""]]}, {"id": "2006.16545", "submitter": "Deqiang Li", "authors": "Deqiang Li and Qianmu Li", "title": "Adversarial Deep Ensemble: Evasion Attacks and Defenses for Malware\n  Detection", "comments": "D. Li and Q. Li, \"Adversarial Deep Ensemble: Evasion Attacks and\n  Defenses for Malware Detection,\" in IEEE Transactions on Information\n  Forensics and Security (early access)", "journal-ref": null, "doi": "10.1109/TIFS.2020.3003571", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware remains a big threat to cyber security, calling for machine learning\nbased malware detection. While promising, such detectors are known to be\nvulnerable to evasion attacks. Ensemble learning typically facilitates\ncountermeasures, while attackers can leverage this technique to improve attack\neffectiveness as well. This motivates us to investigate which kind of\nrobustness the ensemble defense or effectiveness the ensemble attack can\nachieve, particularly when they combat with each other. We thus propose a new\nattack approach, named mixture of attacks, by rendering attackers capable of\nmultiple generative methods and multiple manipulation sets, to perturb a\nmalware example without ruining its malicious functionality. This naturally\nleads to a new instantiation of adversarial training, which is further geared\nto enhancing the ensemble of deep neural networks. We evaluate defenses using\nAndroid malware detectors against 26 different attacks upon two practical\ndatasets. Experimental results show that the new adversarial training\nsignificantly enhances the robustness of deep neural networks against a wide\nrange of attacks, ensemble methods promote the robustness when base classifiers\nare robust enough, and yet ensemble attacks can evade the enhanced malware\ndetectors effectively, even notably downgrading the VirusTotal service.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 05:56:33 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Li", "Deqiang", ""], ["Li", "Qianmu", ""]]}, {"id": "2006.16554", "submitter": "Tianbo Gu", "authors": "Debraj Basu, Tianbo Gu, Prasant Mohapatra", "title": "Security Issues of Low Power Wide Area Networks in the Context of LoRa\n  Networks", "comments": "17 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low Power Wide Area Networks (LPWAN) have been used to support low cost and\nmobile bi-directional communications for the Internet of Things (IoT), smart\ncity and a wide range of industrial applications. A primary security concern of\nLPWAN technology is the attacks that block legitimate communication between\nnodes resulting in scenarios like loss of packets, delayed packet arrival, and\nskewed packet reaching the reporting gateway. LoRa (Long Range) is a promising\nwireless radio access technology that supports long-range communication at low\ndata rates and low power consumption. LoRa is considered as one of the ideal\ncandidates for building LPWANs. We use LoRa as a reference technology to review\nthe IoT security threats on the air and the applicability of different\ncountermeasures that have been adopted so far. LoRa nodes that are close to the\ngateway use a small SF than the nodes which are far away. But it also implies\nlong in-the-air transmission time, which makes the transmitted packets\nvulnerable to different kinds of malicious attacks, especially in the physical\nand the link layer. Therefore, it is not possible to enforce a fixed set of\nrules for all LoRa nodes since they have different levels of vulnerabilities.\nOur survey reveals that there is an urgent need for secure and uninterrupted\ncommunication between an end-device and the gateway, especially when the threat\nmodels are unknown in advance. We explore the traditional countermeasures and\nfind that most of them are ineffective now, such as frequency hopping and\nspread spectrum methods. In order to adapt to new threats, the emerging\ncountermeasures using game-theoretic approaches and reinforcement machine\nlearning methods can effectively identify threats and dynamically choose the\ncorresponding actions to resist threats, thereby making secured and reliable\ncommunications.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 06:30:30 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Basu", "Debraj", ""], ["Gu", "Tianbo", ""], ["Mohapatra", "Prasant", ""]]}, {"id": "2006.16601", "submitter": "Andrea Fioraldi", "authors": "Andrea Fioraldi", "title": "Symbolic Execution and Debugging Synchronization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this thesis, we introduce the idea of combining symbolic execution with\ndynamic analysis for reverse engineering. Differently from DSE, we devise an\napproach where the reverse engineer can use a debugger to drive and inspect a\nconcrete execution engine of the application code and then, when needed,\ntransfer the execution into a symbolic executor in order to automatically\nidentify the input values required to reach a target point in the code. After\nthat, the user can also transfer back the correct input values found with\nsymbolic execution in order to continue the debugging. The synchronization\nbetween a debugger and a symbolic executor can enhance manual dynamic analysis\nand allow a reverser to easily solve small portions of code without leaving the\ndebugger. We implemented a synchronization mechanism on top of the binary\nanalysis framework angr, allowing for transferring the state of the debugged\nprocess to the angr environment and back. The backend library is debugger\nagnostic and can be extended to work with various frontends. We implemented a\nfrontend for the IDA Pro debugger and one for the GNU Debugger, which are both\nwidely popular among reverse engineers.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 08:29:55 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Fioraldi", "Andrea", ""]]}, {"id": "2006.16611", "submitter": "Tyng-Luh Liu", "authors": "Yu-Chen Ho, Yi-Hsuan Chen, Shen-Hua Hung, Chien-Hao Huang, Poga Po,\n  Chung-Hsi Chan, Di-Kai Yang, Yi-Chin Tu, Tyng-Luh Liu and Chi-Tai Fang", "title": "Social Distancing 2.0 with Privacy-Preserving Contact Tracing to Avoid a\n  Second Wave of COVID-19", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to avoid a second wave of COVID-19 after reopening the economy is a\npressing question. The extremely high basic reproductive number $R_0$ (5.7 to\n6.4, shown in new studies) of SARS-CoV-2 further complicates the challenge.\nHere we assess effects of Social distancing 2.0, i.e. proximity alert (to\nmaintain inter-personal distance) plus privacy-preserving contact tracing. To\nsolve the dual task, we developed an open source mobile app. The app uses a\nBluetooth-based, decentralized contact tracing platform over which the\nanonymous user ID cannot be linked by the government or a third party.\nModelling results show that a 50\\% adoption rate of Social distancing 2.0, with\nprivacy-preserving contact tracing, would suffice to decrease the $R_0$ to less\nthan 1 and prevent the resurgence of COVID-19 epidemic.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 09:06:01 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 03:19:36 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Ho", "Yu-Chen", ""], ["Chen", "Yi-Hsuan", ""], ["Hung", "Shen-Hua", ""], ["Huang", "Chien-Hao", ""], ["Po", "Poga", ""], ["Chan", "Chung-Hsi", ""], ["Yang", "Di-Kai", ""], ["Tu", "Yi-Chin", ""], ["Liu", "Tyng-Luh", ""], ["Fang", "Chi-Tai", ""]]}, {"id": "2006.16625", "submitter": "In-Jae Yu", "authors": "In-Jae Yu, Wonhyuk Ahn, Seung-Hun Nam, Heung-Kyu Lee", "title": "BitMix: Data Augmentation for Image Steganalysis", "comments": null, "journal-ref": null, "doi": "10.1049/el.2020.1951", "report-no": null, "categories": "eess.IV cs.CR cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNN) for image steganalysis demonstrate better\nperformances with employing concepts from high-level vision tasks. The major\nemployed concept is to use data augmentation to avoid overfitting due to\nlimited data. To augment data without damaging the message embedding, only\nrotating multiples of 90 degrees or horizontally flipping are used in\nsteganalysis, which generates eight fixed results from one sample. To overcome\nthis limitation, we propose BitMix, a data augmentation method for spatial\nimage steganalysis. BitMix mixes a cover and stego image pair by swapping the\nrandom patch and generates an embedding adaptive label with the ratio of the\nnumber of pixels modified in the swapped patch to those in the cover-stego\npair. We explore optimal hyperparameters, the ratio of applying BitMix in the\nmini-batch, and the size of the bounding box for swapping patch. The results\nreveal that using BitMix improves the performance of spatial image steganalysis\nand better than other data augmentation methods.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 09:36:21 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Yu", "In-Jae", ""], ["Ahn", "Wonhyuk", ""], ["Nam", "Seung-Hun", ""], ["Lee", "Heung-Kyu", ""]]}, {"id": "2006.16640", "submitter": "Grzegorz Blinowski", "authors": "Grzegorz J. Blinowski and Pawe{\\l} Piotrowski", "title": "CVE based classification of vulnerable IoT systems", "comments": "A shorter version of this paper was published in Proc. of the\n  DepCoS-RELCOMEX conference", "journal-ref": "Theory and Applications of Dependable Computer Systems,\n  Proceedings of the Fifteenth International Conference on Dependability of\n  Computer Systems DepCoS-RELCOMEX, June 29 - July 3, 2020, Brunow, Poland;\n  ISBN 978-3-030-48256-5", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Common Vulnerabilities and Exposures database (CVE) is one of the largest\npublicly available source of software and hardware vulnerability data and\nreports. In this work we analyze the CVE database in the context of IoT device\nand system vulnerabilities. We introduce a real-world based classification of\nIoT systems. Then, we employ a SVM algorithm on selected subset of CVE database\nto classify \"new\" vulnerability records in this framework. The subset of\ninterest consists of records that describe vulnerabilities of potential IoT\ndevices of different applications, such as: home, industry, mobile controllers,\nnetworking, etc. The purpose of the classification is to develop and test an\nautomatic system for recognition of vulnerable IoT devices and to test\ncompletes, sufficiency and reliability of CVE data in this respect.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 10:05:09 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Blinowski", "Grzegorz J.", ""], ["Piotrowski", "Pawe\u0142", ""]]}, {"id": "2006.16714", "submitter": "Jacob Swambo MSci", "authors": "Jacob Swambo and Spencer Hommel and Bob McElrath and Bryan Bishop", "title": "Bitcoin Covenants: Three Ways to Control the Future", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A bitcoin covenant is a mechanism to enforce conditions on how the control of\ncoins will be transferred in the future. This work introduces deleted-key\ncovenants; using pre-signed transactions with secure key deletion. With this, a\ngeneral class of covenants are possible without introducing new security risks\nto bitcoin. There is a range of security models for the key deletion process,\nbut this is subject to a security-convenience trade-off and requires\ninteractivity in a multi-party context. On the other hand, this work makes a\ncompelling case for what can be gained through a soft-fork upgrade to the\nsignature hash system [Dec17] which enables recovered-key covenants through\nelliptic curve key recovery. This has similar properties to script-based\ncovenant mechanisms proposed previously [Rub20]. Key factors are discussed and\ncompared for the three covenant mechanisms, including; the enforcement process,\nmethods for proving accessibility of funds and whether or not they are bound by\na covenant, methods for dynamic fee allocation, the underlying cryptographic\nassumptions, and their feasibility in single-party, hierarchical and\nadversarial multi-party contexts. Despite the relative downsides of deleted-key\ncovenants, they are a practical tool for custody protocol design. The\ncomparison shows precisely how soft-fork proposals improve the practicality of\nbitcoin covenants, through non-interactive enforcement and tighter\ncryptographic assumptions, to enhance custody protocols and enable some\nadversarial applications such as payment protocols.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 12:12:17 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Swambo", "Jacob", ""], ["Hommel", "Spencer", ""], ["McElrath", "Bob", ""], ["Bishop", "Bryan", ""]]}, {"id": "2006.16849", "submitter": "Beatrice Perez", "authors": "Beatrice Perez, Sara R. Machado, Jerone T. A. Andrews, Nicolas\n  Kourtellis", "title": "I call BS: Fraud Detection in Crowdfunding Campaigns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Donations to charity-based crowdfunding environments have been on the rise in\nthe last few years. Unsurprisingly, deception and fraud in such platforms have\nalso increased, but have not been thoroughly studied to understand what\ncharacteristics can expose such behavior and allow its automatic detection and\nblocking. Indeed, crowdfunding platforms are the only ones typically performing\noversight for the campaigns launched in each service. However, they are not\nproperly incentivized to combat fraud among users and the campaigns they\nlaunch: on the one hand, a platform's revenue is directly proportional to the\nnumber of transactions performed (since the platform charges a fixed amount per\ndonation); on the other hand, if a platform is transparent with respect to how\nmuch fraud it has, it may discourage potential donors from participating.\n  In this paper, we take the first step in studying fraud in crowdfunding\ncampaigns. We analyze data collected from different crowdfunding platforms, and\nannotate 700 campaigns as fraud or not. We compute various textual and\nimage-based features and study their distributions and how they associate with\ncampaign fraud. Using these attributes, we build machine learning classifiers,\nand show that it is possible to automatically classify such fraudulent behavior\nwith up to 90.14% accuracy and 96.01% AUC, only using features available from\nthe campaign's description at the moment of publication (i.e., with no user or\nmoney activity), making our method applicable for real-time operation on a user\nbrowser.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 14:38:21 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Perez", "Beatrice", ""], ["Machado", "Sara R.", ""], ["Andrews", "Jerone T. A.", ""], ["Kourtellis", "Nicolas", ""]]}, {"id": "2006.16921", "submitter": "Jiska Classen", "authors": "J\\\"orn Tillmanns, Jiska Classen, Felix Rohrbach, Matthias Hollick", "title": "Firmware Insider: Bluetooth Randomness is Mostly Random", "comments": "WOOT'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bluetooth chips must include a Random Number Generator (RNG). This RNG is\nused internally within cryptographic primitives but also exposed to the\noperating system for chip-external applications. In general, it is a black box\nwith security-critical authentication and encryption mechanisms depending on\nit. In this paper, we evaluate the quality of RNGs in various Broadcom and\nCypress Bluetooth chips. We find that the RNG implementation significantly\nchanged over the last decade. Moreover, most devices implement an insecure\nPseudo-Random Number Generator (PRNG) fallback. Multiple popular devices, such\nas the Samsung Galaxy S8 and its variants as well as an iPhone, rely on the\nweak fallback due to missing a Hardware Random Number Generator (HRNG). We\nstatistically evaluate the output of various HRNGs in chips used by hundreds of\nmillions of devices. While the Broadcom and Cypress HRNGs pass advanced tests,\nit remains indistinguishable for users if a Bluetooth chip implements a secure\nRNG without an extensive analysis as in this paper. We describe our measurement\nmethods and publish our tools to enable further public testing.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 15:51:39 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Tillmanns", "J\u00f6rn", ""], ["Classen", "Jiska", ""], ["Rohrbach", "Felix", ""], ["Hollick", "Matthias", ""]]}, {"id": "2006.16974", "submitter": "Jiachen Sun", "authors": "Jiachen Sun, Yulong Cao, Qi Alfred Chen, Z. Morley Mao", "title": "Towards Robust LiDAR-based Perception in Autonomous Driving: General\n  Black-box Adversarial Sensor Attack and Countermeasures", "comments": "18 pages, 27 figures, to be published in USENIX Security 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perception plays a pivotal role in autonomous driving systems, which utilizes\nonboard sensors like cameras and LiDARs (Light Detection and Ranging) to assess\nsurroundings. Recent studies have demonstrated that LiDAR-based perception is\nvulnerable to spoofing attacks, in which adversaries spoof a fake vehicle in\nfront of a victim self-driving car by strategically transmitting laser signals\nto the victim's LiDAR sensor. However, existing attacks suffer from\neffectiveness and generality limitations. In this work, we perform the first\nstudy to explore the general vulnerability of current LiDAR-based perception\narchitectures and discover that the ignored occlusion patterns in LiDAR point\nclouds make self-driving cars vulnerable to spoofing attacks. We construct the\nfirst black-box spoofing attack based on our identified vulnerability, which\nuniversally achieves around 80% mean success rates on all target models. We\nperform the first defense study, proposing CARLO to mitigate LiDAR spoofing\nattacks. CARLO detects spoofed data by treating ignored occlusion patterns as\ninvariant physical features, which reduces the mean attack success rate to\n5.5%. Meanwhile, we take the first step towards exploring a general\narchitecture for robust LiDAR-based perception, and propose SVF that embeds the\nneglected physical features into end-to-end learning. SVF further reduces the\nmean attack success rate to around 2.3%.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 17:07:45 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Sun", "Jiachen", ""], ["Cao", "Yulong", ""], ["Chen", "Qi Alfred", ""], ["Mao", "Z. Morley", ""]]}]